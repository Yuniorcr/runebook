<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="c543b3c390ed1ce750f7a99ce30092a4fe11d2d6" translate="yes" xml:space="preserve">
          <source>NaN values in &lt;code&gt;grid&lt;/code&gt; would be interpreted as &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;grid&lt;/code&gt; 内のNaN値は &lt;code&gt;-1&lt;/code&gt; として解釈されます。</target>
        </trans-unit>
        <trans-unit id="709a23220f2c3d64d1e1d6d18c4d5280f8d82fca" translate="yes" xml:space="preserve">
          <source>Name</source>
          <target state="translated">Name</target>
        </trans-unit>
        <trans-unit id="0585ffb115d09e675d597261b20f2d75a3eb03a7" translate="yes" xml:space="preserve">
          <source>Name propagation semantics</source>
          <target state="translated">名前の伝播のセマンティクス</target>
        </trans-unit>
        <trans-unit id="817cc3c2ad5448f94a4d253bbcac8dd6cc2d1cf9" translate="yes" xml:space="preserve">
          <source>Named Tensors</source>
          <target state="translated">ネームドテンソル</target>
        </trans-unit>
        <trans-unit id="e90e823237a9f4d7fe13c9da511106ba9aee2f03" translate="yes" xml:space="preserve">
          <source>Named Tensors allow users to give explicit names to tensor dimensions. In most cases, operations that take dimension parameters will accept dimension names, avoiding the need to track dimensions by position. In addition, named tensors use names to automatically check that APIs are being used correctly at runtime, providing extra safety. Names can also be used to rearrange dimensions, for example, to support &amp;ldquo;broadcasting by name&amp;rdquo; rather than &amp;ldquo;broadcasting by position&amp;rdquo;.</source>
          <target state="translated">名前付きテンソルを使用すると、ユーザーはテンソル次元に明示的な名前を付けることができます。ほとんどの場合、ディメンションパラメータを受け取る操作はディメンション名を受け入れ、位置ごとにディメンションを追跡する必要がなくなります。さらに、名前付きテンソルは名前を使用して、実行時にAPIが正しく使用されていることを自動的にチェックし、安全性を高めます。名前を使用してディメンションを再配置することもできます。たとえば、「位置によるブロードキャスト」ではなく「名前によるブロードキャスト」をサポートします。</target>
        </trans-unit>
        <trans-unit id="6e3e9a74ab4dd7c6ec7d57c873cd59674e123d29" translate="yes" xml:space="preserve">
          <source>Named Tensors operator coverage</source>
          <target state="translated">ネームドテンソルのオペレータカバレッジ</target>
        </trans-unit>
        <trans-unit id="00f19d99a1a121465f53068cd3e37c47ef1fad72" translate="yes" xml:space="preserve">
          <source>Named Tuples</source>
          <target state="translated">名前付きタプル</target>
        </trans-unit>
        <trans-unit id="d906a9f233a4d60e7ff3266a36abd411378985f0" translate="yes" xml:space="preserve">
          <source>Named dimensions</source>
          <target state="translated">名前付き寸法</target>
        </trans-unit>
        <trans-unit id="d69a85347956dd430a196f336efedfda312c73cf" translate="yes" xml:space="preserve">
          <source>Named dimensions, like regular Tensor dimensions, are ordered. &lt;code&gt;tensor.names[i]&lt;/code&gt; is the name of dimension &lt;code&gt;i&lt;/code&gt; of &lt;code&gt;tensor&lt;/code&gt;.</source>
          <target state="translated">通常のテンソル次元と同様に、名前付き次元が順序付けられます。 &lt;code&gt;tensor.names[i]&lt;/code&gt; は、 &lt;code&gt;tensor&lt;/code&gt; の次元 &lt;code&gt;i&lt;/code&gt; の名前です。</target>
        </trans-unit>
        <trans-unit id="87ade27d950d661d18340b5de9b3d2e0c2886884" translate="yes" xml:space="preserve">
          <source>Named tensor API reference</source>
          <target state="translated">名前付きテンソルAPIリファレンス</target>
        </trans-unit>
        <trans-unit id="554d6e43a251766628f65b287dfa2b6bb568c6f8" translate="yes" xml:space="preserve">
          <source>Named tensors can coexist with unnamed tensors; named tensors are instances of &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;. Unnamed tensors have &lt;code&gt;None&lt;/code&gt;-named dimensions. Named tensors do not require all dimensions to be named.</source>
          <target state="translated">名前付きテンソルは名前なしテンソルと共存できます。名前付きテンソルは&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; の&lt;/a&gt;インスタンスです。名前テンソルは持っている &lt;code&gt;None&lt;/code&gt; -named寸法を。名前付きテンソルは、すべての次元に名前を付ける必要はありません。</target>
        </trans-unit>
        <trans-unit id="9babc66ca4089f8e16cccf70d5e5125ac942af22" translate="yes" xml:space="preserve">
          <source>Named tensors use names to automatically check that APIs are being called correctly at runtime. This occurs in a process called &lt;em&gt;name inference&lt;/em&gt;. More formally, name inference consists of the following two steps:</source>
          <target state="translated">名前付きテンソルは、名前を使用して、実行時にAPIが正しく呼び出されていることを自動的に確認します。これは、&lt;em&gt;名前の推論&lt;/em&gt;と呼ばれるプロセスで発生します。より正式には、名前の推論は次の2つのステップで構成されます。</target>
        </trans-unit>
        <trans-unit id="bc702e382ad1ddf0605ed2f8380fd2e579529d82" translate="yes" xml:space="preserve">
          <source>Namely, joining processes sequentially implies they will terminate sequentially. If they don&amp;rsquo;t, and the first process does not terminate, the process termination will go unnoticed. Also, there are no native facilities for error propagation.</source>
          <target state="translated">つまり、プロセスを順次結合することは、プロセスが順次終了することを意味します。そうでない場合、最初のプロセスが終了しないと、プロセスの終了は見過ごされます。また、エラー伝播のためのネイティブ機能はありません。</target>
        </trans-unit>
        <trans-unit id="ce14504f9d8c7c9312b2871ff6009782be1ad451" translate="yes" xml:space="preserve">
          <source>Nathan Halko, Per-Gunnar Martinsson, and Joel Tropp, Finding structure with randomness: probabilistic algorithms for constructing approximate matrix decompositions, arXiv:0909.4061 [math.NA; math.PR], 2009 (available at &lt;a href=&quot;https://arxiv.org/abs/0909.4061&quot;&gt;arXiv&lt;/a&gt;).</source>
          <target state="translated">Nathan Halko、Per-Gunnar Martinsson、およびJoel Tropp、ランダム性のある構造の検索：近似行列分解を構築するための確率的アルゴリズム、arXiv：0909.4061 [math.NA; math.PR]、2009（&lt;a href=&quot;https://arxiv.org/abs/0909.4061&quot;&gt;arXivで&lt;/a&gt;入手可能）。</target>
        </trans-unit>
        <trans-unit id="1589b41367a72480492d7a5904aab37522c48d37" translate="yes" xml:space="preserve">
          <source>Negative log likelihood loss with Poisson distribution of target.</source>
          <target state="translated">目標のポアソン分布を持つ負の対数尤度損失。</target>
        </trans-unit>
        <trans-unit id="e2c678e1dc9e8fcb17d534c7469483a491efdcab" translate="yes" xml:space="preserve">
          <source>NegativeBinomial</source>
          <target state="translated">NegativeBinomial</target>
        </trans-unit>
        <trans-unit id="b7f2cb3940a28574771032f71b83c2599f143244" translate="yes" xml:space="preserve">
          <source>Neither &lt;code&gt;sampler&lt;/code&gt; nor &lt;code&gt;batch_sampler&lt;/code&gt; is compatible with iterable-style datasets, since such datasets have no notion of a key or an index.</source>
          <target state="translated">&lt;code&gt;sampler&lt;/code&gt; も &lt;code&gt;batch_sampler&lt;/code&gt; も、反復可能なスタイルのデータセットと互換性がありません。そのようなデータセットにはキーやインデックスの概念がないためです。</target>
        </trans-unit>
        <trans-unit id="9821f42c2d297ad4796746e3fa14e55cb3e99e22" translate="yes" xml:space="preserve">
          <source>Nesterov momentum is based on the formula from &lt;a href=&quot;http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf&quot;&gt;On the importance of initialization and momentum in deep learning&lt;/a&gt;.</source>
          <target state="translated">ネステロフの運動量は&lt;a href=&quot;http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf&quot;&gt;、深層学習における初期化と運動量の重要性&lt;/a&gt;についての式に基づいています。</target>
        </trans-unit>
        <trans-unit id="53ebc572b4a44802ba114729f07bdaaf5409a9d7" translate="yes" xml:space="preserve">
          <source>Network</source>
          <target state="translated">Network</target>
        </trans-unit>
        <trans-unit id="813b5b686d397a3b63ce050a22e4bcaa735af1e8" translate="yes" xml:space="preserve">
          <source>New API:</source>
          <target state="translated">新しいAPIです。</target>
        </trans-unit>
        <trans-unit id="cc7e29ed592d2dbd4407e7babc4a099e18fb72ad" translate="yes" xml:space="preserve">
          <source>New distribution instance with batch dimensions expanded to &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="translated">バッチディメンションが &lt;code&gt;batch_size&lt;/code&gt; に拡張された新しい配布インスタンス。</target>
        </trans-unit>
        <trans-unit id="540f7186c4d530bac579f69bb157fd5e121529cc" translate="yes" xml:space="preserve">
          <source>NewType</source>
          <target state="translated">NewType</target>
        </trans-unit>
        <trans-unit id="0013bf26fef8048809165bc5fc20da2af938e96c" translate="yes" xml:space="preserve">
          <source>No expressions except method definitions are allowed in the body of the class.</source>
          <target state="translated">クラスのボディ内ではメソッド定義以外の表現はできません。</target>
        </trans-unit>
        <trans-unit id="7a05537029cdbc40cf12ae1af3fd5798f2e0fb52" translate="yes" xml:space="preserve">
          <source>No support for inheritance or any other polymorphism strategy, except for inheriting from &lt;code&gt;object&lt;/code&gt; to specify a new-style class.</source>
          <target state="translated">新しいスタイルのクラスを指定するために &lt;code&gt;object&lt;/code&gt; から継承することを除いて、継承またはその他のポリモーフィズム戦略はサポートされていません。</target>
        </trans-unit>
        <trans-unit id="16585665bdbf85c2a46ca04dcdf6f3b3c87a4c04" translate="yes" xml:space="preserve">
          <source>No, but the exporter will try to handle that part. Scalars are converted to constant tensors in ONNX. The exporter will try to figure out the right datatype for scalars. However for cases that it failed to do so, you will need to manually provide the datatype information. This often happens with scripted models, where the datatypes are not recorded. We are trying to improve the datatype propagation in the exporter such that manual changes are not required in the future.</source>
          <target state="translated">いいえ、しかし、エクスポータはその部分を処理しようとします。スカラはONNXでは定数テンソルに変換されます。エクスポータはスカラに適したデータ型を見つけようとします。しかし、それに失敗した場合は、データ型情報を手動で提供する必要があります。これは、データ型が記録されていないスクリプトモデルでよく発生します。将来的に手動での変更が必要ないように、エクスポータでのデータ型の伝播を改善しようとしています。</target>
        </trans-unit>
        <trans-unit id="3a122cf075b0ba371ed052ceb0f012b712c9d692" translate="yes" xml:space="preserve">
          <source>Node 1: &lt;em&gt;(IP: 192.168.1.1, and has a free port: 1234)&lt;/em&gt;</source>
          <target state="translated">ノード1：&lt;em&gt;（IP：192.168.1.1、空きポート：1234）&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="d7c20c7d93b71387bce45a0f532f94aceec659b1" translate="yes" xml:space="preserve">
          <source>Node 2:</source>
          <target state="translated">ノード2。</target>
        </trans-unit>
        <trans-unit id="2200871a1ac28c0b5dd797edb44ce5069b3ba408" translate="yes" xml:space="preserve">
          <source>Nominal typing is in development, but structural typing is not</source>
          <target state="translated">名目型付けは開発中ですが、構造型付けは開発中ではありません。</target>
        </trans-unit>
        <trans-unit id="56c04398e9678198426e682b1f9d96427b74b23b" translate="yes" xml:space="preserve">
          <source>Nominal vs structural subtyping</source>
          <target state="translated">名目と構造のサブタイプ</target>
        </trans-unit>
        <trans-unit id="b89eadfaef5d8d82b020885869aa96878170cfaa" translate="yes" xml:space="preserve">
          <source>Non-ATen operators</source>
          <target state="translated">非ATenオペレータ</target>
        </trans-unit>
        <trans-unit id="05ac3d4369dff83cd256460b1c7ab61b3d6873b9" translate="yes" xml:space="preserve">
          <source>Non-linear Activations (other)</source>
          <target state="translated">非線形活性化(その他</target>
        </trans-unit>
        <trans-unit id="37e8f09f37b4ba586b29c8d43264a706f392c534" translate="yes" xml:space="preserve">
          <source>Non-linear Activations (weighted sum, nonlinearity)</source>
          <target state="translated">非線形活性化(加重和、非線形性</target>
        </trans-unit>
        <trans-unit id="90f4c5f6b363fba151454b4dc3811eace77006ea" translate="yes" xml:space="preserve">
          <source>Non-linear activation functions</source>
          <target state="translated">非線形活性化関数</target>
        </trans-unit>
        <trans-unit id="32cfd0f165a52f907e24f0d0d41b54665a307df6" translate="yes" xml:space="preserve">
          <source>Non-local variables are resolved to Python values at compile time when the function is defined. These values are then converted into TorchScript values using the rules described in &lt;a href=&quot;#use-of-python-values&quot;&gt;Use of Python Values&lt;/a&gt;.</source>
          <target state="translated">Non-local variables are resolved to Python values at compile time when the function is defined. These values are then converted into TorchScript values using the rules described in &lt;a href=&quot;#use-of-python-values&quot;&gt;Use of Python Values&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="8acafd3007c1ab1f15fdb73fa725fb8e794923ba" translate="yes" xml:space="preserve">
          <source>None if &lt;code&gt;join&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;ProcessContext&lt;/code&gt; if &lt;code&gt;join&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">場合なし &lt;code&gt;join&lt;/code&gt; ありません &lt;code&gt;True&lt;/code&gt; 、 &lt;code&gt;ProcessContext&lt;/code&gt; あれば &lt;code&gt;join&lt;/code&gt; ている &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ab71bc2480c32bc39f483a12c34cd4676886028d" translate="yes" xml:space="preserve">
          <source>None, module is modified inplace with added observer modules and forward_hooks</source>
          <target state="translated">なし、モジュールはオブザーバーモジュールとforward_hooksを追加してインプレースで修正されています。</target>
        </trans-unit>
        <trans-unit id="e4fa32a75bd8c135dd060f289888f83fb70a2d47" translate="yes" xml:space="preserve">
          <source>None, module is modified inplace with qconfig attached</source>
          <target state="translated">なし、モジュールは qconfig が添付された状態でインプレースで修正されています。</target>
        </trans-unit>
        <trans-unit id="45e118d0563ea8581f830f46e85b60ae714faae4" translate="yes" xml:space="preserve">
          <source>Normal</source>
          <target state="translated">Normal</target>
        </trans-unit>
        <trans-unit id="46e38cc5e7e0b2b170857112460a732303fdb5e3" translate="yes" xml:space="preserve">
          <source>Normalization Layers</source>
          <target state="translated">正規化レイヤー</target>
        </trans-unit>
        <trans-unit id="746e3a4c0d98d2df15064221df23fa7793e56038" translate="yes" xml:space="preserve">
          <source>Normalization functions</source>
          <target state="translated">正規化機能</target>
        </trans-unit>
        <trans-unit id="c4639d9330cdd597089734b95310026444f4de7e" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifft&quot;&gt; &lt;code&gt;ifft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="fae17255f7a6267cdf6f973a75edad225dcf4d82" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifftn&quot;&gt;&lt;code&gt;ifftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifftn&quot;&gt; &lt;code&gt;ifftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="37141e0de089638ade05f2fc80c5c6e1a4b3e953" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ihfft&quot;&gt;&lt;code&gt;ihfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ihfft&quot;&gt; &lt;code&gt;ihfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="d960941bb7a853f66a4f14f14d7f53d0f7022466" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="7b81cd890e0116574dbf7776b7567225bd21e39c" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfftn&quot;&gt;&lt;code&gt;irfftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfftn&quot;&gt; &lt;code&gt;irfftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="e18f2dcd89118b40d295cc2d0f570dae9ee63571" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="20885ecc112a0654f2fd1749899c2aade057f18f" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fftn&quot;&gt;&lt;code&gt;fftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fftn&quot;&gt; &lt;code&gt;fftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="36f2290f1751dd4fd40961edc0b9d58c6d126bef" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.hfft&quot;&gt;&lt;code&gt;hfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.hfft&quot;&gt; &lt;code&gt;hfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="f07c249cb9e5f2751b249e4c52c89f4d38befc44" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="d3864acfcc3775dda73f1b742d452bc185e4b45c" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfftn&quot;&gt; &lt;code&gt;rfftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="290617bd60b4381fb793ad7f08e51d3f4c292b8a" translate="yes" xml:space="preserve">
          <source>Normally, the only way users interact with functions is by creating subclasses and defining new operations. This is a recommended way of extending torch.autograd.</source>
          <target state="translated">通常、ユーザーが関数を操作する方法は、サブクラスを作成して新しい操作を定義することだけです。これは、torch.autogradを拡張する際に推奨される方法です。</target>
        </trans-unit>
        <trans-unit id="ac15bca5bbea06cd32f056c8cbf634e4f1faea41" translate="yes" xml:space="preserve">
          <source>Not implemented</source>
          <target state="translated">未実装</target>
        </trans-unit>
        <trans-unit id="df8f8315e0c299c571aa4226e66410f1097a424b" translate="yes" xml:space="preserve">
          <source>Not providing a value for &lt;code&gt;steps&lt;/code&gt; is deprecated. For backwards compatibility, not providing a value for &lt;code&gt;steps&lt;/code&gt; will create a tensor with 100 elements. Note that this behavior is not reflected in the documented function signature and should not be relied on. In a future PyTorch release, failing to provide a value for &lt;code&gt;steps&lt;/code&gt; will throw a runtime error.</source>
          <target state="translated">Not providing a value for &lt;code&gt;steps&lt;/code&gt; is deprecated. For backwards compatibility, not providing a value for &lt;code&gt;steps&lt;/code&gt; will create a tensor with 100 elements. Note that this behavior is not reflected in the documented function signature and should not be relied on. In a future PyTorch release, failing to provide a value for &lt;code&gt;steps&lt;/code&gt; will throw a runtime error.</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="a73e4c5274c790b0c43ddacd3a38f0f1878acefd" translate="yes" xml:space="preserve">
          <source>Note also that the total number of steps in the cycle can be determined in one of two ways (listed in order of precedence):</source>
          <target state="translated">また、サイクル内のステップの総数は、2つの方法のうちの1つで決定できることにも注意してください(優先順位の高い順にリストアップされています)。</target>
        </trans-unit>
        <trans-unit id="da7038b6159ab37164aeb7442907c881108aff7e" translate="yes" xml:space="preserve">
          <source>Note that</source>
          <target state="translated">以下のことに注意してください。</target>
        </trans-unit>
        <trans-unit id="5433b2e634d55f555a9239d7a13b88b55129e9b2" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;#torch.nn.ModuleDict.update&quot;&gt;&lt;code&gt;update()&lt;/code&gt;&lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt; before Python version 3.6) does not preserve the order of the merged mapping.</source>
          <target state="translated">Note that &lt;a href=&quot;#torch.nn.ModuleDict.update&quot;&gt; &lt;code&gt;update()&lt;/code&gt; &lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt; before Python version 3.6) does not preserve the order of the merged mapping.</target>
        </trans-unit>
        <trans-unit id="a1dc440ad60db846cad7f7d0a7ce1260c129ea8c" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;#torch.nn.ParameterDict.update&quot;&gt;&lt;code&gt;update()&lt;/code&gt;&lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt;) does not preserve the order of the merged mapping.</source>
          <target state="translated">Note that &lt;a href=&quot;#torch.nn.ParameterDict.update&quot;&gt; &lt;code&gt;update()&lt;/code&gt; &lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt; ) does not preserve the order of the merged mapping.</target>
        </trans-unit>
        <trans-unit id="42c994d9673f83cc70c78e02c5d9a230c6566874" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;*args&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; in &lt;a href=&quot;#torch.hub.load&quot;&gt;&lt;code&gt;torch.hub.load()&lt;/code&gt;&lt;/a&gt; are used to &lt;strong&gt;instantiate&lt;/strong&gt; a model. After you have loaded a model, how can you find out what you can do with the model? A suggested workflow is</source>
          <target state="translated">Note that &lt;code&gt;*args&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; in &lt;a href=&quot;#torch.hub.load&quot;&gt; &lt;code&gt;torch.hub.load()&lt;/code&gt; &lt;/a&gt; are used to &lt;strong&gt;instantiate&lt;/strong&gt; a model. After you have loaded a model, how can you find out what you can do with the model? A suggested workflow is</target>
        </trans-unit>
        <trans-unit id="2d1e0d8414eaec791533b2f0922dd4ade580351c" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;BAND&lt;/code&gt;, &lt;code&gt;BOR&lt;/code&gt;, and &lt;code&gt;BXOR&lt;/code&gt; reductions are not available when using the &lt;code&gt;NCCL&lt;/code&gt; backend.</source>
          <target state="translated">Note that &lt;code&gt;BAND&lt;/code&gt; , &lt;code&gt;BOR&lt;/code&gt; , and &lt;code&gt;BXOR&lt;/code&gt; reductions are not available when using the &lt;code&gt;NCCL&lt;/code&gt; backend.</target>
        </trans-unit>
        <trans-unit id="0bd438191e4b3887c615246e19e8361b84bd83a7" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;T[1] == T[-1].conj()&lt;/code&gt; and &lt;code&gt;T[2] == T[-2].conj()&lt;/code&gt; is redundant. We can thus compute the forward transform without considering negative frequencies:</source>
          <target state="translated">Note that &lt;code&gt;T[1] == T[-1].conj()&lt;/code&gt; and &lt;code&gt;T[2] == T[-2].conj()&lt;/code&gt; is redundant. We can thus compute the forward transform without considering negative frequencies:</target>
        </trans-unit>
        <trans-unit id="ee47ccc0fe1d0f9aca7dffbff0fc6bd81769f2e4" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;len(output_tensor_list)&lt;/code&gt; needs to be the same for all the distributed processes calling this function.</source>
          <target state="translated">Note that &lt;code&gt;len(output_tensor_list)&lt;/code&gt; needs to be the same for all the distributed processes calling this function.</target>
        </trans-unit>
        <trans-unit id="de81d60cb1e06955cef77dc7af826512edffc0f1" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;total_count&lt;/code&gt; need not be specified if only &lt;a href=&quot;#torch.distributions.multinomial.Multinomial.log_prob&quot;&gt;&lt;code&gt;log_prob()&lt;/code&gt;&lt;/a&gt; is called (see example below)</source>
          <target state="translated">ことを注意 &lt;code&gt;total_count&lt;/code&gt; 場合のみ必要性が指定されていない&lt;a href=&quot;#torch.distributions.multinomial.Multinomial.log_prob&quot;&gt; &lt;code&gt;log_prob()&lt;/code&gt; は、&lt;/a&gt;（以下の例を参照）と呼ばれています</target>
        </trans-unit>
        <trans-unit id="7ad0240a1b6c1c4077cd6f27931fdf77ffb68b6b" translate="yes" xml:space="preserve">
          <source>Note that QConfig needs to contain observer &lt;strong&gt;classes&lt;/strong&gt; (like MinMaxObserver) or a callable that returns instances on invocation, not the concrete observer instances themselves. Quantization preparation function will instantiate observers multiple times for each of the layers.</source>
          <target state="translated">QConfigには、具体的なオブザーバーインスタンス自体ではなく、オブザーバー&lt;strong&gt;クラス&lt;/strong&gt;（MinMaxObserverなど）または呼び出し時にインスタンスを返す呼び出し可能オブジェクトが含まれている必要があることに注意してください。量子化準備機能は、各レイヤーに対してオブザーバーを複数回インスタンス化します。</target>
        </trans-unit>
        <trans-unit id="1ccf01e0451a8d6abc36c37e011e58952b42e20e" translate="yes" xml:space="preserve">
          <source>Note that QConfigDynamic needs to contain observer &lt;strong&gt;classes&lt;/strong&gt; (like MinMaxObserver) or a callable that returns instances on invocation, not the concrete observer instances themselves. Quantization function will instantiate observers multiple times for each of the layers.</source>
          <target state="translated">QConfigDynamicには、具体的なオブザーバーインスタンス自体ではなく、オブザーバー&lt;strong&gt;クラス&lt;/strong&gt;（MinMaxObserverなど）または呼び出し時にインスタンスを返す呼び出し可能オブジェクトが含まれている必要があることに注意してください。量子化関数は、レイヤーごとにオブザーバーを複数回インスタンス化します。</target>
        </trans-unit>
        <trans-unit id="d9706617db521f3c057495c1501777340ff2c154" translate="yes" xml:space="preserve">
          <source>Note that automatic rank assignment is not supported anymore in the latest distributed package and &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</source>
          <target state="translated">Note that automatic rank assignment is not supported anymore in the latest distributed package and &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</target>
        </trans-unit>
        <trans-unit id="d90621e782b71803aaf8f760cde86adc6ccf606c" translate="yes" xml:space="preserve">
          <source>Note that deterministic operations tend to have worse performance than non-deterministic operations.</source>
          <target state="translated">決定論的な操作は、非決定論的な操作よりもパフォーマンスが悪くなる傾向があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="b7948c066b35cd06338c8b76a0036f57024ca522" translate="yes" xml:space="preserve">
          <source>Note that each element of &lt;code&gt;input_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(output_tensor_list)&lt;/code&gt;, since the function scatters the result from every single GPU in the group. To interpret each element of &lt;code&gt;input_tensor_lists[i]&lt;/code&gt;, note that &lt;code&gt;output_tensor_list[j]&lt;/code&gt; of rank k receives the reduce-scattered result from &lt;code&gt;input_tensor_lists[i][k * world_size + j]&lt;/code&gt;</source>
          <target state="translated">Note that each element of &lt;code&gt;input_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(output_tensor_list)&lt;/code&gt; , since the function scatters the result from every single GPU in the group. To interpret each element of &lt;code&gt;input_tensor_lists[i]&lt;/code&gt; , note that &lt;code&gt;output_tensor_list[j]&lt;/code&gt; of rank k receives the reduce-scattered result from &lt;code&gt;input_tensor_lists[i][k * world_size + j]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f1fa921e9c60fd6eb9bf5d36ace2910b625e1764" translate="yes" xml:space="preserve">
          <source>Note that each element of &lt;code&gt;output_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(input_tensor_list)&lt;/code&gt;, since the function all gathers the result from every single GPU in the group. To interpret each element of &lt;code&gt;output_tensor_lists[i]&lt;/code&gt;, note that &lt;code&gt;input_tensor_list[j]&lt;/code&gt; of rank k will be appear in &lt;code&gt;output_tensor_lists[i][k * world_size + j]&lt;/code&gt;</source>
          <target state="translated">Note that each element of &lt;code&gt;output_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(input_tensor_list)&lt;/code&gt; , since the function all gathers the result from every single GPU in the group. To interpret each element of &lt;code&gt;output_tensor_lists[i]&lt;/code&gt; , note that &lt;code&gt;input_tensor_list[j]&lt;/code&gt; of rank k will be appear in &lt;code&gt;output_tensor_lists[i][k * world_size + j]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a779c7a4b4446c6b4a026c9792070b87e0802a90" translate="yes" xml:space="preserve">
          <source>Note that if there will be a lot of tensors shared, this strategy will keep a large number of file descriptors open most of the time. If your system has low limits for the number of open file descriptors, and you can&amp;rsquo;t raise them, you should use the &lt;code&gt;file_system&lt;/code&gt; strategy.</source>
          <target state="translated">共有されるテンソルが多数ある場合、この戦略では、ほとんどの場合、多数のファイル記述子が開いたままになることに注意してください。システムに開いているファイル記述子の数の下限があり、それらを上げることができない場合は、 &lt;code&gt;file_system&lt;/code&gt; 戦略を使用する必要があります。</target>
        </trans-unit>
        <trans-unit id="261fa08253a2249def1244a03fcd9b8841a48f8d" translate="yes" xml:space="preserve">
          <source>Note that multicast address is not supported anymore in the latest distributed package. &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</source>
          <target state="translated">Note that multicast address is not supported anymore in the latest distributed package. &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</target>
        </trans-unit>
        <trans-unit id="b2830ad219b13cbec38ff7f3f532533bf250586f" translate="yes" xml:space="preserve">
          <source>Note that non-integer &lt;code&gt;step&lt;/code&gt; is subject to floating point rounding errors when comparing against &lt;code&gt;end&lt;/code&gt;; to avoid inconsistency, we advise adding a small epsilon to &lt;code&gt;end&lt;/code&gt; in such cases.</source>
          <target state="translated">Note that non-integer &lt;code&gt;step&lt;/code&gt; is subject to floating point rounding errors when comparing against &lt;code&gt;end&lt;/code&gt; ; to avoid inconsistency, we advise adding a small epsilon to &lt;code&gt;end&lt;/code&gt; in such cases.</target>
        </trans-unit>
        <trans-unit id="112ac3f4ac80a498de80217376157fc61531fc0a" translate="yes" xml:space="preserve">
          <source>Note that one should use &lt;code&gt;cache_size=1&lt;/code&gt; when it comes to &lt;code&gt;NaN/Inf&lt;/code&gt; values.</source>
          <target state="translated">&lt;code&gt;NaN/Inf&lt;/code&gt; 値に関しては、 &lt;code&gt;cache_size=1&lt;/code&gt; を使用する必要があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="0bc75f2496d9d7af4d1e5ae3151f63a061a03230" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;.event_shape&lt;/code&gt; of a &lt;a href=&quot;#torch.distributions.transformed_distribution.TransformedDistribution&quot;&gt;&lt;code&gt;TransformedDistribution&lt;/code&gt;&lt;/a&gt; is the maximum shape of its base distribution and its transforms, since transforms can introduce correlations among events.</source>
          <target state="translated">&lt;a href=&quot;#torch.distributions.transformed_distribution.TransformedDistribution&quot;&gt; &lt;code&gt;TransformedDistribution&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;.event_shape&lt;/code&gt; は、その基本分布とその変換の最大形状であることに注意してください。これは、変換によってイベント間に相関関係が生じる可能性があるためです。</target>
        </trans-unit>
        <trans-unit id="fe417e45eca8b56b8a391ee5d65f646c54c00fc4" translate="yes" xml:space="preserve">
          <source>Note that the input to LongTensor is NOT a list of index tuples. If you want to write your indices this way, you should transpose before passing them to the sparse constructor:</source>
          <target state="translated">LongTensor の入力はインデックスタプルのリストではないことに注意してください。インデックスをこのように書きたい場合は、スパースのコンストラクタに渡す前に転置しなければなりません。</target>
        </trans-unit>
        <trans-unit id="7e0f39780c8cac4e285c8ec3c405982d7cafc31f" translate="yes" xml:space="preserve">
          <source>Note that these cases may in fact be traceable in the future.</source>
          <target state="translated">これらのケースは、実際には将来的に追跡可能になる可能性があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="59bdfd4be005baa7a143e9e7af0a324461ee7947" translate="yes" xml:space="preserve">
          <source>Note that this enumerates over all batched tensors in lock-step &lt;code&gt;[[0, 0], [1, 1], &amp;hellip;]&lt;/code&gt;. With &lt;code&gt;expand=False&lt;/code&gt;, enumeration happens along dim 0, but with the remaining batch dimensions being singleton dimensions, &lt;code&gt;[[0], [1], ..&lt;/code&gt;.</source>
          <target state="translated">これは、ロックステップ &lt;code&gt;[[0, 0], [1, 1], &amp;hellip;]&lt;/code&gt; バッチ処理されたすべてのテンソルを列挙することに注意してください。 &lt;code&gt;expand=False&lt;/code&gt; 、列挙はDIM 0に沿って発生し、残りのバッチの寸法が寸法シングルトンされた状態で、 &lt;code&gt;[[0], [1], ..&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="752392a2ff1e2a39cc0db5f6e4585276ad451ffb" translate="yes" xml:space="preserve">
          <source>Note that this function is simply doing &lt;code&gt;isinstance(obj, Tensor)&lt;/code&gt;. Using that &lt;code&gt;isinstance&lt;/code&gt; check is better for typechecking with mypy, and more explicit - so it&amp;rsquo;s recommended to use that instead of &lt;code&gt;is_tensor&lt;/code&gt;.</source>
          <target state="translated">Note that this function is simply doing &lt;code&gt;isinstance(obj, Tensor)&lt;/code&gt; . Using that &lt;code&gt;isinstance&lt;/code&gt; check is better for typechecking with mypy, and more explicit - so it&amp;rsquo;s recommended to use that instead of &lt;code&gt;is_tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a5b8b84abd5cbd1ff532fd7ae1e19baa9b3b1a28" translate="yes" xml:space="preserve">
          <source>Note that this function requires Python 3.4 or higher.</source>
          <target state="translated">この関数はPython 3.4以上が必要です。</target>
        </trans-unit>
        <trans-unit id="e898adc76bed905448d3327e88134b4893e4bf98" translate="yes" xml:space="preserve">
          <source>Note that this requires the &lt;code&gt;matplotlib&lt;/code&gt; package.</source>
          <target state="translated">Note that this requires the &lt;code&gt;matplotlib&lt;/code&gt; package.</target>
        </trans-unit>
        <trans-unit id="ba4e51216b174df96efb807dbfef6adf290a07f2" translate="yes" xml:space="preserve">
          <source>Note that this requires the &lt;code&gt;moviepy&lt;/code&gt; package.</source>
          <target state="translated">Note that this requires the &lt;code&gt;moviepy&lt;/code&gt; package.</target>
        </trans-unit>
        <trans-unit id="da8c941a1c4dc21607ac70d896e4a7cb648a3554" translate="yes" xml:space="preserve">
          <source>Note that this requires the &lt;code&gt;pillow&lt;/code&gt; package.</source>
          <target state="translated">Note that this requires the &lt;code&gt;pillow&lt;/code&gt; package.</target>
        </trans-unit>
        <trans-unit id="38c3af3645ee3d8c1e85f997b98d93ebdc11ac44" translate="yes" xml:space="preserve">
          <source>Note that when &lt;code&gt;tracker&lt;/code&gt; stores Tensor objects from the LOBPCG instance, it must make copies of these.</source>
          <target state="translated">Note that when &lt;code&gt;tracker&lt;/code&gt; stores Tensor objects from the LOBPCG instance, it must make copies of these.</target>
        </trans-unit>
        <trans-unit id="76d32111f7bcbce3e8104b2ef5376761705e1942" translate="yes" xml:space="preserve">
          <source>Note: A full example to apply nn.Transformer module for the word language model is available in &lt;a href=&quot;https://github.com/pytorch/examples/tree/master/word_language_model&quot;&gt;https://github.com/pytorch/examples/tree/master/word_language_model&lt;/a&gt;</source>
          <target state="translated">Note: A full example to apply nn.Transformer module for the word language model is available in &lt;a href=&quot;https://github.com/pytorch/examples/tree/master/word_language_model&quot;&gt;https://github.com/pytorch/examples/tree/master/word_language_model&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2acb81c5ebbb77d4e03260d44dbd15da614d8dba" translate="yes" xml:space="preserve">
          <source>Note: Due to the multi-head attention architecture in the transformer model, the output sequence length of a transformer is same as the input sequence (i.e. target) length of the decode.</source>
          <target state="translated">注:トランスモデルのマルチヘッド注意アーキテクチャのため、トランスの出力シーケンス長は、デコードの入力シーケンス(すなわちターゲット)長と同じです。</target>
        </trans-unit>
        <trans-unit id="ea3f023c9638ee2f77985080cfee0c3149276897" translate="yes" xml:space="preserve">
          <source>Note: Loading a model is the typical use case, but this can also be used to for loading other objects such as tokenizers, loss functions, etc.</source>
          <target state="translated">注:モデルの読み込みが典型的なユースケースですが、トークナイザーや損失関数などの他のオブジェクトの読み込みにも使用できます。</target>
        </trans-unit>
        <trans-unit id="fec631db96f94a854d531dcf201c32e0e5b12fec" translate="yes" xml:space="preserve">
          <source>Note: When beta is set to 0, this is equivalent to &lt;a href=&quot;torch.nn.l1loss#torch.nn.L1Loss&quot;&gt;&lt;code&gt;L1Loss&lt;/code&gt;&lt;/a&gt;. Passing a negative value in for beta will result in an exception.</source>
          <target state="translated">Note: When beta is set to 0, this is equivalent to &lt;a href=&quot;torch.nn.l1loss#torch.nn.L1Loss&quot;&gt; &lt;code&gt;L1Loss&lt;/code&gt; &lt;/a&gt;. Passing a negative value in for beta will result in an exception.</target>
        </trans-unit>
        <trans-unit id="9b7c2d4ed1b493db790041907421b97fbf38eae9" translate="yes" xml:space="preserve">
          <source>Note: [src/tgt/memory]_mask ensures that position i is allowed to attend the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will be unchanged. If a BoolTensor is provided, positions with &lt;code&gt;True&lt;/code&gt; are not allowed to attend while &lt;code&gt;False&lt;/code&gt; values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight. [src/tgt/memory]_key_padding_mask provides specified elements in the key to be ignored by the attention. If a ByteTensor is provided, the non-zero positions will be ignored while the zero positions will be unchanged. If a BoolTensor is provided, the positions with the value of &lt;code&gt;True&lt;/code&gt; will be ignored while the position with the value of &lt;code&gt;False&lt;/code&gt; will be unchanged.</source>
          <target state="translated">Note: [src/tgt/memory]_mask ensures that position i is allowed to attend the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will be unchanged. If a BoolTensor is provided, positions with &lt;code&gt;True&lt;/code&gt; are not allowed to attend while &lt;code&gt;False&lt;/code&gt; values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight. [src/tgt/memory]_key_padding_mask provides specified elements in the key to be ignored by the attention. If a ByteTensor is provided, the non-zero positions will be ignored while the zero positions will be unchanged. If a BoolTensor is provided, the positions with the value of &lt;code&gt;True&lt;/code&gt; will be ignored while the position with the value of &lt;code&gt;False&lt;/code&gt; will be unchanged.</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="4425723195c4a3b16b476f69800fa3cf16abb9b4" translate="yes" xml:space="preserve">
          <source>Notice that if</source>
          <target state="translated">以下のような場合に注意してください。</target>
        </trans-unit>
        <trans-unit id="d1656ebe55b849d2893f4a0cf92db35aea6025bc" translate="yes" xml:space="preserve">
          <source>Notice that operators can also have associated &lt;code&gt;blocks&lt;/code&gt;, namely the &lt;code&gt;prim::Loop&lt;/code&gt; and &lt;code&gt;prim::If&lt;/code&gt; operators. In the graph print-out, these operators are formatted to reflect their equivalent source code forms to facilitate easy debugging.</source>
          <target state="translated">Notice that operators can also have associated &lt;code&gt;blocks&lt;/code&gt; , namely the &lt;code&gt;prim::Loop&lt;/code&gt; and &lt;code&gt;prim::If&lt;/code&gt; operators. In the graph print-out, these operators are formatted to reflect their equivalent source code forms to facilitate easy debugging.</target>
        </trans-unit>
        <trans-unit id="04a5b9046bd473cb428ae07e5d6a160de265bc5d" translate="yes" xml:space="preserve">
          <source>Notice that the symmetric element &lt;code&gt;T[-1] == T[1].conj()&lt;/code&gt; is omitted. At the Nyquist frequency &lt;code&gt;T[-2] == T[2]&lt;/code&gt; is it&amp;rsquo;s own symmetric pair, and therefore must always be real-valued.</source>
          <target state="translated">Notice that the symmetric element &lt;code&gt;T[-1] == T[1].conj()&lt;/code&gt; is omitted. At the Nyquist frequency &lt;code&gt;T[-2] == T[2]&lt;/code&gt; is it&amp;rsquo;s own symmetric pair, and therefore must always be real-valued.</target>
        </trans-unit>
        <trans-unit id="1956334a42d3e178212344356997b21e347fa273" translate="yes" xml:space="preserve">
          <source>Now PyTorch is able to export &lt;code&gt;elu&lt;/code&gt; operator.</source>
          <target state="translated">Now PyTorch is able to export &lt;code&gt;elu&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="a30a0ffebbaef4efa26c2a00eda09cf59167dfe6" translate="yes" xml:space="preserve">
          <source>Now the exported ONNX graph becomes:</source>
          <target state="translated">これでエクスポートされたONNXのグラフは以下のようになります。</target>
        </trans-unit>
        <trans-unit id="27759972b02a15b63bf671d015c9407939f14fb3" translate="yes" xml:space="preserve">
          <source>Numerical gradient checking</source>
          <target state="translated">数値勾配チェック</target>
        </trans-unit>
        <trans-unit id="08a914cde05039694ef0194d9ee79ff9a79dde33" translate="yes" xml:space="preserve">
          <source>O</source>
          <target state="translated">O</target>
        </trans-unit>
        <trans-unit id="58e9484683a456865672c8a4517b530e0f41cd11" translate="yes" xml:space="preserve">
          <source>ONLY INDICES:</source>
          <target state="translated">唯一の指標です。</target>
        </trans-unit>
        <trans-unit id="b335243efa572b5f0beb01acb45b42a02be187b5" translate="yes" xml:space="preserve">
          <source>ONNX</source>
          <target state="translated">ONNX</target>
        </trans-unit>
        <trans-unit id="98099fd5d344320bb061ab40d4f82b1271288a2a" translate="yes" xml:space="preserve">
          <source>ONNX_ATEN</source>
          <target state="translated">ONNX_ATEN</target>
        </trans-unit>
        <trans-unit id="7fd76316b691135ff7ad4e41541a37a2b2ed8c3d" translate="yes" xml:space="preserve">
          <source>ONNX_ATEN_FALLBACK</source>
          <target state="translated">ONNX_ATEN_FALLBACK</target>
        </trans-unit>
        <trans-unit id="0976054bd35910dc334e574eb3e3c16bf4dc9b17" translate="yes" xml:space="preserve">
          <source>ONNX_FALLTHROUGH</source>
          <target state="translated">ONNX_FALLTHROUGH</target>
        </trans-unit>
        <trans-unit id="946938795b376f71c3a327dfe4ec5463d0103fa6" translate="yes" xml:space="preserve">
          <source>Object Detection, Instance Segmentation and Person Keypoint Detection</source>
          <target state="translated">オブジェクト検出、インスタンスセグメンテーション、人物キーポイント検出</target>
        </trans-unit>
        <trans-unit id="56b40c7447fb6cdfcf37a82cf91030f8b0adc145" translate="yes" xml:space="preserve">
          <source>Observer classes have usually reasonable default arguments, but they can be overwritten with &lt;code&gt;with_args&lt;/code&gt; method (that behaves like functools.partial):</source>
          <target state="translated">オブザーバークラスには通常、妥当なデフォルト引数がありますが、 &lt;code&gt;with_args&lt;/code&gt; メソッド（functools.partialのように動作します）で上書きできます。</target>
        </trans-unit>
        <trans-unit id="05df80fc8f6cd937ee6fca4db89715da3aeb05ee" translate="yes" xml:space="preserve">
          <source>Observer module for computing the quantization parameters based on the moving average of the min and max values.</source>
          <target state="translated">最小値と最大値の移動平均に基づいて量子化パラメータを計算するオブザーバモジュール。</target>
        </trans-unit>
        <trans-unit id="0e6416b8d542683480294d9aa23272830844da59" translate="yes" xml:space="preserve">
          <source>Observer module for computing the quantization parameters based on the running min and max values.</source>
          <target state="translated">実行中の最小値と最大値に基づいて量子化パラメータを計算するためのオブザーバモジュール。</target>
        </trans-unit>
        <trans-unit id="06100f7170e7f76076139e20082a1eb3afab8d09" translate="yes" xml:space="preserve">
          <source>Observer module for computing the quantization parameters based on the running per channel min and max values.</source>
          <target state="translated">チャンネルごとに実行される最小値と最大値に基づいて量子化パラメータを計算するためのオブザーバモジュール。</target>
        </trans-unit>
        <trans-unit id="77e203a6c2d75205e18b618179c387b4e62870c5" translate="yes" xml:space="preserve">
          <source>Observer that doesn&amp;rsquo;t do anything and just passes its configuration to the quantized module&amp;rsquo;s &lt;code&gt;.from_float()&lt;/code&gt;.</source>
          <target state="translated">何もせず、その構成を量子化されたモジュールの &lt;code&gt;.from_float()&lt;/code&gt; に渡すだけのオブザーバー。</target>
        </trans-unit>
        <trans-unit id="0618a214d16e39be75c6315a11d086a7dcbea1b6" translate="yes" xml:space="preserve">
          <source>Observers</source>
          <target state="translated">Observers</target>
        </trans-unit>
        <trans-unit id="8bf3249a3a8cece6d4343af20c9431018c926b24" translate="yes" xml:space="preserve">
          <source>Obtaining log-probabilities in a neural network is easily achieved by adding a &lt;code&gt;LogSoftmax&lt;/code&gt; layer in the last layer of your network. You may use &lt;code&gt;CrossEntropyLoss&lt;/code&gt; instead, if you prefer not to add an extra layer.</source>
          <target state="translated">Obtaining log-probabilities in a neural network is easily achieved by adding a &lt;code&gt;LogSoftmax&lt;/code&gt; layer in the last layer of your network. You may use &lt;code&gt;CrossEntropyLoss&lt;/code&gt; instead, if you prefer not to add an extra layer.</target>
        </trans-unit>
        <trans-unit id="b98c7204267732ffe5bc04ce20cbadbe8642e52b" translate="yes" xml:space="preserve">
          <source>Of course the reality is much more complicated and your script might not be in one of those two extremes depending on the part of the model you&amp;rsquo;re evaluating. If the profiler outputs don&amp;rsquo;t help, you could try looking at the result of &lt;a href=&quot;autograd#torch.autograd.profiler.emit_nvtx&quot;&gt;&lt;code&gt;torch.autograd.profiler.emit_nvtx()&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;nvprof&lt;/code&gt;. However, please take into account that the NVTX overhead is very high and often gives a heavily skewed timeline.</source>
          <target state="translated">Of course the reality is much more complicated and your script might not be in one of those two extremes depending on the part of the model you&amp;rsquo;re evaluating. If the profiler outputs don&amp;rsquo;t help, you could try looking at the result of &lt;a href=&quot;autograd#torch.autograd.profiler.emit_nvtx&quot;&gt; &lt;code&gt;torch.autograd.profiler.emit_nvtx()&lt;/code&gt; &lt;/a&gt; with &lt;code&gt;nvprof&lt;/code&gt; . However, please take into account that the NVTX overhead is very high and often gives a heavily skewed timeline.</target>
        </trans-unit>
        <trans-unit id="c37dc6bfd2614888384f13ab211221f9b141d421" translate="yes" xml:space="preserve">
          <source>Old API:</source>
          <target state="translated">古いAPIです。</target>
        </trans-unit>
        <trans-unit id="fe1a8467f796e691ae75cd019ca47d231225ebf5" translate="yes" xml:space="preserve">
          <source>On CUDA 10.1, set environment variable &lt;code&gt;CUDA_LAUNCH_BLOCKING=1&lt;/code&gt;. This may affect performance.</source>
          <target state="translated">On CUDA 10.1, set environment variable &lt;code&gt;CUDA_LAUNCH_BLOCKING=1&lt;/code&gt; . This may affect performance.</target>
        </trans-unit>
        <trans-unit id="87f5d31208b13882b13d7cef323f2a640539b60a" translate="yes" xml:space="preserve">
          <source>On CUDA 10.2 or later, set environment variable (note the leading colon symbol) &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; or &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:2&lt;/code&gt;.</source>
          <target state="translated">On CUDA 10.2 or later, set environment variable (note the leading colon symbol) &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; or &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="36e5819afd89f0fa826f96c64796ff1578b24bfd" translate="yes" xml:space="preserve">
          <source>On Unix, &lt;code&gt;fork()&lt;/code&gt; is the default &lt;a href=&quot;https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing&quot;&gt;&lt;code&gt;multiprocessing&lt;/code&gt;&lt;/a&gt; start method. Using &lt;code&gt;fork()&lt;/code&gt;, child workers typically can access the &lt;code&gt;dataset&lt;/code&gt; and Python argument functions directly through the cloned address space.</source>
          <target state="translated">Unixでは、 &lt;code&gt;fork()&lt;/code&gt; がデフォルトの&lt;a href=&quot;https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing&quot;&gt; &lt;code&gt;multiprocessing&lt;/code&gt; &lt;/a&gt;開始メソッドです。児童労働者は通常、 &lt;code&gt;fork()&lt;/code&gt; を使用して、複製されたアドレス空間を介して &lt;code&gt;dataset&lt;/code&gt; とPython引数関数に直接アクセスできます。</target>
        </trans-unit>
        <trans-unit id="7e2ae33ff3c9afba44a2228dce980df719a2e771" translate="yes" xml:space="preserve">
          <source>On Windows, &lt;code&gt;spawn()&lt;/code&gt; is the default &lt;a href=&quot;https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing&quot;&gt;&lt;code&gt;multiprocessing&lt;/code&gt;&lt;/a&gt; start method. Using &lt;code&gt;spawn()&lt;/code&gt;, another interpreter is launched which runs your main script, followed by the internal worker function that receives the &lt;code&gt;dataset&lt;/code&gt;, &lt;code&gt;collate_fn&lt;/code&gt; and other arguments through &lt;a href=&quot;https://docs.python.org/3/library/pickle.html#module-pickle&quot;&gt;&lt;code&gt;pickle&lt;/code&gt;&lt;/a&gt; serialization.</source>
          <target state="translated">Windowsでは、 &lt;code&gt;spawn()&lt;/code&gt; がデフォルトの&lt;a href=&quot;https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing&quot;&gt; &lt;code&gt;multiprocessing&lt;/code&gt; &lt;/a&gt;開始メソッドです。 &lt;code&gt;spawn()&lt;/code&gt; を使用して、メインスクリプトを実行する別のインタープリターが起動され、その後、&lt;a href=&quot;https://docs.python.org/3/library/pickle.html#module-pickle&quot;&gt; &lt;code&gt;pickle&lt;/code&gt; &lt;/a&gt;シリアル化を通じて &lt;code&gt;dataset&lt;/code&gt; 、 &lt;code&gt;collate_fn&lt;/code&gt; 、およびその他の引数を受け取る内部ワーカー関数が起動されます。</target>
        </trans-unit>
        <trans-unit id="b433d4e11b599fd15dbc04960281f9eb287632d1" translate="yes" xml:space="preserve">
          <source>On each window, the function computed is:</source>
          <target state="translated">各ウィンドウ上で、計算された関数は次のようになります。</target>
        </trans-unit>
        <trans-unit id="a84bfeb86e4aa154caeb1f582b53ed62fd133141" translate="yes" xml:space="preserve">
          <source>On modules, methods must be compiled before they can be called. The TorchScript compiler recursively compiles methods it sees when compiling other methods. By default, compilation starts on the &lt;code&gt;forward&lt;/code&gt; method. Any methods called by &lt;code&gt;forward&lt;/code&gt; will be compiled, and any methods called by those methods, and so on. To start compilation at a method other than &lt;code&gt;forward&lt;/code&gt;, use the &lt;a href=&quot;jit#torch.jit.export&quot;&gt;&lt;code&gt;@torch.jit.export&lt;/code&gt;&lt;/a&gt; decorator (&lt;code&gt;forward&lt;/code&gt; implicitly is marked &lt;code&gt;@torch.jit.export&lt;/code&gt;).</source>
          <target state="translated">On modules, methods must be compiled before they can be called. The TorchScript compiler recursively compiles methods it sees when compiling other methods. By default, compilation starts on the &lt;code&gt;forward&lt;/code&gt; method. Any methods called by &lt;code&gt;forward&lt;/code&gt; will be compiled, and any methods called by those methods, and so on. To start compilation at a method other than &lt;code&gt;forward&lt;/code&gt; , use the &lt;a href=&quot;jit#torch.jit.export&quot;&gt; &lt;code&gt;@torch.jit.export&lt;/code&gt; &lt;/a&gt; decorator ( &lt;code&gt;forward&lt;/code&gt; implicitly is marked &lt;code&gt;@torch.jit.export&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="a488ba8f17e355abbbc16eb50cb56f628e0ef099" translate="yes" xml:space="preserve">
          <source>On the other hand, invoking &lt;code&gt;trace&lt;/code&gt; with module&amp;rsquo;s instance (e.g. &lt;code&gt;my_module&lt;/code&gt;) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required.</source>
          <target state="translated">On the other hand, invoking &lt;code&gt;trace&lt;/code&gt; with module&amp;rsquo;s instance (e.g. &lt;code&gt;my_module&lt;/code&gt; ) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required.</target>
        </trans-unit>
        <trans-unit id="b392f645cfdecae166313100197dfb1e06d02b4b" translate="yes" xml:space="preserve">
          <source>Once all DDP processes have joined, the context manager will broadcast the model corresponding to the last joined process to all processes to ensure the model is the same across all processes (which is guaranteed by DDP).</source>
          <target state="translated">すべてのDDPプロセスが参加すると、コンテキストマネージャは、最後に参加したプロセスに対応するモデルをすべてのプロセスにブロードキャストし、モデルがすべてのプロセスで同じであることを確認します(これはDDPによって保証されています)。</target>
        </trans-unit>
        <trans-unit id="3ebcd2d39bb7401d6e980dad866025a71193ae15" translate="yes" xml:space="preserve">
          <source>Once these are installed, you can use the backend for Caffe2:</source>
          <target state="translated">これらをインストールすると、Caffe2のバックエンドを利用できるようになります。</target>
        </trans-unit>
        <trans-unit id="c7da4cd77b5400566e4f52a1d8995e48e44e2095" translate="yes" xml:space="preserve">
          <source>Once these are installed, you can use the backend for ONNX Runtime:</source>
          <target state="translated">これらをインストールすると、ONNX Runtimeのバックエンドを利用することができます。</target>
        </trans-unit>
        <trans-unit id="181dde386ac4e48b01ea4c9ac2766b9fdca3442c" translate="yes" xml:space="preserve">
          <source>Once you&amp;rsquo;ve installed TensorBoard, these utilities let you log PyTorch models and metrics into a directory for visualization within the TensorBoard UI. Scalars, images, histograms, graphs, and embedding visualizations are all supported for PyTorch models and tensors as well as Caffe2 nets and blobs.</source>
          <target state="translated">Once you&amp;rsquo;ve installed TensorBoard, these utilities let you log PyTorch models and metrics into a directory for visualization within the TensorBoard UI. Scalars, images, histograms, graphs, and embedding visualizations are all supported for PyTorch models and tensors as well as Caffe2 nets and blobs.</target>
        </trans-unit>
        <trans-unit id="fa0ae9a8c41213fbda341d9975cb44fc985cb402" translate="yes" xml:space="preserve">
          <source>One can either give a &lt;code&gt;scale_factor&lt;/code&gt; or the target output &lt;code&gt;size&lt;/code&gt; to calculate the output size. (You cannot give both, as it is ambiguous)</source>
          <target state="translated">One can either give a &lt;code&gt;scale_factor&lt;/code&gt; or the target output &lt;code&gt;size&lt;/code&gt; to calculate the output size. (You cannot give both, as it is ambiguous)</target>
        </trans-unit>
        <trans-unit id="f84825776234c0c4615edbbd6631eafc8684c310" translate="yes" xml:space="preserve">
          <source>One cannot specify both positional args &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; and keyword args &lt;code&gt;rename_map&lt;/code&gt;.</source>
          <target state="translated">One cannot specify both positional args &lt;a href=&quot;#torch.Tensor.names&quot;&gt; &lt;code&gt;names&lt;/code&gt; &lt;/a&gt; and keyword args &lt;code&gt;rename_map&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f99ff2b17e8a666214d13b388ce8036710cb6b91" translate="yes" xml:space="preserve">
          <source>One way to automatically catch many errors in traces is by using &lt;code&gt;check_inputs&lt;/code&gt; on the &lt;code&gt;torch.jit.trace()&lt;/code&gt; API. &lt;code&gt;check_inputs&lt;/code&gt; takes a list of tuples of inputs that will be used to re-trace the computation and verify the results. For example:</source>
          <target state="translated">One way to automatically catch many errors in traces is by using &lt;code&gt;check_inputs&lt;/code&gt; on the &lt;code&gt;torch.jit.trace()&lt;/code&gt; API. &lt;code&gt;check_inputs&lt;/code&gt; takes a list of tuples of inputs that will be used to re-trace the computation and verify the results. For example:</target>
        </trans-unit>
        <trans-unit id="19248650fc8fc3134816a8981b1c84826b1d56cc" translate="yes" xml:space="preserve">
          <source>OneHotCategorical</source>
          <target state="translated">OneHotCategorical</target>
        </trans-unit>
        <trans-unit id="e9f428e38cd970cf00e186de12fa06466a0c70e3" translate="yes" xml:space="preserve">
          <source>Only 2D input is supported for quantized inputs</source>
          <target state="translated">量子化入力は2D入力のみサポート</target>
        </trans-unit>
        <trans-unit id="e86d4094fa43c487d3762de38c606afefec7936e" translate="yes" xml:space="preserve">
          <source>Only 2D inputs are supported</source>
          <target state="translated">2D入力のみサポート</target>
        </trans-unit>
        <trans-unit id="daede8c2e196c09bd4c265e562b51d50f0840292" translate="yes" xml:space="preserve">
          <source>Only 2D/3D input is supported for quantized inputs</source>
          <target state="translated">量子化入力は2D/3D入力のみサポート</target>
        </trans-unit>
        <trans-unit id="27966aeec004be97d5e6f5f602ef5deb9549007c" translate="yes" xml:space="preserve">
          <source>Only &lt;code&gt;torch.quint8&lt;/code&gt; is supported for the input data type.</source>
          <target state="translated">Only &lt;code&gt;torch.quint8&lt;/code&gt; is supported for the input data type.</target>
        </trans-unit>
        <trans-unit id="04aa0322b01e7ae421d1285e24a5ecee9dd8da63" translate="yes" xml:space="preserve">
          <source>Only &lt;code&gt;zeros&lt;/code&gt; is supported for the &lt;code&gt;padding_mode&lt;/code&gt; argument.</source>
          <target state="translated">Only &lt;code&gt;zeros&lt;/code&gt; is supported for the &lt;code&gt;padding_mode&lt;/code&gt; argument.</target>
        </trans-unit>
        <trans-unit id="63c087cd6938fb9b66dc8e1e4aed57dffdb285a6" translate="yes" xml:space="preserve">
          <source>Only CUDA ops are eligible for autocasting.</source>
          <target state="translated">オートキャスティングの対象となるのはCUDA opsのみです。</target>
        </trans-unit>
        <trans-unit id="a1a79ba7e0818fab9dabcadf1f32212012a954c6" translate="yes" xml:space="preserve">
          <source>Only leaf Tensors will have their &lt;a href=&quot;#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; populated during a call to &lt;a href=&quot;#torch.Tensor.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt;. To get &lt;a href=&quot;#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; populated for non-leaf Tensors, you can use &lt;a href=&quot;#torch.Tensor.retain_grad&quot;&gt;&lt;code&gt;retain_grad()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">リーフテンソルのみが、&lt;a href=&quot;#torch.Tensor.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; の&lt;/a&gt;呼び出し中に&lt;a href=&quot;#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; を設定し&lt;/a&gt;ます。取得するには&lt;a href=&quot;#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt;非リーフテンソルのための人口を、あなたが使用することができます&lt;a href=&quot;#torch.Tensor.retain_grad&quot;&gt; &lt;code&gt;retain_grad()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4e5b1e16b907585048a530098a587f0e967c17c8" translate="yes" xml:space="preserve">
          <source>Only leaf Tensors will have their &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; populated during a call to &lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt;. To get &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; populated for non-leaf Tensors, you can use &lt;a href=&quot;autograd#torch.Tensor.retain_grad&quot;&gt;&lt;code&gt;retain_grad()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Only leaf Tensors will have their &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt; populated during a call to &lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; &lt;/a&gt;. To get &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt; populated for non-leaf Tensors, you can use &lt;a href=&quot;autograd#torch.Tensor.retain_grad&quot;&gt; &lt;code&gt;retain_grad()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="214baf780986ab4b5685dfad680eb394c92a2724" translate="yes" xml:space="preserve">
          <source>Only nccl and gloo backend are currently supported tensors should only be GPU tensors</source>
          <target state="translated">現在サポートされているのは nccl と gloo バックエンドのみです。</target>
        </trans-unit>
        <trans-unit id="db8dc40130a88665cd5bf8f3be6d7ea249aff179" translate="yes" xml:space="preserve">
          <source>Only nccl and gloo backend is currently supported tensors should only be GPU tensors</source>
          <target state="translated">現在サポートされているのは nccl と gloo バックエンドのみです。</target>
        </trans-unit>
        <trans-unit id="df8cfb4a9929de36ffa3e1c6452d25a578580d0f" translate="yes" xml:space="preserve">
          <source>Only nccl backend is currently supported tensors should only be GPU tensors</source>
          <target state="translated">現在サポートされているのは nccl バックエンドのみで、テンソルは GPU テンソルのみにする必要があります。</target>
        </trans-unit>
        <trans-unit id="d7f15fe4ed58d21e3568885b930a49d8cb28d993" translate="yes" xml:space="preserve">
          <source>Only one of &lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix&quot;&gt;&lt;code&gt;covariance_matrix&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix&quot;&gt;&lt;code&gt;precision_matrix&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril&quot;&gt;&lt;code&gt;scale_tril&lt;/code&gt;&lt;/a&gt; can be specified.</source>
          <target state="translated">&lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix&quot;&gt; &lt;code&gt;covariance_matrix&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix&quot;&gt; &lt;code&gt;precision_matrix&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril&quot;&gt; &lt;code&gt;scale_tril&lt;/code&gt; の&lt;/a&gt;いずれか1つのみを指定できます。</target>
        </trans-unit>
        <trans-unit id="02ff51aa952480752b675430ae860b4c527dade3" translate="yes" xml:space="preserve">
          <source>Only out-of-place ops and Tensor methods are eligible. In-place variants and calls that explicitly supply an &lt;code&gt;out=...&lt;/code&gt; Tensor are allowed in autocast-enabled regions, but won&amp;rsquo;t go through autocasting. For example, in an autocast-enabled region &lt;code&gt;a.addmm(b, c)&lt;/code&gt; can autocast, but &lt;code&gt;a.addmm_(b, c)&lt;/code&gt; and &lt;code&gt;a.addmm(b, c, out=d)&lt;/code&gt; cannot. For best performance and stability, prefer out-of-place ops in autocast-enabled regions.</source>
          <target state="translated">アウトオブプレースopsとTensorメソッドのみが対象となります。 &lt;code&gt;out=...&lt;/code&gt; テンソルを明示的に提供するインプレースバリアントと呼び出しは、自動キャストが有効な領域で許可されますが、自動キャストは実行されません。たとえば、自動キャストが有効な領域では、 &lt;code&gt;a.addmm(b, c)&lt;/code&gt; は自動キャストできますが、 &lt;code&gt;a.addmm_(b, c)&lt;/code&gt; および &lt;code&gt;a.addmm(b, c, out=d)&lt;/code&gt; は自動キャストできません。最高のパフォーマンスと安定性を得るには、オートキャストが有効なリージョンでのアウトオブプレース操作をお勧めします。</target>
        </trans-unit>
        <trans-unit id="6f7a0a50221e4f4092d5689875e749bacffbc3f1" translate="yes" xml:space="preserve">
          <source>Only the GPU of &lt;code&gt;tensor_list[dst_tensor]&lt;/code&gt; on the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</source>
          <target state="translated">Only the GPU of &lt;code&gt;tensor_list[dst_tensor]&lt;/code&gt; on the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</target>
        </trans-unit>
        <trans-unit id="c024a1c0a5c1c600879124a8ffc9c018f3eeaa1c" translate="yes" xml:space="preserve">
          <source>Only the following modes are supported for the quantized inputs:</source>
          <target state="translated">量子化された入力は、以下のモードのみサポートされています。</target>
        </trans-unit>
        <trans-unit id="4abce74e0ec5249c62cdd843742dc1fcd44cf957" translate="yes" xml:space="preserve">
          <source>Only the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</source>
          <target state="translated">Only the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</target>
        </trans-unit>
        <trans-unit id="465e942c4c87f62f9475a2c554cc5cf2204bbefd" translate="yes" xml:space="preserve">
          <source>Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted but their usage is not recommended. Users need to verify their dict inputs carefully, and keep in mind that dynamic lookups are not available.</source>
          <target state="translated">JITの入出力としては、タプル、リスト、変数のみがサポートされています。辞書や文字列も受け入れられますが、それらの使用は推奨されません。ユーザーはdict入力を慎重に検証する必要があり、動的なルックアップは利用できないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="c63b5ae248ca6bf9edcb58a14545a2ec8ac9edff" translate="yes" xml:space="preserve">
          <source>Only works with &lt;code&gt;torch.per_tensor_affine&lt;/code&gt; quantization scheme.</source>
          <target state="translated">&lt;code&gt;torch.per_tensor_affine&lt;/code&gt; 量子化スキームでのみ機能します。</target>
        </trans-unit>
        <trans-unit id="b82189b88bcf4f6d2bb2ec50d464f322cc6fbe77" translate="yes" xml:space="preserve">
          <source>Only works with &lt;code&gt;torch.per_tensor_symmetric&lt;/code&gt; quantization scheme</source>
          <target state="translated">&lt;code&gt;torch.per_tensor_symmetric&lt;/code&gt; 量子化スキームでのみ機能します</target>
        </trans-unit>
        <trans-unit id="4315fcaa2c448f9408ac0b9bd62d96495ec80efb" translate="yes" xml:space="preserve">
          <source>Op Eligibility</source>
          <target state="translated">オペの資格</target>
        </trans-unit>
        <trans-unit id="8e1bcca5493f841f86f549bb09efaabbc0b197b6" translate="yes" xml:space="preserve">
          <source>Op-Specific Behavior</source>
          <target state="translated">オペ特有の行動</target>
        </trans-unit>
        <trans-unit id="a14e13faab81577c3e1bd1a5724a666f83008292" translate="yes" xml:space="preserve">
          <source>Opens an nvprof trace file and parses autograd annotations.</source>
          <target state="translated">nvprof トレースファイルを開き、autograd アノテーションを解析します。</target>
        </trans-unit>
        <trans-unit id="d0f4a3ec3e4ad0aecc8e89f342dde91d8ebe6688" translate="yes" xml:space="preserve">
          <source>Operator Export Type</source>
          <target state="translated">オペレータ輸出タイプ</target>
        </trans-unit>
        <trans-unit id="bb7373849dc3f047bbc13778dd3b1cb1da43b12b" translate="yes" xml:space="preserve">
          <source>OperatorExportTypes.ONNX: All ops are exported as regular ONNX ops (with ONNX namespace). OperatorExportTypes.ONNX_ATEN: All ops are exported as ATen ops (with aten namespace). OperatorExportTypes.ONNX_ATEN_FALLBACK: If an ATen op is not supported in ONNX or its symbolic is missing, fall back on ATen op. Registered ops are exported to ONNX regularly. Example graph:</source>
          <target state="translated">OperatorExportTypes.ONNX:すべての操作は、通常の ONNX 操作(ONNX 名前空間を持つ)としてエクスポートされます。OperatorExportTypes.ONNX_ATEN:すべてのオペはATenオペとしてエクスポートされます(aten名前空間を持つ)。OperatorExportTypes.ONNX_ATEN_FALLBACK:ATen opがONNXでサポートされていない場合やシンボリックが欠落している場合は、ATen opにフォールバックします。登録されたopは定期的にONNXにエクスポートされます。グラフ例。</target>
        </trans-unit>
        <trans-unit id="e90414358dbfff0a68e4eb5d68a16978cf197d5a" translate="yes" xml:space="preserve">
          <source>Operators</source>
          <target state="translated">Operators</target>
        </trans-unit>
        <trans-unit id="ae7fe79b856a95e009187cbf46df9c67d852304a" translate="yes" xml:space="preserve">
          <source>Ops called with an explicit &lt;code&gt;dtype=...&lt;/code&gt; argument are not eligible, and will produce output that respects the &lt;code&gt;dtype&lt;/code&gt; argument.</source>
          <target state="translated">明示的な &lt;code&gt;dtype=...&lt;/code&gt; 引数で呼び出された操作は適格ではなく、 &lt;code&gt;dtype&lt;/code&gt; 引数を尊重する出力を生成します。</target>
        </trans-unit>
        <trans-unit id="f728860bd944be6f6762552490261e98b6019554" translate="yes" xml:space="preserve">
          <source>Ops not listed below do not go through autocasting. They run in the type defined by their inputs. However, autocasting may still change the type in which unlisted ops run if they&amp;rsquo;re downstream from autocasted ops.</source>
          <target state="translated">以下にリストされていない操作は、自動キャストを通過しません。それらは、入力によって定義されたタイプで実行されます。ただし、自動キャストによって、リストにない操作が実行されるタイプが変更される場合があります。</target>
        </trans-unit>
        <trans-unit id="1e2c18bb8c291433dee05fffb46fe3081033ce4f" translate="yes" xml:space="preserve">
          <source>Ops that can autocast to &lt;code&gt;float16&lt;/code&gt;</source>
          <target state="translated">float16に &lt;code&gt;float16&lt;/code&gt; できるOps</target>
        </trans-unit>
        <trans-unit id="d41b349395acc2ee22829c823ba6e5272a03f36e" translate="yes" xml:space="preserve">
          <source>Ops that can autocast to &lt;code&gt;float32&lt;/code&gt;</source>
          <target state="translated">float32に &lt;code&gt;float32&lt;/code&gt; できるOps</target>
        </trans-unit>
        <trans-unit id="de95d5ff9adfbfe0e08db9c9f3168e2ebb01f3f5" translate="yes" xml:space="preserve">
          <source>Ops that promote to the widest input type</source>
          <target state="translated">最も広い入力タイプに促進するオペレーション</target>
        </trans-unit>
        <trans-unit id="c518b3a6d985b38fecd8953dbd43a11b6da0e4b9" translate="yes" xml:space="preserve">
          <source>Ops that run in &lt;code&gt;float64&lt;/code&gt; or non-floating-point dtypes are not eligible, and will run in these types whether or not autocast is enabled.</source>
          <target state="translated">&lt;code&gt;float64&lt;/code&gt; または非浮動小数点dtypeで実行される演算は適格ではなく、自動キャストが有効になっているかどうかに関係なく、これらのタイプで実行されます。</target>
        </trans-unit>
        <trans-unit id="326510735a447ec63da9abec360c7b0441bdd180" translate="yes" xml:space="preserve">
          <source>Optional Type Refinement</source>
          <target state="translated">オプションタイプの絞り込み</target>
        </trans-unit>
        <trans-unit id="21826226f40329aa4cc3679f6cd2d7ad202e0147" translate="yes" xml:space="preserve">
          <source>Optional values &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;alpha&lt;/code&gt; are scaling factors on the outer product between &lt;code&gt;vec1&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; and the added matrix &lt;code&gt;input&lt;/code&gt; respectively.</source>
          <target state="translated">Optional values &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;alpha&lt;/code&gt; are scaling factors on the outer product between &lt;code&gt;vec1&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; and the added matrix &lt;code&gt;input&lt;/code&gt; respectively.</target>
        </trans-unit>
        <trans-unit id="14cf9a30a86cd6abc4768ba63268809b6a642a72" translate="yes" xml:space="preserve">
          <source>Optionally set the Torch Hub directory used to save downloaded models &amp;amp; weights.</source>
          <target state="translated">Optionally set the Torch Hub directory used to save downloaded models &amp;amp; weights.</target>
        </trans-unit>
        <trans-unit id="3cdb2fb789b07586dcdc33ff9c3ec35d1394e04a" translate="yes" xml:space="preserve">
          <source>Optionally, you can give non-equal weighting on the classes by passing a 1D &lt;code&gt;weight&lt;/code&gt; tensor into the constructor.</source>
          <target state="translated">Optionally, you can give non-equal weighting on the classes by passing a 1D &lt;code&gt;weight&lt;/code&gt; tensor into the constructor.</target>
        </trans-unit>
        <trans-unit id="657998dbdb24b52285f38e822b9084533640dfff" translate="yes" xml:space="preserve">
          <source>Ordinarily, &amp;ldquo;automatic mixed precision training&amp;rdquo; uses &lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt;&lt;code&gt;torch.cuda.amp.autocast&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.cuda.amp.GradScaler&quot;&gt;&lt;code&gt;torch.cuda.amp.GradScaler&lt;/code&gt;&lt;/a&gt; together, as shown in the &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-examples&quot;&gt;Automatic Mixed Precision examples&lt;/a&gt; and &lt;a href=&quot;https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html&quot;&gt;Automatic Mixed Precision recipe&lt;/a&gt;. However, &lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt;&lt;code&gt;autocast&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.cuda.amp.GradScaler&quot;&gt;&lt;code&gt;GradScaler&lt;/code&gt;&lt;/a&gt; are modular, and may be used separately if desired.</source>
          <target state="translated">通常、「自動混合精度トレーニング」では、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-examples&quot;&gt;自動混合精度の例&lt;/a&gt;と&lt;a href=&quot;https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html&quot;&gt;自動混合精度のレシピに&lt;/a&gt;示すように、&lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt; &lt;code&gt;torch.cuda.amp.autocast&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;#torch.cuda.amp.GradScaler&quot;&gt; &lt;code&gt;torch.cuda.amp.GradScaler&lt;/code&gt; を&lt;/a&gt;一緒に使用します。ただし、&lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt; &lt;code&gt;autocast&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;#torch.cuda.amp.GradScaler&quot;&gt; &lt;code&gt;GradScaler&lt;/code&gt; &lt;/a&gt;はモジュール式であり、必要に応じて別々に使用できます。</target>
        </trans-unit>
        <trans-unit id="ae88acefda9740ca025e9b1e8d82500694df6312" translate="yes" xml:space="preserve">
          <source>Orphan</source>
          <target state="translated">Orphan</target>
        </trans-unit>
        <trans-unit id="6e6a6f2086bb5fe5dbfd17d8d5f502d48759834b" translate="yes" xml:space="preserve">
          <source>Other</source>
          <target state="translated">Other</target>
        </trans-unit>
        <trans-unit id="d51aeaedae53d1689ff4812f653d88f9f69f9530" translate="yes" xml:space="preserve">
          <source>Other NCCL environment variables</source>
          <target state="translated">その他のNCCL環境変数</target>
        </trans-unit>
        <trans-unit id="b41b4ea22c0549444f4374445d8b5be41ed6c7a3" translate="yes" xml:space="preserve">
          <source>Other Operations</source>
          <target state="translated">その他の事業</target>
        </trans-unit>
        <trans-unit id="b4fb6252944f2406950d09755e09e265942a94cb" translate="yes" xml:space="preserve">
          <source>Other dimensions of &lt;code&gt;input&lt;/code&gt; that are not explicitly moved remain in their original order and appear at the positions not specified in &lt;code&gt;destination&lt;/code&gt;.</source>
          <target state="translated">Other dimensions of &lt;code&gt;input&lt;/code&gt; that are not explicitly moved remain in their original order and appear at the positions not specified in &lt;code&gt;destination&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="48ae709d89b00cce606c898dd9a79282ec9c0bb8" translate="yes" xml:space="preserve">
          <source>Otherwise, &lt;code&gt;.grad&lt;/code&gt; is created with rowmajor-contiguous strides.</source>
          <target state="translated">それ以外の場合、 &lt;code&gt;.grad&lt;/code&gt; はrowmajor-contiguousストライドで作成されます。</target>
        </trans-unit>
        <trans-unit id="9b1d762f3a800a1e6b0f118d4aa509412d043de1" translate="yes" xml:space="preserve">
          <source>Otherwise, if &lt;code&gt;map_location&lt;/code&gt; is a dict, it will be used to remap location tags appearing in the file (keys), to ones that specify where to put the storages (values).</source>
          <target state="translated">Otherwise, if &lt;code&gt;map_location&lt;/code&gt; is a dict, it will be used to remap location tags appearing in the file (keys), to ones that specify where to put the storages (values).</target>
        </trans-unit>
        <trans-unit id="9f6ea88f9397a13956243e283a62e08c4833e59a" translate="yes" xml:space="preserve">
          <source>Otherwise, it will not be possible to view &lt;code&gt;self&lt;/code&gt; tensor as &lt;code&gt;shape&lt;/code&gt; without copying it (e.g., via &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt;&lt;code&gt;contiguous()&lt;/code&gt;&lt;/a&gt;). When it is unclear whether a &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;view()&lt;/code&gt;&lt;/a&gt; can be performed, it is advisable to use &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt;&lt;code&gt;reshape()&lt;/code&gt;&lt;/a&gt;, which returns a view if the shapes are compatible, and copies (equivalent to calling &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt;&lt;code&gt;contiguous()&lt;/code&gt;&lt;/a&gt;) otherwise.</source>
          <target state="translated">Otherwise, it will not be possible to view &lt;code&gt;self&lt;/code&gt; tensor as &lt;code&gt;shape&lt;/code&gt; without copying it (e.g., via &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt; &lt;code&gt;contiguous()&lt;/code&gt; &lt;/a&gt;). When it is unclear whether a &lt;a href=&quot;#torch.Tensor.view&quot;&gt; &lt;code&gt;view()&lt;/code&gt; &lt;/a&gt; can be performed, it is advisable to use &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt; &lt;code&gt;reshape()&lt;/code&gt; &lt;/a&gt;, which returns a view if the shapes are compatible, and copies (equivalent to calling &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt; &lt;code&gt;contiguous()&lt;/code&gt; &lt;/a&gt;) otherwise.</target>
        </trans-unit>
        <trans-unit id="5cbc6561d27e47c3ea5b5fa6d9459eb9629b7617" translate="yes" xml:space="preserve">
          <source>Otherwise:</source>
          <target state="translated">Otherwise:</target>
        </trans-unit>
        <trans-unit id="d386f5cc6857d8a2d7baf372e44b4d1117dfed1a" translate="yes" xml:space="preserve">
          <source>Our solution is that BCELoss clamps its log function outputs to be greater than or equal to -100. This way, we can always have a finite loss value and a linear backward method.</source>
          <target state="translated">私たちの解決策は、BCELossがその対数関数の出力を-100以上になるようにクランプすることです。このようにして、我々は常に有限の損失値と線形後方法を持つことができます。</target>
        </trans-unit>
        <trans-unit id="02600672b80ab0a1c4955d9a3e0f68bbce6d3eed" translate="yes" xml:space="preserve">
          <source>Our sparse tensor format permits &lt;em&gt;uncoalesced&lt;/em&gt; sparse tensors, where there may be duplicate coordinates in the indices; in this case, the interpretation is that the value at that index is the sum of all duplicate value entries. Uncoalesced tensors permit us to implement certain operators more efficiently.</source>
          <target state="translated">Our sparse tensor format permits &lt;em&gt;uncoalesced&lt;/em&gt; sparse tensors, where there may be duplicate coordinates in the indices; in this case, the interpretation is that the value at that index is the sum of all duplicate value entries. Uncoalesced tensors permit us to implement certain operators more efficiently.</target>
        </trans-unit>
        <trans-unit id="48c4c6b206793564023af6432f79ea36266139f9" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt;&lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt;&lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt; &lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt; &lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="99a0b833417509afcf74b89d81969fd3e6454e0f" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt;&lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt;&lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt; &lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt; &lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="f02f9ec70b467240dbc6d49d1fba7b03c1442801" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt;&lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt;&lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt; &lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt; &lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="5a8086fbdf63aa63eb1e982f564377b659f098f0" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_fill_&quot;&gt;&lt;code&gt;torch.Tensor.masked_fill_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_fill_&quot;&gt; &lt;code&gt;torch.Tensor.masked_fill_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="73076ad1c2f9be4b4d38d73b62e6c3e6c045bec2" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_scatter_&quot;&gt;&lt;code&gt;torch.Tensor.masked_scatter_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_scatter_&quot;&gt; &lt;code&gt;torch.Tensor.masked_scatter_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e013688ad79fc825d3497306dc29bb552d0e34c4" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_&quot;&gt;&lt;code&gt;torch.Tensor.scatter_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_&quot;&gt; &lt;code&gt;torch.Tensor.scatter_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="725700a259ff1b2b017f60b4e74698aa49714d29" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_add_&quot;&gt;&lt;code&gt;torch.Tensor.scatter_add_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_add_&quot;&gt; &lt;code&gt;torch.Tensor.scatter_add_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6398fea054e2780d871397e980d3cf8c7e956e4c" translate="yes" xml:space="preserve">
          <source>Out-place version of &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt;&lt;code&gt;index_put_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt;&lt;code&gt;torch.Tensor.index_put_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-place version of &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt; &lt;code&gt;index_put_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt; &lt;code&gt;torch.Tensor.index_put_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="33c36eb13432b5622fd7de9ba502b6b4e6d48ded" translate="yes" xml:space="preserve">
          <source>Outer product of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;vec2&lt;/code&gt; の外積。</target>
        </trans-unit>
        <trans-unit id="615e0188218c976163bf2ec4e7c83bb336305665" translate="yes" xml:space="preserve">
          <source>Outer product of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt;. If &lt;code&gt;input&lt;/code&gt; is a vector of size</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;vec2&lt;/code&gt; の外積。場合は &lt;code&gt;input&lt;/code&gt; サイズのベクトルであります</target>
        </trans-unit>
        <trans-unit id="67a0062a0687696c335a2c7d0e459405eba90f74" translate="yes" xml:space="preserve">
          <source>Output lists. It should contain correctly-sized tensors on each GPU to be used for output of the collective, e.g. &lt;code&gt;output_tensor_lists[i]&lt;/code&gt; contains the all_gather result that resides on the GPU of &lt;code&gt;input_tensor_list[i]&lt;/code&gt;.</source>
          <target state="translated">出力リスト。それは例えば、集団の出力に使用する各GPU上の正しくサイズのテンソルを含まなければならない &lt;code&gt;output_tensor_lists[i]&lt;/code&gt; all_gather結果のGPUに存在することを含んで &lt;code&gt;input_tensor_list[i]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1b572830da9a955103a98dbcea6dc96cd3c1bf56" translate="yes" xml:space="preserve">
          <source>Output of running &lt;code&gt;function&lt;/code&gt; on &lt;code&gt;*args&lt;/code&gt;</source>
          <target state="translated">実行中の出力 &lt;code&gt;function&lt;/code&gt; 上 &lt;code&gt;*args&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="90de97722219af193315e02c2b185d1c1a5a4186" translate="yes" xml:space="preserve">
          <source>Output of running &lt;code&gt;functions&lt;/code&gt; sequentially on &lt;code&gt;*inputs&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;*inputs&lt;/code&gt; で実行中の &lt;code&gt;functions&lt;/code&gt; 順番に出力</target>
        </trans-unit>
        <trans-unit id="613a57f34002b7db7e7eb40fb879941fd5f0eb57" translate="yes" xml:space="preserve">
          <source>Output shape: &lt;code&gt;(B, embedding_dim)&lt;/code&gt;</source>
          <target state="translated">出力形状： &lt;code&gt;(B, embedding_dim)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f6a2e936babf4473798688e71160bef838804c5c" translate="yes" xml:space="preserve">
          <source>Output tensors (on different GPUs) to receive the result of the operation.</source>
          <target state="translated">演算結果を受け取るための出力テンソル(異なるGPU上で)。</target>
        </trans-unit>
        <trans-unit id="be4dd5eb977c617cc4374f35ce4dcfe3424e6c52" translate="yes" xml:space="preserve">
          <source>Output1:</source>
          <target state="translated">Output1:</target>
        </trans-unit>
        <trans-unit id="099f2ae15e5d444369fa820ff7e04ecd1eccb38d" translate="yes" xml:space="preserve">
          <source>Output2:</source>
          <target state="translated">Output2:</target>
        </trans-unit>
        <trans-unit id="f3c8c95c5e534bcd2ea0034a0d83177efa6923f4" translate="yes" xml:space="preserve">
          <source>Output:</source>
          <target state="translated">Output:</target>
        </trans-unit>
        <trans-unit id="8063b576f684099c293104f0277e7a1383d61e53" translate="yes" xml:space="preserve">
          <source>Output: &lt;code&gt;(*, embedding_dim)&lt;/code&gt;, where &lt;code&gt;*&lt;/code&gt; is the input shape</source>
          <target state="translated">出力： &lt;code&gt;(*, embedding_dim)&lt;/code&gt; 、ここで &lt;code&gt;*&lt;/code&gt; は入力形状です</target>
        </trans-unit>
        <trans-unit id="7b14dfe86f44f01989354331a43a653a7f8d7f72" translate="yes" xml:space="preserve">
          <source>Output: A Tensor of shape</source>
          <target state="translated">出力します。形状のテンソル</target>
        </trans-unit>
        <trans-unit id="4a4fbbd55c6c3ccbf6bf7220f45ac1790ff9bb33" translate="yes" xml:space="preserve">
          <source>Output: scalar by default. If :attr:&lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then</source>
          <target state="translated">出力：デフォルトではスカラー。：attr： &lt;code&gt;reduction&lt;/code&gt; が &lt;code&gt;'none'&lt;/code&gt; の場合、</target>
        </trans-unit>
        <trans-unit id="7166320ecb31bd6a3586040c60443c5f16f96651" translate="yes" xml:space="preserve">
          <source>Output: scalar by default. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then</source>
          <target state="translated">出力：デフォルトではスカラー。場合 &lt;code&gt;reduction&lt;/code&gt; ありません &lt;code&gt;'none'&lt;/code&gt; 、そして、</target>
        </trans-unit>
        <trans-unit id="88a34ee124c80fdb97be4c7994066abce0b11c8e" translate="yes" xml:space="preserve">
          <source>Output: scalar. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then</source>
          <target state="translated">出力：スカラー。場合 &lt;code&gt;reduction&lt;/code&gt; ありません &lt;code&gt;'none'&lt;/code&gt; 、そして、</target>
        </trans-unit>
        <trans-unit id="816914c299df40485ecf46a1e795a1eb404d91d8" translate="yes" xml:space="preserve">
          <source>Output: scalar. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then same shape as the input</source>
          <target state="translated">出力：スカラー。 &lt;code&gt;reduction&lt;/code&gt; が &lt;code&gt;'none'&lt;/code&gt; 場合、入力と同じ形状</target>
        </trans-unit>
        <trans-unit id="573c4c1298793f227765c23e85deebaee6066af6" translate="yes" xml:space="preserve">
          <source>Output: scalar. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then the same size as the target:</source>
          <target state="translated">出力：スカラー。 &lt;code&gt;reduction&lt;/code&gt; が &lt;code&gt;'none'&lt;/code&gt; 場合、ターゲットと同じサイズ：</target>
        </trans-unit>
        <trans-unit id="6ee76fa98a639a0ac269010b7032639b0a171647" translate="yes" xml:space="preserve">
          <source>Outputs:</source>
          <target state="translated">Outputs:</target>
        </trans-unit>
        <trans-unit id="19620445bec40ebeb61b840841c0effef04f34be" translate="yes" xml:space="preserve">
          <source>Outputs: (h_1, c_1)</source>
          <target state="translated">出力。(h_1,c_1)</target>
        </trans-unit>
        <trans-unit id="9b4d142414484eb98f10e629a2f06df85748b811" translate="yes" xml:space="preserve">
          <source>Outputs: h&amp;rsquo;</source>
          <target state="translated">出力：h '</target>
        </trans-unit>
        <trans-unit id="511c97e64880de564b0676893af9fcc8a480a2e2" translate="yes" xml:space="preserve">
          <source>Outputs: output, (h_n, c_n)</source>
          <target state="translated">出力:出力、(h_n,c_n)</target>
        </trans-unit>
        <trans-unit id="a459eb30ab99f3ae5b662cb99c1f4215b146179c" translate="yes" xml:space="preserve">
          <source>Outputs: output, h_n</source>
          <target state="translated">出力:出力、h_n</target>
        </trans-unit>
        <trans-unit id="3454926b31857082d753c8156d0ffd5035b9d6b1" translate="yes" xml:space="preserve">
          <source>Overloaded function.</source>
          <target state="translated">オーバーロードされた機能。</target>
        </trans-unit>
        <trans-unit id="23672df91d237894c7bd8c7afdec0a1cd14fb6f6" translate="yes" xml:space="preserve">
          <source>Owner Share RRef with User</source>
          <target state="translated">オーナー共有RRefをユーザーと共有</target>
        </trans-unit>
        <trans-unit id="511993d3c99719e38a6779073019dacd7178ddb9" translate="yes" xml:space="preserve">
          <source>P</source>
          <target state="translated">P</target>
        </trans-unit>
        <trans-unit id="4a6bac0b7fcbb3ba201bd5676355ccb5034a278a" translate="yes" xml:space="preserve">
          <source>P(x) = \dfrac{1}{\text{to} - \text{from}}</source>
          <target state="translated">P(x)=\dfrac{1}{Text{to}-¶Text{from}}}}。</target>
        </trans-unit>
        <trans-unit id="964bd5656c7a016ef0c9ada7382da7ca1fee27a4" translate="yes" xml:space="preserve">
          <source>PRODUCT</source>
          <target state="translated">PRODUCT</target>
        </trans-unit>
        <trans-unit id="768bfcbbf6df966e333cf0230ff5aeca88678ff9" translate="yes" xml:space="preserve">
          <source>PReLU</source>
          <target state="translated">PReLU</target>
        </trans-unit>
        <trans-unit id="c6672b1c1e9f2629ba013dde01df96129b495f92" translate="yes" xml:space="preserve">
          <source>PackedSequence</source>
          <target state="translated">PackedSequence</target>
        </trans-unit>
        <trans-unit id="c0577f7163ed4ff21523cd27bc5236f92de452c9" translate="yes" xml:space="preserve">
          <source>Packs a Tensor containing padded sequences of variable length.</source>
          <target state="translated">可変長のパッド付きシーケンスを含むテンソルをパックします。</target>
        </trans-unit>
        <trans-unit id="65d415f11a63c4c34ebb5de81f2e889c9328e53e" translate="yes" xml:space="preserve">
          <source>Packs a list of variable length Tensors</source>
          <target state="translated">可変長テンソルのリストをパックします。</target>
        </trans-unit>
        <trans-unit id="019020b0e5b242a0cc1a8528059f3ad86084afa9" translate="yes" xml:space="preserve">
          <source>Pad a list of variable length Tensors with &lt;code&gt;padding_value&lt;/code&gt;</source>
          <target state="translated">パッド付き可変長テンソルのリスト &lt;code&gt;padding_value&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2560c7ddae8fa20bff911361bd8035aef865bce1" translate="yes" xml:space="preserve">
          <source>Padding Layers</source>
          <target state="translated">パディング層</target>
        </trans-unit>
        <trans-unit id="119765b1620180622c6f6bb53002149703be9254" translate="yes" xml:space="preserve">
          <source>Padding mode:</source>
          <target state="translated">パディングモード。</target>
        </trans-unit>
        <trans-unit id="c28c7b4763bce482c5c0e969cee27313a7b7a4b3" translate="yes" xml:space="preserve">
          <source>Padding size:</source>
          <target state="translated">詰め物のサイズ。</target>
        </trans-unit>
        <trans-unit id="01c1aebd02a3849d24632e98070e328ff731c754" translate="yes" xml:space="preserve">
          <source>Pads a packed batch of variable length sequences.</source>
          <target state="translated">可変長のシーケンスをパックしたバッチをパッドします。</target>
        </trans-unit>
        <trans-unit id="5f2ca3b7c48057f8a6249de795ad4677ba74df59" translate="yes" xml:space="preserve">
          <source>Pads tensor.</source>
          <target state="translated">パッドテンソル。</target>
        </trans-unit>
        <trans-unit id="340e6f3d3040c075fcd53240ac5a1540bc713e60" translate="yes" xml:space="preserve">
          <source>Pads the input tensor boundaries with a constant value.</source>
          <target state="translated">入力テンソルの境界を一定の値でパッドします。</target>
        </trans-unit>
        <trans-unit id="66887cd786c809b7e475e385b383407a6d7e005a" translate="yes" xml:space="preserve">
          <source>Pads the input tensor boundaries with zero.</source>
          <target state="translated">入力テンソルの境界をゼロでパッドします。</target>
        </trans-unit>
        <trans-unit id="15f49157ae62175a9c8bfe59b0dd171af5f13c80" translate="yes" xml:space="preserve">
          <source>Pads the input tensor using replication of the input boundary.</source>
          <target state="translated">入力境界の複製を使用して入力テンソルをパッドします。</target>
        </trans-unit>
        <trans-unit id="2095464e9318d466281e389dabe7d857b2607c1d" translate="yes" xml:space="preserve">
          <source>Pads the input tensor using the reflection of the input boundary.</source>
          <target state="translated">入力境界の反射を利用して入力テンソルをパッドします。</target>
        </trans-unit>
        <trans-unit id="9b861161343780fb206bb4b2ff66ca3fba1cab61" translate="yes" xml:space="preserve">
          <source>PairwiseDistance</source>
          <target state="translated">PairwiseDistance</target>
        </trans-unit>
        <trans-unit id="1ad9f67d0f855f646efb3775c7a4778a3cc5a138" translate="yes" xml:space="preserve">
          <source>Parallelism</source>
          <target state="translated">Parallelism</target>
        </trans-unit>
        <trans-unit id="f699f295e5ae4ac633cfa18437fed38d028b3fdb" translate="yes" xml:space="preserve">
          <source>Parameter</source>
          <target state="translated">Parameter</target>
        </trans-unit>
        <trans-unit id="cb5ac90fcc6e04cb5c8cae65265e51f0ab35a0b7" translate="yes" xml:space="preserve">
          <source>Parameter names except the first must EXACTLY match the names in &lt;code&gt;forward&lt;/code&gt;.</source>
          <target state="translated">最初のパラメータ以外のパラメータ名は、 &lt;code&gt;forward&lt;/code&gt; の名前と完全に一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="4891fc0302ab937e6c97e91f093534d4afb88b1e" translate="yes" xml:space="preserve">
          <source>Parameter ordering does NOT necessarily match what is in &lt;code&gt;VariableType.h&lt;/code&gt;, tensors (inputs) are always first, then non-tensor arguments.</source>
          <target state="translated">パラメータの順序は、 &lt;code&gt;VariableType.h&lt;/code&gt; の順序と必ずしも一致しません。テンソル（入力）が常に最初で、次に非テンソル引数です。</target>
        </trans-unit>
        <trans-unit id="88be3e0f29cc772e39dc2a268a55384b430d8f22" translate="yes" xml:space="preserve">
          <source>ParameterDict</source>
          <target state="translated">ParameterDict</target>
        </trans-unit>
        <trans-unit id="63777906465127a1bb8f4e009ca405717880743f" translate="yes" xml:space="preserve">
          <source>ParameterDict can be indexed like a regular Python dictionary, but parameters it contains are properly registered, and will be visible by all Module methods.</source>
          <target state="translated">ParameterDictは通常のPython辞書のようにインデックス化することができますが、それに含まれるパラメータは適切に登録されており、すべてのモジュールメソッドから可視化されます。</target>
        </trans-unit>
        <trans-unit id="acdf35da4c553e1dfc2210109486c37c589cbf86" translate="yes" xml:space="preserve">
          <source>ParameterList</source>
          <target state="translated">ParameterList</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="b2ef1af91a76a3fb94590270b4864284563ecce3" translate="yes" xml:space="preserve">
          <source>Parameters are &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;&lt;code&gt;Tensor&lt;/code&gt;&lt;/a&gt; subclasses, that have a very special property when used with &lt;code&gt;Module&lt;/code&gt; s - when they&amp;rsquo;re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in &lt;code&gt;parameters()&lt;/code&gt; iterator. Assigning a Tensor doesn&amp;rsquo;t have such effect. This is because one might want to cache some temporary state, like last hidden state of the RNN, in the model. If there was no such class as &lt;a href=&quot;#torch.nn.parameter.Parameter&quot;&gt;&lt;code&gt;Parameter&lt;/code&gt;&lt;/a&gt;, these temporaries would get registered too.</source>
          <target state="translated">パラメータは&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt; &lt;code&gt;Tensor&lt;/code&gt; &lt;/a&gt;サブクラスであり、 &lt;code&gt;Module&lt;/code&gt; で使用すると非常に特殊なプロパティがあります。Module属性として割り当てられると、パラメータのリストに自動的に追加され、たとえば &lt;code&gt;parameters()&lt;/code&gt; イテレータに表示されます。テンソルを割り当てても、そのような効果はありません。これは、RNNの最後の非表示状態など、一時的な状態をモデルにキャッシュしたい場合があるためです。&lt;a href=&quot;#torch.nn.parameter.Parameter&quot;&gt; &lt;code&gt;Parameter&lt;/code&gt; &lt;/a&gt;のようなクラスがなかった場合、これらの一時的なものも登録されます。</target>
        </trans-unit>
        <trans-unit id="3df6923b905b81224f8a63a634516931831a9327" translate="yes" xml:space="preserve">
          <source>Parameters are never broadcast between processes. The module performs an all-reduce step on gradients and assumes that they will be modified by the optimizer in all processes in the same way. Buffers (e.g. BatchNorm stats) are broadcast from the module in process of rank 0, to all other replicas in the system in every iteration.</source>
          <target state="translated">パラメータはプロセス間でブロードキャストされることはありません。モジュールはグラデーションに対して全削減ステップを実行し、すべてのプロセスで同じようにオプティマイザによって変更されることを前提としています。バッファ(例えば、BatchNorm統計値)は、ランク0のプロセスのモジュールから、システム内の他のすべてのレプリカに、反復ごとにブロードキャストされます。</target>
        </trans-unit>
        <trans-unit id="794cc4ffc58cd8aa6cf549921b36b20e1749013e" translate="yes" xml:space="preserve">
          <source>Parameters need to be specified as collections that have a deterministic ordering that is consistent between runs. Examples of objects that don&amp;rsquo;t satisfy those properties are sets and iterators over values of dictionaries.</source>
          <target state="translated">パラメーターは、実行間で一貫した決定論的な順序を持つコレクションとして指定する必要があります。これらのプロパティを満たさないオブジェクトの例は、辞書の値に対するセットとイテレータです。</target>
        </trans-unit>
        <trans-unit id="63ed4981dcd5565ccc67fe6943dae94af81704fd" translate="yes" xml:space="preserve">
          <source>Pareto</source>
          <target state="translated">Pareto</target>
        </trans-unit>
        <trans-unit id="a70edfd33f03d14b9304a9ca1fe474eaf0817702" translate="yes" xml:space="preserve">
          <source>Parsing the local_rank argument</source>
          <target state="translated">local_rank 引数のパース</target>
        </trans-unit>
        <trans-unit id="48a79b6f6f692b43d8485194d95ec3b0c6abe1d9" translate="yes" xml:space="preserve">
          <source>Pass the input through the encoder layer.</source>
          <target state="translated">入力をエンコーダ層に通します。</target>
        </trans-unit>
        <trans-unit id="74a6cfbb8f181d4db771aa9745afb6080e4ee4fe" translate="yes" xml:space="preserve">
          <source>Pass the input through the encoder layers in turn.</source>
          <target state="translated">入力を順番にエンコーダ層に通します。</target>
        </trans-unit>
        <trans-unit id="4d0cc1f642a2a736b4718ae462ea2ac809ed76b7" translate="yes" xml:space="preserve">
          <source>Pass the inputs (and mask) through the decoder layer in turn.</source>
          <target state="translated">入力(とマスク)を順番にデコーダ層に通します。</target>
        </trans-unit>
        <trans-unit id="8c65d8ab6bdf0e2280cb1ffcf102aefaac492303" translate="yes" xml:space="preserve">
          <source>Pass the inputs (and mask) through the decoder layer.</source>
          <target state="translated">入力(とマスク)をデコーダーレイヤーに通します。</target>
        </trans-unit>
        <trans-unit id="fd97c67f36d1e3c87f8ab45030bd4f215e7035cc" translate="yes" xml:space="preserve">
          <source>Passing -1 as the size for a dimension means not changing the size of that dimension.</source>
          <target state="translated">寸法のサイズとして -1 を渡すと、その寸法のサイズを変更しないことを意味します。</target>
        </trans-unit>
        <trans-unit id="1ade9bd239bdf873c59edb2cc4d6f0dd2841681d" translate="yes" xml:space="preserve">
          <source>Passing &lt;code&gt;new_scale&lt;/code&gt; sets the scale directly.</source>
          <target state="translated">&lt;code&gt;new_scale&lt;/code&gt; を渡すと、スケールが直接設定されます。</target>
        </trans-unit>
        <trans-unit id="6f36a4168bfec1245f47f9820a4b54d62ffb6bc8" translate="yes" xml:space="preserve">
          <source>Pathwise derivative</source>
          <target state="translated">パスワイズ誘導体</target>
        </trans-unit>
        <trans-unit id="ea3c8179bd96f54267bf75b132502b2bb1730b13" translate="yes" xml:space="preserve">
          <source>Pattern Matching Assignments</source>
          <target state="translated">パターンマッチングの割り当て</target>
        </trans-unit>
        <trans-unit id="246efe0491937cc86746284b090916b8754123a3" translate="yes" xml:space="preserve">
          <source>Per-parameter options</source>
          <target state="translated">パラメータごとのオプション</target>
        </trans-unit>
        <trans-unit id="bbb4559fe386a24723c5dad9bdcdef77441cfdce" translate="yes" xml:space="preserve">
          <source>Perform a shutdown of the RPC agent, and then destroy the RPC agent. This stops the local agent from accepting outstanding requests, and shuts down the RPC framework by terminating all RPC threads. If &lt;code&gt;graceful=True&lt;/code&gt;, this will block until all local and remote RPC processes reach this method and wait for all outstanding work to complete. Otherwise, if &lt;code&gt;graceful=False&lt;/code&gt;, this is a local shutdown, and it does not wait for other RPC processes to reach this method.</source>
          <target state="translated">RPCエージェントのシャットダウンを実行してから、RPCエージェントを破棄します。これにより、ローカルエージェントが未処理の要求を受け入れるのを停止し、すべてのRPCスレッドを終了してRPCフレームワークをシャットダウンします。 &lt;code&gt;graceful=True&lt;/code&gt; の場合、これはすべてのローカルおよびリモートRPCプロセスがこのメソッドに到達するまでブロックし、すべての未処理の作業が完了するのを待ちます。それ以外の場合、 &lt;code&gt;graceful=False&lt;/code&gt; の場合、これはローカルシャットダウンであり、他のRPCプロセスがこのメソッドに到達するのを待ちません。</target>
        </trans-unit>
        <trans-unit id="000d790b0603ede49c70b8206287b63e59d6ce01" translate="yes" xml:space="preserve">
          <source>Performs</source>
          <target state="translated">Performs</target>
        </trans-unit>
        <trans-unit id="ab6a68d7b5ed065f1d2b1e10ab32e7ca4fa89132" translate="yes" xml:space="preserve">
          <source>Performs Tensor dtype and/or device conversion. A &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; are inferred from the arguments of &lt;code&gt;self.to(*args, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">Tensordtypeおよび/またはデバイス変換を実行します。&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; は&lt;/a&gt;の引数から推論されている &lt;code&gt;self.to(*args, **kwargs)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="148ba906f736c7be8f3690226a95e0fc3751c601" translate="yes" xml:space="preserve">
          <source>Performs a &amp;ldquo;true&amp;rdquo; division like Python 3. See &lt;a href=&quot;torch.floor_divide#torch.floor_divide&quot;&gt;&lt;code&gt;torch.floor_divide()&lt;/code&gt;&lt;/a&gt; for floor division.</source>
          <target state="translated">Python 3のような「真の」除算を実行します。フロア除算については、&lt;a href=&quot;torch.floor_divide#torch.floor_divide&quot;&gt; &lt;code&gt;torch.floor_divide()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="ca1d45c075edfbcf89b6d16ec3eabd49d65b9ace" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;.</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; の行列の行列積。</target>
        </trans-unit>
        <trans-unit id="1d3416bea00d8ee005b5f0e7621baf85cbbbc8e4" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; の行列の行列積。 &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="6629b05e96ef663c5b3cf02ed167a20014b205ec" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices stored in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;, with a reduced add step (all matrix multiplications get accumulated along the first dimension).</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; に格納された行列の行列積を、追加ステップを減らして実行します（すべての行列の乗算は最初の次元に沿って累積されます）。</target>
        </trans-unit>
        <trans-unit id="1710424b09b25bd3fe48dce1c221f445326275f1" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices stored in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;, with a reduced add step (all matrix multiplications get accumulated along the first dimension). &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; に格納された行列の行列積を、追加ステップを減らして実行します（すべての行列の乗算は最初の次元に沿って累積されます）。 &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="6860592c3b78f43f0a520489d41db750bddd29e5" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices stored in &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; に格納されている行列のバッチ行列-行列積を実行します。</target>
        </trans-unit>
        <trans-unit id="df9a63e54344ddcdcb571d3c78f6a26c0d733eac" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the matrices &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;input&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。</target>
        </trans-unit>
        <trans-unit id="e06b6aa87fc19869b8dd410c826fba4f794df727" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the matrices &lt;code&gt;mat1&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;mat1&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。</target>
        </trans-unit>
        <trans-unit id="bc47b86c1cbb06be939cda2d15d03119065f2793" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the matrices &lt;code&gt;mat1&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;. The matrix &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">行列 &lt;code&gt;mat1&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。マトリックス &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="ec815028dc3febded0f07da8c4424505ed14884e" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the sparse matrix &lt;code&gt;mat1&lt;/code&gt; and dense matrix &lt;code&gt;mat2&lt;/code&gt;. Similar to &lt;a href=&quot;generated/torch.mm#torch.mm&quot;&gt;&lt;code&gt;torch.mm()&lt;/code&gt;&lt;/a&gt;, If &lt;code&gt;mat1&lt;/code&gt; is a</source>
          <target state="translated">スパース行列 &lt;code&gt;mat1&lt;/code&gt; とデンス行列 &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。&lt;a href=&quot;generated/torch.mm#torch.mm&quot;&gt; &lt;code&gt;torch.mm()&lt;/code&gt; &lt;/a&gt;と同様に、 &lt;code&gt;mat1&lt;/code&gt; が</target>
        </trans-unit>
        <trans-unit id="0fcbec8807d0db14810ce48d50247513762338dc" translate="yes" xml:space="preserve">
          <source>Performs a matrix-vector product of the matrix &lt;code&gt;input&lt;/code&gt; and the vector &lt;code&gt;vec&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;input&lt;/code&gt; とベクトル &lt;code&gt;vec&lt;/code&gt; の行列-ベクトル積を実行します。</target>
        </trans-unit>
        <trans-unit id="fd688cf71edd9657ad9f3dba62a61d9bb7db410e" translate="yes" xml:space="preserve">
          <source>Performs a matrix-vector product of the matrix &lt;code&gt;mat&lt;/code&gt; and the vector &lt;code&gt;vec&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;mat&lt;/code&gt; とベクトル &lt;code&gt;vec&lt;/code&gt; の行列-ベクトル積を実行します。</target>
        </trans-unit>
        <trans-unit id="0d3f478da414f374637a9f8efee9102a8950a0aa" translate="yes" xml:space="preserve">
          <source>Performs a matrix-vector product of the matrix &lt;code&gt;mat&lt;/code&gt; and the vector &lt;code&gt;vec&lt;/code&gt;. The vector &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">行列 &lt;code&gt;mat&lt;/code&gt; とベクトル &lt;code&gt;vec&lt;/code&gt; の行列-ベクトル積を実行します。ベクトル &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="0efe20233a22c5777e16f0f9f23f0594b1694e45" translate="yes" xml:space="preserve">
          <source>Performs a single optimization step (parameter update).</source>
          <target state="translated">単一の最適化ステップ(パラメータ更新)を実行します。</target>
        </trans-unit>
        <trans-unit id="eb4301873be53ea1f5d5d9d23cf8670a4bf294c6" translate="yes" xml:space="preserve">
          <source>Performs a single optimization step.</source>
          <target state="translated">単一の最適化ステップを実行します。</target>
        </trans-unit>
        <trans-unit id="097227fe1294d426da153667fbb89e50d7a799f6" translate="yes" xml:space="preserve">
          <source>Performs dtype and/or device conversion on &lt;code&gt;self.data&lt;/code&gt;.</source>
          <target state="translated">上の実行DTYPE及び/又はデバイス変換 &lt;code&gt;self.data&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="50008568c0d385fc9c65f3ac3f0c22f33a0fd7e8" translate="yes" xml:space="preserve">
          <source>Performs linear Principal Component Analysis (PCA) on a low-rank matrix, batches of such matrices, or sparse matrix.</source>
          <target state="translated">低ランク行列,そのような行列のバッチ,または疎な行列に対して線形主成分分析(PCA)を実行します.</target>
        </trans-unit>
        <trans-unit id="20ee59ad32c7c62194b8cc1470dab04b5aeb1063" translate="yes" xml:space="preserve">
          <source>Performs the element-wise division of &lt;code&gt;tensor1&lt;/code&gt; by &lt;code&gt;tensor2&lt;/code&gt;, multiply the result by the scalar &lt;code&gt;value&lt;/code&gt; and add it to &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;tensor1&lt;/code&gt; を &lt;code&gt;tensor2&lt;/code&gt; で要素ごとに除算し、その結果にスカラー &lt;code&gt;value&lt;/code&gt; を掛けて、 &lt;code&gt;input&lt;/code&gt; 追加します。</target>
        </trans-unit>
        <trans-unit id="20dfc56a802418cc6cb883565e29a8149e17cc74" translate="yes" xml:space="preserve">
          <source>Performs the element-wise multiplication of &lt;code&gt;tensor1&lt;/code&gt; by &lt;code&gt;tensor2&lt;/code&gt;, multiply the result by the scalar &lt;code&gt;value&lt;/code&gt; and add it to &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">実行の要素ごとの乗算 &lt;code&gt;tensor1&lt;/code&gt; によって &lt;code&gt;tensor2&lt;/code&gt; 、乗算スカラーによって結果 &lt;code&gt;value&lt;/code&gt; とにそれを追加 &lt;code&gt;input&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5b3394929b52d1d2c8a062a547e9e7818f342005" translate="yes" xml:space="preserve">
          <source>Performs the operation.</source>
          <target state="translated">操作を実行します。</target>
        </trans-unit>
        <trans-unit id="b8d3d151e5b759fb242c35ceb1f1a9e038806294" translate="yes" xml:space="preserve">
          <source>Performs the outer-product of vectors &lt;code&gt;vec1&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; and adds it to the matrix &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">ベクトル &lt;code&gt;vec1&lt;/code&gt; と &lt;code&gt;vec2&lt;/code&gt; の外積を実行し、それを行列 &lt;code&gt;input&lt;/code&gt; 追加します。</target>
        </trans-unit>
        <trans-unit id="7775a934f392a3fd32435cb3afba7f94cd7e9125" translate="yes" xml:space="preserve">
          <source>Permutes the dimensions of the &lt;code&gt;self&lt;/code&gt; tensor to match the dimension order in the &lt;code&gt;other&lt;/code&gt; tensor, adding size-one dims for any new names.</source>
          <target state="translated">並べ替えるの寸法 &lt;code&gt;self&lt;/code&gt; テンソルのディメンションの順序と一致するように、 &lt;code&gt;other&lt;/code&gt; 任意の新しい名前のためにサイズ-1暗くなるの追加、テンソル。</target>
        </trans-unit>
        <trans-unit id="172d57479053b5b2d1caa6f27506a79abfa3d89b" translate="yes" xml:space="preserve">
          <source>Permutes the dimensions of the &lt;code&gt;self&lt;/code&gt; tensor to match the order specified in &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt;, adding size-one dims for any new names.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの次元を&lt;a href=&quot;#torch.Tensor.names&quot;&gt; &lt;code&gt;names&lt;/code&gt; &lt;/a&gt;で指定された順序に一致するように並べ替え、新しい名前にサイズ1の薄暗い値を追加します。</target>
        </trans-unit>
        <trans-unit id="89073f3c192cb17be2601e291aa1534b084f3029" translate="yes" xml:space="preserve">
          <source>PixelShuffle</source>
          <target state="translated">PixelShuffle</target>
        </trans-unit>
        <trans-unit id="c026434074e7feb786c10d360bdf80aa00a3000a" translate="yes" xml:space="preserve">
          <source>Platform-specific behaviors</source>
          <target state="translated">プラットフォーム固有の動作</target>
        </trans-unit>
        <trans-unit id="46d351806d607c75c00d9e7addd52a82379f8961" translate="yes" xml:space="preserve">
          <source>Please checkout &lt;a href=&quot;#tracing-vs-scripting&quot;&gt;Tracing vs Scripting&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#tracing-vs-scripting&quot;&gt;トレースとスクリプトを確認して&lt;/a&gt;ください。</target>
        </trans-unit>
        <trans-unit id="77243e0c917ac356b20b9bd68dd15bf839ebd531" translate="yes" xml:space="preserve">
          <source>Please ensure that &lt;code&gt;device_ids&lt;/code&gt; argument is set to be the only GPU device id that your code will be operating on. This is generally the local rank of the process. In other words, the &lt;code&gt;device_ids&lt;/code&gt; needs to be &lt;code&gt;[args.local_rank]&lt;/code&gt;, and &lt;code&gt;output_device&lt;/code&gt; needs to be &lt;code&gt;args.local_rank&lt;/code&gt; in order to use this utility</source>
          <target state="translated">&lt;code&gt;device_ids&lt;/code&gt; 引数が、コードが動作する唯一のGPUデバイスIDに設定されていることを確認してください。これは通常、プロセスのローカルランクです。換言すれば、 &lt;code&gt;device_ids&lt;/code&gt; のニーズであると &lt;code&gt;[args.local_rank]&lt;/code&gt; 、及び &lt;code&gt;output_device&lt;/code&gt; する必要が &lt;code&gt;args.local_rank&lt;/code&gt; このユーティリティを使用するために</target>
        </trans-unit>
        <trans-unit id="489042bcd064b62307292513642ef8adc6ce3919" translate="yes" xml:space="preserve">
          <source>Please refer to &lt;a href=&quot;https://pytorch.org/tutorials/beginner/dist_overview.html&quot;&gt;PyTorch Distributed Overview&lt;/a&gt; for a brief introduction to all features related to distributed training.</source>
          <target state="translated">分散トレーニングに関連するすべての機能の簡単な紹介については、&lt;a href=&quot;https://pytorch.org/tutorials/beginner/dist_overview.html&quot;&gt;PyTorch分散概要&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="17832db8653d0843df90a5d67009e3924ef34997" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;#torch.Tensor.expand&quot;&gt;&lt;code&gt;expand()&lt;/code&gt;&lt;/a&gt; for more information about &lt;code&gt;expand&lt;/code&gt;.</source>
          <target state="translated">参照してください&lt;a href=&quot;#torch.Tensor.expand&quot;&gt; &lt;code&gt;expand()&lt;/code&gt; &lt;/a&gt;の詳細については、 &lt;code&gt;expand&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5ec18ad55b74e4a4762c499e962c30b802cc51eb" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;view()&lt;/code&gt;&lt;/a&gt; for more information about &lt;code&gt;view&lt;/code&gt;.</source>
          <target state="translated">参照してください&lt;a href=&quot;#torch.Tensor.view&quot;&gt; &lt;code&gt;view()&lt;/code&gt; &lt;/a&gt;詳細については、 &lt;code&gt;view&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6ce3ed1431a0c41a218668fa1492f351b3c1863d" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt;&lt;code&gt;reshape()&lt;/code&gt;&lt;/a&gt; for more information about &lt;code&gt;reshape&lt;/code&gt;.</source>
          <target state="translated">参照してください&lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt; &lt;code&gt;reshape()&lt;/code&gt; &lt;/a&gt;詳細については、 &lt;code&gt;reshape&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="037ad39d2570fc5f7861f69bb41699739bb0d316" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU&lt;/a&gt; for more documentation on ReLU.</source>
          <target state="translated">ReLUの詳細については、&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU&quot;&gt;https：//pytorch.org/docs/stable/nn.html#torch.nn.ReLU&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="4353aa1de0244f4e4d17336cf0860de21b27bcfd" translate="yes" xml:space="preserve">
          <source>Point-to-point communication</source>
          <target state="translated">ポイントツーポイント通信</target>
        </trans-unit>
        <trans-unit id="f2954403f1437b0d34c50ea2ba4d35acd2ad8ef0" translate="yes" xml:space="preserve">
          <source>Pointwise Ops</source>
          <target state="translated">ポイントワイズオペレーション</target>
        </trans-unit>
        <trans-unit id="7f6c43edfe5b4aaaf229cadb3d90c7f7c42e39d6" translate="yes" xml:space="preserve">
          <source>Poisson</source>
          <target state="translated">Poisson</target>
        </trans-unit>
        <trans-unit id="fa7dfe92888800753b97007c7d56433a35b2c1ff" translate="yes" xml:space="preserve">
          <source>Poisson negative log likelihood loss.</source>
          <target state="translated">ポアソン負の対数尤度損失。</target>
        </trans-unit>
        <trans-unit id="080ef63a7d510bdbbbb0c01b547bfd9466aafda2" translate="yes" xml:space="preserve">
          <source>PoissonNLLLoss</source>
          <target state="translated">PoissonNLLLoss</target>
        </trans-unit>
        <trans-unit id="8774a7b82c80db34246fbe30ad918e5ef44c7d79" translate="yes" xml:space="preserve">
          <source>Pool type:</source>
          <target state="translated">プールタイプ。</target>
        </trans-unit>
        <trans-unit id="58ef016bfefe7d0fa87dbd8a9397011926b50b05" translate="yes" xml:space="preserve">
          <source>Pooling functions</source>
          <target state="translated">プーリング機能</target>
        </trans-unit>
        <trans-unit id="4f14f8bf99ac13b99d1b436dd62fcdf8537ddee0" translate="yes" xml:space="preserve">
          <source>Pooling layers</source>
          <target state="translated">層をプールする</target>
        </trans-unit>
        <trans-unit id="0b3306afd19e4390fd2c7bf86d987f82d98b6188" translate="yes" xml:space="preserve">
          <source>Pops a range off of a stack of nested range spans. Returns the zero-based depth of the range that is ended.</source>
          <target state="translated">ネストされた範囲スパンのスタックから範囲をポップします。終了した範囲のゼロベースの深さを返します。</target>
        </trans-unit>
        <trans-unit id="7280aa9b126e519bb5acdcab7417841a30bb930a" translate="yes" xml:space="preserve">
          <source>Possible values are:</source>
          <target state="translated">可能な値は以下の通りです。</target>
        </trans-unit>
        <trans-unit id="1774bc5c596634bc97c87b3b60bbe553b38e8300" translate="yes" xml:space="preserve">
          <source>Prefer &lt;code&gt;binary_cross_entropy_with_logits&lt;/code&gt; over &lt;code&gt;binary_cross_entropy&lt;/code&gt;</source>
          <target state="translated">優先 &lt;code&gt;binary_cross_entropy_with_logits&lt;/code&gt; オーバー &lt;code&gt;binary_cross_entropy&lt;/code&gt; を</target>
        </trans-unit>
        <trans-unit id="1167b0995920e6f31e81abce0609fca20a13f6e0" translate="yes" xml:space="preserve">
          <source>Prepares a copy of the model for quantization calibration or quantization-aware training and converts it to quantized version.</source>
          <target state="translated">量子化キャリブレーションや量子化を考慮したトレーニング用のモデルのコピーを用意し、量子化バージョンに変換します。</target>
        </trans-unit>
        <trans-unit id="17bb7ea4855300bdce06f568a4c1e23392bcdee5" translate="yes" xml:space="preserve">
          <source>Prepares a copy of the model for quantization calibration or quantization-aware training.</source>
          <target state="translated">量子化キャリブレーションや量子化を意識したトレーニングのためのモデルのコピーを用意します。</target>
        </trans-unit>
        <trans-unit id="3c85cac74e37970ecc55d37819ce7376a3e2e8cd" translate="yes" xml:space="preserve">
          <source>Preparing model for quantization</source>
          <target state="translated">量子化のためのモデルの準備</target>
        </trans-unit>
        <trans-unit id="6175db74ea439762cf31ac47bf2800599471e037" translate="yes" xml:space="preserve">
          <source>Pretrained weights can either be stored locally in the github repo, or loadable by &lt;a href=&quot;#torch.hub.load_state_dict_from_url&quot;&gt;&lt;code&gt;torch.hub.load_state_dict_from_url()&lt;/code&gt;&lt;/a&gt;. If less than 2GB, it&amp;rsquo;s recommended to attach it to a &lt;a href=&quot;https://help.github.com/en/articles/distributing-large-binaries&quot;&gt;project release&lt;/a&gt; and use the url from the release. In the example above &lt;code&gt;torchvision.models.resnet.resnet18&lt;/code&gt; handles &lt;code&gt;pretrained&lt;/code&gt;, alternatively you can put the following logic in the entrypoint definition.</source>
          <target state="translated">事前にトレーニングされたウェイトは、githubリポジトリにローカルに保存するか、&lt;a href=&quot;#torch.hub.load_state_dict_from_url&quot;&gt; &lt;code&gt;torch.hub.load_state_dict_from_url()&lt;/code&gt; で&lt;/a&gt;ロードできます。2GB未満の場合は、&lt;a href=&quot;https://help.github.com/en/articles/distributing-large-binaries&quot;&gt;プロジェクトリリース&lt;/a&gt;に添付して、リリースのURLを使用することをお勧めします。上記の例では、 &lt;code&gt;torchvision.models.resnet.resnet18&lt;/code&gt; が &lt;code&gt;pretrained&lt;/code&gt; トレーニング済みを処理します。または、エントリポイント定義に次のロジックを含めることもできます。</target>
        </trans-unit>
        <trans-unit id="c189714d06cfa7c01d24df029a774f3f30e4981e" translate="yes" xml:space="preserve">
          <source>Primarily used for quantization to float16 which doesn&amp;rsquo;t require determining ranges.</source>
          <target state="translated">主に、範囲を決定する必要のないfloat16への量子化に使用されます。</target>
        </trans-unit>
        <trans-unit id="fd6f86c9793df0ba1099fc411b3e7ec52a6a1cfe" translate="yes" xml:space="preserve">
          <source>Print Statements</source>
          <target state="translated">ステートメントの印刷</target>
        </trans-unit>
        <trans-unit id="fee7456cc782e1f8058fb173d31005a875e61eb8" translate="yes" xml:space="preserve">
          <source>Prints an EventList as a nicely formatted table.</source>
          <target state="translated">EventListをきれいにフォーマットされたテーブルとして出力します。</target>
        </trans-unit>
        <trans-unit id="06e3b604d03b7cb14c38bef03c1ff6819f9e40ec" translate="yes" xml:space="preserve">
          <source>Prior to PyTorch 1.1.0, the learning rate scheduler was expected to be called before the optimizer&amp;rsquo;s update; 1.1.0 changed this behavior in a BC-breaking way. If you use the learning rate scheduler (calling &lt;code&gt;scheduler.step()&lt;/code&gt;) before the optimizer&amp;rsquo;s update (calling &lt;code&gt;optimizer.step()&lt;/code&gt;), this will skip the first value of the learning rate schedule. If you are unable to reproduce results after upgrading to PyTorch 1.1.0, please check if you are calling &lt;code&gt;scheduler.step()&lt;/code&gt; at the wrong time.</source>
          <target state="translated">PyTorch 1.1.0より前は、オプティマイザーの更新前に学習率スケジューラーが呼び出されることが期待されていました。1.1.0は、この動作をBCを破る方法で変更しました。オプティマイザーの更新（ &lt;code&gt;optimizer.step()&lt;/code&gt; を呼び出す）の前に学習率スケジューラー（ &lt;code&gt;scheduler.step()&lt;/code&gt; を呼び出す）を使用する場合、これは学習率スケジュールの最初の値をスキップします。PyTorch 1.1.0にアップグレードした後、結果を再現できない場合は、 &lt;code&gt;scheduler.step()&lt;/code&gt; を間違ったタイミングで呼び出していないかどうかを確認してください。</target>
        </trans-unit>
        <trans-unit id="7444118490ce8aa2e0fbbbea8ea2ca65e38de32d" translate="yes" xml:space="preserve">
          <source>Probability distributions - torch.distributions</source>
          <target state="translated">確率分布-torch.distribution</target>
        </trans-unit>
        <trans-unit id="d36d84ef2381c76d6d53fffa7008829b5eaeb1fc" translate="yes" xml:space="preserve">
          <source>Process Group Backend</source>
          <target state="translated">プロセスグループ バックエンド</target>
        </trans-unit>
        <trans-unit id="40e121339893a371c4a1b2c140642c9b6a34e9bd" translate="yes" xml:space="preserve">
          <source>Produces several warnings and a graph which simply returns the input:</source>
          <target state="translated">複数の警告と,入力を単純に返すグラフを生成します.</target>
        </trans-unit>
        <trans-unit id="31da1961bbfc7c4ddeb384d30515cc288fec6568" translate="yes" xml:space="preserve">
          <source>Profiler</source>
          <target state="translated">Profiler</target>
        </trans-unit>
        <trans-unit id="a445fe395c6c6d32b8f6c47c9d18f8e8ae1263f5" translate="yes" xml:space="preserve">
          <source>Profiling RPC-based Workloads</source>
          <target state="translated">RPC ベースのワークロードのプロファイリング</target>
        </trans-unit>
        <trans-unit id="6f204147095385ad851c3a0b168d9ac27a7540b0" translate="yes" xml:space="preserve">
          <source>Promotion Examples:</source>
          <target state="translated">プロモーションの例。</target>
        </trans-unit>
        <trans-unit id="d29f4bd5abe504fd6f4217c42fe5687ce1f0ffba" translate="yes" xml:space="preserve">
          <source>Propagate qconfig through the module hierarchy and assign &lt;code&gt;qconfig&lt;/code&gt; attribute on each leaf module</source>
          <target state="translated">モジュール階層を介してqconfigを伝播し、各リーフモジュールに &lt;code&gt;qconfig&lt;/code&gt; 属性を割り当てます</target>
        </trans-unit>
        <trans-unit id="51f45d4a44ddb55152733d7d5ec938ec682205f1" translate="yes" xml:space="preserve">
          <source>Proposed by G. Hinton in his &lt;a href=&quot;https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf&quot;&gt;course&lt;/a&gt;.</source>
          <target state="translated">彼の&lt;a href=&quot;https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf&quot;&gt;コースで&lt;/a&gt;G.ヒントンによって提案されました。</target>
        </trans-unit>
        <trans-unit id="17a62537e52031c55b875c513ecbb2c241853032" translate="yes" xml:space="preserve">
          <source>Protocol Scenarios</source>
          <target state="translated">プロトコルのシナリオ</target>
        </trans-unit>
        <trans-unit id="7a477b80f752e81ae51a71148e25e03d00004834" translate="yes" xml:space="preserve">
          <source>Provides a skeleton for customization requiring the overriding of methods such as &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.compute_mask&quot;&gt;&lt;code&gt;compute_mask()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.apply&quot;&gt;&lt;code&gt;apply()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.compute_mask&quot;&gt; &lt;code&gt;compute_mask()&lt;/code&gt; &lt;/a&gt;や&lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.apply&quot;&gt; &lt;code&gt;apply()&lt;/code&gt; &lt;/a&gt;などのメソッドのオーバーライドを必要とするカスタマイズ用のスケルトンを提供します。</target>
        </trans-unit>
        <trans-unit id="df76ae939d5d588eb6f5766984f7e5d52eb50216" translate="yes" xml:space="preserve">
          <source>Prune (currently unpruned) units in a tensor at random.</source>
          <target state="translated">テンソル内の(現在は剪定されていない)単位をランダムに剪定します。</target>
        </trans-unit>
        <trans-unit id="368202ce04421132a9166203cfc137eb74e9e21c" translate="yes" xml:space="preserve">
          <source>Prune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm.</source>
          <target state="translated">テンソル内の(現在剪定されていない)単位を、L1ノルムが最も低いものをゼロにすることで剪定します。</target>
        </trans-unit>
        <trans-unit id="5b5612215ed58f8a7a594acd4880fde95d901f0f" translate="yes" xml:space="preserve">
          <source>Prune entire (currently unpruned) channels in a tensor at random.</source>
          <target state="translated">テンソル内の(現在は剪定されていない)チャンネル全体をランダムに剪定します。</target>
        </trans-unit>
        <trans-unit id="a802bde3db7f577abbb1b538eee51db0b51ddf30" translate="yes" xml:space="preserve">
          <source>Prune entire (currently unpruned) channels in a tensor based on their Ln-norm.</source>
          <target state="translated">テンソル内の(現在は剪定されていない)チャンネル全体を、そのLn-ノルムに基づいて剪定します。</target>
        </trans-unit>
        <trans-unit id="2306b2b0d296e475c246073f14ea3e13b1639fc6" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by applying the pre-computed mask in &lt;code&gt;mask&lt;/code&gt;.</source>
          <target state="translated">事前に計算されたマスクを &lt;code&gt;mask&lt;/code&gt; 適用することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを削除します。</target>
        </trans-unit>
        <trans-unit id="8222739be42aac5d12f65e68e036f42e19a41197" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by applying the pre-computed mask in &lt;code&gt;mask&lt;/code&gt;. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">事前に計算されたマスクを &lt;code&gt;mask&lt;/code&gt; 適用することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを削除します。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="12f145dd28935b207164778834f46d05e62d324e" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; selected at random.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）チャネルを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。</target>
        </trans-unit>
        <trans-unit id="1993775f18835672e6ea2ee6df5cc4b95f07d89b" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; selected at random. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）チャネルを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="e4cf8aaa8979161ded3d9362964d7e1da3ab5bd2" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; with the lowest L``n``-norm.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを、最小のL``n``-normで指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）チャネルを削除することによってプルーニングします。</target>
        </trans-unit>
        <trans-unit id="e5e671a44c6d84c3fbfdc3856808100dbb577dde" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; with the lowest L``n``-norm. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを、指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在は削除されていない）チャネルを削除し、L``n``-normを最小にします。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="e414308272708bb6595a21b037cefd9b491135bf" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units selected at random.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。</target>
        </trans-unit>
        <trans-unit id="0d1f0e7025ef360a1a8db642ffde843b0c686100" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units selected at random. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="0e2ae92cb48940de59dcf3dcc3eee3fc2761f74b" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units with the lowest L1-norm.</source>
          <target state="translated">L1ノルムが最も低い指定された &lt;code&gt;amount&lt;/code&gt; の（現在は剪定されていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを剪定します。</target>
        </trans-unit>
        <trans-unit id="3ceb680b02bb9fc923a4db9b23afd99bcf23bd57" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units with the lowest L1-norm. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">L1ノルムが最も低い指定された &lt;code&gt;amount&lt;/code&gt; の（現在は剪定されていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを剪定します。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="8ee04a977907bca0b936aebe6227e9be8b0a5084" translate="yes" xml:space="preserve">
          <source>Pruning itself is NOT undone or reversed!</source>
          <target state="translated">剪定自体が元に戻ったり、逆になったりすることはありません!</target>
        </trans-unit>
        <trans-unit id="fae06ff3f9da62952a413ca3bf10b3455201b027" translate="yes" xml:space="preserve">
          <source>PruningContainer</source>
          <target state="translated">PruningContainer</target>
        </trans-unit>
        <trans-unit id="784e725830e98a189da61d3afccea45b6e5a9d0f" translate="yes" xml:space="preserve">
          <source>Publishing models</source>
          <target state="translated">出版モデル</target>
        </trans-unit>
        <trans-unit id="ae8ea7cada42ba595cd41ec28d2ff26795c6d771" translate="yes" xml:space="preserve">
          <source>Pushes a range onto a stack of nested range span. Returns zero-based depth of the range that is started.</source>
          <target state="translated">範囲をネストされた範囲スパンのスタックにプッシュします。開始した範囲の深さをゼロベースで返します。</target>
        </trans-unit>
        <trans-unit id="256db3aa08282f6add3cb3226d3554daf2bee937" translate="yes" xml:space="preserve">
          <source>Puts values from the tensor &lt;code&gt;value&lt;/code&gt; into the tensor &lt;code&gt;self&lt;/code&gt; using the indices specified in &lt;a href=&quot;#torch.Tensor.indices&quot;&gt;&lt;code&gt;indices&lt;/code&gt;&lt;/a&gt; (which is a tuple of Tensors). The expression &lt;code&gt;tensor.index_put_(indices, value)&lt;/code&gt; is equivalent to &lt;code&gt;tensor[indices] = value&lt;/code&gt;. Returns &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">インデックスで指定された&lt;a href=&quot;#torch.Tensor.indices&quot;&gt; &lt;code&gt;indices&lt;/code&gt; &lt;/a&gt;（テンソルのタプル）を使用して、テンソル &lt;code&gt;value&lt;/code&gt; をテンソル &lt;code&gt;self&lt;/code&gt; に入れます。式 &lt;code&gt;tensor.index_put_(indices, value)&lt;/code&gt; は、 &lt;code&gt;tensor[indices] = value&lt;/code&gt; と同等です。 &lt;code&gt;self&lt;/code&gt; を返します。</target>
        </trans-unit>
        <trans-unit id="c148aded3d47eba6bad059e92b2038d207b0a750" translate="yes" xml:space="preserve">
          <source>Putting it all together</source>
          <target state="translated">まとめてみると</target>
        </trans-unit>
        <trans-unit id="98a2e30eeb85238d061519d74935e170e44c72cb" translate="yes" xml:space="preserve">
          <source>PyTorch</source>
          <target state="translated">PyTorch</target>
        </trans-unit>
        <trans-unit id="2837c35a89ca2ff1375acbd6ae4015154d808597" translate="yes" xml:space="preserve">
          <source>PyTorch Contribution Guide</source>
          <target state="translated">PyTorch 貢献ガイド</target>
        </trans-unit>
        <trans-unit id="0de6ec530c1988d0af9e4ce7eb73eef1189976b6" translate="yes" xml:space="preserve">
          <source>PyTorch Functions and Modules</source>
          <target state="translated">PyTorch の関数とモジュール</target>
        </trans-unit>
        <trans-unit id="6517675a341634e77bfecd3ddf631a647d857475" translate="yes" xml:space="preserve">
          <source>PyTorch Governance</source>
          <target state="translated">PyTorch ガバナンス</target>
        </trans-unit>
        <trans-unit id="d35b21e83a6b1a4ee2adc066dff9672eedab98a1" translate="yes" xml:space="preserve">
          <source>PyTorch Governance | Persons of Interest</source>
          <target state="translated">PyTorch ガバナンス|利害関係者の方へ</target>
        </trans-unit>
        <trans-unit id="3a2bd7a8f704e6cdbe374466d0208d799f0651cc" translate="yes" xml:space="preserve">
          <source>PyTorch and ONNX backends(Caffe2, ONNX Runtime, etc) often have implementations of operators with some numeric differences. Depending on model structure, these differences may be negligible, but they can also cause major divergences in behavior (especially on untrained models.) We allow Caffe2 to call directly to Torch implementations of operators, to help you smooth over these differences when precision is important, and to also document these differences.</source>
          <target state="translated">PyTorchやONNXのバックエンド(Caffe2,ONNX Runtimeなど)では、演算子の実装に数値的な違いがあることがよくあります。モデルの構造にもよりますが、これらの違いは無視できるほどのものではありませんが、動作に大きな違いが生じることもあります(特に非訓練モデルでは)。</target>
        </trans-unit>
        <trans-unit id="6148268ed386643e6b3a594818c58fc07ad9c665" translate="yes" xml:space="preserve">
          <source>PyTorch distributed package supports Linux (stable), MacOS (stable), and Windows (prototype). By default for Linux, the Gloo and NCCL backends are built and included in PyTorch distributed (NCCL only when building with CUDA). MPI is an optional backend that can only be included if you build PyTorch from source. (e.g.building PyTorch on a host that has MPI installed.)</source>
          <target state="translated">PyTorch の配布パッケージは Linux (stable)、MacOS (stable)、Windows (prototype)をサポートしています。Linuxの場合、デフォルトではGlooとNCCLのバックエンドがビルドされ、PyTorchに含まれています(NCCLはCUDAでビルドする場合のみ)。MPIはオプションのバックエンドで、ソースからPyTorchをビルドした場合にのみ含まれます。(例:MPI がインストールされているホストで PyTorch をビルドする場合)</target>
        </trans-unit>
        <trans-unit id="9456a74dbb38bfce73f52a1992187228bd2d00fa" translate="yes" xml:space="preserve">
          <source>PyTorch documentation</source>
          <target state="translated">PyTorch ドキュメント</target>
        </trans-unit>
        <trans-unit id="d19d474346c5b08d13d3339e3bf4feebcd91f549" translate="yes" xml:space="preserve">
          <source>PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.</source>
          <target state="translated">PyTorchはGPUやCPUを使ったディープラーニングのための最適化されたテンソルライブラリです。</target>
        </trans-unit>
        <trans-unit id="899246dc869a567118284070768757e2fc424c84" translate="yes" xml:space="preserve">
          <source>PyTorch on XLA Devices</source>
          <target state="translated">XLAデバイスのPyTorch</target>
        </trans-unit>
        <trans-unit id="c93898f1a89d832ed7049068dfa7cb16c03bf3ed" translate="yes" xml:space="preserve">
          <source>PyTorch preserves storage sharing across serialization. See &lt;code&gt;preserve-storage-sharing&lt;/code&gt; for more details.</source>
          <target state="translated">PyTorchは、シリアル化全体でストレージ共有を維持します。詳細については、 &lt;code&gt;preserve-storage-sharing&lt;/code&gt; を参照してください。</target>
        </trans-unit>
        <trans-unit id="27b7e9176c7a6b31ba4779baa5f868bead4ef214" translate="yes" xml:space="preserve">
          <source>PyTorch provides two global &lt;a href=&quot;#torch.distributions.constraint_registry.ConstraintRegistry&quot;&gt;&lt;code&gt;ConstraintRegistry&lt;/code&gt;&lt;/a&gt; objects that link &lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt; objects to &lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt;&lt;code&gt;Transform&lt;/code&gt;&lt;/a&gt; objects. These objects both input constraints and return transforms, but they have different guarantees on bijectivity.</source>
          <target state="translated">PyTorchは、&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;オブジェクトを&lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt; &lt;code&gt;Transform&lt;/code&gt; &lt;/a&gt;オブジェクトにリンクする2つのグローバル&lt;a href=&quot;#torch.distributions.constraint_registry.ConstraintRegistry&quot;&gt; &lt;code&gt;ConstraintRegistry&lt;/code&gt; &lt;/a&gt;オブジェクトを提供します。これらのオブジェクトは、入力制約と戻り変換の両方を行いますが、双射性については異なる保証があります。</target>
        </trans-unit>
        <trans-unit id="ccb71e60b710059778503566d9b6733540438582" translate="yes" xml:space="preserve">
          <source>PyTorch ships with two builtin backends: &lt;code&gt;BackendType.TENSORPIPE&lt;/code&gt; and &lt;code&gt;BackendType.PROCESS_GROUP&lt;/code&gt;. Additional ones can be registered using the &lt;code&gt;register_backend()&lt;/code&gt; function.</source>
          <target state="translated">PyTorchには、 &lt;code&gt;BackendType.TENSORPIPE&lt;/code&gt; と &lt;code&gt;BackendType.PROCESS_GROUP&lt;/code&gt; の2つの組み込みバックエンドが付属しています。追加のものは、 &lt;code&gt;register_backend()&lt;/code&gt; 関数を使用して登録できます。</target>
        </trans-unit>
        <trans-unit id="2d5a1e0600b8abe6782e41ec54cae91372de9186" translate="yes" xml:space="preserve">
          <source>Python 2 does not support Ellipsis but one may use a string literal instead (&lt;code&gt;'...'&lt;/code&gt;).</source>
          <target state="translated">Python 2は省略記号をサポートしていませんが、代わりに文字列リテラルを使用できます（ &lt;code&gt;'...'&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="b5ec6c002217ad80d40ef02a1f4366196fae59b7" translate="yes" xml:space="preserve">
          <source>Python 3 type hints can be used in place of &lt;code&gt;torch.jit.annotate&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.jit.annotate&lt;/code&gt; の代わりにPython3タイプのヒントを使用できます</target>
        </trans-unit>
        <trans-unit id="0711b02500c16372db7e037b0db241051fe28013" translate="yes" xml:space="preserve">
          <source>Python API</source>
          <target state="translated">パイソンエーピーアイ</target>
        </trans-unit>
        <trans-unit id="cad6fbd004ed44f2a0389e7ad1a4cfa89ba1d3fc" translate="yes" xml:space="preserve">
          <source>Python Functions and Modules</source>
          <target state="translated">Python の関数とモジュール</target>
        </trans-unit>
        <trans-unit id="c9209054e624163b69a9eb976a32495c0a33865f" translate="yes" xml:space="preserve">
          <source>Python Language Reference Comparison</source>
          <target state="translated">Python言語リファレンス比較</target>
        </trans-unit>
        <trans-unit id="e4ec2cbb65019f4837950da585dfbc7781b88d91" translate="yes" xml:space="preserve">
          <source>Python Language Reference Coverage</source>
          <target state="translated">Pythonの言語リファレンスカバレッジ</target>
        </trans-unit>
        <trans-unit id="fd58a092a5203baf1b73956b039089eaeff86afb" translate="yes" xml:space="preserve">
          <source>Python classes can be used in TorchScript if they are annotated with &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;@torch.jit.script&lt;/code&gt;&lt;/a&gt;, similar to how you would declare a TorchScript function:</source>
          <target state="translated">Pythonクラスは、TorchScript関数を宣言する方法と同様に、&lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;@torch.jit.script&lt;/code&gt; &lt;/a&gt;でアノテーションが付けられている場合、TorchScriptで使用できます。</target>
        </trans-unit>
        <trans-unit id="dcb69ff04adf584813a764fcff415e81178eed67" translate="yes" xml:space="preserve">
          <source>Python enums can be used in TorchScript without any extra annotation or code:</source>
          <target state="translated">Pythonのenumは、TorchScriptでは余計なアノテーションやコードを使わずに使用できます。</target>
        </trans-unit>
        <trans-unit id="21aa60d14a5d3bf9941c64223102e72e43cd7db3" translate="yes" xml:space="preserve">
          <source>Python-defined Constants</source>
          <target state="translated">Pythonで定義された定数</target>
        </trans-unit>
        <trans-unit id="bca513fe1a1ac6b508002e4d70e9b04a95755456" translate="yes" xml:space="preserve">
          <source>Pytorch Hub is a pre-trained model repository designed to facilitate research reproducibility.</source>
          <target state="translated">Pytorch Hubは、研究の再現性を高めるために設計された、事前に訓練されたモデルリポジトリです。</target>
        </trans-unit>
        <trans-unit id="4a3b71fd725a5570aa333bd5a258f51e9ad067c8" translate="yes" xml:space="preserve">
          <source>Pytorch Hub provides convenient APIs to explore all available models in hub through &lt;a href=&quot;#torch.hub.list&quot;&gt;&lt;code&gt;torch.hub.list()&lt;/code&gt;&lt;/a&gt;, show docstring and examples through &lt;a href=&quot;#torch.hub.help&quot;&gt;&lt;code&gt;torch.hub.help()&lt;/code&gt;&lt;/a&gt; and load the pre-trained models using &lt;a href=&quot;#torch.hub.load&quot;&gt;&lt;code&gt;torch.hub.load()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Pytorch Hubは、&lt;a href=&quot;#torch.hub.list&quot;&gt; &lt;code&gt;torch.hub.list()&lt;/code&gt; &lt;/a&gt;を介してハブで使用可能なすべてのモデルを探索し、&lt;a href=&quot;#torch.hub.help&quot;&gt; &lt;code&gt;torch.hub.help()&lt;/code&gt; &lt;/a&gt;を介してdocstringと例を表示し、&lt;a href=&quot;#torch.hub.load&quot;&gt; &lt;code&gt;torch.hub.load()&lt;/code&gt; &lt;/a&gt;を使用して事前トレーニング済みモデルをロードするための便利なAPIを提供します。</target>
        </trans-unit>
        <trans-unit id="71ea6e31bfc2cea7da3ec5ce3389fe77a6457276" translate="yes" xml:space="preserve">
          <source>Pytorch Hub supports publishing pre-trained models(model definitions and pre-trained weights) to a github repository by adding a simple &lt;code&gt;hubconf.py&lt;/code&gt; file;</source>
          <target state="translated">Pytorch Hubは、単純な &lt;code&gt;hubconf.py&lt;/code&gt; ファイルを追加することで、事前にトレーニングされたモデル（モデル定義と事前にトレーニングされた重み）をgithubリポジトリに公開することをサポートしています。</target>
        </trans-unit>
        <trans-unit id="c3156e00d3c2588c639e0d3cf6821258b05761c7" translate="yes" xml:space="preserve">
          <source>Q</source>
          <target state="translated">Q</target>
        </trans-unit>
        <trans-unit id="817b3643a8c9250c5615063227303b8c5da71cbe" translate="yes" xml:space="preserve">
          <source>Q: Does ONNX support implicit scalar datatype casting?</source>
          <target state="translated">Q:ONNXは暗黙のスカラデータ型キャストをサポートしていますか?</target>
        </trans-unit>
        <trans-unit id="e999540844f438b9780d0892a8883a34284bbec7" translate="yes" xml:space="preserve">
          <source>Q: How do I store attributes on a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;?</source>
          <target state="translated">Q：&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; に&lt;/a&gt;属性を保存するにはどうすればよいですか？</target>
        </trans-unit>
        <trans-unit id="71cd3f9caa34814ac682f01c8799e67876c37c7b" translate="yes" xml:space="preserve">
          <source>Q: How to export models with loops in it?</source>
          <target state="translated">Q:ループが入ったモデルをエクスポートするには?</target>
        </trans-unit>
        <trans-unit id="3ab78ce25486eb77e84e3dce117cf425f112dd6c" translate="yes" xml:space="preserve">
          <source>Q: I have exported my lstm model, but its input size seems to be fixed?</source>
          <target state="translated">Q:lstmモデルをエクスポートしたのですが、入力サイズが固定されているようですが?</target>
        </trans-unit>
        <trans-unit id="a12de1b8a4f8718726ec01c0631665899c7a3116" translate="yes" xml:space="preserve">
          <source>Q: I would like to trace module&amp;rsquo;s method but I keep getting this error:</source>
          <target state="translated">Q：モジュールのメソッドをトレースしたいのですが、次のエラーが発生し続けます：</target>
        </trans-unit>
        <trans-unit id="2b00cd8e47e4d783f5be1951f1dd20a7ce719f21" translate="yes" xml:space="preserve">
          <source>Q: I would like to train a model on GPU and do inference on CPU. What are the best practices?</source>
          <target state="translated">Q:GPUでモデルを学習し、CPUで推論をしたい。ベストプラクティスは何ですか?</target>
        </trans-unit>
        <trans-unit id="470067c814eb1ea3d524592caed0d6e62ae92c6f" translate="yes" xml:space="preserve">
          <source>Q: Is tensor in-place indexed assignment like &lt;code&gt;data[index] = new_data&lt;/code&gt; supported?</source>
          <target state="translated">Q： &lt;code&gt;data[index] = new_data&lt;/code&gt; ようなテンソルインプレースインデックス付き代入はサポートされていますか？</target>
        </trans-unit>
        <trans-unit id="e79884b3f980f1ad19cca2c799bbefd52769c3b3" translate="yes" xml:space="preserve">
          <source>Q: Is tensor list exportable to ONNX?</source>
          <target state="translated">Q:テンソルリストはONNXにエクスポートできますか?</target>
        </trans-unit>
        <trans-unit id="892976819297325dacfe2454b5f3511112ebff7a" translate="yes" xml:space="preserve">
          <source>QFunctional</source>
          <target state="translated">QFunctional</target>
        </trans-unit>
        <trans-unit id="3a8e72c5cc093d92b3cfbbcce054a2f1c557acd3" translate="yes" xml:space="preserve">
          <source>Q_\text{max}</source>
          <target state="translated">Q_\text{max}</target>
        </trans-unit>
        <trans-unit id="d92ca2583a7c56daca5b83e5f89026fff5289864" translate="yes" xml:space="preserve">
          <source>Q_\text{min}</source>
          <target state="translated">Q_\text{min}</target>
        </trans-unit>
        <trans-unit id="97f0eded6b0e44ee7ab93339b4fa67092a5342fa" translate="yes" xml:space="preserve">
          <source>Quantization</source>
          <target state="translated">Quantization</target>
        </trans-unit>
        <trans-unit id="7b80176f26e12114d8e0a0da100ea2dd78841526" translate="yes" xml:space="preserve">
          <source>Quantization configuration should be assigned preemptively to individual submodules in &lt;code&gt;.qconfig&lt;/code&gt; attribute.</source>
          <target state="translated">量子化構成は、 &lt;code&gt;.qconfig&lt;/code&gt; 属性の個々のサブモジュールにプリエンプティブに割り当てる必要があります。</target>
        </trans-unit>
        <trans-unit id="ac5d2b1d677d49a0bd86ef0862a7927fd9191c9e" translate="yes" xml:space="preserve">
          <source>Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision. PyTorch supports both per tensor and per channel asymmetric linear quantization. To learn more how to use quantized functions in PyTorch, please refer to the &lt;a href=&quot;quantization#quantization-doc&quot;&gt;Quantization&lt;/a&gt; documentation.</source>
          <target state="translated">量子化とは、計算を実行し、浮動小数点精度よりも低いビット幅でテンソルを格納するための手法を指します。PyTorchは、テンソルごととチャネルごとの非対称線形量子化の両方をサポートします。PyTorchで量子化関数を使用する方法の詳細については、&lt;a href=&quot;quantization#quantization-doc&quot;&gt;量子化の&lt;/a&gt;ドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="18a85a5632065b99cfe45a2efad2f1ae99da1046" translate="yes" xml:space="preserve">
          <source>Quantize</source>
          <target state="translated">Quantize</target>
        </trans-unit>
        <trans-unit id="f8fde939a75393ebe92d80b644e2d353e60f89e3" translate="yes" xml:space="preserve">
          <source>Quantize stub module, before calibration, this is same as an observer, it will be swapped as &lt;code&gt;nnq.Quantize&lt;/code&gt; in &lt;code&gt;convert&lt;/code&gt;.</source>
          <target state="translated">キャリブレーション前のスタブモジュールの量子化。これはオブザーバーと同じで、 &lt;code&gt;convert&lt;/code&gt; &lt;code&gt;nnq.Quantize&lt;/code&gt; として交換されます。</target>
        </trans-unit>
        <trans-unit id="567337a1768d995cea83bd61b738d0b3fde9158e" translate="yes" xml:space="preserve">
          <source>Quantize the input float model with post training static quantization.</source>
          <target state="translated">学習後の静的量子化を用いて、入力floatモデルを量子化します。</target>
        </trans-unit>
        <trans-unit id="5dc78d5962844144dbb78dcd34c444f89d2360d5" translate="yes" xml:space="preserve">
          <source>Quantized Functions</source>
          <target state="translated">量子化関数</target>
        </trans-unit>
        <trans-unit id="93bd0dbffb4b3754bf685731ec3211818537c4b4" translate="yes" xml:space="preserve">
          <source>Quantized model.</source>
          <target state="translated">量子化モデル。</target>
        </trans-unit>
        <trans-unit id="22040c5f1ace6596f37ed53e5feee71111db31d0" translate="yes" xml:space="preserve">
          <source>Quantizes an incoming tensor</source>
          <target state="translated">入力テンソルを量子化する</target>
        </trans-unit>
        <trans-unit id="7ad43145efa235468f5902d61cd285ed9b73e61e" translate="yes" xml:space="preserve">
          <source>Quasi-random sampling</source>
          <target state="translated">準ランダムサンプリング</target>
        </trans-unit>
        <trans-unit id="06576556d1ad802f247cad11ae748be47b70cd9c" translate="yes" xml:space="preserve">
          <source>R</source>
          <target state="translated">R</target>
        </trans-unit>
        <trans-unit id="a4a12b6d13143948a19488e0d1cd0864bcfcd487" translate="yes" xml:space="preserve">
          <source>R(2+1)D-18 network</source>
          <target state="translated">R(2+1)D-18ネットワーク</target>
        </trans-unit>
        <trans-unit id="6d51f7562aadcec1a3d0cd7c60d6435cbf2ea1a0" translate="yes" xml:space="preserve">
          <source>R3D-18 network</source>
          <target state="translated">R3D-18ネットワーク</target>
        </trans-unit>
        <trans-unit id="c5db7969dcd30635e5d7867040b6cc76158dd175" translate="yes" xml:space="preserve">
          <source>RAW</source>
          <target state="translated">RAW</target>
        </trans-unit>
        <trans-unit id="2fe8814f679602ef8677e9b846ae9cc63646e90c" translate="yes" xml:space="preserve">
          <source>RNN</source>
          <target state="translated">RNN</target>
        </trans-unit>
        <trans-unit id="419fa7ef1354a7471cfefa40385138f81850a613" translate="yes" xml:space="preserve">
          <source>RNNBase</source>
          <target state="translated">RNNBase</target>
        </trans-unit>
        <trans-unit id="22c95097b5426fe43997d6eb11be7ab8c5097b78" translate="yes" xml:space="preserve">
          <source>RNNCell</source>
          <target state="translated">RNNCell</target>
        </trans-unit>
        <trans-unit id="c3282cbbcba660116d62c007822229220838a1c6" translate="yes" xml:space="preserve">
          <source>RPC</source>
          <target state="translated">RPC</target>
        </trans-unit>
        <trans-unit id="b75c8242fd289be2b08bd6f1908eeb3affe74a47" translate="yes" xml:space="preserve">
          <source>RReLU</source>
          <target state="translated">RReLU</target>
        </trans-unit>
        <trans-unit id="e908d326bea7dd110e9821c1f738fe31ee60caf9" translate="yes" xml:space="preserve">
          <source>RRef</source>
          <target state="translated">RRef</target>
        </trans-unit>
        <trans-unit id="e98cb22d66aa1860c5d982443eb2d7e84c9630f1" translate="yes" xml:space="preserve">
          <source>RRef Lifetime</source>
          <target state="translated">RRef ライフタイム</target>
        </trans-unit>
        <trans-unit id="c36d9458e0d1baae7403b5ce642a78b09e4acc7f" translate="yes" xml:space="preserve">
          <source>Raises</source>
          <target state="translated">Raises</target>
        </trans-unit>
        <trans-unit id="d92af57a28c421f8d8438229f0b21202604e4ae3" translate="yes" xml:space="preserve">
          <source>Raises &lt;code&gt;RuntimeError&lt;/code&gt; if &lt;a href=&quot;https://ninja-build.org/&quot;&gt;ninja&lt;/a&gt; build system is not available on the system, does nothing otherwise.</source>
          <target state="translated">調達 &lt;code&gt;RuntimeError&lt;/code&gt; あれば&lt;a href=&quot;https://ninja-build.org/&quot;&gt;忍者&lt;/a&gt;ビルドシステムは、システム上で利用できないそうでない場合は何もしません。</target>
        </trans-unit>
        <trans-unit id="fe6245a65da1996031b65e42c6ba6186170ca87f" translate="yes" xml:space="preserve">
          <source>Raises ValueError if the value is not present.</source>
          <target state="translated">値が存在しない場合、ValueErrorを発生させます。</target>
        </trans-unit>
        <trans-unit id="eef14c4912a222577af3c87a94916617431f0107" translate="yes" xml:space="preserve">
          <source>Random Number Generator</source>
          <target state="translated">乱数発生器</target>
        </trans-unit>
        <trans-unit id="aedcea91bbd64d179e04e09799d9cf9271d320c0" translate="yes" xml:space="preserve">
          <source>Random sampling</source>
          <target state="translated">ランダムサンプリング</target>
        </trans-unit>
        <trans-unit id="4a94ba04a9499be153f8aa33a992c875d347dc19" translate="yes" xml:space="preserve">
          <source>Random sampling creation ops are listed under &lt;a href=&quot;#random-sampling&quot;&gt;Random sampling&lt;/a&gt; and include: &lt;a href=&quot;generated/torch.rand#torch.rand&quot;&gt;&lt;code&gt;torch.rand()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.rand_like#torch.rand_like&quot;&gt;&lt;code&gt;torch.rand_like()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randn#torch.randn&quot;&gt;&lt;code&gt;torch.randn()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randn_like#torch.randn_like&quot;&gt;&lt;code&gt;torch.randn_like()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randint#torch.randint&quot;&gt;&lt;code&gt;torch.randint()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randint_like#torch.randint_like&quot;&gt;&lt;code&gt;torch.randint_like()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randperm#torch.randperm&quot;&gt;&lt;code&gt;torch.randperm()&lt;/code&gt;&lt;/a&gt; You may also use &lt;a href=&quot;generated/torch.empty#torch.empty&quot;&gt;&lt;code&gt;torch.empty()&lt;/code&gt;&lt;/a&gt; with the &lt;a href=&quot;#inplace-random-sampling&quot;&gt;In-place random sampling&lt;/a&gt; methods to create &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; s with values sampled from a broader range of distributions.</source>
          <target state="translated">ランダム作成OPSが下にリストされているサンプリングし&lt;a href=&quot;#random-sampling&quot;&gt;、サンプリングランダム&lt;/a&gt;と、次のとおりです&lt;a href=&quot;generated/torch.rand#torch.rand&quot;&gt; &lt;code&gt;torch.rand()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/torch.rand_like#torch.rand_like&quot;&gt; &lt;code&gt;torch.rand_like()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/torch.randn#torch.randn&quot;&gt; &lt;code&gt;torch.randn()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/torch.randn_like#torch.randn_like&quot;&gt; &lt;code&gt;torch.randn_like()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/torch.randint#torch.randint&quot;&gt; &lt;code&gt;torch.randint()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/torch.randint_like#torch.randint_like&quot;&gt; &lt;code&gt;torch.randint_like()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/torch.randperm#torch.randperm&quot;&gt; &lt;code&gt;torch.randperm()&lt;/code&gt; &lt;/a&gt;あなたは可能また、&lt;a href=&quot;#inplace-random-sampling&quot;&gt;インプレースランダムサンプリング&lt;/a&gt;メソッドで&lt;a href=&quot;generated/torch.empty#torch.empty&quot;&gt; &lt;code&gt;torch.empty()&lt;/code&gt; &lt;/a&gt;を使用して、より広い範囲の分布からサンプリングされた値を持つ&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;を作成します。</target>
        </trans-unit>
        <trans-unit id="1033bbebd194535f79c8257b5bf0911dcfc67f5b" translate="yes" xml:space="preserve">
          <source>RandomStructured</source>
          <target state="translated">RandomStructured</target>
        </trans-unit>
        <trans-unit id="1bc526966e9f4a0fc0dc8703f5e03b9b477135e9" translate="yes" xml:space="preserve">
          <source>RandomUnstructured</source>
          <target state="translated">RandomUnstructured</target>
        </trans-unit>
        <trans-unit id="464ae7dc9e362bdfac200fc767cbef5d1f028f9c" translate="yes" xml:space="preserve">
          <source>Randomized leaky ReLU.</source>
          <target state="translated">無作為化された漏れのあるReLU。</target>
        </trans-unit>
        <trans-unit id="9e67c8ff6a6fe1b402c9707f9ca4025ad7e992ff" translate="yes" xml:space="preserve">
          <source>Randomly masks out entire channels (a channel is a feature map, e.g. the</source>
          <target state="translated">チャンネル全体をランダムにマスクします(チャンネルはフィーチャーマップ、例えば</target>
        </trans-unit>
        <trans-unit id="6b76ae477338397aa80a17779eb1a87460d96c9e" translate="yes" xml:space="preserve">
          <source>Randomly split a dataset into non-overlapping new datasets of given lengths. Optionally fix the generator for reproducible results, e.g.:</source>
          <target state="translated">データセットをランダムに、指定された長さの重なりのない新しいデータセットに分割します。オプションで,再現性のある結果が得られるようにジェネレータを固定する.</target>
        </trans-unit>
        <trans-unit id="f5ee3860ad6da586f04541bda24f379685849499" translate="yes" xml:space="preserve">
          <source>Randomly zero out entire channels (a channel is a 2D feature map, e.g., the</source>
          <target state="translated">チャンネル全体をランダムにゼロアウトする(チャンネルは2Dフィーチャーマップ、例えば</target>
        </trans-unit>
        <trans-unit id="d25942032b09a691f7d96817937bb37b8fc61cbd" translate="yes" xml:space="preserve">
          <source>Randomly zero out entire channels (a channel is a 3D feature map, e.g., the</source>
          <target state="translated">チャンネル全体をランダムにゼロアウトする(チャンネルは3Dフィーチャーマップ、例えば</target>
        </trans-unit>
        <trans-unit id="1e57b50527a8568c0445a4ecc1addecd8c4a65f8" translate="yes" xml:space="preserve">
          <source>Randomness in multi-process data loading</source>
          <target state="translated">マルチプロセスデータローディングにおけるランダム性</target>
        </trans-unit>
        <trans-unit id="e887e4a3161eab98177808f95ed573db9bd91832" translate="yes" xml:space="preserve">
          <source>Rank is a unique identifier assigned to each process within a distributed process group. They are always consecutive integers ranging from 0 to &lt;code&gt;world_size&lt;/code&gt;.</source>
          <target state="translated">ランクは、分散プロセスグループ内の各プロセスに割り当てられた一意の識別子です。これらは常に0から &lt;code&gt;world_size&lt;/code&gt; までの範囲の連続した整数です。</target>
        </trans-unit>
        <trans-unit id="db193220cd72bbc96216458a492d5965637b4287" translate="yes" xml:space="preserve">
          <source>Rather, this directly calls the underlying LAPACK function &lt;code&gt;?geqrf&lt;/code&gt; which produces a sequence of &amp;lsquo;elementary reflectors&amp;rsquo;.</source>
          <target state="translated">むしろ、これは基礎となるLAPACK関数 &lt;code&gt;?geqrf&lt;/code&gt; を直接呼び出し、一連の「基本リフレクター」を生成します。</target>
        </trans-unit>
        <trans-unit id="5a864fcb6762d236bc276a85137cd0fcd44b3001" translate="yes" xml:space="preserve">
          <source>ReLU</source>
          <target state="translated">ReLU</target>
        </trans-unit>
        <trans-unit id="5290128df38d58d4be3bdda2dec90bacff114b1c" translate="yes" xml:space="preserve">
          <source>ReLU6</source>
          <target state="translated">ReLU6</target>
        </trans-unit>
        <trans-unit id="3294ad6b1eda298355d27264864a84bb153e4e5b" translate="yes" xml:space="preserve">
          <source>Real values are finite when they are not NaN, negative infinity, or infinity. Complex values are finite when both their real and imaginary parts are finite.</source>
          <target state="translated">実数値は、NaN、負の無限大、無限大でないときに有限である。複素値は、その実部と虚部の両方が有限であるときに有限である。</target>
        </trans-unit>
        <trans-unit id="6bf7f7c605a0ed647c478d22e23c8b7c103aaf78" translate="yes" xml:space="preserve">
          <source>Real-to-complex Discrete Fourier Transform.</source>
          <target state="translated">実数-複素離散フーリエ変換。</target>
        </trans-unit>
        <trans-unit id="4cb84ee223d1d7f38f89544406d3d898f06cdafb" translate="yes" xml:space="preserve">
          <source>Rearranges elements in a tensor of shape</source>
          <target state="translated">形状のテンソル内の要素を再配置します。</target>
        </trans-unit>
        <trans-unit id="d4d632c1063de7870f16352716202b1f2a8c81c1" translate="yes" xml:space="preserve">
          <source>Receives a tensor asynchronously.</source>
          <target state="translated">テンソルを非同期に受信します。</target>
        </trans-unit>
        <trans-unit id="2f89320a075e26566ba50731edf2f47338c4432f" translate="yes" xml:space="preserve">
          <source>Receives a tensor synchronously.</source>
          <target state="translated">テンソルを同期的に受信します。</target>
        </trans-unit>
        <trans-unit id="d3031eb6413ee9483cf91490238bc6c5cdb0c9c8" translate="yes" xml:space="preserve">
          <source>Reconstruct an event from an IPC handle on the given device.</source>
          <target state="translated">指定されたデバイスのIPCハンドルからイベントを再構築します。</target>
        </trans-unit>
        <trans-unit id="9f19550117b40c6d2db06a55311fcd7ca6f091f5" translate="yes" xml:space="preserve">
          <source>Recorded event.</source>
          <target state="translated">記録されたイベント。</target>
        </trans-unit>
        <trans-unit id="16d8e6844c3490f438ed2b3c2bf4939db0fa6454" translate="yes" xml:space="preserve">
          <source>Records an event.</source>
          <target state="translated">イベントを記録します。</target>
        </trans-unit>
        <trans-unit id="8c8da4978a756400f2a253bb3ea49d3f8d06e10d" translate="yes" xml:space="preserve">
          <source>Records operation history and defines formulas for differentiating ops.</source>
          <target state="translated">操作履歴を記録し、操作を区別するための計算式を定義します。</target>
        </trans-unit>
        <trans-unit id="8417f5f78b257e51c68ac1ce329dbe8dc58722b1" translate="yes" xml:space="preserve">
          <source>Records the event in a given stream.</source>
          <target state="translated">指定されたストリームのイベントを記録します。</target>
        </trans-unit>
        <trans-unit id="6d3b40b37dfe8fdad50303f26863dfa5944ffb83" translate="yes" xml:space="preserve">
          <source>Recurrent Layers</source>
          <target state="translated">リカレントレイヤー</target>
        </trans-unit>
        <trans-unit id="437a7c4fe39d00898697f5eea2075a348d8b6eda" translate="yes" xml:space="preserve">
          <source>Reduce and scatter a list of tensors to the whole group. Only nccl backend is currently supported.</source>
          <target state="translated">テンソルのリストをグループ全体に縮小して分散させます。現在サポートされているのは nccl バックエンドのみです。</target>
        </trans-unit>
        <trans-unit id="62a542ed033585ebe95fd9e187a5f08c926cf3da" translate="yes" xml:space="preserve">
          <source>Reduce learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This scheduler reads a metrics quantity and if no improvement is seen for a &amp;lsquo;patience&amp;rsquo; number of epochs, the learning rate is reduced.</source>
          <target state="translated">指標の改善が止まったら、学習率を下げます。モデルは、学習が停滞すると、学習率を2〜10分の1に減らすことで恩恵を受けることがよくあります。このスケジューラーはメトリック量を読み取り、「忍耐」エポック数の改善が見られない場合、学習率は低下します。</target>
        </trans-unit>
        <trans-unit id="2e154454ad02bd98ccb4e04b626318e2ca6ecea3" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data across all machines in such a way that all get the final result.</source>
          <target state="translated">すべてのマシンが最終的な結果を得るような方法で、すべてのマシンのテンソルデータを削減します。</target>
        </trans-unit>
        <trans-unit id="0845d8a3b333d7e6bdeae11a45e93d821e227572" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data across all machines in such a way that all get the final result. This function reduces a number of tensors on every node, while each tensor resides on different GPUs. Therefore, the input tensor in the tensor list needs to be GPU tensors. Also, each tensor in the tensor list needs to reside on a different GPU.</source>
          <target state="translated">すべてのマシンが最終的な結果を得るような方法で、すべてのマシンのテンソルデータを削減します。この関数は、各テンソルが異なるGPU上に存在する間、各ノード上のテンソルの数を削減します。そのため、テンソルリストの入力テンソルはGPUテンソルである必要があります。また、テンソルリスト内の各テンソルは異なるGPU上に存在する必要があります。</target>
        </trans-unit>
        <trans-unit id="68d09fcde5e8e7a3c4ca4ab69d90b3bd77b87c7d" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data across all machines.</source>
          <target state="translated">すべてのマシンのテンソルデータを削減します。</target>
        </trans-unit>
        <trans-unit id="c6916d4b854bb48bab1b470966a0bd89b2429552" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data on multiple GPUs across all machines. Each tensor in &lt;code&gt;tensor_list&lt;/code&gt; should reside on a separate GPU</source>
          <target state="translated">すべてのマシンで複数のGPU上のテンソルデータを削減します。 &lt;code&gt;tensor_list&lt;/code&gt; の各テンソルは別々のGPUに存在する必要があります</target>
        </trans-unit>
        <trans-unit id="72826c34e0b98307364b7bcd04a0655be2f7559a" translate="yes" xml:space="preserve">
          <source>Reduces, then scatters a list of tensors to all processes in a group.</source>
          <target state="translated">テンソルのリストを削減し、グループ内のすべてのプロセスに分散させます。</target>
        </trans-unit>
        <trans-unit id="44eef8c0a66c5ce295026ad03e889f17e08ed29c" translate="yes" xml:space="preserve">
          <source>Reducing with the addition operation is the same as using &lt;a href=&quot;#torch.Tensor.scatter_add_&quot;&gt;&lt;code&gt;scatter_add_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">加算演算による削減は、&lt;a href=&quot;#torch.Tensor.scatter_add_&quot;&gt; &lt;code&gt;scatter_add_()&lt;/code&gt; &lt;/a&gt;を使用する場合と同じです。</target>
        </trans-unit>
        <trans-unit id="1b6d087fa2831e91be3ac6de64b3da6a95b4c118" translate="yes" xml:space="preserve">
          <source>Reduction Ops</source>
          <target state="translated">削減活動</target>
        </trans-unit>
        <trans-unit id="da9dd3248fef822f41edb238f214a556d8fa5e69" translate="yes" xml:space="preserve">
          <source>Reduction is not yet implemented for the CUDA backend.</source>
          <target state="translated">CUDAバックエンドの削減は未実装です。</target>
        </trans-unit>
        <trans-unit id="45c3dc1c7731c6185824876ed514e54f71bacb64" translate="yes" xml:space="preserve">
          <source>Reference:</source>
          <target state="translated">Reference:</target>
        </trans-unit>
        <trans-unit id="5d20d0fee3b91643dd8d272ac33d01ca95179d82" translate="yes" xml:space="preserve">
          <source>References</source>
          <target state="translated">References</target>
        </trans-unit>
        <trans-unit id="9d1e4e7d27b519b1da3d7266c9c87d7861741080" translate="yes" xml:space="preserve">
          <source>References:</source>
          <target state="translated">References:</target>
        </trans-unit>
        <trans-unit id="9368e2ec97261508237a4befedcf1e3dc15edd5f" translate="yes" xml:space="preserve">
          <source>References::</source>
          <target state="translated">References::</target>
        </trans-unit>
        <trans-unit id="ba0ffdee70f599751e1059c2737dfaa0253ed5bb" translate="yes" xml:space="preserve">
          <source>Refines the dimension names of &lt;code&gt;self&lt;/code&gt; according to &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">名前に従って &lt;code&gt;self&lt;/code&gt; の次元名を調整し&lt;a href=&quot;#torch.Tensor.names&quot;&gt; &lt;code&gt;names&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="fd83bfc89e8951867aebce2ddbcf9aebb755b1db" translate="yes" xml:space="preserve">
          <source>Refining is a special case of renaming that &amp;ldquo;lifts&amp;rdquo; unnamed dimensions. A &lt;code&gt;None&lt;/code&gt; dim can be refined to have any name; a named dim can only be refined to have the same name.</source>
          <target state="translated">絞り込みは、名前のないディメンションを「持ち上げる」名前変更の特殊なケースです。 &lt;code&gt;None&lt;/code&gt; DIMは、任意の名前を持つように洗練することができます。名前付きdimは、同じ名前になるように調整することしかできません。</target>
        </trans-unit>
        <trans-unit id="5acc200962ac427c960517361870d2ca95708a0c" translate="yes" xml:space="preserve">
          <source>ReflectionPad1d</source>
          <target state="translated">ReflectionPad1d</target>
        </trans-unit>
        <trans-unit id="1970d048b8b11bdbb537bc4467b97dde9cbcbcf6" translate="yes" xml:space="preserve">
          <source>ReflectionPad2d</source>
          <target state="translated">ReflectionPad2d</target>
        </trans-unit>
        <trans-unit id="b0e2ded4176f1e93c24c6bb28a1f246d0f065d46" translate="yes" xml:space="preserve">
          <source>Registers a &lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt; subclass in this registry. Usage:</source>
          <target state="translated">このレジストリに&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;サブクラスを登録します。使用法：</target>
        </trans-unit>
        <trans-unit id="44e5f9796886b9f39a08e9c3d313df29a4afdc69" translate="yes" xml:space="preserve">
          <source>Registers a backward hook on the module.</source>
          <target state="translated">モジュールの後方フックを登録します。</target>
        </trans-unit>
        <trans-unit id="780fedc50fbec8a5ee2093bca221ccb17c71d8a2" translate="yes" xml:space="preserve">
          <source>Registers a backward hook.</source>
          <target state="translated">後方フックを登録する。</target>
        </trans-unit>
        <trans-unit id="859ad11a7a9b00f2dc1648434120e2c30f756c3a" translate="yes" xml:space="preserve">
          <source>Registers a forward hook on the module.</source>
          <target state="translated">モジュールのフォワードフックを登録します。</target>
        </trans-unit>
        <trans-unit id="c1cc6d46047e39e672054a7b43c380ab89aa516c" translate="yes" xml:space="preserve">
          <source>Registers a forward pre-hook on the module.</source>
          <target state="translated">モジュールのフォワードプリフックを登録します。</target>
        </trans-unit>
        <trans-unit id="d2f50deb4525028ab1c8e505fb5f42b3b1805265" translate="yes" xml:space="preserve">
          <source>Registry to link constraints to transforms.</source>
          <target state="translated">制約をトランスフォームにリンクするためのレジストリ。</target>
        </trans-unit>
        <trans-unit id="994be4aa8c70d405e9665f571a19642fba261dfd" translate="yes" xml:space="preserve">
          <source>Reinterprets some of the batch dims of a distribution as event dims.</source>
          <target state="translated">ディストリビューションのバッチディムの一部をイベントディムとして再解釈します。</target>
        </trans-unit>
        <trans-unit id="c4e38689980bd0eb675729a3f5eeff33277a75da" translate="yes" xml:space="preserve">
          <source>RelaxedBernoulli</source>
          <target state="translated">RelaxedBernoulli</target>
        </trans-unit>
        <trans-unit id="17435d6989481bd254182b89c973e12b3560805c" translate="yes" xml:space="preserve">
          <source>RelaxedOneHotCategorical</source>
          <target state="translated">RelaxedOneHotCategorical</target>
        </trans-unit>
        <trans-unit id="017e050dc2c81440963780dd987527e102d00635" translate="yes" xml:space="preserve">
          <source>Release memory ASAP in the consumer.</source>
          <target state="translated">コンシューマでメモリを早急に解放してください。</target>
        </trans-unit>
        <trans-unit id="c78aa00da732269786895ce2069aaa539d4c52f2" translate="yes" xml:space="preserve">
          <source>Releases all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible in &lt;code&gt;nvidia-smi&lt;/code&gt;.</source>
          <target state="translated">キャッシュアロケータによって現在保持されているすべての空いているキャッシュメモリを &lt;code&gt;nvidia-smi&lt;/code&gt; て、それらを他のGPUアプリケーションで使用し、nvidia-smiで表示できるようにします。</target>
        </trans-unit>
        <trans-unit id="6aabe5246532aa5e226dacac93b7040def81f191" translate="yes" xml:space="preserve">
          <source>Remote Reference Protocol</source>
          <target state="translated">リモート参照プロトコル</target>
        </trans-unit>
        <trans-unit id="d2611051acb1fb592d77daa5cae8fbc141634b65" translate="yes" xml:space="preserve">
          <source>Remove all items from the ModuleDict.</source>
          <target state="translated">ModuleDictからすべての項目を削除します。</target>
        </trans-unit>
        <trans-unit id="19890e3b8941dee97b6730d3bdd4b5d7d4da71b3" translate="yes" xml:space="preserve">
          <source>Remove all items from the ParameterDict.</source>
          <target state="translated">ParameterDict からすべての項目を削除します。</target>
        </trans-unit>
        <trans-unit id="42e212ea49cffd4d66b50c00fb3332336dc13f4d" translate="yes" xml:space="preserve">
          <source>Remove key from the ModuleDict and return its module.</source>
          <target state="translated">ModuleDictからキーを削除し、そのモジュールを返します。</target>
        </trans-unit>
        <trans-unit id="1225726758ca9313c0c5ad3ef2ebcc4ac3f41d5b" translate="yes" xml:space="preserve">
          <source>Remove key from the ParameterDict and return its parameter.</source>
          <target state="translated">ParameterDict からキーを削除し、そのパラメータを返します。</target>
        </trans-unit>
        <trans-unit id="9168342afe82b61ecfcba245e5a3e85066d9cae2" translate="yes" xml:space="preserve">
          <source>Removes a tensor dimension.</source>
          <target state="translated">テンソル次元を削除します。</target>
        </trans-unit>
        <trans-unit id="10551f8140eae7eec1c2f790aa2c398a8a2c225b" translate="yes" xml:space="preserve">
          <source>Removes the pruning reparameterization from a module and the pruning method from the forward hook.</source>
          <target state="translated">剪定のリパラメータ化をモジュールから削除し、剪定メソッドをフォワードフックから削除します。</target>
        </trans-unit>
        <trans-unit id="4d39954d7304877c790bae592a897de9b12d0614" translate="yes" xml:space="preserve">
          <source>Removes the pruning reparameterization from a module and the pruning method from the forward hook. The pruned parameter named &lt;code&gt;name&lt;/code&gt; remains permanently pruned, and the parameter named &lt;code&gt;name+'_orig'&lt;/code&gt; is removed from the parameter list. Similarly, the buffer named &lt;code&gt;name+'_mask'&lt;/code&gt; is removed from the buffers.</source>
          <target state="translated">モジュールからプルーニングの再パラメーター化を削除し、フォワードフックからプルーニングメソッドを削除します。 &lt;code&gt;name&lt;/code&gt; という名前のプルーニングされたパラメーターは永続的にプルーニングされたままになり、 &lt;code&gt;name+'_orig'&lt;/code&gt; という名前のパラメーターはパラメーターリストから削除されます。同様に、 &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファーがバッファーから削除されます。</target>
        </trans-unit>
        <trans-unit id="c59a012a002ebcdeb37a7a4b34651f264175236e" translate="yes" xml:space="preserve">
          <source>Removes the pruning reparameterization from a module. The pruned parameter named &lt;code&gt;name&lt;/code&gt; remains permanently pruned, and the parameter named &lt;code&gt;name+'_orig'&lt;/code&gt; is removed from the parameter list. Similarly, the buffer named &lt;code&gt;name+'_mask'&lt;/code&gt; is removed from the buffers.</source>
          <target state="translated">モジュールからプルーニングの再パラメーター化を削除します。 &lt;code&gt;name&lt;/code&gt; という名前のプルーニングされたパラメーターは永続的にプルーニングされたままになり、 &lt;code&gt;name+'_orig'&lt;/code&gt; という名前のパラメーターはパラメーターリストから削除されます。同様に、 &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファーがバッファーから削除されます。</target>
        </trans-unit>
        <trans-unit id="dc2f6b46c8953513899753dc6f37ab21a947d81f" translate="yes" xml:space="preserve">
          <source>Removes the spectral normalization reparameterization from a module.</source>
          <target state="translated">モジュールからスペクトル正規化の再パラメータ化を削除します。</target>
        </trans-unit>
        <trans-unit id="e6f3f85d165e444aba5b7212e4c107777c615fa6" translate="yes" xml:space="preserve">
          <source>Removes the weight normalization reparameterization from a module.</source>
          <target state="translated">モジュールから重み正規化の再パラメータ化を削除します。</target>
        </trans-unit>
        <trans-unit id="52a78431ddbd753c3acf927411e5dc4eadd51b45" translate="yes" xml:space="preserve">
          <source>Renames dimension names of &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; のディメンション名の名前を変更します。</target>
        </trans-unit>
        <trans-unit id="1e15bfbedf002065481094064ab67496cead9c00" translate="yes" xml:space="preserve">
          <source>Render matplotlib figure into an image and add it to summary.</source>
          <target state="translated">matplotlibの図を画像にレンダリングしてサマリーに追加します。</target>
        </trans-unit>
        <trans-unit id="d4424e2e484e1d0e2228176a1b9d133567150454" translate="yes" xml:space="preserve">
          <source>Repeat elements of a tensor.</source>
          <target state="translated">テンソルの要素を繰り返す。</target>
        </trans-unit>
        <trans-unit id="c71c8380a78ab9cf6beaa41ffbcea1de55f181da" translate="yes" xml:space="preserve">
          <source>Repeated tensor which has the same shape as input, except along the</source>
          <target state="translated">に沿っている以外は入力と同じ形状を持つ繰り返しテンソル。</target>
        </trans-unit>
        <trans-unit id="fb8854cff80d6a6dd0521042f630c62a94943f9c" translate="yes" xml:space="preserve">
          <source>Repeats this tensor along the specified dimensions.</source>
          <target state="translated">このテンソルを指定された寸法に沿って繰り返します。</target>
        </trans-unit>
        <trans-unit id="b48641d4be70735a27677d2b7a657eb8c5a36bbf" translate="yes" xml:space="preserve">
          <source>Replaces specified modules with dynamic weight-only quantized versions and output the quantized model.</source>
          <target state="translated">指定されたモジュールを動的な重みのみの量子化されたバージョンに置き換え、量子化されたモデルを出力します。</target>
        </trans-unit>
        <trans-unit id="d717a0451eef9c7694fd101a42a92bb95d3c0a0f" translate="yes" xml:space="preserve">
          <source>ReplicationPad1d</source>
          <target state="translated">ReplicationPad1d</target>
        </trans-unit>
        <trans-unit id="7134ff298e79c741cf90df7d64ae3929d67c6005" translate="yes" xml:space="preserve">
          <source>ReplicationPad2d</source>
          <target state="translated">ReplicationPad2d</target>
        </trans-unit>
        <trans-unit id="b3ace69bd0bb68cc7d2ded9c8edec593b271b884" translate="yes" xml:space="preserve">
          <source>ReplicationPad3d</source>
          <target state="translated">ReplicationPad3d</target>
        </trans-unit>
        <trans-unit id="e41aa1fbbb423bb33022752fd330ea4ede8e16b6" translate="yes" xml:space="preserve">
          <source>Reproducibility</source>
          <target state="translated">Reproducibility</target>
        </trans-unit>
        <trans-unit id="f2e21cfb2562445f4e03149dcac964dc2b3217e6" translate="yes" xml:space="preserve">
          <source>ResNeXt</source>
          <target state="translated">ResNeXt</target>
        </trans-unit>
        <trans-unit id="135c48b06dbed678d0d867cebf0cf2de161d70cb" translate="yes" xml:space="preserve">
          <source>ResNeXt-101 32x8d model from &lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;&amp;ldquo;Aggregated Residual Transformation for Deep Neural Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">ResNeXt-10132x8dモデル&lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;「ディープニューラルネットワークの集約された残余変換」&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bd1a95f8f26475fcde5af625d8ad155d8daa61e2" translate="yes" xml:space="preserve">
          <source>ResNeXt-101-32x8d</source>
          <target state="translated">ResNeXt-101-32x8d</target>
        </trans-unit>
        <trans-unit id="6345fcacef60a6153337313629690096bdc6aa78" translate="yes" xml:space="preserve">
          <source>ResNeXt-50 32x4d model from &lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;&amp;ldquo;Aggregated Residual Transformation for Deep Neural Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">ResNeXt-50 &lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;「ディープニューラルネットワークの集約残余変換」の&lt;/a&gt;32x4dモデル</target>
        </trans-unit>
        <trans-unit id="e6816178c1f62a28d2e7d31075a846209cc1ee81" translate="yes" xml:space="preserve">
          <source>ResNeXt-50-32x4d</source>
          <target state="translated">ResNeXt-50-32x4d</target>
        </trans-unit>
        <trans-unit id="78fa6ef9716ebb9b06e34fb7e8ef3e1ee1ff74a3" translate="yes" xml:space="preserve">
          <source>ResNet</source>
          <target state="translated">ResNet</target>
        </trans-unit>
        <trans-unit id="5e9c332cfed41849a28e63e75aa34789f743a723" translate="yes" xml:space="preserve">
          <source>ResNet (2+1)D</source>
          <target state="translated">レジネット(2+1)D</target>
        </trans-unit>
        <trans-unit id="870e5dde5df25034d3630c3aac9cb2c4bf4e76fc" translate="yes" xml:space="preserve">
          <source>ResNet 3D</source>
          <target state="translated">ResNet 3D</target>
        </trans-unit>
        <trans-unit id="da256605d586d089e9e7223940cb0055eadbd1ee" translate="yes" xml:space="preserve">
          <source>ResNet 3D 18</source>
          <target state="translated">ResNet 3D 18</target>
        </trans-unit>
        <trans-unit id="f8475b358157d99679b66bf1c03461ee4befbc51" translate="yes" xml:space="preserve">
          <source>ResNet MC 18</source>
          <target state="translated">ResNet MC 18</target>
        </trans-unit>
        <trans-unit id="1f7d19436196d570e8d470413429de7c74b3c3f2" translate="yes" xml:space="preserve">
          <source>ResNet Mixed Convolution</source>
          <target state="translated">ResNet混合コンボリューション</target>
        </trans-unit>
        <trans-unit id="65817ac0c28cdf514ee310ccdae57eb30ff37866" translate="yes" xml:space="preserve">
          <source>ResNet-101</source>
          <target state="translated">ResNet-101</target>
        </trans-unit>
        <trans-unit id="6cdb79fa3540b98aee4fbbedd859f85dfa5878e1" translate="yes" xml:space="preserve">
          <source>ResNet-101 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;「画像認識のための深い残余学習」&lt;/a&gt;からのResNet-101モデル</target>
        </trans-unit>
        <trans-unit id="ad50fc165163aca8aff90e2401f355f0d73cb36d" translate="yes" xml:space="preserve">
          <source>ResNet-152</source>
          <target state="translated">ResNet-152</target>
        </trans-unit>
        <trans-unit id="ce82bef112318844175b33dd6318fe126f6f7716" translate="yes" xml:space="preserve">
          <source>ResNet-152 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;「画像認識のための深い残余学習」&lt;/a&gt;からのResNet-152モデル</target>
        </trans-unit>
        <trans-unit id="a95e0d1f4879bbdecde67b2d824acd91e0a2a593" translate="yes" xml:space="preserve">
          <source>ResNet-18</source>
          <target state="translated">ResNet-18</target>
        </trans-unit>
        <trans-unit id="0c0f62f5b13f506e60ccc5621518d2252a8fa85e" translate="yes" xml:space="preserve">
          <source>ResNet-18 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;「画像認識のための深い残余学習」&lt;/a&gt;からのResNet-18モデル</target>
        </trans-unit>
        <trans-unit id="a7751035efc6144aca1732aa23112dd3aecb6bc5" translate="yes" xml:space="preserve">
          <source>ResNet-34</source>
          <target state="translated">ResNet-34</target>
        </trans-unit>
        <trans-unit id="e8def5ecc7cddff157e2b586142f5fdf856d05a5" translate="yes" xml:space="preserve">
          <source>ResNet-34 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;「画像認識のための深い残余学習」&lt;/a&gt;からのResNet-34モデル</target>
        </trans-unit>
        <trans-unit id="27444a897bb1c912cdd3b04f0a83fd62a5d2c590" translate="yes" xml:space="preserve">
          <source>ResNet-50</source>
          <target state="translated">ResNet-50</target>
        </trans-unit>
        <trans-unit id="238ac2833cd54b6df3e18e9c24a824061fd3a21c" translate="yes" xml:space="preserve">
          <source>ResNet-50 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;「画像認識のための深い残余学習」&lt;/a&gt;からのResNet-50モデル</target>
        </trans-unit>
        <trans-unit id="6f2d9cd833caae8dbee1966d8ab0943fddb27fd0" translate="yes" xml:space="preserve">
          <source>ResNext</source>
          <target state="translated">ResNext</target>
        </trans-unit>
        <trans-unit id="d6989ed48031dfd0f342adca72920ca82d14ffc5" translate="yes" xml:space="preserve">
          <source>Resets parameter data pointer so that they can use faster code paths.</source>
          <target state="translated">パラメータデータポインタをリセットして、より高速なコードパスを使用できるようにします。</target>
        </trans-unit>
        <trans-unit id="48147200a8245c840b5cf1d24511816f59e2613d" translate="yes" xml:space="preserve">
          <source>Resets the starting point in tracking maximum GPU memory managed by the caching allocator for a given device.</source>
          <target state="translated">指定されたデバイスのキャッシング・アロケータによって管理される最大GPUメモリを追跡する際の開始点をリセットします。</target>
        </trans-unit>
        <trans-unit id="055ff3b94f1675cb0c91b05c26e8f21a16e0aac4" translate="yes" xml:space="preserve">
          <source>Resets the starting point in tracking maximum GPU memory occupied by tensors for a given device.</source>
          <target state="translated">指定されたデバイスのテンソルが占有する最大GPUメモリのトラッキングの開始点をリセットします。</target>
        </trans-unit>
        <trans-unit id="5146907f6db4f1b0f9869f7b411013406ae86ae8" translate="yes" xml:space="preserve">
          <source>Resizes &lt;code&gt;self&lt;/code&gt; tensor to the specified size. If the number of elements is larger than the current storage size, then the underlying storage is resized to fit the new number of elements. If the number of elements is smaller, the underlying storage is not changed. Existing elements are preserved but any new memory is uninitialized.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルを指定されたサイズにサイズ変更します。要素の数が現在のストレージサイズよりも大きい場合、基になるストレージは新しい要素の数に合わせてサイズ変更されます。要素の数が少ない場合、基になるストレージは変更されません。既存の要素は保持されますが、新しいメモリは初期化されません。</target>
        </trans-unit>
        <trans-unit id="70492132da5a47c3477a96c6627fc5933e85e1e1" translate="yes" xml:space="preserve">
          <source>Resizes the &lt;code&gt;self&lt;/code&gt; tensor to be the same size as the specified &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt;. This is equivalent to &lt;code&gt;self.resize_(tensor.size())&lt;/code&gt;.</source>
          <target state="translated">サイズを変更し &lt;code&gt;self&lt;/code&gt; 指定と同じサイズになるようにテンソルを&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt;。これは、 &lt;code&gt;self.resize_(tensor.size())&lt;/code&gt; と同等です。</target>
        </trans-unit>
        <trans-unit id="dc2cdc93dc037b80e1ebd8434da768aef6d0fcaf" translate="yes" xml:space="preserve">
          <source>Result is &lt;code&gt;-inf&lt;/code&gt; if &lt;code&gt;input&lt;/code&gt; has zero log determinant, and is &lt;code&gt;nan&lt;/code&gt; if &lt;code&gt;input&lt;/code&gt; has negative determinant.</source>
          <target state="translated">結果が &lt;code&gt;-inf&lt;/code&gt; 場合 &lt;code&gt;input&lt;/code&gt; ゼロログ行列を持ち、ある &lt;code&gt;nan&lt;/code&gt; 場合 &lt;code&gt;input&lt;/code&gt; 負の決定を持っています。</target>
        </trans-unit>
        <trans-unit id="8ae09aed030eb1a83f83c301c7fc275b3c8a0647" translate="yes" xml:space="preserve">
          <source>RetinaNet</source>
          <target state="translated">RetinaNet</target>
        </trans-unit>
        <trans-unit id="a1e229ed770b9619ca67b1b0aef6ec1a40fa1776" translate="yes" xml:space="preserve">
          <source>RetinaNet ResNet-50 FPN</source>
          <target state="translated">RetinaNet ResNet-50 FPN</target>
        </trans-unit>
        <trans-unit id="2f7a9d4a0bc6f5ce0cbca61c540daaa5837025ee" translate="yes" xml:space="preserve">
          <source>Retrieves a map from Tensor to the appropriate gradient for that Tensor accumulated in the provided context corresponding to the given &lt;code&gt;context_id&lt;/code&gt; as part of the distributed autograd backward pass.</source>
          <target state="translated">分散autograd後方パスの一部として、指定された &lt;code&gt;context_id&lt;/code&gt; に対応する、指定されたコンテキストに蓄積されたTensorの適切な勾配へのマップをTensorから取得します。</target>
        </trans-unit>
        <trans-unit id="1ece76093eabcbca0a40b151ec0259b426ce567d" translate="yes" xml:space="preserve">
          <source>Retrieves the value associated with the given &lt;code&gt;key&lt;/code&gt; in the store. If &lt;code&gt;key&lt;/code&gt; is not present in the store, the function will wait for &lt;code&gt;timeout&lt;/code&gt;, which is defined when initializing the store, before throwing an exception.</source>
          <target state="translated">ストア内の指定された &lt;code&gt;key&lt;/code&gt; に関連付けられている値を取得します。 &lt;code&gt;key&lt;/code&gt; がストアに存在しない場合、関数は例外をスローする前に、ストアの初期化時に定義される &lt;code&gt;timeout&lt;/code&gt; を待機します。</target>
        </trans-unit>
        <trans-unit id="24f096b221f9534bcad007f2b5a32b490950b5b5" translate="yes" xml:space="preserve">
          <source>Return</source>
          <target state="translated">Return</target>
        </trans-unit>
        <trans-unit id="9cae8b09f0118269a649c5008d17c8253bec9782" translate="yes" xml:space="preserve">
          <source>Return &lt;code&gt;True&lt;/code&gt; if this &lt;code&gt;Future&lt;/code&gt; is done. A &lt;code&gt;Future&lt;/code&gt; is done if it has a result or an exception.</source>
          <target state="translated">この &lt;code&gt;Future&lt;/code&gt; が行われた場合、 &lt;code&gt;True&lt;/code&gt; を返します。A &lt;code&gt;Future&lt;/code&gt; それが結果や例外を持っている場合に行われます。</target>
        </trans-unit>
        <trans-unit id="402831e8533c0acc0b144ded8789c976ea34ab74" translate="yes" xml:space="preserve">
          <source>Return a tensor of elements selected from either &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt;, depending on &lt;code&gt;condition&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;condition&lt;/code&gt; に応じて、 &lt;code&gt;x&lt;/code&gt; または &lt;code&gt;y&lt;/code&gt; のいずれかから選択された要素のテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="91f0e9dea6ad89a9cf4c50eeccd2244407a0e3b6" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ModuleDict key/value pairs.</source>
          <target state="translated">ModuleDict のキーと値のペアの反復可能な値を返します。</target>
        </trans-unit>
        <trans-unit id="53758c5a8d9838ee15c5a1139ddc298268e3f550" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ModuleDict keys.</source>
          <target state="translated">ModuleDictキーのイテレータブルを返します。</target>
        </trans-unit>
        <trans-unit id="75b2716bbd52d76a593565ce26e635f35a65eba3" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ModuleDict values.</source>
          <target state="translated">ModuleDictの値の反復可能な値を返します。</target>
        </trans-unit>
        <trans-unit id="39aa7eccaf084effaa1d95b2523664d87adadc63" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ParameterDict key/value pairs.</source>
          <target state="translated">ParameterDict のキーと値のペアの反復可能な値を返します。</target>
        </trans-unit>
        <trans-unit id="36d08ddba7858cda4d75cdfaa632b92a0d271817" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ParameterDict keys.</source>
          <target state="translated">ParameterDict キーのイテレータブルを返します。</target>
        </trans-unit>
        <trans-unit id="0eb7abc74094e832f39c777a2b9fdb3353665e0c" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ParameterDict values.</source>
          <target state="translated">ParameterDict の値の反復可能な値を返します。</target>
        </trans-unit>
        <trans-unit id="6fb5e3008c47afba229895a4aa4b8cfa03845a94" translate="yes" xml:space="preserve">
          <source>Return the next floating-point value after &lt;code&gt;input&lt;/code&gt; towards &lt;code&gt;other&lt;/code&gt;, elementwise.</source>
          <target state="translated">後の次の浮動小数点値を返す &lt;code&gt;input&lt;/code&gt; に向けた &lt;code&gt;other&lt;/code&gt; 、要素ごと。</target>
        </trans-unit>
        <trans-unit id="c457486fbf0726f2b8521c0379e30203a9c59a56" translate="yes" xml:space="preserve">
          <source>Return the recommended gain value for the given nonlinearity function. The values are as follows:</source>
          <target state="translated">与えられた非線形性関数の推奨ゲイン値を返します。値は以下の通りです。</target>
        </trans-unit>
        <trans-unit id="689416efbdc5cadbcaa00d5d52249a2a0b1ad5c6" translate="yes" xml:space="preserve">
          <source>Return the singular value decomposition &lt;code&gt;(U, S, V)&lt;/code&gt; of a matrix, batches of matrices, or a sparse matrix</source>
          <target state="translated">行列、行列のバッチ、またはスパース行列の特異値分解 &lt;code&gt;(U, S, V)&lt;/code&gt; を返します</target>
        </trans-unit>
        <trans-unit id="41b1fb407b7fa442b77381701968fb175362cf78" translate="yes" xml:space="preserve">
          <source>Return type</source>
          <target state="translated">戻り値の種類</target>
        </trans-unit>
        <trans-unit id="1254906d712ed370ba1cdf6cdc5b06fa43eea6c3" translate="yes" xml:space="preserve">
          <source>Returned Tensor shares the same storage with the original one. In-place modifications on either of them will be seen, and may trigger errors in correctness checks. IMPORTANT NOTE: Previously, in-place size / stride / storage changes (such as &lt;code&gt;resize_&lt;/code&gt; / &lt;code&gt;resize_as_&lt;/code&gt; / &lt;code&gt;set_&lt;/code&gt; / &lt;code&gt;transpose_&lt;/code&gt;) to the returned tensor also update the original tensor. Now, these in-place changes will not update the original tensor anymore, and will instead trigger an error. For sparse tensors: In-place indices / values changes (such as &lt;code&gt;zero_&lt;/code&gt; / &lt;code&gt;copy_&lt;/code&gt; / &lt;code&gt;add_&lt;/code&gt;) to the returned tensor will not update the original tensor anymore, and will instead trigger an error.</source>
          <target state="translated">返されたTensorは、元のストレージと同じストレージを共有します。それらのいずれかにインプレースの変更が見られ、正確性チェックでエラーが発生する可能性があります。重要な注意：以前は、返されたテンソルに対するインプレースサイズ/ストライド/ストレージの変更（ &lt;code&gt;resize_&lt;/code&gt; / &lt;code&gt;resize_as_&lt;/code&gt; / &lt;code&gt;set_&lt;/code&gt; / &lt;code&gt;transpose_&lt;/code&gt; など）も元のテンソルを更新します。現在、これらのインプレース変更は元のテンソルを更新せず、代わりにエラーをトリガーします。スパーステンソルの場合：インプレースインデックス/値（例えば、変更 &lt;code&gt;zero_&lt;/code&gt; / &lt;code&gt;copy_&lt;/code&gt; / &lt;code&gt;add_&lt;/code&gt; 返さテンソルへ）はもはやオリジナルテンソルを更新せず、代わりにエラーをトリガします。</target>
        </trans-unit>
        <trans-unit id="24bbb3acca42b36ec251562d04ed070ce8e00154" translate="yes" xml:space="preserve">
          <source>Returned by &lt;a href=&quot;#torch.multiprocessing.spawn&quot;&gt;&lt;code&gt;spawn()&lt;/code&gt;&lt;/a&gt; when called with &lt;code&gt;join=False&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;join=False&lt;/code&gt; で呼び出されたときに&lt;a href=&quot;#torch.multiprocessing.spawn&quot;&gt; &lt;code&gt;spawn()&lt;/code&gt; &lt;/a&gt;によって返されます。</target>
        </trans-unit>
        <trans-unit id="996cd4205ef23a24fd77a57ded3d3ea1bc26418b" translate="yes" xml:space="preserve">
          <source>Returned tensor</source>
          <target state="translated">戻りテンソル</target>
        </trans-unit>
        <trans-unit id="9582a02f141fc4b345b2936eba691cd0654efebc" translate="yes" xml:space="preserve">
          <source>Returns</source>
          <target state="translated">Returns</target>
        </trans-unit>
        <trans-unit id="bececec8df4be65f442e8a241d0d72275aefac53" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;True&lt;/code&gt; if all processes have been joined successfully, &lt;code&gt;False&lt;/code&gt; if there are more processes that need to be joined.</source>
          <target state="translated">すべてのプロセスが正常に結合された場合は &lt;code&gt;True&lt;/code&gt; を返し、結合する必要のあるプロセスがさらにある場合は &lt;code&gt;False&lt;/code&gt; を返します。</target>
        </trans-unit>
        <trans-unit id="11cfd066b647ca21ea710fa73097f97cb102e1f7" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;True&lt;/code&gt; if the &lt;a href=&quot;https://ninja-build.org/&quot;&gt;ninja&lt;/a&gt; build system is available on the system, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">&lt;a href=&quot;https://ninja-build.org/&quot;&gt;ninja&lt;/a&gt;ビルドシステムがシステムで使用可能な場合は &lt;code&gt;True&lt;/code&gt; を返し、それ以外の場合は &lt;code&gt;False&lt;/code&gt; を返します。</target>
        </trans-unit>
        <trans-unit id="196db82d442085adba66ce72a40bf4c6b883e9c5" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;True&lt;/code&gt; if the distributed package is available. Otherwise, &lt;code&gt;torch.distributed&lt;/code&gt; does not expose any other APIs. Currently, &lt;code&gt;torch.distributed&lt;/code&gt; is available on Linux, MacOS and Windows. Set &lt;code&gt;USE_DISTRIBUTED=1&lt;/code&gt; to enable it when building PyTorch from source. Currently, the default value is &lt;code&gt;USE_DISTRIBUTED=1&lt;/code&gt; for Linux and Windows, &lt;code&gt;USE_DISTRIBUTED=0&lt;/code&gt; for MacOS.</source>
          <target state="translated">分散パッケージが利用可能な場合は &lt;code&gt;True&lt;/code&gt; を返します。それ以外の場合、 &lt;code&gt;torch.distributed&lt;/code&gt; は他のAPIを公開しません。現在、 &lt;code&gt;torch.distributed&lt;/code&gt; はLinux、MacOS、Windowsで利用できます。ソースからPyTorchをビルドするときに有効にするには、 &lt;code&gt;USE_DISTRIBUTED=1&lt;/code&gt; を設定します。現在、デフォルト値はLinuxおよびWindowsの場合は &lt;code&gt;USE_DISTRIBUTED=1&lt;/code&gt; 、MacOSの場合は &lt;code&gt;USE_DISTRIBUTED=0&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="616465fba98082b69d414e38f74b13cab726f4ca" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;True&lt;/code&gt; if your system supports flushing denormal numbers and it successfully configures flush denormal mode. &lt;a href=&quot;#torch.set_flush_denormal&quot;&gt;&lt;code&gt;set_flush_denormal()&lt;/code&gt;&lt;/a&gt; is only supported on x86 architectures supporting SSE3.</source>
          <target state="translated">システムが非正規化数のフラッシュをサポートし、フラッシュ非正規モードを正常に構成した場合、 &lt;code&gt;True&lt;/code&gt; を返します。&lt;a href=&quot;#torch.set_flush_denormal&quot;&gt; &lt;code&gt;set_flush_denormal()&lt;/code&gt; &lt;/a&gt;は、SSE3をサポートするx86アーキテクチャでのみサポートされます。</target>
        </trans-unit>
        <trans-unit id="65ca52a0d52509836247baf62510fc9195f808a9" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;self&lt;/code&gt; tensor as a NumPy &lt;code&gt;ndarray&lt;/code&gt;. This tensor and the returned &lt;code&gt;ndarray&lt;/code&gt; share the same underlying storage. Changes to &lt;code&gt;self&lt;/code&gt; tensor will be reflected in the &lt;code&gt;ndarray&lt;/code&gt; and vice versa.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルを &lt;code&gt;ndarray&lt;/code&gt; として返します。このテンソルと返される &lt;code&gt;ndarray&lt;/code&gt; は、同じ基になるストレージを共有します。 &lt;code&gt;self&lt;/code&gt; テンソルへの変更は &lt;code&gt;ndarray&lt;/code&gt; に反映され、その逆も同様です。</target>
        </trans-unit>
        <trans-unit id="606042b612f01e1413a4be37fdcf4bc9fb55a2fd" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;self&lt;/code&gt; tensor&amp;rsquo;s offset in the underlying storage in terms of number of storage elements (not bytes).</source>
          <target state="translated">ストレージ要素の数（バイトではない）の観点から、基になるストレージ内の &lt;code&gt;self&lt;/code&gt; テンソルのオフセットを返します。</target>
        </trans-unit>
        <trans-unit id="f2368e1fd9ddecc9751151ce685ba540173983ea" translate="yes" xml:space="preserve">
          <source>Returns NVCC gencode flags this library were compiled with.</source>
          <target state="translated">このライブラリがコンパイルされたNVCCのgencodeフラグを返します。</target>
        </trans-unit>
        <trans-unit id="bcee86aa4247be4fa57afaf338977b171a646e64" translate="yes" xml:space="preserve">
          <source>Returns True if &lt;code&gt;obj&lt;/code&gt; is a PyTorch storage object.</source>
          <target state="translated">&lt;code&gt;obj&lt;/code&gt; がPyTorchストレージオブジェクトの場合はTrueを返します。</target>
        </trans-unit>
        <trans-unit id="0c0fb790a1f7d7b5df52c8eb6b44b136b1ef5094" translate="yes" xml:space="preserve">
          <source>Returns True if &lt;code&gt;obj&lt;/code&gt; is a PyTorch tensor.</source>
          <target state="translated">&lt;code&gt;obj&lt;/code&gt; がPyTorchテンソルの場合はTrueを返します。</target>
        </trans-unit>
        <trans-unit id="598b755e55cee356b7f7a395b6039f5d177fd41e" translate="yes" xml:space="preserve">
          <source>Returns True if &lt;code&gt;self&lt;/code&gt; tensor is contiguous in memory in the order specified by memory format.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルがメモリ形式で指定された順序でメモリ内で連続している場合、Trueを返します。</target>
        </trans-unit>
        <trans-unit id="f80a083f5b5de080482f9bd320c35bee376edd5c" translate="yes" xml:space="preserve">
          <source>Returns True if all elements in each row of the tensor in the given dimension &lt;code&gt;dim&lt;/code&gt; are True, False otherwise.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; のテンソルの各行のすべての要素がTrueの場合はTrueを返し、それ以外の場合はFalseを返します。</target>
        </trans-unit>
        <trans-unit id="10febb846509f6f2bc8c4b9a8a6d5f7a4d94b02e" translate="yes" xml:space="preserve">
          <source>Returns True if all elements in the tensor are True, False otherwise.</source>
          <target state="translated">テンソルのすべての要素がTrueの場合はTrueを、そうでない場合はFalseを返します。</target>
        </trans-unit>
        <trans-unit id="ec249a00c3df799b548b2828fcdbdce219624299" translate="yes" xml:space="preserve">
          <source>Returns True if any elements in each row of the tensor in the given dimension &lt;code&gt;dim&lt;/code&gt; are True, False otherwise.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; のテンソルの各行の要素がTrueの場合はTrueを返し、それ以外の場合はFalseを返します。</target>
        </trans-unit>
        <trans-unit id="19164100a9af1a366aaf5bd12a4e88efb4270d73" translate="yes" xml:space="preserve">
          <source>Returns True if any elements in the tensor are True, False otherwise.</source>
          <target state="translated">テンソル内の要素がTrueの場合はTrueを、そうでない場合はFalseを返します。</target>
        </trans-unit>
        <trans-unit id="93fef2bb2e23cd032c2bc66acb9ba2af786fd6c1" translate="yes" xml:space="preserve">
          <source>Returns True if both tensors are pointing to the exact same memory (same storage, offset, size and stride).</source>
          <target state="translated">両方のテンソルがまったく同じメモリを指している場合(ストレージ、オフセット、サイズ、ストライドが同じ)に True を返します。</target>
        </trans-unit>
        <trans-unit id="dfeaffdf583441339db6cd69904330215eafe368" translate="yes" xml:space="preserve">
          <source>Returns True if the &lt;code&gt;input&lt;/code&gt; is a single element tensor which is not equal to zero after type conversions.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が型変換後にゼロに等しくない単一要素テンソルである場合、Trueを返します。</target>
        </trans-unit>
        <trans-unit id="c533fa6ff5203fb73d711ade459c89e619986758" translate="yes" xml:space="preserve">
          <source>Returns True if the &lt;code&gt;input&lt;/code&gt; is a single element tensor which is not equal to zero after type conversions. i.e. not equal to &lt;code&gt;torch.tensor([0.])&lt;/code&gt; or &lt;code&gt;torch.tensor([0])&lt;/code&gt; or &lt;code&gt;torch.tensor([False])&lt;/code&gt;. Throws a &lt;code&gt;RuntimeError&lt;/code&gt; if &lt;code&gt;torch.numel() != 1&lt;/code&gt; (even in case of sparse tensors).</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が型変換後にゼロに等しくない単一要素テンソルである場合、Trueを返します。つまり、 &lt;code&gt;torch.tensor([0.])&lt;/code&gt; または &lt;code&gt;torch.tensor([0])&lt;/code&gt; または &lt;code&gt;torch.tensor([False])&lt;/code&gt; と等しくありません。例外 &lt;code&gt;RuntimeError&lt;/code&gt; 場合 &lt;code&gt;torch.numel() != 1&lt;/code&gt; （さえまばらなテンソルの場合）。</target>
        </trans-unit>
        <trans-unit id="4546d55dc55434836d7155a943fded11ace1b513" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;input&lt;/code&gt; is a complex data type i.e., one of &lt;code&gt;torch.complex64&lt;/code&gt;, and &lt;code&gt;torch.complex128&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; のデータ型が複素数データ型、つまり &lt;code&gt;torch.complex64&lt;/code&gt; と &lt;code&gt;torch.complex128&lt;/code&gt; のいずれかである場合、Trueを返します。</target>
        </trans-unit>
        <trans-unit id="5ed711035f4f45a68bdc409be57f591a1203d447" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;input&lt;/code&gt; is a floating point data type i.e., one of &lt;code&gt;torch.float64&lt;/code&gt;, &lt;code&gt;torch.float32&lt;/code&gt; and &lt;code&gt;torch.float16&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; のデータ型が浮動小数点データ型、つまり &lt;code&gt;torch.float64&lt;/code&gt; 、 &lt;code&gt;torch.float32&lt;/code&gt; 、 &lt;code&gt;torch.float16&lt;/code&gt; のいずれかである場合、Trueを返します。</target>
        </trans-unit>
        <trans-unit id="5ad196c93762cde87d752d5a63b5607aaf9d27a9" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;self&lt;/code&gt; is a complex data type.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; のデータ型が複素数データ型の場合はTrueを返します。</target>
        </trans-unit>
        <trans-unit id="47b01dfd12ff21d88fce8263233ddd92fb4ed8af" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;self&lt;/code&gt; is a floating point data type.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; のデータ型が浮動小数点データ型の場合はTrueを返します。</target>
        </trans-unit>
        <trans-unit id="81de301f63a48cfa0447acb0616f4e3a8050d38a" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;self&lt;/code&gt; is a signed data type.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; のデータ型が符号付きデータ型の場合はTrueを返します。</target>
        </trans-unit>
        <trans-unit id="2b3d22229996fcea50652425a0ceef76726b9f91" translate="yes" xml:space="preserve">
          <source>Returns True if the global deterministic flag is turned on.</source>
          <target state="translated">グローバル決定論的フラグがオンになっている場合にTrueを返します。</target>
        </trans-unit>
        <trans-unit id="b5073df54cb09fc1a6407537c2e76e0147566896" translate="yes" xml:space="preserve">
          <source>Returns True if the global deterministic flag is turned on. Refer to &lt;a href=&quot;torch.set_deterministic#torch.set_deterministic&quot;&gt;&lt;code&gt;torch.set_deterministic()&lt;/code&gt;&lt;/a&gt; documentation for more details.</source>
          <target state="translated">グローバル決定論的フラグがオンになっている場合はTrueを返します。詳細については、&lt;a href=&quot;torch.set_deterministic#torch.set_deterministic&quot;&gt; &lt;code&gt;torch.set_deterministic()&lt;/code&gt; の&lt;/a&gt;ドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="c4032dc2622bbc19b42824ae9a76253643ed72f9" translate="yes" xml:space="preserve">
          <source>Returns a 1-D tensor of size</source>
          <target state="translated">サイズの1次元テンソルを返します</target>
        </trans-unit>
        <trans-unit id="d2604008505b663501ba7ccd9df67158c244b1f4" translate="yes" xml:space="preserve">
          <source>Returns a 1-dimensional view of each input tensor with zero dimensions.</source>
          <target state="translated">各入力テンソルの1次元ビューを0次元で返します。</target>
        </trans-unit>
        <trans-unit id="e25d75bccca92cff61915e5211fa5ae4cd4e83b9" translate="yes" xml:space="preserve">
          <source>Returns a 1-dimensional view of each input tensor with zero dimensions. Input tensors with one or more dimensions are returned as-is.</source>
          <target state="translated">0次元の各入力テンソルの1次元ビューを返します。1次元以上の入力テンソルはそのまま返されます。</target>
        </trans-unit>
        <trans-unit id="f9b98594557024de39affd4c070595a178dad181" translate="yes" xml:space="preserve">
          <source>Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</source>
          <target state="translated">対角線上に1つ、他の場所に0を持つ2次元テンソルを返します。</target>
        </trans-unit>
        <trans-unit id="1a93e2128169bc51774f54bd53d2eaec67c329a8" translate="yes" xml:space="preserve">
          <source>Returns a 2-dimensional view of each each input tensor with zero dimensions.</source>
          <target state="translated">各入力テンソルの2次元ビューを0次元で返します。</target>
        </trans-unit>
        <trans-unit id="5d4b7116a250c6d886720ec99aa88d8cbeb63c35" translate="yes" xml:space="preserve">
          <source>Returns a 2-dimensional view of each each input tensor with zero dimensions. Input tensors with two or more dimensions are returned as-is. :param input: :type input: Tensor or list of Tensors</source>
          <target state="translated">0次元の各入力テンソルの2次元ビューを返します。2次元以上の入力テンソルは,そのまま返されます.param input::type input.テンソルまたはテンソルのリスト.</target>
        </trans-unit>
        <trans-unit id="5b208e9701580107f4e0baee12e48579cf84134e" translate="yes" xml:space="preserve">
          <source>Returns a 3-dimensional view of each each input tensor with zero dimensions.</source>
          <target state="translated">各入力テンソルの3次元ビューを0次元で返します。</target>
        </trans-unit>
        <trans-unit id="9be625c9292e0cee5fd9c2f9e9f3ae65376309fe" translate="yes" xml:space="preserve">
          <source>Returns a 3-dimensional view of each each input tensor with zero dimensions. Input tensors with three or more dimensions are returned as-is. :param input: :type input: Tensor or list of Tensors</source>
          <target state="translated">0次元の各入力テンソルの3次元ビューを返します。3次元以上の入力テンソルは,そのまま返されます.param input::type input.テンソルまたはテンソルのリスト.</target>
        </trans-unit>
        <trans-unit id="ca90d78c7ebd1efe1d3973c488edc158aa0b5d0e" translate="yes" xml:space="preserve">
          <source>Returns a &lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt; object representing this distribution&amp;rsquo;s support.</source>
          <target state="translated">このディストリビューションのサポートを表す&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;オブジェクトを返します。</target>
        </trans-unit>
        <trans-unit id="ab61e9a8b5883304b4c24f113af9c2e2c089bc01" translate="yes" xml:space="preserve">
          <source>Returns a &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object to a list of the passed in Futures.</source>
          <target state="translated">渡されたFuturesのリストに&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;オブジェクトを返します。</target>
        </trans-unit>
        <trans-unit id="cff2424065898889ca4c8ceba9391c00be8f3c4e" translate="yes" xml:space="preserve">
          <source>Returns a &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object that can be waited on. When completed, the return value of &lt;code&gt;func&lt;/code&gt; on &lt;code&gt;args&lt;/code&gt; and &lt;code&gt;kwargs&lt;/code&gt; can be retrieved from the &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">待機可能な&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;オブジェクトを返します。完了すると、戻り値 &lt;code&gt;func&lt;/code&gt; 上の &lt;code&gt;args&lt;/code&gt; と &lt;code&gt;kwargs&lt;/code&gt; からはから取得できます&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;オブジェクト。</target>
        </trans-unit>
        <trans-unit id="3012b7f55211365d28ddf4ab3e32e9d56916febf" translate="yes" xml:space="preserve">
          <source>Returns a CPU copy of this storage if it&amp;rsquo;s not already on the CPU</source>
          <target state="translated">このストレージがまだCPUにない場合は、このストレージのCPUコピーを返します</target>
        </trans-unit>
        <trans-unit id="310ef068d2b0176ea9cd4ecb440e8d929300b581" translate="yes" xml:space="preserve">
          <source>Returns a DLPack representing the tensor.</source>
          <target state="translated">テンソルを表すDLPackを返します。</target>
        </trans-unit>
        <trans-unit id="d270dbf83984f38c1be89175b564ec60887173d4" translate="yes" xml:space="preserve">
          <source>Returns a Python float containing the current scale, or 1.0 if scaling is disabled.</source>
          <target state="translated">現在のスケールを含む Python の float、スケーリングが無効な場合は 1.0 を返します。</target>
        </trans-unit>
        <trans-unit id="79f467145c77b5bb1f3f5bd6e7fabcaca51e20bd" translate="yes" xml:space="preserve">
          <source>Returns a Python float containing the scale backoff factor.</source>
          <target state="translated">スケールバックオフ係数を含む Python の float を返します。</target>
        </trans-unit>
        <trans-unit id="fea0c1596123398a7d55be21927faed71a6ab193" translate="yes" xml:space="preserve">
          <source>Returns a Python float containing the scale growth factor.</source>
          <target state="translated">スケール成長係数を含む Python の float を返します。</target>
        </trans-unit>
        <trans-unit id="7844351802a857a8df7b5d5cbf2c31ca4dbaa9b0" translate="yes" xml:space="preserve">
          <source>Returns a Python int containing the growth interval.</source>
          <target state="translated">成長間隔を含むPythonのintを返します。</target>
        </trans-unit>
        <trans-unit id="8d50286946851edf8b261b9ee4ffcf514e96ce11" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with &lt;code&gt;0&lt;/code&gt;. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="translated">&lt;code&gt;0&lt;/code&gt; で満たされたサイズ&lt;a href=&quot;#torch.Tensor.size&quot;&gt; &lt;code&gt;size&lt;/code&gt; &lt;/a&gt;テンソルを返します。デフォルトでは、返されるテンソルはこのテンソルと同じ&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を持ち&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="0ab36bf75992b3e189a293c78e7fdb358c585560" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with &lt;code&gt;1&lt;/code&gt;. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="translated">&lt;code&gt;1&lt;/code&gt; で満たされたサイズ&lt;a href=&quot;#torch.Tensor.size&quot;&gt; &lt;code&gt;size&lt;/code&gt; &lt;/a&gt;テンソルを返します。デフォルトでは、返されるテンソルはこのテンソルと同じ&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を持ち&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="aff928dda115238bd0307d57f02acbba9a324cfb" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="translated">&lt;code&gt;fill_value&lt;/code&gt; で満たされたサイズ&lt;a href=&quot;#torch.Tensor.size&quot;&gt; &lt;code&gt;size&lt;/code&gt; &lt;/a&gt;テンソルを返します。デフォルトでは、返されるテンソルはこのテンソルと同じ&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を持ち&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="545a5b97b3133069c0e8dcc8e1ce77397a1e785a" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with uninitialized data. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="translated">初期化&lt;a href=&quot;#torch.Tensor.size&quot;&gt; &lt;code&gt;size&lt;/code&gt; &lt;/a&gt;れていないデータで満たされたサイズサイズのテンソルを返します。デフォルトでは、返されるテンソルはこのテンソルと同じ&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を持ち&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="e1bd30076d669876272e68e1e793c79f23bddd95" translate="yes" xml:space="preserve">
          <source>Returns a Tensor with same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as the Tensor &lt;code&gt;other&lt;/code&gt;. When &lt;code&gt;non_blocking&lt;/code&gt;, tries to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor. When &lt;code&gt;copy&lt;/code&gt; is set, a new Tensor is created even when the Tensor already matches the desired conversion.</source>
          <target state="translated">テンソルは同じで返し&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;テンソルなど &lt;code&gt;other&lt;/code&gt; 。とき &lt;code&gt;non_blocking&lt;/code&gt; 、CUDAテンソルに固定メモリーとCPUテンソルを変換ホスト可能な場合、例えば、に関して非同期的に変換しようとします。ときに &lt;code&gt;copy&lt;/code&gt; 設定されているテンソルが既に所望の変換と一致した場合でも、新たなテンソルが作成されます。</target>
        </trans-unit>
        <trans-unit id="7ff74c2d1bff3e0ce5952d69b71bd9a1e607f1aa" translate="yes" xml:space="preserve">
          <source>Returns a Tensor with the specified &lt;a href=&quot;#torch.Tensor.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; and (optional) &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;dtype&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; it is inferred to be &lt;code&gt;self.dtype&lt;/code&gt;. When &lt;code&gt;non_blocking&lt;/code&gt;, tries to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor. When &lt;code&gt;copy&lt;/code&gt; is set, a new Tensor is created even when the Tensor already matches the desired conversion.</source>
          <target state="translated">指定された&lt;a href=&quot;#torch.Tensor.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;と（オプションの） &lt;code&gt;dtype&lt;/code&gt; を持つテンソルを返します。場合 &lt;code&gt;dtype&lt;/code&gt; ありません &lt;code&gt;None&lt;/code&gt; あることを推測さ &lt;code&gt;self.dtype&lt;/code&gt; 。とき &lt;code&gt;non_blocking&lt;/code&gt; 、CUDAテンソルに固定メモリーとCPUテンソルを変換ホスト可能な場合、例えば、に関して非同期的に変換しようとします。ときに &lt;code&gt;copy&lt;/code&gt; 設定されているテンソルが既に所望の変換と一致した場合でも、新たなテンソルが作成されます。</target>
        </trans-unit>
        <trans-unit id="da569f76cd483df9524efcb31fcf2ea99e390904" translate="yes" xml:space="preserve">
          <source>Returns a Tensor with the specified &lt;code&gt;dtype&lt;/code&gt;</source>
          <target state="translated">指定された &lt;code&gt;dtype&lt;/code&gt; のテンソルを返します</target>
        </trans-unit>
        <trans-unit id="da2702897f096fbbfeecf34312faf90efede2de3" translate="yes" xml:space="preserve">
          <source>Returns a bool indicating if CUDA is currently available.</source>
          <target state="translated">現在CUDAが利用可能かどうかを示すboolを返します。</target>
        </trans-unit>
        <trans-unit id="6724b6006e294e6e49650c83c7e2700124a4da5f" translate="yes" xml:space="preserve">
          <source>Returns a bool indicating if CUDNN is currently available.</source>
          <target state="translated">CUDNNが現在利用可能かどうかを示すboolを返します。</target>
        </trans-unit>
        <trans-unit id="623f6de5f91be71aa002bb6ab0ba269d8348512a" translate="yes" xml:space="preserve">
          <source>Returns a bool indicating whether this instance is enabled.</source>
          <target state="translated">このインスタンスが有効かどうかを示すboolを返します。</target>
        </trans-unit>
        <trans-unit id="005b46932efde89028d44d377485c52b269ce9de" translate="yes" xml:space="preserve">
          <source>Returns a byte tensor of &lt;code&gt;sample_shape + batch_shape&lt;/code&gt; indicating whether each event in value satisfies this constraint.</source>
          <target state="translated">値の各イベントがこの制約を満たすかどうかを示す &lt;code&gt;sample_shape + batch_shape&lt;/code&gt; バイトテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="e15fd6f4de5dc5fea9ffd2c5465a552199dc217b" translate="yes" xml:space="preserve">
          <source>Returns a contiguous in memory tensor containing the same data as &lt;code&gt;self&lt;/code&gt; tensor. If &lt;code&gt;self&lt;/code&gt; tensor is already in the specified memory format, this function returns the &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルと同じデータを含む連続したメモリ内テンソルを返します。場合は &lt;code&gt;self&lt;/code&gt; テンソルは、指定されたメモリ形式で既にある、この関数は返す &lt;code&gt;self&lt;/code&gt; テンソルを。</target>
        </trans-unit>
        <trans-unit id="27f4f3450faf371eb6306a54c86ee05877b30941" translate="yes" xml:space="preserve">
          <source>Returns a contraction of a and b over multiple dimensions.</source>
          <target state="translated">aとbの多次元にわたる収縮を返します。</target>
        </trans-unit>
        <trans-unit id="28370d731f31276aa7e934060964f2e577e96a76" translate="yes" xml:space="preserve">
          <source>Returns a copy of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; コピーを返します。</target>
        </trans-unit>
        <trans-unit id="3318b58b5db87c6ad9827c719c9a9b9dbdc40b78" translate="yes" xml:space="preserve">
          <source>Returns a copy of the tensor in &lt;code&gt;torch.mkldnn&lt;/code&gt; layout.</source>
          <target state="translated">&lt;code&gt;torch.mkldnn&lt;/code&gt; レイアウトのテンソルのコピーを返します。</target>
        </trans-unit>
        <trans-unit id="f6881bd2839553790195cb237970005b22687467" translate="yes" xml:space="preserve">
          <source>Returns a copy of this object in CPU memory.</source>
          <target state="translated">CPUメモリ内のこのオブジェクトのコピーを返します。</target>
        </trans-unit>
        <trans-unit id="bd445c8d669710f667e23d46ff8038e303167c04" translate="yes" xml:space="preserve">
          <source>Returns a copy of this object in CUDA memory.</source>
          <target state="translated">CUDAメモリ内のこのオブジェクトのコピーを返します。</target>
        </trans-unit>
        <trans-unit id="2d7501c9a5a1714d3c3684f56c90bd8b61fff5d3" translate="yes" xml:space="preserve">
          <source>Returns a copy of this storage</source>
          <target state="translated">このストレージのコピーを返します。</target>
        </trans-unit>
        <trans-unit id="7d518eb5a72df432375d8394da8f628d15fd3b22" translate="yes" xml:space="preserve">
          <source>Returns a dictionary containing a whole state of the module.</source>
          <target state="translated">モジュールの状態全体を含む辞書を返します。</target>
        </trans-unit>
        <trans-unit id="7da6f33bf2a479dba2b7480dac5819fb18cbbc2f" translate="yes" xml:space="preserve">
          <source>Returns a dictionary from argument names to &lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt; objects that should be satisfied by each argument of this distribution. Args that are not tensors need not appear in this dict.</source>
          <target state="translated">引数名から、この分布の各引数が満たす必要のある&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;オブジェクトへのディクショナリを返します。テンソルではない引数は、このdictに表示される必要はありません。</target>
        </trans-unit>
        <trans-unit id="e46b2212af694a636c66b6d3e83683486d2db4d8" translate="yes" xml:space="preserve">
          <source>Returns a dictionary of CUDA memory allocator statistics for a given device.</source>
          <target state="translated">指定したデバイスのCUDAメモリアロケータ統計情報の辞書を返します。</target>
        </trans-unit>
        <trans-unit id="915db01bc1c22d7e1017e2a0ebc05f0845ed5843" translate="yes" xml:space="preserve">
          <source>Returns a human-readable printout of the current memory allocator statistics for a given device.</source>
          <target state="translated">指定したデバイスの現在のメモリアロケータの統計情報を、人間が読めるように印刷して返します。</target>
        </trans-unit>
        <trans-unit id="dbff7cc734b7142fc6847934bd6e1e33f653b796" translate="yes" xml:space="preserve">
          <source>Returns a list containing the elements of this storage</source>
          <target state="translated">このストレージの要素を含むリストを返します</target>
        </trans-unit>
        <trans-unit id="97fd9a7e3427d9329387c86b5fc1fc50b3513d44" translate="yes" xml:space="preserve">
          <source>Returns a list of ByteTensor representing the random number states of all devices.</source>
          <target state="translated">すべてのデバイスの乱数状態を表すByteTensorのリストを返します。</target>
        </trans-unit>
        <trans-unit id="dd4681a72abe05d09c99ad2246c5c6f58da6423c" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the &lt;code&gt;k&lt;/code&gt; th smallest element of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は、指定された次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; テンソルの各行の &lt;code&gt;k&lt;/code&gt; 番目に小さい要素です。</target>
        </trans-unit>
        <trans-unit id="ee8ea74a50bcff655454904543731546a0784b94" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the &lt;code&gt;k&lt;/code&gt; th smallest element of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each element found.</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は、指定された次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; テンソルの各行の &lt;code&gt;k&lt;/code&gt; 番目に小さい要素です。また、 &lt;code&gt;indices&lt;/code&gt; は、見つかった各要素のインデックスの場所です。</target>
        </trans-unit>
        <trans-unit id="1e386080072251f678a51090a4553c8d16a045fa" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative maximum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は、次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; 要素の累積最大値です。</target>
        </trans-unit>
        <trans-unit id="126e4b96929c50182f17c4bb4a58b7d0fe049898" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative maximum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each maximum value found in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は、次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; 要素の累積最大値です。また、 &lt;code&gt;indices&lt;/code&gt; は、ディメンション &lt;code&gt;dim&lt;/code&gt; で見つかった各最大値のインデックス位置です。</target>
        </trans-unit>
        <trans-unit id="0588c1c3069407fd276a9514a421bf82e6313f49" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative minimum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; 要素の累積最小値です。</target>
        </trans-unit>
        <trans-unit id="c882e37440105ee95efe87d7c7a08229fc1a4c09" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative minimum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each maximum value found in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; 要素の累積最小値です。また、 &lt;code&gt;indices&lt;/code&gt; は、ディメンション &lt;code&gt;dim&lt;/code&gt; で見つかった各最大値のインデックス位置です。</target>
        </trans-unit>
        <trans-unit id="967b821b8f0b7a1f96a4f7d0f792de5f0185c446" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the maximum value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each maximum value found (argmax).</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は、指定された次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; テンソルの各行の最大値です。そして &lt;code&gt;indices&lt;/code&gt; それぞれ最大値を見出した（ARGMAX）のインデックス位置です。</target>
        </trans-unit>
        <trans-unit id="340d25e61485b289574a04d557988b6aad2f299c" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the median value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each median value found.</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は、指定された次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; テンソルの各行の中央値です。また、 &lt;code&gt;indices&lt;/code&gt; は、見つかった各中央値のインデックスの場所です。</target>
        </trans-unit>
        <trans-unit id="6b24dd1ba3e9b5a8840a923ed9f1831a7b9b04bb" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the minimum value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each minimum value found (argmin).</source>
          <target state="translated">名前付きタプル &lt;code&gt;(values, indices)&lt;/code&gt; 返します。ここで、 &lt;code&gt;values&lt;/code&gt; は、指定された次元 &lt;code&gt;dim&lt;/code&gt; 内の &lt;code&gt;input&lt;/code&gt; テンソルの各行の最小値です。そして &lt;code&gt;indices&lt;/code&gt; （argmin）検出された各最小値のインデックス位置です。</target>
        </trans-unit>
        <trans-unit id="bc8471de2c101d3651a6d7a76fd12e82843e6661" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the mode value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;, i.e.</source>
          <target state="translated">戻りnamedtuple &lt;code&gt;(values, indices)&lt;/code&gt; &lt;code&gt;values&lt;/code&gt; の各列の最頻値である &lt;code&gt;input&lt;/code&gt; 所定の寸法でテンソル &lt;code&gt;dim&lt;/code&gt; 、すなわち</target>
        </trans-unit>
        <trans-unit id="a4cc2f3a360a06df266083c92ef6ae91e2b318f1" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the mode value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;, i.e. a value which appears most often in that row, and &lt;code&gt;indices&lt;/code&gt; is the index location of each mode value found.</source>
          <target state="translated">戻りnamedtuple &lt;code&gt;(values, indices)&lt;/code&gt; &lt;code&gt;values&lt;/code&gt; の各列の最頻値である &lt;code&gt;input&lt;/code&gt; 所与次元におけるテンソル &lt;code&gt;dim&lt;/code&gt; すなわち、その行で最も頻繁に表示される値、及び、 &lt;code&gt;indices&lt;/code&gt; 各モード値のインデックス位置が発見されます。</target>
        </trans-unit>
        <trans-unit id="55daf74ff9a749b34582eb6dc5a7e9467d0b17d0" translate="yes" xml:space="preserve">
          <source>Returns a new 1-D tensor which indexes the &lt;code&gt;input&lt;/code&gt; tensor according to the boolean mask &lt;code&gt;mask&lt;/code&gt; which is a &lt;code&gt;BoolTensor&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;BoolTensor&lt;/code&gt; であるブールマスク &lt;code&gt;mask&lt;/code&gt; に従って &lt;code&gt;input&lt;/code&gt; テンソルにインデックスを付ける新しい1-Dテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="cc996281b6d8b730ea490f35416e253843087c8c" translate="yes" xml:space="preserve">
          <source>Returns a new SparseTensor with values from Tensor &lt;code&gt;input&lt;/code&gt; filtered by indices of &lt;code&gt;mask&lt;/code&gt; and values are ignored. &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;mask&lt;/code&gt; must have the same shape.</source>
          <target state="translated">&lt;code&gt;mask&lt;/code&gt; インデックスでフィルタリングされたTensor &lt;code&gt;input&lt;/code&gt; からの値を持つ新しいSparseTensorを返し、値は無視されます。 &lt;code&gt;input&lt;/code&gt; と &lt;code&gt;mask&lt;/code&gt; は同じ形状である必要があります。</target>
        </trans-unit>
        <trans-unit id="650add904aa71e494da203b253a7e5daaa3f4c87" translate="yes" xml:space="preserve">
          <source>Returns a new Tensor with &lt;code&gt;data&lt;/code&gt; as the tensor data. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="translated">&lt;code&gt;data&lt;/code&gt; をテンソルデータとして持つ新しいテンソルを返します。デフォルトでは、返されるテンソルはこのテンソルと同じ&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を持ち&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="6f5b88777af1b3fb2f4856550ea09e3d3ade90f2" translate="yes" xml:space="preserve">
          <source>Returns a new Tensor, detached from the current graph.</source>
          <target state="translated">現在のグラフから切り離された新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="adfa10a0d579afab7d4a1e2dd4d592e805a24bbd" translate="yes" xml:space="preserve">
          <source>Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to &lt;code&gt;batch_shape&lt;/code&gt;. This method calls &lt;a href=&quot;tensors#torch.Tensor.expand&quot;&gt;&lt;code&gt;expand&lt;/code&gt;&lt;/a&gt; on the distribution&amp;rsquo;s parameters. As such, this does not allocate new memory for the expanded distribution instance. Additionally, this does not repeat any args checking or parameter broadcasting in &lt;code&gt;__init__.py&lt;/code&gt;, when an instance is first created.</source>
          <target state="translated">バッチディメンションが &lt;code&gt;batch_shape&lt;/code&gt; に展開された新しい配布インスタンスを返します（または派生クラスによって提供される既存のインスタンスにデータを入力します）。このメソッド呼び出しは、ディストリビューションのパラメーターを&lt;a href=&quot;tensors#torch.Tensor.expand&quot;&gt; &lt;code&gt;expand&lt;/code&gt; &lt;/a&gt;します。そのため、これは拡張された配布インスタンスに新しいメモリを割り当てません。さらに、これは、インスタンスが最初に作成されたときに、 &lt;code&gt;__init__.py&lt;/code&gt; で引数チェックまたはパラメータブロードキャストを繰り返さない。</target>
        </trans-unit>
        <trans-unit id="b6cad31d8dba22f0073db8447536a302dee9ee8b" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing imaginary values of the &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの虚数を含む新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a474356ccaab506872384349a8c7d3cc842edfca" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing imaginary values of the &lt;code&gt;self&lt;/code&gt; tensor. The returned tensor and &lt;code&gt;self&lt;/code&gt; share the same underlying storage.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの虚数を含む新しいテンソルを返します。返されたテンソルと &lt;code&gt;self&lt;/code&gt; は、同じ基盤となるストレージを共有します。</target>
        </trans-unit>
        <trans-unit id="0417e03c0fc21d8aa9cfd0ad69033f35d283ab8f" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing real values of the &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの実数値を含む新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="ecd577300f229280c9c5bc1fe369db0f8475652e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing real values of the &lt;code&gt;self&lt;/code&gt; tensor. The returned tensor and &lt;code&gt;self&lt;/code&gt; share the same underlying storage.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの実数値を含む新しいテンソルを返します。返されたテンソルと &lt;code&gt;self&lt;/code&gt; は、同じ基盤となるストレージを共有します。</target>
        </trans-unit>
        <trans-unit id="84c3a649630732036f386759b3c1fe0f4082f284" translate="yes" xml:space="preserve">
          <source>Returns a new tensor that is a narrowed version of &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルの狭められたバージョンである新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="446ae7f4205e67fe0ead00f78a291ab93a7e711a" translate="yes" xml:space="preserve">
          <source>Returns a new tensor that is a narrowed version of &lt;code&gt;input&lt;/code&gt; tensor. The dimension &lt;code&gt;dim&lt;/code&gt; is input from &lt;code&gt;start&lt;/code&gt; to &lt;code&gt;start + length&lt;/code&gt;. The returned tensor and &lt;code&gt;input&lt;/code&gt; tensor share the same underlying storage.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルの狭められたバージョンである新しいテンソルを返します。寸法 &lt;code&gt;dim&lt;/code&gt; は、 &lt;code&gt;start&lt;/code&gt; から &lt;code&gt;start + length&lt;/code&gt; まで入力されます。返されたテンソルと &lt;code&gt;input&lt;/code&gt; テンソルは、同じ基になるストレージを共有します。</target>
        </trans-unit>
        <trans-unit id="d6897347512206bded239af0259e282422aa1908" translate="yes" xml:space="preserve">
          <source>Returns a new tensor which indexes the &lt;code&gt;input&lt;/code&gt; tensor along dimension &lt;code&gt;dim&lt;/code&gt; using the entries in &lt;code&gt;index&lt;/code&gt; which is a &lt;code&gt;LongTensor&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;LongTensor&lt;/code&gt; である &lt;code&gt;index&lt;/code&gt; のエントリを使用して、次元 &lt;code&gt;dim&lt;/code&gt; に沿って &lt;code&gt;input&lt;/code&gt; テンソルにインデックスを付ける新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="d9c1e11a5f9f21aaf09f7c09b28d3efe9b79c1c9" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with a dimension of size one inserted at the specified position.</source>
          <target state="translated">指定した位置にサイズ1の次元を挿入した新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="3224c262166ef14a2d46031572904d6b7dc8f710" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element is &lt;code&gt;finite&lt;/code&gt; or not.</source>
          <target state="translated">各要素が &lt;code&gt;finite&lt;/code&gt; かどうかを表すブール要素を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="95e1f8a1ccb8a8da884d7e84169520f79117ec5e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is &amp;ldquo;close&amp;rdquo; to the corresponding element of &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素が &lt;code&gt;other&lt;/code&gt; 対応する要素に「近い」かどうかを表すブール要素を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="4be234d2b824b3afbb8b6e3c023a9678a2fef898" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is &amp;ldquo;close&amp;rdquo; to the corresponding element of &lt;code&gt;other&lt;/code&gt;. Closeness is defined as:</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素が &lt;code&gt;other&lt;/code&gt; 対応する要素に「近い」かどうかを表すブール要素を持つ新しいテンソルを返します。近さは次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="e9a96751e78a2d8505653806cfbbeebe8f0da987" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is NaN or not.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素がNaNであるかどうかを表すブール要素を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="f12a3acfcbbec29775876cc40c95d5a00ba9dd4a" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is NaN or not. Complex values are considered NaN when either their real and/or imaginary part is NaN.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素がNaNであるかどうかを表すブール要素を持つ新しいテンソルを返します。複素数値は、実数部および/または虚数部がNaNの場合、NaNと見なされます。</target>
        </trans-unit>
        <trans-unit id="c183c7e7c59ca8cd11a1eb4078b588d714403acc" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is real-valued or not.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素が実数値であるかどうかを表すブール要素を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="1d49a6f7124bd5cd437a7a8fee3ecaa6dd817cb5" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is real-valued or not. All real-valued types are considered real. Complex values are considered real when their imaginary part is 0.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素が実数値であるかどうかを表すブール要素を持つ新しいテンソルを返します。すべての実数値型は実数と見なされます。複素数値は、虚数部が0の場合に実数と見なされます。</target>
        </trans-unit>
        <trans-unit id="fc57cc29526229bfe21bab4f3ac0fa280da67107" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with each of the elements of &lt;code&gt;input&lt;/code&gt; converted from angles in degrees to radians.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素が度単位の角度からラジアンに変換された新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="e88584aef7be0fb19dcf3caab156e7c17acae22e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with each of the elements of &lt;code&gt;input&lt;/code&gt; converted from angles in radians to degrees.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素がラジアン単位の角度から度に変換された新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="1fd6a07571fec21877bbfab5cd7f129520d284d3" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with each of the elements of &lt;code&gt;input&lt;/code&gt; rounded to the closest integer.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各要素が最も近い整数に丸められた新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="fbe9fedb3aa9a3f8d1c80fddb5c3023ad4eb0562" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the arcsine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のアークサインを持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="e7301245f47a696980faac9e988f16c20bfda8b7" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the arctangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のアークタンジェントを持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="48ba42f2193edb51a142cab5570b31530effd843" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the ceil of the elements of &lt;code&gt;input&lt;/code&gt;, the smallest integer greater than or equal to each element.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のセル、各要素以上の最小の整数を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="ec380dfec0f03433bc5e3eb0dc32821c6d58c884" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the cosine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のコサインを持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="b0f7755628d00f3662eb39d02532aaee3f952862" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the elements of &lt;code&gt;input&lt;/code&gt; at the given indices.</source>
          <target state="translated">指定されたインデックスの &lt;code&gt;input&lt;/code&gt; 要素を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="1c910712ac5b779edd94af13b8675d26b2ec9292" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the elements of &lt;code&gt;input&lt;/code&gt; at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices.</source>
          <target state="translated">指定されたインデックスの &lt;code&gt;input&lt;/code&gt; 要素を持つ新しいテンソルを返します。入力テンソルは、1次元テンソルとして表示されたかのように扱われます。結果はインデックスと同じ形になります。</target>
        </trans-unit>
        <trans-unit id="303a77ef9e4e8ebea411b724b70cc880893ce1e5" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the exponential of the elements minus 1 of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">要素の指数から &lt;code&gt;input&lt;/code&gt; 1を引いた新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="fc8c5f6e874a9d0acbadee7550724c3fd5e88f46" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the exponential of the elements of the input tensor &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">入力テンソル &lt;code&gt;input&lt;/code&gt; 要素の指数を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="66422619029217fb49c5540ea658003ab25d0251" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the floor of the elements of &lt;code&gt;input&lt;/code&gt;, the largest integer less than or equal to each element.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のフロアを持つ新しいテンソルを返します。最大の整数は各要素以下です。</target>
        </trans-unit>
        <trans-unit id="54289275fc2999c18e519269b9c836fadd53ce09" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the hyperbolic cosine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の双曲線余弦を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="60d4e278d41229d94159bb88a5a80098f0f17944" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the hyperbolic sine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の双曲線正弦を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="529a1d5ed854492ced22f20ca045b03cdb98828a" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the hyperbolic tangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の双曲線正接を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="9966d85e500f92c101949dbcee56d3622b0b7c74" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the inverse hyperbolic cosine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の逆双曲線余弦を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="016516e7b6362bc2420ae10e09ad46e7409d58cb" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the inverse hyperbolic sine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の逆双曲線正弦を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="8624b8361034217c02a1c5e88fca1edddd5ce5dd" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the inverse hyperbolic tangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の逆双曲線正接を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="dfd8b16427d7265384f4ab1669de0b012956b1e0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logarithm to the base 10 of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の10を底とする対数の新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="ca59edbe372ab054262e278a40d31de7be114996" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logarithm to the base 2 of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の基数2に対する対数を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="768981f99c3160fc5f2a6b954d047547f7f51a33" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logit of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のロジットを持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="83c02ed817fb8ffcff4e801d08d12130cb9f1cab" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logit of the elements of &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; is clamped to [eps, 1 - eps] when eps is not None. When eps is None and &lt;code&gt;input&lt;/code&gt; &amp;lt; 0 or &lt;code&gt;input&lt;/code&gt; &amp;gt; 1, the function will yields NaN.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のロジットを持つ新しいテンソルを返します。epsがNoneでない場合、 &lt;code&gt;input&lt;/code&gt; は[eps、1-eps]にクランプされます。epsがNoneで、 &lt;code&gt;input&lt;/code&gt; &amp;lt;0または &lt;code&gt;input&lt;/code&gt; &amp;gt; 1の場合、関数はNaNを生成します。</target>
        </trans-unit>
        <trans-unit id="743fb44188d39b917a57a969a7a2bdfa54f07c5c" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the natural logarithm of (1 + &lt;code&gt;input&lt;/code&gt;).</source>
          <target state="translated">（1 + &lt;code&gt;input&lt;/code&gt; ）の自然対数を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="7802c5deb620e1b95914f599e220dfe558ee03c0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the natural logarithm of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の自然対数を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="c9bebfac39f90f81173963e0ca1f126dea57da57" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the negative of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の負の値を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a0595e3a74577061b95243faf09a3387b6e217a7" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the reciprocal of the elements of &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 要素の逆数を持つ新しいテンソルを返します</target>
        </trans-unit>
        <trans-unit id="40e790541f395ea8a715d66e7db7815ecda1464f" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the reciprocal of the square-root of each of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の各要素の平方根の逆数を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="82f5d4bb888952c73ce51e1bac717329cb2869c0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the same data as the &lt;code&gt;self&lt;/code&gt; tensor but of a different &lt;code&gt;shape&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルと同じデータであるが &lt;code&gt;shape&lt;/code&gt; が異なる新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="736d1d1a205da1b8f4c4709de8f6235951658a7e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the sigmoid of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素のシグモイドを持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="5e2b36eb81199cdbe569cc67684536ac9defc3a0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the signs of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の符号を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="47f02b09b0f6a0ab4b9c1f34438e6706d93ade59" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the sine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の正弦を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="75f7c6fa74ae5240454bfc9ef7f507262ffe9ed2" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the square of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の2乗を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="b2f28004537b23138d7c295a5914cf3e65ab6fd0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the square-root of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の平方根を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="baf6cf4928d6ab113308458333184cd46b1dbec9" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the tangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の接線を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="c51c660d43995f5399bc591984337fa3aa3dd1db" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the truncated integer values of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の要素の切り捨てられた整数値を持つ新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="71a9122ea30596ae8f8e0cfb84c73297b46f8b8e" translate="yes" xml:space="preserve">
          <source>Returns a new view of the &lt;code&gt;self&lt;/code&gt; tensor with singleton dimensions expanded to a larger size.</source>
          <target state="translated">シングルトン次元がより大きなサイズに拡張された &lt;code&gt;self&lt;/code&gt; テンソルの新しいビューを返します。</target>
        </trans-unit>
        <trans-unit id="04f242c1b997d817d7997eb7a445d6e3823e9344" translate="yes" xml:space="preserve">
          <source>Returns a partial view of &lt;code&gt;input&lt;/code&gt; with the its diagonal elements with respect to &lt;code&gt;dim1&lt;/code&gt; and &lt;code&gt;dim2&lt;/code&gt; appended as a dimension at the end of the shape.</source>
          <target state="translated">形状の最後に寸法として追加された &lt;code&gt;dim1&lt;/code&gt; および &lt;code&gt;dim2&lt;/code&gt; に関する対角要素を含む &lt;code&gt;input&lt;/code&gt; 部分ビューを返します。</target>
        </trans-unit>
        <trans-unit id="d3032b88cf4f390e50cfecedba4f33edc6cf5043" translate="yes" xml:space="preserve">
          <source>Returns a pretty-printed representation (as valid Python syntax) of the internal graph for the &lt;code&gt;forward&lt;/code&gt; method. See &lt;a href=&quot;../jit#inspecting-code&quot;&gt;Inspecting Code&lt;/a&gt; for details.</source>
          <target state="translated">&lt;code&gt;forward&lt;/code&gt; メソッドの内部グラフの（有効なPython構文として）きれいに印刷された表現を返します。詳細については、&lt;a href=&quot;../jit#inspecting-code&quot;&gt;コードの検査&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="21aab95a18e188886df073751e7d106cd6f9db59" translate="yes" xml:space="preserve">
          <source>Returns a random permutation of integers from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;n - 1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;0&lt;/code&gt; から &lt;code&gt;n - 1&lt;/code&gt; までの整数のランダム順列を返します。</target>
        </trans-unit>
        <trans-unit id="af613cf5c56817cafaa6ac101470a6f4a4596731" translate="yes" xml:space="preserve">
          <source>Returns a result tensor where each</source>
          <target state="translated">結果テンソルを返します。</target>
        </trans-unit>
        <trans-unit id="38827e466d04bcb489dba158a3d8570409e939d7" translate="yes" xml:space="preserve">
          <source>Returns a set of sharing strategies supported on a current system.</source>
          <target state="translated">現在のシステムでサポートされている共有戦略のセットを返します。</target>
        </trans-unit>
        <trans-unit id="a40e726bb013fd09820ae8ca46b5c0798f7ebbbb" translate="yes" xml:space="preserve">
          <source>Returns a snapshot of the CUDA memory allocator state across all devices.</source>
          <target state="translated">すべてのデバイスにわたる CUDA メモリアロケータの状態のスナップショットを返します。</target>
        </trans-unit>
        <trans-unit id="a13c7d88cad174382717397efbd3cfcb039a6695" translate="yes" xml:space="preserve">
          <source>Returns a sparse copy of the tensor. PyTorch supports sparse tensors in &lt;a href=&quot;sparse#sparse-docs&quot;&gt;coordinate format&lt;/a&gt;.</source>
          <target state="translated">テンソルのスパースコピーを返します。PyTorchは、&lt;a href=&quot;sparse#sparse-docs&quot;&gt;座標形式の&lt;/a&gt;スパーステンソルをサポートします。</target>
        </trans-unit>
        <trans-unit id="d0a96d92340e65cc2a84c22d4d7b7ff9aa5fc4fe" translate="yes" xml:space="preserve">
          <source>Returns a string representation of the internal graph for the &lt;code&gt;forward&lt;/code&gt; method. See &lt;a href=&quot;../jit#interpreting-graphs&quot;&gt;Interpreting Graphs&lt;/a&gt; for details.</source>
          <target state="translated">&lt;code&gt;forward&lt;/code&gt; メソッドの内部グラフの文字列表現を返します。詳細については、&lt;a href=&quot;../jit#interpreting-graphs&quot;&gt;グラフの解釈&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="597e1ef5a6ebc351d6f9d2b405bdd9101ff81520" translate="yes" xml:space="preserve">
          <source>Returns a string representation of the internal graph for the &lt;code&gt;forward&lt;/code&gt; method. This graph will be preprocessed to inline all function and method calls. See &lt;a href=&quot;../jit#interpreting-graphs&quot;&gt;Interpreting Graphs&lt;/a&gt; for details.</source>
          <target state="translated">&lt;code&gt;forward&lt;/code&gt; メソッドの内部グラフの文字列表現を返します。このグラフは、すべての関数とメソッドの呼び出しをインライン化するために前処理されます。詳細については、&lt;a href=&quot;../jit#interpreting-graphs&quot;&gt;グラフの解釈&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="bbb10017036639ab22d4a14313f02dc34ac957a3" translate="yes" xml:space="preserve">
          <source>Returns a tensor containing the indices of all non-zero elements of &lt;code&gt;input&lt;/code&gt;. Each row in the result contains the indices of a non-zero element in &lt;code&gt;input&lt;/code&gt;. The result is sorted lexicographically, with the last index changing the fastest (C-style).</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; のすべての非ゼロ要素のインデックスを含むテンソルを返します。結果の各行には、 &lt;code&gt;input&lt;/code&gt; ゼロ以外の要素のインデックスが含まれています。結果は辞書式にソートされ、最後のインデックスが最も速く変更されます（Cスタイル）。</target>
        </trans-unit>
        <trans-unit id="92387ca99fbc648117949c0806c35a077690e5b2" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with random integers generated uniformly between &lt;code&gt;low&lt;/code&gt; (inclusive) and &lt;code&gt;high&lt;/code&gt; (exclusive).</source>
          <target state="translated">&lt;code&gt;low&lt;/code&gt; （包括的）と &lt;code&gt;high&lt;/code&gt; （排他的）の間で均一に生成されたランダムな整数で満たされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a3052366ee17d89fee66f156e0077cbbe80ebcf2" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with random numbers from a normal distribution with mean &lt;code&gt;0&lt;/code&gt; and variance &lt;code&gt;1&lt;/code&gt; (also called the standard normal distribution).</source>
          <target state="translated">平均が &lt;code&gt;0&lt;/code&gt; で分散が &lt;code&gt;1&lt;/code&gt; の正規分布（標準正規分布とも呼ばれます）から乱数で満たされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="071f27bb3cbfbdac0a3664bb5e1e9b570135a766" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with random numbers from a uniform distribution on the interval</source>
          <target state="translated">区間上の一様分布からの乱数で満たされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="f6ccb0d318d2aea6d35f4cd94e4134bbdd4f3636" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;0&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じサイズのスカラー値 &lt;code&gt;0&lt;/code&gt; で満たされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="5053ad71aa6f4e2e9cdde0c5980a9be98d8e91ca" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;0&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;torch.zeros_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.zeros(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じサイズのスカラー値 &lt;code&gt;0&lt;/code&gt; で満たされたテンソルを返します。 &lt;code&gt;torch.zeros_like(input)&lt;/code&gt; は、 &lt;code&gt;torch.zeros(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="53e8d496bf6d2306beb97ee488fa23a9b84ced51" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;0&lt;/code&gt;, with the shape defined by the variable argument &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="translated">可変引数 &lt;code&gt;size&lt;/code&gt; で定義された形状で、スカラー値 &lt;code&gt;0&lt;/code&gt; で満たされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="19bc36fafde43e2e6ce27a396db27c69f93641b5" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;1&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じサイズのスカラー値 &lt;code&gt;1&lt;/code&gt; で満たされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="45f89a095c06d9b0650d201a4622d88088b3f6da" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;1&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;torch.ones_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じサイズのスカラー値 &lt;code&gt;1&lt;/code&gt; で満たされたテンソルを返します。 &lt;code&gt;torch.ones_like(input)&lt;/code&gt; は、 &lt;code&gt;torch.ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="380e4f75952135cee58ac0cb34dec6379c82103a" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;1&lt;/code&gt;, with the shape defined by the variable argument &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="translated">可変引数 &lt;code&gt;size&lt;/code&gt; で定義された形状で、スカラー値 &lt;code&gt;1&lt;/code&gt; で満たされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="2619f65f9f0c07b8f2554ca2a356bbee1fb49067" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with uninitialized data.</source>
          <target state="translated">初期化されていないデータで埋められたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="6c9d253aa1bcbf44289c2a22a9efa2be86cdae22" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with uninitialized data. The shape and strides of the tensor is defined by the variable argument &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;stride&lt;/code&gt; respectively. &lt;code&gt;torch.empty_strided(size, stride)&lt;/code&gt; is equivalent to &lt;code&gt;torch.empty(size).as_strided(size, stride)&lt;/code&gt;.</source>
          <target state="translated">初期化されていないデータで満たされたテンソルを返します。テンソルの形状とストライドは、それぞれ可変引数 &lt;code&gt;size&lt;/code&gt; と &lt;code&gt;stride&lt;/code&gt; によって定義されます。 &lt;code&gt;torch.empty_strided(size, stride)&lt;/code&gt; と等価である &lt;code&gt;torch.empty(size).as_strided(size, stride)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="480a441694f9fb4e384f61d0c285c3346aba2867" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with uninitialized data. The shape of the tensor is defined by the variable argument &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="translated">初期化されていないデータで満たされたテンソルを返します。テンソルの形状は、可変引数 &lt;code&gt;size&lt;/code&gt; によって定義されます。</target>
        </trans-unit>
        <trans-unit id="5a9df9f8590e35dc409160c4e4da50e8473fc470" translate="yes" xml:space="preserve">
          <source>Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.</source>
          <target state="translated">平均と標準偏差が与えられた別々の正規分布から引き出された乱数のテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="ef9879439829f78c493eca54baa6bd3b9da4b6a9" translate="yes" xml:space="preserve">
          <source>Returns a tensor of the same size as &lt;code&gt;input&lt;/code&gt; with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in &lt;code&gt;input&lt;/code&gt; i.e.,</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じサイズのテンソルを返します。各要素は、 &lt;code&gt;input&lt;/code&gt; 対応する要素によって指定されたレートパラメーターを使用してポアソン分布からサンプリングされます。</target>
        </trans-unit>
        <trans-unit id="dee1e5e90adcef58cad4a12a8016b3c535cc3f0d" translate="yes" xml:space="preserve">
          <source>Returns a tensor that is a transposed version of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の転置バージョンであるテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="3c3720e104640e1187905d7635a3f6f3703b6e8e" translate="yes" xml:space="preserve">
          <source>Returns a tensor that is a transposed version of &lt;code&gt;input&lt;/code&gt;. The given dimensions &lt;code&gt;dim0&lt;/code&gt; and &lt;code&gt;dim1&lt;/code&gt; are swapped.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; の転置バージョンであるテンソルを返します。指定された次元 &lt;code&gt;dim0&lt;/code&gt; と &lt;code&gt;dim1&lt;/code&gt; が交換されます。</target>
        </trans-unit>
        <trans-unit id="bc2a3afc167973637c7f4b6c69bc81e1a7b7c261" translate="yes" xml:space="preserve">
          <source>Returns a tensor where each row contains &lt;code&gt;num_samples&lt;/code&gt; indices sampled from the multinomial probability distribution located in the corresponding row of tensor &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">各行に、テンソル &lt;code&gt;input&lt;/code&gt; 対応する行にある多項確率分布からサンプリングされた &lt;code&gt;num_samples&lt;/code&gt; インデックスが含まれているテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="bfd4b9d9504c67da6e3c81783a008d55415316b9" translate="yes" xml:space="preserve">
          <source>Returns a tensor where each sub-tensor of &lt;code&gt;input&lt;/code&gt; along dimension &lt;code&gt;dim&lt;/code&gt; is normalized such that the &lt;code&gt;p&lt;/code&gt;-norm of the sub-tensor is lower than the value &lt;code&gt;maxnorm&lt;/code&gt;</source>
          <target state="translated">次元 &lt;code&gt;dim&lt;/code&gt; に沿った &lt;code&gt;input&lt;/code&gt; 各サブテンソルが、サブテンソルの &lt;code&gt;p&lt;/code&gt; ノルムが値 &lt;code&gt;maxnorm&lt;/code&gt; よりも低くなるように正規化されているテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a3a6b5909320cbc074af2544b9626c6f4bda5986" translate="yes" xml:space="preserve">
          <source>Returns a tensor with all the dimensions of &lt;code&gt;input&lt;/code&gt; of size &lt;code&gt;1&lt;/code&gt; removed.</source>
          <target state="translated">サイズ &lt;code&gt;1&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; すべての次元が削除されたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="d4dca01252775c3a510432e13b2a50bd68aaad47" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same data and number of elements as &lt;code&gt;input&lt;/code&gt;, but with the specified shape.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じデータと要素数で、指定された形状のテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="10ea5ae4aa9d17fa5857d769438a3aa3d3b7e12d" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same data and number of elements as &lt;code&gt;input&lt;/code&gt;, but with the specified shape. When possible, the returned tensor will be a view of &lt;code&gt;input&lt;/code&gt;. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs. viewing behavior.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じデータと要素数で、指定された形状のテンソルを返します。可能な場合、返されるテンソルは &lt;code&gt;input&lt;/code&gt; ビューになります。それ以外の場合は、コピーになります。連続する入力と互換性のあるストライドを持つ入力は、コピーせずに再形成できますが、コピーと表示の動作に依存しないでください。</target>
        </trans-unit>
        <trans-unit id="859366eeae9c89a2d4641ddcda6c14627157bccd" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same data and number of elements as &lt;code&gt;self&lt;/code&gt; but with the specified shape. This method returns a view if &lt;code&gt;shape&lt;/code&gt; is compatible with the current shape. See &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;torch.Tensor.view()&lt;/code&gt;&lt;/a&gt; on when it is possible to return a view.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; と同じデータと要素数を持つが、指定された形状のテンソルを返します。このメソッドは、 &lt;code&gt;shape&lt;/code&gt; が現在の形状と互換性がある場合にビューを返します。ビューを返すことができる場合については、&lt;a href=&quot;#torch.Tensor.view&quot;&gt; &lt;code&gt;torch.Tensor.view()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="4ddaf7cc67581deb40ac49cd798acd828948f3ec" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same shape as Tensor &lt;code&gt;input&lt;/code&gt; filled with random integers generated uniformly between &lt;code&gt;low&lt;/code&gt; (inclusive) and &lt;code&gt;high&lt;/code&gt; (exclusive).</source>
          <target state="translated">&lt;code&gt;low&lt;/code&gt; （包括的）と &lt;code&gt;high&lt;/code&gt; （排他的）の間で均一に生成されたランダムな整数で満たされたテンソル &lt;code&gt;input&lt;/code&gt; と同じ形状のテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="f4d7f431450f08dca6e6bf02ccea73d644849cfb" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fill_value&lt;/code&gt; で満たされた &lt;code&gt;input&lt;/code&gt; と同じサイズのテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="03ce7caeebb968b62c8d34b90b828d1ce8423f2f" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;. &lt;code&gt;torch.full_like(input, fill_value)&lt;/code&gt; is equivalent to &lt;code&gt;torch.full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fill_value&lt;/code&gt; で満たされた &lt;code&gt;input&lt;/code&gt; と同じサイズのテンソルを返します。 &lt;code&gt;torch.full_like(input, fill_value)&lt;/code&gt; は、 &lt;code&gt;torch.full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="c4b1fea8767410865166f5ee9867a018bc11da8d" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; that is filled with random numbers from a normal distribution with mean 0 and variance 1.</source>
          <target state="translated">平均が0で分散が1の正規分布からの乱数で満たされた &lt;code&gt;input&lt;/code&gt; と同じサイズのテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="ea94290136057228a379eae661032b4dbc67bcaf" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; that is filled with random numbers from a normal distribution with mean 0 and variance 1. &lt;code&gt;torch.randn_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.randn(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="translated">平均が0で分散が1の正規分布から乱数で満たされた &lt;code&gt;input&lt;/code&gt; と同じサイズのテンソルを返します &lt;code&gt;torch.randn_like(input)&lt;/code&gt; は &lt;code&gt;torch.randn(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0152430be2c09d5c5103cb904fde37d1ace3b55a" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; that is filled with random numbers from a uniform distribution on the interval</source>
          <target state="translated">区間の一様分布から乱数で満たされた &lt;code&gt;input&lt;/code&gt; と同じサイズのテンソルを返します</target>
        </trans-unit>
        <trans-unit id="823c3c765d13781fa9b963395a22444e3b621c72" translate="yes" xml:space="preserve">
          <source>Returns a tuple of 1-D tensors, one for each dimension in &lt;code&gt;input&lt;/code&gt;, each containing the indices (in that dimension) of all non-zero elements of &lt;code&gt;input&lt;/code&gt; .</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各次元に1つずつ、1次元テンソルのタプルを返します。各テンソルには、入力のすべての非ゼロ要素のインデックス（その次元内）が含まれてい &lt;code&gt;input&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fcd5e2fc8161aab0c115280174b5bb6b68911439" translate="yes" xml:space="preserve">
          <source>Returns a tuple of all slices along a given dimension, already without it.</source>
          <target state="translated">指定された次元に沿ったすべてのスライスのタプルを返します。</target>
        </trans-unit>
        <trans-unit id="f9c24c4caad4a1ea9a709ef4d25a5add23c5abc6" translate="yes" xml:space="preserve">
          <source>Returns a tuple of tensors as &lt;code&gt;(the pivots, the L tensor, the U tensor)&lt;/code&gt;.</source>
          <target state="translated">テンソルのタプルを &lt;code&gt;(the pivots, the L tensor, the U tensor)&lt;/code&gt; として返します。</target>
        </trans-unit>
        <trans-unit id="cad07505f53debb40a34d79ccc9f58807d93a22d" translate="yes" xml:space="preserve">
          <source>Returns a tuple of:</source>
          <target state="translated">のタプルを返します。</target>
        </trans-unit>
        <trans-unit id="48ec84de6060a777e4b133c0cc4cbb5c195b63f4" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a complex tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; ビューを複素テンソルとして返します。</target>
        </trans-unit>
        <trans-unit id="cbd534c7cdca6e762bf6f1efb8dbc311c8d5604b" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a complex tensor. For an input complex tensor of &lt;code&gt;size&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; ビューを複素テンソルとして返します。 &lt;code&gt;size&lt;/code&gt; 入力複素テンソルの場合</target>
        </trans-unit>
        <trans-unit id="d5219316aa3ad16a6268bf6cb076669b071e63b0" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a real tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; ビューを実際のテンソルとして返します。</target>
        </trans-unit>
        <trans-unit id="feec717f015dd3a3543847bb4922909ce0df9768" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a real tensor. For an input complex tensor of &lt;code&gt;size&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; ビューを実際のテンソルとして返します。 &lt;code&gt;size&lt;/code&gt; 入力複素テンソルの場合</target>
        </trans-unit>
        <trans-unit id="b19c812d92695d71cc123c4309dfdfb970e00990" translate="yes" xml:space="preserve">
          <source>Returns a view of the original tensor which contains all slices of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; from &lt;code&gt;self&lt;/code&gt; tensor in the dimension &lt;code&gt;dimension&lt;/code&gt;.</source>
          <target state="translated">次元 &lt;code&gt;dimension&lt;/code&gt; &lt;code&gt;self&lt;/code&gt; テンソルからのサイズ&lt;a href=&quot;#torch.Tensor.size&quot;&gt; &lt;code&gt;size&lt;/code&gt; &lt;/a&gt;すべてのスライスを含む元のテンソルのビューを返します。</target>
        </trans-unit>
        <trans-unit id="af681be32c7d06253ca1c1b67c18e2b4ecd6f876" translate="yes" xml:space="preserve">
          <source>Returns a view of the original tensor with its dimensions permuted.</source>
          <target state="translated">元のテンソルの寸法をパーミュレートしたビューを返します。</target>
        </trans-unit>
        <trans-unit id="92e60f922f107927ce27990d6a2076704c10ee26" translate="yes" xml:space="preserve">
          <source>Returns an IPC handle of this event. If not recorded yet, the event will use the current device.</source>
          <target state="translated">このイベントのIPCハンドルを返します。まだ記録されていない場合、イベントは現在のデバイスを使用します。</target>
        </trans-unit>
        <trans-unit id="c55cff2ceacf5489627870098b732610149ca753" translate="yes" xml:space="preserve">
          <source>Returns an fp32 Tensor by dequantizing a quantized Tensor</source>
          <target state="translated">量子化されたテンソルの量子化を解除して,fp32テンソルを返します.</target>
        </trans-unit>
        <trans-unit id="8a760468481f662aec69f0d66a0af21b8d01fcc9" translate="yes" xml:space="preserve">
          <source>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</source>
          <target state="translated">ネットワーク内のすべてのモジュールを対象としたイテレータを返します。</target>
        </trans-unit>
        <trans-unit id="ac68eb8bdb577f36ea46f58e6159bc7bdc815476" translate="yes" xml:space="preserve">
          <source>Returns an iterator over all modules in the network.</source>
          <target state="translated">ネットワーク内のすべてのモジュールのイテレータを返します。</target>
        </trans-unit>
        <trans-unit id="94fc7e2a384a791953b1e205101832ccf08471ae" translate="yes" xml:space="preserve">
          <source>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</source>
          <target state="translated">直近の子モジュールのイテレータを返し、モジュール名とモジュール自体の両方を返します。</target>
        </trans-unit>
        <trans-unit id="06d88a90e624553bccb897dec896158a9e8cbe10" translate="yes" xml:space="preserve">
          <source>Returns an iterator over immediate children modules.</source>
          <target state="translated">直前の子モジュールのイテレータを返します。</target>
        </trans-unit>
        <trans-unit id="710ada787bca81e41a3d40e51f40a7c77bf13dde" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</source>
          <target state="translated">モジュールバッファに対するイテレータを返し、バッファの名前とバッファ自体の両方を返します。</target>
        </trans-unit>
        <trans-unit id="6eff830e357832045671934c63ceb5cb2fcb5978" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module buffers.</source>
          <target state="translated">モジュールバッファのイテレータを返します。</target>
        </trans-unit>
        <trans-unit id="b1b975207d4ac5172ef30d4d877fa0c9ee98199a" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</source>
          <target state="translated">モジュールのパラメータに対するイテレータを返し、パラメータの名前とパラメータ自体の両方を返します。</target>
        </trans-unit>
        <trans-unit id="aa5e4dda23bfdd55410c837a325f1f9ec0f370cb" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module parameters.</source>
          <target state="translated">モジュールパラメータのイテレータを返します。</target>
        </trans-unit>
        <trans-unit id="48fce4dac8987007e7e689346df86ef5aaaf8d0c" translate="yes" xml:space="preserve">
          <source>Returns an uninitialized tensor with the same size as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じサイズの初期化されていないテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="25a01c60e025b196abbdae1e228f044292cc80b3" translate="yes" xml:space="preserve">
          <source>Returns an uninitialized tensor with the same size as &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;torch.empty_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と同じサイズの初期化されていないテンソルを返します。 &lt;code&gt;torch.empty_like(input)&lt;/code&gt; は、 &lt;code&gt;torch.empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="ab487b617ce0598b5cf2a7578485a234f9dec28c" translate="yes" xml:space="preserve">
          <source>Returns cosine similarity between</source>
          <target state="translated">の間のコサイン類似度を返します。</target>
        </trans-unit>
        <trans-unit id="e36c4e3a7a9f1d367dee6c46085960ff3fa5e136" translate="yes" xml:space="preserve">
          <source>Returns cosine similarity between x1 and x2, computed along dim.</source>
          <target state="translated">x1とx2の間のコサイン類似度を dimに沿って計算して返します。</target>
        </trans-unit>
        <trans-unit id="e9ee7bb84b7690f6d9a479786aae93fb8de0a027" translate="yes" xml:space="preserve">
          <source>Returns cublasHandle_t pointer to current cuBLAS handle</source>
          <target state="translated">現在のcuBLASハンドルへのcublasHandle_tポインタを返します。</target>
        </trans-unit>
        <trans-unit id="415079d9dd9bf0c3a5f12e73dab28b75c28128b7" translate="yes" xml:space="preserve">
          <source>Returns either a complex tensor of size</source>
          <target state="translated">サイズの複素テンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a4b4474f9674a58aa04ea930d85c7a5dc2c0abdc" translate="yes" xml:space="preserve">
          <source>Returns entropy of distribution, batched over batch_shape.</source>
          <target state="translated">分布のエントロピーを返します。</target>
        </trans-unit>
        <trans-unit id="dfc3ffdf3e62461b544a4b95b691f57d57a7486b" translate="yes" xml:space="preserve">
          <source>Returns list CUDA architectures this library was compiled for.</source>
          <target state="translated">このライブラリがコンパイルされた CUDA アーキテクチャの一覧を返します。</target>
        </trans-unit>
        <trans-unit id="efcc116701cc62cfdac8737d78b2800ae566068b" translate="yes" xml:space="preserve">
          <source>Returns perplexity of distribution, batched over batch_shape.</source>
          <target state="translated">分布の複雑さを返します。</target>
        </trans-unit>
        <trans-unit id="bdbba2c4c769cf86fe1ade7dbe8c1a8c12ab8f3b" translate="yes" xml:space="preserve">
          <source>Returns scaled outputs. If this instance of &lt;a href=&quot;#torch.cuda.amp.GradScaler&quot;&gt;&lt;code&gt;GradScaler&lt;/code&gt;&lt;/a&gt; is not enabled, outputs are returned unmodified.</source>
          <target state="translated">スケーリングされた出力を返します。&lt;a href=&quot;#torch.cuda.amp.GradScaler&quot;&gt; &lt;code&gt;GradScaler&lt;/code&gt; の&lt;/a&gt;このインスタンスが有効になっていない場合、出力は変更されずに返されます。</target>
        </trans-unit>
        <trans-unit id="468f8e57e6feeaa4ca9cfb85917c23990eabfb8c" translate="yes" xml:space="preserve">
          <source>Returns tensor containing all values supported by a discrete distribution. The result will enumerate over dimension 0, so the shape of the result will be &lt;code&gt;(cardinality,) + batch_shape + event_shape&lt;/code&gt; (where &lt;code&gt;event_shape = ()&lt;/code&gt; for univariate distributions).</source>
          <target state="translated">離散分布でサポートされているすべての値を含むテンソルを返します。結果は次元0で列挙されるため、結果の形状は &lt;code&gt;(cardinality,) + batch_shape + event_shape&lt;/code&gt; （ここで、単変量分布の場合は &lt;code&gt;event_shape = ()&lt;/code&gt; ）になります。</target>
        </trans-unit>
        <trans-unit id="d89b2ba3d69dbf0c5536d8dba9d4a8221b96833a" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; that would result from performing an arithmetic operation on the provided input tensors. See type promotion &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;documentation&lt;/a&gt; for more information on the type promotion logic.</source>
          <target state="translated">指定された入力テンソルで算術演算を実行した結果の&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;を返します。タイププロモーションロジックの詳細については、タイププロモーションの&lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;ドキュメント&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="3a64cb8b4d560048c2d03eaad56133c0e7564a88" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; with the smallest size and scalar kind that is not smaller nor of lower kind than either &lt;code&gt;type1&lt;/code&gt; or &lt;code&gt;type2&lt;/code&gt;. See type promotion &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;documentation&lt;/a&gt; for more information on the type promotion logic.</source>
          <target state="translated">最小サイズでスカラーの種類が &lt;code&gt;type1&lt;/code&gt; または &lt;code&gt;type2&lt;/code&gt; よりも小さくも低くもない&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;を返します。タイププロモーションロジックの詳細については、タイププロモーションの&lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;ドキュメント&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="615a0842a40834e6013343600f3be5a6a5475da4" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; that would result from performing an arithmetic operation on the provided input tensors.</source>
          <target state="translated">指定された入力テンソルで算術演算を実行した結果の&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;を返します。</target>
        </trans-unit>
        <trans-unit id="6d1fdb76adea0e220c4916182503a08888092e2a" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; with the smallest size and scalar kind that is not smaller nor of lower kind than either &lt;code&gt;type1&lt;/code&gt; or &lt;code&gt;type2&lt;/code&gt;.</source>
          <target state="translated">最小サイズでスカラーの種類が &lt;code&gt;type1&lt;/code&gt; または &lt;code&gt;type2&lt;/code&gt; よりも小さくも低くもない&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;を返します。</target>
        </trans-unit>
        <trans-unit id="bf82a1ecc16fe682cb2b7f0a986e6561051951df" translate="yes" xml:space="preserve">
          <source>Returns the &lt;code&gt;k&lt;/code&gt; largest elements of the given &lt;code&gt;input&lt;/code&gt; tensor along a given dimension.</source>
          <target state="translated">指定された次元に沿った指定された &lt;code&gt;input&lt;/code&gt; テンソルの &lt;code&gt;k&lt;/code&gt; 個の最大要素を返します。</target>
        </trans-unit>
        <trans-unit id="8bed4d210c184a7836660a5c8e790f223aef9984" translate="yes" xml:space="preserve">
          <source>Returns the Generator state as a &lt;code&gt;torch.ByteTensor&lt;/code&gt;.</source>
          <target state="translated">ジェネレータの状態を &lt;code&gt;torch.ByteTensor&lt;/code&gt; として返します。</target>
        </trans-unit>
        <trans-unit id="b326f89b0009d9a68d7ef03ea15be0ad2d1ff47f" translate="yes" xml:space="preserve">
          <source>Returns the LU solve of the linear system</source>
          <target state="translated">線形システムのLU解を返します。</target>
        </trans-unit>
        <trans-unit id="f7e41a542d6bed1cb096c1ed65295fbd9d0b0caa" translate="yes" xml:space="preserve">
          <source>Returns the address of the first element of &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの最初の要素のアドレスを返します。</target>
        </trans-unit>
        <trans-unit id="2dcc3de7b8c8581e1cdbe092b04332f6662ee7fa" translate="yes" xml:space="preserve">
          <source>Returns the backend of the given process group.</source>
          <target state="translated">指定したプロセスグループのバックエンドを返します。</target>
        </trans-unit>
        <trans-unit id="0ff2118aeefe8e264108f6bd90694f18e03d42e7" translate="yes" xml:space="preserve">
          <source>Returns the cross product of vectors in dimension &lt;code&gt;dim&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;other&lt;/code&gt; 次元 &lt;code&gt;dim&lt;/code&gt; のベクトルの外積を返します。</target>
        </trans-unit>
        <trans-unit id="ac3e83f04f1e5b5b04b0171c84cf8b30b1da0e51" translate="yes" xml:space="preserve">
          <source>Returns the cumulative density/mass function evaluated at &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">で評価された累積密度/質量関数戻り &lt;code&gt;value&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3ea80ae8957ba72ac8ddc6e085e6f544e8ae8c05" translate="yes" xml:space="preserve">
          <source>Returns the cumulative product of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; 要素の累積積を返します。</target>
        </trans-unit>
        <trans-unit id="672aa95c90df23603089d78e5a986ac0c7ee6f37" translate="yes" xml:space="preserve">
          <source>Returns the cumulative sum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; 要素の累積合計を返します。</target>
        </trans-unit>
        <trans-unit id="543b4e544f696735e42e91a48b1a05b0d0275c5e" translate="yes" xml:space="preserve">
          <source>Returns the current GPU memory managed by the caching allocator in bytes for a given device.</source>
          <target state="translated">指定されたデバイスのキャッシングアロケータによって管理されている現在の GPU メモリをバイト単位で返します。</target>
        </trans-unit>
        <trans-unit id="353af166fcd46553479e01ad58f7b83a7e79e6b9" translate="yes" xml:space="preserve">
          <source>Returns the current GPU memory occupied by tensors in bytes for a given device.</source>
          <target state="translated">指定されたデバイスのテンソルが占有する現在の GPU メモリをバイト単位で返します。</target>
        </trans-unit>
        <trans-unit id="96ed2eb11bac807a9796664f42b21924320e0776" translate="yes" xml:space="preserve">
          <source>Returns the current random seed of the current GPU.</source>
          <target state="translated">現在のGPUの現在のランダムシードを返します。</target>
        </trans-unit>
        <trans-unit id="e5e450695734676a7d659d903827db864e4c16d8" translate="yes" xml:space="preserve">
          <source>Returns the current strategy for sharing CPU tensors.</source>
          <target state="translated">CPUテンソルを共有するための現在の戦略を返します。</target>
        </trans-unit>
        <trans-unit id="67bc3c1de929ca35a480af3381de6be2f62d0bd8" translate="yes" xml:space="preserve">
          <source>Returns the currently selected &lt;a href=&quot;#torch.cuda.Stream&quot;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; for a given device.</source>
          <target state="translated">指定されたデバイスに対して現在選択されている&lt;a href=&quot;#torch.cuda.Stream&quot;&gt; &lt;code&gt;Stream&lt;/code&gt; &lt;/a&gt;を返します。</target>
        </trans-unit>
        <trans-unit id="214e82956aaf7597b71c309353db304a3f55c7e8" translate="yes" xml:space="preserve">
          <source>Returns the default &lt;a href=&quot;#torch.cuda.Stream&quot;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; for a given device.</source>
          <target state="translated">指定されたデバイスのデフォルトの&lt;a href=&quot;#torch.cuda.Stream&quot;&gt; &lt;code&gt;Stream&lt;/code&gt; &lt;/a&gt;を返します。</target>
        </trans-unit>
        <trans-unit id="59028083782bdbe4c0f1ae0141a2a0d44a986b01" translate="yes" xml:space="preserve">
          <source>Returns the index of a currently selected device.</source>
          <target state="translated">現在選択されているデバイスのインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="711b80d2744d16d4fcb6dea10d90a382b486d415" translate="yes" xml:space="preserve">
          <source>Returns the indices of the buckets to which each value in the &lt;code&gt;input&lt;/code&gt; belongs, where the boundaries of the buckets are set by &lt;code&gt;boundaries&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各値が属するバケットのインデックスを返します。バケットの境界は &lt;code&gt;boundaries&lt;/code&gt; によって設定されます。</target>
        </trans-unit>
        <trans-unit id="8f4a40b7b47151439ff4a946635582981d1e9915" translate="yes" xml:space="preserve">
          <source>Returns the indices of the buckets to which each value in the &lt;code&gt;input&lt;/code&gt; belongs, where the boundaries of the buckets are set by &lt;code&gt;boundaries&lt;/code&gt;. Return a new tensor with the same size as &lt;code&gt;input&lt;/code&gt;. If &lt;code&gt;right&lt;/code&gt; is False (default), then the left boundary is closed. More formally, the returned index satisfies the following rules:</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 各値が属するバケットのインデックスを返します。バケットの境界は &lt;code&gt;boundaries&lt;/code&gt; によって設定されます。 &lt;code&gt;input&lt;/code&gt; と同じサイズの新しいテンソルを返します。場合は &lt;code&gt;right&lt;/code&gt; False（デフォルト）の場合、左の境界が閉じられています。より正式には、返されるインデックスは次のルールを満たします。</target>
        </trans-unit>
        <trans-unit id="8e89c9544d1eb7458a38f74393c854c8ecda06cb" translate="yes" xml:space="preserve">
          <source>Returns the indices of the lower triangular part of a &lt;code&gt;row&lt;/code&gt;-by- &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</source>
          <target state="translated">戻りの下三角部分のインデックス &lt;code&gt;row&lt;/code&gt; 行列 &lt;code&gt;col&lt;/code&gt; 最初の行は、すべてのインデックスと第二行は列座標を含むの行座標を含む2行Nテンソルでマトリックス。</target>
        </trans-unit>
        <trans-unit id="2a481df57e472778d81eb9d047f3b776a831dacb" translate="yes" xml:space="preserve">
          <source>Returns the indices of the lower triangular part of a &lt;code&gt;row&lt;/code&gt;-by- &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates. Indices are ordered based on rows and then columns.</source>
          <target state="translated">戻りの下三角部分のインデックス &lt;code&gt;row&lt;/code&gt; 行列 &lt;code&gt;col&lt;/code&gt; 最初の行は、すべてのインデックスと第二行は列座標を含むの行座標を含む2行Nテンソルでマトリックス。インデックスは、行、次に列に基づいて順序付けられます。</target>
        </trans-unit>
        <trans-unit id="36d1fcc471f42fd072f6a49d3437bd2fb723f49b" translate="yes" xml:space="preserve">
          <source>Returns the indices of the maximum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の最大値のインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="27e8f13c991f81ab6eaf5ea019cec0319d74f97f" translate="yes" xml:space="preserve">
          <source>Returns the indices of the maximum values of a tensor across a dimension.</source>
          <target state="translated">次元にわたるテンソルの最大値のインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="02a6d25f17c18c20395b7dbfe38496f775ac3649" translate="yes" xml:space="preserve">
          <source>Returns the indices of the minimum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の最小値のインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="c7c9c6f3bffff8c19d01d21b7330abaf2fed0de4" translate="yes" xml:space="preserve">
          <source>Returns the indices of the minimum values of a tensor across a dimension.</source>
          <target state="translated">次元にわたるテンソルの最小値のインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="6112a2a2de721ce77e0fbceb09a5d99e7c8b1b09" translate="yes" xml:space="preserve">
          <source>Returns the indices of the upper triangular part of a &lt;code&gt;row&lt;/code&gt; by &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</source>
          <target state="translated">上三角部分の指標を返し &lt;code&gt;row&lt;/code&gt; によって &lt;code&gt;col&lt;/code&gt; 最初の行は、すべてのインデックスの行座標を含み、第二行は列座標を含む2行Nテンソルでマトリックス。</target>
        </trans-unit>
        <trans-unit id="0c610a94f21c0e29b9389ef4636aaf00f7bcfcca" translate="yes" xml:space="preserve">
          <source>Returns the indices of the upper triangular part of a &lt;code&gt;row&lt;/code&gt; by &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates. Indices are ordered based on rows and then columns.</source>
          <target state="translated">上三角部分の指標を返し &lt;code&gt;row&lt;/code&gt; によって &lt;code&gt;col&lt;/code&gt; 最初の行は、すべてのインデックスの行座標を含み、第二行は列座標を含む2行Nテンソルでマトリックス。インデックスは、行、次に列に基づいて順序付けられます。</target>
        </trans-unit>
        <trans-unit id="c38cd5cab4c0cbb6855ee937ca43e344a716d2eb" translate="yes" xml:space="preserve">
          <source>Returns the indices that sort a tensor along a given dimension in ascending order by value.</source>
          <target state="translated">テンソルを指定された次元に沿って値の昇順に並べ替えるインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="12d3b5fef61c4a9ef299d2984d5e7f942e44587a" translate="yes" xml:space="preserve">
          <source>Returns the information about the current &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; iterator worker process.</source>
          <target state="translated">現在の&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;イテレータワーカープロセスに関する情報を返します。</target>
        </trans-unit>
        <trans-unit id="528f25a31d271ea8c283f1c3f903d83097bb316f" translate="yes" xml:space="preserve">
          <source>Returns the initial seed for generating random numbers as a Python &lt;code&gt;long&lt;/code&gt;.</source>
          <target state="translated">Pythonのように乱数を生成するための初期シードを返し &lt;code&gt;long&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b3583d38607467b25587c688245c573295c38448" translate="yes" xml:space="preserve">
          <source>Returns the initial seed for generating random numbers.</source>
          <target state="translated">乱数を生成するための初期シードを返します。</target>
        </trans-unit>
        <trans-unit id="d3aa84ac404b56cbb6665579407061f3f1829f6d" translate="yes" xml:space="preserve">
          <source>Returns the inverse &lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt;&lt;code&gt;Transform&lt;/code&gt;&lt;/a&gt; of this transform. This should satisfy &lt;code&gt;t.inv.inv is t&lt;/code&gt;.</source>
          <target state="translated">この変換の逆&lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt; &lt;code&gt;Transform&lt;/code&gt; &lt;/a&gt;を返します。これは、 &lt;code&gt;t.inv.inv is t&lt;/code&gt; を満たす必要があります。</target>
        </trans-unit>
        <trans-unit id="c1aef1f541873f46619d10b39465c4cebb0a9884" translate="yes" xml:space="preserve">
          <source>Returns the inverse cumulative density/mass function evaluated at &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">戻り値で評価逆累積密度/質量関数 &lt;code&gt;value&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f756dfcdc4b88f47cc8afe02c13bb828b05c63e7" translate="yes" xml:space="preserve">
          <source>Returns the log of summed exponentials of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の合計指数の対数を返します。</target>
        </trans-unit>
        <trans-unit id="b6389ff7f37373c9ca57e71fc477f0c668bda055" translate="yes" xml:space="preserve">
          <source>Returns the log of summed exponentials of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. The computation is numerically stabilized.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の合計指数の対数を返します。計算は数値的に安定しています。</target>
        </trans-unit>
        <trans-unit id="cf79c17bd23741493f06836ca1da65ec3e27f2d9" translate="yes" xml:space="preserve">
          <source>Returns the log of the probability density/mass function evaluated at &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">で評価確率密度/質量関数のログ返し &lt;code&gt;value&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d7b57cf20e91ac970ff715302367553ab5d606f0" translate="yes" xml:space="preserve">
          <source>Returns the logarithm of the cumulative summation of the exponentiation of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; 要素のべき乗の累積合計の対数を返します。</target>
        </trans-unit>
        <trans-unit id="ece733a42c60a3b1bb785f7b96e5ca90ed6c9354" translate="yes" xml:space="preserve">
          <source>Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices &lt;code&gt;input&lt;/code&gt;, the other elements of the result tensor &lt;code&gt;out&lt;/code&gt; are set to 0.</source>
          <target state="translated">行列の下三角部分（2次元テンソル）または行列 &lt;code&gt;input&lt;/code&gt; バッチを返します。結果のテンソル &lt;code&gt;out&lt;/code&gt; 他の要素は0に設定されます。</target>
        </trans-unit>
        <trans-unit id="903bb5ad470677dd96718bed7dd424b4eea58c19" translate="yes" xml:space="preserve">
          <source>Returns the matrix exponential. Supports batched input. For a matrix &lt;code&gt;A&lt;/code&gt;, the matrix exponential is defined as</source>
          <target state="translated">行列指数を返します。バッチ入力をサポートします。行列 &lt;code&gt;A&lt;/code&gt; の場合、行列指数は次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="57632c5d6ea2c48ab4c7ad8c0de751aa58bc8ad6" translate="yes" xml:space="preserve">
          <source>Returns the matrix norm or vector norm of a given tensor.</source>
          <target state="translated">与えられたテンソルの行列ノルムまたはベクトルノルムを返します。</target>
        </trans-unit>
        <trans-unit id="aa8212443e4c775af178e39c5b9d95062b7f280a" translate="yes" xml:space="preserve">
          <source>Returns the matrix product of the</source>
          <target state="translated">の行列積を返します。</target>
        </trans-unit>
        <trans-unit id="2056ceddf487b6aeac66141f77f1593dd5d51a33" translate="yes" xml:space="preserve">
          <source>Returns the matrix raised to the power &lt;code&gt;n&lt;/code&gt; for square matrices.</source>
          <target state="translated">正方行列の &lt;code&gt;n&lt;/code&gt; 乗した行列を返します。</target>
        </trans-unit>
        <trans-unit id="7a715df6cd530cefa49cad9ca42363f5dcc48be7" translate="yes" xml:space="preserve">
          <source>Returns the matrix raised to the power &lt;code&gt;n&lt;/code&gt; for square matrices. For batch of matrices, each individual matrix is raised to the power &lt;code&gt;n&lt;/code&gt;.</source>
          <target state="translated">正方行列の &lt;code&gt;n&lt;/code&gt; 乗した行列を返します。行列のバッチの場合、個々の行列はそれぞれ &lt;code&gt;n&lt;/code&gt; 乗されます。</target>
        </trans-unit>
        <trans-unit id="03824d09bb5c54243f197f9c9ba3e110276ea20d" translate="yes" xml:space="preserve">
          <source>Returns the maximum GPU memory managed by the caching allocator in bytes for a given device.</source>
          <target state="translated">指定されたデバイスのキャッシングアロケータが管理する最大 GPU メモリをバイト単位で返します。</target>
        </trans-unit>
        <trans-unit id="0caf8ade3d9c0d603d539d45bc8b1a8d76a7591a" translate="yes" xml:space="preserve">
          <source>Returns the maximum GPU memory occupied by tensors in bytes for a given device.</source>
          <target state="translated">指定されたデバイスのテンソルが占有するGPUメモリの最大値をバイト単位で返します。</target>
        </trans-unit>
        <trans-unit id="2592d5f82bbbc822a97e96b68b786a9c78bb926c" translate="yes" xml:space="preserve">
          <source>Returns the maximum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の最大値を返します。</target>
        </trans-unit>
        <trans-unit id="fa13bd7559d027b3477eb7ddbb196e1171a0bca9" translate="yes" xml:space="preserve">
          <source>Returns the maximum value of each slice of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension(s) &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各スライスの最大値を返します。</target>
        </trans-unit>
        <trans-unit id="bca8e17597f7810508efae907eae755779bfdb1a" translate="yes" xml:space="preserve">
          <source>Returns the mean of the distribution.</source>
          <target state="translated">分布の平均を返します。</target>
        </trans-unit>
        <trans-unit id="809ee94cff5a85854481052825bc00d99efb4eb6" translate="yes" xml:space="preserve">
          <source>Returns the mean value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の平均値を返します。</target>
        </trans-unit>
        <trans-unit id="b95b8ed42b947df36f019475ad19d862230385ee" translate="yes" xml:space="preserve">
          <source>Returns the mean value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の平均値を返します。 &lt;code&gt;dim&lt;/code&gt; が次元のリストである場合は、それらすべてを減らします。</target>
        </trans-unit>
        <trans-unit id="f2abf9fb9cf56489f6a00a784d4d458d7895d090" translate="yes" xml:space="preserve">
          <source>Returns the median value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の中央値を返します。</target>
        </trans-unit>
        <trans-unit id="8878f4d09befec1d421d046a625ff001883087d7" translate="yes" xml:space="preserve">
          <source>Returns the minimum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の最小値を返します。</target>
        </trans-unit>
        <trans-unit id="0a0cee886c48025d366605a4d62185c2c9000596" translate="yes" xml:space="preserve">
          <source>Returns the minimum value of each slice of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension(s) &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各スライスの最小値を返します。</target>
        </trans-unit>
        <trans-unit id="1b3e9ec11a895a649216c83f8ca9adf589921f7c" translate="yes" xml:space="preserve">
          <source>Returns the number of GPUs available.</source>
          <target state="translated">利用可能なGPUの数を返します。</target>
        </trans-unit>
        <trans-unit id="fd09e78e1b1393b57b6e81bd22e6b7089ac87df8" translate="yes" xml:space="preserve">
          <source>Returns the number of dimensions of &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの次元数を返します。</target>
        </trans-unit>
        <trans-unit id="074c1198678efc321484286e167225dc00032bc7" translate="yes" xml:space="preserve">
          <source>Returns the number of keys set in the store. Note that this number will typically be one greater than the number of keys added by &lt;code&gt;set()&lt;/code&gt; and &lt;code&gt;add()&lt;/code&gt; since one key is used to coordinate all the workers using the store.</source>
          <target state="translated">ストアに設定されているキーの数を返します。ストアを使用するすべてのワーカーを調整するために1つのキーが使用されるため、この数は通常、 &lt;code&gt;set()&lt;/code&gt; および &lt;code&gt;add()&lt;/code&gt; によって追加されるキーの数よりも1つ大きいことに注意してください。</target>
        </trans-unit>
        <trans-unit id="77a1f23eab350f2cc1dff14c648c4ff6203e6c58" translate="yes" xml:space="preserve">
          <source>Returns the number of processes in the current process group</source>
          <target state="translated">現在のプロセスグループ内のプロセス数を返します</target>
        </trans-unit>
        <trans-unit id="c6ca89b8a3b13965452fa2d1cea6ac87f72d7a23" translate="yes" xml:space="preserve">
          <source>Returns the number of threads used for inter-op parallelism on CPU (e.g.</source>
          <target state="translated">CPU上でのホップ間並列処理に使用されているスレッド数を返します(例)</target>
        </trans-unit>
        <trans-unit id="d8b5e8f68adc8148c1f9e13acbeae8fd51bfefc0" translate="yes" xml:space="preserve">
          <source>Returns the number of threads used for inter-op parallelism on CPU (e.g. in JIT interpreter)</source>
          <target state="translated">CPU上での相互ホップ並列化に使用されているスレッド数を返します(JITインタープリタなど)。</target>
        </trans-unit>
        <trans-unit id="7c423a746fa97a8c78c6c6a0bea67a7ee6cacc04" translate="yes" xml:space="preserve">
          <source>Returns the number of threads used for parallelizing CPU operations</source>
          <target state="translated">CPU操作の並列化に使用するスレッド数を返します。</target>
        </trans-unit>
        <trans-unit id="76a9d76393683122be08a7059b22ee9487de8af7" translate="yes" xml:space="preserve">
          <source>Returns the numerical rank of a 2-D tensor.</source>
          <target state="translated">2次元テンソルの数値ランクを返します。</target>
        </trans-unit>
        <trans-unit id="915a8c083943d2bf3a4491860c8c37370cb6d81a" translate="yes" xml:space="preserve">
          <source>Returns the numerical rank of a 2-D tensor. The method to compute the matrix rank is done using SVD by default. If &lt;code&gt;symmetric&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then &lt;code&gt;input&lt;/code&gt; is assumed to be symmetric, and the computation of the rank is done by obtaining the eigenvalues.</source>
          <target state="translated">2次元テンソルの数値ランクを返します。行列のランクを計算する方法は、デフォルトでSVDを使用して行われます。場合 &lt;code&gt;symmetric&lt;/code&gt; ある &lt;code&gt;True&lt;/code&gt; 、その後、 &lt;code&gt;input&lt;/code&gt; 対称であると仮定され、ランクの計算は、固有値を求めることにより行われます。</target>
        </trans-unit>
        <trans-unit id="b9021b2a01727f502181983387c837330544dbe0" translate="yes" xml:space="preserve">
          <source>Returns the p-norm of (&lt;code&gt;input&lt;/code&gt; - &lt;code&gt;other&lt;/code&gt;)</source>
          <target state="translated">（ &lt;code&gt;input&lt;/code&gt; - &lt;code&gt;other&lt;/code&gt; ）のpノルムを返します</target>
        </trans-unit>
        <trans-unit id="0db967e67efe6e63a87c0ce474cb74d7038305af" translate="yes" xml:space="preserve">
          <source>Returns the product of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の積を返します。</target>
        </trans-unit>
        <trans-unit id="a7140a19943936f9d48bbfc1f4b6d873ec50ed19" translate="yes" xml:space="preserve">
          <source>Returns the product of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の積を返します。</target>
        </trans-unit>
        <trans-unit id="971be3e3aa0bf4f890c81c3791eba6b84f38ff83" translate="yes" xml:space="preserve">
          <source>Returns the q-th quantiles of all elements in the &lt;code&gt;input&lt;/code&gt; tensor, doing a linear interpolation when the q-th quantile lies between two data points.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソル内のすべての要素のq番目の分位数を返し、q番目の分位数が2つのデータポイントの間にあるときに線形補間を実行します。</target>
        </trans-unit>
        <trans-unit id="1aa60514b18ba933ebc0d3b97778472f133a31e9" translate="yes" xml:space="preserve">
          <source>Returns the q-th quantiles of each row of the &lt;code&gt;input&lt;/code&gt; tensor along the dimension &lt;code&gt;dim&lt;/code&gt;, doing a linear interpolation when the q-th quantile lies between two data points. By default, &lt;code&gt;dim&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; resulting in the &lt;code&gt;input&lt;/code&gt; tensor being flattened before computation.</source>
          <target state="translated">次元 &lt;code&gt;dim&lt;/code&gt; に沿った &lt;code&gt;input&lt;/code&gt; テンソルの各行のq番目の分位数を返し、q番目の分位数が2つのデータポイントの間にあるときに線形補間を実行します。デフォルトでは、 &lt;code&gt;dim&lt;/code&gt; は &lt;code&gt;None&lt;/code&gt; であり、計算前に &lt;code&gt;input&lt;/code&gt; テンソルがフラット化されます。</target>
        </trans-unit>
        <trans-unit id="855eae4c3b5ff9439f790aa02a1e5edcb2f9666b" translate="yes" xml:space="preserve">
          <source>Returns the quantization scheme of a given QTensor.</source>
          <target state="translated">与えられたQTensorの量子化スキームを返します。</target>
        </trans-unit>
        <trans-unit id="7d9c1cd994cab4ee1d9aadcaf26ce62a26fd9235" translate="yes" xml:space="preserve">
          <source>Returns the random number generator state as a &lt;code&gt;torch.ByteTensor&lt;/code&gt;.</source>
          <target state="translated">乱数ジェネレーターの状態を &lt;code&gt;torch.ByteTensor&lt;/code&gt; として返します。</target>
        </trans-unit>
        <trans-unit id="5e5816534688f7e46f4af65ebc7314df9d504c09" translate="yes" xml:space="preserve">
          <source>Returns the random number generator state of the specified GPU as a ByteTensor.</source>
          <target state="translated">指定されたGPUの乱数発生器の状態をByteTensorとして返す。</target>
        </trans-unit>
        <trans-unit id="627a3c7f5879a8778db877ff3b00bbcfbf03056f" translate="yes" xml:space="preserve">
          <source>Returns the rank of current process group</source>
          <target state="translated">現在のプロセスグループのランクを返します</target>
        </trans-unit>
        <trans-unit id="4525ac2f89a3ac5d0c306f28833d2a44e3540a50" translate="yes" xml:space="preserve">
          <source>Returns the real and the imaginary parts together as one tensor of the same shape of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">実数部と虚数部を同じ形状の &lt;code&gt;input&lt;/code&gt; 1つのテンソルとして一緒に返します。</target>
        </trans-unit>
        <trans-unit id="7e3148edb8aa985705a099b8ae7ab9879b62393f" translate="yes" xml:space="preserve">
          <source>Returns the result of running &lt;code&gt;func&lt;/code&gt; with &lt;code&gt;args&lt;/code&gt; and &lt;code&gt;kwargs&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;args&lt;/code&gt; と &lt;code&gt;kwargs&lt;/code&gt; を使用して &lt;code&gt;func&lt;/code&gt; を実行した結果を返します。</target>
        </trans-unit>
        <trans-unit id="64531174d404b10b93897ed2b88aba389572d7db" translate="yes" xml:space="preserve">
          <source>Returns the return value of &lt;code&gt;optimizer.step(*args, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;optimizer.step(*args, **kwargs)&lt;/code&gt; の戻り値を返します。</target>
        </trans-unit>
        <trans-unit id="6acc79cd313eeed62eea5f7e0ca05acecdcbc531" translate="yes" xml:space="preserve">
          <source>Returns the shape of a single sample (without batching).</source>
          <target state="translated">単一サンプルの形状を返します(バッチングなし)。</target>
        </trans-unit>
        <trans-unit id="4121b94d8bee0076d793dcc54679dd64a1c94a20" translate="yes" xml:space="preserve">
          <source>Returns the shape over which parameters are batched.</source>
          <target state="translated">パラメータがバッチ化された形状を返します。</target>
        </trans-unit>
        <trans-unit id="e4dd6ff47ca4bddd8efc777b8ef0c3a2c983568d" translate="yes" xml:space="preserve">
          <source>Returns the sign of the determinant of the Jacobian, if applicable. In general this only makes sense for bijective transforms.</source>
          <target state="translated">該当する場合は、ヤコビアンの行列式の符号を返します。一般に、これは両射形変換に対してのみ意味を持ちます。</target>
        </trans-unit>
        <trans-unit id="7d3d453cc3ee6cad8567bb601546cc4fa1aa1364" translate="yes" xml:space="preserve">
          <source>Returns the size in bytes of an individual element.</source>
          <target state="translated">個々の要素のサイズをバイト単位で返します。</target>
        </trans-unit>
        <trans-unit id="38820622e4a658519544ad686f76dee59368c29c" translate="yes" xml:space="preserve">
          <source>Returns the size of the &lt;code&gt;self&lt;/code&gt; tensor. The returned value is a subclass of &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;&lt;code&gt;tuple&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルのサイズを返します。戻り値は&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt; &lt;code&gt;tuple&lt;/code&gt; &lt;/a&gt;サブクラスです。</target>
        </trans-unit>
        <trans-unit id="11ff079b4e3d88cd650436812653217a81a77a46" translate="yes" xml:space="preserve">
          <source>Returns the standard deviation of the distribution.</source>
          <target state="translated">分布の標準偏差を返します。</target>
        </trans-unit>
        <trans-unit id="159dfd0ce2a90b4d47c871e593a62731a632dc99" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation and mean of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の標準偏差と平均を返します。</target>
        </trans-unit>
        <trans-unit id="b541928a3e9600b386da860747f66bb8139c4d0a" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation and mean of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="translated">次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の標準偏差と平均を返します。 &lt;code&gt;dim&lt;/code&gt; が次元のリストである場合は、それらすべてを減らします。</target>
        </trans-unit>
        <trans-unit id="8bbd91280991e2a9737689547bbddca952d63287" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の標準偏差を返します。</target>
        </trans-unit>
        <trans-unit id="e297a06301ae289868c8331b63443bb83703e3b8" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="translated">次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の標準偏差を返します。 &lt;code&gt;dim&lt;/code&gt; が次元のリストである場合は、それらすべてを減らします。</target>
        </trans-unit>
        <trans-unit id="8527f000d10d08462f55a7df699877bf3a2b4a09" translate="yes" xml:space="preserve">
          <source>Returns the state of the optimizer as a &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">オプティマイザの状態を&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt; &lt;code&gt;dict&lt;/code&gt; &lt;/a&gt;として返します。</target>
        </trans-unit>
        <trans-unit id="ddacfefa1e98c3901d53623a3db23fafb076c7fc" translate="yes" xml:space="preserve">
          <source>Returns the state of the scaler as a &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/a&gt;. It contains five entries:</source>
          <target state="translated">スケーラーの状態を&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt; &lt;code&gt;dict&lt;/code&gt; &lt;/a&gt;として返します。5つのエントリが含まれています。</target>
        </trans-unit>
        <trans-unit id="cbae1c6724a7b43e4ce8327e553e968ab36fa3db" translate="yes" xml:space="preserve">
          <source>Returns the state of the scheduler as a &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">スケジューラの状態を&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt; &lt;code&gt;dict&lt;/code&gt; &lt;/a&gt;として返します。</target>
        </trans-unit>
        <trans-unit id="1ebb6fa0d71baf28bcf461777f1c5e425a2744c2" translate="yes" xml:space="preserve">
          <source>Returns the stride of &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルのストライドを返します。</target>
        </trans-unit>
        <trans-unit id="b5f0fbc903ffee7b0004fd1f9bcd5996f44017b1" translate="yes" xml:space="preserve">
          <source>Returns the sum of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の合計を返します。</target>
        </trans-unit>
        <trans-unit id="1863758d4c0f9cfda8c72c22853117ba70ebdee5" translate="yes" xml:space="preserve">
          <source>Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.</source>
          <target state="translated">Not a Numbers (NaNs)をゼロとして、すべての要素の合計を返します。</target>
        </trans-unit>
        <trans-unit id="14e6166614886b7770d3ecf48dce1bfb59192744" translate="yes" xml:space="preserve">
          <source>Returns the sum of each row of SparseTensor &lt;code&gt;input&lt;/code&gt; in the given dimensions &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them. When sum over all &lt;code&gt;sparse_dim&lt;/code&gt;, this method returns a Tensor instead of SparseTensor.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; のSparseTensor &lt;code&gt;input&lt;/code&gt; 各行の合計を返します。 &lt;code&gt;dim&lt;/code&gt; が次元のリストである場合は、それらすべてを減らします。すべての &lt;code&gt;sparse_dim&lt;/code&gt; を合計すると、このメソッドはSparseTensorではなくTensorを返します。</target>
        </trans-unit>
        <trans-unit id="bf49e8cc86ca6a6600ce29a25884a785a376abc6" translate="yes" xml:space="preserve">
          <source>Returns the sum of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;, treating Not a Numbers (NaNs) as zero. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="translated">Not a Numbers（NaNs）をゼロとして扱い、指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の合計を返します。 &lt;code&gt;dim&lt;/code&gt; が次元のリストである場合は、それらすべてを減らします。</target>
        </trans-unit>
        <trans-unit id="4d434d5c1c4d2f8c246ee3548fb97e54d9889e29" translate="yes" xml:space="preserve">
          <source>Returns the sum of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の合計を返します。 &lt;code&gt;dim&lt;/code&gt; が次元のリストである場合は、それらすべてを減らします。</target>
        </trans-unit>
        <trans-unit id="28abb051bc478158b8e05bc1054f16151a20a7cb" translate="yes" xml:space="preserve">
          <source>Returns the sum of the elements of the diagonal of the input 2-D matrix.</source>
          <target state="translated">入力された2次元行列の対角線の要素の和を返します。</target>
        </trans-unit>
        <trans-unit id="628247234e04df2fd2dd0c458a3e5e95270ff4e1" translate="yes" xml:space="preserve">
          <source>Returns the tensor as a (nested) list. For scalars, a standard Python number is returned, just like with &lt;a href=&quot;#torch.Tensor.item&quot;&gt;&lt;code&gt;item()&lt;/code&gt;&lt;/a&gt;. Tensors are automatically moved to the CPU first if necessary.</source>
          <target state="translated">テンソルを（ネストされた）リストとして返します。スカラーの場合、&lt;a href=&quot;#torch.Tensor.item&quot;&gt; &lt;code&gt;item()&lt;/code&gt; の&lt;/a&gt;場合と同様に、標準のPython数値が返されます。テンソルは、必要に応じて最初に自動的にCPUに移動されます。</target>
        </trans-unit>
        <trans-unit id="035dc69af946dc6fb060b51cabe8b5996eafc4da" translate="yes" xml:space="preserve">
          <source>Returns the time elapsed in milliseconds after the event was recorded and before the end_event was recorded.</source>
          <target state="translated">イベントが記録されてから、end_eventが記録されるまでの経過時間をミリ秒単位で返します。</target>
        </trans-unit>
        <trans-unit id="94ea64072a9591f059633c957623237cd647f97a" translate="yes" xml:space="preserve">
          <source>Returns the total number of elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルの要素の総数を返します。</target>
        </trans-unit>
        <trans-unit id="1d3970a743c03ce9d28802ddc4f6588b09bb7c8b" translate="yes" xml:space="preserve">
          <source>Returns the type if &lt;code&gt;dtype&lt;/code&gt; is not provided, else casts this object to the specified type.</source>
          <target state="translated">&lt;code&gt;dtype&lt;/code&gt; が指定されていない場合は型を返し、そうでない場合はこのオブジェクトを指定された型にキャストします。</target>
        </trans-unit>
        <trans-unit id="2fea27b4bcbff9f0edb11c8bfcd39329450a9b92" translate="yes" xml:space="preserve">
          <source>Returns the type of the underlying storage.</source>
          <target state="translated">ベースとなるストレージの型を返します。</target>
        </trans-unit>
        <trans-unit id="4ac509092325d5bcdffb0cc3612c7cf497735d46" translate="yes" xml:space="preserve">
          <source>Returns the underlying storage.</source>
          <target state="translated">基底となるストレージを返します。</target>
        </trans-unit>
        <trans-unit id="32fcdf754b9cb5a228ef02efc503187163097afb" translate="yes" xml:space="preserve">
          <source>Returns the unique elements of the input tensor.</source>
          <target state="translated">入力テンソルの一意の要素を返します。</target>
        </trans-unit>
        <trans-unit id="26e4d829967fdd7e5612995ff5e9602634c0689a" translate="yes" xml:space="preserve">
          <source>Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices &lt;code&gt;input&lt;/code&gt;, the other elements of the result tensor &lt;code&gt;out&lt;/code&gt; are set to 0.</source>
          <target state="translated">行列（2次元テンソル）または行列 &lt;code&gt;input&lt;/code&gt; バッチの上三角部分を返します。結果のテンソル &lt;code&gt;out&lt;/code&gt; 他の要素は0に設定されます。</target>
        </trans-unit>
        <trans-unit id="f17ab21227456440a4bca3f2fb221dbfad6b68d3" translate="yes" xml:space="preserve">
          <source>Returns the value of this tensor as a standard Python number. This only works for tensors with one element. For other cases, see &lt;a href=&quot;#torch.Tensor.tolist&quot;&gt;&lt;code&gt;tolist()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">このテンソルの値を標準のPython数値として返します。これは、1つの要素を持つテンソルに対してのみ機能します。その他の場合については、&lt;a href=&quot;#torch.Tensor.tolist&quot;&gt; &lt;code&gt;tolist()&lt;/code&gt; を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="f1cc620c9c632e9d45f1d98e6550b6c3781efad4" translate="yes" xml:space="preserve">
          <source>Returns the variance and mean of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の分散と平均を返します。</target>
        </trans-unit>
        <trans-unit id="9ff1d1aa2591afcd14de03b53682da2b82cb9cc7" translate="yes" xml:space="preserve">
          <source>Returns the variance and mean of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の分散と平均を返します。</target>
        </trans-unit>
        <trans-unit id="af4e03a6f47c5a06e9dc95d8b7b0827b12d10bac" translate="yes" xml:space="preserve">
          <source>Returns the variance of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; テンソルのすべての要素の分散を返します。</target>
        </trans-unit>
        <trans-unit id="0298d938b904aa1e59745be5e3318e09914487aa" translate="yes" xml:space="preserve">
          <source>Returns the variance of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; の &lt;code&gt;input&lt;/code&gt; テンソルの各行の分散を返します。</target>
        </trans-unit>
        <trans-unit id="fdcaff1a07dc530f557ad4bcd05c34a11bb994e8" translate="yes" xml:space="preserve">
          <source>Returns the variance of the distribution.</source>
          <target state="translated">分布の分散を返します。</target>
        </trans-unit>
        <trans-unit id="88e4f4506a554a4b89da7d55d5cfa7515f220fb9" translate="yes" xml:space="preserve">
          <source>Returns the version of cuDNN</source>
          <target state="translated">cuDNNのバージョンを返します。</target>
        </trans-unit>
        <trans-unit id="9c3ac5c69999b0a023804bb506ededc917b6c131" translate="yes" xml:space="preserve">
          <source>Returns this tensor as the same shape as &lt;code&gt;other&lt;/code&gt;. &lt;code&gt;self.reshape_as(other)&lt;/code&gt; is equivalent to &lt;code&gt;self.reshape(other.sizes())&lt;/code&gt;. This method returns a view if &lt;code&gt;other.sizes()&lt;/code&gt; is compatible with the current shape. See &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;torch.Tensor.view()&lt;/code&gt;&lt;/a&gt; on when it is possible to return a view.</source>
          <target state="translated">このテンソルを &lt;code&gt;other&lt;/code&gt; テンソルと同じ形状として返します。 &lt;code&gt;self.reshape_as(other)&lt;/code&gt; は &lt;code&gt;self.reshape(other.sizes())&lt;/code&gt; と同等です。 &lt;code&gt;other.sizes()&lt;/code&gt; が現在の形状と互換性がある場合、このメソッドはビューを返します。ビューを返すことができる場合については、&lt;a href=&quot;#torch.Tensor.view&quot;&gt; &lt;code&gt;torch.Tensor.view()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="586000b57d8c3b25d201cf41023bcdd3dcb6f713" translate="yes" xml:space="preserve">
          <source>Returns this tensor cast to the type of the given tensor.</source>
          <target state="translated">与えられたテンソルの型にキャストされたテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="ba9ebe14b855b8e57d04a421d5dedae584879e50" translate="yes" xml:space="preserve">
          <source>Returns total time spent on CPU obtained as a sum of all self times across all the events.</source>
          <target state="translated">すべてのイベントにまたがるすべての自己時間の合計として得られた、CPUに費やされた時間の合計を返します。</target>
        </trans-unit>
        <trans-unit id="88c329059251d00815688b5e671bb43e44ab8c23" translate="yes" xml:space="preserve">
          <source>Returns true if &lt;code&gt;self.data&lt;/code&gt; stored on a gpu</source>
          <target state="translated">&lt;code&gt;self.data&lt;/code&gt; がGPUに保存されている場合はtrueを返します</target>
        </trans-unit>
        <trans-unit id="69352252bee0873e3fb0a65734cef7e6482fff70" translate="yes" xml:space="preserve">
          <source>Returns true if &lt;code&gt;self.data&lt;/code&gt; stored on in pinned memory</source>
          <target state="translated">固定されたメモリに &lt;code&gt;self.data&lt;/code&gt; が格納されている場合はtrueを返します</target>
        </trans-unit>
        <trans-unit id="373aeaf23062f8c5ecaff73e9be00cb54c4e37f3" translate="yes" xml:space="preserve">
          <source>Returns true if this tensor resides in pinned memory.</source>
          <target state="translated">このテンソルがピン留めされたメモリに存在する場合、trueを返します。</target>
        </trans-unit>
        <trans-unit id="c8e3480d7d70ecfc7b3c25ecaed7108c83b90b62" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with CUDA support. Note that this doesn&amp;rsquo;t necessarily mean CUDA is available; just that if this PyTorch binary were run a machine with working CUDA drivers and devices, we would be able to use it.</source>
          <target state="translated">PyTorchがCUDAサポートで構築されているかどうかを返します。これは必ずしもCUDAが利用可能であることを意味するわけではないことに注意してください。このPyTorchバイナリが、動作するCUDAドライバーとデバイスを備えたマシンで実行された場合、それを使用できるようになります。</target>
        </trans-unit>
        <trans-unit id="98fd0f653522d8480237ac570476e6435a37e06f" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with MKL support.</source>
          <target state="translated">PyTorch が MKL をサポートしてビルドされているかどうかを返します。</target>
        </trans-unit>
        <trans-unit id="620b15262eed97044ef3e21b5235ee100fef8185" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with MKL-DNN support.</source>
          <target state="translated">PyTorch が MKL-DNN サポートでビルドされているかどうかを返します。</target>
        </trans-unit>
        <trans-unit id="957ab7585c4317f19aa9cfbd05dcb5165584e9c9" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with OpenMP support.</source>
          <target state="translated">PyTorch が OpenMP をサポートしてビルドされているかどうかを返します。</target>
        </trans-unit>
        <trans-unit id="57fa332c1c053f80c3eff6f20003e44a174f7e50" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1</source>
          <target state="translated">PyTorch が _GLIBCXX_USE_CXX11_ABI=1 でビルドされているかどうかを返します。</target>
        </trans-unit>
        <trans-unit id="4f1dfa1c8e9678eac6dccc5f732ccd2cbc520cad" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch&amp;rsquo;s CUDA state has been initialized.</source>
          <target state="translated">PyTorchのCUDA状態が初期化されているかどうかを返します。</target>
        </trans-unit>
        <trans-unit id="770f265f08ee812cf8c52d62b5ca51586f3291bd" translate="yes" xml:space="preserve">
          <source>Returns whether or not the current node is the owner of this &lt;code&gt;RRef&lt;/code&gt;.</source>
          <target state="translated">現在のノードがこの &lt;code&gt;RRef&lt;/code&gt; の所有者であるかどうかを返します。</target>
        </trans-unit>
        <trans-unit id="65ba60da18a01009c75c582854b7076b39cbf39e" translate="yes" xml:space="preserve">
          <source>Returns whether this &lt;code&gt;RRef&lt;/code&gt; has been confirmed by the owner. &lt;code&gt;OwnerRRef&lt;/code&gt; always returns true, while &lt;code&gt;UserRRef&lt;/code&gt; only returns true when the owner knowns about this &lt;code&gt;UserRRef&lt;/code&gt;.</source>
          <target state="translated">この &lt;code&gt;RRef&lt;/code&gt; が所有者によって確認されているかどうかを返します。 &lt;code&gt;OwnerRRef&lt;/code&gt; は常にtrueを返しますが、 &lt;code&gt;UserRRef&lt;/code&gt; は、所有者がこの &lt;code&gt;UserRRef&lt;/code&gt; について知っている場合にのみtrueを返します。</target>
        </trans-unit>
        <trans-unit id="a0f5e59205b44dcceb0ac6759e21e032f1501bc8" translate="yes" xml:space="preserve">
          <source>Returns worker information of the node that owns this &lt;code&gt;RRef&lt;/code&gt;.</source>
          <target state="translated">この &lt;code&gt;RRef&lt;/code&gt; を所有するノードのワーカー情報を返します。</target>
        </trans-unit>
        <trans-unit id="4edad2b2ca35229024c67f3f0d3bff7d93093b61" translate="yes" xml:space="preserve">
          <source>Returns worker name of the node that owns this &lt;code&gt;RRef&lt;/code&gt;.</source>
          <target state="translated">この &lt;code&gt;RRef&lt;/code&gt; を所有するノードのワーカー名を返します。</target>
        </trans-unit>
        <trans-unit id="7749fcf802c472b6c2f5bd0556805e456ffd5674" translate="yes" xml:space="preserve">
          <source>Returns:</source>
          <target state="translated">Returns:</target>
        </trans-unit>
        <trans-unit id="614439f097ad878a8635d81ef81858113ba66ffa" translate="yes" xml:space="preserve">
          <source>Returns: self</source>
          <target state="translated">戻り値:self</target>
        </trans-unit>
        <trans-unit id="63fbd9687bea5bf2237b15e3392da627d72bce65" translate="yes" xml:space="preserve">
          <source>Reverse the order of a n-D tensor along given axis in dims.</source>
          <target state="translated">与えられた軸に沿ったn-Dテンソルの次数をdimsで反転させます。</target>
        </trans-unit>
        <trans-unit id="7787cde8d62a04058bf7bd3bc0e17bb68ebcb122" translate="yes" xml:space="preserve">
          <source>Right now all parameters have to be on a single device. This will be improved in the future.</source>
          <target state="translated">現在、すべてのパラメータは単一のデバイス上になければなりません。これは将来的に改善される予定です。</target>
        </trans-unit>
        <trans-unit id="c79c0386989b48b4178b173f296df3e3c68180f2" translate="yes" xml:space="preserve">
          <source>Right now, this works only if the module is on the GPU and cuDNN is enabled. Otherwise, it&amp;rsquo;s a no-op.</source>
          <target state="translated">現在、これはモジュールがGPU上にあり、cuDNNが有効になっている場合にのみ機能します。それ以外の場合は、何もしません。</target>
        </trans-unit>
        <trans-unit id="bf85deb85c247cf504b5145a433d00570a94475a" translate="yes" xml:space="preserve">
          <source>Roll the tensor along the given dimension(s).</source>
          <target state="translated">テンソルを与えられた次元に沿って転がす。</target>
        </trans-unit>
        <trans-unit id="61764ff63ec4f189d73879d14b23769ece78814a" translate="yes" xml:space="preserve">
          <source>Roll the tensor along the given dimension(s). Elements that are shifted beyond the last position are re-introduced at the first position. If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.</source>
          <target state="translated">与えられた次元に沿ってテンソルを転がす.最後の位置からずれた要素は最初の位置に再導入されます。寸法が指定されていない場合、テンソルはロールする前に平坦化され、元の形状に復元されます。</target>
        </trans-unit>
        <trans-unit id="8f164f4fea8febd9cad272e82ab328161a3c6dcb" translate="yes" xml:space="preserve">
          <source>Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.</source>
          <target state="translated">dims軸で指定された平面内でn-Dテンソルを90度回転させる。</target>
        </trans-unit>
        <trans-unit id="8dfaeb09d713bebac16f06e9df8c867ae92ec360" translate="yes" xml:space="preserve">
          <source>Rotate a n-D tensor by 90 degrees in the plane specified by dims axis. Rotation direction is from the first towards the second axis if k &amp;gt; 0, and from the second towards the first for k &amp;lt; 0.</source>
          <target state="translated">Rotate a n-D tensor by 90 degrees in the plane specified by dims axis. Rotation direction is from the first towards the second axis if k &amp;gt; 0, and from the second towards the first for k &amp;lt; 0.</target>
        </trans-unit>
        <trans-unit id="8f997250f8d2d3174e19a84c2938437affe12ee1" translate="yes" xml:space="preserve">
          <source>Rule of thumb</source>
          <target state="translated">経験則</target>
        </trans-unit>
        <trans-unit id="f35ba84a98c82f892526356da88061a3501723bb" translate="yes" xml:space="preserve">
          <source>Run it on the command line with</source>
          <target state="translated">コマンドラインで</target>
        </trans-unit>
        <trans-unit id="312956888e10f6c9efa0be100898714e9d49a550" translate="yes" xml:space="preserve">
          <source>Running a loaded model:</source>
          <target state="translated">ロードされたモデルを実行します。</target>
        </trans-unit>
        <trans-unit id="5359eea6ab0e87db9479836bb9761e7ad6a157fe" translate="yes" xml:space="preserve">
          <source>Runtime characteristics</source>
          <target state="translated">ランタイム特性</target>
        </trans-unit>
        <trans-unit id="02aa629c8b16cd17a44f3a0efec2feed43937642" translate="yes" xml:space="preserve">
          <source>S</source>
          <target state="translated">S</target>
        </trans-unit>
        <trans-unit id="d7c8ea15b98297abf6f0c48aa6d1cd297394d77c" translate="yes" xml:space="preserve">
          <source>S ** 2 / (m - 1)</source>
          <target state="translated">S **2/(m-1</target>
        </trans-unit>
        <trans-unit id="dc71df7ac9f3ac27b7d12ac3903965de330de133" translate="yes" xml:space="preserve">
          <source>S = \text{max target length, if shape is } (N, S)</source>
          <target state="translated">S=\text{max target length,if shape is}(N,S)</target>
        </trans-unit>
        <trans-unit id="1678c8d5a5e1b27b84ba49edaa49f332453af05c" translate="yes" xml:space="preserve">
          <source>S=\text{num\_layers} * \text{num\_directions}</source>
          <target state="translated">S=text{num_layers}*ﾃｸﾄ{num_directions}*ﾃｸﾄ{num_directions}</target>
        </trans-unit>
        <trans-unit id="d4cd3df709d03592b7820bf91be2a174166e078a" translate="yes" xml:space="preserve">
          <source>SELU</source>
          <target state="translated">SELU</target>
        </trans-unit>
        <trans-unit id="bad45f89fe2643171a9f0af482912ef53c58c8d3" translate="yes" xml:space="preserve">
          <source>SMART mode algorithm</source>
          <target state="translated">SMARTモードアルゴリズム</target>
        </trans-unit>
        <trans-unit id="2c798885ebfbe383227dbd5c2205277f8af9d524" translate="yes" xml:space="preserve">
          <source>SUM</source>
          <target state="translated">SUM</target>
        </trans-unit>
        <trans-unit id="6f0eaf31574764cd755cbd6a055a6fcbc66e5dae" translate="yes" xml:space="preserve">
          <source>SWA has been proposed in &lt;a href=&quot;https://arxiv.org/abs/1803.05407&quot;&gt;Averaging Weights Leads to Wider Optima and Better Generalization&lt;/a&gt;.</source>
          <target state="translated">SWAは、&lt;a href=&quot;https://arxiv.org/abs/1803.05407&quot;&gt;重みの平均化がより広い最適化とより良い一般化&lt;/a&gt;につながることで提案されています。</target>
        </trans-unit>
        <trans-unit id="f84f75a03bd05c4bba727eb6c0d6fe360d00d818" translate="yes" xml:space="preserve">
          <source>SWA learning rate schedules</source>
          <target state="translated">SWAの学習率スケジュール</target>
        </trans-unit>
        <trans-unit id="2e4fbb0a9e252120bad1b2cf3ddef7f9a08b3c65" translate="yes" xml:space="preserve">
          <source>Same as &lt;a href=&quot;#torch.Tensor.narrow&quot;&gt;&lt;code&gt;Tensor.narrow()&lt;/code&gt;&lt;/a&gt; except returning a copy rather than shared storage. This is primarily for sparse tensors, which do not have a shared-storage narrow method. Calling &lt;code&gt;`narrow_copy&lt;/code&gt; with &lt;code&gt;`dimemsion &amp;gt; self.sparse_dim()`&lt;/code&gt; will return a copy with the relevant dense dimension narrowed, and &lt;code&gt;`self.shape`&lt;/code&gt; updated accordingly.</source>
          <target state="translated">Same as &lt;a href=&quot;#torch.Tensor.narrow&quot;&gt; &lt;code&gt;Tensor.narrow()&lt;/code&gt; &lt;/a&gt; except returning a copy rather than shared storage. This is primarily for sparse tensors, which do not have a shared-storage narrow method. Calling &lt;code&gt;`narrow_copy&lt;/code&gt; with &lt;code&gt;`dimemsion &amp;gt; self.sparse_dim()`&lt;/code&gt; will return a copy with the relevant dense dimension narrowed, and &lt;code&gt;`self.shape`&lt;/code&gt; updated accordingly.</target>
        </trans-unit>
        <trans-unit id="12f6402d6b42f6b20df7c7e5514d35048980475e" translate="yes" xml:space="preserve">
          <source>Sampled tensor of same shape as &lt;code&gt;logits&lt;/code&gt; from the Gumbel-Softmax distribution. If &lt;code&gt;hard=True&lt;/code&gt;, the returned samples will be one-hot, otherwise they will be probability distributions that sum to 1 across &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">Sampled tensor of same shape as &lt;code&gt;logits&lt;/code&gt; from the Gumbel-Softmax distribution. If &lt;code&gt;hard=True&lt;/code&gt; , the returned samples will be one-hot, otherwise they will be probability distributions that sum to 1 across &lt;code&gt;dim&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0f11d31dedd1a06aeb7fd6c168cfb8046bb4af97" translate="yes" xml:space="preserve">
          <source>Sampler that restricts data loading to a subset of the dataset.</source>
          <target state="translated">データセットのサブセットにデータの読み込みを制限するサンプラー。</target>
        </trans-unit>
        <trans-unit id="46c4eda8f0682c6a4eca16cae1bf03c979256658" translate="yes" xml:space="preserve">
          <source>Samples are binary (0 or 1). They take the value &lt;code&gt;1&lt;/code&gt; with probability &lt;code&gt;p&lt;/code&gt; and &lt;code&gt;0&lt;/code&gt; with probability &lt;code&gt;1 - p&lt;/code&gt;.</source>
          <target state="translated">サンプルはバイナリ（0または1）です。彼らは価値取る &lt;code&gt;1&lt;/code&gt; を確率で &lt;code&gt;p&lt;/code&gt; と &lt;code&gt;0&lt;/code&gt; の確率で &lt;code&gt;1 - p&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="290387605cb78533c282d0e9d73fda591d532885" translate="yes" xml:space="preserve">
          <source>Samples are integers from</source>
          <target state="translated">サンプルは</target>
        </trans-unit>
        <trans-unit id="58b74a9d8f020ad3d0017c06dac17a64698c94e6" translate="yes" xml:space="preserve">
          <source>Samples are logits of values in (0, 1). See [1] for more details.</source>
          <target state="translated">サンプルは(0,1)の値のロジットです。詳細は[1]を参照してください。</target>
        </trans-unit>
        <trans-unit id="038b1821087530df9b32220979af778b78c446a1" translate="yes" xml:space="preserve">
          <source>Samples are non-negative integers [0,</source>
          <target state="translated">サンプルは非負の整数[0.</target>
        </trans-unit>
        <trans-unit id="19b7a569829985718d97274f88b37fe1917c9e92" translate="yes" xml:space="preserve">
          <source>Samples are nonnegative integers, with a pmf given by</source>
          <target state="translated">サンプルは非負の整数で、pmfは次式で与えられます。</target>
        </trans-unit>
        <trans-unit id="c447ff4f78d86ac69f689268060727181fbe9807" translate="yes" xml:space="preserve">
          <source>Samples are one-hot coded vectors of size &lt;code&gt;probs.size(-1)&lt;/code&gt;.</source>
          <target state="translated">サンプルは、サイズ &lt;code&gt;probs.size(-1)&lt;/code&gt; のワンホットコード化されたベクトルです。</target>
        </trans-unit>
        <trans-unit id="19104e555389bebae6c56e80fa764ee086be702a" translate="yes" xml:space="preserve">
          <source>Samples elements from &lt;code&gt;[0,..,len(weights)-1]&lt;/code&gt; with given probabilities (weights).</source>
          <target state="translated">&lt;code&gt;[0,..,len(weights)-1]&lt;/code&gt; 、指定された確率（重み）で要素をサンプリングします。</target>
        </trans-unit>
        <trans-unit id="9e9e089066c3d2af4277a5ab0054e52473f2c07f" translate="yes" xml:space="preserve">
          <source>Samples elements randomly from a given list of indices, without replacement.</source>
          <target state="translated">指定されたインデックスのリストからランダムに要素をサンプリングします.</target>
        </trans-unit>
        <trans-unit id="24e35b463a3cf98fd449e886fc4e86f3a0dab5f2" translate="yes" xml:space="preserve">
          <source>Samples elements randomly. If without replacement, then sample from a shuffled dataset. If with replacement, then user can specify &lt;code&gt;num_samples&lt;/code&gt; to draw.</source>
          <target state="translated">要素をランダムにサンプリングします。置換しない場合は、シャッフルされたデータセットからサンプリングします。置換する場合、ユーザーは描画する &lt;code&gt;num_samples&lt;/code&gt; を指定できます。</target>
        </trans-unit>
        <trans-unit id="09f894ef8557b505ad9a0b93997e1c4496877755" translate="yes" xml:space="preserve">
          <source>Samples elements sequentially, always in the same order.</source>
          <target state="translated">常に同じ順番で要素を順次サンプリングします。</target>
        </trans-unit>
        <trans-unit id="22779ddf6cbe4d8bc9ff5fafe1e2aa1b1ff778a6" translate="yes" xml:space="preserve">
          <source>Samples from a Cauchy (Lorentz) distribution. The distribution of the ratio of independent normally distributed random variables with means &lt;code&gt;0&lt;/code&gt; follows a Cauchy distribution.</source>
          <target state="translated">コーシー（ローレンツ）分布からのサンプル。平均が &lt;code&gt;0&lt;/code&gt; の独立した正規分布確率変数の比率の分布は、コーシー分布に従います。</target>
        </trans-unit>
        <trans-unit id="2cb9d9b0dcc4dfe9421ee8a8fe988bef0860c270" translate="yes" xml:space="preserve">
          <source>Samples from a Gumbel Distribution.</source>
          <target state="translated">ガンベル分布からのサンプル。</target>
        </trans-unit>
        <trans-unit id="f796da3db0834b82a9b597a027df4fe0a3710f34" translate="yes" xml:space="preserve">
          <source>Samples from a Pareto Type 1 distribution.</source>
          <target state="translated">パレート1型分布からのサンプル。</target>
        </trans-unit>
        <trans-unit id="e40b18d593f8292cd1929002560bba0658812862" translate="yes" xml:space="preserve">
          <source>Samples from a two-parameter Weibull distribution.</source>
          <target state="translated">2パラメータのワイブル分布からのサンプル。</target>
        </trans-unit>
        <trans-unit id="870cb0523222c3bafa82fc03370a9998186a6c8a" translate="yes" xml:space="preserve">
          <source>Samples from the Gumbel-Softmax distribution (&lt;a href=&quot;https://arxiv.org/abs/1611.00712&quot;&gt;Link 1&lt;/a&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;Link 2&lt;/a&gt;) and optionally discretizes.</source>
          <target state="translated">Samples from the Gumbel-Softmax distribution (&lt;a href=&quot;https://arxiv.org/abs/1611.00712&quot;&gt;Link 1&lt;/a&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;Link 2&lt;/a&gt;) and optionally discretizes.</target>
        </trans-unit>
        <trans-unit id="bb9c2993371e955a4cc850805ced703ca0a14469" translate="yes" xml:space="preserve">
          <source>Save an offline version of this module for use in a separate process.</source>
          <target state="translated">このモジュールのオフラインバージョンを保存して、別のプロセスで使用します。</target>
        </trans-unit>
        <trans-unit id="c01b4e6f82d950b9eb933dee7fd7ccb2a95a9e86" translate="yes" xml:space="preserve">
          <source>Save an offline version of this module for use in a separate process. The saved module serializes all of the methods, submodules, parameters, and attributes of this module. It can be loaded into the C++ API using &lt;code&gt;torch::jit::load(filename)&lt;/code&gt; or into the Python API with &lt;a href=&quot;torch.jit.load#torch.jit.load&quot;&gt;&lt;code&gt;torch.jit.load&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Save an offline version of this module for use in a separate process. The saved module serializes all of the methods, submodules, parameters, and attributes of this module. It can be loaded into the C++ API using &lt;code&gt;torch::jit::load(filename)&lt;/code&gt; or into the Python API with &lt;a href=&quot;torch.jit.load#torch.jit.load&quot;&gt; &lt;code&gt;torch.jit.load&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="ae2ed5816db3fac279ce9e6772770274eeecffb6" translate="yes" xml:space="preserve">
          <source>Saves an object to a disk file.</source>
          <target state="translated">オブジェクトをディスクファイルに保存します。</target>
        </trans-unit>
        <trans-unit id="4568659c737ca6dd6d7cb2b416c756b4fa3d4b2e" translate="yes" xml:space="preserve">
          <source>Saves given tensors for a future call to &lt;code&gt;backward()&lt;/code&gt;.</source>
          <target state="translated">将来の &lt;code&gt;backward()&lt;/code&gt; の呼び出しのために、指定されたテンソルを保存します。</target>
        </trans-unit>
        <trans-unit id="122590ee88a0a7371836192fc7f0f566864870ca" translate="yes" xml:space="preserve">
          <source>Say we have a model like:</source>
          <target state="translated">このようなモデルがあるとします。</target>
        </trans-unit>
        <trans-unit id="66da7860d1535f34a78cf5749db3d68876d558e1" translate="yes" xml:space="preserve">
          <source>Scatters a list of tensors to all processes in a group.</source>
          <target state="translated">テンソルのリストをグループ内の全プロセスに分散します。</target>
        </trans-unit>
        <trans-unit id="106090197649a7e069056e240a9ad14c57a1cbfa" translate="yes" xml:space="preserve">
          <source>Scatters tensor across multiple GPUs.</source>
          <target state="translated">テンソルを複数のGPUに分散させます。</target>
        </trans-unit>
        <trans-unit id="b687feeb25ef199e522b82d65d8c03c4535af2a9" translate="yes" xml:space="preserve">
          <source>Score function</source>
          <target state="translated">スコア機能</target>
        </trans-unit>
        <trans-unit id="ca23ef4c78c4b30679a7feed50e583d779b937a2" translate="yes" xml:space="preserve">
          <source>Scores the sample by inverting the transform(s) and computing the score using the score of the base distribution and the log abs det jacobian.</source>
          <target state="translated">変換を反転して標本を採点し,基底分布のスコアと log abs det jacobian を用いてスコアを計算します.</target>
        </trans-unit>
        <trans-unit id="8003f43b6ada6148476432121a9ade7662e59807" translate="yes" xml:space="preserve">
          <source>ScriptFunction</source>
          <target state="translated">ScriptFunction</target>
        </trans-unit>
        <trans-unit id="45d3892e0529a64b6123a79e03cc7e0f2432a98c" translate="yes" xml:space="preserve">
          <source>ScriptModule</source>
          <target state="translated">ScriptModule</target>
        </trans-unit>
        <trans-unit id="3fb95588d29ea3da9d0dc7585a2020bf65e56741" translate="yes" xml:space="preserve">
          <source>Scripted functions can call traced functions. This is particularly useful when you need to use control-flow around a simple feed-forward model. For instance the beam search of a sequence to sequence model will typically be written in script but can call an encoder module generated using tracing.</source>
          <target state="translated">スクリプト化された関数はトレースされた関数を呼び出すことができます。これは、単純なフィードフォワードモデルの周りでコントロールフローを使用する必要がある場合に特に便利です。例えば、シーケンスからシーケンスへのモデルのビームサーチは通常スクリプトで書かれますが、トレースを使って生成されたエンコーダモジュールを呼び出すことができます。</target>
        </trans-unit>
        <trans-unit id="898752673b10b861d8ace49b60919a48cd4eac78" translate="yes" xml:space="preserve">
          <source>Scripting a function or &lt;code&gt;nn.Module&lt;/code&gt; will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Scripting a function or &lt;code&gt;nn.Module&lt;/code&gt; will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="af454137fb34eaadd60d3d10157722e0668fe3b2" translate="yes" xml:space="preserve">
          <source>Scripting a function or &lt;code&gt;nn.Module&lt;/code&gt; will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt;. TorchScript itself is a subset of the Python language, so not all features in Python work, but we provide enough functionality to compute on tensors and do control-dependent operations. For a complete guide, see the &lt;a href=&quot;../jit_language_reference#language-reference&quot;&gt;TorchScript Language Reference&lt;/a&gt;.</source>
          <target state="translated">Scripting a function or &lt;code&gt;nn.Module&lt;/code&gt; will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt;. TorchScript itself is a subset of the Python language, so not all features in Python work, but we provide enough functionality to compute on tensors and do control-dependent operations. For a complete guide, see the &lt;a href=&quot;../jit_language_reference#language-reference&quot;&gt;TorchScript Language Reference&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="033419356306d2d296e24d272874b31ebedcd66e" translate="yes" xml:space="preserve">
          <source>Scripting an &lt;code&gt;nn.Module&lt;/code&gt; by default will compile the &lt;code&gt;forward&lt;/code&gt; method and recursively compile any methods, submodules, and functions called by &lt;code&gt;forward&lt;/code&gt;. If a &lt;code&gt;nn.Module&lt;/code&gt; only uses features supported in TorchScript, no changes to the original module code should be necessary. &lt;code&gt;script&lt;/code&gt; will construct &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; that has copies of the attributes, parameters, and methods of the original module.</source>
          <target state="translated">Scripting an &lt;code&gt;nn.Module&lt;/code&gt; by default will compile the &lt;code&gt;forward&lt;/code&gt; method and recursively compile any methods, submodules, and functions called by &lt;code&gt;forward&lt;/code&gt; . If a &lt;code&gt;nn.Module&lt;/code&gt; only uses features supported in TorchScript, no changes to the original module code should be necessary. &lt;code&gt;script&lt;/code&gt; will construct &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; that has copies of the attributes, parameters, and methods of the original module.</target>
        </trans-unit>
        <trans-unit id="19791ed5c10ea9f7f4c0c92eb2869473896cff09" translate="yes" xml:space="preserve">
          <source>Search the distribution in the histogram for optimal min/max values.</source>
          <target state="translated">ヒストグラム内の分布を検索して,最適な最小値/最大値を求めます.</target>
        </trans-unit>
        <trans-unit id="2b7757dc0bce246d1f7d37c65a1b7323d32d2496" translate="yes" xml:space="preserve">
          <source>Second, some operators will produce different values depending on whether or not they are coalesced or not (e.g., &lt;a href=&quot;#torch.sparse.FloatTensor._values&quot;&gt;&lt;code&gt;torch.sparse.FloatTensor._values()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.sparse.FloatTensor._indices&quot;&gt;&lt;code&gt;torch.sparse.FloatTensor._indices()&lt;/code&gt;&lt;/a&gt;, as well as &lt;a href=&quot;tensors#torch.Tensor.sparse_mask&quot;&gt;&lt;code&gt;torch.Tensor.sparse_mask()&lt;/code&gt;&lt;/a&gt;). These operators are prefixed by an underscore to indicate that they reveal internal implementation details and should be used with care, since code that works with coalesced sparse tensors may not work with uncoalesced sparse tensors; generally speaking, it is safest to explicitly coalesce before working with these operators.</source>
          <target state="translated">Second, some operators will produce different values depending on whether or not they are coalesced or not (e.g., &lt;a href=&quot;#torch.sparse.FloatTensor._values&quot;&gt; &lt;code&gt;torch.sparse.FloatTensor._values()&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;#torch.sparse.FloatTensor._indices&quot;&gt; &lt;code&gt;torch.sparse.FloatTensor._indices()&lt;/code&gt; &lt;/a&gt;, as well as &lt;a href=&quot;tensors#torch.Tensor.sparse_mask&quot;&gt; &lt;code&gt;torch.Tensor.sparse_mask()&lt;/code&gt; &lt;/a&gt;). These operators are prefixed by an underscore to indicate that they reveal internal implementation details and should be used with care, since code that works with coalesced sparse tensors may not work with uncoalesced sparse tensors; generally speaking, it is safest to explicitly coalesce before working with these operators.</target>
        </trans-unit>
        <trans-unit id="a158648517089dfe2e8140b70f8bef8fa8b3034b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#dataloader-collate-fn&quot;&gt;this section&lt;/a&gt; on more about &lt;code&gt;collate_fn&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;collate_fn&lt;/code&gt; 詳細については、&lt;a href=&quot;#dataloader-collate-fn&quot;&gt;このセクション&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="36c23f7f90f14da5821a9b8b12151f9fc9d50660" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#dataset-types&quot;&gt;Dataset Types&lt;/a&gt; for more details on these two types of datasets and how &lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt;&lt;code&gt;IterableDataset&lt;/code&gt;&lt;/a&gt; interacts with &lt;a href=&quot;#multi-process-data-loading&quot;&gt;Multi-process data loading&lt;/a&gt;.</source>
          <target state="translated">参照&lt;a href=&quot;#dataset-types&quot;&gt;データセットの種類&lt;/a&gt;のデータセットのこれら2つのタイプの詳細については、どのよう&lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt; &lt;code&gt;IterableDataset&lt;/code&gt; は&lt;/a&gt;と対話する&lt;a href=&quot;#multi-process-data-loading&quot;&gt;マルチプロセスデータのロード&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b547fa358f4d375a4ada3bd99e7498b8afae4202" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#module-torch.utils.data&quot;&gt;&lt;code&gt;torch.utils.data&lt;/code&gt;&lt;/a&gt; documentation page for more details.</source>
          <target state="translated">詳細については、&lt;a href=&quot;#module-torch.utils.data&quot;&gt; &lt;code&gt;torch.utils.data&lt;/code&gt; の&lt;/a&gt;ドキュメントページを参照してください。</target>
        </trans-unit>
        <trans-unit id="5b6dced15fa8a0213a82f02ae1effe79ccf48d16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; for restrictions on tensor names.</source>
          <target state="translated">See &lt;a href=&quot;#torch.Tensor.names&quot;&gt; &lt;code&gt;names&lt;/code&gt; &lt;/a&gt; for restrictions on tensor names.</target>
        </trans-unit>
        <trans-unit id="243a5526f4842ad1af50687b538ec9b7b7b4698f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.cuda.max_memory_allocated&quot;&gt;&lt;code&gt;max_memory_allocated()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">詳細については、&lt;a href=&quot;#torch.cuda.max_memory_allocated&quot;&gt; &lt;code&gt;max_memory_allocated()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="18ad60e0a411bdc88fa0f09bd839bc7ff6f95e28" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.cuda.max_memory_cached&quot;&gt;&lt;code&gt;max_memory_cached()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">詳細については、&lt;a href=&quot;#torch.cuda.max_memory_cached&quot;&gt; &lt;code&gt;max_memory_cached()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="d23b93420a80f6bb1829feef82f05084851c1675" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.nn.quantized.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">See &lt;a href=&quot;#torch.nn.quantized.Conv1d&quot;&gt; &lt;code&gt;Conv1d&lt;/code&gt; &lt;/a&gt; for details and output shape.</target>
        </trans-unit>
        <trans-unit id="b27704ec42ef1503a1d419e6619ba79f9a13ebfb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.nn.quantized.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">See &lt;a href=&quot;#torch.nn.quantized.Conv2d&quot;&gt; &lt;code&gt;Conv2d&lt;/code&gt; &lt;/a&gt; for details and output shape.</target>
        </trans-unit>
        <trans-unit id="56a1d3982f38299aa1d9205f01ea00cd34354fef" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.nn.quantized.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">See &lt;a href=&quot;#torch.nn.quantized.Conv3d&quot;&gt; &lt;code&gt;Conv3d&lt;/code&gt; &lt;/a&gt; for details and output shape.</target>
        </trans-unit>
        <trans-unit id="b4ccb661511817b74aa1b611837a5a3335536f1d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.utils.checkpoint.checkpoint&quot;&gt;&lt;code&gt;checkpoint()&lt;/code&gt;&lt;/a&gt; on how checkpointing works.</source>
          <target state="translated">See &lt;a href=&quot;#torch.utils.checkpoint.checkpoint&quot;&gt; &lt;code&gt;checkpoint()&lt;/code&gt; &lt;/a&gt; on how checkpointing works.</target>
        </trans-unit>
        <trans-unit id="592148f1f545aa4c74a139446df1dc46e1b6f5ca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.utils.cpp_extension.load&quot;&gt;&lt;code&gt;load()&lt;/code&gt;&lt;/a&gt; for a description of arguments omitted below.</source>
          <target state="translated">See &lt;a href=&quot;#torch.utils.cpp_extension.load&quot;&gt; &lt;code&gt;load()&lt;/code&gt; &lt;/a&gt; for a description of arguments omitted below.</target>
        </trans-unit>
        <trans-unit id="3896f3dcf8c1d0bd4419fbc3e2eb2617d32af3a0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;&lt;code&gt;Dataset&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">詳細については、&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt; &lt;code&gt;Dataset&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="1b587694da52c7658cba1e5d21c7a0bf9aad6739" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt;&lt;code&gt;IterableDataset&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">詳細については、&lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt; &lt;code&gt;IterableDataset&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="dd3e6f221b9ffca56a618c8ce4986b9d9a3b9a59" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#variable-resolution&quot;&gt;Variable Resolution&lt;/a&gt; for how variables are resolved.</source>
          <target state="translated">See &lt;a href=&quot;#variable-resolution&quot;&gt;Variable Resolution&lt;/a&gt; for how variables are resolved.</target>
        </trans-unit>
        <trans-unit id="6663536c00122040c87a44bdc2b745caee1f1423" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../jit#inspecting-code&quot;&gt;Inspecting Code&lt;/a&gt; for details.</source>
          <target state="translated">See &lt;a href=&quot;../jit#inspecting-code&quot;&gt;Inspecting Code&lt;/a&gt; for details.</target>
        </trans-unit>
        <trans-unit id="eb8c27e43e09f15fd524c6c5a38cd014825e6c23" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../tensors#torch.Tensor.view&quot;&gt;&lt;code&gt;torch.Tensor.view()&lt;/code&gt;&lt;/a&gt; on when it is possible to return a view.</source>
          <target state="translated">See &lt;a href=&quot;../tensors#torch.Tensor.view&quot;&gt; &lt;code&gt;torch.Tensor.view()&lt;/code&gt; &lt;/a&gt; on when it is possible to return a view.</target>
        </trans-unit>
        <trans-unit id="0410d55962a7fc08aaf5d7b12288cb6edf33cd4b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.abs#torch.abs&quot;&gt;&lt;code&gt;torch.abs()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.abs#torch.abs&quot;&gt; &lt;code&gt;torch.abs()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ced4292c46e2d0f9084a0d4bbafd060bcaf8de87" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.acos#torch.acos&quot;&gt;&lt;code&gt;torch.acos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.acos#torch.acos&quot;&gt; &lt;code&gt;torch.acos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d557ccd80fb3258ddffbbb8174134a02d6cf179c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.acosh#torch.acosh&quot;&gt;&lt;code&gt;torch.acosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.acosh#torch.acosh&quot;&gt; &lt;code&gt;torch.acosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="789fcdc7d8a9ef51de9ddf2ef8954e307a7dd712" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.add#torch.add&quot;&gt;&lt;code&gt;torch.add()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.add#torch.add&quot;&gt; &lt;code&gt;torch.add()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="37a8639e7cd42640a040dc7726bd5f806eb0bd35" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addbmm#torch.addbmm&quot;&gt;&lt;code&gt;torch.addbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.addbmm#torch.addbmm&quot;&gt; &lt;code&gt;torch.addbmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d031d4e4498ba97f52d6d80a33dad228fb9f2cbe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addcdiv#torch.addcdiv&quot;&gt;&lt;code&gt;torch.addcdiv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.addcdiv#torch.addcdiv&quot;&gt; &lt;code&gt;torch.addcdiv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="565ec468f6c035b17c0ac0bb82ee2cbcd8edaca7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addcmul#torch.addcmul&quot;&gt;&lt;code&gt;torch.addcmul()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.addcmul#torch.addcmul&quot;&gt; &lt;code&gt;torch.addcmul()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b2d04f2a20233d7e081134dcc2710d272865025a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addmm#torch.addmm&quot;&gt;&lt;code&gt;torch.addmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.addmm#torch.addmm&quot;&gt; &lt;code&gt;torch.addmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fbb6e45db46d337e88fb01997ddfd0d38b1e36e5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addmv#torch.addmv&quot;&gt;&lt;code&gt;torch.addmv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.addmv#torch.addmv&quot;&gt; &lt;code&gt;torch.addmv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0415452e192f39adc1dfb989387d7c4f3dd04593" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addr#torch.addr&quot;&gt;&lt;code&gt;torch.addr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.addr#torch.addr&quot;&gt; &lt;code&gt;torch.addr()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7040368b881cece8154506daeab47e7b26bc4465" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.allclose#torch.allclose&quot;&gt;&lt;code&gt;torch.allclose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.allclose#torch.allclose&quot;&gt; &lt;code&gt;torch.allclose()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b5b8be1187577d5e5a0b32510f1f32129626cca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.amax#torch.amax&quot;&gt;&lt;code&gt;torch.amax()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.amax#torch.amax&quot;&gt; &lt;code&gt;torch.amax()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bac9b8922811f35c234bf464a4494dbef74933b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.amin#torch.amin&quot;&gt;&lt;code&gt;torch.amin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.amin#torch.amin&quot;&gt; &lt;code&gt;torch.amin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d5518b7da2603866919ecc93573fb7693cbe1d28" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.angle#torch.angle&quot;&gt;&lt;code&gt;torch.angle()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.angle#torch.angle&quot;&gt; &lt;code&gt;torch.angle()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6d6f36d28f663492799df5b5fcb97f2c82893849" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arccos#torch.arccos&quot;&gt;&lt;code&gt;torch.arccos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.arccos#torch.arccos&quot;&gt; &lt;code&gt;torch.arccos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="95b1cd872f49253eed8e157b208ed8426d2a08f0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arccosh#torch.arccosh&quot;&gt;&lt;code&gt;torch.arccosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.arccosh#torch.arccosh&quot;&gt; &lt;code&gt;torch.arccosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="20d7592e91b8ac1020ec98e06fb5bdf07f1891bc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arcsin#torch.arcsin&quot;&gt;&lt;code&gt;torch.arcsin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.arcsin#torch.arcsin&quot;&gt; &lt;code&gt;torch.arcsin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="92063535c0e36748fc07d3768b27df3f9db98d33" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arcsinh#torch.arcsinh&quot;&gt;&lt;code&gt;torch.arcsinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.arcsinh#torch.arcsinh&quot;&gt; &lt;code&gt;torch.arcsinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f471a52f4701848a5c13052260382f54ba5f2bf2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arctan#torch.arctan&quot;&gt;&lt;code&gt;torch.arctan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.arctan#torch.arctan&quot;&gt; &lt;code&gt;torch.arctan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6352e358921d4176f31796abd8e2e1d94c2c4807" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arctanh#torch.arctanh&quot;&gt;&lt;code&gt;torch.arctanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.arctanh#torch.arctanh&quot;&gt; &lt;code&gt;torch.arctanh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8a3005660e169df440b195c1013e466fc0dc0f85" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.argmax#torch.argmax&quot;&gt;&lt;code&gt;torch.argmax()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.argmax#torch.argmax&quot;&gt; &lt;code&gt;torch.argmax()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9336c76dce7b82519130c38591a8f4bc511802b3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.argmin#torch.argmin&quot;&gt;&lt;code&gt;torch.argmin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.argmin#torch.argmin&quot;&gt; &lt;code&gt;torch.argmin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8db3f6696a6f968e7692af8c5ef5b20e20027f77" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.argsort#torch.argsort&quot;&gt;&lt;code&gt;torch.argsort()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.argsort#torch.argsort&quot;&gt; &lt;code&gt;torch.argsort()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4a2ff963efa23ea4ed3e29949ad7d7c3a624603f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.as_strided#torch.as_strided&quot;&gt;&lt;code&gt;torch.as_strided()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.as_strided#torch.as_strided&quot;&gt; &lt;code&gt;torch.as_strided()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="885b7e053cac4178633ab2cdae8c61527522af3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.asin#torch.asin&quot;&gt;&lt;code&gt;torch.asin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.asin#torch.asin&quot;&gt; &lt;code&gt;torch.asin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4b825056a4e3742071a4388ba1c9dd880e2f684d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.asinh#torch.asinh&quot;&gt;&lt;code&gt;torch.asinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.asinh#torch.asinh&quot;&gt; &lt;code&gt;torch.asinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="85ed8161a1e7cf3d498c0e025910cad264dbb99e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.atan#torch.atan&quot;&gt;&lt;code&gt;torch.atan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.atan#torch.atan&quot;&gt; &lt;code&gt;torch.atan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7c4e94754d2f650204d6da4aafe2bedeb278399d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.atan2#torch.atan2&quot;&gt;&lt;code&gt;torch.atan2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.atan2#torch.atan2&quot;&gt; &lt;code&gt;torch.atan2()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ed04a790c582bea4569ce9ba2a1f5fb49e96591b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.atanh#torch.atanh&quot;&gt;&lt;code&gt;torch.atanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.atanh#torch.atanh&quot;&gt; &lt;code&gt;torch.atanh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f172a9267504e77b4582e306093325cd390dbe6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.baddbmm#torch.baddbmm&quot;&gt;&lt;code&gt;torch.baddbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.baddbmm#torch.baddbmm&quot;&gt; &lt;code&gt;torch.baddbmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0ee51350ddf5c14b20523cca547052313b6da137" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bernoulli#torch.bernoulli&quot;&gt;&lt;code&gt;torch.bernoulli()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.bernoulli#torch.bernoulli&quot;&gt; &lt;code&gt;torch.bernoulli()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fa6bd5fd2fc0d4cbf209b32b685dcd15549e17a1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bincount#torch.bincount&quot;&gt;&lt;code&gt;torch.bincount()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.bincount#torch.bincount&quot;&gt; &lt;code&gt;torch.bincount()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1330e38a3bff864a896452adaef91e316142ee7a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_and#torch.bitwise_and&quot;&gt;&lt;code&gt;torch.bitwise_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.bitwise_and#torch.bitwise_and&quot;&gt; &lt;code&gt;torch.bitwise_and()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b232e0fb96bd322c2458574164c04bbfc68e696b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_not#torch.bitwise_not&quot;&gt;&lt;code&gt;torch.bitwise_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.bitwise_not#torch.bitwise_not&quot;&gt; &lt;code&gt;torch.bitwise_not()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="49bd1ecf94a298ed7136ddaa7b129d79af6f4f58" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_or#torch.bitwise_or&quot;&gt;&lt;code&gt;torch.bitwise_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.bitwise_or#torch.bitwise_or&quot;&gt; &lt;code&gt;torch.bitwise_or()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="74f2dbe9a2909c1557b61d4ca27fc1dfa0ee2a38" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_xor#torch.bitwise_xor&quot;&gt;&lt;code&gt;torch.bitwise_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.bitwise_xor#torch.bitwise_xor&quot;&gt; &lt;code&gt;torch.bitwise_xor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="50e2d514fed6ae782003300fa73df0e3bb831323" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bmm#torch.bmm&quot;&gt;&lt;code&gt;torch.bmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.bmm#torch.bmm&quot;&gt; &lt;code&gt;torch.bmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1c1407ae846f94e16c4554a9aed2a962bd7d5b41" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ceil#torch.ceil&quot;&gt;&lt;code&gt;torch.ceil()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.ceil#torch.ceil&quot;&gt; &lt;code&gt;torch.ceil()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0ee9005d9f7612dda3673351dab212c7597eacf9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cholesky#torch.cholesky&quot;&gt;&lt;code&gt;torch.cholesky()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cholesky#torch.cholesky&quot;&gt; &lt;code&gt;torch.cholesky()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9234f12a7920c48c92b0b92789cbf7f520e6cce2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cholesky_inverse#torch.cholesky_inverse&quot;&gt;&lt;code&gt;torch.cholesky_inverse()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cholesky_inverse#torch.cholesky_inverse&quot;&gt; &lt;code&gt;torch.cholesky_inverse()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="95412d4a68f7be2f448d2f6abdef3ba1039693ce" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cholesky_solve#torch.cholesky_solve&quot;&gt;&lt;code&gt;torch.cholesky_solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cholesky_solve#torch.cholesky_solve&quot;&gt; &lt;code&gt;torch.cholesky_solve()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="70d52135d5fe5109fdf4b68140efc30ed3ff15ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.chunk#torch.chunk&quot;&gt;&lt;code&gt;torch.chunk()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.chunk#torch.chunk&quot;&gt; &lt;code&gt;torch.chunk()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d2a8fa141c274f1ecc888c9dee97f508028c310" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.clamp#torch.clamp&quot;&gt;&lt;code&gt;torch.clamp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.clamp#torch.clamp&quot;&gt; &lt;code&gt;torch.clamp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="db643765ea3bdabe789a609a784f6f21e8b15ff6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.clone#torch.clone&quot;&gt;&lt;code&gt;torch.clone()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.clone#torch.clone&quot;&gt; &lt;code&gt;torch.clone()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2c5dee157b17c3fc64e10f3c111962a223627009" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.conj#torch.conj&quot;&gt;&lt;code&gt;torch.conj()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.conj#torch.conj&quot;&gt; &lt;code&gt;torch.conj()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="00b6992059c4a2ecf9c5ba83b4b4d6367e100b3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cos#torch.cos&quot;&gt;&lt;code&gt;torch.cos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cos#torch.cos&quot;&gt; &lt;code&gt;torch.cos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5f760d7b54a866c270d1f4f0fee69afc86260ce1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cosh#torch.cosh&quot;&gt;&lt;code&gt;torch.cosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cosh#torch.cosh&quot;&gt; &lt;code&gt;torch.cosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2e6ca2ba899e5a5ed0308b11c6dec0f921c1c386" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.count_nonzero#torch.count_nonzero&quot;&gt;&lt;code&gt;torch.count_nonzero()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.count_nonzero#torch.count_nonzero&quot;&gt; &lt;code&gt;torch.count_nonzero()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3154a66df758bedd23c1ca8d445818980c877056" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cross#torch.cross&quot;&gt;&lt;code&gt;torch.cross()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cross#torch.cross&quot;&gt; &lt;code&gt;torch.cross()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c33b1f8ea95f5374185b2beef8bdc0333006ca40" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cummax#torch.cummax&quot;&gt;&lt;code&gt;torch.cummax()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cummax#torch.cummax&quot;&gt; &lt;code&gt;torch.cummax()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b7a6c4b7502006ffffe7f61bc361df0a8f5c3485" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cummin#torch.cummin&quot;&gt;&lt;code&gt;torch.cummin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cummin#torch.cummin&quot;&gt; &lt;code&gt;torch.cummin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="175fd7991a76a77d1e7947c94b32c3900db2a22a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cumprod#torch.cumprod&quot;&gt;&lt;code&gt;torch.cumprod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cumprod#torch.cumprod&quot;&gt; &lt;code&gt;torch.cumprod()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ecda9d651f57ce0a80f553759df7118f9fc98f17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cumsum#torch.cumsum&quot;&gt;&lt;code&gt;torch.cumsum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.cumsum#torch.cumsum&quot;&gt; &lt;code&gt;torch.cumsum()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e4c2bb557dabd8b8d6424a1086a8f0e49082dcc1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.deg2rad#torch.deg2rad&quot;&gt;&lt;code&gt;torch.deg2rad()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.deg2rad#torch.deg2rad&quot;&gt; &lt;code&gt;torch.deg2rad()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="74fe8f78b0f15bbe31849b729e7353cfc88dda04" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.det#torch.det&quot;&gt;&lt;code&gt;torch.det()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.det#torch.det&quot;&gt; &lt;code&gt;torch.det()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="87d829bc645704d604ad02215c0bb4c96717d9da" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diag#torch.diag&quot;&gt;&lt;code&gt;torch.diag()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.diag#torch.diag&quot;&gt; &lt;code&gt;torch.diag()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d17eea2fe4310acb0e6689f3868245d146ae748a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diag_embed#torch.diag_embed&quot;&gt;&lt;code&gt;torch.diag_embed()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.diag_embed#torch.diag_embed&quot;&gt; &lt;code&gt;torch.diag_embed()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="07ddff47af47155cb8195d49fd74ab5f110f0de6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diagflat#torch.diagflat&quot;&gt;&lt;code&gt;torch.diagflat()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.diagflat#torch.diagflat&quot;&gt; &lt;code&gt;torch.diagflat()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e9871639ca6ca069867ff9833f0d0bad21e81d3f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;torch.diagonal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;torch.diagonal()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fd7c0b43d807db12fbff5fc78c8898e1347cf1a1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.digamma#torch.digamma&quot;&gt;&lt;code&gt;torch.digamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.digamma#torch.digamma&quot;&gt; &lt;code&gt;torch.digamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ec5b576fe8744daae4dc7030555211156b888d46" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.dist#torch.dist&quot;&gt;&lt;code&gt;torch.dist()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.dist#torch.dist&quot;&gt; &lt;code&gt;torch.dist()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8ab62666946a8333d7379a60a2d1d9d3ae225fa2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.div#torch.div&quot;&gt;&lt;code&gt;torch.div()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.div#torch.div&quot;&gt; &lt;code&gt;torch.div()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0cfd78ad9784ac679c7a2b9b5bca896325ba89a4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.divide#torch.divide&quot;&gt;&lt;code&gt;torch.divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.divide#torch.divide&quot;&gt; &lt;code&gt;torch.divide()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="593f13a108fe5ed0675dcd7c508f6c35b99b0b10" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.dot#torch.dot&quot;&gt;&lt;code&gt;torch.dot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.dot#torch.dot&quot;&gt; &lt;code&gt;torch.dot()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="59a8ed7a18a443621255817cd4ad0bf4a0e632ca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.eig#torch.eig&quot;&gt;&lt;code&gt;torch.eig()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.eig#torch.eig&quot;&gt; &lt;code&gt;torch.eig()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5ab6c51079e17cb89630c1e4a91f1d3454d90b6f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.eq#torch.eq&quot;&gt;&lt;code&gt;torch.eq()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.eq#torch.eq&quot;&gt; &lt;code&gt;torch.eq()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4813e89ec9293f99dfa5025547b461fb432f69d3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.equal#torch.equal&quot;&gt;&lt;code&gt;torch.equal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.equal#torch.equal&quot;&gt; &lt;code&gt;torch.equal()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3f7360444c9397fc1d5c5b1bc067d9af3c6e9edd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.erf#torch.erf&quot;&gt;&lt;code&gt;torch.erf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.erf#torch.erf&quot;&gt; &lt;code&gt;torch.erf()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="08fb634ad4f6c40b3935c0b3378501a7339f8fbe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.erfc#torch.erfc&quot;&gt;&lt;code&gt;torch.erfc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">See &lt;a href=&quot;generated/torch.erfc#torch.erfc&quot;&gt; &lt;code&gt;torch.erfc()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2bd6c425dc9b646c2b2bed4edf1c5a988917c21f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.erfinv#torch.erfinv&quot;&gt;&lt;code&gt;torch.erfinv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.erfinv#torch.erfinv&quot;&gt; &lt;code&gt;torch.erfinv()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="ad29dad56d468c778a3c249cc44c87db316a44e6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.exp#torch.exp&quot;&gt;&lt;code&gt;torch.exp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.exp#torch.exp&quot;&gt; &lt;code&gt;torch.exp()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="6b6fbfd00b7b75b48f9ccfcacaa40ee11ef98750" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.expm1#torch.expm1&quot;&gt;&lt;code&gt;torch.expm1()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.expm1#torch.expm1&quot;&gt; &lt;code&gt;torch.expm1()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="4bbb47f4968cd75aa8ca7739f121cb837ee30c39" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fft#torch.fft&quot;&gt;&lt;code&gt;torch.fft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.fft#torch.fft&quot;&gt; &lt;code&gt;torch.fft()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="a9a77b8be814999a1e18a3bcfe6fdc2b3f1b3bf0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fix#torch.fix&quot;&gt;&lt;code&gt;torch.fix()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/torch.fix#torch.fix&quot;&gt; &lt;code&gt;torch.fix()&lt;/code&gt; を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="aad979493ad2ea8c7660622a96be7811d0a81b87" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.flip#torch.flip&quot;&gt;&lt;code&gt;torch.flip()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.flip#torch.flip&quot;&gt; &lt;code&gt;torch.flip()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="bad831a531ebee9d67a2612a1d0e6978cc7ed27b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fliplr#torch.fliplr&quot;&gt;&lt;code&gt;torch.fliplr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.fliplr#torch.fliplr&quot;&gt; &lt;code&gt;torch.fliplr()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="87f6a8078b8a3f6f5a4247460381f4e94549ef39" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.flipud#torch.flipud&quot;&gt;&lt;code&gt;torch.flipud()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.flipud#torch.flipud&quot;&gt; &lt;code&gt;torch.flipud()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="399317938ad3be99c06e85c37e27d75701458b99" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.floor#torch.floor&quot;&gt;&lt;code&gt;torch.floor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.floor#torch.floor&quot;&gt; &lt;code&gt;torch.floor()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="bcdf651ea00fbe14dab01c29ec405b9ced982377" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.floor_divide#torch.floor_divide&quot;&gt;&lt;code&gt;torch.floor_divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.floor_divide#torch.floor_divide&quot;&gt; &lt;code&gt;torch.floor_divide()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="2efd0d46fdaf4a4f7fc46d9063330efa363c69ce" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fmod#torch.fmod&quot;&gt;&lt;code&gt;torch.fmod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.fmod#torch.fmod&quot;&gt; &lt;code&gt;torch.fmod()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="eb5589e94e3540a14e8e7b3fac4f8fdf408c5f2f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.frac#torch.frac&quot;&gt;&lt;code&gt;torch.frac()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.frac#torch.frac&quot;&gt; &lt;code&gt;torch.frac()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="fe3455e99f31e058dbdc692b113c1359d89488d7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.gather#torch.gather&quot;&gt;&lt;code&gt;torch.gather()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/torch.gather#torch.gather&quot;&gt; &lt;code&gt;torch.gather()&lt;/code&gt; を&lt;/a&gt;参照してください</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
