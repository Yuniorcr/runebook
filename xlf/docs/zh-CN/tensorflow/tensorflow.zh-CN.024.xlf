<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="518b59930c6aba89eacb1d11ae58ecb811d616aa" translate="yes" xml:space="preserve">
          <source>Sequence of all sub-modules.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77d33f49edae396f86350b207276bb3695b6378b" translate="yes" xml:space="preserve">
          <source>Sequence of trainable variables owned by this module and its submodules.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3f1d94e94b85124fcce6f3e4a558dad963712d8" translate="yes" xml:space="preserve">
          <source>Sequence of variables owned by this module and its submodules.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be5344f4e08fccd605ede2af586ad05148fddb02" translate="yes" xml:space="preserve">
          <source>Sequences longer than &lt;code&gt;num_timesteps&lt;/code&gt; are truncated so that they fit the desired length. The position where padding or truncation happens is determined by the arguments &lt;code&gt;padding&lt;/code&gt; and &lt;code&gt;truncating&lt;/code&gt;, respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdcc1d0546d49f37f108c4b90e55c5886698ffd0" translate="yes" xml:space="preserve">
          <source>Sequences that are shorter than &lt;code&gt;num_timesteps&lt;/code&gt; are padded with &lt;code&gt;value&lt;/code&gt; at the end.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df96bb1e937831e2c805016ef1785a1be98f2bd9" translate="yes" xml:space="preserve">
          <source>Sergey Ioffe, Christian Szegedy</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cda8b23adee9ccebc4f0ee14eb0856f276cdb138" translate="yes" xml:space="preserve">
          <source>Serialize &lt;code&gt;N&lt;/code&gt;-minibatch &lt;code&gt;SparseTensor&lt;/code&gt; into an &lt;code&gt;[N, 3]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd6e9915c3012a1991bd2cb773131895928dac7e" translate="yes" xml:space="preserve">
          <source>Serialize Keras object into JSON.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70b742bd7d5132c017e37c97bc7002dd5c15e8e9" translate="yes" xml:space="preserve">
          <source>Serialize a &lt;code&gt;SparseTensor&lt;/code&gt; into a 3-vector (1-D &lt;code&gt;Tensor&lt;/code&gt;) object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="387bc1747419aab3e8c0cd9fce2a44287ca4f717" translate="yes" xml:space="preserve">
          <source>Serialize a graph along with other Python objects such as &lt;code&gt;QueueRunner&lt;/code&gt;, &lt;code&gt;Variable&lt;/code&gt; into a &lt;code&gt;MetaGraphDef&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="194f3fc08c9ae161f9584c69b7e614affd39ae79" translate="yes" xml:space="preserve">
          <source>Serialize the ProfileProto to a binary string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b223667c02dfe98fd9e504bdcfb350ab3bbf7648" translate="yes" xml:space="preserve">
          <source>Serializes a list as a CSV string or unicode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8ffc3d75e2ae6e2c695e965396c6efad99c4b77" translate="yes" xml:space="preserve">
          <source>Serializes the flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aba77dbba5568088bbb6d959635ef17d6b8f9d69" translate="yes" xml:space="preserve">
          <source>Session-like object that handles initialization, recovery and hooks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48c79c47e20b16985ff763355cf65710d044a709" translate="yes" xml:space="preserve">
          <source>Session-like object that handles initialization, restoring, and hooks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46893ca773425535bdadeda51dc3f006148b7e4d" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;x[:, 3, :] = 0.&lt;/code&gt; and &lt;code&gt;x[:, 5, :] = 0.&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad047cfaa68caa1c3db011a461aefd34950ce606" translate="yes" xml:space="preserve">
          <source>Set a &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; as current without &lt;code&gt;with strategy.scope()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77762344b3eeefb7d5d8440477e63198d9fd1bdd" translate="yes" xml:space="preserve">
          <source>Set caching_device for this scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ccdef39b2ba0c658c6864bb5350b21d1c676c0c" translate="yes" xml:space="preserve">
          <source>Set custom getter for this scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e4c693df73432d9b224bf0a703523782bdae2c" translate="yes" xml:space="preserve">
          <source>Set data type for this scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9291f2652d56e29e2003d31f1c3c02e8bbdbb96" translate="yes" xml:space="preserve">
          <source>Set experimental optimizer options.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f40acf12c60f73570ce227513e0fe349679d3b21" translate="yes" xml:space="preserve">
          <source>Set if JIT compilation is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e64d6fb8ece5f461d68de885a93a9cee281d8e3d" translate="yes" xml:space="preserve">
          <source>Set if device placements should be logged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb7ca3d2b34b3cf92a9a8da5406cc8920b37367a" translate="yes" xml:space="preserve">
          <source>Set if memory growth should be enabled for a &lt;code&gt;PhysicalDevice&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bf36098a63c869b0141ff0f43f9ff3ba0844cd1" translate="yes" xml:space="preserve">
          <source>Set if soft device placement is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="796585419b43d9eceb6738683df615eda205554c" translate="yes" xml:space="preserve">
          <source>Set initializer for this scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dedc542f22d4594b43eb3efcfe545bbbdbeebc1e" translate="yes" xml:space="preserve">
          <source>Set number of threads used for parallelism between independent operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82747f8ffb2d4a288dc813ca2ed7be04331f620b" translate="yes" xml:space="preserve">
          <source>Set number of threads used within an individual op for parallelism.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf3f0ddac040aaf5b4d59bdb2ed55c27914f9963" translate="yes" xml:space="preserve">
          <source>Set of tools for real-time data augmentation on image data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c54672e9e7917803b57b36352423d4eeed81f7d" translate="yes" xml:space="preserve">
          <source>Set partitioner for this scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f4132cf847abb73dff5a8da1552edde55a72bca" translate="yes" xml:space="preserve">
          <source>Set regularizer for this scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="785d44923eabbf7703915e72866e368ec759a967" translate="yes" xml:space="preserve">
          <source>Set the list of visible devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fd54c097269449a834528679cdaa3277317db33" translate="yes" xml:space="preserve">
          <source>Set the logical device configuration for a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc5bc3aa4792ffb17b488fdab0db17f316de7d54" translate="yes" xml:space="preserve">
          <source>Set the maximum depth of display.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8385cc2994ca430a788d3ad888514e6d1ab7d8e" translate="yes" xml:space="preserve">
          <source>Sets Keras model and creates summary ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22d6f7a214f9c2601d906cb380f53cf537bedc95" translate="yes" xml:space="preserve">
          <source>Sets Keras model and writes graph if specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f11cd7e280cc3ae4ab5ec8d73b9cf82e018d551" translate="yes" xml:space="preserve">
          <source>Sets attributes to use later for processing files into a batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46a75e77654be7340a64ab7e8fdb3212e4c0f0be" translate="yes" xml:space="preserve">
          <source>Sets entries in &lt;code&gt;x&lt;/code&gt; to zero at random, while scaling the entire tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53a4ffa2cb16e85275ec3dafa3a60ef0fb2a5bf1" translate="yes" xml:space="preserve">
          <source>Sets stop requested field.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e30e85ef5b9784a4bc13bb7f4133a675b327d3b3" translate="yes" xml:space="preserve">
          <source>Sets summary recording on or off per the provided boolean value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b01db1185bf6c8610fcd6e68749085f6779cb603" translate="yes" xml:space="preserve">
          <source>Sets the AutoGraph verbosity level.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5eee6e4b23edd9d039095db17f400acc13212df1" translate="yes" xml:space="preserve">
          <source>Sets the current thread device policy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69aeb14a87cd9bb1d92bc6975c1a6ff0178ce261" translate="yes" xml:space="preserve">
          <source>Sets the default float type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81ee165c08a161961e636c871163a138f3c06d75" translate="yes" xml:space="preserve">
          <source>Sets the default summary step for the current thread.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6ee376b220695cc14c8651d5944644b5ca38101" translate="yes" xml:space="preserve">
          <source>Sets the global Policy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b60e305d9f40ed7048515d95cd6ae85a4a93866" translate="yes" xml:space="preserve">
          <source>Sets the global TensorFlow session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87559fecd3f45916d97c6e9fbd6227b2aacf9415" translate="yes" xml:space="preserve">
          <source>Sets the global random seed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34db6c7e3f0d7339e94c79d52f9bdd4a063f0615" translate="yes" xml:space="preserve">
          <source>Sets the global time step of the accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1203cecd4c168b15b56316a61570bda52858c7e7" translate="yes" xml:space="preserve">
          <source>Sets the graph-level random seed for the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f82070f4e6e578084e2bcfce350c2c40eb9811c7" translate="yes" xml:space="preserve">
          <source>Sets the learning phase to a fixed value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c36e7ccd12af3e2921d55376aed6a178d9dce246" translate="yes" xml:space="preserve">
          <source>Sets the list of old checkpoint filenames and timestamps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f1f7f924a96a25924bd4ffa8d90642ae8bcbc51" translate="yes" xml:space="preserve">
          <source>Sets the list of old checkpoint filenames.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd1ec01930055185c723c2164a4ee961ebe3e731" translate="yes" xml:space="preserve">
          <source>Sets the manual variable initialization flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44f6aa83524e8110a15510e482c4f7f69176ba12" translate="yes" xml:space="preserve">
          <source>Sets the parameters of this estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56a313eaa4d7219c0e54a35524dd48fd016f708d" translate="yes" xml:space="preserve">
          <source>Sets the threshold for what messages will be logged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11ca3ad7417baf7f998046a059f0228174b2ffe2" translate="yes" xml:space="preserve">
          <source>Sets the value of a variable, from a Numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1517ea48001427554cf370385a0726e25cc147e" translate="yes" xml:space="preserve">
          <source>Sets the value of the fuzz factor used in numeric expressions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72cf04bee0bc2722d3e620d885646dd816e3c9ab" translate="yes" xml:space="preserve">
          <source>Sets the value of the image data format convention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b6406cb503da1fb9f6e6a4513446339017d45f7" translate="yes" xml:space="preserve">
          <source>Sets the value of the input tensor. Note this copies data in &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca85f21725b3895962c5c41d8ee4badd9566c1a0" translate="yes" xml:space="preserve">
          <source>Sets the values of many tensor variables at once.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93d4ff12e9b47a77f00869086fc9dea5a82d066f" translate="yes" xml:space="preserve">
          <source>Sets the weights of the layer, from Numpy arrays.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0654a1305fc13289ab53b2062558d71378812c24" translate="yes" xml:space="preserve">
          <source>Sets up a Monitored or Hooked Session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5143090d4de7f657548f9137355ea82c80bc3e74" translate="yes" xml:space="preserve">
          <source>Sets up a graph with feeds and fetches for partial run.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9031702dfbe9a6eaf1e712063391d87f017a1a49" translate="yes" xml:space="preserve">
          <source>Sets vocabulary (and optionally document frequency) data for this layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e08368a366513eb104acaaf1c716a4d2e93b2ce7" translate="yes" xml:space="preserve">
          <source>Sets whether or not to use GNU style scanning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e25c325d68a191bf94048b2e56ffc29cdcbdcba8" translate="yes" xml:space="preserve">
          <source>Sets whether to use ResourceVariables for this scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1ac28b31a1edd841df4e792cf901bfb44e32631" translate="yes" xml:space="preserve">
          <source>Settable attribute indicating whether the model should run eagerly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a4bfb358dca5dac451b5b1d4d36881360437571" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;l = (1 + (q - 1) * z)&lt;/code&gt;, to ensure stability and avoid overflow, the implementation uses</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d38a742a55ebdf3234cb2609807919063a2aed43" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;new_shape&lt;/code&gt; as [2, 3, 6] will be fine as this shape is larger or equal in every dimension compared to the original shape [2, 3, 5].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f4878a5d627ce0b4cb5d7aa839f9c424a437da6" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;trainable&lt;/code&gt; on an model containing other layers will recursively set the &lt;code&gt;trainable&lt;/code&gt; value of all inner layers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55b7e50e9668e45dcf8255f80ca6fadf2582adc0" translate="yes" xml:space="preserve">
          <source>Setting environment variable depends on the platform. For example, on Linux, it can be done as follows (&lt;code&gt;$&lt;/code&gt; is the shell prompt):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98ad210a1d424d551560599f71277ae77def8cb8" translate="yes" xml:space="preserve">
          <source>Settings for warm-starting in &lt;code&gt;tf.estimator.Estimators&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a98628dac38a3430897e254ca10765d67ac37f0e" translate="yes" xml:space="preserve">
          <source>Shai Shalev-Shwartz, Tong Zhang. 2012</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03b27b03a5a8c1c0c654f82f78f573cfbaed2f7f" translate="yes" xml:space="preserve">
          <source>Shannon entropy in nats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="009311e40b8a060c5eba67f1263146e04b4c6942" translate="yes" xml:space="preserve">
          <source>Shape &lt;code&gt;[B1,...,Bb, N]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; of same &lt;code&gt;dtype&lt;/code&gt; as &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5f650ce75b03189c59505b001df917ebf24c8e8" translate="yes" xml:space="preserve">
          <source>Shape &lt;code&gt;[B1,...,Bb]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; of same &lt;code&gt;dtype&lt;/code&gt; as &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1001d9c716df0dd002a90e5c7fd8de460514793" translate="yes" xml:space="preserve">
          <source>Shape compatibility</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac03ca13af059aaa395f5255f16fd2fd96c23ad5" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single batch as a 1-D int32 &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7a27ac567178ca13d2c09207cad38c1e0d0b931" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single batch as a &lt;code&gt;TensorShape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f99bcf8393473453e114ff85b09d70b2a53cf20" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single event index as a 1-D &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7161805a9dac7fd0ebaae5bd71a7d234bdc85012" translate="yes" xml:space="preserve">
          <source>Shape of a single sample from a single event index as a &lt;code&gt;TensorShape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6483c91eba66015ed4ab8776064d3eff5ab14061" translate="yes" xml:space="preserve">
          <source>Shape of batch dimensions of this operator, determined at runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86345db94ce3a243e33554a24858c2c6ec60dcbd" translate="yes" xml:space="preserve">
          <source>Shape of the block dimensions of &lt;code&gt;self.spectrum&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7771a110dd20b18041b5dd6f9cc30e1bbacace1" translate="yes" xml:space="preserve">
          <source>Shape of this &lt;code&gt;LinearOperator&lt;/code&gt;, determined at runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1985e387405e4d4afb40d5dac9b2656f5d6f770" translate="yes" xml:space="preserve">
          <source>Shapes</source>
          <target state="translated">Shapes</target>
        </trans-unit>
        <trans-unit id="8430380665211689f2767ccff906ec9a4099f769" translate="yes" xml:space="preserve">
          <source>Shapes of parameters given the desired shape of a call to &lt;code&gt;sample()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fee9aae8e9097ba138d796c2823f16ecbde75b1b" translate="yes" xml:space="preserve">
          <source>Shards &lt;code&gt;computation&lt;/code&gt; along the batch dimension for parallel execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4bb91eacfcfd178011a31a6c6822d94c8087f62" translate="yes" xml:space="preserve">
          <source>Shards &lt;code&gt;computation&lt;/code&gt; for parallel execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="debe55a1300ea7ca4f227b9dd635acc8ca3e4415" translate="yes" xml:space="preserve">
          <source>Sharing a variable by capturing a scope and setting reuse:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd4356118ce17af4ac61d8e18b734f9c851e6a93" translate="yes" xml:space="preserve">
          <source>Shift the zero-frequency component to the center of the spectrum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc7f2ac5dda0cc4b1661846c36ed51a2eb0bf538" translate="yes" xml:space="preserve">
          <source>Should be called by the same thread which called &lt;code&gt;start()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b13ab1f9184cdb80dd3b3d41d39fff0fa20bca5c" translate="yes" xml:space="preserve">
          <source>Show operation time and memory consumptions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6565ab72f751d6e2a51ac78e2d5fc643343301f7" translate="yes" xml:space="preserve">
          <source>Shows the directory name where evaluation metrics are dumped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9de79067e565fc76cd3de53fce4b140bf7336fc3" translate="yes" xml:space="preserve">
          <source>Shuffles and repeats a Dataset, reshuffling with each repetition. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4f00c7e0891d5c31b2c8a6e17b656882662f089" translate="yes" xml:space="preserve">
          <source>Shuts down a running a distributed TPU system.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc806c70d1611220fd7aeabffc0d3443c8d9ead0" translate="yes" xml:space="preserve">
          <source>Shuts down the TPU devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="653f9237345e8d0600d0ec6769702eee8a0052a9" translate="yes" xml:space="preserve">
          <source>Sigmoid activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a2ebe28a5b913a93292c6f412f0d6d3f3ef1e4c" translate="yes" xml:space="preserve">
          <source>Sigmoid is equivalent to a 2-element Softmax, where the second element is assumed to be zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69de1c17f59d07d87a7f26dd959bbed0c9e2517e" translate="yes" xml:space="preserve">
          <source>Signal processing operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60a6d3dc2068bbd0e202a705df4076defbac1a1c" translate="yes" xml:space="preserve">
          <source>Signature constants for SavedModel save and restore operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d756df7ce4459b133ef8b55a21a899c0ad61fbc4" translate="yes" xml:space="preserve">
          <source>SignatureDef utility functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dd975d808d1764b7c7f8ac983bc35a1fa661a03" translate="yes" xml:space="preserve">
          <source>Signatures are available in objects returned by &lt;a href=&quot;load&quot;&gt;&lt;code&gt;tf.saved_model.load&lt;/code&gt;&lt;/a&gt; as a &lt;code&gt;.signatures&lt;/code&gt; attribute. This is a reserved attribute: &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; on an object with a custom &lt;code&gt;.signatures&lt;/code&gt; attribute will raise an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dab261f335187b67b677777cdba885fb48cdddc8" translate="yes" xml:space="preserve">
          <source>Signatures associated with the SavedModel are available as functions:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="624f9b9b51fcc8c2cb3e5e2ecd0130f80784494b" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;numpy.assert_allclose&lt;/code&gt;, except tolerance depends on data type. This is due to the fact that &lt;code&gt;TensorFlow&lt;/code&gt; is often used with &lt;code&gt;32bit&lt;/code&gt;, &lt;code&gt;64bit&lt;/code&gt;, and even &lt;code&gt;16bit&lt;/code&gt; data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c87d10048c4cbad8372cf7d364561c0e72d785c8" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;parse_example&lt;/code&gt;, except:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4de3634c50466157902a321a02b640e31be54ca3" translate="yes" xml:space="preserve">
          <source>Similar to AdamOptimizer, the epsilon is added for numerical stability (especially to get rid of division by zero when v_t = 0).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e09d8883f82a81272daabf33772fad0fb0c8817e" translate="yes" xml:space="preserve">
          <source>Similar to the unidirectional case above (rnn) but takes input and builds independent forward and backward RNNs with the final forward and backward outputs depth-concatenated, such that the output will have the format [time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of forward and backward cell must match. The initial state for both directions is zero by default (but can be set optionally) and no intermediate states are ever returned -- the network is fully unrolled for the given (passed in) length(s) of the sequence(s) or completely unrolled if length(s) is not given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96173f43f9d1e4fc459561cb67357e147eabfef0" translate="yes" xml:space="preserve">
          <source>Similarly to initialize the whole line as keys and the line number as values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41e75f4217ba1a24afbe7a28f6325ea930c061df" translate="yes" xml:space="preserve">
          <source>Similarly, a sequence of &lt;code&gt;with_space_to_batch&lt;/code&gt; operations with identical (not uniformly 1) &lt;code&gt;dilation_rate&lt;/code&gt; parameters, &quot;SAME&quot; padding, and odd filter dimensions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="054ffb3d11e09da3aee30ad29c8d4f62a44cd16c" translate="yes" xml:space="preserve">
          <source>Similarly, for the following input of shape &lt;code&gt;[1 2 2 4]&lt;/code&gt;, and a block size of 2:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7109f8585ba165d9ea6569c12e4bf258fbfc4419" translate="yes" xml:space="preserve">
          <source>Similarly, for the following input of shape &lt;code&gt;[1 4 4 1]&lt;/code&gt;, and a block size of 2:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27aaa10f901b0745041dcdfe2c1fa5c22a8f5591" translate="yes" xml:space="preserve">
          <source>Similarly, if the regularizer is &lt;code&gt;None&lt;/code&gt; (the default), the default regularizer passed in the variable scope will be used (if that is &lt;code&gt;None&lt;/code&gt; too, then by default no regularization is performed).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db81e254d32ebfc457fd518e82be835eabb42976" translate="yes" xml:space="preserve">
          <source>Similarly, we raise an exception when trying to get a variable that does not exist in reuse mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b19adeccf3b4fca9b692f573cead18c7b6a60bb" translate="yes" xml:space="preserve">
          <source>Simpilfy creating loss and metrics for the train and test loop in Eager execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b623fadddbd419adf01bb1b94c77999b5aa2c2b" translate="yes" xml:space="preserve">
          <source>Simple example of how to create a new variable:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a5da838ff3165a207fd299af72846704817596b" translate="yes" xml:space="preserve">
          <source>Simple example of how to reenter a premade variable scope safely:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cab3d3babf94443c799382f4fccfd16541936062" translate="yes" xml:space="preserve">
          <source>Simple implementation of ClusterResolver that accepts a ClusterSpec.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6111f09e0dac798ce37b958000c7772f9a4fc90" translate="yes" xml:space="preserve">
          <source>Simple indexing into a matrix:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6ae8276e39b497fd17f4088846d89e28bba5559" translate="yes" xml:space="preserve">
          <source>Simplify writing model_fn and to make model_fn more configurable for Estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8315af54a6663133741824c0be422ac2397d08e" translate="yes" xml:space="preserve">
          <source>Since &lt;a href=&quot;../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; objects are also Trackable, this function can be used to export Keras models. For example, exporting with a signature specified:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="985151447a1d9d253acc12d655dc23bfee7a7e23" translate="yes" xml:space="preserve">
          <source>Since &lt;a href=&quot;fill&quot;&gt;&lt;code&gt;tf.fill&lt;/code&gt;&lt;/a&gt; does not embed the value, it can produce dynamically sized outputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e62738c37806ffe366436c3da479daa7dfcc7ff" translate="yes" xml:space="preserve">
          <source>Since RepaparameterizationType instances are constant static global instances, equality checks if two instances' id() values are equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c5ffebed7cf9ec80c72712271fcad69d30db523" translate="yes" xml:space="preserve">
          <source>Since it is only traced once, variables and state may be created inside the function and owned by the function wrapper object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ba257e987a6ec0d23383c4f65c48c3f5a7e84a6" translate="yes" xml:space="preserve">
          <source>Since python &amp;gt;= 3.5 the @ operator is supported (see &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt;). In TensorFlow, it simply calls the &lt;a href=&quot;../../linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul()&lt;/code&gt;&lt;/a&gt; function, so the following lines are equivalent:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b99374751d687608923563ea3ad3d8ae48b9e59a" translate="yes" xml:space="preserve">
          <source>Since python &amp;gt;= 3.5 the @ operator is supported (see &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt;). In TensorFlow, it simply calls the &lt;a href=&quot;linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul()&lt;/code&gt;&lt;/a&gt; function, so the following lines are equivalent:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33c43d8e2c8435ba1c70dd9f1c5833ddcd430b11" translate="yes" xml:space="preserve">
          <source>Since python &amp;gt;= 3.5 the @ operator is supported (see &lt;a href=&quot;https://www.python.org/dev/peps/pep-0465/&quot;&gt;PEP 465&lt;/a&gt;). In TensorFlow, it simply calls the &lt;a href=&quot;matmul&quot;&gt;&lt;code&gt;tf.matmul()&lt;/code&gt;&lt;/a&gt; function, so the following lines are equivalent:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c24586d747ff13c9898915f9c6e35375c327247" translate="yes" xml:space="preserve">
          <source>Since the DFT of a real signal is Hermitian-symmetric, &lt;code&gt;RFFT2D&lt;/code&gt; only returns the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the FFT for the inner-most dimension of &lt;code&gt;output&lt;/code&gt;: the zero-frequency term, followed by the &lt;code&gt;fft_length / 2&lt;/code&gt; positive-frequency terms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c097ba51429f68058eff266dfe6cc4cfcb58b9a" translate="yes" xml:space="preserve">
          <source>Since the DFT of a real signal is Hermitian-symmetric, &lt;code&gt;RFFT3D&lt;/code&gt; only returns the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the FFT for the inner-most dimension of &lt;code&gt;output&lt;/code&gt;: the zero-frequency term, followed by the &lt;code&gt;fft_length / 2&lt;/code&gt; positive-frequency terms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1e248daa91294df97613a89bf8b58086208a4f1" translate="yes" xml:space="preserve">
          <source>Since the DFT of a real signal is Hermitian-symmetric, &lt;code&gt;RFFT&lt;/code&gt; only returns the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the FFT: the zero-frequency term, followed by the &lt;code&gt;fft_length / 2&lt;/code&gt; positive-frequency terms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c67d048cd6c2913cd8d994cb1ded2c7adf3a8ba3" translate="yes" xml:space="preserve">
          <source>Since the function takes numpy arrays, you cannot take gradients through a numpy_function. If you require something that is differentiable, please consider using tf.py_function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9a68f1c294406fa4a8ecaa3e3461419d04f7f5b" translate="yes" xml:space="preserve">
          <source>Single TensorSpec or nested structure of TensorSpec objects, describing how the layer would transform the provided input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88fd65a1c7507102379f1c644b7234548a37e96b" translate="yes" xml:space="preserve">
          <source>Single or list of &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; which &lt;code&gt;func&lt;/code&gt; computes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc31f17d3be434d3691746b3f80ea4176a1c5e98" translate="yes" xml:space="preserve">
          <source>Single-input usage:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fc818dae3875a35fb808f116b7d884f4e5a68ca" translate="yes" xml:space="preserve">
          <source>Size entries in the specified shapes are checked against other entries by their &lt;strong&gt;hash&lt;/strong&gt;, except: - a size entry is interpreted as an explicit size if it can be parsed as an integer primitive. - a size entry is interpreted as &lt;em&gt;any&lt;/em&gt; size if it is None or '.'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2e425277c86cf87b08f16d6e85336a78993742d" translate="yes" xml:space="preserve">
          <source>Size of the last dimension of the logits &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a008fa4b1b36f74860c2b0319ada954a82d0026f" translate="yes" xml:space="preserve">
          <source>Skip the data if it is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5ea08df6d74ffe12d371d56e3535c8ca96d4047" translate="yes" xml:space="preserve">
          <source>Skip this test.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc3578c5f747f70325a17b79e89d9cd6ce54d02b" translate="yes" xml:space="preserve">
          <source>Slice a &lt;code&gt;SparseTensor&lt;/code&gt; based on the &lt;code&gt;start&lt;/code&gt; and `size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee71d16608227222a38300f09a56709ba50fac40" translate="yes" xml:space="preserve">
          <source>Slice indexing into a matrix:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3f2f860e7230e19be9c90ddaafa179acf158e07" translate="yes" xml:space="preserve">
          <source>Slices a shape &lt;code&gt;size&lt;/code&gt; portion out of &lt;code&gt;value&lt;/code&gt; at a uniformly chosen offset. Requires &lt;code&gt;value.shape &amp;gt;= size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dde09794c40b9ff8d5edc9bca08c6f0b4982af49" translate="yes" xml:space="preserve">
          <source>Slides a window of size &lt;code&gt;frame_length&lt;/code&gt; over &lt;code&gt;signal&lt;/code&gt;'s &lt;code&gt;axis&lt;/code&gt; dimension with a stride of &lt;code&gt;frame_step&lt;/code&gt;, replacing the &lt;code&gt;axis&lt;/code&gt; dimension with &lt;code&gt;[frames, frame_length]&lt;/code&gt; frames.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c1a16e17517d5db584e59f03e5701a1df0aec29" translate="yes" xml:space="preserve">
          <source>Slots</source>
          <target state="translated">Slots</target>
        </trans-unit>
        <trans-unit id="43d71da8d4d61956de0bee2c8031a772e572d8e9" translate="yes" xml:space="preserve">
          <source>Small helper to get the global step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cb7bde6d7a37e1c073124906d5e4a5a1de3cce9" translate="yes" xml:space="preserve">
          <source>So we will quantize input values in the range (-10, 9.921875) to (-128, 127).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c9d521a5361c2a4e0c8be9915daeeb347ef99b6" translate="yes" xml:space="preserve">
          <source>So, for example, in the following code</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd84a8e23b8d2ff2cbfa9622de69fe4f6a14dee2" translate="yes" xml:space="preserve">
          <source>Softmax activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="435a5fbd962f93b0e89d8a9426fbd39681b834f5" translate="yes" xml:space="preserve">
          <source>Softmax converts a real vector to a vector of categorical probabilities.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="249c1a48d4ec51326b792523af23da85663854be" translate="yes" xml:space="preserve">
          <source>Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8982e960ed4f330d0cb5926c5c4b221c348a553" translate="yes" xml:space="preserve">
          <source>Softmax of a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2202b3e41bb92b188bacbc372d323cfbcb9740a9" translate="yes" xml:space="preserve">
          <source>Softplus activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8df1d4d78a7aabc863e4139f21878e11ce36dd73" translate="yes" xml:space="preserve">
          <source>Softplus of a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43b8de4427acbb41005ce6b4afa9d4ea7a06be43" translate="yes" xml:space="preserve">
          <source>Softsign activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3823a5541395abfd11e5acd5bb48e38fef9b5479" translate="yes" xml:space="preserve">
          <source>Softsign of a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3351dcb01c7f12cd9e045a1b6aae29aac909ca39" translate="yes" xml:space="preserve">
          <source>Solution to &lt;code&gt;A x = rhs&lt;/code&gt;, shape &lt;code&gt;[..., M, K]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0579522c86b686853068caf06aebd1d1ae6f6310" translate="yes" xml:space="preserve">
          <source>Solve (exact or approx) &lt;code&gt;R&lt;/code&gt; (batch) systems of equations: &lt;code&gt;A X = rhs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4c2e52438cd935f70a74acd4d38768b01e1a684" translate="yes" xml:space="preserve">
          <source>Solve single equation with best effort: &lt;code&gt;A X = rhs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30b5f81be63f62e7ed07c97f7610ff7e0335f79c" translate="yes" xml:space="preserve">
          <source>Solves and determinants will be attempted unless the &quot;is_non_singular&quot; property of L and D is False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cef513b85495a63c763aa1ff3fe9333568ffc35d" translate="yes" xml:space="preserve">
          <source>Solves one or more linear least-squares problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24624018f5a4d5f829f115776528e0a470a298b2" translate="yes" xml:space="preserve">
          <source>Solves systems of linear eqns &lt;code&gt;A X = RHS&lt;/code&gt;, given Cholesky factorizations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68140ca3dee6c8c6fa35ce72695917b227b59d2e" translate="yes" xml:space="preserve">
          <source>Solves systems of linear eqns &lt;code&gt;A X = RHS&lt;/code&gt;, given LU factorizations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8db83c4672e0b070edd5ca0add3871905385cc13" translate="yes" xml:space="preserve">
          <source>Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ac71fd5f2af5c2c74118e3fda788f2d57c82bcb" translate="yes" xml:space="preserve">
          <source>Solves systems of linear equations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86ed1050cfe36e63b5ab748299b6d79ebedba8a7" translate="yes" xml:space="preserve">
          <source>Solves tridiagonal systems of equations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="233c464b3700ed0d67632d8ee7a7f1c70df38bb6" translate="yes" xml:space="preserve">
          <source>Some &lt;code&gt;Optimizer&lt;/code&gt; subclasses use additional variables. For example &lt;code&gt;Momentum&lt;/code&gt; and &lt;code&gt;Adagrad&lt;/code&gt; use variables to accumulate updates. This method gives access to these &lt;code&gt;Variable&lt;/code&gt; objects if for some reason you need them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8a5c8d8f8398cf8f49b3a4c453c5a68d4c865e" translate="yes" xml:space="preserve">
          <source>Some distributions do not have well-defined statistics for all initialization parameter values. For example, the beta distribution is parameterized by positive real numbers &lt;code&gt;concentration1&lt;/code&gt; and &lt;code&gt;concentration0&lt;/code&gt;, and does not have well-defined mode if &lt;code&gt;concentration1 &amp;lt; 1&lt;/code&gt; or &lt;code&gt;concentration0 &amp;lt; 1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c48b1d1e86f2b2608be9d7366644d3071986fef" translate="yes" xml:space="preserve">
          <source>Some examples below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01706013cfdbcb0fc543d3c97784f3f4c235d630" translate="yes" xml:space="preserve">
          <source>Some examples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5888e34897c8c7e5c512a504808b2aefe317599c" translate="yes" xml:space="preserve">
          <source>Some losses (for instance, activity regularization losses) may be dependent on the inputs passed when calling a layer. Hence, when reusing the same layer on different inputs &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, some entries in &lt;code&gt;layer.losses&lt;/code&gt; may be dependent on &lt;code&gt;a&lt;/code&gt; and some on &lt;code&gt;b&lt;/code&gt;. This method automatically keeps track of dependencies.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64f905b7f1fcde32b3aea4717774e00ef6c12c19" translate="yes" xml:space="preserve">
          <source>Some notes on passing Callables to customize splitting and normalization for this layer: 1) Any callable can be passed to this Layer, but if you want to serialize this object you should only pass functions that are registered Keras serializables (see &lt;a href=&quot;../../../utils/register_keras_serializable&quot;&gt;&lt;code&gt;tf.keras.utils.register_keras_serializable&lt;/code&gt;&lt;/a&gt; for more details). 2) When using a custom callable for &lt;code&gt;standardize&lt;/code&gt;, the data recieved by the callable will be exactly as passed to this layer. The callable should return a tensor of the same shape as the input. 3) When using a custom callable for &lt;code&gt;split&lt;/code&gt;, the data recieved by the callable will have the 1st dimension squeezed out - instead of &lt;code&gt;[[&quot;string to split&quot;], [&quot;another string to split&quot;]]&lt;/code&gt;, the Callable will see &lt;code&gt;[&quot;string to split&quot;, &quot;another string to split&quot;]&lt;/code&gt;. The callable should return a Tensor with the first dimension containing the split tokens - in this example, we should see something like &lt;code&gt;[[&quot;string&quot;, &quot;to&quot;, &quot;split], [&quot;another&quot;, &quot;string&quot;, &quot;to&quot;, &quot;split&quot;]]&lt;/code&gt;. This makes the callable site natively compatible with &lt;a href=&quot;../../../../strings/split&quot;&gt;&lt;code&gt;tf.strings.split()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feb7b4ee12e100be2f687c1c0bcffc79014d8346" translate="yes" xml:space="preserve">
          <source>Some of the args below are hyperparameters, where a hyperparameter is defined as a scalar Tensor, a regular Python value, or a callable (which will be evaluated when &lt;code&gt;apply_gradients&lt;/code&gt; is called) returning a scalar Tensor or a Python value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11f76fcf688ca010a98217641ecd535f27ce8159" translate="yes" xml:space="preserve">
          <source>Some operations may raise this error when passed otherwise-valid arguments that it does not currently support. For example, running the &lt;a href=&quot;../nn/max_pool2d&quot;&gt;&lt;code&gt;tf.nn.max_pool2d&lt;/code&gt;&lt;/a&gt; operation would raise this error if pooling was requested on the batch dimension, because this is not yet supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20cef832e1649a427e222d654a87a81502c3b58e" translate="yes" xml:space="preserve">
          <source>Some optimizations may come at the cost of accuracy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eea1875658d39629200b30d5f8a835b05524f8c2" translate="yes" xml:space="preserve">
          <source>Some optimizer subclasses, such as &lt;code&gt;MomentumOptimizer&lt;/code&gt; and &lt;code&gt;AdagradOptimizer&lt;/code&gt; allocate and manage additional variables associated with the variables to train. These are called</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8116995a516d4171a76880af533d292c0bbc2e45" translate="yes" xml:space="preserve">
          <source>Some resource has been exhausted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0a1011ddf516ad6ec7be68cafcf80c7f137789d" translate="yes" xml:space="preserve">
          <source>Some useful examples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f25ae134af3b43a3a1105e6fe76023fec8620e82" translate="yes" xml:space="preserve">
          <source>Some useful partitioners are available. See, e.g., &lt;code&gt;variable_axis_size_partitioner&lt;/code&gt; and &lt;code&gt;min_max_variable_partitioner&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="667cf0b7e45f4e36e4bea2c73c06b38bafc26add" translate="yes" xml:space="preserve">
          <source>Sorts a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f620b61bc526606d7744ac5849b8a20527d8358e" translate="yes" xml:space="preserve">
          <source>Source Datasets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7cc83312e2a1c912c21eec7771b4fd2244b10c4" translate="yes" xml:space="preserve">
          <source>Source: &quot;Searching for Activation Functions&quot; (Ramachandran et al. 2017) https://arxiv.org/abs/1710.05941</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb6aebda039a15f53e457e68d7d438b1cff01ed3" translate="yes" xml:space="preserve">
          <source>Source: &lt;a href=&quot;http://www.cs.utoronto.ca/%7Ekriz/conv-cifar10-aug2010.pdf&quot;&gt;Convolutional Deep Belief Networks on CIFAR-10. A. Krizhevsky&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d171992414a7599766d9131cfb8c37f4925b830" translate="yes" xml:space="preserve">
          <source>Source: &lt;a href=&quot;https://ai.stanford.edu/%7Eamaas/papers/relu_hybrid_icml2013_final.pdf&quot;&gt;Rectifier Nonlinearities Improve Neural Network Acoustic Models. AL Maas, AY Hannun, AY Ng - Proc. ICML, 2013&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b607ebb0ce412857986816d3db8a881d545fbfc" translate="yes" xml:space="preserve">
          <source>SpaceToBatch for 4-D tensors of type T.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="083730c076520c06f329b3a1d05a2c9ceace46aa" translate="yes" xml:space="preserve">
          <source>SpaceToBatch for N-D tensors of type T.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70947ab2fc979f29296aaef123d22483ba02139e" translate="yes" xml:space="preserve">
          <source>SpaceToDepth for tensors of type T.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b32e033310ebd5e93b4041f5df9964210ade963a" translate="yes" xml:space="preserve">
          <source>Sparse Tensor Representation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="069a9228c751a538f52a392a1cd0e50f26fac743" translate="yes" xml:space="preserve">
          <source>Sparse gradients are represented by &lt;code&gt;IndexedSlices&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b4c1d1909f9bc68a995624a409254a398966f07" translate="yes" xml:space="preserve">
          <source>SparseTensor is not supported. The return value of the decorated function must be a Tensor or a list/tuple of Tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1ffd7ce11921ece1834d4731c951cc910508d1f" translate="yes" xml:space="preserve">
          <source>SparseTensor referred by first key:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c32b414e828af630366a2f4a79388908c22a788" translate="yes" xml:space="preserve">
          <source>SparseTensor referred by second key:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa5e3369b1a543faf6701e41ac2ec3d01253f981" translate="yes" xml:space="preserve">
          <source>SparseTensorValue(indices, values, dense_shape)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ee93c8da33edf23834992d6432a8f0e409815de" translate="yes" xml:space="preserve">
          <source>Spatial 1D version of Dropout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44ada72cd6d79ae9c07a9cb3d7a9ed46bb7aa114" translate="yes" xml:space="preserve">
          <source>Spatial 2D version of Dropout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b491fa379bdaddd72ebc9a3730d0e2efd96f9bc" translate="yes" xml:space="preserve">
          <source>Spatial 3D version of Dropout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3f29e68c2f47d80899bc4477479be5589b1d283" translate="yes" xml:space="preserve">
          <source>Special math functions (like: &lt;a href=&quot;../../math/igamma&quot;&gt;&lt;code&gt;tf.math.igamma&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../math/zeta&quot;&gt;&lt;code&gt;tf.math.zeta&lt;/code&gt;&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42e77439e21bd348d1d9ca7ffa4988277cfd7529" translate="yes" xml:space="preserve">
          <source>Special math functions (like: &lt;a href=&quot;math/igamma&quot;&gt;&lt;code&gt;tf.math.igamma&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;math/zeta&quot;&gt;&lt;code&gt;tf.math.zeta&lt;/code&gt;&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7001c1ac0b17fbd7ca3a02ab7f20b52959b8e41" translate="yes" xml:space="preserve">
          <source>Specifically, &lt;code&gt;y = 1 / (1 + exp(-x))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="954c9de28a55b63501fe0fe04e4bf1cb501e7df5" translate="yes" xml:space="preserve">
          <source>Specifically, &lt;code&gt;y = log(1 / (1 + exp(-x)))&lt;/code&gt;. For numerical stability, we use &lt;code&gt;y = -tf.nn.softplus(-x)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6597172c93c2b702bcd7586ce5fa7c1bf3b6fa02" translate="yes" xml:space="preserve">
          <source>Specifically, in the case that &lt;code&gt;data_format&lt;/code&gt; does not start with &quot;NC&quot;, given a rank (N+2) &lt;code&gt;input&lt;/code&gt; Tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4685e2fad46095eee9ba25a53c669f27eb8ab429" translate="yes" xml:space="preserve">
          <source>Specifically, returns &lt;code&gt;True&lt;/code&gt; if the dtype of &lt;code&gt;tensor&lt;/code&gt; is one of the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0556709f41308a40346ba1c586e66a03dc18eabe" translate="yes" xml:space="preserve">
          <source>Specifically, the op extracts patches of shape &lt;code&gt;sizes&lt;/code&gt; which are &lt;code&gt;strides&lt;/code&gt; apart in the input image. The output is subsampled using the &lt;code&gt;rates&lt;/code&gt; argument, in the same manner as &quot;atrous&quot; or &quot;dilated&quot; convolutions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fae6543b085f90e9db03167ac9f6f9969607441e" translate="yes" xml:space="preserve">
          <source>Specifically, this function implements single-machine multi-GPU data parallelism. It works in the following way:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c8f3483a76d71d8bb0d00a6d0eabe91ca24c35a" translate="yes" xml:space="preserve">
          <source>Specification of target device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea883e74b6a3843ac1a29b4ff2add9d3a018b23d" translate="yes" xml:space="preserve">
          <source>Specifies a TensorFlow value type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50ddb4ee8c52d872568fecc64ff41f8830ff5dee" translate="yes" xml:space="preserve">
          <source>Specifies that a flag is a key flag for a module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60e17bd62fb185088c8acaab226bfbeedef8f34c" translate="yes" xml:space="preserve">
          <source>Specifies that ops of type &lt;code&gt;op_type&lt;/code&gt; is not differentiable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="847ad11bfeecb8d48ed0c0033c02e5d0d9d05fd9" translate="yes" xml:space="preserve">
          <source>Specifies the device for ops created/executed in this context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a23f6051fc3fbb5815e141c943efca771d21b5b9" translate="yes" xml:space="preserve">
          <source>Specifies the ndim, dtype and shape of every input to a layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17dc1bc89affaacc3206c6d8f591c91199d8edfc" translate="yes" xml:space="preserve">
          <source>Specifies whether operations are executed synchronously or asynchronously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86a70a978ffb3c314d3fa9e073f9f1ebb89c519c" translate="yes" xml:space="preserve">
          <source>Specifies which &lt;code&gt;PhysicalDevice&lt;/code&gt; objects are visible to the runtime. TensorFlow will only allocate memory and place operations on visible physical devices, as otherwise no &lt;code&gt;LogicalDevice&lt;/code&gt; will be created on them. By default all discovered devices are marked as visible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1dc8e11dd50b0215e624b3b32a9d0f31a9f6f8b" translate="yes" xml:space="preserve">
          <source>Specify tensors to watch and their Jacobian-vector products.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5641c8d22b21d1e9602ce014b4719ee01c9c37b" translate="yes" xml:space="preserve">
          <source>Specifying &lt;code&gt;''&lt;/code&gt; requests an in-process session that does not use RPC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="405b7de568617cf3ae840e38096fa116bfa8c971" translate="yes" xml:space="preserve">
          <source>Specifying &lt;code&gt;'grpc://hostname:port'&lt;/code&gt; requests a session that uses the RPC interface to a specific host, and also allows the in-process master to access remote tensorflow workers. Often, it is appropriate to pass &lt;code&gt;server.target&lt;/code&gt; (for some &lt;a href=&quot;../../../distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; named `server).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26bd73b0bd8bb18d70c2dc4595792f67ad9856b4" translate="yes" xml:space="preserve">
          <source>Specifying &lt;code&gt;'local'&lt;/code&gt; requests a session that uses the RPC-based &quot;Master interface&quot; to run TensorFlow programs. See &lt;code&gt;tf.train.Server.create_local_server&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8d93b14898782206a27c2f623c3e13068558d40" translate="yes" xml:space="preserve">
          <source>Split a &lt;code&gt;SparseTensor&lt;/code&gt; into &lt;code&gt;num_split&lt;/code&gt; tensors along &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48c476197d75a69934319a7ec0da01331434b536" translate="yes" xml:space="preserve">
          <source>Split a &lt;code&gt;SparseTensor&lt;/code&gt; into &lt;code&gt;num_split&lt;/code&gt; tensors along &lt;code&gt;axis&lt;/code&gt;. (deprecated arguments)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da7b9513b11ddbf83b6b96223d58f5a656aa657d" translate="yes" xml:space="preserve">
          <source>Split elements of &lt;code&gt;input&lt;/code&gt; based on &lt;code&gt;sep&lt;/code&gt; into a &lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58404bb00065199a0e549c463f07be748d39a794" translate="yes" xml:space="preserve">
          <source>Split elements of &lt;code&gt;input&lt;/code&gt; based on &lt;code&gt;sep&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48ef48c846fb000283c6182d2a2c88def70c9079" translate="yes" xml:space="preserve">
          <source>Split elements of &lt;code&gt;source&lt;/code&gt; based on &lt;code&gt;delimiter&lt;/code&gt;. (deprecated arguments)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feeb0afbc717961d923c1bb6d0a2cbd2235c11fc" translate="yes" xml:space="preserve">
          <source>Split string elements of &lt;code&gt;input&lt;/code&gt; into bytes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ec109a46f53e7a89dab4ee2f80314ae2e476dd5" translate="yes" xml:space="preserve">
          <source>Split the values of a &lt;code&gt;Tensor&lt;/code&gt; into the TensorArray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2525a2c7ac0234994f7780711bb8b426b3f60464" translate="yes" xml:space="preserve">
          <source>Splits a tensor into sub tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d43c36bbfca1a538b2005f5a195827db6f584b5" translate="yes" xml:space="preserve">
          <source>Splits each rank-N &lt;a href=&quot;../../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt; in this dataset row-wise. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2558021e23f8309108fd307b098699b10771f98" translate="yes" xml:space="preserve">
          <source>Splits each rank-N &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt; in this dataset row-wise. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4d1aaee79561119dd0a5d338e2a7ca4f1422ce7" translate="yes" xml:space="preserve">
          <source>Splits each string in &lt;code&gt;input&lt;/code&gt; into a sequence of Unicode code points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94584a38ee61d0af4ef0ac0752e5ef4eaa3d1dc9" translate="yes" xml:space="preserve">
          <source>Splits each string into a sequence of code points with start offsets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c47b3f827bb53db64e834684eba00cbf35296512" translate="yes" xml:space="preserve">
          <source>Splits elements of a dataset into multiple elements on the batch dimension. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8bd28acaf2b895effd8654557c3dacbebf4a2c4" translate="yes" xml:space="preserve">
          <source>Splits elements of a dataset into multiple elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3dcf86335eb4dcd9df560b318acb47a8f5d257d" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank &lt;code&gt;R&lt;/code&gt; tensors into a rank &lt;code&gt;R+1&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8f192bcec355d760ffbcfb5d4356d125221a71c" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank-&lt;code&gt;R&lt;/code&gt; tensors into one rank-&lt;code&gt;(R+1)&lt;/code&gt; tensor in parallel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="411d8e2a06e5fa2c606474dc5fbe557c7d2ba8bb" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank-&lt;code&gt;R&lt;/code&gt; tensors into one rank-&lt;code&gt;(R+1)&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07a81968a5e580e3ddc7f3c1dfe616f113f25eb2" translate="yes" xml:space="preserve">
          <source>Stacks a list of rank-&lt;code&gt;R&lt;/code&gt; tensors into one rank-&lt;code&gt;(R+1)&lt;/code&gt;&lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="244b873bd8fa37f33bd8c2425d0c77e7748a72b7" translate="yes" xml:space="preserve">
          <source>Stacks dynamic partitions of a Tensor or RaggedTensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c79e6e247019a81999cc68e49d7a710622176286" translate="yes" xml:space="preserve">
          <source>Standard deviation is defined as,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="055d92b4a3c41965fe47264346978d7a3185cce9" translate="yes" xml:space="preserve">
          <source>Standard deviation of a tensor, alongside the specified axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df9f5f66c6d3882cf2305d67d9a9474489134d03" translate="yes" xml:space="preserve">
          <source>Standard deviation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f057b861993d91873adb8d03059b68337b2c76e0" translate="yes" xml:space="preserve">
          <source>Standard names for Estimator model modes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f99c39141bb3ddf1a7d22eeab71658b76e3cad1" translate="yes" xml:space="preserve">
          <source>Standard names to use for graph collections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="594ca634eb315bc3997ded1357b2f6c715d7772e" translate="yes" xml:space="preserve">
          <source>Start a LooperThread that calls a function periodically.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15aa8e658d8f3e8d9e2bcd223fef378355b8f614" translate="yes" xml:space="preserve">
          <source>Start a step: fetch variables and compute gradients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08ad0056ecc29209217961803b2e9f7137506856" translate="yes" xml:space="preserve">
          <source>Start by either creating a &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; normally or using &lt;code&gt;tf.distribute.experimental_make_numpy_dataset&lt;/code&gt; to make a dataset out of a &lt;code&gt;numpy&lt;/code&gt; array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d86e406e531f06a60d2dee1e4984ec027b2308d0" translate="yes" xml:space="preserve">
          <source>Start the next batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faf298f1e87c04adba60787926533cc120075122" translate="yes" xml:space="preserve">
          <source>Start the scope block.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cbf1285faa03571413d56c285dbab6cefc1bca8" translate="yes" xml:space="preserve">
          <source>Start the standard services for 'sess'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6981642129cbd20083e772ec5f952609a47be106" translate="yes" xml:space="preserve">
          <source>Start the thread's activity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83b5898849275d244f9dc1b3986f7cb88a3fa122" translate="yes" xml:space="preserve">
          <source>Start threads for &lt;code&gt;QueueRunners&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edf1fcfb7060b839d58846461c7fe9ea1192ffb9" translate="yes" xml:space="preserve">
          <source>Starts a trace to record computation graphs and profiling information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="817af290c476c6f8d3234f21fb9c38bd1fc07a8f" translate="yes" xml:space="preserve">
          <source>Starts all queue runners collected in the graph. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8263038cce7fa6e464120a6a80cc9bb67343087c" translate="yes" xml:space="preserve">
          <source>Starts reading from current position in file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e91bf74af9bf0945d6f92cab271e149069e0083c" translate="yes" xml:space="preserve">
          <source>Starts the handler's workers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4baf635ff2545da5d38edb917b754f17529ea58" translate="yes" xml:space="preserve">
          <source>Starts this server.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4342bc56c343c89819e7b2431ab23a0028e31c50" translate="yes" xml:space="preserve">
          <source>Stateful operations, such as variables and queues, can maintain their states on devices so that they can be shared by multiple processes. A resource container is a string name under which these stateful operations are tracked. These resources can be released or cleared with &lt;code&gt;tf.Session.reset()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2656236f800a76ebc0f7b49c14ff22e2c68fde8c" translate="yes" xml:space="preserve">
          <source>Static assert that values is a &quot;proper&quot; iterable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffa05fac8dc7f5a7d7afa20754fed148f2437c90" translate="yes" xml:space="preserve">
          <source>Statically asserts that the given &lt;code&gt;Tensor&lt;/code&gt; is of the specified type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60df8ae87178e3ec5ce8d8d0fa30901d76174405" translate="yes" xml:space="preserve">
          <source>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)**2] is also undefined.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22071530d6c4d9de4a3df64a6b62d022124955f6" translate="yes" xml:space="preserve">
          <source>Steps 2 through 4 are done automatically by class &lt;a href=&quot;../../../keras/optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; if you call its &lt;a href=&quot;../../../keras/optimizers/optimizer#apply_gradients&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer.apply_gradients&lt;/code&gt;&lt;/a&gt; method in a replica context. They are also done automatically if you call an &lt;code&gt;assign*&lt;/code&gt; method on a (non sync-on-read) variable that was constructed with an aggregation method (which is used to determine the reduction used in step 3).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f210a94770e322853957792583d184bd18568f9b" translate="yes" xml:space="preserve">
          <source>Steps 2 through 4 are done automatically by class &lt;a href=&quot;../keras/optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; if you call its &lt;a href=&quot;../keras/optimizers/optimizer#apply_gradients&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer.apply_gradients&lt;/code&gt;&lt;/a&gt; method in a replica context. They are also done automatically if you call an &lt;code&gt;assign*&lt;/code&gt; method on a (non sync-on-read) variable that was constructed with an aggregation method (which is used to determine the reduction used in step 3).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85a411ea2f2761d1ddcb88eb51ad0e8e10187389" translate="yes" xml:space="preserve">
          <source>Stochastic Dual Coordinate Ascent helper for linear estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5db97c77f8ae58c61c9d9965b48bf1937ae6418f" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent and momentum optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="133b83393780c8ea9a29cf07bcedf37ff11c6738" translate="yes" xml:space="preserve">
          <source>Stop condition: In order to support both distributed and non-distributed configuration reliably, the only supported stop condition for model training is &lt;code&gt;train_spec.max_steps&lt;/code&gt;. If &lt;code&gt;train_spec.max_steps&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the model is trained forever. &lt;em&gt;Use with care&lt;/em&gt; if model stop condition is different. For example, assume that the model is expected to be trained with one epoch of training data, and the training &lt;code&gt;input_fn&lt;/code&gt; is configured to throw &lt;code&gt;OutOfRangeError&lt;/code&gt; after going through one epoch, which stops the &lt;a href=&quot;../compat/v1/estimator/estimator#train&quot;&gt;&lt;code&gt;Estimator.train&lt;/code&gt;&lt;/a&gt;. For a three-training-worker distributed configuration, each training worker is likely to go through the whole epoch independently. So, the model will be trained with three epochs of training data instead of one epoch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b73c19e56bb305894a3de5407fb01e4f9a8fe89" translate="yes" xml:space="preserve">
          <source>Stop the services and the coordinator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acaf908480f4f7513719d5d37193f12e822e8df4" translate="yes" xml:space="preserve">
          <source>Stop training when a monitored quantity has stopped improving.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5492e7af5bc227efd8741534cde9d83c515b2fee" translate="yes" xml:space="preserve">
          <source>StopIteration</source>
          <target state="translated">StopIteration</target>
        </trans-unit>
        <trans-unit id="7ca958edd4ae9334803b83d98f9fa435aceacaef" translate="yes" xml:space="preserve">
          <source>Stops and exports the active trace as a Summary and/or profile file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55a9229e4f89292e865188cb6a0d2d8542aff987" translate="yes" xml:space="preserve">
          <source>Stops gradient computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4e14f4106f6a3870d0e38ef853369d42ee937fd" translate="yes" xml:space="preserve">
          <source>Stops running threads and wait for them to exit, if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b208b5f31ff1c56cafbcbee9b5e3c8091431b21" translate="yes" xml:space="preserve">
          <source>Stops the current trace and discards any collected information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d87fc3a0f3a70413df9f203b126effeeeda2c89" translate="yes" xml:space="preserve">
          <source>Stops the trace and exports all metadata collected during the trace to the default SummaryWriter, if one has been set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="498891dd84278fabc1afd5025cb9d7776029cb2e" translate="yes" xml:space="preserve">
          <source>Stores &lt;code&gt;value&lt;/code&gt; in the collection with the given &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7487de8aca0f8eb26902fa7d5921abad1adb56f6" translate="yes" xml:space="preserve">
          <source>Stores &lt;code&gt;value&lt;/code&gt; in the collections given by &lt;code&gt;names&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8ad5005cffff07e7ce60dc5e8a6e835ce897462" translate="yes" xml:space="preserve">
          <source>Stores two elements: &lt;code&gt;(c, h)&lt;/code&gt;, in that order. Where &lt;code&gt;c&lt;/code&gt; is the hidden state and &lt;code&gt;h&lt;/code&gt; is the output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dae3f8a26c540bddc508bd4fc20a264913a3400" translate="yes" xml:space="preserve">
          <source>Strict nesting also applies to combinations of &lt;code&gt;ForwardAccumulator&lt;/code&gt; and &lt;a href=&quot;../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. More deeply nested &lt;code&gt;GradientTape&lt;/code&gt; objects will ignore the products of outer &lt;code&gt;ForwardAccumulator&lt;/code&gt; objects. This allows (for example) memory-efficient forward-over-backward computation of Hessian-vector products, where the inner &lt;code&gt;GradientTape&lt;/code&gt; would otherwise hold on to all intermediate JVPs:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1491a3bd88f9e10c7ce3a5a0f1112506bd8f631c" translate="yes" xml:space="preserve">
          <source>String denoting the name attribute of the input function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b4c8e7832ea4bb28fb1ecea1eb04c21acf3235a" translate="yes" xml:space="preserve">
          <source>String lengths of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c2aad5c6a931d4c7513d72ecffc8d9eb68b3cc5" translate="yes" xml:space="preserve">
          <source>String paths to latest checkpoint files as they arrive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aeb494b5d1b54f48ea849048d1edcfe06dd51044" translate="yes" xml:space="preserve">
          <source>String to Id table wrapper that assigns out-of-vocabulary keys to buckets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaa81af7916f61c4c8df3b14acde35215be76a44" translate="yes" xml:space="preserve">
          <source>String, dtype of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea9f5b6cc332ffad44ba87818cd1c1307282d6c3" translate="yes" xml:space="preserve">
          <source>String, path to the saved model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0a3d9cd808b86047665f49535c974af481846b3" translate="yes" xml:space="preserve">
          <source>String, path where to save the model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54bc218b3ac398424451a14065ba255b110489cd" translate="yes" xml:space="preserve">
          <source>String, the current default float type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57e5867b01bfc07f9eb74efe89e78ace68c7ff5a" translate="yes" xml:space="preserve">
          <source>String: name of an optimizer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4783a53435e04475242288debdaae1f5d02699bf" translate="yes" xml:space="preserve">
          <source>Strings.</source>
          <target state="translated">Strings.</target>
        </trans-unit>
        <trans-unit id="66bf723a15be4c8e82544fa8db7d3459828330ba" translate="yes" xml:space="preserve">
          <source>Strip leading and trailing whitespaces from the Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f350b1261d4080472d67731c5c9e2f0603eeb906" translate="yes" xml:space="preserve">
          <source>Structure to create or gather pieces commonly needed to train a model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c98ab4418a813d6b943f2b02fac0d62645ae018" translate="yes" xml:space="preserve">
          <source>Student's t-distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ffaefd8b7f218faf62448be773733b362a94c3c" translate="yes" xml:space="preserve">
          <source>Subclasses are expected to implement a leading-underscore version of the same-named function. The argument signature should be identical except for the omission of &lt;code&gt;name=&quot;...&quot;&lt;/code&gt;. For example, to enable &lt;code&gt;log_prob(value, name=&quot;log_prob&quot;)&lt;/code&gt; a subclass should implement &lt;code&gt;_log_prob(value)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a6721e7c506f9fb97672ded9cc77a3beb182cd0" translate="yes" xml:space="preserve">
          <source>Subclasses can append to public-level docstrings by providing docstrings for their method specializations. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7aec789137a8d9a01ede9775ea920d915b4cb613" translate="yes" xml:space="preserve">
          <source>Subclasses of &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt; can also take advantage of the &lt;code&gt;_flatten&lt;/code&gt; method which can be used to implement tracking of any other types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6710338017625456fa4561184c0ed0ef98bc5b38" translate="yes" xml:space="preserve">
          <source>Subclasses of &lt;code&gt;LinearOperator&lt;/code&gt; provide access to common methods on a (batch) matrix, without the need to materialize the matrix. This allows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42876d8a9661050716824a58ac5a82c08c248d20" translate="yes" xml:space="preserve">
          <source>Subclasses should also define a syntactic_help string which may be presented to the user to describe the form of the legal values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aea78081ca45ef2980de5a15e286ad2bbda54156" translate="yes" xml:space="preserve">
          <source>Subclasses should only implement the assert methods (e.g. &lt;code&gt;assert_non_singular&lt;/code&gt;) if they can be done in less than &lt;code&gt;O(N^3)&lt;/code&gt; time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf637286e0e32e92c7c31e4552b50b7fae1598ef" translate="yes" xml:space="preserve">
          <source>Subclasses should override class method &lt;code&gt;_param_shapes&lt;/code&gt; to return constant-valued tensors when constant values are fed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37df94753f92ace08cbf9f39640c831c989de432" translate="yes" xml:space="preserve">
          <source>Subclasses should override class method &lt;code&gt;_param_shapes&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ce7d0131be24554322a374d91443a37c9bff932" translate="yes" xml:space="preserve">
          <source>Subclasses should override for any actions to run.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7a01ff259fb1b5c2717e8c75756ea59f3bfc673" translate="yes" xml:space="preserve">
          <source>Subclasses should override for any actions to run. This function should only be called during TRAIN mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82494d5df2327066831b19fcbdbc11f57f406da0" translate="yes" xml:space="preserve">
          <source>Subclassing</source>
          <target state="translated">Subclassing</target>
        </trans-unit>
        <trans-unit id="4ee2b1df95332be247a338e3703c536ed3849d29" translate="yes" xml:space="preserve">
          <source>Submodules are modules which are properties of this module, or found as properties of modules which are properties of this module (and so on).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="165eb6fe055989673d9f7ff7fc05154aebafbb3c" translate="yes" xml:space="preserve">
          <source>Subtracts &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; from this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f35f0686291951a05d8c56e0435069d27921f5e4" translate="yes" xml:space="preserve">
          <source>Subtracts &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; from this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="862f9417a21c1ab694eec964a2530921649cc05a" translate="yes" xml:space="preserve">
          <source>Subtracts a value from this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="533efd56cc6494d580885f7e5b88d2e19d328bec" translate="yes" xml:space="preserve">
          <source>Subtracts sparse &lt;code&gt;updates&lt;/code&gt; from an existing tensor according to &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7f817b1800d31c4059e5eec01c90ea508fa2de1" translate="yes" xml:space="preserve">
          <source>Subtracts sparse updates to a variable reference.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffab6af063b75339c2da62f252c5b9fd21c5a8b2" translate="yes" xml:space="preserve">
          <source>Such a boolean flag does not take an argument. If a user wants to specify a false value explicitly, the long option beginning with 'no' must be used: i.e. --noflag</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a79dcd29d4b3b6000264a88496dc0b21c3bb9bd" translate="yes" xml:space="preserve">
          <source>Suitable for passing to &lt;a href=&quot;checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt; to resume training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0767ec9c89c14ac885f6aac10f61d8b491a9b0fe" translate="yes" xml:space="preserve">
          <source>Sum of concentration parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e620e3b949e70befef0ae092fde25014ac70320" translate="yes" xml:space="preserve">
          <source>Sum of last dim of concentration parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="828ac024d0a463272c3865c79e2c0bf52a749629" translate="yes" xml:space="preserve">
          <source>Sum of the values in a tensor, alongside the specified axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="099c5812d8fa488a0e61fa106c074634bb1f9d7f" translate="yes" xml:space="preserve">
          <source>Sum the input tensor across replicas according to group_assignment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10af7e4de27c05194aa88c5baa285ca841cf04ab" translate="yes" xml:space="preserve">
          <source>Sum the weights of false positives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a3284e36f760f4254131fea54732c3ba499239f" translate="yes" xml:space="preserve">
          <source>Sum the weights of true_negatives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42dd5be548c1e47f53fdb48f3d5c971ee04367e9" translate="yes" xml:space="preserve">
          <source>Sum the weights of true_positives.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8333177a21c8e3581d5ed83f3b343cfae98cec5f" translate="yes" xml:space="preserve">
          <source>Summarizes textual data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b079c2d8619aadef5a47beee8545f1de33276597" translate="yes" xml:space="preserve">
          <source>Support class for stubbing methods out for unit testing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c570510ec02530b48ce8c6a2822119f29cc294e" translate="yes" xml:space="preserve">
          <source>Support for training models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f45023b45c5bcb0e2e566e86c212c8ad3099045" translate="yes" xml:space="preserve">
          <source>Support wide range of machine learning models. Since most heads can work with logits, they can support DNN, RNN, Wide, Wide&amp;amp;Deep, Global objectives, Gradient boosted trees and many other types of machine learning models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ca7b2b776a1a659ec26ed62726c8ba0fc984e92" translate="yes" xml:space="preserve">
          <source>Supported Python entities include: * functions * classes * object methods</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ce9158bd839abeef632632d7ada1c1f6e0c0ccf" translate="yes" xml:space="preserve">
          <source>Supported attribute includes micros, bytes, occurrence, params, etc. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9794d24ec85271049a86498f820c37d015564882" translate="yes" xml:space="preserve">
          <source>Supported types</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abd5978641e98b805d5cc09691807cae3f3387cc" translate="yes" xml:space="preserve">
          <source>Supports all values that can be represented as a string, including 1D iterables such as np.ndarray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="104d684cf03eff52e2dbd8ee731bf94a0c3b8a59" translate="yes" xml:space="preserve">
          <source>Supports custom &lt;code&gt;loss_fn&lt;/code&gt;. &lt;code&gt;loss_fn&lt;/code&gt; takes &lt;code&gt;(labels, logits)&lt;/code&gt; or &lt;code&gt;(labels, logits, features, loss_reduction)&lt;/code&gt; as arguments and returns unreduced loss with shape &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a316cf92878313bf869404b90ceec201fde29a87" translate="yes" xml:space="preserve">
          <source>Supports loading into partitioned variables, which are represented as &lt;code&gt;'&amp;lt;variable&amp;gt;/part_&amp;lt;part #&amp;gt;'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e964d3014915281d079adadf918032ad21ee9376" translate="yes" xml:space="preserve">
          <source>Supports many numeric types and boolean.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7d38c23447a54dd0a8a5a8f23ba246013d5bca2" translate="yes" xml:space="preserve">
          <source>Supports multidimensional indexing and slicing, with one restriction: indexing into a ragged inner dimension is not allowed. This case is problematic because the indicated value may exist in some rows but not others. In such cases, it's not obvious whether we should (1) report an IndexError; (2) use a default value; or (3) skip that value and return a tensor with fewer rows than we started with. Following the guiding principles of Python (&quot;In the face of ambiguity, refuse the temptation to guess&quot;), we simply disallow this operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="465d7f75658c4dd0bcc894320c0de2a6164e5f1f" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;H.shape = [B1,...,Bb, N0, N1, N2]&lt;/code&gt;, we say that &lt;code&gt;H&lt;/code&gt; is a Hermitian spectrum if, with &lt;code&gt;%&lt;/code&gt; meaning modulus division,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f72a981b2d0bc9ee25053f2c6bb8efd804f77034" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;H.shape = [B1,...,Bb, N0, N1]&lt;/code&gt;, we say that &lt;code&gt;H&lt;/code&gt; is a Hermitian spectrum if, with &lt;code&gt;%&lt;/code&gt; indicating modulus division,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69e9539be0d74edf27965ae7808985529de3daca" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;H.shape = [B1,...,Bb, N]&lt;/code&gt;. We say that &lt;code&gt;H&lt;/code&gt; is a Hermitian spectrum if, with &lt;code&gt;%&lt;/code&gt; meaning modulus division,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c13ea8e213e123c5d46aca6ff82c0ff6d54078b" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorCirculant&lt;/code&gt; of shape &lt;code&gt;[N, N]&lt;/code&gt;, and &lt;code&gt;x.shape = [N, R]&lt;/code&gt;. Then</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7ae0d4dbc265f3305695b532a6acdf5985ab031" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorDiag&lt;/code&gt; of shape &lt;code&gt;[N, N]&lt;/code&gt;, and &lt;code&gt;x.shape = [N, R]&lt;/code&gt;. Then</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ba1a907b3f27c40ff85272978f14bd8fe9cc06b" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorLowRankUpdate&lt;/code&gt; of shape &lt;code&gt;[M, N]&lt;/code&gt;, made from a rank &lt;code&gt;K&lt;/code&gt; update of &lt;code&gt;base_operator&lt;/code&gt; which performs &lt;code&gt;.matmul(x)&lt;/code&gt; on &lt;code&gt;x&lt;/code&gt; having &lt;code&gt;x.shape = [N, R]&lt;/code&gt; with &lt;code&gt;O(L_matmul*N*R)&lt;/code&gt; complexity (and similarly for &lt;code&gt;solve&lt;/code&gt;, &lt;code&gt;determinant&lt;/code&gt;. Then, if &lt;code&gt;x.shape = [N, R]&lt;/code&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c77e9c8aaab3edc5678c3e6e549ae40d1713585" translate="yes" xml:space="preserve">
          <source>Suppose &lt;code&gt;operator&lt;/code&gt; is a &lt;code&gt;LinearOperatorLowerTriangular&lt;/code&gt; of shape &lt;code&gt;[N, N]&lt;/code&gt;, and &lt;code&gt;x.shape = [N, R]&lt;/code&gt;. Then</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23ed1b4df71c9959792073ca5b67ae2e12e27635" translate="yes" xml:space="preserve">
          <source>Suppose head1.logits_dimension = 2 and head2.logits_dimension = 3. After</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c269bc606f19d8edaa319f84a6c255fb252f362" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is &lt;code&gt;[len(values)] + fn(initializer, values[0]).shape&lt;/code&gt;. If reverse=True, it's fn(initializer, values[-1]).shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3c35f6ed89e8be18a5dda61c0fefcaae20da780" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is &lt;code&gt;[values.shape[0]] + fn(values[0]).shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dffca82b48f3566d75cc894aa925b53a25bf73ca" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is &lt;code&gt;fn(initializer, values[0]).shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bdc81326d20683103cdcdb7d7d719aec67b18bc" translate="yes" xml:space="preserve">
          <source>Suppose that &lt;code&gt;elems&lt;/code&gt; is unpacked into &lt;code&gt;values&lt;/code&gt;, a list of tensors. The shape of the result tensor is fn(initializer, values[0]).shape`.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f480af4470b536307bbf09765cdc8e2696cc548a" translate="yes" xml:space="preserve">
          <source>Survival function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3226a9be6189190c548f628801bd70aeb6bac060" translate="yes" xml:space="preserve">
          <source>Switch to cross-replica mode by calling &lt;code&gt;tf.distribute.get_replica_context().merge_call()&lt;/code&gt; with the updates and variables as arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c82b9c388b0f25a72fdba537900d4ee1afe829a0" translate="yes" xml:space="preserve">
          <source>Switches between two operations depending on a scalar value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bd6d6747309915056dbba0e2193c97595c133f2" translate="yes" xml:space="preserve">
          <source>Symbolic tensors are allowed to pass through.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed4aff47c3be607749bd2e1d76c1e799b5c23200" translate="yes" xml:space="preserve">
          <source>Synchronous training in TPU donuts or Pods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9cb28847740ddfa22df77ecf9af53c7bcc458c9" translate="yes" xml:space="preserve">
          <source>System configuration library.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3c9fd8a607c0fc8d5f20ab08a585b5a769813a4" translate="yes" xml:space="preserve">
          <source>TFDecorator captures and exposes the wrapped target, and provides details about the current decorator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0ae8b7e5c1a9027f31ac3b8b9a304ad1f03ee67" translate="yes" xml:space="preserve">
          <source>TFLiteConverter class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40c2a70a8ac9081500125d800973c1f2856d001e" translate="yes" xml:space="preserve">
          <source>TFLiteConverter object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a3f9ca39eb5977717f75ea98c14ebd341cb7b0c" translate="yes" xml:space="preserve">
          <source>TFRecord and tf.Example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2a1cfdc5a677069b65778d10bf6ba1ec74141b1" translate="yes" xml:space="preserve">
          <source>THIS CLASS IS DEPRECATED. Training with HDF5Matrix may not be optimized for performance, and might not work with every distribution strategy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea3b5253f8acd939a0fcfcfde0d4f81758ceb6ec" translate="yes" xml:space="preserve">
          <source>THIS FUNCTION IS EXPERIMENTAL. Keras layers/models are the recommended APIs for logit and model composition.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e68009384c2a3495a678e12d2ac69897187a9e4" translate="yes" xml:space="preserve">
          <source>TIP: V2 is recommended as it is more flexible (eg: batching, etc).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86c515aa235c35a6dd43d1bb6f6bd5b2174b6173" translate="yes" xml:space="preserve">
          <source>TODO(phawkins): consider adding support for broadcasting Tensors passed as inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0670d6d1899b8c7a6ede58b5b723e5aff4b026c8" translate="yes" xml:space="preserve">
          <source>TODO: add doc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6907e140b23b35d38f6441293f654f8fc707a293" translate="yes" xml:space="preserve">
          <source>TPU distribution strategy implementation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2e6d3a312671dc52e2d71bde402cdc7f8d14f6d" translate="yes" xml:space="preserve">
          <source>TPU embeddings do not support arbitrary Tensorflow optimizers and the main optimizer you use for your model will be ignored for the embedding table variables. Instead TPU embeddigns support a fixed set of predefined optimizers that you can select from and set the parameters of. These include adagrad, adam and stochastic gradient descent. Each supported optimizer has a &lt;code&gt;Parameters&lt;/code&gt; class in the &lt;a href=&quot;../../../../../tpu/experimental&quot;&gt;&lt;code&gt;tf.tpu.experimental&lt;/code&gt;&lt;/a&gt; namespace.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c46f66d84964d9d9b6cca0e4bf0d96c3c3563722" translate="yes" xml:space="preserve">
          <source>TPU evaluation only works on a single host (one TPU worker) except BROADCAST mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="608813e35435b00f9557600b0760339a8be2fba8" translate="yes" xml:space="preserve">
          <source>TPU prediction only works on a single host (one TPU worker).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bea46edc5a09b34d108296e7caa64c56863439a0" translate="yes" xml:space="preserve">
          <source>TPU related configuration required by &lt;code&gt;TPUEstimator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15462f6b704e5cb2f8f24f59de3042ec97404e38" translate="yes" xml:space="preserve">
          <source>TPU version of &lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d40306c82f3b12d754e570cc8b1cc658af2d7ec" translate="yes" xml:space="preserve">
          <source>TPU version of &lt;a href=&quot;../../feature_column/shared_embedding_columns&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.shared_embedding_columns&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87bcdd18e5c8f3b283a01e8df873660ee1d3e88c" translate="yes" xml:space="preserve">
          <source>TPUClusterResolver supports the following distinct environments: Google Compute Engine Google Kubernetes Engine Google internal</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3090232b8a50e355f64d4b6a9078737dd646c783" translate="yes" xml:space="preserve">
          <source>TPUEstimator also supports training on CPU and GPU. You don't need to define a separate &lt;a href=&quot;../../../../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ddc9467e5f271b2c256312505abf3c2d4c6b0c7" translate="yes" xml:space="preserve">
          <source>TPUEstimator handles many of the details of running on TPU devices, such as replicating inputs and models for each core, and returning to host periodically to run hooks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7e3ce08e3020395f3645372f9a127852462deaa" translate="yes" xml:space="preserve">
          <source>TPUEstimator transforms a global batch size in params to a per-shard batch size when calling the &lt;code&gt;input_fn&lt;/code&gt; and &lt;code&gt;model_fn&lt;/code&gt;. Users should specify global batch size in constructor, and then get the batch size for each shard in &lt;code&gt;input_fn&lt;/code&gt; and &lt;code&gt;model_fn&lt;/code&gt; by &lt;code&gt;params['batch_size']&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39242b58e44e50c227c356940f2f4790b1a6c7ad" translate="yes" xml:space="preserve">
          <source>Table initializers from a text file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9a99855991e9fba416a14570cf1cb6a0187f661" translate="yes" xml:space="preserve">
          <source>Table initializers given &lt;code&gt;keys&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt; tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1af97a71a1a73644d18d0f047160d91771a21862" translate="yes" xml:space="preserve">
          <source>Takes a &lt;strong&gt;doc&lt;/strong&gt; string and reformats it as help.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5507e3c183afb3feb1fdd594429bbf04fe50d0d" translate="yes" xml:space="preserve">
          <source>Takes data &amp;amp; label arrays, generates batches of augmented data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc5dd136fb3e20832ac83739b0d79852faeb82ca" translate="yes" xml:space="preserve">
          <source>Takes input and builds independent forward and backward RNNs. The input_size of forward and backward cell must match. The initial state for both directions is zero by default (but can be set optionally) and no intermediate states are ever returned -- the network is fully unrolled for the given (passed in) length(s) of the sequence(s) or completely unrolled if length(s) is not given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53df57e552ce83928403023542fdf87dfd9006ea" translate="yes" xml:space="preserve">
          <source>Takes the dataframe and the path to a directory and generates batches of augmented/normalized data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="271a488ff4179dc414b9d598c0dc902bde38633e" translate="yes" xml:space="preserve">
          <source>Takes the path to a directory &amp;amp; generates batches of augmented data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ca63275fee9de8e1de06948cce8c928cfa17e6c" translate="yes" xml:space="preserve">
          <source>Task: The task index.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d5c8c8a1221df9d08630309c4e00e480ca26a66" translate="yes" xml:space="preserve">
          <source>Temporarily stops recording operations on this tape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b284c7bc2378fc04ec8bfcb09803127b9f601fb1" translate="yes" xml:space="preserve">
          <source>Tensor contraction of a and b along specified axes and outer product.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38618f2d27b4f14fefef4170aa6ae920945a40f0" translate="yes" xml:space="preserve">
          <source>Tensor contraction over specified indices and outer product.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0eb7922b93e36f198944524d3ccbd887eb62554c" translate="yes" xml:space="preserve">
          <source>Tensor holding edge maps for each channel. Returns a tensor with shape [batch_size, h, w, d, 2] where the last two dimensions hold [[dy[0], dx[0]], [dy[1], dx[1]], ..., [dy[d-1], dx[d-1]]] calculated using the Sobel filter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="998135bad24dda7870bc2f0601f12e030cb5ca03" translate="yes" xml:space="preserve">
          <source>Tensor instance (with Keras metadata included).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd4eaaecc52921b6ace4791b28568b11625a63a9" translate="yes" xml:space="preserve">
          <source>Tensor of rank N+2, of shape [batch_size] + output_spatial_shape + [num_channels]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb76e00fc954d9b6160cc47c8ab840677d6dc502" translate="yes" xml:space="preserve">
          <source>Tensor of same shape and dtype of input &lt;code&gt;x&lt;/code&gt;, with tanh activation: &lt;code&gt;tanh(x) = sinh(x)/cosh(x) = ((exp(x) - exp(-x))/(exp(x) + exp(-x)))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f229fd06f270a1472ee5fc7d946ec114e17083e8" translate="yes" xml:space="preserve">
          <source>Tensor with dtype &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b127d103d72c024e0c3a7e4c213e3125d5bed59" translate="yes" xml:space="preserve">
          <source>Tensor with exponential activation: &lt;code&gt;exp(x)&lt;/code&gt;. Tensor will be of same shape and dtype of input &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c04a1202ada48999add7a1b4944833aee2cdad3e" translate="yes" xml:space="preserve">
          <source>Tensor with one scalar loss entry per sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1bcf3e6714689670e8871ddc1423b42db7d58cf" translate="yes" xml:space="preserve">
          <source>Tensor with same type and shape as &lt;code&gt;initializer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eb3ed83767298c300168c3e7bea9ba8df3bf9a3" translate="yes" xml:space="preserve">
          <source>Tensor with shape (samples,1) containing the CTC loss of each element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6e0a539edac6a669824128887ac83f25a022bed" translate="yes" xml:space="preserve">
          <source>Tensor with the sigmoid activation: &lt;code&gt;(1.0 / (1.0 + exp(-x)))&lt;/code&gt;. Tensor will be of same shape and dtype of input &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86989d8c3ba1ef406d202928da376f95029f14db" translate="yes" xml:space="preserve">
          <source>Tensor, output of softmax transformation (all values are non-negative and sum to 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c870eac18cde0821e85a6e2e0cd690795d9b0f8" translate="yes" xml:space="preserve">
          <source>TensorBoard is a visualization tool provided with TensorFlow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6c5b7495606642427d84d9560c2c6fa48e983ac" translate="yes" xml:space="preserve">
          <source>TensorBoard will pick the graph from the file and display it graphically so you can interactively explore the graph you built. You will usually pass the graph from the session in which you launched it:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91920dffa2de075aa71252ce246c4919ca2918b7" translate="yes" xml:space="preserve">
          <source>TensorFlow</source>
          <target state="translated">TensorFlow</target>
        </trans-unit>
        <trans-unit id="0aa8b8730f9d4ee0f6fd230f9d2510cbf8c53747" translate="yes" xml:space="preserve">
          <source>TensorFlow 1 version</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e54099f7adc352258d80aa2a07931abd0dfaf7a" translate="yes" xml:space="preserve">
          <source>TensorFlow 1.x and 2.x</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="895342c8e5449651b084f46f85af49138e2e8798" translate="yes" xml:space="preserve">
          <source>TensorFlow 2 quickstart for experts</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d7a6f2a780bcce78ffe938ccead5b3061683157" translate="yes" xml:space="preserve">
          <source>TensorFlow Compiler Bridge (TF Bridge) is responsible for translating parts of TensorFlow graph into a form that can be accepted as an input by a backend compiler such as XLA.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5218d7001def4141ae436cbd9f4e4ab5c90eec24" translate="yes" xml:space="preserve">
          <source>TensorFlow can execute operations synchronously or asynchronously. If asynchronous execution is enabled, operations may return &quot;non-ready&quot; handles.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b177522823bac7fab49a3e953658eb26bd8be99" translate="yes" xml:space="preserve">
          <source>TensorFlow can utilize various devices such as the CPU or multiple GPUs for computation. Before initializing a local device for use, the user can customize certain properties of the device such as it's visibility or memory configuration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aeb6cbc7489405eda828caa72395bff0364182ee" translate="yes" xml:space="preserve">
          <source>TensorFlow does not support strides, &lt;a href=&quot;matrix_transpose&quot;&gt;&lt;code&gt;linalg.matrix_transpose&lt;/code&gt;&lt;/a&gt; returns a new tensor with the items permuted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ab173e45e5b70ecdfa453b1565a9d48b4aea76c" translate="yes" xml:space="preserve">
          <source>TensorFlow does not support strides, so &lt;code&gt;transpose&lt;/code&gt; returns a new tensor with the items permuted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7258b473d648b978f0063efc0c3f0fba649a7ae7" translate="yes" xml:space="preserve">
          <source>TensorFlow example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80a5a18b376b7e19393c2007205799ec5fa64c3e" translate="yes" xml:space="preserve">
          <source>TensorFlow graph optimization with Grappler</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faa0af6a22961093bbe0a8dd50a78c706f27b26f" translate="yes" xml:space="preserve">
          <source>TensorFlow has been supporting a 3 week forward-compatibility window for programs compiled from source at HEAD.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72769cecd87d42b437dab4e9d4a607af2d9ab1dc" translate="yes" xml:space="preserve">
          <source>TensorFlow lacks support for unsigned integers. The ops represent uint64 types as a &lt;code&gt;DT_INT64&lt;/code&gt; with the same twos-complement bit pattern (the obvious way). Unsigned int32 values can be represented exactly by specifying type &lt;code&gt;DT_INT64&lt;/code&gt;, or using twos-complement if the caller specifies &lt;code&gt;DT_INT32&lt;/code&gt; in the &lt;code&gt;output_types&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="173be625ee6b740f87a6f6b6b09514fbf3c93296" translate="yes" xml:space="preserve">
          <source>TensorFlow multi-step profiler.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d014f833e885f8b8ed6b7a6c3ea673ead6d65d8" translate="yes" xml:space="preserve">
          <source>TensorFlow provides a variety of math functions including:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="305519ec0cbf6a7bdfd33f052e7a4a788bce222c" translate="yes" xml:space="preserve">
          <source>TensorFlow provides several operations that you can use to perform common math computations on tensor segments. Here a segmentation is a partitioning of a tensor along the first dimension, i.e. it defines a mapping from the first dimension onto &lt;code&gt;segment_ids&lt;/code&gt;. The &lt;code&gt;segment_ids&lt;/code&gt; tensor should be the size of the first dimension, &lt;code&gt;d0&lt;/code&gt;, with consecutive IDs in the range &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;k&lt;/code&gt;, where &lt;code&gt;k&amp;lt;d0&lt;/code&gt;. In particular, a segmentation of a matrix tensor is a mapping of rows to segments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="476649b1950b2c7e7e27717793935f815d493aa9" translate="yes" xml:space="preserve">
          <source>TensorFlow represents a sparse tensor as three separate dense tensors: &lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, and &lt;code&gt;dense_shape&lt;/code&gt;. In Python, the three tensors are collected into a &lt;code&gt;SparseTensor&lt;/code&gt; class for ease of use. If you have separate &lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, and &lt;code&gt;dense_shape&lt;/code&gt; tensors, wrap them in a &lt;code&gt;SparseTensor&lt;/code&gt; object before passing to the ops below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a47222eb58bbdfce0fc55dcabde531b7c9adb406" translate="yes" xml:space="preserve">
          <source>TensorShape(None) is compatible with all shapes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bac8d5b9c3640fab327ab07d92ee55320fd3913d" translate="yes" xml:space="preserve">
          <source>TensorShape([1, 2, 3]) is the most specific TensorShape compatible with both TensorShape([1, 2, 3]) and TensorShape([1, 2, 3]). There are more less specific TensorShapes compatible with above mentioned TensorShapes, e.g. TensorShape([1, 2, None]), TensorShape(None).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0224569211f435d2df63b768abb6efc726a69d01" translate="yes" xml:space="preserve">
          <source>TensorShape([32, 784]) is compatible with itself, and also TensorShape([32, None]), TensorShape([None, 784]), TensorShape([None, None]) and TensorShape(None). It is not compatible with, for example, TensorShape([32, 1, 784]) or TensorShape([None]).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d64401ff7bd3446564470a92463f73e24f52237" translate="yes" xml:space="preserve">
          <source>TensorShape([32, None]) is compatible with all two-dimensional shapes with size 32 in the 0th dimension, and also TensorShape([None, None]) and TensorShape(None). It is not compatible with, for example, TensorShape([32]), TensorShape([32, None, 1]) or TensorShape([64, None]).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59fc38face567505b51ef9cc1d627c3ec48e0458" translate="yes" xml:space="preserve">
          <source>TensorShape([None, 1]) is the most specific TensorShape compatible with both TensorShape([2, 1]) and TensorShape([5, 1]). Note that TensorShape(None) is also compatible with above mentioned TensorShapes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f0011d7d16cb288f3076f4ccc9f15a9b93ab18d" translate="yes" xml:space="preserve">
          <source>TensorShape([None, None]) is compatible with all two-dimensional shapes, such as TensorShape([32, 784]), and also TensorShape(None). It is not compatible with, for example, TensorShape([None]) or TensorShape([None, None, None]).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb7208ca53baf0c906efb86ab8419484372d57aa" translate="yes" xml:space="preserve">
          <source>Tensordot (also known as tensor contraction) sums the product of elements from &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; over the indices specified by &lt;code&gt;a_axes&lt;/code&gt; and &lt;code&gt;b_axes&lt;/code&gt;. The lists &lt;code&gt;a_axes&lt;/code&gt; and &lt;code&gt;b_axes&lt;/code&gt; specify those pairs of axes along which to contract the tensors. The axis &lt;code&gt;a_axes[i]&lt;/code&gt; of &lt;code&gt;a&lt;/code&gt; must have the same dimension as axis &lt;code&gt;b_axes[i]&lt;/code&gt; of &lt;code&gt;b&lt;/code&gt; for all &lt;code&gt;i&lt;/code&gt; in &lt;code&gt;range(0, len(a_axes))&lt;/code&gt;. The lists &lt;code&gt;a_axes&lt;/code&gt; and &lt;code&gt;b_axes&lt;/code&gt; must have identical length and consist of unique integers that specify valid axes for each of the tensors. Additionally outer product is supported by passing &lt;code&gt;axes=0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3da1e8a48fb9ee2ea5423ca2bee26f977fbfb800" translate="yes" xml:space="preserve">
          <source>Tensorflow 1.x and 2.x APIs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df64ef28dfdc0fed49d20c14d6e6f4dee9cf4df9" translate="yes" xml:space="preserve">
          <source>Tensorflow set operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c78b40e19c215435bc3ed71dd1958e2bcae7efd3" translate="yes" xml:space="preserve">
          <source>Tensorlow Activation function denoted by input string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08f39ae099e26b016733e9e9c40c5aeddf309f4f" translate="yes" xml:space="preserve">
          <source>Tensors are broadcast to all shards if they are lexically captured by &lt;code&gt;computation&lt;/code&gt;. e.g.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf0313234b1dcd5626309aecb9ec7ec9391ddedf" translate="yes" xml:space="preserve">
          <source>Tensors returned by the call to either &lt;code&gt;true_fn&lt;/code&gt; or &lt;code&gt;false_fn&lt;/code&gt;. If the callables return a singleton list, the element is extracted from the list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a48b71c8b807b599bf508a6dbc5c09d5b67d8a03" translate="yes" xml:space="preserve">
          <source>Tensors where required information about the tensor is not found are not added to the list. This includes temporary tensors without a name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7b5ca3ec5313c82b6abfc2564bf0e69a6804f5b" translate="yes" xml:space="preserve">
          <source>Tensors with the same shapes and dtypes as &lt;code&gt;primals&lt;/code&gt;, or None if no JVP is available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f63302361128babd351769e59c1a4b3a6ec16f94" translate="yes" xml:space="preserve">
          <source>Test the model on a single batch of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdf696f0dd4d97504f4a88d9e975e9f3294e8162" translate="yes" xml:space="preserve">
          <source>Testing.</source>
          <target state="translated">Testing.</target>
        </trans-unit>
        <trans-unit id="922aa0452fde3720fa66aa3c8e60b54fc1c9bf57" translate="yes" xml:space="preserve">
          <source>Tests if a variable has been initialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f458c872a2ebaf65e5d7df76b800c1d13ed30e7f" translate="yes" xml:space="preserve">
          <source>Tests whether &lt;code&gt;v&lt;/code&gt; was created while this strategy scope was active.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0beba45f94aef1d128461a461734027a1cbdc6a" translate="yes" xml:space="preserve">
          <source>Text classification with TensorFlow Hub: Movie reviews</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af2326670284928f1fa19c7cb38f5c886d723da5" translate="yes" xml:space="preserve">
          <source>Text classification with an RNN</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="666b2045ab57fe75e30e76d0ab8d952507d4bb84" translate="yes" xml:space="preserve">
          <source>Text classification with preprocessed text: Movie reviews</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="238cbda9697b2819cc76abe6b2dfc721f459f878" translate="yes" xml:space="preserve">
          <source>Text data summarized via this plugin will be visible in the Text Dashboard in TensorBoard. The standard TensorBoard Text Dashboard will render markdown in the strings, and will automatically organize 1d and 2d tensors into tables. If a tensor with more than 2 dimensions is provided, a 2d subarray will be displayed along with a warning message. (Note that this behavior is not intrinsic to the text summary api, but rather to the default TensorBoard text plugin.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="215d4fed2fcabcf3c40621205317566597794ae1" translate="yes" xml:space="preserve">
          <source>Text generation with an RNN</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61400e23cf34d05c482b01eaced08ef2d8868035" translate="yes" xml:space="preserve">
          <source>Text tokenization utility class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdb6f1dda58b475840646d14c94922eb6f72f336" translate="yes" xml:space="preserve">
          <source>Text vectorization layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1625deb08cd91b1818022a22d98396b875c5eb8" translate="yes" xml:space="preserve">
          <source>TextFileIndex.LINE_NUMBER means use the line number starting from zero, expects data type int64.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52639d0bc1ea1e6f18d19dfc84aced6fc473d4b7" translate="yes" xml:space="preserve">
          <source>TextFileIndex.WHOLE_LINE means use the whole line content, expects data type string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fad4058d06803c465e05d1c5344e342b15bc7c35" translate="yes" xml:space="preserve">
          <source>That is, the data from the input tensors is joined along the &lt;code&gt;axis&lt;/code&gt; dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="819444ab5f8a03046c9bdaef264812c5a336db87" translate="yes" xml:space="preserve">
          <source>The &quot;default&quot; behavior to is to output all intermediates when using v2 control flow inside Keras models in graph mode (possibly inside Estimators). This is needed to support taking gradients of v2 control flow. In graph mode, Keras can sometimes freeze the forward graph before the gradient computation which does not work for v2 control flow since it requires updating the forward ops to output the needed intermediates. We work around this by proactively outputting the needed intermediates when building the forward pass itself. Ideally any such extra tensors should be pruned out at runtime. However, if for any reason this doesn't work for you or if you have an infernce-only model you can turn this behavior off using &lt;a href=&quot;output_all_intermediates&quot;&gt;&lt;code&gt;tf.compat.v1.experimental.output_all_intermediates(False)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b9fa0a04a1154461443bf2e15e0c100a29ae547" translate="yes" xml:space="preserve">
          <source>The 'key' part of the state of a counter-based RNG.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3318a80b2f7ae85ea4618b44f96f90cdc30913bf" translate="yes" xml:space="preserve">
          <source>The 'step' here refers to the step defined by &lt;code&gt;Profiler.add_step()&lt;/code&gt; API.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32756cff4dc3fe86f44d1b62b470239afbc36f52" translate="yes" xml:space="preserve">
          <source>The -32768 to 32767 signed 16-bit values will be scaled to -1.0 to 1.0 in float.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a500fcca2783caaf16ae016a052e05e8f3aac0f1" translate="yes" xml:space="preserve">
          <source>The .value attribute of the registered 'Flag' objects can be accessed as attributes of this 'FlagValues' object, through &lt;strong&gt;getattr&lt;/strong&gt;. Both the long and short name of the original 'Flag' objects can be used to access its value: FLAGS.longname # parsed flag value FLAGS.x # parsed flag value (short name)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="310600070b5ce2b07429f189bd9cdba9eeaed7e3" translate="yes" xml:space="preserve">
          <source>The 4-D &lt;code&gt;input&lt;/code&gt; tensor is treated as a 3-D array of 1-D vectors (along the last dimension), and each vector is normalized independently. Within a given vector, each component is divided by the weighted, squared sum of inputs within &lt;code&gt;depth_radius&lt;/code&gt;. In detail,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f0e683a1673564b6d46b0b9fa5e4680c1843f5c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;input_fn&lt;/code&gt; should have a per-replica batch size, which may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="457c92aa7bdffea8661a2def17f70e375b2b0d14" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;input_fn&lt;/code&gt; should have a per-replica batch size, which may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c669108152980f350f27d9f945606a7f5042af07" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../compat&quot;&gt;&lt;code&gt;tf.compat&lt;/code&gt;&lt;/a&gt; module contains two sets of compatibility functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01d2d82dc787cbf3a2ae3987bb1b5d16410bae2e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../v1&quot;&gt;&lt;code&gt;compat.v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../v2&quot;&gt;&lt;code&gt;compat.v2&lt;/code&gt;&lt;/a&gt; submodules provide a complete copy of both the &lt;a href=&quot;../v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../v2&quot;&gt;&lt;code&gt;v2&lt;/code&gt;&lt;/a&gt; APIs for backwards and forwards compatibility across TensorFlow versions 1.x and 2.x. See the &lt;a href=&quot;https://www.tensorflow.org/guide/migrate&quot;&gt;migration guide&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe9cc0c9957673c491ce6d30fbea4a26885b807" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;as_dtype&quot;&gt;&lt;code&gt;tf.as_dtype()&lt;/code&gt;&lt;/a&gt; function converts numpy types and string type names to a &lt;code&gt;DType&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32f6a4f580c3c6e3fc936c05d3cb6e72f0b9bb8c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;asin&quot;&gt;&lt;code&gt;tf.math.asin&lt;/code&gt;&lt;/a&gt; operation returns the inverse of &lt;a href=&quot;sin&quot;&gt;&lt;code&gt;tf.math.sin&lt;/code&gt;&lt;/a&gt;, such that if &lt;code&gt;y = tf.math.sin(x)&lt;/code&gt; then, &lt;code&gt;x = tf.math.asin(y)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fe608389d1e1d156ec65aaf39eda66bf4b6d78b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;atan&quot;&gt;&lt;code&gt;tf.math.atan&lt;/code&gt;&lt;/a&gt; operation returns the inverse of &lt;a href=&quot;tan&quot;&gt;&lt;code&gt;tf.math.tan&lt;/code&gt;&lt;/a&gt;, such that if &lt;code&gt;y = tf.math.tan(x)&lt;/code&gt; then, &lt;code&gt;x = tf.math.atan(y)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="377c0dfe96375de255d1078e440f823480e3a6ef" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;compat&quot;&gt;&lt;code&gt;tf.compat&lt;/code&gt;&lt;/a&gt; module contains two sets of compatibility functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3d73ba603d6fb92f75b91298f4942e6c40c7715" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;compat/v1&quot;&gt;&lt;code&gt;compat.v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;compat/v2&quot;&gt;&lt;code&gt;compat.v2&lt;/code&gt;&lt;/a&gt; submodules provide a complete copy of both the &lt;a href=&quot;compat/v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;compat/v2&quot;&gt;&lt;code&gt;v2&lt;/code&gt;&lt;/a&gt; APIs for backwards and forwards compatibility across TensorFlow versions 1.x and 2.x. See the &lt;a href=&quot;https://www.tensorflow.org/guide/migrate&quot;&gt;migration guide&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="296ec246e39e89b77945b24475c46eb438f28485" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; API supports writing descriptive and efficient input pipelines. &lt;code&gt;Dataset&lt;/code&gt; usage follows a common pattern:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c3d4e4e633551f12e713ed696a5627504df6738" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;dtypes/dtype&quot;&gt;&lt;code&gt;tf.dtypes.DType&lt;/code&gt;&lt;/a&gt; specified by this type for the SparseTensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70d5ec6de5836f215309b5a86984ea31fb17eefc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto&quot;&gt;&lt;code&gt;ConfigProto&lt;/code&gt;&lt;/a&gt; protocol buffer exposes various configuration options for a session. For example, to create a session that uses soft constraints for device placement, and log the resulting placement decisions, create a session as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee6db31a7766468eec0b350c9fc9a1f275e8fb70" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;reshape&quot;&gt;&lt;code&gt;tf.reshape&lt;/code&gt;&lt;/a&gt; does not change the order of or the total number of elements in the tensor, and so it can reuse the underlying data buffer. This makes it a fast operation independent of how big of a tensor it is operating on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7963552cb54b1ec49bf3619d53b5f98fe3bf0679" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;summary&quot;&gt;&lt;code&gt;tf.summary&lt;/code&gt;&lt;/a&gt; module provides APIs for writing summary data. This data can be visualized in TensorBoard, the visualization toolkit that comes with TensorFlow. See the &lt;a href=&quot;https://www.tensorflow.org/tensorboard&quot;&gt;TensorBoard website&lt;/a&gt; for more detailed tutorials about how to use these APIs, or some quick examples below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24f9ea8adfa7610b42fddb644a5a51e051b8eaa7" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; of elements in this TensorArray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04e6781a375d8a3c0003a07e94ac44bcb3e616e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; specified by this type for the SparseTensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66692c6576fc19dc600e497055779a41aa378ba7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;AUTOGRAPH_VERBOSITY&lt;/code&gt; environment variable</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dca74f64b67802ef6255942a005b4b0e987ede6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;D&lt;/code&gt; dimensional DFT of this kernel is the frequency domain spectrum of this operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66b37f1319974cb5f0fa3b6a811c37b0c0727341" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of &lt;code&gt;Tensor&lt;/code&gt;s handled by this &lt;code&gt;Distribution&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bb640578d6cd791bb5862104fe6d0205745975e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of &lt;code&gt;Tensor&lt;/code&gt;s handled by this &lt;code&gt;LinearOperator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9d4756bd9db645b28103af34e5194ce4953cfef" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of elements in this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5ab67eadac883aa6725083774a80ae7132a5bd6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53e90665615d6d49947adc54462569d15bfa77ff" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DType&lt;/code&gt; of values in this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7a67bba30f7a7c9709251275c277fca1bfce8ef" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DeviceSpec&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0310f14b96c9ed2b643415080c07ecfa0544c1f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Estimator&lt;/code&gt; object wraps a model which is specified by a &lt;code&gt;model_fn&lt;/code&gt;, which, given inputs and a number of other parameters, returns the ops necessary to perform training, evaluation, or predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="196e0cebbe1e15bfa0065abbfc42918c9e99edb0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;FileWriter&lt;/code&gt; class provides a mechanism to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="196ae7d5b42d47f46f7482c41ead4515ecb54223" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; of this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="584ca58bfd11413a8b78de2539e6a0dc60006c1e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains the index, value, and dense_shape tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ca109a80501f1caf39360f020e2482be69cd6ee" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains the values, indices, and shape tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3f124e19ecf06b5bede3c16429a910c11d7deff" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains this operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca5e3e755e232a9bd4baefb017c11720d3cb6b8d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Graph&lt;/code&gt; that contains this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad04e8ed6553bb23d3fbb8f177dc964899bc3ca0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;IndexedSlices&lt;/code&gt; class is used principally in the definition of gradients for operations that have sparse gradients (e.g. &lt;a href=&quot;gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b67dd6295f95267a6fd766fa43e3a4f8445ff608" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Lambda&lt;/code&gt; layer exists so that arbitrary TensorFlow functions can be used when constructing &lt;code&gt;Sequential&lt;/code&gt; and Functional API models. &lt;code&gt;Lambda&lt;/code&gt; layers are best suited for simple operations or quick experimentation. For more advanced usecases, follow &lt;a href=&quot;https://www.tensorflow.org/guide/keras/custom_layers_and_models&quot;&gt;this guide&lt;/a&gt; for subclassing &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12b734c9cea4d788668e7d42b41afdea642fee23" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LinearOperatorIdentity&lt;/code&gt; is initialized with arguments defining &lt;code&gt;dtype&lt;/code&gt; and shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d73311c5178545cf753217309588019e38f9d709" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LinearOperatorScaledIdentity&lt;/code&gt; is initialized with &lt;code&gt;num_rows&lt;/code&gt;, which determines the size of each identity matrix, and a &lt;code&gt;multiplier&lt;/code&gt;, which defines &lt;code&gt;dtype&lt;/code&gt;, batch shape, and scale of each matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6a140a1c911bc07b4bf6bf40190ce8128dc1514" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LinearOperatorZeros&lt;/code&gt; is initialized with arguments defining &lt;code&gt;dtype&lt;/code&gt; and shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1f24df7eab694b0f1703da39cd73b8c86b688da" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LocallyConnected1D&lt;/code&gt; layer works similarly to the &lt;code&gt;Conv1D&lt;/code&gt; layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70697b9bab37838191095266898ffadfd97d828c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LocallyConnected2D&lt;/code&gt; layer works similarly to the &lt;code&gt;Conv2D&lt;/code&gt; layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8fa1143a320d647d8e801e00a58c7e05a50565b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;LossScale&lt;/code&gt; instance associated with this optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98a41775ad95ce382b63a77e41954693dabb7a8c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;MetaGraphDef&lt;/code&gt; allows running the given graph via &lt;code&gt;saver.import_meta_graph()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d513aeb35380001cdceb5f916046f228692a7e2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer loaded in the provided session. This can be used to further extract signature-defs, collection-defs, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb465f350147752217292b36e4f6e8af3b681307" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;NodeDef&lt;/code&gt; proto representing the op that failed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff313cdcfce21b44585ea5f9a91a7a3dc6de0178" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; objects on which this op has a control dependency.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87fc441eb7b6054082173c9f1ab6bf4c42c56cd4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; of this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a9cda719e59cf9091cbf0d01fc46d4aaf72fff1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; that failed, or None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="438a9dc8c58e4a098826c43ea413784f9b3995d6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; that produces &lt;code&gt;values&lt;/code&gt; as an output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9d068224c3abe35b7ed380528fe996c78ebd4f5" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; that produces this tensor as an output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05c1129e9d0be24dc0a8495f7e24b9eaf32d0723" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Operation&lt;/code&gt; with the given &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="207e00a2d0ea7a2feedfe3c413469ac89cde7bb0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;QueueRunner&lt;/code&gt;, combined with the &lt;code&gt;Coordinator&lt;/code&gt;, helps handle these issues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6875e1876426bfecf07e4b4acdb8ea569eea6f3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SavedModel&lt;/code&gt; contains:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f4f2790a6a7f05dc0c928fcd21f48c92ded1ee8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SavedModel&lt;/code&gt; saved by the &lt;code&gt;export_saved_model&lt;/code&gt; method does not include the cluster centers. However, the cluster centers may be retrieved by the latest checkpoint saved during training. Specifically,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6039bfa2164055554cd488d18e16d9f34bf9b47" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SavedModelBuilder&lt;/code&gt; class provides functionality to build a &lt;code&gt;SavedModel&lt;/code&gt; protocol buffer. Specifically, this allows multiple meta graphs to be saved as part of a single language-neutral &lt;code&gt;SavedModel&lt;/code&gt;, while sharing variables and assets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cd194d774bf843726a9b31fd8c5760738d54965" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Saver&lt;/code&gt; class adds ops to save and restore variables to and from &lt;em&gt;checkpoints&lt;/em&gt;. It also provides convenience methods to run these ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4996fa4000c885aea5b079a558bc6345b7b96a57" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SparseTensor&lt;/code&gt; must have rank &lt;code&gt;R&lt;/code&gt; greater than 1, and the first dimension is treated as the minibatch dimension. Elements of the &lt;code&gt;SparseTensor&lt;/code&gt; must be sorted in increasing order of this first dimension. The serialized &lt;code&gt;SparseTensor&lt;/code&gt; objects going into each row of the output &lt;code&gt;Tensor&lt;/code&gt; will have rank &lt;code&gt;R-1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b42219c4a7badee8ff4052cb167c2aad9136d9f3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SparseTensor&lt;/code&gt; returned by this function has the following properties:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef8d47ae2cffd6a60717723743196db2da48e873" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e61a9703a7b332edaa3d2a56d6128abb09ee039b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;Operation&lt;/code&gt; in the Graph corresponding to &lt;code&gt;obj&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21aeac68c332c23a4035410d874f4d643b5e9753" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Tensor&lt;/code&gt; with the given &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="062bc5ef63073ebe0bba42c69dd60fbbac0ba11a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;TensorShape&lt;/code&gt; of this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d5f495d7cfc5ed68324d2dab206b4e7d15c1c2e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Variable()&lt;/code&gt; constructor requires an initial value for the variable, which can be a &lt;code&gt;Tensor&lt;/code&gt; of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1083cab47ab61c7cdda4d83367b338d6c7e04350" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Variable()&lt;/code&gt; constructor requires an initial value for the variable, which can be a &lt;code&gt;Tensor&lt;/code&gt; of any type and shape. This initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="127a5eff8bb10c7a9751d8d922f006229b0755c5" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Variable&lt;/code&gt; for the slot if it was created, &lt;code&gt;None&lt;/code&gt; otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="368fe6644a57bbac64f15832c728e327af009d67" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Vocabulary&lt;/code&gt; object will performs the following mapping:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="519c59ffc79a16af729e3142dd3abe9ca662d6c6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;accuracy&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;predictions&lt;/code&gt; matches &lt;code&gt;labels&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb05150efdb907d6c2345164aacf0bfaba0751c2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;apply()&lt;/code&gt; method adds shadow copies of trained variables and add ops that maintain a moving average of the trained variables in their shadow copies. It is used when building the training model. The ops that maintain moving averages are typically run after each training step. The &lt;code&gt;average()&lt;/code&gt; and &lt;code&gt;average_name()&lt;/code&gt; methods give access to the shadow variables and their names. They are useful when building an evaluation model, or when restoring a model from a checkpoint file. They help use the moving averages in place of the last trained values for evaluations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="606eed9ef4b94263c255e5099fa91bbc0424bdd2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;apply()&lt;/code&gt; method has to be called to create shadow variables and add ops to maintain moving averages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc2517e9824df1742df7d5a7c8c3c56a268719aa" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;auc&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the AUC. To discretize the AUC curve, a linearly spaced set of thresholds is used to compute pairs of recall and precision values. The area under the ROC-curve is therefore computed using the height of the recall values by the false positive rate, while the area under the PR-curve is the computed using the height of the precision values by the recall.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8af58715c30e66d456c8d6905c0d5153fbdbbc7c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;band&lt;/code&gt; part is computed as follows: Assume &lt;code&gt;input&lt;/code&gt; has &lt;code&gt;k&lt;/code&gt; dimensions &lt;code&gt;[I, J, K, ..., M, N]&lt;/code&gt;, then the output is a tensor with the same shape where</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1eb08b43ce7219e68f0c3bd3c76b2d17d8da595" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;branch_fns&lt;/code&gt; parameter is either a dict from &lt;code&gt;int&lt;/code&gt; to callables, or list of (&lt;code&gt;int&lt;/code&gt;, callable) pairs, or simply a list of callables (in which case the index is implicitly the key). The &lt;code&gt;branch_index&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; is used to select an element in &lt;code&gt;branch_fns&lt;/code&gt; with matching &lt;code&gt;int&lt;/code&gt; key, falling back to &lt;code&gt;default&lt;/code&gt; if none match, or &lt;code&gt;max(keys)&lt;/code&gt; if no &lt;code&gt;default&lt;/code&gt; is provided. The keys must form a contiguous set from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;len(branch_fns) - 1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="191ea315ef50769cbc5f21b205a7c35e5f727b01" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;capacity&lt;/code&gt; argument controls the how long the prefetching is allowed to grow the queues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90470bf7983fc786e9b2f478b52410df3cb933b0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;compact&lt;/code&gt; format is recommended as the one with best performance. In case you need to cast a tensor into a compact format manually, use &lt;a href=&quot;../gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;. An example for a tensor of shape [m, m]:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97f57a9366600ee779830b27b2d179f2f5db2b92" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;concentration&lt;/code&gt; represents mean total counts of class occurrence, i.e.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01ab58045b90ae07778088607a3eab393fc1bb6a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;condition&lt;/code&gt; tensor acts as a mask that chooses, based on the value at each element, whether the corresponding element / row in the output should be taken from &lt;code&gt;x&lt;/code&gt; (if true) or &lt;code&gt;y&lt;/code&gt; (if false).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bfb9121150515c59120455c6322fe9bdac07ae9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;config&lt;/code&gt; argument can be passed &lt;a href=&quot;../../../estimator/runconfig&quot;&gt;&lt;code&gt;tf.estimator.RunConfig&lt;/code&gt;&lt;/a&gt; object containing information about the execution environment. It is passed on to the &lt;code&gt;model_fn&lt;/code&gt;, if the &lt;code&gt;model_fn&lt;/code&gt; has a parameter named &quot;config&quot; (and input functions in the same manner). If the &lt;code&gt;config&lt;/code&gt; parameter is not passed, it is instantiated by the &lt;code&gt;Estimator&lt;/code&gt;. Not passing config means that defaults useful for local execution are used. &lt;code&gt;Estimator&lt;/code&gt; makes config available to the model (for instance, to allow specialization based on the number of workers available), and also uses some of its fields to control internals, especially regarding checkpointing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bec4775822937a50bbd9f3cbf347be8160f7726" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;config&lt;/code&gt; argument can be passed &lt;a href=&quot;runconfig&quot;&gt;&lt;code&gt;tf.estimator.RunConfig&lt;/code&gt;&lt;/a&gt; object containing information about the execution environment. It is passed on to the &lt;code&gt;model_fn&lt;/code&gt;, if the &lt;code&gt;model_fn&lt;/code&gt; has a parameter named &quot;config&quot; (and input functions in the same manner). If the &lt;code&gt;config&lt;/code&gt; parameter is not passed, it is instantiated by the &lt;code&gt;Estimator&lt;/code&gt;. Not passing config means that defaults useful for local execution are used. &lt;code&gt;Estimator&lt;/code&gt; makes config available to the model (for instance, to allow specialization based on the number of workers available), and also uses some of its fields to control internals, especially regarding checkpointing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0aeca4b97eca00ef17635cebe947fcd9da586a15" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;context_features&lt;/code&gt; keys are associated with a &lt;code&gt;SequenceExample&lt;/code&gt; as a whole, independent of time / frame. In contrast, the &lt;code&gt;sequence_features&lt;/code&gt; keys provide a way to access variable-length data within the &lt;code&gt;FeatureList&lt;/code&gt; section of the &lt;code&gt;SequenceExample&lt;/code&gt; proto. While the shapes of &lt;code&gt;context_features&lt;/code&gt; values are fixed with respect to frame, the frame dimension (the first dimension) of &lt;code&gt;sequence_features&lt;/code&gt; values may vary between &lt;code&gt;SequenceExample&lt;/code&gt; protos, and even between &lt;code&gt;feature_list&lt;/code&gt; keys within the same &lt;code&gt;SequenceExample&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb1682e2f681183d97e2a0110f16b4f60410e0df" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;coord&lt;/code&gt; argument is an optional coordinator that the threads will use to terminate together and report exceptions. If a coordinator is given, this method starts an additional thread to close the queue when the coordinator requests a stop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79d54183b850ac8c8ff0b7cfd536e56b95627d32" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;../../../../data/dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee978764731ae2547628b468794cefc836bc4795" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;../../../data/dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04f48577e80fcfb603fa15b3b9e05181dd539f9e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;../dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eccbe3ff90cfb1e82cccca44957962bdd5ce30cd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cycle_length&lt;/code&gt; and &lt;code&gt;block_length&lt;/code&gt; arguments control the order in which elements are produced. &lt;code&gt;cycle_length&lt;/code&gt; controls the number of input elements that are processed concurrently. If you set &lt;code&gt;cycle_length&lt;/code&gt; to 1, this transformation will handle one input element at a time, and will produce identical results to &lt;a href=&quot;dataset#flat_map&quot;&gt;&lt;code&gt;tf.data.Dataset.flat_map&lt;/code&gt;&lt;/a&gt;. In general, this transformation will apply &lt;code&gt;map_func&lt;/code&gt; to &lt;code&gt;cycle_length&lt;/code&gt; input elements, open iterators on the returned &lt;code&gt;Dataset&lt;/code&gt; objects, and cycle through them producing &lt;code&gt;block_length&lt;/code&gt; consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdd71fb6bd2b9b57b19cddd99579978c6dafa2a7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;data_format&lt;/code&gt; attr specifies the layout of the input and output tensors with the following options: &quot;NHWC&quot;: &lt;code&gt;[ batch, height, width, channels ]&lt;/code&gt; &quot;NCHW&quot;: &lt;code&gt;[ batch, channels, height, width ]&lt;/code&gt; &quot;NCHW_VECT_C&quot;: &lt;code&gt;qint8 [ batch, channels / 4, height, width, 4 ]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cd12fa44d77e3c12fe697b0db4b93e48339e374" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e86d0834b58ce3b47a884a1d468afe9d9201946" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dab43a435b361f56a83a42c04da29fda060c86e3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7ca657c4395755383bc81fcb9f2b453ce90db09" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;../inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fde1903f8238ad03f3998edc676b8256c4d75c5" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;dataset_fn&lt;/code&gt; should take an &lt;a href=&quot;inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; instance where information about batching and input replication can be accessed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f20e1c4521e0296106d88f47b84176329b10342a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decode_proto&lt;/code&gt; op extracts fields from a serialized protocol buffers message into tensors. The fields in &lt;code&gt;field_names&lt;/code&gt; are decoded and converted to the corresponding &lt;code&gt;output_types&lt;/code&gt; if possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61bfd7600a5bc08577b34e4662502a0cb1a1a96f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decorator_func&lt;/code&gt; argument with new metadata attached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a514f3a1501df389c97cb427fbd5d632c8c0d4a6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;default_value&lt;/code&gt; is used for keys not present in the table.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f256cc69c0f762014c0c50a38e920065363cfb4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;descriptor_source&lt;/code&gt; attribute selects the source of protocol descriptors to consult when looking up &lt;code&gt;message_type&lt;/code&gt;. This may be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a92bd94cb0af3355b6f29220671131a1d4a6adc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;device_name_or_function&lt;/code&gt; argument may either be a device name string, a device function, or None:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19b121f477789a4199014186a6e228b0aa000947" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;enqueuer.get()&lt;/code&gt; should be an infinite stream of datas.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae1bab6951216e7b0f3d9533c0fe4cef0e27a5dc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;fetches&lt;/code&gt; argument may be a single graph element, or an arbitrarily nested list, tuple, namedtuple, dict, or OrderedDict containing graph elements at its leaves. A graph element can be one of the following types:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="785d7e8c57af0973369bcb00a38fc045b0c9ae7b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;../../../../data/dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae29332866e5bc8b9ee07b134fda5a738b8021d6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;../../../data/dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f18a1c227e50f0bcfa83536b4f1a61f14aca11e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;../dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5d371bf05fee9ac34c79b3ecb1708c225ca7a5e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;file_pattern&lt;/code&gt; argument should be a small number of glob patterns. If your filenames have already been globbed, use &lt;a href=&quot;dataset#from_tensor_slices&quot;&gt;&lt;code&gt;Dataset.from_tensor_slices(filenames)&lt;/code&gt;&lt;/a&gt; instead, as re-globbing every filename with &lt;code&gt;list_files&lt;/code&gt; may result in poor performance with remote storage systems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae4fe9c389bd86de17fd613b2cb617cf5b34971a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;generator&lt;/code&gt; argument must be a callable object that returns an object that supports the &lt;code&gt;iter()&lt;/code&gt; protocol (e.g. a generator function). The elements generated by &lt;code&gt;generator&lt;/code&gt; must be compatible with the given &lt;code&gt;output_types&lt;/code&gt; and (optional) &lt;code&gt;output_shapes&lt;/code&gt; arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d34ef9051018aee7b571f4ddcf30ab7cfc4276af" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;get_losses_for&lt;/code&gt; method allows to retrieve the losses relevant to a specific set of inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c06d13d8339819e2aa27ef381a46e85c67ddba64" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;get_updates_for&lt;/code&gt; method allows to retrieve the updates relevant to a specific set of inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec9647e5e43640fc561f86326ed66d7b1839d523" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;ignore_longer_outputs_than_inputs&lt;/code&gt; option allows to specify the behavior of the CTCLoss when dealing with sequences that have longer outputs than inputs. If true, the CTCLoss will simply return zero gradient for those items, otherwise an InvalidArgument error is returned, stopping training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e77ea3b32e4a62532979c99f1006fa100924b5f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, and &lt;code&gt;shapes&lt;/code&gt; lists must have the same length.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cca3019d062a9892e2676ec309dbc9e2a90d317" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;filter&lt;/code&gt; tensor has shape &lt;code&gt;[filter_height, filter_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e66cb3e17296e0dbd7031b533b7074c9bfdfef6b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;filters&lt;/code&gt; tensor has shape &lt;code&gt;[filter_height, filter_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17d78b23014241429cebda7a7ed18dd11ac18169" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; object where information about batching and input sharding can be accessed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a7667b672c0fb6a912c80d541aa0d63d101f97d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input_fn&lt;/code&gt; should take an &lt;a href=&quot;../../../distribute/inputcontext&quot;&gt;&lt;code&gt;tf.distribute.InputContext&lt;/code&gt;&lt;/a&gt; object where information about batching and input sharding can be accessed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="659e1fc33dd53c3ed2709a794415182888957e1f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;inputs&lt;/code&gt; Tensor's innermost dimension size, &lt;code&gt;num_classes&lt;/code&gt;, represents &lt;code&gt;num_labels + 1&lt;/code&gt; classes, where num_labels is the number of true labels, and the largest value &lt;code&gt;(num_classes - 1)&lt;/code&gt; is reserved for the blank label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54adbaacaf1b1235d65bae24606d9417fde02168" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;job_name&lt;/code&gt;, &lt;code&gt;task_index&lt;/code&gt;, and &lt;code&gt;protocol&lt;/code&gt; arguments are optional, and override any information provided in &lt;code&gt;server_or_cluster_def&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a121b1c952b1d66b82abf663f7114cd18e26ce58" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;labels&lt;/code&gt; shape must match &lt;code&gt;logits&lt;/code&gt;, namely &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;. If &lt;code&gt;label_dimension=1&lt;/code&gt;, shape &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt; is also supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a7473ff7ad3c16ed4893e43c01e352fd1f3c9c8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;labels&lt;/code&gt; shape must match &lt;code&gt;logits&lt;/code&gt;, namely &lt;code&gt;[D0, D1, ... DN]&lt;/code&gt; or &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="337997246db8337cb34ef7810fd235c2b2595916" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;load&lt;/code&gt; operation requires the session in which to restore the graph definition and variables, the tags used to identify the meta graph def to load and the location of the SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d30c15fc4a153c98926b67d30f2faeb014c1e26" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;local_init_op&lt;/code&gt; is an &lt;code&gt;Operation&lt;/code&gt; that is run always after a new session was created. If &lt;code&gt;None&lt;/code&gt;, this step is skipped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2701808169cb5f6edee74183d83e4eef575157e2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;logs&lt;/code&gt; dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc148a0836cef52be69ad741735a0b91ff403bfd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;loss_collection&lt;/code&gt; argument is ignored when executing eagerly. Consider holding on to the return value or collecting losses via a &lt;a href=&quot;../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e3ee2c38e78144a1138ef9d3009b14144429a19" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the average of &lt;code&gt;values&lt;/code&gt;. This average is ultimately returned as &lt;code&gt;mean&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d502617cdf652bd304ad5b305d7afe67fbd9b64" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_absolute_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean absolute error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_absolute_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5274af314d757e1ddc8b38db5fa05ae667819167" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_cosine_distance&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the average cosine distance between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_distance&lt;/code&gt;, which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="336c620aa42f01c6ce6a5a126282c5957ed048ef" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_relative_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean relative absolute error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_relative_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67c2bbcc205906b964a9ff8ac3199c6be162fe51" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_squared_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean squared error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_squared_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b117bfd9e6e5a2c416636178e1f60670fea3d28" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_tensor&lt;/code&gt; function creates two local variables, &lt;code&gt;total_tensor&lt;/code&gt; and &lt;code&gt;count_tensor&lt;/code&gt; that are used to compute the average of &lt;code&gt;values&lt;/code&gt;. This average is ultimately returned as &lt;code&gt;mean&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61901168dd1572e51930a90d2c41288724617770" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;min_after_dequeue&lt;/code&gt; argument allows the caller to specify a minimum number of elements that will remain in the queue after a &lt;code&gt;dequeue&lt;/code&gt; or &lt;code&gt;dequeue_many&lt;/code&gt; operation completes, to ensure a minimum level of mixing of elements. This invariant is maintained by blocking those operations until sufficient elements have been enqueued. The &lt;code&gt;min_after_dequeue&lt;/code&gt; argument is ignored after the queue has been closed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87f93cdb7fe70e84bf2c6a1f629508cf097e91cf" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;model_fn&lt;/code&gt; with following signature: &lt;code&gt;def model_fn(features, labels, mode, config)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b0f2d1521a662066e2e88bb2088b1a4f0eee648" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;name&lt;/code&gt; argument determines the compute and variable dtype, the default loss scale, and has no additional effect on the Policy. The compute and variable dtypes can only be specified through &lt;code&gt;name&lt;/code&gt;, and cannot be specified directly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caae61aec33371ff4b676bc337e8ca5b2b3735d7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;name&lt;/code&gt; argument will be interpreted as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bb4358003786fb876ae7af1510a743596ce0c00" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;output&lt;/code&gt; is a string &lt;code&gt;Tensor&lt;/code&gt; of the same shape as &lt;code&gt;bytes&lt;/code&gt;, each element containing the decompressed data from the corresponding element in &lt;code&gt;bytes&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b4d4c43eca0087042a4ac89a69f9618fa9ccf44" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument has no effect on the size of each patch, it determines how many patches are extracted. If &lt;code&gt;VALID&lt;/code&gt;, only patches which are fully contained in the input image are included. If &lt;code&gt;SAME&lt;/code&gt;, all patches whose starting point is inside the input are included, and areas outside the input default to zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d6511601b9be092f62183d45376bcdd0b07ca55" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;params&lt;/code&gt; argument contains hyperparameters. It is passed to the &lt;code&gt;model_fn&lt;/code&gt;, if the &lt;code&gt;model_fn&lt;/code&gt; has a parameter named &quot;params&quot;, and to the input functions in the same manner. &lt;code&gt;Estimator&lt;/code&gt; only passes params along, it does not inspect it. The structure of &lt;code&gt;params&lt;/code&gt; is therefore entirely up to the developer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d95e516d4f18ca77f6adc9dd062547aed852bf4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;partition_strategy&lt;/code&gt; is always &lt;code&gt;&quot;div&quot;&lt;/code&gt; currently. This means that we assign ids to partitions in a contiguous manner. For instance, 13 ids are split across 5 partitions as: &lt;code&gt;[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52630b2e3206fda8f0264a5aa2143342644368d9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;percentage_below&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the percentage of &lt;code&gt;values&lt;/code&gt; that fall below &lt;code&gt;threshold&lt;/code&gt;. This rate is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;percentage&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ff7ad77d0b4964b4f1ddd1a1b58d2783393a3a7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;precision&lt;/code&gt; function creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;, that are used to compute the precision. This value is ultimately returned as &lt;code&gt;precision&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dd1225edff0d711a1d881f6569af599477db82d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;precision_at_thresholds&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; for various values of thresholds. &lt;code&gt;precision[i]&lt;/code&gt; is defined as the total weight of values in &lt;code&gt;predictions&lt;/code&gt; above &lt;code&gt;thresholds[i]&lt;/code&gt; whose corresponding entry in &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, divided by the total weight of values in &lt;code&gt;predictions&lt;/code&gt; above &lt;code&gt;thresholds[i]&lt;/code&gt; (&lt;code&gt;true_positives[i] / (true_positives[i] + false_positives[i])&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eefdf49a7cc35e9901e07fb1fbbe5c8a0436241" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;pred_fn_pairs&lt;/code&gt; parameter is a dict or list of pairs of size N. Each pair contains a boolean scalar tensor and a python callable that creates the tensors to be returned if the boolean evaluates to True. &lt;code&gt;default&lt;/code&gt; is a callable generating a list of tensors. All the callables in &lt;code&gt;pred_fn_pairs&lt;/code&gt; as well as &lt;code&gt;default&lt;/code&gt; (if provided) should return the same number and types of tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34976fcb5528295e8ddc3902a61df136b0d0ffdf" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;pred_fn_pairs&lt;/code&gt; parameter is a list of pairs of size N. Each pair contains a boolean scalar tensor and a python callable that creates the tensors to be returned if the boolean evaluates to True. &lt;code&gt;default&lt;/code&gt; is a callable generating a list of tensors. All the callables in &lt;code&gt;pred_fn_pairs&lt;/code&gt; as well as &lt;code&gt;default&lt;/code&gt; (if provided) should return the same number and types of tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="968a8378fc8eb3fdd1fb2170f34eb48e9c1bec93" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;ready_for_local_init_op&lt;/code&gt; is an &lt;code&gt;Operation&lt;/code&gt; used to check if the model is ready to run local_init_op. The model is considered ready if that operation returns an empty 1D string tensor. If the operation returns a non empty 1D string tensor, the elements are concatenated and used to indicate to the user why the model is not ready.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8200e403875e28ce9b4147cac96db59b27a581ff" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;ready_op&lt;/code&gt; is an &lt;code&gt;Operation&lt;/code&gt; used to check if the model is ready. The model is considered ready if that operation returns an empty 1D string tensor. If the operation returns a non empty 1D string tensor, the elements are concatenated and used to indicate to the user why the model is not ready.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e2627a0b13cf79619cf55143c1bafbedffc6df2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;recall&lt;/code&gt; function creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;, that are used to compute the recall. This value is ultimately returned as &lt;code&gt;recall&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb44adc5fb4d7d2974a8444bc13883fdc576fe0e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;recall_at_thresholds&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; for various values of thresholds. &lt;code&gt;recall[i]&lt;/code&gt; is defined as the total weight of values in &lt;code&gt;predictions&lt;/code&gt; above &lt;code&gt;thresholds[i]&lt;/code&gt; whose corresponding entry in &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, divided by the total weight of &lt;code&gt;True&lt;/code&gt; values in &lt;code&gt;labels&lt;/code&gt; (&lt;code&gt;true_positives[i] / (true_positives[i] + false_negatives[i])&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1de524f73c4314e7c1d91fd220ad1d6d3224de54" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;reverse&lt;/code&gt; and &lt;code&gt;exclusive&lt;/code&gt; kwargs can also be combined:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7095d9dae674a6139b14cf56a48942249fb95a3a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;root_mean_squared_error&lt;/code&gt; function creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the root mean squared error. This average is weighted by &lt;code&gt;weights&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;root_mean_squared_error&lt;/code&gt;: an idempotent operation that takes the square root of the division of &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="458e5a2574272cd3d33b7c903a0b4f0ec7f14636" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;run_context&lt;/code&gt; argument is a &lt;code&gt;SessionRunContext&lt;/code&gt; that provides information about the upcoming &lt;code&gt;run()&lt;/code&gt; call: the originally requested op/tensors, the TensorFlow Session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf828e3dc7b5c6afebb2a4e95b3f86639dbbc64b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;run_context&lt;/code&gt; argument is the same one send to &lt;code&gt;before_run&lt;/code&gt; call. &lt;code&gt;run_context.request_stop()&lt;/code&gt; can be called to stop the iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94f5d1df32e6ce942188c9ddfd764b608ff17856" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;run_values&lt;/code&gt; argument contains results of requested ops/tensors by &lt;code&gt;before_run()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be802e4b5940c54925a16198fd046cde07510ef1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;save_path&lt;/code&gt; argument is typically a value previously returned from a &lt;code&gt;save()&lt;/code&gt; call, or a call to &lt;code&gt;latest_checkpoint()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f865f0bbd1d6f2fff1a5c15f6500c2a842d180ca" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;seed&lt;/code&gt; argument produces a deterministic sequence of tensors across multiple calls. To repeat that sequence, use &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd56b7af0c6b81f60b1e8953cb5fa5a8ea87a447" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sensitivity_at_specificity&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the sensitivity at the given specificity value. The threshold for the given specificity value is computed and used to evaluate the corresponding sensitivity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e87df8700aa595c22c3204338d3a54c757320ca4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sequence&lt;/code&gt; format is recommended as the one with the best performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c2d41a4697cb394d4d9e0620c83a904374239b4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;session&lt;/code&gt; argument can be used in case the hook wants to run final ops, such as saving a last checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c5409b22ac50361a38c4e5620fb792814a952ea" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;session&lt;/code&gt; argument to the constructor makes the returned &lt;code&gt;FileWriter&lt;/code&gt; a compatibility layer over new graph-based summaries (&lt;code&gt;tf.contrib.summary&lt;/code&gt;). Crucially, this means the underlying writer resource and events file will be shared with any other &lt;code&gt;FileWriter&lt;/code&gt; using the same &lt;code&gt;session&lt;/code&gt; and &lt;code&gt;logdir&lt;/code&gt;, and with any &lt;code&gt;tf.contrib.summary.SummaryWriter&lt;/code&gt; in this session using the the same shared resource name (which by default scoped to the logdir). If no such resource exists, one will be created using the remaining arguments to this constructor, but if one already exists those arguments are ignored. In either case, ops will be added to &lt;code&gt;session.graph&lt;/code&gt; to control the underlying file writer resource. See &lt;code&gt;tf.contrib.summary&lt;/code&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97ff29fadf0e70b89b34fdebe66a53feae7519dd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;set_verbosity&lt;/code&gt; function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="303d3a64650f2563c6f2537d372e68f6d33680c2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;shape&lt;/code&gt; argument to &lt;code&gt;Variable&lt;/code&gt;'s constructor allows you to construct a variable with a less defined shape than its &lt;code&gt;initial_value&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c69ff0d563e037b396ab2e9976bb7ebc62fb1134" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;shapes&lt;/code&gt; argument must be specified; each component of a queue element must have the respective shape. Shapes of fixed rank but variable size are allowed by setting any shape dimension to None. In this case, the inputs' shape may vary along the given dimension, and &lt;code&gt;dequeue_many&lt;/code&gt; will pad the given dimension with zeros up to the maximum shape of all elements in the given batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d1e6359fd2b9322b254250e0bc1bdb6607c603e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sizes&lt;/code&gt; tensor specifies repeat counts for each field. The repeat count (last dimension) of a each tensor in &lt;code&gt;values&lt;/code&gt; must be greater than or equal to corresponding repeat count in &lt;code&gt;sizes&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6881b3cf0171ded834c55d240775c14753ca1a7e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;sparse_combiner&lt;/code&gt; argument works as follows For example, for two features represented as the categorical columns:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8e8fe9df97a94b949937ed1f21ec89b558385be" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;specificity_at_sensitivity&lt;/code&gt; function creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the specificity at the given sensitivity value. The threshold for the given sensitivity value is computed and used to evaluate the corresponding specificity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb73b0594146c19de95fb48de33a2ddca84ec873" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;stride&lt;/code&gt; argument determines the stride of the input elements, and the &lt;code&gt;shift&lt;/code&gt; argument determines the shift of the window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cb863ed936a846c83669117e5a427aa5ac1c932" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;tensors_list&lt;/code&gt; argument is a list of tuples of tensors, or a list of dictionaries of tensors. Each element in the list is treated similarly to the &lt;code&gt;tensors&lt;/code&gt; argument of &lt;a href=&quot;batch&quot;&gt;&lt;code&gt;tf.compat.v1.train.batch()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="410a750f639c5f1de66d97c0804239f72c4604d0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;tensors_list&lt;/code&gt; argument is a list of tuples of tensors, or a list of dictionaries of tensors. Each element in the list is treated similarly to the &lt;code&gt;tensors&lt;/code&gt; argument of &lt;a href=&quot;shuffle_batch&quot;&gt;&lt;code&gt;tf.compat.v1.train.shuffle_batch()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8643ae6bb3114dbfb70eef96843715bb87d8ebd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;timeout&lt;/code&gt; argument is the maximum number of seconds to block waiting for a new checkpoint. It is used in combination with the &lt;code&gt;timeout_fn&lt;/code&gt; as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="972185be83406631ec3872d41f4d67b45194a05d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;value&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;filters&lt;/code&gt; tensor has shape &lt;code&gt;[filters_height, filters_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9754d069f440bf7569706c44c08fdac07bea1efd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;value&lt;/code&gt; tensor has shape &lt;code&gt;[batch, in_height, in_width, depth]&lt;/code&gt; and the &lt;code&gt;kernel&lt;/code&gt; tensor has shape &lt;code&gt;[kernel_height, kernel_width, depth]&lt;/code&gt;, i.e., each input channel is processed independently of the others with its own structuring function. The &lt;code&gt;output&lt;/code&gt; tensor has shape &lt;code&gt;[batch, out_height, out_width, depth]&lt;/code&gt;. The spatial dimensions of the output tensor depend on the &lt;code&gt;padding&lt;/code&gt; algorithm. We currently only support the default &quot;NHWC&quot; &lt;code&gt;data_format&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e0b84cabe53e9e5c6c0da1ca87fa0c58be00cc6" translate="yes" xml:space="preserve">
          <source>The &lt;em&gt;EM&lt;/em&gt; algorithm where the &lt;em&gt;M-step&lt;/em&gt; should not involve backpropagation through the output of the &lt;em&gt;E-step&lt;/em&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b18ff4b0c03781a21c34b4aa7c91c48fe6607e87" translate="yes" xml:space="preserve">
          <source>The API also assigns ops in tf.compat.v1.trainable_variables() an op type called '_trainable_variables'. The API also logs 'flops' statistics for ops with op.RegisterStatistics() defined. flops calculation depends on Tensor shapes defined in 'graph', which might not be complete. 'run_meta', if provided, completes the shape information with best effort.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d0fc1f05596c2c92bd92cba556fe327b716c416" translate="yes" xml:space="preserve">
          <source>The Bernoulli distribution with &lt;code&gt;probs&lt;/code&gt; parameter, i.e., the probability of a &lt;code&gt;1&lt;/code&gt; outcome (vs a &lt;code&gt;0&lt;/code&gt; outcome).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9353ab8095bc0b0b24b3be126e8e9c7fb1f1ad3d" translate="yes" xml:space="preserve">
          <source>The Beta distribution is defined over the &lt;code&gt;(0, 1)&lt;/code&gt; interval using parameters &lt;code&gt;concentration1&lt;/code&gt; (aka &quot;alpha&quot;) and &lt;code&gt;concentration0&lt;/code&gt; (aka &quot;beta&quot;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abea42cad220fd20eda787ac80e243e2cf47e13d" translate="yes" xml:space="preserve">
          <source>The Categorical distribution is closely related to the &lt;code&gt;OneHotCategorical&lt;/code&gt; and &lt;code&gt;Multinomial&lt;/code&gt; distributions. The Categorical distribution can be intuited as generating samples according to &lt;code&gt;argmax{ OneHotCategorical(probs) }&lt;/code&gt; itself being identical to &lt;code&gt;argmax{ Multinomial(probs, total_count=1) }&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c2637ba9bb0ae73ad068069b2445eb1bf971490" translate="yes" xml:space="preserve">
          <source>The Categorical distribution is parameterized by either probabilities or log-probabilities of a set of &lt;code&gt;K&lt;/code&gt; classes. It is defined over the integers &lt;code&gt;{0, 1, ..., K}&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a66f064277a2e3928ce326dffecdba70543ff622" translate="yes" xml:space="preserve">
          <source>The ClusterResolver will then use the parameters to query the Cloud TPU APIs for the IP addresses and ports of each Cloud TPU listed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="345e361eb29b1a63bf06b68ef8175eed879cd43c" translate="yes" xml:space="preserve">
          <source>The Coordinator can be useful if you want to run multiple threads during your training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="762ae5bf9871f156d31ebbf73968a3d2925b8520" translate="yes" xml:space="preserve">
          <source>The Dirichlet distribution is defined over the &lt;a href=&quot;https://en.wikipedia.org/wiki/Simplex&quot;&gt;&lt;code&gt;(k-1)&lt;/code&gt;-simplex&lt;/a&gt; using a positive, length-&lt;code&gt;k&lt;/code&gt; vector &lt;code&gt;concentration&lt;/code&gt; (&lt;code&gt;k &amp;gt; 1&lt;/code&gt;). The Dirichlet is identically the Beta distribution when &lt;code&gt;k = 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e30884de69ccdd0148c69a6e73300256037fabed" translate="yes" xml:space="preserve">
          <source>The Dirichlet is a distribution over the open &lt;code&gt;(k-1)&lt;/code&gt;-simplex, i.e.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e41a41e81118c558d85cbc4587e8d93ce2121bf" translate="yes" xml:space="preserve">
          <source>The Dirichlet-Multinomial distribution is parameterized by a (batch of) length-&lt;code&gt;K&lt;/code&gt;&lt;code&gt;concentration&lt;/code&gt; vectors (&lt;code&gt;K &amp;gt; 1&lt;/code&gt;) and a &lt;code&gt;total_count&lt;/code&gt; number of trials, i.e., the number of trials per draw from the DirichletMultinomial. It is defined over a (batch of) length-&lt;code&gt;K&lt;/code&gt; vector &lt;code&gt;counts&lt;/code&gt; such that &lt;code&gt;tf.reduce_sum(counts, -1) = total_count&lt;/code&gt;. The Dirichlet-Multinomial is identically the Beta-Binomial distribution when &lt;code&gt;K = 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e283a7e839668d96942d9fe27b03aceff70e822" translate="yes" xml:space="preserve">
          <source>The Dirichlet-Multinomial is a distribution over &lt;code&gt;K&lt;/code&gt;-class counts, i.e., a length-&lt;code&gt;K&lt;/code&gt; vector of non-negative integer &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f02fcb57d9bed9fe1cb9e26959ca7e29bea23df5" translate="yes" xml:space="preserve">
          <source>The Exponential distribution is a special case of the Gamma distribution, i.e.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6f3e5f56915f923971b04b2d769299865559dab" translate="yes" xml:space="preserve">
          <source>The Exponential distribution is parameterized by an event &lt;code&gt;rate&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2d0890a7adeefe2d23082f4a11de8d57d4d1ed8" translate="yes" xml:space="preserve">
          <source>The Exponential distribution uses a &lt;code&gt;rate&lt;/code&gt; parameter, or &quot;inverse scale&quot;, which can be intuited as,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="609d4d600899851c7fc93aa7a4ce757600207e0c" translate="yes" xml:space="preserve">
          <source>The Gamma distribution is defined over positive real numbers using parameters &lt;code&gt;concentration&lt;/code&gt; (aka &quot;alpha&quot;) and &lt;code&gt;rate&lt;/code&gt; (aka &quot;beta&quot;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79a61f2d86901aebd84ad8b2d9002905d13b2a9f" translate="yes" xml:space="preserve">
          <source>The Glorot normal initializer, also called Xavier normal initializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d823ca2ee407bbabe7dc4bda0e7dfaa683e7ffd" translate="yes" xml:space="preserve">
          <source>The Glorot uniform initializer, also called Xavier uniform initializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10c27f35329e2804c14ef129a0fd65ea4a51e512" translate="yes" xml:space="preserve">
          <source>The GraphDef of the sub-graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="216c6a790806834283ef828e6ca13d0147897e6b" translate="yes" xml:space="preserve">
          <source>The GraphDef version information of this graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="655c4658cd7a0d63da53a13b211c6ef8e7cc1af3" translate="yes" xml:space="preserve">
          <source>The Hessian is a matrix of second-order partial derivatives of a scalar tensor (see https://en.wikipedia.org/wiki/Hessian_matrix for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d81e5e619b3ab76ee0da2d228e26df5c365438e4" translate="yes" xml:space="preserve">
          <source>The Hurwitz zeta function is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ed2ecdaa3bd96954ea77dce173719510eac3340" translate="yes" xml:space="preserve">
          <source>The ID of the module which registered the flag with this name. If no such module exists (i.e. no flag with this name exists), we return default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87056d72e53edb8e1ee915616502d31a9e2351aa" translate="yes" xml:space="preserve">
          <source>The Keras functional API in TensorFlow</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36e14ec6d1ffdc156a9c3f1daa6d9890ec3b1e0e" translate="yes" xml:space="preserve">
          <source>The L1 regularization penalty is computed as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c4ad0ec53302f5554ee8c8eb2b239ae6b215ee1" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f994e1d48c4b2ebd97fc4c0f1abd04009e95050" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7557d40db7eef29f9f5cf0c8852c6278d915ffe" translate="yes" xml:space="preserve">
          <source>The Laplace distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f02ec145e8b375175cc81c541eb3f581408f36f" translate="yes" xml:space="preserve">
          <source>The Lpalce distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="179fc5d20bec0f4afac4c22aa43296f1c61f1b50" translate="yes" xml:space="preserve">
          <source>The Multinomial is a distribution over &lt;code&gt;K&lt;/code&gt;-class counts, i.e., a length-&lt;code&gt;K&lt;/code&gt; vector of non-negative integer &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="024145881176dd778a381db52296681ba8110801" translate="yes" xml:space="preserve">
          <source>The Normal distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7626aa48ba3874551b7938ac31ee1cdb369fcdfb" translate="yes" xml:space="preserve">
          <source>The Normal distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef840b903d3e772791466fbdbfc1be244accb53f" translate="yes" xml:space="preserve">
          <source>The Python type for values that are compatible with this TypeSpec.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb43dc4932964141b3fdd553bcbf71855032420a" translate="yes" xml:space="preserve">
          <source>The RNG algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="930b59a35037eb9f2e4f2e6718a1e37b8aaa1b56" translate="yes" xml:space="preserve">
          <source>The SDCA algorithm was originally introduced in [1] and it was followed by the L1 proximal step [2], a distributed version [3] and adaptive sampling [4]. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] https://arxiv.org/pdf/1309.2375.pdf [3] https://arxiv.org/pdf/1502.03508.pdf [4] https://arxiv.org/pdf/1502.08053.pdf Details specific to this implementation are provided in: https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a77ce4bc58a785318ac8e94fd8eec273d01ff9a4" translate="yes" xml:space="preserve">
          <source>The SavedModel serialization path uses &lt;a href=&quot;../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; to save the model and all trackable objects attached to the model (e.g. layers and variables). &lt;code&gt;@tf.function&lt;/code&gt;-decorated methods are also saved. Additional trackable objects and functions are added to the SavedModel to allow the model to be loaded back as a Keras Model object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60a134651d9227079722cdc9e74feb1653be5aa4" translate="yes" xml:space="preserve">
          <source>The Scaled Exponential Linear Unit (SELU) activation function is: &lt;code&gt;scale * x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;scale * alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; where &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are pre-defined constants (&lt;code&gt;alpha = 1.67326324&lt;/code&gt; and &lt;code&gt;scale = 1.05070098&lt;/code&gt;). The SELU activation function multiplies &lt;code&gt;scale&lt;/code&gt; &amp;gt; 1 with the &lt;code&gt;[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)&lt;/code&gt; (Exponential Linear Unit (ELU)) to ensure a slope larger than one for positive net inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c9823ad487742ec2d729142bb77debf58c1e901" translate="yes" xml:space="preserve">
          <source>The SignatureDef will specify outputs as described in this ExportOutput, and will use the provided receiver_tensors as inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4545224fedce8f364aa3fd2d6cac68ea4817f884" translate="yes" xml:space="preserve">
          <source>The SimpleClusterResolver does not do automatic detection of accelerators, so a TensorFlow session will never be created, and thus all arguments are unused and we simply assume that the type of accelerator is a GPU and return the value in provided to us in the constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95d35b03ae5ea7cdb3cc356783df4e423a2dc6c1" translate="yes" xml:space="preserve">
          <source>The StudentT distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c2d5184416b64215504aa1a967e583b20731ca8" translate="yes" xml:space="preserve">
          <source>The Supervisor is a small wrapper around a &lt;code&gt;Coordinator&lt;/code&gt;, a &lt;code&gt;Saver&lt;/code&gt;, and a &lt;code&gt;SessionManager&lt;/code&gt; that takes care of common needs of TensorFlow training programs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41bd5ff6b458ccdec0fd96ba0408336a12a70400" translate="yes" xml:space="preserve">
          <source>The TF-TRT converted Function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="363164ea24b07b74dc51248150c976cfc6c56e68" translate="yes" xml:space="preserve">
          <source>The Tensor or SparseTensor or CompositeTensor in &lt;code&gt;graph&lt;/code&gt; described by &lt;code&gt;tensor_info&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b213eabf8ccb6ff5bf4ab0a41158ab15e62ff3b" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;../model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ab4684c965e60031ddf80734d60fea35c517d3d" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7638d4a5c348f022578401c2f1df999594f7eff" translate="yes" xml:space="preserve">
          <source>The TensorFlow process to which this session will connect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16a70a758b7ef6d7fd0aad2771edf2a93446ebcd" translate="yes" xml:space="preserve">
          <source>The Tensors returned by computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45ecd5a2e94b407ef5967be01d6aea7e5dfb3bca" translate="yes" xml:space="preserve">
          <source>The Variable has rank &lt;code&gt;P&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt; of rank &lt;code&gt;Q&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f53a9ea2c1d95dd8b27a8885316c2bc7fb8ad0c0" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the input become the high order component of the output channel index.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d6c86d0708bda3da64a9da6d3c863b9ab737231" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the output image are determined by the high order component of the input channel index.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cd36e977186fec64e8448a96228fbf260cd4605" translate="yes" xml:space="preserve">
          <source>The ZLIB compression level, &lt;code&gt;compression&lt;/code&gt;, can be -1 for the PNG-encoder default or a value from 0 to 9. 9 is the highest compression level, generating the smallest output, but is slower.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce03da9cead6e86adf2a8009f5862736d75ecdca" translate="yes" xml:space="preserve">
          <source>The [batch] scalar &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt; in &lt;code&gt;cI&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaf6c09a17773617259c0e894f03f2f3f8ff8317" translate="yes" xml:space="preserve">
          <source>The above changes os.path.exists into a lambda that returns 1. Once the ... part of the code finishes, the CleanUp() looks up the old value of os.path.exists and restores it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8bb936a65c3ce409995481c6a4f6df5ec2956c6" translate="yes" xml:space="preserve">
          <source>The activation value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da7330feac6d473367759d5dd1a21e9334b8d8de" translate="yes" xml:space="preserve">
          <source>The added Keras attribute is: &lt;code&gt;_keras_history&lt;/code&gt;: Last layer applied to the tensor. the entire layer graph is retrievable from that layer, recursively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f24861cc1a42612e73b3f3665071eeed2c9ea315" translate="yes" xml:space="preserve">
          <source>The additional robustness comes at a cost of roughly 4x higher compute time than &lt;code&gt;tf.string_to_hash_bucket_fast&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92d822d5e3a4a473e569254158aeaed3f44c8de9" translate="yes" xml:space="preserve">
          <source>The address of the given task in the given job.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1044e0e4428294ca84bc27c7d972e47ecc834421" translate="yes" xml:space="preserve">
          <source>The address of the master.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a671b38fc84a246388b74802d7c3903f8c308213" translate="yes" xml:space="preserve">
          <source>The adjoint (a.k.a. Hermitian transpose a.k.a. conjugate transpose) of matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d26f5dd591fe207d72f8bf3767404f30851360da" translate="yes" xml:space="preserve">
          <source>The adjusted &lt;code&gt;min_range&lt;/code&gt; and &lt;code&gt;max_range&lt;/code&gt; are returned as outputs 2 and 3 of this operation. These outputs should be used as the range for any further calculations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34a7065e06c55b3339a4e1c47bf34bd00d072e70" translate="yes" xml:space="preserve">
          <source>The algorithm starts by setting the loss scale to an initial value. Every N steps that the gradients are finite, the loss scale is increased by some factor. However, if a NaN or Inf gradient is found, the gradients for that step are not applied, and the loss scale is decreased by the factor. This process tends to keep the loss scale as high as possible without gradients overflowing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec9f002d6d3b1e71963d9cf73b905f9b84153981" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="821f24c959536d42cc6fec55c7d0ad6a3d16e3c7" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;. As an operator. The operator also has a &lt;code&gt;assign()&lt;/code&gt; method that can be used to generate an assignment operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23ef91f4c9a43b0bf509fbf539d12c4d114f51e2" translate="yes" xml:space="preserve">
          <source>The area within the interval is (slope / total_pos_weight) times</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2d3e064486f4100aead5629a0acce01f2954896" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;normalized&lt;/code&gt; and &lt;code&gt;centered&lt;/code&gt; controls how the windows are built:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="572a6d647b031b519cd29780ad535922e4e59db7" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;shape&lt;/code&gt; is optional. If present, it specifies the dimensions of the resulting tensor. If not present, the shape of &lt;code&gt;value&lt;/code&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13e87601baeedfadd1e05e7b900ecdbd205d0bf6" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;tensors&lt;/code&gt; can be a list or a dictionary of tensors. The value returned by the function will be of the same type as &lt;code&gt;tensors&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a32d0e1dadf3135bed15ded733117d1a197ad906" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the &lt;code&gt;shape&lt;/code&gt; argument (if specified). In the case where the list length is less than the number of elements specified by &lt;code&gt;shape&lt;/code&gt;, the last element in the list will be used to fill the remaining entries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f585d29c2b28791ced3d5b4a780f2d82b9f8bf3" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the desired shape of the tensor. In the case where the total number of elements in &lt;code&gt;value&lt;/code&gt; is less than the number of elements required by the tensor shape, the last element in &lt;code&gt;value&lt;/code&gt; will be used to fill the remaining entries. If the total number of elements in &lt;code&gt;value&lt;/code&gt; is greater than the number of elements required by the tensor shape, the initializer will raise a &lt;code&gt;ValueError&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35b02213c63b22c6aa288eadb099101e8c7a8bb2" translate="yes" xml:space="preserve">
          <source>The argument returned by this function is of the form \(atan2(b, a)\). If &lt;code&gt;input&lt;/code&gt; is real, a tensor of all zeros is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bce43bdee979454925721c507561e0a29cfacb37" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., &lt;code&gt;local_step&lt;/code&gt; is less than the accumulator's global time step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2d9f9b7d3b4bc909dac3ec1179989967a68da98" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., local_step is less than the accumulator's global time step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8f6f1e67bc16f32d9f24b6bf9dc1327c99b4c20" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;block_size&lt;/code&gt; must be greater than one. It indicates the block size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b44ab2abacbb2efdb69194961a5971ce5296193c" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;channels&lt;/code&gt; indicates the desired number of color channels for the decoded image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60563f76a3b65c009555c6aca9d9b0a28f8e6c56" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;format&lt;/code&gt; can be used to override the color format of the encoded output. Values can be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae606ee2da5f189375721f138e9665ac82e81365" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;ratio&lt;/code&gt; allows downscaling the image by an integer factor during decoding. Allowed values are: 1, 2, 4, and 8. This is much faster than downscaling the image later.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43192d2acab6f30a3fb88a081e4480c6a4eaf531" translate="yes" xml:space="preserve">
          <source>The base class for all flags errors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95fac0e9d908797873ec2155df12d61346d3ec3c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is an approximately log-uniform or Zipfian distribution:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e03722f7ec155314d6d64a06632231a0220ddf21" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is constructed on the fly during training. It is a unigram distribution over the target classes seen so far during training. Every integer in &lt;code&gt;[0, range_max)&lt;/code&gt; begins with a weight of 1, and is incremented by 1 each time it is seen as a target class. The base distribution is not saved to checkpoints, so it is reset when the model is reloaded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b285a7357154664da97ef50a86143b40cc66c8c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is the uniform distribution over the range of integers &lt;code&gt;[0, range_max)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77b83a8d332ed8aca766d79f4120f4e0ba2ea928" translate="yes" xml:space="preserve">
          <source>The base distribution is read from a file or passed in as an in-memory array. There is also an option to skew the distribution by applying a distortion power to the weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c0a22a2ecdff77c481cab7326fe4aaa0b144cf7" translate="yes" xml:space="preserve">
          <source>The batch dimensions are indexes into independent, non-identical parameterizations of this distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b55a5f5737af8dc7c66469a674fe7b35b3d67f61" translate="yes" xml:space="preserve">
          <source>The batch dimensions, denoted as &lt;code&gt;...&lt;/code&gt;, must be the same in &lt;code&gt;diagonals&lt;/code&gt; and &lt;code&gt;rhs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8d1e654d8a3893e3ebd1816b79375a5883dc270" translate="yes" xml:space="preserve">
          <source>The batch of the output tensor is &lt;code&gt;batch * block_size * block_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9d6c8abb90d01f2c83046e4ffaae926e1136406" translate="yes" xml:space="preserve">
          <source>The biggest difference between this and MIN_COMBINED is that the minimum range is rounded first, before it's subtracted from the rounded value. With MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing and dequantizing will introduce a larger and larger error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72445c1ce9af91d1b7756490161ef93a455800a7" translate="yes" xml:space="preserve">
          <source>The binomial distribution with parameters &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;p&lt;/code&gt; is the probability distribution of the number of successful Bernoulli process. Only supports &lt;code&gt;n&lt;/code&gt; = 1 for now.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9046a47f005a317609f27142cf924b36a45d9e12" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="794d80e295e24e3ff23cc23c744638ef8dd2ef67" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;tf.SavedModel&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e7703441ddf5ba9641cb1cc0ad74e7c6c58e3a7" translate="yes" xml:space="preserve">
          <source>The brightness-adjusted image(s).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1e48a233423d312fda6e60318a1f77840441ac1" translate="yes" xml:space="preserve">
          <source>The call arguments for this layer are the same as those of the wrapped RNN layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e327ae814821b8183785f0c019aba0430d092c8e" translate="yes" xml:space="preserve">
          <source>The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffd9bc04f2dc35c549a84231faac7f8f675d1f25" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;../../../train/checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efb4974f19ee7156bcbc2c149c6eb12fbb9c2851" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cf3d251f72fdb454086ef22c80d6dfc9f2a709b" translate="yes" xml:space="preserve">
          <source>The checkpoint prefix. If there are no checkpoints, returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54c52716619b24d86f051441e79e67309f282670" translate="yes" xml:space="preserve">
          <source>The class specifies the parameters to configure a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; as it is initialized to a &lt;a href=&quot;logicaldevice&quot;&gt;&lt;code&gt;tf.config.LogicalDevice&lt;/code&gt;&lt;/a&gt; during runtime initialization. Not all fields are valid for all device types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cadabc814bf5f30961f39db7a416141d019058e" translate="yes" xml:space="preserve">
          <source>The class uses optional peep-hole connections, optional cell clipping, and an optional projection layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5550331649ac8852e50082985bc4347ae4ddf34" translate="yes" xml:space="preserve">
          <source>The classes &lt;code&gt;Tensor&lt;/code&gt; must provide string labels, not integer class IDs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8055f38c5a2a613d3b7898156485e396610a7e44" translate="yes" xml:space="preserve">
          <source>The companion method &lt;code&gt;start_queue_runners()&lt;/code&gt; can be used to start threads for all the collected queue runners.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97a9b8c4557a2e822deec22848a2c3bf8b143002" translate="yes" xml:space="preserve">
          <source>The compatibility module also provides the following aliases for common sets of python types:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c76eb8b972301e83c208f809121c80f183543a3c" translate="yes" xml:space="preserve">
          <source>The compatibility relation is reflexive and symmetric, but not transitive. For example, TensorShape([32, 784]) is compatible with TensorShape(None), and TensorShape(None) is compatible with TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with TensorShape([4, 4]).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc1fe8d57fc26b638818429d0e0fce300365e0f7" translate="yes" xml:space="preserve">
          <source>The compilation flags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="004ddc3feaeb4999946bd055243271e6c1c5e458" translate="yes" xml:space="preserve">
          <source>The compilation is a hint and only supported on a best-effort basis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a97fc9aeef3aac0ee7b0d6fc3913b5f131a8ce4" translate="yes" xml:space="preserve">
          <source>The complex conjugate returned by this operation is of the form \(a - bj\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f00bf6687c043d2091a7a6b17f2dcc072382a50" translate="yes" xml:space="preserve">
          <source>The components of the resulting element will have an additional outer dimension, which will be &lt;code&gt;batch_size&lt;/code&gt; (or &lt;code&gt;N % batch_size&lt;/code&gt; for the last element if &lt;code&gt;batch_size&lt;/code&gt; does not divide the number of input elements &lt;code&gt;N&lt;/code&gt; evenly and &lt;code&gt;drop_remainder&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;). If your program depends on the batches having the same outer dimension, you should set the &lt;code&gt;drop_remainder&lt;/code&gt; argument to &lt;code&gt;True&lt;/code&gt; to prevent the smaller batch from being produced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="344c73fb9ddb71179637f498f0b34262b87c80b8" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy, or None if the compute dtype should be inferred from the inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="205f439cb062a6f6e02604aa48a1bdc6926c8224" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a56e1ae6d24fcbef9729431047071ed9efb2c36" translate="yes" xml:space="preserve">
          <source>The concatenated rows for this ragged tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e975fea798f7bc222374c880c42a36989a17b66" translate="yes" xml:space="preserve">
          <source>The concatenated values for all rows in this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f6fe2c98e185c3c57a927e557bcc1cd36a6a7d8" translate="yes" xml:space="preserve">
          <source>The concentration parameters represent mean total counts of a &lt;code&gt;1&lt;/code&gt; or a &lt;code&gt;0&lt;/code&gt;, i.e.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b10cf771707704e5f421193cabc5bea06bcefd0e" translate="yes" xml:space="preserve">
          <source>The config of a layer does not include connectivity information, nor the layer class name. These are handled by &lt;code&gt;Network&lt;/code&gt; (one layer of abstraction above).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6cabe853a86fe4b25fb9e66ffa23b7c23ff8a8" translate="yes" xml:space="preserve">
          <source>The constraint function that was passed to the variable constructor. Can be &lt;code&gt;None&lt;/code&gt; if no constraint was passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c73cc83e59c2cc8b75ad073ccf807211d4803200" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adc492d7eedfc240429addc422d2a1187a94cf41" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value. Args: flag_name: str, name of the flag to be checked. checker: callable, a function to validate the flag. input - A single positional argument: The value of the corresponding flag (string, boolean, etc. This value will be passed to checker by the library). output - bool, True if validator constraint is satisfied. If constraint is not satisfied, it should either return False or raise flags.ValidationError(desired_error_message). message: str, error text to be shown to the user if checker returns False. If checker raises flags.ValidationError, message from the raised error will be shown. flag_values: flags.FlagValues, optional FlagValues instance to validate against. Raises: AttributeError: Raised when flag_name is not registered as a valid flag name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dc698ae175b05a09fb4ee349bbc6ecaa1e8c775" translate="yes" xml:space="preserve">
          <source>The constructor adds ops to save and restore variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65be7a0d51d3df0c44e8373ef2d8cce6fba1ba7f" translate="yes" xml:space="preserve">
          <source>The contents of that resource.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b796712e9d45d917e86f476afcbd17188df9e41f" translate="yes" xml:space="preserve">
          <source>The context manager is typically used as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4d7d6dd724445c75543c5c53e6ef9742d69f23b" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the exception as the 'exception' attribute. This allows you to inspect the exception after the assertion::</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b36c5f83db5c2031ce81fe755689bacbd226c222" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the first matching warning as the 'warning' attribute; similarly, the 'filename' and 'lineno' attributes give you information about the line of Python code from which the warning was triggered. This allows you to inspect the warning after the assertion::</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eb98e6489cd882c0c18e1586be464efd5024b02" translate="yes" xml:space="preserve">
          <source>The contracted &lt;code&gt;Tensor&lt;/code&gt;, with shape determined by &lt;code&gt;equation&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db43655e2d0d002f7fe5b43dfac52f092c80941c" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image or images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7ed10745c14b330776ee5fc3a5ec88c5d4b915d" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image(s).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14bfe517dc85759a813f2eb60977041c4d4420dc" translate="yes" xml:space="preserve">
          <source>The conversion function may return &lt;code&gt;NotImplemented&lt;/code&gt; for some inputs. In this case, the conversion process will continue to try subsequent conversion functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="993593e7b0bd02f95abe229cbbe58be1069a603a" translate="yes" xml:space="preserve">
          <source>The conversion function must have the following signature:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62c1d16c5d29bf1d22b745f14080c7842854b090" translate="yes" xml:space="preserve">
          <source>The conversion rules are as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e10ca4df9812779b916afce6a1d1c3326adb544f" translate="yes" xml:space="preserve">
          <source>The converted code as string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a4c4fcb504882f83a37ad22c73c28617ce613ed" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f85bd8e5f77e08669b54d651dbd9c3373a46949" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format. Either a TFLite Flatbuffer or a Graphviz graph depending on value in &lt;code&gt;output_format&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1373b125f4cfa9b84ebc99ddf4f15c0c28515a5" translate="yes" xml:space="preserve">
          <source>The converted data. For example if TFLite was the destination, then this will be a tflite flatbuffer in a bytes array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60fb348ae8fb1997effd221344f7a9df143ed5c3" translate="yes" xml:space="preserve">
          <source>The converted grayscale image(s).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="947c64ff75e26c329d08f9139c4ae882c26c7ee7" translate="yes" xml:space="preserve">
          <source>The copyright for Fashion-MNIST is held by Zalando SE. Fashion-MNIST is licensed under the &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE&quot;&gt;MIT license&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1800b9129135de634c28deac11e3c72d5b276b9a" translate="yes" xml:space="preserve">
          <source>The corresponding &lt;code&gt;equation&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d08fae5c7558eeecccf8b9086f7da5fad59afff7" translate="yes" xml:space="preserve">
          <source>The corresponding dense tensor satisfies:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e9a5d7d3994fde2a58974f329ed60d12e01398" translate="yes" xml:space="preserve">
          <source>The covariance between elements in a batch is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f7c01ee2660f457c23437a997e09405b750c261" translate="yes" xml:space="preserve">
          <source>The covariance for each batch member is defined as the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab3d07f930a48f37a430eaef5bc7e0c838a99b3b" translate="yes" xml:space="preserve">
          <source>The created &lt;a href=&quot;../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf06fef8a51d3d2222f888311b63cf162081ff33" translate="yes" xml:space="preserve">
          <source>The created Operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf8da6d42e9abc38af87cab58b26796f2a78e3eb" translate="yes" xml:space="preserve">
          <source>The created or existing &lt;code&gt;Variable&lt;/code&gt; (or &lt;code&gt;PartitionedVariable&lt;/code&gt;, if a partitioner was used).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="703c3b3c61be2bbfe2cef58610e4241c0cec208f" translate="yes" xml:space="preserve">
          <source>The created variable. Usually either a &lt;code&gt;Variable&lt;/code&gt; or &lt;code&gt;ResourceVariable&lt;/code&gt; instance. If &lt;code&gt;partitioner&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, a &lt;code&gt;PartitionedVariable&lt;/code&gt; instance is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a064f7a86a7da90002c28e35d9ae72e6f6639e8c" translate="yes" xml:space="preserve">
          <source>The creator is supposed to eventually call the next_creator to create a variable if it does want to create a variable and not call Variable or ResourceVariable directly. This helps make creators composable. A creator may choose to create multiple variables, return already existing variables, or simply register that a variable was created and defer to the next creators in line. Creators can also modify the keyword arguments seen by the next creators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caefb816a5bf9fa47c79fd26eae5407f9e0b0029" translate="yes" xml:space="preserve">
          <source>The cumulative density function (cdf) is,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e6cf6bfd84a9de01475c57535a86c638dabf3bb" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;replicacontext&quot;&gt;&lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt;&lt;/a&gt; object when in a replica context scope, else &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f540e5e4425b87ae1543241ecadb7b9cf3701bab" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7121b0671de74726a9379ae7d9c7f6f65ce0582e" translate="yes" xml:space="preserve">
          <source>The current scope, enabling or disabling compilation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7dbd9f518a88378558ef3aa8f6e9b7c42f12504" translate="yes" xml:space="preserve">
          <source>The data type of this TensorArray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7ba10f144cbc87647590b7009fafb20f1cb2173" translate="yes" xml:space="preserve">
          <source>The data will be looped over (in batches).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7f912374554b917dc7b6ee9e848a59b9a0fe71e" translate="yes" xml:space="preserve">
          <source>The datatype of the gradients accumulated by this accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4e8811eed25239dbc70516d5c5274e75126f7f5" translate="yes" xml:space="preserve">
          <source>The debugging information is dumped to a directory on the file system specified as &lt;code&gt;dump_root&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af2ff91f6275afef5f274f54f89df6225cefc596" translate="yes" xml:space="preserve">
          <source>The decorated function will return the unbatched computation output Tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6284a54323a552b0a785e97eec39ef3920661508" translate="yes" xml:space="preserve">
          <source>The decorator argument &lt;code&gt;op_type&lt;/code&gt; is the string type of an operation. This corresponds to the &lt;code&gt;OpDef.name&lt;/code&gt; field for the proto that defines the operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f564553c5a97e5c3c841f380324c41f020971604" translate="yes" xml:space="preserve">
          <source>The decorator function must use &lt;code&gt;&amp;lt;decorator name&amp;gt;.__wrapped__&lt;/code&gt; instead of the wrapped function that is normally used:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="364632908db2fc42ec644ce9139f9d8cd2996dcc" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Graph&lt;/code&gt; being used in the current thread.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6131e418f0fe8f055f5c1a72e6a16e1545b1880" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Session&lt;/code&gt; being used in the current thread.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f66d887de726d32ad140fa1257a1df52151a3df" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;atol&lt;/code&gt; and &lt;code&gt;rtol&lt;/code&gt; is &lt;code&gt;10 * eps&lt;/code&gt;, where &lt;code&gt;eps&lt;/code&gt; is the smallest representable positive number such that &lt;code&gt;1 + eps != 1&lt;/code&gt;. This is about &lt;code&gt;1.2e-6&lt;/code&gt; in &lt;code&gt;32bit&lt;/code&gt;, &lt;code&gt;2.22e-15&lt;/code&gt; in &lt;code&gt;64bit&lt;/code&gt;, and &lt;code&gt;0.00977&lt;/code&gt; in &lt;code&gt;16bit&lt;/code&gt;. See &lt;code&gt;numpy.finfo&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62dd8de847ac23e7ac8e6762e2b31102b93ee7ae" translate="yes" xml:space="preserve">
          <source>The default Scaffold local init op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="113557875e0d10c0495e5968c62aac634844babc" translate="yes" xml:space="preserve">
          <source>The default graph is a property of the current thread. If you create a new thread, and wish to use the default graph in that thread, you must explicitly add a &lt;code&gt;with g.as_default():&lt;/code&gt; in that thread's function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3c4fe416ddd6e4cf097d426615758d9e0a2f0da" translate="yes" xml:space="preserve">
          <source>The default non-peephole implementation is based on:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b36d1ca5df94e6636114077cb6330c3dd4eb155f" translate="yes" xml:space="preserve">
          <source>The default type of the returned tensor is &lt;code&gt;'int32'&lt;/code&gt; to match TensorFlow's default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c204a6e1f3b1ac9d5e05754cf3c4c6bfcbf5ab6" translate="yes" xml:space="preserve">
          <source>The default value may be either a single value or an iterable of values. A single value is transformed into a single-item list of that value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2676c22d8481d2093eb1222e6a62c6e07d9d33bd" translate="yes" xml:space="preserve">
          <source>The default value of 1e-7 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dce55634f5d3cd5afd750385d4cb7a72c3b4e6e" translate="yes" xml:space="preserve">
          <source>The default value of 1e-8 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="615a8ce189d67deb5b00de2e039f587d13916340" translate="yes" xml:space="preserve">
          <source>The default value of the table.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="726ed70f0dc33ddfe7a4cc805d63238531bb85eb" translate="yes" xml:space="preserve">
          <source>The dense tensor &lt;code&gt;dense&lt;/code&gt; represented by an &lt;code&gt;IndexedSlices&lt;/code&gt;&lt;code&gt;slices&lt;/code&gt; has</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4266ae52077c5b23e390601d308e04d84d60ebbe" translate="yes" xml:space="preserve">
          <source>The deprecated &quot;infer&quot; policy</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47a704b6d6ba8a557d500ba37d0cbd25291c9ff6" translate="yes" xml:space="preserve">
          <source>The depth depends on profiling view. For 'scope' view, it's the depth of name scope hierarchy (tree), for 'op' view, it's the number of operation types (list), etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2137c8c00ab29126bb362981cb4aca8aa9eecd42" translate="yes" xml:space="preserve">
          <source>The depth of the input tensor must be divisible by &lt;code&gt;block_size * block_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="856f925406c2e2660e650087c5e577d9ef121b34" translate="yes" xml:space="preserve">
          <source>The depth of the output tensor is &lt;code&gt;block_size * block_size * input_depth&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56afabb9b384a9ae87fad18ee9dbf3881d1ccc16" translate="yes" xml:space="preserve">
          <source>The device of this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98f163e49909ba226b86dab21a009212ea93fb62" translate="yes" xml:space="preserve">
          <source>The device policy controls how operations requiring inputs on a specific device (e.g., on GPU:0) handle inputs on a different device (e.g. GPU:1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f251515ee7a7da78599205d7a6518a062a6c0f5e" translate="yes" xml:space="preserve">
          <source>The devices this replica is to be executed on, as a tuple of strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87dd79764107968d1c698ee175a895a731232435" translate="yes" xml:space="preserve">
          <source>The difference between &lt;code&gt;stack&lt;/code&gt; and &lt;code&gt;parallel_stack&lt;/code&gt; is that &lt;code&gt;stack&lt;/code&gt; requires all the inputs be computed before the operation will begin but doesn't require that the input shapes be known during graph construction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a741b7f6b1d2304d511eed765b55f2d892e70b1b" translate="yes" xml:space="preserve">
          <source>The dimensions in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; are merged elementwise, according to the rules defined for &lt;code&gt;Dimension.merge_with()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bc7db80b0d2774479326226a4890a6e2d843629" translate="yes" xml:space="preserve">
          <source>The directory as string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f003820357db00c0553228e9493dca5bc931d2d" translate="yes" xml:space="preserve">
          <source>The directory where files specified in data attribute of py_test and py_binary are stored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b7ccc3fd24de1a06b23a805fbbf6bc02487c531" translate="yes" xml:space="preserve">
          <source>The distances from each input point to each cluster center.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f58b91125c882dc2a62587a652492f254f94698" translate="yes" xml:space="preserve">
          <source>The distribution functions can be evaluated on counts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b6104158da73f015822f02cd6abbe4e2cf5c6cf" translate="yes" xml:space="preserve">
          <source>The distribution strategy options associated with the dataset. See &lt;a href=&quot;experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf743a144dc0600d6b32b4a4db31e72e8fcd7021" translate="yes" xml:space="preserve">
          <source>The distributions have degree of freedom &lt;code&gt;df&lt;/code&gt;, mean &lt;code&gt;loc&lt;/code&gt;, and scale &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2de0b5493fea7bb1bb4b3e017251bece76051fd5" translate="yes" xml:space="preserve">
          <source>The drawn samples of shape &lt;code&gt;[batch_size, num_samples]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd52ea2eb7ea5be6e405a118979acc052f206e1b" translate="yes" xml:space="preserve">
          <source>The dtype of the resulting tensor is inferred from the inputs unless it is provided explicitly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b69591d001104f8e2eec546d13dfde13802ef40" translate="yes" xml:space="preserve">
          <source>The dumped debugging information can be ingested by debugger UIs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c3bb311f55c44615e851ca1393dedf962117d6f" translate="yes" xml:space="preserve">
          <source>The dynamic calculation performed is, at time &lt;code&gt;t&lt;/code&gt; for batch row &lt;code&gt;b&lt;/code&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aae6b9d4f5b2d213b88b3723da3ddb26ced9416" translate="yes" xml:space="preserve">
          <source>The effective spatial dimensions of the zero-padded input tensor will be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9acfbbdfe245ea88de02f1a818fe0b504d8ee2c" translate="yes" xml:space="preserve">
          <source>The eigenvalues and eigenvectors for a non-Hermitian matrix in general are complex. The eigenvectors are not guaranteed to be linearly independent.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee408bc36c08a8eb79de0b041ba288a43ece416b" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x divided by y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee6f05fbd02c64e68c12a5dd5234049b70dd5c18" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x times y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5056d7193c98ed08aca24d8fed6317ade12de9af" translate="yes" xml:space="preserve">
          <source>The elements are shifted positively (towards larger indices) by the offset of &lt;code&gt;shift&lt;/code&gt; along the dimension of &lt;code&gt;axis&lt;/code&gt;. Negative &lt;code&gt;shift&lt;/code&gt; values will shift elements in the opposite direction. Elements that roll passed the last position will wrap around to the first and vice versa. Multiple shifts along multiple axes may be specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c40643e8152d969c58abd0946b228718afbfd024" translate="yes" xml:space="preserve">
          <source>The elements in &lt;code&gt;input&lt;/code&gt; are considered to be complex numbers of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part. If &lt;code&gt;input&lt;/code&gt; is real then &lt;em&gt;b&lt;/em&gt; is zero by definition.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd6b82f2a01c27554a110fc1c60a8688cc656c5b" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;result&lt;/code&gt; will be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e5122262788d16dcc2a476a1ccd5d94e319a27e" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;sampled_candidates&lt;/code&gt; are drawn without replacement (if &lt;code&gt;unique=True&lt;/code&gt;) or with replacement (if &lt;code&gt;unique=False&lt;/code&gt;) from the base distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48ab33f1524aaeaed08c07c88c40746479f023b7" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;seq_lengths&lt;/code&gt; must obey &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_dim]&lt;/code&gt;, and &lt;code&gt;seq_lengths&lt;/code&gt; must be a vector of length &lt;code&gt;input.dims[batch_dim]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39f08dabb4ebd036182bf4e154d99641a60b1bde" translate="yes" xml:space="preserve">
          <source>The elements of the dataset must be scalar strings. To serialize dataset elements as strings, you can use the &lt;a href=&quot;../../io/serialize_tensor&quot;&gt;&lt;code&gt;tf.io.serialize_tensor&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3650e19170e124ae92368cff21395feb363f4884" translate="yes" xml:space="preserve">
          <source>The elements of this dataset correspond to records from the file(s). RFC 4180 format is expected for CSV files (https://tools.ietf.org/html/rfc4180) Note that we allow leading and trailing spaces with int or float field.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3aeafaf8f36325e7f515de971621d719406107b" translate="yes" xml:space="preserve">
          <source>The end result is that if the input is marked as an explicit endianness the transcoding is faithful to all codepoints in the source. If it is not marked with an explicit endianness, the BOM is not considered part of the string itself but as metadata, and so is not preserved in the output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7d3c35f0e85c1a6bf781b776ea72d3b7217b57e" translate="yes" xml:space="preserve">
          <source>The entire Python program exits when no alive non-daemon threads are left.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcab26b6f1d2bad63f4beb447401d7b8916bee05" translate="yes" xml:space="preserve">
          <source>The entire optimizer is currently thread compatible, not thread-safe. The user needs to perform synchronization if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c33387bb265f08d2eccc0ee4964677edfa18dfee" translate="yes" xml:space="preserve">
          <source>The error message that describes the error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3992d2c2ef24613a2edd3a09184b92d4f6c82dcc" translate="yes" xml:space="preserve">
          <source>The estimator uses a user-specified head.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0f4a9f9118713f2c65753167fbc45edc83681df" translate="yes" xml:space="preserve">
          <source>The event shape and the batch shape are properties of a Distribution object, whereas the sample shape is associated with a specific call to &lt;code&gt;sample&lt;/code&gt; or &lt;code&gt;log_prob&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d89bb90670419b9d3a4b50ee4e20b8624c955245" translate="yes" xml:space="preserve">
          <source>The example has two variables containing parameters, &lt;code&gt;dense.kernel&lt;/code&gt; (2 parameters) and &lt;code&gt;dense.bias&lt;/code&gt; (1 parameter). Considering the training data &lt;code&gt;x&lt;/code&gt; as a constant, this means the Jacobian matrix for the function mapping from parameters to loss has one row and three columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c18ab207b5195ffc68356ad590594bcf1dfa71" translate="yes" xml:space="preserve">
          <source>The examples below are for the case when only indices have leading extra dimensions. If both 'params' and 'indices' have leading batch dimensions, use the 'batch_dims' parameter to run gather_nd in batch mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78ad8b1f8ab153e6768481eb32292aa26fa61403" translate="yes" xml:space="preserve">
          <source>The expected output of its iterations is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a97b08c68384c6b725f7994e4ae0a05ba85ecb6" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string or int to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying the features to be passed to the model. Note: if &lt;code&gt;features&lt;/code&gt; passed is not a dict, it will be wrapped in a dict with a single entry, using 'feature' as the key. Consequently, the model must accept a feature dict of the form {'feature': tensor}. You may use &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; if you want the tensor to be passed as is. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31f7e12f63f032ea1d264ce969a77506eba82800" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A single &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, representing the feature to be passed to the model. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a40612bf469e8a522446e66d41d431047e69cf63" translate="yes" xml:space="preserve">
          <source>The expected size of the &lt;code&gt;logits&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0f440ff029659182acbea8855f46dd42d2a4e96" translate="yes" xml:space="preserve">
          <source>The expected table key dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31bcecc626aa91dd2b7d91005cf6117e6bde9f72" translate="yes" xml:space="preserve">
          <source>The expected table value dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce7ef07c28defdcd9df2cbeda8fcff1eb3a70cf0" translate="yes" xml:space="preserve">
          <source>The expected values are &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dec1b3abe2b21793505b8807293f4669331e6f37" translate="yes" xml:space="preserve">
          <source>The experimental_mode parameter can be used to export a single train/eval/predict graph as a &lt;code&gt;SavedModel&lt;/code&gt;. See &lt;code&gt;experimental_export_all_saved_models&lt;/code&gt; for full docs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7605e2fe49cffe7e518a9ae0d1ab56de778f3211" translate="yes" xml:space="preserve">
          <source>The exponential is computed using a combination of the scaling and squaring method and the Pade approximation. Details can be found in: Nicholas J. Higham, &quot;The scaling and squaring method for the matrix exponential revisited,&quot; SIAM J. Matrix Anal. Applic., 26:1179-1193, 2005.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f5a78bc935e9e08409cbf0ad9095df30519c6ba" translate="yes" xml:space="preserve">
          <source>The exponential linear activation: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x)-1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a8c6448917add778eb240e31bd6ab87cce7e676" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2875cf5dfc1a19c0a389906972c0cc62d32b4f" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72c1a65a7779ecfbc3e340268769bc17bef0c731" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f952c6857d4170532f4c4a40882608ceb9fe6cf5" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d89ddec6391085569ef9d73498cfde0f5e37d2b" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;SavedModel&lt;/code&gt; is a standalone serialization of Tensorflow objects, and is supported by TF language APIs and the Tensorflow Serving system. To load the model, use the function &lt;code&gt;tf.keras.experimental.load_from_saved_model&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="115b43cdf7131901fe589992324081fddba4d32c" translate="yes" xml:space="preserve">
          <source>The factory function &lt;a href=&quot;raggedtensor#from_nested_row_splits&quot;&gt;&lt;code&gt;RaggedTensor.from_nested_row_splits&lt;/code&gt;&lt;/a&gt; may be used to construct a &lt;code&gt;RaggedTensor&lt;/code&gt; with multiple ragged dimensions directly, by providing a list of &lt;code&gt;row_splits&lt;/code&gt; tensors:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84412542c638bfe39a033a0e5c516c5c165f7f74" translate="yes" xml:space="preserve">
          <source>The files in the dump directory contain the following information: - TensorFlow Function construction (e.g., compilation of Python functions decorated with @tf.function), the op types, names (if available), context, the input and output tensors, and the associated stack traces. - Execution of TensorFlow operations (ops) and Functions and their stack traces, op types, names (if available) and contexts. In addition, depending on the value of the &lt;code&gt;tensor_debug_mode&lt;/code&gt; argument (see Args section below), the value(s) of the output tensors or more concise summaries of the tensor values will be dumped. - A snapshot of Python source files involved in the execution of the TensorFlow program.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50c753605d6ee518cbe6dced5742e28ec63d5987" translate="yes" xml:space="preserve">
          <source>The first dict contains the context key/values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21b3efb51e905408dc7d30df6c5476374dd7b033" translate="yes" xml:space="preserve">
          <source>The first matching Enum class member in Enum class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aea8fe33a13a43f1f933680d9ce0f5a2db48535e" translate="yes" xml:space="preserve">
          <source>The first matching element from enum_values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf18fd4e6ab37edcfe93bf741aad23fe79581af4" translate="yes" xml:space="preserve">
          <source>The first output contains a Tensor with the content of the audio samples. The lowest dimension will be the number of channels, and the second will be the number of samples. For example, a ten-sample-long stereo WAV file should give an output shape of [10, 2].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="386e01aa23336af9951f682033560f681c83315e" translate="yes" xml:space="preserve">
          <source>The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f90632e85082c59f117ebff04eaae1a05ddf870" translate="yes" xml:space="preserve">
          <source>The flag value is parsed with a CSV parser.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96f145cafd13cfdf0d9a0f61a17dd04e31f2f508" translate="yes" xml:space="preserve">
          <source>The flag's current value is also updated if the flag is currently using the default value, i.e. not specified in the command line, and not set by FLAGS.name = value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43c9fd434671ebe599abe72c41c1f1beb298f354" translate="yes" xml:space="preserve">
          <source>The flow &lt;code&gt;Tensor&lt;/code&gt; forcing ops leading to this TensorArray state.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5802a84878124b124beac42194fc2361ed2f11d6" translate="yes" xml:space="preserve">
          <source>The following &lt;code&gt;DType&lt;/code&gt; objects are defined:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f23bf2a65eeb471ae91c72707d1429b81ec5054e" translate="yes" xml:space="preserve">
          <source>The following accumulators/queue are created:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="591cee6bba7aa3b795b8bd5b56dc88de0c7af0c0" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are experimental and may not be supported in future releases:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a5195ca6a5ce9a55280235bcdfa18337e633d87" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are part of the stable API for aggregating gradients:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ee6cb9dfe69d9d22f1caaeae67551de61d1e04d" translate="yes" xml:space="preserve">
          <source>The following code examples are equivalent:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe70fcf720ef0fde06fcd7d33ac8492a73efc566" translate="yes" xml:space="preserve">
          <source>The following example can be rewritten using a numpy.ndarray instead of the &lt;code&gt;value&lt;/code&gt; list, even reshaped, as shown in the two commented lines below the &lt;code&gt;value&lt;/code&gt; list initialization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd2231c4c2e6ac8a925f85e0e3d53aba21ee51d7" translate="yes" xml:space="preserve">
          <source>The following example creates a TensorFlow graph with &lt;code&gt;np.sinh()&lt;/code&gt; as an operation in the graph:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96cf93e8858013a75fb44334359039c6f25c846e" translate="yes" xml:space="preserve">
          <source>The following example demonstrates disabling the first GPU on the machine.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5252c999d447d634884b440e481ad68aacf0ae9" translate="yes" xml:space="preserve">
          <source>The following example lists the number of visible GPUs on the host.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cdccf83ed29fb9603555106e738bca275fd3c3f" translate="yes" xml:space="preserve">
          <source>The following example splits the CPU into 2 logical devices:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ace04a5fda844a89c5ee4c9be9654bd7abe4446" translate="yes" xml:space="preserve">
          <source>The following example splits the GPU into 2 logical devices with 100 MB each:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e92322d00886dec66262eaafdb4b32cf9a853e78" translate="yes" xml:space="preserve">
          <source>The following example verifies all visible GPUs have been disabled:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d32c07164d7968452b087497fbdd283446aa73c" translate="yes" xml:space="preserve">
          <source>The following is an example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed38596eeae1ed9d7dcfb7df999c45674415489a" translate="yes" xml:space="preserve">
          <source>The following is an example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24bdb030bb46a068c505477e8cd1862a69826946" translate="yes" xml:space="preserve">
          <source>The following local variable is created:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c83149474e8e1bdaa43183ac0053126fc2f29c2" translate="yes" xml:space="preserve">
          <source>The following optional keyword arguments are reserved for specific uses:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b2e176467ad37b3b7339e39c7c7f1f162f5fc98" translate="yes" xml:space="preserve">
          <source>The following pieces are directly accessible as attributes of the &lt;code&gt;Scaffold&lt;/code&gt; object:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2ed2efebe2e500e729949e45ea5460a93f492fe" translate="yes" xml:space="preserve">
          <source>The following snippet initializes a table with the first column as keys and second column as values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6f97267e796a462cd648b32cdaea5e143b3612c" translate="yes" xml:space="preserve">
          <source>The following standard keys are &lt;em&gt;defined&lt;/em&gt;, but their collections are &lt;strong&gt;not&lt;/strong&gt; automatically populated as many of the others are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99bfb2634af3adab05d0f542c47d1e0966b2dddf" translate="yes" xml:space="preserve">
          <source>The following standard keys are defined:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5b0b8ccd1f0abc3ddefae0423fee59c58a2cd57" translate="yes" xml:space="preserve">
          <source>The fraction of zeros in &lt;code&gt;value&lt;/code&gt;, with type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="992778fe6a92285eff91d32500db456a86a4fc54" translate="yes" xml:space="preserve">
          <source>The full name of this operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="743b7a6db57523722e378bc070ddcab709a5ac83" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint (i.e. &lt;code&gt;file_prefix&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17174d3c9eb2bd17d3031f0d66dc8f9b3b509e75" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acdec3e98e6b61dcd2da29992ebc62ad6f5bf20c" translate="yes" xml:space="preserve">
          <source>The full path to the latest checkpoint or &lt;code&gt;None&lt;/code&gt; if no checkpoint was found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47f2fc665d0afe391e8a43fb1ae4db7142668b97" translate="yes" xml:space="preserve">
          <source>The function &lt;code&gt;grad_grad_fn&lt;/code&gt; will be calculating the first order gradient of &lt;code&gt;grad_fn&lt;/code&gt; with respect to &lt;code&gt;dy&lt;/code&gt;, which is used to generate forward-mode gradient graphs from backward-mode gradient graphs, but is not the same as the second order gradient of &lt;code&gt;op&lt;/code&gt; with respect to &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45872032316d782b7cca27465e024bb311aaa0d6" translate="yes" xml:space="preserve">
          <source>The function arguments use the same convention as Theano's arange: if only one argument is provided, it is in fact the &quot;stop&quot; argument and &quot;start&quot; is 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a54988c5a27bf3df304066330e8659cc62c5ae14" translate="yes" xml:space="preserve">
          <source>The function may use variable scopes and other templates internally to create and reuse variables, but it shouldn't use &lt;a href=&quot;global_variables&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt;&lt;/a&gt; to capture variables that are defined outside of the scope of the function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7473045784de1b0d1dced2ea1e88e2739636aca8" translate="yes" xml:space="preserve">
          <source>The function returns a 1-arg callable to compute the piecewise constant when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7935c69bd80f01354e2709843f6b51eb870975aa" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate while taking into account possible warm restarts. The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86355e2388af8622a11980472ee114bf3a474b98" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate. It is computed as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbeb4f9954a2b9fb0a88492d0bff2e967c29ba25" translate="yes" xml:space="preserve">
          <source>The function should create all trainable variables and any variables that should be reused by calling &lt;a href=&quot;get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt;&lt;/a&gt;. If a trainable variable is created using &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;, then a ValueError will be thrown. Variables that are intended to be locals can be created by specifying &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable(..., trainable=false)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e1312f2dcf17101a4e17a36133e6bbffe530ce3" translate="yes" xml:space="preserve">
          <source>The function writes the SavedModel protocol buffer to the export directory in serialized format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00cf308c9f40a9f1b859f12fd033e78caa4d14cd" translate="yes" xml:space="preserve">
          <source>The functions &lt;code&gt;f1&lt;/code&gt; and &lt;code&gt;f2&lt;/code&gt; will be executed serially, and updates to &lt;code&gt;v&lt;/code&gt; will be atomic.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dde4529b22d96c16a9b96a541d58c5d0a1f7056a" translate="yes" xml:space="preserve">
          <source>The generated &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt;&lt;code&gt;Summary&lt;/code&gt;&lt;/a&gt; has one summary value containing a histogram for &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="062e4980e54d60fb22e75f6c9b5206c3bc85ad28" translate="yes" xml:space="preserve">
          <source>The generated Summary has a Tensor.proto containing the input Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6c1194a7570536aae2b3653d7c1dba93fd5851" translate="yes" xml:space="preserve">
          <source>The generated values follow a binomial distribution with specified count and probability of success parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34cfd1936eb36f5d55d6eea6019586d8abfd6453" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f713a6a0ff6a46795bef18d9e29d3e2780e55f6" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than two standard deviations from the mean are dropped and re-picked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4eafca9e4f8c3067d55709b52f16b752c27ed7e" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="729a8a331d955e25ac8cf2c6b6a31b0effcb1a59" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded. (For float numbers especially low-precision types like bfloat16, because of rounding, the result may sometimes include &lt;code&gt;maxval&lt;/code&gt;.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f254b2b1969b3fd6753653a609c42efa67f8dfa" translate="yes" xml:space="preserve">
          <source>The given &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt; can be merged as long as there does not exist an attribute that is set to different values in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;options&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d60ebc741d192476c8f1b6c1be3c6bd74a4d508" translate="yes" xml:space="preserve">
          <source>The given tensors are sliced along their first dimension. This operation preserves the structure of the input tensors, removing the first dimension of each tensor and using it as the dataset dimension. All input tensors must have the same size in their first dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccd566669127e41c5c83f5e51e6e655e2023b466" translate="yes" xml:space="preserve">
          <source>The global Policy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f44fcbf38635afbe0c45b61c517d01f18c4ad9b" translate="yes" xml:space="preserve">
          <source>The global id in the training cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c06234718e1efd425d9fee36736f9c49d1c25446" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no global policy is set, layers will instead default to a Policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2. In TensorFlow 1, layers default to an &quot;infer&quot; policy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aa023817c66fefe7d12596fe9f5c2f950738ad5" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no policy has been set with &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt;, this will return a policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2 (floatx defaults to float32), or an &quot;infer&quot; policy in TensorFlow 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="147a0f3f093ca1fdfeeb131812693ae892afe50f" translate="yes" xml:space="preserve">
          <source>The global step tensor must be an integer variable. We first try to find it in the collection &lt;code&gt;GLOBAL_STEP&lt;/code&gt;, or by name &lt;code&gt;global_step:0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b54d047ac096c3ae7f021822844b86acfbb5227" translate="yes" xml:space="preserve">
          <source>The global step tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95db374c08adfbc24c444a5e0edf15c6723034b8" translate="yes" xml:space="preserve">
          <source>The global step value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27f92d2c600461e2b55ce1161093f706c000d648" translate="yes" xml:space="preserve">
          <source>The global step variable, or &lt;code&gt;None&lt;/code&gt; if none was found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2344c5579f4717a0862d524efae16729bc6ed70" translate="yes" xml:space="preserve">
          <source>The gradient computation of this operation will only take advantage of sparsity in the input gradient when that gradient comes from a Relu.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d051520aa4dd277f3ed0bb66ae2aa2ab1b266a18" translate="yes" xml:space="preserve">
          <source>The gradient computed for 'op_type' will then propagate zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71b1d3537cf96813de8a96c3c5f5d393309ab752" translate="yes" xml:space="preserve">
          <source>The gradient expression can be analytically simplified to provide numerical stability:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ab3e3e9ec9dadb6bed29c4d9fadd240cfe53d58" translate="yes" xml:space="preserve">
          <source>The gradient of y with respect to x can be zero in two different ways: there could be no differentiable path in the graph connecting x to y (and so we can statically prove that the gradient is zero) or it could be that runtime values of tensors in a particular execution lead to a gradient of zero (say, if a relu unit happens to not be activated). To allow you to distinguish between these two cases you can choose what value gets returned for the gradient when there is no path in the graph from x to y:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5c157361d6bbe7fc68fa055766a81dc3624c016" translate="yes" xml:space="preserve">
          <source>The graph described by the protocol buffer will be displayed by TensorBoard. Most users pass a graph in the constructor instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="661d2d430bf12295ddf1be3a1e881f38bccfdb01" translate="yes" xml:space="preserve">
          <source>The graph is written as a text proto unless &lt;code&gt;as_text&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed620881b1cf97ec1349e99d3e7fd253aa216b39" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the &lt;code&gt;dtype&lt;/code&gt; of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in  auto_mixed_precision_lists.h:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae4960be0391bc0449f500287c2e9601d2d28fb9" translate="yes" xml:space="preserve">
          <source>The graph that was launched in this session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff2ceded61c6685a839fd2d7a80fa7375d194758" translate="yes" xml:space="preserve">
          <source>The graph with quantize training done.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e6f6623fe7498e3548d52e61a0b5aeb7212fa47" translate="yes" xml:space="preserve">
          <source>The graph-level random seed of this graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ddc50d95cf25f219ea2579cde9bf22435bfdc02" translate="yes" xml:space="preserve">
          <source>The hard sigmoid activation:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f4987b71fd23d4d24937f4f99fea76affcae8b1" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process and will never change. However, it is not suitable for cryptography. This function may be used when CPU time is scarce and inputs are trusted or unimportant. There is a risk of adversaries constructing inputs that all hash to the same bucket. To prevent this problem, use a strong hash function with &lt;code&gt;tf.string_to_hash_bucket_strong&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd0bfc8db5880e8eee54fb3385531988b2ad4a55" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61f428a10a4305c850461ee00f387b0cacfe0ef7" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process. The hash function is a keyed hash function, where attribute &lt;code&gt;key&lt;/code&gt; defines the key of the hash function. &lt;code&gt;key&lt;/code&gt; is an array of 2 elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e7a8b7c173f99d4be181a635239bd0a5322a9de" translate="yes" xml:space="preserve">
          <source>The hash function used for generating out-of-vocabulary buckets ID is Fingerprint64.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69a6e09f76ddf4e19a4f8311d3f8fdc0b3c24b22" translate="yes" xml:space="preserve">
          <source>The head can be used with a canned estimator. Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8faf861d99f75e3ed7e367680c294894cd4fcef" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, 1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c11316cb9d31dc7288f1ee66c33f5379df0eac90" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfb83e6dd754125ed65384336314d4dfea48278d" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, n_classes]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d067db23fc00d02a594d5d3f6689549c9f412c9" translate="yes" xml:space="preserve">
          <source>The higher the value, the more important the corresponding feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec4887ee6136cea3e95782b65b373451d365f518" translate="yes" xml:space="preserve">
          <source>The ids and weights may be multi-dimensional. Embeddings are always aggregated along the last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dedfa9fac99909c847ee188683a18acc13d4781" translate="yes" xml:space="preserve">
          <source>The image sizes must be at least 11x11 because of the filter size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d3ec374ef70a5b15f88b06660be75d304545cf4" translate="yes" xml:space="preserve">
          <source>The implementation is based on: http://arxiv.org/abs/1409.2329.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ceeee7cb755fec502e82f78579a1a2aeacda20b" translate="yes" xml:space="preserve">
          <source>The implementation of reduce of &lt;code&gt;per_replica_value&lt;/code&gt; to &lt;code&gt;destinations&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39a73acc3a718d665ade71e6fcdb4d6f64ce1525" translate="yes" xml:space="preserve">
          <source>The index of the closest cluster center for each input point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bea3fce0b788c98ad4fd4961601d66fd0a86dd08" translate="yes" xml:space="preserve">
          <source>The index of this tensor in the outputs of its &lt;code&gt;Operation&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14e09cd196d124b973e167954c771249f4762ea9" translate="yes" xml:space="preserve">
          <source>The indicator function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e479f7d6722440bc7a24c4b0e9bd9fc43faf862a" translate="yes" xml:space="preserve">
          <source>The indices in &lt;code&gt;argmax&lt;/code&gt; are flattened, so that a maximum value at position &lt;code&gt;[b, y, x, c]&lt;/code&gt; becomes flattened index: &lt;code&gt;(y * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is False; &lt;code&gt;((b * height + y) * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c8ef3b2e283d0175df2945495378ccedf137327" translate="yes" xml:space="preserve">
          <source>The indices of any input &lt;code&gt;SparseTensor&lt;/code&gt; are assumed ordered in standard lexicographic order. If this is not the case, before this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b80ce2ebdd8a066053015d24d2b36c5006bb3c4b" translate="yes" xml:space="preserve">
          <source>The indices of non-zero values in the represented dense tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6678184e53cf5eab61e8f12ffd050f2da0981541" translate="yes" xml:space="preserve">
          <source>The indices returned are always in &lt;code&gt;[0, height) x [0, width)&lt;/code&gt; before flattening, even if padding is involved and the mathematically correct answer is outside (either negative or too large). This is a bug, but fixing it is difficult to do in a safe backwards compatible way, especially due to flattening.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="982eccddab4c7cb8698248ade435084245e7ba3a" translate="yes" xml:space="preserve">
          <source>The inferred shape of a tensor is used to provide shape information without having to launch the graph in a session. This can be used for debugging, and providing early error messages. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0cd21ff5f1c8bdcbdb1615eade35bd02cd426a1" translate="yes" xml:space="preserve">
          <source>The initial value for every thread's stack is set to the current value of the stack when &lt;code&gt;switch_to_thread_local()&lt;/code&gt; was first called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1520071416fcbbf59fdfe9d1fb1a38e0c5b7ec1a" translate="yes" xml:space="preserve">
          <source>The initializer operation for this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fe0073bfbc54ff4aabd7ab72b5b3609d630078b" translate="yes" xml:space="preserve">
          <source>The inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT2D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="577a2328b01f8435a1e76dd0c500fccff4c87199" translate="yes" xml:space="preserve">
          <source>The inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT3D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66227bf2a70d8c8a13c900791ef88cd485b7b62a" translate="yes" xml:space="preserve">
          <source>The inner-most dimension of &lt;code&gt;input&lt;/code&gt; is assumed to be the result of &lt;code&gt;RFFT&lt;/code&gt;: the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most dimension of &lt;code&gt;input&lt;/code&gt; (&lt;code&gt;fft_length = 2 * (inner - 1)&lt;/code&gt;). If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb19a900483721ea4e289126af04d4611c3ccdec" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; array for this ragged tensor value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be345c7ea127005969c68124a7827e30c5e6f496" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; tensor for this ragged tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f25a7f282e145204d03b73aafeaa7a9ae16b013a" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of &lt;code&gt;ref&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e89d3b63e4cb6ebffdeb167da39f2e0f1f1c9d2" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of self.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e7a91084b5b310e293a78ea32ab3d511383ccff" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; must be in row-major order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="559dc2e144980c6b2098537801cec29d9fedba3c" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, after this step run &lt;a href=&quot;../sparse/reorder&quot;&gt;&lt;code&gt;sparse.reorder&lt;/code&gt;&lt;/a&gt; to restore index ordering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56bbf31df5c3f0a722000a2eadd2da99c153bf4d" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must be a string matrix of shape &lt;code&gt;[N x 3]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to packed outputs of &lt;code&gt;serialize_sparse&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d39dc101c55542dec858072079860af67df42d8f" translate="yes" xml:space="preserve">
          <source>The input can be supplied in various formats: &lt;code&gt;matrix&lt;/code&gt;, &lt;code&gt;sequence&lt;/code&gt; and &lt;code&gt;compact&lt;/code&gt;, specified by the &lt;code&gt;diagonals_format&lt;/code&gt; arg.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a3aea890ab7c25d251475a5c0c175df4fead28f" translate="yes" xml:space="preserve">
          <source>The input data can be padded on both the start and end of the sequence, if desired, using the &lt;code&gt;pad_values&lt;/code&gt; argument. If set, &lt;code&gt;pad_values&lt;/code&gt; should contain either a tuple of strings or a single string; the 0th element of the tuple will be used to pad the left side of the sequence and the 1st element of the tuple will be used to pad the right side of the sequence. The &lt;code&gt;padding_width&lt;/code&gt; arg controls how many padding values are added to each side; it defaults to &lt;code&gt;ngram_width-1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3483a88e5028197c2c707cc3c8c51e5ba5c5cc43" translate="yes" xml:space="preserve">
          <source>The input has to be invertible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cb547f4554af98d950886c485fb31114efae486" translate="yes" xml:space="preserve">
          <source>The input has to be symmetric and positive definite. Only the lower-triangular part of the input will be used for this operation. The upper-triangular part will not be read.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ab6f7a1383accb84e03cfc01fbf2de71cc3ce58" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The output is a string tensor of the same shape containing the transcoded strings. Output strings are always valid unicode. If the input contains invalid encoding positions, the &lt;code&gt;errors&lt;/code&gt; attribute sets the policy for how to deal with them. If the default error-handling policy is used, invalid formatting will be substituted in the output by the &lt;code&gt;replacement_char&lt;/code&gt;. If the errors policy is to &lt;code&gt;ignore&lt;/code&gt;, any invalid encoding positions in the input are skipped and not included in the output. If it set to &lt;code&gt;strict&lt;/code&gt; then any invalid formatting will result in an InvalidArgument error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f41ed33e18d35e0df944af43170682bbfbe88dab" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The pattern is a scalar string tensor which is applied to every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a49b12f6890eee0fa5006296181dd36a3c0eae12" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a95ccad7688f828b4538240858954215386b157" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor containing the determinants for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb52980da5474b532e1e714b4de037ffa27b4127" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the exponential for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72c07ff69dfab5a23cee03f8eae86a2093c70b45" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the inverse for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f84ae4c58a555dd2a241282a825d52ffb2a896e6" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the matrix square root for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a47976575bd700d1896c1a9ad76ef8970d05df43" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[N, M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The outputs are two tensors containing the signs and absolute values of the log determinants for all N input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt; such that the determinant = sign&lt;em&gt;exp(log_abs_determinant). The log_abs_determinant is computed as det(P)&lt;/em&gt;sum(log(diag(LU))) where LU is the LU decomposition of the input and P is the corresponding permutation matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16509370e9a14e359dbc8b8062b8734116aafda6" translate="yes" xml:space="preserve">
          <source>The input matrix should be invertible. If the input matrix is real, it should have no eigenvalues which are real and negative (pairs of complex conjugate eigenvalues are allowed).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4fb5738c7b407c21bcad2cacc1ef5ec4dff9b6d" translate="yes" xml:space="preserve">
          <source>The input must be at least a matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c4f7bbe843d34cb236ccedebe4df570c214e3da" translate="yes" xml:space="preserve">
          <source>The input pipeline checkpoint may be large, if there are large shuffle or prefetch buffers for instance, and may bloat the checkpoint size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bf2cfde9a379c9cc0a2626ec6eaa414e577c963" translate="yes" xml:space="preserve">
          <source>The input samples are processed batch by batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db9e617ad287d3e54cdcc5d77f3a84dc0ecefefc" translate="yes" xml:space="preserve">
          <source>The input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a7245281a652bfbac8628bc44c29674340d8332" translate="yes" xml:space="preserve">
          <source>The input signature of &lt;code&gt;map_func&lt;/code&gt; is determined by the structure of each element in this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a4202e509f04a4e2e240929b7033cbd28325042" translate="yes" xml:space="preserve">
          <source>The input tensor (potentially converted to a &lt;code&gt;Tensor&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1339cf26956739f44025e7d445e29017a72d735" translate="yes" xml:space="preserve">
          <source>The input tensor can now be quantized by clipping values to the range &lt;code&gt;min_range&lt;/code&gt; to &lt;code&gt;max_range&lt;/code&gt;, then multiplying by scale_factor as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de4692e0721f2fcc2ac3eb25677f89cdae882775" translate="yes" xml:space="preserve">
          <source>The input tensor's height and width must be divisible by block_size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bd030040de18dc6a388054f2ae79e10c262d194" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;real&lt;/code&gt; and &lt;code&gt;imag&lt;/code&gt; must have the same shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa6b1cb251ad12bc98e4df6e1fe21cc0d8438940" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;starts&lt;/code&gt;, &lt;code&gt;limits&lt;/code&gt;, and &lt;code&gt;deltas&lt;/code&gt; may be scalars or vectors. The vector inputs must all have the same size. Scalar inputs are broadcast to match the size of the vector inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d39bc5c493315c0c2bb73635f284f6d3773b3fe6" translate="yes" xml:space="preserve">
          <source>The inputs and arguments of these functions both use an instance of the class so they can have independent numbering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0798e60c9a60a309c2780811ed22bf523e44034" translate="yes" xml:space="preserve">
          <source>The inputs are quantized tensors where the lowest value represents the real number of the associated minimum, and the highest represents the maximum. This means that you can only interpret the quantized output in the same way, by taking the returned minimum and maximum values into account.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af76f45e776e3f0a5b635d397e36c82661d856e8" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; must match the outer dimension of &quot;b&quot;. Both &quot;a&quot; and &quot;b&quot; must be &lt;code&gt;Tensor&lt;/code&gt;s not &lt;code&gt;SparseTensor&lt;/code&gt;s. This op is optimized for the case where at least one of &quot;a&quot; or &quot;b&quot; is sparse, in the sense that they have a large proportion of zero values. The breakeven for using this versus a dense matrix multiply on one platform was 30% zero values in the sparse matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="851dd7f69bc57652716eb3a5a344fc6b5525127d" translate="yes" xml:space="preserve">
          <source>The inputs must, following any transpositions, be tensors of rank &amp;gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea6567bbb82a2153b18593d35fddb52d49ff3e46" translate="yes" xml:space="preserve">
          <source>The inputs represent an N-D SparseTensor with logical shape &lt;code&gt;[..., B, C]&lt;/code&gt; (where &lt;code&gt;N &amp;gt;= 2&lt;/code&gt;), and with indices sorted in the canonical lexicographic order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="786b18b1428c9b9d0c0ea9b230ad273866de4e7c" translate="yes" xml:space="preserve">
          <source>The integer error code that describes the error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f081e7633128ce109e045c67ad35e5e5ed00d6f" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88afca652283c5de09f863feb56ef262251ef585" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf691a6e4942a79a3eb610931eed1d4815c80c50" translate="yes" xml:space="preserve">
          <source>The internal state of the RNG.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4e9fea1c0c7520b3774550dafc300a0edeccb05" translate="yes" xml:space="preserve">
          <source>The inverse of fftshift.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f58aa3901c7e60d466c168f7dbe6f460db432cc" translate="yes" xml:space="preserve">
          <source>The iterator only checks for new checkpoints when control flow has been reverted to it. This means it can miss checkpoints if your code takes longer to run between iterations than &lt;code&gt;min_interval_secs&lt;/code&gt; or the interval at which new checkpoints are written.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="751b0fbfa4aeea2c579ce7d09f30705a335965fb" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified by the &lt;code&gt;key_index&lt;/code&gt; and &lt;code&gt;value_index&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e732a302356fd06e3da95b03500ebf97f84d0506" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified either by the following, or a value &lt;code&gt;&amp;gt;=0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0771e36c5a66ef95bdba36fa510d228d752d2d4" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b464317f2f49a3771499c8be27b73752b57cff0e" translate="yes" xml:space="preserve">
          <source>The key and value type of the table to initialize is given by &lt;code&gt;key_dtype&lt;/code&gt; and &lt;code&gt;value_dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2cb43e5a33cda57c35ab173bdca64268dd6064f" translate="yes" xml:space="preserve">
          <source>The last &lt;code&gt;concentration&lt;/code&gt; dimension parametrizes a single Dirichlet-Multinomial distribution. When calling distribution functions (e.g., &lt;code&gt;dist.prob(counts)&lt;/code&gt;), &lt;code&gt;concentration&lt;/code&gt;, &lt;code&gt;total_count&lt;/code&gt; and &lt;code&gt;counts&lt;/code&gt; are broadcast to the same shape. The last dimension of &lt;code&gt;counts&lt;/code&gt; corresponds single Dirichlet-Multinomial distributions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78cc8d00f8e7491129a68b99d8285b81a0423488" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; can be at most the rank of &lt;code&gt;params&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecdf342100af669eb1e5196eae29b7087572c686" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to elements (if &lt;code&gt;indices.shape[-1] == params.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; params.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;params&lt;/code&gt;. The output tensor has shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="286ceed5a9e73c8174db8660f8e7395f9150777f" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to indices into elements (if &lt;code&gt;indices.shape[-1] = shape.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; shape.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;shape&lt;/code&gt;. &lt;code&gt;updates&lt;/code&gt; is a tensor with shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1334749bed79f5a39ed1f5844527d62a1a905c7c" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;sp_input.indices&lt;/code&gt; is discarded and replaced with the values of &lt;code&gt;sp_input&lt;/code&gt;. If &lt;code&gt;sp_input.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt;, then &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt;, where</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbd03a9648fd276c59e057bf5a188513a3c7e179" translate="yes" xml:space="preserve">
          <source>The last three dimensions of input are expected to be [height, width, depth].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d8c5a256ceb0281a5abfd9ab601681d1b6839bc" translate="yes" xml:space="preserve">
          <source>The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function that uses a different behavior at train time and test time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0a124fd12c8c65bb6844115fdf183c1b942c532" translate="yes" xml:space="preserve">
          <source>The learning phase gets restored to its original value upon exiting the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1de5c67a1eb0290c7057fa80ed33f8f702db5481" translate="yes" xml:space="preserve">
          <source>The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28b092429ddde1497c6f3dfbaf3344b66f15e153" translate="yes" xml:space="preserve">
          <source>The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90bbcad1f9bed80766758a96fdfa14681f8c6dd6" translate="yes" xml:space="preserve">
          <source>The link flags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eef29fe89c1421162e4e09274c7ca8daa2971972" translate="yes" xml:space="preserve">
          <source>The list is in arbitrary order. It does not contain the special entries &quot;.&quot; and &quot;..&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fe2aa6417d3855190d90b82f9abd178eaf4e42b" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects representing the outputs of this op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72b9f570910bc85398790d90eea0b57ff816aa6f" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects unstacked from &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1da5ffc250e1d720f6279716c9d6aade88b1077" translate="yes" xml:space="preserve">
          <source>The list of arguments not parsed as options, including argv[0].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a2668eec12c1d3cf3f187776719d83faec8967b" translate="yes" xml:space="preserve">
          <source>The list of concatenated tensors that was dequeued.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70e71f616ed088b5e1a5217c440dcc82210678f0" translate="yes" xml:space="preserve">
          <source>The list of dtypes for each component of a queue element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfa264d47e9935a6a337f111d8bbcf3f713d945a" translate="yes" xml:space="preserve">
          <source>The list of names for each component of a queue element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afc23fa1ddc71634846115e66b755cdfe5e1dce3" translate="yes" xml:space="preserve">
          <source>The list of shapes for each component of a queue element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39c799e61ec6d452a92b2f433fe078d01b37f5db" translate="yes" xml:space="preserve">
          <source>The list of threads started for the &lt;code&gt;QueueRunners&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17c761809240285ed679e6893972139bfc169439" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88981d3f5cd5ac5b5640b8a47ed0e63488d7e59c" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. Note that this returns the collection list itself, which can be modified in place to change the collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9ede6fcf47022786b23b7b18ee2bcbd80557011" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. The list contains the values in the order under which they were collected.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7016678a2375c9753e8eaf54d3415095320d885f" translate="yes" xml:space="preserve">
          <source>The locations represented by indices in &lt;code&gt;indices&lt;/code&gt; take value &lt;code&gt;on_value&lt;/code&gt;, while all other locations take value &lt;code&gt;off_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d12a72f932ac01058fe17db625020a638310386" translate="yes" xml:space="preserve">
          <source>The logarithm of \(|Beta(x)|\) reducing along the last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcad86f6653e28bded1ae388b8b9d533057cc10b" translate="yes" xml:space="preserve">
          <source>The logical to physical core mapping.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53c66b9be9a4d574723adcf23a86e3d3823c9748" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over all input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;, the loss is the weighted sum over both &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;label_dimension&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed8e3f66cfff153d9268a06149cbecc331a07647" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over the input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, 1]&lt;/code&gt;, the loss is the weighted sum over &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d3c5f122953381dbc3e40a95fb1e99d6fa1a036" translate="yes" xml:space="preserve">
          <source>The loss scale can either be a fixed constant, chosen by the user, or be dynamically determined. Dynamically determining the loss scale is convenient as a loss scale does not have to be explicitly chosen. However it reduces performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f2c12568d11b3b33927e92671eaa159d3a45974" translate="yes" xml:space="preserve">
          <source>The loss scale is not updated for the lifetime of instances of this class. A given instance of this class always returns the same number when called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c182a3c24f8448fb2c7d3d37bb39bed65ff10d2" translate="yes" xml:space="preserve">
          <source>The loss scale will be potentially updated, based on the value of &lt;code&gt;grads&lt;/code&gt;. The tensor returned by calling this class is only updated when this function is evaluated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90f307f8c8cab35fd072b8a08ea2d9e8126898ba" translate="yes" xml:space="preserve">
          <source>The lower regularized incomplete Gamma function is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2793511554b8b49f5f134322351c8feaf894969" translate="yes" xml:space="preserve">
          <source>The main reason to subclass &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt; instead of using a &lt;code&gt;Lambda&lt;/code&gt; layer is saving and inspecting a Model. &lt;code&gt;Lambda&lt;/code&gt; layers are saved by serializing the Python bytecode, whereas subclassed Layers can be saved via overriding their &lt;code&gt;get_config&lt;/code&gt; method. Overriding &lt;code&gt;get_config&lt;/code&gt; improves the portability of Models. Models that rely on subclassed Layers are also often easier to visualize and reason about.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a2c99d4f1e6d03bbc1af13e3314d300799e01bf" translate="yes" xml:space="preserve">
          <source>The map vectorization options associated with the dataset. See &lt;a href=&quot;mapvectorizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.MapVectorizationOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8214e9e9da90e26f5fe7ae19cb9d8f2cd4e068c" translate="yes" xml:space="preserve">
          <source>The masked &lt;code&gt;IndexedSlices&lt;/code&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="221a20910838d03246163841206f72d038ef571a" translate="yes" xml:space="preserve">
          <source>The matrix &lt;code&gt;a&lt;/code&gt; must, following any transpositions, be a tensor of rank &amp;gt;= 2, with &lt;code&gt;shape(a)[-1] == shape(b)[-1]&lt;/code&gt;, and &lt;code&gt;shape(a)[:-2]&lt;/code&gt; able to broadcast with &lt;code&gt;shape(b)[:-1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd71aa391cda25307463e674c4cbc2ea6a909c84" translate="yes" xml:space="preserve">
          <source>The matrix can be used with &lt;a href=&quot;../tensordot&quot;&gt;&lt;code&gt;tf.tensordot&lt;/code&gt;&lt;/a&gt; to convert an arbitrary rank &lt;code&gt;Tensor&lt;/code&gt; of linear-scale spectral bins into the mel scale.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11e987b7f304f6e3dd583d8302496f7bf0e8c7c9" translate="yes" xml:space="preserve">
          <source>The matrix columns represent the prediction labels and the rows represent the real labels. The confusion matrix is always a 2-D array of shape &lt;code&gt;[n, n]&lt;/code&gt;, where &lt;code&gt;n&lt;/code&gt; is the number of valid labels for a given classification task. Both prediction and labels must be 1-D arrays of the same shape in order for this function to work.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b5db825d45e0c9d1dc6abe9745f59c698b3a58a" translate="yes" xml:space="preserve">
          <source>The matrix square root is computed by first reducing the matrix to quasi-triangular form with the real Schur decomposition. The square root of the quasi-triangular matrix is then computed directly. Details of the algorithm can be found in: Nicholas J. Higham, &quot;Computing real square roots of a real matrix&quot;, Linear Algebra Appl., 1987.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e52e55f2b2b641c09e44a69eccc168205a706b2" translate="yes" xml:space="preserve">
          <source>The maximum error in between the two Jacobians.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c20357476750adc337729874b4e2eabc8868c3d" translate="yes" xml:space="preserve">
          <source>The mean and variance are calculated by aggregating the contents of &lt;code&gt;x&lt;/code&gt; across &lt;code&gt;axes&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is 1-D and &lt;code&gt;axes = [0]&lt;/code&gt; this is just the mean and variance of a vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3746fb2d4eae6a4ec87d65fc23bec2fa55150f2" translate="yes" xml:space="preserve">
          <source>The mean of Student's T equals &lt;code&gt;loc&lt;/code&gt; if &lt;code&gt;df &amp;gt; 1&lt;/code&gt;, otherwise it is &lt;code&gt;NaN&lt;/code&gt;. If &lt;code&gt;self.allow_nan_stats=True&lt;/code&gt;, then an exception will be raised rather than returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66b167be0f051cc6e8d71c967e67b0309cb7feab" translate="yes" xml:space="preserve">
          <source>The meaning of &lt;code&gt;query&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; and &lt;code&gt;key&lt;/code&gt; depend on the application. In the case of text similarity, for example, &lt;code&gt;query&lt;/code&gt; is the sequence embeddings of the first piece of text and &lt;code&gt;value&lt;/code&gt; is the sequence embeddings of the second piece of text. &lt;code&gt;key&lt;/code&gt; is usually the same tensor as &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92510595be575a3f901083a76e505b27be4bea36" translate="yes" xml:space="preserve">
          <source>The meaning of setting &lt;code&gt;layer.trainable = False&lt;/code&gt; is to freeze the layer, i.e. its internal state will not change during training: its trainable weights will not be updated during &lt;code&gt;fit()&lt;/code&gt; or &lt;code&gt;train_on_batch()&lt;/code&gt;, and its state updates will not be run.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae04b245da8a7e16dadcfeccbc7fd1f3884fcfad" translate="yes" xml:space="preserve">
          <source>The method returns the path prefix of the newly created checkpoint files. This string can be passed directly to a call to &lt;code&gt;restore()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c6e6621d848cf3b840ae66983d6900ad6f06a8b" translate="yes" xml:space="preserve">
          <source>The metric creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt; that are used to compute the precision. This value is ultimately returned as &lt;code&gt;precision&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
