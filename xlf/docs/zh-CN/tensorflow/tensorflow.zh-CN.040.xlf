<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="6ed2ecdaa3bd96954ea77dce173719510eac3340" translate="yes" xml:space="preserve">
          <source>The ID of the module which registered the flag with this name. If no such module exists (i.e. no flag with this name exists), we return default.</source>
          <target state="translated">用这个名字注册标志的模块的ID。如果没有这样的模块存在(即没有这个名称的标志存在),我们返回默认值。</target>
        </trans-unit>
        <trans-unit id="cc574746ad8c9b3dfc37ed70a6e4e32342676b91" translate="yes" xml:space="preserve">
          <source>The IDCT type to perform. Must be 1, 2, 3 or 4.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87056d72e53edb8e1ee915616502d31a9e2351aa" translate="yes" xml:space="preserve">
          <source>The Keras functional API in TensorFlow</source>
          <target state="translated">TensorFlow中的Keras功能API</target>
        </trans-unit>
        <trans-unit id="4d52998a6cc31a940d4ebb5910a3ac5329dbc67f" translate="yes" xml:space="preserve">
          <source>The Kubernetes client (usually automatically retrieved using &lt;code&gt;from kubernetes import client as k8sclient&lt;/code&gt;). If you pass this in, you are responsible for setting Kubernetes credentials manually.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36e14ec6d1ffdc156a9c3f1daa6d9890ec3b1e0e" translate="yes" xml:space="preserve">
          <source>The L1 regularization penalty is computed as:</source>
          <target state="translated">L1正则化惩罚的计算方法为。</target>
        </trans-unit>
        <trans-unit id="542768df94a1b938a660f48e17ba6915139cc683" translate="yes" xml:space="preserve">
          <source>The L1 regularization penalty is computed as: &lt;code&gt;loss = l1 * reduce_sum(abs(x))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c4ad0ec53302f5554ee8c8eb2b239ae6b215ee1" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as</source>
          <target state="translated">L2正则化惩罚的计算公式为</target>
        </trans-unit>
        <trans-unit id="d1be35376788281d0763761fe0b7decbcf96e523" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as &lt;code&gt;loss = l2 * reduce_sum(square(x))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f994e1d48c4b2ebd97fc4c0f1abd04009e95050" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as:</source>
          <target state="translated">L2正则化惩罚的计算方法是:</target>
        </trans-unit>
        <trans-unit id="3f0fa67aec74dc973d97bbb91f9762fcefa49c81" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as: &lt;code&gt;loss = l2 * reduce_sum(square(x))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7557d40db7eef29f9f5cf0c8852c6278d915ffe" translate="yes" xml:space="preserve">
          <source>The Laplace distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="translated">具有位置 &lt;code&gt;loc&lt;/code&gt; 和 &lt;code&gt;scale&lt;/code&gt; 参数的Laplace分布。</target>
        </trans-unit>
        <trans-unit id="cf61c2fbf2839d5025a99155287ab24829dc5c40" translate="yes" xml:space="preserve">
          <source>The Lightning Memory-Mapped Database Manager, or LMDB, is an embedded binary key-value database. This dataset can read the contents of LMDB database files, the names of which generally have the &lt;code&gt;.mdb&lt;/code&gt; suffix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f02ec145e8b375175cc81c541eb3f581408f36f" translate="yes" xml:space="preserve">
          <source>The Lpalce distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">Lpalce分布是&lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;位置范围族的成员&lt;/a&gt;，即可以将其构建为</target>
        </trans-unit>
        <trans-unit id="179fc5d20bec0f4afac4c22aa43296f1c61f1b50" translate="yes" xml:space="preserve">
          <source>The Multinomial is a distribution over &lt;code&gt;K&lt;/code&gt;-class counts, i.e., a length-&lt;code&gt;K&lt;/code&gt; vector of non-negative integer &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt;.</source>
          <target state="translated">多项式是 &lt;code&gt;K&lt;/code&gt; 类计数的分布，即，非负整数 &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt; 的长度 &lt;code&gt;K&lt;/code&gt; 矢量= n = [n_0，...，n_ {K-1}]。</target>
        </trans-unit>
        <trans-unit id="024145881176dd778a381db52296681ba8110801" translate="yes" xml:space="preserve">
          <source>The Normal distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">正态分布是&lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;位置范围族的成员&lt;/a&gt;，即可以将其构造为</target>
        </trans-unit>
        <trans-unit id="7626aa48ba3874551b7938ac31ee1cdb369fcdfb" translate="yes" xml:space="preserve">
          <source>The Normal distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="translated">具有位置 &lt;code&gt;loc&lt;/code&gt; 和 &lt;code&gt;scale&lt;/code&gt; 参数的正态分布。</target>
        </trans-unit>
        <trans-unit id="a5d10a5e52f889fef0937f17600830c2e3265076" translate="yes" xml:space="preserve">
          <source>The OK difference between compared values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61bb4d6d17edca6217e2b2286030e9ba936a8932" translate="yes" xml:space="preserve">
          <source>The Optimizer instance to wrap.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20cd1c5b899f8db8c65884d1566d810b08070a16" translate="yes" xml:space="preserve">
          <source>The Python API &lt;a href=&quot;../data/experimental/parallel_interleave&quot;&gt;&lt;code&gt;tf.data.experimental.parallel_interleave&lt;/code&gt;&lt;/a&gt; creates instances of this op. &lt;a href=&quot;../data/experimental/parallel_interleave&quot;&gt;&lt;code&gt;tf.data.experimental.parallel_interleave&lt;/code&gt;&lt;/a&gt; is a deprecated API.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0bdc97d45fdd9ed6ed73f745bcb974b2865e78b" translate="yes" xml:space="preserve">
          <source>The Python string encoding to use. Defaults to &lt;code&gt;'utf-8'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef840b903d3e772791466fbdbfc1be244accb53f" translate="yes" xml:space="preserve">
          <source>The Python type for values that are compatible with this TypeSpec.</source>
          <target state="translated">与此TypeSpec兼容的Python类型的值。</target>
        </trans-unit>
        <trans-unit id="c6c5a52f571080e818c0861dc1504abe80f61cf9" translate="yes" xml:space="preserve">
          <source>The RGB tensor to convert. The last dimension must have size 3 and should contain RGB values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55ebecb1d7e2330ca5e012023168889f2960e982" translate="yes" xml:space="preserve">
          <source>The RNG algorithm id (a Python integer or scalar integer Tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb43dc4932964141b3fdd553bcbf71855032420a" translate="yes" xml:space="preserve">
          <source>The RNG algorithm.</source>
          <target state="translated">RNG算法。</target>
        </trans-unit>
        <trans-unit id="76339cee66ec7159c145a078be1135ca3e02b709" translate="yes" xml:space="preserve">
          <source>The RNN inputs. If &lt;code&gt;time_major == False&lt;/code&gt; (default), this must be a &lt;code&gt;Tensor&lt;/code&gt; of shape: &lt;code&gt;[batch_size, max_time, ...]&lt;/code&gt;, or a nested tuple of such elements. If &lt;code&gt;time_major == True&lt;/code&gt;, this must be a &lt;code&gt;Tensor&lt;/code&gt; of shape: &lt;code&gt;[max_time, batch_size, ...]&lt;/code&gt;, or a nested tuple of such elements. This may also be a (possibly nested) tuple of Tensors satisfying this property. The first two dimensions must match across all the inputs, but otherwise the ranks and other shape components may differ. In this case, input to &lt;code&gt;cell&lt;/code&gt; at each time-step will replicate the structure of these tuples, except for the time dimension (from which the time is taken). The input to &lt;code&gt;cell&lt;/code&gt; at each time step will be a &lt;code&gt;Tensor&lt;/code&gt; or (possibly nested) tuple of Tensors each with dimensions &lt;code&gt;[batch_size, ...]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86a6adce8d77079953ad4cee35e139a001725441" translate="yes" xml:space="preserve">
          <source>The RNN inputs. If time_major == False (default), this must be a tensor of shape: &lt;code&gt;[batch_size, max_time, ...]&lt;/code&gt;, or a nested tuple of such elements. If time_major == True, this must be a tensor of shape: &lt;code&gt;[max_time, batch_size, ...]&lt;/code&gt;, or a nested tuple of such elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbcdb35da9c3d356564a35feaefe2aec308e6f5b" translate="yes" xml:space="preserve">
          <source>The RNN output &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8edcb3ff2e37ea406f1dfe82fa8ca8a4f0949af0" translate="yes" xml:space="preserve">
          <source>The RPC layer TensorFlow should use to communicate across instances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cf01358783b1025c197ff7c7e5d39c6fec8ac09" translate="yes" xml:space="preserve">
          <source>The RaggedTensor to slice.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5a45b5478a38a615eea2684c2d241f9352d6680" translate="yes" xml:space="preserve">
          <source>The SDCA algorithm was originally introduced in [1] and it was followed by the L1 proximal step [2], a distributed version [3] and adaptive sampling [4]. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] &lt;a href=&quot;https://arxiv.org/pdf/1309.2375.pdf&quot;&gt;https://arxiv.org/pdf/1309.2375.pdf&lt;/a&gt; [3] &lt;a href=&quot;https://arxiv.org/pdf/1502.03508.pdf&quot;&gt;https://arxiv.org/pdf/1502.03508.pdf&lt;/a&gt; [4] &lt;a href=&quot;https://arxiv.org/pdf/1502.08053.pdf&quot;&gt;https://arxiv.org/pdf/1502.08053.pdf&lt;/a&gt; Details specific to this implementation are provided in: &lt;a href=&quot;https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb&quot;&gt;https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="930b59a35037eb9f2e4f2e6718a1e37b8aaa1b56" translate="yes" xml:space="preserve">
          <source>The SDCA algorithm was originally introduced in [1] and it was followed by the L1 proximal step [2], a distributed version [3] and adaptive sampling [4]. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] https://arxiv.org/pdf/1309.2375.pdf [3] https://arxiv.org/pdf/1502.03508.pdf [4] https://arxiv.org/pdf/1502.08053.pdf Details specific to this implementation are provided in: https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb</source>
          <target state="translated">SDCA算法最初是在[1]中提出的,之后又有L1近端步骤[2]、分布式版本[3]和自适应采样[4]。[1]www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2]https://arxiv.org/pdf/1309.2375.pdf [3]https://arxiv.org/pdf/1502.03508.pdf [4]https://arxiv.org/pdf/1502.08053.pdf 本实施例的具体细节见:https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb。</target>
        </trans-unit>
        <trans-unit id="f7780b9525d55737cd5cef56696d5858bdaaf0de" translate="yes" xml:space="preserve">
          <source>The SavedModel directory to load from.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a77ce4bc58a785318ac8e94fd8eec273d01ff9a4" translate="yes" xml:space="preserve">
          <source>The SavedModel serialization path uses &lt;a href=&quot;../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; to save the model and all trackable objects attached to the model (e.g. layers and variables). &lt;code&gt;@tf.function&lt;/code&gt;-decorated methods are also saved. Additional trackable objects and functions are added to the SavedModel to allow the model to be loaded back as a Keras Model object.</source>
          <target state="translated">SavedModel序列化路径使用&lt;a href=&quot;../../saved_model/save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt;保存模型以及附加到模型的所有可跟踪对象（例如，图层和变量）。 &lt;code&gt;@tf.function&lt;/code&gt; 装饰的方法也被保存。其他可跟踪对象和功能已添加到SavedModel，以允许将模型作为Keras Model对象重新加载。</target>
        </trans-unit>
        <trans-unit id="303d5e3e630192c45b52ffe0ee781cadd1bb5c9c" translate="yes" xml:space="preserve">
          <source>The SavedModel will load in TensorFlow Serving and supports the &lt;a href=&quot;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/predict.proto&quot;&gt;Predict API&lt;/a&gt;. To use the Classify, Regress, or MultiInference APIs, please use either &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator&quot;&gt;tf.Estimator&lt;/a&gt; or the lower level &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md&quot;&gt;SavedModel APIs&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec1d78c7c8d9476450024b537502a2e94f916edd" translate="yes" xml:space="preserve">
          <source>The Scaled Exponential Linear Unit (SELU) activation function is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60a134651d9227079722cdc9e74feb1653be5aa4" translate="yes" xml:space="preserve">
          <source>The Scaled Exponential Linear Unit (SELU) activation function is: &lt;code&gt;scale * x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;scale * alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; where &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are pre-defined constants (&lt;code&gt;alpha = 1.67326324&lt;/code&gt; and &lt;code&gt;scale = 1.05070098&lt;/code&gt;). The SELU activation function multiplies &lt;code&gt;scale&lt;/code&gt; &amp;gt; 1 with the &lt;code&gt;[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)&lt;/code&gt; (Exponential Linear Unit (ELU)) to ensure a slope larger than one for positive net inputs.</source>
          <target state="translated">可缩放指数线性单元（九色鹿）活化功能： &lt;code&gt;scale * x&lt;/code&gt; 如果 &lt;code&gt;x &amp;gt; 0&lt;/code&gt; 和 &lt;code&gt;scale * alpha * (exp(x) - 1)&lt;/code&gt; 如果 &lt;code&gt;x &amp;lt; 0&lt;/code&gt; 其中 &lt;code&gt;alpha&lt;/code&gt; 和 &lt;code&gt;scale&lt;/code&gt; 是预定义的常数（ &lt;code&gt;alpha = 1.67326324&lt;/code&gt; 和 &lt;code&gt;scale = 1.05070098&lt;/code&gt; ）。SELU激活函数将 &lt;code&gt;scale&lt;/code&gt; &amp;gt; 1与 &lt;code&gt;[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)&lt;/code&gt; 相乘（https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu）（指数线性单位（ELU））确保正输入净值的斜率大于1。</target>
        </trans-unit>
        <trans-unit id="8c9823ad487742ec2d729142bb77debf58c1e901" translate="yes" xml:space="preserve">
          <source>The SignatureDef will specify outputs as described in this ExportOutput, and will use the provided receiver_tensors as inputs.</source>
          <target state="translated">SignatureDef将指定该ExportOutput中描述的输出,并将使用提供的receiver_tensors作为输入。</target>
        </trans-unit>
        <trans-unit id="f8a1119122b895a52e2361e72bc315143919a691" translate="yes" xml:space="preserve">
          <source>The SimpleClusterResolver does not do automatic detection of accelerators, and thus all arguments are unused and we simply return the value provided in the constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4545224fedce8f364aa3fd2d6cac68ea4817f884" translate="yes" xml:space="preserve">
          <source>The SimpleClusterResolver does not do automatic detection of accelerators, so a TensorFlow session will never be created, and thus all arguments are unused and we simply assume that the type of accelerator is a GPU and return the value in provided to us in the constructor.</source>
          <target state="translated">SimpleClusterResolver不会对加速器进行自动检测,所以永远不会创建TensorFlow会话,因此所有的参数都是未使用的,我们只是假设加速器的类型是GPU,并在构造函数中返回提供给我们的值。</target>
        </trans-unit>
        <trans-unit id="069bf31d9ffb91c874ca093882e0a6589ff1df14" translate="yes" xml:space="preserve">
          <source>The SparseAdd op calculates A + B, where A, B, and the sum are all represented as &lt;code&gt;SparseTensor&lt;/code&gt; objects. This op takes in the upstream gradient w.r.t. non-empty values of the sum, and outputs the gradients w.r.t. the non-empty values of A and B.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3870013c51b6be5e7f15c3e32c4df520066f45b2" translate="yes" xml:space="preserve">
          <source>The SparseTensor to reduce. Should have numeric type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95d35b03ae5ea7cdb3cc356783df4e423a2dc6c1" translate="yes" xml:space="preserve">
          <source>The StudentT distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">StudentT分布是&lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;位置范围族的成员&lt;/a&gt;，即可以将其构造为</target>
        </trans-unit>
        <trans-unit id="5c2d5184416b64215504aa1a967e583b20731ca8" translate="yes" xml:space="preserve">
          <source>The Supervisor is a small wrapper around a &lt;code&gt;Coordinator&lt;/code&gt;, a &lt;code&gt;Saver&lt;/code&gt;, and a &lt;code&gt;SessionManager&lt;/code&gt; that takes care of common needs of TensorFlow training programs.</source>
          <target state="translated">Supervisor是围绕 &lt;code&gt;Coordinator&lt;/code&gt; ， &lt;code&gt;Saver&lt;/code&gt; 和 &lt;code&gt;SessionManager&lt;/code&gt; 的小型包装，用于照顾TensorFlow培训程序的常见需求。</target>
        </trans-unit>
        <trans-unit id="41bd5ff6b458ccdec0fd96ba0408336a12a70400" translate="yes" xml:space="preserve">
          <source>The TF-TRT converted Function.</source>
          <target state="translated">TF-TRT转换功能。</target>
        </trans-unit>
        <trans-unit id="32c993dd695d77eb671cae70a4627b9e130bca1a" translate="yes" xml:space="preserve">
          <source>The TPU system performs the embedding lookups and aggregations specified by the arguments to TPUEmbeddingEnqueue(Integer/Sparse/SparseTensor)Batch. The results of these aggregations are visible to the Tensorflow Graph as the outputs of a RecvTPUEmbeddingActivations op. This op returns a list containing one Tensor of activations per table specified in the model. There can be at most one RecvTPUEmbeddingActivations op in the TPU graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a05a9d3dc8221db263c61479e69d13cee15f7429" translate="yes" xml:space="preserve">
          <source>The TPUEmbedding mid level API.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="363164ea24b07b74dc51248150c976cfc6c56e68" translate="yes" xml:space="preserve">
          <source>The Tensor or SparseTensor or CompositeTensor in &lt;code&gt;graph&lt;/code&gt; described by &lt;code&gt;tensor_info&lt;/code&gt;.</source>
          <target state="translated">张量或SparseTensor或CompositeTensor在 &lt;code&gt;graph&lt;/code&gt; 描述由 &lt;code&gt;tensor_info&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c0a0c7223ee1c65527cd175c2c03c00b8052eaee" translate="yes" xml:space="preserve">
          <source>The Tensor to be evaluated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b213eabf8ccb6ff5bf4ab0a41158ab15e62ff3b" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;../model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="translated">所述TensorFlow格式由起始于根对象，匹配的对象和变量 &lt;code&gt;self&lt;/code&gt; 为 &lt;code&gt;save_weights&lt;/code&gt; ，和贪婪地匹配的属性的名字。对于&lt;a href=&quot;../model#save&quot;&gt; &lt;code&gt;Model.save&lt;/code&gt; ,&lt;/a&gt;这是 &lt;code&gt;Model&lt;/code&gt; ，对于&lt;a href=&quot;../../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save&lt;/code&gt; ,&lt;/a&gt;这是 &lt;code&gt;Checkpoint&lt;/code&gt; ,即使 &lt;code&gt;Checkpoint&lt;/code&gt; 附加了模型也是如此。这意味着节约了&lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt;使用 &lt;code&gt;save_weights&lt;/code&gt; 和装载到&lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt;与 &lt;code&gt;Model&lt;/code&gt; 附接（或反之亦然）将不匹配 &lt;code&gt;Model&lt;/code&gt; 的变量。请参阅&lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;培训检查站指南&lt;/a&gt; 有关TensorFlow格式的详细信息。</target>
        </trans-unit>
        <trans-unit id="9ab4684c965e60031ddf80734d60fea35c517d3d" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="translated">所述TensorFlow格式由起始于根对象，匹配的对象和变量 &lt;code&gt;self&lt;/code&gt; 为 &lt;code&gt;save_weights&lt;/code&gt; ，和贪婪地匹配的属性的名字。对于&lt;a href=&quot;model#save&quot;&gt; &lt;code&gt;Model.save&lt;/code&gt; ,&lt;/a&gt;这是 &lt;code&gt;Model&lt;/code&gt; ，对于&lt;a href=&quot;../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save&lt;/code&gt; ,&lt;/a&gt;这是 &lt;code&gt;Checkpoint&lt;/code&gt; ,即使 &lt;code&gt;Checkpoint&lt;/code&gt; 附加了模型也是如此。这意味着节约了&lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt;使用 &lt;code&gt;save_weights&lt;/code&gt; 和装载到&lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt;与 &lt;code&gt;Model&lt;/code&gt; 附接（或反之亦然）将不匹配 &lt;code&gt;Model&lt;/code&gt; 的变量。请参阅&lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;培训检查站指南&lt;/a&gt; 有关TensorFlow格式的详细信息。</target>
        </trans-unit>
        <trans-unit id="b7638d4a5c348f022578401c2f1df999594f7eff" translate="yes" xml:space="preserve">
          <source>The TensorFlow process to which this session will connect.</source>
          <target state="translated">这个会话将连接到的TensorFlow进程。</target>
        </trans-unit>
        <trans-unit id="b91f22954ced4bccf875faf8127d8545ea485449" translate="yes" xml:space="preserve">
          <source>The TensorFlow session from which to save the meta graph and variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="849cc5eecef306c2866f4ba201ccfdcdd2f534c9" translate="yes" xml:space="preserve">
          <source>The TensorFlow session to restore the variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16a70a758b7ef6d7fd0aad2771edf2a93446ebcd" translate="yes" xml:space="preserve">
          <source>The Tensors returned by computation.</source>
          <target state="translated">计算返回的Tensors。</target>
        </trans-unit>
        <trans-unit id="45ecd5a2e94b407ef5967be01d6aea7e5dfb3bca" translate="yes" xml:space="preserve">
          <source>The Variable has rank &lt;code&gt;P&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt; of rank &lt;code&gt;Q&lt;/code&gt;.</source>
          <target state="translated">变量的等级为 &lt;code&gt;P&lt;/code&gt; ， &lt;code&gt;indices&lt;/code&gt; 为等级 &lt;code&gt;Q&lt;/code&gt; 的 &lt;code&gt;Tensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f53a9ea2c1d95dd8b27a8885316c2bc7fb8ad0c0" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the input become the high order component of the output channel index.</source>
          <target state="translated">每个输入块内的Y、X坐标成为输出通道指数的高阶分量。</target>
        </trans-unit>
        <trans-unit id="3d6c86d0708bda3da64a9da6d3c863b9ab737231" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the output image are determined by the high order component of the input channel index.</source>
          <target state="translated">输出图像的每个块内的Y、X坐标由输入通道指数的高阶分量决定。</target>
        </trans-unit>
        <trans-unit id="8cd36e977186fec64e8448a96228fbf260cd4605" translate="yes" xml:space="preserve">
          <source>The ZLIB compression level, &lt;code&gt;compression&lt;/code&gt;, can be -1 for the PNG-encoder default or a value from 0 to 9. 9 is the highest compression level, generating the smallest output, but is slower.</source>
          <target state="translated">对于PNG编码器默认值，ZLIB压缩级别 &lt;code&gt;compression&lt;/code&gt; 可以为-1，或者0到9之间的一个值。9是最高压缩级别，生成最小的输出，但是速度较慢。</target>
        </trans-unit>
        <trans-unit id="ce03da9cead6e86adf2a8009f5862736d75ecdca" translate="yes" xml:space="preserve">
          <source>The [batch] scalar &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt; in &lt;code&gt;cI&lt;/code&gt;.</source>
          <target state="translated">[batch]标量 &lt;code&gt;Tensor&lt;/code&gt; ， &lt;code&gt;c&lt;/code&gt; in &lt;code&gt;cI&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="875c6e8cec176a06af7a1f91d361f7f6428356f1" translate="yes" xml:space="preserve">
          <source>The above &lt;code&gt;matmul&lt;/code&gt; is equivalent to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaf6c09a17773617259c0e894f03f2f3f8ff8317" translate="yes" xml:space="preserve">
          <source>The above changes os.path.exists into a lambda that returns 1. Once the ... part of the code finishes, the CleanUp() looks up the old value of os.path.exists and restores it.</source>
          <target state="translated">上述代码将 os.path.exists 改为一个返回 1 的 lambda。一旦......部分代码完成,CleanUp()就会查找 os.path.exists 的旧值并将其还原。</target>
        </trans-unit>
        <trans-unit id="c6eeb39f253767567cdcdb00a4d19d1c71b1dcf0" translate="yes" xml:space="preserve">
          <source>The above computation has a replicated input of two replicas.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d2ea5c0bd79dcd10faca424dbd0b0996316230c" translate="yes" xml:space="preserve">
          <source>The above computation has a replicated output of two replicas.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f77b4838e9006d8d501115feb3f16fc46ba644b3" translate="yes" xml:space="preserve">
          <source>The above configuration has 2 tables, and three features. The first two features will be looked up in the first table and the third feature will be looked up in the second table.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be70405fbae38c2509b5b1ab685f99f4d89a4d97" translate="yes" xml:space="preserve">
          <source>The above example corresponds to the case where you have only one device. If you have two devices, for example,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ef3aa1fdfb679e9cef445f78d4851d53a003535" translate="yes" xml:space="preserve">
          <source>The above round function rounds the value based on the given round_mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2733c781ff4485ef11f43f16e3b526edaa1ff91" translate="yes" xml:space="preserve">
          <source>The accepted enum names, in lowercase if not case sensitive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa718bc26e2d4009bae4f7cc79776b6a1f114908" translate="yes" xml:space="preserve">
          <source>The accumulator accepts gradients marked with local_step greater or equal to the most recent global_step known to the accumulator. The average can be extracted from the accumulator, provided sufficient gradients have been accumulated. Extracting the average automatically resets the aggregate to 0, and increments the global_step recorded by the accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f260205d3bbed38b27587f7081a1e0eb839bfaf" translate="yes" xml:space="preserve">
          <source>The accumulator accepts gradients marked with local_step greater or equal to the most recent global_step known to the accumulator. The average can be extracted from the accumulator, provided sufficient gradients have been accumulated. Extracting the average automatically resets the aggregate to 0, and increments the global_step recorded by the accumulator. This is a resource version of ConditionalAccumulator that will work in TF2.0 with tf.cond version 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8bb936a65c3ce409995481c6a4f6df5ec2956c6" translate="yes" xml:space="preserve">
          <source>The activation value.</source>
          <target state="translated">激活值;</target>
        </trans-unit>
        <trans-unit id="19792f4506e01a3e2d4abd5364a4484e6f9c0588" translate="yes" xml:space="preserve">
          <source>The actual numpy &lt;code&gt;ndarray&lt;/code&gt;, or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor), or any arbitrarily nested of structure of these.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d36b573b08555814e732c53194782119f852b6d2" translate="yes" xml:space="preserve">
          <source>The actual optimizer that will be used to compute and apply the gradients. Must be one of the Optimizer classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da7330feac6d473367759d5dd1a21e9334b8d8de" translate="yes" xml:space="preserve">
          <source>The added Keras attribute is: &lt;code&gt;_keras_history&lt;/code&gt;: Last layer applied to the tensor. the entire layer graph is retrievable from that layer, recursively.</source>
          <target state="translated">添加的 &lt;code&gt;_keras_history&lt;/code&gt; 属性是：_keras_history：应用于张量的最后一层。整个层图可以从该层递归检索。</target>
        </trans-unit>
        <trans-unit id="f24861cc1a42612e73b3f3665071eeed2c9ea315" translate="yes" xml:space="preserve">
          <source>The additional robustness comes at a cost of roughly 4x higher compute time than &lt;code&gt;tf.string_to_hash_bucket_fast&lt;/code&gt;.</source>
          <target state="translated">与 &lt;code&gt;tf.string_to_hash_bucket_fast&lt;/code&gt; 相比，额外的健壮性要花费大约4倍的计算时间。</target>
        </trans-unit>
        <trans-unit id="1097b0db24625e152362ea61e1c9239db1bd02c3" translate="yes" xml:space="preserve">
          <source>The address of the coordinator (typically an ip:port pair). If set to None, a TF server will be started. If coordinator_name is None, a TF server will not be started even if coordinator_address is None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92d822d5e3a4a473e569254158aeaed3f44c8de9" translate="yes" xml:space="preserve">
          <source>The address of the given task in the given job.</source>
          <target state="translated">给定工作中给定任务的地址。</target>
        </trans-unit>
        <trans-unit id="1044e0e4428294ca84bc27c7d972e47ecc834421" translate="yes" xml:space="preserve">
          <source>The address of the master.</source>
          <target state="translated">主人的地址。</target>
        </trans-unit>
        <trans-unit id="a671b38fc84a246388b74802d7c3903f8c308213" translate="yes" xml:space="preserve">
          <source>The adjoint (a.k.a. Hermitian transpose a.k.a. conjugate transpose) of matrix.</source>
          <target state="translated">矩阵的邻接(又名赫米特转置,又名共轭转置)。</target>
        </trans-unit>
        <trans-unit id="2f35f817cc6a40c758997d4ca9d651aca344e6db" translate="yes" xml:space="preserve">
          <source>The adjoint case is solved similarly, beginning with &lt;code&gt;x_n = A_nn.solve(y_n, adjoint=True)&lt;/code&gt; and proceeding backwards.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d26f5dd591fe207d72f8bf3767404f30851360da" translate="yes" xml:space="preserve">
          <source>The adjusted &lt;code&gt;min_range&lt;/code&gt; and &lt;code&gt;max_range&lt;/code&gt; are returned as outputs 2 and 3 of this operation. These outputs should be used as the range for any further calculations.</source>
          <target state="translated">调整后的 &lt;code&gt;min_range&lt;/code&gt; 和 &lt;code&gt;max_range&lt;/code&gt; 作为此操作的输出2和3返回。这些输出应用作任何进一步计算的范围。</target>
        </trans-unit>
        <trans-unit id="23463dc8793b352e4536a04ab556ea601344e39c" translate="yes" xml:space="preserve">
          <source>The advantages of sampling candidates per-batch are simplicity and the possibility of efficient dense matrix multiplication. The disadvantage is that the sampled candidates must be chosen independently of the context and of the true labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34a7065e06c55b3339a4e1c47bf34bd00d072e70" translate="yes" xml:space="preserve">
          <source>The algorithm starts by setting the loss scale to an initial value. Every N steps that the gradients are finite, the loss scale is increased by some factor. However, if a NaN or Inf gradient is found, the gradients for that step are not applied, and the loss scale is decreased by the factor. This process tends to keep the loss scale as high as possible without gradients overflowing.</source>
          <target state="translated">该算法首先将损失尺度设置为初始值。梯度是有限的,每隔N个步骤,损失尺度就增加一个系数。但是,如果发现NaN或Inf梯度,则不应用该步的梯度,损失标度按系数减少。这个过程倾向于在不使梯度溢出的情况下,使损失尺度尽可能高。</target>
        </trans-unit>
        <trans-unit id="ec9f002d6d3b1e71963d9cf73b905f9b84153981" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;.</source>
          <target state="translated">基于 &quot;slice_spec &quot;的 &quot;张量 &quot;的适当片断。</target>
        </trans-unit>
        <trans-unit id="821f24c959536d42cc6fec55c7d0ad6a3d16e3c7" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;. As an operator. The operator also has a &lt;code&gt;assign()&lt;/code&gt; method that can be used to generate an assignment operator.</source>
          <target state="translated">基于&amp;ldquo; slice_spec&amp;rdquo;的&amp;ldquo;张量&amp;rdquo;的适当切片。作为操作员。该运算符还具有一个 &lt;code&gt;assign()&lt;/code&gt; 方法，可用于生成一个赋值运算符。</target>
        </trans-unit>
        <trans-unit id="23ef91f4c9a43b0bf509fbf539d12c4d114f51e2" translate="yes" xml:space="preserve">
          <source>The area within the interval is (slope / total_pos_weight) times</source>
          <target state="translated">区间内的面积为(斜率/总重量)乘以</target>
        </trans-unit>
        <trans-unit id="6ecef333fac070655838aed6ec7905dde692ac00" translate="yes" xml:space="preserve">
          <source>The args to be substituted into the msg.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2d3e064486f4100aead5629a0acce01f2954896" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;normalized&lt;/code&gt; and &lt;code&gt;centered&lt;/code&gt; controls how the windows are built:</source>
          <target state="translated">参数 &lt;code&gt;normalized&lt;/code&gt; 和 &lt;code&gt;centered&lt;/code&gt; 控制着窗口的构建方式：</target>
        </trans-unit>
        <trans-unit id="572a6d647b031b519cd29780ad535922e4e59db7" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;shape&lt;/code&gt; is optional. If present, it specifies the dimensions of the resulting tensor. If not present, the shape of &lt;code&gt;value&lt;/code&gt; is used.</source>
          <target state="translated">参数 &lt;code&gt;shape&lt;/code&gt; 是可选的。如果存在，它指定所得张量的尺寸。如果不存在，则使用 &lt;code&gt;value&lt;/code&gt; 的形状。</target>
        </trans-unit>
        <trans-unit id="13e87601baeedfadd1e05e7b900ecdbd205d0bf6" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;tensors&lt;/code&gt; can be a list or a dictionary of tensors. The value returned by the function will be of the same type as &lt;code&gt;tensors&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;tensors&lt;/code&gt; 参数可以是张量的列表或字典。该函数返回的值将与 &lt;code&gt;tensors&lt;/code&gt; 具有相同的类型。</target>
        </trans-unit>
        <trans-unit id="a32d0e1dadf3135bed15ded733117d1a197ad906" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the &lt;code&gt;shape&lt;/code&gt; argument (if specified). In the case where the list length is less than the number of elements specified by &lt;code&gt;shape&lt;/code&gt;, the last element in the list will be used to fill the remaining entries.</source>
          <target state="translated">参数 &lt;code&gt;value&lt;/code&gt; 可以是常量值，也可以是 &lt;code&gt;dtype&lt;/code&gt; 类型的值列表。如果 &lt;code&gt;value&lt;/code&gt; 是一个列表，则列表的长度必须小于或等于 &lt;code&gt;shape&lt;/code&gt; 参数所隐含的元素数（如果指定）。如果列表长度小于 &lt;code&gt;shape&lt;/code&gt; 指定的元素数，则列表中的最后一个元素将用于填充其余条目。</target>
        </trans-unit>
        <trans-unit id="4f585d29c2b28791ced3d5b4a780f2d82b9f8bf3" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the desired shape of the tensor. In the case where the total number of elements in &lt;code&gt;value&lt;/code&gt; is less than the number of elements required by the tensor shape, the last element in &lt;code&gt;value&lt;/code&gt; will be used to fill the remaining entries. If the total number of elements in &lt;code&gt;value&lt;/code&gt; is greater than the number of elements required by the tensor shape, the initializer will raise a &lt;code&gt;ValueError&lt;/code&gt;.</source>
          <target state="translated">参数 &lt;code&gt;value&lt;/code&gt; 可以是常量值，也可以是 &lt;code&gt;dtype&lt;/code&gt; 类型的值列表。如果 &lt;code&gt;value&lt;/code&gt; 是一个列表，则列表的长度必须小于或等于所需张量形状所隐含的元素数量。如果 &lt;code&gt;value&lt;/code&gt; 的元素总数少于张量形状所需的元素数，则 &lt;code&gt;value&lt;/code&gt; 的最后一个元素将用于填充其余条目。如果 &lt;code&gt;value&lt;/code&gt; 中元素的总数大于张量形状所需的元素数，则初始化程序将引发 &lt;code&gt;ValueError&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ce316117b38a170bc69e8657284f9032bf2d1a61" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a scalar constant value, or a list of values. Scalars broadcast to whichever shape is requested from the initializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35b02213c63b22c6aa288eadb099101e8c7a8bb2" translate="yes" xml:space="preserve">
          <source>The argument returned by this function is of the form \(atan2(b, a)\). If &lt;code&gt;input&lt;/code&gt; is real, a tensor of all zeros is returned.</source>
          <target state="translated">此函数返回的参数的格式为\（atan2（b，a）\）。如果 &lt;code&gt;input&lt;/code&gt; 为实数，则返回全零的张量。</target>
        </trans-unit>
        <trans-unit id="1b8141113a16ee9c1ee49249a42c4ec753fd4479" translate="yes" xml:space="preserve">
          <source>The argument returned by this operation is of the form \(atan2(b, a)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c08c5bbd3a3384802afbf07c0b86453afc140d85" translate="yes" xml:space="preserve">
          <source>The argument tuple for the target invocation. Defaults to ().</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8925ea25cd72607e66cde54201ec4e13ca4e3936" translate="yes" xml:space="preserve">
          <source>The arguments to &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Tensor#__getitem__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd368055cee84276738860ec0ec0f93a1536f9fa" translate="yes" xml:space="preserve">
          <source>The arguments to &lt;a href=&quot;tensor#__getitem__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08b05ba34abcf5462dc06534466ce94b701e498e" translate="yes" xml:space="preserve">
          <source>The arguments to Tensor.&lt;strong&gt;getitem&lt;/strong&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56bf9f2cd73c00e2baa02cf649b84dad59db80fe" translate="yes" xml:space="preserve">
          <source>The assertion is checked at runtime (when iterating the dataset) and an error is raised if the actual and expected cardinality differ.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bce43bdee979454925721c507561e0a29cfacb37" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., &lt;code&gt;local_step&lt;/code&gt; is less than the accumulator's global time step.</source>
          <target state="translated">如果梯度是陈旧的，即 &lt;code&gt;local_step&lt;/code&gt; 小于累加器的全局时间步长，则尝试将被静默地放弃。</target>
        </trans-unit>
        <trans-unit id="c2d9f9b7d3b4bc909dac3ec1179989967a68da98" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., local_step is less than the accumulator's global time step.</source>
          <target state="translated">如果梯度是陈旧的,即local_step小于累加器的全局时间步长,则会默默放弃该尝试。</target>
        </trans-unit>
        <trans-unit id="d8f6f1e67bc16f32d9f24b6bf9dc1327c99b4c20" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;block_size&lt;/code&gt; must be greater than one. It indicates the block size.</source>
          <target state="translated">attr &lt;code&gt;block_size&lt;/code&gt; 必须大于1。它指示块大小。</target>
        </trans-unit>
        <trans-unit id="b44ab2abacbb2efdb69194961a5971ce5296193c" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;channels&lt;/code&gt; indicates the desired number of color channels for the decoded image.</source>
          <target state="translated">attr &lt;code&gt;channels&lt;/code&gt; 指示解码图像所需的颜色通道数。</target>
        </trans-unit>
        <trans-unit id="60563f76a3b65c009555c6aca9d9b0a28f8e6c56" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;format&lt;/code&gt; can be used to override the color format of the encoded output. Values can be:</source>
          <target state="translated">attr &lt;code&gt;format&lt;/code&gt; 可用于替代编码输出的颜色格式。值可以是：</target>
        </trans-unit>
        <trans-unit id="ae606ee2da5f189375721f138e9665ac82e81365" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;ratio&lt;/code&gt; allows downscaling the image by an integer factor during decoding. Allowed values are: 1, 2, 4, and 8. This is much faster than downscaling the image later.</source>
          <target state="translated">attr &lt;code&gt;ratio&lt;/code&gt; 允许在解码期间将图像按比例缩小整数倍。允许的值为：1、2、4和8。这比以后缩小图像的速度要快得多。</target>
        </trans-unit>
        <trans-unit id="1dfd0d9d6161eef67f30788b5c5ad724fc4b4c90" translate="yes" xml:space="preserve">
          <source>The attribute &lt;code&gt;source&lt;/code&gt; is added as a suffix to the forward TensorArray's name when performing the creation / lookup, so that each separate gradient calculation gets its own TensorArray accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6570b67f35dff908278e6c1092e20dca85cfcf" translate="yes" xml:space="preserve">
          <source>The attributes themselves are defined in the &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/boston&quot;&gt;StatLib website&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c251209154f7690ac8f45548c2019ab6de3993b" translate="yes" xml:space="preserve">
          <source>The axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape &lt;code&gt;(batch, height, width, channels)&lt;/code&gt;, and you wish to share parameters across space so that each filter only has one set of parameters, set &lt;code&gt;shared_axes=[1, 2]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab2b7a67aab4c51b1e0d6376358a5f7e5c4b44b1" translate="yes" xml:space="preserve">
          <source>The axis along which to sort. The default is -1, which sorts the last axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20b05f039f9c533c5583921e0ed9aed8213b7f85" translate="yes" xml:space="preserve">
          <source>The axis that the output values are concatenated along. Default is -1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eaf9bdc79969635901c1b7428a237e7743aef889" translate="yes" xml:space="preserve">
          <source>The axis to fill (default: -1, a new inner-most axis).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a537279d84220ef606eff7333b56720a53d5d752" translate="yes" xml:space="preserve">
          <source>The axis to partition along. Default: outermost axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a06b05d6c855c1eb850eace9884f0d972ce19029" translate="yes" xml:space="preserve">
          <source>The axis to slice over. Axes at and below &lt;code&gt;axis&lt;/code&gt; will be flattened before bin counting. Currently, only &lt;code&gt;0&lt;/code&gt;, and &lt;code&gt;-1&lt;/code&gt; are supported. If None, all axes will be flattened (identical to passing &lt;code&gt;0&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="735485241e46184aca9b9d13dea029d8a1bc84d8" translate="yes" xml:space="preserve">
          <source>The backend learning phase affects any code that calls &lt;a href=&quot;learning_phase&quot;&gt;&lt;code&gt;backend.learning&lt;em&gt;phase()&lt;/em&gt;&lt;/code&gt;&lt;/a&gt; In particular, all Keras built-in layers use the learning phase as the default for the &lt;code&gt;training&lt;/code&gt; arg to &amp;lt;a href=&quot;../../../tf/keras/layers/Layer#&lt;em&gt;call&lt;/em&gt;&lt;em&gt;&quot;&amp;gt;&lt;code&gt;Layer.&lt;/code&gt;&lt;/em&gt;&lt;em&gt;call&lt;/em&gt;_.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e683aeb65a23e8619a38b301846fe9aa22a79e70" translate="yes" xml:space="preserve">
          <source>The backward operation for &quot;BiasAdd&quot; on the &quot;bias&quot; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43192d2acab6f30a3fb88a081e4480c6a4eaf531" translate="yes" xml:space="preserve">
          <source>The base class for all flags errors.</source>
          <target state="translated">所有标志错误的基类。</target>
        </trans-unit>
        <trans-unit id="95fac0e9d908797873ec2155df12d61346d3ec3c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is an approximately log-uniform or Zipfian distribution:</source>
          <target state="translated">这个操作的基本分布是一个近似对数均匀分布或Zipfian分布。</target>
        </trans-unit>
        <trans-unit id="e03722f7ec155314d6d64a06632231a0220ddf21" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is constructed on the fly during training. It is a unigram distribution over the target classes seen so far during training. Every integer in &lt;code&gt;[0, range_max)&lt;/code&gt; begins with a weight of 1, and is incremented by 1 each time it is seen as a target class. The base distribution is not saved to checkpoints, so it is reset when the model is reloaded.</source>
          <target state="translated">此操作的基本分发是在训练过程中即时构建的。这是迄今为止在培训期间看到的目标类别的字母组合分布。 &lt;code&gt;[0, range_max)&lt;/code&gt; 每个整数都以1的权重开始，并在每次被视为目标类时增加1。基本分布不会保存到检查点，因此在重新加载模型时会将其重置。</target>
        </trans-unit>
        <trans-unit id="9b285a7357154664da97ef50a86143b40cc66c8c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is the uniform distribution over the range of integers &lt;code&gt;[0, range_max)&lt;/code&gt;.</source>
          <target state="translated">该操作的基本分布是整数 &lt;code&gt;[0, range_max)&lt;/code&gt; 范围内的均匀分布。</target>
        </trans-unit>
        <trans-unit id="77b83a8d332ed8aca766d79f4120f4e0ba2ea928" translate="yes" xml:space="preserve">
          <source>The base distribution is read from a file or passed in as an in-memory array. There is also an option to skew the distribution by applying a distortion power to the weights.</source>
          <target state="translated">基础分布是从文件中读取的,或者以内存数组的形式传入。还有一个选项是通过对权重施加一个失真力来偏斜分布。</target>
        </trans-unit>
        <trans-unit id="dbe1df14f66fa0efdc79542406d6783493a122af" translate="yes" xml:space="preserve">
          <source>The base type or tuple of base types for all objects that &lt;code&gt;conversion_func&lt;/code&gt; accepts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="742c5ef9e662d0b65e94999280201b89cf344cb4" translate="yes" xml:space="preserve">
          <source>The basename for checkpoint saving.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ded41e0565ef5f400dbd93cc56863d8aef5c6704" translate="yes" xml:space="preserve">
          <source>The basic functionality is similar to dequeue with many fewer capabilities and options. This Op is optimized for performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dade1361cd3ab94fd2385c47804539cc6fda3a6a" translate="yes" xml:space="preserve">
          <source>The basic functionality of this Op is similar to a queue with many fewer capabilities and options. This Op is optimized for performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c0a22a2ecdff77c481cab7326fe4aaa0b144cf7" translate="yes" xml:space="preserve">
          <source>The batch dimensions are indexes into independent, non-identical parameterizations of this distribution.</source>
          <target state="translated">批量维度是这个分布的独立、非相同参数化的索引。</target>
        </trans-unit>
        <trans-unit id="b55a5f5737af8dc7c66469a674fe7b35b3d67f61" translate="yes" xml:space="preserve">
          <source>The batch dimensions, denoted as &lt;code&gt;...&lt;/code&gt;, must be the same in &lt;code&gt;diagonals&lt;/code&gt; and &lt;code&gt;rhs&lt;/code&gt;.</source>
          <target state="translated">批处理尺寸（表示为 &lt;code&gt;...&lt;/code&gt; )在 &lt;code&gt;diagonals&lt;/code&gt; 和 &lt;code&gt;rhs&lt;/code&gt; 上必须相同。</target>
        </trans-unit>
        <trans-unit id="b8d1e654d8a3893e3ebd1816b79375a5883dc270" translate="yes" xml:space="preserve">
          <source>The batch of the output tensor is &lt;code&gt;batch * block_size * block_size&lt;/code&gt;.</source>
          <target state="translated">输出张量的 &lt;code&gt;batch * block_size * block_size&lt;/code&gt; 为batch * block_size * block_size。</target>
        </trans-unit>
        <trans-unit id="49fd2aeae8e83aee3d7e1d3b09e0905a7ad1a450" translate="yes" xml:space="preserve">
          <source>The below table describes the performance on ImageNet 2012:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9d6c8abb90d01f2c83046e4ffaae926e1136406" translate="yes" xml:space="preserve">
          <source>The biggest difference between this and MIN_COMBINED is that the minimum range is rounded first, before it's subtracted from the rounded value. With MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing and dequantizing will introduce a larger and larger error.</source>
          <target state="translated">这与MIN_COMBINED最大的区别是,最小范围先被四舍五入,然后再从四舍五入的值中减去。使用MIN_COMBINED,会引入一个小的偏差,反复的量化和去量化会带来越来越大的误差。</target>
        </trans-unit>
        <trans-unit id="72445c1ce9af91d1b7756490161ef93a455800a7" translate="yes" xml:space="preserve">
          <source>The binomial distribution with parameters &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;p&lt;/code&gt; is the probability distribution of the number of successful Bernoulli process. Only supports &lt;code&gt;n&lt;/code&gt; = 1 for now.</source>
          <target state="translated">参数为 &lt;code&gt;n&lt;/code&gt; 和 &lt;code&gt;p&lt;/code&gt; 的二项式分布是成功的伯努利过程数的概率分布。目前仅支持 &lt;code&gt;n&lt;/code&gt; = 1。</target>
        </trans-unit>
        <trans-unit id="1b8c51d786a68de27c6b4224613923d5f7bdaf37" translate="yes" xml:space="preserve">
          <source>The bitwidth of the quantization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9046a47f005a317609f27142cf924b36a45d9e12" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">函数的主体（即 &lt;code&gt;func&lt;/code&gt; ）将不会在 &lt;code&gt;GraphDef&lt;/code&gt; 中序列化。因此，如果需要序列化模型并在其他环境中还原它，则不应使用此功能。</target>
        </trans-unit>
        <trans-unit id="794d80e295e24e3ff23cc23c744638ef8dd2ef67" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;tf.SavedModel&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">函数的主体（即 &lt;code&gt;func&lt;/code&gt; ）不会在 &lt;code&gt;tf.SavedModel&lt;/code&gt; 中序列化。因此，如果需要序列化模型并在其他环境中还原它，则不应使用此功能。</target>
        </trans-unit>
        <trans-unit id="2f2bb2d689c89f9383b7eeefb755379869595cea" translate="yes" xml:space="preserve">
          <source>The boolean tensor to reduce.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e7703441ddf5ba9641cb1cc0ad74e7c6c58e3a7" translate="yes" xml:space="preserve">
          <source>The brightness-adjusted image(s).</source>
          <target state="translated">亮度调整后的图像。</target>
        </trans-unit>
        <trans-unit id="0ed98e5a86a1390e9cad2bb3ecc49819e326a775" translate="yes" xml:space="preserve">
          <source>The broadcasted dimensions are placed in the corresponding location of the ellipsis in the output subscript. If the broadcasted dimensions are non-empty and the output subscripts do not contain ellipsis, then an InvalidArgument error is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fb502dacff4b6e562a2e1abdf5e1fedac860a6d" translate="yes" xml:space="preserve">
          <source>The byte count relative to the whence argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1e48a233423d312fda6e60318a1f77840441ac1" translate="yes" xml:space="preserve">
          <source>The call arguments for this layer are the same as those of the wrapped RNN layer.</source>
          <target state="translated">该层的调用参数与封装的RNN层的参数相同。</target>
        </trans-unit>
        <trans-unit id="d95f69aee0e146ccee9411fd2276d3062c98c22d" translate="yes" xml:space="preserve">
          <source>The call arguments for this layer are the same as those of the wrapped RNN layer. Beware that when passing the &lt;code&gt;initial_state&lt;/code&gt; argument during the call of this layer, the first half in the list of elements in the &lt;code&gt;initial_state&lt;/code&gt; list will be passed to the forward RNN call and the last half in the list of elements will be passed to the backward RNN call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3de2a1c81ff025749f22e62594b5197eb7231958" translate="yes" xml:space="preserve">
          <source>The callable taking two arguments and an optional msg= argument that raises self.failureException with a useful error message when the two arguments are not equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82b53f2208b8142725b57f3ebcfebf74479c1fc5" translate="yes" xml:space="preserve">
          <source>The callable to be performed if pred is false.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85b417d9584c69781a88c04ac220da15b4ffef62" translate="yes" xml:space="preserve">
          <source>The callable to be performed if pred is true.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6882837a3f25aad358b428438ef5466b3477a237" translate="yes" xml:space="preserve">
          <source>The callable to be performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d4c459c8aeff7109ccacc7811c716196afbf950" translate="yes" xml:space="preserve">
          <source>The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt;, and returns a possibly nested structure of Tensors and Operations, which may be different than the structure of &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f567f5385cd69b7cfcbd75d2a67b18740363cbef" translate="yes" xml:space="preserve">
          <source>The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt;. Its output must have the same structure as &lt;code&gt;fn_output_signature&lt;/code&gt; if one is provided; otherwise it must have the same structure as &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fad8c402c4ad4c03ff5742a4c9d67125becbdeb" translate="yes" xml:space="preserve">
          <source>The callable to be performed. It accepts two arguments. The first will have the same structure as &lt;code&gt;initializer&lt;/code&gt; if one is provided, otherwise it will have the same structure as &lt;code&gt;elems&lt;/code&gt;. The second will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt;. Its output must have the same structure as &lt;code&gt;initializer&lt;/code&gt; if one is provided, otherwise it must have the same structure as &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f42894533083db2f0bd479a307d6b9de88ad2ac" translate="yes" xml:space="preserve">
          <source>The casting only occurs in TensorFlow 2, but can be enabled if &lt;a href=&quot;../../../compat/v1/disable_v2_behavior&quot;&gt;&lt;code&gt;tf.compat.v1.disable_v2_behavior()&lt;/code&gt;&lt;/a&gt; has been called with &lt;a href=&quot;../../../compat/v1/keras/layers/enable_v2_dtype_behavior&quot;&gt;&lt;code&gt;tf.compat.v1.keras.layers.enable_v2_dtype_behavior()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d65e2fd04371734d652468cc491b0cee4ff69e4f" translate="yes" xml:space="preserve">
          <source>The centered RMSProp algorithm uses an estimate of the centered second moment (i.e., the variance) for normalization, as opposed to regular RMSProp, which uses the (uncentered) second moment. This often helps with training, but is slightly more expensive in terms of computation and memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33fbe725d21fc4d2840623043975b6cc7b98b5de" translate="yes" xml:space="preserve">
          <source>The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e327ae814821b8183785f0c019aba0430d092c8e" translate="yes" xml:space="preserve">
          <source>The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance:</source>
          <target state="translated">中心化的版本还保持了梯度的移动平均,并使用该平均来估计方差。</target>
        </trans-unit>
        <trans-unit id="bfef6db15137d8681f7bb35f6eac52b4909761b8" translate="yes" xml:space="preserve">
          <source>The character codepoints for all strings are returned using a single vector &lt;code&gt;char_values&lt;/code&gt;, with strings expanded to characters in row-major order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa3eb72957dbe620013c33a95407b9be5d104b9f" translate="yes" xml:space="preserve">
          <source>The character codepoints for all strings are returned using a single vector &lt;code&gt;char_values&lt;/code&gt;, with strings expanded to characters in row-major order. Similarly, the character start byte offsets are returned using a single vector &lt;code&gt;char_to_byte_starts&lt;/code&gt;, with strings expanded in row-major order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c31a51be422fab4cffa6c991deea2add3c6021c8" translate="yes" xml:space="preserve">
          <source>The check occurs when iterating over the contents of the dataset, which means that the check happens &lt;em&gt;after&lt;/em&gt; any static optimizations are applied to the dataset graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cde4b2ea69bdd9358c33f59eb179d46a7db32c3c" translate="yes" xml:space="preserve">
          <source>The checkpoint file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffd9bc04f2dc35c549a84231faac7f8f675d1f25" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;../../../train/checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">该检查点包括由此对象及其在调用&lt;a href=&quot;../../../train/checkpoint#write&quot;&gt; &lt;code&gt;Checkpoint.write()&lt;/code&gt; 时&lt;/a&gt;所依赖的任何可跟踪对象创建的变量。</target>
        </trans-unit>
        <trans-unit id="efb4974f19ee7156bcbc2c149c6eb12fbb9c2851" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">该检查点包括由此对象及其在调用&lt;a href=&quot;checkpoint#write&quot;&gt; &lt;code&gt;Checkpoint.write()&lt;/code&gt; 时&lt;/a&gt;所依赖的任何可跟踪对象创建的变量。</target>
        </trans-unit>
        <trans-unit id="38c24ccd874623d2c0df0fab88b6eb678631c447" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca19bcae5c51ffa24942d83670cdc3ac1b84f4ae" translate="yes" xml:space="preserve">
          <source>The checkpoint path to export.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dfa3f47f142cfb8c822aafba714441dd881e206" translate="yes" xml:space="preserve">
          <source>The checkpoint path to export. If &lt;code&gt;None&lt;/code&gt; (the default), the most recent checkpoint found within the model directory is chosen.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cf3d251f72fdb454086ef22c80d6dfc9f2a709b" translate="yes" xml:space="preserve">
          <source>The checkpoint prefix. If there are no checkpoints, returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">检查点前缀。如果没有检查点，则返回 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2b84dcebdb9409917518369da2c415dffacda85b" translate="yes" xml:space="preserve">
          <source>The class dimension. Defaulted to -1 which is the last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54c52716619b24d86f051441e79e67309f282670" translate="yes" xml:space="preserve">
          <source>The class specifies the parameters to configure a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; as it is initialized to a &lt;a href=&quot;logicaldevice&quot;&gt;&lt;code&gt;tf.config.LogicalDevice&lt;/code&gt;&lt;/a&gt; during runtime initialization. Not all fields are valid for all device types.</source>
          <target state="translated">该类指定用于配置&lt;a href=&quot;physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; &lt;/a&gt;的参数，因为在运行时初始化期间将其初始化为&lt;a href=&quot;logicaldevice&quot;&gt; &lt;code&gt;tf.config.LogicalDevice&lt;/code&gt; &lt;/a&gt;。并非所有字段都对所有设备类型均有效。</target>
        </trans-unit>
        <trans-unit id="8cadabc814bf5f30961f39db7a416141d019058e" translate="yes" xml:space="preserve">
          <source>The class uses optional peep-hole connections, optional cell clipping, and an optional projection layer.</source>
          <target state="translated">该类使用可选的窥视孔连接、可选的单元格剪裁和可选的投影层。</target>
        </trans-unit>
        <trans-unit id="a5550331649ac8852e50082985bc4347ae4ddf34" translate="yes" xml:space="preserve">
          <source>The classes &lt;code&gt;Tensor&lt;/code&gt; must provide string labels, not integer class IDs.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; 类必须提供字符串标签，而不是整数类ID。</target>
        </trans-unit>
        <trans-unit id="69874b3cb85190e4e3a8170c5f59a6adad260ddf" translate="yes" xml:space="preserve">
          <source>The column name containing the example ids.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11021faea4863b89bafde61f7853da18c9740ef5" translate="yes" xml:space="preserve">
          <source>The communication protocol, such as &lt;code&gt;&quot;grpc&quot;&lt;/code&gt;. If unspecified, will use the default from &lt;code&gt;python/platform/remote_utils.py&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8055f38c5a2a613d3b7898156485e396610a7e44" translate="yes" xml:space="preserve">
          <source>The companion method &lt;code&gt;start_queue_runners()&lt;/code&gt; can be used to start threads for all the collected queue runners.</source>
          <target state="translated">伴随方法 &lt;code&gt;start_queue_runners()&lt;/code&gt; 可用于为所有收集的队列运行器启动线程。</target>
        </trans-unit>
        <trans-unit id="97a9b8c4557a2e822deec22848a2c3bf8b143002" translate="yes" xml:space="preserve">
          <source>The compatibility module also provides the following aliases for common sets of python types:</source>
          <target state="translated">兼容性模块还为常见的python类型集提供了以下别名。</target>
        </trans-unit>
        <trans-unit id="c76eb8b972301e83c208f809121c80f183543a3c" translate="yes" xml:space="preserve">
          <source>The compatibility relation is reflexive and symmetric, but not transitive. For example, TensorShape([32, 784]) is compatible with TensorShape(None), and TensorShape(None) is compatible with TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with TensorShape([4, 4]).</source>
          <target state="translated">兼容性关系是反身的、对称的,但不是反身的。例如,TensorShape([32,784])与TensorShape(None)兼容,TensorShape(None)与TensorShape([4,4])兼容,但TensorShape([32,784])与TensorShape([4,4])不兼容。</target>
        </trans-unit>
        <trans-unit id="bc1fe8d57fc26b638818429d0e0fce300365e0f7" translate="yes" xml:space="preserve">
          <source>The compilation flags.</source>
          <target state="translated">汇编标志。</target>
        </trans-unit>
        <trans-unit id="004ddc3feaeb4999946bd055243271e6c1c5e458" translate="yes" xml:space="preserve">
          <source>The compilation is a hint and only supported on a best-effort basis.</source>
          <target state="translated">汇编是一种提示,只支持尽力而为。</target>
        </trans-unit>
        <trans-unit id="2a97fc9aeef3aac0ee7b0d6fc3913b5f131a8ce4" translate="yes" xml:space="preserve">
          <source>The complex conjugate returned by this operation is of the form \(a - bj\).</source>
          <target state="translated">这个操作返回的复共轭的形式是/(a-bj/)。</target>
        </trans-unit>
        <trans-unit id="c2a070804637f1f7cd7f3478e19c13e4ff6876a9" translate="yes" xml:space="preserve">
          <source>The components input has k elements, which correspond to the components of tuples stored in the given queue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f00bf6687c043d2091a7a6b17f2dcc072382a50" translate="yes" xml:space="preserve">
          <source>The components of the resulting element will have an additional outer dimension, which will be &lt;code&gt;batch_size&lt;/code&gt; (or &lt;code&gt;N % batch_size&lt;/code&gt; for the last element if &lt;code&gt;batch_size&lt;/code&gt; does not divide the number of input elements &lt;code&gt;N&lt;/code&gt; evenly and &lt;code&gt;drop_remainder&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;). If your program depends on the batches having the same outer dimension, you should set the &lt;code&gt;drop_remainder&lt;/code&gt; argument to &lt;code&gt;True&lt;/code&gt; to prevent the smaller batch from being produced.</source>
          <target state="translated">结果元素的组件将具有一个附加的外部尺寸，该尺寸将为 &lt;code&gt;batch_size&lt;/code&gt; （如果 &lt;code&gt;batch_size&lt;/code&gt; 未将输入元素的数量 &lt;code&gt;N&lt;/code&gt; 均匀划分并且 &lt;code&gt;drop_remainder&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; ，则为最后一个元素的 &lt;code&gt;N % batch_size&lt;/code&gt; ）。如果程序依赖于具有相同外部尺寸的批次，则应将 &lt;code&gt;drop_remainder&lt;/code&gt; 参数设置为 &lt;code&gt;True&lt;/code&gt; ,以防止产生较小的批次。</target>
        </trans-unit>
        <trans-unit id="344c73fb9ddb71179637f498f0b34262b87c80b8" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy, or None if the compute dtype should be inferred from the inputs.</source>
          <target state="translated">该策略的计算类型,如果计算类型应从输入中推断,则为None。</target>
        </trans-unit>
        <trans-unit id="205f439cb062a6f6e02604aa48a1bdc6926c8224" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy.</source>
          <target state="translated">该策略的计算类型。</target>
        </trans-unit>
        <trans-unit id="e48ef827cb89494677d2274efaf5e966b8a2acf1" translate="yes" xml:space="preserve">
          <source>The computed norms with the same shape and dtype &lt;code&gt;tensor&lt;/code&gt; but the final axis is 1 instead. Same as running &lt;code&gt;tf.cast(tf.linalg.norm(tensor, ord, axis keepdims=True), tensor.dtype)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a56e1ae6d24fcbef9729431047071ed9efb2c36" translate="yes" xml:space="preserve">
          <source>The concatenated rows for this ragged tensor.</source>
          <target state="translated">这个粗糙的张量的并列行。</target>
        </trans-unit>
        <trans-unit id="2e975fea798f7bc222374c880c42a36989a17b66" translate="yes" xml:space="preserve">
          <source>The concatenated values for all rows in this tensor.</source>
          <target state="translated">这个张量中所有行的连接值。</target>
        </trans-unit>
        <trans-unit id="853436dd51ebd4a92a981ee25b9140e01e3a8cb8" translate="yes" xml:space="preserve">
          <source>The concatenation of the lists trainable_weights and non_trainable_weights (in this order).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f6fe2c98e185c3c57a927e557bcc1cd36a6a7d8" translate="yes" xml:space="preserve">
          <source>The concentration parameters represent mean total counts of a &lt;code&gt;1&lt;/code&gt; or a &lt;code&gt;0&lt;/code&gt;, i.e.,</source>
          <target state="translated">浓度参数表示 &lt;code&gt;1&lt;/code&gt; 或 &lt;code&gt;0&lt;/code&gt; 的平均总数，即</target>
        </trans-unit>
        <trans-unit id="8b33c64ef5a9a221894d1d8c3eff40c36b6dadba" translate="yes" xml:space="preserve">
          <source>The condition to evaluate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b10cf771707704e5f421193cabc5bea06bcefd0e" translate="yes" xml:space="preserve">
          <source>The config of a layer does not include connectivity information, nor the layer class name. These are handled by &lt;code&gt;Network&lt;/code&gt; (one layer of abstraction above).</source>
          <target state="translated">层的配置不包括连通性信息，也不包括层类名称。这些由 &lt;code&gt;Network&lt;/code&gt; （上面一层抽象）处理。</target>
        </trans-unit>
        <trans-unit id="8880562899c802327a9dcd3decd4ce5b9c9c4257" translate="yes" xml:space="preserve">
          <source>The configuration object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6cabe853a86fe4b25fb9e66ffa23b7c23ff8a8" translate="yes" xml:space="preserve">
          <source>The constraint function that was passed to the variable constructor. Can be &lt;code&gt;None&lt;/code&gt; if no constraint was passed.</source>
          <target state="translated">传递给变量构造函数的约束函数。如果未传递任何约束，则可以为 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c73cc83e59c2cc8b75ad073ccf807211d4803200" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value.</source>
          <target state="translated">当最初解析标志时,以及每次改变相应标志的值后,都会验证该约束。</target>
        </trans-unit>
        <trans-unit id="adc492d7eedfc240429addc422d2a1187a94cf41" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value. Args: flag_name: str, name of the flag to be checked. checker: callable, a function to validate the flag. input - A single positional argument: The value of the corresponding flag (string, boolean, etc. This value will be passed to checker by the library). output - bool, True if validator constraint is satisfied. If constraint is not satisfied, it should either return False or raise flags.ValidationError(desired_error_message). message: str, error text to be shown to the user if checker returns False. If checker raises flags.ValidationError, message from the raised error will be shown. flag_values: flags.FlagValues, optional FlagValues instance to validate against. Raises: AttributeError: Raised when flag_name is not registered as a valid flag name.</source>
          <target state="translated">在最初解析flag时,以及每次改变相应flag的值后,都会对该约束进行验证。Args:flag_name:str,要检查的标志的名称.checker:callable,一个验证标志的函数.input--一个单一的位置参数。对应的flag的值(string,boolean等.这个值将由库传递给checker).output-bool,如果验证器约束条件被满足,则为True.如果约束不满足,它应该返回False或者引发flags.ValidationError(w desired_error_message).message:str,如果检查器返回False,将向用户显示的错误文本。flag_values:flags.FlagValidationError,可选的FlagValues实例,用于验证。会引发。AttributeError:当flag_name没有被注册为有效的flag名称时引发。</target>
        </trans-unit>
        <trans-unit id="4dc698ae175b05a09fb4ee349bbc6ecaa1e8c775" translate="yes" xml:space="preserve">
          <source>The constructor adds ops to save and restore variables.</source>
          <target state="translated">构造函数增加了保存和恢复变量的操作。</target>
        </trans-unit>
        <trans-unit id="a67ba085bb1cb054e5519f5de4ec3d7a1afd97f0" translate="yes" xml:space="preserve">
          <source>The container string to use in the context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88bfee8d69b86f8c88e1a6cd1fbfe637af690d6d" translate="yes" xml:space="preserve">
          <source>The container the flag is registered to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65be7a0d51d3df0c44e8373ef2d8cce6fba1ba7f" translate="yes" xml:space="preserve">
          <source>The contents of that resource.</source>
          <target state="translated">该资源的内容;</target>
        </trans-unit>
        <trans-unit id="62b621910705576177d148ac0a9d7924f1417008" translate="yes" xml:space="preserve">
          <source>The context in which the attribute child_name is to be changed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b796712e9d45d917e86f476afcbd17188df9e41f" translate="yes" xml:space="preserve">
          <source>The context manager is typically used as follows:</source>
          <target state="translated">上下文管理器的使用方法通常如下:</target>
        </trans-unit>
        <trans-unit id="b4d7d6dd724445c75543c5c53e6ef9742d69f23b" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the exception as the 'exception' attribute. This allows you to inspect the exception after the assertion::</source>
          <target state="translated">上下文管理器将异常的引用作为'exception'属性。这允许你在断言之后检查异常:。</target>
        </trans-unit>
        <trans-unit id="b36c5f83db5c2031ce81fe755689bacbd226c222" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the first matching warning as the 'warning' attribute; similarly, the 'filename' and 'lineno' attributes give you information about the line of Python code from which the warning was triggered. This allows you to inspect the warning after the assertion::</source>
          <target state="translated">上下文管理器保留了对第一个匹配的警告的引用,作为'warning'属性;同样,'filename'和'lineno'属性提供了关于触发警告的 Python 代码行的信息。这允许你在断言之后检查警告:。</target>
        </trans-unit>
        <trans-unit id="4baa6600f582743434abf2183d3229add8562932" translate="yes" xml:space="preserve">
          <source>The context manager to enter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39b31dd33d6410a26fac94ed5cf60c3b73346aa3" translate="yes" xml:space="preserve">
          <source>The continual decay of learning rates throughout training</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eb98e6489cd882c0c18e1586be464efd5024b02" translate="yes" xml:space="preserve">
          <source>The contracted &lt;code&gt;Tensor&lt;/code&gt;, with shape determined by &lt;code&gt;equation&lt;/code&gt;.</source>
          <target state="translated">收缩的 &lt;code&gt;Tensor&lt;/code&gt; ，其形状由 &lt;code&gt;equation&lt;/code&gt; 确定。</target>
        </trans-unit>
        <trans-unit id="db43655e2d0d002f7fe5b43dfac52f092c80941c" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image or images.</source>
          <target state="translated">对比度调整后的图像或图像。</target>
        </trans-unit>
        <trans-unit id="d7ed10745c14b330776ee5fc3a5ec88c5d4b915d" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image(s).</source>
          <target state="translated">对比度调整后的图像。</target>
        </trans-unit>
        <trans-unit id="b873b8e81b36897bcb81b13c24b9d9584a21302b" translate="yes" xml:space="preserve">
          <source>The convenience function &lt;a href=&quot;../../image/resize&quot;&gt;&lt;code&gt;tf.image.resize&lt;/code&gt;&lt;/a&gt; supports both 4-D and 3-D tensors as input and output. 4-D tensors are for batches of images, 3-D tensors for individual images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1ead59666a162707f70c2bb42eccfd78a56d994" translate="yes" xml:space="preserve">
          <source>The convenience function &lt;a href=&quot;image/resize&quot;&gt;&lt;code&gt;tf.image.resize&lt;/code&gt;&lt;/a&gt; supports both 4-D and 3-D tensors as input and output. 4-D tensors are for batches of images, 3-D tensors for individual images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14bfe517dc85759a813f2eb60977041c4d4420dc" translate="yes" xml:space="preserve">
          <source>The conversion function may return &lt;code&gt;NotImplemented&lt;/code&gt; for some inputs. In this case, the conversion process will continue to try subsequent conversion functions.</source>
          <target state="translated">对于某些输入，转换函数可能返回 &lt;code&gt;NotImplemented&lt;/code&gt; 。在这种情况下，转换过程将继续尝试后续的转换功能。</target>
        </trans-unit>
        <trans-unit id="993593e7b0bd02f95abe229cbbe58be1069a603a" translate="yes" xml:space="preserve">
          <source>The conversion function must have the following signature:</source>
          <target state="translated">转换函数必须具有以下签名:</target>
        </trans-unit>
        <trans-unit id="62c1d16c5d29bf1d22b745f14080c7842854b090" translate="yes" xml:space="preserve">
          <source>The conversion rules are as follows:</source>
          <target state="translated">转换规则如下:</target>
        </trans-unit>
        <trans-unit id="e10ca4df9812779b916afce6a1d1c3326adb544f" translate="yes" xml:space="preserve">
          <source>The converted code as string.</source>
          <target state="translated">转换后的代码为字符串。</target>
        </trans-unit>
        <trans-unit id="1a4c4fcb504882f83a37ad22c73c28617ce613ed" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format.</source>
          <target state="translated">转换后的数据为序列化格式。</target>
        </trans-unit>
        <trans-unit id="0f85bd8e5f77e08669b54d651dbd9c3373a46949" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format. Either a TFLite Flatbuffer or a Graphviz graph depending on value in &lt;code&gt;output_format&lt;/code&gt;.</source>
          <target state="translated">以序列化格式转换的数据。TFLite Flatbuffer或Graphviz图取决于 &lt;code&gt;output_format&lt;/code&gt; 中的值。</target>
        </trans-unit>
        <trans-unit id="d1373b125f4cfa9b84ebc99ddf4f15c0c28515a5" translate="yes" xml:space="preserve">
          <source>The converted data. For example if TFLite was the destination, then this will be a tflite flatbuffer in a bytes array.</source>
          <target state="translated">转换后的数据。例如,如果TFLite是目的地,那么这将是一个字节数组中的tflite flatbuffer。</target>
        </trans-unit>
        <trans-unit id="60fb348ae8fb1997effd221344f7a9df143ed5c3" translate="yes" xml:space="preserve">
          <source>The converted grayscale image(s).</source>
          <target state="translated">转换后的灰度图像。</target>
        </trans-unit>
        <trans-unit id="947c64ff75e26c329d08f9139c4ae882c26c7ee7" translate="yes" xml:space="preserve">
          <source>The copyright for Fashion-MNIST is held by Zalando SE. Fashion-MNIST is licensed under the &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE&quot;&gt;MIT license&lt;/a&gt;.</source>
          <target state="translated">Fashion-MNIST的版权由Zalando SE持有。Fashion-MNIST已获得&lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE&quot;&gt;MIT许可&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="efcf46084087344d6f569da9f4649c1142f8c478" translate="yes" xml:space="preserve">
          <source>The core difference between the two APIs is that this function is a graph rewrite, and so it changes the graph to use mixed precision under the hood. You still build your graph in float32, and the graph rewrite will change certain ops to float16. The Keras mixed precision API directly builds the Keras Model using a mix of float16 and float32.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1800b9129135de634c28deac11e3c72d5b276b9a" translate="yes" xml:space="preserve">
          <source>The corresponding &lt;code&gt;equation&lt;/code&gt; is:</source>
          <target state="translated">相应的 &lt;code&gt;equation&lt;/code&gt; 为：</target>
        </trans-unit>
        <trans-unit id="d08fae5c7558eeecccf8b9086f7da5fad59afff7" translate="yes" xml:space="preserve">
          <source>The corresponding dense tensor satisfies:</source>
          <target state="translated">相应的致密张量满足。</target>
        </trans-unit>
        <trans-unit id="25e9a5d7d3994fde2a58974f329ed60d12e01398" translate="yes" xml:space="preserve">
          <source>The covariance between elements in a batch is defined as:</source>
          <target state="translated">一批元素之间的共线性定义为:</target>
        </trans-unit>
        <trans-unit id="3f7c01ee2660f457c23437a997e09405b750c261" translate="yes" xml:space="preserve">
          <source>The covariance for each batch member is defined as the following:</source>
          <target state="translated">每个批次成员的协方差定义如下:</target>
        </trans-unit>
        <trans-unit id="ab3d07f930a48f37a430eaef5bc7e0c838a99b3b" translate="yes" xml:space="preserve">
          <source>The created &lt;a href=&quot;../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">创建的&lt;a href=&quot;../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bf06fef8a51d3d2222f888311b63cf162081ff33" translate="yes" xml:space="preserve">
          <source>The created Operation.</source>
          <target state="translated">创建的行动。</target>
        </trans-unit>
        <trans-unit id="bf8da6d42e9abc38af87cab58b26796f2a78e3eb" translate="yes" xml:space="preserve">
          <source>The created or existing &lt;code&gt;Variable&lt;/code&gt; (or &lt;code&gt;PartitionedVariable&lt;/code&gt;, if a partitioner was used).</source>
          <target state="translated">已创建或现有的 &lt;code&gt;Variable&lt;/code&gt; （如果使用了分区程序，则为 &lt;code&gt;PartitionedVariable&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="703c3b3c61be2bbfe2cef58610e4241c0cec208f" translate="yes" xml:space="preserve">
          <source>The created variable. Usually either a &lt;code&gt;Variable&lt;/code&gt; or &lt;code&gt;ResourceVariable&lt;/code&gt; instance. If &lt;code&gt;partitioner&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, a &lt;code&gt;PartitionedVariable&lt;/code&gt; instance is returned.</source>
          <target state="translated">创建的变量。通常是 &lt;code&gt;Variable&lt;/code&gt; 或 &lt;code&gt;ResourceVariable&lt;/code&gt; 实例。如果 &lt;code&gt;partitioner&lt;/code&gt; 不为 &lt;code&gt;None&lt;/code&gt; ，则返回 &lt;code&gt;PartitionedVariable&lt;/code&gt; 实例。</target>
        </trans-unit>
        <trans-unit id="a064f7a86a7da90002c28e35d9ae72e6f6639e8c" translate="yes" xml:space="preserve">
          <source>The creator is supposed to eventually call the next_creator to create a variable if it does want to create a variable and not call Variable or ResourceVariable directly. This helps make creators composable. A creator may choose to create multiple variables, return already existing variables, or simply register that a variable was created and defer to the next creators in line. Creators can also modify the keyword arguments seen by the next creators.</source>
          <target state="translated">创建者如果真的要创建一个变量,最终应该调用next_creator来创建变量,而不是直接调用Variable或ResourceVariable。这有助于使创建者可以复合。一个创建者可以选择创建多个变量,返回已经存在的变量,或者只是简单地注册一个变量被创建了,然后推迟到下一个创建者。创建者还可以修改下一个创建者看到的关键字参数。</target>
        </trans-unit>
        <trans-unit id="caefb816a5bf9fa47c79fd26eae5407f9e0b0029" translate="yes" xml:space="preserve">
          <source>The cumulative density function (cdf) is,</source>
          <target state="translated">累积密度函数(cdf)为:</target>
        </trans-unit>
        <trans-unit id="1e6cf6bfd84a9de01475c57535a86c638dabf3bb" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;replicacontext&quot;&gt;&lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt;&lt;/a&gt; object when in a replica context scope, else &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">在副本上下文范围内时当前的&lt;a href=&quot;replicacontext&quot;&gt; &lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt; &lt;/a&gt;对象，否则为 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f540e5e4425b87ae1543241ecadb7b9cf3701bab" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">当前的&lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;对象。</target>
        </trans-unit>
        <trans-unit id="0e1e3663ead0f80d5379392c5fb54bbf32b5424f" translate="yes" xml:space="preserve">
          <source>The current implementation memmaps the tensor from a file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7121b0671de74726a9379ae7d9c7f6f65ce0582e" translate="yes" xml:space="preserve">
          <source>The current scope, enabling or disabling compilation.</source>
          <target state="translated">当前范围,启用或禁用编译。</target>
        </trans-unit>
        <trans-unit id="6bc15ae139d05655dd2c4e393854e2c5c2fbb9ce" translate="yes" xml:space="preserve">
          <source>The current step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8745f63ae4946ac904ac85702804cdaabd80e53" translate="yes" xml:space="preserve">
          <source>The data format for input. Either &quot;NHWC&quot; (default) or &quot;NCHW&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1197173f8eacaa8f59bfc457afa910117b2511e" translate="yes" xml:space="preserve">
          <source>The data format for x. Either &quot;NHWC&quot; (default) or &quot;NCHW&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62ecb5db83683dd3080a11272c27160c0ee495ee" translate="yes" xml:space="preserve">
          <source>The data to train on. It can be passed either as a tf.data Dataset, as a NumPy array, a string tensor, or as a list of texts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eba17f1716c87ef57986eff77c3c1dd87e545657" translate="yes" xml:space="preserve">
          <source>The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="050a7e1310c5296c653e9c4a8cdd359fd2123e3a" translate="yes" xml:space="preserve">
          <source>The data type expected by the input, as a string (&lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;...)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02d8c288bbfe19ff5e3738bf18458a723f75bb21" translate="yes" xml:space="preserve">
          <source>The data type expected by the input. Default: &lt;code&gt;'float32'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc1f2fe24c93178a0cdc99089b0070c826bc8e7a" translate="yes" xml:space="preserve">
          <source>The data type for the &lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cba4765f6f6eab73eaa37643a033ccaf9abbf020" translate="yes" xml:space="preserve">
          <source>The data type of the output tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7dbd9f518a88378558ef3aa8f6e9b7c42f12504" translate="yes" xml:space="preserve">
          <source>The data type of this TensorArray.</source>
          <target state="translated">该TensorArray的数据类型。</target>
        </trans-unit>
        <trans-unit id="5860939eea91c5f2bfc6092504ee0e23ca7c09b6" translate="yes" xml:space="preserve">
          <source>The data type to call this function on when both values are of the same type in assertEqual().</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78041258434d725f1d8ee592df7ca0eb3e942ade" translate="yes" xml:space="preserve">
          <source>The data type to produce. Must be a floating point type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7ba10f144cbc87647590b7009fafb20f1cb2173" translate="yes" xml:space="preserve">
          <source>The data will be looped over (in batches).</source>
          <target state="translated">数据将被循环播放(分批播放)。</target>
        </trans-unit>
        <trans-unit id="79058d99313ceca7b802a44719e1215d8b01c4a7" translate="yes" xml:space="preserve">
          <source>The dataset produced by the &lt;code&gt;distribute&lt;/code&gt; transformation can be passed to Keras' &lt;a href=&quot;../../../keras/model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt; or Distribution Strategy's &lt;a href=&quot;../../../distribute/strategy#experimental_distribute_dataset&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset&lt;/code&gt;&lt;/a&gt; like any other &lt;a href=&quot;../../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;. We recommend setting a &lt;code&gt;job_name&lt;/code&gt; on the call to &lt;code&gt;distribute&lt;/code&gt; so that if there are multiple workers, they read data from the same job. Note that the autosharding normally performed by &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; will be disabled when setting a &lt;code&gt;job_name&lt;/code&gt;, since sharing the job already results in splitting data across the workers. When using a shared job, data will be dynamically balanced across workers, so that they reach end of input about the same time. This results in better worker utilization than with autosharding, where each worker processes an independent set of files, and some workers may run out of data earlier than others.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c103aa56baa5c32c667b938b6ce2201d2873c73f" translate="yes" xml:space="preserve">
          <source>The dataset to save.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7f912374554b917dc7b6ee9e848a59b9a0fe71e" translate="yes" xml:space="preserve">
          <source>The datatype of the gradients accumulated by this accumulator.</source>
          <target state="translated">该累加器积累的梯度数据类型。</target>
        </trans-unit>
        <trans-unit id="a4e8811eed25239dbc70516d5c5274e75126f7f5" translate="yes" xml:space="preserve">
          <source>The debugging information is dumped to a directory on the file system specified as &lt;code&gt;dump_root&lt;/code&gt;.</source>
          <target state="translated">调试信息将转储到文件系统上指定为 &lt;code&gt;dump_root&lt;/code&gt; 的目录中。</target>
        </trans-unit>
        <trans-unit id="af2ff91f6275afef5f274f54f89df6225cefc596" translate="yes" xml:space="preserve">
          <source>The decorated function will return the unbatched computation output Tensors.</source>
          <target state="translated">装饰的函数将返回未包干的计算输出Tensors。</target>
        </trans-unit>
        <trans-unit id="6284a54323a552b0a785e97eec39ef3920661508" translate="yes" xml:space="preserve">
          <source>The decorator argument &lt;code&gt;op_type&lt;/code&gt; is the string type of an operation. This corresponds to the &lt;code&gt;OpDef.name&lt;/code&gt; field for the proto that defines the operation.</source>
          <target state="translated">装饰器参数 &lt;code&gt;op_type&lt;/code&gt; 是操作的字符串类型。这对应于定义操作的原型的 &lt;code&gt;OpDef.name&lt;/code&gt; 字段。</target>
        </trans-unit>
        <trans-unit id="f564553c5a97e5c3c841f380324c41f020971604" translate="yes" xml:space="preserve">
          <source>The decorator function must use &lt;code&gt;&amp;lt;decorator name&amp;gt;.__wrapped__&lt;/code&gt; instead of the wrapped function that is normally used:</source>
          <target state="translated">装饰器函数必须使用 &lt;code&gt;&amp;lt;decorator name&amp;gt;.__wrapped__&lt;/code&gt; 而不是通常使用的包装函数：</target>
        </trans-unit>
        <trans-unit id="364632908db2fc42ec644ce9139f9d8cd2996dcc" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Graph&lt;/code&gt; being used in the current thread.</source>
          <target state="translated">当前线程中使用的默认 &lt;code&gt;Graph&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d6131e418f0fe8f055f5c1a72e6a16e1545b1880" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Session&lt;/code&gt; being used in the current thread.</source>
          <target state="translated">当前线程中使用的默认 &lt;code&gt;Session&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1f66d887de726d32ad140fa1257a1df52151a3df" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;atol&lt;/code&gt; and &lt;code&gt;rtol&lt;/code&gt; is &lt;code&gt;10 * eps&lt;/code&gt;, where &lt;code&gt;eps&lt;/code&gt; is the smallest representable positive number such that &lt;code&gt;1 + eps != 1&lt;/code&gt;. This is about &lt;code&gt;1.2e-6&lt;/code&gt; in &lt;code&gt;32bit&lt;/code&gt;, &lt;code&gt;2.22e-15&lt;/code&gt; in &lt;code&gt;64bit&lt;/code&gt;, and &lt;code&gt;0.00977&lt;/code&gt; in &lt;code&gt;16bit&lt;/code&gt;. See &lt;code&gt;numpy.finfo&lt;/code&gt;.</source>
          <target state="translated">默认的 &lt;code&gt;atol&lt;/code&gt; 和 &lt;code&gt;rtol&lt;/code&gt; 为 &lt;code&gt;10 * eps&lt;/code&gt; ，其中 &lt;code&gt;eps&lt;/code&gt; 是可表示的最小正数，因此 &lt;code&gt;1 + eps != 1&lt;/code&gt; 。这是一个关于 &lt;code&gt;1.2e-6&lt;/code&gt; 在 &lt;code&gt;32bit&lt;/code&gt; ， &lt;code&gt;2.22e-15&lt;/code&gt; 在 &lt;code&gt;64bit&lt;/code&gt; ，和 &lt;code&gt;0.00977&lt;/code&gt; 在 &lt;code&gt;16bit&lt;/code&gt; 。参见 &lt;code&gt;numpy.finfo&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="62dd8de847ac23e7ac8e6762e2b31102b93ee7ae" translate="yes" xml:space="preserve">
          <source>The default Scaffold local init op.</source>
          <target state="translated">默认的Scaffold本地init操作。</target>
        </trans-unit>
        <trans-unit id="d6e0519f99f3caed3a61af27ab387f572c9ce96e" translate="yes" xml:space="preserve">
          <source>The default dtype of variables created by &lt;a href=&quot;../../layers/layer#add_weight&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.add_weight&lt;/code&gt;&lt;/a&gt; is the layer's policy's variable dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="113557875e0d10c0495e5968c62aac634844babc" translate="yes" xml:space="preserve">
          <source>The default graph is a property of the current thread. If you create a new thread, and wish to use the default graph in that thread, you must explicitly add a &lt;code&gt;with g.as_default():&lt;/code&gt; in that thread's function.</source>
          <target state="translated">默认图是当前线程的属性。如果创建新线程，并希望在该线程中使用默认图形，则必须在该线程的函数中显式添加 &lt;code&gt;with g.as_default():&lt;/code&gt; 的a。</target>
        </trans-unit>
        <trans-unit id="af54ef57315265afe23c10353375841fe5684e25" translate="yes" xml:space="preserve">
          <source>The default name to use if the &lt;code&gt;name&lt;/code&gt; argument is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2836ebf9a61a1e040d248e87727142b11b48fa08" translate="yes" xml:space="preserve">
          <source>The default name to use if the &lt;code&gt;name_or_scope&lt;/code&gt; argument is &lt;code&gt;None&lt;/code&gt;, this name will be uniquified. If name_or_scope is provided it won't be used and therefore it is not required and can be None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9102c8e082f516efb1ceffb5e0598d25f581124b" translate="yes" xml:space="preserve">
          <source>The default non-peephole implementation is based on (Gers et al., 1999). The peephole implementation is based on (Sak et al., 2014).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3c4fe416ddd6e4cf097d426615758d9e0a2f0da" translate="yes" xml:space="preserve">
          <source>The default non-peephole implementation is based on:</source>
          <target state="translated">默认的非窥视孔实现是基于。</target>
        </trans-unit>
        <trans-unit id="b36d1ca5df94e6636114077cb6330c3dd4eb155f" translate="yes" xml:space="preserve">
          <source>The default type of the returned tensor is &lt;code&gt;'int32'&lt;/code&gt; to match TensorFlow's default.</source>
          <target state="translated">返回的张量的默认类型为 &lt;code&gt;'int32'&lt;/code&gt; 以匹配TensorFlow的默认类型。</target>
        </trans-unit>
        <trans-unit id="9c204a6e1f3b1ac9d5e05754cf3c4c6bfcbf5ab6" translate="yes" xml:space="preserve">
          <source>The default value may be either a single value or an iterable of values. A single value is transformed into a single-item list of that value.</source>
          <target state="translated">默认值可以是一个单一的值,也可以是一个可迭代的值。单个值被转化为该值的单项列表。</target>
        </trans-unit>
        <trans-unit id="95591cde8a6af9f0d83c1cbffce3447430c66fd4" translate="yes" xml:space="preserve">
          <source>The default value of 1e-7 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since Adam uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2676c22d8481d2093eb1222e6a62c6e07d9d33bd" translate="yes" xml:space="preserve">
          <source>The default value of 1e-7 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="translated">epsilon的默认值1e-7在一般情况下可能不是一个好的默认值。例如,在ImageNet上训练Inception网络时,目前好的选择是1.0或0.1。需要注意的是,由于AdamOptimizer使用的是Kingma和Ba论文第2.1节之前的公式,而不是算法1中的公式,所以这里所说的 &quot;epsilon &quot;是论文中的 &quot;epsilon帽子&quot;。</target>
        </trans-unit>
        <trans-unit id="7dce55634f5d3cd5afd750385d4cb7a72c3b4e6e" translate="yes" xml:space="preserve">
          <source>The default value of 1e-8 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="translated">epsilon的默认值1e-8在一般情况下可能不是一个好的默认值。例如,在ImageNet上训练Inception网络时,目前好的选择是1.0或0.1。需要注意的是,由于AdamOptimizer使用的是Kingma和Ba论文第2.1节之前的公式,而不是算法1中的公式,所以这里所说的 &quot;epsilon &quot;是论文中的 &quot;epsilon帽子&quot;。</target>
        </trans-unit>
        <trans-unit id="941c46320d31066669249101c341db7e0407ec86" translate="yes" xml:space="preserve">
          <source>The default value of the flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="615a8ce189d67deb5b00de2e039f587d13916340" translate="yes" xml:space="preserve">
          <source>The default value of the table.</source>
          <target state="translated">该表的默认值。</target>
        </trans-unit>
        <trans-unit id="5db08c92a6a8c4d1a19b3993d9edfeea8416589f" translate="yes" xml:space="preserve">
          <source>The default_value will be broadcast to the output shape. After that, the values from the ragged tensor overwrite the default values. Note that the default_value must have less dimensions than the value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89e2a62666c59169f6b3797f7e217d09c589a372" translate="yes" xml:space="preserve">
          <source>The delimiter to separate fields in a line.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00a0e2bb4cc9be91006217ca3ee3c8c2cea06b3f" translate="yes" xml:space="preserve">
          <source>The dense shape of the &lt;code&gt;IndexedSlices&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; to allow any dense shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afdbba2532bfdeb33e8af1bfa9b4559b2cf2e5ab" translate="yes" xml:space="preserve">
          <source>The dense shape of the &lt;code&gt;SparseTensor&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; to allow any dense shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="becf28b4c84759149d018b04bb5b5bc5f4cec754" translate="yes" xml:space="preserve">
          <source>The dense tensor &lt;code&gt;b&lt;/code&gt; may be either a scalar; otherwise &lt;code&gt;a&lt;/code&gt; must be a rank-3 &lt;code&gt;SparseMatrix&lt;/code&gt;; in this case &lt;code&gt;b&lt;/code&gt; must be shaped &lt;code&gt;[batch_size, 1, 1]&lt;/code&gt; and the multiply operation broadcasts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="726ed70f0dc33ddfe7a4cc805d63238531bb85eb" translate="yes" xml:space="preserve">
          <source>The dense tensor &lt;code&gt;dense&lt;/code&gt; represented by an &lt;code&gt;IndexedSlices&lt;/code&gt;&lt;code&gt;slices&lt;/code&gt; has</source>
          <target state="translated">致密张量 &lt;code&gt;dense&lt;/code&gt; 由表示 &lt;code&gt;IndexedSlices&lt;/code&gt; &lt;code&gt;slices&lt;/code&gt; 具有</target>
        </trans-unit>
        <trans-unit id="4266ae52077c5b23e390601d308e04d84d60ebbe" translate="yes" xml:space="preserve">
          <source>The deprecated &quot;infer&quot; policy</source>
          <target state="translated">废弃的 &quot;推断 &quot;策略</target>
        </trans-unit>
        <trans-unit id="47a704b6d6ba8a557d500ba37d0cbd25291c9ff6" translate="yes" xml:space="preserve">
          <source>The depth depends on profiling view. For 'scope' view, it's the depth of name scope hierarchy (tree), for 'op' view, it's the number of operation types (list), etc.</source>
          <target state="translated">深度取决于剖析视图。对于'scope'视图,是名称范围层次结构(树)的深度,对于'op'视图,是操作类型的数量(列表)等。</target>
        </trans-unit>
        <trans-unit id="2137c8c00ab29126bb362981cb4aca8aa9eecd42" translate="yes" xml:space="preserve">
          <source>The depth of the input tensor must be divisible by &lt;code&gt;block_size * block_size&lt;/code&gt;.</source>
          <target state="translated">输入张量的深度必须可被 &lt;code&gt;block_size * block_size&lt;/code&gt; 整除。</target>
        </trans-unit>
        <trans-unit id="856f925406c2e2660e650087c5e577d9ef121b34" translate="yes" xml:space="preserve">
          <source>The depth of the output tensor is &lt;code&gt;block_size * block_size * input_depth&lt;/code&gt;.</source>
          <target state="translated">输出张量的深度为 &lt;code&gt;block_size * block_size * input_depth&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b3dbf4f851a379190dde773c74ad7ff19b84f6a4" translate="yes" xml:space="preserve">
          <source>The desired DType of the returned &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0745ef41dcfcf7dc3af6f9af5a9ea5d649093458" translate="yes" xml:space="preserve">
          <source>The desired output &lt;code&gt;DType&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aba8863b230b8558a7b0bbc35057be0011a2be11" translate="yes" xml:space="preserve">
          <source>The destination type. The list of supported dtypes is the same as &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcdbb419b80b09c56eaabe4016b06b5e0aa6fcbf" translate="yes" xml:space="preserve">
          <source>The device filters can be partically specified. For remote tasks that do not have device filters specified, all devices will be visible to them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfeda8f899a5e6b3bd48a82937d06ce834bf27e7" translate="yes" xml:space="preserve">
          <source>The device name or function to use in the context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a06647ca6f050400b627e80f77759a71a57117ac" translate="yes" xml:space="preserve">
          <source>The device name to use in the context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56afabb9b384a9ae87fad18ee9dbf3881d1ccc16" translate="yes" xml:space="preserve">
          <source>The device of this variable.</source>
          <target state="translated">该变量的装置。</target>
        </trans-unit>
        <trans-unit id="3225614cf1d4291df3f5e762921b470644535a9b" translate="yes" xml:space="preserve">
          <source>The device on which to run the embedding lookup. Valid options are &quot;cpu&quot;, &quot;tpu_tensor_core&quot;, and &quot;tpu_embedding_core&quot;. If specifying &quot;tpu_tensor_core&quot;, a tensor_core_shape must be supplied. Defaults to &quot;cpu&quot;. If not specified, the default behavior is embedding lookup on &quot;tpu_embedding_core&quot; for training and &quot;cpu&quot; for inference. Valid options for training : [&quot;tpu_embedding_core&quot;, &quot;tpu_tensor_core&quot;] Valid options for serving : [&quot;cpu&quot;, &quot;tpu_tensor_core&quot;] For training, tpu_embedding_core is good for large embedding vocab (&amp;gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c44e9d347e5ccf542ed1c29e0c5e77c462ccf1ab" translate="yes" xml:space="preserve">
          <source>The device on which to run the embedding lookup. Valid options are &quot;cpu&quot;, &quot;tpu_tensor_core&quot;, and &quot;tpu_embedding_core&quot;. If specifying &quot;tpu_tensor_core&quot;, a tensor_core_shape must be supplied. If not specified, the default behavior is embedding lookup on &quot;tpu_embedding_core&quot; for training and &quot;cpu&quot; for inference. Valid options for training : [&quot;tpu_embedding_core&quot;, &quot;tpu_tensor_core&quot;] Valid options for serving : [&quot;cpu&quot;, &quot;tpu_tensor_core&quot;] For training, tpu_embedding_core is good for large embedding vocab (&amp;gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98f163e49909ba226b86dab21a009212ea93fb62" translate="yes" xml:space="preserve">
          <source>The device policy controls how operations requiring inputs on a specific device (e.g., on GPU:0) handle inputs on a different device (e.g. GPU:1).</source>
          <target state="translated">设备策略控制了需要在特定设备上输入的操作(例如在GPU:0上)如何处理不同设备上的输入(例如GPU:1)。</target>
        </trans-unit>
        <trans-unit id="f251515ee7a7da78599205d7a6518a062a6c0f5e" translate="yes" xml:space="preserve">
          <source>The devices this replica is to be executed on, as a tuple of strings.</source>
          <target state="translated">这个副本要执行的设备,作为一个字符串元组。</target>
        </trans-unit>
        <trans-unit id="87dd79764107968d1c698ee175a895a731232435" translate="yes" xml:space="preserve">
          <source>The difference between &lt;code&gt;stack&lt;/code&gt; and &lt;code&gt;parallel_stack&lt;/code&gt; is that &lt;code&gt;stack&lt;/code&gt; requires all the inputs be computed before the operation will begin but doesn't require that the input shapes be known during graph construction.</source>
          <target state="translated">&lt;code&gt;stack&lt;/code&gt; 和 &lt;code&gt;parallel_stack&lt;/code&gt; 之间的区别在于， &lt;code&gt;stack&lt;/code&gt; 要求在操作开始之前先计算所有输入，但不需要在图形构造期间知道输入形状。</target>
        </trans-unit>
        <trans-unit id="bcc3aba817880e065f4223ea3362fcfb9ea484b3" translate="yes" xml:space="preserve">
          <source>The difference between concat and parallel_concat is that concat requires all of the inputs be computed before the operation will begin but doesn't require that the input shapes be known during graph construction. Parallel concat will copy pieces of the input into the output as they become available, in some situations this can provide a performance benefit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2969267833427bcd62d3db92c629c1bcf7573937" translate="yes" xml:space="preserve">
          <source>The dimension along which the cosine distance is computed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1950ef9079ccb8fdab95487686c7eb37ab33631" translate="yes" xml:space="preserve">
          <source>The dimension softmax would be performed on. The default is -1 which indicates the last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a741b7f6b1d2304d511eed765b55f2d892e70b1b" translate="yes" xml:space="preserve">
          <source>The dimensions in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; are merged elementwise, according to the rules defined for &lt;code&gt;Dimension.merge_with()&lt;/code&gt;.</source>
          <target state="translated">根据为 &lt;code&gt;Dimension.merge_with()&lt;/code&gt; 定义的规则， &lt;code&gt;self&lt;/code&gt; 和 &lt;code&gt;other&lt;/code&gt; 中的维度将逐元素合并。</target>
        </trans-unit>
        <trans-unit id="6e700d4efdcd9fa4c17a75442e4f67358801b0cd" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input), rank(input))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c3884296f2f81a69d25f2d74a953505cb36e099" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input_tensor), rank(input_tensor))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="524dc0cac6bb52e1a46462ec8553ccc9e4362acf" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input_tensor), rank(input_tensor)]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8ce19192adc15b5220fef2532366cfeacb9e19d" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce; list or scalar. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d1b6053c3cee0279e3dc86b7090198e408447ec" translate="yes" xml:space="preserve">
          <source>The direction in which to sort the values (&lt;code&gt;'ASCENDING'&lt;/code&gt; or &lt;code&gt;'DESCENDING'&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bc7db80b0d2774479326226a4890a6e2d843629" translate="yes" xml:space="preserve">
          <source>The directory as string.</source>
          <target state="translated">目录为字符串。</target>
        </trans-unit>
        <trans-unit id="d47beb327611bfd25299d1d2b4c584bd5f48dbf4" translate="yes" xml:space="preserve">
          <source>The directory in which checkpoints are saved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e7ea210352ff9e76412951da939c6e46cfe6639" translate="yes" xml:space="preserve">
          <source>The directory of checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="115f901deb7759892ab1dbde3055bf4ffc36bc3e" translate="yes" xml:space="preserve">
          <source>The directory path where the dumping information will be written.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23759a3b8009ddee2c9ccc70d3ee85712ccf2888" translate="yes" xml:space="preserve">
          <source>The directory to save the model results and log files.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f003820357db00c0553228e9493dca5bc931d2d" translate="yes" xml:space="preserve">
          <source>The directory where files specified in data attribute of py_test and py_binary are stored.</source>
          <target state="translated">存储py_test和py_binary数据属性中指定文件的目录。</target>
        </trans-unit>
        <trans-unit id="57821be3cc06a5ba465c47d01aaf44aa61e1d383" translate="yes" xml:space="preserve">
          <source>The distance metric used for clustering. One of:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b7ccc3fd24de1a06b23a805fbbf6bc02487c531" translate="yes" xml:space="preserve">
          <source>The distances from each input point to each cluster center.</source>
          <target state="translated">每个输入点到每个集群中心的距离。</target>
        </trans-unit>
        <trans-unit id="adcc609cd8c69dbaffd925d5301fb26f55e523e5" translate="yes" xml:space="preserve">
          <source>The distortion is used to skew the unigram probability distribution. Each weight is first raised to the distortion's power before adding to the internal unigram distribution. As a result, &lt;code&gt;distortion = 1.0&lt;/code&gt; gives regular unigram sampling (as defined by the vocab file), and &lt;code&gt;distortion = 0.0&lt;/code&gt; gives a uniform distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a47603ed00a4a39f84d7b7101c2b650f89e2c48b" translate="yes" xml:space="preserve">
          <source>The distribution from which the parameters of the random features map (layer) are sampled determines which shift-invariant kernel the layer approximates (see paper for more details). You can use the distribution of your choice. The layer supports out-of-the-box approximation sof the following two RBF kernels:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f58b91125c882dc2a62587a652492f254f94698" translate="yes" xml:space="preserve">
          <source>The distribution functions can be evaluated on counts.</source>
          <target state="translated">分布函数可以对计数进行评估。</target>
        </trans-unit>
        <trans-unit id="7b6104158da73f015822f02cd6abbe4e2cf5c6cf" translate="yes" xml:space="preserve">
          <source>The distribution strategy options associated with the dataset. See &lt;a href=&quot;experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">与数据集关联的分配策略选项。有关更多详细信息，请参见&lt;a href=&quot;experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bf743a144dc0600d6b32b4a4db31e72e8fcd7021" translate="yes" xml:space="preserve">
          <source>The distributions have degree of freedom &lt;code&gt;df&lt;/code&gt;, mean &lt;code&gt;loc&lt;/code&gt;, and scale &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="translated">分布具有自由度 &lt;code&gt;df&lt;/code&gt; ，均值 &lt;code&gt;loc&lt;/code&gt; 和 &lt;code&gt;scale&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9974cdad7192faff5dd2133a51cc98b931250694" translate="yes" xml:space="preserve">
          <source>The document frequency of the OOV token. Only necessary if output_mode is TFIDF.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2de0b5493fea7bb1bb4b3e017251bece76051fd5" translate="yes" xml:space="preserve">
          <source>The drawn samples of shape &lt;code&gt;[batch_size, num_samples]&lt;/code&gt;.</source>
          <target state="translated">形状为 &lt;code&gt;[batch_size, num_samples]&lt;/code&gt; 的绘制样本。</target>
        </trans-unit>
        <trans-unit id="5e74b8b7d0df8fed16c79b98fd21910718bbb784" translate="yes" xml:space="preserve">
          <source>The dropout rate, between 0 and 1. E.g. &lt;code&gt;rate=0.1&lt;/code&gt; would drop out 10% of input units.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b307d95f377afd55d64b7df5ef858732cff45363" translate="yes" xml:space="preserve">
          <source>The dtype for &lt;code&gt;row_splits&lt;/code&gt;. One of &lt;a href=&quot;../tf#int32&quot;&gt;&lt;code&gt;tf.int32&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="650e6295ecdc851a5073e1cf59012505607bda82" translate="yes" xml:space="preserve">
          <source>The dtype for the return value. Defaults to &lt;code&gt;segment_ids.dtype&lt;/code&gt;, or &lt;a href=&quot;../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;segment_ids&lt;/code&gt; does not have a dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651f8e3ce30e01a19884517237de61dd305a37d2" translate="yes" xml:space="preserve">
          <source>The dtype for the return value. Defaults to &lt;code&gt;splits.dtype&lt;/code&gt;, or &lt;a href=&quot;../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;splits&lt;/code&gt; does not have a dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d0125518627216e27c3aadddc389fb684e07985" translate="yes" xml:space="preserve">
          <source>The dtype of the layer's computations and weights (default of &lt;code&gt;None&lt;/code&gt; means use &lt;a href=&quot;../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx&lt;/code&gt;&lt;/a&gt; in TensorFlow 2, or the type of the first input in TensorFlow 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80fd7b4c05a902c0f01fd54f89719616e3a0775c" translate="yes" xml:space="preserve">
          <source>The dtype of the layer's computations and weights. If mixed precision is used with a &lt;a href=&quot;../mixed_precision/experimental/policy&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.Policy&lt;/code&gt;&lt;/a&gt;, this is instead just the dtype of the layer's weights, as the computations are done in a different dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd52ea2eb7ea5be6e405a118979acc052f206e1b" translate="yes" xml:space="preserve">
          <source>The dtype of the resulting tensor is inferred from the inputs unless it is provided explicitly.</source>
          <target state="translated">生成的张量的d类型是由输入推断出来的,除非它是明确提供的。</target>
        </trans-unit>
        <trans-unit id="5d16a87cf006dd1b3cd4d0dcbb040b8f7357e681" translate="yes" xml:space="preserve">
          <source>The dtype that should be used for the &lt;code&gt;row_splits&lt;/code&gt; of any new ragged tensors. Existing &lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt; elements do not have their row_splits dtype changed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b69591d001104f8e2eec546d13dfde13802ef40" translate="yes" xml:space="preserve">
          <source>The dumped debugging information can be ingested by debugger UIs.</source>
          <target state="translated">转储的调试信息可以被调试器用户界面摄取。</target>
        </trans-unit>
        <trans-unit id="1c3bb311f55c44615e851ca1393dedf962117d6f" translate="yes" xml:space="preserve">
          <source>The dynamic calculation performed is, at time &lt;code&gt;t&lt;/code&gt; for batch row &lt;code&gt;b&lt;/code&gt;,</source>
          <target state="translated">动态计算来执行，在时间 &lt;code&gt;t&lt;/code&gt; 为一批行 &lt;code&gt;b&lt;/code&gt; ，</target>
        </trans-unit>
        <trans-unit id="8941174f7a82cad8c90f6e6a03ac3a820dea0104" translate="yes" xml:space="preserve">
          <source>The dynamic range of the images (i.e., the difference between the maximum the and minimum allowed values).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aae6b9d4f5b2d213b88b3723da3ddb26ced9416" translate="yes" xml:space="preserve">
          <source>The effective spatial dimensions of the zero-padded input tensor will be:</source>
          <target state="translated">零垫输入张量的有效空间维度将为。</target>
        </trans-unit>
        <trans-unit id="b9acfbbdfe245ea88de02f1a818fe0b504d8ee2c" translate="yes" xml:space="preserve">
          <source>The eigenvalues and eigenvectors for a non-Hermitian matrix in general are complex. The eigenvectors are not guaranteed to be linearly independent.</source>
          <target state="translated">一般来说,非赫米特矩阵的特征值和特征向量是复杂的。特征向量不能保证是线性独立的。</target>
        </trans-unit>
        <trans-unit id="ee408bc36c08a8eb79de0b041ba288a43ece416b" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x divided by y.</source>
          <target state="translated">x除以y的元素值。</target>
        </trans-unit>
        <trans-unit id="ee6f05fbd02c64e68c12a5dd5234049b70dd5c18" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x times y.</source>
          <target state="translated">x乘以y的元素值。</target>
        </trans-unit>
        <trans-unit id="5056d7193c98ed08aca24d8fed6317ade12de9af" translate="yes" xml:space="preserve">
          <source>The elements are shifted positively (towards larger indices) by the offset of &lt;code&gt;shift&lt;/code&gt; along the dimension of &lt;code&gt;axis&lt;/code&gt;. Negative &lt;code&gt;shift&lt;/code&gt; values will shift elements in the opposite direction. Elements that roll passed the last position will wrap around to the first and vice versa. Multiple shifts along multiple axes may be specified.</source>
          <target state="translated">元件通过的偏移正移（朝向较大索引） &lt;code&gt;shift&lt;/code&gt; 沿的尺寸 &lt;code&gt;axis&lt;/code&gt; 。负 &lt;code&gt;shift&lt;/code&gt; 值将使元素向相反方向偏移。滚动经过最后位置的元素将环绕到第一位置，反之亦然。可以指定沿多个轴的多个移位。</target>
        </trans-unit>
        <trans-unit id="c40643e8152d969c58abd0946b228718afbfd024" translate="yes" xml:space="preserve">
          <source>The elements in &lt;code&gt;input&lt;/code&gt; are considered to be complex numbers of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part. If &lt;code&gt;input&lt;/code&gt; is real then &lt;em&gt;b&lt;/em&gt; is zero by definition.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 中的元素被认为是形式为\（a + bj \）的复数，其中&lt;em&gt;a&lt;/em&gt;是实部，&lt;em&gt;b&lt;/em&gt;是虚部。如果 &lt;code&gt;input&lt;/code&gt; 是实数，则&lt;em&gt;b&lt;/em&gt;定义为零。</target>
        </trans-unit>
        <trans-unit id="bd6b82f2a01c27554a110fc1c60a8688cc656c5b" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;result&lt;/code&gt; will be:</source>
          <target state="translated">&lt;code&gt;result&lt;/code&gt; 的元素将是：</target>
        </trans-unit>
        <trans-unit id="7e5122262788d16dcc2a476a1ccd5d94e319a27e" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;sampled_candidates&lt;/code&gt; are drawn without replacement (if &lt;code&gt;unique=True&lt;/code&gt;) or with replacement (if &lt;code&gt;unique=False&lt;/code&gt;) from the base distribution.</source>
          <target state="translated">从基本分布中绘制了 &lt;code&gt;sampled_candidates&lt;/code&gt; 的元素时不进行替换（如果 &lt;code&gt;unique=True&lt;/code&gt; ），或者进行替换（如果 &lt;code&gt;unique=False&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="f8cb760115d6699c4a14874f1c5206c7b83dc9f1" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;seq_lengths&lt;/code&gt; must obey &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_axis]&lt;/code&gt;, and &lt;code&gt;seq_lengths&lt;/code&gt; must be a vector of length &lt;code&gt;input.dims[batch_axis]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48ab33f1524aaeaed08c07c88c40746479f023b7" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;seq_lengths&lt;/code&gt; must obey &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_dim]&lt;/code&gt;, and &lt;code&gt;seq_lengths&lt;/code&gt; must be a vector of length &lt;code&gt;input.dims[batch_dim]&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;seq_lengths&lt;/code&gt; 的元素必须遵守 &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_dim]&lt;/code&gt; ，并且 &lt;code&gt;seq_lengths&lt;/code&gt; 必须是长度为 &lt;code&gt;input.dims[batch_dim]&lt;/code&gt; 的向量。</target>
        </trans-unit>
        <trans-unit id="0d38c9da5faf42a7a6a14d9cb5caf234ae8f9c01" translate="yes" xml:space="preserve">
          <source>The elements of each job will be split between the two processes, with elements being consumed by the processes on a first-come first-served basis. One possible result is that process 1 prints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39f08dabb4ebd036182bf4e154d99641a60b1bde" translate="yes" xml:space="preserve">
          <source>The elements of the dataset must be scalar strings. To serialize dataset elements as strings, you can use the &lt;a href=&quot;../../io/serialize_tensor&quot;&gt;&lt;code&gt;tf.io.serialize_tensor&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">数据集的元素必须是标量字符串。要将数据集元素序列化为字符串，可以使用&lt;a href=&quot;../../io/serialize_tensor&quot;&gt; &lt;code&gt;tf.io.serialize_tensor&lt;/code&gt; &lt;/a&gt;函数。</target>
        </trans-unit>
        <trans-unit id="056215457d55383c82886d3fc40bfbe65262e4c1" translate="yes" xml:space="preserve">
          <source>The elements of the output vector are in range (0, 1) and sum to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b779b04f9885caafc27f0474205a244037f9aefe" translate="yes" xml:space="preserve">
          <source>The elements of the resulting dataset are created by zipping corresponding elements from each of the input datasets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3650e19170e124ae92368cff21395feb363f4884" translate="yes" xml:space="preserve">
          <source>The elements of this dataset correspond to records from the file(s). RFC 4180 format is expected for CSV files (https://tools.ietf.org/html/rfc4180) Note that we allow leading and trailing spaces with int or float field.</source>
          <target state="translated">这个数据集的元素对应于文件中的记录。RFC 4180格式是CSV文件的预期格式(https://tools.ietf.org/html/rfc4180),请注意,我们允许int或float字段使用前导和尾部空格。</target>
        </trans-unit>
        <trans-unit id="bd68739a9e7ae81bc68e96ee2b6122f5a70e5503" translate="yes" xml:space="preserve">
          <source>The embedding dimension (width) of the table.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b86ebc65ff7fe45f105d160f18d2c35f7cb8da0f" translate="yes" xml:space="preserve">
          <source>The empty string, in which case the corresponding tensor is saved normally.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c58cc0575d8bcfe00176a01cd63f2a1558bbe2e1" translate="yes" xml:space="preserve">
          <source>The encode and decode Ops apply to one image at a time. Their input and output are all of variable size. If you need fixed size images, pass the output of the decode Ops to one of the cropping and resizing Ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3aeafaf8f36325e7f515de971621d719406107b" translate="yes" xml:space="preserve">
          <source>The end result is that if the input is marked as an explicit endianness the transcoding is faithful to all codepoints in the source. If it is not marked with an explicit endianness, the BOM is not considered part of the string itself but as metadata, and so is not preserved in the output.</source>
          <target state="translated">最终的结果是,如果输入被标记为显式endianness,转码就会忠实于源码中的所有代码点。如果它没有被标记为显式endianness,则BOM不被认为是字符串本身的一部分,而是作为元数据,因此在输出中不会被保留。</target>
        </trans-unit>
        <trans-unit id="a7d3c35f0e85c1a6bf781b776ea72d3b7217b57e" translate="yes" xml:space="preserve">
          <source>The entire Python program exits when no alive non-daemon threads are left.</source>
          <target state="translated">当没有活着的非守护进程线程时,整个Python程序就会退出。</target>
        </trans-unit>
        <trans-unit id="c67894db798c48ee917afae60b483f03b8c6455e" translate="yes" xml:space="preserve">
          <source>The entire Python program exits when only daemon threads are left.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcab26b6f1d2bad63f4beb447401d7b8916bee05" translate="yes" xml:space="preserve">
          <source>The entire optimizer is currently thread compatible, not thread-safe. The user needs to perform synchronization if necessary.</source>
          <target state="translated">目前整个优化器是线程兼容的,不是线程安全的。必要时用户需要进行同步。</target>
        </trans-unit>
        <trans-unit id="c33387bb265f08d2eccc0ee4964677edfa18dfee" translate="yes" xml:space="preserve">
          <source>The error message that describes the error.</source>
          <target state="translated">描述错误的错误信息。</target>
        </trans-unit>
        <trans-unit id="3992d2c2ef24613a2edd3a09184b92d4f6c82dcc" translate="yes" xml:space="preserve">
          <source>The estimator uses a user-specified head.</source>
          <target state="translated">估计器使用用户指定的头。</target>
        </trans-unit>
        <trans-unit id="c0f4a9f9118713f2c65753167fbc45edc83681df" translate="yes" xml:space="preserve">
          <source>The event shape and the batch shape are properties of a Distribution object, whereas the sample shape is associated with a specific call to &lt;code&gt;sample&lt;/code&gt; or &lt;code&gt;log_prob&lt;/code&gt;.</source>
          <target state="translated">事件形状和批次形状是Distribution对象的属性，而样本形状与对 &lt;code&gt;sample&lt;/code&gt; 或 &lt;code&gt;log_prob&lt;/code&gt; 的特定调用相关联。</target>
        </trans-unit>
        <trans-unit id="e19c4b1d5034eb4e65cdca6271a9f69191e90f42" translate="yes" xml:space="preserve">
          <source>The example above uses the keyword argument &quot;step_num&quot; to specify the training step being traced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d89bb90670419b9d3a4b50ee4e20b8624c955245" translate="yes" xml:space="preserve">
          <source>The example has two variables containing parameters, &lt;code&gt;dense.kernel&lt;/code&gt; (2 parameters) and &lt;code&gt;dense.bias&lt;/code&gt; (1 parameter). Considering the training data &lt;code&gt;x&lt;/code&gt; as a constant, this means the Jacobian matrix for the function mapping from parameters to loss has one row and three columns.</source>
          <target state="translated">该示例有两个包含参数的变量， &lt;code&gt;dense.kernel&lt;/code&gt; （2个参数）和 &lt;code&gt;dense.bias&lt;/code&gt; （1个参数）。将训练数据 &lt;code&gt;x&lt;/code&gt; 视为常数，这意味着从参数到损失的函数映射的雅可比矩阵具有一行三列。</target>
        </trans-unit>
        <trans-unit id="84c18ab207b5195ffc68356ad590594bcf1dfa71" translate="yes" xml:space="preserve">
          <source>The examples below are for the case when only indices have leading extra dimensions. If both 'params' and 'indices' have leading batch dimensions, use the 'batch_dims' parameter to run gather_nd in batch mode.</source>
          <target state="translated">下面的例子是针对只有index有领先的额外维度的情况。如果'params'和'indices'都有领先的批处理尺寸,使用'batch_dims'参数在批处理模式下运行gather_nd。</target>
        </trans-unit>
        <trans-unit id="d6bb9f9b8e615c827d76fd441b8f54dc8cd4e856" translate="yes" xml:space="preserve">
          <source>The execution engine to connect to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8918766792e879b9d59da00a6e0e039a16054478" translate="yes" xml:space="preserve">
          <source>The expected cardinality of the input dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5de696bdbf9044458c641e379962d440aa33f58" translate="yes" xml:space="preserve">
          <source>The expected datatype of the sequences, or None if no datatype should be enforced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3928718719fe99849e7ac1ac65a36c562e1538d" translate="yes" xml:space="preserve">
          <source>The expected hash string of the file after download. The sha256 and md5 hash algorithms are both supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e7988b38263986e25122de775533e193c686e78" translate="yes" xml:space="preserve">
          <source>The expected length of the container.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bda1fab4530bea5769655be69388620ba7cc79a3" translate="yes" xml:space="preserve">
          <source>The expected numpy &lt;code&gt;ndarray&lt;/code&gt;, or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor), or any arbitrarily nested of structure of these.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78ad8b1f8ab153e6768481eb32292aa26fa61403" translate="yes" xml:space="preserve">
          <source>The expected output of its iterations is:</source>
          <target state="translated">其迭代的预期输出为:。</target>
        </trans-unit>
        <trans-unit id="7a97b08c68384c6b725f7994e4ae0a05ba85ecb6" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string or int to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying the features to be passed to the model. Note: if &lt;code&gt;features&lt;/code&gt; passed is not a dict, it will be wrapped in a dict with a single entry, using 'feature' as the key. Consequently, the model must accept a feature dict of the form {'feature': tensor}. You may use &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; if you want the tensor to be passed as is. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="translated">预期的返回值包括：features： &lt;code&gt;Tensor&lt;/code&gt; ， &lt;code&gt;SparseTensor&lt;/code&gt; 或 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;SparseTensor&lt;/code&gt; 的字符串或整数的dict ，指定要传递给模型的特征。注意：如果传递的 &lt;code&gt;features&lt;/code&gt; 不是字典，则将其包装在字典中，并以&amp;ldquo;特征&amp;rdquo;为键将其包含在单个条目中。因此，模型必须接受{'feature'：tensor}形式的特征字典。如果您希望按 &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; 传递张量，则可以使用TensorServingInputReceiver。 receiver_tensors： &lt;code&gt;Tensor&lt;/code&gt; ， &lt;code&gt;SparseTensor&lt;/code&gt; 或字符串dict到 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;SparseTensor&lt;/code&gt; ，指定默认情况下希望此接收器馈入的输入节点。通常，这是一个预期占位符 &lt;code&gt;tf.Example&lt;/code&gt; 占位符。 receiver_tensors_alternatives：附加接收方张量组的字符串字典，每个组可以是 &lt;code&gt;Tensor&lt;/code&gt; ， &lt;code&gt;SparseTensor&lt;/code&gt; 或 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;SparseTensor&lt;/code&gt; 字符串的字典。这些命名的接收器张量替代方案生成其他服务签名，这些签名可以用于在输入接收器子图中的不同点处馈送输入。一种典型用法是允许在tf.parse_example（）操作的&lt;em&gt;下游&lt;/em&gt;提供原始特征 &lt;code&gt;Tensor&lt;/code&gt; 。默认为无。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="31f7e12f63f032ea1d264ce969a77506eba82800" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A single &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, representing the feature to be passed to the model. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="translated">预期的返回值包括：features：单个 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;SparseTensor&lt;/code&gt; ，表示要传递给模型的特征。 receiver_tensors： &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;SparseTensor&lt;/code&gt; 的 &lt;code&gt;Tensor&lt;/code&gt; ， &lt;code&gt;SparseTensor&lt;/code&gt; 或字符串字典，指定默认情况下希望接收此接收器的输入节点。通常，这是一个预期占位符 &lt;code&gt;tf.Example&lt;/code&gt; 占位符。 receiver_tensors_alternatives：串的一个字典到接收机张量另外的基团，其中的每一个可以是 &lt;code&gt;Tensor&lt;/code&gt; ， &lt;code&gt;SparseTensor&lt;/code&gt; 或字符串的字典来 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;SparseTensor&lt;/code&gt; 。这些命名的接收器张量替代方案生成其他服务签名，这些签名可以用于在输入接收器子图中的不同点处馈送输入。一种典型用法是允许在tf.parse_example（）操作的&lt;em&gt;下游&lt;/em&gt;提供原始特征 &lt;code&gt;Tensor&lt;/code&gt; 。默认为无。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="a09896f6b4f647e3c96ed132a504af085f335053" translate="yes" xml:space="preserve">
          <source>The expected shape of the output tensor (excluding the batch dimension and any dimensions represented by ellipses). You can specify None for any dimension that is unknown or can be inferred from the input shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a40612bf469e8a522446e66d41d431047e69cf63" translate="yes" xml:space="preserve">
          <source>The expected size of the &lt;code&gt;logits&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;logits&lt;/code&gt; 张量的预期大小。</target>
        </trans-unit>
        <trans-unit id="a0f440ff029659182acbea8855f46dd42d2a4e96" translate="yes" xml:space="preserve">
          <source>The expected table key dtype.</source>
          <target state="translated">预期的表键dtype。</target>
        </trans-unit>
        <trans-unit id="31bcecc626aa91dd2b7d91005cf6117e6bde9f72" translate="yes" xml:space="preserve">
          <source>The expected table value dtype.</source>
          <target state="translated">预期表值dtype。</target>
        </trans-unit>
        <trans-unit id="376e0fcfa926199ad6e385d57f40bbf540152a01" translate="yes" xml:space="preserve">
          <source>The expected type of exception that should be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce7ef07c28defdcd9df2cbeda8fcff1eb3a70cf0" translate="yes" xml:space="preserve">
          <source>The expected values are &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">期望值为&lt;a href=&quot;../../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.SparseTensor&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c7c8fde13147479cf3364c839442aedae9a726dc" translate="yes" xml:space="preserve">
          <source>The expected values are &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dec1b3abe2b21793505b8807293f4669331e6f37" translate="yes" xml:space="preserve">
          <source>The experimental_mode parameter can be used to export a single train/eval/predict graph as a &lt;code&gt;SavedModel&lt;/code&gt;. See &lt;code&gt;experimental_export_all_saved_models&lt;/code&gt; for full docs.</source>
          <target state="translated">&lt;code&gt;SavedModel&lt;/code&gt; 参数可用于将单个火车/评估/预测图导出为SavedModel。有关完整文档，请参见 &lt;code&gt;experimental_export_all_saved_models&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7605e2fe49cffe7e518a9ae0d1ab56de778f3211" translate="yes" xml:space="preserve">
          <source>The exponential is computed using a combination of the scaling and squaring method and the Pade approximation. Details can be found in: Nicholas J. Higham, &quot;The scaling and squaring method for the matrix exponential revisited,&quot; SIAM J. Matrix Anal. Applic., 26:1179-1193, 2005.</source>
          <target state="translated">指数的计算采用了缩放和平方法以及Pade近似法的组合。详情见:Nicholas J.Higham,&quot;矩阵指数的缩放和平方法重温&quot;。Nicholas J.Higham,&quot;矩阵指数的缩放和平方法再探讨&quot; SIAM J.Matrix Anal.Applic.,26:1179-1193,2005。</target>
        </trans-unit>
        <trans-unit id="4f5a78bc935e9e08409cbf0ad9095df30519c6ba" translate="yes" xml:space="preserve">
          <source>The exponential linear activation: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x)-1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt;.</source>
          <target state="translated">指数线性活化： &lt;code&gt;x&lt;/code&gt; 如果 &lt;code&gt;x &amp;gt; 0&lt;/code&gt; 和 &lt;code&gt;alpha * (exp(x)-1)&lt;/code&gt; ，如果 &lt;code&gt;x &amp;lt; 0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2d28f89676ea4197a32d7a392e0d037302ffbd35" translate="yes" xml:space="preserve">
          <source>The exponential linear unit (ELU) activation function: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cf62415d8dce700f1230ed830d364734140b756" translate="yes" xml:space="preserve">
          <source>The exponential linear unit (ELU) with &lt;code&gt;alpha &amp;gt; 0&lt;/code&gt; is: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; The ELU hyperparameter &lt;code&gt;alpha&lt;/code&gt; controls the value to which an ELU saturates for negative net inputs. ELUs diminish the vanishing gradient effect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a8c6448917add778eb240e31bd6ab87cce7e676" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; 字典的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="9e2875cf5dfc1a19c0a389906972c0cc62d32b4f" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; 字典的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="72c1a65a7779ecfbc3e340268769bc17bef0c731" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; 字典的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;../export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="f952c6857d4170532f4c4a40882608ceb9fe6cf5" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; 字典的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="7d89ddec6391085569ef9d73498cfde0f5e37d2b" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;SavedModel&lt;/code&gt; is a standalone serialization of Tensorflow objects, and is supported by TF language APIs and the Tensorflow Serving system. To load the model, use the function &lt;code&gt;tf.keras.experimental.load_from_saved_model&lt;/code&gt;.</source>
          <target state="translated">导出的 &lt;code&gt;SavedModel&lt;/code&gt; 是Tensorflow对象的独立序列化，并且受TF语言API和Tensorflow Serving系统支持。要加载模型，请使用函数 &lt;code&gt;tf.keras.experimental.load_from_saved_model&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="115b43cdf7131901fe589992324081fddba4d32c" translate="yes" xml:space="preserve">
          <source>The factory function &lt;a href=&quot;raggedtensor#from_nested_row_splits&quot;&gt;&lt;code&gt;RaggedTensor.from_nested_row_splits&lt;/code&gt;&lt;/a&gt; may be used to construct a &lt;code&gt;RaggedTensor&lt;/code&gt; with multiple ragged dimensions directly, by providing a list of &lt;code&gt;row_splits&lt;/code&gt; tensors:</source>
          <target state="translated">通过提供 &lt;code&gt;row_splits&lt;/code&gt; 张量的列表，工厂函数&lt;a href=&quot;raggedtensor#from_nested_row_splits&quot;&gt; &lt;code&gt;RaggedTensor.from_nested_row_splits&lt;/code&gt; &lt;/a&gt;可以用于直接构造具有多个 &lt;code&gt;RaggedTensor&lt;/code&gt; 尺寸的RaggedTensor：</target>
        </trans-unit>
        <trans-unit id="2fe7017c754a0ab851bc9cefd6824cd6141a0f6a" translate="yes" xml:space="preserve">
          <source>The features dict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5250bfc0637fd3caf98029dfc4f15e7f982fc0a9" translate="yes" xml:space="preserve">
          <source>The filename of the text file to be used for initialization. The path must be accessible from wherever the graph is initialized (eg. trainer or eval workers). The filename may be a scalar &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8e6fb1c6f484ae15d3065837532041a4bcf6093" translate="yes" xml:space="preserve">
          <source>The filename.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88abaf7b1285ab3d50567c2571a1737eb63924d9" translate="yes" xml:space="preserve">
          <source>The files in the dump directory contain the following information:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84412542c638bfe39a033a0e5c516c5c165f7f74" translate="yes" xml:space="preserve">
          <source>The files in the dump directory contain the following information: - TensorFlow Function construction (e.g., compilation of Python functions decorated with @tf.function), the op types, names (if available), context, the input and output tensors, and the associated stack traces. - Execution of TensorFlow operations (ops) and Functions and their stack traces, op types, names (if available) and contexts. In addition, depending on the value of the &lt;code&gt;tensor_debug_mode&lt;/code&gt; argument (see Args section below), the value(s) of the output tensors or more concise summaries of the tensor values will be dumped. - A snapshot of Python source files involved in the execution of the TensorFlow program.</source>
          <target state="translated">转储目录中的文件包含以下信息：-TensorFlow函数构造（例如，用@ tf.function装饰的Python函数的编译），op类型，名称（如果可用），上下文，输入和输出张量以及关联的堆栈跟踪。-执行TensorFlow操作（ops）和函数及其堆栈跟踪，操作类型，名称（如果可用）和上下文。另外，根据 &lt;code&gt;tensor_debug_mode&lt;/code&gt; 参数的值（请参见下面的Args部分），将转储输出张量的值或张量值的更简洁的摘要。-参与TensorFlow程序执行的Python源文件的快照。</target>
        </trans-unit>
        <trans-unit id="9b2fccc77c27cb9da14140ce6802364bb75efc8d" translate="yes" xml:space="preserve">
          <source>The final callable to be wrapped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09f8439348997f787869e438ea0a2a5a324c4fe3" translate="yes" xml:space="preserve">
          <source>The final state. If &lt;code&gt;cell.state_size&lt;/code&gt; is an int, this will be shaped &lt;code&gt;[batch_size, cell.state_size]&lt;/code&gt;. If it is a &lt;code&gt;TensorShape&lt;/code&gt;, this will be shaped &lt;code&gt;[batch_size] + cell.state_size&lt;/code&gt;. If it is a (possibly nested) tuple of ints or &lt;code&gt;TensorShape&lt;/code&gt;, this will be a tuple having the corresponding shapes. If cells are &lt;code&gt;LSTMCells&lt;/code&gt;&lt;code&gt;state&lt;/code&gt; will be a tuple containing a &lt;code&gt;LSTMStateTuple&lt;/code&gt; for each cell.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36ee6080bb9a8b37b0bbd48b91307f93d8a3c47a" translate="yes" xml:space="preserve">
          <source>The first and last &lt;code&gt;summarize&lt;/code&gt; elements within each dimension are recursively printed per Tensor. If None, then the first 3 and last 3 elements of each dimension are printed for each tensor. If set to -1, it will print all elements of every tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64d3781f8c1cf2f73b0435ec5f118276a042b180" translate="yes" xml:space="preserve">
          <source>The first argument in the example slice is turned into &lt;code&gt;begin = 1&lt;/code&gt; and &lt;code&gt;end = begin + 1 = 2&lt;/code&gt;. To disambiguate from the original spec &lt;code&gt;2:4&lt;/code&gt; we also set the appropriate bit in &lt;code&gt;shrink_axis_mask&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50c753605d6ee518cbe6dced5742e28ec63d5987" translate="yes" xml:space="preserve">
          <source>The first dict contains the context key/values.</source>
          <target state="translated">第一个dict包含上下文键/值。</target>
        </trans-unit>
        <trans-unit id="5344b4467816487b27f53d3359aea3ba20354b84" translate="yes" xml:space="preserve">
          <source>The first distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8723eb87dd8e28a8fab5df851a599f355edbe887" translate="yes" xml:space="preserve">
          <source>The first list to compare.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21b3efb51e905408dc7d30df6c5476374dd7b033" translate="yes" xml:space="preserve">
          <source>The first matching Enum class member in Enum class.</source>
          <target state="translated">Enum类中第一个匹配的Enum类成员。</target>
        </trans-unit>
        <trans-unit id="aea8fe33a13a43f1f933680d9ce0f5a2db48535e" translate="yes" xml:space="preserve">
          <source>The first matching element from enum_values.</source>
          <target state="translated">enum_values的第一个匹配元素。</target>
        </trans-unit>
        <trans-unit id="1bce44f5aa098a07b694b38a57e97ffc2fd000fa" translate="yes" xml:space="preserve">
          <source>The first operand; &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf18fd4e6ab37edcfe93bf741aad23fe79581af4" translate="yes" xml:space="preserve">
          <source>The first output contains a Tensor with the content of the audio samples. The lowest dimension will be the number of channels, and the second will be the number of samples. For example, a ten-sample-long stereo WAV file should give an output shape of [10, 2].</source>
          <target state="translated">第一个输出包含一个包含音频样本内容的Tensor。最低的维度将是通道数,第二个维度将是样本数。例如,一个10个样本长度的立体声WAV文件应该给出一个[10,2]的输出形状。</target>
        </trans-unit>
        <trans-unit id="0febdfe0f37ee26156ab95b6c46f6c5edc75f5fb" translate="yes" xml:space="preserve">
          <source>The first port number to start with for processes on a node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="619642211ad5dce04a43e25b202652de1a8fad1c" translate="yes" xml:space="preserve">
          <source>The first sequence to compare.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc9c74061cbc9739e15176d22eb3bd77d76e6366" translate="yes" xml:space="preserve">
          <source>The first set to compare.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="852357a82fe8610e108e7001278c4fd3f4edcf3b" translate="yes" xml:space="preserve">
          <source>The first structure to compare.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="386e01aa23336af9951f682033560f681c83315e" translate="yes" xml:space="preserve">
          <source>The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data.</source>
          <target state="translated">数据集第一次迭代时,其元素将被缓存在指定的文件或内存中。随后的迭代将使用缓存的数据。</target>
        </trans-unit>
        <trans-unit id="8262a6a814226b4d2cd3a8aa3b8db9e5eb5fc35b" translate="yes" xml:space="preserve">
          <source>The first tuple to compare.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ef6022d2f562cb6afde1b6c189e84e6188a8d28" translate="yes" xml:space="preserve">
          <source>The first value used (&lt;code&gt;elems[-1]&lt;/code&gt; in case of None)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d030300b3efc2ffafb70c636249365dc53dadd74" translate="yes" xml:space="preserve">
          <source>The first value used (&lt;code&gt;elems[0]&lt;/code&gt; in case of None)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7831825ba8f0a4c3399d402b9f0a29404570764" translate="yes" xml:space="preserve">
          <source>The flag object for this flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f90632e85082c59f117ebff04eaae1a05ddf870" translate="yes" xml:space="preserve">
          <source>The flag value is parsed with a CSV parser.</source>
          <target state="translated">用CSV解析器对标志值进行解析。</target>
        </trans-unit>
        <trans-unit id="96f145cafd13cfdf0d9a0f61a17dd04e31f2f508" translate="yes" xml:space="preserve">
          <source>The flag's current value is also updated if the flag is currently using the default value, i.e. not specified in the command line, and not set by FLAGS.name = value.</source>
          <target state="translated">如果该标志当前使用的是默认值,即没有在命令行中指定,也没有通过FLAGS.name=value来设置,那么该标志的当前值也会被更新。</target>
        </trans-unit>
        <trans-unit id="43c9fd434671ebe599abe72c41c1f1beb298f354" translate="yes" xml:space="preserve">
          <source>The flow &lt;code&gt;Tensor&lt;/code&gt; forcing ops leading to this TensorArray state.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; 强制操作流导致此TensorArray状态。</target>
        </trans-unit>
        <trans-unit id="1099e35b936ecbdd40bed25b2b837d0cd15a755e" translate="yes" xml:space="preserve">
          <source>The folded size of each dimension D of the output is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5802a84878124b124beac42194fc2361ed2f11d6" translate="yes" xml:space="preserve">
          <source>The following &lt;code&gt;DType&lt;/code&gt; objects are defined:</source>
          <target state="translated">定义了以下 &lt;code&gt;DType&lt;/code&gt; 对象：</target>
        </trans-unit>
        <trans-unit id="f23bf2a65eeb471ae91c72707d1429b81ec5054e" translate="yes" xml:space="preserve">
          <source>The following accumulators/queue are created:</source>
          <target state="translated">创建以下累加器/队列:</target>
        </trans-unit>
        <trans-unit id="591cee6bba7aa3b795b8bd5b56dc88de0c7af0c0" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are experimental and may not be supported in future releases:</source>
          <target state="translated">以下聚合方法是试验性的,未来版本可能不支持。</target>
        </trans-unit>
        <trans-unit id="0a5195ca6a5ce9a55280235bcdfa18337e633d87" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are part of the stable API for aggregating gradients:</source>
          <target state="translated">以下聚合方法是聚合梯度的稳定API的一部分。</target>
        </trans-unit>
        <trans-unit id="ed747da915011723a2fa4461445d8b7e32c7a59d" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a52726e4632c6900863c9f3672bf906f2f1bdf5" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="492121a81bde0442283493d70aeb6ab59ed150cf" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48a55cd9397b04385ee28d777547e0bf00cef4d5" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ee6cb9dfe69d9d22f1caaeae67551de61d1e04d" translate="yes" xml:space="preserve">
          <source>The following code examples are equivalent:</source>
          <target state="translated">下面的代码示例是等价的。</target>
        </trans-unit>
        <trans-unit id="fe70fcf720ef0fde06fcd7d33ac8492a73efc566" translate="yes" xml:space="preserve">
          <source>The following example can be rewritten using a numpy.ndarray instead of the &lt;code&gt;value&lt;/code&gt; list, even reshaped, as shown in the two commented lines below the &lt;code&gt;value&lt;/code&gt; list initialization.</source>
          <target state="translated">可以使用numpy.ndarray而不是 &lt;code&gt;value&lt;/code&gt; 列表来重写以下示例，甚至可以重整代码，如 &lt;code&gt;value&lt;/code&gt; 列表初始化下方的两条注释行所示。</target>
        </trans-unit>
        <trans-unit id="dd2231c4c2e6ac8a925f85e0e3d53aba21ee51d7" translate="yes" xml:space="preserve">
          <source>The following example creates a TensorFlow graph with &lt;code&gt;np.sinh()&lt;/code&gt; as an operation in the graph:</source>
          <target state="translated">以下示例使用 &lt;code&gt;np.sinh()&lt;/code&gt; 创建TensorFlow图作为图中的操作：</target>
        </trans-unit>
        <trans-unit id="96cf93e8858013a75fb44334359039c6f25c846e" translate="yes" xml:space="preserve">
          <source>The following example demonstrates disabling the first GPU on the machine.</source>
          <target state="translated">下面的例子演示了如何禁用机器上的第一个GPU。</target>
        </trans-unit>
        <trans-unit id="f5252c999d447d634884b440e481ad68aacf0ae9" translate="yes" xml:space="preserve">
          <source>The following example lists the number of visible GPUs on the host.</source>
          <target state="translated">下面的例子列出了主机上可见的GPU数量。</target>
        </trans-unit>
        <trans-unit id="2cdccf83ed29fb9603555106e738bca275fd3c3f" translate="yes" xml:space="preserve">
          <source>The following example splits the CPU into 2 logical devices:</source>
          <target state="translated">下面的例子将CPU分割成2个逻辑设备。</target>
        </trans-unit>
        <trans-unit id="4ace04a5fda844a89c5ee4c9be9654bd7abe4446" translate="yes" xml:space="preserve">
          <source>The following example splits the GPU into 2 logical devices with 100 MB each:</source>
          <target state="translated">下面的例子将GPU分割成2个逻辑设备,每个设备100MB。</target>
        </trans-unit>
        <trans-unit id="e92322d00886dec66262eaafdb4b32cf9a853e78" translate="yes" xml:space="preserve">
          <source>The following example verifies all visible GPUs have been disabled:</source>
          <target state="translated">下面的例子验证了所有可见的GPU已经被禁用。</target>
        </trans-unit>
        <trans-unit id="4d32c07164d7968452b087497fbdd283446aa73c" translate="yes" xml:space="preserve">
          <source>The following is an example</source>
          <target state="translated">以下是一个例子</target>
        </trans-unit>
        <trans-unit id="ed38596eeae1ed9d7dcfb7df999c45674415489a" translate="yes" xml:space="preserve">
          <source>The following is an example:</source>
          <target state="translated">以下是一个例子。</target>
        </trans-unit>
        <trans-unit id="24bdb030bb46a068c505477e8cd1862a69826946" translate="yes" xml:space="preserve">
          <source>The following local variable is created:</source>
          <target state="translated">创建以下局部变量。</target>
        </trans-unit>
        <trans-unit id="6c83149474e8e1bdaa43183ac0053126fc2f29c2" translate="yes" xml:space="preserve">
          <source>The following optional keyword arguments are reserved for specific uses:</source>
          <target state="translated">以下可选关键字参数保留给特定用途。</target>
        </trans-unit>
        <trans-unit id="6b2e176467ad37b3b7339e39c7c7f1f162f5fc98" translate="yes" xml:space="preserve">
          <source>The following pieces are directly accessible as attributes of the &lt;code&gt;Scaffold&lt;/code&gt; object:</source>
          <target state="translated">以下部分可以直接作为 &lt;code&gt;Scaffold&lt;/code&gt; 对象的属性访问：</target>
        </trans-unit>
        <trans-unit id="c2ed2efebe2e500e729949e45ea5460a93f492fe" translate="yes" xml:space="preserve">
          <source>The following snippet initializes a table with the first column as keys and second column as values:</source>
          <target state="translated">下面的代码段初始化了一个表,第一列是键,第二列是值。</target>
        </trans-unit>
        <trans-unit id="e6f97267e796a462cd648b32cdaea5e143b3612c" translate="yes" xml:space="preserve">
          <source>The following standard keys are &lt;em&gt;defined&lt;/em&gt;, but their collections are &lt;strong&gt;not&lt;/strong&gt; automatically populated as many of the others are:</source>
          <target state="translated">&lt;em&gt;定义了&lt;/em&gt;以下标准键，但是&lt;strong&gt;不会&lt;/strong&gt;像其他许多键&lt;strong&gt;那样&lt;/strong&gt;自动填充它们的集合：</target>
        </trans-unit>
        <trans-unit id="99bfb2634af3adab05d0f542c47d1e0966b2dddf" translate="yes" xml:space="preserve">
          <source>The following standard keys are defined:</source>
          <target state="translated">定义了以下标准钥匙:</target>
        </trans-unit>
        <trans-unit id="afd1e679060dea3282d2910a495bdcd89bae687d" translate="yes" xml:space="preserve">
          <source>The following table describes the performance of</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c31091b8864e6e40a0add92be10029fb2426b1d" translate="yes" xml:space="preserve">
          <source>The following table describes the size and accuracy of the 100% MobileNet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3f6e3ce6202511b6216af33c5c3cad6bb0dbfc1" translate="yes" xml:space="preserve">
          <source>The following will raise an exception starting 2.0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91b487c69a091d3a3e964a72f6e8d59454bf3d7c" translate="yes" xml:space="preserve">
          <source>The format definition of the pattern is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5b0b8ccd1f0abc3ddefae0423fee59c58a2cd57" translate="yes" xml:space="preserve">
          <source>The fraction of zeros in &lt;code&gt;value&lt;/code&gt;, with type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">类型为 &lt;code&gt;float32&lt;/code&gt; 的零 &lt;code&gt;value&lt;/code&gt; 的分数。</target>
        </trans-unit>
        <trans-unit id="2501fc3382d34a61610662e4f61871c3957e8082" translate="yes" xml:space="preserve">
          <source>The frame hop size in samples. An integer or scalar &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8eacf4bf4a1e68b198d56b34b1c0c689db8338a7" translate="yes" xml:space="preserve">
          <source>The frame length in samples. An integer or scalar &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcd354bde47573036d72572be433b39a54714152" translate="yes" xml:space="preserve">
          <source>The frequency it should save at. Currently, the callback supports saving at the end of every epoch, or after a fixed number of training batches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71fdf778c80994adcf246068ec1f8befff71b20a" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that a checkpoint is saved using a default checkpoint saver. If both &lt;code&gt;save_checkpoint_steps&lt;/code&gt; and &lt;code&gt;save_checkpoint_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default checkpoint saver isn't used. If both are provided, then only &lt;code&gt;save_checkpoint_secs&lt;/code&gt; is used. Default not enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fb7193e8657058899d68bff4052e052b9f275c9" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that the global step and the loss will be logged during training. Also controls the frequency that the global steps / s will be logged (and written to summary) during training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b502ff4833f61fd9f9f6d0ad8bb30c38b89b253" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that the global step/sec is logged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="905a157c941ebd772aa422c7c4efd7a063f30d17" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that the summaries are written to disk using a default summary saver. If both &lt;code&gt;save_summaries_steps&lt;/code&gt; and &lt;code&gt;save_summaries_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default summary saver isn't used. Default 100.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d58dfeea5f5010f5f4f788d0923d660ec7ad4548" translate="yes" xml:space="preserve">
          <source>The frequency, in seconds, that a checkpoint is saved using a default checkpoint saver. If both &lt;code&gt;save_checkpoint_steps&lt;/code&gt; and &lt;code&gt;save_checkpoint_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default checkpoint saver isn't used. If both are provided, then only &lt;code&gt;save_checkpoint_secs&lt;/code&gt; is used. Default 600.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b936a6236c199c7dbaccd7f328139e3e55255549" translate="yes" xml:space="preserve">
          <source>The frequency, in secs, that the summaries are written to disk using a default summary saver. If both &lt;code&gt;save_summaries_steps&lt;/code&gt; and &lt;code&gt;save_summaries_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default summary saver isn't used. Default not enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="992778fe6a92285eff91d32500db456a86a4fc54" translate="yes" xml:space="preserve">
          <source>The full name of this operation.</source>
          <target state="translated">这次行动的全称。</target>
        </trans-unit>
        <trans-unit id="743b7a6db57523722e378bc070ddcab709a5ac83" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint (i.e. &lt;code&gt;file_prefix&lt;/code&gt;).</source>
          <target state="translated">检查点的完整路径（即 &lt;code&gt;file_prefix&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="17174d3c9eb2bd17d3031f0d66dc8f9b3b509e75" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint.</source>
          <target state="translated">通往检查站的完整路径。</target>
        </trans-unit>
        <trans-unit id="acdec3e98e6b61dcd2da29992ebc62ad6f5bf20c" translate="yes" xml:space="preserve">
          <source>The full path to the latest checkpoint or &lt;code&gt;None&lt;/code&gt; if no checkpoint was found.</source>
          <target state="translated">最新的检查点或完整路径 &lt;code&gt;None&lt;/code&gt; 如果没有检查点被发现。</target>
        </trans-unit>
        <trans-unit id="3f455e1b045b42fc22bb44e2db67ba33bc859100" translate="yes" xml:space="preserve">
          <source>The function 'f' must be a numerical function which takes N inputs and produces M outputs. Its gradient function 'g', which is computed by this SymbolicGradient op is a function taking N + M inputs and produces N outputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47f2fc665d0afe391e8a43fb1ae4db7142668b97" translate="yes" xml:space="preserve">
          <source>The function &lt;code&gt;grad_grad_fn&lt;/code&gt; will be calculating the first order gradient of &lt;code&gt;grad_fn&lt;/code&gt; with respect to &lt;code&gt;dy&lt;/code&gt;, which is used to generate forward-mode gradient graphs from backward-mode gradient graphs, but is not the same as the second order gradient of &lt;code&gt;op&lt;/code&gt; with respect to &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">函数 &lt;code&gt;grad_grad_fn&lt;/code&gt; 将计算相对于 &lt;code&gt;dy&lt;/code&gt; 的 &lt;code&gt;grad_fn&lt;/code&gt; 的一阶梯度，该梯度用于从后向模式梯度图生成前向模式梯度图，但与 &lt;code&gt;op&lt;/code&gt; 相对于 &lt;code&gt;x&lt;/code&gt; 的二阶梯度不同。</target>
        </trans-unit>
        <trans-unit id="45872032316d782b7cca27465e024bb311aaa0d6" translate="yes" xml:space="preserve">
          <source>The function arguments use the same convention as Theano's arange: if only one argument is provided, it is in fact the &quot;stop&quot; argument and &quot;start&quot; is 0.</source>
          <target state="translated">函数参数使用与Theano的arrange相同的约定:如果只提供一个参数,其实就是 &quot;停止 &quot;参数,&quot;开始 &quot;为0。</target>
        </trans-unit>
        <trans-unit id="5b48f1f01f262f6a95842647a89db44aed8acfaa" translate="yes" xml:space="preserve">
          <source>The function given by &lt;code&gt;f&lt;/code&gt; is assumed to be stateless, and is executed concurrently on all the slices; up to batch_size (i.e. the size of the 0th dimension of each argument) functions will be scheduled at once.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a54988c5a27bf3df304066330e8659cc62c5ae14" translate="yes" xml:space="preserve">
          <source>The function may use variable scopes and other templates internally to create and reuse variables, but it shouldn't use &lt;a href=&quot;global_variables&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt;&lt;/a&gt; to capture variables that are defined outside of the scope of the function.</source>
          <target state="translated">该函数可以在内部使用变量作用域和其他模板来创建和重用变量，但不应使用&lt;a href=&quot;global_variables&quot;&gt; &lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt; &lt;/a&gt;捕获在函数范围之外定义的变量。</target>
        </trans-unit>
        <trans-unit id="7473045784de1b0d1dced2ea1e88e2739636aca8" translate="yes" xml:space="preserve">
          <source>The function returns a 1-arg callable to compute the piecewise constant when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="translated">该函数返回一个1-arg的可调用函数,用于计算传递当前优化器步骤时的片断常数。这对于改变不同优化器函数调用的学习率值很有用。</target>
        </trans-unit>
        <trans-unit id="7935c69bd80f01354e2709843f6b51eb870975aa" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate while taking into account possible warm restarts. The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="translated">该函数返回衰减的学习速率，同时考虑到可能的热重启。对于 &lt;code&gt;first_decay_steps&lt;/code&gt; 步骤，学习率乘数首先从1衰减到 &lt;code&gt;alpha&lt;/code&gt; 。然后，执行热重启。每次新的热启动都会以 &lt;code&gt;t_mul&lt;/code&gt; 倍的步数运行，而以 &lt;code&gt;m_mul&lt;/code&gt; 倍的初始学习率运行。</target>
        </trans-unit>
        <trans-unit id="86355e2388af8622a11980472ee114bf3a474b98" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate. It is computed as:</source>
          <target state="translated">该函数返回衰减的学习率。它的计算方法是:</target>
        </trans-unit>
        <trans-unit id="bbeb4f9954a2b9fb0a88492d0bff2e967c29ba25" translate="yes" xml:space="preserve">
          <source>The function should create all trainable variables and any variables that should be reused by calling &lt;a href=&quot;get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt;&lt;/a&gt;. If a trainable variable is created using &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;, then a ValueError will be thrown. Variables that are intended to be locals can be created by specifying &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable(..., trainable=false)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">该函数应创建所有可训练变量以及应通过调用&lt;a href=&quot;get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt; &lt;/a&gt;重用的所有变量。如果使用&lt;a href=&quot;../../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt;创建可训练的变量，则将引发ValueError。可以通过指定&lt;a href=&quot;../../variable&quot;&gt; &lt;code&gt;tf.Variable(..., trainable=false)&lt;/code&gt; &lt;/a&gt;来创建旨在用作本地变量的变量。</target>
        </trans-unit>
        <trans-unit id="ba018ba32690d333b62a34c97deeda897ce164c2" translate="yes" xml:space="preserve">
          <source>The function to be evaluated. Takes input tensor as first argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e907a33ddfd6da0b56e4114475edd885278841a5" translate="yes" xml:space="preserve">
          <source>The function to execute. Must return at least one tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e4d2297438553bf056c22e891e3cecb8fe842de" translate="yes" xml:space="preserve">
          <source>The function to run to generate values. It is called for each replica with &lt;code&gt;tf.distribute.ValueContext&lt;/code&gt; as the sole argument. It must return a Tensor or a type that can be converted to a Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cb705f7c58e8e1b04b26492ea1ad09028dbf43c" translate="yes" xml:space="preserve">
          <source>The function to run. The inputs to the function must match the outputs of &lt;code&gt;input_iterator.get_next()&lt;/code&gt;. The output must be a &lt;a href=&quot;../../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="579f33c18a20c35d0e6bad8c31ac59b2c5a138bd" translate="yes" xml:space="preserve">
          <source>The function to run. The inputs to the function must match the outputs of &lt;code&gt;input_iterator.get_next()&lt;/code&gt;. The output must be a &lt;a href=&quot;../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="852a50a7728a6fd7607421cbe4af6011056e859b" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d27cb3a61380f733c1a764c217224b74c44ff381" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd6977a402d5af69ff9d5af0a33cb56304518592" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78ce4aa7e51e00f628bab76b1b138c468eab06e1" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d78455957704f506f9390b364cd5e99854c75cd" translate="yes" xml:space="preserve">
          <source>The function to use for the KL divergence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="818483846ef2282fe88a2ae296752a2d10573267" translate="yes" xml:space="preserve">
          <source>The function to wrap.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e1312f2dcf17101a4e17a36133e6bbffe530ce3" translate="yes" xml:space="preserve">
          <source>The function writes the SavedModel protocol buffer to the export directory in serialized format.</source>
          <target state="translated">该函数将SavedModel协议缓冲区以序列化格式写入导出目录。</target>
        </trans-unit>
        <trans-unit id="00cf308c9f40a9f1b859f12fd033e78caa4d14cd" translate="yes" xml:space="preserve">
          <source>The functions &lt;code&gt;f1&lt;/code&gt; and &lt;code&gt;f2&lt;/code&gt; will be executed serially, and updates to &lt;code&gt;v&lt;/code&gt; will be atomic.</source>
          <target state="translated">函数 &lt;code&gt;f1&lt;/code&gt; 和 &lt;code&gt;f2&lt;/code&gt; 将依次执行，对 &lt;code&gt;v&lt;/code&gt; 的更新将是原子的。</target>
        </trans-unit>
        <trans-unit id="dde4529b22d96c16a9b96a541d58c5d0a1f7056a" translate="yes" xml:space="preserve">
          <source>The generated &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt;&lt;code&gt;Summary&lt;/code&gt;&lt;/a&gt; has one summary value containing a histogram for &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="translated">将所生成的&lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt; &lt;code&gt;Summary&lt;/code&gt; &lt;/a&gt;具有包含用于直方图一个摘要值 &lt;code&gt;values&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="062e4980e54d60fb22e75f6c9b5206c3bc85ad28" translate="yes" xml:space="preserve">
          <source>The generated Summary has a Tensor.proto containing the input Tensor.</source>
          <target state="translated">生成的Summary有一个Tensor.proto,包含输入的Tensor。</target>
        </trans-unit>
        <trans-unit id="83836bb270c947f8350589c70a4bb97f00394569" translate="yes" xml:space="preserve">
          <source>The generated batches contain augmented/normalized data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83e4f5e3d1731cbc1599b80b8ef76caeb81edab7" translate="yes" xml:space="preserve">
          <source>The generated values are uniform integers covering the whole range of &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4d0e9a2a91b309d7ff0adf11bf3c435181bcb9c" translate="yes" xml:space="preserve">
          <source>The generated values are uniform integers in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a8e22261f08ee2c0135f17d838b4636ab11c865" translate="yes" xml:space="preserve">
          <source>The generated values follow a Poisson distribution with specified rate parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6c1194a7570536aae2b3653d7c1dba93fd5851" translate="yes" xml:space="preserve">
          <source>The generated values follow a binomial distribution with specified count and probability of success parameters.</source>
          <target state="translated">生成的数值遵循二项式分布,具有指定的计数和成功概率参数。</target>
        </trans-unit>
        <trans-unit id="8a3b970769a2106f11ed64fa7b1620c03aad121a" translate="yes" xml:space="preserve">
          <source>The generated values follow a gamma distribution with specified concentration (&lt;code&gt;alpha&lt;/code&gt;) and inverse scale (&lt;code&gt;beta&lt;/code&gt;) parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaccd314351760e5cabf42f9640ec2685d7cb77b" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with mean 0 and standard deviation 1, except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34cfd1936eb36f5d55d6eea6019586d8abfd6453" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked.</source>
          <target state="translated">生成的数值按照指定的均值和标准差进行正态分布,但如果数值的大小与均值相差超过2个标准差,则会被剔除,然后重新挑选。</target>
        </trans-unit>
        <trans-unit id="0f713a6a0ff6a46795bef18d9e29d3e2780e55f6" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than two standard deviations from the mean are dropped and re-picked.</source>
          <target state="translated">生成的数值按照指定的均值和标准差进行正态分布,但如果数值的幅度超过均值的两个标准差,则会被剔除,然后重新选取。</target>
        </trans-unit>
        <trans-unit id="ad922f688ee4660e4c8bf530c9eb75a9c98e5b45" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[0, 1)&lt;/code&gt;. The lower bound 0 is included in the range, while the upper bound 1 is excluded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74c424169a88b80e0d5085c0b28049f21d25d95f" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4eafca9e4f8c3067d55709b52f16b752c27ed7e" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded.</source>
          <target state="translated">生成的值在 &lt;code&gt;[minval, maxval)&lt;/code&gt; 范围内遵循均匀分布。该范围包括下限 &lt;code&gt;minval&lt;/code&gt; ，而上限 &lt;code&gt;maxval&lt;/code&gt; 被排除。</target>
        </trans-unit>
        <trans-unit id="729a8a331d955e25ac8cf2c6b6a31b0effcb1a59" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded. (For float numbers especially low-precision types like bfloat16, because of rounding, the result may sometimes include &lt;code&gt;maxval&lt;/code&gt;.)</source>
          <target state="translated">生成的值在 &lt;code&gt;[minval, maxval)&lt;/code&gt; 范围内遵循均匀分布。该范围包括下限 &lt;code&gt;minval&lt;/code&gt; ，而上限 &lt;code&gt;maxval&lt;/code&gt; 被排除。（由于四舍五入，对于浮点数尤其是诸如bfloat16之类的低精度类型，结果有时可能包含 &lt;code&gt;maxval&lt;/code&gt; 。）</target>
        </trans-unit>
        <trans-unit id="3ef793d516e9c255e6083a55e2c214fa9d53e3d0" translate="yes" xml:space="preserve">
          <source>The generated values will have mean 0 and standard deviation 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="435c1caf59e1323627f0000c63fea7965b6e39ca" translate="yes" xml:space="preserve">
          <source>The gist of RMSprop is to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f254b2b1969b3fd6753653a609c42efa67f8dfa" translate="yes" xml:space="preserve">
          <source>The given &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt; can be merged as long as there does not exist an attribute that is set to different values in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;options&lt;/code&gt;.</source>
          <target state="translated">只要不存在在 &lt;code&gt;self&lt;/code&gt; 和 &lt;code&gt;options&lt;/code&gt; 中设置为不同值的属性，就可以合并给定的&lt;a href=&quot;options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0d60ebc741d192476c8f1b6c1be3c6bd74a4d508" translate="yes" xml:space="preserve">
          <source>The given tensors are sliced along their first dimension. This operation preserves the structure of the input tensors, removing the first dimension of each tensor and using it as the dataset dimension. All input tensors must have the same size in their first dimensions.</source>
          <target state="translated">给定的张量沿其第一维度被切分。这个操作保留了输入张量的结构,去掉了每个张量的第一维,并将其作为数据集的维度。所有输入张量在其第一维度上必须具有相同的大小。</target>
        </trans-unit>
        <trans-unit id="c5f30df096e972187d2845f5f792a695d8948e14" translate="yes" xml:space="preserve">
          <source>The global &lt;a href=&quot;generator&quot;&gt;&lt;code&gt;tf.random.Generator&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccd566669127e41c5c83f5e51e6e655e2023b466" translate="yes" xml:space="preserve">
          <source>The global Policy.</source>
          <target state="translated">全球政策。</target>
        </trans-unit>
        <trans-unit id="d7a438a2cfde234e4966d3aff26afbb96ef542c4" translate="yes" xml:space="preserve">
          <source>The global batch size that you indend to use. Note that is fixed and the same batch size must be used for both training and evaluation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f44fcbf38635afbe0c45b61c517d01f18c4ad9b" translate="yes" xml:space="preserve">
          <source>The global id in the training cluster.</source>
          <target state="translated">训练集群中的全局ID。</target>
        </trans-unit>
        <trans-unit id="c06234718e1efd425d9fee36736f9c49d1c25446" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no global policy is set, layers will instead default to a Policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2. In TensorFlow 1, layers default to an &quot;infer&quot; policy.</source>
          <target state="translated">如果未将任何策略传递给图层构造函数，则全局策略是用于图层的默认策略。如果未设置全局策略，则层将默认为从TensorFlow 2中的&lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt;构造的策略。在Te​​nsorFlow 1中，层默认为&amp;ldquo;推断&amp;rdquo;策略。</target>
        </trans-unit>
        <trans-unit id="a24374cc9cda5c5142d42bd656066ec74ccfe3d0" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no global policy is set, layers will instead default to a Policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1016f9f2efa6dbdf2080ac5fb0e6a2efdf1abe3" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no policy has been set with &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt;, this will return a policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; (floatx defaults to float32).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aa023817c66fefe7d12596fe9f5c2f950738ad5" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no policy has been set with &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt;, this will return a policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2 (floatx defaults to float32), or an &quot;infer&quot; policy in TensorFlow 1.</source>
          <target state="translated">如果未将任何策略传递给图层构造函数，则全局策略是用于图层的默认策略。如果未使用&lt;a href=&quot;set_policy&quot;&gt; &lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt; &lt;/a&gt;设置任何策略，这将返回由TensorFlow 2中的&lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt;构造的策略（floatx默认为float32）或TensorFlow 1中的&amp;ldquo;推断&amp;rdquo;策略。</target>
        </trans-unit>
        <trans-unit id="147a0f3f093ca1fdfeeb131812693ae892afe50f" translate="yes" xml:space="preserve">
          <source>The global step tensor must be an integer variable. We first try to find it in the collection &lt;code&gt;GLOBAL_STEP&lt;/code&gt;, or by name &lt;code&gt;global_step:0&lt;/code&gt;.</source>
          <target state="translated">全局步长张量必须是整数变量。我们首先尝试在集合 &lt;code&gt;GLOBAL_STEP&lt;/code&gt; 或名称为 &lt;code&gt;global_step:0&lt;/code&gt; 中找到它。</target>
        </trans-unit>
        <trans-unit id="1b54d047ac096c3ae7f021822844b86acfbb5227" translate="yes" xml:space="preserve">
          <source>The global step tensor.</source>
          <target state="translated">全局阶梯张量。</target>
        </trans-unit>
        <trans-unit id="95db374c08adfbc24c444a5e0edf15c6723034b8" translate="yes" xml:space="preserve">
          <source>The global step value.</source>
          <target state="translated">全局步骤值。</target>
        </trans-unit>
        <trans-unit id="27f92d2c600461e2b55ce1161093f706c000d648" translate="yes" xml:space="preserve">
          <source>The global step variable, or &lt;code&gt;None&lt;/code&gt; if none was found.</source>
          <target state="translated">全球步变，或 &lt;code&gt;None&lt;/code&gt; ，如果没有被发现。</target>
        </trans-unit>
        <trans-unit id="99d903697b9ca80a681aa088eea14a311d3cfb53" translate="yes" xml:space="preserve">
          <source>The goal of this op is to produce a new tensor with a subset of the elements from the &lt;code&gt;n&lt;/code&gt; dimensional &lt;code&gt;input&lt;/code&gt; tensor. The subset is chosen using a sequence of &lt;code&gt;m&lt;/code&gt; sparse range specifications encoded into the arguments of this function. Note, in some cases &lt;code&gt;m&lt;/code&gt; could be equal to &lt;code&gt;n&lt;/code&gt;, but this need not be the case. Each range specification entry can be one of the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b19676d8e2406a216d2d74b877270145ae7d383" translate="yes" xml:space="preserve">
          <source>The gradient &lt;code&gt;IndexedSlices&lt;/code&gt; to be applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2344c5579f4717a0862d524efae16729bc6ed70" translate="yes" xml:space="preserve">
          <source>The gradient computation of this operation will only take advantage of sparsity in the input gradient when that gradient comes from a Relu.</source>
          <target state="translated">该操作的梯度计算只有在输入梯度来自Relu时,才会利用该梯度的稀疏性。</target>
        </trans-unit>
        <trans-unit id="d051520aa4dd277f3ed0bb66ae2aa2ab1b266a18" translate="yes" xml:space="preserve">
          <source>The gradient computed for 'op_type' will then propagate zeros.</source>
          <target state="translated">为'op_type'计算的梯度将传播零。</target>
        </trans-unit>
        <trans-unit id="71b1d3537cf96813de8a96c3c5f5d393309ab752" translate="yes" xml:space="preserve">
          <source>The gradient expression can be analytically simplified to provide numerical stability:</source>
          <target state="translated">梯度表达式可以通过分析简化来提供数值稳定性。</target>
        </trans-unit>
        <trans-unit id="66f6394f68f095fb6407b72059c63e54607c1a7e" translate="yes" xml:space="preserve">
          <source>The gradient of SparseFillEmptyRows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ab3e3e9ec9dadb6bed29c4d9fadd240cfe53d58" translate="yes" xml:space="preserve">
          <source>The gradient of y with respect to x can be zero in two different ways: there could be no differentiable path in the graph connecting x to y (and so we can statically prove that the gradient is zero) or it could be that runtime values of tensors in a particular execution lead to a gradient of zero (say, if a relu unit happens to not be activated). To allow you to distinguish between these two cases you can choose what value gets returned for the gradient when there is no path in the graph from x to y:</source>
          <target state="translated">y 相对于 x 的梯度可能在两种情况下为零:在连接 x 和 y 的图中没有可微分的路径(因此我们可以静态地证明梯度为零),或者是在特定的执行中ensors 的运行时值导致梯度为零(例如,如果一个 relu 单元恰好没有被激活)。为了让你区分这两种情况,你可以选择当图中没有从x到y的路径时,梯度返回的值。</target>
        </trans-unit>
        <trans-unit id="e557b207c1bf0f24f7b6478ec86b6e18a701dea1" translate="yes" xml:space="preserve">
          <source>The gradient operator for the SparseAdd op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1aa83bb60002d17ea0a36a621a83f096102e24dd" translate="yes" xml:space="preserve">
          <source>The gradient operator for the SparseSlice op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="506e6c0e4b5d041a489d5af54d1312d2417b8fa8" translate="yes" xml:space="preserve">
          <source>The gradient tensor to be applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6537a20daecb5b5cdb196626f45c6602644de72" translate="yes" xml:space="preserve">
          <source>The gradients of SparseMatrixAdd outputs with respect to alpha and beta are not currently defined (TensorFlow will return zeros for these entries).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5c157361d6bbe7fc68fa055766a81dc3624c016" translate="yes" xml:space="preserve">
          <source>The graph described by the protocol buffer will be displayed by TensorBoard. Most users pass a graph in the constructor instead.</source>
          <target state="translated">协议缓冲区描述的图形将由TensorBoard显示。大多数用户在构造函数中传递一个图形来代替。</target>
        </trans-unit>
        <trans-unit id="cee27050675be79d589848fe27aab1e7b8f14449" translate="yes" xml:space="preserve">
          <source>The graph in which to create the global step tensor. If missing, use default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbdbb3541583ec055cc057fc7380e7b06e65a362" translate="yes" xml:space="preserve">
          <source>The graph is not frozen. input_arrays or output_arrays contains an invalid tensor name. input_shapes is not correctly defined when required</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="661d2d430bf12295ddf1be3a1e881f38bccfdb01" translate="yes" xml:space="preserve">
          <source>The graph is written as a text proto unless &lt;code&gt;as_text&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">除非 &lt;code&gt;as_text&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; ,否则该图将作为文本原型写入。</target>
        </trans-unit>
        <trans-unit id="ed620881b1cf97ec1349e99d3e7fd253aa216b39" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the &lt;code&gt;dtype&lt;/code&gt; of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in  auto_mixed_precision_lists.h:</source>
          <target state="translated">该图重写操作改变所述 &lt;code&gt;dtype&lt;/code&gt; 的某些操作的图中的从FLOAT32到float16。此重写操作包含或排除了几类操作。以下类别的Ops 在auto_mixed_precision_lists.h中的类 &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; 下的相应函数内定义：</target>
        </trans-unit>
        <trans-unit id="f8a95853ba686885563f0cb093070ca0be189fd7" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the &lt;code&gt;dtype&lt;/code&gt; of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h&quot;&gt; auto_mixed_precision_lists.h&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="392b7dd1d0b2ec49c8bc79fcfe637691fe3461a3" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the dtype of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h&quot;&gt; auto_mixed_precision_lists.h&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="186101c609f7e0b73c5beb88b3d3fda49788c5a2" translate="yes" xml:space="preserve">
          <source>The graph should be constructed so if one op runs with shared_name value &lt;code&gt;c&lt;/code&gt;, then &lt;code&gt;num_devices&lt;/code&gt; ops will run with shared_name value &lt;code&gt;c&lt;/code&gt;. Failure to do so will cause the graph execution to fail to complete.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54dd05e38efeb9304c2e7af28168698a594f9293" translate="yes" xml:space="preserve">
          <source>The graph should be constructed so that all inputs have a valid device assignment, and the op itself is assigned one of these devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4be0b8b705593560d211ca0abc094810b42f770" translate="yes" xml:space="preserve">
          <source>The graph should be constructed so that all ops connected to the output have a valid device assignment, and the op itself is assigned one of these devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae4960be0391bc0449f500287c2e9601d2d28fb9" translate="yes" xml:space="preserve">
          <source>The graph that was launched in this session.</source>
          <target state="translated">本届会议推出的图。</target>
        </trans-unit>
        <trans-unit id="40aa8e68a00de5dbe27aa7ae38408c5a0d4706a5" translate="yes" xml:space="preserve">
          <source>The graph to find the global step in. If missing, use default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff2ceded61c6685a839fd2d7a80fa7375d194758" translate="yes" xml:space="preserve">
          <source>The graph with quantize training done.</source>
          <target state="translated">做了量化训练的图。</target>
        </trans-unit>
        <trans-unit id="3e6f6623fe7498e3548d52e61a0b5aeb7212fa47" translate="yes" xml:space="preserve">
          <source>The graph-level random seed of this graph.</source>
          <target state="translated">本图的图级随机种子。</target>
        </trans-unit>
        <trans-unit id="b19682167ffcfe3c04ed8fb01a75a8aa799a4834" translate="yes" xml:space="preserve">
          <source>The ground truth output tensor, same dimensions as 'predictions'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d40415d775a65d5e9c240e06cfa7ef2938a3a8e" translate="yes" xml:space="preserve">
          <source>The ground truth output tensor, whose shape must match the shape of &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ce49e07066730c52addc7241cd12da10f5be42a" translate="yes" xml:space="preserve">
          <source>The ground truth output tensor. Its shape should match the shape of logits. The values of the tensor are expected to be 0.0 or 1.0. Internally the {0,1} labels are converted to {-1,1} when calculating the hinge loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e5ec338b593d91f4875e9143cbbc83aa6f393e3" translate="yes" xml:space="preserve">
          <source>The ground truth values, a &lt;code&gt;Tensor&lt;/code&gt; whose dimensions must match &lt;code&gt;predictions&lt;/code&gt;. Will be cast to &lt;code&gt;bool&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60096598c979dc6d254911e38f80ad100e27b230" translate="yes" xml:space="preserve">
          <source>The ground truth values, a &lt;code&gt;Tensor&lt;/code&gt; whose shape matches &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="605e115f8ae90c28fbc9ece17ff2e60055be11a5" translate="yes" xml:space="preserve">
          <source>The ground truth values, with the same dimensions as &lt;code&gt;y_pred&lt;/code&gt;. Will be cast to &lt;code&gt;bool&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52b0a2c7f13eb68767ea820eccfa44a1fa1d1417" translate="yes" xml:space="preserve">
          <source>The ground truth values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23fc95f30242886be69cc146eccbc44fbd3a9182" translate="yes" xml:space="preserve">
          <source>The ground truth values. &lt;code&gt;y_true&lt;/code&gt; values are expected to be -1 or 1. If binary (0 or 1) labels are provided we will convert them to -1 or 1. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59439dc5cc92da495265d90185dbcfa8d277e54f" translate="yes" xml:space="preserve">
          <source>The ground truth values. &lt;code&gt;y_true&lt;/code&gt; values are expected to be 0 or 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db4406cca6113b5fab1f1335e874fc3df16b4d0" translate="yes" xml:space="preserve">
          <source>The handle flow_in forces the execution of the gradient lookup to occur only after certain other operations have occurred. For example, when the forward TensorArray is dynamically sized, writes to this TensorArray may resize the object. The gradient TensorArray is statically sized based on the size of the forward TensorArray when this operation executes. Furthermore, the size of the forward TensorArray is frozen by this call. As a result, the flow is used to ensure that the call to generate the gradient TensorArray only happens after all writes are executed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="386f2f718150cc3d8ab94292f585fc5254536634" translate="yes" xml:space="preserve">
          <source>The hard sigmoid activation, defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ddc50d95cf25f219ea2579cde9bf22435bfdc02" translate="yes" xml:space="preserve">
          <source>The hard sigmoid activation:</source>
          <target state="translated">硬性的乙状腺激活。</target>
        </trans-unit>
        <trans-unit id="0f4987b71fd23d4d24937f4f99fea76affcae8b1" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process and will never change. However, it is not suitable for cryptography. This function may be used when CPU time is scarce and inputs are trusted or unimportant. There is a risk of adversaries constructing inputs that all hash to the same bucket. To prevent this problem, use a strong hash function with &lt;code&gt;tf.string_to_hash_bucket_strong&lt;/code&gt;.</source>
          <target state="translated">哈希函数取决于进程中字符串的内容，并且永远不会更改。但是，它不适用于密码学。当CPU时间不足并且输入是可信任的或不重要的时，可以使用此功能。对手可能会构建所有哈希都散列到同一存储桶的输入。为避免此问题，请对 &lt;code&gt;tf.string_to_hash_bucket_strong&lt;/code&gt; 使用强大的哈希函数。</target>
        </trans-unit>
        <trans-unit id="fd0bfc8db5880e8eee54fb3385531988b2ad4a55" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process.</source>
          <target state="translated">哈希函数对进程内的字符串内容是确定的。</target>
        </trans-unit>
        <trans-unit id="61f428a10a4305c850461ee00f387b0cacfe0ef7" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process. The hash function is a keyed hash function, where attribute &lt;code&gt;key&lt;/code&gt; defines the key of the hash function. &lt;code&gt;key&lt;/code&gt; is an array of 2 elements.</source>
          <target state="translated">哈希函数取决于进程中字符串的内容。哈希函数是键控哈希函数，其中属性 &lt;code&gt;key&lt;/code&gt; 定义哈希函数的键。 &lt;code&gt;key&lt;/code&gt; 是2个元素的数组。</target>
        </trans-unit>
        <trans-unit id="1e7a8b7c173f99d4be181a635239bd0a5322a9de" translate="yes" xml:space="preserve">
          <source>The hash function used for generating out-of-vocabulary buckets ID is Fingerprint64.</source>
          <target state="translated">用于生成词汇外桶ID的哈希函数是Fingerprint64。</target>
        </trans-unit>
        <trans-unit id="69a6e09f76ddf4e19a4f8311d3f8fdc0b3c24b22" translate="yes" xml:space="preserve">
          <source>The head can be used with a canned estimator. Example:</source>
          <target state="translated">头部可与罐装估计器配合使用。例如:</target>
        </trans-unit>
        <trans-unit id="d8faf861d99f75e3ed7e367680c294894cd4fcef" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, 1]&lt;/code&gt;.</source>
          <target state="translated">头部预计 &lt;code&gt;logits&lt;/code&gt; 具有形状 &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt; 。在许多应用程序中，形状为 &lt;code&gt;[batch_size, 1]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c11316cb9d31dc7288f1ee66c33f5379df0eac90" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;.</source>
          <target state="translated">头部预计 &lt;code&gt;logits&lt;/code&gt; 具有形状 &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt; 。在许多应用程序中，形状为 &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bfb83e6dd754125ed65384336314d4dfea48278d" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, n_classes]&lt;/code&gt;.</source>
          <target state="translated">头部预计 &lt;code&gt;logits&lt;/code&gt; 具有形状 &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt; 。在许多应用程序中，形状为 &lt;code&gt;[batch_size, n_classes]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0d067db23fc00d02a594d5d3f6689549c9f412c9" translate="yes" xml:space="preserve">
          <source>The higher the value, the more important the corresponding feature.</source>
          <target state="translated">该值越高,对应的特征越重要。</target>
        </trans-unit>
        <trans-unit id="8521813f904a22ffdfed697b68b5f435421da5d1" translate="yes" xml:space="preserve">
          <source>The hyperparameter dict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8f83801fea0c2b2d476a98f4924fa4ac4c7e365" translate="yes" xml:space="preserve">
          <source>The id to use for an entry with no features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4057b28d9bdcaa801a67add7d2746bf429a07212" translate="yes" xml:space="preserve">
          <source>The id to use for an entry with no features. Defaults to 0-vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec4887ee6136cea3e95782b65b373451d365f518" translate="yes" xml:space="preserve">
          <source>The ids and weights may be multi-dimensional. Embeddings are always aggregated along the last dimension.</source>
          <target state="translated">ID和权重可以是多维的。嵌入总是沿着最后一个维度汇总。</target>
        </trans-unit>
        <trans-unit id="2dedfa9fac99909c847ee188683a18acc13d4781" translate="yes" xml:space="preserve">
          <source>The image sizes must be at least 11x11 because of the filter size.</source>
          <target state="translated">由于滤镜尺寸的原因,图像尺寸必须至少为11x11。</target>
        </trans-unit>
        <trans-unit id="64a71045d71d24f6cb099b242b2b3b3524c6c175" translate="yes" xml:space="preserve">
          <source>The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c48ed1044647075aee18b6c60d833446c1e6e4e9" translate="yes" xml:space="preserve">
          <source>The images have the same number of channels as the input tensor. For float input, the values are normalized one image at a time to fit in the range &lt;code&gt;[0, 255]&lt;/code&gt;. &lt;code&gt;uint8&lt;/code&gt; values are unchanged. The op uses two different normalization algorithms:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7512c5f22af2e468e091d738afee317bd6f3ab0c" translate="yes" xml:space="preserve">
          <source>The implementation is based on</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d3ec374ef70a5b15f88b06660be75d304545cf4" translate="yes" xml:space="preserve">
          <source>The implementation is based on: http://arxiv.org/abs/1409.2329.</source>
          <target state="translated">实施依据:http://arxiv.org/abs/1409.2329。</target>
        </trans-unit>
        <trans-unit id="4ceeee7cb755fec502e82f78579a1a2aeacda20b" translate="yes" xml:space="preserve">
          <source>The implementation of reduce of &lt;code&gt;per_replica_value&lt;/code&gt; to &lt;code&gt;destinations&lt;/code&gt;.</source>
          <target state="translated">将 &lt;code&gt;per_replica_value&lt;/code&gt; 减少至 &lt;code&gt;destinations&lt;/code&gt; 的实现。</target>
        </trans-unit>
        <trans-unit id="a45943ff8ffbe5eb14bb769ef477b63bf1e6634b" translate="yes" xml:space="preserve">
          <source>The implementation of this layer is based on the following paper: &lt;a href=&quot;https://people.eecs.berkeley.edu/%7Ebrecht/papers/07.rah.rec.nips.pdf&quot;&gt;&quot;Random Features for Large-Scale Kernel Machines&quot;&lt;/a&gt; by Ali Rahimi and Ben Recht.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bf2a5f575ee57fc6179092cf074536b99352e2c" translate="yes" xml:space="preserve">
          <source>The index &lt;code&gt;Tensor&lt;/code&gt;. Must be one of the following types: &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;int64&lt;/code&gt;. Must be in range &lt;code&gt;[0, params.shape[axis])&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39a73acc3a718d665ade71e6fcdb4d6f64ce1525" translate="yes" xml:space="preserve">
          <source>The index of the closest cluster center for each input point.</source>
          <target state="translated">每个输入点最近的簇中心的指数。</target>
        </trans-unit>
        <trans-unit id="bea3fce0b788c98ad4fd4961601d66fd0a86dd08" translate="yes" xml:space="preserve">
          <source>The index of this tensor in the outputs of its &lt;code&gt;Operation&lt;/code&gt;.</source>
          <target state="translated">该张量在其 &lt;code&gt;Operation&lt;/code&gt; 输出中的索引。</target>
        </trans-unit>
        <trans-unit id="14e09cd196d124b973e167954c771249f4762ea9" translate="yes" xml:space="preserve">
          <source>The indicator function</source>
          <target state="translated">指标功能</target>
        </trans-unit>
        <trans-unit id="e479f7d6722440bc7a24c4b0e9bd9fc43faf862a" translate="yes" xml:space="preserve">
          <source>The indices in &lt;code&gt;argmax&lt;/code&gt; are flattened, so that a maximum value at position &lt;code&gt;[b, y, x, c]&lt;/code&gt; becomes flattened index: &lt;code&gt;(y * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is False; &lt;code&gt;((b * height + y) * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is True.</source>
          <target state="translated">&lt;code&gt;argmax&lt;/code&gt; 中的索引被展平，因此如果 &lt;code&gt;include_batch_in_index&lt;/code&gt; 为False，则 &lt;code&gt;[b, y, x, c]&lt;/code&gt; 处的最大值变为展平的索引： &lt;code&gt;(y * width + x) * channels + c&lt;/code&gt; 。 &lt;code&gt;((b * height + y) * width + x) * channels + c&lt;/code&gt; 如果 &lt;code&gt;include_batch_in_index&lt;/code&gt; 为True）。</target>
        </trans-unit>
        <trans-unit id="aded17676aa9e31637aa4cd1d72c2f01005a52db" translate="yes" xml:space="preserve">
          <source>The indices of &lt;code&gt;values&lt;/code&gt; within the last dimension of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c8ef3b2e283d0175df2945495378ccedf137327" translate="yes" xml:space="preserve">
          <source>The indices of any input &lt;code&gt;SparseTensor&lt;/code&gt; are assumed ordered in standard lexicographic order. If this is not the case, before this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="translated">假定任何输入 &lt;code&gt;SparseTensor&lt;/code&gt; 的索引都按标准词典顺序排序。如果不是这种情况，请在此步骤之前运行 &lt;code&gt;SparseReorder&lt;/code&gt; 以恢复索引排序。</target>
        </trans-unit>
        <trans-unit id="b80ce2ebdd8a066053015d24d2b36c5006bb3c4b" translate="yes" xml:space="preserve">
          <source>The indices of non-zero values in the represented dense tensor.</source>
          <target state="translated">所代表的密张量中的非零值的指数。</target>
        </trans-unit>
        <trans-unit id="6678184e53cf5eab61e8f12ffd050f2da0981541" translate="yes" xml:space="preserve">
          <source>The indices returned are always in &lt;code&gt;[0, height) x [0, width)&lt;/code&gt; before flattening, even if padding is involved and the mathematically correct answer is outside (either negative or too large). This is a bug, but fixing it is difficult to do in a safe backwards compatible way, especially due to flattening.</source>
          <target state="translated">即使平铺涉及并且数学上正确的答案在外部（负数或太大 &lt;code&gt;[0, height) x [0, width)&lt;/code&gt; 在展平之前，返回的索引始终为[0，高度）x [0，宽度）。这是一个错误，但是修复该问题很难以安全的向后兼容方式进行，尤其是由于展平。</target>
        </trans-unit>
        <trans-unit id="308dc80a122084288a0ffca0b6ff7c164285d050" translate="yes" xml:space="preserve">
          <source>The indices to be used in the operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="982eccddab4c7cb8698248ade435084245e7ba3a" translate="yes" xml:space="preserve">
          <source>The inferred shape of a tensor is used to provide shape information without having to launch the graph in a session. This can be used for debugging, and providing early error messages. For example:</source>
          <target state="translated">张量的推断形状用于提供形状信息,而无需在会话中启动图形。这可以用于调试,并提供早期错误信息。例如</target>
        </trans-unit>
        <trans-unit id="d0cd21ff5f1c8bdcbdb1615eade35bd02cd426a1" translate="yes" xml:space="preserve">
          <source>The initial value for every thread's stack is set to the current value of the stack when &lt;code&gt;switch_to_thread_local()&lt;/code&gt; was first called.</source>
          <target state="translated">首次调用 &lt;code&gt;switch_to_thread_local()&lt;/code&gt; 时，每个线程堆栈的初始值均设置为堆栈的当前值。</target>
        </trans-unit>
        <trans-unit id="1520071416fcbbf59fdfe9d1fb1a38e0c5b7ec1a" translate="yes" xml:space="preserve">
          <source>The initializer operation for this variable.</source>
          <target state="translated">此变量的初始化操作。</target>
        </trans-unit>
        <trans-unit id="5fe0073bfbc54ff4aabd7ab72b5b3609d630078b" translate="yes" xml:space="preserve">
          <source>The inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT2D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">假定 &lt;code&gt;input&lt;/code&gt; 的最里面的2维是 &lt;code&gt;RFFT2D&lt;/code&gt; 的结果：最里面的维包含实值信号DFT 的 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 唯一分量。如果未提供 &lt;code&gt;fft_length&lt;/code&gt; ，则根据 &lt;code&gt;input&lt;/code&gt; 的最里面2个维的大小来计算。如果用于计算 &lt;code&gt;input&lt;/code&gt; 的FFT长度为奇数，则应提供该长度，因为无法正确推断。</target>
        </trans-unit>
        <trans-unit id="577a2328b01f8435a1e76dd0c500fccff4c87199" translate="yes" xml:space="preserve">
          <source>The inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT3D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 的最里面的3个维度被假定为 &lt;code&gt;RFFT3D&lt;/code&gt; 的结果：最里面的维度包含 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 个实值信号DFT的唯一分量。如果未提供 &lt;code&gt;fft_length&lt;/code&gt; ，则根据 &lt;code&gt;input&lt;/code&gt; 的最里面3个维度的大小来计算。如果用于计算 &lt;code&gt;input&lt;/code&gt; 的FFT长度为奇数，则应提供该长度，因为无法正确推断。</target>
        </trans-unit>
        <trans-unit id="66227bf2a70d8c8a13c900791ef88cd485b7b62a" translate="yes" xml:space="preserve">
          <source>The inner-most dimension of &lt;code&gt;input&lt;/code&gt; is assumed to be the result of &lt;code&gt;RFFT&lt;/code&gt;: the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most dimension of &lt;code&gt;input&lt;/code&gt; (&lt;code&gt;fft_length = 2 * (inner - 1)&lt;/code&gt;). If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 的最内层尺寸假定为 &lt;code&gt;RFFT&lt;/code&gt; 的结果：实值信号DFT 的 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 唯一分量。如果未提供 &lt;code&gt;fft_length&lt;/code&gt; ，则根据 &lt;code&gt;input&lt;/code&gt; 的最内层尺寸（ &lt;code&gt;fft_length = 2 * (inner - 1)&lt;/code&gt; ）进行计算。如果用于计算 &lt;code&gt;input&lt;/code&gt; 的FFT长度为奇数，则应提供该长度，因为无法正确推断。</target>
        </trans-unit>
        <trans-unit id="bb19a900483721ea4e289126af04d4611c3ccdec" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; array for this ragged tensor value.</source>
          <target state="translated">此参差不齐的张量值的最里面的 &lt;code&gt;values&lt;/code&gt; 数组。</target>
        </trans-unit>
        <trans-unit id="be345c7ea127005969c68124a7827e30c5e6f496" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; tensor for this ragged tensor.</source>
          <target state="translated">此参差不齐的张量的最里面的 &lt;code&gt;values&lt;/code&gt; 张量。</target>
        </trans-unit>
        <trans-unit id="8b90c8353eaabcd1c4389d292135b80ad60f5db5" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or &lt;code&gt;(P-K)&lt;/code&gt;-dimensional slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f25a7f282e145204d03b73aafeaa7a9ae16b013a" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of &lt;code&gt;ref&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 的最内部维度（长度为 &lt;code&gt;K&lt;/code&gt; ）对应于沿着 &lt;code&gt;ref&lt;/code&gt; 的第 &lt;code&gt;K&lt;/code&gt; 个维度元素（如果 &lt;code&gt;K = P&lt;/code&gt; ）或切片（如果 &lt;code&gt;K &amp;lt; P&lt;/code&gt; ）的索引。</target>
        </trans-unit>
        <trans-unit id="5e89d3b63e4cb6ebffdeb167da39f2e0f1f1c9d2" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of self.</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 的最内部维度（长度为 &lt;code&gt;K&lt;/code&gt; ）对应于自身第 &lt;code&gt;K&lt;/code&gt; 个维度上元素（如果 &lt;code&gt;K = P&lt;/code&gt; ）或切片（如果 &lt;code&gt;K &amp;lt; P&lt;/code&gt; ）的索引。</target>
        </trans-unit>
        <trans-unit id="9d4e204148af56a0113e634b28635c0d262a9319" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; is represented via the tuple of inputs (&lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, &lt;code&gt;dense_shape&lt;/code&gt;). The output &lt;code&gt;SparseTensor&lt;/code&gt; has the same &lt;code&gt;dense_shape&lt;/code&gt; but with indices &lt;code&gt;output_indices&lt;/code&gt; and values &lt;code&gt;output_values&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e7a91084b5b310e293a78ea32ab3d511383ccff" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; must be in row-major order.</source>
          <target state="translated">输入 &lt;code&gt;SparseTensor&lt;/code&gt; 必须按行顺序排列。</target>
        </trans-unit>
        <trans-unit id="369bf999e77085bb3dbcbb8c678bff357cac4ab0" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; must have rank &lt;code&gt;R&lt;/code&gt; greater than 1, and the first dimension is treated as the minibatch dimension. Elements of the &lt;code&gt;SparseTensor&lt;/code&gt; must be sorted in increasing order of this first dimension. The stored &lt;code&gt;SparseTensor&lt;/code&gt; objects pointed to by each row of the output &lt;code&gt;sparse_handles&lt;/code&gt; will have rank &lt;code&gt;R-1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="559dc2e144980c6b2098537801cec29d9fedba3c" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, after this step run &lt;a href=&quot;../sparse/reorder&quot;&gt;&lt;code&gt;sparse.reorder&lt;/code&gt;&lt;/a&gt; to restore index ordering.</source>
          <target state="translated">假定输入 &lt;code&gt;SparseTensor&lt;/code&gt; 对象的索引按标准词典顺序排序。如果不是这种情况，请在此步骤之后运行&lt;a href=&quot;../sparse/reorder&quot;&gt; &lt;code&gt;sparse.reorder&lt;/code&gt; &lt;/a&gt;以恢复索引顺序。</target>
        </trans-unit>
        <trans-unit id="e24902595b5bc86bf69741800b0bbd97af15f6bd" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, after this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbc5a9f23625ad51e259ef181b6a17732102c364" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, before this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76f573f126a945d7c18465e0384fd69d0f88a658" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; with &lt;code&gt;N&lt;/code&gt; non-empty elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f15580c2b04bab1dc867fb59f4c3b641b00ff298" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2c6d3c475df3ca344370164bdadaba77954ef82" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must be a string matrix of shape &lt;code&gt;[N x 3]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to packed outputs of &lt;code&gt;SerializeSparse&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56bbf31df5c3f0a722000a2eadd2da99c153bf4d" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must be a string matrix of shape &lt;code&gt;[N x 3]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to packed outputs of &lt;code&gt;serialize_sparse&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension).</source>
          <target state="translated">输入 &lt;code&gt;serialized_sparse&lt;/code&gt; 必须是形状为 &lt;code&gt;[N x 3]&lt;/code&gt; 的字符串矩阵，其中 &lt;code&gt;N&lt;/code&gt; 是最小批量大小，并且行对应于 &lt;code&gt;serialize_sparse&lt;/code&gt; 的打包输出。原始 &lt;code&gt;SparseTensor&lt;/code&gt; 对象的等级必须全部匹配。创建最终的 &lt;code&gt;SparseTensor&lt;/code&gt; 时，其等级比传入的 &lt;code&gt;SparseTensor&lt;/code&gt; 对象的等级高1 （它们已沿着新的行维度连接在一起）。</target>
        </trans-unit>
        <trans-unit id="1a26b3031ce9b2139c0f9a566a88efe37f0d9f15" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must have the shape &lt;code&gt;[?, ?, ..., ?, 3]&lt;/code&gt; where the last dimension stores serialized &lt;code&gt;SparseTensor&lt;/code&gt; objects and the other N dimensions (N &amp;gt;= 0) correspond to a batch. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, its rank is the rank of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects plus N; the sparse tensors have been concatenated along new dimensions, one for each batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0acda681393d7c0ea437e5f7eb4637e2f5dc3c0f" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;sparse_handles&lt;/code&gt; must be an &lt;code&gt;int64&lt;/code&gt; matrix of shape &lt;code&gt;[N, 1]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to the output handles of &lt;code&gt;AddSparseToTensorsMap&lt;/code&gt; or &lt;code&gt;AddManySparseToTensorsMap&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects that went into the given input ops must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension on the left).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6797d5a30fe0809d6c99b3fe7233e4388f788d3d" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;tags&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt; must have the same shape. The generated summary has a summary value for each tag-value pair in &lt;code&gt;tags&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d39dc101c55542dec858072079860af67df42d8f" translate="yes" xml:space="preserve">
          <source>The input can be supplied in various formats: &lt;code&gt;matrix&lt;/code&gt;, &lt;code&gt;sequence&lt;/code&gt; and &lt;code&gt;compact&lt;/code&gt;, specified by the &lt;code&gt;diagonals_format&lt;/code&gt; arg.</source>
          <target state="translated">输入可以采用多种格式提供： &lt;code&gt;matrix&lt;/code&gt; ， &lt;code&gt;sequence&lt;/code&gt; 和 &lt;code&gt;compact&lt;/code&gt; ，由 &lt;code&gt;diagonals_format&lt;/code&gt; 格式arg 指定。</target>
        </trans-unit>
        <trans-unit id="2d48efdb90f50c04e629b26b90744cae3caa313b" translate="yes" xml:space="preserve">
          <source>The input cannot be converted to a tensor, or the specified axis cannot be squeezed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a3aea890ab7c25d251475a5c0c175df4fead28f" translate="yes" xml:space="preserve">
          <source>The input data can be padded on both the start and end of the sequence, if desired, using the &lt;code&gt;pad_values&lt;/code&gt; argument. If set, &lt;code&gt;pad_values&lt;/code&gt; should contain either a tuple of strings or a single string; the 0th element of the tuple will be used to pad the left side of the sequence and the 1st element of the tuple will be used to pad the right side of the sequence. The &lt;code&gt;padding_width&lt;/code&gt; arg controls how many padding values are added to each side; it defaults to &lt;code&gt;ngram_width-1&lt;/code&gt;.</source>
          <target state="translated">如果需要，可以使用 &lt;code&gt;pad_values&lt;/code&gt; 参数在序列的开头和结尾处填充输入数据。如果设置， &lt;code&gt;pad_values&lt;/code&gt; 应该包含一个字符串元组或一个字符串。元组的第0个元素将用于填充序列的左侧，而元组的第1个元素将用于填充序列的右侧。所述 &lt;code&gt;padding_width&lt;/code&gt; ARG控制许多填充值是如何加入到每个侧; 它默认为 &lt;code&gt;ngram_width-1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="04197da47b84221763ac70ad3af1dee562c7d6bb" translate="yes" xml:space="preserve">
          <source>The input function is not a valid one.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3483a88e5028197c2c707cc3c8c51e5ba5c5cc43" translate="yes" xml:space="preserve">
          <source>The input has to be invertible.</source>
          <target state="translated">输入必须是可逆的。</target>
        </trans-unit>
        <trans-unit id="6cb547f4554af98d950886c485fb31114efae486" translate="yes" xml:space="preserve">
          <source>The input has to be symmetric and positive definite. Only the lower-triangular part of the input will be used for this operation. The upper-triangular part will not be read.</source>
          <target state="translated">输入必须是对称的和正定的。只有输入的下三角部分才会被用于此操作,上三角部分不会被读取。上三角部分将不被读取。</target>
        </trans-unit>
        <trans-unit id="d751c1504cdeea4fe2c77555b81110d615e4802e" translate="yes" xml:space="preserve">
          <source>The input image is considered in the RGB colorspace. Conceptually, the RGB colors are first mapped into HSV. A delta is then applied all the hue values, and then remapped back to RGB colorspace.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a0a6cfeac0c5da1f89ebf29a1c3a1974b9f86fa" translate="yes" xml:space="preserve">
          <source>The input image is considered in the RGB colorspace. Conceptually, the RGB colors are first mapped into HSV. A scale is then applied all the saturation values, and then remapped back to RGB colorspace.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ab6f7a1383accb84e03cfc01fbf2de71cc3ce58" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The output is a string tensor of the same shape containing the transcoded strings. Output strings are always valid unicode. If the input contains invalid encoding positions, the &lt;code&gt;errors&lt;/code&gt; attribute sets the policy for how to deal with them. If the default error-handling policy is used, invalid formatting will be substituted in the output by the &lt;code&gt;replacement_char&lt;/code&gt;. If the errors policy is to &lt;code&gt;ignore&lt;/code&gt;, any invalid encoding positions in the input are skipped and not included in the output. If it set to &lt;code&gt;strict&lt;/code&gt; then any invalid formatting will result in an InvalidArgument error.</source>
          <target state="translated">输入是任何形状的字符串张量。输出是包含转码字符串的相同形状的字符串张量。输出字符串始终是有效的unicode。如果输入包含无效的编码位置，则 &lt;code&gt;errors&lt;/code&gt; 属性将设置如何处理它们的策略。如果使用默认的错误处理策略，则无效的格式将在输出中 &lt;code&gt;replacement_char&lt;/code&gt; 为replace_char。如果错误策略要 &lt;code&gt;ignore&lt;/code&gt; ，则将跳过输入中的任何无效编码位置，并且不将其包括在输出中。如果将其设置为 &lt;code&gt;strict&lt;/code&gt; ,则任何无效的格式都会导致InvalidArgument错误。</target>
        </trans-unit>
        <trans-unit id="f41ed33e18d35e0df944af43170682bbfbe88dab" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The pattern is a scalar string tensor which is applied to every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.</source>
          <target state="translated">输入是一个任意形状的字符串张量。模式是一个标量字符串张量,应用于输入张量的每个元素。输出张量的布尔值(True或False)表示输入是否符合所提供的regex模式。</target>
        </trans-unit>
        <trans-unit id="f8ccdd5a5cb3af5106d6fe3c083e5d2def727b0e" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The pattern is the regular expression to be matched with every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ef8ae1c6e33447e6640de2cbf18a9aca428cda0" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices, with the same constraints as the single matrix SelfAdjointEig.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a49b12f6890eee0fa5006296181dd36a3c0eae12" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices.</source>
          <target state="translated">输入是一个形状为 &lt;code&gt;[..., M, M]&lt;/code&gt; 的张量，其最里面的两个维构成正方形矩阵。</target>
        </trans-unit>
        <trans-unit id="4a95ccad7688f828b4538240858954215386b157" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor containing the determinants for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">输入是一个形状为 &lt;code&gt;[..., M, M]&lt;/code&gt; 的张量，其最里面的两个维构成正方形矩阵。输出是一个张量，其中包含所有输入子矩阵 &lt;code&gt;[..., :, :]&lt;/code&gt; 的行列式。</target>
        </trans-unit>
        <trans-unit id="bb52980da5474b532e1e714b4de037ffa27b4127" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the exponential for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">输入是一个形状为 &lt;code&gt;[..., M, M]&lt;/code&gt; 的张量，其最里面的两个维构成正方形矩阵。输出是与输入相同形状的张量，其中包含所有输入子矩阵 &lt;code&gt;[..., :, :]&lt;/code&gt; 的指数。</target>
        </trans-unit>
        <trans-unit id="72c07ff69dfab5a23cee03f8eae86a2093c70b45" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the inverse for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">输入是一个形状为 &lt;code&gt;[..., M, M]&lt;/code&gt; 的张量，其最里面的两个维构成正方形矩阵。输出是具有与输入相同形状的张量，其中包含所有输入子矩阵 &lt;code&gt;[..., :, :]&lt;/code&gt; 的逆。</target>
        </trans-unit>
        <trans-unit id="f84ae4c58a555dd2a241282a825d52ffb2a896e6" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the matrix square root for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">输入是一个形状为 &lt;code&gt;[..., M, M]&lt;/code&gt; 的张量，其最里面的两个维构成正方形矩阵。输出是与所有输入子矩阵 &lt;code&gt;[..., :, :]&lt;/code&gt; 都包含矩阵平方根的输入具有相同形状的张量。</target>
        </trans-unit>
        <trans-unit id="a47976575bd700d1896c1a9ad76ef8970d05df43" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[N, M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The outputs are two tensors containing the signs and absolute values of the log determinants for all N input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt; such that the determinant = sign&lt;em&gt;exp(log_abs_determinant). The log_abs_determinant is computed as det(P)&lt;/em&gt;sum(log(diag(LU))) where LU is the LU decomposition of the input and P is the corresponding permutation matrix.</source>
          <target state="translated">输入是形状为 &lt;code&gt;[N, M, M]&lt;/code&gt; 的张量，其最里面的两个维构成正方形矩阵。输出是两个张量，包含所有N个输入子矩阵 &lt;code&gt;[..., :, :]&lt;/code&gt; 的对数行列式的符号和绝对值，使得行列式=符号&lt;em&gt;exp（log_abs_determinant）。log_abs_determinant计算为det（P）&lt;/em&gt; sum（log（diag（&lt;em&gt;LUg&lt;/em&gt;））），其中LU是输入的LU分解，P是相应的置换矩阵。</target>
        </trans-unit>
        <trans-unit id="16509370e9a14e359dbc8b8062b8734116aafda6" translate="yes" xml:space="preserve">
          <source>The input matrix should be invertible. If the input matrix is real, it should have no eigenvalues which are real and negative (pairs of complex conjugate eigenvalues are allowed).</source>
          <target state="translated">输入矩阵应是可逆的。如果输入矩阵是实数,它应该没有实数和负数的特征值(允许有一对复数共轭特征值)。</target>
        </trans-unit>
        <trans-unit id="b4fb5738c7b407c21bcad2cacc1ef5ec4dff9b6d" translate="yes" xml:space="preserve">
          <source>The input must be at least a matrix.</source>
          <target state="translated">输入必须至少是一个矩阵。</target>
        </trans-unit>
        <trans-unit id="3c4f7bbe843d34cb236ccedebe4df570c214e3da" translate="yes" xml:space="preserve">
          <source>The input pipeline checkpoint may be large, if there are large shuffle or prefetch buffers for instance, and may bloat the checkpoint size.</source>
          <target state="translated">输入管道检查点可能很大,比如有大的洗牌或预取缓冲区,可能会使检查点大小膨胀。</target>
        </trans-unit>
        <trans-unit id="deff7be907795c0056b42668a7693ec0a82247dc" translate="yes" xml:space="preserve">
          <source>The input pixels values are scaled between 0 and 1 and each channel is normalized with respect to the ImageNet dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1771ed960e007f08f6b91d9fc4bf87f366612095" translate="yes" xml:space="preserve">
          <source>The input rank &lt;code&gt;R&lt;/code&gt;&lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bf2cfde9a379c9cc0a2626ec6eaa414e577c963" translate="yes" xml:space="preserve">
          <source>The input samples are processed batch by batch.</source>
          <target state="translated">对输入的样品进行逐批处理。</target>
        </trans-unit>
        <trans-unit id="db9e617ad287d3e54cdcc5d77f3a84dc0ecefefc" translate="yes" xml:space="preserve">
          <source>The input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.</source>
          <target state="translated">输入的数据应该至少是三维的,索引一的维度将被认为是时间维度。</target>
        </trans-unit>
        <trans-unit id="4a7245281a652bfbac8628bc44c29674340d8332" translate="yes" xml:space="preserve">
          <source>The input signature of &lt;code&gt;map_func&lt;/code&gt; is determined by the structure of each element in this dataset.</source>
          <target state="translated">&lt;code&gt;map_func&lt;/code&gt; 的输入签名由该数据集中每个元素的结构确定。</target>
        </trans-unit>
        <trans-unit id="d2a30b4754eaaadad621a00ac65ed1446d4c24f6" translate="yes" xml:space="preserve">
          <source>The input sparse matrix and the fill-in reducing permutation &lt;code&gt;permutation&lt;/code&gt; must have compatible shapes. If the sparse matrix has rank 3; with the batch dimension &lt;code&gt;B&lt;/code&gt;, then the &lt;code&gt;permutation&lt;/code&gt; must be of rank 2; with the same batch dimension &lt;code&gt;B&lt;/code&gt;. There is no support for broadcasting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42875650119a49af17e9b194c7f7044943508dd9" translate="yes" xml:space="preserve">
          <source>The input sparse matrix may have rank 2 or rank 3. The output Tensor, representing would then have rank 1 or 2 respectively, with the same batch shape as the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a4202e509f04a4e2e240929b7033cbd28325042" translate="yes" xml:space="preserve">
          <source>The input tensor (potentially converted to a &lt;code&gt;Tensor&lt;/code&gt;).</source>
          <target state="translated">输入张量（可能转换为 &lt;code&gt;Tensor&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="f1339cf26956739f44025e7d445e29017a72d735" translate="yes" xml:space="preserve">
          <source>The input tensor can now be quantized by clipping values to the range &lt;code&gt;min_range&lt;/code&gt; to &lt;code&gt;max_range&lt;/code&gt;, then multiplying by scale_factor as follows:</source>
          <target state="translated">现在可以通过将值裁剪到 &lt;code&gt;min_range&lt;/code&gt; 到 &lt;code&gt;max_range&lt;/code&gt; 范围内，然后按比例乘以scale_factor来量化输入张量：</target>
        </trans-unit>
        <trans-unit id="d3b2781a0d53ff2a6f99fd5cbdcd70a0377dfcba" translate="yes" xml:space="preserve">
          <source>The input tensor whose shape will be used to generate dropout mask.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de4692e0721f2fcc2ac3eb25677f89cdae882775" translate="yes" xml:space="preserve">
          <source>The input tensor's height and width must be divisible by block_size.</source>
          <target state="translated">输入张量的高度和宽度必须可以除以block_size。</target>
        </trans-unit>
        <trans-unit id="549cec4325e7bdb0f314e4738e2091614fdd06cc" translate="yes" xml:space="preserve">
          <source>The input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bd030040de18dc6a388054f2ae79e10c262d194" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;real&lt;/code&gt; and &lt;code&gt;imag&lt;/code&gt; must have the same shape.</source>
          <target state="translated">输入张量 &lt;code&gt;real&lt;/code&gt; 和 &lt;code&gt;imag&lt;/code&gt; 必须具有相同的形状。</target>
        </trans-unit>
        <trans-unit id="aa6b1cb251ad12bc98e4df6e1fe21cc0d8438940" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;starts&lt;/code&gt;, &lt;code&gt;limits&lt;/code&gt;, and &lt;code&gt;deltas&lt;/code&gt; may be scalars or vectors. The vector inputs must all have the same size. Scalar inputs are broadcast to match the size of the vector inputs.</source>
          <target state="translated">输入张量 &lt;code&gt;starts&lt;/code&gt; ， &lt;code&gt;limits&lt;/code&gt; ，并且 &lt;code&gt;deltas&lt;/code&gt; 可以是标量或向量。向量输入必须全部具有相同的大小。广播标量输入以匹配矢量输入的大小。</target>
        </trans-unit>
        <trans-unit id="b8ff1df3e5bbb4197a5fcf6ebfa2ea96c023b0d7" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are 2-D or higher with shape &lt;code&gt;[..., r_x, c_x]&lt;/code&gt; and &lt;code&gt;[..., r_y, c_y]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff60fbd9db5f41897771ca434c8e26b7b8f91862" translate="yes" xml:space="preserve">
          <source>The input tensors are all required to have size 1 in the first dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d661f6ceb58229bddc491bc4e8ad81a91a05cfb1" translate="yes" xml:space="preserve">
          <source>The input tensors must have &lt;code&gt;rank=2&lt;/code&gt;, and must all have the same number of rows. The result is a &lt;code&gt;RaggedTensor&lt;/code&gt; with the same number of rows as the inputs, where &lt;code&gt;result[row]&lt;/code&gt; contains a list of all combinations of values formed by taking a single value from each input's corresponding row (&lt;code&gt;inputs[i][row]&lt;/code&gt;). Values are combined by hashing together their fingerprints. E.g.:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f325df8aa80a521b9173906f05b6c3d477009cc" translate="yes" xml:space="preserve">
          <source>The input tensors must have &lt;code&gt;rank=2&lt;/code&gt;, and must all have the same number of rows. The result is a &lt;code&gt;RaggedTensor&lt;/code&gt; with the same number of rows as the inputs, where &lt;code&gt;result[row]&lt;/code&gt; contains a list of all combinations of values formed by taking a single value from each input's corresponding row (&lt;code&gt;inputs[i][row]&lt;/code&gt;). Values are combined by joining their strings with '&lt;em&gt;X&lt;/em&gt;'. E.g.:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc0e2ea8ed20f6c76d70887002fa098e766f9ed8" translate="yes" xml:space="preserve">
          <source>The input values in are the log-odds of the resulting probability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1846b54df868865021ca6028d9ca189f0c062b0" translate="yes" xml:space="preserve">
          <source>The input(s) of the model: a &lt;a href=&quot;input&quot;&gt;&lt;code&gt;keras.Input&lt;/code&gt;&lt;/a&gt; object or list of &lt;a href=&quot;input&quot;&gt;&lt;code&gt;keras.Input&lt;/code&gt;&lt;/a&gt; objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7b5b4e0f6e030ce553913f501525ac473f64915" translate="yes" xml:space="preserve">
          <source>The input, unmodified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d39bc5c493315c0c2bb73635f284f6d3773b3fe6" translate="yes" xml:space="preserve">
          <source>The inputs and arguments of these functions both use an instance of the class so they can have independent numbering.</source>
          <target state="translated">这些函数的输入和参数都使用一个类的实例,所以它们可以有独立的编号。</target>
        </trans-unit>
        <trans-unit id="d0798e60c9a60a309c2780811ed22bf523e44034" translate="yes" xml:space="preserve">
          <source>The inputs are quantized tensors where the lowest value represents the real number of the associated minimum, and the highest represents the maximum. This means that you can only interpret the quantized output in the same way, by taking the returned minimum and maximum values into account.</source>
          <target state="translated">输入是量化的时值,其中最低值代表相关最小值的实数,最高值代表最大值。这意味着你只能以同样的方式解释量化输出,将返回的最小值和最大值考虑在内。</target>
        </trans-unit>
        <trans-unit id="7d5491d4d1fe59ff0b726933e4fd0f37e6b34849" translate="yes" xml:space="preserve">
          <source>The inputs are variable-length sequences provided by SparseTensors (hypothesis_indices, hypothesis_values, hypothesis_shape) and (truth_indices, truth_values, truth_shape).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b2d715db408ed4c68b80c58649420f90265275e" translate="yes" xml:space="preserve">
          <source>The inputs are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5487c5634d45a531fcdfa8c1d83dcdf3f48a363d" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2314b3685b224ccc966442df5d3a609d47564351" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt;. Then do relu activation to get non-negative result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e61d8b21ec9285bc0e40af26ba2ce90301743e71" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt;. Then do relu activation to get non-negative result. Then do requantize operation to get final uint8 result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd731653b58f2631c265c170d9e7475175fa31c7" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; (after being transposed if transpose_a is true) must match the outer dimension of &quot;b&quot; (after being transposed if transposed_b is true).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af76f45e776e3f0a5b635d397e36c82661d856e8" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; must match the outer dimension of &quot;b&quot;. Both &quot;a&quot; and &quot;b&quot; must be &lt;code&gt;Tensor&lt;/code&gt;s not &lt;code&gt;SparseTensor&lt;/code&gt;s. This op is optimized for the case where at least one of &quot;a&quot; or &quot;b&quot; is sparse, in the sense that they have a large proportion of zero values. The breakeven for using this versus a dense matrix multiply on one platform was 30% zero values in the sparse matrix.</source>
          <target state="translated">输入必须是二维矩阵，内部尺寸&amp;ldquo; a&amp;rdquo;必须与外部尺寸&amp;ldquo; b&amp;rdquo;匹配。&amp;ldquo; a&amp;rdquo;和&amp;ldquo; b&amp;rdquo;都必须是 &lt;code&gt;Tensor&lt;/code&gt; ,而不是 &lt;code&gt;SparseTensor&lt;/code&gt; 。从&amp;ldquo; a&amp;rdquo;或&amp;ldquo; b&amp;rdquo;中至少一个稀疏的意义上说，该运算是优化的，因为它们具有很大比例的零值。在一个平台上使用此矩阵与稠密矩阵相乘的盈亏平衡点是稀疏矩阵中的30％零值。</target>
        </trans-unit>
        <trans-unit id="ff06fbddb811e99d2772aad28bf55f55c80fc380" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ec73a355bd346786f44656782393b17ea3017cb" translate="yes" xml:space="preserve">
          <source>The inputs must have compatible shapes. That is, the inner dimension of &lt;code&gt;a&lt;/code&gt; must be equal to the outer dimension of &lt;code&gt;b&lt;/code&gt;. This requirement is adjusted according to whether either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; is transposed or adjointed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="851dd7f69bc57652716eb3a5a344fc6b5525127d" translate="yes" xml:space="preserve">
          <source>The inputs must, following any transpositions, be tensors of rank &amp;gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</source>
          <target state="translated">在进行任何换位后，输入必须为等级&amp;gt; = 2的张量，其中内部2个维指定有效的矩阵乘法维，而任何其他外部维指定匹配的批次大小。</target>
        </trans-unit>
        <trans-unit id="2af5973c44cbbca03420397524238d5ac415d59c" translate="yes" xml:space="preserve">
          <source>The inputs pixel values are scaled between -1 and 1, sample-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea6567bbb82a2153b18593d35fddb52d49ff3e46" translate="yes" xml:space="preserve">
          <source>The inputs represent an N-D SparseTensor with logical shape &lt;code&gt;[..., B, C]&lt;/code&gt; (where &lt;code&gt;N &amp;gt;= 2&lt;/code&gt;), and with indices sorted in the canonical lexicographic order.</source>
          <target state="translated">输入表示一个具有逻辑形状 &lt;code&gt;[..., B, C]&lt;/code&gt; （其中 &lt;code&gt;N &amp;gt;= 2&lt;/code&gt; ）并且索引按规范词典顺序排序的ND SparseTensor 。</target>
        </trans-unit>
        <trans-unit id="a4f1d56f863e44297f61aff16d5b045b54f4c8aa" translate="yes" xml:space="preserve">
          <source>The integer ID value to return for out-of-vocabulary feature values, defaults to &lt;code&gt;-1&lt;/code&gt;. This can not be specified with a positive &lt;code&gt;num_oov_buckets&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="786b18b1428c9b9d0c0ea9b230ad273866de4e7c" translate="yes" xml:space="preserve">
          <source>The integer error code that describes the error.</source>
          <target state="translated">描述错误的整数错误代码。</target>
        </trans-unit>
        <trans-unit id="1f081e7633128ce109e045c67ad35e5e5ed00d6f" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="translated">该库的目的是您可以以程式化的方式编写算法，并且该算法可用于各种不同的&lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;实现。每个后代将实施不同的策略以在多个设备/机器之间分配算法。此外，这些更改可以隐藏在特定的图层以及需要特殊处理才能在分布式设置中运行的其他库类内部，以便大多数用户的模型定义代码可以不变地运行。该&lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; API的工作充满渴望和图形执行相同的方式。</target>
        </trans-unit>
        <trans-unit id="88afca652283c5de09f863feb56ef262251ef585" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="translated">该库的目的是您可以以程式化的方式编写算法，并且该算法可用于各种不同的&lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;实现。每个后代将实施不同的策略以在多个设备/机器之间分配算法。此外，这些更改可以隐藏在特定的图层以及需要特殊处理才能在分布式设置中运行的其他库类内部，以便大多数用户的模型定义代码可以不变地运行。该&lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; API的工作充满渴望和图形执行相同的方式。</target>
        </trans-unit>
        <trans-unit id="bf691a6e4942a79a3eb610931eed1d4815c80c50" translate="yes" xml:space="preserve">
          <source>The internal state of the RNG.</source>
          <target state="translated">RNG的内部状态。</target>
        </trans-unit>
        <trans-unit id="f4e9fea1c0c7520b3774550dafc300a0edeccb05" translate="yes" xml:space="preserve">
          <source>The inverse of fftshift.</source>
          <target state="translated">fftshift的倒数。</target>
        </trans-unit>
        <trans-unit id="6f58aa3901c7e60d466c168f7dbe6f460db432cc" translate="yes" xml:space="preserve">
          <source>The iterator only checks for new checkpoints when control flow has been reverted to it. This means it can miss checkpoints if your code takes longer to run between iterations than &lt;code&gt;min_interval_secs&lt;/code&gt; or the interval at which new checkpoints are written.</source>
          <target state="translated">迭代器仅在控制流已还原到它时才检查新的检查点。这意味着如果您的代码在 &lt;code&gt;min_interval_secs&lt;/code&gt; 迭代之间花费的时间比min_interval_secs或写入新检查点的时间间隔长，则它可能会错过检查点。</target>
        </trans-unit>
        <trans-unit id="bbc287cd067fb3f315911c649ff5a7aa6eb20b54" translate="yes" xml:space="preserve">
          <source>The job (the XXX in TensorFlow device specification /job:XXX) that contains the TPU devices that will be initialized. If job=None it is assumed there is only one job in the TensorFlow flock, and an error will be returned if this assumption does not hold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7761a900373227a5908c2ab270802392dddf9229" translate="yes" xml:space="preserve">
          <source>The job (the XXX in TensorFlow device specification /job:XXX) that contains the TPU devices that will be shutdown. If job=None it is assumed there is only one job in the TensorFlow flock, and an error will be returned if this assumption does not hold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16441d46dfcb0fd71d29af5e06be782473ef7ef7" translate="yes" xml:space="preserve">
          <source>The job name under which the new server will be accessible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="751b0fbfa4aeea2c579ce7d09f30705a335965fb" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified by the &lt;code&gt;key_index&lt;/code&gt; and &lt;code&gt;value_index&lt;/code&gt;.</source>
          <target state="translated">从每一行获取的键和值内容由 &lt;code&gt;key_index&lt;/code&gt; 和 &lt;code&gt;value_index&lt;/code&gt; 指定。</target>
        </trans-unit>
        <trans-unit id="e732a302356fd06e3da95b03500ebf97f84d0506" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified either by the following, or a value &lt;code&gt;&amp;gt;=0&lt;/code&gt;.</source>
          <target state="translated">从每一行获取的键和值内容由以下内容指定，或者值 &lt;code&gt;&amp;gt;=0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c0771e36c5a66ef95bdba36fa510d228d752d2d4" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line.</source>
          <target state="translated">要从每条线上得到的关键和价值内容。</target>
        </trans-unit>
        <trans-unit id="b464317f2f49a3771499c8be27b73752b57cff0e" translate="yes" xml:space="preserve">
          <source>The key and value type of the table to initialize is given by &lt;code&gt;key_dtype&lt;/code&gt; and &lt;code&gt;value_dtype&lt;/code&gt;.</source>
          <target state="translated">要初始化的表的键和值类型由 &lt;code&gt;key_dtype&lt;/code&gt; 和 &lt;code&gt;value_dtype&lt;/code&gt; 给出。</target>
        </trans-unit>
        <trans-unit id="7f231eccba572c9745a56b810b3c3047e7ea0454" translate="yes" xml:space="preserve">
          <source>The key for the collection. For example, the &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68713242651f0ec86fa38fc63c0f68575067f7ec" translate="yes" xml:space="preserve">
          <source>The key for the collection. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f799300f7af4ad7bf22ac56cc9d8c592e154fb0" translate="yes" xml:space="preserve">
          <source>The key for the collections. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffb06b79cd9a7c754d2c0b3d48045fd9d3624a00" translate="yes" xml:space="preserve">
          <source>The keys for the collections to add to. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93ae0a77af7d45a8107b1bfa71735de24854f107" translate="yes" xml:space="preserve">
          <source>The keyword arguments that are passed on to &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c7afb2c0ad248ba222c168b5103cb8f08e6923f" translate="yes" xml:space="preserve">
          <source>The keyword arguments that are passed on to BaseLayer.&lt;strong&gt;init&lt;/strong&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="339c24317a151f1ccadbe2bc95f1998f249689f6" translate="yes" xml:space="preserve">
          <source>The keyword arguments that are passed on to BaseLayer.&lt;strong&gt;init&lt;/strong&gt;. Allowed keyword arguments include &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2cb43e5a33cda57c35ab173bdca64268dd6064f" translate="yes" xml:space="preserve">
          <source>The last &lt;code&gt;concentration&lt;/code&gt; dimension parametrizes a single Dirichlet-Multinomial distribution. When calling distribution functions (e.g., &lt;code&gt;dist.prob(counts)&lt;/code&gt;), &lt;code&gt;concentration&lt;/code&gt;, &lt;code&gt;total_count&lt;/code&gt; and &lt;code&gt;counts&lt;/code&gt; are broadcast to the same shape. The last dimension of &lt;code&gt;counts&lt;/code&gt; corresponds single Dirichlet-Multinomial distributions.</source>
          <target state="translated">最后一个 &lt;code&gt;concentration&lt;/code&gt; 维参数化单个Dirichlet-多项式分布。当调用分配函数（例如 &lt;code&gt;dist.prob(counts)&lt;/code&gt; ）时， &lt;code&gt;concentration&lt;/code&gt; ， &lt;code&gt;total_count&lt;/code&gt; 和 &lt;code&gt;counts&lt;/code&gt; 将广播为相同形状。 &lt;code&gt;counts&lt;/code&gt; 的最后一个维度对应于单个Dirichlet-多项式分布。</target>
        </trans-unit>
        <trans-unit id="78cc8d00f8e7491129a68b99d8285b81a0423488" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; can be at most the rank of &lt;code&gt;params&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 的最后一个维度最多可以是 &lt;code&gt;params&lt;/code&gt; 的等级：</target>
        </trans-unit>
        <trans-unit id="ecdf342100af669eb1e5196eae29b7087572c686" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to elements (if &lt;code&gt;indices.shape[-1] == params.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; params.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;params&lt;/code&gt;. The output tensor has shape</source>
          <target state="translated">的最后一维 &lt;code&gt;indices&lt;/code&gt; 对应于元件（如果 &lt;code&gt;indices.shape[-1] == params.rank&lt;/code&gt; ）或片（如果 &lt;code&gt;indices.shape[-1] &amp;lt; params.rank&lt;/code&gt; ）沿尺寸 &lt;code&gt;indices.shape[-1]&lt;/code&gt; 的 &lt;code&gt;params&lt;/code&gt; 。输出张量具有形状</target>
        </trans-unit>
        <trans-unit id="286ceed5a9e73c8174db8660f8e7395f9150777f" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to indices into elements (if &lt;code&gt;indices.shape[-1] = shape.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; shape.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;shape&lt;/code&gt;. &lt;code&gt;updates&lt;/code&gt; is a tensor with shape</source>
          <target state="translated">的最后一维 &lt;code&gt;indices&lt;/code&gt; 对应（如果到索引为元素 &lt;code&gt;indices.shape[-1] = shape.rank&lt;/code&gt; ）或片（如果 &lt;code&gt;indices.shape[-1] &amp;lt; shape.rank&lt;/code&gt; ）沿尺寸 &lt;code&gt;indices.shape[-1]&lt;/code&gt; 的 &lt;code&gt;shape&lt;/code&gt; 。 &lt;code&gt;updates&lt;/code&gt; 是具有形状的张量</target>
        </trans-unit>
        <trans-unit id="2bf929456df7864e36863c3aad01721261ffcbb9" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to indices into elements (if &lt;code&gt;indices.shape[-1] = tensor.shape.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; tensor.shape.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;tensor.shape&lt;/code&gt;. &lt;code&gt;updates&lt;/code&gt; is a tensor with shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1334749bed79f5a39ed1f5844527d62a1a905c7c" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;sp_input.indices&lt;/code&gt; is discarded and replaced with the values of &lt;code&gt;sp_input&lt;/code&gt;. If &lt;code&gt;sp_input.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt;, then &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt;, where</source>
          <target state="translated">&lt;code&gt;sp_input.indices&lt;/code&gt; 的最后一个维被丢弃，并替换为 &lt;code&gt;sp_input&lt;/code&gt; 的值。如果 &lt;code&gt;sp_input.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt; ，则 &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt; ，其中</target>
        </trans-unit>
        <trans-unit id="fbd03a9648fd276c59e057bf5a188513a3c7e179" translate="yes" xml:space="preserve">
          <source>The last three dimensions of input are expected to be [height, width, depth].</source>
          <target state="translated">输入的最后三个维度预计为[高度,宽度,深度]。</target>
        </trans-unit>
        <trans-unit id="d9e40b42f372ce30bcad2557b4fbb4971315076a" translate="yes" xml:space="preserve">
          <source>The layer to be wrapped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d8c5a256ceb0281a5abfd9ab601681d1b6839bc" translate="yes" xml:space="preserve">
          <source>The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function that uses a different behavior at train time and test time.</source>
          <target state="translated">学习阶段标志是一个bool张量(0=测试,1=训练),作为输入传递给任何在训练时间和测试时间使用不同行为的Keras函数。</target>
        </trans-unit>
        <trans-unit id="a0a124fd12c8c65bb6844115fdf183c1b942c532" translate="yes" xml:space="preserve">
          <source>The learning phase gets restored to its original value upon exiting the scope.</source>
          <target state="translated">学习阶段在退出范围后会恢复到原来的值。</target>
        </trans-unit>
        <trans-unit id="1de5c67a1eb0290c7057fa80ed33f8f702db5481" translate="yes" xml:space="preserve">
          <source>The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="translated">对于 &lt;code&gt;first_decay_steps&lt;/code&gt; 步骤，学习率乘数首先从1衰减到 &lt;code&gt;alpha&lt;/code&gt; 。然后，执行热重启。每次新的热启动都会以 &lt;code&gt;t_mul&lt;/code&gt; 倍的步数运行，而以 &lt;code&gt;m_mul&lt;/code&gt; 倍的初始学习率运行。</target>
        </trans-unit>
        <trans-unit id="28b092429ddde1497c6f3dfbaf3344b66f15e153" translate="yes" xml:space="preserve">
          <source>The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">学习率进度表也可以使用&lt;a href=&quot;serialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;deserialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt; 进行&lt;/a&gt;序列化和反序列化。</target>
        </trans-unit>
        <trans-unit id="01e40bb81194de53f99fe696ad30a914f2acff24" translate="yes" xml:space="preserve">
          <source>The learning rate. It should be a floating point value or a callable taking no arguments for a dynamic learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d51c3e8c1e064693087f30b29f778802b426021e" translate="yes" xml:space="preserve">
          <source>The left-hand side of the &lt;code&gt;!=&lt;/code&gt; operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf752d5e27436ab728a37f163c777a5586d0910a" translate="yes" xml:space="preserve">
          <source>The left-hand side of the &lt;code&gt;+&lt;/code&gt; operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15f4d7d0d6ba87c9c2b8ec8a96bd5bdea5cf5f18" translate="yes" xml:space="preserve">
          <source>The left-hand side of the &lt;code&gt;==&lt;/code&gt; operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5da8626faf43a1f562532d639d80375ea4ddfc06" translate="yes" xml:space="preserve">
          <source>The length of each row in this ragged tensor, or None if rows are ragged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="622693f2c5cb15d1481ed89936db4a11927a96bd" translate="yes" xml:space="preserve">
          <source>The length of output lists are all of the same length, &lt;code&gt;num_features&lt;/code&gt;. The output shapes are compatible in a way that the first dimension of all tensors of all lists are the same and equal to the number of possible split nodes for each feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69dda73634b99af43599a42bd633812c4b338c88" translate="yes" xml:space="preserve">
          <source>The length of the transform. If length is less than sequence length, only the first n elements of the sequence are considered for the DCT. If n is greater than the sequence length, zeros are padded and then the DCT is computed as usual.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d85658d0fa4fe8b1b20f2beaec2fc4b746948c87" translate="yes" xml:space="preserve">
          <source>The level at which to log.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90bbcad1f9bed80766758a96fdfa14681f8c6dd6" translate="yes" xml:space="preserve">
          <source>The link flags.</source>
          <target state="translated">链接标志。</target>
        </trans-unit>
        <trans-unit id="eef29fe89c1421162e4e09274c7ca8daa2971972" translate="yes" xml:space="preserve">
          <source>The list is in arbitrary order. It does not contain the special entries &quot;.&quot; and &quot;..&quot;.</source>
          <target state="translated">该清单的顺序是任意的。它不包含&quot;.&quot;和&quot;.&quot;这两个特殊条目。</target>
        </trans-unit>
        <trans-unit id="8a23b9208c8b55e07cbbf14bb7a18492cdb5be1b" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; arguments that are passed to the op function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fe2aa6417d3855190d90b82f9abd178eaf4e42b" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects representing the outputs of this op.</source>
          <target state="translated">代表此op的输出的 &lt;code&gt;Tensor&lt;/code&gt; 对象列表。</target>
        </trans-unit>
        <trans-unit id="72b9f570910bc85398790d90eea0b57ff816aa6f" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects unstacked from &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">从 &lt;code&gt;value&lt;/code&gt; 中未堆叠的 &lt;code&gt;Tensor&lt;/code&gt; 对象列表。</target>
        </trans-unit>
        <trans-unit id="e1da5ffc250e1d720f6279716c9d6aade88b1077" translate="yes" xml:space="preserve">
          <source>The list of arguments not parsed as options, including argv[0].</source>
          <target state="translated">未解析为选项的参数列表,包括 argv[0]。</target>
        </trans-unit>
        <trans-unit id="7a2668eec12c1d3cf3f187776719d83faec8967b" translate="yes" xml:space="preserve">
          <source>The list of concatenated tensors that was dequeued.</source>
          <target state="translated">被去掉队列的连词列表。</target>
        </trans-unit>
        <trans-unit id="70e71f616ed088b5e1a5217c440dcc82210678f0" translate="yes" xml:space="preserve">
          <source>The list of dtypes for each component of a queue element.</source>
          <target state="translated">队列元素的每个组件的dtypes列表。</target>
        </trans-unit>
        <trans-unit id="bfa264d47e9935a6a337f111d8bbcf3f713d945a" translate="yes" xml:space="preserve">
          <source>The list of names for each component of a queue element.</source>
          <target state="translated">队列元素的每个组件的名称列表。</target>
        </trans-unit>
        <trans-unit id="afc23fa1ddc71634846115e66b755cdfe5e1dce3" translate="yes" xml:space="preserve">
          <source>The list of shapes for each component of a queue element.</source>
          <target state="translated">队列元素的每个组件的形状列表。</target>
        </trans-unit>
        <trans-unit id="39c799e61ec6d452a92b2f433fe078d01b37f5db" translate="yes" xml:space="preserve">
          <source>The list of threads started for the &lt;code&gt;QueueRunners&lt;/code&gt;.</source>
          <target state="translated">为 &lt;code&gt;QueueRunners&lt;/code&gt; 启动的线程列表。</target>
        </trans-unit>
        <trans-unit id="17c761809240285ed679e6893972139bfc169439" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection.</source>
          <target state="translated">具有给定 &lt;code&gt;name&lt;/code&gt; 的集合中的值的列表；如果未向该集合中添加任何值，则为空列表。</target>
        </trans-unit>
        <trans-unit id="88981d3f5cd5ac5b5640b8a47ed0e63488d7e59c" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. Note that this returns the collection list itself, which can be modified in place to change the collection.</source>
          <target state="translated">具有给定 &lt;code&gt;name&lt;/code&gt; 的集合中的值的列表；如果未向该集合中添加任何值，则为空列表。请注意，这将返回集合列表本身，可以对其进行修改以更改集合。</target>
        </trans-unit>
        <trans-unit id="d9ede6fcf47022786b23b7b18ee2bcbd80557011" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. The list contains the values in the order under which they were collected.</source>
          <target state="translated">具有给定 &lt;code&gt;name&lt;/code&gt; 的集合中的值的列表；如果未向该集合中添加任何值，则为空列表。列表包含值的收集顺序。</target>
        </trans-unit>
        <trans-unit id="6538ac74002e8b4bac2992b02a57d0b02a01c00b" translate="yes" xml:space="preserve">
          <source>The list or dictionary of tensors to enqueue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72b6afead45a5c197fda6e2bbed35e9b2df07fc4" translate="yes" xml:space="preserve">
          <source>The local task index.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bfb8caff21900bf5e14d413b5ce56c051949f79" translate="yes" xml:space="preserve">
          <source>The local tensor to the sum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7016678a2375c9753e8eaf54d3415095320d885f" translate="yes" xml:space="preserve">
          <source>The locations represented by indices in &lt;code&gt;indices&lt;/code&gt; take value &lt;code&gt;on_value&lt;/code&gt;, while all other locations take value &lt;code&gt;off_value&lt;/code&gt;.</source>
          <target state="translated">在指数所代表的位置 &lt;code&gt;indices&lt;/code&gt; 取值 &lt;code&gt;on_value&lt;/code&gt; ，而所有其他地点取值 &lt;code&gt;off_value&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3d12a72f932ac01058fe17db625020a638310386" translate="yes" xml:space="preserve">
          <source>The logarithm of \(|Beta(x)|\) reducing along the last dimension.</source>
          <target state="translated">沿着最后一个维度减少的对数(|Beta(x)|)。</target>
        </trans-unit>
        <trans-unit id="cc2a2b682bde19cda29671bdd447522bc2609c77" translate="yes" xml:space="preserve">
          <source>The logic for one evaluation step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb1c02a9347c76b0eb9525d98ba6d17466885bcd" translate="yes" xml:space="preserve">
          <source>The logic for one inference step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91e2ef43e46f963e6adb77ffb3ae3fdcd8e43230" translate="yes" xml:space="preserve">
          <source>The logic for one training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cabf0d11d7d05a82a8264a276c299a29ceb6060" translate="yes" xml:space="preserve">
          <source>The logical device id presented is not consistent with total number of partitions specified by the device assignment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcad86f6653e28bded1ae388b8b9d533057cc10b" translate="yes" xml:space="preserve">
          <source>The logical to physical core mapping.</source>
          <target state="translated">逻辑核心到物理核心的映射。</target>
        </trans-unit>
        <trans-unit id="52db0b11c9a30f712036906862cfb94de23cb0bc" translate="yes" xml:space="preserve">
          <source>The logits, a float tensor. Note that logits are assumed to be unbounded and 0-centered. A value &amp;gt; 0 (resp. &amp;lt; 0) is considered a positive (resp. negative) binary prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="115853f39fe8d408f8bde4c8f093c2786d017e1d" translate="yes" xml:space="preserve">
          <source>The loss function to wrap, with signature &lt;code&gt;fn(y_true, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53c66b9be9a4d574723adcf23a86e3d3823c9748" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over all input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;, the loss is the weighted sum over both &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;label_dimension&lt;/code&gt;.</source>
          <target state="translated">损失是所有输入维度上的加权总和。即，如果输入标签的形状为 &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt; ，则损失为 &lt;code&gt;batch_size&lt;/code&gt; 和 &lt;code&gt;label_dimension&lt;/code&gt; 上的加权总和。</target>
        </trans-unit>
        <trans-unit id="ed8e3f66cfff153d9268a06149cbecc331a07647" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over the input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, 1]&lt;/code&gt;, the loss is the weighted sum over &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="translated">损失是输入维度上的加权总和。即，如果输入标签的形状为 &lt;code&gt;[batch_size, 1]&lt;/code&gt; ，则损失为 &lt;code&gt;batch_size&lt;/code&gt; 上的加权总和。</target>
        </trans-unit>
        <trans-unit id="6d3c5f122953381dbc3e40a95fb1e99d6fa1a036" translate="yes" xml:space="preserve">
          <source>The loss scale can either be a fixed constant, chosen by the user, or be dynamically determined. Dynamically determining the loss scale is convenient as a loss scale does not have to be explicitly chosen. However it reduces performance.</source>
          <target state="translated">损耗等级可以是一个固定的常数,由用户选择,也可以动态确定。动态确定损耗等级很方便,因为不必明确选择损耗等级。但它会降低性能。</target>
        </trans-unit>
        <trans-unit id="0f2c12568d11b3b33927e92671eaa159d3a45974" translate="yes" xml:space="preserve">
          <source>The loss scale is not updated for the lifetime of instances of this class. A given instance of this class always returns the same number when called.</source>
          <target state="translated">在这个类的实例的生命周期内,损失尺度不会更新。该类的一个给定实例在调用时总是返回相同的数字。</target>
        </trans-unit>
        <trans-unit id="e8cc3d97c2f9a64a6e0f3c844b54283387973842" translate="yes" xml:space="preserve">
          <source>The loss scale to scale the loss and gradients. This can either be an int/float to use a fixed loss scale, the string &quot;dynamic&quot; to use dynamic loss scaling, or an instance of a LossScale. The string &quot;dynamic&quot; equivalent to passing &lt;code&gt;DynamicLossScale()&lt;/code&gt;, and passing an int/float is equivalent to passing a FixedLossScale with the given loss scale.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c182a3c24f8448fb2c7d3d37bb39bed65ff10d2" translate="yes" xml:space="preserve">
          <source>The loss scale will be potentially updated, based on the value of &lt;code&gt;grads&lt;/code&gt;. The tensor returned by calling this class is only updated when this function is evaluated.</source>
          <target state="translated">损失规模将可能更新的基础上的价值 &lt;code&gt;grads&lt;/code&gt; 。通过调用此类返回的张量仅在评估此函数时更新。</target>
        </trans-unit>
        <trans-unit id="d57e591f877f94ccd0c69a35ed4f95a452a44b64" translate="yes" xml:space="preserve">
          <source>The loss, which will be multiplied by the loss scale. Can either be a tensor or a callable returning a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90f307f8c8cab35fd072b8a08ea2d9e8126898ba" translate="yes" xml:space="preserve">
          <source>The lower regularized incomplete Gamma function is defined as:</source>
          <target state="translated">下正则化不完全Gamma函数定义为:</target>
        </trans-unit>
        <trans-unit id="901b07d42e65c9f0c403e10ea3c5514df3c63502" translate="yes" xml:space="preserve">
          <source>The main advantage of the graph rewrite (this function) is that it works even if you do not use Keras layers or any other part of Keras. The Keras mixed precision API requires models which use Keras layers, as it only inserts casts inside Keras layers and models. Another advantage is that the graph rewrite never results in a TypeError, which the Keras API may introduce if you do certain operations outside Keras. For example, the following will result in a TypeError if the Keras mixed precision API is enabled, as a float16 and float32 tensor will be added: &lt;code&gt;tf.keras.layers.Dense(2)(x) + tf.keras.layers.Dense(2, dtype=&quot;float32&quot;)(x)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2793511554b8b49f5f134322351c8feaf894969" translate="yes" xml:space="preserve">
          <source>The main reason to subclass &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt; instead of using a &lt;code&gt;Lambda&lt;/code&gt; layer is saving and inspecting a Model. &lt;code&gt;Lambda&lt;/code&gt; layers are saved by serializing the Python bytecode, whereas subclassed Layers can be saved via overriding their &lt;code&gt;get_config&lt;/code&gt; method. Overriding &lt;code&gt;get_config&lt;/code&gt; improves the portability of Models. Models that rely on subclassed Layers are also often easier to visualize and reason about.</source>
          <target state="translated">&lt;a href=&quot;layer&quot;&gt; &lt;code&gt;tf.keras.layers.Layer&lt;/code&gt; &lt;/a&gt;而不使用 &lt;code&gt;Lambda&lt;/code&gt; 层的主要原因是保存和检查模型。 &lt;code&gt;Lambda&lt;/code&gt; 图层是通过序列化Python字节码来保存的，而子类化的 &lt;code&gt;get_config&lt;/code&gt; 可以通过覆盖其get_config方法来保存。覆盖 &lt;code&gt;get_config&lt;/code&gt; 改善了模型的可移植性。依赖于子类化图层的模型通常也更易于可视化和推理。</target>
        </trans-unit>
        <trans-unit id="819f3cd059d735134db06c3d8502fabffae5741e" translate="yes" xml:space="preserve">
          <source>The main roles of the &lt;a href=&quot;../gfile&quot;&gt;&lt;code&gt;tf.io.gfile&lt;/code&gt;&lt;/a&gt; module are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e62c58738b23223c2be9a210223b49cb5226c9b5" translate="yes" xml:space="preserve">
          <source>The main use case for this is to provide additional shape information that cannot be inferred from the graph alone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a2c99d4f1e6d03bbc1af13e3314d300799e01bf" translate="yes" xml:space="preserve">
          <source>The map vectorization options associated with the dataset. See &lt;a href=&quot;mapvectorizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.MapVectorizationOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">与数据集关联的地图矢量化选项。有关更多详细信息，请参见&lt;a href=&quot;mapvectorizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.MapVectorizationOptions&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f8214e9e9da90e26f5fe7ae19cb9d8f2cd4e068c" translate="yes" xml:space="preserve">
          <source>The masked &lt;code&gt;IndexedSlices&lt;/code&gt; instance.</source>
          <target state="translated">带掩码的 &lt;code&gt;IndexedSlices&lt;/code&gt; 实例。</target>
        </trans-unit>
        <trans-unit id="221a20910838d03246163841206f72d038ef571a" translate="yes" xml:space="preserve">
          <source>The matrix &lt;code&gt;a&lt;/code&gt; must, following any transpositions, be a tensor of rank &amp;gt;= 2, with &lt;code&gt;shape(a)[-1] == shape(b)[-1]&lt;/code&gt;, and &lt;code&gt;shape(a)[:-2]&lt;/code&gt; able to broadcast with &lt;code&gt;shape(b)[:-1]&lt;/code&gt;.</source>
          <target state="translated">矩阵 &lt;code&gt;a&lt;/code&gt; 在任何转置之后都必须是等级&amp;gt; = 2的张量，其中 &lt;code&gt;shape(a)[-1] == shape(b)[-1]&lt;/code&gt; 和 &lt;code&gt;shape(a)[:-2]&lt;/code&gt; 能够以 &lt;code&gt;shape(b)[:-1]&lt;/code&gt; 广播。</target>
        </trans-unit>
        <trans-unit id="fd71aa391cda25307463e674c4cbc2ea6a909c84" translate="yes" xml:space="preserve">
          <source>The matrix can be used with &lt;a href=&quot;../tensordot&quot;&gt;&lt;code&gt;tf.tensordot&lt;/code&gt;&lt;/a&gt; to convert an arbitrary rank &lt;code&gt;Tensor&lt;/code&gt; of linear-scale spectral bins into the mel scale.</source>
          <target state="translated">该矩阵可以与&lt;a href=&quot;../tensordot&quot;&gt; &lt;code&gt;tf.tensordot&lt;/code&gt; &lt;/a&gt;一起使用，以将线性谱段的任意秩 &lt;code&gt;Tensor&lt;/code&gt; 转换为梅尔标度。</target>
        </trans-unit>
        <trans-unit id="11e987b7f304f6e3dd583d8302496f7bf0e8c7c9" translate="yes" xml:space="preserve">
          <source>The matrix columns represent the prediction labels and the rows represent the real labels. The confusion matrix is always a 2-D array of shape &lt;code&gt;[n, n]&lt;/code&gt;, where &lt;code&gt;n&lt;/code&gt; is the number of valid labels for a given classification task. Both prediction and labels must be 1-D arrays of the same shape in order for this function to work.</source>
          <target state="translated">矩阵列代表预测标签，行代表真实标签。混淆矩阵始终是形状 &lt;code&gt;[n, n]&lt;/code&gt; 的2维数组，其中 &lt;code&gt;n&lt;/code&gt; 是给定分类任务的有效标签数。为了使此功能起作用，预测和标签都必须是相同形状的一维数组。</target>
        </trans-unit>
        <trans-unit id="1b5db825d45e0c9d1dc6abe9745f59c698b3a58a" translate="yes" xml:space="preserve">
          <source>The matrix square root is computed by first reducing the matrix to quasi-triangular form with the real Schur decomposition. The square root of the quasi-triangular matrix is then computed directly. Details of the algorithm can be found in: Nicholas J. Higham, &quot;Computing real square roots of a real matrix&quot;, Linear Algebra Appl., 1987.</source>
          <target state="translated">矩阵平方根的计算方法是:首先用实舒尔分解法将矩阵还原为准三角形式。然后直接计算准三角矩阵的平方根。算法的详细内容可参见。Nicholas J.Higham,&quot;计算实数矩阵的实数平方根&quot;,《线性代数应用》,1987年。</target>
        </trans-unit>
        <trans-unit id="9a3f4491229c91cec072bbea8b93dd0af684f6f0" translate="yes" xml:space="preserve">
          <source>The matrix_inv, i.e., &lt;code&gt;tf.matrix_inverse(tf.linalg.lu_reconstruct(lu, perm))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cbe11326425a2d54b10de9163c8a24f5b723b61" translate="yes" xml:space="preserve">
          <source>The maximum depth of the batch queue. Defaults to 10.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e52e55f2b2b641c09e44a69eccc168205a706b2" translate="yes" xml:space="preserve">
          <source>The maximum error in between the two Jacobians.</source>
          <target state="translated">两个雅各布之间的最大误差。</target>
        </trans-unit>
        <trans-unit id="3be13be49d81cebdf3179f6f054bd1716af0f051" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations allowed to run in parallel at any given time. Note that this does not guarantee parallel execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29ead67ff92bddff9eff04834e8bb493908a2db7" translate="yes" xml:space="preserve">
          <source>The maximum number of recent checkpoint files to keep. As new files are created, older files are deleted. If &lt;code&gt;None&lt;/code&gt; or 0, all checkpoint files are kept. Defaults to 5 (that is, the 5 most recent checkpoint files are kept). If a saver is passed to the estimator, this argument will be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c842279a5926425077d49c4d323753d5555a6974" translate="yes" xml:space="preserve">
          <source>The maximum number of seconds to wait between checkpoints. If left as &lt;code&gt;None&lt;/code&gt;, then the process will wait indefinitely.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fec7fdc53285af99f3c39f517df820603ae9970" translate="yes" xml:space="preserve">
          <source>The maximum number of shards in int created taking precedence over &lt;code&gt;max_shard_bytes&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce69417dfa16ffede7fef0c558fc36b98c931ccd" translate="yes" xml:space="preserve">
          <source>The maximum size any given shard is allowed to be.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2f9f6a5b1ba47e00d259277177486caa909f7c3" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf7f7963ad951a38de619a169bd063732ab43414" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary contains 1 OOV token, so the effective number of tokens is &lt;code&gt;(max_tokens - 1 - (1 if output == &quot;int&quot; else 0))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="823dcf626318cd7da7d9199f74b8dc7942281b83" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary includes the OOV and mask tokens, so the effective number of tokens is (max_tokens - num_oov_indices - (1 if mask_token else 0))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fce588fe3287d94ea0532f096d110229f0b8aff4" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary includes the OOV and mask values, so the effective number of values is (max_values - num_oov_values - (1 if mask_token else 0))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c20357476750adc337729874b4e2eabc8868c3d" translate="yes" xml:space="preserve">
          <source>The mean and variance are calculated by aggregating the contents of &lt;code&gt;x&lt;/code&gt; across &lt;code&gt;axes&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is 1-D and &lt;code&gt;axes = [0]&lt;/code&gt; this is just the mean and variance of a vector.</source>
          <target state="translated">平均值和方差是通过汇总 &lt;code&gt;x&lt;/code&gt; 跨 &lt;code&gt;axes&lt;/code&gt; 的内容来计算的。如果 &lt;code&gt;x&lt;/code&gt; 为1-D并且 &lt;code&gt;axes = [0]&lt;/code&gt; 这只是矢量的均值和方差。</target>
        </trans-unit>
        <trans-unit id="e3746fb2d4eae6a4ec87d65fc23bec2fa55150f2" translate="yes" xml:space="preserve">
          <source>The mean of Student's T equals &lt;code&gt;loc&lt;/code&gt; if &lt;code&gt;df &amp;gt; 1&lt;/code&gt;, otherwise it is &lt;code&gt;NaN&lt;/code&gt;. If &lt;code&gt;self.allow_nan_stats=True&lt;/code&gt;, then an exception will be raised rather than returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;df &amp;gt; 1&lt;/code&gt; ，则学生T的平均值等于 &lt;code&gt;loc&lt;/code&gt; ，否则为 &lt;code&gt;NaN&lt;/code&gt; 。如果 &lt;code&gt;self.allow_nan_stats=True&lt;/code&gt; ，则会引发异常，而不是返回 &lt;code&gt;NaN&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="66b167be0f051cc6e8d71c967e67b0309cb7feab" translate="yes" xml:space="preserve">
          <source>The meaning of &lt;code&gt;query&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; and &lt;code&gt;key&lt;/code&gt; depend on the application. In the case of text similarity, for example, &lt;code&gt;query&lt;/code&gt; is the sequence embeddings of the first piece of text and &lt;code&gt;value&lt;/code&gt; is the sequence embeddings of the second piece of text. &lt;code&gt;key&lt;/code&gt; is usually the same tensor as &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;query&lt;/code&gt; ， &lt;code&gt;value&lt;/code&gt; 和 &lt;code&gt;key&lt;/code&gt; 的含义取决于应用程序。例如，在文本相似的情况下， &lt;code&gt;query&lt;/code&gt; 是第一条文本的序列嵌入，而 &lt;code&gt;value&lt;/code&gt; 是第二条文本的序列嵌入。 &lt;code&gt;key&lt;/code&gt; 通常是与 &lt;code&gt;value&lt;/code&gt; 相同的张量。</target>
        </trans-unit>
        <trans-unit id="92510595be575a3f901083a76e505b27be4bea36" translate="yes" xml:space="preserve">
          <source>The meaning of setting &lt;code&gt;layer.trainable = False&lt;/code&gt; is to freeze the layer, i.e. its internal state will not change during training: its trainable weights will not be updated during &lt;code&gt;fit()&lt;/code&gt; or &lt;code&gt;train_on_batch()&lt;/code&gt;, and its state updates will not be run.</source>
          <target state="translated">设置 &lt;code&gt;layer.trainable = False&lt;/code&gt; 的含义是冻结该层，即其内部状态在训练期间不会更改：其可训练权重不会在 &lt;code&gt;fit()&lt;/code&gt; 或 &lt;code&gt;train_on_batch()&lt;/code&gt; 期间更新，并且其状态更新不会运行。</target>
        </trans-unit>
        <trans-unit id="528237c36c5e86dd6df7548b941e9ca56236a205" translate="yes" xml:space="preserve">
          <source>The message string describing the failure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="529560d839d515582efcee9c67d4aa3e5b977208" translate="yes" xml:space="preserve">
          <source>The message to be logged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="927b26e1d502dee1491ea322ed177902d5b783af" translate="yes" xml:space="preserve">
          <source>The message to be printed if the test fails.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc3b5afc215b729af496233be8e56b7e96ac2370" translate="yes" xml:space="preserve">
          <source>The method is primarily intended for use by higher level checkpoint management utilities that use &lt;code&gt;write()&lt;/code&gt; instead of &lt;code&gt;save()&lt;/code&gt; and have their own mechanisms to number and track checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae04b245da8a7e16dadcfeccbc7fd1f3884fcfad" translate="yes" xml:space="preserve">
          <source>The method returns the path prefix of the newly created checkpoint files. This string can be passed directly to a call to &lt;code&gt;restore()&lt;/code&gt;.</source>
          <target state="translated">该方法返回新创建的检查点文件的路径前缀。该字符串可以直接传递给对 &lt;code&gt;restore()&lt;/code&gt; 的调用。</target>
        </trans-unit>
        <trans-unit id="1836c8d92cb040c17ca773b41548d6aa87cf1d6f" translate="yes" xml:space="preserve">
          <source>The method sums gradients from all replicas in the presence of &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; by default. You can aggregate gradients yourself by passing &lt;code&gt;experimental_aggregate_gradients=False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0ac25102d39a598793fa8f0fe151f95b652dfdf" translate="yes" xml:space="preserve">
          <source>The method sums gradients from all replicas in the presence of &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; by default. You can aggregate gradients yourself by passing &lt;code&gt;experimental_aggregate_gradients=False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ff8c3ac6acac3abb6a93f8bb5141bf050b9a99b" translate="yes" xml:space="preserve">
          <source>The method to wrap.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c6e6621d848cf3b840ae66983d6900ad6f06a8b" translate="yes" xml:space="preserve">
          <source>The metric creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt; that are used to compute the precision. This value is ultimately returned as &lt;code&gt;precision&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;.</source>
          <target state="translated">度量标准创建两个局部变量，即 &lt;code&gt;true_positives&lt;/code&gt; 和 &lt;code&gt;false_positives&lt;/code&gt; ，用于计算精度。该值最终以 &lt;code&gt;precision&lt;/code&gt; 返回，这是一个幂等运算，将 &lt;code&gt;true_positives&lt;/code&gt; 除以 &lt;code&gt;true_positives&lt;/code&gt; 和 &lt;code&gt;false_positives&lt;/code&gt; 之和即可。</target>
        </trans-unit>
        <trans-unit id="a1847f02504cca83cac29940c7bc8134ccc574f2" translate="yes" xml:space="preserve">
          <source>The min and max can be the same size as &lt;code&gt;t&lt;/code&gt;, or broadcastable to that size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c879ab9978d630c89fff8cae92e9db4343f09490" translate="yes" xml:space="preserve">
          <source>The minibatch size &lt;code&gt;N&lt;/code&gt; is extracted from &lt;code&gt;sparse_shape[0]&lt;/code&gt;.</source>
          <target state="translated">最小批量大小 &lt;code&gt;N&lt;/code&gt; 是从 &lt;code&gt;sparse_shape[0]&lt;/code&gt; 提取的。</target>
        </trans-unit>
        <trans-unit id="e7bc279c2507aa25ef22019845fdd46f52af29f0" translate="yes" xml:space="preserve">
          <source>The minimum number of seconds between yielding checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2ce5fd43a91250f68e4b68161729fe63f5fffc0" translate="yes" xml:space="preserve">
          <source>The minimum value to clip to. A scalar &lt;code&gt;Tensor&lt;/code&gt; or one that is broadcastable to the shape of &lt;code&gt;t&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adafbd0cce3b5754618ae2da17c9902f6cae336a" translate="yes" xml:space="preserve">
          <source>The mode of a gamma distribution is &lt;code&gt;(shape - 1) / rate&lt;/code&gt; when &lt;code&gt;shape &amp;gt; 1&lt;/code&gt;, and &lt;code&gt;NaN&lt;/code&gt; otherwise. If &lt;code&gt;self.allow_nan_stats&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, an exception will be raised rather than returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">当 &lt;code&gt;shape &amp;gt; 1&lt;/code&gt; ，伽玛分布的模式为 &lt;code&gt;(shape - 1) / rate&lt;/code&gt; ，否则为 &lt;code&gt;NaN&lt;/code&gt; 。如果 &lt;code&gt;self.allow_nan_stats&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; ，将引发异常，而不是返回 &lt;code&gt;NaN&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ccf3763dcb0dcb0536020350fdb380b642b68362" translate="yes" xml:space="preserve">
          <source>The model architecture, allowing to re-instantiate the model.</source>
          <target state="translated">模型架构,允许重新建立模型。</target>
        </trans-unit>
        <trans-unit id="2c5272bf28fc9b4f93ddcbb47262f8771af50748" translate="yes" xml:space="preserve">
          <source>The model weights.</source>
          <target state="translated">模型权重。</target>
        </trans-unit>
        <trans-unit id="ea7ad3d000098fbd9c3f8078136ad7545a66a1a5" translate="yes" xml:space="preserve">
          <source>The monitoring result is a light weight performance summary of your model execution. This method will block the caller thread until it receives the monitoring result. This method currently supports Cloud TPU only.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff3e822749aa45b217109835dbb8a4c4930f2cb5" translate="yes" xml:space="preserve">
          <source>The most basic RNN cell.</source>
          <target state="translated">最基本的RNN细胞。</target>
        </trans-unit>
        <trans-unit id="92ef4fa2dcf9047cf590c368e2e76fcb4cd1ce27" translate="yes" xml:space="preserve">
          <source>The most common initialization pattern is to use the convenience function &lt;code&gt;global_variables_initializer()&lt;/code&gt; to add an Op to the graph that initializes all the variables. You then run that Op after launching the graph.</source>
          <target state="translated">最常见的初始化模式是使用便利函数 &lt;code&gt;global_variables_initializer()&lt;/code&gt; 向图形添加一个Op，以初始化所有变量。然后，在启动图形后运行该Op。</target>
        </trans-unit>
        <trans-unit id="be28bd956ec3dd71f96903bf3e90304d770c19da" translate="yes" xml:space="preserve">
          <source>The most common use case for this function occurs when feature ids and their corresponding values are stored in &lt;code&gt;Example&lt;/code&gt; protos on disk. &lt;code&gt;parse_example&lt;/code&gt; will return a batch of ids and a batch of values, and this function joins them into a single logical &lt;code&gt;SparseTensor&lt;/code&gt; for use in functions such as &lt;code&gt;sparse_tensor_dense_matmul&lt;/code&gt;, &lt;code&gt;sparse_to_dense&lt;/code&gt;, etc.</source>
          <target state="translated">当功能ID及其对应的值存储在磁盘上的 &lt;code&gt;Example&lt;/code&gt; protos中时，会发生此功能的最常见用例。 &lt;code&gt;parse_example&lt;/code&gt; 将返回一批id和一批值，并且此函数将它们连接到单个逻辑 &lt;code&gt;SparseTensor&lt;/code&gt; 中,以用于 &lt;code&gt;sparse_tensor_dense_matmul&lt;/code&gt; ， &lt;code&gt;sparse_to_dense&lt;/code&gt; 等功能。</target>
        </trans-unit>
        <trans-unit id="a69bd33774ebc03eef1cf8370253b0bcf30e7aa7" translate="yes" xml:space="preserve">
          <source>The moving average 'x' is updated with 'value' following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76823a81079db8809cfb267b11ddd3da1ded660e" translate="yes" xml:space="preserve">
          <source>The moving average momentum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c37b111e7c1a2dfc5ac3657ac3eb40f6697f662" translate="yes" xml:space="preserve">
          <source>The moving averages are computed using exponential decay. You specify the decay value when creating the &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; object. The shadow variables are initialized with the same initial values as the trained variables. When you run the ops to maintain the moving averages, each shadow variable is updated with the formula:</source>
          <target state="translated">移动平均值是使用指数衰减来计算的。在创建 &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; 对象时，可以指定衰减值。阴影变量使用与训练变量相同的初始值进行初始化。当您运行ops来维持移动平均线时，每个阴影变量都会使用以下公式进行更新：</target>
        </trans-unit>
        <trans-unit id="f305dca235c43ee1a853f11ce26d4431d5e87ca7" translate="yes" xml:space="preserve">
          <source>The multiplier to use when increasing or decreasing the loss scale.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3435f5d772da81bd99891e4904cc5b3c397d1c9f" translate="yes" xml:space="preserve">
          <source>The name argument that is passed to the op function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d20e166c1cf227f369943da2e63973914a88b08e" translate="yes" xml:space="preserve">
          <source>The name associated with the object, or the default Python name if the object is not registered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2171b8f310d13c802a9a28d101182783fe8adb9e" translate="yes" xml:space="preserve">
          <source>The name for an operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2717d81e9c492087a9d97bf3dcb31386b0e2f366" translate="yes" xml:space="preserve">
          <source>The name of a device to which elements will be copied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e102ebd7e44cf3878287ddf4c08d8cb2be4fd58f" translate="yes" xml:space="preserve">
          <source>The name of the &lt;code&gt;Operation&lt;/code&gt; to return.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aec966e4ab5b0c806f06d99f9dc3e1f466185982" translate="yes" xml:space="preserve">
          <source>The name of the &lt;code&gt;Tensor&lt;/code&gt; to return.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94df2d413ae96a0a117fa46769022f06a44e6ff4" translate="yes" xml:space="preserve">
          <source>The name of the &lt;code&gt;TensorArray&lt;/code&gt; (even if passed in) is uniquified: each time a new &lt;code&gt;TensorArray&lt;/code&gt; is created at runtime it is assigned its own name for the duration of the run. This avoids name collisions if a &lt;code&gt;TensorArray&lt;/code&gt; is created within a &lt;code&gt;while_loop&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;TensorArray&lt;/code&gt; 的名称（即使传入）也是唯一的：每次在运行时创建新的 &lt;code&gt;TensorArray&lt;/code&gt; 时，都会在运行期间为其分配自己的名称。如果这避免名称冲突 &lt;code&gt;TensorArray&lt;/code&gt; 是内创建 &lt;code&gt;while_loop&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f394dc9c1e1c5f94915c443c9936510156504edb" translate="yes" xml:space="preserve">
          <source>The name of the TPU job. Typically, this name is auto-inferred within TPUEstimator, however when using ClusterSpec propagation in more esoteric cluster configurations, you may need to specify the job name as a string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1aa3a17d239638bffd8da87470925d90fc14587" translate="yes" xml:space="preserve">
          <source>The name of the activation function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1fad2a11c1fa88593c78a2b8dbc37f823e55dcb" translate="yes" xml:space="preserve">
          <source>The name of the attr to fetch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51b48f4480def25ba4d61ddbb25309d908422157" translate="yes" xml:space="preserve">
          <source>The name of the attribute to change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3411600001d2f7bf3a52d4bd93fdb012e4af3205" translate="yes" xml:space="preserve">
          <source>The name of the attribute to modify.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbb0bb41743f114fce1ea1f179c3a700f65b6093" translate="yes" xml:space="preserve">
          <source>The name of the decorator. If &lt;code&gt;None&lt;/code&gt;, the name of the function calling make_decorator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fcdbd427dc016b6defe717193d13e8a5ff2954b" translate="yes" xml:space="preserve">
          <source>The name of the device on which &lt;code&gt;values&lt;/code&gt; will be produced, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">将在其上产生 &lt;code&gt;values&lt;/code&gt; 的设备的名称，或 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="37ecde1c1b33e8dfdb61f844e3753c1a790bb482" translate="yes" xml:space="preserve">
          <source>The name of the device on which this tensor will be produced, or None.</source>
          <target state="translated">产生该张量的设备名称,或无。</target>
        </trans-unit>
        <trans-unit id="513390ceda7c6a57cd491aa38c353737462bdd7c" translate="yes" xml:space="preserve">
          <source>The name of the device to which this op has been assigned, if any.</source>
          <target state="translated">该操作被分配到的设备名称(如有)。</target>
        </trans-unit>
        <trans-unit id="0484306d12f825b7f062712ebb91e1e5070c26cd" translate="yes" xml:space="preserve">
          <source>The name of the layer (string).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e0dea9bfe26a7beb65886a09d49cbd06a620222" translate="yes" xml:space="preserve">
          <source>The name of the local job.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf636fc4624183a99bcc4c7c7fbe0a44c0ebb8f7" translate="yes" xml:space="preserve">
          <source>The name of the module which registered the flag with this name. If no such module exists (i.e. no flag with this name exists), we return default.</source>
          <target state="translated">用这个名字注册标志的模块的名称。如果没有这样的模块存在(即没有这个名称的标志存在),我们返回默认值。</target>
        </trans-unit>
        <trans-unit id="d507fbefee6f858beaba994a2d5222c827f1ac97" translate="yes" xml:space="preserve">
          <source>The name of the new or existing variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bc9ed5993c993f81f4eb7f3f3150297cebf93a8" translate="yes" xml:space="preserve">
          <source>The name of the op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48b66664c86691b5553fd1d2c5bdf4eaa5d9161f" translate="yes" xml:space="preserve">
          <source>The name of the operation to be created</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca71906a25ae77a1092de8617dc7e418a294cb12" translate="yes" xml:space="preserve">
          <source>The name of the output &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6f9aa3bfdd3d1620c355dda8c15d6285fa32c9" translate="yes" xml:space="preserve">
          <source>The name of the output &lt;code&gt;Tensor&lt;/code&gt; (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7f41644b081b946d6a6996c5793e8e0c8a0ca0c" translate="yes" xml:space="preserve">
          <source>The name of the returned tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d3b4cc387786491f2cb51bc2065fde0324f391f" translate="yes" xml:space="preserve">
          <source>The name of the scope itself can be captured by &lt;code&gt;with g.name_scope(...) as scope:&lt;/code&gt;, which stores the name of the scope in the variable &lt;code&gt;scope&lt;/code&gt;. This value can be used to name an operation that represents the overall result of executing the ops in a scope. For example:</source>
          <target state="translated">可以 &lt;code&gt;with g.name_scope(...) as scope:&lt;/code&gt; 捕获范围本身的名称，该名称将范围的名称存储在变量 &lt;code&gt;scope&lt;/code&gt; 中。该值可用于命名一个操作，该操作代表在范围内执行操作的总体结果。例如：</target>
        </trans-unit>
        <trans-unit id="c5bdc797aad3e657271b859b7dc8d873a1c5776b" translate="yes" xml:space="preserve">
          <source>The name of the table.</source>
          <target state="translated">表的名称。</target>
        </trans-unit>
        <trans-unit id="29294a5bc0faead00c55b881e7f2f01d1f8fd3c6" translate="yes" xml:space="preserve">
          <source>The name of the trace event.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f8f2953a3d445a0fc6a56065d426682fba17223" translate="yes" xml:space="preserve">
          <source>The name of the underlying accumulator.</source>
          <target state="translated">基础蓄电池的名称。</target>
        </trans-unit>
        <trans-unit id="96809ba43c27a83619ec011b30fe50853f001590" translate="yes" xml:space="preserve">
          <source>The name of the underlying queue.</source>
          <target state="translated">底层队列的名称。</target>
        </trans-unit>
        <trans-unit id="f89f168ead7cdce407789bc51f70ca1fc8c5be20" translate="yes" xml:space="preserve">
          <source>The name of this &lt;code&gt;IndexedSlices&lt;/code&gt;.</source>
          <target state="translated">此 &lt;code&gt;IndexedSlices&lt;/code&gt; 的名称。</target>
        </trans-unit>
        <trans-unit id="da911221082c7da030b3afee2bb6138d5ed15e00" translate="yes" xml:space="preserve">
          <source>The name of this ExponentialMovingAverage object.</source>
          <target state="translated">这个ExponentialMovingAverage对象的名称。</target>
        </trans-unit>
        <trans-unit id="a0b8c507e7f0e7b6a1373421e05579d1965778f3" translate="yes" xml:space="preserve">
          <source>The name of this head.</source>
          <target state="translated">这头的名字。</target>
        </trans-unit>
        <trans-unit id="d713b72d40825a59e98f4bc908a8370877bdd57f" translate="yes" xml:space="preserve">
          <source>The name of this variable.</source>
          <target state="translated">这个变量的名称。</target>
        </trans-unit>
        <trans-unit id="1d01abc5e97d43035681b7621f742a7e0e4f87f3" translate="yes" xml:space="preserve">
          <source>The name or URL of the session master.</source>
          <target state="translated">会话主站的名称或URL。</target>
        </trans-unit>
        <trans-unit id="22b1df8c09c11cf1299228c2a025d453b2932406" translate="yes" xml:space="preserve">
          <source>The name passed to &lt;a href=&quot;../../name_scope&quot;&gt;&lt;code&gt;tf.name_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="647b627abb244e52e977dfb90e76736f5a70efdc" translate="yes" xml:space="preserve">
          <source>The name to look up.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e36e7449d4e0998fc78c6e3977716de004b31a" translate="yes" xml:space="preserve">
          <source>The name to serialize this class under in this package. If None, the class' name will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c8e14eb227eb8d0282158234a5e6ae09b22ded5" translate="yes" xml:space="preserve">
          <source>The name to use for the coordinator. Set to None if the coordinator should not be included in the computed ClusterSpec.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5beb388dc9de0f3a44e8c2ae92390e5cddbd00f3" translate="yes" xml:space="preserve">
          <source>The name to use when creating the execute operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be158487fb11e20f31b9a766e704ebc058b51521" translate="yes" xml:space="preserve">
          <source>The named axis labels may be any single character other than those having special meaning, namely &lt;code&gt;,.-&amp;gt;&lt;/code&gt;. The behavior of this Op is undefined if it receives an ill-formatted equation; since the validation is done at graph-building time, we omit format validation checks at runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="947e2daa3bb98d0bc923e5ca008b708b99d1db05" translate="yes" xml:space="preserve">
          <source>The natural log of the determinant of &lt;code&gt;matrix&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;matrix&lt;/code&gt; 的自然对数。</target>
        </trans-unit>
        <trans-unit id="ca6f16df867a9e980034d2567f42c641b28a79b7" translate="yes" xml:space="preserve">
          <source>The need for a manually selected global learning rate</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e172fe7e51a351d69f78266150cbe93d41a966dd" translate="yes" xml:space="preserve">
          <source>The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.</source>
          <target state="translated">对转置卷积的需求一般来自于希望使用与正常卷积相反方向的变换,即,从具有某种卷积的输出形状的东西到具有其输入形状的东西,同时保持与所述卷积相容的连接模式。</target>
        </trans-unit>
        <trans-unit id="497bcc780928cec8678167a0943cfb8a236572bc" translate="yes" xml:space="preserve">
          <source>The nest is or contains a dict with non-sortable keys.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87443d4ab1ed1b3ecff97672f0081e558c9e3e8c" translate="yes" xml:space="preserve">
          <source>The nested structure of &lt;code&gt;Tensor&lt;/code&gt;s to all-reduce. The structure must be compatible with &lt;a href=&quot;../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="591766edefc12d264f15ba10d8ba1725a7aa8e44" translate="yes" xml:space="preserve">
          <source>The new axis location matches Python &lt;code&gt;list.insert(axis, 1)&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="958033fa33493f00248ba20803119af783c47f8d" translate="yes" xml:space="preserve">
          <source>The new batch size pulled from the queue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3db6116c7d99fcd620f590077cbf1f7679e81227" translate="yes" xml:space="preserve">
          <source>The new callable signature of this decorator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a92087301e7ffb88316b9135c1aafd2aa583aa2a" translate="yes" xml:space="preserve">
          <source>The new default value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e63348dbbced4923128564bd3253cc502100689d" translate="yes" xml:space="preserve">
          <source>The new generator will be initialized by one of the following ways, with decreasing precedence: (1) If &lt;code&gt;copy_from&lt;/code&gt; is not None, the new generator is initialized by copying information from another generator. (3) If &lt;code&gt;state&lt;/code&gt; and &lt;code&gt;alg&lt;/code&gt; are not None (they must be set together), the new generator is initialized by a state.</source>
          <target state="translated">新生成器将通过以下一种方式初始化，并且优先级降低：（1）如果 &lt;code&gt;copy_from&lt;/code&gt; 不为None，则通过复制其他生成器的信息来初始化新生成器。（3）如果 &lt;code&gt;state&lt;/code&gt; 和 &lt;code&gt;alg&lt;/code&gt; 不为None（必须将它们设置在一起），则新生成器将由state初始化。</target>
        </trans-unit>
        <trans-unit id="8cbbc58e1d6e45f7538d48a88e9145ff0816310e" translate="yes" xml:space="preserve">
          <source>The new generator.</source>
          <target state="translated">新的发电机。</target>
        </trans-unit>
        <trans-unit id="c92d3a1d88d5bb846fb6922638676753f654e62e" translate="yes" xml:space="preserve">
          <source>The new generators will be put on the current device (possible different from the old generator's), for example:</source>
          <target state="translated">新的发电机将放在当前设备上(可能与旧发电机的不同),例如。</target>
        </trans-unit>
        <trans-unit id="aed9e7e391104d869576ed733d9adb3a806218e3" translate="yes" xml:space="preserve">
          <source>The new value for the attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9b227961e3d04545a92b5ce44cb233f0e0e2e32" translate="yes" xml:space="preserve">
          <source>The new value of the attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e426c7afe47b5f55c3dfa85e599a773e3d38d777" translate="yes" xml:space="preserve">
          <source>The new variable is added to the graph collections listed in &lt;code&gt;collections&lt;/code&gt;, which defaults to &lt;code&gt;[GraphKeys.GLOBAL_VARIABLES]&lt;/code&gt;.</source>
          <target state="translated">新变量被添加到中列出的图表的集合 &lt;code&gt;collections&lt;/code&gt; ，缺省值为 &lt;code&gt;[GraphKeys.GLOBAL_VARIABLES]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b23ad53a08722aede7339ef0814174529ec55158" translate="yes" xml:space="preserve">
          <source>The next element in the queue, i.e. a tuple &lt;code&gt;(inputs, targets)&lt;/code&gt; or &lt;code&gt;(inputs, targets, sample_weights)&lt;/code&gt;.</source>
          <target state="translated">队列中的下一个元素，即元组 &lt;code&gt;(inputs, targets)&lt;/code&gt; 或 &lt;code&gt;(inputs, targets, sample_weights)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="44b4a8428f7aea36b41515b3369e33369a93a616" translate="yes" xml:space="preserve">
          <source>The node to be assigned to a device. Could be either an ops.Operation or NodeDef.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bc3974c53a4bc03fb9e4842cff39c86a0d8870a" translate="yes" xml:space="preserve">
          <source>The non-zero values in the represented dense tensor.</source>
          <target state="translated">所代表的密张量中的非零值。</target>
        </trans-unit>
        <trans-unit id="a794ea3a692cf3249d1fcc991ee60c5b4cf01417" translate="yes" xml:space="preserve">
          <source>The normal &lt;code&gt;ServingInputReceiver&lt;/code&gt; always returns a feature dict, even if it contains only one entry, and so can be used only with models that accept such a dict. For models that accept only a single raw feature, the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; provided to &lt;a href=&quot;../../compat/v1/estimator/estimator#export_saved_model&quot;&gt;&lt;code&gt;Estimator.export_saved_model()&lt;/code&gt;&lt;/a&gt; should return this &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; instead. See: https://github.com/tensorflow/tensorflow/issues/11674</source>
          <target state="translated">普通的 &lt;code&gt;ServingInputReceiver&lt;/code&gt; 始终返回功能字典，即使它仅包含一个条目，因此只能与接受该字典的模型一起使用。对于只接受一个单一的原始功能，该机型 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供给&lt;a href=&quot;../../compat/v1/estimator/estimator#export_saved_model&quot;&gt; &lt;code&gt;Estimator.export_saved_model()&lt;/code&gt; &lt;/a&gt;应该返回这个 &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; 代替。参见：https://github.com/tensorflow/tensorflow/issues/11674</target>
        </trans-unit>
        <trans-unit id="991f940c882656d1963be8e5f9d6859e831fc269" translate="yes" xml:space="preserve">
          <source>The normalization to apply. &lt;code&gt;None&lt;/code&gt; for no normalization or &lt;code&gt;'ortho'&lt;/code&gt; for orthonormal normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c37a70332a45acca66a9732b1b0e6e1956e2217" translate="yes" xml:space="preserve">
          <source>The normalizer values with same shape as predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61b02be5d26057c5d50879cdbf7a93b5057253da" translate="yes" xml:space="preserve">
          <source>The number of batches in the Sequence.</source>
          <target state="translated">序列中的批次数。</target>
        </trans-unit>
        <trans-unit id="792c47def67649a01faf5dd32bfc0006287f5ca5" translate="yes" xml:space="preserve">
          <source>The number of bits for quantize training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e8251a908793c7f7ac158d55fc205bd7b475f75" translate="yes" xml:space="preserve">
          <source>The number of classes, &lt;code&gt;K&lt;/code&gt;, must not exceed:</source>
          <target state="translated">类数 &lt;code&gt;K&lt;/code&gt; 不得超过：</target>
        </trans-unit>
        <trans-unit id="a0b5ca9e1bc6804bae0a759249d34d9c89546684" translate="yes" xml:space="preserve">
          <source>The number of columns of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from &lt;code&gt;d_lower&lt;/code&gt;, &lt;code&gt;d_upper&lt;/code&gt;, and the innermost dimension of &lt;code&gt;diagonal&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d08b3ea9208738ea9c6ff069ba01794b88c8ec9" translate="yes" xml:space="preserve">
          <source>The number of consecutive elements to pull from an input &lt;code&gt;Dataset&lt;/code&gt; before advancing to the next input &lt;code&gt;Dataset&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26bbe52e7e5ab91d858fdf92eb9164c22baffaaa" translate="yes" xml:space="preserve">
          <source>The number of cores per replica.</source>
          <target state="translated">每个副本的核心数量。</target>
        </trans-unit>
        <trans-unit id="14a13b9b3afa611575c6fded44823e34fb935055" translate="yes" xml:space="preserve">
          <source>The number of decimal places to compare.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dc06462d30b8a2c0735ca8850d3a620b646263e" translate="yes" xml:space="preserve">
          <source>The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to &lt;code&gt;filters_in * depth_multiplier&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="973da0cb517d5a151fa65418511378c398a77944" translate="yes" xml:space="preserve">
          <source>The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to &lt;code&gt;num_filters_in * depth_multiplier&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1fb954517b208177e2433a3bd0d5008bff1f85f" translate="yes" xml:space="preserve">
          <source>The number of devices attached to this input pipeline. This will be automatically set by MultiDeviceIterator.</source>
          <target state="translated">连接到这个输入管道的设备数量。这将由MultiDeviceIterator自动设置。</target>
        </trans-unit>
        <trans-unit id="a4e68945735abb3b2e9d8c11a95d91c8a876e87a" translate="yes" xml:space="preserve">
          <source>The number of dimensions of the input tensors must match, and all dimensions except &lt;code&gt;axis&lt;/code&gt; must be equal.</source>
          <target state="translated">输入张量的维数必须匹配，除 &lt;code&gt;axis&lt;/code&gt; 外的所有维数必须相等。</target>
        </trans-unit>
        <trans-unit id="d8c231051c2a82603951bb4be6326674a1e8aa3c" translate="yes" xml:space="preserve">
          <source>The number of elements each iterator being interleaved should buffer (similar to the &lt;code&gt;.prefetch()&lt;/code&gt; transformation for each interleaved iterator).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c94708e0d399f895eb43d6150e45fd77b82a379" translate="yes" xml:space="preserve">
          <source>The number of elements in the file, if known.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b80ca01a0514c265b481f3eda4caaa27b83fdda1" translate="yes" xml:space="preserve">
          <source>The number of input &lt;code&gt;Dataset&lt;/code&gt;s to interleave from in parallel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e13e9c7600bcb73d445f6ddf6ab2c7a5b20cf4c7" translate="yes" xml:space="preserve">
          <source>The number of input elements to transform to iterators before they are needed for interleaving.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0eab278bde3870b804deae9229a39fcd34b7b41a" translate="yes" xml:space="preserve">
          <source>The number of iterations allowed to run in parallel. It must be a positive integer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="486c99e01cf220bcbab45ab943b6612bf5691de3" translate="yes" xml:space="preserve">
          <source>The number of out-of-vocabulary tokens to use; defaults to</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba07a119e82c4ff8c5cef8c905bb48f6f124a4db" translate="yes" xml:space="preserve">
          <source>The number of out-of-vocabulary values to use; defaults to</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a76e8c314c1da65707aae12379f6c7ff6a28dcd7" translate="yes" xml:space="preserve">
          <source>The number of parameters and number of multiply-adds can be modified by using the &lt;code&gt;alpha&lt;/code&gt; parameter, which increases/decreases the number of filters in each layer. By altering the image size and &lt;code&gt;alpha&lt;/code&gt; parameter, all 22 models from the paper can be built, with ImageNet weights provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="516b803f18d035a65572fcbdfc2900dc7b8d516a" translate="yes" xml:space="preserve">
          <source>The number of ragged dimensions in this ragged tensor value.</source>
          <target state="translated">这个粗糙的张量值中的粗糙维数。</target>
        </trans-unit>
        <trans-unit id="04f639280f7ec10513cb4839cfeda1135a578887" translate="yes" xml:space="preserve">
          <source>The number of ragged dimensions in this ragged tensor.</source>
          <target state="translated">这个粗糙的张量中的粗糙维数。</target>
        </trans-unit>
        <trans-unit id="87460175f8c6b31c8d362f42e4ca508e7497ab37" translate="yes" xml:space="preserve">
          <source>The number of replicas of the computation.</source>
          <target state="translated">计算的副本数。</target>
        </trans-unit>
        <trans-unit id="4ca03556aba7a6aedb5ec7bb5f557eed2de6bf50" translate="yes" xml:space="preserve">
          <source>The number of rows in the constructed RaggedTensor. If not specified, then it defaults to &lt;code&gt;nvals/uniform_row_length&lt;/code&gt; (or &lt;code&gt;0&lt;/code&gt; if &lt;code&gt;uniform_row_length==0&lt;/code&gt;). &lt;code&gt;nrows&lt;/code&gt; only needs to be specified if &lt;code&gt;uniform_row_length&lt;/code&gt; might be zero. &lt;code&gt;uniform_row_length*nrows&lt;/code&gt; must be &lt;code&gt;nvals&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ae2058fda59f914aa10436122a33d5b20b79d14" translate="yes" xml:space="preserve">
          <source>The number of rows of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from &lt;code&gt;d_lower&lt;/code&gt;, &lt;code&gt;d_upper&lt;/code&gt;, and the innermost dimension of &lt;code&gt;diagonal&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f95cc9deb1ad31a316d21a1000cc42bf6795a45d" translate="yes" xml:space="preserve">
          <source>The number of seconds the infeed thread should wait before enqueueing the first batch. This helps avoid timeouts for models that require a long compilation time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b14ac2c4857aac3f94fec3f43b6a18b61307e30" translate="yes" xml:space="preserve">
          <source>The number of shards.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feba654d8cbad0859a90722bb20fd89543e94016" translate="yes" xml:space="preserve">
          <source>The number of steps after which the updated cluster centers are synced back to a master copy. Used only if &lt;code&gt;use_mini_batch=True&lt;/code&gt;. See explanation above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="605dc8d4d33374c29a7f650a9b0f5eab0e0e6145" translate="yes" xml:space="preserve">
          <source>The number of tasks defined in the given job.</source>
          <target state="translated">给定工作中定义的任务数量。</target>
        </trans-unit>
        <trans-unit id="7bc399a4786dff1562b68cd701307e615fd2d911" translate="yes" xml:space="preserve">
          <source>The number of threads enqueuing &lt;code&gt;tensor_list&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f02da5b6da02a7c7e237c388ce04fe447f06fe0f" translate="yes" xml:space="preserve">
          <source>The number of threads enqueuing &lt;code&gt;tensors&lt;/code&gt;. The batching will be nondeterministic if &lt;code&gt;num_threads &amp;gt; 1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac616f1e962121eef44a63281771c333c773f02b" translate="yes" xml:space="preserve">
          <source>The number of thresholds to use for matching the given sensitivity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce3752ac0167d41dbccfee2db45c450ff2ae474a" translate="yes" xml:space="preserve">
          <source>The number of thresholds to use for matching the given specificity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e43e72ea1b04138c6081865e0dcfc5971740b57" translate="yes" xml:space="preserve">
          <source>The number of thresholds to use when discretizing the roc curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b04f07fa32838fddf785b03c8a08de5c2a3e8304" translate="yes" xml:space="preserve">
          <source>The number of times this should be called before it is logged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a2d5e323b8ac2af372dafbb2ccb4f737135220d" translate="yes" xml:space="preserve">
          <source>The numerics checking mechanism will cause any TensorFlow eager execution or graph execution to error out as soon as an op's output tensor contains infinity or NaN.</source>
          <target state="translated">数字检查机制将导致任何TensorFlow急于执行或图执行,只要一个op的输出张量包含无穷大或NaN,就会出错。</target>
        </trans-unit>
        <trans-unit id="625fd6a720c05ff0edaf547e1f7c698308bb3918" translate="yes" xml:space="preserve">
          <source>The numpy &lt;code&gt;ndarray&lt;/code&gt;, or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4302dccd839f803738d3151980944012f9528e1e" translate="yes" xml:space="preserve">
          <source>The numpy dtype of values in this tensor.</source>
          <target state="translated">这个张量值的numpy dtype。</target>
        </trans-unit>
        <trans-unit id="7a3478da2033233febed2c5abb6b940a69ae44f9" translate="yes" xml:space="preserve">
          <source>The object to look up.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4018ef2a9d807780c174adef5e5e353be6c00acd" translate="yes" xml:space="preserve">
          <source>The object whose attributes we want to modify.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10073c85f700d07cd9e27b920a2bb28c0e1e6aa0" translate="yes" xml:space="preserve">
          <source>The object will be registered under the key 'package&amp;gt;name' where &lt;code&gt;name&lt;/code&gt;, defaults to the object name if not passed.</source>
          <target state="translated">该对象将在&amp;ldquo; package&amp;gt; name&amp;rdquo;键下注册，其中 &lt;code&gt;name&lt;/code&gt; ，如果未传递，则默认为对象名。</target>
        </trans-unit>
        <trans-unit id="45d19e778f47f1e0cf9ddae2e351bf27f7263440" translate="yes" xml:space="preserve">
          <source>The old (deprecated) name for &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfeb840ee57e08986b18ad64fb148a52d19a3b93" translate="yes" xml:space="preserve">
          <source>The old (deprecated) name for axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceae2a98903e4e9554b3ffa1be72b116c87afeec" translate="yes" xml:space="preserve">
          <source>The one-hot tensor.</source>
          <target state="translated">的一热张量。</target>
        </trans-unit>
        <trans-unit id="2214e2794dfd82c41f2566b3dfe3c682d8ae3fc2" translate="yes" xml:space="preserve">
          <source>The only change you have to do to the single program code is to indicate if the program is running as the &lt;em&gt;chief&lt;/em&gt;.</source>
          <target state="translated">你所要做的单一程序代码的唯一变化是，以指示在程序运行的&lt;em&gt;首席&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="2ac713e042499abe0ad5ad2caf8a0b3b2c0f1068" translate="yes" xml:space="preserve">
          <source>The only difference with a regular &lt;code&gt;Session&lt;/code&gt; is that an &lt;code&gt;InteractiveSession&lt;/code&gt; installs itself as the default session on construction. The methods &lt;a href=&quot;../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../operation#run&quot;&gt;&lt;code&gt;tf.Operation.run&lt;/code&gt;&lt;/a&gt; will use that session to run ops.</source>
          <target state="translated">与常规 &lt;code&gt;Session&lt;/code&gt; 的唯一区别在于， &lt;code&gt;InteractiveSession&lt;/code&gt; 将自身安装为构造时的默认会话。&lt;a href=&quot;../../tensor#eval&quot;&gt; &lt;code&gt;tf.Tensor.eval&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;../../operation#run&quot;&gt; &lt;code&gt;tf.Operation.run&lt;/code&gt; &lt;/a&gt;方法将使用该会话来运行操作。</target>
        </trans-unit>
        <trans-unit id="31601f998aa3aad1333ec413e01d618a81800515" translate="yes" xml:space="preserve">
          <source>The only public method of a 'Flag' object is parse(), but it is typically only called by a 'FlagValues' object. The parse() method is a thin wrapper around the 'ArgumentParser' parse() method. The parsed value is saved in .value, and the .present attribute is updated. If this flag was already present, an Error is raised.</source>
          <target state="translated">'Flag'对象的唯一公共方法是 parse(),但它通常只被'FlagValues'对象调用。parse()方法是'ArgumentParser'parse()方法的一个薄包装器。解析后的值保存在.value中,并且更新.present属性。如果这个标志已经存在,就会产生一个Error。</target>
        </trans-unit>
        <trans-unit id="e1d57348a97b9a1a6578e16bf09a6e76a32d9952" translate="yes" xml:space="preserve">
          <source>The op also returns a count of how many entries in the new vocabulary were present in the old vocabulary, which is used to calculate the number of values to initialize in a weight matrix remapping</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a51ce2977b54408b0ebf05f943b7e7ef7f2b4b9" translate="yes" xml:space="preserve">
          <source>The op blocks until sufficient (i.e., more than num_required) gradients have been accumulated. If the accumulator has already aggregated more than num_required gradients, it returns the average of the accumulated gradients. Also automatically increments the recorded global_step in the accumulator by 1, and resets the aggregate to 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0ab6e564ddbe98c027618ff7ffc593086f5c97a" translate="yes" xml:space="preserve">
          <source>The op extracts fields from a serialized protocol buffers message into tensors.</source>
          <target state="translated">该操作将序列化协议缓冲区消息中的字段提取为时序器。</target>
        </trans-unit>
        <trans-unit id="4524786c0641258f1c43ff84a36d1e64fc7c7b2a" translate="yes" xml:space="preserve">
          <source>The op isn't guaranteed to raise an error if the input matrix is not invertible. &lt;a href=&quot;../debugging/check_numerics&quot;&gt;&lt;code&gt;tf.debugging.check_numerics&lt;/code&gt;&lt;/a&gt; can be applied to the output to detect invertibility problems.</source>
          <target state="translated">如果输入矩阵不可逆，则不能保证op会引发错误。可以将&lt;a href=&quot;../debugging/check_numerics&quot;&gt; &lt;code&gt;tf.debugging.check_numerics&lt;/code&gt; &lt;/a&gt;应用于输出以检测可逆性问题。</target>
        </trans-unit>
        <trans-unit id="7bd5e782cef1401f27f1a4ce3d8e792728deb240" translate="yes" xml:space="preserve">
          <source>The op name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03769badeb10027d149bea16946940ff275316cf" translate="yes" xml:space="preserve">
          <source>The op returns an error if no system is running.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb943cd0e3db6ad9fffc66a537388998786a4519" translate="yes" xml:space="preserve">
          <source>The op serializes protobuf messages provided in the input tensors.</source>
          <target state="translated">该操作将输入时序器中提供的protobuf信息序列化。</target>
        </trans-unit>
        <trans-unit id="b8b5527fcf850d5c166175ec39fd18231818c0f3" translate="yes" xml:space="preserve">
          <source>The op takes two lists, one of 2D &lt;code&gt;SparseTensor&lt;/code&gt; and one of 2D &lt;code&gt;Tensor&lt;/code&gt;, each representing features of one feature column. It outputs a 2D &lt;code&gt;SparseTensor&lt;/code&gt; with the batchwise crosses of these features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1331b377f4a8a3fc8082f77642e632d68fc16e64" translate="yes" xml:space="preserve">
          <source>The op to colocate all created ops with, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fc6099d0a9bbd2e8df15fdd3fb6314367cb02cc" translate="yes" xml:space="preserve">
          <source>The op to dequeue a token so the replicas can exit this batch and start the next one. This is executed by each replica.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4c5664cfd278d67f9bbf9eb0ae9656ce1cd8f8e" translate="yes" xml:space="preserve">
          <source>The op uses LU decomposition with partial pivoting to compute the inverses.</source>
          <target state="translated">op使用LU分解与部分枢轴来计算反演。</target>
        </trans-unit>
        <trans-unit id="cdf5001b31416df4d7ddde7f5a11360958f3382b" translate="yes" xml:space="preserve">
          <source>The op will blocks until sufficient (i.e., more than num_required) gradients have been accumulated. If the accumulator has already aggregated more than num_required gradients, it will return its average of the accumulated gradients. Also automatically increments the recorded global_step in the accumulator by 1, and resets the aggregate to 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47e700a39a6284fa854225b8729284d0f8f18e3a" translate="yes" xml:space="preserve">
          <source>The operation blocks until sufficient number of gradients have been successfully applied to the accumulator.</source>
          <target state="translated">在足够数量的梯度被成功应用于蓄能器之前,该操作会被阻止。</target>
        </trans-unit>
        <trans-unit id="8790d3057b1a7dc53661bb4f237b850fe1057d19" translate="yes" xml:space="preserve">
          <source>The operation casts &lt;code&gt;x&lt;/code&gt; (in case of &lt;code&gt;Tensor&lt;/code&gt;) or &lt;code&gt;x.values&lt;/code&gt; (in case of &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;IndexedSlices&lt;/code&gt;) to &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">操作管型 &lt;code&gt;x&lt;/code&gt; （在的情况下， &lt;code&gt;Tensor&lt;/code&gt; ）或 &lt;code&gt;x.values&lt;/code&gt; （在的情况下， &lt;code&gt;SparseTensor&lt;/code&gt; 或 &lt;code&gt;IndexedSlices&lt;/code&gt; ）至 &lt;code&gt;dtype&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="776fb3f15a3fb7bc8e3ba0841d38241b6b787b08" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Tensor#__add__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;add&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7306f5f9b2f16d84f1b9ff9bd10ca67995a18b69" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;tensor#__add__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;add&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="296ef5a55f3d72d1bc6447dffc6aa283d2bd9c3c" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;tensor#__eq__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;eq&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d125afae21f1524ca9020b80d01460cbb92b8a4d" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;tensor#__ne__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;ne&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93211cf6300703e21c3cdf804cff040a7b2a55a6" translate="yes" xml:space="preserve">
          <source>The operation logs a warning if we attempt to set to a time step that is lower than the accumulator's own time step.</source>
          <target state="translated">如果我们试图设置到比累加器本身的时间步长更低的时间步长,该操作会记录一个警告。</target>
        </trans-unit>
        <trans-unit id="ec87d8afa16231d11efcb471f5e52a7d2a894559" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">该操作必须在与调用&lt;a href=&quot;numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function()&lt;/code&gt; &lt;/a&gt;的Python程序相同的地址空间中运行。如果使用分布式TensorFlow，则必须在与调用&lt;a href=&quot;numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function&lt;/code&gt; &lt;/a&gt;的程序相同的过程中运行&lt;a href=&quot;distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt;，您必须将创建的操作固定到该服务器上的设备（例如， &lt;code&gt;with tf.device():&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="2eb160b49a8c0e9200d47f580c46000b2caec03e" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;py_func&quot;&gt;&lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;../../distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;py_func&quot;&gt;&lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt;&lt;/a&gt; and you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">该操作必须在与调用&lt;a href=&quot;py_func&quot;&gt; &lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt; &lt;/a&gt;的Python程序相同的地址空间中运行。如果使用分布式TensorFlow，则必须在与调用&lt;a href=&quot;py_func&quot;&gt; &lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt; &lt;/a&gt;的程序相同的过程中运行&lt;a href=&quot;../../distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt;，并且必须将创建的操作固定到该服务器上的设备（例如使用 &lt;code&gt;with tf.device():&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3cd48c99e2e66fcb5c484164b2f3d03eb702bcd9" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function()&lt;/code&gt;&lt;/a&gt; and you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">该操作必须在与调用&lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function()&lt;/code&gt; &lt;/a&gt;的Python程序相同的地址空间中运行。如果使用分布式TensorFlow，则必须在与调用&lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function()&lt;/code&gt; &lt;/a&gt;的程序相同的过程中运行&lt;a href=&quot;distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt;，并且必须将创建的操作固定到该服务器上的设备（例如， &lt;code&gt;with tf.device():&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="12a018d5761a73fb797a8185b603d78340c9da47" translate="yes" xml:space="preserve">
          <source>The operation of &lt;code&gt;raw_rnn&lt;/code&gt;, in pseudo-code, is basically the following:</source>
          <target state="translated">使用伪代码的 &lt;code&gt;raw_rnn&lt;/code&gt; 的操作基本上如下：</target>
        </trans-unit>
        <trans-unit id="666e744ea2e81d27484651c5a90d39fe7463b5f8" translate="yes" xml:space="preserve">
          <source>The operation returns the cardinality of &lt;code&gt;dataset&lt;/code&gt;. The operation may return &lt;a href=&quot;../experimental#INFINITE_CARDINALITY&quot;&gt;&lt;code&gt;tf.data.experimental.INFINITE_CARDINALITY&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;dataset&lt;/code&gt; contains an infinite number of elements or &lt;a href=&quot;../experimental#UNKNOWN_CARDINALITY&quot;&gt;&lt;code&gt;tf.data.experimental.UNKNOWN_CARDINALITY&lt;/code&gt;&lt;/a&gt; if the analysis fails to determine the number of elements in &lt;code&gt;dataset&lt;/code&gt; (e.g. when the dataset source is a file).</source>
          <target state="translated">该操作返回 &lt;code&gt;dataset&lt;/code&gt; 的基数。操作可以返回&lt;a href=&quot;../experimental#INFINITE_CARDINALITY&quot;&gt; &lt;code&gt;tf.data.experimental.INFINITE_CARDINALITY&lt;/code&gt; &lt;/a&gt;如果 &lt;code&gt;dataset&lt;/code&gt; 包含的元素或在无限多个&lt;a href=&quot;../experimental#UNKNOWN_CARDINALITY&quot;&gt; &lt;code&gt;tf.data.experimental.UNKNOWN_CARDINALITY&lt;/code&gt; &lt;/a&gt;如果分析失败，以确定元件的数量 &lt;code&gt;dataset&lt;/code&gt; （例如，当数据集源是一个文件）。</target>
        </trans-unit>
        <trans-unit id="b1aa4d33454ed3399a3f83fe0b47437e589dd1db" translate="yes" xml:space="preserve">
          <source>The operation supports data types (for &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt;) of &lt;code&gt;uint8&lt;/code&gt;, &lt;code&gt;uint16&lt;/code&gt;, &lt;code&gt;uint32&lt;/code&gt;, &lt;code&gt;uint64&lt;/code&gt;, &lt;code&gt;int8&lt;/code&gt;, &lt;code&gt;int16&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;int64&lt;/code&gt;, &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;, &lt;code&gt;bfloat16&lt;/code&gt;. In case of casting from complex types (&lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;) to real types, only the real part of &lt;code&gt;x&lt;/code&gt; is returned. In case of casting from real types to complex types (&lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;), the imaginary part of the returned value is set to &lt;code&gt;0&lt;/code&gt;. The handling of complex types here matches the behavior of numpy.</source>
          <target state="translated">操作支撑件的数据类型（ &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;dtype&lt;/code&gt; ）的 &lt;code&gt;uint8&lt;/code&gt; ， &lt;code&gt;uint16&lt;/code&gt; ， &lt;code&gt;uint32&lt;/code&gt; ， &lt;code&gt;uint64&lt;/code&gt; ， &lt;code&gt;int8&lt;/code&gt; ， &lt;code&gt;int16&lt;/code&gt; ， &lt;code&gt;int32&lt;/code&gt; ， &lt;code&gt;int64&lt;/code&gt; 类型， &lt;code&gt;float16&lt;/code&gt; ， &lt;code&gt;float32&lt;/code&gt; ， &lt;code&gt;float64&lt;/code&gt; ， &lt;code&gt;complex64&lt;/code&gt; ， &lt;code&gt;complex128&lt;/code&gt; ， &lt;code&gt;bfloat16&lt;/code&gt; 。如果将复杂类型（ &lt;code&gt;complex64&lt;/code&gt; ， &lt;code&gt;complex128&lt;/code&gt; ）转换为实数类型，则仅返回 &lt;code&gt;x&lt;/code&gt; 的实数部分。如果将实型转换为复杂类型（ &lt;code&gt;complex64&lt;/code&gt; ， &lt;code&gt;complex128&lt;/code&gt; ），则返回值的虚部设置为 &lt;code&gt;0&lt;/code&gt; 。这里对复杂类型的处理与numpy的行为相匹配。</target>
        </trans-unit>
        <trans-unit id="633cea8689c5cf5392fe403777889735793f4042" translate="yes" xml:space="preserve">
          <source>The operation that (conditionally) applies a gradient to the accumulator.</source>
          <target state="translated">(有条件地)对累加器施加梯度的操作。</target>
        </trans-unit>
        <trans-unit id="be412a34e6685ca321b38fae5794bdc3419b0f98" translate="yes" xml:space="preserve">
          <source>The operation that closes the queue.</source>
          <target state="translated">关闭队列的操作。</target>
        </trans-unit>
        <trans-unit id="b2e5f0ceeecca2686d84b94bc3fa75e7225fc1f4" translate="yes" xml:space="preserve">
          <source>The operation that enqueues a batch of tuples of tensors to the queue.</source>
          <target state="translated">操作,将一批元组的 tensors enqueues 到队列中。</target>
        </trans-unit>
        <trans-unit id="59123e207e4121d978f651d18670cf600162571e" translate="yes" xml:space="preserve">
          <source>The operation that enqueues a new tuple of tensors to the queue.</source>
          <target state="translated">将一个新的时序元组加入队列的操作。</target>
        </trans-unit>
        <trans-unit id="99898763428cef52c27daa776a42aecf7741168c" translate="yes" xml:space="preserve">
          <source>The operation that failed, if known.</source>
          <target state="translated">失败的操作,如果知道的话。</target>
        </trans-unit>
        <trans-unit id="99d34ac6542deab6f4080fc89f4db33d67017bad" translate="yes" xml:space="preserve">
          <source>The operation that implements the reader.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21259fcd1f38c739e8e877f9049101d45ed6faeb" translate="yes" xml:space="preserve">
          <source>The operation that initializes the table.</source>
          <target state="translated">初始化表格的操作。</target>
        </trans-unit>
        <trans-unit id="88d1101fb9e57b49ac3b0eb22875a3459c4f2b28" translate="yes" xml:space="preserve">
          <source>The operation that should be applied to the RaggedTensor &lt;code&gt;flat_values&lt;/code&gt;. &lt;code&gt;op&lt;/code&gt; is typically an element-wise operation (such as math_ops.add), but any operation that preserves the size of the outermost dimension can be used. I.e., &lt;code&gt;shape[0]&lt;/code&gt; of the value returned by &lt;code&gt;op&lt;/code&gt; must match &lt;code&gt;shape[0]&lt;/code&gt; of the &lt;code&gt;RaggedTensor&lt;/code&gt;s' &lt;code&gt;flat_values&lt;/code&gt; tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d4203f69addf4215a9f75fa10050cf92a106167" translate="yes" xml:space="preserve">
          <source>The operation was aborted, typically due to a concurrent action.</source>
          <target state="translated">该操作被中止,通常是由于同时发生的行动。</target>
        </trans-unit>
        <trans-unit id="182e7dce9af9390db25d63cce38f101933dc52f8" translate="yes" xml:space="preserve">
          <source>The operation works for the following input types:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d2fbee8f6406df6777f5eab458e89a6b6c00fa3" translate="yes" xml:space="preserve">
          <source>The operator before inversion.</source>
          <target state="translated">反转前的运营商。</target>
        </trans-unit>
        <trans-unit id="dca167c313a3afe14fe0a9adc69f0f5e8d1c9afb" translate="yes" xml:space="preserve">
          <source>The operator before taking the adjoint.</source>
          <target state="translated">运算器在取从句之前。</target>
        </trans-unit>
        <trans-unit id="dd77aed70dd9284b7d6c31fc643a9815d5df72eb" translate="yes" xml:space="preserve">
          <source>The optimization options associated with the dataset. See &lt;a href=&quot;experimental/optimizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">与数据集关联的优化选项。有关更多详细信息，请参见&lt;a href=&quot;experimental/optimizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d41bfab8487c080f4a52aaa4180a3c960ee957f3" translate="yes" xml:space="preserve">
          <source>The optimizer adds nodes to the graph to collect gradients and pause the trainers until variables are updated. For the Parameter Server job:</source>
          <target state="translated">优化器向图中添加节点以收集梯度并暂停训练器,直到变量更新。对于参数服务器工作。</target>
        </trans-unit>
        <trans-unit id="54fde7cedba37819ea597c67bd03d0eccd830d20" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;feed_dict&lt;/code&gt; argument allows the caller to override the value of tensors in the graph. Each key in &lt;code&gt;feed_dict&lt;/code&gt; can be one of the following types:</source>
          <target state="translated">可选的 &lt;code&gt;feed_dict&lt;/code&gt; 参数允许调用者覆盖图中的张量值。 &lt;code&gt;feed_dict&lt;/code&gt; 中的每个键可以是以下类型之一：</target>
        </trans-unit>
        <trans-unit id="802a640d90b4b6b27f2c21f94a40f0d9fba6af8f" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;feed_dict&lt;/code&gt; argument allows the caller to override the value of tensors in the graph. See run() for more information.</source>
          <target state="translated">可选的 &lt;code&gt;feed_dict&lt;/code&gt; 参数允许调用者覆盖图中的张量值。有关更多信息，请参见run（）。</target>
        </trans-unit>
        <trans-unit id="eacc79006fb44e1fd531dba67ace0548202f07d4" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;num_updates&lt;/code&gt; parameter allows one to tweak the decay rate dynamically. It is typical to pass the count of training steps, usually kept in a variable that is incremented at each step, in which case the decay rate is lower at the start of training. This makes moving averages move faster. If passed, the actual decay rate used is:</source>
          <target state="translated">可选的 &lt;code&gt;num_updates&lt;/code&gt; 参数允许用户动态调整衰减率。通常要传递训练步骤的数量，通常保持在每个步骤中递增的变量中，在这种情况下，衰减速率在训练开始时较低。这使移动平均线移动得更快。如果通过，则使用的实际衰减率是：</target>
        </trans-unit>
        <trans-unit id="4d5f2024e82b1f112cdc773a7a0d099d108bab47" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;options&lt;/code&gt; argument expects a [&lt;code&gt;RunOptions&lt;/code&gt;] proto. The options allow controlling the behavior of this particular step (e.g. turning tracing on).</source>
          <target state="translated">可选的 &lt;code&gt;options&lt;/code&gt; 参数需要一个[ &lt;code&gt;RunOptions&lt;/code&gt; ]原型。这些选项允许控制此特定步骤的行为（例如，打开跟踪）。</target>
        </trans-unit>
        <trans-unit id="5dd8b71d547dc1502ab3faa2f08ccf41ba7e8b18" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;reshape&lt;/code&gt; argument, if &lt;code&gt;True&lt;/code&gt;, allows restoring a variable from a save file where the variable had a different shape, but the same number of elements and type. This is useful if you have reshaped a variable and want to reload it from an older checkpoint.</source>
          <target state="translated">可选的 &lt;code&gt;reshape&lt;/code&gt; 参数，如果为 &lt;code&gt;True&lt;/code&gt; ，则允许从保存文件还原变量，该变量的形状不同，但是元素和类型的数量相同。如果您已经调整了变量的形状并想从较旧的检查点重新加载它，这将很有用。</target>
        </trans-unit>
        <trans-unit id="e970942946ff441e315a637342ca6559423698ca" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;run_metadata&lt;/code&gt; argument expects a [&lt;code&gt;RunMetadata&lt;/code&gt;] proto. When appropriate, the non-Tensor output of this step will be collected there. For example, when users turn on tracing in &lt;code&gt;options&lt;/code&gt;, the profiled info will be collected into this argument and passed back.</source>
          <target state="translated">可选的 &lt;code&gt;run_metadata&lt;/code&gt; 参数需要一个[ &lt;code&gt;RunMetadata&lt;/code&gt; ]原型。适当时，将在此收集此步骤的非Tensor输出。例如，当用户打开 &lt;code&gt;options&lt;/code&gt; 跟踪时，配置文件信息将收集到此参数中并传递回去。</target>
        </trans-unit>
        <trans-unit id="4463c9db10422ab0ce9fc83cbdf23e0b400b34c3" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;sharded&lt;/code&gt; argument, if &lt;code&gt;True&lt;/code&gt;, instructs the saver to shard checkpoints per device.</source>
          <target state="translated">可选的 &lt;code&gt;sharded&lt;/code&gt; 的说法，如果 &lt;code&gt;True&lt;/code&gt; ，指示保护每个设备碎片关卡。</target>
        </trans-unit>
        <trans-unit id="9211a71d92ea323063ffa11455da47bbb168e612" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;signatures&lt;/code&gt; argument controls which methods in &lt;code&gt;obj&lt;/code&gt; will be available to programs which consume &lt;code&gt;SavedModel&lt;/code&gt;s, for example serving APIs. Python functions may be decorated with &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; and passed as signatures directly, or lazily with a call to &lt;code&gt;get_concrete_function&lt;/code&gt; on the method decorated with &lt;code&gt;@tf.function&lt;/code&gt;.</source>
          <target state="translated">可选的 &lt;code&gt;signatures&lt;/code&gt; 参数控制 &lt;code&gt;obj&lt;/code&gt; 中的哪些方法可用于使用 &lt;code&gt;SavedModel&lt;/code&gt; 的程序，例如服务API。Python函数可以使用 &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; 并直接作为签名传递，或者通过 &lt;code&gt;@tf.function&lt;/code&gt; 修饰的方法对 &lt;code&gt;get_concrete_function&lt;/code&gt; 的调用来懒惰地传递。</target>
        </trans-unit>
        <trans-unit id="7b76c8215965b6d6548dad5cc3be42ab9b948c2e" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;signatures&lt;/code&gt; argument controls which methods in &lt;code&gt;obj&lt;/code&gt; will be available to programs which consume &lt;code&gt;SavedModel&lt;/code&gt;s, for example, serving APIs. Python functions may be decorated with &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; and passed as signatures directly, or lazily with a call to &lt;code&gt;get_concrete_function&lt;/code&gt; on the method decorated with &lt;code&gt;@tf.function&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5eb10eb93ba6242a60bc81190f01e4562cc7c7f2" translate="yes" xml:space="preserve">
          <source>The options are &quot;global&quot; in the sense they apply to the entire dataset. If options are set multiple times, they are merged as long as different options do not use different non-default values.</source>
          <target state="translated">这些选项是 &quot;全局 &quot;的,因为它们适用于整个数据集。如果选项被多次设置,只要不同的选项不使用不同的非默认值,它们就会被合并。</target>
        </trans-unit>
        <trans-unit id="839958c9eddae1511a49cbdd886b3f520fbec271" translate="yes" xml:space="preserve">
          <source>The order of output arguments here is &lt;code&gt;s&lt;/code&gt;, &lt;code&gt;u&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; when &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, as opposed to &lt;code&gt;u&lt;/code&gt;, &lt;code&gt;s&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; for numpy.linalg.svd.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3bc730bbfda16a7dd0623a512f8a88cc6217898" translate="yes" xml:space="preserve">
          <source>The original device on which &lt;code&gt;input_dataset&lt;/code&gt; will be placed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18d387209dd33fca87db5f4de4ba44e61656b7a9" translate="yes" xml:space="preserve">
          <source>The original input to &lt;a href=&quot;lu&quot;&gt;&lt;code&gt;tf.linalg.lu&lt;/code&gt;&lt;/a&gt;, i.e., &lt;code&gt;x&lt;/code&gt; as in, &lt;code&gt;lu_reconstruct(*tf.linalg.lu(x))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af401239a74cc22bb0656ceab277ae88265e81dd" translate="yes" xml:space="preserve">
          <source>The original method wrapped such that it enters the module's name scope.</source>
          <target state="translated">原方法包装后,使其进入模块的名称范围。</target>
        </trans-unit>
        <trans-unit id="f891d19803fb509490762be082d2f8ade6148c86" translate="yes" xml:space="preserve">
          <source>The original registered Flag objects can be retrieved through the use of the dictionary-like operator, &lt;strong&gt;getitem&lt;/strong&gt;: x = FLAGS['longname'] # access the registered Flag object</source>
          <target state="translated">可以使用类似于字典的运算符&lt;strong&gt;getitem&lt;/strong&gt;来检索原始注册的Flag对象：x = FLAGS ['longname']＃访问注册的Flag对象</target>
        </trans-unit>
        <trans-unit id="b71549bb8296bfb172b0e5fa059a19b9055f4136" translate="yes" xml:space="preserve">
          <source>The other method &lt;code&gt;uniform&lt;/code&gt; only covers the range [minval, maxval), which cannot be &lt;code&gt;dtype&lt;/code&gt;'s full range because &lt;code&gt;maxval&lt;/code&gt; is of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">另一种方法 &lt;code&gt;uniform&lt;/code&gt; 仅覆盖范围[MINVAL，MAXVAL），其不能是 &lt;code&gt;dtype&lt;/code&gt; 的全范围内，因为 &lt;code&gt;maxval&lt;/code&gt; 的类型为 &lt;code&gt;dtype&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8d650eca6a136e51fc7375e0969bc2ea1115b2e2" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; object's shape values for all dimensions but the first are the max across the input &lt;code&gt;SparseTensor&lt;/code&gt; objects' shape values for the corresponding dimensions. Its first shape value is &lt;code&gt;N&lt;/code&gt;, the minibatch size.</source>
          <target state="translated">所有维度的输出 &lt;code&gt;SparseTensor&lt;/code&gt; 对象的形状值，但第一个是相应维度的输入 &lt;code&gt;SparseTensor&lt;/code&gt; 对象的形状值的最大值。它的第一个形状值是 &lt;code&gt;N&lt;/code&gt; （最小批量大小）。</target>
        </trans-unit>
        <trans-unit id="f7899fd3a60fa39b01002b08a0bd2e514e0a6d60" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; object's shape values for the original dimensions are the max across the input &lt;code&gt;SparseTensor&lt;/code&gt; objects' shape values for the corresponding dimensions. The new dimensions match the size of the batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27cd935b967006cc01a667a4b3f9d0444d7da4c5" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; will be in row-major order and will have the same shape as the input.</source>
          <target state="translated">输出 &lt;code&gt;SparseTensor&lt;/code&gt; 将按行顺序排列，并具有与输入相同的形状。</target>
        </trans-unit>
        <trans-unit id="3ed7c320b010e6441e9928df89e4f8feea635e72" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;y&lt;/code&gt; has the same rank as &lt;code&gt;x&lt;/code&gt;. The shapes of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; satisfy: &lt;code&gt;y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac7bc3e3640548894477903c76a63029f0684b7b" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;y&lt;/code&gt; has the same rank as &lt;code&gt;x&lt;/code&gt;. The shapes of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; satisfy: &lt;code&gt;y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]&lt;/code&gt;&lt;code&gt;y[i,j,k,...,s,t,u] == conj(x[perm[i], perm[j], perm[k],...,perm[s], perm[t], perm[u]])&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25a24380035e136d9ea98af6a346f119051ef56c" translate="yes" xml:space="preserve">
          <source>The output Tensor as described above, dimensions will vary based on the op provided.</source>
          <target state="translated">如上所述的输出Tensor,尺寸将根据所提供的操作而变化。</target>
        </trans-unit>
        <trans-unit id="47c4d6134bd40a175fa44afa8f9b377d5850de3c" translate="yes" xml:space="preserve">
          <source>The output consists of two tensors LU and P containing the LU decomposition of all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;. LU encodes the lower triangular and upper triangular factors.</source>
          <target state="translated">输出由两个张量LU和P组成，其中包含所有输入子矩阵 &lt;code&gt;[..., :, :]&lt;/code&gt; 的LU分解。LU编码下三角和上三角因子。</target>
        </trans-unit>
        <trans-unit id="797ecd44b1fb4a552924484c7a55ad507593ed55" translate="yes" xml:space="preserve">
          <source>The output dtype; defaults to &lt;a href=&quot;../../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31482f2ff54a3aa8fae10ccd117f3f60685fed5f" translate="yes" xml:space="preserve">
          <source>The output dtype; defaults to &lt;a href=&quot;../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="048c6e1cfd308f6012ab77e90cbc674670b136c0" translate="yes" xml:space="preserve">
          <source>The output elements are taken from the input at intervals given by the &lt;code&gt;rate&lt;/code&gt; argument, as in dilated convolutions.</source>
          <target state="translated">输出元素按 &lt;code&gt;rate&lt;/code&gt; 参数给定的间隔从输入中获取，如膨胀卷积一样。</target>
        </trans-unit>
        <trans-unit id="01cfec4a29cc69f6abe94502062c73070782ab76" translate="yes" xml:space="preserve">
          <source>The output elements will be resorted to preserve the sort order along increasing dimension number.</source>
          <target state="translated">输出元素的排序顺序会随着维数的增加而保留。</target>
        </trans-unit>
        <trans-unit id="38c8f8944795768b987abf44161bc29810671bc1" translate="yes" xml:space="preserve">
          <source>The output is a tensor of rank &lt;code&gt;k+1&lt;/code&gt; with dimensions &lt;code&gt;[I, J, ..., L, M, N]&lt;/code&gt;. If &lt;code&gt;k&lt;/code&gt; is scalar or &lt;code&gt;k[0] == k[1]&lt;/code&gt;:</source>
          <target state="translated">输出是维数为 &lt;code&gt;[I, J, ..., L, M, N]&lt;/code&gt; 的等级 &lt;code&gt;k+1&lt;/code&gt; 的张量。如果 &lt;code&gt;k&lt;/code&gt; 是标量或 &lt;code&gt;k[0] == k[1]&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="b9f3b180f0596bc470d2fb79c1dedac7776f93d9" translate="yes" xml:space="preserve">
          <source>The output is a tensor of shape &lt;code&gt;[..., M, K]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the strictly then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;.</source>
          <target state="translated">输出是形状为 &lt;code&gt;[..., M, K]&lt;/code&gt; 的张量。如果 &lt;code&gt;adjoint&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ,则 &lt;code&gt;output&lt;/code&gt; 最里面的矩阵满足矩阵方程 &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt; 。如果 &lt;code&gt;adjoint&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; ,则 &lt;code&gt;output&lt;/code&gt; 的最里面矩阵严格满足矩阵方程 &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1488da1cb166b21e2e086e4e08f96c22ee229379" translate="yes" xml:space="preserve">
          <source>The output is a tensor of shape &lt;code&gt;[..., M, N]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the strictly then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6768fd2c3c792ee19a1c494dc0c8f3d25ef95d97" translate="yes" xml:space="preserve">
          <source>The output is a tensor of shape &lt;code&gt;[..., M, N]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in output satisfy matrix equations &lt;code&gt;sum_k matrix[..., i, k] * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the innermost matrices in output satisfy matrix equations &lt;code&gt;sum_k adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24258a9b3cf1537928d726a4c142766d14a612d5" translate="yes" xml:space="preserve">
          <source>The output is a tensor of the same shape as &lt;code&gt;rhs&lt;/code&gt;: either &lt;code&gt;[..., M]&lt;/code&gt; or &lt;code&gt;[..., M, K]&lt;/code&gt;.</source>
          <target state="translated">输出是与 &lt;code&gt;rhs&lt;/code&gt; 形状相同的张量： &lt;code&gt;[..., M]&lt;/code&gt; 或 &lt;code&gt;[..., M, K]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7d3db7f6f2ef07d73508fa555433bf8d83a75eaa" translate="yes" xml:space="preserve">
          <source>The output is a tensor of the same shape as the input containing the Cholesky decompositions for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">输出是与所有输入子矩阵 &lt;code&gt;[..., :, :]&lt;/code&gt; 包含Cholesky分解的输入具有相同形状的张量。</target>
        </trans-unit>
        <trans-unit id="6194740e93c206c46e0bfecd7aa22357ddec1b58" translate="yes" xml:space="preserve">
          <source>The output is computed as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b74ff8ee45b0b8f3cea227a5cb8b0ca2512e0fa1" translate="yes" xml:space="preserve">
          <source>The output is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02cc9038a532f36829ca3735f949f57712e9a776" translate="yes" xml:space="preserve">
          <source>The output locations corresponding to the implicitly zero elements in the sparse tensor will be zero (i.e., will not take up storage space), regardless of the contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).</source>
          <target state="translated">稀疏张量中隐含的零元素所对应的输出位置将为零(即不会占用存储空间),无论密张量的内容如何(即使它是+/-INF,并且INF*0 ==NaN)。</target>
        </trans-unit>
        <trans-unit id="4921b3c960168ec33230d0e2275991a2a480fee7" translate="yes" xml:space="preserve">
          <source>The output of &lt;a href=&quot;../compat/v1/estimator/estimator#evaluate&quot;&gt;&lt;code&gt;Estimator.evaluate&lt;/code&gt;&lt;/a&gt; on this checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b30d98674beeba8558b72dc407638d1340b74552" translate="yes" xml:space="preserve">
          <source>The output of the 1-arg function that takes the &lt;code&gt;step&lt;/code&gt; is &lt;code&gt;values[0]&lt;/code&gt; when &lt;code&gt;step &amp;lt;= boundaries[0]&lt;/code&gt;, &lt;code&gt;values[1]&lt;/code&gt; when &lt;code&gt;step &amp;gt; boundaries[0]&lt;/code&gt; and &lt;code&gt;step &amp;lt;= boundaries[1]&lt;/code&gt;, ..., and values[-1] when &lt;code&gt;step &amp;gt; boundaries[-1]&lt;/code&gt;.</source>
          <target state="translated">1-ARG函数，它接受所述的输出 &lt;code&gt;step&lt;/code&gt; 是 &lt;code&gt;values[0]&lt;/code&gt; 时 &lt;code&gt;step &amp;lt;= boundaries[0]&lt;/code&gt; ， &lt;code&gt;values[1]&lt;/code&gt; 时 &lt;code&gt;step &amp;gt; boundaries[0]&lt;/code&gt; 和 &lt;code&gt;step &amp;lt;= boundaries[1]&lt;/code&gt; ，...，当 &lt;code&gt;step &amp;gt; boundaries[-1]&lt;/code&gt; 时，则使用value [-1]和值。</target>
        </trans-unit>
        <trans-unit id="d04584f160db196293c2030ae17c2dacfbfcd30d" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../../../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;../../../image/draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="translated">该Op的输出是单个边界框，可用于裁剪原始图像。输出以3个张量返回： &lt;code&gt;begin&lt;/code&gt; ， &lt;code&gt;size&lt;/code&gt; 和 &lt;code&gt;bboxes&lt;/code&gt; 。前两个张量可以直接馈入&lt;a href=&quot;../../../slice&quot;&gt; &lt;code&gt;tf.slice&lt;/code&gt; &lt;/a&gt;以裁剪图像。后者可以提供给&lt;a href=&quot;../../../image/draw_bounding_boxes&quot;&gt; &lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt; &lt;/a&gt;以可视化边界框的外观。</target>
        </trans-unit>
        <trans-unit id="cc8ae412cea3a206e259aeb86af6654e659ed171" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;../image/draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e995a951ce7a3cd16e04e8cd70419e327350a30" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="translated">该Op的输出是单个边界框，可用于裁剪原始图像。输出以3个张量返回： &lt;code&gt;begin&lt;/code&gt; ， &lt;code&gt;size&lt;/code&gt; 和 &lt;code&gt;bboxes&lt;/code&gt; 。前两个张量可以直接馈入&lt;a href=&quot;../slice&quot;&gt; &lt;code&gt;tf.slice&lt;/code&gt; &lt;/a&gt;以裁剪图像。后者可以提供给&lt;a href=&quot;draw_bounding_boxes&quot;&gt; &lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt; &lt;/a&gt;以可视化边界框的外观。</target>
        </trans-unit>
        <trans-unit id="867a41c15dc52766b0de85d04ee44344a9063866" translate="yes" xml:space="preserve">
          <source>The output of this method is a 3D &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[batch_size, T, D]&lt;/code&gt;. &lt;code&gt;T&lt;/code&gt; is the maximum sequence length for this batch, which could differ from batch to batch.</source>
          <target state="translated">该方法的输出是 &lt;code&gt;[batch_size, T, D]&lt;/code&gt; 形状的3D &lt;code&gt;Tensor&lt;/code&gt; 。 &lt;code&gt;T&lt;/code&gt; 是该批次的最大序列长度，可能因批次而异。</target>
        </trans-unit>
        <trans-unit id="753b9e20d6aac1628ca75bf0511c387d43eb2530" translate="yes" xml:space="preserve">
          <source>The output of this operation is a set of integers indexing into the input collection of bounding boxes representing the selected boxes. The bounding box coordinates corresponding to the selected indices can then be obtained using the &lt;code&gt;tf.gather operation&lt;/code&gt;. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da6a14177a19f48147884875b20440b0d347e68f" translate="yes" xml:space="preserve">
          <source>The output shape is identical to the inputs', except along the concat dimension, where it is the sum of the inputs' sizes along that dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b30057b1110d4946855f0f7f77e28efcaa8cc94" translate="yes" xml:space="preserve">
          <source>The output shapes are compatible in a way that the first dimension of all tensors are the same and equal to the number of possible split nodes for each feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3907a316796c56324c363351b8f0ffb1dbcb1c06" translate="yes" xml:space="preserve">
          <source>The output signature of &lt;code&gt;fn&lt;/code&gt;. Must be specified if &lt;code&gt;fn&lt;/code&gt;'s input and output signatures are different (i.e., if their structures, dtypes, or tensor types do not match). &lt;code&gt;fn_output_signature&lt;/code&gt; can be specified using any of the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eac10a40d7ace5a75143c2fbccbd028ece77a9fb" translate="yes" xml:space="preserve">
          <source>The output slice &lt;code&gt;i&lt;/code&gt; along dimension &lt;code&gt;batch_axis&lt;/code&gt; is then given by input slice &lt;code&gt;i&lt;/code&gt;, with the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; slices along dimension &lt;code&gt;seq_axis&lt;/code&gt; reversed.</source>
          <target state="translated">沿维度 &lt;code&gt;batch_axis&lt;/code&gt; 的输出切片 &lt;code&gt;i&lt;/code&gt; 然后由输入切片 &lt;code&gt;i&lt;/code&gt; 给出，沿维度seq_axis的第一 &lt;code&gt;seq_lengths[i]&lt;/code&gt; 切片 &lt;code&gt;seq_axis&lt;/code&gt; 颠倒。</target>
        </trans-unit>
        <trans-unit id="b24ce3e8aaca6570e3ec8cec6e775f6c5f2c52dd" translate="yes" xml:space="preserve">
          <source>The output slice &lt;code&gt;i&lt;/code&gt; along dimension &lt;code&gt;batch_dim&lt;/code&gt; is then given by input slice &lt;code&gt;i&lt;/code&gt;, with the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; slices along dimension &lt;code&gt;seq_dim&lt;/code&gt; reversed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76e5d3d89821526e9a3ed69b0fc0e5605bddfe28" translate="yes" xml:space="preserve">
          <source>The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.logging.error are also supported. To print to a file, pass a string started with &quot;file://&quot; followed by the file path, e.g., &quot;file:///tmp/foo.out&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="098e1ce5365a1d1a1384c17c4ced06e659b0880f" translate="yes" xml:space="preserve">
          <source>The output subscripts must contain only labels appearing in at least one of the input subscripts. Furthermore, all dimensions mapping to the same axis label must be equal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0270145e0963e3fa6b4466fddef88fdbf60e481" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量具有形状 &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; 1、2、2、1 ]和值：</target>
        </trans-unit>
        <trans-unit id="aff644b1606cf977042c3f329c0b44912b343d5f" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量具有形状 &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt; 1、2、2、3 ]和值：</target>
        </trans-unit>
        <trans-unit id="26ecc2d485656620c8ddae36c3377b136f2c8ef6" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 4, 4, 1]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量具有形状 &lt;code&gt;[1, 4, 4, 1]&lt;/code&gt; 1、4、4、1 ]和值：</target>
        </trans-unit>
        <trans-unit id="413cce56d7e73e0557f6955da012eeb198f78207" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[2, 2, 4, 1]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量的形状为 &lt;code&gt;[2, 2, 4, 1]&lt;/code&gt; 2，2，4，1 ]，其值是：</target>
        </trans-unit>
        <trans-unit id="580524501d7754a464d140a489afd8a69565b7e8" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 1, 1, 1]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量的形状为 &lt;code&gt;[4, 1, 1, 1]&lt;/code&gt; 4，1，1，1 ]，其值是：</target>
        </trans-unit>
        <trans-unit id="43b93cea1c5beede2692779450404b22ddd16414" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 1, 1, 3]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量的形状为 &lt;code&gt;[4, 1, 1, 3]&lt;/code&gt; 4，1，1，3 ]，其值是：</target>
        </trans-unit>
        <trans-unit id="863590a97a6747705662d02c1d09d524c465ba85" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 2, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量具有形状 &lt;code&gt;[4, 2, 2, 1]&lt;/code&gt; 4，2，2，1 ]和值：</target>
        </trans-unit>
        <trans-unit id="951a2f1acb5ea54cd01c5c69fad552b3af0398ec" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[8, 1, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量的形状为 &lt;code&gt;[8, 1, 2, 1]&lt;/code&gt; 8，1，2，1 ]，其值是：</target>
        </trans-unit>
        <trans-unit id="b991f9c184601aa1cf79a030dce35cd2e1811686" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[8, 1, 3, 1]&lt;/code&gt; and value:</source>
          <target state="translated">输出张量的形状为 &lt;code&gt;[8, 1, 3, 1]&lt;/code&gt; 8，1，3，1 ]，其值是：</target>
        </trans-unit>
        <trans-unit id="8a7212b9117e06db921246aafe5499cc8ff0cedb" translate="yes" xml:space="preserve">
          <source>The output tensor is 2-D or higher with shape &lt;code&gt;[..., r_o, c_o]&lt;/code&gt;, where:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6dc975d4ffc27e7fe4b516c5e078460e61b472d" translate="yes" xml:space="preserve">
          <source>The output tensor is a tensor with dimensions described by 'size' whose values are extracted from 'input' starting at the offsets in 'begin'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="018a92a28c57571fe5c1edcfb924689c52abc4b8" translate="yes" xml:space="preserve">
          <source>The output tensor, of rank 3.</source>
          <target state="translated">输出张量,等级为3。</target>
        </trans-unit>
        <trans-unit id="1f5eef2e4414626524178eb10c4ab831f83220c9" translate="yes" xml:space="preserve">
          <source>The output tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f156d1cf6b13fd91d5c1751333de4bfa7481e5ec" translate="yes" xml:space="preserve">
          <source>The output tensors for the loop variables after the loop. If &lt;code&gt;return_same_structure&lt;/code&gt; is True, the return value has the same structure as &lt;code&gt;loop_vars&lt;/code&gt;. If &lt;code&gt;return_same_structure&lt;/code&gt; is False, the return value is a Tensor, TensorArray or IndexedSlice if the length of &lt;code&gt;loop_vars&lt;/code&gt; is 1, or a list otherwise.</source>
          <target state="translated">循环后循环变量的输出张量。如果 &lt;code&gt;return_same_structure&lt;/code&gt; 为True，则返回值具有与 &lt;code&gt;loop_vars&lt;/code&gt; 相同的结构。如果 &lt;code&gt;return_same_structure&lt;/code&gt; 是假，返回值是一个张量，TensorArray或IndexedSlice如果长度 &lt;code&gt;loop_vars&lt;/code&gt; 为1，或列表其他。</target>
        </trans-unit>
        <trans-unit id="0bda5fbd6b0783b500c1218ac7c4c0e7746a4905" translate="yes" xml:space="preserve">
          <source>The output tensors for the loop variables after the loop. The return value has the same structure as &lt;code&gt;loop_vars&lt;/code&gt;.</source>
          <target state="translated">循环后循环变量的输出张量。返回值与 &lt;code&gt;loop_vars&lt;/code&gt; 具有相同的结构。</target>
        </trans-unit>
        <trans-unit id="5a54d6c5881e40fdc200259b55b1119a1261f8a4" translate="yes" xml:space="preserve">
          <source>The output type (&lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt;). Default is &lt;a href=&quot;../tf#int32&quot;&gt;&lt;code&gt;tf.int32&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abf2d0fef772f974b83b58a081ba47917d2e0a4c" translate="yes" xml:space="preserve">
          <source>The output will be a 3x2 matrix:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bcada90c4c3eacc21413e8c1e200a0e90b07ffc" translate="yes" xml:space="preserve">
          <source>The output will then have shape &lt;code&gt;(32, 10, 32)&lt;/code&gt;.</source>
          <target state="translated">然后，输出将具有形状 &lt;code&gt;(32, 10, 32)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6d23cb786d0f9d1271884eaa7c1f7cc8c8a656c8" translate="yes" xml:space="preserve">
          <source>The output will then have shape &lt;code&gt;(32, 10, 8)&lt;/code&gt;.</source>
          <target state="translated">然后，输出将具有形状 &lt;code&gt;(32, 10, 8)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="95238fe986246430e838c38242139b3ddafc69a1" translate="yes" xml:space="preserve">
          <source>The output(s) of the model. See Functional API example below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25ae41f4c527c0741341a2f8b321fd1e43f0f98b" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt; and &lt;code&gt;seed&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="179a09c09a45e5c62e2dec3d73d951ec617567f3" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, &lt;code&gt;counts&lt;/code&gt;, and &lt;code&gt;probs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d94bca360c8d84e96136112086d8b12a0b843587" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, &lt;code&gt;minval&lt;/code&gt;, and &lt;code&gt;maxval&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94289abe2083c6f7cb75f0c826a60167f1e5c8a7" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, and &lt;code&gt;alpha&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="228f72119b53e369b51ce6a29a98f2313a7f281f" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, and &lt;code&gt;lam&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="262b53d310948dd3d4d6f3d1b24c8027dcc78d4c" translate="yes" xml:space="preserve">
          <source>The outputs from all shards are concatenated back together along their 0-th dimension.</source>
          <target state="translated">所有碎片的输出都沿其0-th维度连接在一起。</target>
        </trans-unit>
        <trans-unit id="fec5d02e1747f7a22db33ab6777959dc638f2020" translate="yes" xml:space="preserve">
          <source>The outputs of functions used as &lt;code&gt;signatures&lt;/code&gt; must either be flat lists, in which case outputs will be numbered, or a dictionary mapping string keys to &lt;code&gt;Tensor&lt;/code&gt;, in which case the keys will be used to name outputs.</source>
          <target state="translated">用作 &lt;code&gt;signatures&lt;/code&gt; 的函数的输出必须是平面列表（在这种情况下，输出将被编号），或者是将字符串键映射到 &lt;code&gt;Tensor&lt;/code&gt; 的字典，在这种情况下，键将用于命名输出。</target>
        </trans-unit>
        <trans-unit id="3777ae82c580b33611793d1c79fb38091c169efb" translate="yes" xml:space="preserve">
          <source>The package that this class belongs to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4fe37226e907ad6b84032ccb7a1a60c428d9656" translate="yes" xml:space="preserve">
          <source>The padded size of each dimension D of the output is:</source>
          <target state="translated">输出的每个维度D的填充大小为。</target>
        </trans-unit>
        <trans-unit id="a3493bda610bfabe1d614c17be7bea5bab6bc509" translate="yes" xml:space="preserve">
          <source>The padding algorithm, must be &quot;SAME&quot; or &quot;VALID&quot;. Defaults to &quot;SAME&quot;. See the &quot;returns&quot; section of &lt;a href=&quot;convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94a793cb35afefaa9825726cef177d5eba1c0835" translate="yes" xml:space="preserve">
          <source>The padding algorithm, must be &quot;SAME&quot; or &quot;VALID&quot;. See the &quot;returns&quot; section of &lt;a href=&quot;../../../nn/convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82cf1bc0ef022c1c7dcb21d0cd3cf77bf756e7b4" translate="yes" xml:space="preserve">
          <source>The paper demonstrates the performance of MobileNets using &lt;code&gt;alpha&lt;/code&gt; values of 1.0 (also called 100 % MobileNet), 0.35, 0.5, 0.75, 1.0, 1.3, and 1.4 For each of these &lt;code&gt;alpha&lt;/code&gt; values, weights for 5 different input image sizes are provided (224, 192, 160, 128, and 96).</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
