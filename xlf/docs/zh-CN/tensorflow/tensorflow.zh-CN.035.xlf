<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="4e9b8dff8aa28948209bf39777d987bf37ab6136" translate="yes" xml:space="preserve">
          <source>Module: tf.data.experimental.service</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="766ad7e416c498b2ad45f1539479e87b2c8d5486" translate="yes" xml:space="preserve">
          <source>Module: tf.debugging</source>
          <target state="translated">模块:tf.debugging</target>
        </trans-unit>
        <trans-unit id="3662ca6d115266110ff416dcda122a5c8db354e5" translate="yes" xml:space="preserve">
          <source>Module: tf.debugging.experimental</source>
          <target state="translated">模块:tf.debugging.experimental</target>
        </trans-unit>
        <trans-unit id="42ab2d51c874a01a2731eae41227e706868def0c" translate="yes" xml:space="preserve">
          <source>Module: tf.distribute</source>
          <target state="translated">模块:tf.distribution</target>
        </trans-unit>
        <trans-unit id="2cbf726f148c56874af97f386b0b519d325d72df" translate="yes" xml:space="preserve">
          <source>Module: tf.distribute.cluster_resolver</source>
          <target state="translated">模块:tf.distribution.cluster_resolver.</target>
        </trans-unit>
        <trans-unit id="70366e789bba19d6feb3d67b904cad32e1e7d9c4" translate="yes" xml:space="preserve">
          <source>Module: tf.distribute.experimental</source>
          <target state="translated">模块:tf.distribution.experimental</target>
        </trans-unit>
        <trans-unit id="281a9024b91d97c70d2db549561f82282a00df8d" translate="yes" xml:space="preserve">
          <source>Module: tf.dtypes</source>
          <target state="translated">模块:tf.dtypes</target>
        </trans-unit>
        <trans-unit id="38c88a2a2f5f6b2c20e9df570f34fa9654eee477" translate="yes" xml:space="preserve">
          <source>Module: tf.errors</source>
          <target state="translated">模块:tf.errors</target>
        </trans-unit>
        <trans-unit id="3bbc4967b6656ab968d00624174595595ccb50fd" translate="yes" xml:space="preserve">
          <source>Module: tf.estimator</source>
          <target state="translated">模块:TF.Estimator</target>
        </trans-unit>
        <trans-unit id="2ae056df054efc4b23d29890bf7956f3e3b0a994" translate="yes" xml:space="preserve">
          <source>Module: tf.estimator.experimental</source>
          <target state="translated">模块:TF.Estimator.Experimental。</target>
        </trans-unit>
        <trans-unit id="8d88340c9ef77961972c3661431612b1de354997" translate="yes" xml:space="preserve">
          <source>Module: tf.estimator.export</source>
          <target state="translated">模块:TF.估计器.导出</target>
        </trans-unit>
        <trans-unit id="7f4186a4343e9fc2e13e2473f4ebb587d280b204" translate="yes" xml:space="preserve">
          <source>Module: tf.experimental</source>
          <target state="translated">模块:tf.experimental</target>
        </trans-unit>
        <trans-unit id="ab8edf78584b8a8ab382a3eb71ceb6cf3bb13331" translate="yes" xml:space="preserve">
          <source>Module: tf.experimental.dlpack</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1927722bf45b4f025e40504d581575280527ab95" translate="yes" xml:space="preserve">
          <source>Module: tf.experimental.tensorrt</source>
          <target state="translated">模块:tf.experimental.tensorrt</target>
        </trans-unit>
        <trans-unit id="c98265df3417934b2a9662ce378c9445b0af3e55" translate="yes" xml:space="preserve">
          <source>Module: tf.feature_column</source>
          <target state="translated">模块:tf.feature_column</target>
        </trans-unit>
        <trans-unit id="8d551a79eeabc0ec2220a237168d1b3191533a4a" translate="yes" xml:space="preserve">
          <source>Module: tf.graph_util</source>
          <target state="translated">模块:tf.graph_util</target>
        </trans-unit>
        <trans-unit id="7c81f6aafc3be2a02e47c7e8a04aa42d6fbce37c" translate="yes" xml:space="preserve">
          <source>Module: tf.image</source>
          <target state="translated">模块:tf.image</target>
        </trans-unit>
        <trans-unit id="b560f84600bfafb56408243ffd6267af5ca37394" translate="yes" xml:space="preserve">
          <source>Module: tf.io</source>
          <target state="translated">模块:tf.io</target>
        </trans-unit>
        <trans-unit id="60e14ce155a4ec7de0d541d4788fc226feff1b6e" translate="yes" xml:space="preserve">
          <source>Module: tf.io.gfile</source>
          <target state="translated">模块:tf.io.gfile</target>
        </trans-unit>
        <trans-unit id="62b34493fbbb808c3c13a7d66697935a260c1d42" translate="yes" xml:space="preserve">
          <source>Module: tf.keras</source>
          <target state="translated">模块:tf.keras</target>
        </trans-unit>
        <trans-unit id="3a61a47190a2a94e7e078a9b9754db93d703db5f" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.activations</source>
          <target state="translated">模块:tf.keras.activations</target>
        </trans-unit>
        <trans-unit id="14b3200b3ce02f11e71deb01d53d00cdcb23be6b" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications</source>
          <target state="translated">模块:tf.keras.applications</target>
        </trans-unit>
        <trans-unit id="567859b8e6b20f15c063408009b9d3b1f59a397c" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.densenet</source>
          <target state="translated">模块:tf.keras.application.densenet</target>
        </trans-unit>
        <trans-unit id="d0ffb8b67228d7cb8eedc2070484b55c70a16459" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.efficientnet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5305b62aa6b9bda4e939c7bc78229c44f1a412fe" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.imagenet_utils</source>
          <target state="translated">模块:tf.keras.applications.imagenet_utils</target>
        </trans-unit>
        <trans-unit id="474e492770d8f4ef84237ecf1ea769e5e8d33772" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.inception_resnet_v2</source>
          <target state="translated">模块:tf.keras.application.inception_resnet_v2</target>
        </trans-unit>
        <trans-unit id="88586f0164ef1713c98e0494dfb479e0f9ba2478" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.inception_v3</source>
          <target state="translated">模块:tf.keras.application.inception_v3</target>
        </trans-unit>
        <trans-unit id="0fdb9f23452dc85d72188aad5a7a8c483a448880" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.mobilenet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="906b95627638ee8b0ffafd30d0315073171396df" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.mobilenet_v2</source>
          <target state="translated">模块:tf.keras.application.mobilenet_v2。</target>
        </trans-unit>
        <trans-unit id="1a1f15ca3b373b9ab951be4f17d1174c4245d269" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.nasnet</source>
          <target state="translated">模块:tf.keras.application.nasnet</target>
        </trans-unit>
        <trans-unit id="6e20ad5f8ef73ac960c70c5f444f5d63811ea18a" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.resnet</source>
          <target state="translated">模块:tf.keras.application.resnet</target>
        </trans-unit>
        <trans-unit id="7a5fe6ad985b656706be519ea1c7a91a40d48c66" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.resnet50</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23a827b62d4a35c11772230156a50c6de318c694" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.resnet_v2</source>
          <target state="translated">模块:tf.keras.applications.resnet_v2</target>
        </trans-unit>
        <trans-unit id="3a10427d4ca1b148ad22f5d3734b3d803aedda69" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.vgg16</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1e84c1b02989cc6111aeca1738c294446068e48" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.vgg19</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf2e2bfd56816a4fdd14d08fa391ef6211b43ab5" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.applications.xception</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de4f7df51d3bb0a535310ba3728c0a442cc6f9f5" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.backend</source>
          <target state="translated">模块:tf.keras.backend</target>
        </trans-unit>
        <trans-unit id="4606dd70d37e074e5c55431ef4b0509d92b55f47" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.callbacks</source>
          <target state="translated">模块:tf.keras.callbacks</target>
        </trans-unit>
        <trans-unit id="b3b2823ba371c7d47e4487628f57ad6bc279274d" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.callbacks.experimental</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1713b2b7ca316d37827a0a64c6c166d066c1cdd0" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.constraints</source>
          <target state="translated">模块:tf.keras.constraints</target>
        </trans-unit>
        <trans-unit id="01a2f0667f9165efb48a4767505a1dc1238373e1" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets</source>
          <target state="translated">模块:tf.keras.datasets</target>
        </trans-unit>
        <trans-unit id="9f2f6fcaccf555783797ccdc6e6cf6b2c10b69d2" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets.boston_housing</source>
          <target state="translated">模块:TF.Keras.datasets.Boston_housing。</target>
        </trans-unit>
        <trans-unit id="503eddfc1727595d16538481f430d553862ba952" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets.cifar10</source>
          <target state="translated">模块:TF.Keras.datasets.cifar10</target>
        </trans-unit>
        <trans-unit id="73006b80f912c388c804efbfaaac9316bda9b124" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets.cifar100</source>
          <target state="translated">模块:TF.Keras.datasets.cifar100</target>
        </trans-unit>
        <trans-unit id="35b228e67fefe320c4ab05851847b969ff8a6e30" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets.fashion_mnist</source>
          <target state="translated">模块:tf.keras.datasets.fashion_mnist。</target>
        </trans-unit>
        <trans-unit id="e5224aa650c87521ea851cae6a48ec70fa79b12c" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets.imdb</source>
          <target state="translated">模块:tf.keras.datasets.imdb</target>
        </trans-unit>
        <trans-unit id="5bcee1b17559b0f2d444ff18b60c2ded6e985a41" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets.mnist</source>
          <target state="translated">模块:tf.keras.datasets.mnist。</target>
        </trans-unit>
        <trans-unit id="fc13a4aaab7a435576bb20a428a0e0e7625fa554" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.datasets.reuters</source>
          <target state="translated">模块:tf.keras.datasets.reuters</target>
        </trans-unit>
        <trans-unit id="ad48630c5fe4cf5ba85fd2c66797a28f3d8f6556" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.estimator</source>
          <target state="translated">模块:TF.Keras.Estimator</target>
        </trans-unit>
        <trans-unit id="56723e70ca1141c75ef1b9c5141c1b5a3862ff46" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.experimental</source>
          <target state="translated">模块:tf.keras.experimental</target>
        </trans-unit>
        <trans-unit id="9783f6eb284db2c02e9a0d2f14ca7d2502d050ec" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.initializers</source>
          <target state="translated">模块:tf.keras.initializers</target>
        </trans-unit>
        <trans-unit id="12efd5c1e51067f555a06ea02d3e4a8a3223e377" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.layers</source>
          <target state="translated">模块:tf.keras.layer</target>
        </trans-unit>
        <trans-unit id="339b46aac7dddeb665b5da5377a2fc3aad9a5a0f" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.layers.experimental</source>
          <target state="translated">模块:tf.keras.layer.experimental。</target>
        </trans-unit>
        <trans-unit id="35902804ea971a2f79d6d663e15ebcfc7b1aad17" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.layers.experimental.preprocessing</source>
          <target state="translated">模块:tf.keras.layer.experimental.preprocessing。</target>
        </trans-unit>
        <trans-unit id="8efb58457fdb8b0875e0187a3e4b6fcbdc3abe32" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.losses</source>
          <target state="translated">模块:tf.keras.loses</target>
        </trans-unit>
        <trans-unit id="40ee695cd0c0dd67629b279a1a5626b34d9d5d55" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.metrics</source>
          <target state="translated">模块:tf.keras.metrics</target>
        </trans-unit>
        <trans-unit id="22c8dc31d809601650ca9cde67298dbdf2500ff9" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.mixed_precision</source>
          <target state="translated">模块:tf.keras.mixed_precision</target>
        </trans-unit>
        <trans-unit id="7d27299723378d48344fe00475a965c6bc4e51db" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.mixed_precision.experimental</source>
          <target state="translated">模块:tf.keras.mixed_precision.experimental。</target>
        </trans-unit>
        <trans-unit id="60ead6b4b5714de02be73a20b63c5e49f891a34e" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.models</source>
          <target state="translated">模块:tf.keras.models</target>
        </trans-unit>
        <trans-unit id="55b7358c3f927ca5891e368a85bbcecf0d4cb610" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.optimizers</source>
          <target state="translated">模块:tf.keras.optimizers</target>
        </trans-unit>
        <trans-unit id="a9038672f97393e68ee563dcc6b0ce88bd2ba073" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.optimizers.schedules</source>
          <target state="translated">模块:tf.keras.optimizers.schedules</target>
        </trans-unit>
        <trans-unit id="aad395d625636b1ef872968179c5f7201dce23b0" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.preprocessing</source>
          <target state="translated">模块:tf.keras.preprocessing</target>
        </trans-unit>
        <trans-unit id="985c9fe08beca20c3f19673219ee983ef85bbf5b" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.preprocessing.image</source>
          <target state="translated">模块:tf.keras.预处理.图像</target>
        </trans-unit>
        <trans-unit id="7a37c9eb542efa46d06e38ce16310629718dbfd4" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.preprocessing.sequence</source>
          <target state="translated">模块:tf.keras.preprocessing.sequence</target>
        </trans-unit>
        <trans-unit id="6231d0a30a2a478fce71ccd348d0697bb487b201" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.preprocessing.text</source>
          <target state="translated">模块:tf.keras.preprocessing.text</target>
        </trans-unit>
        <trans-unit id="65dd6eef3c3cb5b8ff3b9fb60720def29e446377" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.regularizers</source>
          <target state="translated">模块:tf.keras.regularizers</target>
        </trans-unit>
        <trans-unit id="f1d72276ba6bf622712254ba3239064c96074e21" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.utils</source>
          <target state="translated">模块:tf.keras.utils</target>
        </trans-unit>
        <trans-unit id="3a9176ec0f4a64ee0c4aeb11a203cb57236d34e5" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.wrappers</source>
          <target state="translated">模块:tf.keras.wrappers</target>
        </trans-unit>
        <trans-unit id="19ae98ecc591cfb3c55c94054ca0253abb4a67ed" translate="yes" xml:space="preserve">
          <source>Module: tf.keras.wrappers.scikit_learn</source>
          <target state="translated">模块:tf.keras.wrappers.scikit_learn</target>
        </trans-unit>
        <trans-unit id="f6a09751cdd7d0ca683af8797af26a7da516a42c" translate="yes" xml:space="preserve">
          <source>Module: tf.linalg</source>
          <target state="translated">模块:tf.linalg</target>
        </trans-unit>
        <trans-unit id="711f51d0d4a0332075b037ada7fe090c1c55fd8c" translate="yes" xml:space="preserve">
          <source>Module: tf.linalg.experimental</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9a98410327b7ab6ebee6d6ad4068aa8a28fa219" translate="yes" xml:space="preserve">
          <source>Module: tf.lite</source>
          <target state="translated">模块:tf.lite</target>
        </trans-unit>
        <trans-unit id="5119440e4b0902a2f9e3bc15934d20e8ad9b7d81" translate="yes" xml:space="preserve">
          <source>Module: tf.lite.experimental</source>
          <target state="translated">模块:tf.lite.experimental</target>
        </trans-unit>
        <trans-unit id="7ca3916d05c9fbfbc0a145bbbf629cf4ae123a85" translate="yes" xml:space="preserve">
          <source>Module: tf.lookup</source>
          <target state="translated">模块:tf.lookup</target>
        </trans-unit>
        <trans-unit id="d84cbf6de1c45d2e6c747bf381aeec29a6a0b5d3" translate="yes" xml:space="preserve">
          <source>Module: tf.lookup.experimental</source>
          <target state="translated">模块:tf.lookup.experimental</target>
        </trans-unit>
        <trans-unit id="52d57dd79174188f7fe06b0687c3990243a79ff5" translate="yes" xml:space="preserve">
          <source>Module: tf.math</source>
          <target state="translated">模块:tf.math</target>
        </trans-unit>
        <trans-unit id="17c76bad16151463019b9847960addc0bedeec0d" translate="yes" xml:space="preserve">
          <source>Module: tf.math.special</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b66b43861572f13ac464893a79fdcf54e9b18de7" translate="yes" xml:space="preserve">
          <source>Module: tf.mixed_precision</source>
          <target state="translated">模块:tf.mixed_precision(混合精度)</target>
        </trans-unit>
        <trans-unit id="51e6e7b40c893c3bc63952e418a3440bf54f704f" translate="yes" xml:space="preserve">
          <source>Module: tf.mixed_precision.experimental</source>
          <target state="translated">模块:tf.mixed_precision.experimental.</target>
        </trans-unit>
        <trans-unit id="75c1d0effa8b127f48fd78fc5bca665e58934c86" translate="yes" xml:space="preserve">
          <source>Module: tf.mlir</source>
          <target state="translated">模块:tf.mlir</target>
        </trans-unit>
        <trans-unit id="336b4a755085d14033d5449dddc58e38dfdbf7f6" translate="yes" xml:space="preserve">
          <source>Module: tf.mlir.experimental</source>
          <target state="translated">模块:tf.mlir.experimental</target>
        </trans-unit>
        <trans-unit id="51a9d8a37e17c143bd93aa0ccc757e06e1af7ade" translate="yes" xml:space="preserve">
          <source>Module: tf.nest</source>
          <target state="translated">模块:tf.nest</target>
        </trans-unit>
        <trans-unit id="308f774a13bc5bcd091757e998fb5dfaaa56d7e2" translate="yes" xml:space="preserve">
          <source>Module: tf.nn</source>
          <target state="translated">模块:tf.nn</target>
        </trans-unit>
        <trans-unit id="fb38ea5839c5db1f14412b0280a9de530e53005a" translate="yes" xml:space="preserve">
          <source>Module: tf.profiler</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f220abbdb31f834288ba07d8a4625c26d4039ce" translate="yes" xml:space="preserve">
          <source>Module: tf.profiler.experimental</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c553dad9435082345d56965e51416ce923d6c9ea" translate="yes" xml:space="preserve">
          <source>Module: tf.profiler.experimental.client</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2a7e100be6756b3368da94496c22032f2f635d8" translate="yes" xml:space="preserve">
          <source>Module: tf.profiler.experimental.server</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff66cd137efc0b592837d7f382cda8d23a8c0458" translate="yes" xml:space="preserve">
          <source>Module: tf.quantization</source>
          <target state="translated">模块:tf.quantization</target>
        </trans-unit>
        <trans-unit id="a5d2f6a05dcf42c93a1f07948e678709b7cc0e8a" translate="yes" xml:space="preserve">
          <source>Module: tf.queue</source>
          <target state="translated">模块:tf.queue</target>
        </trans-unit>
        <trans-unit id="94ac524bcde758f5bfea5267b7b4c63e40c1d6f3" translate="yes" xml:space="preserve">
          <source>Module: tf.ragged</source>
          <target state="translated">模块:tf.ragged</target>
        </trans-unit>
        <trans-unit id="226d63c95bf2ae9b78aced830fec359e36584f39" translate="yes" xml:space="preserve">
          <source>Module: tf.random</source>
          <target state="translated">模块:tf.random</target>
        </trans-unit>
        <trans-unit id="1e0e97b20a3b3fa5545bb1e397b444ba7b0717cc" translate="yes" xml:space="preserve">
          <source>Module: tf.random.experimental</source>
          <target state="translated">模块:tf.random.experimental</target>
        </trans-unit>
        <trans-unit id="e333a461f8ee0f7824177b27fe5ce02567ee6bac" translate="yes" xml:space="preserve">
          <source>Module: tf.raw_ops</source>
          <target state="translated">模块:tf.raw_ops</target>
        </trans-unit>
        <trans-unit id="4d2720dd4551b2bb04c91df53a6f8f1ec743f39d" translate="yes" xml:space="preserve">
          <source>Module: tf.saved_model</source>
          <target state="translated">模块:tf.saved_model</target>
        </trans-unit>
        <trans-unit id="7fea0e8b66bfdf6f75962dca2a09e7ea39f49692" translate="yes" xml:space="preserve">
          <source>Module: tf.sets</source>
          <target state="translated">模块:tf.set</target>
        </trans-unit>
        <trans-unit id="65ad550a8957e484267d822d2d8a9cda6c822225" translate="yes" xml:space="preserve">
          <source>Module: tf.signal</source>
          <target state="translated">模块:tf.signal</target>
        </trans-unit>
        <trans-unit id="807427894dd22d64865c126b6fc7c2578032f08a" translate="yes" xml:space="preserve">
          <source>Module: tf.sparse</source>
          <target state="translated">模块:tf.sparse</target>
        </trans-unit>
        <trans-unit id="5948e3907dac1b5644b5da46255b0cf41abc32c8" translate="yes" xml:space="preserve">
          <source>Module: tf.strings</source>
          <target state="translated">模块:tf.strings</target>
        </trans-unit>
        <trans-unit id="1a6f9cb1c84e11bb46d5c4383df1a28f7804aa69" translate="yes" xml:space="preserve">
          <source>Module: tf.summary</source>
          <target state="translated">模块:tf.summary</target>
        </trans-unit>
        <trans-unit id="b1c7577e5d0e367dd0ec3d0fe650c7ad6dc3802d" translate="yes" xml:space="preserve">
          <source>Module: tf.summary.experimental</source>
          <target state="translated">模块:tf.summary.experimental</target>
        </trans-unit>
        <trans-unit id="65d423b3ca5d7b85844cbf9b078f1f14f21b4c85" translate="yes" xml:space="preserve">
          <source>Module: tf.sysconfig</source>
          <target state="translated">模块:tf.sysconfig</target>
        </trans-unit>
        <trans-unit id="61f527c0dffced0aa9924d1494a52b8948a6a9a5" translate="yes" xml:space="preserve">
          <source>Module: tf.test</source>
          <target state="translated">模块:tf.test</target>
        </trans-unit>
        <trans-unit id="aee07cdc435c48724ac75e5ca0a4dd08092ac8a3" translate="yes" xml:space="preserve">
          <source>Module: tf.tpu</source>
          <target state="translated">模块:TF.TPU</target>
        </trans-unit>
        <trans-unit id="f40f06cd3dafa7bff6b8f933fbd23c9db48a3489" translate="yes" xml:space="preserve">
          <source>Module: tf.tpu.experimental</source>
          <target state="translated">模块:tf.tpu.experimental</target>
        </trans-unit>
        <trans-unit id="87fd50d5ddb622d057f574c801089263f3f07cc9" translate="yes" xml:space="preserve">
          <source>Module: tf.tpu.experimental.embedding</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2511a0f8e062acd4fff1a29bd2c7cb37f191a85f" translate="yes" xml:space="preserve">
          <source>Module: tf.train</source>
          <target state="translated">模块:tf.train</target>
        </trans-unit>
        <trans-unit id="4cfc4bc046001b910fd7e9757e1d6791e4c7a836" translate="yes" xml:space="preserve">
          <source>Module: tf.train.experimental</source>
          <target state="translated">模块:tf.train.experimental</target>
        </trans-unit>
        <trans-unit id="e16b7d340e90a15775f83f89ac253213909d08ec" translate="yes" xml:space="preserve">
          <source>Module: tf.version</source>
          <target state="translated">模块:tf.version</target>
        </trans-unit>
        <trans-unit id="77c50e0c68b7601b4ca6968d9f5e444040af7025" translate="yes" xml:space="preserve">
          <source>Module: tf.xla</source>
          <target state="translated">模块:tf.xla</target>
        </trans-unit>
        <trans-unit id="806e6f0af5a535da0d1411d128810f02bc22ff67" translate="yes" xml:space="preserve">
          <source>Module: tf.xla.experimental</source>
          <target state="translated">模块:tf.xla.experimental</target>
        </trans-unit>
        <trans-unit id="04e9462c0ff02bb9032b92abd45881a3c7e15fb7" translate="yes" xml:space="preserve">
          <source>Modules</source>
          <target state="translated">Modules</target>
        </trans-unit>
        <trans-unit id="dc618687f6b0b9c9b34a9e7ee609b35c04820985" translate="yes" xml:space="preserve">
          <source>Momentum for the moving average.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7713c3e7c0b47e633a062338bb41eebdbdb34515" translate="yes" xml:space="preserve">
          <source>Momentum used to update the moving means and standard deviations with renorm. Unlike &lt;code&gt;momentum&lt;/code&gt;, this affects training and should be neither too small (which would add noise) nor too large (which would give stale estimates). Note that &lt;code&gt;momentum&lt;/code&gt; is still applied to get the means and variances for inference.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d1217d8eb2ce02780571a3a5cce351f01e73a2a" translate="yes" xml:space="preserve">
          <source>Monitors the loss tensor and stops training if loss is NaN.</source>
          <target state="translated">监控损失张量,如果损失为NaN,则停止训练。</target>
        </trans-unit>
        <trans-unit id="cc2cda5246e2a84d564ee453b3dab66f0d7e61ed" translate="yes" xml:space="preserve">
          <source>Monotonically increasing sequence of &lt;code&gt;num_spatial_dims&lt;/code&gt; integers (which are &amp;gt;= 1) specifying the spatial dimensions of &lt;code&gt;input&lt;/code&gt; and output. Defaults to: &lt;code&gt;range(1, num_spatial_dims+1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08965269be31a1f77226663d4b16152886fa2985" translate="yes" xml:space="preserve">
          <source>More examples:</source>
          <target state="translated">更多的例子。</target>
        </trans-unit>
        <trans-unit id="7eca691c96a6c73420f0814fa97ed710f8916fb4" translate="yes" xml:space="preserve">
          <source>More formally, let</source>
          <target state="translated">更正式地说,让</target>
        </trans-unit>
        <trans-unit id="67687fbbfa5b35f0206bb307d17182c160ee9340" translate="yes" xml:space="preserve">
          <source>More information about SavedModel and signatures can be found here: &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md&quot;&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6df85f59a780af302cc4c65ad2ae971b93b79625" translate="yes" xml:space="preserve">
          <source>More information about SavedModel and signatures can be found here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md.</source>
          <target state="translated">关于SavedModel和签名的更多信息可以在这里找到:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md。</target>
        </trans-unit>
        <trans-unit id="6ecf714381162b0b5997018ef32b76d0a0ef35aa" translate="yes" xml:space="preserve">
          <source>More information about cuDNN can be found on the &lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;NVIDIA developer website&lt;/a&gt;. Can only be run on GPU.</source>
          <target state="translated">可以在&lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;NVIDIA开发人员网站&lt;/a&gt;上找到有关cuDNN的更多信息。只能在GPU上运行。</target>
        </trans-unit>
        <trans-unit id="1d92fd499d38c58885410121b45e11028258bb7d" translate="yes" xml:space="preserve">
          <source>More precisely, where &lt;a href=&quot;reduce_logsumexp&quot;&gt;&lt;code&gt;tf.math.reduce_logsumexp&lt;/code&gt;&lt;/a&gt; uses the following trick:</source>
          <target state="translated">更确切地说，在&lt;a href=&quot;reduce_logsumexp&quot;&gt; &lt;code&gt;tf.math.reduce_logsumexp&lt;/code&gt; &lt;/a&gt;使用以下技巧：</target>
        </trans-unit>
        <trans-unit id="4d39c130b6efea5237e9e9cf557b27d05adf32c9" translate="yes" xml:space="preserve">
          <source>More precisely: With probability &lt;code&gt;rate&lt;/code&gt; elements of &lt;code&gt;x&lt;/code&gt; are set to &lt;code&gt;0&lt;/code&gt;. The remaining elemenst are scaled up by &lt;code&gt;1.0 / (1 - rate)&lt;/code&gt;, so that the expected value is preserved.</source>
          <target state="translated">更精确地讲： &lt;code&gt;x&lt;/code&gt; 的概率 &lt;code&gt;rate&lt;/code&gt; 元素设置为 &lt;code&gt;0&lt;/code&gt; 。剩余元素按 &lt;code&gt;1.0 / (1 - rate)&lt;/code&gt; 放大，以便保留期望值。</target>
        </trans-unit>
        <trans-unit id="35e3f3895338a8d4e7b1b7a126049c16a43ffc21" translate="yes" xml:space="preserve">
          <source>More precisely: With probability &lt;code&gt;rate&lt;/code&gt; elements of &lt;code&gt;x&lt;/code&gt; are set to &lt;code&gt;0&lt;/code&gt;. The remaining elements are scaled up by &lt;code&gt;1.0 / (1 - rate)&lt;/code&gt;, so that the expected value is preserved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fd765d4b9a4d9102d8a4a364cc4e6758c048ff6" translate="yes" xml:space="preserve">
          <source>More specifically:</source>
          <target state="translated">更具体地说:</target>
        </trans-unit>
        <trans-unit id="460fa196449002a40abc9ebd910c8436ea57cd6c" translate="yes" xml:space="preserve">
          <source>More verbose logging is useful to enable when filing bug reports or doing more in-depth debugging.</source>
          <target state="translated">在提交错误报告或进行更深入的调试时,启用更详细的日志记录是很有用的。</target>
        </trans-unit>
        <trans-unit id="f73ce5d4d78b2a64ac869595355a54d06eacb14f" translate="yes" xml:space="preserve">
          <source>Most &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; methods may only be executed in a cross-replica context, in a replica context you should use the API of the &lt;a href=&quot;replicacontext&quot;&gt;&lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt;&lt;/a&gt; object returned by this method instead.</source>
          <target state="translated">大多数&lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;方法只能在跨副本上下文中执行，在副本上下文中，应使用此方法返回的&lt;a href=&quot;replicacontext&quot;&gt; &lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt; &lt;/a&gt;对象的API 。</target>
        </trans-unit>
        <trans-unit id="7f7dd2612e3255c926b529275b877b094ddd3a59" translate="yes" xml:space="preserve">
          <source>Most dataset input pipelines should end with a call to &lt;code&gt;prefetch&lt;/code&gt;. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.</source>
          <target state="translated">大多数数据集输入管道应以对 &lt;code&gt;prefetch&lt;/code&gt; 的调用结束。这允许在处理当前元素时准备后面的元素。这通常会提高延迟和吞吐量，但以使用额外的内存存储预取元素为代价。</target>
        </trans-unit>
        <trans-unit id="582df1cfd3ab64b57b645cc1cc784c2d4bcf5001" translate="yes" xml:space="preserve">
          <source>Most operations produce tensors of fully-known shapes if the shapes of their inputs are also fully known, but in some cases it's only possible to find the shape of a tensor at execution time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99e95db046870f238aa86e26d2ccffd1b1eef433" translate="yes" xml:space="preserve">
          <source>Most users should use one of the wrapper initializers (such as &lt;code&gt;tf.contrib.framework.load_and_remap_matrix_initializer&lt;/code&gt;) instead of this function directly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d29a735e0a5e68a47bd783dc12341f2f408ce6a1" translate="yes" xml:space="preserve">
          <source>Most users will also want to call &lt;a href=&quot;../train/create_global_step&quot;&gt;&lt;code&gt;tf.compat.v1.train.create_global_step&lt;/code&gt;&lt;/a&gt; which can happen before or after this function is called.</source>
          <target state="translated">大多数用户还希望调用&lt;a href=&quot;../train/create_global_step&quot;&gt; &lt;code&gt;tf.compat.v1.train.create_global_step&lt;/code&gt; &lt;/a&gt;，该操作可以在调用此函数之前或之后发生。</target>
        </trans-unit>
        <trans-unit id="b0eccc945bc9774c76c8755832329a850ce0ce3d" translate="yes" xml:space="preserve">
          <source>Mostly equivalent to numpy.linalg.norm. Not supported: ord &amp;lt;= 0, 2-norm for matrices, nuclear norm. Other differences: a) If axis is &lt;code&gt;None&lt;/code&gt;, treats the flattened &lt;code&gt;tensor&lt;/code&gt; as a vector regardless of rank. b) Explicitly supports 'euclidean' norm as the default, including for higher order tensors.</source>
          <target state="translated">主要等同于numpy.linalg.norm。不支持：ord &amp;lt;= 0，矩阵的2范数，核范数。其他区别：a）如果axis为 &lt;code&gt;None&lt;/code&gt; ，则将平化 &lt;code&gt;tensor&lt;/code&gt; 视为向量，而与等级无关。b）明确支持默认的&amp;ldquo;欧几里得&amp;rdquo;范式，包括高阶张量。</target>
        </trans-unit>
        <trans-unit id="a36c617e5e5b16937ee5d931f17c5522798355c4" translate="yes" xml:space="preserve">
          <source>Mostly equivalent to numpy.linalg.svd, except that</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6edca7a5606796b22a9f22f08c2d2b9f9851b51" translate="yes" xml:space="preserve">
          <source>Mostly equivalent to numpy.linalg.svd, except that * The order of output arguments here is &lt;code&gt;s&lt;/code&gt;, &lt;code&gt;u&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; when &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, as opposed to &lt;code&gt;u&lt;/code&gt;, &lt;code&gt;s&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; for numpy.linalg.svd. * full_matrices is &lt;code&gt;False&lt;/code&gt; by default as opposed to &lt;code&gt;True&lt;/code&gt; for numpy.linalg.svd. * tf.linalg.svd uses the standard definition of the SVD \(A = U \Sigma V^H\), such that the left singular vectors of &lt;code&gt;a&lt;/code&gt; are the columns of &lt;code&gt;u&lt;/code&gt;, while the right singular vectors of &lt;code&gt;a&lt;/code&gt; are the columns of &lt;code&gt;v&lt;/code&gt;. On the other hand, numpy.linalg.svd returns the adjoint \(V^H\) as the third output argument.</source>
          <target state="translated">晴相当于numpy.linalg.svd，除了*的输出参数的顺序这里是 &lt;code&gt;s&lt;/code&gt; ， &lt;code&gt;u&lt;/code&gt; ， &lt;code&gt;v&lt;/code&gt; 当 &lt;code&gt;compute_uv&lt;/code&gt; 是 &lt;code&gt;True&lt;/code&gt; ，而不是 &lt;code&gt;u&lt;/code&gt; ， &lt;code&gt;s&lt;/code&gt; ^， &lt;code&gt;v&lt;/code&gt; 为numpy.linalg.svd。 * 对于numpy.linalg.svd，full_matrices 默认为 &lt;code&gt;False&lt;/code&gt; ，而不是 &lt;code&gt;True&lt;/code&gt; 。 * tf.linalg.svd使用SVD \的标准清晰度（A = U \西格玛V 1 H \），使得左奇异向量 &lt;code&gt;a&lt;/code&gt; 是的列 &lt;code&gt;u&lt;/code&gt; ，而右奇异向量 &lt;code&gt;a&lt;/code&gt; 是列的 &lt;code&gt;v&lt;/code&gt; 。另一方面，numpy.linalg.svd返回伴随\（V ^ H \）作为第三个输出参数。</target>
        </trans-unit>
        <trans-unit id="bbd047da0be55151eb36335e2daf8007e4892af2" translate="yes" xml:space="preserve">
          <source>Much like Adam is essentially RMSprop with momentum, Nadam is Adam with Nesterov momentum.</source>
          <target state="translated">就像亚当本质上是带有动量的RMSprop,纳达姆是带有内斯特洛夫动量的亚当。</target>
        </trans-unit>
        <trans-unit id="84acd8bc955a67b3e57fc5d4e1f21da9ff4cd61d" translate="yes" xml:space="preserve">
          <source>Mul</source>
          <target state="translated">Mul</target>
        </trans-unit>
        <trans-unit id="b9c4453380be27e0c7b673c1b2471a06e39401ee" translate="yes" xml:space="preserve">
          <source>MulNoNan</source>
          <target state="translated">MulNoNan</target>
        </trans-unit>
        <trans-unit id="31407e66dc0e52cc1edbb37d05fa245bde93a717" translate="yes" xml:space="preserve">
          <source>Multi-Scale Context Aggregation by Dilated Convolutions: &lt;a href=&quot;https://arxiv.org/abs/1511.07122&quot;&gt;Yu et al., 2016&lt;/a&gt; (&lt;a href=&quot;https://arxiv.org/pdf/1511.07122.pdf&quot;&gt;pdf&lt;/a&gt;) Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs: &lt;a href=&quot;http://arxiv.org/abs/1412.7062&quot;&gt;Chen et al., 2015&lt;/a&gt; (&lt;a href=&quot;https://arxiv.org/pdf/1412.7062&quot;&gt;pdf&lt;/a&gt;) OverFeat - Integrated Recognition, Localization and Detection using Convolutional Networks: &lt;a href=&quot;https://arxiv.org/abs/1312.6229&quot;&gt;Sermanet et al., 2014&lt;/a&gt; (&lt;a href=&quot;https://arxiv.org/pdf/1312.6229.pdf&quot;&gt;pdf&lt;/a&gt;) Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks: &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/6738831&quot;&gt;Giusti et al., 2013&lt;/a&gt; (&lt;a href=&quot;https://arxiv.org/pdf/1302.1700.pdf&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25867a36c8cee72b523eb985d468821e9f148927" translate="yes" xml:space="preserve">
          <source>Multi-input usage:</source>
          <target state="translated">多输入使用。</target>
        </trans-unit>
        <trans-unit id="d05322a9f3c047910c102b74c67ec9b4d7c8028b" translate="yes" xml:space="preserve">
          <source>Multi-label classification handles the case where each example may have zero or more associated labels, from a discrete set. This is distinct from &lt;code&gt;MultiClassHead&lt;/code&gt; which has exactly one label per example.</source>
          <target state="translated">多标签分类处理每个示例可能具有零个或多个来自离散集合的关联标签的情况。这与 &lt;code&gt;MultiClassHead&lt;/code&gt; 不同，后者每个示例仅具有一个标签。</target>
        </trans-unit>
        <trans-unit id="3e6fa541d5398c3a673c1ac63d0c40e6406bb339" translate="yes" xml:space="preserve">
          <source>Multi-worker training with Estimator</source>
          <target state="translated">多工种培训与估算员</target>
        </trans-unit>
        <trans-unit id="4a5e1ae500bb7cdeea9988923f2efa5b06aaebe9" translate="yes" xml:space="preserve">
          <source>Multi-worker training with Keras</source>
          <target state="translated">Keras的多工种培训</target>
        </trans-unit>
        <trans-unit id="f9b50b83fb00e1501151357468bdc37000c2c097" translate="yes" xml:space="preserve">
          <source>MultiDeviceIterator</source>
          <target state="translated">MultiDeviceIterator</target>
        </trans-unit>
        <trans-unit id="f9fdef0a423aa3b78f43c2ac3d33d5f56cb9ef12" translate="yes" xml:space="preserve">
          <source>MultiDeviceIteratorFromStringHandle</source>
          <target state="translated">MultiDeviceIteratorFromStringHandle</target>
        </trans-unit>
        <trans-unit id="5e72c951a21e7652fd880f3cb2fdc5422ec9f943" translate="yes" xml:space="preserve">
          <source>MultiDeviceIteratorGetNextFromShard</source>
          <target state="translated">MultiDeviceIteratorGetNextFromShard</target>
        </trans-unit>
        <trans-unit id="aefe3e94f3b04fe818539e67aaff5effe9072f57" translate="yes" xml:space="preserve">
          <source>MultiDeviceIteratorInit</source>
          <target state="translated">MultiDeviceIteratorInit</target>
        </trans-unit>
        <trans-unit id="fb270f8549121b8fcc414bcba8009693590f3be9" translate="yes" xml:space="preserve">
          <source>MultiDeviceIteratorToStringHandle</source>
          <target state="translated">MultiDeviceIteratorToStringHandle</target>
        </trans-unit>
        <trans-unit id="4319c2711cce37df073896273f25e2e05b39cbdd" translate="yes" xml:space="preserve">
          <source>Multinomial</source>
          <target state="translated">Multinomial</target>
        </trans-unit>
        <trans-unit id="fa542a40b5540f372d928bad0d2990977695ad81" translate="yes" xml:space="preserve">
          <source>Multinomial distribution.</source>
          <target state="translated">多项分布。</target>
        </trans-unit>
        <trans-unit id="0e18692bd370f834d92f369dcf0d15e10b60c738" translate="yes" xml:space="preserve">
          <source>Multiple Ragged Dimensions</source>
          <target state="translated">多重锯齿尺寸</target>
        </trans-unit>
        <trans-unit id="562992811ea87dc609a5aaa3da8e6225fc1e034b" translate="yes" xml:space="preserve">
          <source>Multiple calls to &lt;code&gt;control_dependencies()&lt;/code&gt; can be nested, and in that case a new &lt;code&gt;Operation&lt;/code&gt; will have control dependencies on the union of &lt;code&gt;control_inputs&lt;/code&gt; from all active contexts.</source>
          <target state="translated">可以嵌套多次调用 &lt;code&gt;control_dependencies()&lt;/code&gt; ，在这种情况下，新的 &lt;code&gt;Operation&lt;/code&gt; 将对所有活动上下文中的 &lt;code&gt;control_inputs&lt;/code&gt; 的并集具有控件依赖性。</target>
        </trans-unit>
        <trans-unit id="60973512970131f46ebd77d688d5836d76340ac6" translate="yes" xml:space="preserve">
          <source>Multiplexing between &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31887cb569d1572c4168bf59aa0743cef6ef6cf0" translate="yes" xml:space="preserve">
          <source>Multiplicative factor to apply to the identity matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="824c2fff609ec3d94874ba050f77d853d1d165a2" translate="yes" xml:space="preserve">
          <source>Multiplies 2 tensors (and/or variables) and returns a &lt;em&gt;tensor&lt;/em&gt;.</source>
          <target state="translated">将2张量（和/或变量）相乘并返回&lt;em&gt;张量&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="007f4944d01599f67a440a706dc9dcf3e698774a" translate="yes" xml:space="preserve">
          <source>Multiplies 2 tensors (and/or variables) and returns a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d203061bc6d7cd80cb3cc679057951c296ee8aa4" translate="yes" xml:space="preserve">
          <source>Multiplies a scalar times a &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;IndexedSlices&lt;/code&gt; object.</source>
          <target state="translated">将标量乘以 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;IndexedSlices&lt;/code&gt; 对象。</target>
        </trans-unit>
        <trans-unit id="9e01d93409b600f63d41ee5ffb5186905a570d86" translate="yes" xml:space="preserve">
          <source>Multiplies all slices of &lt;code&gt;Tensor&lt;/code&gt;&lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; (each slice can be viewed as an element of a batch), and arranges the individual results in a single output tensor of the same batch size. Each of the individual slices can optionally be adjointed (to adjoint a matrix means to transpose and conjugate it) before multiplication by setting the &lt;code&gt;adj_x&lt;/code&gt; or &lt;code&gt;adj_y&lt;/code&gt; flag to &lt;code&gt;True&lt;/code&gt;, which are by default &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a27617a6cf526d8a5d4a069782ec117f36e5e98a" translate="yes" xml:space="preserve">
          <source>Multiplies matrix &lt;code&gt;a&lt;/code&gt; by matrix &lt;code&gt;b&lt;/code&gt;, producing &lt;code&gt;a&lt;/code&gt; * &lt;code&gt;b&lt;/code&gt;.</source>
          <target state="translated">将矩阵 &lt;code&gt;a&lt;/code&gt; 乘以矩阵 &lt;code&gt;b&lt;/code&gt; ，得到 &lt;code&gt;a&lt;/code&gt; * &lt;code&gt;b&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d2c82c98fa4cb4919387e141410545701b28bcb7" translate="yes" xml:space="preserve">
          <source>Multiplies matrix &lt;code&gt;a&lt;/code&gt; by vector &lt;code&gt;b&lt;/code&gt;, producing &lt;code&gt;a&lt;/code&gt; * &lt;code&gt;b&lt;/code&gt;.</source>
          <target state="translated">将矩阵 &lt;code&gt;a&lt;/code&gt; 与向量 &lt;code&gt;b&lt;/code&gt; 相乘，得到 &lt;code&gt;a&lt;/code&gt; * &lt;code&gt;b&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2a2d32e03c631cbb29b78b3e4b0848f80f8a418e" translate="yes" xml:space="preserve">
          <source>Multiplies slices of two tensors in batches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7fe462d932cc32436afe71eb8be4c2a382790ac" translate="yes" xml:space="preserve">
          <source>Multiplies sparse updates into a variable reference.</source>
          <target state="translated">将稀疏的更新乘以变量引用。</target>
        </trans-unit>
        <trans-unit id="c49abf45a68045ef042bcdf59db27205ca6c8a0a" translate="yes" xml:space="preserve">
          <source>Multiplies sparse updates into the variable referenced by &lt;code&gt;resource&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1dd3d0c16c907a98d4a8db0ba2dd37a67bb7f77" translate="yes" xml:space="preserve">
          <source>Multiplies the values in a tensor, alongside the specified axis.</source>
          <target state="translated">沿着指定的轴,将张量值相乘。</target>
        </trans-unit>
        <trans-unit id="b3908189000ccde8c1b0543f0f63d22e39436f6b" translate="yes" xml:space="preserve">
          <source>Multiplies tridiagonal matrix by matrix.</source>
          <target state="translated">将三边形矩阵乘以矩阵。</target>
        </trans-unit>
        <trans-unit id="c9230895f1414212a457175d41d4c27592e4da88" translate="yes" xml:space="preserve">
          <source>Multiply SparseTensor (of rank 2) &quot;A&quot; by dense matrix &quot;B&quot;.</source>
          <target state="translated">将SparseTensor(等级为2)&quot;A &quot;乘以密集矩阵 &quot;B&quot;。</target>
        </trans-unit>
        <trans-unit id="c3b8bb7157382bea6e99533cf6fbb07bc2cfaef3" translate="yes" xml:space="preserve">
          <source>Multiply SparseTensor (or dense Matrix) (of rank 2) &quot;A&quot; by dense matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abf828610480805dbb7cbd5ccd123f4353c11fe4" translate="yes" xml:space="preserve">
          <source>Multiply inputs by &lt;code&gt;scale&lt;/code&gt; and adds &lt;code&gt;offset&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fde029073f5a60f4cb9396422627b162b7f0f0d2" translate="yes" xml:space="preserve">
          <source>Multiply matrix &quot;a&quot; by matrix &quot;b&quot;.</source>
          <target state="translated">将矩阵 &quot;a &quot;乘以矩阵 &quot;b&quot;。</target>
        </trans-unit>
        <trans-unit id="dc76290c6e50aabfc95562c978c88bf4e079ca88" translate="yes" xml:space="preserve">
          <source>Multiply the matrix &quot;a&quot; by the matrix &quot;b&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2d1888d872bbe781f6582fc36890ae04953a5cf" translate="yes" xml:space="preserve">
          <source>Multiply this variable by &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">将此变量乘以&lt;a href=&quot;../../indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7e23a6d0ada7f1a33b06417960a582de3fe90fcb" translate="yes" xml:space="preserve">
          <source>Multiply this variable by &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">将此变量乘以&lt;a href=&quot;indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="fce0730f41e4926a271243e9d540e0468eb10cba" translate="yes" xml:space="preserve">
          <source>Multivalent categorical columns are not normalized. In other words the &lt;code&gt;sparse_combiner&lt;/code&gt; argument in the estimator constructor should be &quot;sum&quot;.</source>
          <target state="translated">多价分类列未规范化。换句话说，estimator构造函数中的 &lt;code&gt;sparse_combiner&lt;/code&gt; 参数应为&amp;ldquo; sum&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="3ef9edeb12e7bdb30fed6da3d9cad9ca56fc131d" translate="yes" xml:space="preserve">
          <source>Must be invoked in eager mode.</source>
          <target state="translated">必须在急切模式下调用。</target>
        </trans-unit>
        <trans-unit id="1e4bfced5dc6febd1b4f7fdec1eb20c3f4a60c7c" translate="yes" xml:space="preserve">
          <source>Must have &lt;code&gt;strides[0] = strides[3] = 1&lt;/code&gt;. For the most common case of the same horizontal and vertical strides, &lt;code&gt;strides = [1, stride, stride, 1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5bead550d70b3848380b69013e328ccadfac1c4" translate="yes" xml:space="preserve">
          <source>Must have &lt;code&gt;strides[0] = strides[3] = 1&lt;/code&gt;. For the most common case of the same horizontal and vertical strides, &lt;code&gt;strides = [1, stride, stride, 1]&lt;/code&gt;. If any value in &lt;code&gt;rate&lt;/code&gt; is greater than 1, we perform atrous depthwise convolution, in which case all values in the &lt;code&gt;strides&lt;/code&gt; tensor must be equal to 1.</source>
          <target state="translated">必须具有 &lt;code&gt;strides[0] = strides[3] = 1&lt;/code&gt; 。对于水平和垂直步幅相同的最常见情况， &lt;code&gt;strides = [1, stride, stride, 1]&lt;/code&gt; 。如果 &lt;code&gt;rate&lt;/code&gt; 中的任何值大于1，我们将执行无深度的深度卷积，在这种情况下， &lt;code&gt;strides&lt;/code&gt; 张量中的所有值必须等于1。</target>
        </trans-unit>
        <trans-unit id="3f54286532c883373748b3609c3f73f3626e66f1" translate="yes" xml:space="preserve">
          <source>Must have &lt;code&gt;strides[0] = strides[3] = 1&lt;/code&gt;. For the most common case of the same horizontal and vertices strides, &lt;code&gt;strides = [1, stride, stride, 1]&lt;/code&gt;.</source>
          <target state="translated">必须具有 &lt;code&gt;strides[0] = strides[3] = 1&lt;/code&gt; 。对于相同的水平和顶点步幅，在最常见的情况下， &lt;code&gt;strides = [1, stride, stride, 1]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bfccfdf0da7e16719add842526a9f32bdf0fb6a0" translate="yes" xml:space="preserve">
          <source>Mutable properties:</source>
          <target state="translated">可变属性。</target>
        </trans-unit>
        <trans-unit id="ded7dc276581a80ea0fbfd41fab047452c31822c" translate="yes" xml:space="preserve">
          <source>MutableDenseHashTable</source>
          <target state="translated">MutableDenseHashTable</target>
        </trans-unit>
        <trans-unit id="aab4ae6558171d7257b6dcc571fdc13fe1d8987e" translate="yes" xml:space="preserve">
          <source>MutableDenseHashTableV2</source>
          <target state="translated">MutableDenseHashTableV2</target>
        </trans-unit>
        <trans-unit id="d422e07341c0b31bf12e7cb2c78b237847aaccf2" translate="yes" xml:space="preserve">
          <source>MutableHashTable</source>
          <target state="translated">MutableHashTable</target>
        </trans-unit>
        <trans-unit id="244ed10c252ef4691478544861ec5b15a483ed54" translate="yes" xml:space="preserve">
          <source>MutableHashTableOfTensors</source>
          <target state="translated">MutableHashTableOfTensors</target>
        </trans-unit>
        <trans-unit id="2529966a6c55365e84942c643d02e956d271093a" translate="yes" xml:space="preserve">
          <source>MutableHashTableOfTensorsV2</source>
          <target state="translated">MutableHashTableOfTensorsV2</target>
        </trans-unit>
        <trans-unit id="f6616a12d1b435212719cf562ad905b61704da7b" translate="yes" xml:space="preserve">
          <source>MutableHashTableV2</source>
          <target state="translated">MutableHashTableV2</target>
        </trans-unit>
        <trans-unit id="59996b45ff3caee3123e82b1e4955126447c1c35" translate="yes" xml:space="preserve">
          <source>MutexLock</source>
          <target state="translated">MutexLock</target>
        </trans-unit>
        <trans-unit id="b818c4466cf332676512380f8cf5708c197cf2c6" translate="yes" xml:space="preserve">
          <source>MutexV2</source>
          <target state="translated">MutexV2</target>
        </trans-unit>
        <trans-unit id="6367f1f2da145af59759cf178785fc1adf128411" translate="yes" xml:space="preserve">
          <source>Mutually accumulates multiple tensors of identical type and shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="524d301917ba0a50bcc4830582da7f5221f85625" translate="yes" xml:space="preserve">
          <source>Mutually reduces multiple tensors of identical type and shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2db6d4239cd20837c3760914738b611e987aea46" translate="yes" xml:space="preserve">
          <source>N &lt;code&gt;gradient accumulators&lt;/code&gt;, one per variable to train. Gradients are pushed to them and the chief worker will wait until enough gradients are collected and then average them before applying to variables. The accumulator will drop all stale gradients (more details in the accumulator op).</source>
          <target state="translated">N个 &lt;code&gt;gradient accumulators&lt;/code&gt; ，每个变量训练一个。将渐变推向它们，首席工作人员将等到收集到足够的渐变后再对它们求平均，然后再应用于变量。累加器将丢弃所有过时的渐变（更多详细信息在累加器op中）。</target>
        </trans-unit>
        <trans-unit id="601342c23ed3a9dc69e9068d892e043cf7b620fb" translate="yes" xml:space="preserve">
          <source>N = 2, input[0] is 'hello world' and input[1] is 'a b c', then the output will be</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d2bd952f1c7effd6f2b36e12c5f6207364af23f" translate="yes" xml:space="preserve">
          <source>N is the size of the segment being reduced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="236a093f2847be051725becd4a56f5210c6de810" translate="yes" xml:space="preserve">
          <source>N x M &lt;code&gt;SparseTensor&lt;/code&gt; of int64 ids where N is typically batch size and M is arbitrary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c13758985d7df413ceff424231d4285baea2e419" translate="yes" xml:space="preserve">
          <source>N-D &lt;code&gt;SparseTensor&lt;/code&gt; representing the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32546e025d57b58896a627a9020c8304bdc77742" translate="yes" xml:space="preserve">
          <source>N-D &lt;code&gt;SparseTensor&lt;/code&gt;, where &lt;code&gt;N &amp;gt;= 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d84048302a72ddcb4fec9a73ca785abff24e80b8" translate="yes" xml:space="preserve">
          <source>N-D &lt;code&gt;Tensor&lt;/code&gt; containing a sorted sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f4c2945526e09d604a0ccc8a441967f07005ced" translate="yes" xml:space="preserve">
          <source>N-D &lt;code&gt;Tensor&lt;/code&gt; containing the search values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a083ef5352b5d650b2a079357a1f2ade54e8efbf" translate="yes" xml:space="preserve">
          <source>N-D tensor with shape &lt;code&gt;[batch_size, timesteps, ...]&lt;/code&gt; or &lt;code&gt;[timesteps, batch_size, ...]&lt;/code&gt; when time_major is True.</source>
          <target state="translated">当time_major为True时 &lt;code&gt;[timesteps, batch_size, ...]&lt;/code&gt; ND张量具有 &lt;code&gt;[batch_size, timesteps, ...]&lt;/code&gt; 或[timesteps，batch_size，...]形状。</target>
        </trans-unit>
        <trans-unit id="fd6016f78695ef1a5b0efc9a3ba859d270928e9e" translate="yes" xml:space="preserve">
          <source>N-D tensor with shape: &lt;code&gt;(batch_size, ..., input_dim)&lt;/code&gt;. The most common situation would be a 2D input with shape &lt;code&gt;(batch_size, input_dim)&lt;/code&gt;.</source>
          <target state="translated">形状为 &lt;code&gt;(batch_size, ..., input_dim)&lt;/code&gt; ND张量。最常见的情况是形状为 &lt;code&gt;(batch_size, input_dim)&lt;/code&gt; 的2D输入。</target>
        </trans-unit>
        <trans-unit id="b1aad43f56084e08f9722f42e6a896ddf11136f4" translate="yes" xml:space="preserve">
          <source>N-D tensor with shape: &lt;code&gt;(batch_size, ..., units)&lt;/code&gt;. For instance, for a 2D input with shape &lt;code&gt;(batch_size, input_dim)&lt;/code&gt;, the output would have shape &lt;code&gt;(batch_size, units)&lt;/code&gt;.</source>
          <target state="translated">形状为 &lt;code&gt;(batch_size, ..., units)&lt;/code&gt; ND张量。例如，对于形状为 &lt;code&gt;(batch_size, input_dim)&lt;/code&gt; 的2D输入，输出将具有形状 &lt;code&gt;(batch_size, units)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="007cc2c810b8ca3ea7cc54ba301b246045f3233d" translate="yes" xml:space="preserve">
          <source>N-D tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13cb025d768971f708f129f328f88bee346789bc" translate="yes" xml:space="preserve">
          <source>N-D. Tensor of type &lt;code&gt;dtype&lt;/code&gt;. The Tensor to write to this index.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f0b3f11232d02c0692c41b012c0be9b71bef392" translate="yes" xml:space="preserve">
          <source>N.B. If the queue is empty, this operation will block until &lt;code&gt;n&lt;/code&gt; elements have been dequeued (or 'timeout_ms' elapses, if specified).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15edac9a10a3b2ceba17bebea2b154b134d1d3d4" translate="yes" xml:space="preserve">
          <source>N.B. If the queue is empty, this operation will block until an element has been dequeued (or 'timeout_ms' elapses, if specified).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="605552d6b3250138c325be1b0310be2519d2ddd5" translate="yes" xml:space="preserve">
          <source>N.B. If the queue is full, this operation will block until the given element has been enqueued (or 'timeout_ms' elapses, if specified).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eadc904521d31a519316fe2b6796af40e970373f" translate="yes" xml:space="preserve">
          <source>N.B. If the queue is full, this operation will block until the given elements have been enqueued (or 'timeout_ms' elapses, if specified).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="134a28286eba79ace1a76b7f9cb98dd98d8d2be5" translate="yes" xml:space="preserve">
          <source>N.B. This operation will fail with an error if it is executed. It is intended as a way to represent a value that will always be fed, and to provide attrs that enable the fed value to be checked at runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bc35e77c4356443aaf21d56595cb19ef70a848b" translate="yes" xml:space="preserve">
          <source>N.B.: If &lt;code&gt;save_checkpoints_steps&lt;/code&gt; or &lt;code&gt;save_checkpoints_secs&lt;/code&gt; is set, &lt;code&gt;keep_checkpoint_max&lt;/code&gt; might need to be adjusted accordingly, especially in distributed training. For example, setting &lt;code&gt;save_checkpoints_secs&lt;/code&gt; as 60 without adjusting &lt;code&gt;keep_checkpoint_max&lt;/code&gt; (defaults to 5) leads to situation that checkpoint would be garbage collected after 5 minutes. In distributed training, the evaluation job starts asynchronously and might fail to load or find the checkpoint due to race condition.</source>
          <target state="translated">注意：如果设置了 &lt;code&gt;save_checkpoints_steps&lt;/code&gt; 或 &lt;code&gt;save_checkpoints_secs&lt;/code&gt; ， &lt;code&gt;keep_checkpoint_max&lt;/code&gt; 可能需要相应地调整keep_checkpoint_max，尤其是在分布式培训中。例如，将 &lt;code&gt;save_checkpoints_secs&lt;/code&gt; 设置为60而未调整 &lt;code&gt;keep_checkpoint_max&lt;/code&gt; （默认为5）会导致5分钟后将垃圾回收检查点的情况。在分布式培训中，评估作业异步启动，并且可能由于竞争条件而无法加载或找到检查点。</target>
        </trans-unit>
        <trans-unit id="f1b036dd02a8b4c164d9b49324eaf607a4876b94" translate="yes" xml:space="preserve">
          <source>NASNet refers to Neural Architecture Search Network, a family of models that were designed automatically by learning the model architectures directly on the dataset of interest.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b30f636c1db14fd95b07c47ee096c9e7b2992dc" translate="yes" xml:space="preserve">
          <source>NASNet-A models for Keras.</source>
          <target state="translated">Keras的NASNet-A模型。</target>
        </trans-unit>
        <trans-unit id="329be6cd697d977c9ec99cb5a8eb3c08e2e6a197" translate="yes" xml:space="preserve">
          <source>NB: The amount of time this method waits for the session is bounded by max_wait_secs. By default, this function will wait indefinitely.</source>
          <target state="translated">NB:这个方法等待会话的时间是由max_wait_secs限制的。默认情况下,该函数将无限期等待。</target>
        </trans-unit>
        <trans-unit id="e53950c2b094f4e3159c13deb3697bdb6958726a" translate="yes" xml:space="preserve">
          <source>NCCL all-reduce implementation of CrossDeviceOps.</source>
          <target state="translated">NCCL全部还原CrossDeviceOps的实现。</target>
        </trans-unit>
        <trans-unit id="693e6eee00689877593dc033fcfd1d8136218b73" translate="yes" xml:space="preserve">
          <source>NOTE &lt;a href=&quot;../reverse&quot;&gt;&lt;code&gt;tf.reverse&lt;/code&gt;&lt;/a&gt; has now changed behavior in preparation for 1.0. &lt;code&gt;tf.reverse_v2&lt;/code&gt; is currently an alias that will be deprecated before TF 1.0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef16280c8437524c7ebbab7dc8d561a3662ba768" translate="yes" xml:space="preserve">
          <source>NOTE &lt;a href=&quot;reverse&quot;&gt;&lt;code&gt;tf.reverse&lt;/code&gt;&lt;/a&gt; has now changed behavior in preparation for 1.0. &lt;code&gt;tf.reverse_v2&lt;/code&gt; is currently an alias that will be deprecated before TF 1.0.</source>
          <target state="translated">注意&lt;a href=&quot;reverse&quot;&gt; &lt;code&gt;tf.reverse&lt;/code&gt; &lt;/a&gt;现在已更改行为以准备1.0。 &lt;code&gt;tf.reverse_v2&lt;/code&gt; 当前是别名，在TF 1.0之前将不推荐使用。</target>
        </trans-unit>
        <trans-unit id="507488f99fc1b5b7806610b3faecfa9e4861330e" translate="yes" xml:space="preserve">
          <source>NOTE this op currently does not support broadcasting and so &lt;code&gt;value&lt;/code&gt;'s shape must be exactly the shape produced by the slice of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21c472582fae51eefef758568f945bf9f2bcc88c" translate="yes" xml:space="preserve">
          <source>NOTE this op currently does not support broadcasting and so &lt;code&gt;value&lt;/code&gt;'s shape must be exactly the shape produced by the slice of &lt;code&gt;ref&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96b4d2f86094a7ae0f46ccf88a4fb050ca38b073" translate="yes" xml:space="preserve">
          <source>NOTE(mrry): If we register &lt;strong&gt;getitem&lt;/strong&gt; as an overloaded operator, Python will valiantly attempt to iterate over the variable's Tensor from 0 to infinity. Declaring this method prevents this unintended behavior.</source>
          <target state="translated">注意（mrry）：如果我们将&lt;strong&gt;getitem&lt;/strong&gt;注册为重载运算符，Python会&lt;strong&gt;明智&lt;/strong&gt;地尝试在变量的Tensor上从0迭代到无穷大。声明此方法可防止出现这种意外行为。</target>
        </trans-unit>
        <trans-unit id="c3755a1d24438725e354f03134b93411d9bb33bd" translate="yes" xml:space="preserve">
          <source>NOTE(mrry): In normal circumstances, you should not need to construct a &lt;code&gt;DataType&lt;/code&gt; object directly. Instead, use the &lt;a href=&quot;as_dtype&quot;&gt;&lt;code&gt;tf.as_dtype()&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">注意（mrry）：在通常情况下，您不需要直接构造 &lt;code&gt;DataType&lt;/code&gt; 对象。而是使用&lt;a href=&quot;as_dtype&quot;&gt; &lt;code&gt;tf.as_dtype()&lt;/code&gt; &lt;/a&gt;函数。</target>
        </trans-unit>
        <trans-unit id="9dc6a3593a4e151bb413f36d6e9936e9b4062f05" translate="yes" xml:space="preserve">
          <source>NOTE(mrry): traceback.extract_stack eagerly retrieves the line of code for each stack frame using linecache, which results in an abundance of stat() calls. This implementation does not retrieve the code, and any consumer should apply _convert_stack to the result to obtain a traceback that can be formatted etc. using traceback methods.</source>
          <target state="translated">注(mrry):traceback.extract_stack急于用linecache检索每个栈帧的代码行,这导致了大量的stat()调用。这个实现并不检索代码,任何消费者都应该对结果应用_convert_stack来获得一个可以使用traceback方法进行格式化等的traceback。</target>
        </trans-unit>
        <trans-unit id="8c6abbe86b9a3dd54d847c73d2fcb02c7646f939" translate="yes" xml:space="preserve">
          <source>NOTE:</source>
          <target state="translated">NOTE:</target>
        </trans-unit>
        <trans-unit id="3616225191e3c898977be493d7426a0de5ac18e6" translate="yes" xml:space="preserve">
          <source>NOTE: &lt;code&gt;begin&lt;/code&gt; and &lt;code&gt;end&lt;/code&gt; are zero-indexed. &lt;code&gt;strides&lt;/code&gt; entries must be non-zero.</source>
          <target state="translated">注意： &lt;code&gt;begin&lt;/code&gt; 和 &lt;code&gt;end&lt;/code&gt; 是零索引。 &lt;code&gt;strides&lt;/code&gt; 条目必须为非零。</target>
        </trans-unit>
        <trans-unit id="7045712e8cad5b57d0508b61d04032562c6cb2f7" translate="yes" xml:space="preserve">
          <source>NOTE: Although the transformation creates a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;, the transformation must be the final &lt;code&gt;Dataset&lt;/code&gt; in the input pipeline.</source>
          <target state="translated">注意：尽管转换创建了&lt;a href=&quot;../dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;，但转换必须是输入管道中的最终 &lt;code&gt;Dataset&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3f04427d92e52a05f96d958afb9cf2a5fce96d1a" translate="yes" xml:space="preserve">
          <source>NOTE: Currently, the user cannot add any more transformations to a distributed dataset.</source>
          <target state="translated">注意:目前,用户不能再向分布式数据集添加任何转换。</target>
        </trans-unit>
        <trans-unit id="56e88c91e01d7a1793225a810e0c446c7309d471" translate="yes" xml:space="preserve">
          <source>NOTE: For backwards compatibility, this method returns a list. If the given job was defined with a sparse set of task indices, the length of this list may not reflect the number of tasks defined in this job. Use the &lt;a href=&quot;clusterspec#num_tasks&quot;&gt;&lt;code&gt;tf.train.ClusterSpec.num_tasks&lt;/code&gt;&lt;/a&gt; method to find the number of tasks defined in a particular job.</source>
          <target state="translated">注意：为了向后兼容，此方法返回一个列表。如果给定作业是用稀疏的任务索引集定义的，则此列表的长度可能无法反映此作业中定义的任务数。使用&lt;a href=&quot;clusterspec#num_tasks&quot;&gt; &lt;code&gt;tf.train.ClusterSpec.num_tasks&lt;/code&gt; &lt;/a&gt;方法查找在特定作业中定义的任务数。</target>
        </trans-unit>
        <trans-unit id="83d2c9c851b7d2d7c844cd7135f938a898d81b53" translate="yes" xml:space="preserve">
          <source>NOTE: If &lt;code&gt;generator&lt;/code&gt; depends on mutable global variables or other external state, be aware that the runtime may invoke &lt;code&gt;generator&lt;/code&gt; multiple times (in order to support repeating the &lt;code&gt;Dataset&lt;/code&gt;) and at any time between the call to &lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; and the production of the first element from the generator. Mutating global variables or external state can cause undefined behavior, and we recommend that you explicitly cache any external state in &lt;code&gt;generator&lt;/code&gt; before calling &lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">注意：如果 &lt;code&gt;generator&lt;/code&gt; 依赖于可变的全局变量或其他外部状态，请注意运行时可能会多次调用 &lt;code&gt;generator&lt;/code&gt; （以支持重复 &lt;code&gt;Dataset&lt;/code&gt; ），并且在调用&lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;与生成之间有任何时间。生成器的第一个元素。突变全局变量或外部状态可能会导致未定义的行为，我们建议您在调用&lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;之前在 &lt;code&gt;generator&lt;/code&gt; 显式缓存任何外部状态。</target>
        </trans-unit>
        <trans-unit id="c17ac4a32fdbe745971e574b31777a99c3b8a992" translate="yes" xml:space="preserve">
          <source>NOTE: If &lt;code&gt;generator&lt;/code&gt; depends on mutable global variables or other external state, be aware that the runtime may invoke &lt;code&gt;generator&lt;/code&gt; multiple times (in order to support repeating the &lt;code&gt;Dataset&lt;/code&gt;) and at any time between the call to &lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; and the production of the first element from the generator. Mutating global variables or external state can cause undefined behavior, and we recommend that you explicitly cache any external state in &lt;code&gt;generator&lt;/code&gt; before calling &lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">注意：如果 &lt;code&gt;generator&lt;/code&gt; 依赖于可变的全局变量或其他外部状态，请注意运行时可能会多次调用 &lt;code&gt;generator&lt;/code&gt; （以支持重复 &lt;code&gt;Dataset&lt;/code&gt; ），并且在调用&lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;与生成之间有任何时间。生成器的第一个元素。突变全局变量或外部状态可能会导致未定义的行为，我们建议您在调用&lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;之前在 &lt;code&gt;generator&lt;/code&gt; 显式缓存任何外部状态。</target>
        </trans-unit>
        <trans-unit id="10f1420e0dca2a52deb3aa6ef6240aabe5c810bf" translate="yes" xml:space="preserve">
          <source>NOTE: If &lt;code&gt;generator&lt;/code&gt; depends on mutable global variables or other external state, be aware that the runtime may invoke &lt;code&gt;generator&lt;/code&gt; multiple times (in order to support repeating the &lt;code&gt;Dataset&lt;/code&gt;) and at any time between the call to &lt;a href=&quot;../dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; and the production of the first element from the generator. Mutating global variables or external state can cause undefined behavior, and we recommend that you explicitly cache any external state in &lt;code&gt;generator&lt;/code&gt; before calling &lt;a href=&quot;../dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">注意：如果 &lt;code&gt;generator&lt;/code&gt; 依赖于可变的全局变量或其他外部状态，请注意运行时可能会多次调用 &lt;code&gt;generator&lt;/code&gt; （以支持重复 &lt;code&gt;Dataset&lt;/code&gt; ），并且在调用&lt;a href=&quot;../dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;与生成之间有任何时间。生成器的第一个元素。突变全局变量或外部状态可能会导致未定义的行为，我们建议您在调用&lt;a href=&quot;../dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;之前在 &lt;code&gt;generator&lt;/code&gt; 显式缓存任何外部状态。</target>
        </trans-unit>
        <trans-unit id="b6d2276627b413ef99b740ac93ae825c0b27fc0a" translate="yes" xml:space="preserve">
          <source>NOTE: If &lt;code&gt;generator&lt;/code&gt; depends on mutable global variables or other external state, be aware that the runtime may invoke &lt;code&gt;generator&lt;/code&gt; multiple times (in order to support repeating the &lt;code&gt;Dataset&lt;/code&gt;) and at any time between the call to &lt;a href=&quot;dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; and the production of the first element from the generator. Mutating global variables or external state can cause undefined behavior, and we recommend that you explicitly cache any external state in &lt;code&gt;generator&lt;/code&gt; before calling &lt;a href=&quot;dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">注意：如果 &lt;code&gt;generator&lt;/code&gt; 依赖于可变的全局变量或其他外部状态，请注意运行时可能会多次调用 &lt;code&gt;generator&lt;/code&gt; （以支持重复 &lt;code&gt;Dataset&lt;/code&gt; ），并且在调用&lt;a href=&quot;dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;与生成之间有任何时间。生成器的第一个元素。突变全局变量或外部状态可能会导致未定义的行为，我们建议您在调用&lt;a href=&quot;dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;之前在 &lt;code&gt;generator&lt;/code&gt; 显式缓存任何外部状态。</target>
        </trans-unit>
        <trans-unit id="6b9cb830fb1aba495b51ee58fb852a6e93c4fd3c" translate="yes" xml:space="preserve">
          <source>NOTE: If this dataset is a function of global state (e.g. a random number generator), then different repetitions may produce different elements.</source>
          <target state="translated">注意:如果这个数据集是全局状态的函数(如随机数发生器),那么不同的重复可能产生不同的元素。</target>
        </trans-unit>
        <trans-unit id="5a3f57ec4be212445892ef82cad032bba6c1f951" translate="yes" xml:space="preserve">
          <source>NOTE: In TensorFlow 2.0, AutoGraph is automatically applied when using &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. This module contains lower-level APIs for advanced use.</source>
          <target state="translated">注意：在TensorFlow 2.0中，使用&lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;时会自动应用AutoGraph。该模块包含供高级使用的低级API。</target>
        </trans-unit>
        <trans-unit id="f240f4661deba5fe80a4a164dab4babe654538c0" translate="yes" xml:space="preserve">
          <source>NOTE: In TensorFlow 2.0, AutoGraph is automatically applied when using &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. This module contains lower-level APIs for advanced use.</source>
          <target state="translated">注意：在TensorFlow 2.0中，使用&lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;时会自动应用AutoGraph。该模块包含供高级使用的低级API。</target>
        </trans-unit>
        <trans-unit id="1bfce4b170745e63142f9ddfec2414472a587003" translate="yes" xml:space="preserve">
          <source>NOTE: In eager mode, &lt;code&gt;computation&lt;/code&gt; will have &lt;code&gt;@tf.function&lt;/code&gt; semantics.</source>
          <target state="translated">注意：在渴望模式下， &lt;code&gt;computation&lt;/code&gt; 将具有 &lt;code&gt;@tf.function&lt;/code&gt; 语义。</target>
        </trans-unit>
        <trans-unit id="d7fda0f65c4494686dc1b872369c52d1aa3cd210" translate="yes" xml:space="preserve">
          <source>NOTE: In graph mode, to ensure that Assert executes, one usually attaches a dependency:</source>
          <target state="translated">注意:在图模式下,为了保证Assert的执行,通常会附加一个依赖关系。</target>
        </trans-unit>
        <trans-unit id="1e1866295af5ffe36c310d38b9ab92ff7aff9206" translate="yes" xml:space="preserve">
          <source>NOTE: It is legitimate to call &lt;code&gt;Iterator.get_next()&lt;/code&gt; multiple times, e.g. when you are distributing different elements to multiple devices in a single step. However, a common pitfall arises when users call &lt;code&gt;Iterator.get_next()&lt;/code&gt; in each iteration of their training loop. &lt;code&gt;Iterator.get_next()&lt;/code&gt; adds ops to the graph, and executing each op allocates resources (including threads); as a consequence, invoking it in every iteration of a training loop causes slowdown and eventual resource exhaustion. To guard against this outcome, we log a warning when the number of uses crosses a fixed threshold of suspiciousness.</source>
          <target state="translated">注意：多次调用 &lt;code&gt;Iterator.get_next()&lt;/code&gt; 是合法的，例如，在单个步骤中将不同的元素分配给多个设备时。但是，当用户在训练循环的每次迭代中调用 &lt;code&gt;Iterator.get_next()&lt;/code&gt; 时，都会出现一个常见的陷阱。 &lt;code&gt;Iterator.get_next()&lt;/code&gt; 将ops添加到图中，执行每个op都会分配资源（包括线程）；结果，在训练循环的每次迭代中调用它都会导致速度减慢并最终耗尽资源。为防止此结果，当使用次数超过可疑的固定阈值时，我们会记录警告。</target>
        </trans-unit>
        <trans-unit id="7023c08721fbd7fda8836f8ea1b83784ff6c62b2" translate="yes" xml:space="preserve">
          <source>NOTE: MLIR-Based TensorFlow Compiler is under active development and has missing features, please refrain from using. This API exists for development and testing only.</source>
          <target state="translated">注意:基于MLIR的TensorFlow编译器正在开发中,有缺失的功能,请不要使用。本API仅用于开发和测试。</target>
        </trans-unit>
        <trans-unit id="bf308e87b24a8a223b70e3706e19b171c98ffbe0" translate="yes" xml:space="preserve">
          <source>NOTE: MUST mirror the behavior of the C++ AppendFlagsIntoFile from https://github.com/gflags/gflags.</source>
          <target state="translated">注意:必须镜像来自https://github.com/gflags/gflags 的 C++AppendFlagsIntoFile 的行为。</target>
        </trans-unit>
        <trans-unit id="0c56cdc96cd42f0a4d8b37d7d35b3a76756d542a" translate="yes" xml:space="preserve">
          <source>NOTE: MUST mirror the behavior of the C++ CommandlineFlagsIntoString from https://github.com/gflags/gflags.</source>
          <target state="translated">注意:必须镜像来自https://github.com/gflags/gflags 的 C++CommandlineFlagsIntoString 的行为。</target>
        </trans-unit>
        <trans-unit id="683847739697af93b0d15ac410a6e53485306ed7" translate="yes" xml:space="preserve">
          <source>NOTE: Prefer using the Tensor division operator or tf.divide which obey Python 3 division operator semantics.</source>
          <target state="translated">注意:最好使用 Tensor 除法运算符或 tf.divide,它们符合 Python 3 除法运算符的语义。</target>
        </trans-unit>
        <trans-unit id="c0ad0a2f05ff98feecaf73439669929c69e4987f" translate="yes" xml:space="preserve">
          <source>NOTE: Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</source>
          <target state="translated">注意:最好使用 Tensor 运算符或 tf.divide,它们符合 Python 除法运算符的语义。</target>
        </trans-unit>
        <trans-unit id="4cbb6a77026e9cb146e1edde53ce44fb21a35ce0" translate="yes" xml:space="preserve">
          <source>NOTE: Restarting training from saved &lt;code&gt;meta_graph&lt;/code&gt; only works if the device assignments have not changed.</source>
          <target state="translated">注意：仅当设备分配未更改时，才从保存的 &lt;code&gt;meta_graph&lt;/code&gt; 重新开始训练。</target>
        </trans-unit>
        <trans-unit id="efa6d9d345e9a9207c5928e4a1ab9f0a189b4b04" translate="yes" xml:space="preserve">
          <source>NOTE: The context managers will always be exited without any error information. This is an unfortunate implementation detail due to some internals of how unittest runs tests.</source>
          <target state="translated">注意:上下文管理器总是在没有任何错误信息的情况下被退出。这是一个不幸的实现细节,因为 unittest 运行测试的一些内部结构。</target>
        </trans-unit>
        <trans-unit id="996f3ec56e99068804b3b11dd656edb2925215d7" translate="yes" xml:space="preserve">
          <source>NOTE: The conversion functions will execute in order of priority, followed by order of registration. To ensure that a conversion function &lt;code&gt;F&lt;/code&gt; runs before another conversion function &lt;code&gt;G&lt;/code&gt;, ensure that &lt;code&gt;F&lt;/code&gt; is registered with a smaller priority than &lt;code&gt;G&lt;/code&gt;.</source>
          <target state="translated">注意：转换功能将按照优先级顺序执行，然后是注册顺序。为了确保转换函数 &lt;code&gt;F&lt;/code&gt; 之前另一个转换函数运行 &lt;code&gt;G&lt;/code&gt; ，确保 &lt;code&gt;F&lt;/code&gt; 以比较小的优先级注册 &lt;code&gt;G&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8a1284bfef15f833b77a1c83325c3bf163d03ccb" translate="yes" xml:space="preserve">
          <source>NOTE: The current implementation of &lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; uses &lt;a href=&quot;../../../../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and inherits the same constraints. In particular, it requires the &lt;code&gt;Dataset&lt;/code&gt;- and &lt;code&gt;Iterator&lt;/code&gt;-related operations to be placed on a device in the same process as the Python program that called &lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;. The body of &lt;code&gt;generator&lt;/code&gt; will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;, and you should not use this method if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">注意：&lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的当前实现使用&lt;a href=&quot;../../../../numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function&lt;/code&gt; &lt;/a&gt;并继承相同的约束。特别是，它要求将与 &lt;code&gt;Dataset&lt;/code&gt; 和 &lt;code&gt;Iterator&lt;/code&gt; 相关的操作放在与名为&lt;a href=&quot;../../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的Python程序相同的进程中的设备上。 &lt;code&gt;generator&lt;/code&gt; 的主体将不会在 &lt;code&gt;GraphDef&lt;/code&gt; 中进行序列化，并且如果需要序列化模型并将其还原到其他环境中，则不应使用此方法。</target>
        </trans-unit>
        <trans-unit id="0ce30723353df28ded04090716887f0f65646338" translate="yes" xml:space="preserve">
          <source>NOTE: The current implementation of &lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; uses &lt;a href=&quot;../../../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and inherits the same constraints. In particular, it requires the &lt;code&gt;Dataset&lt;/code&gt;- and &lt;code&gt;Iterator&lt;/code&gt;-related operations to be placed on a device in the same process as the Python program that called &lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;. The body of &lt;code&gt;generator&lt;/code&gt; will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;, and you should not use this method if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">注意：&lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的当前实现使用&lt;a href=&quot;../../../numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function&lt;/code&gt; &lt;/a&gt;并继承相同的约束。特别是，它要求将与 &lt;code&gt;Dataset&lt;/code&gt; 和 &lt;code&gt;Iterator&lt;/code&gt; 相关的操作放在与名为&lt;a href=&quot;../../../data/dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的Python程序相同的进程中的设备上。 &lt;code&gt;generator&lt;/code&gt; 的主体将不会在 &lt;code&gt;GraphDef&lt;/code&gt; 中进行序列化，并且如果需要序列化模型并将其还原到其他环境中，则不应使用此方法。</target>
        </trans-unit>
        <trans-unit id="9dc1c962a7f62c6d8ec9ddf837aee055cfc38042" translate="yes" xml:space="preserve">
          <source>NOTE: The current implementation of &lt;a href=&quot;../dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; uses &lt;a href=&quot;../../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and inherits the same constraints. In particular, it requires the &lt;code&gt;Dataset&lt;/code&gt;- and &lt;code&gt;Iterator&lt;/code&gt;-related operations to be placed on a device in the same process as the Python program that called &lt;a href=&quot;../dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;. The body of &lt;code&gt;generator&lt;/code&gt; will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;, and you should not use this method if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">注意：&lt;a href=&quot;../dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的当前实现使用&lt;a href=&quot;../../numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function&lt;/code&gt; &lt;/a&gt;并继承相同的约束。特别是，它要求将与 &lt;code&gt;Dataset&lt;/code&gt; 和 &lt;code&gt;Iterator&lt;/code&gt; 相关的操作放在与名为&lt;a href=&quot;../dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的Python程序相同的进程中的设备上。 &lt;code&gt;generator&lt;/code&gt; 的主体将不会在 &lt;code&gt;GraphDef&lt;/code&gt; 中进行序列化，并且如果需要序列化模型并将其还原到其他环境中，则不应使用此方法。</target>
        </trans-unit>
        <trans-unit id="ef3251a0d5af6f13bc8d97c66b6c26ad0b5983b1" translate="yes" xml:space="preserve">
          <source>NOTE: The current implementation of &lt;a href=&quot;dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt; uses &lt;a href=&quot;../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and inherits the same constraints. In particular, it requires the &lt;code&gt;Dataset&lt;/code&gt;- and &lt;code&gt;Iterator&lt;/code&gt;-related operations to be placed on a device in the same process as the Python program that called &lt;a href=&quot;dataset#from_generator&quot;&gt;&lt;code&gt;Dataset.from_generator()&lt;/code&gt;&lt;/a&gt;. The body of &lt;code&gt;generator&lt;/code&gt; will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;, and you should not use this method if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">注意：&lt;a href=&quot;dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的当前实现使用&lt;a href=&quot;../numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function&lt;/code&gt; &lt;/a&gt;并继承相同的约束。特别是，它要求将与 &lt;code&gt;Dataset&lt;/code&gt; 和 &lt;code&gt;Iterator&lt;/code&gt; 相关的操作放在与名为&lt;a href=&quot;dataset#from_generator&quot;&gt; &lt;code&gt;Dataset.from_generator()&lt;/code&gt; &lt;/a&gt;的Python程序相同的进程中的设备上。 &lt;code&gt;generator&lt;/code&gt; 的主体将不会在 &lt;code&gt;GraphDef&lt;/code&gt; 中进行序列化，并且如果需要序列化模型并将其还原到其他环境中，则不应使用此方法。</target>
        </trans-unit>
        <trans-unit id="8ff878ce6ae336084bc9e1b27ee6cdb321684acd" translate="yes" xml:space="preserve">
          <source>NOTE: The default behavior of this method is to return filenames in a non-deterministic random shuffled order. Pass a &lt;code&gt;seed&lt;/code&gt; or &lt;code&gt;shuffle=False&lt;/code&gt; to get results in a deterministic order.</source>
          <target state="translated">注意：此方法的默认行为是按不确定的随机混排顺序返回文件名。传递 &lt;code&gt;seed&lt;/code&gt; 或 &lt;code&gt;shuffle=False&lt;/code&gt; 以获得确定性顺序的结果。</target>
        </trans-unit>
        <trans-unit id="24ad263ff6825f62b2024bae8370843c8715b4ec" translate="yes" xml:space="preserve">
          <source>NOTE: The default graph is a property of the current thread. If you create a new thread, and wish to use the default graph in that thread, you must explicitly add a &lt;code&gt;with g.as_default():&lt;/code&gt; in that thread's function.</source>
          <target state="translated">注意：默认图形是当前线程的属性。如果创建新线程，并希望在该线程中使用默认图形，则必须在该线程的函数中显式添加 &lt;code&gt;with g.as_default():&lt;/code&gt; 的a。</target>
        </trans-unit>
        <trans-unit id="d95d78127ee2a7c8ba9bf73dbd7708d35d9d43b2" translate="yes" xml:space="preserve">
          <source>NOTE: The default graph is a property of the current thread. This function applies only to the current thread. Calling this function while a &lt;a href=&quot;session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;interactivesession&quot;&gt;&lt;code&gt;tf.compat.v1.InteractiveSession&lt;/code&gt;&lt;/a&gt; is active will result in undefined behavior. Using any previously created &lt;a href=&quot;../../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects after calling this function will result in undefined behavior. Raises: AssertionError: If this function is called within a nested graph.</source>
          <target state="translated">注意：默认图形是当前线程的属性。此功能仅适用于当前线程。在&lt;a href=&quot;session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;interactivesession&quot;&gt; &lt;code&gt;tf.compat.v1.InteractiveSession&lt;/code&gt; &lt;/a&gt;处于活动状态时调用此函数将导致未定义的行为。在调用此函数后使用任何以前创建的&lt;a href=&quot;../../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt;对象将导致未定义的行为。引发：AssertionError：如果在嵌套图中调用此函数。</target>
        </trans-unit>
        <trans-unit id="dd7a93678f86da193b39dcf8b3b1c3be378f8382" translate="yes" xml:space="preserve">
          <source>NOTE: The default session is a property of the current thread. If you create a new thread, and wish to use the default session in that thread, you must explicitly add a &lt;code&gt;with sess.as_default():&lt;/code&gt; in that thread's function.</source>
          <target state="translated">注意：默认会话是当前线程的属性。如果创建新线程，并希望在该线程中使用默认会话，则必须在该线程的函数中显式添加 &lt;code&gt;with sess.as_default():&lt;/code&gt; 的a。</target>
        </trans-unit>
        <trans-unit id="4baa89782dc8c888eebd2e10e436d541a7e7222b" translate="yes" xml:space="preserve">
          <source>NOTE: The directory and its contents will be recursively cleared before creation. This ensures that there is no pre-existing state.</source>
          <target state="translated">注意:在创建之前,目录及其内容将被递归清除。这确保了没有预先存在的状态。</target>
        </trans-unit>
        <trans-unit id="f33812b825ed1f4a589cca82e95a10ebf6e3f7a4" translate="yes" xml:space="preserve">
          <source>NOTE: The order of elements yielded by this transformation is deterministic, as long as &lt;code&gt;map_func&lt;/code&gt; is a pure function. If &lt;code&gt;map_func&lt;/code&gt; contains any stateful operations, the order in which that state is accessed is undefined.</source>
          <target state="translated">注意：只要 &lt;code&gt;map_func&lt;/code&gt; 是纯函数，此转换产生的元素顺序是确定性的。如果 &lt;code&gt;map_func&lt;/code&gt; 包含任何有状态操作，则访问该状态的顺序是不确定的。</target>
        </trans-unit>
        <trans-unit id="b2eb6aa3cc50328f6f5589131571e8b6f8ff578c" translate="yes" xml:space="preserve">
          <source>NOTE: The order of the files returned is deterministic.</source>
          <target state="translated">注意:返回文件的顺序是确定的。</target>
        </trans-unit>
        <trans-unit id="729538d9da4ffd659710e20715b4836a9e18734f" translate="yes" xml:space="preserve">
          <source>NOTE: This constructor validates the given &lt;code&gt;name&lt;/code&gt;. Valid scope names match one of the following regular expressions:</source>
          <target state="translated">注意：此构造函数将验证给定 &lt;code&gt;name&lt;/code&gt; 。有效的作用域名称与以下正则表达式之一匹配：</target>
        </trans-unit>
        <trans-unit id="b6c05e852481b6aa8d8a5c62a532de2680ca2337" translate="yes" xml:space="preserve">
          <source>NOTE: This constructor validates the name of the &lt;code&gt;Operation&lt;/code&gt; (passed as &lt;code&gt;node_def.name&lt;/code&gt;). Valid &lt;code&gt;Operation&lt;/code&gt; names match the following regular expression:</source>
          <target state="translated">注意：此构造函数验证 &lt;code&gt;Operation&lt;/code&gt; 的名称（作为 &lt;code&gt;node_def.name&lt;/code&gt; 传递）。有效的 &lt;code&gt;Operation&lt;/code&gt; 名称与以下正则表达式匹配：</target>
        </trans-unit>
        <trans-unit id="da2fcb0e3008820bc83d67c4c47ec7579e199830" translate="yes" xml:space="preserve">
          <source>NOTE: This differs from &lt;a href=&quot;tensor#set_shape&quot;&gt;&lt;code&gt;Tensor.set_shape&lt;/code&gt;&lt;/a&gt; in that it sets the static shape of the resulting tensor and enforces it at runtime, raising an error if the tensor's runtime shape is incompatible with the specified shape. &lt;a href=&quot;tensor#set_shape&quot;&gt;&lt;code&gt;Tensor.set_shape&lt;/code&gt;&lt;/a&gt; sets the static shape of the tensor without enforcing it at runtime, which may result in inconsistencies between the statically-known shape of tensors and the runtime value of tensors.</source>
          <target state="translated">注意：这与&lt;a href=&quot;tensor#set_shape&quot;&gt; &lt;code&gt;Tensor.set_shape&lt;/code&gt; 的&lt;/a&gt;不同之处在于，它设置结果张量的静态形状并在运行时对其进行强制，如果张量的运行时形状与指定形状不兼容，则会引发错误。&lt;a href=&quot;tensor#set_shape&quot;&gt; &lt;code&gt;Tensor.set_shape&lt;/code&gt; &lt;/a&gt;设置张量的静态形状而不在运行时对其进行强制，这可能会导致静态已知的张量形状与张量的运行时值之间不一致。</target>
        </trans-unit>
        <trans-unit id="d8710a149aad34772c8807c22293080935b4bfb4" translate="yes" xml:space="preserve">
          <source>NOTE: This function is obsolete and will be removed in 6 months. Please change your implementation to use &lt;code&gt;report_uninitialized_variables()&lt;/code&gt;.</source>
          <target state="translated">注意：此功能已过时，将在6个月内删除。请更改您的实现以使用 &lt;code&gt;report_uninitialized_variables()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8973611dbe3347bc91476e1fed5550c3db7f323d" translate="yes" xml:space="preserve">
          <source>NOTE: This is an escape hatch for existing uses of &lt;code&gt;filter&lt;/code&gt; that do not work with V2 functions. New uses are strongly discouraged and existing uses should migrate to &lt;code&gt;filter&lt;/code&gt; as this method will be removed in V2.</source>
          <target state="translated">注意：这是对V2功能不起作用的 &lt;code&gt;filter&lt;/code&gt; 现有用途的逃生线。强烈建议不要使用新用途，而应将现有用途迁移到 &lt;code&gt;filter&lt;/code&gt; 因为此方法将在V2中删除。</target>
        </trans-unit>
        <trans-unit id="9c375eea5e94508c273735102f4bc69d276fde7c" translate="yes" xml:space="preserve">
          <source>NOTE: This is an escape hatch for existing uses of &lt;code&gt;map&lt;/code&gt; that do not work with V2 functions. New uses are strongly discouraged and existing uses should migrate to &lt;code&gt;map&lt;/code&gt; as this method will be removed in V2.</source>
          <target state="translated">注意：这是对V2功能不起作用的现有 &lt;code&gt;map&lt;/code&gt; 用途的逃生舱口。强烈建议不要使用新用途，并且应将现有用途迁移到 &lt;code&gt;map&lt;/code&gt; 因为此方法将在V2中删除。</target>
        </trans-unit>
        <trans-unit id="1c464ca4e817e3d69d913a48d0265ab146368a4f" translate="yes" xml:space="preserve">
          <source>NOTE: This is an escape hatch for existing uses of &lt;code&gt;map_and_batch&lt;/code&gt; that do not work with V2 functions. New uses are strongly discouraged and existing uses should migrate to &lt;code&gt;map_and_batch&lt;/code&gt; as this method will not be removed in V2.</source>
          <target state="translated">注意：这是对不兼容V2函数的 &lt;code&gt;map_and_batch&lt;/code&gt; 的现有用法的转义线。强烈建议不要使用新方法，并且应将现有方法迁移到 &lt;code&gt;map_and_batch&lt;/code&gt; ,因为此方法不会在V2中删除。</target>
        </trans-unit>
        <trans-unit id="fa46499d4cf0599cd6282c538d0aaae468f3bd91" translate="yes" xml:space="preserve">
          <source>NOTE: This is an experimental feature.</source>
          <target state="translated">注:这是一个实验性功能。</target>
        </trans-unit>
        <trans-unit id="c9903d34bfa5caeff689a3a18fefd7d2cd61afe4" translate="yes" xml:space="preserve">
          <source>NOTE: This is not the same as the &lt;code&gt;self.name_scope.name&lt;/code&gt; which includes parent module names.</source>
          <target state="translated">注意：这与包括父模块名称的 &lt;code&gt;self.name_scope.name&lt;/code&gt; 不同。</target>
        </trans-unit>
        <trans-unit id="d7dc3e032f53c199a0f604e1edc35f7cbcd055b1" translate="yes" xml:space="preserve">
          <source>NOTE: This method takes an argument that defines the structure of the value that would be contained in the returned &lt;code&gt;Optional&lt;/code&gt; if it had a value.</source>
          <target state="translated">注意：此方法采用一个参数，该参数定义了具有值的情况下将包含在返回的 &lt;code&gt;Optional&lt;/code&gt; 中的值的结构。</target>
        </trans-unit>
        <trans-unit id="25fb85da18624797a3defa0d51095bf82f41fffc" translate="yes" xml:space="preserve">
          <source>NOTE: This modified program still works fine as a single program. The single program marks itself as the chief.</source>
          <target state="translated">注:这个修改后的程序作为单程序仍然可以正常使用。单个程序将自己标记为首席。</target>
        </trans-unit>
        <trans-unit id="2638e7baff5cec4b35bd96338994a8e0b5185b12" translate="yes" xml:space="preserve">
          <source>NOTE: This shape is not enforced at runtime. Setting incorrect shapes can result in inconsistencies between the statically-known graph and the runtime value of tensors. For runtime validation of the shape, use &lt;a href=&quot;ensure_shape&quot;&gt;&lt;code&gt;tf.ensure_shape&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">注意：在运行时不会强制执行此形状。设置不正确的形状可能导致静态已知图形与张量的运行时值之间不一致。对于形状的运行时验证，请改用&lt;a href=&quot;ensure_shape&quot;&gt; &lt;code&gt;tf.ensure_shape&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="cd3ea3ff47dc681a1f1086660a0f3b033315c559" translate="yes" xml:space="preserve">
          <source>NOTE: This will zero-out the file. This ensures there is no pre-existing state. NOTE: If the file already exists, it will be made writable and overwritten.</source>
          <target state="translated">注意:这将使文件归零。这将确保没有预先存在的状态。注意:如果文件已经存在,将使其可写并被覆盖。</target>
        </trans-unit>
        <trans-unit id="4fd629fd5aa77ce9bf3a720206387efce64814f3" translate="yes" xml:space="preserve">
          <source>NOTE: We use element names that are consistent with those used by the C++ command-line flag library, from https://github.com/gflags/gflags. We also use a few new elements (e.g.,</source>
          <target state="translated">注意:我们使用的元素名称与C++命令行标志库使用的名称一致,来自https://github.com/gflags/gflags。我们还使用了一些新的元素(例如。</target>
        </trans-unit>
        <trans-unit id="f054bd2415d59834c5afa4d8fb3a21b3323535bb" translate="yes" xml:space="preserve">
          <source>NOTE: in the docstrings of all DEFINE* functions, &quot;registers&quot; is short for &quot;creates a new flag and registers it&quot;.</source>
          <target state="translated">注意:在所有DEFINE*函数的docstrings中,&quot;registers &quot;是 &quot;创建一个新标志并注册它 &quot;的缩写。</target>
        </trans-unit>
        <trans-unit id="8bc4687dbd0f799253d60f4172ac9a2623210f34" translate="yes" xml:space="preserve">
          <source>NOTE: we use strings, and not the types.*Type constants because our flags can have more exotic types, e.g., 'comma separated list of strings', 'whitespace separated list of strings', etc.</source>
          <target state="translated">注意:我们使用字符串,而不是类型.*类型常量,因为我们的标志可以有更多奇异的类型,例如,&quot;逗号分隔的字符串列表&quot;,&quot;空格分隔的字符串列表 &quot;等。</target>
        </trans-unit>
        <trans-unit id="ed229f884cbcef052b8bb22cd2fce08a94d34add" translate="yes" xml:space="preserve">
          <source>Name for the operation (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f50b4f2f96e73609b70cb58ada068eade93dfa00" translate="yes" xml:space="preserve">
          <source>Name of argument. This is included in the Identity hint op names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="373f3dd8634a93b1269761bec3c646233d1c84cb" translate="yes" xml:space="preserve">
          <source>Name of attribute to use to store the index for this hint. i.e. FUNCTION_INPUT_INDEX or FUNCTION_OUTPUT_INDEX</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f981e7b1ada8c0abe08cd5c55c91ddeab3c36a5" translate="yes" xml:space="preserve">
          <source>Name of new update operation, and namespace for other dependent ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cb816fa6d07e28d701e8c2e3ae2ed71c1ffb098" translate="yes" xml:space="preserve">
          <source>Name of shared library containing the &lt;a href=&quot;https://www.tensorflow.org/lite/performance/delegates&quot;&gt;TfLiteDelegate&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b33f5c888a3d493e98c52366399db63c78d0ecbf" translate="yes" xml:space="preserve">
          <source>Name of the &lt;code&gt;Tensor&lt;/code&gt; in &lt;code&gt;ckpt_to_load_from&lt;/code&gt; from which to restore the column weights. Required if &lt;code&gt;ckpt_to_load_from&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c327189576f2e704c54154e34e9c33a1844ac4b9" translate="yes" xml:space="preserve">
          <source>Name of the GCE instance group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9553b07ad8bbab23c3858eb348c5dcc259618b7" translate="yes" xml:space="preserve">
          <source>Name of the GCE project.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b86fbbe750c53703aeb189ee89815bd8551b3a20" translate="yes" xml:space="preserve">
          <source>Name of the GCP project containing Cloud TPUs. If omitted or empty, we will try to discover the project name of the GCE VM from the GCE metadata service.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f6e22a6b3ee97630f8680f0093b5417873e20b5" translate="yes" xml:space="preserve">
          <source>Name of the TensorFlow job the TPUs belong to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18fbe82c07ce8dd17070b017255a2de9df5113ff" translate="yes" xml:space="preserve">
          <source>Name of the TensorFlow job this GCE instance group of VM instances belong to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfce8fecdb173f547a25ed2d08889e80574605fa" translate="yes" xml:space="preserve">
          <source>Name of the containing graph (if available).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5da97b6cded683a9ed49cd3f65ba919186376042" translate="yes" xml:space="preserve">
          <source>Name of the evaluation if user needs to run multiple evaluations on different data sets, such as on training data vs test data. Metrics for different evaluations are saved in separate folders, and appear separately in tensorboard.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c02ca2e4d51dc5364977ca459ac0cea1795353d8" translate="yes" xml:space="preserve">
          <source>Name of the file. If an absolute path &lt;code&gt;/path/to/file.txt&lt;/code&gt; is specified the file will be saved at that location.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8e395e187648ef903e503288a77494628e958f9" translate="yes" xml:space="preserve">
          <source>Name of the full variable of which this &lt;code&gt;Variable&lt;/code&gt; is a slice.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f3a84342bb0d7f7c178116038b247184a756ea0" translate="yes" xml:space="preserve">
          <source>Name of the function (the custom op name in tflite)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b08d85c917ffb08ffb8313481fd157ea46964c39" translate="yes" xml:space="preserve">
          <source>Name of the function that this tracks arguments for.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91dc292e52361350181db18845d432ac976278b2" translate="yes" xml:space="preserve">
          <source>Name of the head. If provided, summary and metrics keys will be suffixed by &lt;code&gt;&quot;/&quot; + name&lt;/code&gt;. Also used as &lt;code&gt;name_scope&lt;/code&gt; when creating ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dec777b90f3a78e9082df8f11d85516bd1b5b2db" translate="yes" xml:space="preserve">
          <source>Name of the op to use to restore the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc0cf90cf4340fb3a0c6765613cd7163afdc7301" translate="yes" xml:space="preserve">
          <source>Name of the variable to return.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1104eefed6514b1f5cdaa6a29c1337f707ac335d" translate="yes" xml:space="preserve">
          <source>Name prepended to all ops created by this &lt;code&gt;Distribution&lt;/code&gt;.</source>
          <target state="translated">名称由此 &lt;code&gt;Distribution&lt;/code&gt; 创建的所有操作之前。</target>
        </trans-unit>
        <trans-unit id="a7746578f84ffdc5775b6ba46fc11c99af24f55c" translate="yes" xml:space="preserve">
          <source>Name scope context manager.</source>
          <target state="translated">名称范围上下文管理器。</target>
        </trans-unit>
        <trans-unit id="6560a395613521136316a0a5112734ef76fcecd1" translate="yes" xml:space="preserve">
          <source>Name to give to the DenseFeatures.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d86f64bb4498f01f2c4d091a2e266394f92cc72a" translate="yes" xml:space="preserve">
          <source>Name to give to the SequenceFeatures.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dec45d6c262e2a1f6ad49b11df413f7a81b96f72" translate="yes" xml:space="preserve">
          <source>Name to give to the layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53f07afa7cf2191320c9541fbce922407686bb08" translate="yes" xml:space="preserve">
          <source>Name used to scope the operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="292311d3e9ad21cd46a5e14db8249514f1992059" translate="yes" xml:space="preserve">
          <source>Name used to scope the operations that compute the moments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f41410a5caf431730e0d2b650724180d9e573e5" translate="yes" xml:space="preserve">
          <source>Name used to scope the operations that compute the sufficient stats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f340ff6565652028b5a658440e8c4ba297b9762" translate="yes" xml:space="preserve">
          <source>Name-based &lt;a href=&quot;../compat/v1/train/saver&quot;&gt;&lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt;&lt;/a&gt; checkpoints from TensorFlow 1.x can be loaded using this method. Names are used to match variables. Re-encode name-based checkpoints using &lt;a href=&quot;checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; as soon as possible.</source>
          <target state="translated">可以使用此方法从TensorFlow 1.x加载基于名称的&lt;a href=&quot;../compat/v1/train/saver&quot;&gt; &lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt; &lt;/a&gt;检查点。名称用于匹配变量。尽快使用&lt;a href=&quot;checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt;重新编码基于名称的检查点。</target>
        </trans-unit>
        <trans-unit id="2a5eb5447e34cfda4ed5b878b12576d5e95aed0e" translate="yes" xml:space="preserve">
          <source>Name-based &lt;a href=&quot;saver&quot;&gt;&lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt;&lt;/a&gt; checkpoints can be loaded using this method. Names are used to match variables. No restore ops are created/run until &lt;code&gt;run_restore_ops()&lt;/code&gt; or &lt;code&gt;initialize_or_restore()&lt;/code&gt; are called on the returned status object when graph building, but there is restore-on-creation when executing eagerly. Re-encode name-based checkpoints using &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; as soon as possible.</source>
          <target state="translated">可以使用此方法加载基于名称的&lt;a href=&quot;saver&quot;&gt; &lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt; &lt;/a&gt;检查点。名称用于匹配变量。在创建图形时，在返回的状态对象上调用 &lt;code&gt;run_restore_ops()&lt;/code&gt; 或 &lt;code&gt;initialize_or_restore()&lt;/code&gt; 之前，不会创建/运行任何还原操作，但是，急切地执行时，会进行创建时还原。尽快使用&lt;a href=&quot;../../../train/checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt;重新编码基于名称的检查点。</target>
        </trans-unit>
        <trans-unit id="28d5c9549dfad381de16f27e40b1abd9011bb761" translate="yes" xml:space="preserve">
          <source>Named outputs must be provided as a dict from string to &lt;code&gt;Tensor&lt;/code&gt;,</source>
          <target state="translated">必须提供命名输出作为从字符串到 &lt;code&gt;Tensor&lt;/code&gt; 的字典，</target>
        </trans-unit>
        <trans-unit id="ef9b6db8963f03a2f4b950ad54027da8119efa30" translate="yes" xml:space="preserve">
          <source>Namespace to embed the computation in.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d894c9966e500515e2428de3c69f3d7bb0106221" translate="yes" xml:space="preserve">
          <source>NcclAllReduce</source>
          <target state="translated">NcclAllReduce</target>
        </trans-unit>
        <trans-unit id="ee90175f325f998d04e12db3d52fc76272ce20fd" translate="yes" xml:space="preserve">
          <source>NcclBroadcast</source>
          <target state="translated">NcclBroadcast</target>
        </trans-unit>
        <trans-unit id="1ffbe884914cb8e02fcc6070da8187c64cc59b31" translate="yes" xml:space="preserve">
          <source>NcclReduce</source>
          <target state="translated">NcclReduce</target>
        </trans-unit>
        <trans-unit id="dd00bb8d093d5e93fd4de6110711234e3f1770a7" translate="yes" xml:space="preserve">
          <source>Ndtri</source>
          <target state="translated">Ndtri</target>
        </trans-unit>
        <trans-unit id="ad9041802b2ad5cd647573800f68f895c77cc8fe" translate="yes" xml:space="preserve">
          <source>Neg</source>
          <target state="translated">Neg</target>
        </trans-unit>
        <trans-unit id="c047751220a4a022bf8b34d1d07288536626e59e" translate="yes" xml:space="preserve">
          <source>Negative means, for every element &lt;code&gt;x[i]&lt;/code&gt; of &lt;code&gt;x&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;lt; 0&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty this is trivially satisfied.</source>
          <target state="translated">阴性装置，用于每个元素 &lt;code&gt;x[i]&lt;/code&gt; 的 &lt;code&gt;x&lt;/code&gt; ，我们有 &lt;code&gt;x[i] &amp;lt; 0&lt;/code&gt; 。如果 &lt;code&gt;x&lt;/code&gt; 为空，这是很简单的。</target>
        </trans-unit>
        <trans-unit id="9997061cc1df2fc344d7b363fa6a6c8dbc975409" translate="yes" xml:space="preserve">
          <source>Neither &lt;code&gt;args&lt;/code&gt; nor &lt;code&gt;kwargs&lt;/code&gt; may contain per-replica values. If they contain mirrored values, they will be unwrapped before calling &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;args&lt;/code&gt; 和 &lt;code&gt;kwargs&lt;/code&gt; 都不能包含每个副本的值。如果它们包含镜像值，则将在调用 &lt;code&gt;fn&lt;/code&gt; 之前将其解包。</target>
        </trans-unit>
        <trans-unit id="b5d65f7e771d765b385b8e4a5327471bef2ae471" translate="yes" xml:space="preserve">
          <source>Nested structure of &lt;a href=&quot;../../tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; to pass to &lt;a href=&quot;../dataset#padded_batch&quot;&gt;&lt;code&gt;tf.data.Dataset.padded_batch&lt;/code&gt;&lt;/a&gt;. If not provided, will use &lt;code&gt;dataset.output_shapes&lt;/code&gt;, which will result in variable length dimensions being padded out to the maximum length in each batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ababa750a8ab37a614c8befd6d95261b856efe88" translate="yes" xml:space="preserve">
          <source>Nested structure, whose structure is given by nested lists, tuples, and dicts. Note: numpy arrays and strings are considered scalars.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9a9abf30cef4dff5ab30c1aa4c6cfcb04ec5d70" translate="yes" xml:space="preserve">
          <source>Nesting custom gradients can lead to unintuitive results. The default behavior does not correspond to n-th order derivatives. For example</source>
          <target state="translated">嵌套自定义梯度会导致不直观的结果。默认行为与n-th阶导数不对应。例如</target>
        </trans-unit>
        <trans-unit id="335ccce34af96cd9cfababd5a7d789ebe051352d" translate="yes" xml:space="preserve">
          <source>Neural Optimizer Search with Reinforcement Learning: &lt;a href=&quot;http://proceedings.mlr.press/v70/bello17a.html&quot;&gt;Bello et al., 2017&lt;/a&gt; (&lt;a href=&quot;http://proceedings.mlr.press/v70/bello17a/bello17a.pdf&quot;&gt;pdf&lt;/a&gt;) Stochastic Gradient Descent with Warm Restarts: &lt;a href=&quot;https://openreview.net/forum?id=Skq89Scxx&amp;amp;noteId=Skq89Scxx&quot;&gt;Loshchilov et al., 2017&lt;/a&gt; (&lt;a href=&quot;https://openreview.net/pdf?id=Skq89Scxx&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbacaddc658debb06d141833d26e0cd44d13023a" translate="yes" xml:space="preserve">
          <source>Neural machine translation with attention</source>
          <target state="translated">带有注意力的神经机器翻译</target>
        </trans-unit>
        <trans-unit id="55d7fd8cd5468a225d03e756ead0c2dd940cb199" translate="yes" xml:space="preserve">
          <source>Neural style transfer</source>
          <target state="translated">神经式转移</target>
        </trans-unit>
        <trans-unit id="df3e49001e3d6ba6769a46b475ccd41b26b3e0de" translate="yes" xml:space="preserve">
          <source>Never learns to output repeated classes, as they are collapsed in the input labels before training.</source>
          <target state="translated">永远也学不会输出重复的类,因为它们在训练前就被折叠在输入标签中。</target>
        </trans-unit>
        <trans-unit id="0d8cee794ca609da92a448ad76164b7e16c75c36" translate="yes" xml:space="preserve">
          <source>New &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options()&lt;/code&gt;&lt;/a&gt; object which is the result of merging self with the input &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">新的&lt;a href=&quot;options&quot;&gt; &lt;code&gt;tf.data.Options()&lt;/code&gt; &lt;/a&gt;对象，这是将self与输入&lt;a href=&quot;options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt;合并的结果。</target>
        </trans-unit>
        <trans-unit id="7c104981a4fc4d7de3140b6d8211d59b008dc3b1" translate="yes" xml:space="preserve">
          <source>New variable value</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe0226ce7bb4d26ccf6d7d0209ba867cc25146f1" translate="yes" xml:space="preserve">
          <source>Newlines are stripped from the output. See ReaderBase for supported methods.</source>
          <target state="translated">新行从输出中剥离。参见ReaderBase支持的方法。</target>
        </trans-unit>
        <trans-unit id="eee2db34d9ef66c20e3614255cedfebf30179b34" translate="yes" xml:space="preserve">
          <source>NextAfter</source>
          <target state="translated">NextAfter</target>
        </trans-unit>
        <trans-unit id="19c8ced05c527b1c123e8b9ae670f7f42155f758" translate="yes" xml:space="preserve">
          <source>NextIteration</source>
          <target state="translated">NextIteration</target>
        </trans-unit>
        <trans-unit id="90f69608f8882787ac0a9bb33f531638220c5141" translate="yes" xml:space="preserve">
          <source>No concrete functions is specified. Multiple concrete functions are specified. Input shape is not specified. Invalid quantization parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="458935459d7140127b19628c83fd2e4689e9e0ca" translate="yes" xml:space="preserve">
          <source>No operations should be added to the graph inside this scope, it should only be used when creating variables (some implementations work by changing variable creation, others work by using a tf.compat.v1.colocate_with() scope).</source>
          <target state="translated">在这个作用域内不应该向图中添加任何操作,它只应该在创建变量时使用(有些实现通过改变变量的创建来工作,有些则通过使用tf.compat.v1.colocate_with()作用域来工作)。</target>
        </trans-unit>
        <trans-unit id="e4724ced8c9eb466bc6d5981fbe7b5105a2edce4" translate="yes" xml:space="preserve">
          <source>No validity checking is performed on the indices of &lt;code&gt;A&lt;/code&gt;. However, the following input format is recommended for optimal behavior:</source>
          <target state="translated">不对 &lt;code&gt;A&lt;/code&gt; 的索引执行有效性检查。但是，建议使用以下输入格式以获得最佳性能：</target>
        </trans-unit>
        <trans-unit id="5ac4c6c116b42186a729df63dea493c647859d1c" translate="yes" xml:space="preserve">
          <source>No validity checking is performed on the indices of A. However, the following input format is recommended for optimal behavior:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baa9424065053bee1448386c382d6514b035d61f" translate="yes" xml:space="preserve">
          <source>NoOp</source>
          <target state="translated">NoOp</target>
        </trans-unit>
        <trans-unit id="11666704a84af89311580ed98c76fe597a2315b5" translate="yes" xml:space="preserve">
          <source>Nodes with task type &lt;code&gt;worker&lt;/code&gt; can have id 0, 1, 2. Nodes with task type &lt;code&gt;ps&lt;/code&gt; can have id, 0, 1. So, &lt;code&gt;task_id&lt;/code&gt; is not unique, but the pair (&lt;code&gt;task_type&lt;/code&gt;, &lt;code&gt;task_id&lt;/code&gt;) can uniquely determine a node in the cluster.</source>
          <target state="translated">任务类型为 &lt;code&gt;worker&lt;/code&gt; 的节点的ID可以为0、1、2。任务类型为 &lt;code&gt;ps&lt;/code&gt; 的节点的ID可以为ID 0、1。因此， &lt;code&gt;task_id&lt;/code&gt; 不是唯一的，但是对（ &lt;code&gt;task_type&lt;/code&gt; ， &lt;code&gt;task_id&lt;/code&gt; ）可以唯一地确定集群中的一个节点。 。</target>
        </trans-unit>
        <trans-unit id="b71868446a581b9b3c63c315de1ee252c1d7183d" translate="yes" xml:space="preserve">
          <source>Noise-contrastive estimation - A new estimation principle for unnormalized statistical models: &lt;a href=&quot;http://proceedings.mlr.press/v9/gutmann10a&quot;&gt;Gutmann et al., 2010&lt;/a&gt; (&lt;a href=&quot;http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="446d48d537cd949871e6d4e403d6feadf85c918d" translate="yes" xml:space="preserve">
          <source>Non-deterministically generates some integers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="749ac5365a67ff7882d98d367420f46f872627d3" translate="yes" xml:space="preserve">
          <source>Non-negative &lt;code&gt;int32&lt;/code&gt; scalar &lt;code&gt;Tensor&lt;/code&gt; giving the number of rows in each batch matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c628b9de9519c993db4a7728a7baebb0dd18d7aa" translate="yes" xml:space="preserve">
          <source>Non-negative floating point tensor with shape broadcastable to &lt;code&gt;[N1,..., Nm]&lt;/code&gt; with &lt;code&gt;m &amp;gt;= 0&lt;/code&gt;. Defines this as a batch of &lt;code&gt;N1 x ... x Nm&lt;/code&gt; different Multinomial distributions. Its components should be equal to integer values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24edf165cfafd8a605507a259c00c27fcda62224" translate="yes" xml:space="preserve">
          <source>Non-negative floating point tensor, whose dtype is the same as &lt;code&gt;concentration&lt;/code&gt;. The shape is broadcastable to &lt;code&gt;[N1,..., Nm]&lt;/code&gt; with &lt;code&gt;m &amp;gt;= 0&lt;/code&gt;. Defines this as a batch of &lt;code&gt;N1 x ... x Nm&lt;/code&gt; different Dirichlet multinomial distributions. Its components should be equal to integer values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9d4d2b9496ea5ec4c1aac1f0a9b0c866a9f2255" translate="yes" xml:space="preserve">
          <source>Non-negative integer or &lt;code&gt;int32&lt;/code&gt; scalar &lt;code&gt;tensor&lt;/code&gt; giving the number of rows in the resulting matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24e624f84b8b086a2ccf51286471f05c5e8df298" translate="yes" xml:space="preserve">
          <source>Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range &lt;code&gt;[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets)&lt;/code&gt; based on a hash of the input value. A positive &lt;code&gt;num_oov_buckets&lt;/code&gt; can not be specified with &lt;code&gt;default_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89c51fd26e20d73efd6f8a8f18736f87d5aa9ab0" translate="yes" xml:space="preserve">
          <source>Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range &lt;code&gt;[vocabulary_size, vocabulary_size+num_oov_buckets)&lt;/code&gt; based on a hash of the input value. A positive &lt;code&gt;num_oov_buckets&lt;/code&gt; can not be specified with &lt;code&gt;default_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c979e6e5d3f4ead496e670d40a836151f1ab6c4f" translate="yes" xml:space="preserve">
          <source>Non-negative means, for every element &lt;code&gt;x[i]&lt;/code&gt; of &lt;code&gt;x&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;gt;= 0&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty this is trivially satisfied.</source>
          <target state="translated">非负装置，用于每个元素 &lt;code&gt;x[i]&lt;/code&gt; 的 &lt;code&gt;x&lt;/code&gt; ，我们有 &lt;code&gt;x[i] &amp;gt;= 0&lt;/code&gt; 。如果 &lt;code&gt;x&lt;/code&gt; 为空，这是很简单的。</target>
        </trans-unit>
        <trans-unit id="34c8973bf00e274f72e3e9d129db1bfd9504fc85" translate="yes" xml:space="preserve">
          <source>Non-numeric, unordered, and quantized types are not considered unsigned, and this function returns &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">非数字，无序和量化类型不视为无符号，并且此函数返回 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ba8ab04a76afb8ed04a27bf3433d7f51df786e2c" translate="yes" xml:space="preserve">
          <source>Non-overlapping blocks of size &lt;code&gt;block_size x block size&lt;/code&gt; are rearranged into depth at each location.</source>
          <target state="translated">大小为 &lt;code&gt;block_size x block size&lt;/code&gt; 非重叠块在每个位置都重新排列为深度。</target>
        </trans-unit>
        <trans-unit id="9b52814376942be4a2e4ffe80f42e42f8bbec394" translate="yes" xml:space="preserve">
          <source>Non-overlapping blocks of size &lt;code&gt;block_size x block size&lt;/code&gt; in the height and width dimensions are rearranged into the batch dimension at each location.</source>
          <target state="translated">高度和宽度尺寸中大小为 &lt;code&gt;block_size x block size&lt;/code&gt; 非重叠块在每个位置都重新排列为批处理尺寸。</target>
        </trans-unit>
        <trans-unit id="64df6f701202b39390bcf5e8b4c436903270eae0" translate="yes" xml:space="preserve">
          <source>Non-positive means, for every element &lt;code&gt;x[i]&lt;/code&gt; of &lt;code&gt;x&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;lt;= 0&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty this is trivially satisfied.</source>
          <target state="translated">非正装置，用于每个元素 &lt;code&gt;x[i]&lt;/code&gt; 的 &lt;code&gt;x&lt;/code&gt; ，我们有 &lt;code&gt;x[i] &amp;lt;= 0&lt;/code&gt; 。如果 &lt;code&gt;x&lt;/code&gt; 为空，这是很简单的。</target>
        </trans-unit>
        <trans-unit id="098cb29614487f46e74a99926600dcf076a2bb22" translate="yes" xml:space="preserve">
          <source>NonDeterministicInts</source>
          <target state="translated">NonDeterministicInts</target>
        </trans-unit>
        <trans-unit id="93146f550afb29f8746da81a541ddfc83143e4d5" translate="yes" xml:space="preserve">
          <source>NonMaxSuppression</source>
          <target state="translated">NonMaxSuppression</target>
        </trans-unit>
        <trans-unit id="22b2640c14f3ea391df4bb948dca41ffeb574852" translate="yes" xml:space="preserve">
          <source>NonMaxSuppressionV2</source>
          <target state="translated">NonMaxSuppressionV2</target>
        </trans-unit>
        <trans-unit id="6bf451dcde41d36b4c1ca713b7bb98f55c5a22b5" translate="yes" xml:space="preserve">
          <source>NonMaxSuppressionV3</source>
          <target state="translated">NonMaxSuppressionV3</target>
        </trans-unit>
        <trans-unit id="0497429db5a6dde4c5cab987b59287f60a3c4a82" translate="yes" xml:space="preserve">
          <source>NonMaxSuppressionV4</source>
          <target state="translated">NonMaxSuppressionV4</target>
        </trans-unit>
        <trans-unit id="f2f6e475ef7dc568f06534876dafc07846241120" translate="yes" xml:space="preserve">
          <source>NonMaxSuppressionV5</source>
          <target state="translated">NonMaxSuppressionV5</target>
        </trans-unit>
        <trans-unit id="f14785646cc2df66363f8a37d2ebb84f4363918f" translate="yes" xml:space="preserve">
          <source>NonMaxSuppressionWithOverlaps</source>
          <target state="translated">NonMaxSuppressionWithOverlaps</target>
        </trans-unit>
        <trans-unit id="0077c454c508c38b3a07889768e21015dd2611df" translate="yes" xml:space="preserve">
          <source>NonSerializableDataset</source>
          <target state="translated">NonSerializableDataset</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="5f406869b2e44bfe3d5da3d815b75e2ba59450e6" translate="yes" xml:space="preserve">
          <source>None (no labels).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a371a845b414cfec67792524ed7bfd7d6b1d705e" translate="yes" xml:space="preserve">
          <source>None is a synonym for &lt;a href=&quot;../../tf#newaxis&quot;&gt;&lt;code&gt;tf.newaxis&lt;/code&gt;&lt;/a&gt;. This means insert a dimension of size 1 dimension in the final shape. Dummy values are contributed to begin, end and stride, while the new_axis_mask bit is set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14bbac7c58836e5b5a602a379b51110d6ae97db4" translate="yes" xml:space="preserve">
          <source>None of &lt;code&gt;Estimator&lt;/code&gt;'s methods can be overridden in subclasses (its constructor enforces this). Subclasses should use &lt;code&gt;model_fn&lt;/code&gt; to configure the base class, and may add methods implementing specialized functionality.</source>
          <target state="translated">没有 &lt;code&gt;Estimator&lt;/code&gt; 的方法可以在子类（它的构造强制执行此）覆盖。子类应使用 &lt;code&gt;model_fn&lt;/code&gt; 来配置基类，并可以添加实现专门功能的方法。</target>
        </trans-unit>
        <trans-unit id="adfb7662711b80f1013dedb7a61b85ad11154879" translate="yes" xml:space="preserve">
          <source>None or a &lt;code&gt;SessionRunArgs&lt;/code&gt; object.</source>
          <target state="translated">无或 &lt;code&gt;SessionRunArgs&lt;/code&gt; 对象。</target>
        </trans-unit>
        <trans-unit id="d8d92ebc4f96cf6d286ec1a11a06ca796351ea64" translate="yes" xml:space="preserve">
          <source>None or a tensor (or list of tensors, one per output tensor of the layer).</source>
          <target state="translated">无或一个张量(或张量列表,每个层的输出张量一个)。</target>
        </trans-unit>
        <trans-unit id="59ece98a1ef42f6fe226402c30252533e61ed4c8" translate="yes" xml:space="preserve">
          <source>None or a vector representing the new shape for the returned &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52f5a29a6b68e1c8a5f2aa8b8925183fa90044f7" translate="yes" xml:space="preserve">
          <source>None or str (default: None). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a0fbd028589f38608b21906f558dd3f64e5ffa6" translate="yes" xml:space="preserve">
          <source>None when executing eagerly. During graph tracing this returns a TF operator that prints the specified inputs in the specified output stream or logging level. This operator will be automatically executed except inside of &lt;a href=&quot;compat/v1&quot;&gt;&lt;code&gt;tf.compat.v1&lt;/code&gt;&lt;/a&gt; graphs and sessions.</source>
          <target state="translated">急于执行时无。在图形跟踪期间，这将返回TF运算符，该运算符将在指定的输出流或日志记录级别中打印指定的输入。除了&lt;a href=&quot;compat/v1&quot;&gt; &lt;code&gt;tf.compat.v1&lt;/code&gt; &lt;/a&gt;图形和会话内部，此运算符将自动执行。</target>
        </trans-unit>
        <trans-unit id="9a9707be07da6862114abd49d2570046d4810ca5" translate="yes" xml:space="preserve">
          <source>None.</source>
          <target state="translated">None.</target>
        </trans-unit>
        <trans-unit id="72a4bf1028692e704541b00acacece0a73ff9a0d" translate="yes" xml:space="preserve">
          <source>None: Switch to a system default.</source>
          <target state="translated">无:切换到系统默认值。</target>
        </trans-unit>
        <trans-unit id="13c325d58f707f1ad1e369aa42ee653eda1ae052" translate="yes" xml:space="preserve">
          <source>None: sets the system default.</source>
          <target state="translated">无:设置系统默认值。</target>
        </trans-unit>
        <trans-unit id="19767beec7ee693e0960708a3f947c86a520c900" translate="yes" xml:space="preserve">
          <source>Nonlinearity to use. Default: &lt;code&gt;tanh&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0a51a7890d5532285e086a02d6fd35e3c002044" translate="yes" xml:space="preserve">
          <source>Nonlinearity to use. Default: &lt;code&gt;tanh&lt;/code&gt;. It could also be string that is within Keras activation function names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7547e1f1bfa737c51026448bbe37403315a54990" translate="yes" xml:space="preserve">
          <source>Normalization equations: Consider the intermediate activations (x) of a mini-batch of size (m):</source>
          <target state="translated">归一化方程。考虑大小为(m)的小批量的中间活化(x)。</target>
        </trans-unit>
        <trans-unit id="5eccc35eb116ebc324a90f87200c8bfc4f374b12" translate="yes" xml:space="preserve">
          <source>Normalization equations: Consider the intermediate activations (x) of a mini-batch of size \(m\): We can compute the mean and variance of the batch \({\mu_B} = \frac{1}{m} \sum_{i=1}^{m} {x_i}\) \({\sigma_B^2} = \frac{1}{m} \sum_{i=1}^{m} ({x_i} - {\mu_B})^2\) and then compute a normalized \(x\), including a small factor \({\epsilon}\) for numerical stability. \(\hat{x_i} = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon} }\) And finally \(\hat{x}\) is linearly transformed by \({\gamma}\) and \({\beta}\), which are learned parameters: \({y_i} = {\gamma * \hat{x_i} + \beta}\) Reference:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2fab6a0df78a83648bec88434dd8c3cb779fd48" translate="yes" xml:space="preserve">
          <source>Normalization order (e.g. &lt;code&gt;order=2&lt;/code&gt; for L2 norm).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a57cb9001891b22a0c99ca1123681d9cad919408" translate="yes" xml:space="preserve">
          <source>Normalize and scale inputs or activations synchronously across replicas.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ddd89aec0dc15d71d99ee089608470181d83d1d1" translate="yes" xml:space="preserve">
          <source>Normalize and scale inputs or activations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="064324fb9ad9a7e601e5b04ac9bc9980e4416ae4" translate="yes" xml:space="preserve">
          <source>Normalize and scale inputs or activations. (Ioffe and Szegedy, 2014).</source>
          <target state="translated">规范化和规模化输入或激活。Ioffe和Szegedy,2014)。</target>
        </trans-unit>
        <trans-unit id="3ddfbadcf1463f788dedd93859f2f59e781e0f26" translate="yes" xml:space="preserve">
          <source>Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.</source>
          <target state="translated">归一化上一层在每个批次的激活,即应用一个转换,保持平均激活接近0和激活标准差接近1。</target>
        </trans-unit>
        <trans-unit id="916f594677c93ac279cb0019816ce04eba385fec" translate="yes" xml:space="preserve">
          <source>Normalize the activations of the previous layer for each given example in a batch independently, rather than across a batch like Batch Normalization. i.e. applies a transformation that maintains the mean activation within each example close to 0 and the activation standard deviation close to 1.</source>
          <target state="translated">对批次中每个给定实例的前一层激活进行独立的归一化,而不是像批次归一化那样对整个批次进行归一化,即应用一种变换,使每个实例内的平均激活量保持接近于0,激活标准差接近于1。</target>
        </trans-unit>
        <trans-unit id="e58a6e978455eb49c7db072e10761ebfdcbc42d6" translate="yes" xml:space="preserve">
          <source>Normalized, scaled, offset tensor.</source>
          <target state="translated">归一化、缩放、偏移张量。</target>
        </trans-unit>
        <trans-unit id="5c4f815e6c91d4e73f820c37ba7f1bcee095c74a" translate="yes" xml:space="preserve">
          <source>Normalizes &lt;code&gt;tensor&lt;/code&gt; along dimension &lt;code&gt;axis&lt;/code&gt; using specified norm.</source>
          <target state="translated">使用指定的范数沿尺寸 &lt;code&gt;axis&lt;/code&gt; 标准化 &lt;code&gt;tensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="aff38eeab4b14f7649f14f65c0b7825af7df202d" translate="yes" xml:space="preserve">
          <source>Normalizes a Numpy array.</source>
          <target state="translated">归一化Numpy数组。</target>
        </trans-unit>
        <trans-unit id="c7b4d2f24bb4bf14315a15330bc468f30500a09f" translate="yes" xml:space="preserve">
          <source>Normalizes a tensor by &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;variance&lt;/code&gt;, and applies (optionally) a &lt;code&gt;scale&lt;/code&gt; \(\gamma\) to it, as well as an &lt;code&gt;offset&lt;/code&gt; \(\beta\):</source>
          <target state="translated">通过 &lt;code&gt;mean&lt;/code&gt; 和 &lt;code&gt;variance&lt;/code&gt; 归一化张量，并对其（可选）应用 &lt;code&gt;scale&lt;/code&gt; \（\ gamma \）以及 &lt;code&gt;offset&lt;/code&gt; \（\ beta \）：</target>
        </trans-unit>
        <trans-unit id="2308ef7fe7e52a90b654582b28aba02dc69d0986" translate="yes" xml:space="preserve">
          <source>Normalizes a tensor wrt the L2 norm alongside the specified axis.</source>
          <target state="translated">归一化张量与指定轴线上的L2法线的关系。</target>
        </trans-unit>
        <trans-unit id="c5bb725c2a1943788fbf0021b845c6ac5dd5243c" translate="yes" xml:space="preserve">
          <source>Normalizes along dimension &lt;code&gt;axis&lt;/code&gt; using an L2 norm.</source>
          <target state="translated">使用L2范数沿尺寸 &lt;code&gt;axis&lt;/code&gt; 归一化。</target>
        </trans-unit>
        <trans-unit id="97edba55c7e8ea1e2ab91117f1f0bae959c27151" translate="yes" xml:space="preserve">
          <source>Normalizes along dimension &lt;code&gt;axis&lt;/code&gt; using an L2 norm. (deprecated arguments)</source>
          <target state="translated">使用L2范数沿尺寸 &lt;code&gt;axis&lt;/code&gt; 归一化。（不建议使用的参数）</target>
        </trans-unit>
        <trans-unit id="17303e7ba9d3afb7e4db135e192b17f1cf35f45d" translate="yes" xml:space="preserve">
          <source>Normally used together with 'scope' view.</source>
          <target state="translated">通常与 &quot;范围 &quot;视图一起使用。</target>
        </trans-unit>
        <trans-unit id="e1dfda3ff8dc12277e03539152639a01ac561478" translate="yes" xml:space="preserve">
          <source>Normally, the module that calls the DEFINE_xxx functions claims the flag to be its key flag. This is undesirable for modules that define additional DEFINE_yyy functions with its own flag parsers and serializers, since that module will accidentally claim flags defined by DEFINE_yyy as its key flags. After calling this function, the module disclaims flag definitions thereafter, so the key flags will be correctly attributed to the caller of DEFINE_yyy.</source>
          <target state="translated">通常情况下,调用DEFINE_xxx函数的模块会要求将这个标志作为它的关键标志,这对于用自己的标志解析器和序列化器定义额外的DEFINE_yyy函数的模块来说是不可取的。这对于用自己的标志解析器和序列器定义额外的DEFINE_yyy函数的模块来说是不可取的,因为该模块会意外地将DEFINE_yyy定义的标志宣称为它的关键标志。调用这个函数后,模块会放弃此后的标志定义,所以关键标志将正确地归属于DEFINE_yyy的调用者。</target>
        </trans-unit>
        <trans-unit id="d56a188097b32e96166fb55a8afc1f964b4839b3" translate="yes" xml:space="preserve">
          <source>Not all Readers support being restored, so this can produce an Unimplemented error.</source>
          <target state="translated">并非所有的读卡器都支持被还原,所以这会产生一个未执行的错误。</target>
        </trans-unit>
        <trans-unit id="8a82abb5f2cf27a5f3715b34b452bf30a6056cc5" translate="yes" xml:space="preserve">
          <source>Not all Readers support being serialized, so this can produce an Unimplemented error.</source>
          <target state="translated">并非所有的读卡器都支持被序列化,所以这会产生一个未执行的错误。</target>
        </trans-unit>
        <trans-unit id="6363875392bd4c1ceda918196093dc232be1cab2" translate="yes" xml:space="preserve">
          <source>Not compatible with eager execution. To check for &lt;code&gt;Inf&lt;/code&gt;s and &lt;code&gt;NaN&lt;/code&gt;s under eager execution, call &lt;a href=&quot;../../debugging/enable_check_numerics&quot;&gt;&lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt;&lt;/a&gt; once before executing the checked operations.</source>
          <target state="translated">与急切执行不兼容。要在急切执行的情况下检查 &lt;code&gt;Inf&lt;/code&gt; 和 &lt;code&gt;NaN&lt;/code&gt; ，请在执行检查的操作之前调用&lt;a href=&quot;../../debugging/enable_check_numerics&quot;&gt; &lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt; &lt;/a&gt;一次。</target>
        </trans-unit>
        <trans-unit id="9237eedc5589ecc6b8ee36e7cfb8a8fee3226e44" translate="yes" xml:space="preserve">
          <source>Not compatible with eager execution. To ingest data under eager execution, use the &lt;a href=&quot;../../../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; API instead.</source>
          <target state="translated">与急切执行不兼容。要在急切执行的情况下提取数据，请改用&lt;a href=&quot;../../../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; API。</target>
        </trans-unit>
        <trans-unit id="2ada071819daf1f780987786f85add4894c2abdf" translate="yes" xml:space="preserve">
          <source>Not compatible with eager execution. To write TensorBoard summaries under eager execution, use &lt;code&gt;tf.contrib.summary&lt;/code&gt; instead.</source>
          <target state="translated">与急切执行不兼容。要在渴望执行的情况下编写TensorBoard摘要，请改用 &lt;code&gt;tf.contrib.summary&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f5e998614be9275ecb64d014a6265aaaf223bc24" translate="yes" xml:space="preserve">
          <source>Not threadsafe.</source>
          <target state="translated">不是线程安全。</target>
        </trans-unit>
        <trans-unit id="b635222b25197edcc314ad98c082066bf2c71793" translate="yes" xml:space="preserve">
          <source>Not used in the current implementation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69acf7bcfc30306c695cdb99ebd465e728d2210a" translate="yes" xml:space="preserve">
          <source>Not used in the current implementation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db7e90c0287dc26e08c3f25c9eb2d2b14f070fd1" translate="yes" xml:space="preserve">
          <source>Not well supported when graph building. From TensorFlow 1.x, &lt;a href=&quot;../compat/v1/enable_eager_execution&quot;&gt;&lt;code&gt;tf.compat.v1.enable_eager_execution()&lt;/code&gt;&lt;/a&gt; should run first. Calling tf.saved_model.save in a loop when graph building from TensorFlow 1.x will add new save operations to the default graph each iteration.</source>
          <target state="translated">建立图形时没有很好的支持。从TensorFlow 1.x开始，&lt;a href=&quot;../compat/v1/enable_eager_execution&quot;&gt; &lt;code&gt;tf.compat.v1.enable_eager_execution()&lt;/code&gt; &lt;/a&gt;应该首先运行。从TensorFlow 1.x构建图形时，在循环中调用tf.saved_model.save将在每次迭代中向默认图形添加新的保存操作。</target>
        </trans-unit>
        <trans-unit id="3728769b640112145ecff55faa304b398d6bf9f7" translate="yes" xml:space="preserve">
          <source>NotEqual</source>
          <target state="translated">NotEqual</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="b1f1ce74633bbea6355b2c8b27c5770dec70ab10" translate="yes" xml:space="preserve">
          <source>Note here that &lt;code&gt;call()&lt;/code&gt; method in &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; is little bit different from &lt;code&gt;keras&lt;/code&gt; API. In &lt;code&gt;keras&lt;/code&gt; API, you can pass support masking for layers as additional arguments. Whereas &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; has &lt;code&gt;compute_mask()&lt;/code&gt; method to support masking.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb184c4bb0651f62ca35c7a5b94ae490d249ae1d" translate="yes" xml:space="preserve">
          <source>Note here we derive &amp;amp; use a closed formula not present in the paper as follows:</source>
          <target state="translated">请注意，这里我们导出并使用了本文中不存在的封闭公式，如下所示：</target>
        </trans-unit>
        <trans-unit id="fdb081339fe18821c3b4957f4521ff58a7b015f6" translate="yes" xml:space="preserve">
          <source>Note how the mask token '' and the OOV token [UNK] have been added to the vocabulary. The remaining tokens are sorted by frequency ('d', which has 2 occurrences, is first) then by inverse sort order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f30291373a8d62a246f5b2f9f5030a9fe87b563b" translate="yes" xml:space="preserve">
          <source>Note how the mask value 0 and the OOV value -1 have been added to the vocabulary. The remaining values are sorted by frequency (1138, which has 2 occurrences, is first) then by inverse sort order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2a909050364856639562bf47332b2d0870db232" translate="yes" xml:space="preserve">
          <source>Note in the case that &lt;code&gt;dilation_rate&lt;/code&gt; is not uniformly 1, specifying &quot;VALID&quot; padding is equivalent to specifying &lt;code&gt;padding = &quot;SAME&quot;&lt;/code&gt; with a filter_shape of &lt;code&gt;[1]*N&lt;/code&gt;.</source>
          <target state="translated">注意，在的情况下 &lt;code&gt;dilation_rate&lt;/code&gt; 是不能均匀地1，并指定&amp;ldquo;VALID&amp;rdquo;填充相当于指定 &lt;code&gt;padding = &quot;SAME&quot;&lt;/code&gt; 与的filter_shape &lt;code&gt;[1]*N&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bbe33858c120c8bcc624c14b698f8958aefff666" translate="yes" xml:space="preserve">
          <source>Note internally this op reshapes and uses the underlying 2d operation.</source>
          <target state="translated">请注意,在内部,这个操作会重塑和使用底层的二维操作。</target>
        </trans-unit>
        <trans-unit id="4a26bc83d674c780bc68baa219aef1ce71e32c5a" translate="yes" xml:space="preserve">
          <source>Note on duality: The dilation of &lt;code&gt;input&lt;/code&gt; by the &lt;code&gt;filter&lt;/code&gt; is equal to the negation of the erosion of &lt;code&gt;-input&lt;/code&gt; by the reflected &lt;code&gt;filter&lt;/code&gt;.</source>
          <target state="translated">注意在对偶：所述的扩张 &lt;code&gt;input&lt;/code&gt; 由 &lt;code&gt;filter&lt;/code&gt; 等于的侵蚀的否定 &lt;code&gt;-input&lt;/code&gt; 由反射 &lt;code&gt;filter&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="538256a5d774819d8174f664f11592327abdf052" translate="yes" xml:space="preserve">
          <source>Note on duality: The dilation of &lt;code&gt;input&lt;/code&gt; by the &lt;code&gt;filters&lt;/code&gt; is equal to the negation of the erosion of &lt;code&gt;-input&lt;/code&gt; by the reflected &lt;code&gt;filters&lt;/code&gt;.</source>
          <target state="translated">注意在对偶：所述的扩张 &lt;code&gt;input&lt;/code&gt; 由 &lt;code&gt;filters&lt;/code&gt; 等于的侵蚀的否定 &lt;code&gt;-input&lt;/code&gt; 由反射 &lt;code&gt;filters&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="be6447f1f27b843430d012e2d67e3c5399c7398a" translate="yes" xml:space="preserve">
          <source>Note on notation of the variables:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="509981eb2711e602b52010090ca68b6f7a3a9779" translate="yes" xml:space="preserve">
          <source>Note on passing external constants to RNNs: You can pass &quot;external&quot; constants to the cell using the &lt;code&gt;constants&lt;/code&gt; keyword argument of &lt;a href=&quot;rnn#__call__&quot;&gt;&lt;code&gt;RNN.&lt;strong&gt;call&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; (as well as &lt;a href=&quot;rnn#call&quot;&gt;&lt;code&gt;RNN.call&lt;/code&gt;&lt;/a&gt;) method. This requires that the &lt;code&gt;cell.call&lt;/code&gt; method accepts the same keyword argument &lt;code&gt;constants&lt;/code&gt;. Such constants can be used to condition the cell transformation on additional static inputs (not changing over time), a.k.a. an attention mechanism.</source>
          <target state="translated">关于将外部常量传递给&lt;a href=&quot;rnn#__call__&quot;&gt; &lt;code&gt;RNN.&lt;strong&gt;call&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt;：您可以使用RNN的 &lt;code&gt;constants&lt;/code&gt; 关键字参数将&amp;ldquo;外部&amp;rdquo;常量传递给单元格。&lt;strong&gt;调用&lt;/strong&gt;（以及&lt;a href=&quot;rnn#call&quot;&gt; &lt;code&gt;RNN.call&lt;/code&gt; &lt;/a&gt;）方法。这要求 &lt;code&gt;cell.call&lt;/code&gt; 方法接受相同的关键字参数 &lt;code&gt;constants&lt;/code&gt; 。这样的常数可用于根据附加的静态输入（不随时间变化）来调节单元格转换，也就是一种关注机制。</target>
        </trans-unit>
        <trans-unit id="270d0bda224ad5af83ed8d483360479d2bba6ff4" translate="yes" xml:space="preserve">
          <source>Note on specifying the initial state of RNNs: You can specify the initial state of RNN layers symbolically by calling them with the keyword argument &lt;code&gt;initial_state&lt;/code&gt;. The value of &lt;code&gt;initial_state&lt;/code&gt; should be a tensor or list of tensors representing the initial state of the RNN layer.</source>
          <target state="translated">有关指定RNN初始状态的注意事项：您可以通过使用关键字参数 &lt;code&gt;initial_state&lt;/code&gt; 调用RNN层来象征性地指定RNN层的初始状态。 &lt;code&gt;initial_state&lt;/code&gt; 的值应该是表示RNN层初始状态的张量或张量列表。</target>
        </trans-unit>
        <trans-unit id="a20c526cc3c0884bce765b065839388631d91867" translate="yes" xml:space="preserve">
          <source>Note on supported columns: &lt;code&gt;linear_model&lt;/code&gt; treats categorical columns as &lt;code&gt;indicator_column&lt;/code&gt;s. To be specific, assume the input as &lt;code&gt;SparseTensor&lt;/code&gt; looks like:</source>
          <target state="translated">关于支持的列的注释： &lt;code&gt;linear_model&lt;/code&gt; 将分类列视为 &lt;code&gt;indicator_column&lt;/code&gt; 。具体来说，假设输入为 &lt;code&gt;SparseTensor&lt;/code&gt; ,如下所示：</target>
        </trans-unit>
        <trans-unit id="49ff5aa79e4a7608bb5495ed706a66a929042770" translate="yes" xml:space="preserve">
          <source>Note on using statefulness in RNNs: You can set RNN layers to be 'stateful', which means that the states computed for the samples in one batch will be reused as initial states for the samples in the next batch. This assumes a one-to-one mapping between samples in different successive batches.</source>
          <target state="translated">关于在RNNs中使用状态性的说明。您可以将RNN层设置为 &quot;有状态&quot;,这意味着为一批样本计算出的状态将作为下一批样本的初始状态重新使用。这假设不同连续批次的样本之间存在一对一的映射。</target>
        </trans-unit>
        <trans-unit id="fe82ff91f29b9942d4bd3b011dbec641092ef35c" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; acts like a re-run of a program in this case. When the global seed is set but operation seeds are not set, the sequence of random numbers are the same for each &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72777dbfe4f2e5939c7704c40aca1c5dccec5d23" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;matmul&quot;&gt;&lt;code&gt;tf.matmul&lt;/code&gt;&lt;/a&gt; provides kwargs allowing for transpose of arguments. This is done with minimal cost, and is preferable to using this function. E.g.</source>
          <target state="translated">请注意，&lt;a href=&quot;matmul&quot;&gt; &lt;code&gt;tf.matmul&lt;/code&gt; &lt;/a&gt;提供了允许参数转置的kwarg。这是用最小的成本完成的，并且比使用此功能更可取。例如</target>
        </trans-unit>
        <trans-unit id="e568fc17bc710ccc123c49d3ba60116212a21197" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;tensor#__getitem__&quot;&gt;&lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; is typically a more pythonic way to perform slices, as it allows you to write &lt;code&gt;foo[3:7, :-2]&lt;/code&gt; instead of &lt;code&gt;tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2])&lt;/code&gt;.</source>
          <target state="translated">注意&lt;a href=&quot;tensor#__getitem__&quot;&gt; &lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt;通常是执行切片的更Python方式，因为它允许您编写 &lt;code&gt;foo[3:7, :-2]&lt;/code&gt; 而不是 &lt;code&gt;tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2])&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="40ac51b571e44961669851b81a2bc8f6fff71e6a" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;A&lt;/code&gt; itself will not in general be circulant.</source>
          <target state="translated">注意， &lt;code&gt;A&lt;/code&gt; 本身通常不会循环。</target>
        </trans-unit>
        <trans-unit id="1ec112c82a2c107126719b79f0120392dea4eeaa" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;ForwardAccumulator&lt;/code&gt;s are always applied in the order their context managers were entered, so inner accumulators will not see JVP computation from outer accumulators. Take higher-order JVPs from outer accumulators:</source>
          <target state="translated">请注意， &lt;code&gt;ForwardAccumulator&lt;/code&gt; 始终按输入上下文管理器的顺序应用，因此内部累加器将不会从外部累加器看到JVP计算。从外部累加器获取高阶JVP：</target>
        </trans-unit>
        <trans-unit id="a46da24c95f918ff32cd2978453114c08f12e928" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;alt&lt;/code&gt; should have the &lt;em&gt;same shape&lt;/em&gt; as &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;alt&lt;/code&gt; 的&lt;em&gt;形状&lt;/em&gt;应与 &lt;code&gt;x&lt;/code&gt; &lt;em&gt;相同&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="2a58a5fccc21621a4cf80221dd59a80ac92faf70" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;apply()&lt;/code&gt; can be called multiple times. When eager execution is enabled each call to apply will update the variables once, so this needs to be called in a loop.</source>
          <target state="translated">请注意， &lt;code&gt;apply()&lt;/code&gt; 可以多次调用。启用急切执行后，每次应用调用都会更新一次变量，因此需要在循环中调用。</target>
        </trans-unit>
        <trans-unit id="50f6f8f321ec3b4a9cf9fab3a94eff9e934546e1" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;cond&lt;/code&gt; calls &lt;code&gt;true_fn&lt;/code&gt; and &lt;code&gt;false_fn&lt;/code&gt;&lt;em&gt;exactly once&lt;/em&gt; (inside the call to &lt;code&gt;cond&lt;/code&gt;, and not at all during &lt;code&gt;Session.run()&lt;/code&gt;). &lt;code&gt;cond&lt;/code&gt; stitches together the graph fragments created during the &lt;code&gt;true_fn&lt;/code&gt; and &lt;code&gt;false_fn&lt;/code&gt; calls with some additional graph nodes to ensure that the right branch gets executed depending on the value of &lt;code&gt;pred&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;cond&lt;/code&gt; &lt;code&gt;true_fn&lt;/code&gt; &lt;em&gt;一次&lt;/em&gt;调用true_fn和 &lt;code&gt;false_fn&lt;/code&gt; （在对 &lt;code&gt;cond&lt;/code&gt; 的调用内，而在 &lt;code&gt;Session.run()&lt;/code&gt; 期间完全不调用）。 &lt;code&gt;cond&lt;/code&gt; 将 &lt;code&gt;true_fn&lt;/code&gt; 和 &lt;code&gt;false_fn&lt;/code&gt; 调用期间创建的图形片段与一些其他图形节点缝合在一起，以确保根据 &lt;code&gt;pred&lt;/code&gt; 的值执行正确的分支。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="de089ab8093eb718cd1111124fcc919e11c4b52f" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;minimum&lt;/code&gt; supports broadcast semantics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c35116aab4ffda3f5b8febb9a2fbfcf9f98ca4b2" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;onehot_labels&lt;/code&gt; and &lt;code&gt;logits&lt;/code&gt; must have the same shape, e.g. &lt;code&gt;[batch_size, num_classes]&lt;/code&gt;. The shape of &lt;code&gt;weights&lt;/code&gt; must be broadcastable to loss, whose shape is decided by the shape of &lt;code&gt;logits&lt;/code&gt;. In case the shape of &lt;code&gt;logits&lt;/code&gt; is &lt;code&gt;[batch_size, num_classes]&lt;/code&gt;, loss is a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[batch_size]&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;onehot_labels&lt;/code&gt; 和 &lt;code&gt;logits&lt;/code&gt; 必须具有相同的形状，例如 &lt;code&gt;[batch_size, num_classes]&lt;/code&gt; 。 &lt;code&gt;weights&lt;/code&gt; 的形状必须可以传播到损失，其形状 &lt;code&gt;logits&lt;/code&gt; 对数的形状。如果 &lt;code&gt;logits&lt;/code&gt; 的形状为 &lt;code&gt;[batch_size, num_classes]&lt;/code&gt; ，则损失为 &lt;code&gt;[batch_size]&lt;/code&gt; 形状的 &lt;code&gt;Tensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f1b99c871f303c6654c92ba2a6577333ec5e3056" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;output&lt;/code&gt; preserves the mask dimensions &lt;code&gt;a1...aA&lt;/code&gt;; this differs from &lt;a href=&quot;../boolean_mask&quot;&gt;&lt;code&gt;tf.boolean_mask&lt;/code&gt;&lt;/a&gt;, which flattens those dimensions.</source>
          <target state="translated">请注意， &lt;code&gt;output&lt;/code&gt; 保留了蒙版尺寸 &lt;code&gt;a1...aA&lt;/code&gt; ；这与&lt;a href=&quot;../boolean_mask&quot;&gt; &lt;code&gt;tf.boolean_mask&lt;/code&gt; &lt;/a&gt;不同，后者将这些尺寸展平。</target>
        </trans-unit>
        <trans-unit id="b7f020afa36ab3da134530fec37d9ded2a125980" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;print_tensor&lt;/code&gt; returns a new tensor identical to &lt;code&gt;x&lt;/code&gt; which should be used in the following code. Otherwise the print operation is not taken into account during evaluation.</source>
          <target state="translated">请注意， &lt;code&gt;print_tensor&lt;/code&gt; 返回的新张量与 &lt;code&gt;x&lt;/code&gt; 相同，应在以下代码中使用。否则在评估过程中将不考虑打印操作。</target>
        </trans-unit>
        <trans-unit id="5354d47dcf912a72d45acaff759032e08a161cbe" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;rt1&lt;/code&gt; only contains one ragged dimension (the innermost dimension). In contrast, if &lt;code&gt;from_row_splits&lt;/code&gt; is used to construct a similar &lt;code&gt;RaggedTensor&lt;/code&gt;, then that &lt;code&gt;RaggedTensor&lt;/code&gt; will have two ragged dimensions:</source>
          <target state="translated">请注意， &lt;code&gt;rt1&lt;/code&gt; 仅包含一个参差不齐的维度（最里面的维度）。相反，如果将 &lt;code&gt;from_row_splits&lt;/code&gt; 用于构造类似的 &lt;code&gt;RaggedTensor&lt;/code&gt; ，则该 &lt;code&gt;RaggedTensor&lt;/code&gt; 将具有两个参差不齐的维度：</target>
        </trans-unit>
        <trans-unit id="e5610ad5b9af5428acd48a2b3a48d463377d1dda" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;rt6&lt;/code&gt; only contains one ragged dimension (the innermost dimension). In contrast, if &lt;code&gt;from_row_splits&lt;/code&gt; is used to construct a similar &lt;code&gt;RaggedTensor&lt;/code&gt;, then that &lt;code&gt;RaggedTensor&lt;/code&gt; will have two ragged dimensions:</source>
          <target state="translated">请注意， &lt;code&gt;rt6&lt;/code&gt; 仅包含一个参差不齐的维度（最里面的维度）。相反，如果将 &lt;code&gt;from_row_splits&lt;/code&gt; 用于构造类似的 &lt;code&gt;RaggedTensor&lt;/code&gt; ，则该 &lt;code&gt;RaggedTensor&lt;/code&gt; 将具有两个参差不齐的维度：</target>
        </trans-unit>
        <trans-unit id="3dda3d3a3e15aed235eeed849a924d5cb03f30cb" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;while_loop&lt;/code&gt; calls &lt;code&gt;cond&lt;/code&gt; and &lt;code&gt;body&lt;/code&gt;&lt;em&gt;exactly once&lt;/em&gt; (inside the call to &lt;code&gt;while_loop&lt;/code&gt;, and not at all during &lt;code&gt;Session.run()&lt;/code&gt;). &lt;code&gt;while_loop&lt;/code&gt; stitches together the graph fragments created during the &lt;code&gt;cond&lt;/code&gt; and &lt;code&gt;body&lt;/code&gt; calls with some additional graph nodes to create the graph flow that repeats &lt;code&gt;body&lt;/code&gt; until &lt;code&gt;cond&lt;/code&gt; returns false.</source>
          <target state="translated">需要注意的是 &lt;code&gt;while_loop&lt;/code&gt; 调用 &lt;code&gt;cond&lt;/code&gt; 和 &lt;code&gt;body&lt;/code&gt; &lt;em&gt;恰好一次&lt;/em&gt;（内部调用 &lt;code&gt;while_loop&lt;/code&gt; ，而不是在所有期间 &lt;code&gt;Session.run()&lt;/code&gt; ）。 &lt;code&gt;while_loop&lt;/code&gt; 将在 &lt;code&gt;cond&lt;/code&gt; 和 &lt;code&gt;body&lt;/code&gt; 调用期间创建的图形片段与一些其他图形节点缝合在一起，以创建重复 &lt;code&gt;body&lt;/code&gt; 直到 &lt;code&gt;cond&lt;/code&gt; 返回false 的图形流。</target>
        </trans-unit>
        <trans-unit id="8d7fa6d4c7f23e3bd24a1c5fb86f12cf2aecce4b" translate="yes" xml:space="preserve">
          <source>Note that a RNN cell has: - a &lt;code&gt;call&lt;/code&gt; method. - a &lt;code&gt;state_size&lt;/code&gt; attribute. - a &lt;code&gt;output_size&lt;/code&gt; attribute. - a &lt;code&gt;get_initial_state&lt;/code&gt; method. See the documentation on &lt;a href=&quot;../../keras/layers/rnn&quot;&gt;&lt;code&gt;tf.keras.layers.RNN&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">请注意，RNN单元具有：- &lt;code&gt;call&lt;/code&gt; 方法。-一个 &lt;code&gt;state_size&lt;/code&gt; 属性。-一个 &lt;code&gt;output_size&lt;/code&gt; 属性。-一个 &lt;code&gt;get_initial_state&lt;/code&gt; 方法。有关更多详细信息，请参见&lt;a href=&quot;../../keras/layers/rnn&quot;&gt; &lt;code&gt;tf.keras.layers.RNN&lt;/code&gt; &lt;/a&gt;上的文档。</target>
        </trans-unit>
        <trans-unit id="2598e6e6e3ed83c4641fe5b7584bdf58631bc1af" translate="yes" xml:space="preserve">
          <source>Note that a RNN cell is has: - a &lt;code&gt;call&lt;/code&gt; method. - a &lt;code&gt;state_size&lt;/code&gt; attribute. - a &lt;code&gt;output_size&lt;/code&gt; attribute. - a &lt;code&gt;get_initial_state&lt;/code&gt; method. See the documentation on &lt;a href=&quot;../../keras/layers/rnn&quot;&gt;&lt;code&gt;tf.keras.layers.RNN&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">请注意，RNN单元具有：- &lt;code&gt;call&lt;/code&gt; 方法。-一个 &lt;code&gt;state_size&lt;/code&gt; 属性。-一个 &lt;code&gt;output_size&lt;/code&gt; 属性。-一个 &lt;code&gt;get_initial_state&lt;/code&gt; 方法。有关更多详细信息，请参见&lt;a href=&quot;../../keras/layers/rnn&quot;&gt; &lt;code&gt;tf.keras.layers.RNN&lt;/code&gt; &lt;/a&gt;上的文档。</target>
        </trans-unit>
        <trans-unit id="3346ac203c551f5dee084a97a7117570693fae84" translate="yes" xml:space="preserve">
          <source>Note that a call to &lt;code&gt;sample()&lt;/code&gt; without arguments will generate a single sample.</source>
          <target state="translated">请注意，不带参数的 &lt;code&gt;sample()&lt;/code&gt; 调用将生成一个样本。</target>
        </trans-unit>
        <trans-unit id="364c0af0bec38c1bc33126a30320d7920e1cae9f" translate="yes" xml:space="preserve">
          <source>Note that a regular session installs itself as the default session when it is created in a &lt;code&gt;with&lt;/code&gt; statement. The common usage in non-interactive programs is to follow that pattern:</source>
          <target state="translated">请注意，在 &lt;code&gt;with&lt;/code&gt; 语句中创建常规会话时，会将其自身安装为默认会话。非交互式程序的常见用法是遵循以下模式：</target>
        </trans-unit>
        <trans-unit id="7cf4d553e1b47318848fe5f52ae9a8683fb2afa1" translate="yes" xml:space="preserve">
          <source>Note that assignments currently do not support NumPy broadcasting semantics.</source>
          <target state="translated">请注意,赋值目前不支持NumPy广播语义。</target>
        </trans-unit>
        <trans-unit id="5f05ab6494191c495422b3d779843d05126cda1c" translate="yes" xml:space="preserve">
          <source>Note that at this time, subclassed models can only be saved using &lt;code&gt;serving_only=True&lt;/code&gt;.</source>
          <target state="translated">请注意，此时，只能使用 &lt;code&gt;serving_only=True&lt;/code&gt; 保存子类模型。</target>
        </trans-unit>
        <trans-unit id="e77cb553dc0560db17d2e186e3bd42eaa1bf7dd3" translate="yes" xml:space="preserve">
          <source>Note that both &lt;code&gt;then_expression&lt;/code&gt; and &lt;code&gt;else_expression&lt;/code&gt; should be symbolic tensors of the &lt;em&gt;same shape&lt;/em&gt;.</source>
          <target state="translated">注意 &lt;code&gt;then_expression&lt;/code&gt; 和 &lt;code&gt;else_expression&lt;/code&gt; 都应是&lt;em&gt;相同形状的&lt;/em&gt;符号张量。</target>
        </trans-unit>
        <trans-unit id="332486ee0645460b69c61fd87acb5e3c20435fe4" translate="yes" xml:space="preserve">
          <source>Note that by convention, all sparse ops preserve the canonical ordering along increasing dimension number. The only time ordering can be violated is during manual manipulation of the indices and values to add entries.</source>
          <target state="translated">请注意,按照惯例,所有的稀疏操作都会沿着增加的维数保持规范的排序。唯一可能违反排序的情况是在手动操作索引和值以增加条目时。</target>
        </trans-unit>
        <trans-unit id="7769ab09e3d507777d77b48be6a5d278918e37ef" translate="yes" xml:space="preserve">
          <source>Note that by convention, all sparse ops preserve the canonical ordering along increasing dimension number. The only time ordering can be violated is during manual manipulation of the indices and values vectors to add entries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdaefb21a24bd1dd8a5c3e809a7ec46b615166b8" translate="yes" xml:space="preserve">
          <source>Note that checkpoints saved due to &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt; will not show up in this list (to avoid ever-growing filename lists).</source>
          <target state="translated">请注意，由于 &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt; 而保存的检查点将不会显示在此列表中（以避免不断增长的文件名列表）。</target>
        </trans-unit>
        <trans-unit id="7ea2bdfbd0a043277143ad28f235408aa46b132f" translate="yes" xml:space="preserve">
          <source>Note that collections are not sets, so it is possible to add a value to a collection several times.</source>
          <target state="translated">请注意,集合不是集合,所以可以多次向一个集合添加值。</target>
        </trans-unit>
        <trans-unit id="ba0fffcab7a08b358786725ddffcd0bb7d98dc79" translate="yes" xml:space="preserve">
          <source>Note that collections are not sets, so it is possible to add a value to a collection several times. This function makes sure that duplicates in &lt;code&gt;names&lt;/code&gt; are ignored, but it will not check for pre-existing membership of &lt;code&gt;value&lt;/code&gt; in any of the collections in &lt;code&gt;names&lt;/code&gt;.</source>
          <target state="translated">请注意，集合不是集合，因此可以多次向集合添加值。此函数可确保忽略 &lt;code&gt;names&lt;/code&gt; 中的重复项，但不会检查 &lt;code&gt;names&lt;/code&gt; 中任何集合中 &lt;code&gt;value&lt;/code&gt; 的现有成员资格。</target>
        </trans-unit>
        <trans-unit id="801ba4cea6838bbd2e02399dea989d5f6a9fbb1e" translate="yes" xml:space="preserve">
          <source>Note that compared to &lt;a href=&quot;gradienttape#jacobian&quot;&gt;&lt;code&gt;GradientTape.jacobian&lt;/code&gt;&lt;/a&gt; which computes gradient of each output value w.r.t each input value, this function is useful when &lt;code&gt;target[i,...]&lt;/code&gt; is independent of &lt;code&gt;source[j,...]&lt;/code&gt; for &lt;code&gt;j != i&lt;/code&gt;. This assumption allows more efficient computation as compared to &lt;a href=&quot;gradienttape#jacobian&quot;&gt;&lt;code&gt;GradientTape.jacobian&lt;/code&gt;&lt;/a&gt;. The output, as well as intermediate activations, are lower dimensional and avoid a bunch of redundant zeros which would result in the jacobian computation given the independence assumption.</source>
          <target state="translated">请注意，与计算每个输入值的每个输出值的梯度的&lt;a href=&quot;gradienttape#jacobian&quot;&gt; &lt;code&gt;GradientTape.jacobian&lt;/code&gt; &lt;/a&gt;相比，当 &lt;code&gt;target[i,...]&lt;/code&gt; 独立于 &lt;code&gt;j != i&lt;/code&gt; 的 &lt;code&gt;source[j,...]&lt;/code&gt; 时，此函数很有用。与&lt;a href=&quot;gradienttape#jacobian&quot;&gt; &lt;code&gt;GradientTape.jacobian&lt;/code&gt; &lt;/a&gt;相比，此假设可实现更有效的计算。输出以及中间激活的维数较低，并避免了一堆多余的零，在给定独立性假设的情况下，这些多余的零会导致雅可比计算。</target>
        </trans-unit>
        <trans-unit id="4b852e27625d73d3d93735f5029a52efe498d4dc" translate="yes" xml:space="preserve">
          <source>Note that contrary to &lt;code&gt;run&lt;/code&gt;, &lt;code&gt;feeds&lt;/code&gt; only specifies the graph elements. The tensors will be supplied by the subsequent &lt;code&gt;partial_run&lt;/code&gt; calls.</source>
          <target state="translated">请注意，与 &lt;code&gt;run&lt;/code&gt; 相反， &lt;code&gt;feeds&lt;/code&gt; 仅指定图形元素。张量将由随后的 &lt;code&gt;partial_run&lt;/code&gt; 调用提供。</target>
        </trans-unit>
        <trans-unit id="46a36ec8db81e609e755404715f4c85858c0cb57" translate="yes" xml:space="preserve">
          <source>Note that converting from floating point inputs to integer types may lead to over/underflow problems. Set saturate to &lt;code&gt;True&lt;/code&gt; to avoid such problem in problematic conversions. If enabled, saturation will clip the output into the allowed range before performing a potentially dangerous cast (and only before performing such a cast, i.e., when casting from a floating point to an integer type, and when casting from a signed to an unsigned type; &lt;code&gt;saturate&lt;/code&gt; has no effect on casts between floats, or on casts that increase the type's range).</source>
          <target state="translated">请注意，从浮点输入转换为整数类型可能会导致上溢/下溢问题。将saturate设置为 &lt;code&gt;True&lt;/code&gt; 可以避免出现问题的转换时出现此类问题。如果启用，则饱和将在执行潜在危险的强制转换之前（并且仅在执行此类强制转换之前，即从浮点类型转换为整数类型时，以及从有符号类型转换为无符号类型时，将输出限制在允许的范围内） ； &lt;code&gt;saturate&lt;/code&gt; 对浮点数之间的转换或对增加类型范围的转换无效。</target>
        </trans-unit>
        <trans-unit id="43089211f7d966bba1084d9b1cb2d624e46d32d4" translate="yes" xml:space="preserve">
          <source>Note that decimal places (from zero) are usually not the same as significant digits (measured from the most significant digit).</source>
          <target state="translated">请注意,小数点(从零开始)通常与重要数字不一样(从最重要的数字开始测量)。</target>
        </trans-unit>
        <trans-unit id="ce86c620fc651875c394846ce089267b5ac5cbaf" translate="yes" xml:space="preserve">
          <source>Note that dense dimensions cannot be modified by the shape argument. Trying to change the size of a dense dimension will cause the op to fail. Examples: natural shape: [4, 5, 6] shape: -1 output shape: [4, 5, 6]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c113677112cbefeae4abd9f5dc1ee8116547f90" translate="yes" xml:space="preserve">
          <source>Note that during eager execution, you may discover your &lt;code&gt;Tensors&lt;/code&gt; are actually of type &lt;code&gt;EagerTensor&lt;/code&gt;. This is an internal detail, but it does give you access to a useful function, &lt;code&gt;numpy&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="025c1c19d885a0b6ebb4cbc90bf2628ba9802113" translate="yes" xml:space="preserve">
          <source>Note that even if eager execution is enabled, &lt;code&gt;Input&lt;/code&gt; produces a symbolic tensor (i.e. a placeholder). This symbolic tensor can be used with other TensorFlow ops, as such:</source>
          <target state="translated">请注意，即使启用了急切执行， &lt;code&gt;Input&lt;/code&gt; 也会产生符号张量（即占位符）。此符号张量可与其他TensorFlow操作一起使用，例如：</target>
        </trans-unit>
        <trans-unit id="1cb5eb3fbbdba794d252abb70bc5cc13d38eb40b" translate="yes" xml:space="preserve">
          <source>Note that even if the compute dtype is float16 or bfloat16, hardware devices may not do individual adds, multiplies, and other fundamental operations in [b]float16, but instead may do some of them in float32 for numeric stability. The compute dtype is the dtype of the inputs and outputs of the TensorFlow ops that the layer executes. Internally, many TensorFlow ops will do certain internal calculations in float32, or some other device-internal intermediate format with higher precision than [b]float16, to increase numeric stability.</source>
          <target state="translated">请注意,即使计算dtype是float16或bfloat16,硬件设备可能不会在[b]float16中进行单独的加法、乘法和其他基本运算,而是为了数值的稳定性,可能会在float32中进行一些运算。计算dtype是该层执行的TensorFlow ops的输入和输出的dtype。在内部,许多TensorFlow操作会用float32,或者其他比[b]float16精度更高的设备内部中间格式来做某些内部计算,以提高数值稳定性。</target>
        </trans-unit>
        <trans-unit id="70e19c346145c0fb6ad3ab3ebca758a0424b77a5" translate="yes" xml:space="preserve">
          <source>Note that execution:</source>
          <target state="translated">注意,执行。</target>
        </trans-unit>
        <trans-unit id="b84e02044a808bbb932bde57bef7368168b23370" translate="yes" xml:space="preserve">
          <source>Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.</source>
          <target state="translated">请注意,对于UTF-8,传递一个以1个字节表示的替换字符,例如'',将保留字符串与源码的对齐方式,因为无效的字节将被1个字节替换。对于UTF-16-BE和UTF-16-LE,任何1或2个字节的替换字符都将保留源的字节对齐方式。</target>
        </trans-unit>
        <trans-unit id="0e90575d6196e86c10aac224353957df97c3e5a9" translate="yes" xml:space="preserve">
          <source>Note that if $z = [u, v]$, then</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="158d7059f4ad1c1072885a9be9b7372ddbfa2d14" translate="yes" xml:space="preserve">
          <source>Note that if &lt;code&gt;at_end&lt;/code&gt; is True, &lt;code&gt;tensors&lt;/code&gt; should not include any tensor whose evaluation produces a side effect such as consuming additional inputs.</source>
          <target state="translated">请注意，如果 &lt;code&gt;at_end&lt;/code&gt; 为True，则 &lt;code&gt;tensors&lt;/code&gt; 不应包含其评估会产生副作用（例如，消耗额外的输入）的任何张量。</target>
        </trans-unit>
        <trans-unit id="adf6de6b692d567d6bb0e8d441b44e6a714fe300" translate="yes" xml:space="preserve">
          <source>Note that if &lt;code&gt;distance_metric=KMeansClustering.SQUARED_EUCLIDEAN_DISTANCE&lt;/code&gt;, this function returns the squared Euclidean distance while the corresponding sklearn function returns the Euclidean distance.</source>
          <target state="translated">请注意，如果 &lt;code&gt;distance_metric=KMeansClustering.SQUARED_EUCLIDEAN_DISTANCE&lt;/code&gt; ，则此函数返回平方的欧几里得距离，而相应的sklearn函数返回欧几里得距离。</target>
        </trans-unit>
        <trans-unit id="0ae5427b502a43a2066640827fb2560fd6c5ea15" translate="yes" xml:space="preserve">
          <source>Note that if &lt;code&gt;tensors&lt;/code&gt; contains a NumPy array, and eager execution is not enabled, the values will be embedded in the graph as one or more &lt;a href=&quot;../../../../constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt; operations. For large datasets (&amp;gt; 1 GB), this can waste memory and run into byte limits of graph serialization. If &lt;code&gt;tensors&lt;/code&gt; contains one or more large NumPy arrays, consider the alternative described in &lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;this guide&lt;/a&gt;.</source>
          <target state="translated">请注意，如果 &lt;code&gt;tensors&lt;/code&gt; 包含NumPy数组，并且未启用急切执行，则值将作为一个或多个&lt;a href=&quot;../../../../constant&quot;&gt; &lt;code&gt;tf.constant&lt;/code&gt; &lt;/a&gt;操作嵌入到图中。对于大型数据集（&amp;gt; 1 GB），这可能浪费内存并遇到图序列化的字节限制。如果 &lt;code&gt;tensors&lt;/code&gt; 包含一个或多个大NumPy数组，请考虑&lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;本指南中&lt;/a&gt;描述的替代方法。</target>
        </trans-unit>
        <trans-unit id="0a60ee121bf53c2c9d25970a777d3c84e6e10575" translate="yes" xml:space="preserve">
          <source>Note that if &lt;code&gt;tensors&lt;/code&gt; contains a NumPy array, and eager execution is not enabled, the values will be embedded in the graph as one or more &lt;a href=&quot;../../../constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt; operations. For large datasets (&amp;gt; 1 GB), this can waste memory and run into byte limits of graph serialization. If &lt;code&gt;tensors&lt;/code&gt; contains one or more large NumPy arrays, consider the alternative described in &lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;this guide&lt;/a&gt;.</source>
          <target state="translated">请注意，如果 &lt;code&gt;tensors&lt;/code&gt; 包含NumPy数组，并且未启用急切执行，则值将作为一个或多个&lt;a href=&quot;../../../constant&quot;&gt; &lt;code&gt;tf.constant&lt;/code&gt; &lt;/a&gt;操作嵌入到图中。对于大型数据集（&amp;gt; 1 GB），这可能浪费内存并遇到图序列化的字节限制。如果 &lt;code&gt;tensors&lt;/code&gt; 包含一个或多个大NumPy数组，请考虑&lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;本指南中&lt;/a&gt;描述的替代方法。</target>
        </trans-unit>
        <trans-unit id="6149cccad273c165e08d7e6144dee086ed6d8789" translate="yes" xml:space="preserve">
          <source>Note that if &lt;code&gt;tensors&lt;/code&gt; contains a NumPy array, and eager execution is not enabled, the values will be embedded in the graph as one or more &lt;a href=&quot;../../constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt; operations. For large datasets (&amp;gt; 1 GB), this can waste memory and run into byte limits of graph serialization. If &lt;code&gt;tensors&lt;/code&gt; contains one or more large NumPy arrays, consider the alternative described in &lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;this guide&lt;/a&gt;.</source>
          <target state="translated">请注意，如果 &lt;code&gt;tensors&lt;/code&gt; 包含NumPy数组，并且未启用急切执行，则值将作为一个或多个&lt;a href=&quot;../../constant&quot;&gt; &lt;code&gt;tf.constant&lt;/code&gt; &lt;/a&gt;操作嵌入到图中。对于大型数据集（&amp;gt; 1 GB），这可能浪费内存并遇到图序列化的字节限制。如果 &lt;code&gt;tensors&lt;/code&gt; 包含一个或多个大NumPy数组，请考虑&lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;本指南中&lt;/a&gt;描述的替代方法。</target>
        </trans-unit>
        <trans-unit id="b140bc33ea5918eda9257d6a5eb4297dfff01508" translate="yes" xml:space="preserve">
          <source>Note that if &lt;code&gt;tensors&lt;/code&gt; contains a NumPy array, and eager execution is not enabled, the values will be embedded in the graph as one or more &lt;a href=&quot;../constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt; operations. For large datasets (&amp;gt; 1 GB), this can waste memory and run into byte limits of graph serialization. If &lt;code&gt;tensors&lt;/code&gt; contains one or more large NumPy arrays, consider the alternative described in &lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;this guide&lt;/a&gt;.</source>
          <target state="translated">请注意，如果 &lt;code&gt;tensors&lt;/code&gt; 包含NumPy数组，并且未启用急切执行，则值将作为一个或多个&lt;a href=&quot;../constant&quot;&gt; &lt;code&gt;tf.constant&lt;/code&gt; &lt;/a&gt;操作嵌入到图中。对于大型数据集（&amp;gt; 1 GB），这可能浪费内存并遇到图序列化的字节限制。如果 &lt;code&gt;tensors&lt;/code&gt; 包含一个或多个大NumPy数组，请考虑&lt;a href=&quot;https://tensorflow.org/guide/data#consuming_numpy_arrays&quot;&gt;本指南中&lt;/a&gt;描述的替代方法。</target>
        </trans-unit>
        <trans-unit id="00bb33e7f2f86bdf06a1e536c75f45eb309c3131" translate="yes" xml:space="preserve">
          <source>Note that if &lt;code&gt;z = [u, v]&lt;/code&gt;, then \(Beta(z) = int_0^1 t^{u-1} (1 - t)^{v-1} dt\), which defines the traditional bivariate beta function.</source>
          <target state="translated">请注意，如果 &lt;code&gt;z = [u, v]&lt;/code&gt; ，则\（Beta（z）= int_0 ^ 1 t ^ {u-1}（1- t）^ {v-1} dt \），它定义了传统的双变量beta功能。</target>
        </trans-unit>
        <trans-unit id="7519284befce3224d8263f11a5b37ae2ea167867" translate="yes" xml:space="preserve">
          <source>Note that if no bounding box information is available, setting &lt;code&gt;use_image_if_no_bounding_boxes = True&lt;/code&gt; will assume there is a single implicit bounding box covering the whole image. If &lt;code&gt;use_image_if_no_bounding_boxes&lt;/code&gt; is false and no bounding boxes are supplied, an error is raised.</source>
          <target state="translated">请注意，如果没有可用的边界框信息，则设置 &lt;code&gt;use_image_if_no_bounding_boxes = True&lt;/code&gt; 会假设存在一个覆盖整个图像的隐式边界框。如果 &lt;code&gt;use_image_if_no_bounding_boxes&lt;/code&gt; 为false，并且没有提供边界框，则会引发错误。</target>
        </trans-unit>
        <trans-unit id="f74e716187681901232ad385acb6272f138a2835" translate="yes" xml:space="preserve">
          <source>Note that if no bounding box information is available, setting &lt;code&gt;use_image_if_no_bounding_boxes = true&lt;/code&gt; will assume there is a single implicit bounding box covering the whole image. If &lt;code&gt;use_image_if_no_bounding_boxes&lt;/code&gt; is false and no bounding boxes are supplied, an error is raised.</source>
          <target state="translated">请注意，如果没有可用的边界框信息，则设置 &lt;code&gt;use_image_if_no_bounding_boxes = true&lt;/code&gt; 会假定存在一个覆盖整个图像的隐式边界框。如果 &lt;code&gt;use_image_if_no_bounding_boxes&lt;/code&gt; 为false，并且没有提供边界框，则会引发错误。</target>
        </trans-unit>
        <trans-unit id="f2a58af8e763b1a3ca51fe9d410888f1b8bdb075" translate="yes" xml:space="preserve">
          <source>Note that if the decorated function uses &lt;code&gt;Variable&lt;/code&gt;s, the enclosing variable scope must be using &lt;code&gt;ResourceVariable&lt;/code&gt;s.</source>
          <target state="translated">请注意，如果修饰的函数使用 &lt;code&gt;Variable&lt;/code&gt; ，则封闭变量作用域必须使用 &lt;code&gt;ResourceVariable&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="574f3094ad03b3573fefc33c555f5a8b34f72df2" translate="yes" xml:space="preserve">
          <source>Note that if the spectrum is not Hermitian, then this operator corresponds to a complex matrix with non-zero imaginary part. In this case, setting &lt;code&gt;input_output_dtype&lt;/code&gt; to a real type will forcibly cast the output to be real, resulting in incorrect results!</source>
          <target state="translated">注意，如果频谱不是厄米光谱，则该算符对应于虚部非零的复数矩阵。在这种情况下，将 &lt;code&gt;input_output_dtype&lt;/code&gt; 设置为实型会强制将输出强制转换为实数，从而导致错误的结果！</target>
        </trans-unit>
        <trans-unit id="802c1e3c748f52b2e8502b92a2842c236d074065" translate="yes" xml:space="preserve">
          <source>Note that if you use the defun decorator, any non-TensorFlow Python code that you may have written in your function won't get executed. See &lt;code&gt;tf.contrib.eager.defun&lt;/code&gt; for more details. The recommendation would be to debug without defun but switch to defun to get performance benefits of running map_fn in parallel.</source>
          <target state="translated">请注意，如果使用defun装饰器，则可能不会执行您在函数中编写的任何非TensorFlow Python代码。有关更多详细信息，请参见 &lt;code&gt;tf.contrib.eager.defun&lt;/code&gt; 。建议不使用defun进行调试，而切换到defun以获得并行运行map_fn的性能优势。</target>
        </trans-unit>
        <trans-unit id="1d045237fce6313ee64e728627f02291e9b72a30" translate="yes" xml:space="preserve">
          <source>Note that in V2, is_dynamic_op=False is not supported, meaning TRT engines will be built only when the corresponding TRTEngineOp is executed. But we still provide a way to avoid the cost of building TRT engines during inference (see more below).</source>
          <target state="translated">请注意,在V2中,不支持is_dynamic_op=False,这意味着只有在执行相应的TRTEngineOp时才会构建TRT引擎。但我们仍然提供了一种方法来避免在推理过程中构建TRT引擎的成本(详见下文)。</target>
        </trans-unit>
        <trans-unit id="7aef98ded340bdef8c93dca85b3052da7ad45324" translate="yes" xml:space="preserve">
          <source>Note that in case of ties the identity of the return value is not guaranteed.</source>
          <target state="translated">需要注意的是,在绑定的情况下,不保证返回值的身份。</target>
        </trans-unit>
        <trans-unit id="cb8d4e9baf7359bda9fbe89f7ba6b1626ffaa22e" translate="yes" xml:space="preserve">
          <source>Note that in current implementation &lt;code&gt;estimator.evaluate&lt;/code&gt; will be called multiple times. This means that evaluation graph (including eval_input_fn) will be re-created for each &lt;code&gt;evaluate&lt;/code&gt; call. &lt;code&gt;estimator.train&lt;/code&gt; will be called only once.</source>
          <target state="translated">请注意，在当前实现中， &lt;code&gt;estimator.evaluate&lt;/code&gt; 将被多次调用。这意味着将为每个 &lt;code&gt;evaluate&lt;/code&gt; 调用重新创建评估图（包括eval_input_fn）。 &lt;code&gt;estimator.train&lt;/code&gt; 将仅被调用一次。</target>
        </trans-unit>
        <trans-unit id="e7616e1aa53c94592d33ac7e0737c6785da1f8d7" translate="yes" xml:space="preserve">
          <source>Note that in dense implementation of this algorithm, mg, ms, and mom will update even if the grad is zero, but in this sparse implementation, mg, ms, and mom will not update in iterations during which the grad is zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc672c1f5fc31fa8e9274784514690343a04938e" translate="yes" xml:space="preserve">
          <source>Note that in dense implementation of this algorithm, ms and mom will update even if the grad is zero, but in this sparse implementation, ms and mom will not update in iterations during which the grad is zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c874f4cdb32e3408a903d8be798db049f586c58" translate="yes" xml:space="preserve">
          <source>Note that in the dense implementation of this algorithm, variables and their corresponding accumulators (momentum, gradient moving average, square gradient moving average) will be updated even if the gradient is zero (i.e. accumulators will decay, momentum will be applied). The sparse implementation (used when the gradient is an &lt;code&gt;IndexedSlices&lt;/code&gt; object, typically because of &lt;a href=&quot;../../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt; or an embedding lookup in the forward pass) will not update variable slices or their accumulators unless those slices were used in the forward pass (nor is there an &quot;eventual&quot; correction to account for these omitted updates). This leads to more efficient updates for large embedding lookup tables (where most of the slices are not accessed in a particular graph execution), but differs from the published algorithm.</source>
          <target state="translated">请注意，在该算法的密集实现中，即使梯度为零（即，累加器将衰减，将应用动量），变量及其相应的累加器（动量，梯度移动平均值，平方梯度移动平均值）也会更新。稀疏实现（在渐变为 &lt;code&gt;IndexedSlices&lt;/code&gt; 对象时使用，通常是由于&lt;a href=&quot;../../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt;或在前向遍历中进行嵌入查找）将不会更新变量片或它们的累加器，除非在前向遍历中使用了这些切片（也不存在&amp;ldquo;最终&amp;rdquo;校正以解决这些省略的更新）。这将为大型嵌入查找表（其中在特定的图形执行中不访问大多数切片）带来更有效的更新，但与已发布的算法不同。</target>
        </trans-unit>
        <trans-unit id="5addfb077cb90b2905455a6f6c3ac84c7a531720" translate="yes" xml:space="preserve">
          <source>Note that in the dense implementation of this algorithm, variables and their corresponding accumulators (momentum, gradient moving average, square gradient moving average) will be updated even if the gradient is zero (i.e. accumulators will decay, momentum will be applied). The sparse implementation (used when the gradient is an &lt;code&gt;IndexedSlices&lt;/code&gt; object, typically because of &lt;a href=&quot;../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt; or an embedding lookup in the forward pass) will not update variable slices or their accumulators unless those slices were used in the forward pass (nor is there an &quot;eventual&quot; correction to account for these omitted updates). This leads to more efficient updates for large embedding lookup tables (where most of the slices are not accessed in a particular graph execution), but differs from the published algorithm.</source>
          <target state="translated">请注意，在该算法的密集实现中，即使梯度为零（即，累加器将衰减，将应用动量），变量及其相应的累加器（动量，梯度移动平均值，平方梯度移动平均值）也会更新。稀疏实现（在渐变为 &lt;code&gt;IndexedSlices&lt;/code&gt; 对象时使用，通常是由于&lt;a href=&quot;../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt;或在前向遍历中进行嵌入查找）将不会更新变量片或它们的累加器，除非在前向遍历中使用了这些切片（也不存在&amp;ldquo;最终&amp;rdquo;校正以解决这些省略的更新）。这将为大型嵌入查找表（其中在特定的图形执行中不访问大多数切片）带来更有效的更新，但与已发布的算法不同。</target>
        </trans-unit>
        <trans-unit id="401f6f824f04da5bfe9a2a4ccf6ab0af933625b7" translate="yes" xml:space="preserve">
          <source>Note that in the dense version of this algorithm, &lt;code&gt;accumulation&lt;/code&gt; is updated and applied regardless of a gradient's value, whereas the sparse version (when the gradient is an &lt;code&gt;IndexedSlices&lt;/code&gt;, typically because of &lt;a href=&quot;../../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt; or an embedding) only updates variable slices and corresponding &lt;code&gt;accumulation&lt;/code&gt; terms when that part of the variable was used in the forward pass.</source>
          <target state="translated">请注意，在此算法的密集版本中，无论渐变值如何，都将更新和应用 &lt;code&gt;accumulation&lt;/code&gt; ，而稀疏版本（当渐变为 &lt;code&gt;IndexedSlices&lt;/code&gt; 时，通常是由于&lt;a href=&quot;../../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt;或嵌入）仅更新变量切片和相应的 &lt;code&gt;accumulation&lt;/code&gt; 变量的该部分在正向传递中使用时的术语。</target>
        </trans-unit>
        <trans-unit id="e8a32dc2413778e96f975302de5d8bf07367587a" translate="yes" xml:space="preserve">
          <source>Note that irrespective of the context in which &lt;code&gt;map_func&lt;/code&gt; is defined (eager vs. graph), tf.data traces the function and executes it as a graph. To use Python code inside of the function you have a few options:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39c3d030be7ba2922cf8bbf68f2329852ffcf52e" translate="yes" xml:space="preserve">
          <source>Note that irrespective of the context in which &lt;code&gt;map_func&lt;/code&gt; is defined (eager vs. graph), tf.data traces the function and executes it as a graph. To use Python code inside of the function you have two options:</source>
          <target state="translated">请注意，无论定义了 &lt;code&gt;map_func&lt;/code&gt; 的上下文（热切还是相对于图），tf.data都会跟踪该函数并将其作为图执行。要在函数内部使用Python代码，您有两个选择：</target>
        </trans-unit>
        <trans-unit id="81e2886f72c4b06507aed5644584dc1de37f32c4" translate="yes" xml:space="preserve">
          <source>Note that it is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity. This makes it usable as a loss function in a setting where you try to maximize the proximity between predictions and targets.</source>
          <target state="translated">请注意,它是一个介于-1和0之间的负数,其中0表示正交,接近-1的值表示更大的相似性。这使得它可以作为一个损失函数,在你试图最大化预测和目标之间的接近度的环境中使用。</target>
        </trans-unit>
        <trans-unit id="faa9f010cf8dd24eeb8fa216aff982dd0d2f0a67" translate="yes" xml:space="preserve">
          <source>Note that it is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity. This makes it usable as a loss function in a setting where you try to maximize the proximity between predictions and targets. If either &lt;code&gt;y_true&lt;/code&gt; or &lt;code&gt;y_pred&lt;/code&gt; is a zero vector, cosine similarity will be 0 regardless of the proximity between predictions and targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2377cccc1a513d7d25ea34b9cbb384a40d8ed5b3" translate="yes" xml:space="preserve">
          <source>Note that it is a number between -1 and 1. When it is a negative number between -1 and 0, 0 indicates orthogonality and values closer to -1 indicate greater similarity. The values closer to 1 indicate greater dissimilarity. This makes it usable as a loss function in a setting where you try to maximize the proximity between predictions and targets. If either &lt;code&gt;y_true&lt;/code&gt; or &lt;code&gt;y_pred&lt;/code&gt; is a zero vector, cosine similarity will be 0 regardless of the proximity between predictions and targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c28e62cca57c3d102d22c561e1a4b87e1b5c1a28" translate="yes" xml:space="preserve">
          <source>Note that linear cosine decay is more aggressive than cosine decay and larger initial learning rates can typically be used.</source>
          <target state="translated">请注意,线性余弦衰减比余弦衰减更激进,通常可以使用更大的初始学习率。</target>
        </trans-unit>
        <trans-unit id="960ca71d30cfa024c4186818fe683f8901541ddd" translate="yes" xml:space="preserve">
          <source>Note that namedtuples with identical name and fields are always considered to have the same shallow structure (even with &lt;code&gt;check_types=True&lt;/code&gt;). For instance, this code will print &lt;code&gt;True&lt;/code&gt;:</source>
          <target state="translated">注意，具有相同名称和字段的 &lt;code&gt;check_types=True&lt;/code&gt; 总是被认为具有相同的浅层结构（即使使用check_types = True）。例如，此代码将输出 &lt;code&gt;True&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="b6a77bc75104df995d6f88f50b9882464033d84e" translate="yes" xml:space="preserve">
          <source>Note that near image edges the filtering kernel may be partially outside the image boundaries. For these pixels, only input pixels inside the image will be included in the filter sum, and the output value will be appropriately normalized.</source>
          <target state="translated">请注意,在图像边缘附近,滤波核可能部分超出图像边界。对于这些像素,只有图像内部的输入像素才会被包含在滤波和中,输出值将被适当地归一化。</target>
        </trans-unit>
        <trans-unit id="f681d0bb5b7658560521a3cd86f2ed01b6b2cf79" translate="yes" xml:space="preserve">
          <source>Note that on CPU, if an out of bound index is found, an error is returned. On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.</source>
          <target state="translated">请注意,在CPU上,如果发现一个出界索引,将返回一个错误。在GPU上,如果发现了一个越界索引,则在相应的输出值中存储一个0。</target>
        </trans-unit>
        <trans-unit id="e924de5440ed92a5d655bd9edc466f27be84b709" translate="yes" xml:space="preserve">
          <source>Note that on CPU, if an out of bound index is found, an error is returned. On GPU, if an out of bound index is found, the index is ignored.</source>
          <target state="translated">请注意,在CPU上,如果发现了一个越界索引,将返回一个错误。在GPU上,如果发现了一个越界索引,则忽略该索引。</target>
        </trans-unit>
        <trans-unit id="7bf2ca8e05c2d036783ef692d352b86293224b53" translate="yes" xml:space="preserve">
          <source>Note that only tensors with real or complex dtypes are differentiable.</source>
          <target state="translated">请注意,只有具有实型或复型d型的时序才是可微分的。</target>
        </trans-unit>
        <trans-unit id="6dd4d12e28c131a4ef36edec1e2547ad8eef803c" translate="yes" xml:space="preserve">
          <source>Note that optimizations are only applied in graph mode, (within tf.function).</source>
          <target state="translated">请注意,优化只适用于图模式,(在tf.function内)。</target>
        </trans-unit>
        <trans-unit id="adaa530ba8bea623bb180c32cb91cb7914b931fc" translate="yes" xml:space="preserve">
          <source>Note that optimizations are only applied in graph mode, (within tf.function). In addition, as these are experimental options, the list is subject to change.</source>
          <target state="translated">请注意,优化仅在图形模式下应用(在 tf.function 内)。此外,由于这些都是试验性选项,列表可能会有变化。</target>
        </trans-unit>
        <trans-unit id="9228866469d8a6c003f357c83f3a35d34583c266" translate="yes" xml:space="preserve">
          <source>Note that optimizations are only applied to code that is compiled into a graph. In eager mode, which is the TF2 API default, that means only code that is defined under a tf.function decorator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d10665627c13017344ac380dc501f8de838d757c" translate="yes" xml:space="preserve">
          <source>Note that other implementations of layer normalization may choose to define &lt;code&gt;gamma&lt;/code&gt; and &lt;code&gt;beta&lt;/code&gt; over a separate set of axes from the axes being normalized across. For example, Group Normalization (&lt;a href=&quot;https://arxiv.org/abs/1803.08494&quot;&gt;Wu et al. 2018&lt;/a&gt;) with group size of 1 corresponds to a Layer Normalization that normalizes across height, width, and channel and has &lt;code&gt;gamma&lt;/code&gt; and &lt;code&gt;beta&lt;/code&gt; span only the channel dimension. So, this Layer Normalization implementation will not match a Group Normalization layer with group size set to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abd13efb9bf7159213cd4e7443c620dd130c44f3" translate="yes" xml:space="preserve">
          <source>Note that repeats are allowed in the input SparseTensor. This op is useful for converting &lt;code&gt;SparseTensor&lt;/code&gt;s into dense formats for compatibility with ops that expect dense tensors.</source>
          <target state="translated">请注意，输入SparseTensor中允许重复。此op有助于将 &lt;code&gt;SparseTensor&lt;/code&gt; 转换为密集格式，以便与期望密集张量的op 兼容。</target>
        </trans-unit>
        <trans-unit id="ecc42f0caf8eca72001bc334e02efac9851163e1" translate="yes" xml:space="preserve">
          <source>Note that since the inputs are of shape &lt;code&gt;[batch_size, d0, ... dN]&lt;/code&gt;, the corresponding pairs are computed within each batch sample but not across samples within a batch. For example, if &lt;code&gt;predictions&lt;/code&gt; represents a batch of 16 grayscale images of dimension [batch_size, 100, 200], then the set of pairs is drawn from each image, but not across images.</source>
          <target state="translated">请注意，由于输入的形状为 &lt;code&gt;[batch_size, d0, ... dN]&lt;/code&gt; ，因此在每个批次样本中计算了相应的对，但没有跨批次样本进行计算。例如，如果 &lt;code&gt;predictions&lt;/code&gt; 代表了一批尺寸为[batch_size，100，200]的16幅灰度图像，则从每个图像中绘制成对的集合，但不跨图像绘制。</target>
        </trans-unit>
        <trans-unit id="5db26b033faf30cbafe9cfea9a99401b7c132601" translate="yes" xml:space="preserve">
          <source>Note that the 'out of vocabulary' character is only used for words that were present in the training set but are not included because they're not making the &lt;code&gt;num_words&lt;/code&gt; cut here. Words that were not seen in the training set but are in the test set have simply been skipped.</source>
          <target state="translated">请注意，&amp;ldquo;词汇外&amp;rdquo;字符仅用于训练集中存在但未包含在内的单词，因为它们没有在 &lt;code&gt;num_words&lt;/code&gt; 切入num_words。在训练集中看不到但在测试集中出现的单词只是被跳过了。</target>
        </trans-unit>
        <trans-unit id="6113ba4d508f3e53788a1f5665cfc593eba750e1" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;reuse&lt;/code&gt; flag is inherited: if we open a reusing scope, then all its sub-scopes become reusing as well.</source>
          <target state="translated">请注意， &lt;code&gt;reuse&lt;/code&gt; 标志是继承的：如果我们打开重用范围，则其所有子作用域也将被重用。</target>
        </trans-unit>
        <trans-unit id="3280df457f1a2d1631b02da41c24dee10d57c745" translate="yes" xml:space="preserve">
          <source>Note that the Dropout layer only applies when &lt;code&gt;training&lt;/code&gt; is set to True such that no values are dropped during inference. When using &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;training&lt;/code&gt; will be appropriately set to True automatically, and in other contexts, you can set the kwarg explicitly to True when calling the layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b3a746df435b568689ea2e75e40f139ff2e8b05" translate="yes" xml:space="preserve">
          <source>Note that the Laplace distribution can be thought of two exponential distributions spliced together &quot;back-to-back.&quot;</source>
          <target state="translated">请注意,拉普拉斯分布可以认为是两个指数分布 &quot;背靠背 &quot;拼接在一起。</target>
        </trans-unit>
        <trans-unit id="2f6a7ca6f92652a0be931d16ad6f8410e2297471" translate="yes" xml:space="preserve">
          <source>Note that the PriorityQueue requires the first component of any element to be a scalar int64, in addition to the other elements declared by component_types. Therefore calls to Enqueue and EnqueueMany (resp. Dequeue and DequeueMany) on a PriorityQueue will all require (resp. output) one extra entry in their input (resp. output) lists.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a327f673b782b592aab19565e55d4f259175c75" translate="yes" xml:space="preserve">
          <source>Note that the above mentioned behavior matches python's str.split.</source>
          <target state="translated">请注意,上面提到的行为与python的str.split一致。</target>
        </trans-unit>
        <trans-unit id="63f6136812ef0e4e6d9a0d0fef892e8a8175d1e3" translate="yes" xml:space="preserve">
          <source>Note that the actual keys and values returned by this function is subject to change across different versions of TensorFlow or across platforms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db5aa9b93169253c9ed6fc79d61f87962c43dca2" translate="yes" xml:space="preserve">
          <source>Note that the base &lt;a href=&quot;../../layers/layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt; class inserts the casts. If subclassing your own layer, you do not have to insert any casts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dbf7b0210d50e915dc0b161e9a8111daa542dd5" translate="yes" xml:space="preserve">
          <source>Note that the batch version of this function, &lt;code&gt;tf.parse_sequence_example&lt;/code&gt;, is written for better memory efficiency and will be faster on large &lt;code&gt;SequenceExample&lt;/code&gt;s.</source>
          <target state="translated">请注意，此函数的批处理版本 &lt;code&gt;tf.parse_sequence_example&lt;/code&gt; 的编写目的是为了提高内存效率，并且在大型 &lt;code&gt;SequenceExample&lt;/code&gt; 上将更快。</target>
        </trans-unit>
        <trans-unit id="9e6d585d4dcdfce3574eb75d838a42e338b46f67" translate="yes" xml:space="preserve">
          <source>Note that the chief worker also does the model training job, similar to other non-chief training workers (see next paragraph). In addition to the model training, it manages some extra work, e.g., checkpoint saving and restoring, writing summaries, etc.</source>
          <target state="translated">需要注意的是,总工也是做模型训练的工作,类似于其他非总工的训练工作(见下段)。除了模型训练,它还管理一些额外的工作,如检查点的保存和恢复,写总结等。</target>
        </trans-unit>
        <trans-unit id="815d2135340cb3441d170536899a25d3e970ac75" translate="yes" xml:space="preserve">
          <source>Note that the function assumes that &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; are already unit-normalized.</source>
          <target state="translated">请注意，该函数假定 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 已经进行了单位归一化。</target>
        </trans-unit>
        <trans-unit id="f8e0bd078f9684315af3bfa48a956847252b6cbf" translate="yes" xml:space="preserve">
          <source>Note that the hash function may change from time to time. This functionality will be deprecated and it's recommended to use &lt;a href=&quot;to_hash_bucket_fast&quot;&gt;&lt;code&gt;tf.strings.to_hash_bucket_fast()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;to_hash_bucket_strong&quot;&gt;&lt;code&gt;tf.strings.to_hash_bucket_strong()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">请注意，哈希函数可能会不时更改。不建议使用此功能，建议使用&lt;a href=&quot;to_hash_bucket_fast&quot;&gt; &lt;code&gt;tf.strings.to_hash_bucket_fast()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;to_hash_bucket_strong&quot;&gt; &lt;code&gt;tf.strings.to_hash_bucket_strong()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9ad485251b1b8a5eee42170ad14d607d7705dfc3" translate="yes" xml:space="preserve">
          <source>Note that the hash function may change from time to time. This functionality will be deprecated and it's recommended to use &lt;code&gt;tf.string_to_hash_bucket_fast()&lt;/code&gt; or &lt;code&gt;tf.string_to_hash_bucket_strong()&lt;/code&gt;.</source>
          <target state="translated">请注意，哈希函数可能会不时更改。不建议使用此功能，建议使用 &lt;code&gt;tf.string_to_hash_bucket_fast()&lt;/code&gt; 或 &lt;code&gt;tf.string_to_hash_bucket_strong()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="129d1a89f45603733de5852bdc538919f04fd58f" translate="yes" xml:space="preserve">
          <source>Note that the input may have empty columns at the end, with no effect on this op.</source>
          <target state="translated">需要注意的是,输入端可能是空列,对本操作没有影响。</target>
        </trans-unit>
        <trans-unit id="819ca5b56f7a2a5e50188def7fd443175d0d790f" translate="yes" xml:space="preserve">
          <source>Note that the integer 5, which is out of the vocabulary space, returns an OOV token.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8abe593be83ba37c636e73a6158bffecf3631b83" translate="yes" xml:space="preserve">
          <source>Note that the interface for &lt;code&gt;tf.tpu.experimental.embedding_column&lt;/code&gt; is different from that of &lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt;&lt;/a&gt;: The following arguments are NOT supported: &lt;code&gt;ckpt_to_load_from&lt;/code&gt;, &lt;code&gt;tensor_name_in_ckpt&lt;/code&gt;, &lt;code&gt;max_norm&lt;/code&gt; and &lt;code&gt;trainable&lt;/code&gt;.</source>
          <target state="translated">请注意，该接口 &lt;code&gt;tf.tpu.experimental.embedding_column&lt;/code&gt; 是从不同&lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt; &lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt; &lt;/a&gt;：以下参数不支持： &lt;code&gt;ckpt_to_load_from&lt;/code&gt; ， &lt;code&gt;tensor_name_in_ckpt&lt;/code&gt; ， &lt;code&gt;max_norm&lt;/code&gt; 和 &lt;code&gt;trainable&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bcf780ffbcf5c45eca299de25e2e480df268ae01" translate="yes" xml:space="preserve">
          <source>Note that the interface for &lt;code&gt;tf.tpu.experimental.shared_embedding_columns&lt;/code&gt; is different from that of &lt;a href=&quot;../../feature_column/shared_embedding_columns&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.shared_embedding_columns&lt;/code&gt;&lt;/a&gt;: The following arguments are NOT supported: &lt;code&gt;ckpt_to_load_from&lt;/code&gt;, &lt;code&gt;tensor_name_in_ckpt&lt;/code&gt;, &lt;code&gt;max_norm&lt;/code&gt; and &lt;code&gt;trainable&lt;/code&gt;.</source>
          <target state="translated">请注意，该接口 &lt;code&gt;tf.tpu.experimental.shared_embedding_columns&lt;/code&gt; 是从不同&lt;a href=&quot;../../feature_column/shared_embedding_columns&quot;&gt; &lt;code&gt;tf.compat.v1.feature_column.shared_embedding_columns&lt;/code&gt; &lt;/a&gt;：以下参数不支持： &lt;code&gt;ckpt_to_load_from&lt;/code&gt; ， &lt;code&gt;tensor_name_in_ckpt&lt;/code&gt; ， &lt;code&gt;max_norm&lt;/code&gt; 和 &lt;code&gt;trainable&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="32d78207ce6eaaece77df7019a2f96d27da9a9f2" translate="yes" xml:space="preserve">
          <source>Note that the keyword arg name &quot;cuda_only&quot; is misleading (since routine will return true when a GPU device is available irrespective of whether TF was built with CUDA support or ROCm support. However no changes here because</source>
          <target state="translated">请注意,关键字arg名 &quot;cuda_only &quot;是有误导性的(因为当GPU设备可用时,无论TF是用CUDA支持还是ROCm支持来构建,例程都会返回true。然而这里没有变化,因为</target>
        </trans-unit>
        <trans-unit id="1078bab89eef78bd7deb667016df30a78bb455b0" translate="yes" xml:space="preserve">
          <source>Note that the method &lt;code&gt;add_weight()&lt;/code&gt; offers a shortcut to create weights:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0270125bc4993a0541d9fa512f3fe8c1a196a78" translate="yes" xml:space="preserve">
          <source>Note that the method does not load any data by itself. If the method returns &lt;code&gt;false&lt;/code&gt;, the export directory definitely does not contain a SavedModel. If the method returns &lt;code&gt;true&lt;/code&gt;, the export directory may contain a SavedModel but provides no guarantee that it can be loaded.</source>
          <target state="translated">请注意，该方法本身不会加载任何数据。如果该方法返回 &lt;code&gt;false&lt;/code&gt; ，则导出目录肯定不包含SavedModel。如果该方法返回 &lt;code&gt;true&lt;/code&gt; ，则导出目录可能包含SavedModel，但不保证可以加载它。</target>
        </trans-unit>
        <trans-unit id="efd8961718075260e60596a8e765d914c33662c7" translate="yes" xml:space="preserve">
          <source>Note that the model weights may have different scoped names after being loaded. Scoped names include the model/layer names, such as &lt;code&gt;&quot;dense_1/kernel:0&quot;&lt;/code&gt;. It is recommended that you use the layer properties to access specific variables, e.g. &lt;code&gt;model.get_layer(&quot;dense_1&quot;).kernel&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dad74cb7d420e31005cd496cc671f85f30cf05ba" translate="yes" xml:space="preserve">
          <source>Note that the neutral element of the log-sum-exp operation is &lt;code&gt;-inf&lt;/code&gt;, however, for performance reasons, the minimal value representable by the floating point type is used instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a28acd6357f163827fd0205dd008db4015e575b6" translate="yes" xml:space="preserve">
          <source>Note that the output for OOV value 'm' is 1, while the output for OOV value 'z' is 2. The in-vocab terms have their output index increased by 1 from earlier examples (a maps to 3, etc) in order to make space for the extra OOV value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de7ee0230abb342b5834ae4a41897d18b18a295f" translate="yes" xml:space="preserve">
          <source>Note that the output for OOV value 37 is 2, while the output for OOV value 1000 is 1. The in-vocab terms have their output index increased by 1 from earlier examples (12 maps to 3, etc) in order to make space for the extra OOV value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de2fd6e750c0385c53f58920f3e50864bd9f204c" translate="yes" xml:space="preserve">
          <source>Note that the params buffer may not be compatible across different GPUs. So any save and restoration should be converted to and from the canonical weights and biases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f7264bc1d90f49c816d4917489736fdf408647f" translate="yes" xml:space="preserve">
          <source>Note that the possible labels are assumed to be &lt;code&gt;[0, 1, 2, 3, 4]&lt;/code&gt;, resulting in a 5x5 confusion matrix.</source>
          <target state="translated">请注意，假定可能的标签为 &lt;code&gt;[0, 1, 2, 3, 4]&lt;/code&gt; ，导致5x5混淆矩阵。</target>
        </trans-unit>
        <trans-unit id="40c79f656225cda5e6e51f6ea16d3455c49922f1" translate="yes" xml:space="preserve">
          <source>Note that the queue runners collected in the graph key &lt;code&gt;QUEUE_RUNNERS&lt;/code&gt; are already started automatically when you create a session with the supervisor, so unless you have non-collected queue runners to start you do not need to call this explicitly.</source>
          <target state="translated">请注意，当您与主管创建会话时，在图形键 &lt;code&gt;QUEUE_RUNNERS&lt;/code&gt; 中收集的队列运行器已经自动启动，因此，除非您有未收集的队列运行器启动，否则您无需显式调用它。</target>
        </trans-unit>
        <trans-unit id="9e317428edda1b83776dc82560d20fc661ed1b6c" translate="yes" xml:space="preserve">
          <source>Note that the receiver_tensors and receiver_tensor_alternatives arguments will be automatically converted to the dict representation in either case, because the SavedModel format requires each input &lt;code&gt;Tensor&lt;/code&gt; to have a name (provided by the dict key).</source>
          <target state="translated">注意，无论哪种情况，receiver_tensors和receiver_tensor_alternatives参数都会自动转换为dict表示形式，因为SavedModel格式要求每个输入 &lt;code&gt;Tensor&lt;/code&gt; 都具有一个名称（由dict键提供）。</target>
        </trans-unit>
        <trans-unit id="5fe31008d0aed5e9ffa8cc21ffdc12abed84aab0" translate="yes" xml:space="preserve">
          <source>Note that the size of 4D Tensors are defined by either &quot;NHWC&quot; or &quot;NCHW&quot;. The size of 1D Tensors matches the dimension C of the 4D Tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="814eacb7262395c75669dea8c319db36d64af71e" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;a href=&quot;../../../../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../../py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; in general precludes the possibility of executing user-defined transformations in parallel (because of Python GIL).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48ef802c93d5e5213fec28095b29622647e30157" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;a href=&quot;../../../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; in general precludes the possibility of executing user-defined transformations in parallel (because of Python GIL).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="107e1c44db5ab15d9bbae3b8ff797d0f6721ef1c" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;a href=&quot;../../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; in general precludes the possibility of executing user-defined transformations in parallel (because of Python GIL).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d69e8c7f8d612ff01d585b29ebc7d4d2b6b73874" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;a href=&quot;../numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; in general precludes the possibility of executing user-defined transformations in parallel (because of Python GIL).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fe6d1eafeae4c39f85dd9382c952d6ce0c0d5cf" translate="yes" xml:space="preserve">
          <source>Note that this can only be called after calling apply_gradients() which actually generates this queuerunner.</source>
          <target state="translated">请注意,这只能在调用apply_gradients()之后调用,因为apply_gradients()会实际生成这个queuerunner。</target>
        </trans-unit>
        <trans-unit id="d5094d67f3d8892e018bb62aab3647e7a6f48b27" translate="yes" xml:space="preserve">
          <source>Note that this cell is not optimized for performance on GPU. Please use &lt;a href=&quot;cudnnlstm&quot;&gt;&lt;code&gt;tf.compat.v1.keras.layers.CuDNNLSTM&lt;/code&gt;&lt;/a&gt; for better performance on GPU.</source>
          <target state="translated">请注意，此单元未针对GPU的性能进行优化。请使用&lt;a href=&quot;cudnnlstm&quot;&gt; &lt;code&gt;tf.compat.v1.keras.layers.CuDNNLSTM&lt;/code&gt; &lt;/a&gt;在GPU上获得更好的性能。</target>
        </trans-unit>
        <trans-unit id="676d50925133445521758d01e690fca8975be084" translate="yes" xml:space="preserve">
          <source>Note that this cell is not optimized for performance. Please use &lt;code&gt;tf.contrib.cudnn_rnn.CudnnGRU&lt;/code&gt; for better performance on GPU, or &lt;code&gt;tf.contrib.rnn.GRUBlockCellV2&lt;/code&gt; for better performance on CPU.</source>
          <target state="translated">请注意，此单元未针对性能进行优化。请使用 &lt;code&gt;tf.contrib.cudnn_rnn.CudnnGRU&lt;/code&gt; 在GPU上获得更好的性能，或者使用 &lt;code&gt;tf.contrib.rnn.GRUBlockCellV2&lt;/code&gt; 在CPU上获得更好的性能。</target>
        </trans-unit>
        <trans-unit id="eb201df3d2b5bfd572776e39fa9037413277cb8c" translate="yes" xml:space="preserve">
          <source>Note that this cell is not optimized for performance. Please use &lt;code&gt;tf.contrib.cudnn_rnn.CudnnLSTM&lt;/code&gt; for better performance on GPU, or &lt;code&gt;tf.contrib.rnn.LSTMBlockCell&lt;/code&gt; and &lt;code&gt;tf.contrib.rnn.LSTMBlockFusedCell&lt;/code&gt; for better performance on CPU.</source>
          <target state="translated">请注意，此单元未针对性能进行优化。请使用 &lt;code&gt;tf.contrib.cudnn_rnn.CudnnLSTM&lt;/code&gt; 在GPU上获得更好的性能，或者使用 &lt;code&gt;tf.contrib.rnn.LSTMBlockCell&lt;/code&gt; 和 &lt;code&gt;tf.contrib.rnn.LSTMBlockFusedCell&lt;/code&gt; 在CPU上获得更好的性能。</target>
        </trans-unit>
        <trans-unit id="9798837973ed57184ac031583d759a1a635c568b" translate="yes" xml:space="preserve">
          <source>Note that this cell is not optimized for performance. Please use &lt;code&gt;tf.contrib.cudnn_rnn.CudnnLSTM&lt;/code&gt; for better performance on GPU, or &lt;code&gt;tf.contrib.rnn.LSTMBlockCell&lt;/code&gt; and &lt;code&gt;tf.contrib.rnn.LSTMBlockFusedCell&lt;/code&gt; for better performance on CPU. References: Long short-term memory recurrent neural network architectures for large scale acoustic modeling: &lt;a href=&quot;https://www.isca-speech.org/archive/interspeech_2014/i14_0338.html&quot;&gt;Sak et al., 2014&lt;/a&gt; (&lt;a href=&quot;https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0338.pdf&quot;&gt;pdf&lt;/a&gt;) Learning to forget: &lt;a href=&quot;http://digital-library.theiet.org/content/conferences/10.1049/cp_19991218&quot;&gt;Gers et al., 1999&lt;/a&gt; (&lt;a href=&quot;https://arxiv.org/pdf/1409.2329.pdf&quot;&gt;pdf&lt;/a&gt;) Long Short-Term Memory: &lt;a href=&quot;https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735&quot;&gt;Hochreiter et al., 1997&lt;/a&gt; (&lt;a href=&quot;http://ml.jku.at/publications/older/3504.pdf&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83f3a3a4f4f4189819189a9354e97a10007b9dbd" translate="yes" xml:space="preserve">
          <source>Note that this cell is not optimized for performance. Please use &lt;code&gt;tf.contrib.cudnn_rnn.CudnnRNNTanh&lt;/code&gt; for better performance on GPU.</source>
          <target state="translated">请注意，此单元未针对性能进行优化。请使用 &lt;code&gt;tf.contrib.cudnn_rnn.CudnnRNNTanh&lt;/code&gt; 在GPU上获得更好的性能。</target>
        </trans-unit>
        <trans-unit id="27964ccc16ae82fcd7d78d2911af33e20462ca9a" translate="yes" xml:space="preserve">
          <source>Note that this function is different from the corresponding one in sklearn which returns the negative sum.</source>
          <target state="translated">请注意,这个函数与sklearn中相应的函数不同,sklearn返回的是负数。</target>
        </trans-unit>
        <trans-unit id="ec2b844ffc0cde99c0b5406566187f053bcc143c" translate="yes" xml:space="preserve">
          <source>Note that this is different from &lt;code&gt;initialized_value()&lt;/code&gt; which runs the op that initializes the variable before returning its value. This method returns the tensor that is used by the op that initializes the variable.</source>
          <target state="translated">请注意，这与 &lt;code&gt;initialized_value()&lt;/code&gt; 不同，后者在返回变量值之前运行用于初始化变量的操作。此方法返回由初始化变量的op使用的张量。</target>
        </trans-unit>
        <trans-unit id="4269a0cb623feb3d775921dbf7f25dbea72e2e6a" translate="yes" xml:space="preserve">
          <source>Note that this is unrelated to the &lt;a href=&quot;graph#graph_def_versions&quot;&gt;&lt;code&gt;tf.Graph.graph_def_versions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">请注意，这与&lt;a href=&quot;graph#graph_def_versions&quot;&gt; &lt;code&gt;tf.Graph.graph_def_versions&lt;/code&gt; &lt;/a&gt;无关。</target>
        </trans-unit>
        <trans-unit id="e4641dbf377897d7cafbc94dd8e7458b0ed9ea46" translate="yes" xml:space="preserve">
          <source>Note that this method performs no computation, and simply looks up a JVP that was already computed (unlike backprop using a &lt;a href=&quot;../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, where the computation happens on the call to &lt;code&gt;tape.gradient&lt;/code&gt;).</source>
          <target state="translated">请注意，此方法不执行任何计算，而只是查找已经计算出的JVP（与使用&lt;a href=&quot;../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 的backprop不同&lt;/a&gt;，在计算时发生在对 &lt;code&gt;tape.gradient&lt;/code&gt; 的调用上）。</target>
        </trans-unit>
        <trans-unit id="0a411633494993285b2ca66ea033f5305ceb9ccd" translate="yes" xml:space="preserve">
          <source>Note that this op fingerprints the raw underlying buffer, and it does not fingerprint Tensor's metadata such as data type and/or shape. For example, the fingerprint values are invariant under reshapes and bitcasts as long as the batch dimension remain the same:</source>
          <target state="translated">请注意,这个操作对原始的底层缓冲区进行指纹识别,而不是指纹识别Tensor的元数据,比如数据类型和/或形状。例如,只要批次维度保持不变,指纹值在重塑和位播下是不变的。</target>
        </trans-unit>
        <trans-unit id="ce844cbeee4ae1222f32165361aadbb88f08e18c" translate="yes" xml:space="preserve">
          <source>Note that this op is not exposed to users directly, but is invoked in tf.data rewrites.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9dba7b57bd500edaeb9bc0b8ab7f9a2c33f1255" translate="yes" xml:space="preserve">
          <source>Note that this op only supports floating point and complex dtypes, due to tf.sqrt only supporting these types.</source>
          <target state="translated">需要注意的是,由于tf.sqrt只支持浮点和复数类型,所以这个操作只支持这些类型。</target>
        </trans-unit>
        <trans-unit id="c0799a68acd5cc28b1a646b6509f272d67280d7d" translate="yes" xml:space="preserve">
          <source>Note that this op splits strings into bytes, not unicode characters. To split strings into unicode characters, use &lt;a href=&quot;unicode_split&quot;&gt;&lt;code&gt;tf.strings.unicode_split&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">请注意，此操作将字符串拆分为字节，而不是unicode字符。要将字符串拆分为unicode字符，请使用&lt;a href=&quot;unicode_split&quot;&gt; &lt;code&gt;tf.strings.unicode_split&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e12d122ac6753337440a18a6a1d0aa802f8b84be" translate="yes" xml:space="preserve">
          <source>Note that this process modifies decorator_func.</source>
          <target state="translated">请注意,这个过程修改了 decorator_func。</target>
        </trans-unit>
        <trans-unit id="876236a77b480dcabe6632d74a00e2db650c95d7" translate="yes" xml:space="preserve">
          <source>Note that this routine only supports wildcard characters in the basename portion of the pattern, not in the directory portion. Note also that the order of filenames returned is deterministic.</source>
          <target state="translated">请注意,这个例程只支持模式中基名部分的通配符,不支持目录部分的通配符。还请注意,返回的文件名的顺序是确定的。</target>
        </trans-unit>
        <trans-unit id="f0d1946702052ea01b4b396d107d11992b78bac4" translate="yes" xml:space="preserve">
          <source>Note that this will set this session and the graph as global defaults.</source>
          <target state="translated">请注意,这将把这个会话和图形设置为全局默认值。</target>
        </trans-unit>
        <trans-unit id="3be9b356e9054ff0eaea728af20417c9c659c12b" translate="yes" xml:space="preserve">
          <source>Note that to be serialized and deserialized, classes must implement the &lt;code&gt;get_config()&lt;/code&gt; method. Functions do not have this requirement.</source>
          <target state="translated">请注意，要进行序列化和反序列化，类必须实现 &lt;code&gt;get_config()&lt;/code&gt; 方法。函数没有此要求。</target>
        </trans-unit>
        <trans-unit id="ebaec6d2ae38f8ee01d39fb611110d3391887ecd" translate="yes" xml:space="preserve">
          <source>Note that to load a previously saved dataset, you need to specify &lt;code&gt;element_spec&lt;/code&gt; -- a type signature of the elements of the saved dataset, which can be obtained via &lt;a href=&quot;../dataset#element_spec&quot;&gt;&lt;code&gt;tf.data.Dataset.element_spec&lt;/code&gt;&lt;/a&gt;. This requirement exists so that shape inference of the loaded dataset does not need to perform I/O.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b25355986fc7d3e9088919e96d5864bee0968626" translate="yes" xml:space="preserve">
          <source>Note that unlike &lt;a href=&quot;checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore()&lt;/code&gt;&lt;/a&gt;, this method doesn't return a load status object that users can run assertions on (e.g. assert_consumed()). Thus to run assertions, users should directly use &lt;a href=&quot;checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore()&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a91f1f0560a4b9ed496da98bbfb0a9885720ad4" translate="yes" xml:space="preserve">
          <source>Note that up to and including version 1.0, it was allowed (though explicitly discouraged) to pass False to the reuse argument, yielding undocumented behaviour slightly different from None. Starting at 1.1.0 passing None and False as reuse has exactly the same effect.</source>
          <target state="translated">请注意,在1.0版本之前(包括1.0版本),允许(虽然明确不鼓励)将False传递给重用参数,从而产生与None略有不同的无文档行为。从1.1.0版开始,传递None和False作为重用,效果完全一样。</target>
        </trans-unit>
        <trans-unit id="51f5f3efe60d6cb37d9a6a407c1cdfb18af2859e" translate="yes" xml:space="preserve">
          <source>Note that we don't have to implement &lt;code&gt;from_config&lt;/code&gt; in the example above since the constructor arguments of the class the keys in the config returned by &lt;code&gt;get_config&lt;/code&gt; are the same. In this case, the default &lt;code&gt;from_config&lt;/code&gt; works fine.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="569aab2ab65e778fc24ba965c22ff099243998b7" translate="yes" xml:space="preserve">
          <source>Note that we provide a default version of &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; that is used when no other strategy is in scope, that provides the same API with reasonable default behavior.</source>
          <target state="translated">请注意，我们提供了&lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;的默认版本，该默认版本在范围内没有其他策略时使用，它提供具有合理默认行为的相同API。</target>
        </trans-unit>
        <trans-unit id="c752a62b7496ca1c5e19ed8c92074d65d7e426d0" translate="yes" xml:space="preserve">
          <source>Note that we provide a default version of &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; that is used when no other strategy is in scope, that provides the same API with reasonable default behavior.</source>
          <target state="translated">请注意，我们提供了&lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;的默认版本，该默认版本在范围内没有其他策略时使用，它提供具有合理默认行为的相同API。</target>
        </trans-unit>
        <trans-unit id="49df504efd1de90320b92bbd82907222413f3073" translate="yes" xml:space="preserve">
          <source>Note that when P_A == 0 the above calculation simplifies into</source>
          <target state="translated">请注意,当P_A==0时,上述计算简化为</target>
        </trans-unit>
        <trans-unit id="13a872977c3f70438c317712189bdc6190cf3b3e" translate="yes" xml:space="preserve">
          <source>Note that when the &lt;code&gt;window&lt;/code&gt; transformation is applied to a dataset of nested elements, it produces a dataset of nested windows.</source>
          <target state="translated">请注意，将 &lt;code&gt;window&lt;/code&gt; 转换应用于嵌套元素的数据集时，它将生成嵌套窗口的数据集。</target>
        </trans-unit>
        <trans-unit id="1ed0aac11222ae873f11e5dc6c38c61ae3205a36" translate="yes" xml:space="preserve">
          <source>Note that when using models you should ensure that your variables exist when using &lt;code&gt;watch_accessed_variables=False&lt;/code&gt;. Otherwise it's quite easy to make your first iteration not have any gradients:</source>
          <target state="translated">请注意，在使用模型时，应确保在使用 &lt;code&gt;watch_accessed_variables=False&lt;/code&gt; 时变量存在。否则，让您的第一次迭代没有任何渐变是很容易的：</target>
        </trans-unit>
        <trans-unit id="e220ac89835270e7612d3930a3852330a3191ee5" translate="yes" xml:space="preserve">
          <source>Note that you can manually set the global session via &lt;code&gt;K.set_session(sess)&lt;/code&gt;.</source>
          <target state="translated">请注意，您可以通过 &lt;code&gt;K.set_session(sess)&lt;/code&gt; 手动设置全局会话。</target>
        </trans-unit>
        <trans-unit id="35e829814838a40a87e9a64882348df552c61fff" translate="yes" xml:space="preserve">
          <source>Note that you must re-normalize by 1/(2n) to obtain an inverse if &lt;code&gt;norm&lt;/code&gt; is not &lt;code&gt;'ortho'&lt;/code&gt;. That is: &lt;code&gt;signal == idct(dct(signal)) * 0.5 / signal.shape[-1]&lt;/code&gt;. When &lt;code&gt;norm='ortho'&lt;/code&gt;, we have: &lt;code&gt;signal == idct(dct(signal, norm='ortho'), norm='ortho')&lt;/code&gt;.</source>
          <target state="translated">请注意，如果 &lt;code&gt;norm&lt;/code&gt; 不是 &lt;code&gt;'ortho'&lt;/code&gt; ，则必须以1 /（2n）重新归一化以获得逆。也就是说： &lt;code&gt;signal == idct(dct(signal)) * 0.5 / signal.shape[-1]&lt;/code&gt; 。当 &lt;code&gt;norm='ortho'&lt;/code&gt; ，我们有： &lt;code&gt;signal == idct(dct(signal, norm='ortho'), norm='ortho')&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="695160d316b33a7e2dd72201788c50694f5e52a1" translate="yes" xml:space="preserve">
          <source>Note that you still have to call the &lt;code&gt;save()&lt;/code&gt; method to save the model. Passing these arguments to the constructor will not save variables automatically for you.</source>
          <target state="translated">请注意，您仍然必须调用 &lt;code&gt;save()&lt;/code&gt; 方法来保存模型。将这些参数传递给构造函数不会自动为您保存变量。</target>
        </trans-unit>
        <trans-unit id="1299f149def6c9c56c9387e40d116ad83071db3f" translate="yes" xml:space="preserve">
          <source>Note that you will likely need to use &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; with the returned dataset to further distribute it with the strategy.</source>
          <target state="translated">请注意，您可能需要对返回的数据集使用 &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; ，以通过策略进一步进行分配。</target>
        </trans-unit>
        <trans-unit id="4f808324e8fca6d8d656dc7ad92ecdbee3860f1b" translate="yes" xml:space="preserve">
          <source>Note that you will likely need to use tf.distribute.Strategy.experimental_distribute_dataset with the returned dataset to further distribute it with the strategy.</source>
          <target state="translated">请注意,你可能需要对返回的数据集使用tf.distribut.Strategy.experimental_distribute_dataset来进一步用策略分发。</target>
        </trans-unit>
        <trans-unit id="dc8bdbc21ffa96ba14f99f122f39d6ce850bbe4b" translate="yes" xml:space="preserve">
          <source>Note that your application's flags are still defined the usual way using absl.flags DEFINE_flag() type functions.</source>
          <target state="translated">需要注意的是,你的应用程序的标志仍然是用absl.flags DEFINE_flag()类型的函数来定义的。</target>
        </trans-unit>
        <trans-unit id="42533e28866644d24b25744a516d1f6960f87b1d" translate="yes" xml:space="preserve">
          <source>Note that, the args of &lt;code&gt;features&lt;/code&gt; and &lt;code&gt;mode&lt;/code&gt; are most likely not used, but some Head implementations may require them.</source>
          <target state="translated">请注意， &lt;code&gt;features&lt;/code&gt; 和 &lt;code&gt;mode&lt;/code&gt; 的参数很可能未使用，但是某些Head实现可能需要它们。</target>
        </trans-unit>
        <trans-unit id="285f98e8d01e4962eff6724b78a3c6724d0931e6" translate="yes" xml:space="preserve">
          <source>Note that:</source>
          <target state="translated">请注意:</target>
        </trans-unit>
        <trans-unit id="a06ae04ab8de10c8c7fb61efdc138663538e5ae8" translate="yes" xml:space="preserve">
          <source>Note the &lt;code&gt;'mixed_float16'&lt;/code&gt; policy will apply loss scaling by default in &lt;a href=&quot;../../model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../model#train_on_batch&quot;&gt;&lt;code&gt;Model.train_on_batch&lt;/code&gt;&lt;/a&gt;, and other training methods. If no such method is used (e.g., a custom training loop is used) and &lt;code&gt;'mixed_float16'&lt;/code&gt; is used, the loss scale must be manually applied. See &lt;a href=&quot;lossscaleoptimizer&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.LossScaleOptimizer&lt;/code&gt;&lt;/a&gt; for details. For &lt;code&gt;'mixed_bfloat16'&lt;/code&gt;, no loss scaling is done and loss scaling never needs to be manually applied.</source>
          <target state="translated">请注意，默认情况下， &lt;code&gt;'mixed_float16'&lt;/code&gt; 策略将在&lt;a href=&quot;../../model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;../../model#train_on_batch&quot;&gt; &lt;code&gt;Model.train_on_batch&lt;/code&gt; &lt;/a&gt;和其他训练方法中应用损耗缩放。如果不使用这种方法（例如，使用自定义训练循环）并且使用 &lt;code&gt;'mixed_float16'&lt;/code&gt; ，则必须手动应用损失标度。有关详细信息，请参见&lt;a href=&quot;lossscaleoptimizer&quot;&gt; &lt;code&gt;tf.keras.mixed_precision.experimental.LossScaleOptimizer&lt;/code&gt; &lt;/a&gt;。对于 &lt;code&gt;'mixed_bfloat16'&lt;/code&gt; ，不进行损耗定标，并且不需要手动应用损耗定标。</target>
        </trans-unit>
        <trans-unit id="3a99f9a50883bd4f6df261cd21c56e862effa7e6" translate="yes" xml:space="preserve">
          <source>Note this copies data in &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d91d968a0531cc5f1293686bacf481ffdae11ca" translate="yes" xml:space="preserve">
          <source>Note to Implementors of &lt;a href=&quot;clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; subclass: In addition to these abstract methods, when task_type, task_id, and rpc_layer attributes are applicable, you should also implement them either as properties with getters or setters, or directly set the attributes &lt;code&gt;self._task_type&lt;/code&gt;, &lt;code&gt;self._task_id&lt;/code&gt;, or &lt;code&gt;self._rpc_layer&lt;/code&gt; so the base class' getters and setters are used. See &lt;a href=&quot;simpleclusterresolver#__init__&quot;&gt;&lt;code&gt;tf.distribute.cluster&lt;em&gt;resolver.SimpleClusterResolver.&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;_&lt;/code&gt;&lt;/a&gt; for an example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79b85dc8d51a6da6086679dde9574f6544327b4a" translate="yes" xml:space="preserve">
          <source>Note to Implementors: In addition to these abstract methods, you must also implement the task_type, task_id, and rpc_layer attributes. You may choose to implement them either as properties with getters or setters or directly set the attributes.</source>
          <target state="translated">实施者注意。除了这些抽象方法之外,你还必须实现task_type、task_id和rpc_layer属性。你可以选择将它们作为带有获取器或设置器的属性来实现,或者直接设置这些属性。</target>
        </trans-unit>
        <trans-unit id="6c63f7b2e1fe52b70cb6e4024c044d873867e7b1" translate="yes" xml:space="preserve">
          <source>Note, above &lt;code&gt;P(a, x)&lt;/code&gt; (&lt;code&gt;Igamma&lt;/code&gt;) is the lower regularized complete Gamma function.</source>
          <target state="translated">请注意，在 &lt;code&gt;P(a, x)&lt;/code&gt; （ &lt;code&gt;Igamma&lt;/code&gt; ）上方是较低的正规化完整Gamma函数。</target>
        </trans-unit>
        <trans-unit id="de2540fadbae1eb6e760d4d7e7f13dc8a00af55b" translate="yes" xml:space="preserve">
          <source>Note, above &lt;code&gt;Q(a, x)&lt;/code&gt; (&lt;code&gt;Igammac&lt;/code&gt;) is the upper regularized complete Gamma function.</source>
          <target state="translated">注意，上面的 &lt;code&gt;Q(a, x)&lt;/code&gt; （ &lt;code&gt;Igammac&lt;/code&gt; ）是上部正规化的完整Gamma函数。</target>
        </trans-unit>
        <trans-unit id="81ae6a2ab2fd652b5b5c6e0c656f1aaca1c48948" translate="yes" xml:space="preserve">
          <source>Note, by default (unless a custom &lt;code&gt;dropout_state_filter&lt;/code&gt; is provided), the memory state (&lt;code&gt;c&lt;/code&gt; component of any &lt;code&gt;LSTMStateTuple&lt;/code&gt;) passing through a &lt;code&gt;DropoutWrapper&lt;/code&gt; is never modified. This behavior is described in the above article.</source>
          <target state="translated">请注意，默认情况下（除非提供了自定义的 &lt;code&gt;dropout_state_filter&lt;/code&gt; ），永远不会修改通过 &lt;code&gt;DropoutWrapper&lt;/code&gt; 传递的内存状态（任何 &lt;code&gt;LSTMStateTuple&lt;/code&gt; 的 &lt;code&gt;c&lt;/code&gt; 组件）。上面的文章中描述了此行为。</target>
        </trans-unit>
        <trans-unit id="61353057d98afbcb05a7bdf960d064322ec004e6" translate="yes" xml:space="preserve">
          <source>Note, if &lt;code&gt;cell.output_size&lt;/code&gt; is a (possibly nested) tuple of integers or &lt;code&gt;TensorShape&lt;/code&gt; objects, then &lt;code&gt;outputs&lt;/code&gt; will be a tuple having the same structure as &lt;code&gt;cell.output_size&lt;/code&gt;, containing Tensors having shapes corresponding to the shape data in &lt;code&gt;cell.output_size&lt;/code&gt;.</source>
          <target state="translated">请注意，如果 &lt;code&gt;cell.output_size&lt;/code&gt; 是一个整数（或嵌套的）整数或 &lt;code&gt;TensorShape&lt;/code&gt; 对象的元组，则 &lt;code&gt;outputs&lt;/code&gt; 将是与 &lt;code&gt;cell.output_size&lt;/code&gt; 具有相同结构的元组，其中包含具有与 &lt;code&gt;cell.output_size&lt;/code&gt; 中的形状数据相对应的形状的Tensors。</target>
        </trans-unit>
        <trans-unit id="e9b9d0e36c25b2c5ab37239f927ff36f6746704b" translate="yes" xml:space="preserve">
          <source>Note, most python users will want to use the Python &lt;a href=&quot;../tensor#__getitem__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../variable#__getitem__&quot;&gt;&lt;code&gt;Variable.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; rather than this op directly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa2d99a7e37b130d2bf017f7c652bbb40183becd" translate="yes" xml:space="preserve">
          <source>Note, once keras style has been set, it is set globally for the entire program and cannot be unset.</source>
          <target state="translated">需要注意的是,一旦keras样式被设置,它将被全局地设置在整个程序中,不能被取消设置。</target>
        </trans-unit>
        <trans-unit id="03b559d2e1aefa68c92b87df3d6a56014c371f34" translate="yes" xml:space="preserve">
          <source>Note, preferably use &lt;code&gt;VarLenFeature&lt;/code&gt; (possibly in combination with a &lt;code&gt;SequenceExample&lt;/code&gt;) in order to parse out &lt;code&gt;SparseTensor&lt;/code&gt;s instead of &lt;code&gt;SparseFeature&lt;/code&gt; due to its simplicity.</source>
          <target state="translated">注意，为了解析 &lt;code&gt;SparseTensor&lt;/code&gt; 而不是 &lt;code&gt;SparseFeature&lt;/code&gt; ，最好使用 &lt;code&gt;VarLenFeature&lt;/code&gt; （可能与 &lt;code&gt;SequenceExample&lt;/code&gt; 结合使用），因为它很简单。</target>
        </trans-unit>
        <trans-unit id="7b4548198a643d107f04994df0dd15e63e85cc8f" translate="yes" xml:space="preserve">
          <source>Note, that this is somewhat like builtin Python file I/O, but there are semantic differences to make it more efficient for some backing filesystems. For example, a write mode file will not be opened until the first write call (to minimize RPC invocations in network filesystems).</source>
          <target state="translated">请注意,这有点像内置的Python文件I/O,但有语义上的差异,以使它对一些后盾文件系统更有效。例如,一个写模式的文件在第一次写调用之前不会被打开(以减少网络文件系统中的RPC调用)。</target>
        </trans-unit>
        <trans-unit id="0d192db9c1f8a94502f84b9eca72dad3700d8f3f" translate="yes" xml:space="preserve">
          <source>Note, the batch shapes for the inputs only need to broadcast.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="translated">Note:</target>
        </trans-unit>
        <trans-unit id="bd1a113245b76f772cbd5a8d732d7b5bbdccbba7" translate="yes" xml:space="preserve">
          <source>Notes (assuming we're getting a commandline of some sort as our input): --&amp;gt; For duplicate flags, the last one we hit should &quot;win&quot;. --&amp;gt; Since flags that appear later win, a flagfile's settings can be &quot;weak&quot; if the --flagfile comes at the beginning of the argument sequence, and it can be &quot;strong&quot; if the --flagfile comes at the end. --&amp;gt; A further &quot;--flagfile=</source>
          <target state="translated">注意事项（假设我们得到某种命令行作为输入）：-&amp;gt;对于重复的标志，我们打到的最后一个应该&amp;ldquo;获胜&amp;rdquo;。-&amp;gt;由于以后出现的标志会获胜，因此如果--flagfile位于参数序列的开头，则标志文件的设置可以为&amp;ldquo;弱&amp;rdquo;，如果--flagfile位于末尾，则标志文件的设置可以为&amp;ldquo;强&amp;rdquo;。-&amp;gt;再加上一个&amp;ldquo; --flagfile =</target>
        </trans-unit>
        <trans-unit id="9c3befe7e22c8667bc957541f49b0ee79970b588" translate="yes" xml:space="preserve">
          <source>Notes:</source>
          <target state="translated">Notes:</target>
        </trans-unit>
        <trans-unit id="13a8c93c592fc92e9aecac52a9be4b756c401a93" translate="yes" xml:space="preserve">
          <source>Notes: The parent directories need to exist. Use &lt;a href=&quot;../../../io/gfile/makedirs&quot;&gt;&lt;code&gt;tf.io.gfile.makedirs&lt;/code&gt;&lt;/a&gt; instead if there is the possibility that the parent dirs don't exist.</source>
          <target state="translated">注意：父目录必须存在。如果父目录可能不存在，请改用&lt;a href=&quot;../../../io/gfile/makedirs&quot;&gt; &lt;code&gt;tf.io.gfile.makedirs&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="323fb8b8573630ac70581d8cdaf19bf54bdb5796" translate="yes" xml:space="preserve">
          <source>Notes: The parent directories need to exist. Use &lt;a href=&quot;makedirs&quot;&gt;&lt;code&gt;tf.io.gfile.makedirs&lt;/code&gt;&lt;/a&gt; instead if there is the possibility that the parent dirs don't exist.</source>
          <target state="translated">注意：父目录必须存在。如果父目录可能不存在，请改用&lt;a href=&quot;makedirs&quot;&gt; &lt;code&gt;tf.io.gfile.makedirs&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1b3f141ab87179d0755abc1d4da67f0c04e3ab7c" translate="yes" xml:space="preserve">
          <source>Nothing.</source>
          <target state="translated">Nothing.</target>
        </trans-unit>
        <trans-unit id="df411adcbc859409d5288ffe48789d187b06b316" translate="yes" xml:space="preserve">
          <source>Notice how this function avoids making a numpy array directly. This is because it is important to not hold actual numpy views to the data longer than necessary. If you do, then the interpreter can no longer be invoked, because it is possible the interpreter would resize and invalidate the referenced tensors. The NumPy API doesn't allow any mutability of the the underlying buffers.</source>
          <target state="translated">请注意这个函数如何避免直接制作一个numpy数组。这是因为不要将实际的numpy视图保持在数据上超过必要的时间,这一点很重要。如果你这样做了,那么解释器就不能再被调用了,因为解释器有可能会调整大小,并使引用的tensors无效。NumPy API不允许底层缓冲区的任何突变。</target>
        </trans-unit>
        <trans-unit id="1d50c26e0e094319167ab9cf4ea2664a67497326" translate="yes" xml:space="preserve">
          <source>Notice that &lt;code&gt;scale&lt;/code&gt; has semantics more similar to standard deviation than variance. However it is not actually the std. deviation; the Student's t-distribution std. dev. is &lt;code&gt;scale sqrt(df / (df - 2))&lt;/code&gt; when &lt;code&gt;df &amp;gt; 2&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;scale&lt;/code&gt; 语义比方差更类似于标准差。但是，它实际上不是std。偏差; 学生的t分布标准。开发。是 &lt;code&gt;df &amp;gt; 2&lt;/code&gt; 时的 &lt;code&gt;scale sqrt(df / (df - 2))&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b5e94b13635d875908427bb8c4b6c6fda85ec9a6" translate="yes" xml:space="preserve">
          <source>Notice that with Layer Normalization the normalization happens across the axes &lt;em&gt;within&lt;/em&gt; each example, rather than across different examples in the batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4beac5b490cc1843a3a26957320103b18894807" translate="yes" xml:space="preserve">
          <source>NthElement</source>
          <target state="translated">NthElement</target>
        </trans-unit>
        <trans-unit id="feaa006c7cb998d0daf98aa74c2dc0b3047ff5a1" translate="yes" xml:space="preserve">
          <source>NumPy advanced indexing is currently not supported.</source>
          <target state="translated">目前不支持NumPy高级索引。</target>
        </trans-unit>
        <trans-unit id="8269e97856d8215a91d4e6b9cbb4da8af671827e" translate="yes" xml:space="preserve">
          <source>Number of GPUs available on each node. Defaults to the number of GPUs reported by nvidia-smi</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fbacc138562658bc8bf85db215daa9948c27734" translate="yes" xml:space="preserve">
          <source>Number of GPUs to be used for each task. Default is to evenly distribute the gpus_per_node to tasks_per_node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fadbeafab5975a1d39cf73aaf8ae5008b25f914e" translate="yes" xml:space="preserve">
          <source>Number of PS servers to start.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff1bed83b6ad2769b544f9574354263198f224c9" translate="yes" xml:space="preserve">
          <source>Number of accumulated gradients currently in accumulator.</source>
          <target state="translated">当前蓄能器中的累计梯度数。</target>
        </trans-unit>
        <trans-unit id="4d460bea4c03e911bf946d418f5de7c62b94cbf5" translate="yes" xml:space="preserve">
          <source>Number of axes of the tensor. At least one of {&lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;ndim&lt;/code&gt;} must be specified. If both are specified, &lt;code&gt;shape&lt;/code&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c28eef31422890e190a8a735bef2bbc3ca45dd3f" translate="yes" xml:space="preserve">
          <source>Number of batch in the Sequence.</source>
          <target state="translated">序列中的批次数。</target>
        </trans-unit>
        <trans-unit id="13053e03f4102abf06caa055563658bdfd09e0a8" translate="yes" xml:space="preserve">
          <source>Number of buckets to use for out-of-vocabulary keys. Must be greater than zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1443a310f6b8af3c2608621537943e22c0697294" translate="yes" xml:space="preserve">
          <source>Number of burn-in iterations to run.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60150846a32da8a3f98beb66fec64a5013fc543a" translate="yes" xml:space="preserve">
          <source>Number of classes, must be greater than 1 (for 1 class, use &lt;code&gt;BinaryClassHead&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8da73bd74420f129b234734924c59cde9f05631" translate="yes" xml:space="preserve">
          <source>Number of classes, must be greater than 2 (for 2 classes, use &lt;code&gt;BinaryClassHead&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f6a946a099ad04b95847337ff5003475a136d9" translate="yes" xml:space="preserve">
          <source>Number of columns of zeros to add on the left.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="262b0a4d87615eb019b2c38b73f61e9402d24c90" translate="yes" xml:space="preserve">
          <source>Number of epochs with no improvement after which training will be stopped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78b9147de33a1caa5c940ab8a8297f809eb1fa95" translate="yes" xml:space="preserve">
          <source>Number of exports to keep. Older exports will be garbage-collected. Defaults to 5. Set to &lt;code&gt;None&lt;/code&gt; to disable garbage collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f2b3d4e44c2dda30e3b17cb23d237235a76295a" translate="yes" xml:space="preserve">
          <source>Number of feature batches to prefetch in order to improve performance. Recommended value is the number of batches consumed per training step. Defaults to auto-tune.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88c84f9eed23b2738c86fe8c8df27a937f9b93b1" translate="yes" xml:space="preserve">
          <source>Number of gradients that have currently been aggregated in accumulator.</source>
          <target state="translated">蓄能器中目前已聚集的梯度数。</target>
        </trans-unit>
        <trans-unit id="b05bd0cd3e986fd697647079792350137e0dfd9e" translate="yes" xml:space="preserve">
          <source>Number of gradients that needs to have been aggregated</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="901334c141d33a81e7f6b838bfc8fd75d341f913" translate="yes" xml:space="preserve">
          <source>Number of hash bins.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff0fe469cdba9459b286b9c19981fdac86737378" translate="yes" xml:space="preserve">
          <source>Number of hours between each checkpoint to be saved. The default value of 10,000 hours effectively disables the feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cb457c7af7d739ad935cc3f477ed2968c405531" translate="yes" xml:space="preserve">
          <source>Number of label classes. Defaults to 2, namely binary classification. Must be &amp;gt; 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c294a32144f9624cbbda9c7a7085da61f5995d68" translate="yes" xml:space="preserve">
          <source>Number of parallel threads</source>
          <target state="translated">并行线程数</target>
        </trans-unit>
        <trans-unit id="581a69d6b04bd27aab733eeb6af1bf7e4b0d4499" translate="yes" xml:space="preserve">
          <source>Number of periods in the cosine part of the decay. See computation above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11c7cc720b83a68beb323871aa0786b39f0b5b92" translate="yes" xml:space="preserve">
          <source>Number of records to read.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb40d55cc22caebed131af41c5be172e15cf65d0" translate="yes" xml:space="preserve">
          <source>Number of regression labels per example. This is the size of the last dimension of the labels &lt;code&gt;Tensor&lt;/code&gt; (typically, this has shape &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cc1183d27b6ba256c180c5406a346e7cfb3b6b5" translate="yes" xml:space="preserve">
          <source>Number of regression targets per example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c446862c9fbba5e6c6414124c699ded01fef351" translate="yes" xml:space="preserve">
          <source>Number of regression targets per example. This is the size of the last dimension of the labels and logits &lt;code&gt;Tensor&lt;/code&gt; objects (typically, these have shape &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32b55518afa11259f74567f2fe4b54f2649fc1f1" translate="yes" xml:space="preserve">
          <source>Number of rows of a file to use for type inference if record_defaults is not provided. If None, reads all the rows of all the files. Defaults to 100.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3cb9ef46218a468caea3ed00648aafac5dd9f39" translate="yes" xml:space="preserve">
          <source>Number of rows of zeros to add on top.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44335fb001c23a486d732de56f4084297d4c243b" translate="yes" xml:space="preserve">
          <source>Number of scheduling threads for processing batches of work. Determines the number of batches processed in parallel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13a8dd63fe60d7a1f2a10794ccf69c497e49e79f" translate="yes" xml:space="preserve">
          <source>Number of seconds between checks that the model is ready. Used by supervisors when waiting for a chief supervisor to initialize or restore the model. Defaults to 30 seconds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10f9184982d92a54930294d111db397bd65bcef9" translate="yes" xml:space="preserve">
          <source>Number of seconds between the computation of summaries for the event log. Defaults to 120 seconds. Pass 0 to disable summaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8515c0d773c155b18f61d6d697e29d155e7ab5f" translate="yes" xml:space="preserve">
          <source>Number of seconds between the creation of model checkpoints. Defaults to 600 seconds. Pass 0 to disable checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5dd8958e130af8fde509c1a07316b465179d0c9" translate="yes" xml:space="preserve">
          <source>Number of seconds given to threads to stop after &lt;code&gt;close()&lt;/code&gt; has been called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="658b8f1bea052c92de34eb04e9069d61655b83a6" translate="yes" xml:space="preserve">
          <source>Number of seconds given to threads to stop after &lt;code&gt;request_stop()&lt;/code&gt; has been called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7bfe1262ea2958af48678ef5ac23dd9f933390d" translate="yes" xml:space="preserve">
          <source>Number of shards of the internal state table, typically set to match the number of parameter servers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34d86113a104e45e0b3e02a8e51de5244f881023" translate="yes" xml:space="preserve">
          <source>Number of steps for which to evaluate model. If &lt;code&gt;None&lt;/code&gt;, evaluates until &lt;code&gt;input_fn&lt;/code&gt; raises an end-of-input exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb631a87fb87f018b17874b84afef3e290d88f03" translate="yes" xml:space="preserve">
          <source>Number of steps for which to train the model. If &lt;code&gt;None&lt;/code&gt;, train forever or train until &lt;code&gt;input_fn&lt;/code&gt; generates the &lt;code&gt;tf.errors.OutOfRange&lt;/code&gt; error or &lt;code&gt;StopIteration&lt;/code&gt; exception. &lt;code&gt;steps&lt;/code&gt; works incrementally. If you call two times &lt;code&gt;train(steps=10)&lt;/code&gt; then training occurs in total 20 steps. If &lt;code&gt;OutOfRange&lt;/code&gt; or &lt;code&gt;StopIteration&lt;/code&gt; occurs in the middle, training stops before 20 steps. If you don't want to have incremental behavior please set &lt;code&gt;max_steps&lt;/code&gt; instead. If set, &lt;code&gt;max_steps&lt;/code&gt; must be &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4b7a57d8bca55b2ccdae953a7f16590caf9b7a1" translate="yes" xml:space="preserve">
          <source>Number of steps to execute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ef8360dfd574b0130c627395c539a6045e7854c" translate="yes" xml:space="preserve">
          <source>Number of steps to run on device before returning to the host. Note that this can have side-effects on performance, hooks, metrics, summaries etc. This parameter is only used when Distribution Strategy is used with estimator or keras.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b905eda057223872ca4aecb71a934e1232a5fb21" translate="yes" xml:space="preserve">
          <source>Number of tasks in the &lt;code&gt;ps&lt;/code&gt; job. Ignored if &lt;code&gt;cluster&lt;/code&gt; is provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7547f35fb5f82c100cf57ba4f123ff563dc84261" translate="yes" xml:space="preserve">
          <source>Number of tasks running on each node. Can be an integer if the number of tasks per node is constant or a dictionary mapping hostnames to number of tasks on that node. If not set the Slurm environment is queried for the correct mapping.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77df78ef9a250da3c8e34283fa874b2ed31d5b67" translate="yes" xml:space="preserve">
          <source>Number of the elements in the vocabulary. This must be no greater than length of &lt;code&gt;vocabulary_file&lt;/code&gt;, if less than length, later values are ignored. If None, it is set to the length of &lt;code&gt;vocabulary_file&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a83e4648ea913acf6bf2749238a868bc52b4ab88" translate="yes" xml:space="preserve">
          <source>Number of threads to use for parsing &lt;code&gt;Example&lt;/code&gt; tensors into a dictionary of &lt;code&gt;Feature&lt;/code&gt; tensors. Defaults to &lt;code&gt;2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c4e782ca2a84116ac9d0872b233c849cb8aaa90" translate="yes" xml:space="preserve">
          <source>Number of threads used to read &lt;code&gt;Example&lt;/code&gt; records. If &amp;gt;1, the results will be interleaved. Defaults to &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3666fb2f4a22587e8e6f58862bbc81c3a260dff2" translate="yes" xml:space="preserve">
          <source>Number of threads used to read CSV records from files. If &amp;gt;1, the results will be interleaved. Defaults to &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="845613e15354deaccb2f6021644678ee579ecd51" translate="yes" xml:space="preserve">
          <source>Number of timeseries samples in each batch (except maybe the last one).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="149b07a5ad40eff3a0d4bc201df48ef05b22db56" translate="yes" xml:space="preserve">
          <source>Number of tokens to add to the queue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235c58fa9d10805fc80c06497d8dca1e6263a98f" translate="yes" xml:space="preserve">
          <source>Number of total steps for which to train model. If &lt;code&gt;None&lt;/code&gt;, train forever or train until &lt;code&gt;input_fn&lt;/code&gt; generates the &lt;code&gt;tf.errors.OutOfRange&lt;/code&gt; error or &lt;code&gt;StopIteration&lt;/code&gt; exception. If set, &lt;code&gt;steps&lt;/code&gt; must be &lt;code&gt;None&lt;/code&gt;. If &lt;code&gt;OutOfRange&lt;/code&gt; or &lt;code&gt;StopIteration&lt;/code&gt; occurs in the middle, training stops before &lt;code&gt;max_steps&lt;/code&gt; steps. Two calls to &lt;code&gt;train(steps=100)&lt;/code&gt; means 200 training iterations. On the other hand, two calls to &lt;code&gt;train(max_steps=100)&lt;/code&gt; means that the second call will not do any iteration since first call did all 100 steps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="273bc020e0834613612160f28f8fbeb43f04c1ba" translate="yes" xml:space="preserve">
          <source>Number of trials used to construct a sample.</source>
          <target state="translated">用于构建样本的试验次数。</target>
        </trans-unit>
        <trans-unit id="ebe61f4e8d997295a062c34ad481902b3b6562b0" translate="yes" xml:space="preserve">
          <source>Number of unique elements along last dimension of input &lt;code&gt;set&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4282d21a586d4f489202f9a1621f662f3e1f9f72" translate="yes" xml:space="preserve">
          <source>Number of worker servers to start.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9be26548965f26254127fb59be2f650fae5304a" translate="yes" xml:space="preserve">
          <source>Number of workers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="542cf22e18541e5328e5153a53e2cca65eaf14ad" translate="yes" xml:space="preserve">
          <source>Number. How often, in seconds, to flush the pending events and summaries to disk.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e808ec4652e792bc4629deddcaa93266d1c92846" translate="yes" xml:space="preserve">
          <source>Number. Optional global step counter to record with the StepStats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e34a8141e1d6f92d4a15bf9f9dcc20dbf6bfb89" translate="yes" xml:space="preserve">
          <source>Number. Optional global step counter to record with the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a15f179e66623c7f652c48c008e3a77196a71b0" translate="yes" xml:space="preserve">
          <source>Number. Optional global step value to record with the summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ba31ab5ba03d8c4b06ac105f5b58f57aa7ad256" translate="yes" xml:space="preserve">
          <source>Number. Time boundaries at which to call &lt;code&gt;target&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdd501c55a07a059d3575f35611deaf7f9fa0326" translate="yes" xml:space="preserve">
          <source>Numeric &lt;code&gt;Tensor&lt;/code&gt;, same dtype as and broadcastable to &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aa1ffaa27e1c026cd21b818569e06710d6bde29" translate="yes" xml:space="preserve">
          <source>Numeric &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1af01a6a3a60a69ffe9330122a83273e0c190b18" translate="yes" xml:space="preserve">
          <source>Numeric threshold for the given metric.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="991ad41f4eb1372ed8d8090d4cf371d4b165ad81" translate="yes" xml:space="preserve">
          <source>Numpy Compatibility</source>
          <target state="translated">Numpy兼容性</target>
        </trans-unit>
        <trans-unit id="06b868354272c57e8c16e1f12829e0d853934af8" translate="yes" xml:space="preserve">
          <source>Numpy array (will not flatten):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30f1b2ab4e0ff2c9c870d869e66c9512f7e0f7b4" translate="yes" xml:space="preserve">
          <source>Numpy array - value of the tensor.</source>
          <target state="translated">Numpy数组-张量值。</target>
        </trans-unit>
        <trans-unit id="a35597b786f921773e7dc275ffdfd31a3f525e6e" translate="yes" xml:space="preserve">
          <source>Numpy array encoding a batch of predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b52c8909cd415b3988f376f368311e8008ffea7" translate="yes" xml:space="preserve">
          <source>Numpy array of input data or tuple. If tuple, the second elements is either another numpy array or a list of numpy arrays, each of which gets passed through as an output without any modifications.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86f507ff25e4eb4699de3f618b6d5a2bf67e670a" translate="yes" xml:space="preserve">
          <source>Numpy array of sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8a87bc965104f891b4cd2e32d4597348172e3d5" translate="yes" xml:space="preserve">
          <source>Numpy array of targets data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f6bec0de1193a4da3e16558eea99c89819c877b" translate="yes" xml:space="preserve">
          <source>Numpy array or TensorFlow tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25a4598b57b4dc9d9807e62dda4b423a5d0ab0ad" translate="yes" xml:space="preserve">
          <source>Numpy array or eager tensor containing consecutive data points (timesteps). Axis 0 is expected to be the time dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d106b83336bf681f22523baafa2f40caeadc13d5" translate="yes" xml:space="preserve">
          <source>Numpy array to normalize.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="011364b0e827a045890c19110f6278e68c030895" translate="yes" xml:space="preserve">
          <source>Numpy array with shape &lt;code&gt;(len(sequences), maxlen)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1e2609b31e3d2e9ce0cf87ec3f24aa44820553d" translate="yes" xml:space="preserve">
          <source>Numpy array(s) of predictions.</source>
          <target state="translated">Numpy预测数组。</target>
        </trans-unit>
        <trans-unit id="fd92b1e6cdd1c6eb843df99f6c032fd62515cdb2" translate="yes" xml:space="preserve">
          <source>Numpy array, initial value of the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bd78ceaa60a01fb740fe15fd8b40b08463c3e46" translate="yes" xml:space="preserve">
          <source>Numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="586425c3ed508309560dea818b51f3e5895cbc95" translate="yes" xml:space="preserve">
          <source>Numpy equivalent is &lt;code&gt;tensor[mask]&lt;/code&gt;.</source>
          <target state="translated">numpy等效于 &lt;code&gt;tensor[mask]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e579f4166acc6d45575c924c3e813775a47fa39d" translate="yes" xml:space="preserve">
          <source>OPTIMIZE_FOR_LATENCY Deprecated. Does the same as DEFAULT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ad9083737b233fb380047614a5463018accc3d5" translate="yes" xml:space="preserve">
          <source>OPTIMIZE_FOR_SIZE Deprecated. Does the same as DEFAULT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0bec7241f649c869673060c3e29bbf228431bab" translate="yes" xml:space="preserve">
          <source>Object of type &lt;code&gt;CustomObjectScope&lt;/code&gt;.</source>
          <target state="translated">类型为 &lt;code&gt;CustomObjectScope&lt;/code&gt; 的对象。</target>
        </trans-unit>
        <trans-unit id="4779701bd20a5a61c58bdc831a0015bc1da5645e" translate="yes" xml:space="preserve">
          <source>Object to be checked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0688906bde395ec5cf13c83ae2cab47ade9ad65d" translate="yes" xml:space="preserve">
          <source>Object to compare against.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88bc41dfbd4c0979d50c81310b3ae4670a2d1f30" translate="yes" xml:space="preserve">
          <source>Objects exported with &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; additionally have trackable objects and functions assigned to attributes:</source>
          <target state="translated">使用&lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt;导出的对象还具有可跟踪的对象和分配给属性的功能：</target>
        </trans-unit>
        <trans-unit id="dbc1198baa525915f9df34e4b9a278a51a386960" translate="yes" xml:space="preserve">
          <source>Objects of this class are intended to be provided as the optimizer argument (though LinearSDCA objects do not implement the &lt;code&gt;tf.train.Optimizer&lt;/code&gt; interface) when creating &lt;a href=&quot;../linearclassifier&quot;&gt;&lt;code&gt;tf.estimator.LinearClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../linearregressor&quot;&gt;&lt;code&gt;tf.estimator.LinearRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">在创建&lt;a href=&quot;../linearclassifier&quot;&gt; &lt;code&gt;tf.estimator.LinearClassifier&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;../linearregressor&quot;&gt; &lt;code&gt;tf.estimator.LinearRegressor&lt;/code&gt; &lt;/a&gt;时， &lt;code&gt;tf.train.Optimizer&lt;/code&gt; 此类的对象作为优化程序参数提供（尽管LinearSDCA对象不实现tf.train.Optimizer接口）。</target>
        </trans-unit>
        <trans-unit id="2fb98b5a16bdcac87f3ce98bd2305af9a9612446" translate="yes" xml:space="preserve">
          <source>Objects that are equal automatically fail.</source>
          <target state="translated">对象相同的自动失败。</target>
        </trans-unit>
        <trans-unit id="b2e5c1e2b5d06754ab3dcf8b43b2dfcb2d52cff3" translate="yes" xml:space="preserve">
          <source>Offset of this &lt;code&gt;Variable&lt;/code&gt; into the full variable, as a list of int.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8c575aea4d9a7963448001e0b8e8eb341a2a2f6" translate="yes" xml:space="preserve">
          <source>Often is the number of classes, labels, or real values to be predicted. Typically, logits is of shape &lt;code&gt;[batch_size, logits_dimension]&lt;/code&gt;.</source>
          <target state="translated">通常是要预测的类，标签或实数值的数量。通常，logits的形状为 &lt;code&gt;[batch_size, logits_dimension]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="584d73536e1737bcb9cda36f8bcb019e2225fbf2" translate="yes" xml:space="preserve">
          <source>Often the use case is that two executions of the same graph, in parallel, wish to run &lt;code&gt;fn&lt;/code&gt;; and we wish to ensure that only one of them executes at a time. This is especially important if &lt;code&gt;fn&lt;/code&gt; modifies one or more variables at a time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e0252e164cdccd96d0caaa6a85c500f8d598fc4" translate="yes" xml:space="preserve">
          <source>Often, a numerical approximation can be used for &lt;code&gt;log_cdf(x)&lt;/code&gt; that yields a more accurate answer than simply taking the logarithm of the &lt;code&gt;cdf&lt;/code&gt; when &lt;code&gt;x &amp;lt;&amp;lt; -1&lt;/code&gt;.</source>
          <target state="translated">通常，数值近似可用于 &lt;code&gt;log_cdf(x)&lt;/code&gt; ，与 &lt;code&gt;x &amp;lt;&amp;lt; -1&lt;/code&gt; 时简单地取 &lt;code&gt;cdf&lt;/code&gt; 的对数相比，它得出的答案更准确。</target>
        </trans-unit>
        <trans-unit id="ed90168839377398da0c664ba554b2bf1e20d14c" translate="yes" xml:space="preserve">
          <source>On CPU, only the &lt;code&gt;embedding_table&lt;/code&gt; property is usable. This will allow you to restore a checkpoint to the object and have access to the table variables:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e0058c2f49888894302e3af1724340ee675bca4" translate="yes" xml:space="preserve">
          <source>On CPU, solution is computed via Gaussian elimination with or without partial pivoting, depending on &lt;code&gt;partial_pivoting&lt;/code&gt; parameter. On GPU, Nvidia's cuSPARSE library is used: &lt;a href=&quot;https://docs.nvidia.com/cuda/cusparse/index.html#gtsv&quot;&gt;https://docs.nvidia.com/cuda/cusparse/index.html#gtsv&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bda78bed7a0f6a710d158e631a2f115e70dd3122" translate="yes" xml:space="preserve">
          <source>On CPU, solution is computed via Gaussian elimination with or without partial pivoting, depending on &lt;code&gt;partial_pivoting&lt;/code&gt; parameter. On GPU, Nvidia's cuSPARSE library is used: https://docs.nvidia.com/cuda/cusparse/index.html#gtsv</source>
          <target state="translated">在CPU上，取决于 &lt;code&gt;partial_pivoting&lt;/code&gt; 参数，通过带或不带部分枢轴的高斯消除来计算解决方案。在GPU上，使用Nvidia的cuSPARSE库：https://docs.nvidia.com/cuda/cusparse/index.html#gtsv</target>
        </trans-unit>
        <trans-unit id="d157d43dbd1b25a38191a077845611dc4b587b8e" translate="yes" xml:space="preserve">
          <source>On CPU: Caller may use SparseTensor or dense padded labels but calling with a SparseTensor will be significantly faster.</source>
          <target state="translated">在CPU上。调用者可以使用SparseTensor或密垫标签,但用SparseTensor调用会快很多。</target>
        </trans-unit>
        <trans-unit id="0d3c2424191fe98a04f507b34139b8292646a77a" translate="yes" xml:space="preserve">
          <source>On ImageNet, this model gets to a top-1 validation accuracy of 0.790 and a top-5 validation accuracy of 0.945.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="611a5e996806cb9084c625b66e4eba3b7f6146d3" translate="yes" xml:space="preserve">
          <source>On TPU and GPU: Only dense padded labels are supported.</source>
          <target state="translated">在TPU和GPU上。只支持密集的软垫标签。</target>
        </trans-unit>
        <trans-unit id="36266786e21b76f70f77a7c2675a1b6ace430516" translate="yes" xml:space="preserve">
          <source>On Using Very Large Target Vocabulary for Neural Machine Translation: &lt;a href=&quot;https://aclanthology.coli.uni-saarland.de/papers/P15-1001/p15-1001&quot;&gt;Jean et al., 2014&lt;/a&gt; (&lt;a href=&quot;http://aclweb.org/anthology/P15-1001&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e6956260fd255d4a418eb60548c30ae41f00092" translate="yes" xml:space="preserve">
          <source>On construction the &lt;code&gt;QueueRunner&lt;/code&gt; adds an op to close the queue. That op will be run if the enqueue ops raise exceptions.</source>
          <target state="translated">在构造中， &lt;code&gt;QueueRunner&lt;/code&gt; 添加了一个操作以关闭队列。如果入队操作引发异常，则将运行该操作。</target>
        </trans-unit>
        <trans-unit id="b9d75e2931a7af7defcbdef66f71252695d35e54" translate="yes" xml:space="preserve">
          <source>On each replica, the input is split into &lt;code&gt;split_count&lt;/code&gt; blocks along &lt;code&gt;split_dimension&lt;/code&gt; and send to the other replicas given group_assignment. After receiving &lt;code&gt;split_count&lt;/code&gt; - 1 blocks from other replicas, we concatenate the blocks along &lt;code&gt;concat_dimension&lt;/code&gt; as the output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="582dd7c76bb00f3973025eb377159fc82895a93f" translate="yes" xml:space="preserve">
          <source>On incorrect number of channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ef1ed46c6c76d57d009c22a3702c77081fe2572" translate="yes" xml:space="preserve">
          <source>On the difficulty of training Recurrent Neural Networks: &lt;a href=&quot;http://proceedings.mlr.press/v28/pascanu13.html&quot;&gt;Pascanu et al., 2012&lt;/a&gt; (&lt;a href=&quot;http://proceedings.mlr.press/v28/pascanu13.pdf&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f9810fcd997ace84c6ae88c8ae6fec9dddda47a" translate="yes" xml:space="preserve">
          <source>On the other hand, setting new_shape as [2, 3, 4] is also an error: The third dimension is smaller than the original shape &lt;a href=&quot;and%20an%0a%60invalidargumenterror%60%20will%20be%20raised&quot;&gt;2, 3, 5&lt;/a&gt;.</source>
          <target state="translated">在另一方面，设置new_shape如[2，3，4]也是一个错误：第三尺寸比原始形状更小的&lt;a href=&quot;and%20an%0a%60invalidargumenterror%60%20will%20be%20raised&quot;&gt;2，3，5&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="786e5efaffd2535a0930a115dd35ea4e6cfb94d8" translate="yes" xml:space="preserve">
          <source>Once a visible &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; is initialized one or more &lt;a href=&quot;logicaldevice&quot;&gt;&lt;code&gt;tf.config.LogicalDevice&lt;/code&gt;&lt;/a&gt; objects are created. Use &lt;a href=&quot;set_visible_devices&quot;&gt;&lt;code&gt;tf.config.set_visible_devices&lt;/code&gt;&lt;/a&gt; to configure the visibility of a physical device and &lt;a href=&quot;set_logical_device_configuration&quot;&gt;&lt;code&gt;tf.config.set_logical_device_configuration&lt;/code&gt;&lt;/a&gt; to configure multiple &lt;a href=&quot;logicaldevice&quot;&gt;&lt;code&gt;tf.config.LogicalDevice&lt;/code&gt;&lt;/a&gt; objects for a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt;. This is useful when separation between models is needed or to simulate a multi-device environment.</source>
          <target state="translated">初始化可见的&lt;a href=&quot;physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; 后,&lt;/a&gt;将创建一个或多个&lt;a href=&quot;logicaldevice&quot;&gt; &lt;code&gt;tf.config.LogicalDevice&lt;/code&gt; &lt;/a&gt;对象。使用&lt;a href=&quot;set_visible_devices&quot;&gt; &lt;code&gt;tf.config.set_visible_devices&lt;/code&gt; &lt;/a&gt;配置物理设备的可视性&lt;a href=&quot;set_logical_device_configuration&quot;&gt; &lt;code&gt;tf.config.set_logical_device_configuration&lt;/code&gt; &lt;/a&gt;配置多个&lt;a href=&quot;logicaldevice&quot;&gt; &lt;code&gt;tf.config.LogicalDevice&lt;/code&gt; &lt;/a&gt;的对象&lt;a href=&quot;physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; &lt;/a&gt;。当需要分离模型或模拟多设备环境时，这很有用。</target>
        </trans-unit>
        <trans-unit id="a380a819e0abe835751488f0036f75ec2d80df15" translate="yes" xml:space="preserve">
          <source>Once enabled, the check-numerics mechanism can be disabled by using &lt;a href=&quot;disable_check_numerics&quot;&gt;&lt;code&gt;tf.debugging.disable_check_numerics()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">启用后，可以使用&lt;a href=&quot;disable_check_numerics&quot;&gt; &lt;code&gt;tf.debugging.disable_check_numerics()&lt;/code&gt; &lt;/a&gt;禁用检查数字机制。</target>
        </trans-unit>
        <trans-unit id="0ee7ecde4cf0b08ac81928b426328e497121fde2" translate="yes" xml:space="preserve">
          <source>Once enabled, the dumping can be disabled with the corresponding &lt;code&gt;disable_dump_debug_info()&lt;/code&gt; method under the same Python namespace. Calling this method more than once with the same &lt;code&gt;dump_root&lt;/code&gt; is idempotent. Calling this method more than once with different &lt;code&gt;tensor_debug_mode&lt;/code&gt;s leads to a &lt;code&gt;ValueError&lt;/code&gt;. Calling this method more than once with different &lt;code&gt;circular_buffer_size&lt;/code&gt;s leads to a &lt;code&gt;ValueError&lt;/code&gt;. Calling this method with a different &lt;code&gt;dump_root&lt;/code&gt; abolishes the previously-enabled &lt;code&gt;dump_root&lt;/code&gt;.</source>
          <target state="translated">启用转储后，可以使用相同的Python命名空间下的相应 &lt;code&gt;disable_dump_debug_info()&lt;/code&gt; 方法禁用转储。幂等是用相同的 &lt;code&gt;dump_root&lt;/code&gt; 多次调用此方法。使用不同的 &lt;code&gt;tensor_debug_mode&lt;/code&gt; 多次调用此方法会导致 &lt;code&gt;ValueError&lt;/code&gt; 。调用此方法多有不同，一旦 &lt;code&gt;circular_buffer_size&lt;/code&gt; 小号导致一个 &lt;code&gt;ValueError&lt;/code&gt; 异常。用不同的 &lt;code&gt;dump_root&lt;/code&gt; 调用此方法将废除先前启用的 &lt;code&gt;dump_root&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="46b621bf1b7b42205b3975360b4207fe02efd4d2" translate="yes" xml:space="preserve">
          <source>Once successful, the following actions are also triggered:</source>
          <target state="translated">一旦成功,也会触发以下动作。</target>
        </trans-unit>
        <trans-unit id="fe96882ea18141ec51f448bd8ad39a29aba58073" translate="yes" xml:space="preserve">
          <source>Once the gradients have been computed, push them into gradient accumulators. Each accumulator will check the staleness and drop the stale.</source>
          <target state="translated">一旦计算出梯度,就把它们推到梯度累积器中。每个蓄能器都会检查陈旧度,并丢弃陈旧度。</target>
        </trans-unit>
        <trans-unit id="5356976368fe53ff276ba4b9dbdbb7ba809c3e7f" translate="yes" xml:space="preserve">
          <source>Once the model is created, you can config the model with losses and metrics with &lt;code&gt;model.compile()&lt;/code&gt;, train the model with &lt;code&gt;model.fit()&lt;/code&gt;, or use the model to do prediction with &lt;code&gt;model.predict()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46b705867e9bac681c91b44d28e06299c9cab993" translate="yes" xml:space="preserve">
          <source>Once you have a dataset, you can apply transformations to prepare the data for your model:</source>
          <target state="translated">一旦你有了一个数据集,你就可以应用转换来为你的模型准备数据。</target>
        </trans-unit>
        <trans-unit id="e2ba1b8af4e995cd4f8b31347bc1761b4e9336d6" translate="yes" xml:space="preserve">
          <source>One &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt; and one single &lt;code&gt;bool&lt;/code&gt;, where the result will be calculated by applying logical AND with the single element to each element in the larger Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbf88e448c1bc51a4b3f8189328f9aba8b41698b" translate="yes" xml:space="preserve">
          <source>One &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt; and one single &lt;code&gt;bool&lt;/code&gt;, where the result will be calculated by applying logical XOR with the single element to each element in the larger Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ac2c254b4c0ad15ebd1b8c8457ebec8407fe0cd" translate="yes" xml:space="preserve">
          <source>One &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt; and one single &lt;code&gt;bool&lt;/code&gt;, where the result will be calculated by applying logical AND with the single element to each element in the larger Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f248fea8d481fa70fb6fd8bcec482c686c8d1ef" translate="yes" xml:space="preserve">
          <source>One &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt; and one single &lt;code&gt;bool&lt;/code&gt;, where the result will be calculated by applying logical XOR with the single element to each element in the larger Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae0a4d156ba93b8e18bdeb6a8cf4a1de016abdbb" translate="yes" xml:space="preserve">
          <source>One &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt; and one single &lt;code&gt;bool&lt;/code&gt;, where the result will be calculated by applying logical AND with the single element to each element in the larger Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15b8180597cd55c2da35bbf81b134b7c98a48ba3" translate="yes" xml:space="preserve">
          <source>One &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt; and one single &lt;code&gt;bool&lt;/code&gt;, where the result will be calculated by applying logical XOR with the single element to each element in the larger Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6805a4eabbe180810d68488f7cb9d93684c9c9a" translate="yes" xml:space="preserve">
          <source>One can create a &lt;a href=&quot;optional&quot;&gt;&lt;code&gt;tf.experimental.Optional&lt;/code&gt;&lt;/a&gt; from a value using the &lt;code&gt;from_value()&lt;/code&gt; method:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fefdee3c3c28c0fc420023e879f567b73ea343d" translate="yes" xml:space="preserve">
          <source>One can set &lt;code&gt;use_tpu&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; for testing. All training, evaluation, and predict will be executed on CPU. &lt;code&gt;input_fn&lt;/code&gt; and &lt;code&gt;model_fn&lt;/code&gt; will receive &lt;code&gt;train_batch_size&lt;/code&gt; or &lt;code&gt;eval_batch_size&lt;/code&gt; unmodified as &lt;code&gt;params['batch_size']&lt;/code&gt;.</source>
          <target state="translated">可以将 &lt;code&gt;use_tpu&lt;/code&gt; 设置为 &lt;code&gt;False&lt;/code&gt; 进行测试。所有训练，评估和预测将在CPU上执行。 &lt;code&gt;input_fn&lt;/code&gt; 和 &lt;code&gt;model_fn&lt;/code&gt; 将接收未经修改为 &lt;code&gt;params['batch_size']&lt;/code&gt; &lt;code&gt;train_batch_size&lt;/code&gt; 或 &lt;code&gt;eval_batch_size&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3ade1a29c7a747e136f0b03f2aa63cce0936de3b" translate="yes" xml:space="preserve">
          <source>One common optimization is to break gradients all-reduce into multiple packs so that weight updates can overlap with gradient all-reduce.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fdcea108936dbc246217519733040c88557dfa0" translate="yes" xml:space="preserve">
          <source>One core advantage of the Keras API is it supports mixed precision with Eager execution, i.e. mixed precision outside &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s. The graph rewrite will only affect ops within &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, making it harder to debug if issues occur with mixed precision. The Keras API is also more customizable, as you can override any layer to run in float32 by passing &lt;code&gt;dtype=&quot;float32&quot;&lt;/code&gt; to the layer constructor. Additionally, you can query the dtype of tensors in the model by checking &lt;code&gt;tensor.dtype&lt;/code&gt;. With the graph rewrite, all tensors appear to be float32 since the dtype is only changed under the hood.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cdbd2be2e630d6c954854753e6a1795863db859" translate="yes" xml:space="preserve">
          <source>One example of this is when using TensorFlow's RNN classes with Keras Models or Networks. Because Keras models do not properly set variable scopes, users of RNNs may either accidentally share scopes between two different models, or get errors about variables that already exist.</source>
          <target state="translated">其中一个例子是在使用TensorFlow的RNN类与Keras模型或网络时。由于Keras模型没有正确地设置变量作用域,RNN的用户可能会在两个不同的模型之间意外地共享作用域,或者得到关于已经存在的变量的错误。</target>
        </trans-unit>
        <trans-unit id="2ee7c661e768665b00f9899c7bfa63c6f6693861" translate="yes" xml:space="preserve">
          <source>One might see performance advantages by batching &lt;code&gt;Example&lt;/code&gt; protos with &lt;code&gt;parse_example&lt;/code&gt; instead of using this function directly.</source>
          <target state="translated">通过使用 &lt;code&gt;parse_example&lt;/code&gt; 批处理 &lt;code&gt;Example&lt;/code&gt; 原型而不是直接使用此函数，可能会看到性能优势。</target>
        </trans-unit>
        <trans-unit id="f908f1e8f19c18970ec6aa122bec0a6cf986df6f" translate="yes" xml:space="preserve">
          <source>One of &quot;CONSTANT&quot;, &quot;REFLECT&quot;, or &quot;SYMMETRIC&quot; (case-insensitive)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afee276e3eb264a4d93da50e2abde152ac01979b" translate="yes" xml:space="preserve">
          <source>One of &quot;caffe&quot;, &quot;tf&quot; or &quot;torch&quot;. Defaults to &quot;caffe&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e64e983ff6e386593658fbd7481a284ac6e38c7" translate="yes" xml:space="preserve">
          <source>One of &quot;categorical&quot;, &quot;binary&quot;, &quot;sparse&quot;, &quot;input&quot;, or None. Default: &quot;categorical&quot;. Determines the type of label arrays that are returned: - &quot;categorical&quot; will be 2D one-hot encoded labels, - &quot;binary&quot; will be 1D binary labels, &quot;sparse&quot; will be 1D integer labels, - &quot;input&quot; will be images identical to input images (mainly used to work with autoencoders). - If None, no labels are returned (the generator will only yield batches of image data, which is useful to use with &lt;code&gt;model.predict_generator()&lt;/code&gt;). Please note that in case of class_mode None, the data still needs to reside in a subdirectory of &lt;code&gt;directory&lt;/code&gt; for it to work correctly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe3e4b2e5da5ccd8e7182149c44e73f5a7c03613" translate="yes" xml:space="preserve">
          <source>One of &quot;fan_in&quot;, &quot;fan_out&quot;, &quot;fan_avg&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4621822cc8109296f4df83659df0daba060ef766" translate="yes" xml:space="preserve">
          <source>One of &quot;grayscale&quot;, &quot;rgb&quot;, &quot;rgba&quot;. Default: &quot;rgb&quot;. The desired image format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b18d2bc9213ef9539535150372753b78938a522d" translate="yes" xml:space="preserve">
          <source>One of &quot;grayscale&quot;, &quot;rgb&quot;, &quot;rgba&quot;. Default: &quot;rgb&quot;. Whether the images will be converted to have 1, 3, or 4 channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e32eda91f05c6f61e5ad850185d0780c22cb925b" translate="yes" xml:space="preserve">
          <source>One of &quot;png&quot;, &quot;jpeg&quot; (only relevant if &lt;code&gt;save_to_dir&lt;/code&gt; is set). Default: &quot;png&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be96c108b354d049bfd64628dd4e2b8853b77518" translate="yes" xml:space="preserve">
          <source>One of &quot;training&quot; or &quot;validation&quot;. Only used if &lt;code&gt;validation_split&lt;/code&gt; is set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="990c7dcb7a8adb68784bc65c4a2f51acec49b6be" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; except &lt;code&gt;NONE&lt;/code&gt;. Describes how to reduce training loss over batch. Defaults to &lt;code&gt;SUM_OVER_BATCH_SIZE&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b8d9df9e08f950ba2c9cf4798ccb01c9cc8e792" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; except &lt;code&gt;NONE&lt;/code&gt;. Decides how to reduce training loss over batch and label dimension. Defaults to &lt;code&gt;SUM_OVER_BATCH_SIZE&lt;/code&gt;, namely weighted sum of losses divided by &lt;code&gt;batch size * label_dimension&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bab782b5d9b906b629dc20909ca8400d4ce2f9b3" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; except &lt;code&gt;NONE&lt;/code&gt;. Decides how to reduce training loss over batch and label dimension. Defaults to &lt;code&gt;SUM_OVER_BATCH_SIZE&lt;/code&gt;, namely weighted sum of losses divided by &lt;code&gt;batch_size * label_dimension&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb1d6e77f961c70e4de951af4f2a7f75bcf00f94" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; except &lt;code&gt;NONE&lt;/code&gt;. Decides how to reduce training loss over batch. Defaults to &lt;code&gt;SUM_OVER_BATCH_SIZE&lt;/code&gt;, namely weighted sum of losses divided by &lt;code&gt;batch size * label_dimension&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="217ad19ff7504d876e68004750c8078aa0b1c513" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; except &lt;code&gt;NONE&lt;/code&gt;. Decides how to reduce training loss over batch. Defaults to &lt;code&gt;SUM_OVER_BATCH_SIZE&lt;/code&gt;, namely weighted sum of losses divided by batch size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d740f45b237e46982e7acc4a50312c9a60173a77" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; except &lt;code&gt;NONE&lt;/code&gt;. Describes how to reduce training loss over batch. Defaults to &lt;code&gt;SUM&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efb6fa170a45c186c3b2646879f77dbadca97b33" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; except &lt;code&gt;NONE&lt;/code&gt;. Describes how to reduce training loss over batch. Defaults to &lt;code&gt;SUM_OVER_BATCH_SIZE&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dab0cd7480ebf7f860f247acda7fcf14eb80268b" translate="yes" xml:space="preserve">
          <source>One of &lt;a href=&quot;../keras/losses/reduction&quot;&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">一个&lt;a href=&quot;../keras/losses/reduction&quot;&gt; &lt;code&gt;tf.losses.Reduction&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e3c68f3e47ffba70305d5969813f97e519e1a763" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;, &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed342e0dedf44d8fc494e9bd41080fc3cc1d14b0" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;rgb&quot;&lt;/code&gt;, &lt;code&gt;&quot;rgba&quot;&lt;/code&gt;, &lt;code&gt;&quot;grayscale&quot;&lt;/code&gt;. Color mode to read images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be0dd91a68e8fd22d9be543ee8968d02bd224a93" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;steps&quot;&lt;/code&gt; or &lt;code&gt;&quot;samples&quot;&lt;/code&gt;. Whether the progress bar should count samples seen or steps (batches) seen.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21ba8a2f84599c86151f6ec18b3528dfbea181c2" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;valid&quot;&lt;/code&gt; or &lt;code&gt;&quot;same&quot;&lt;/code&gt; (case-insensitive).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f3ebe4e698a493d2a0cdea3794cd45fa8e630bc" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;valid&quot;&lt;/code&gt; or &lt;code&gt;&quot;same&quot;&lt;/code&gt; (case-insensitive). &quot;valid&quot; adds no padding. &quot;same&quot; adds padding such that if the stride is 1, the output shape is the same as the input shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd3e1b4f81a74553a47701e75e69d0337a6b3d5e" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;valid&quot;&lt;/code&gt; or &lt;code&gt;&quot;same&quot;&lt;/code&gt; (case-insensitive). &quot;valid&quot; adds no zero padding. &quot;same&quot; adds padding such that if the stride is 1, the output shape is the same as input shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ac107ace071ba86a4f5ae467506eb2f21aaccbf" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;valid&quot;&lt;/code&gt;, &lt;code&gt;&quot;causal&quot;&lt;/code&gt; or &lt;code&gt;&quot;same&quot;&lt;/code&gt; (case-insensitive). &lt;code&gt;&quot;causal&quot;&lt;/code&gt; results in causal (dilated) convolutions, e.g. &lt;code&gt;output[t]&lt;/code&gt; does not depend on &lt;code&gt;input[t+1:]&lt;/code&gt;. Useful when modeling temporal data where the model should not violate the temporal order. See &lt;a href=&quot;https://arxiv.org/abs/1609.03499&quot;&gt;WaveNet: A Generative Model for Raw Audio, section 2.1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="711eb8aebc8f85e47e6f755ec8fafcc6481f9799" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;&quot;valid&quot;&lt;/code&gt;, &lt;code&gt;&quot;same&quot;&lt;/code&gt;, or &lt;code&gt;&quot;causal&quot;&lt;/code&gt; (case-insensitive).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1184a12347aef20d34e8fd97b47d6f1056981ab0" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;None&lt;/code&gt; (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to 'imagenet'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b27a198ba806caf4c7a7f8e3c9f5ef49ef0b284" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;None&lt;/code&gt; (random initialization), &lt;code&gt;imagenet&lt;/code&gt; (pre-training on ImageNet), or the path to the weights file to be loaded. Default to &lt;code&gt;imagenet&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2476c7777be9de89e8e8ae8e795cb432d7a0f2b" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;channels_last&lt;/code&gt; or &lt;code&gt;channels_first&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98a9708d9e97049a86b310c078783cc32984b42e" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;save_steps&lt;/code&gt; or &lt;code&gt;save_secs&lt;/code&gt; should be set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46c269e3422cfd1ab33631a472ccce262c2199f9" translate="yes" xml:space="preserve">
          <source>One of &lt;code&gt;{&quot;auto&quot;, &quot;min&quot;, &quot;max&quot;}&lt;/code&gt;. In &lt;code&gt;min&lt;/code&gt; mode, training will stop when the quantity monitored has stopped decreasing; in &lt;code&gt;&quot;max&quot;&lt;/code&gt; mode it will stop when the quantity monitored has stopped increasing; in &lt;code&gt;&quot;auto&quot;&lt;/code&gt; mode, the direction is automatically inferred from the name of the monitored quantity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e4743dcb8cf195acbafdb323e70260636bd7b65" translate="yes" xml:space="preserve">
          <source>One of the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8daf03b1171e7a988e42df6eeca1d85c1e630a88" translate="yes" xml:space="preserve">
          <source>One of {&quot;constant&quot;, &quot;nearest&quot;, &quot;reflect&quot; or &quot;wrap&quot;}. Default is 'nearest'. Points outside the boundaries of the input are filled according to the given mode:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d878c19bfa2774c551f29410b41c12c25f72a3f" translate="yes" xml:space="preserve">
          <source>One reasonable value for &lt;code&gt;max_shard_bytes&lt;/code&gt; is &lt;code&gt;(64 &amp;lt;&amp;lt; 20) - 1&lt;/code&gt;, or almost &lt;code&gt;64MB&lt;/code&gt;, to keep below the protobuf byte limit.</source>
          <target state="translated">&lt;code&gt;max_shard_bytes&lt;/code&gt; 的一个合理值是 &lt;code&gt;(64 &amp;lt;&amp;lt; 20) - 1&lt;/code&gt; 或接近 &lt;code&gt;64MB&lt;/code&gt; ，以保持低于protobuf字节限制。</target>
        </trans-unit>
        <trans-unit id="23690d2e7db0c6a104ef9930fdbff3c0c2557f87" translate="yes" xml:space="preserve">
          <source>One tensor for each component of an element of &lt;code&gt;input_dataset&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ade7827b79599b460ed9c89f5f5bdd545f679d2" translate="yes" xml:space="preserve">
          <source>One tensor for each value in &lt;code&gt;other_arguments&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ced8582aa84e5c4c5c0760bcd3b9d3d64bdc93d" translate="yes" xml:space="preserve">
          <source>One-hot encodes a text into a list of word indexes of size &lt;code&gt;n&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="835e31555f7691800120ca12eb99164bb510fe2c" translate="yes" xml:space="preserve">
          <source>One-hot encodes a text into a list of word indexes of size n.</source>
          <target state="translated">一热将一个文本编码成一个大小为n的词索引列表。</target>
        </trans-unit>
        <trans-unit id="1d7a99a4ff0f2993f0a258331a2bc21becd848cc" translate="yes" xml:space="preserve">
          <source>One-hot ground truth values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db695985d72c1b01345a8154647649146bfe1b70" translate="yes" xml:space="preserve">
          <source>One-hot-encoded labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f95076aab3aea3dc5e796c851267d9d45ca0bb4" translate="yes" xml:space="preserve">
          <source>One-shot iterators have the following limitations:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d902204ed8502cc47b55b1826754d58c9d230a16" translate="yes" xml:space="preserve">
          <source>OneHot</source>
          <target state="translated">OneHot</target>
        </trans-unit>
        <trans-unit id="dc1e47fad2dfd00c8991fa022edd4ed9784eba35" translate="yes" xml:space="preserve">
          <source>OneShotIterator</source>
          <target state="translated">OneShotIterator</target>
        </trans-unit>
        <trans-unit id="721e01ef498769611884261f9e49c7b2cee77275" translate="yes" xml:space="preserve">
          <source>OnesLike</source>
          <target state="translated">OnesLike</target>
        </trans-unit>
        <trans-unit id="49f42a9e80efe91c440ed17544473e6ea5d019ea" translate="yes" xml:space="preserve">
          <source>Only &lt;code&gt;.txt&lt;/code&gt; files are supported at this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="334c28d7f95e6546b1f8527110248a36e83aca1b" translate="yes" xml:space="preserve">
          <source>Only accepts value typed tensors as inputs and rejects resource variable handles as input.</source>
          <target state="translated">只接受值类型的时器作为输入,拒绝资源变量句柄作为输入。</target>
        </trans-unit>
        <trans-unit id="2c9a5a5a96ded8e32df86874f36ecf44968ba5d1" translate="yes" xml:space="preserve">
          <source>Only after all variables have been updated, increment the global step.</source>
          <target state="translated">只有在所有变量更新后,才会递增全局步骤。</target>
        </trans-unit>
        <trans-unit id="7f16d87add9a4d1b320177e1e3408f9f4905fd3b" translate="yes" xml:space="preserve">
          <source>Only after step 4, pushes &lt;code&gt;global_step&lt;/code&gt; in the &lt;code&gt;token_queue&lt;/code&gt;, once for each worker replica. The workers can now fetch the global step, use it to update its local_step variable and start the next batch. Please note that some workers can consume multiple minibatches, while some may not consume even one. This is because each worker fetches minibatches as long as a token exists. If one worker is stuck for some reason and does not consume a token, another worker can use it.</source>
          <target state="translated">只有第4步后，推 &lt;code&gt;global_step&lt;/code&gt; 在 &lt;code&gt;token_queue&lt;/code&gt; ，一次为每个工人副本。工人现在可以获取全局步骤，使用它来更新其local_step变量并开始下一个批次。请注意，有些工人可以消耗多个迷你批，而有些工人甚至不能消耗一个。这是因为只要令牌存在，每个工作人员都会获取迷你批。如果一个工作人员由于某种原因而被卡住并且不使用令牌，则另一个工作人员可以使用它。</target>
        </trans-unit>
        <trans-unit id="848aabde175071eb7d2973c6b997c576ce3f230e" translate="yes" xml:space="preserve">
          <source>Only applicable if the layer has exactly one inbound node, i.e. if it is connected to one incoming layer.</source>
          <target state="translated">只有当该层正好有一个入库节点,即连接到一个入库层时才适用。</target>
        </trans-unit>
        <trans-unit id="f8ae9708c35c08dd3a91689c37a43a53d064c8a7" translate="yes" xml:space="preserve">
          <source>Only applicable if the layer has exactly one input, i.e. if it is connected to one incoming layer, or if all inputs have the same shape.</source>
          <target state="translated">只有当该层正好有一个输入时才适用,即如果该层与一个输入层相连,或者所有输入都具有相同的形状。</target>
        </trans-unit>
        <trans-unit id="5f93f160e8a3cd13974c1d1d07ae49506b264c02" translate="yes" xml:space="preserve">
          <source>Only applicable if the layer has exactly one input, i.e. if it is connected to one incoming layer.</source>
          <target state="translated">只有当该层正好有一个输入时才适用,即如果它连接到一个输入层。</target>
        </trans-unit>
        <trans-unit id="e1a00617e9118b765a5da4cea50f9eb37fc4a6d0" translate="yes" xml:space="preserve">
          <source>Only applicable if the layer has exactly one output, i.e. if it is connected to one incoming layer.</source>
          <target state="translated">只有当该层正好有一个输出时才适用,即如果它连接到一个输入层。</target>
        </trans-unit>
        <trans-unit id="46aefa0a3c890bb9ab3d8dbd7a554536f18592f1" translate="yes" xml:space="preserve">
          <source>Only applicable if the layer has one output, or if all outputs have the same shape.</source>
          <target state="translated">只适用于层有一个输出,或者所有输出都有相同形状的情况下。</target>
        </trans-unit>
        <trans-unit id="e5d2f36053d80483c7c77e2dabe525d87a1b0a41" translate="yes" xml:space="preserve">
          <source>Only elements not equal to zero will be present in the result. The resulting &lt;code&gt;SparseTensor&lt;/code&gt; has the same dtype and shape as the input.</source>
          <target state="translated">结果中将仅包含不等于零的元素。生成的 &lt;code&gt;SparseTensor&lt;/code&gt; 具有与输入相同的dtype和形状。</target>
        </trans-unit>
        <trans-unit id="975a6cab99f4fc8794526ba91ae6b5de1a717063" translate="yes" xml:space="preserve">
          <source>Only exists for API compatibility with multi-backend Keras.</source>
          <target state="translated">只存在于与多后端Keras的API兼容性。</target>
        </trans-unit>
        <trans-unit id="8ccd8232d6dd45378801d71dad30fc02f816e410" translate="yes" xml:space="preserve">
          <source>Only log &lt;code&gt;first_n&lt;/code&gt; number of times. Negative numbers log always; this is the default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27e31d70d4abb5eca2b2a9f6b5782cb4db320ce9" translate="yes" xml:space="preserve">
          <source>Only print this many entries of each tensor. If None, then a maximum of 3 elements are printed per input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73b8cbf91b427a28014ad3ea68099b55ec816e56" translate="yes" xml:space="preserve">
          <source>Only relevant if &lt;code&gt;validation_data&lt;/code&gt; is provided and is a &lt;a href=&quot;../../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. If 'validation_steps' is None, validation will run until the &lt;code&gt;validation_data&lt;/code&gt; dataset is exhausted. In the case of an infinitely repeated dataset, it will run into an infinite loop. If 'validation_steps' is specified and only part of the dataset will be consumed, the evaluation will start from the beginning of the dataset at each epoch. This ensures that the same validation samples are used every time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f0ec07d81b1d9111c9a2b020089c7d530a901a1" translate="yes" xml:space="preserve">
          <source>Only relevant if &lt;code&gt;validation_data&lt;/code&gt; is provided and is a &lt;a href=&quot;../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. If 'validation_steps' is None, validation will run until the &lt;code&gt;validation_data&lt;/code&gt; dataset is exhausted. In the case of an infinitely repeated dataset, it will run into an infinite loop. If 'validation_steps' is specified and only part of the dataset will be consumed, the evaluation will start from the beginning of the dataset at each epoch. This ensures that the same validation samples are used every time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c480b201fe61bfbbffe2373ba0ae539b560b7f56" translate="yes" xml:space="preserve">
          <source>Only relevant if validation data is provided. Integer or &lt;code&gt;collections_abc.Container&lt;/code&gt; instance (e.g. list, tuple, etc.). If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. &lt;code&gt;validation_freq=2&lt;/code&gt; runs validation every 2 epochs. If a Container, specifies the epochs on which to run validation, e.g. &lt;code&gt;validation_freq=[1, 2, 10]&lt;/code&gt; runs validation at the end of the 1st, 2nd, and 10th epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bd483022a6b771acac0ed0f19ce4356587336fa" translate="yes" xml:space="preserve">
          <source>Only required if &lt;code&gt;featurewise_center&lt;/code&gt; or &lt;code&gt;featurewise_std_normalization&lt;/code&gt; or &lt;code&gt;zca_whitening&lt;/code&gt; are set to True.</source>
          <target state="translated">仅当 &lt;code&gt;featurewise_center&lt;/code&gt; 或 &lt;code&gt;featurewise_std_normalization&lt;/code&gt; 或 &lt;code&gt;zca_whitening&lt;/code&gt; 设置为True 时才需要。</target>
        </trans-unit>
        <trans-unit id="05c0d7b3529c6720a7c3873f091985554cd2a448" translate="yes" xml:space="preserve">
          <source>Only scalar values are allowed. The constant value provided must be convertible to the dtype requested when calling the initializer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f8096d4e4e3b3ae5194ceefa56f39a2cc8387ee" translate="yes" xml:space="preserve">
          <source>Only show nodes including no less than this.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0deb9469624ef3de6a5fca8370a75f399e9abc5" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes consuming no less than 'min_bytes'.</source>
          <target state="translated">只显示消耗不低于'min_bytes'的剖析器节点。</target>
        </trans-unit>
        <trans-unit id="3543223ca94b517ce1d79b980379a6e684dce160" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes consuming no less than 'min_float_ops'.</source>
          <target state="translated">只显示消耗不少于'min_float_ops'的剖析器节点。</target>
        </trans-unit>
        <trans-unit id="ecaa035d4228cf192bd8636b6e1185b75d710286" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes consuming no less than 'min_micros'.</source>
          <target state="translated">只显示消耗量不小于'min_micros'的剖析器节点。</target>
        </trans-unit>
        <trans-unit id="88c23a396c7dd32049a99cf1883234667484c317" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes have no less than this bytes not being de-allocated after Compute() ends. For profiler nodes consist of multiple graph nodes, it sums the graph nodes' residual_bytes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5135ba1cc0d9589a918bb29d3cb908a6d75181c2" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes have no less than this bytes output. The output are not necessarily allocated by this profiler nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfa200f6671cd877447f75d362b0d97739f37e0c" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes holding no less than 'min_params' parameters.</source>
          <target state="translated">只显示持有不少于'min_params'参数的剖析器节点。</target>
        </trans-unit>
        <trans-unit id="27426f1944a4fe37033bd0bb43ee7beb29a9e1e6" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes holding number parameters no less than this.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d15204c8cdf25510527c9049aa608dcb8e11ebe4" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes including no less than 'min_occurrence' graph nodes.</source>
          <target state="translated">只显示剖析器节点,包括不少于'min_occurrence'的图节点。</target>
        </trans-unit>
        <trans-unit id="0e4ec7d9c1353526f85caf29ad6691e64cf26a5d" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes requested to allocate no less bytes than this.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d376bf3727a91daa470d2bb308e37f4c80b350b" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes spend no less than this time on accelerator (e.g. GPU).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2da5f53008c7c7cee4a14944c8159e1f0d66bfcc" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes spend no less than this time on cpu.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89bf624b4a8346dc10c636e511d3389c9a20b023" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes using no less than this bytes at peak (high watermark). For profiler nodes consist of multiple graph nodes, it sums the graph nodes' peak_bytes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c15e227013087fe4f13417bc2f6a9c0038221259" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes with execution time no less than this. It sums accelerator and cpu times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4210d7cf5842d6a166c96c969da13c2a813d8967" translate="yes" xml:space="preserve">
          <source>Only show profiler nodes with float operations no less than this.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45014a153ba2554cdda5fbff52db2fccc9a3d832" translate="yes" xml:space="preserve">
          <source>Only the properties in the following list are allowed to be replaced:</source>
          <target state="translated">只有以下列表中的属性才允许被替换。</target>
        </trans-unit>
        <trans-unit id="9bf44bdfaaf8a75129eb96c14731b91e83dbe6b3" translate="yes" xml:space="preserve">
          <source>Only top &lt;code&gt;num_words-1&lt;/code&gt; most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.</source>
          <target state="translated">仅考虑前 &lt;code&gt;num_words-1&lt;/code&gt; 个最常用的单词。仅考虑分词器已知的单词。</target>
        </trans-unit>
        <trans-unit id="6207cf0b1fcae2548ea275564b9d80af705e5075" translate="yes" xml:space="preserve">
          <source>Only topological loading (&lt;code&gt;by_name=False&lt;/code&gt;) is supported when loading weights from the TensorFlow format. Note that topological loading differs slightly between TensorFlow and HDF5 formats for user-defined classes inheriting from &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;: HDF5 loads based on a flattened list of weights, while the TensorFlow format loads based on the object-local names of attributes to which layers are assigned in the &lt;code&gt;Model&lt;/code&gt;'s constructor.</source>
          <target state="translated">从TensorFlow格式加载权重时仅支持拓扑加载（ &lt;code&gt;by_name=False&lt;/code&gt; ）。请注意，从&lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt;继承的用户定义类的TensorFlow和HDF5格式之间的拓扑加载略有不同：HDF5基于权重的扁平列表进行加载，而TensorFlow格式基于属性的对象本地名称进行加载层在 &lt;code&gt;Model&lt;/code&gt; 的构造函数中分配。</target>
        </trans-unit>
        <trans-unit id="6b4fb8cd75e1cd47b418d479e0e5ffe20c3d8a51" translate="yes" xml:space="preserve">
          <source>Only topological loading (&lt;code&gt;by_name=False&lt;/code&gt;) is supported when loading weights from the TensorFlow format. Note that topological loading differs slightly between TensorFlow and HDF5 formats for user-defined classes inheriting from &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;: HDF5 loads based on a flattened list of weights, while the TensorFlow format loads based on the object-local names of attributes to which layers are assigned in the &lt;code&gt;Model&lt;/code&gt;'s constructor.</source>
          <target state="translated">从TensorFlow格式加载权重时仅支持拓扑加载（ &lt;code&gt;by_name=False&lt;/code&gt; ）。请注意，从&lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt;继承的用户定义类的TensorFlow和HDF5格式之间的拓扑加载略有不同：HDF5基于权重的扁平列表进行加载，而TensorFlow格式基于属性的对象本地名称进行加载层在 &lt;code&gt;Model&lt;/code&gt; 的构造函数中分配。</target>
        </trans-unit>
        <trans-unit id="9b86028b1109ded4a7fcfee7a963dc0ef717ff66" translate="yes" xml:space="preserve">
          <source>Only unknown dimensions can be resized when &lt;code&gt;strict&lt;/code&gt; is True. Unknown dimensions are indicated as &lt;code&gt;-1&lt;/code&gt; in the &lt;code&gt;shape_signature&lt;/code&gt; attribute of a given tensor. (default False)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05f782d29e458b8d99d6c4d07a40205de4864303" translate="yes" xml:space="preserve">
          <source>Only usable for generating 2D matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07c6635c2c9cb1a4a8d05f9319ab6dd4e5048d19" translate="yes" xml:space="preserve">
          <source>Only use for 2D matrices.</source>
          <target state="translated">只用于二维矩阵。</target>
        </trans-unit>
        <trans-unit id="4b340c8b7563412570948f5811d2e0d1fcfc6fd6" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;state_is_tuple=True&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;state_is_tuple=True&lt;/code&gt; 时使用。</target>
        </trans-unit>
        <trans-unit id="7af88a8503a82c42406f9239933e074c72517f48" translate="yes" xml:space="preserve">
          <source>Only useful as a placeholder for control edges.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7fab8eaab012110e2cb1c8d8c0671eebb338808" translate="yes" xml:space="preserve">
          <source>Only valid if &quot;labels&quot; is &quot;inferred&quot;. This is the explict list of class names (must match names of subdirectories). Used to control the order of the classes (otherwise alphanumerical order is used).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55b298bc86ae63ec2b8faca503a6c53377f7ecf2" translate="yes" xml:space="preserve">
          <source>Only valid in &quot;binary&quot;, &quot;count&quot;, and &quot;tf-idf&quot; modes. If True, the output will have its feature axis padded to &lt;code&gt;max_elements&lt;/code&gt; even if the number of unique values in the vocabulary is less than max_elements, resulting in a tensor of shape [batch_size, max_elements] regardless of vocabulary size. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="481d9c6561c435d0d16786766e67242fa593268b" translate="yes" xml:space="preserve">
          <source>Only valid in &quot;binary&quot;, &quot;count&quot;, and &quot;tf-idf&quot; modes. If True, the output will have its feature axis padded to &lt;code&gt;max_tokens&lt;/code&gt; even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8eadf05eef92f8a78907a6201373351050ff633" translate="yes" xml:space="preserve">
          <source>Only valid in INT mode. If set, the output will have its time dimension padded or truncated to exactly &lt;code&gt;output_sequence_length&lt;/code&gt; values, resulting in a tensor of shape [batch_size, output_sequence_length] regardless of how many tokens resulted from the splitting step. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e9bb8d9d9260e56b267db657d78ba4c6c29883b" translate="yes" xml:space="preserve">
          <source>Only valid in INT mode. If set, the output will have its time dimension padded or truncated to exactly &lt;code&gt;output_sequence_length&lt;/code&gt; values, resulting in a tensor of shape [batch_size, output_sequence_length] regardless of the input shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd32dc2399a1de058b9d055eb8d1b45bae536385" translate="yes" xml:space="preserve">
          <source>Op Name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67f05c2aba07949bda40953f397b358b5fbed2be" translate="yes" xml:space="preserve">
          <source>Op for the training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a555ee9c56f5d0c50c498efd5977817143a86831" translate="yes" xml:space="preserve">
          <source>Op is similar to a lightweight Dequeue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e49ba22d06956df5d2595a354b06079e8695a04" translate="yes" xml:space="preserve">
          <source>Op peeks at the values at the specified index. If the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d7ecc1623673559cd67e4153f2fb923d7013875" translate="yes" xml:space="preserve">
          <source>Op peeks at the values at the specified key. If the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b15b2e628cec174a105574d79fe2f17a084d3986" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; has specified rank or higher. If static checks determine &lt;code&gt;x&lt;/code&gt; has correct rank, a &lt;code&gt;no_op&lt;/code&gt; is returned.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 具有指定的等级或更高等级，否则将引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。如果静态检查确定 &lt;code&gt;x&lt;/code&gt; 具有正确的等级，则返回 &lt;code&gt;no_op&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="098f6e5bf7bdeda25821fc7d4a97c3d1e3084c0e" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; has specified rank or higher. If static checks determine &lt;code&gt;x&lt;/code&gt; has correct rank, a &lt;code&gt;no_op&lt;/code&gt; is returned. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 具有指定的等级或更高等级，否则将引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。如果静态检查确定 &lt;code&gt;x&lt;/code&gt; 具有正确的等级，则返回 &lt;code&gt;no_op&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="596890038d2f4619ff502aa203e2a4fe8fbc7d6b" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; has specified rank. If static checks determine &lt;code&gt;x&lt;/code&gt; has correct rank, a &lt;code&gt;no_op&lt;/code&gt; is returned.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 已指定等级，否则将引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。如果静态检查确定 &lt;code&gt;x&lt;/code&gt; 具有正确的等级，则返回 &lt;code&gt;no_op&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="06c195988461802db40ca52cef9448571d1118c6" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; has specified rank. If static checks determine &lt;code&gt;x&lt;/code&gt; has correct rank, a &lt;code&gt;no_op&lt;/code&gt; is returned. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 已指定等级，否则将引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。如果静态检查确定 &lt;code&gt;x&lt;/code&gt; 具有正确的等级，则返回 &lt;code&gt;no_op&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="e0d1d83d20389674f847577ddd6e9ef6a46070d2" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; is all negative. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 均为负，否则操作引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="ba1ee87854f8947ddd651440e36e379c615c1291" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; is all non-negative. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 均为非负数，否则将引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="361fa9e13cc2c8099b40d309ed5e8e66b0d24ae8" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; is all non-positive. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 均为非正数，否则会引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="3dfb0fd99082882c62cc797dfaf0f9ab1227cbda" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless &lt;code&gt;x&lt;/code&gt; is all positive. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 均为正数，否则操作引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="2d6ccd9e38a5515f27f2a37371ad8f3c121c0c9a" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless all shape constraints are satisfied. If static checks determine all constraints are satisfied, a &lt;code&gt;no_op&lt;/code&gt; is returned.</source>
          <target state="translated">除非所有形状约束均得到满足，否则将引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。如果静态检查确定满足所有约束，则返回 &lt;code&gt;no_op&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d7343d9c604bc27b934f3ca86d9e1cc4a5673860" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless rank of &lt;code&gt;x&lt;/code&gt; is in &lt;code&gt;ranks&lt;/code&gt;. If static checks determine &lt;code&gt;x&lt;/code&gt; has matching rank, a &lt;code&gt;no_op&lt;/code&gt; is returned.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 的等级在 &lt;code&gt;ranks&lt;/code&gt; 中,否则操作引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。如果静态检查确定 &lt;code&gt;x&lt;/code&gt; 具有匹配的等级，则返回 &lt;code&gt;no_op&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="808751f20236ba9f4f46801b57a61e0d86834323" translate="yes" xml:space="preserve">
          <source>Op raising &lt;code&gt;InvalidArgumentError&lt;/code&gt; unless rank of &lt;code&gt;x&lt;/code&gt; is in &lt;code&gt;ranks&lt;/code&gt;. If static checks determine &lt;code&gt;x&lt;/code&gt; has matching rank, a &lt;code&gt;no_op&lt;/code&gt; is returned. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">除非 &lt;code&gt;x&lt;/code&gt; 的等级在 &lt;code&gt;ranks&lt;/code&gt; 中,否则操作引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。如果静态检查确定 &lt;code&gt;x&lt;/code&gt; 具有匹配的等级，则返回 &lt;code&gt;no_op&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="59fc5a2e2ab81494882598f44f41cfbecd6c4400" translate="yes" xml:space="preserve">
          <source>Op removes all elements in the underlying container.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4ea440b59e8ad62cdef7519468ef82746d8882d" translate="yes" xml:space="preserve">
          <source>Op removes and returns a random (key, value)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d97aa64bc18b6f13a30d2938880ea5d6c20d2e53" translate="yes" xml:space="preserve">
          <source>Op removes and returns the (key, value) element with the smallest</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5798f652839dd0d753c5e6c2bb56db5527c8f7f3" translate="yes" xml:space="preserve">
          <source>Op removes and returns the values associated with the key</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fb29d648ac39efdff99702c3835fe7585e2afb4" translate="yes" xml:space="preserve">
          <source>Op returns the number of elements in the underlying container.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="686ef5dc434b2edc93280db6354a5b043b9469de" translate="yes" xml:space="preserve">
          <source>Op returns the number of incomplete elements in the underlying container.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a19ee52efc0952940edf50fdbcbc099519f9e25" translate="yes" xml:space="preserve">
          <source>Op that implements the reader.</source>
          <target state="translated">实现阅读器的操作。</target>
        </trans-unit>
        <trans-unit id="1a11911596171403f2263a0a984a017e9748e964" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x != y&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x != y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="b2b19c558b3588adc05816f9473cfb88b38c582d" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x != y&lt;/code&gt; is ever False. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">如果 &lt;code&gt;x != y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="09f874893b2fc224a7dfd38cfb8c6a10d790a5fc" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;gt; 0&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="464eabae7d7fa985507d2ba02ae595aa482df84f" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;gt; y&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;gt; y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="a5fd2c61b376adb0a0791130d5b81aa81aa2de96" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;gt; y&lt;/code&gt; is False. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;gt; y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="ba327da79e6f24d205ecb9ef42082d3a9301bc60" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;gt;= 0&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;gt;= 0&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="77076716bbb2b2e88130a5da704ae24948005fef" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;gt;= y&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;gt;= y&lt;/code&gt; 为False，则会引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6f532e09fec1098afc3963be64c488ced5dedaaa" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;gt;= y&lt;/code&gt; is False. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;gt;= y&lt;/code&gt; 为False，则会引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="cf7859f98feb3c9f7d25c16475ac1246fa3778f6" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;lt; 0&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="d81689e7e8a76ba8fbdb2064e97ec101d0aacb7b" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;lt; y&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;lt; y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="f90ad3a5b249fd5537961700f1302053660222ef" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;lt; y&lt;/code&gt; is False. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;lt; y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="9b37b28d7bb99c46c4d44ae58900d328ef7202b4" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;lt;= 0&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;lt;= 0&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="e581b8c6f240dd46805d52f991c0d60e535f71a8" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;lt;= y&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;lt;= y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="3f13f20824ad6bdff284387f7172bc4de5602335" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x &amp;lt;= y&lt;/code&gt; is False. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">如果 &lt;code&gt;x &amp;lt;= y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="dbb4d55356cee9c6a8b5684a56bc7b91e0cbb757" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x == y&lt;/code&gt; is False.</source>
          <target state="translated">如果 &lt;code&gt;x == y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。</target>
        </trans-unit>
        <trans-unit id="ea943b48081b9bd9676cd7cc43c9e94e29c96e1e" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x == y&lt;/code&gt; is False. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">如果 &lt;code&gt;x == y&lt;/code&gt; 为False ，则引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的 Op 。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="d53311e78cb142f3f9436e93d1606f9e6da6d210" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are not close enough.</source>
          <target state="translated">如果 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 距离不够近，则会引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的操作。</target>
        </trans-unit>
        <trans-unit id="72a4ae90a715348967138b3fcbd8685c54fa3a78" translate="yes" xml:space="preserve">
          <source>Op that raises &lt;code&gt;InvalidArgumentError&lt;/code&gt; if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are not close enough. This can be used with &lt;a href=&quot;../control_dependencies&quot;&gt;&lt;code&gt;tf.control_dependencies&lt;/code&gt;&lt;/a&gt; inside of &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to block followup computation until the check has executed.</source>
          <target state="translated">如果 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 距离不够近，则会引发 &lt;code&gt;InvalidArgumentError&lt;/code&gt; 的操作。可以将其与&lt;a href=&quot;../control_dependencies&quot;&gt; &lt;code&gt;tf.control_dependencies&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;一起使用，以阻止后续计算，直到执行检查为止。</target>
        </trans-unit>
        <trans-unit id="bccea016596f36edd90aeb64b7d766923c244a1e" translate="yes" xml:space="preserve">
          <source>Op to close the queue and cancel pending enqueue ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8e92ff0c37340aa9d97604febb4960c676edf6b" translate="yes" xml:space="preserve">
          <source>Op to close the queue. Pending enqueue ops are preserved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35c5e2ec794459bddc1ddf1b60547938da726fe2" translate="yes" xml:space="preserve">
          <source>OpHint level.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52b08fd68d529008ade1eace0482c686f5187b77" translate="yes" xml:space="preserve">
          <source>Opens file &lt;code&gt;path&lt;/code&gt; and creates a &lt;code&gt;TFRecordWriter&lt;/code&gt; writing to it.</source>
          <target state="translated">打开文件 &lt;code&gt;path&lt;/code&gt; 并创建一个写入其中的 &lt;code&gt;TFRecordWriter&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ef3134c526daef3feabac60d9bea2532557040bb" translate="yes" xml:space="preserve">
          <source>Operation that sets the accumulator's time step.</source>
          <target state="translated">设置蓄能器时间步长的操作。</target>
        </trans-unit>
        <trans-unit id="b216bc043bf0865daa7a9f1e34fbf240fb88bb65" translate="yes" xml:space="preserve">
          <source>Operation was rejected because the system is not in a state to execute it.</source>
          <target state="translated">操作被拒绝,因为系统不在执行状态。</target>
        </trans-unit>
        <trans-unit id="6addc295033cd35d638cd2b11559aa95b52a739c" translate="yes" xml:space="preserve">
          <source>Operations are applied to the input(s) according to the following rules:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fe833131379f7149f6f75890d7b60087f1ee397" translate="yes" xml:space="preserve">
          <source>Operations are recorded if they are executed within this context manager and at least one of their inputs is being &quot;watched&quot;.</source>
          <target state="translated">如果操作在这个上下文管理器中执行,并且至少有一个输入被 &quot;监视&quot;,就会被记录下来。</target>
        </trans-unit>
        <trans-unit id="452adcb0c5eb3c57c14e11658d9251a00c2c91a1" translate="yes" xml:space="preserve">
          <source>Operations executed while this context manager is active will not be recorded on the tape. This is useful for reducing the memory used by tracing all computations.</source>
          <target state="translated">当这个上下文管理器处于活动状态时执行的操作将不会被记录在磁带上。这对于减少跟踪所有计算所使用的内存非常有用。</target>
        </trans-unit>
        <trans-unit id="2ec755af8320a82448a2a6b17f8ba178dc018416" translate="yes" xml:space="preserve">
          <source>Operations for linear algebra.</source>
          <target state="translated">线性代数的运算。</target>
        </trans-unit>
        <trans-unit id="334df36539c6e4cce07013b66310e92bcf787d75" translate="yes" xml:space="preserve">
          <source>Operations for manipulating the binary representations of integers.</source>
          <target state="translated">对整数的二进制表示进行操作。</target>
        </trans-unit>
        <trans-unit id="f5bad7dc8a50fe4eebd66d7fa1ad13d16ed2c8ca" translate="yes" xml:space="preserve">
          <source>Operations for working with string Tensors.</source>
          <target state="translated">用于处理字符串Tensors的操作。</target>
        </trans-unit>
        <trans-unit id="abc751fc0c326ebea8001fb31e16b8d8b1721d43" translate="yes" xml:space="preserve">
          <source>Operations for writing summary data, for use in analysis and visualization.</source>
          <target state="translated">编写摘要数据的操作,用于分析和可视化。</target>
        </trans-unit>
        <trans-unit id="4b1cbaf378acc35ccbcbc07e1f83af9ab385dbbc" translate="yes" xml:space="preserve">
          <source>Operations that rely on a random seed actually derive it from two seeds: the global and operation-level seeds. This sets the global seed.</source>
          <target state="translated">依靠随机种子的操作,实际上是由两个种子衍生出来的:全局种子和操作级种子。这就设置了全局种子。</target>
        </trans-unit>
        <trans-unit id="2658e3359b4262ab02a920e6c5dec7fa284414b3" translate="yes" xml:space="preserve">
          <source>Operations that rely on a random seed actually derive it from two seeds: the graph-level and operation-level seeds. This sets the graph-level seed.</source>
          <target state="translated">依靠随机种子的操作,实际上是由两个种子衍生出来的:图级种子和操作级种子。这就设置了图级种子。</target>
        </trans-unit>
        <trans-unit id="3d146f13f4d8e62dbc36974460cb3b660a9b1243" translate="yes" xml:space="preserve">
          <source>Operator adding dropout to inputs and outputs of the given cell.</source>
          <target state="translated">在给定单元格的输入和输出上添加滤波的运算符。</target>
        </trans-unit>
        <trans-unit id="7bbab9f36e30418243383f860fc5513a33528162" translate="yes" xml:space="preserve">
          <source>Operator properties deduced from the spectrum.</source>
          <target state="translated">从光谱推导出的算子特性。</target>
        </trans-unit>
        <trans-unit id="3385f7455d003dbc3d051edfc9c33774c251c0e5" translate="yes" xml:space="preserve">
          <source>Operator that ensures an RNNCell runs on a particular device.</source>
          <target state="translated">确保RNNCell在特定设备上运行的操作员。</target>
        </trans-unit>
        <trans-unit id="6301248b258d4f9a381794cda385e7cdd34b58d7" translate="yes" xml:space="preserve">
          <source>Operators for manipulating tensors.</source>
          <target state="translated">操纵数十项的运算器。</target>
        </trans-unit>
        <trans-unit id="9ec35601b80aa19f3b4b7c5ddf43dd0a1d469e42" translate="yes" xml:space="preserve">
          <source>Operators that take advantage of special structure, while providing a consistent API to users.</source>
          <target state="translated">利用特殊结构的操作器,同时为用户提供一致的API。</target>
        </trans-unit>
        <trans-unit id="ac3910e0eb9ec4f52f53e69e4274f28e10a5c4a5" translate="yes" xml:space="preserve">
          <source>Ops and objects returned from a &lt;code&gt;model_fn&lt;/code&gt; and passed to &lt;code&gt;TPUEstimator&lt;/code&gt;.</source>
          <target state="translated">操作和对象从 &lt;code&gt;model_fn&lt;/code&gt; 返回并传递给 &lt;code&gt;TPUEstimator&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0e84fa506f27d9e235c1dd3f9433ae633ce53833" translate="yes" xml:space="preserve">
          <source>Ops and objects returned from a &lt;code&gt;model_fn&lt;/code&gt; and passed to an &lt;code&gt;Estimator&lt;/code&gt;.</source>
          <target state="translated">操作和对象从 &lt;code&gt;model_fn&lt;/code&gt; 返回并传递给 &lt;code&gt;Estimator&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="40300876c268c41e58c76b564bf9d1e081234568" translate="yes" xml:space="preserve">
          <source>Ops related to Tensor Processing Units.</source>
          <target state="translated">与张量处理单元有关的操作。</target>
        </trans-unit>
        <trans-unit id="19777719fe2603acd25e3b5805752db67e4f25e0" translate="yes" xml:space="preserve">
          <source>Ops/function calls inside the scope can return before finishing the actual execution. When exiting the async scope, a synchronization barrier will be automatically added to ensure the completion of all async op and function execution, potentially raising exceptions if async execution results in an error state.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5426d893d942b54b23899f742bab27b471bf0e32" translate="yes" xml:space="preserve">
          <source>Optimization parameters for Adagrad with TPU embeddings.</source>
          <target state="translated">阿达格拉德与TPU嵌入的优化参数。</target>
        </trans-unit>
        <trans-unit id="f512565257e0380650b3bc0fa1daf65251cf7470" translate="yes" xml:space="preserve">
          <source>Optimization parameters for Adagrad.</source>
          <target state="translated">Adagrad的优化参数。</target>
        </trans-unit>
        <trans-unit id="cbb2549250e3290a52381b55fea9c5ae2823fe3c" translate="yes" xml:space="preserve">
          <source>Optimization parameters for Adam with TPU embeddings.</source>
          <target state="translated">Adam与TPU嵌入的优化参数。</target>
        </trans-unit>
        <trans-unit id="a43d3c78a674d5aa846145fee1f1da005db6a080" translate="yes" xml:space="preserve">
          <source>Optimization parameters for Adam.</source>
          <target state="translated">亚当的优化参数。</target>
        </trans-unit>
        <trans-unit id="630b10b29c447b5449027733446a0f3f7c92bfc4" translate="yes" xml:space="preserve">
          <source>Optimization parameters for Ftrl with TPU embeddings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="867d697831ddd77fc7a7c3224735bac5910a9e0a" translate="yes" xml:space="preserve">
          <source>Optimization parameters for stochastic gradient descent for TPU embeddings.</source>
          <target state="translated">TPU嵌入的随机梯度下降的优化参数。</target>
        </trans-unit>
        <trans-unit id="13592d7ff798a59baabd3e82f73d38f0549d8e7d" translate="yes" xml:space="preserve">
          <source>Optimization parameters for stochastic gradient descent.</source>
          <target state="translated">随机梯度下降的优化参数。</target>
        </trans-unit>
        <trans-unit id="2fdf9e3cda9890a48ade21132d9045564aa26e07" translate="yes" xml:space="preserve">
          <source>OptimizeDataset</source>
          <target state="translated">OptimizeDataset</target>
        </trans-unit>
        <trans-unit id="24deb31136df317e41f6006c8fcc6c7ebb207bf1" translate="yes" xml:space="preserve">
          <source>Optimizer accepts a callable learning rate in two ways. The first way is through built-in or customized &lt;a href=&quot;schedules/learningrateschedule&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.LearningRateSchedule&lt;/code&gt;&lt;/a&gt;. The schedule will be called on each iteration with &lt;code&gt;schedule(iteration)&lt;/code&gt;, a &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt; owned by the optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e33463360eba704e43e494e1ff9bcbe64702f331" translate="yes" xml:space="preserve">
          <source>Optimizer configuration dictionary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f6b07762ffa8357ab0597d205c228789f4c30ba" translate="yes" xml:space="preserve">
          <source>Optimizer identifier, one of</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38a277ebb3b736522bf69478e7a2188cbb37a6ae" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the Adadelta algorithm.</source>
          <target state="translated">实现Adadelta算法的优化器。</target>
        </trans-unit>
        <trans-unit id="228602481c7f2e8ba729c600e5efed58674b1fed" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the Adagrad algorithm.</source>
          <target state="translated">实现Adagrad算法的优化器。</target>
        </trans-unit>
        <trans-unit id="789cbde5dc49057407e9d1ed70e7ded6a7450f2d" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the Adam algorithm.</source>
          <target state="translated">实现亚当算法的优化器。</target>
        </trans-unit>
        <trans-unit id="c8794e9a41cd3b971d66476e5a3b1b251ef019f5" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the Adamax algorithm.</source>
          <target state="translated">实现Adamax算法的优化器。</target>
        </trans-unit>
        <trans-unit id="697c1368bc112191e0cc03d43870878745b0d2ba" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the FTRL algorithm.</source>
          <target state="translated">实现FTRL算法的优化器。</target>
        </trans-unit>
        <trans-unit id="ed9d476d0a7d49448991afea7571cbf4e700af52" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the Momentum algorithm.</source>
          <target state="translated">实现动量算法的优化器。</target>
        </trans-unit>
        <trans-unit id="31b7076e799b416e0580c81190655c33e247eed7" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the NAdam algorithm.</source>
          <target state="translated">实现NAdam算法的优化器。</target>
        </trans-unit>
        <trans-unit id="6d5b5b1196bc3b128f28d763f02c2404ecd95a58" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the Proximal Adagrad algorithm.</source>
          <target state="translated">实现近端Adagrad算法的优化器。</target>
        </trans-unit>
        <trans-unit id="2d1be445d483e0ac5b322dbc18d28ca0bdfd554b" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the RMSProp algorithm (Tielemans et al.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3d453c733beca74a5f8203eff5967d046d0d9b4" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the RMSProp algorithm.</source>
          <target state="translated">实现RMSProp算法的优化器。</target>
        </trans-unit>
        <trans-unit id="36977c109aa83bcecbfac2cbcfdcd95a074b5ba0" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the RMSprop algorithm.</source>
          <target state="translated">实现RMSprop算法的优化器。</target>
        </trans-unit>
        <trans-unit id="5520e1fae29cfb2fdac0cb031d6697d8395de04a" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the gradient descent algorithm.</source>
          <target state="translated">实现梯度下降算法的优化器。</target>
        </trans-unit>
        <trans-unit id="a499daeedc601ee747fb3c542d345f02f8c35525" translate="yes" xml:space="preserve">
          <source>Optimizer that implements the proximal gradient descent algorithm.</source>
          <target state="translated">实现近端梯度下降算法的优化器。</target>
        </trans-unit>
        <trans-unit id="35756709959d376bb981bfeb576aab77c9979a59" translate="yes" xml:space="preserve">
          <source>Option Builder for Profiling API.</source>
          <target state="translated">剖析API的选项生成器。</target>
        </trans-unit>
        <trans-unit id="d1872194c20d4ec8e06354d26456ef70d70ffa36" translate="yes" xml:space="preserve">
          <source>Optional (list of) &lt;code&gt;InputSpec&lt;/code&gt; object(s) specifying the constraints on inputs that can be accepted by the layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c3a82c5709e9b29985185d2cee2ea0eee0d4c60" translate="yes" xml:space="preserve">
          <source>Optional 2d int32 lists with shape [num_groups, num_replicas_per_group] which describles how to apply optimizer to subgroups.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34253d7f792111189b5808a4f27b8e2493340f28" translate="yes" xml:space="preserve">
          <source>Optional 2d int32 lists with shape [num_groups, num_replicas_per_group]. &lt;code&gt;group_assignment[i]&lt;/code&gt; represents the replica ids in the ith subgroup.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a78bf9aa937291357ba338de2b0d414845d861d6" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; object. Defaults to a &lt;a href=&quot;../../../../distribute/cluster_resolver/tfconfigclusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.TFConfigClusterResolver&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="986cb69e5478bc33b6834663afe0c7b25ae14ce7" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; for evaluation.</source>
          <target state="translated">可选的&lt;a href=&quot;../../../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;。评估策略。</target>
        </trans-unit>
        <trans-unit id="41cbfe393a53582d133cd8e35ebd371a2dee49f4" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; for training.</source>
          <target state="translated">可选的&lt;a href=&quot;../../../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;。培训策略。</target>
        </trans-unit>
        <trans-unit id="40ae6c1606343f7e1d6d2a4c0eeaab94bae9c50e" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../../../tpu/experimental/deviceassignment&quot;&gt;&lt;code&gt;tf.tpu.experimental.DeviceAssignment&lt;/code&gt;&lt;/a&gt; to specify the placement of replicas on the TPU cluster. Currently only supports the usecase of using a single core within a TPU cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7034ded71b0368a4c29bb866151d4705185ba6a8" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../saved_model/loadoptions&quot;&gt;&lt;code&gt;tf.saved_model.LoadOptions&lt;/code&gt;&lt;/a&gt; object that specifies options for loading from SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcf9a188a14b8a90997e0901812a1fe355f1c251" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../saved_model/saveoptions&quot;&gt;&lt;code&gt;tf.saved_model.SaveOptions&lt;/code&gt;&lt;/a&gt; object that specifies options for saving to SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="790a92bb4237f8c764dd2100db9c08c53c42848a" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../tpu/experimental/deviceassignment&quot;&gt;&lt;code&gt;tf.tpu.experimental.DeviceAssignment&lt;/code&gt;&lt;/a&gt; to specify the placement of replicas on the TPU cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0eadc56d17013385e2bf2380bbf42c366eebab5" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../train/checkpointoptions&quot;&gt;&lt;code&gt;tf.train.CheckpointOptions&lt;/code&gt;&lt;/a&gt; object if &lt;code&gt;save_weights_only&lt;/code&gt; is true or optional &lt;code&gt;tf.saved_model.SavedOptions&lt;/code&gt; object if &lt;code&gt;save_weights_only&lt;/code&gt; is false.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9667d1f07a6a4d5d3132b29e72308b99b115feb9" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../train/checkpointoptions&quot;&gt;&lt;code&gt;tf.train.CheckpointOptions&lt;/code&gt;&lt;/a&gt; object that specifies options for loading weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a8a8fc2d9dd80fadd003c3e70d04d738489a4e0" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../../train/checkpointoptions&quot;&gt;&lt;code&gt;tf.train.CheckpointOptions&lt;/code&gt;&lt;/a&gt; object that specifies options for saving weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a9a1c4db11014f8755b3be61a2eb6473f002f1b" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; object. Defaults to a &lt;a href=&quot;../cluster_resolver/tfconfigclusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.TFConfigClusterResolver&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ce28161a073666ce7000ca9d585a27514f224cb" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; for evaluation.</source>
          <target state="translated">可选的&lt;a href=&quot;../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;。评估策略。</target>
        </trans-unit>
        <trans-unit id="acfde78a85ff6cc95839c0d5fe29210952e75e03" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; for training.</source>
          <target state="translated">可选的&lt;a href=&quot;../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;。培训策略。</target>
        </trans-unit>
        <trans-unit id="61dd1ca3c7f8151619a343471ea2c1b3c35992bf" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../saved_model/saveoptions&quot;&gt;&lt;code&gt;tf.saved_model.SaveOptions&lt;/code&gt;&lt;/a&gt; object that specifies options for saving to SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13b129b42c28823876c3deb54188f7b6bb0b76a6" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../tpu/experimental/deviceassignment&quot;&gt;&lt;code&gt;tf.tpu.experimental.DeviceAssignment&lt;/code&gt;&lt;/a&gt; to specify the placement of replicas on the TPU cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c21846c57a11121626fcf77d580a9d91d19de792" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../train/checkpointoptions&quot;&gt;&lt;code&gt;tf.train.CheckpointOptions&lt;/code&gt;&lt;/a&gt; object that specifies options for loading weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66ef3c6a79273eeb5fc11acefed43715f69f1ebf" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;../train/checkpointoptions&quot;&gt;&lt;code&gt;tf.train.CheckpointOptions&lt;/code&gt;&lt;/a&gt; object that specifies options for saving weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70da78689b276cb3e9cf0c5d74ee7324c29feacd" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;checkpointoptions&quot;&gt;&lt;code&gt;tf.train.CheckpointOptions&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58754ddabf797a50cdf20d6c941b4335e08da752" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;rnn&quot;&gt;&lt;code&gt;keras.layers.RNN&lt;/code&gt;&lt;/a&gt;, or &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;keras.layers.Layer&lt;/code&gt;&lt;/a&gt; instance to be used to handle backwards input processing. If &lt;code&gt;backward_layer&lt;/code&gt; is not provided, the layer instance passed as the &lt;code&gt;layer&lt;/code&gt; argument will be used to generate the backward layer automatically. Note that the provided &lt;code&gt;backward_layer&lt;/code&gt; layer should have properties matching those of the &lt;code&gt;layer&lt;/code&gt; argument, in particular it should have the same values for &lt;code&gt;stateful&lt;/code&gt;, &lt;code&gt;return_states&lt;/code&gt;, &lt;code&gt;return_sequence&lt;/code&gt;, etc. In addition, &lt;code&gt;backward_layer&lt;/code&gt; and &lt;code&gt;layer&lt;/code&gt; should have different &lt;code&gt;go_backwards&lt;/code&gt; argument values. A &lt;code&gt;ValueError&lt;/code&gt; will be raised if these requirements are not met.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc82ef2834679ec891befa522d4ab81449c9bf66" translate="yes" xml:space="preserve">
          <source>Optional &lt;a href=&quot;saver&quot;&gt;&lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt;&lt;/a&gt; object to use to save and restore variables. May also be a &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; object, in which case object-based checkpoints are saved. This will also load some object-based checkpoints saved from elsewhere, but that loading may be fragile since it uses fixed keys rather than performing a full graph-based match. For example if a variable has two paths from the &lt;code&gt;Checkpoint&lt;/code&gt; object because two &lt;code&gt;Model&lt;/code&gt; objects share the &lt;code&gt;Layer&lt;/code&gt; object that owns it, removing one &lt;code&gt;Model&lt;/code&gt; may change the keys and break checkpoint loading through this API, whereas a graph-based match would match the variable through the other &lt;code&gt;Model&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="719870265d8afd1d08870a2243c6eea0dae5aff9" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;1-D&lt;/code&gt; integer &lt;code&gt;Tensor&lt;/code&gt;. The shape of the leading dimensions. If &lt;code&gt;None&lt;/code&gt;, this operator has no leading dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c88f77514488ed420d83967d6f3a51c7cceb09b" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;ConfigProto&lt;/code&gt; proto used to configure the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1376ace1cd1f457cddc36e89b66a193ce8c36bf" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;ConfigProto&lt;/code&gt; proto used to configure the session. Passed as-is to create the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a5184e6a50e7746b596163a5998944a9eab98f7" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Coordinator&lt;/code&gt; for coordinating the started threads.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8af8278b16e02fe43594772fc8634db53d7553c5" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Coordinator&lt;/code&gt; object for reporting errors and checking stop conditions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="189ba88dcff544ad7bec8f7721c3dec823c47cc0" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Exception&lt;/code&gt;, or Python &lt;code&gt;exc_info&lt;/code&gt; tuple as returned by &lt;code&gt;sys.exc_info()&lt;/code&gt;. If this is the first call to &lt;code&gt;request_stop()&lt;/code&gt; the corresponding exception is recorded and re-raised from &lt;code&gt;join()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="120bbdd81459b17e9d28919173d8dd08198e0b2f" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; object, used to maintain moving averages for the variables passed in &lt;code&gt;variables_to_average&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="524ccc2780f8f9cc13d0db834cc48c30b398aaae" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Operation&lt;/code&gt; used to initialize the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2bf58cdcbdf6c76b453e4c80832dc618577ff9a" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;QueueRunnerDef&lt;/code&gt; protocol buffer. If specified, recreates the QueueRunner from its contents. &lt;code&gt;queue_runner_def&lt;/code&gt; and the other arguments are mutually exclusive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3ee1fd3f3dc39ad996a2b6c81fb6654b412f7aa" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;SaverBuilder&lt;/code&gt; to use if a &lt;code&gt;saver_def&lt;/code&gt; was not provided. Defaults to &lt;code&gt;BulkSaverBuilder()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17125e77968ea6e53be304c015750ad80683d1b5" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;SaverDef&lt;/code&gt; proto to use instead of running the builder. This is only useful for specialty code that wants to recreate a &lt;code&gt;Saver&lt;/code&gt; object for a previously built &lt;code&gt;Graph&lt;/code&gt; that had a &lt;code&gt;Saver&lt;/code&gt;. The &lt;code&gt;saver_def&lt;/code&gt; proto should be the one returned by the &lt;code&gt;as_saver_def()&lt;/code&gt; call of the &lt;code&gt;Saver&lt;/code&gt; that was created for that &lt;code&gt;Graph&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bd3516d5c539a0919c563812df15ee952f38e6d" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Tensor&lt;/code&gt; of same &lt;code&gt;dtype&lt;/code&gt; as &lt;code&gt;u&lt;/code&gt; and shape &lt;code&gt;[B1,...,Bb, N, K]&lt;/code&gt; Defaults to &lt;code&gt;v = u&lt;/code&gt;, in which case the perturbation is symmetric. If &lt;code&gt;M != N&lt;/code&gt;, then &lt;code&gt;v&lt;/code&gt; must be set since the perturbation is not square.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1573cd9cf813bec2e8e66f6a884cba6e7d05bc71" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Tensor&lt;/code&gt; that is broadcastable to loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d10e99540ba90fbd2171235a263622dc4e069826" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Tensor&lt;/code&gt; whose rank is either 0, or the same rank as &lt;code&gt;labels&lt;/code&gt;, and must be broadcastable to &lt;code&gt;labels&lt;/code&gt; (i.e., all dimensions must be either &lt;code&gt;1&lt;/code&gt;, or the same as the corresponding &lt;code&gt;labels&lt;/code&gt; dimension).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a41400a9381efa41217f25838b7d22d49d98e479" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Tensor&lt;/code&gt; whose rank is either 0, or the same rank as &lt;code&gt;labels&lt;/code&gt;, and must be broadcastable to &lt;code&gt;labels&lt;/code&gt; (i.e., all dimensions must be either &lt;code&gt;1&lt;/code&gt;, or the same as the corresponding &lt;code&gt;labels&lt;/code&gt; dimension). Also, dimension &lt;code&gt;dim&lt;/code&gt; must be &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7990233480f56f9e85db531e92798212a53e527f" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Tensor&lt;/code&gt; whose rank is either 0, or the same rank as &lt;code&gt;labels&lt;/code&gt;, and must be broadcastable to &lt;code&gt;labels&lt;/code&gt; (i.e., all dimensions must be either &lt;code&gt;1&lt;/code&gt;, or the same as the corresponding &lt;code&gt;losses&lt;/code&gt; dimension).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bc55ae627519b3fb39550dc570232359013ee75" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Tensor&lt;/code&gt; whose rank is either 0, or the same rank as &lt;code&gt;losses&lt;/code&gt;, and must be broadcastable to &lt;code&gt;losses&lt;/code&gt; (i.e., all dimensions must be either &lt;code&gt;1&lt;/code&gt;, or the same as the corresponding &lt;code&gt;losses&lt;/code&gt; dimension).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e829661b0d3fe1a5b1077ad6c99b8ca7c3e929d6" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Tensor&lt;/code&gt; whose rank is either 0, or the same rank as &lt;code&gt;values&lt;/code&gt;, and must be broadcastable to &lt;code&gt;values&lt;/code&gt; (i.e., all dimensions must be either &lt;code&gt;1&lt;/code&gt;, or the same as the corresponding &lt;code&gt;values&lt;/code&gt; dimension).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b623f603d82df72a5d4f7ceef4feb35afbe2673c" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;Variable&lt;/code&gt; to increment by one after the variables have been updated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3859250f61bf230296a77b81c68bc5cc79d2304" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;int&lt;/code&gt; or rank-0 integer &lt;code&gt;Tensor&lt;/code&gt;. At most this many audio clips will be emitted at each step. When more than &lt;code&gt;max_outputs&lt;/code&gt; many clips are provided, the first &lt;code&gt;max_outputs&lt;/code&gt; many clips will be used and the rest silently discarded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="478ae27f5f4795c8168032e041519671648783eb" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;int&lt;/code&gt; or rank-0 integer &lt;code&gt;Tensor&lt;/code&gt;. At most this many images will be emitted at each step. When more than &lt;code&gt;max_outputs&lt;/code&gt; many images are provided, the first &lt;code&gt;max_outputs&lt;/code&gt; many images will be used and the rest silently discarded.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63e8fd4befac6f85ca457da0feb69baf7283bc89" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;sample_weight&lt;/code&gt; acts as a coefficient for the loss. If a scalar is provided, then the loss is simply scaled by the given value. If &lt;code&gt;sample_weight&lt;/code&gt; is a tensor of size &lt;code&gt;[batch_size]&lt;/code&gt;, then the total loss for each sample of the batch is rescaled by the corresponding element in the &lt;code&gt;sample_weight&lt;/code&gt; vector. If the shape of &lt;code&gt;sample_weight&lt;/code&gt; is &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt; (or can be broadcasted to this shape), then each loss element of &lt;code&gt;y_pred&lt;/code&gt; is scaled by the corresponding value of &lt;code&gt;sample_weight&lt;/code&gt;. (Note on&lt;code&gt;dN-1&lt;/code&gt;: all loss functions reduce by 1 dimension, usually axis=-1.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="046bd44ce69e887bd4c0cf902276a941e9a0a24f" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;sample_weight&lt;/code&gt; acts as a coefficient for the metric. If a scalar is provided, then the metric is simply scaled by the given value. If &lt;code&gt;sample_weight&lt;/code&gt; is a tensor of size &lt;code&gt;[batch_size]&lt;/code&gt;, then the metric for each sample of the batch is rescaled by the corresponding element in the &lt;code&gt;sample_weight&lt;/code&gt; vector. If the shape of &lt;code&gt;sample_weight&lt;/code&gt; is &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt; (or can be broadcasted to this shape), then each metric element of &lt;code&gt;y_pred&lt;/code&gt; is scaled by the corresponding value of &lt;code&gt;sample_weight&lt;/code&gt;. (Note on &lt;code&gt;dN-1&lt;/code&gt;: all metric functions reduce by 1 dimension, usually the last axis (-1)).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1111ec888dd4b6979a17837c8d96b20cc0106d71" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;string&lt;/code&gt; -- if specified, prepend this string followed by '/' to all loaded tensor names. This scope is applied to tensor instances loaded into the passed session, but it is &lt;em&gt;not&lt;/em&gt; written through to the static &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer that is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3402422a542a48a5d93756f661438d27d675aed5" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;string&lt;/code&gt;. Name scope to add to the &lt;code&gt;Variable.&lt;/code&gt; Only used when initializing from protocol buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d521af4161fe6987e8cc931e6bbc4a5f2ab6fde" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;string&lt;/code&gt;. Name scope to add. Only used when initializing from protocol buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="490fca72031d82288a0b73beb3fd703591473b8c" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;string&lt;/code&gt;. Name scope to remove.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d87788b9112e199c8b662e37bd0b6e5c78d33fa9" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;string&lt;/code&gt;. Name scope to use.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d20b0ac08b7f7c534c040fed79cfd64e0f2b003a" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;string&lt;/code&gt;. Name scope under which to extract the subgraph. The scope name will be striped from the node definitions for easy import later into new name scopes. If &lt;code&gt;None&lt;/code&gt;, the whole graph is exported. graph_def and export_scope cannot both be specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14e0607b300b0498b183beea08848f7abefb6c20" translate="yes" xml:space="preserve">
          <source>Optional &lt;code&gt;{function_name: function_obj}&lt;/code&gt; dictionary listing user-provided activation functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e538bd3b09ff997391630a4b80d9562c84337f5" translate="yes" xml:space="preserve">
          <source>Optional ConfigProto proto used to configure the session, which is passed as-is to create the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0830da8df378ec01b9d068d8d528cd07af92df9a" translate="yes" xml:space="preserve">
          <source>Optional ConfigProto proto used to configure the session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a74b8f74fa7df073a9fca41794635f7eeed2a9c" translate="yes" xml:space="preserve">
          <source>Optional DType of an element in the resulting &lt;code&gt;Tensor&lt;/code&gt;. Default is &lt;a href=&quot;../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6103fad31eabd46fa92cbbac94aebdd6a0d16f19" translate="yes" xml:space="preserve">
          <source>Optional EmbeddingConfigSpec instance to support using TPU embedding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f24baf2c323eb518eda620c1f91075c70a0afecd" translate="yes" xml:space="preserve">
          <source>Optional Int, maximum length of all sequences. If not provided, sequences will be padded to the length of the longest individual sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c1137e21d31da4acb0a85c3fa35bb23bb3db8fe" translate="yes" xml:space="preserve">
          <source>Optional Keras tensor (i.e. output of &lt;a href=&quot;../input&quot;&gt;&lt;code&gt;layers.Input()&lt;/code&gt;&lt;/a&gt;) to use as image input for the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="176198cc77bc4adbdc6cf82445a2f5b65567ae2f" translate="yes" xml:space="preserve">
          <source>Optional Keras tensor (i.e. output of &lt;a href=&quot;../input&quot;&gt;&lt;code&gt;layers.Input()&lt;/code&gt;&lt;/a&gt;) to use as image input for the model. &lt;code&gt;input_tensor&lt;/code&gt; is useful for sharing inputs between multiple different networks. Default to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77cc92f7827ad1d3b2b03e1c8d40f4b2ff2a987c" translate="yes" xml:space="preserve">
          <source>Optional Numpy array of weights for the test samples, used for weighting the loss function. You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape &lt;code&gt;(samples, sequence_length)&lt;/code&gt;, to apply a different weight to every timestep of every sample. This argument is not supported when &lt;code&gt;x&lt;/code&gt; is a dataset, instead pass sample weights as the third element of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11949cf41c97d69dfb6e6343401bd785f3533b22" translate="yes" xml:space="preserve">
          <source>Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape &lt;code&gt;(samples, sequence_length)&lt;/code&gt;, to apply a different weight to every timestep of every sample. This argument is not supported when &lt;code&gt;x&lt;/code&gt; is a dataset, generator, or &lt;a href=&quot;../utils/sequence&quot;&gt;&lt;code&gt;keras.utils.Sequence&lt;/code&gt;&lt;/a&gt; instance, instead provide the sample_weights as the third element of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d45c13e67aeb03d1ea7e4c01670ab7870cdae03a" translate="yes" xml:space="preserve">
          <source>Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape &lt;code&gt;(samples, sequence_length)&lt;/code&gt;, to apply a different weight to every timestep of every sample. This argument is not supported when &lt;code&gt;x&lt;/code&gt; is a dataset, generator, or &lt;a href=&quot;utils/sequence&quot;&gt;&lt;code&gt;keras.utils.Sequence&lt;/code&gt;&lt;/a&gt; instance, instead provide the sample_weights as the third element of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa9bde481b5e74ac1c714556b820b30c75ff2602" translate="yes" xml:space="preserve">
          <source>Optional SummaryMetadata proto (which describes which plugins may use the summary value).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b660717c36b9ca00220a13f19531576301aa1ca0" translate="yes" xml:space="preserve">
          <source>Optional SummaryMetadata, as a proto or serialized bytes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67a684cda3ee6162b3cd3f97b4c998ce83af5837" translate="yes" xml:space="preserve">
          <source>Optional Variable to increment by one after the variables have been updated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52fba3d544a7a08e63ee06f65ddcbe39ae4bf6f0" translate="yes" xml:space="preserve">
          <source>Optional argument specifying whether to clear the state of the layer at the start of the call to &lt;code&gt;adapt&lt;/code&gt;, or whether to start from the existing state. Subclasses may choose to throw if reset_state is set to 'False'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75f9b07a6c027d42811dfd4e9b32ab640e90675f" translate="yes" xml:space="preserve">
          <source>Optional argument specifying whether to clear the state of the layer at the start of the call to &lt;code&gt;adapt&lt;/code&gt;, or whether to start from the existing state. This argument may not be relevant to all preprocessing layers: a subclass of PreprocessingLayer may choose to throw if 'reset_state' is set to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d59e77214e2671bc82f857dc37e1ae61308780ea" translate="yes" xml:space="preserve">
          <source>Optional argument specifying whether to clear the state of the layer at the start of the call to &lt;code&gt;adapt&lt;/code&gt;. This must be True for this layer, which does not support repeated calls to &lt;code&gt;adapt&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cb6cd47b97c5a0fd0d2b3bebcc9779f1eb0d518" translate="yes" xml:space="preserve">
          <source>Optional arguments to pass to &lt;code&gt;target&lt;/code&gt; when calling it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e7e204df556c9780ec0adb2c417b68c6cc326a3" translate="yes" xml:space="preserve">
          <source>Optional array of the same length as x, containing weights to apply to the model's loss for each sample. In the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29d7fbe6c7e16899687d3d3510bebe9e7d476668" translate="yes" xml:space="preserve">
          <source>Optional bool. Setting it to &lt;code&gt;True&lt;/code&gt; is mathematically equivalent to tf.math.conj(tf.linalg.matrix_transpose(input)).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="522003f4690954bd75345ff08469e86ef60b0017" translate="yes" xml:space="preserve">
          <source>Optional bool. Setting it to &lt;code&gt;True&lt;/code&gt; is mathematically equivalent to tf.math.conj(tf.transpose(input)).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6eacac21b7481b1920790c7b6434c1babaa77e7" translate="yes" xml:space="preserve">
          <source>Optional boundary specification. Bins include the left boundary and exclude the right boundary, so &lt;code&gt;bins=[0., 1., 2.]&lt;/code&gt; generates bins &lt;code&gt;(-inf, 0.)&lt;/code&gt;, &lt;code&gt;[0., 1.)&lt;/code&gt;, &lt;code&gt;[1., 2.)&lt;/code&gt;, and &lt;code&gt;[2., +inf)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6bf30d2a0485f766b0acc2155dfa4e950d6932b" translate="yes" xml:space="preserve">
          <source>Optional callable object that will be executed in the thread.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed37d7f0d56115231e6daca0a7e0012489df82fe" translate="yes" xml:space="preserve">
          <source>Optional callable that accepts a fully defined &lt;code&gt;TensorShape&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt; of the Variable to be created, and returns a list of partitions for each axis (currently only one axis can be partitioned).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a019285c92e388003fcf54b066897e5915bc17e" translate="yes" xml:space="preserve">
          <source>Optional callable that returns a list of tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab80bb4c5daf93a3cf4f7d8c159788fce02fca0a" translate="yes" xml:space="preserve">
          <source>Optional callable that returns a structure of tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63212d87c9cdf41fb31fff549783879251a1c3a9" translate="yes" xml:space="preserve">
          <source>Optional callable used to initialize the model. Called after the optional &lt;code&gt;init_op&lt;/code&gt; is called. The callable must accept one argument, the session being initialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9060609ec1a33edce5f5f6a4b00e619351d1b9c" translate="yes" xml:space="preserve">
          <source>Optional cleanup policy on when/if to remove the directory (and all its contents) at the end of the test. If None, then uses &lt;code&gt;self.tempfile_cleanup&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c62d5830d029b22c35147b88837cfb194080fef8" translate="yes" xml:space="preserve">
          <source>Optional collection to add the loss to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91057ef786d8057c28538d97fb6e416ae2077442" translate="yes" xml:space="preserve">
          <source>Optional collective name of these columns. If not given, a reasonable name will be chosen based on the names of &lt;code&gt;categorical_columns&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="862da596c81f05229ccedf69798dd5089b8dc5ce" translate="yes" xml:space="preserve">
          <source>Optional constant &lt;code&gt;str&lt;/code&gt; for the desired encoding. Only &quot;wav&quot; is currently supported, but this is not guaranteed to remain the default, so if you want &quot;wav&quot; in particular, set this explicitly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eb1183fe0697992121b61de5d91049db6ee812e" translate="yes" xml:space="preserve">
          <source>Optional constraint for the beta weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87d406e3197716fabbb165369cedfeabc849a814" translate="yes" xml:space="preserve">
          <source>Optional constraint for the beta weight. None by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="827979382d73c0d790afecb18a087d7623bd69c4" translate="yes" xml:space="preserve">
          <source>Optional constraint for the gamma weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="534b2b9bdf16c7af816b69fb2f4211bc8baa242c" translate="yes" xml:space="preserve">
          <source>Optional constraint for the gamma weight. None by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e8ac7236f955850df124b625ab24b348e19920" translate="yes" xml:space="preserve">
          <source>Optional count of number of updates applied to variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af089fcc2c28273cfa0bc09a0496a47c191d76c4" translate="yes" xml:space="preserve">
          <source>Optional custom getter for variables used in &lt;code&gt;func_&lt;/code&gt;. See the &lt;a href=&quot;get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt;&lt;/a&gt;&lt;code&gt;custom_getter&lt;/code&gt; documentation for more information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc9ecfe58b5f73e105cf2d38dcd488a788b4b44a" translate="yes" xml:space="preserve">
          <source>Optional data format of the image tensor/array. Defaults to None, in which case the global setting &lt;a href=&quot;../../backend/image_data_format&quot;&gt;&lt;code&gt;tf.keras.backend.image_data_format()&lt;/code&gt;&lt;/a&gt; is used (unless you changed it, it defaults to &quot;channels_last&quot;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64a6b87a19bde8f3a7cadee0e910068e125c458b" translate="yes" xml:space="preserve">
          <source>Optional datatype of the input. When not provided, the Keras default float type will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9507a4ad3a93ba23ef089d83d2bdf42ba93ca7fe" translate="yes" xml:space="preserve">
          <source>Optional device string describing where the Variable should be cached for reading. Defaults to the Variable's device. If not &lt;code&gt;None&lt;/code&gt;, caches on another device. Typical use is to cache on the device where the Ops using the Variable reside, to deduplicate copying through &lt;code&gt;Switch&lt;/code&gt; and other conditional statements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa857ecb1b13a97ea8649782845a38e3cc5835ae" translate="yes" xml:space="preserve">
          <source>Optional device string or function describing where the Variable should be cached for reading. Defaults to the Variable's device. If not &lt;code&gt;None&lt;/code&gt;, caches on another device. Typical use is to cache on the device where the Ops using the Variable reside, to deduplicate copying through &lt;code&gt;Switch&lt;/code&gt; and other conditional statements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b583eb110734d73e416f759b266d604de3973adb" translate="yes" xml:space="preserve">
          <source>Optional device type string (e.g. &quot;CPU&quot; or &quot;GPU&quot;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e18a3e5cca2d064c81dca7d8b5202db400320fa1" translate="yes" xml:space="preserve">
          <source>Optional dictionary mapping Keras model output metric names to custom names. This can be used to override the default Keras model output metrics names in a multi IO model use case and provide custom names for the &lt;code&gt;eval_metric_ops&lt;/code&gt; in Estimator. The Keras model metric names can be obtained using &lt;code&gt;model.metrics_names&lt;/code&gt; excluding any loss metrics such as total loss and output losses. For example, if your Keras model has two outputs &lt;code&gt;out_1&lt;/code&gt; and &lt;code&gt;out_2&lt;/code&gt;, with &lt;code&gt;mse&lt;/code&gt; loss and &lt;code&gt;acc&lt;/code&gt; metric, then &lt;code&gt;model.metrics_names&lt;/code&gt; will be &lt;code&gt;['loss', 'out_1_loss', 'out_2_loss', 'out_1_acc', 'out_2_acc']&lt;/code&gt;. The model metric names excluding the loss metrics will be &lt;code&gt;['out_1_acc', 'out_2_acc']&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d943ec4b89a4212155acfea216145506a9ec0c5" translate="yes" xml:space="preserve">
          <source>Optional dictionary mapping class indices (integers) to a weight (float) to apply to the model's loss for the samples from this class during training. This can be useful to tell the model to &quot;pay more attention&quot; to samples from an under-represented class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae7344dbe803c7de436408ecfb8544b77498c6cb" translate="yes" xml:space="preserve">
          <source>Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to &quot;pay more attention&quot; to samples from an under-represented class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eaccb32b299f68498de9196d2dd52d8ce478fdc7" translate="yes" xml:space="preserve">
          <source>Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca4f383ea90459daf0d1d73debbe79f7da887163" translate="yes" xml:space="preserve">
          <source>Optional dictionary mapping names (strings) to custom objects (classes and functions) to be considered during deserialization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0db7f1c8e49e28f495974f0c9f5e97f495fe1fdc" translate="yes" xml:space="preserve">
          <source>Optional dictionary mapping string names to custom classes or functions (e.g. custom loss functions).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab93f46bffcf331a9cbb057f5d5d74983e761036" translate="yes" xml:space="preserve">
          <source>Optional dictionary of keyword arguments to be passed to the function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22c06c4c12b612a6363b1613f9b2301ab8be055c" translate="yes" xml:space="preserve">
          <source>Optional dictionary that maps &lt;code&gt;Tensor&lt;/code&gt; objects to feed values. This feed dictionary is passed to the session &lt;code&gt;run()&lt;/code&gt; call when running the init op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d23bb819c007f8f804b55b17ce6ac4f5d1e3002b" translate="yes" xml:space="preserve">
          <source>Optional dimensions of resulting tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ea6e3112a9cde4f572586f48cfaef673de0f9d8" translate="yes" xml:space="preserve">
          <source>Optional directory where to save the pictures being yielded, in a viewable format. This is useful for visualizing the random transformations being applied, for debugging purposes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60c81838ec8c925ac21e3afe5b1f7a71638ca351" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b148b6de1a1db6d2d92c78f1df2348439fa12f26" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. If not provided the dtype of the tensor created will be the type of the inital value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40c0293515d3349dddbb3eb5b795f09ef94d51d1" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. If not provided use the initializer dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8adf7515bec4911db854fe84d2ec3c05c10d61d" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. If not specified, &lt;a href=&quot;../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; is used, which default to &lt;code&gt;float32&lt;/code&gt; unless you configured it otherwise (via &lt;a href=&quot;../backend/set_floatx&quot;&gt;&lt;code&gt;tf.keras.backend.set_floatx(float_dtype)&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87c23caacfc83892f415f073e7c5cf3ba7c9fe56" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. Only floating point and integer types are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec6ed6efd59e9dcfeb725a5e46a5643ba1e9da47" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. Only floating point and integer types are supported. If not specified, &lt;a href=&quot;../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; is used, which default to &lt;code&gt;float32&lt;/code&gt; unless you configured it otherwise (via &lt;a href=&quot;../backend/set_floatx&quot;&gt;&lt;code&gt;tf.keras.backend.set_floatx(float_dtype)&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08853e56d8da6815478876c5f8b91722eb88c3bd" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. Only floating point types are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="801d5094dafee59890845d558984e0b619847456" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. Only floating point types are supported. If not specified, &lt;a href=&quot;../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; is used, which default to &lt;code&gt;float32&lt;/code&gt; unless you configured it otherwise (via &lt;a href=&quot;../backend/set_floatx&quot;&gt;&lt;code&gt;tf.keras.backend.set_floatx(float_dtype)&lt;/code&gt;&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f68b02356fc8152ef095ee136218e408db09bd7" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. Only numeric or boolean dtypes are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5218d861a78aa19c281a47ffbf6481cd7b29ec39" translate="yes" xml:space="preserve">
          <source>Optional dtype of the tensor. Only numeric or boolean dtypes are supported. If not specified, &lt;a href=&quot;../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; is used, which default to &lt;code&gt;float32&lt;/code&gt; unless you configured it otherwise (via &lt;a href=&quot;../backend/set_floatx&quot;&gt;&lt;code&gt;tf.keras.backend.set_floatx(float_dtype)&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="946ae2c4b5ff49c1f310b3458b28392c177aabdb" translate="yes" xml:space="preserve">
          <source>Optional element type for the returned tensor, used when dtype is None. In some cases, a caller may not have a dtype in mind when converting to a tensor, so dtype_hint can be used as a soft preference. If the conversion to &lt;code&gt;dtype_hint&lt;/code&gt; is not possible, this argument has no effect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf8a7695489d2fe1cdf6620afd1b4c65f60b9766" translate="yes" xml:space="preserve">
          <source>Optional element type for the returned tensor, used when dtype is None. In some cases, a caller may not have a dtype in mind when converting to a tensor, so preferred_dtype can be used as a soft preference. If the conversion to &lt;code&gt;preferred_dtype&lt;/code&gt; is not possible, this argument has no effect.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf7976ca9f1346974d395d3675747da955edbc56" translate="yes" xml:space="preserve">
          <source>Optional element type for the returned tensor. If missing, the type is inferred from the type of &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4cdd590b32556498228134b187703c19912d0d4" translate="yes" xml:space="preserve">
          <source>Optional existing tensor to wrap into the &lt;code&gt;Input&lt;/code&gt; layer. If set, the layer will not create a placeholder tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b80a208075ff2d9c81bf8be272e3021b65e8e35" translate="yes" xml:space="preserve">
          <source>Optional file format override. If omitted, the format to use is determined from the filename extension. If a file object was used instead of a filename, this parameter should always be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1493e1d5d1e3ad181de04cf9c475657bf51e0cc" translate="yes" xml:space="preserve">
          <source>Optional file path for the temp file. If not given, a unique file name will be generated and used. Slashes are allowed in the name; any missing intermediate directories will be created. NOTE: This path is the path that will be cleaned up, including any directories in the path, e.g., 'foo/bar/baz.txt' will &lt;code&gt;rm -r foo&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f84a4579107baee1da29da63e9727525306305e8" translate="yes" xml:space="preserve">
          <source>Optional filename including the path for writing the generated &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb58ad4f282b4517886ece071e32e9da6683d6c2" translate="yes" xml:space="preserve">
          <source>Optional float between 0 and 1, fraction of data to reserve for validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="596bcfdf1565bfa9f5d1f5381d71eefca0c8ba51" translate="yes" xml:space="preserve">
          <source>Optional function to call after a timeout. If the function returns True, then it means that no new checkpoints will be generated and the iterator will exit. The function is called with no arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9a788bca95d06ad91cb6f6c40fa066fca6a0b64" translate="yes" xml:space="preserve">
          <source>Optional function to use to initialize the model after running the init_op. Will be called as &lt;code&gt;init_fn(scaffold, session)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b99a8cc0bbc3441298c482df3bffc3331a78dad" translate="yes" xml:space="preserve">
          <source>Optional global batch size value. Defaults to (size of first dimension of &lt;code&gt;losses&lt;/code&gt;) * (number of replicas).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da68f7a84688d9fc9ecdb12d19b72d2177d3cad3" translate="yes" xml:space="preserve">
          <source>Optional graph to use during the returned session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235ccccd979de930acb5e449e386268c47e4192f" translate="yes" xml:space="preserve">
          <source>Optional information about the possible partitioning of a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f8266ad2f893c95c1aa095cf797a96e6ad6015c" translate="yes" xml:space="preserve">
          <source>Optional initial option dict to start with.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2084925349b5c2d5208bda13a6cfaceeac58d1ab" translate="yes" xml:space="preserve">
          <source>Optional input batch size (integer or None).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="116aa2e17213963a8a4c10c8cdf4e28ee112c70c" translate="yes" xml:space="preserve">
          <source>Optional int32 Tensor of shape [N, 2]. Specifies the minimum amount of padding to use. All elements must be &amp;gt;= 0. If not specified, defaults to 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9831fd6ff084640732c70f47d690246d14e1a1a2" translate="yes" xml:space="preserve">
          <source>Optional int; data points earlier (exclusive) than &lt;code&gt;start_index&lt;/code&gt; will not be used in the output sequences. This is useful to reserve part of the data for test or validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b34a208a59b7ce9244c764c223e708bf97908674" translate="yes" xml:space="preserve">
          <source>Optional int; data points later (exclusive) than &lt;code&gt;end_index&lt;/code&gt; will not be used in the output sequences. This is useful to reserve part of the data for test or validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f7ec626d142681db158eaf073564235d25c813" translate="yes" xml:space="preserve">
          <source>Optional int; random seed for shuffling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8064312b486681ad5ba21e752b852edd04be5ecd" translate="yes" xml:space="preserve">
          <source>Optional integer that indicates the priority for applying this conversion function. Conversion functions with smaller priority values run earlier than conversion functions with larger priority values. Defaults to 100.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3451938a8ab3295aa188757d7a915be5277fcf2e" translate="yes" xml:space="preserve">
          <source>Optional inverse link function, also known as 'mean function'. Defaults to identity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed7694c0e01d80f9a6b7b3b14c311b500301067d" translate="yes" xml:space="preserve">
          <source>Optional keyed arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e39d9cc008d1ff479812c61bfed4c0adf5451bb" translate="yes" xml:space="preserve">
          <source>Optional keyword arguments passed through to Saver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b35c5c73f443b874f380531d26b5cf4145142077" translate="yes" xml:space="preserve">
          <source>Optional keyword arguments passed to &lt;code&gt;train_step_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
