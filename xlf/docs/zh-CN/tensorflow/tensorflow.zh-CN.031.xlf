<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="2a153ad993b58e91534aaa1b0194100c39e780a2" translate="yes" xml:space="preserve">
          <source>Float. Range for random channel shifts.</source>
          <target state="translated">浮动。通道随机移动的范围。</target>
        </trans-unit>
        <trans-unit id="f298b29df0aaed3c2269372e55d5d95d6479cc14" translate="yes" xml:space="preserve">
          <source>Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)</source>
          <target state="translated">浮动。剪切强度(逆时针方向的剪切角,单位为度)</target>
        </trans-unit>
        <trans-unit id="d61a6c9d692f4f07e8ed530942501016a4e248b8" translate="yes" xml:space="preserve">
          <source>Float. Sleep for up to that many seconds waiting for should_stop() to become True.</source>
          <target state="translated">Float。最多可以睡那么几秒,等待should_stop()变成True。</target>
        </trans-unit>
        <trans-unit id="b216453945e2387161200857251f449d037b3948" translate="yes" xml:space="preserve">
          <source>Float. The decay to use.</source>
          <target state="translated">浮。腐化使用。</target>
        </trans-unit>
        <trans-unit id="6a8d2374e2cdf12bb0ad483865021b7b46af8084" translate="yes" xml:space="preserve">
          <source>Float. Threshold value for thresholded activation. Default to 0.</source>
          <target state="translated">浮点数。阈值激活的阈值。默认为0。</target>
        </trans-unit>
        <trans-unit id="7bb464c8d0de78b41f137b84b0a45a7ef1df1306" translate="yes" xml:space="preserve">
          <source>Float; L1 regularization factor.</source>
          <target state="translated">Float;L1正则化系数。</target>
        </trans-unit>
        <trans-unit id="e545332d824ca10ae9436e8e94121d2688432cd4" translate="yes" xml:space="preserve">
          <source>Float; L2 regularization factor.</source>
          <target state="translated">Float;L2正则化系数。</target>
        </trans-unit>
        <trans-unit id="d98d28f78e216bda13139a52fd08416526b5fd50" translate="yes" xml:space="preserve">
          <source>Floating point dtype of &lt;code&gt;alpha&lt;/code&gt;, &lt;code&gt;beta&lt;/code&gt;, and the output.</source>
          <target state="translated">&lt;code&gt;alpha&lt;/code&gt; ， &lt;code&gt;beta&lt;/code&gt; 和输出的浮点dtype 。</target>
        </trans-unit>
        <trans-unit id="1108f1c23cbc1e57319f627f818d48f1bc5ea8b3" translate="yes" xml:space="preserve">
          <source>Floating point tensor representing unnormalized log-probabilities of a positive event with shape broadcastable to &lt;code&gt;[N1,..., Nm, K]&lt;/code&gt;&lt;code&gt;m &amp;gt;= 0&lt;/code&gt;, and the same dtype as &lt;code&gt;total_count&lt;/code&gt;. Defines this as a batch of &lt;code&gt;N1 x ... x Nm&lt;/code&gt; different &lt;code&gt;K&lt;/code&gt; class Multinomial distributions. Only one of &lt;code&gt;logits&lt;/code&gt; or &lt;code&gt;probs&lt;/code&gt; should be passed in.</source>
          <target state="translated">浮点张量表示正事件的未归一化对数概率，其形状可广播为 &lt;code&gt;[N1,..., Nm, K]&lt;/code&gt; &lt;code&gt;m &amp;gt;= 0&lt;/code&gt; ，并且具有与 &lt;code&gt;total_count&lt;/code&gt; 相同的dtype。将此定义为一批 &lt;code&gt;N1 x ... x Nm&lt;/code&gt; 不同的 &lt;code&gt;K&lt;/code&gt; 类多项式分布。只有一个 &lt;code&gt;logits&lt;/code&gt; 或 &lt;code&gt;probs&lt;/code&gt; 也应传递。</target>
        </trans-unit>
        <trans-unit id="ecab45c217e3d9a346314ec4e398aa11dd87ce21" translate="yes" xml:space="preserve">
          <source>Floating point tensor which characterizes the location (center) of the distribution.</source>
          <target state="translated">浮点张量,表示分布的位置(中心)。</target>
        </trans-unit>
        <trans-unit id="c22ad41332a3111722a8770b295e776925f1ab64" translate="yes" xml:space="preserve">
          <source>Floating point tensor, equivalent to &lt;code&gt;1 / mean&lt;/code&gt;. Must contain only positive values.</source>
          <target state="translated">浮点张量，等于 &lt;code&gt;1 / mean&lt;/code&gt; 。必须仅包含正值。</target>
        </trans-unit>
        <trans-unit id="ebec1c58e95127ff044f512a93e456ed5e0f423a" translate="yes" xml:space="preserve">
          <source>Floating point tensor, lower boundary of the output interval. Must have &lt;code&gt;low &amp;lt; high&lt;/code&gt;.</source>
          <target state="translated">浮点张量，输出间隔的下边界。必须从 &lt;code&gt;low &amp;lt; high&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b0a469e0804bf541623d16583f6919e570634685" translate="yes" xml:space="preserve">
          <source>Floating point tensor, the concentration params of the distribution(s). Must contain only positive values.</source>
          <target state="translated">浮点张量,分布的浓度参数。必须只包含正值。</target>
        </trans-unit>
        <trans-unit id="4c8a724a94fb47724c39c1be0f5af846a44c632d" translate="yes" xml:space="preserve">
          <source>Floating point tensor, the inverse scale params of the distribution(s). Must contain only positive values.</source>
          <target state="translated">浮点张量,分布的反比例参数。必须只包含正值。</target>
        </trans-unit>
        <trans-unit id="5327a6fa2b169fe97edfd87b3231c2fc0e85d1d3" translate="yes" xml:space="preserve">
          <source>Floating point tensor, upper boundary of the output interval. Must have &lt;code&gt;low &amp;lt; high&lt;/code&gt;.</source>
          <target state="translated">浮点张量，输出间隔的上限。必须从 &lt;code&gt;low &amp;lt; high&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f21ecae5ea295908a041bff28ab082db7d65a86e" translate="yes" xml:space="preserve">
          <source>Floating point tensor; the means of the distribution(s).</source>
          <target state="translated">浮点张量;分布的平均值。</target>
        </trans-unit>
        <trans-unit id="f1f7e6b0fe6613bd3d52f8409a688348e04f4a6d" translate="yes" xml:space="preserve">
          <source>Floating point tensor; the stddevs of the distribution(s). Must contain only positive values.</source>
          <target state="translated">浮点张量;分布的stddevs。必须只包含正值。</target>
        </trans-unit>
        <trans-unit id="ddaf74f02e9ba66941d4fb8e98d09812330541ef" translate="yes" xml:space="preserve">
          <source>Floating-point &lt;code&gt;Tensor&lt;/code&gt; with shape &lt;code&gt;[B1, ..., Bn, k', k']&lt;/code&gt; where the first &lt;code&gt;n&lt;/code&gt; dimensions are batch coordinates and &lt;code&gt;k' = reduce_prod(self.event_shape)&lt;/code&gt;.</source>
          <target state="translated">形状为 &lt;code&gt;[B1, ..., Bn, k', k']&lt;/code&gt; 浮点 &lt;code&gt;Tensor&lt;/code&gt; ，其中前 &lt;code&gt;n&lt;/code&gt; 个维是批处理坐标，并且 &lt;code&gt;k' = reduce_prod(self.event_shape)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1009ba855ce72dff0358aacd603e698195e0cc2e" translate="yes" xml:space="preserve">
          <source>Floating-point &lt;code&gt;Tensor&lt;/code&gt; with shape identical to &lt;code&gt;batch_shape + event_shape&lt;/code&gt;, i.e., the same shape as &lt;code&gt;self.mean()&lt;/code&gt;.</source>
          <target state="translated">浮点 &lt;code&gt;Tensor&lt;/code&gt; 具有与 &lt;code&gt;batch_shape + event_shape&lt;/code&gt; 相同的形状，即与 &lt;code&gt;self.mean()&lt;/code&gt; 相同的形状。</target>
        </trans-unit>
        <trans-unit id="bc7844a942513a10bbbb9e00e72332f173c63976" translate="yes" xml:space="preserve">
          <source>Floating-point &lt;code&gt;Tensor&lt;/code&gt;. The degrees of freedom of the distribution(s). &lt;code&gt;df&lt;/code&gt; must contain only positive values.</source>
          <target state="translated">浮点 &lt;code&gt;Tensor&lt;/code&gt; 。分布的自由度。 &lt;code&gt;df&lt;/code&gt; 必须仅包含正值。</target>
        </trans-unit>
        <trans-unit id="9d90b467f05cdb99ed3725de235ef01720d9a043" translate="yes" xml:space="preserve">
          <source>Floating-point &lt;code&gt;Tensor&lt;/code&gt;. The mean(s) of the distribution(s).</source>
          <target state="translated">浮点 &lt;code&gt;Tensor&lt;/code&gt; 。分布的平均值。</target>
        </trans-unit>
        <trans-unit id="30e8504e26a1e405a364b16182f146926ce77d1d" translate="yes" xml:space="preserve">
          <source>Floating-point &lt;code&gt;Tensor&lt;/code&gt;. The scaling factor(s) for the distribution(s). Note that &lt;code&gt;scale&lt;/code&gt; is not technically the standard deviation of this distribution but has semantics more similar to standard deviation than variance.</source>
          <target state="translated">浮点 &lt;code&gt;Tensor&lt;/code&gt; 。分布的比例因子。请注意，从技术上讲， &lt;code&gt;scale&lt;/code&gt; 不是该分布的标准差，而是具有比标准差更接近于方差的语义。</target>
        </trans-unit>
        <trans-unit id="7db82f74092fc3160e6bc0d9e9bd4849c5c06c0f" translate="yes" xml:space="preserve">
          <source>Floor</source>
          <target state="translated">Floor</target>
        </trans-unit>
        <trans-unit id="6459c53ba8e729ad9aabb9ade4a34e551f147d2f" translate="yes" xml:space="preserve">
          <source>FloorDiv</source>
          <target state="translated">FloorDiv</target>
        </trans-unit>
        <trans-unit id="e19f1321e0f0e74f314d249fb2231ea22ddbb827" translate="yes" xml:space="preserve">
          <source>FloorMod</source>
          <target state="translated">FloorMod</target>
        </trans-unit>
        <trans-unit id="3a522d2554ce1f4be52f55076b2741713cbd45ec" translate="yes" xml:space="preserve">
          <source>Flush the file.</source>
          <target state="translated">冲洗文件。</target>
        </trans-unit>
        <trans-unit id="dd5993032f3482cc7f5027e64c00852d5ba8b251" translate="yes" xml:space="preserve">
          <source>Flush the quantile summaries from each quantile stream resource.</source>
          <target state="translated">刷新每个量化流资源的量化摘要。</target>
        </trans-unit>
        <trans-unit id="dfeaaa5a96eaede43e8bbe386e2dc6ef41feac38" translate="yes" xml:space="preserve">
          <source>Flush the summaries for a quantile stream resource.</source>
          <target state="translated">刷新量化流资源的摘要。</target>
        </trans-unit>
        <trans-unit id="bd5e3fc25c8039e27103eb4fe6d62a39fa677f1d" translate="yes" xml:space="preserve">
          <source>FlushSummaryWriter</source>
          <target state="translated">FlushSummaryWriter</target>
        </trans-unit>
        <trans-unit id="6f8d4e8b184b36bf829848dabccbd29eed8aad30" translate="yes" xml:space="preserve">
          <source>Flushes and closes the summary writer.</source>
          <target state="translated">冲洗并关闭摘要作者。</target>
        </trans-unit>
        <trans-unit id="9dbf53cec96a5446255caa0966d9befabc811892" translate="yes" xml:space="preserve">
          <source>Flushes any buffered data.</source>
          <target state="translated">刷新任何缓冲数据。</target>
        </trans-unit>
        <trans-unit id="bb205e45a353b942abb883e789503bde26fce540" translate="yes" xml:space="preserve">
          <source>Flushes the Writable file.</source>
          <target state="translated">刷新可写文件。</target>
        </trans-unit>
        <trans-unit id="7ba4cab89493ed49c06282e139f3f44d50a23884" translate="yes" xml:space="preserve">
          <source>Flushes the event file to disk and close the file.</source>
          <target state="translated">将事件文件刷新到磁盘并关闭文件。</target>
        </trans-unit>
        <trans-unit id="411ec1b384ddb34e5e50e858b2000e66bb3e655d" translate="yes" xml:space="preserve">
          <source>Flushes the event file to disk.</source>
          <target state="translated">将事件文件刷新到磁盘。</target>
        </trans-unit>
        <trans-unit id="9b7edfcf83a187737117b2f47b6141554f630be7" translate="yes" xml:space="preserve">
          <source>Folds in data to an RNG seed to form a new RNG seed.</source>
          <target state="translated">将数据折叠到RNG种子中,形成一个新的RNG种子。</target>
        </trans-unit>
        <trans-unit id="15713d62ed5ca4009b476df4c237ce2bc0ad0830" translate="yes" xml:space="preserve">
          <source>Following explains differences between the expected SparseTensors: For example if dense form of your sparse data has shape &lt;code&gt;[3, 5]&lt;/code&gt; and values:</source>
          <target state="translated">以下内容解释了预期的SparseTensor之间的差异：例如，如果稀疏数据的密集形式具有形状 &lt;code&gt;[3, 5]&lt;/code&gt; 和值：</target>
        </trans-unit>
        <trans-unit id="1f587840359f89bcceb77644a681ee1053752a4d" translate="yes" xml:space="preserve">
          <source>Following standard Python indexing rules, a negative &lt;code&gt;axis&lt;/code&gt; counts from the end so &lt;code&gt;axis=-1&lt;/code&gt; adds an inner most dimension:</source>
          <target state="translated">遵循标准的Python索引规则，负 &lt;code&gt;axis&lt;/code&gt; 从末尾开始计数，因此 &lt;code&gt;axis=-1&lt;/code&gt; 增加了最内层的尺寸：</target>
        </trans-unit>
        <trans-unit id="3a4d707a678724dde2fddb59f45c1e15e1429fb9" translate="yes" xml:space="preserve">
          <source>Following standard python indexing rules, a negative &lt;code&gt;axis&lt;/code&gt; counts from the end so &lt;code&gt;axis=-1&lt;/code&gt; adds an inner most dimension:</source>
          <target state="translated">遵循标准的python索引规则，负 &lt;code&gt;axis&lt;/code&gt; 从末尾开始计数，因此 &lt;code&gt;axis=-1&lt;/code&gt; 增加了最内层的尺寸：</target>
        </trans-unit>
        <trans-unit id="f7880600348a091a43e2a84906d6002820643108" translate="yes" xml:space="preserve">
          <source>For</source>
          <target state="translated">For</target>
        </trans-unit>
        <trans-unit id="4fd9985785e46b3b8d2eb080ecf31ffb84a61f11" translate="yes" xml:space="preserve">
          <source>For &amp;gt;0D tensors, truthiness is determined by looking at the number of elements. If has zero elements, then the result is false. Otherwise the result is true.</source>
          <target state="translated">对于&amp;gt; 0D张量，真实性是通过查看元素数量来确定的。如果元素为零，则结果为false。否则结果为true。</target>
        </trans-unit>
        <trans-unit id="a9f9a841a7e0cc5b022e6318bea78b55a9efc104" translate="yes" xml:space="preserve">
          <source>For 'channels_last' data_format, the 2nd, 3rd and 4th dimension will be padded. For 'channels_first' data_format, the 3rd, 4th and 5th dimension will be padded.</source>
          <target state="translated">对于'channels_last'数据格式,第二、三、四维将被填充。对于'channels_first'数据格式,第3、4、5维将被填充。</target>
        </trans-unit>
        <trans-unit id="4d447d9221f45cdb582dda20329208318ce162fc" translate="yes" xml:space="preserve">
          <source>For 0 &amp;lt;= i &amp;lt; len(spatial_dims), we assign:</source>
          <target state="translated">对于0 &amp;lt;= i &amp;lt;len（spatial_dims），我们分配：</target>
        </trans-unit>
        <trans-unit id="146f00a85b68b92b896f97b975828e18300e6475" translate="yes" xml:space="preserve">
          <source>For 0-D (scalar) &lt;code&gt;indices&lt;/code&gt;:</source>
          <target state="translated">对于0-D（标量） &lt;code&gt;indices&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="547112f2822cdd1e4adf3817f29d09a381834041" translate="yes" xml:space="preserve">
          <source>For 0D tensors, truthiness is determined by comparing against a &quot;zero&quot; value. For numerical types it is the obvious zero. For strings it is the empty string.</source>
          <target state="translated">对于0D时序,真实性是通过与一个 &quot;零 &quot;值进行比较来确定的。对于数值类型,它是明显的零。对于字符串来说,它是空字符串。</target>
        </trans-unit>
        <trans-unit id="93086c1250897fa853eb236163fc696ad9b7ad7a" translate="yes" xml:space="preserve">
          <source>For 1-D (vector) &lt;code&gt;indices&lt;/code&gt; with &lt;code&gt;batch_dims=0&lt;/code&gt;:</source>
          <target state="translated">对于1-d（矢量） &lt;code&gt;indices&lt;/code&gt; 与 &lt;code&gt;batch_dims=0&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="0a015181e096f8a1581f3a9641d414e5785efcf9" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;1+1j&lt;/code&gt; the value would be computed as: \(e^1{\\cos(1)+i\\sin(1)} = 2.7182817 \\times (0.5403023+0.84147096j)\)</source>
          <target state="translated">对于 &lt;code&gt;1+1j&lt;/code&gt; ,该值将被计算为：\（e ^ 1 {\\ cos（1）+ i \\ sin（1）} = 2.7182817 \\ times（0.5403023 + 0.84147096j）\）</target>
        </trans-unit>
        <trans-unit id="defba424886a691f2ba7bcc4056171fb0d0e0d47" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;SparseTensor&lt;/code&gt;s, the first (batch) column of the indices matrix is removed (the indices matrix is a column vector), the values vector is unchanged, and the first (&lt;code&gt;batch_size&lt;/code&gt;) entry of the shape vector is removed (it is now a single element vector).</source>
          <target state="translated">对于 &lt;code&gt;SparseTensor&lt;/code&gt; ，删除索引矩阵的第一（批处理）列（索引矩阵是列向量），值向量不变，并且删除形状向量的第一项（ &lt;code&gt;batch_size&lt;/code&gt; ）（现在是单个元素向量）。</target>
        </trans-unit>
        <trans-unit id="44ae4bb96a98281ba7a5f41018a3c0cf10c4dea5" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;mode == ModeKeys.EVAL&lt;/code&gt;: required field is &lt;code&gt;loss&lt;/code&gt;.</source>
          <target state="translated">对于 &lt;code&gt;mode == ModeKeys.EVAL&lt;/code&gt; ：必填字段为 &lt;code&gt;loss&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fa798daa39c957c071f1ef2d8ef9c584caee3af3" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;mode == ModeKeys.PREDICT&lt;/code&gt;: required fields are &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="translated">对于 &lt;code&gt;mode == ModeKeys.PREDICT&lt;/code&gt; ：必填字段是 &lt;code&gt;predictions&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5c1da15aacc237948a45719180b4b1f05786246a" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;mode == ModeKeys.TRAIN&lt;/code&gt;: required fields are &lt;code&gt;loss&lt;/code&gt; and &lt;code&gt;train_op&lt;/code&gt;.</source>
          <target state="translated">对于 &lt;code&gt;mode == ModeKeys.TRAIN&lt;/code&gt; ：必填字段为 &lt;code&gt;loss&lt;/code&gt; 和 &lt;code&gt;train_op&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e7f68e1644d616fa9efc4179ea412ad0959f6e10" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;nesterov=True&lt;/code&gt;, See &lt;a href=&quot;http://jmlr.org/proceedings/papers/v28/sutskever13.pdf&quot;&gt;Sutskever et al., 2013&lt;/a&gt;.</source>
          <target state="translated">对于 &lt;code&gt;nesterov=True&lt;/code&gt; ，请参见&lt;a href=&quot;http://jmlr.org/proceedings/papers/v28/sutskever13.pdf&quot;&gt;Sutskever等人，2013年&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="66bd7f5eecabe99afa580fb13d864a7f7973624c" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;x&lt;/code&gt; with more dimensions, independently normalizes each 1-D slice along dimension &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="translated">对于具有更大尺寸的 &lt;code&gt;x&lt;/code&gt; ，独立地沿尺寸 &lt;code&gt;axis&lt;/code&gt; 标准化每个1-D切片。</target>
        </trans-unit>
        <trans-unit id="43544e8b815a7d32d165c045ffe8994b597cc573" translate="yes" xml:space="preserve">
          <source>For AMSGrad see &lt;a href=&quot;https://openreview.net/pdf?id=ryQu7f-RZ&quot;&gt;On The Convergence Of Adam And Beyond. Reddi et al., 5-8&lt;/a&gt;.</source>
          <target state="translated">有关AMSGrad的信息，请参阅&lt;a href=&quot;https://openreview.net/pdf?id=ryQu7f-RZ&quot;&gt;《亚当与&lt;/a&gt;未来的融合》。Reddi et al。，5-8。</target>
        </trans-unit>
        <trans-unit id="13ebc2a0e8c090e78de3fad9e601fded772c3334" translate="yes" xml:space="preserve">
          <source>For DNN model, &lt;code&gt;indicator_column&lt;/code&gt; can be used to wrap any &lt;code&gt;categorical_column_*&lt;/code&gt; (e.g., to feed to DNN). Consider to Use &lt;code&gt;embedding_column&lt;/code&gt; if the number of buckets/unique(values) are large.</source>
          <target state="translated">对于DNN模型， &lt;code&gt;indicator_column&lt;/code&gt; 可以用于包装任何 &lt;code&gt;categorical_column_*&lt;/code&gt; （例如，馈送给DNN）。如果存储桶/唯一值（值）的数量很大，请考虑使用 &lt;code&gt;embedding_column&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="358d84aa8148063b462186c221ef88a0bda8ec99" translate="yes" xml:space="preserve">
          <source>For Example:</source>
          <target state="translated">例如:</target>
        </trans-unit>
        <trans-unit id="698c0c83d084957c23756fca89030c92b5e65b9c" translate="yes" xml:space="preserve">
          <source>For Gaussian and Laplacian kernels, this corresponds to a scaling factor of the corresponding kernel approximated by the layer (see concrete definitions above). When provided, it should be a positive float. If None, a default value is used: if the kernel initializer is set to &quot;gaussian&quot;, &lt;code&gt;scale&lt;/code&gt; defaults to &lt;code&gt;sqrt(input_dim / 2)&lt;/code&gt;, otherwise, it defaults to 1.0. Both the approximation error of the kernel and the classification quality are sensitive to this parameter. If &lt;code&gt;trainable&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, this parameter is learned end-to-end during training and the provided value serves as the initial value. &lt;strong&gt;Note:&lt;/strong&gt; When features from this layer are fed to a linear model, by making &lt;code&gt;scale&lt;/code&gt; trainable, the resulting optimization problem is no longer convex (even if the loss function used by the linear model is convex).</source>
          <target state="translated">对于高斯和拉普拉斯内核，这对应于由该层近似的相应内核的缩放因子（请参见上面的具体定义）。提供时，它应该是正浮点数。如果为None，则使用默认值：如果内核初始化程序设置为&amp;ldquo; gaussian&amp;rdquo;，则 &lt;code&gt;scale&lt;/code&gt; 默认为 &lt;code&gt;sqrt(input_dim / 2)&lt;/code&gt; ，否则默认为1.0。核的近似误差和分类质量都对该参数敏感。如果 &lt;code&gt;trainable&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; ，那么将在训练过程中端对端学习此参数，并且将提供的值用作初始值。&lt;strong&gt;注意：&lt;/strong&gt;当通过 &lt;code&gt;scale&lt;/code&gt; 将这一层中的要素馈入线性模型时， 可训练的，最终的优化问题不再是凸的（即使线性模型使用的损失函数是凸的）。</target>
        </trans-unit>
        <trans-unit id="12448879835e54272469ca384e2db601805a9b6d" translate="yes" xml:space="preserve">
          <source>For NVIDIA GPUs with Tensor cores, as a general performance guide, dimensions (such as batch size, input size, output size, and channel counts) should be powers of two if under 256, or otherwise divisible by 8 if above 256. For more information, check out the &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html&quot;&gt;NVIDIA Deep Learning Performance Guide&lt;/a&gt;.</source>
          <target state="translated">对于具有Tensor内核的NVIDIA GPU，作为一般性能指南，尺寸（例如批大小，输入大小，输出大小和通道数）如果小于256，则应为2的幂；如果大于256，则应除以8。有关信息，请查看《&lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html&quot;&gt;NVIDIA深度学习性能指南》&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e6c57b61b2025e89cc1b96b3f8c44dc568631574" translate="yes" xml:space="preserve">
          <source>For RaggedTensors with multiple ragged dimensions, the &lt;code&gt;row_splits&lt;/code&gt; for all nested &lt;code&gt;RaggedTensor&lt;/code&gt; objects are cast to the given dtype.</source>
          <target state="translated">对于具有多个参差不齐尺寸的 &lt;code&gt;RaggedTensor&lt;/code&gt; s，所有嵌套RaggedTensor对象的 &lt;code&gt;row_splits&lt;/code&gt; 都将强制转换为给定的dtype。</target>
        </trans-unit>
        <trans-unit id="680d2331fce0b7a83d542b4d1de0958158b6ff5b" translate="yes" xml:space="preserve">
          <source>For Tensor arguments, &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; instantiates a separate graph for every unique set of input shapes and datatypes. The example below creates two separate graphs, each specialized to a different shape:</source>
          <target state="translated">对于Tensor自变量，&lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; 会为每组&lt;/a&gt;唯一的输入形状和数据类型实例化一个单独的图。下面的示例创建两个单独的图，每个图专门化为不同的形状：</target>
        </trans-unit>
        <trans-unit id="affb3fda9deede559b712893d926e23f939195d8" translate="yes" xml:space="preserve">
          <source>For Unicode, see the &lt;a href=&quot;working%20with%20unicode%20text&quot;&gt;https://www.tensorflow.org/tutorials/representation/unicode&lt;/a&gt; tutorial.</source>
          <target state="translated">对于Unicode，请参阅&lt;a href=&quot;working%20with%20unicode%20text&quot;&gt;https://www.tensorflow.org/tutorials/representation/unicode&lt;/a&gt;教程。</target>
        </trans-unit>
        <trans-unit id="438450c314656d91b7eb58ac47d34990ac07e0e9" translate="yes" xml:space="preserve">
          <source>For Wide (aka linear) model, &lt;code&gt;indicator_column&lt;/code&gt; is the internal representation for categorical column when passing categorical column directly (as any element in feature_columns) to &lt;code&gt;linear_model&lt;/code&gt;. See &lt;code&gt;linear_model&lt;/code&gt; for details.</source>
          <target state="translated">对于宽（aka线性）模型，当将分类列（作为feature_columns中的任何元素）直接传递给 &lt;code&gt;linear_model&lt;/code&gt; 时， &lt;code&gt;indicator_column&lt;/code&gt; 是分类列的内部表示形式。有关详细信息，请参见 &lt;code&gt;linear_model&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d1809fcc8df392d7ea85c0ac28ccfcbd2a81ee6c" translate="yes" xml:space="preserve">
          <source>For a 1-D tensor with &lt;code&gt;axis = 0&lt;/code&gt;, computes</source>
          <target state="translated">对于 &lt;code&gt;axis = 0&lt;/code&gt; 的一维张量，计算</target>
        </trans-unit>
        <trans-unit id="eb040fc5b017a63cdc59b792f1488c8b7f490212" translate="yes" xml:space="preserve">
          <source>For a 1D tensor, &lt;code&gt;tf.gather(values, tf.argsort(values))&lt;/code&gt; is equivalent to &lt;a href=&quot;sort&quot;&gt;&lt;code&gt;tf.sort(values)&lt;/code&gt;&lt;/a&gt;. For higher dimensions, the output has the same shape as &lt;code&gt;values&lt;/code&gt;, but along the given axis, values represent the index of the sorted element in that slice of the tensor at the given position.</source>
          <target state="translated">对于一维张量， &lt;code&gt;tf.gather(values, tf.argsort(values))&lt;/code&gt; 等效于&lt;a href=&quot;sort&quot;&gt; &lt;code&gt;tf.sort(values)&lt;/code&gt; &lt;/a&gt;。对于较大的尺寸，输出具有与 &lt;code&gt;values&lt;/code&gt; 相同的形状，但是沿着给定的轴，值表示在给定位置的张量的该切片中已排序元素的索引。</target>
        </trans-unit>
        <trans-unit id="fb2c582ee71ccd0dae80f698e01ac135396f67ca" translate="yes" xml:space="preserve">
          <source>For a chief, this utility sets proper session initializer/restorer. It also creates hooks related to checkpoint and summary saving. For workers, this utility sets proper session creator which waits for the chief to initialize/restore. Please check &lt;a href=&quot;monitoredsession&quot;&gt;&lt;code&gt;tf.compat.v1.train.MonitoredSession&lt;/code&gt;&lt;/a&gt; for more information.</source>
          <target state="translated">对于负责人，此实用程序可以设置适当的会话初始化程序/恢复程序。它还创建与检查点和摘要保存相关的挂钩。对于工作者，此实用程序设置适当的会话创建者，该创建者等待负责人初始化/还原。请检查&lt;a href=&quot;monitoredsession&quot;&gt; &lt;code&gt;tf.compat.v1.train.MonitoredSession&lt;/code&gt; &lt;/a&gt;了解更多信息。</target>
        </trans-unit>
        <trans-unit id="1e685a37c8c58056e8f3530b78115d9f73810c25" translate="yes" xml:space="preserve">
          <source>For a complete example showing the speed-up on training an image classification task on CIFAR10, check out this Colab notebook.</source>
          <target state="translated">对于一个完整的例子,显示了在CIFAR10上训练图像分类任务的速度,请查看这个Colab笔记本。</target>
        </trans-unit>
        <trans-unit id="b151bbc686479044821007cc7d7dd7e642e9457f" translate="yes" xml:space="preserve">
          <source>For a counter-base RNG algorithm such as Philox and ThreeFry (as described in paper 'Parallel Random Numbers: As Easy as 1, 2, 3' [&lt;a href=&quot;https://www.thesalmons.org/john/random123/papers/random123sc11.pdf&quot;&gt;https://www.thesalmons.org/john/random123/papers/random123sc11.pdf&lt;/a&gt;]), the RNG state consists of two parts: counter and key. The output is generated via the formula: output=hash(key, counter), i.e. a hashing of the counter parametrized by the key. Two RNGs with two different keys can be thought as generating two independent random-number streams (a stream is formed by increasing the counter).</source>
          <target state="translated">对于反基准RNG算法，例如Philox和ThreeFry（如论文&amp;ldquo;并行随机数：1、2、3一样容易&amp;rdquo;中所述[ &lt;a href=&quot;https://www.thesalmons.org/john/random123/papers/random123sc11.pdf&quot;&gt;https://www.thesalmons.org/john/random123/papers/random123sc11。 pdf&lt;/a&gt; ]），RNG状态由两部分组成：计数器和密钥。通过以下公式生成输出：output = hash（key，counter），即由密钥参数化的计数器的哈希。可以将具有两个不同密钥的两个RNG视为生成两个独立的随机数流（通过增加计数器来形成流）。</target>
        </trans-unit>
        <trans-unit id="c0f028ef007ecbff710e7dba8c5a5dabc991f9c1" translate="yes" xml:space="preserve">
          <source>For a counter-base RNG algorithm such as Philox and ThreeFry (as described in paper 'Parallel Random Numbers: As Easy as 1, 2, 3' [https://www.thesalmons.org/john/random123/papers/random123sc11.pdf]), the RNG state consists of two parts: counter and key. The output is generated via the formula: output=hash(key, counter), i.e. a hashing of the counter parametrized by the key. Two RNGs with two different keys can be thought as generating two independent random-number streams (a stream is formed by increasing the counter).</source>
          <target state="translated">对于一个计数器基础的RNG算法,如Philox和ThreeFry(如论文'Parallel Random Numbers.As Easy as 1,2,3'[]所述),RNG状态由两部分组成:计数器和密钥。As Easy as 1,2,3' [https://www.thesalmons.org/john/random123/papers/random123sc11.pdf]),RNG状态由两部分组成:计数器和密钥。输出通过公式生成:output=hash(key,counter),即由key参数化的counter的散列。两个不同键的RNG可以认为是产生了两个独立的随机数流(一个流是通过增加计数器形成的)。</target>
        </trans-unit>
        <trans-unit id="9a5ce116616d9115cf39dfc32b5ace717bbeef6e" translate="yes" xml:space="preserve">
          <source>For a description of atrous convolution and how it can be used for dense feature extraction, please see: (Chen et al., 2015). The same operation is investigated further in (Yu et al., 2016). Previous works that effectively use atrous convolution in different ways are, among others, (Sermanet et al., 2014) and (Giusti et al., 2013). Atrous convolution is also closely related to the so-called noble identities in multi-rate signal processing.</source>
          <target state="translated">关于阿特拉斯卷积的描述,以及如何将其用于密集特征提取,请参见。(Chen et al.,2015)。在(Yu等,2016)中进一步研究了同样的操作。之前以不同方式有效使用阿特鲁斯卷积的作品有:(Sermanet等,2014)和(Giusti等,2013)等。阿特鲁斯卷积也与多速率信号处理中的所谓贵族身份密切相关。</target>
        </trans-unit>
        <trans-unit id="9459e940f5730676b9001d651d28cb51b42d969c" translate="yes" xml:space="preserve">
          <source>For a description of atrous convolution and how it can be used for dense feature extraction, please see: &lt;a href=&quot;http://arxiv.org/abs/1412.7062&quot;&gt;Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs&lt;/a&gt;. The same operation is investigated further in &lt;a href=&quot;http://arxiv.org/abs/1511.07122&quot;&gt;Multi-Scale Context Aggregation by Dilated Convolutions&lt;/a&gt;. Previous works that effectively use atrous convolution in different ways are, among others, &lt;a href=&quot;http://arxiv.org/abs/1312.6229&quot;&gt;OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks&lt;/a&gt; and &lt;a href=&quot;http://arxiv.org/abs/1302.1700&quot;&gt;Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks&lt;/a&gt;. Atrous convolution is also closely related to the so-called noble identities in multi-rate signal processing.</source>
          <target state="translated">有关无声卷积及其如何用于密集特征提取的描述，请参见：&lt;a href=&quot;http://arxiv.org/abs/1412.7062&quot;&gt;深度卷积网络和全连接CRF的语义图像分割&lt;/a&gt;。&lt;a href=&quot;http://arxiv.org/abs/1511.07122&quot;&gt;通过扩张卷积&lt;/a&gt;在多尺度上下文聚合中进一步研究了相同的操作。以不同的方式有效地使用atrous卷积以前的作品，除其他外，&lt;a href=&quot;http://arxiv.org/abs/1312.6229&quot;&gt;OverFeat：综合识别，定位和检测使用卷积网络&lt;/a&gt;，并&lt;a href=&quot;http://arxiv.org/abs/1302.1700&quot;&gt;与深马克斯池卷积神经网络的快速图像扫描&lt;/a&gt;。多孔卷积还与多速率信号处理中的所谓贵族身份密切相关。</target>
        </trans-unit>
        <trans-unit id="9395aea9a50261f21aee7ad93d28f55ca17890b1" translate="yes" xml:space="preserve">
          <source>For a detailed guide, see &lt;a href=&quot;https://tensorflow.org/guide/saved_model#savedmodels_from_estimators&quot;&gt;SavedModel from Estimators&lt;/a&gt;.</source>
          <target state="translated">有关详细指南，请参见&lt;a href=&quot;https://tensorflow.org/guide/saved_model#savedmodels_from_estimators&quot;&gt;Estimators中的SavedModel&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="faf1eab5a6b813e3139fd4358594343e9ec1b061" translate="yes" xml:space="preserve">
          <source>For a detailed guide, see &lt;a href=&quot;https://tensorflow.org/guide/saved_model#using_savedmodel_with_estimators&quot;&gt;Using SavedModel with Estimators&lt;/a&gt;.</source>
          <target state="translated">有关详细指南，请参见&lt;a href=&quot;https://tensorflow.org/guide/saved_model#using_savedmodel_with_estimators&quot;&gt;将SavedModel与Estimators一起使用&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="57997fbb3307d6157f9ed4d1c8e94e6ae2cc97cf" translate="yes" xml:space="preserve">
          <source>For a given score-label-distribution the required precision might not be achievable, in this case 0.0 is returned as recall.</source>
          <target state="translated">对于一个给定的分数-标签-分布,可能无法达到所需的精度,在这种情况下,0.0作为召回返回。</target>
        </trans-unit>
        <trans-unit id="82871db36d8768d1a3be8c39394657eb4327cd7d" translate="yes" xml:space="preserve">
          <source>For a nested python tuple:</source>
          <target state="translated">对于一个嵌套的python元组。</target>
        </trans-unit>
        <trans-unit id="220ccd8b164a992646be9626d306ae4431c07d07" translate="yes" xml:space="preserve">
          <source>For a profile data structure, profiler first finds the profiler nodes matching 'start_name_regexes', and starts displaying profiler nodes from there. Then, if a node matches 'show_name_regexes' and doesn't match 'hide_name_regexes', it's displayed. If a node matches 'trim_name_regexes', profiler stops further searching that branch.</source>
          <target state="translated">对于profile数据结构,profiler首先找到与'start_name_regexes'匹配的profiler节点,并从那里开始显示profiler节点。然后,如果一个节点匹配'show_name_regexes'而不匹配'hide_name_regexes',就会被显示。如果一个节点匹配'trim_name_regexes',profiler就会停止进一步搜索该分支。</target>
        </trans-unit>
        <trans-unit id="9939180266b3d93448c8fea23d0f6dfa98cc31b6" translate="yes" xml:space="preserve">
          <source>For a tutorial, see the &lt;a href=&quot;https://www.tensorflow.org/guide/function&quot;&gt;tf.function and AutoGraph guide&lt;/a&gt;. For more detailed information, see the &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md&quot;&gt;AutoGraph reference documentation&lt;/a&gt;.</source>
          <target state="translated">有关教程，请参见&lt;a href=&quot;https://www.tensorflow.org/guide/function&quot;&gt;tf.function和AutoGraph指南&lt;/a&gt;。有关更多详细信息，请参见&lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md&quot;&gt;AutoGraph参考文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3961b8c97504a885300108217230a73b23f20c07" translate="yes" xml:space="preserve">
          <source>For additional ClusterResolver properties such as task type, task index, rpc layer, environment, etc..., we will return the value from the first ClusterResolver in the union.</source>
          <target state="translated">对于额外的ClusterResolver属性,如任务类型、任务索引、rpc层、环境等......,我们将返回联盟中第一个ClusterResolver的值。</target>
        </trans-unit>
        <trans-unit id="4710c7702380e37df383d4f1e0b6d32988898a50" translate="yes" xml:space="preserve">
          <source>For additional information about specificity and sensitivity, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;the following&lt;/a&gt;.</source>
          <target state="translated">有关特异性和敏感性的其他信息，请参阅&lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;以下内容&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="28b4f32d54970e27ef51cc570317aa7cc036c269" translate="yes" xml:space="preserve">
          <source>For additional information about specificity and sensitivity, see the following: &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&lt;/a&gt;</source>
          <target state="translated">有关特异性和敏感性的其他信息，请参见以下内容：&lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;https&lt;/a&gt; : //en.wikipedia.org/wiki/Sensitivity_and_specificity</target>
        </trans-unit>
        <trans-unit id="8ba9a27fb906c20b62b7961623bd63a85b7a2467" translate="yes" xml:space="preserve">
          <source>For additional information about specificity and sensitivity, see the following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity</source>
          <target state="translated">有关特异性和敏感性的更多信息,请参见以下内容:https://en.wikipedia.org/wiki/Sensitivity_and_specificity。</target>
        </trans-unit>
        <trans-unit id="63527db3074c5cfec63b6889a3a6425bedc1846b" translate="yes" xml:space="preserve">
          <source>For advanced models, please use the full &lt;a href=&quot;lstmcell&quot;&gt;&lt;code&gt;tf.compat.v1.nn.rnn_cell.LSTMCell&lt;/code&gt;&lt;/a&gt; that follows.</source>
          <target state="translated">对于高级模型，请使用下面的完整&lt;a href=&quot;lstmcell&quot;&gt; &lt;code&gt;tf.compat.v1.nn.rnn_cell.LSTMCell&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="343d6ea49aad072975b79ade2c38a0aa2de8f433" translate="yes" xml:space="preserve">
          <source>For an &lt;code&gt;2-D&lt;/code&gt; tensor &lt;code&gt;x&lt;/code&gt; with &lt;code&gt;axis = 0&lt;/code&gt;:</source>
          <target state="translated">对于 &lt;code&gt;2-D&lt;/code&gt; 张量 &lt;code&gt;x&lt;/code&gt; 与 &lt;code&gt;axis = 0&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="716108a64b24f9071a5ec3137f73a30034ffd3e1" translate="yes" xml:space="preserve">
          <source>For an &lt;code&gt;2-D&lt;/code&gt; tensor &lt;code&gt;x&lt;/code&gt; with &lt;code&gt;axis = 1&lt;/code&gt;:</source>
          <target state="translated">对于 &lt;code&gt;2-D&lt;/code&gt; 张量 &lt;code&gt;x&lt;/code&gt; 与 &lt;code&gt;axis = 1&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="eadb22d5f122e214c4d8d886fe174ffa6b50bd2b" translate="yes" xml:space="preserve">
          <source>For an explanation see &quot;Differentiation of the Cholesky algorithm&quot; by Iain Murray &lt;a href=&quot;http://arxiv.org/abs/1602.07527&quot;&gt;http://arxiv.org/abs/1602.07527&lt;/a&gt;</source>
          <target state="translated">有关说明，请参见Iain Murray撰写的&amp;ldquo; Cholesky算法的微分&amp;rdquo; &lt;a href=&quot;http://arxiv.org/abs/1602.07527&quot;&gt;http://arxiv.org/abs/1602.07527&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fb090946cbd078325cc5454075dae1f83d327ccf" translate="yes" xml:space="preserve">
          <source>For an explanation see &quot;Differentiation of the Cholesky algorithm&quot; by Iain Murray &lt;a href=&quot;https://arxiv.org/abs/1602.07527&quot;&gt;http://arxiv.org/abs/1602.07527&lt;/a&gt;</source>
          <target state="translated">有关说明，请参见Iain Murray撰写的&amp;ldquo; Cholesky算法的微分&amp;rdquo; &lt;a href=&quot;https://arxiv.org/abs/1602.07527&quot;&gt;http://arxiv.org/abs/1602.07527&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="58bdfb47c0eae123b4f1b48443620758180eb094" translate="yes" xml:space="preserve">
          <source>For an input tensor with larger depth, here of shape &lt;code&gt;[1, 1, 1, 12]&lt;/code&gt;, e.g.</source>
          <target state="translated">对于具有较大深度的输入张量，此处的形状为 &lt;code&gt;[1, 1, 1, 12]&lt;/code&gt; ，例如</target>
        </trans-unit>
        <trans-unit id="73c52c9278ce524597d2c5b7b688185a99fdfc11" translate="yes" xml:space="preserve">
          <source>For an input tensor with larger depth, here of shape &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt;, e.g.</source>
          <target state="translated">对于具有较大深度的输入张量，此处的形状为 &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt; ，例如</target>
        </trans-unit>
        <trans-unit id="1f05e924ab8a0eee6cd58d652fef01bc7ebd2bac" translate="yes" xml:space="preserve">
          <source>For backward compatibility with the V1 format, this Op currently allows restoring from a V1 checkpoint as well:</source>
          <target state="translated">为了向后兼容V1格式,该操作目前也允许从V1检查点恢复。</target>
        </trans-unit>
        <trans-unit id="870b413d457e7d3b6fb91573e35aa40eaf69e580" translate="yes" xml:space="preserve">
          <source>For backwards compatibility only.</source>
          <target state="translated">只为向后兼容。</target>
        </trans-unit>
        <trans-unit id="3bbf0e36ec059b3f4c0f63308a870c314c931ac4" translate="yes" xml:space="preserve">
          <source>For best results, &lt;code&gt;predictions&lt;/code&gt; should be distributed approximately uniformly in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC approximation may be poor if this is not the case. Setting &lt;code&gt;summation_method&lt;/code&gt; to 'minoring' or 'majoring' can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC.</source>
          <target state="translated">为了获得最佳结果， &lt;code&gt;predictions&lt;/code&gt; 应该在[0，1]范围内大致均匀分布，并且不要在0或1附近达到峰值。如果不是这种情况，则AUC近似值的质量可能很差。将 &lt;code&gt;summation_method&lt;/code&gt; 设置为&amp;ldquo; minoring&amp;rdquo;或&amp;ldquo; majoring&amp;rdquo;可以通过提供AUC的下限或上限估算值来帮助量化近似值中的误差。</target>
        </trans-unit>
        <trans-unit id="f78743990c17f9299a8953827006e26051a5a3fd" translate="yes" xml:space="preserve">
          <source>For best results, &lt;code&gt;predictions&lt;/code&gt; should be distributed approximately uniformly in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC approximation may be poor if this is not the case. Setting &lt;code&gt;summation_method&lt;/code&gt; to 'minoring' or 'majoring' can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC. The &lt;code&gt;thresholds&lt;/code&gt; parameter can be used to manually specify thresholds which split the predictions more evenly.</source>
          <target state="translated">为了获得最佳结果， &lt;code&gt;predictions&lt;/code&gt; 应该在[0，1]范围内大致均匀分布，并且不要在0或1附近达到峰值。如果不是这种情况，则AUC近似值的质量可能很差。将 &lt;code&gt;summation_method&lt;/code&gt; 设置为&amp;ldquo; minoring&amp;rdquo;或&amp;ldquo; majoring&amp;rdquo;可以通过提供AUC的下限或上限估算值来帮助量化近似值中的误差。 &lt;code&gt;thresholds&lt;/code&gt; 参数可用于手动指定阈值，这些阈值可以更均匀地划分预测。</target>
        </trans-unit>
        <trans-unit id="daff1b722d0fb127a20bad0fd4ebd0412bf72bd5" translate="yes" xml:space="preserve">
          <source>For brevity, let &lt;code&gt;c = log(x) = log_input&lt;/code&gt;, &lt;code&gt;z = targets&lt;/code&gt;. The log Poisson loss is</source>
          <target state="translated">为简便起见，令 &lt;code&gt;c = log(x) = log_input&lt;/code&gt; ， &lt;code&gt;z = targets&lt;/code&gt; 。对数泊松损失为</target>
        </trans-unit>
        <trans-unit id="d6219a532f9c408cd0729ad6b959c0bbe42f179a" translate="yes" xml:space="preserve">
          <source>For brevity, let &lt;code&gt;x = logits&lt;/code&gt;, &lt;code&gt;z = labels&lt;/code&gt;, &lt;code&gt;q = pos_weight&lt;/code&gt;. The loss is:</source>
          <target state="translated">为简便起见，让 &lt;code&gt;x = logits&lt;/code&gt; ， &lt;code&gt;z = labels&lt;/code&gt; ， &lt;code&gt;q = pos_weight&lt;/code&gt; 。损失是：</target>
        </trans-unit>
        <trans-unit id="ff9d01f67c929c82f2ffed8b81b820d23e32b1da" translate="yes" xml:space="preserve">
          <source>For brevity, let &lt;code&gt;x = logits&lt;/code&gt;, &lt;code&gt;z = labels&lt;/code&gt;. The logistic loss is</source>
          <target state="translated">为简便起见，让 &lt;code&gt;x = logits&lt;/code&gt; ， &lt;code&gt;z = labels&lt;/code&gt; 。物流损失是</target>
        </trans-unit>
        <trans-unit id="1301e2ab85c859b04f71a10ca5d0a61ed66dc9bc" translate="yes" xml:space="preserve">
          <source>For classification: binary label.</source>
          <target state="translated">用于分类:二元标签。</target>
        </trans-unit>
        <trans-unit id="e22a3f22d875842280028907e515e5b1ceef3a59" translate="yes" xml:space="preserve">
          <source>For complex numbers, &lt;code&gt;y = sign(x) = x / |x|&lt;/code&gt; if &lt;code&gt;x != 0&lt;/code&gt;, otherwise &lt;code&gt;y = 0&lt;/code&gt;.</source>
          <target state="translated">对于复数， &lt;code&gt;y = sign(x) = x / |x|&lt;/code&gt; 如果 &lt;code&gt;x != 0&lt;/code&gt; ，否则 &lt;code&gt;y = 0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0b4484477dc0ad27cefcf137a2c8cf12a0ec4bd1" translate="yes" xml:space="preserve">
          <source>For complex numbers, the exponential value is calculated as \(e^{x+iy}={e^x}{e^{iy} }={e^x}{\\cos(y)+i\\sin(y)}\)</source>
          <target state="translated">对于复数,指数值的计算方法为:/(e^{x+iy}={e^x}{e^{iy}}={e^x}{\cos(y)+i\sin(y)}})</target>
        </trans-unit>
        <trans-unit id="cb5d4419a8e723474e43b51cd45a962afee640c2" translate="yes" xml:space="preserve">
          <source>For complex numbers, the exponential value is calculated as follows:</source>
          <target state="translated">对于复数,指数值的计算方法如下。</target>
        </trans-unit>
        <trans-unit id="ab8f171225b6810fb2121ef3a2ccfb37c7669be7" translate="yes" xml:space="preserve">
          <source>For complex numbers, y = sign(x) = x / |x| if x != 0, otherwise y = 0.</source>
          <target state="translated">对于复数,y=sign(x)=x/|x|,如果x !=0,否则y=0。</target>
        </trans-unit>
        <trans-unit id="49462dde41ed51282a18f24b9ae73b7df90a2ba4" translate="yes" xml:space="preserve">
          <source>For convenience, The requested number of partitions does not have to divide the corresponding dimension evenly. If it does not, the shapes of the partitions are incremented by 1 starting from partition 0 until all slack is absorbed. The adjustment rules may change in the future, but as you can save/restore these variables with different slicing specifications this should not be a problem.</source>
          <target state="translated">为方便起见,要求的分区数不一定要把相应的维度平均分配。如果不是这样,分区的形状从0号分区开始以1递增,直到吸收所有的空隙。调整规则将来可能会改变,但由于您可以用不同的切片规格保存/恢复这些变量,这应该不是问题。</target>
        </trans-unit>
        <trans-unit id="1350aabb6a166b4a9adc5331f9bfc6c8e1f4e703" translate="yes" xml:space="preserve">
          <source>For convenience, this function sets a default value for the &lt;code&gt;step&lt;/code&gt; parameter used in summary-writing functions elsewhere in the API so that it need not be explicitly passed in every such invocation. The value can be a constant or a variable, and can be retrieved via &lt;a href=&quot;get_step&quot;&gt;&lt;code&gt;tf.summary.experimental.get_step()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">为方便起见，此函数为API其他地方的摘要编写函数中使用的 &lt;code&gt;step&lt;/code&gt; 参数设置默认值，因此无需在每次此类调用中都明确传递它。该值可以是常量或变量，可以通过&lt;a href=&quot;get_step&quot;&gt; &lt;code&gt;tf.summary.experimental.get_step()&lt;/code&gt; &lt;/a&gt;进行检索。</target>
        </trans-unit>
        <trans-unit id="4334d314960569ae2e72fe3de9077256f0d3ba99" translate="yes" xml:space="preserve">
          <source>For correctness, &lt;a href=&quot;../../while_loop&quot;&gt;&lt;code&gt;tf.while_loop()&lt;/code&gt;&lt;/a&gt; strictly enforces shape invariants for the loop variables. A shape invariant is a (possibly partial) shape that is unchanged across the iterations of the loop. An error will be raised if the shape of a loop variable after an iteration is determined to be more general than or incompatible with its shape invariant. For example, a shape of [11, None] is more general than a shape of [11, 17], and [11, 21] is not compatible with [11, 17]. By default (if the argument &lt;code&gt;shape_invariants&lt;/code&gt; is not specified), it is assumed that the initial shape of each tensor in &lt;code&gt;loop_vars&lt;/code&gt; is the same in every iteration. The &lt;code&gt;shape_invariants&lt;/code&gt; argument allows the caller to specify a less specific shape invariant for each loop variable, which is needed if the shape varies between iterations. The &lt;a href=&quot;../../tensor#set_shape&quot;&gt;&lt;code&gt;tf.Tensor.set_shape&lt;/code&gt;&lt;/a&gt; function may also be used in the &lt;code&gt;body&lt;/code&gt; function to indicate that the output loop variable has a particular shape. The shape invariant for SparseTensor and IndexedSlices are treated specially as follows:</source>
          <target state="translated">为了正确&lt;a href=&quot;../../while_loop&quot;&gt; &lt;code&gt;tf.while_loop()&lt;/code&gt; &lt;/a&gt;，tf.while_loop（）严格为循环变量强制执行形状不变量。形状不变性是（可能是部分的）形状，在循环的迭代过程中没有变化。如果将迭代后的循环变量的形状确定为比其形状不变性更笼统或与其不兼容，则会引发错误。例如，[11，无]的形状比[11，17]的形状更笼统，[11，21]与[11，17]不兼容。默认情况下（如果未指定参数 &lt;code&gt;shape_invariants&lt;/code&gt; ），则假定 &lt;code&gt;loop_vars&lt;/code&gt; 中每个张量的初始形状在每次迭代中均相同。该 &lt;code&gt;shape_invariants&lt;/code&gt; 参数允许调用者为每个循环变量指定不太具体的形状不变性，如果形状在迭代之间变化，则需要此参数。该&lt;a href=&quot;../../tensor#set_shape&quot;&gt; &lt;code&gt;tf.Tensor.set_shape&lt;/code&gt; &lt;/a&gt;功能也可以在所使用的 &lt;code&gt;body&lt;/code&gt; 功能，以指示所述输出循环变量具有特定的形状。对SparseTensor和IndexedSlices的形状不变量进行以下特殊处理：</target>
        </trans-unit>
        <trans-unit id="2d86798b077ac794a34c4729b8903d92155fb358" translate="yes" xml:space="preserve">
          <source>For correctness, &lt;a href=&quot;while_loop&quot;&gt;&lt;code&gt;tf.while_loop()&lt;/code&gt;&lt;/a&gt; strictly enforces shape invariants for the loop variables. A shape invariant is a (possibly partial) shape that is unchanged across the iterations of the loop. An error will be raised if the shape of a loop variable after an iteration is determined to be more general than or incompatible with its shape invariant. For example, a shape of [11, None] is more general than a shape of [11, 17], and [11, 21] is not compatible with [11, 17]. By default (if the argument &lt;code&gt;shape_invariants&lt;/code&gt; is not specified), it is assumed that the initial shape of each tensor in &lt;code&gt;loop_vars&lt;/code&gt; is the same in every iteration. The &lt;code&gt;shape_invariants&lt;/code&gt; argument allows the caller to specify a less specific shape invariant for each loop variable, which is needed if the shape varies between iterations. The &lt;a href=&quot;tensor#set_shape&quot;&gt;&lt;code&gt;tf.Tensor.set_shape&lt;/code&gt;&lt;/a&gt; function may also be used in the &lt;code&gt;body&lt;/code&gt; function to indicate that the output loop variable has a particular shape. The shape invariant for SparseTensor and IndexedSlices are treated specially as follows:</source>
          <target state="translated">为了正确&lt;a href=&quot;while_loop&quot;&gt; &lt;code&gt;tf.while_loop()&lt;/code&gt; &lt;/a&gt;，tf.while_loop（）严格为循环变量强制执行形状不变量。形状不变性是（可能是部分的）形状，在循环的迭代过程中没有变化。如果将迭代后的循环变量的形状确定为比其形状不变性更笼统或与其不兼容，则会引发错误。例如，[11，无]的形状比[11，17]的形状更笼统，[11，21]与[11，17]不兼容。默认情况下（如果未指定参数 &lt;code&gt;shape_invariants&lt;/code&gt; ），则假定 &lt;code&gt;loop_vars&lt;/code&gt; 中每个张量的初始形状在每次迭代中均相同。该 &lt;code&gt;shape_invariants&lt;/code&gt; 参数允许调用者为每个循环变量指定不太具体的形状不变性，如果形状在迭代之间变化，则需要此参数。该&lt;a href=&quot;tensor#set_shape&quot;&gt; &lt;code&gt;tf.Tensor.set_shape&lt;/code&gt; &lt;/a&gt;功能也可以在所使用的 &lt;code&gt;body&lt;/code&gt; 功能，以指示所述输出循环变量具有特定的形状。对SparseTensor和IndexedSlices的形状不变量进行以下特殊处理：</target>
        </trans-unit>
        <trans-unit id="cbc00d3ab4b824f23aa4250f9ca61bea7ee84f1a" translate="yes" xml:space="preserve">
          <source>For dense results in two serialized &lt;code&gt;Example&lt;/code&gt;s:</source>
          <target state="translated">对于两个序列化的 &lt;code&gt;Example&lt;/code&gt; s中的密集结果：</target>
        </trans-unit>
        <trans-unit id="260832edfc6e827a99bc3598303ea1cef15de510" translate="yes" xml:space="preserve">
          <source>For dense tensors, the returned &lt;code&gt;Tensor&lt;/code&gt; is identical to the output of &lt;code&gt;parse_example&lt;/code&gt;, except there is no batch dimension, the output shape is the same as the shape given in &lt;code&gt;dense_shape&lt;/code&gt;.</source>
          <target state="translated">对于密集张量，返回的 &lt;code&gt;Tensor&lt;/code&gt; 与 &lt;code&gt;parse_example&lt;/code&gt; 的输出相同，除了没有批处理维，输出形状与 &lt;code&gt;dense_shape&lt;/code&gt; 给出的形状相同。</target>
        </trans-unit>
        <trans-unit id="4cd4bd6d5ebf6a3540e2292e02f738b12afb9ed8" translate="yes" xml:space="preserve">
          <source>For detailed usage examples of TensorFlow Distributions shapes, see &lt;a href=&quot;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Understanding_TensorFlow_Distributions_Shapes.ipynb&quot;&gt;this tutorial&lt;/a&gt;</source>
          <target state="translated">有关TensorFlow Distributions形状的详细用法示例，请参阅&lt;a href=&quot;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Understanding_TensorFlow_Distributions_Shapes.ipynb&quot;&gt;本教程&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="868bc9411021e63ffd85c6f1e5eb98ca3d3b255f" translate="yes" xml:space="preserve">
          <source>For details on how the graph-level seed interacts with op seeds, see &lt;a href=&quot;set_random_seed&quot;&gt;&lt;code&gt;tf.compat.v1.random.set_random_seed&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">有关图级种子如何与op种子相互作用的详细信息，请参见&lt;a href=&quot;set_random_seed&quot;&gt; &lt;code&gt;tf.compat.v1.random.set_random_seed&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d5b62bcdafb111a4f348589cf96332ab6f0a487b" translate="yes" xml:space="preserve">
          <source>For details on the meaning of each version, see &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto&quot;&gt;&lt;code&gt;GraphDef&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">有关每个版本的含义的详细信息，请参见&lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto&quot;&gt; &lt;code&gt;GraphDef&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c866dd9eacd53156ef05bb3168960ebd7b5e18a3" translate="yes" xml:space="preserve">
          <source>For details, see &lt;a href=&quot;http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot;&gt;Krizhevsky et al., ImageNet classification with deep convolutional neural networks (NIPS 2012)&lt;/a&gt;.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot;&gt;Krizhevsky等人的《具有深度卷积神经网络的ImageNet分类》（NIPS 2012）&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="11f72ea95f4d5434f57a9675d8fca114eb68909d" translate="yes" xml:space="preserve">
          <source>For each 3-D image &lt;code&gt;x&lt;/code&gt; in &lt;code&gt;image&lt;/code&gt;, computes &lt;code&gt;(x - mean) / adjusted_stddev&lt;/code&gt;, where</source>
          <target state="translated">对于每个3-d的图像 &lt;code&gt;x&lt;/code&gt; 中 &lt;code&gt;image&lt;/code&gt; ，单位计算 &lt;code&gt;(x - mean) / adjusted_stddev&lt;/code&gt; ，其中</target>
        </trans-unit>
        <trans-unit id="3227496e32cef4b95ac21bbcfb379b6c8563c22f" translate="yes" xml:space="preserve">
          <source>For each batch &lt;code&gt;i&lt;/code&gt; and class &lt;code&gt;j&lt;/code&gt; we have</source>
          <target state="translated">对于每批 &lt;code&gt;i&lt;/code&gt; 和 &lt;code&gt;j&lt;/code&gt; 类，我们都有</target>
        </trans-unit>
        <trans-unit id="38ee7d6b0b564eb41b147c9865f0b162072dea3f" translate="yes" xml:space="preserve">
          <source>For each batch of counts, &lt;code&gt;value = [n_0, ... ,n_{k-1}]&lt;/code&gt;, &lt;code&gt;P[value]&lt;/code&gt; is the probability that after sampling &lt;code&gt;self.total_count&lt;/code&gt; draws from this Multinomial distribution, the number of draws falling in class &lt;code&gt;j&lt;/code&gt; is &lt;code&gt;n_j&lt;/code&gt;. Since this definition is &lt;a href=&quot;https://en.wikipedia.org/wiki/Exchangeable_random_variables&quot;&gt;exchangeable&lt;/a&gt;; different sequences have the same counts so the probability includes a combinatorial coefficient.</source>
          <target state="translated">对于每一批计数， &lt;code&gt;value = [n_0, ... ,n_{k-1}]&lt;/code&gt; ， &lt;code&gt;P[value]&lt;/code&gt; 是从此多项式分布中对 &lt;code&gt;self.total_count&lt;/code&gt; 抽奖进行采样后，属于 &lt;code&gt;j&lt;/code&gt; 类的抽奖次数的概率是 &lt;code&gt;n_j&lt;/code&gt; 。由于该定义是&lt;a href=&quot;https://en.wikipedia.org/wiki/Exchangeable_random_variables&quot;&gt;可交换的&lt;/a&gt;；不同的序列具有相同的计数，因此概率包括组合系数。</target>
        </trans-unit>
        <trans-unit id="62e6f600d1795850660493678c7d313f17bb03f6" translate="yes" xml:space="preserve">
          <source>For each batch of counts, &lt;code&gt;value = [n_0, ..., n_{K-1}]&lt;/code&gt;, &lt;code&gt;P[value]&lt;/code&gt; is the probability that after sampling &lt;code&gt;self.total_count&lt;/code&gt; draws from this Dirichlet-Multinomial distribution, the number of draws falling in class &lt;code&gt;j&lt;/code&gt; is &lt;code&gt;n_j&lt;/code&gt;. Since this definition is &lt;a href=&quot;https://en.wikipedia.org/wiki/Exchangeable_random_variables&quot;&gt;exchangeable&lt;/a&gt;; different sequences have the same counts so the probability includes a combinatorial coefficient.</source>
          <target state="translated">对于每一批计数， &lt;code&gt;value = [n_0, ..., n_{K-1}]&lt;/code&gt; ， &lt;code&gt;P[value]&lt;/code&gt; 是在从Dirichlet-多项式分布中对 &lt;code&gt;self.total_count&lt;/code&gt; 抽奖进行采样后，抽奖次数落入的概率类 &lt;code&gt;j&lt;/code&gt; 是 &lt;code&gt;n_j&lt;/code&gt; 。由于该定义是&lt;a href=&quot;https://en.wikipedia.org/wiki/Exchangeable_random_variables&quot;&gt;可交换的&lt;/a&gt;；不同的序列具有相同的计数，因此概率包括组合系数。</target>
        </trans-unit>
        <trans-unit id="bb818b9007e09539540e92f84325c27b3ee59e8b" translate="yes" xml:space="preserve">
          <source>For each batch, this op picks a single set of sampled candidate labels.</source>
          <target state="translated">对于每一个批次,这个操作挑选出一组单一的采样候选标签。</target>
        </trans-unit>
        <trans-unit id="cd53ff76cccc96ec695fa6a623c56b5fe4ad9802" translate="yes" xml:space="preserve">
          <source>For each channel, the Op first computes the mean of the image pixels in the channel and then adjusts each component of each pixel to &lt;code&gt;(x - mean) * contrast_factor + mean&lt;/code&gt;.</source>
          <target state="translated">对于每个通道，Op首先计算通道中图像像素的均值，然后将每个像素的每个分量调整为 &lt;code&gt;(x - mean) * contrast_factor + mean&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b564f7dfac5634b944029ff0a934eb0322773539" translate="yes" xml:space="preserve">
          <source>For each channel, this Op computes the mean of the image pixels in the channel and then adjusts each component &lt;code&gt;x&lt;/code&gt; of each pixel to &lt;code&gt;(x - mean) * contrast_factor + mean&lt;/code&gt;.</source>
          <target state="translated">对于每个通道，此Op计算通道中图像像素的均值，然后将每个像素的每个分量 &lt;code&gt;x&lt;/code&gt; 调整为 &lt;code&gt;(x - mean) * contrast_factor + mean&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ff2fe1b034bb2ad174dd976537594c894cf480ba" translate="yes" xml:space="preserve">
          <source>For each channel, this layer computes the mean of the image pixels in the channel and then adjusts each component &lt;code&gt;x&lt;/code&gt; of each pixel to &lt;code&gt;(x - mean) * contrast_factor + mean&lt;/code&gt;.</source>
          <target state="translated">对于每个通道，此层计算通道中图像像素的均值，然后将每个像素的每个分量 &lt;code&gt;x&lt;/code&gt; 调整为 &lt;code&gt;(x - mean) * contrast_factor + mean&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e51add3cb58cbf81d2d2183dae647c67c4f8839c" translate="yes" xml:space="preserve">
          <source>For each element of &lt;code&gt;x&lt;/code&gt;, with probability &lt;code&gt;rate&lt;/code&gt;, outputs &lt;code&gt;0&lt;/code&gt;, and otherwise scales up the input by &lt;code&gt;1 / (1-rate)&lt;/code&gt;. The scaling is such that the expected sum is unchanged.</source>
          <target state="translated">对于的每个元素 &lt;code&gt;x&lt;/code&gt; ，以概率 &lt;code&gt;rate&lt;/code&gt; ，输出 &lt;code&gt;0&lt;/code&gt; ，并且以其他方式扩展了输入 &lt;code&gt;1 / (1-rate)&lt;/code&gt; 。缩放比例使得期望的总和不变。</target>
        </trans-unit>
        <trans-unit id="86602bb631fb5fb59349ca0b2955fe851ca22911" translate="yes" xml:space="preserve">
          <source>For each entry in &lt;code&gt;x&lt;/code&gt;, calculates the number of &lt;code&gt;1&lt;/code&gt; (on) bits in the binary representation of that entry.</source>
          <target state="translated">对于 &lt;code&gt;x&lt;/code&gt; 中的每个条目，计算该条目的二进制表示形式中 &lt;code&gt;1&lt;/code&gt; （在）位的数量。</target>
        </trans-unit>
        <trans-unit id="28ab9495d8c09b2b7b1ceee1fc8792b4dada3fe0" translate="yes" xml:space="preserve">
          <source>For each index tuple &lt;code&gt;js&lt;/code&gt; of size &lt;code&gt;partitions.ndim&lt;/code&gt;, the slice &lt;code&gt;data[js, ...]&lt;/code&gt; becomes part of &lt;code&gt;outputs[partitions[js]]&lt;/code&gt;. The slices with &lt;code&gt;partitions[js] = i&lt;/code&gt; are placed in &lt;code&gt;outputs[i]&lt;/code&gt; in lexicographic order of &lt;code&gt;js&lt;/code&gt;, and the first dimension of &lt;code&gt;outputs[i]&lt;/code&gt; is the number of entries in &lt;code&gt;partitions&lt;/code&gt; equal to &lt;code&gt;i&lt;/code&gt;. In detail,</source>
          <target state="translated">对于大小为 &lt;code&gt;partitions.ndim&lt;/code&gt; 的每个索引元组 &lt;code&gt;js&lt;/code&gt; ，切片 &lt;code&gt;data[js, ...]&lt;/code&gt; 成为 &lt;code&gt;outputs[partitions[js]]&lt;/code&gt; 。与切片 &lt;code&gt;partitions[js] = i&lt;/code&gt; 被放置在 &lt;code&gt;outputs[i]&lt;/code&gt; 中的字典顺序 &lt;code&gt;js&lt;/code&gt; ，并且所述第一维度 &lt;code&gt;outputs[i]&lt;/code&gt; 是条目的数量 &lt;code&gt;partitions&lt;/code&gt; 等于 &lt;code&gt;i&lt;/code&gt; 。详细地，</target>
        </trans-unit>
        <trans-unit id="8f890fa1a354ef3fc8ec0c534b58bd8321503214" translate="yes" xml:space="preserve">
          <source>For each input submatrix of shape &lt;code&gt;[M, M]&lt;/code&gt;, L is a lower triangular matrix of shape &lt;code&gt;[M, M]&lt;/code&gt; with unit diagonal whose entries correspond to the strictly lower triangular part of LU. U is a upper triangular matrix of shape &lt;code&gt;[M, M]&lt;/code&gt; whose entries correspond to the upper triangular part, including the diagonal, of LU.</source>
          <target state="translated">对于形状的每个子矩阵的输入 &lt;code&gt;[M, M]&lt;/code&gt; ，L是形状的下三角矩阵 &lt;code&gt;[M, M]&lt;/code&gt; 与单元对角线其条目对应于LU的严格下三角部分。 U是形状为 &lt;code&gt;[M, M]&lt;/code&gt; 的上三角矩阵，其入口对应于LU的上三角部分，包括对角线。</target>
        </trans-unit>
        <trans-unit id="c00b7a881865ff1e4e2196d95bae3abcdc4cd784" translate="yes" xml:space="preserve">
          <source>For each job, if the task index space is dense, the corresponding value will be a list of network addresses; otherwise it will be a dictionary mapping (sparse) task indices to the corresponding addresses.</source>
          <target state="translated">对于每一个任务,如果任务索引空间很密集,对应的值将是一个网络地址列表;否则将是一个字典,将(稀疏的)任务索引映射到对应的地址。</target>
        </trans-unit>
        <trans-unit id="aea6c2ab4366a16a529a52527d4b03de1704be35" translate="yes" xml:space="preserve">
          <source>For each key, assigns the respective value to the specified component.</source>
          <target state="translated">对于每个键,将各自的值分配给指定的组件。</target>
        </trans-unit>
        <trans-unit id="487d8b92f2cc03f24f4ba27c6c59fe187e5d7046" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;../../../../estimator/modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../../estimator/modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;../../../../estimator/modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="translated">对于通过 &lt;code&gt;input_receiver_fn_map&lt;/code&gt; 传递的每种模式，此方法都通过调用 &lt;code&gt;input_receiver_fn&lt;/code&gt; 获取特征并标记 &lt;code&gt;Tensor&lt;/code&gt; 来构建新图。接下来，此方法在传递模式下调用 &lt;code&gt;Estimator&lt;/code&gt; 的 &lt;code&gt;model_fn&lt;/code&gt; 以基于这些功能和标签生成模型图，并将给定的检查点（或者缺少该检查点）还原到图中。只有一种模式用于将变量保存到 &lt;code&gt;SavedModel&lt;/code&gt; （优先顺序：&lt;a href=&quot;../../../../estimator/modekeys#TRAIN&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;../../../../estimator/modekeys#EVAL&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt; &lt;/a&gt;，然后是&lt;a href=&quot;../../../../estimator/modekeys#PREDICT&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt; &lt;/a&gt;），这样最多三个 &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; 与一组变量一起保存在单个 &lt;code&gt;SavedModel&lt;/code&gt; 目录中。</target>
        </trans-unit>
        <trans-unit id="894633909e50b7d3307fbbac8ff5cae1f413ff86" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;../../../estimator/modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../estimator/modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;../../../estimator/modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="translated">对于通过 &lt;code&gt;input_receiver_fn_map&lt;/code&gt; 传递的每种模式，此方法都通过调用 &lt;code&gt;input_receiver_fn&lt;/code&gt; 获取特征并标记 &lt;code&gt;Tensor&lt;/code&gt; 来构建新图。接下来，此方法在传递模式下调用 &lt;code&gt;Estimator&lt;/code&gt; 的 &lt;code&gt;model_fn&lt;/code&gt; 以基于这些功能和标签生成模型图，并将给定的检查点（或者缺少该检查点）还原到图中。只有一种模式用于将变量保存到 &lt;code&gt;SavedModel&lt;/code&gt; （优先顺序：&lt;a href=&quot;../../../estimator/modekeys#TRAIN&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;../../../estimator/modekeys#EVAL&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt; &lt;/a&gt;，然后是&lt;a href=&quot;../../../estimator/modekeys#PREDICT&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt; &lt;/a&gt;），这样最多三个 &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; 与一组变量一起保存在单个 &lt;code&gt;SavedModel&lt;/code&gt; 目录中。</target>
        </trans-unit>
        <trans-unit id="84ad1b7c0e6d676b66b6c0000beb81f60843b517" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;../modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;../modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="translated">对于通过 &lt;code&gt;input_receiver_fn_map&lt;/code&gt; 传递的每种模式，此方法都通过调用 &lt;code&gt;input_receiver_fn&lt;/code&gt; 获取特征并标记 &lt;code&gt;Tensor&lt;/code&gt; 来构建新图。接下来，此方法在传递模式下调用 &lt;code&gt;Estimator&lt;/code&gt; 的 &lt;code&gt;model_fn&lt;/code&gt; 以基于这些功能和标签生成模型图，并将给定的检查点（或者缺少该检查点）还原到图中。只有一种模式用于将变量保存到 &lt;code&gt;SavedModel&lt;/code&gt; （优先顺序：&lt;a href=&quot;../modekeys#TRAIN&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;../modekeys#EVAL&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt; &lt;/a&gt;，然后是&lt;a href=&quot;../modekeys#PREDICT&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt; &lt;/a&gt;），这样最多三个 &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; 与一组变量一起保存在单个 &lt;code&gt;SavedModel&lt;/code&gt; 目录中。</target>
        </trans-unit>
        <trans-unit id="b412fda993e08f3c91f400db4d8146e4d0f5bc5f" translate="yes" xml:space="preserve">
          <source>For each mode passed in via the &lt;code&gt;input_receiver_fn_map&lt;/code&gt;, this method builds a new graph by calling the &lt;code&gt;input_receiver_fn&lt;/code&gt; to obtain feature and label &lt;code&gt;Tensor&lt;/code&gt;s. Next, this method calls the &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; in the passed mode to generate the model graph based on those features and labels, and restores the given checkpoint (or, lacking that, the most recent checkpoint) into the graph. Only one of the modes is used for saving variables to the &lt;code&gt;SavedModel&lt;/code&gt; (order of preference: &lt;a href=&quot;modekeys#TRAIN&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;modekeys#EVAL&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt;&lt;/a&gt;, then &lt;a href=&quot;modekeys#PREDICT&quot;&gt;&lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt;&lt;/a&gt;), such that up to three &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; are saved with a single set of variables in a single &lt;code&gt;SavedModel&lt;/code&gt; directory.</source>
          <target state="translated">对于通过 &lt;code&gt;input_receiver_fn_map&lt;/code&gt; 传递的每种模式，此方法都通过调用 &lt;code&gt;input_receiver_fn&lt;/code&gt; 获取特征并标记 &lt;code&gt;Tensor&lt;/code&gt; 来构建新图。接下来，此方法在传递模式下调用 &lt;code&gt;Estimator&lt;/code&gt; 的 &lt;code&gt;model_fn&lt;/code&gt; 以基于这些功能和标签生成模型图，并将给定的检查点（或者缺少该检查点）还原到图中。只有一种模式用于将变量保存到 &lt;code&gt;SavedModel&lt;/code&gt; （优先顺序：&lt;a href=&quot;modekeys#TRAIN&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.TRAIN&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;modekeys#EVAL&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.EVAL&lt;/code&gt; &lt;/a&gt;，然后是&lt;a href=&quot;modekeys#PREDICT&quot;&gt; &lt;code&gt;tf.estimator.ModeKeys.PREDICT&lt;/code&gt; &lt;/a&gt;），这样最多三个 &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; 与一组变量一起保存在单个 &lt;code&gt;SavedModel&lt;/code&gt; 目录中。</target>
        </trans-unit>
        <trans-unit id="36b982fc21506a7f2190761f16a3f5fcc9ede9c0" translate="yes" xml:space="preserve">
          <source>For each patch, right-multiplies the filter matrix and the image patch vector.</source>
          <target state="translated">对于每个补丁,右乘滤波器矩阵和图像补丁向量。</target>
        </trans-unit>
        <trans-unit id="495118d7bdd44315c26aae5e3bf24f66dcd99d0d" translate="yes" xml:space="preserve">
          <source>For each point that is sampled during kmeans++ initialization, this parameter specifies the number of additional points to draw from the current distribution before selecting the best. If a negative value is specified, a heuristic is used to sample &lt;code&gt;O(log(num_to_sample))&lt;/code&gt; additional points. Used only if &lt;code&gt;initial_clusters=KMeansClustering.KMEANS_PLUS_PLUS_INIT&lt;/code&gt;.</source>
          <target state="translated">对于在kmeans ++初始化期间采样的每个点，此参数指定在选择最佳点之前从当前分布中提取的其他点数。如果指定了负值，则使用启发式方法对 &lt;code&gt;O(log(num_to_sample))&lt;/code&gt; 个附加点进行采样。仅在 &lt;code&gt;initial_clusters=KMeansClustering.KMEANS_PLUS_PLUS_INIT&lt;/code&gt; 时使用。</target>
        </trans-unit>
        <trans-unit id="840e6ba53f4417ca11f6403319bc3e83421092e5" translate="yes" xml:space="preserve">
          <source>For each sample &lt;code&gt;x_i&lt;/code&gt; in &lt;code&gt;inputs&lt;/code&gt; with &lt;code&gt;k&lt;/code&gt; features, we compute the mean and variance of the sample:</source>
          <target state="translated">对于每个样品 &lt;code&gt;x_i&lt;/code&gt; 在 &lt;code&gt;inputs&lt;/code&gt; 与 &lt;code&gt;k&lt;/code&gt; 特征，我们计算的平均值和样品的方差：</target>
        </trans-unit>
        <trans-unit id="1c15a30d01baef30188c69bc7ff85b21e3e935e7" translate="yes" xml:space="preserve">
          <source>For each step, calls &lt;code&gt;input_fn&lt;/code&gt;, which returns one batch of data. Evaluates until:</source>
          <target state="translated">对于每个步骤，都调用 &lt;code&gt;input_fn&lt;/code&gt; ，它返回一批数据。评估直到：</target>
        </trans-unit>
        <trans-unit id="76eabb6e369edfcf348e56ad957e852ddec0f36e" translate="yes" xml:space="preserve">
          <source>For each string in the input &lt;code&gt;Tensor&lt;/code&gt;, creates a substring starting at index &lt;code&gt;pos&lt;/code&gt; with a total length of &lt;code&gt;len&lt;/code&gt;.</source>
          <target state="translated">对于输入 &lt;code&gt;Tensor&lt;/code&gt; 中的每个字符串，创建一个从索引 &lt;code&gt;pos&lt;/code&gt; 开始，总长度为 &lt;code&gt;len&lt;/code&gt; 的子字符串。</target>
        </trans-unit>
        <trans-unit id="ad124c85b4e4ed2992f3d2d7226cc6682efb0d10" translate="yes" xml:space="preserve">
          <source>For each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to &lt;code&gt;mask_value&lt;/code&gt;, then the timestep will be masked (skipped) in all downstream layers (as long as they support masking).</source>
          <target state="translated">对于输入张量中的每个时间步长（张量中的维数1），如果该时间步长上输入张量中的所有值都等于 &lt;code&gt;mask_value&lt;/code&gt; ，则该时间步长将在所有下游层中被屏蔽（跳过）（只要它们支持）掩蔽）。</target>
        </trans-unit>
        <trans-unit id="2370b2414271135ef1678cb23ef39f45a5fc2cb3" translate="yes" xml:space="preserve">
          <source>For each value x in &lt;code&gt;error = y_true - y_pred&lt;/code&gt;:</source>
          <target state="translated">对于每个 &lt;code&gt;error = y_true - y_pred&lt;/code&gt; 值x = y_true-y_pred：</target>
        </trans-unit>
        <trans-unit id="b30a7e920276e3b902f956f91fd308b9a443509f" translate="yes" xml:space="preserve">
          <source>For each value x in &lt;code&gt;error=labels-predictions&lt;/code&gt;, the following is calculated:</source>
          <target state="translated">对于 &lt;code&gt;error=labels-predictions&lt;/code&gt; 中的每个值x ，将计算以下内容：</target>
        </trans-unit>
        <trans-unit id="0e81aa8da6e2ca9d6903d446870611925fa37da7" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates the accuracy of each class and returns them.</source>
          <target state="translated">为了估计数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新每个类的准确性并返回它们。</target>
        </trans-unit>
        <trans-unit id="bbcc260a82187cfff98a34fb724a50f62fa1bb51" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;accuracy&lt;/code&gt;. Internally, an &lt;code&gt;is_correct&lt;/code&gt; operation computes a &lt;code&gt;Tensor&lt;/code&gt; with elements 1.0 where the corresponding elements of &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; match and 0.0 otherwise. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;is_correct&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="translated">对于以上的数据流度量的估计，该函数创建一个 &lt;code&gt;update_op&lt;/code&gt; ，更新这些变量和返回操作 &lt;code&gt;accuracy&lt;/code&gt; 。在内部， &lt;code&gt;is_correct&lt;/code&gt; 操作将使用元素1.0 计算 &lt;code&gt;Tensor&lt;/code&gt; ，其中 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 的相应元素匹配，否则为0.0。然后 &lt;code&gt;update_op&lt;/code&gt; 增量 &lt;code&gt;total&lt;/code&gt; 用的产品的降低的总和 &lt;code&gt;weights&lt;/code&gt; 和 &lt;code&gt;is_correct&lt;/code&gt; ，并且它的增量 &lt;code&gt;count&lt;/code&gt; 与的总和减小的 &lt;code&gt;weights&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="dad08a503e11b5156a4a3427dfc7515950a48e4f" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;auc&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;auc&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6e6ad6df8adaafa9f6c503da039855e65bd9b58e" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;weights&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;mean&lt;/code&gt; 。 &lt;code&gt;update_op&lt;/code&gt; 增量 &lt;code&gt;total&lt;/code&gt; 用的产品的降低的总和 &lt;code&gt;values&lt;/code&gt; 和 &lt;code&gt;weights&lt;/code&gt; ，并将其增量 &lt;code&gt;count&lt;/code&gt; 与的总和减小的 &lt;code&gt;weights&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d4ab931d2efc0e42b3a757d047bf7f98096c2b78" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_absolute_error&lt;/code&gt;. Internally, an &lt;code&gt;absolute_errors&lt;/code&gt; operation computes the absolute value of the differences between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;absolute_errors&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作将更新这些变量并返回 &lt;code&gt;mean_absolute_error&lt;/code&gt; 。在内部， &lt;code&gt;absolute_errors&lt;/code&gt; 运算会计算 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 之间差异的绝对值。然后 &lt;code&gt;update_op&lt;/code&gt; 增量 &lt;code&gt;total&lt;/code&gt; 用的产品的降低的总和 &lt;code&gt;weights&lt;/code&gt; 和 &lt;code&gt;absolute_errors&lt;/code&gt; ，并且它的增量 &lt;code&gt;count&lt;/code&gt; 与的总和减小的 &lt;code&gt;weights&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="614a1783a568ced9d248f52d9352d35b40792a7a" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_distance&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;mean_distance&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b7bdad2b2535c192103954072920dd86f8d7f97e" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_iou&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;mean_iou&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="21a28b15071e2e3057222499cce4c758670a6204" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_reative_error&lt;/code&gt;. Internally, a &lt;code&gt;relative_errors&lt;/code&gt; operation divides the absolute value of the differences between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; by the &lt;code&gt;normalizer&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;relative_errors&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;mean_reative_error&lt;/code&gt; 。在内部， &lt;code&gt;relative_errors&lt;/code&gt; 操作划分的之间的差的绝对值 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 由 &lt;code&gt;normalizer&lt;/code&gt; 。然后 &lt;code&gt;update_op&lt;/code&gt; 增量 &lt;code&gt;total&lt;/code&gt; 用的产品的降低的总和 &lt;code&gt;weights&lt;/code&gt; 和 &lt;code&gt;relative_errors&lt;/code&gt; ，并且它的增量 &lt;code&gt;count&lt;/code&gt; 与的总和减小的 &lt;code&gt;weights&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2622e71a2a20b6c576fe07f66c3861f4ae1d6554" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;mean_squared_error&lt;/code&gt;. Internally, a &lt;code&gt;squared_error&lt;/code&gt; operation computes the element-wise square of the difference between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;squared_error&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;mean_squared_error&lt;/code&gt; 。在内部， &lt;code&gt;squared_error&lt;/code&gt; 运算会计算 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 之间的差异的逐元素平方。然后 &lt;code&gt;update_op&lt;/code&gt; 增量 &lt;code&gt;total&lt;/code&gt; 用的产品的降低的总和 &lt;code&gt;weights&lt;/code&gt; 和 &lt;code&gt;squared_error&lt;/code&gt; ，并且它的增量 &lt;code&gt;count&lt;/code&gt; 与的总和减小的 &lt;code&gt;weights&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="482044def86d900d6f880303c2541fe53cd45fe2" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;percentage&lt;/code&gt;.</source>
          <target state="translated">对于以上的数据流度量的估计，该函数创建一个 &lt;code&gt;update_op&lt;/code&gt; ，更新这些变量和返回操作 &lt;code&gt;percentage&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="11887ce5609f24f245ab19a0dae14981801f1e03" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;precision&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;precision&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2073b65f678bcea68507c8aced29c54089672a4c" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;precision&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; weights each prediction by the corresponding value in &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;precision&lt;/code&gt; 。 &lt;code&gt;update_op&lt;/code&gt; 通过权重中的相应值对每个预测 &lt;code&gt;weights&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5fa9d8aac2d1f3e8b41e5f969b7c9069f2763710" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;precision_at_&amp;lt;k&amp;gt;&lt;/code&gt;. Internally, a &lt;code&gt;top_k&lt;/code&gt; operation computes a &lt;code&gt;Tensor&lt;/code&gt; indicating the top &lt;code&gt;k&lt;/code&gt;&lt;code&gt;predictions&lt;/code&gt;. Set operations applied to &lt;code&gt;top_k&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; calculate the true positives and false positives weighted by &lt;code&gt;weights&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;true_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; and &lt;code&gt;false_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; using these values.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;precision_at_&amp;lt;k&amp;gt;&lt;/code&gt; 。在内部， &lt;code&gt;top_k&lt;/code&gt; 运算会计算一个表示前 &lt;code&gt;k&lt;/code&gt; 个 &lt;code&gt;predictions&lt;/code&gt; 的 &lt;code&gt;Tensor&lt;/code&gt; 。应用于 &lt;code&gt;top_k&lt;/code&gt; 的设置操作和 &lt;code&gt;labels&lt;/code&gt; 计算按 &lt;code&gt;weights&lt;/code&gt; 加权的真实肯定和错误肯定。然后， &lt;code&gt;update_op&lt;/code&gt; 使用这些值使 &lt;code&gt;true_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; 和 &lt;code&gt;false_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; 递增。</target>
        </trans-unit>
        <trans-unit id="1d641bbb0bd1f36939980470649afd513c5fe109" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;recall&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流中的指标，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;recall&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9e926696bf238fa1af7b7fd153c6b149672d0579" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;recall_at_&amp;lt;k&amp;gt;&lt;/code&gt;. Internally, a &lt;code&gt;top_k&lt;/code&gt; operation computes a &lt;code&gt;Tensor&lt;/code&gt; indicating the top &lt;code&gt;k&lt;/code&gt;&lt;code&gt;predictions&lt;/code&gt;. Set operations applied to &lt;code&gt;top_k&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; calculate the true positives and false negatives weighted by &lt;code&gt;weights&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;true_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; and &lt;code&gt;false_negative_at_&amp;lt;k&amp;gt;&lt;/code&gt; using these values.</source>
          <target state="translated">为了估计数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;recall_at_&amp;lt;k&amp;gt;&lt;/code&gt; 。在内部， &lt;code&gt;top_k&lt;/code&gt; 运算会计算一个表示前 &lt;code&gt;k&lt;/code&gt; 个 &lt;code&gt;predictions&lt;/code&gt; 的 &lt;code&gt;Tensor&lt;/code&gt; 。应用于 &lt;code&gt;top_k&lt;/code&gt; 的设置操作和 &lt;code&gt;labels&lt;/code&gt; 计算按 &lt;code&gt;weights&lt;/code&gt; 加权的正负数。然后， &lt;code&gt;update_op&lt;/code&gt; 使用这些值使 &lt;code&gt;true_positive_at_&amp;lt;k&amp;gt;&lt;/code&gt; 和 &lt;code&gt;false_negative_at_&amp;lt;k&amp;gt;&lt;/code&gt; 递增。</target>
        </trans-unit>
        <trans-unit id="e592409ad4457c95b12184bde9fb30acffe72920" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;root_mean_squared_error&lt;/code&gt;. Internally, a &lt;code&gt;squared_error&lt;/code&gt; operation computes the element-wise square of the difference between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. Then &lt;code&gt;update_op&lt;/code&gt; increments &lt;code&gt;total&lt;/code&gt; with the reduced sum of the product of &lt;code&gt;weights&lt;/code&gt; and &lt;code&gt;squared_error&lt;/code&gt;, and it increments &lt;code&gt;count&lt;/code&gt; with the reduced sum of &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;root_mean_squared_error&lt;/code&gt; 。在内部， &lt;code&gt;squared_error&lt;/code&gt; 运算会计算 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 之间的差异的逐元素平方。然后 &lt;code&gt;update_op&lt;/code&gt; 增量 &lt;code&gt;total&lt;/code&gt; 用的产品的降低的总和 &lt;code&gt;weights&lt;/code&gt; 和 &lt;code&gt;squared_error&lt;/code&gt; ，并且它的增量 &lt;code&gt;count&lt;/code&gt; 与的总和减小的 &lt;code&gt;weights&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8a7f0bed98595b5568f1d9ffe04c5cc4a5ca7387" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;sensitivity&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; increments the &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; counts with the weight of each case found in the &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;sensitivity&lt;/code&gt; 。 &lt;code&gt;update_op&lt;/code&gt; 使用在 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 找到的每种情况的权重来递增 &lt;code&gt;true_positives&lt;/code&gt; ， &lt;code&gt;true_negatives&lt;/code&gt; ， &lt;code&gt;false_positives&lt;/code&gt; 和 &lt;code&gt;false_negatives&lt;/code&gt; 计数。</target>
        </trans-unit>
        <trans-unit id="b07e75d0103c0e548428284e5efc113eab68537b" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; operation that updates these variables and returns the &lt;code&gt;specificity&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; increments the &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; counts with the weight of each case found in the &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; 操作，该操作更新这些变量并返回 &lt;code&gt;specificity&lt;/code&gt; 。 &lt;code&gt;update_op&lt;/code&gt; 使用在 &lt;code&gt;predictions&lt;/code&gt; 和 &lt;code&gt;labels&lt;/code&gt; 找到的每种情况的权重来递增 &lt;code&gt;true_positives&lt;/code&gt; ， &lt;code&gt;true_negatives&lt;/code&gt; ， &lt;code&gt;false_positives&lt;/code&gt; 和 &lt;code&gt;false_negatives&lt;/code&gt; 计数。</target>
        </trans-unit>
        <trans-unit id="84f3ab8b259e10c767171cb16e1ed0bedcdf7bd6" translate="yes" xml:space="preserve">
          <source>For estimation of the metric over a stream of data, the function creates an &lt;code&gt;update_op&lt;/code&gt; that updates these variables and returns the &lt;code&gt;recall&lt;/code&gt;. &lt;code&gt;update_op&lt;/code&gt; weights each prediction by the corresponding value in &lt;code&gt;weights&lt;/code&gt;.</source>
          <target state="translated">为了估算数据流上的度量，该函数创建了一个 &lt;code&gt;update_op&lt;/code&gt; ，该update_op更新这些变量并返回 &lt;code&gt;recall&lt;/code&gt; 。 &lt;code&gt;update_op&lt;/code&gt; 通过权重中的相应值对每个预测 &lt;code&gt;weights&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="16fe84732ca0277f0c85a01f97b90cbe49eed312" translate="yes" xml:space="preserve">
          <source>For eval, merges metrics by adding &lt;code&gt;head.name&lt;/code&gt; suffix to the keys in eval metrics, such as &lt;code&gt;precision/head1.name&lt;/code&gt;, &lt;code&gt;precision/head2.name&lt;/code&gt;.</source>
          <target state="translated">对于eval，通过将 &lt;code&gt;head.name&lt;/code&gt; 后缀添加到eval指标中的键来合并指标，例如 &lt;code&gt;precision/head1.name&lt;/code&gt; ， &lt;code&gt;precision/head2.name&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="096f439eadd884160cca18be357dd236e0d9b954" translate="yes" xml:space="preserve">
          <source>For evaluation and prediction, &lt;code&gt;model_fn&lt;/code&gt; gets per-core batch size and &lt;code&gt;input_fn&lt;/code&gt; get per-host batch size.</source>
          <target state="translated">为了进行评估和预测， &lt;code&gt;model_fn&lt;/code&gt; 获取每个内核的批处理大小， &lt;code&gt;input_fn&lt;/code&gt; 获取每个主机的批处理大小。</target>
        </trans-unit>
        <trans-unit id="9aaddffdb76b42aacd2bb37b2bc66b758d2d660a" translate="yes" xml:space="preserve">
          <source>For evaluation, &lt;code&gt;eval_metrics&lt;/code&gt;is a tuple of &lt;code&gt;metric_fn&lt;/code&gt; and &lt;code&gt;tensors&lt;/code&gt;, where &lt;code&gt;metric_fn&lt;/code&gt; runs on CPU to generate metrics and &lt;code&gt;tensors&lt;/code&gt; represents the &lt;code&gt;Tensor&lt;/code&gt;s transferred from TPU system to CPU host and passed to &lt;code&gt;metric_fn&lt;/code&gt;. To be precise, TPU evaluation expects a slightly different signature from the &lt;a href=&quot;../../../../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt;. While &lt;a href=&quot;../../../../estimator/estimatorspec#eval_metric_ops&quot;&gt;&lt;code&gt;EstimatorSpec.eval_metric_ops&lt;/code&gt;&lt;/a&gt; expects a dict, &lt;code&gt;TPUEstimatorSpec.eval_metrics&lt;/code&gt; is a tuple of &lt;code&gt;metric_fn&lt;/code&gt; and &lt;code&gt;tensors&lt;/code&gt;. The &lt;code&gt;tensors&lt;/code&gt; could be a list of &lt;code&gt;Tensor&lt;/code&gt;s or dict of names to &lt;code&gt;Tensor&lt;/code&gt;s. The &lt;code&gt;tensors&lt;/code&gt; usually specify the model logits, which are transferred back from TPU system to CPU host. All tensors must have be batch-major, i.e., the batch size is the first dimension. Once all tensors are available at CPU host from all shards, they are concatenated (on CPU) and passed as positional arguments to the &lt;code&gt;metric_fn&lt;/code&gt; if &lt;code&gt;tensors&lt;/code&gt; is list or keyword arguments if &lt;code&gt;tensors&lt;/code&gt; is a dict. &lt;code&gt;metric_fn&lt;/code&gt; takes the &lt;code&gt;tensors&lt;/code&gt; and returns a dict from metric string name to the result of calling a metric function, namely a &lt;code&gt;(metric_tensor, update_op)&lt;/code&gt; tuple. See &lt;code&gt;TPUEstimator&lt;/code&gt; for MNIST example how to specify the &lt;code&gt;eval_metrics&lt;/code&gt;.</source>
          <target state="translated">为了评价， &lt;code&gt;eval_metrics&lt;/code&gt; 是元组 &lt;code&gt;metric_fn&lt;/code&gt; 和 &lt;code&gt;tensors&lt;/code&gt; ，其中 &lt;code&gt;metric_fn&lt;/code&gt; 上CPU运行以生成度量和 &lt;code&gt;tensors&lt;/code&gt; 表示 &lt;code&gt;Tensor&lt;/code&gt; 期从TPU系统到CPU主机传送并传递给 &lt;code&gt;metric_fn&lt;/code&gt; 。确切地说，TPU评估期望的签名与&lt;a href=&quot;../../../../estimator/estimator&quot;&gt; &lt;code&gt;tf.estimator.Estimator&lt;/code&gt; &lt;/a&gt;略有不同。虽然&lt;a href=&quot;../../../../estimator/estimatorspec#eval_metric_ops&quot;&gt; &lt;code&gt;EstimatorSpec.eval_metric_ops&lt;/code&gt; &lt;/a&gt;需要一个dict， &lt;code&gt;TPUEstimatorSpec.eval_metrics&lt;/code&gt; 是 &lt;code&gt;metric_fn&lt;/code&gt; 和 &lt;code&gt;tensors&lt;/code&gt; 的元组。该 &lt;code&gt;tensors&lt;/code&gt; 可能是一个列表 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;Tensor&lt;/code&gt; 的名称字典。的 &lt;code&gt;tensors&lt;/code&gt; 通常指定模型logits，这是从系统TPU传输回CPU主机。所有张量都必须是批量张量，即，批量大小是第一维。一旦所有分片在所有主机上都在CPU主机上可用后，它们就会被串联（在CPU上）并作为位置参数（如果 &lt;code&gt;tensors&lt;/code&gt; 是列表，则作为参数传递给 &lt;code&gt;metric_fn&lt;/code&gt; 或如果 &lt;code&gt;tensors&lt;/code&gt; 是dict 则传递给关键字参数）。 &lt;code&gt;metric_fn&lt;/code&gt; 获取 &lt;code&gt;tensors&lt;/code&gt; 并返回一个从度量标准字符串名称到调用度量标准函数（即 &lt;code&gt;(metric_tensor, update_op)&lt;/code&gt; 元组）的结果的字典。见 &lt;code&gt;TPUEstimator&lt;/code&gt; 对于MNIST示例，如何指定 &lt;code&gt;eval_metrics&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f118a36ef432860d92562aadbab18ae4b06bc7e8" translate="yes" xml:space="preserve">
          <source>For evaluation, &lt;code&gt;eval_metrics&lt;/code&gt;is a tuple of &lt;code&gt;metric_fn&lt;/code&gt; and &lt;code&gt;tensors&lt;/code&gt;, where &lt;code&gt;metric_fn&lt;/code&gt; runs on CPU to generate metrics and &lt;code&gt;tensors&lt;/code&gt; represents the &lt;code&gt;Tensor&lt;/code&gt;s transferred from TPU system to CPU host and passed to &lt;code&gt;metric_fn&lt;/code&gt;. To be precise, TPU evaluation expects a slightly different signature from the &lt;a href=&quot;../../../../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt;. While &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec#eval_metric_ops&quot;&gt;&lt;code&gt;EstimatorSpec.eval_metric_ops&lt;/code&gt;&lt;/a&gt; expects a dict, &lt;code&gt;TPUEstimatorSpec.eval_metrics&lt;/code&gt; is a tuple of &lt;code&gt;metric_fn&lt;/code&gt; and &lt;code&gt;tensors&lt;/code&gt;. The &lt;code&gt;tensors&lt;/code&gt; could be a list of &lt;code&gt;Tensor&lt;/code&gt;s or dict of names to &lt;code&gt;Tensor&lt;/code&gt;s. The &lt;code&gt;tensors&lt;/code&gt; usually specify the model logits, which are transferred back from TPU system to CPU host. All tensors must have be batch-major, i.e., the batch size is the first dimension. Once all tensors are available at CPU host from all shards, they are concatenated (on CPU) and passed as positional arguments to the &lt;code&gt;metric_fn&lt;/code&gt; if &lt;code&gt;tensors&lt;/code&gt; is list or keyword arguments if &lt;code&gt;tensors&lt;/code&gt; is a dict. &lt;code&gt;metric_fn&lt;/code&gt; takes the &lt;code&gt;tensors&lt;/code&gt; and returns a dict from metric string name to the result of calling a metric function, namely a &lt;code&gt;(metric_tensor, update_op)&lt;/code&gt; tuple. See &lt;code&gt;TPUEstimator&lt;/code&gt; for MNIST example how to specify the &lt;code&gt;eval_metrics&lt;/code&gt;.</source>
          <target state="translated">为了评价， &lt;code&gt;eval_metrics&lt;/code&gt; 是元组 &lt;code&gt;metric_fn&lt;/code&gt; 和 &lt;code&gt;tensors&lt;/code&gt; ，其中 &lt;code&gt;metric_fn&lt;/code&gt; 上CPU运行以生成度量和 &lt;code&gt;tensors&lt;/code&gt; 表示 &lt;code&gt;Tensor&lt;/code&gt; 期从TPU系统到CPU主机传送并传递给 &lt;code&gt;metric_fn&lt;/code&gt; 。确切地说，TPU评估期望的签名与&lt;a href=&quot;../../../../estimator/estimator&quot;&gt; &lt;code&gt;tf.estimator.Estimator&lt;/code&gt; &lt;/a&gt;略有不同。虽然&lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec#eval_metric_ops&quot;&gt; &lt;code&gt;EstimatorSpec.eval_metric_ops&lt;/code&gt; &lt;/a&gt;需要一个dict， &lt;code&gt;TPUEstimatorSpec.eval_metrics&lt;/code&gt; 是 &lt;code&gt;metric_fn&lt;/code&gt; 和 &lt;code&gt;tensors&lt;/code&gt; 的元组。该 &lt;code&gt;tensors&lt;/code&gt; 可能是一个列表 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;Tensor&lt;/code&gt; 的名称字典。的 &lt;code&gt;tensors&lt;/code&gt; 通常指定模型logits，这是从系统TPU传输回CPU主机。所有张量都必须是批量张量，即，批量大小是第一维。一旦所有主机上所有分片上的所有张量都可用，它们就会被串联（在CPU上）并作为位置参数（如果 &lt;code&gt;tensors&lt;/code&gt; 是列表，则作为参数传递给 &lt;code&gt;metric_fn&lt;/code&gt; 或如果 &lt;code&gt;tensors&lt;/code&gt; 是dict则传递给关键字参数）。 &lt;code&gt;metric_fn&lt;/code&gt; 获取 &lt;code&gt;tensors&lt;/code&gt; 并返回一个从度量标准字符串名称到调用度量标准函数（即 &lt;code&gt;(metric_tensor, update_op)&lt;/code&gt; 元组）的结果的字典。见 &lt;code&gt;TPUEstimator&lt;/code&gt; 对于MNIST示例，如何指定 &lt;code&gt;eval_metrics&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="233690c252f396e774e862ecef25a5d76e450f3d" translate="yes" xml:space="preserve">
          <source>For every layer, a &lt;code&gt;group&lt;/code&gt; named &lt;code&gt;layer.name&lt;/code&gt;</source>
          <target state="translated">对于每个图层，一个名为 &lt;code&gt;layer.name&lt;/code&gt; 的 &lt;code&gt;group&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3e630abe4632e77580d682ff1b578d80d9f94bb8" translate="yes" xml:space="preserve">
          <source>For every such layer group, a group attribute &lt;code&gt;weight_names&lt;/code&gt;, a list of strings (ordered names of weights tensor of the layer).</source>
          <target state="translated">对于每个这样的图层组，一个组属性 &lt;code&gt;weight_names&lt;/code&gt; ，是一个字符串列表（该图层的权重张量的有序名称）。</target>
        </trans-unit>
        <trans-unit id="922382a037863a11613e937b2f92117b3dfa1b3d" translate="yes" xml:space="preserve">
          <source>For every weight in the layer, a dataset storing the weight value, named after the weight tensor.</source>
          <target state="translated">对于层中的每一个权重,一个存储权重值的数据集,以权重张量命名。</target>
        </trans-unit>
        <trans-unit id="177050bf0b29fb3f08398a12bddac7a0a078af5e" translate="yes" xml:space="preserve">
          <source>For example &lt;code&gt;foo[3:5,...,4:5]&lt;/code&gt; on a shape 10x3x3x10 tensor is equivalent to &lt;code&gt;foo[3:5,:,:,4:5]&lt;/code&gt; and &lt;code&gt;foo[3:5,...]&lt;/code&gt; is equivalent to &lt;code&gt;foo[3:5,:,:,:]&lt;/code&gt;.</source>
          <target state="translated">例如 &lt;code&gt;foo[3:5,...,4:5]&lt;/code&gt; 形状为10x3x3x10张量的foo [3：5，...，4：5]等效于 &lt;code&gt;foo[3:5,:,:,4:5]&lt;/code&gt; 而 &lt;code&gt;foo[3:5,...]&lt;/code&gt; 为等效于 &lt;code&gt;foo[3:5,:,:,:]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4dd7ff6a28b3c8f6de1619b3709d89a90256ca48" translate="yes" xml:space="preserve">
          <source>For example if we have a file with the following content:</source>
          <target state="translated">例如,如果我们有一个文件,内容如下。</target>
        </trans-unit>
        <trans-unit id="315792fe0731f8fd6c7594397b55834eb861bb3c" translate="yes" xml:space="preserve">
          <source>For example if you know all the images in a dataset have shape [28,28,3] you can set it with &lt;code&gt;tf.set_shape&lt;/code&gt;:</source>
          <target state="translated">例如，如果您知道数据集中的所有图像都具有[28,28,3]形状，则可以使用 &lt;code&gt;tf.set_shape&lt;/code&gt; 进行设置：</target>
        </trans-unit>
        <trans-unit id="6db6725e9e7d5c088630e348048d1e73fc7657d3" translate="yes" xml:space="preserve">
          <source>For example,</source>
          <target state="translated">例如:</target>
        </trans-unit>
        <trans-unit id="f7cb3885a2d5b333dd84f8883e526c3c627d832d" translate="yes" xml:space="preserve">
          <source>For example, &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;'s &lt;code&gt;input_signature&lt;/code&gt; argument accepts a list (or nested structure) of &lt;code&gt;TypeSpec&lt;/code&gt;s.</source>
          <target state="translated">例如，&lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;input_signature&lt;/code&gt; 参数接受的列表（或嵌套结构） &lt;code&gt;TypeSpec&lt;/code&gt; 秒。</target>
        </trans-unit>
        <trans-unit id="3e0fb3305e7269deaf00a94f40306ad8dc3b8739" translate="yes" xml:space="preserve">
          <source>For example, &lt;code&gt;foo[:4, tf.newaxis, :2]&lt;/code&gt; would produce a shape &lt;code&gt;(4, 1, 2)&lt;/code&gt; tensor.</source>
          <target state="translated">例如， &lt;code&gt;foo[:4, tf.newaxis, :2]&lt;/code&gt; 将产生形状 &lt;code&gt;(4, 1, 2)&lt;/code&gt; 4，1，2 ）张量。</target>
        </trans-unit>
        <trans-unit id="fc792685b1d9aab00aa3a406ffbf92c58d9d4cb3" translate="yes" xml:space="preserve">
          <source>For example, N = 2, source[0] is 'hello world' and source[1] is 'a b c', then the output will be</source>
          <target state="translated">例如,N=2,source[0]是'hello world',source[1]是'a b c',那么输出将是</target>
        </trans-unit>
        <trans-unit id="4cb0994aab88328f91b6706a654056d092b65ec9" translate="yes" xml:space="preserve">
          <source>For example, a &lt;a href=&quot;../../layers/dense&quot;&gt;&lt;code&gt;tf.keras.layers.Dense&lt;/code&gt;&lt;/a&gt; layer, when run on a GPU with a float16 compute dtype, will pass float16 inputs to tf.matmul. But, tf.matmul will do use float32 intermediate math. The performance benefit of float16 is still apparent, due to increased memory bandwidth and the fact modern GPUs have specialized hardware for computing matmuls on float16 while still keeping intermediate computations in float32.</source>
          <target state="translated">例如，当在具有float16计算dtype的GPU上运行时，&lt;a href=&quot;../../layers/dense&quot;&gt; &lt;code&gt;tf.keras.layers.Dense&lt;/code&gt; &lt;/a&gt;层会将float16输入传递给tf.matmul。但是，tf.matmul将使用float32中间数学。由于增加了内存带宽，float16的性能优势仍然显而易见，而且现代GPU具有专用的硬件，可以在float16上计算matmul，同时仍将中间计算保留在float32中。</target>
        </trans-unit>
        <trans-unit id="5f7fb0826a5a86cfd624ab2a8d7d2b8c6ddef6b1" translate="yes" xml:space="preserve">
          <source>For example, a Dense layer returns a list of two values-- per-output weights and the bias value. These can be used to set the weights of another Dense layer:</source>
          <target state="translated">例如,一个Dense层返回两个值的列表--每输出权重和偏置值。这些值可以用来设置另一个Dense层的权重。</target>
        </trans-unit>
        <trans-unit id="85a2affea67c5e39397e4468831c1fffecfdec41" translate="yes" xml:space="preserve">
          <source>For example, a blockwise &lt;code&gt;3 x 3&lt;/code&gt;&lt;code&gt;LinearOperatorBlockLowerTriangular&lt;/code&gt; is initialized with the list &lt;code&gt;[[op_00], [op_10, op_11], [op_20, op_21, op_22]]&lt;/code&gt;, where the &lt;code&gt;op_ij&lt;/code&gt;, &lt;code&gt;i &amp;lt; 3, j &amp;lt;= i&lt;/code&gt;, are &lt;code&gt;LinearOperator&lt;/code&gt; instances. The &lt;code&gt;LinearOperatorBlockLowerTriangular&lt;/code&gt; behaves as the following blockwise matrix, where &lt;code&gt;0&lt;/code&gt; represents appropriately-sized [batch] matrices of zeros:</source>
          <target state="translated">例如，以列表 &lt;code&gt;[[op_00], [op_10, op_11], [op_20, op_21, op_22]]&lt;/code&gt; 初始化 &lt;code&gt;LinearOperatorBlockLowerTriangular&lt;/code&gt; &lt;code&gt;3 x 3&lt;/code&gt; LinearOperatorBlockLowerTriangular，其中 &lt;code&gt;op_ij&lt;/code&gt; ， &lt;code&gt;i &amp;lt; 3, j &amp;lt;= i&lt;/code&gt; 是 &lt;code&gt;LinearOperator&lt;/code&gt; 实例。所述 &lt;code&gt;LinearOperatorBlockLowerTriangular&lt;/code&gt; 表现为下列嵌段矩阵，其中 &lt;code&gt;0&lt;/code&gt; 表示零的适当大小的[批次]矩阵：</target>
        </trans-unit>
        <trans-unit id="fcebdd5340244173df800627bd1fd4d61eafaaf9" translate="yes" xml:space="preserve">
          <source>For example, a long-running operation (e.g. &lt;code&gt;tf.QueueBase.enqueue&lt;/code&gt; may be cancelled by running another operation (e.g. &lt;code&gt;tf.QueueBase.close&lt;/code&gt;, or by &lt;code&gt;tf.Session.close&lt;/code&gt;. A step that is running such a long-running operation will fail by raising &lt;code&gt;CancelledError&lt;/code&gt;.</source>
          <target state="translated">例如，长时间运行的操作（例如 &lt;code&gt;tf.QueueBase.enqueue&lt;/code&gt; 可以通过运行另一操作（例如取消 &lt;code&gt;tf.QueueBase.close&lt;/code&gt; ，或通过 &lt;code&gt;tf.Session.close&lt;/code&gt; 运行这样的一种步骤长时间运行的操作将通过引发 &lt;code&gt;CancelledError&lt;/code&gt; 失败。</target>
        </trans-unit>
        <trans-unit id="d8e89184316bed55c53786f62c2b2ad4e3ff94d1" translate="yes" xml:space="preserve">
          <source>For example, a variable created under a &lt;code&gt;MirroredStrategy&lt;/code&gt; is a &lt;code&gt;MirroredVariable&lt;/code&gt;. If no devices are specified in the constructor argument of the strategy then it will use all the available GPUs. If no GPUs are found, it will use the available CPUs. Note that TensorFlow treats all CPUs on a machine as a single device, and uses threads internally for parallelism.</source>
          <target state="translated">例如，在 &lt;code&gt;MirroredStrategy&lt;/code&gt; 下创建的变量是 &lt;code&gt;MirroredVariable&lt;/code&gt; 。如果在策略的构造函数参数中未指定任何设备，则它将使用所有可用的GPU。如果找不到GPU，它将使用可用的CPU。请注意，TensorFlow将机器上的所有CPU视为单个设备，并在内部使用线程进行并行处理。</target>
        </trans-unit>
        <trans-unit id="ef45f8f5ea52443b495bf1c4d1f242d4e99b9f14" translate="yes" xml:space="preserve">
          <source>For example, assuming that operations of type &lt;code&gt;&quot;Sub&quot;&lt;/code&gt; take two inputs &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, and return a single output &lt;code&gt;x - y&lt;/code&gt;, the following gradient function would be registered:</source>
          <target state="translated">例如，假设类型为 &lt;code&gt;&quot;Sub&quot;&lt;/code&gt; 采用两个输入 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; ，并返回单个输出 &lt;code&gt;x - y&lt;/code&gt; ，则将注册以下梯度函数：</target>
        </trans-unit>
        <trans-unit id="180f2ef709a54a11af8fe0feb0049ea09edaa93b" translate="yes" xml:space="preserve">
          <source>For example, consider the case where a new operation &lt;code&gt;MyNewAwesomeAdd&lt;/code&gt; is created with the intent of replacing the implementation of an existing Python wrapper - &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt;. The Python wrapper implementation should change from something like:</source>
          <target state="translated">例如，考虑以下情况：创建新操作 &lt;code&gt;MyNewAwesomeAdd&lt;/code&gt; 旨在替换现有Python包装器&lt;a href=&quot;../math/add&quot;&gt; &lt;code&gt;tf.add&lt;/code&gt; &lt;/a&gt;。Python包装器的实现应与以下类似：</target>
        </trans-unit>
        <trans-unit id="5485292a2195c6dfb3a48825eb198beefa168928" translate="yes" xml:space="preserve">
          <source>For example, consider the following feature vectors:</source>
          <target state="translated">例如,考虑以下特征向量。</target>
        </trans-unit>
        <trans-unit id="4ebe2904fc13a0afda0a0801fae06da9da930550" translate="yes" xml:space="preserve">
          <source>For example, consider the following function that commonly occurs in the computation of cross entropy and log likelihoods:</source>
          <target state="translated">例如,考虑以下函数,它通常出现在交叉熵和对数似然的计算中。</target>
        </trans-unit>
        <trans-unit id="36b3d8f67113dade2a57685778931fd4aac40c92" translate="yes" xml:space="preserve">
          <source>For example, consider the function &lt;code&gt;y = x * x&lt;/code&gt;. The gradient at &lt;code&gt;x = 3.0&lt;/code&gt; can be computed as:</source>
          <target state="translated">例如，考虑函数 &lt;code&gt;y = x * x&lt;/code&gt; 。 &lt;code&gt;x = 3.0&lt;/code&gt; 的梯度可以计算为：</target>
        </trans-unit>
        <trans-unit id="a0f0b737266cb9508dec913b7e40d2a11a33a917" translate="yes" xml:space="preserve">
          <source>For example, for a cluster set up for parameter server training, the following device filters might be specified:</source>
          <target state="translated">例如,对于一个为参数服务器训练而设置的集群,可以指定以下设备过滤器。</target>
        </trans-unit>
        <trans-unit id="623e0c89de281259a4a76c11ecbd4f9ce138793a" translate="yes" xml:space="preserve">
          <source>For example, for a length-&lt;code&gt;k&lt;/code&gt;, vector-valued distribution, it is calculated as,</source>
          <target state="translated">例如，对于长度为 &lt;code&gt;k&lt;/code&gt; 的矢量值分布，其计算公式为：</target>
        </trans-unit>
        <trans-unit id="f6368f536fbdc467faaf091386024de7a14c3cdc" translate="yes" xml:space="preserve">
          <source>For example, for a vocabulary containing 3 labels &lt;code&gt;[a, b, c]&lt;/code&gt;, &lt;code&gt;num_classes = 4&lt;/code&gt; and the labels indexing is &lt;code&gt;{a: 0, b: 1, c: 2, blank: 3}&lt;/code&gt;.</source>
          <target state="translated">例如，对于包含3个标签 &lt;code&gt;[a, b, c]&lt;/code&gt; 的词汇表， &lt;code&gt;num_classes = 4&lt;/code&gt; 且标签索引为 &lt;code&gt;{a: 0, b: 1, c: 2, blank: 3}&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c3115c15a9fb018968e5c6d980aaf6a85e52aa08" translate="yes" xml:space="preserve">
          <source>For example, for stride=(1,1) and padding=&quot;same&quot;:</source>
          <target state="translated">例如,对于stride=(1,1)和padding=&quot;相同&quot;。</target>
        </trans-unit>
        <trans-unit id="00cb23acbd39732b0289b04ffd814e294ed82c1d" translate="yes" xml:space="preserve">
          <source>For example, for stride=(1,1) and padding=&quot;valid&quot;:</source>
          <target state="translated">例如,对于 stride=(1,1)和 padding=&quot;valid&quot;。</target>
        </trans-unit>
        <trans-unit id="f975567f0c60114a08dd76e03f219202f64cefff" translate="yes" xml:space="preserve">
          <source>For example, for stride=(2,2) and padding=&quot;valid&quot;:</source>
          <target state="translated">例如,对于stride=(2,2)和padding=&quot;valid&quot;。</target>
        </trans-unit>
        <trans-unit id="7255e66a73d48695729736c11b4e69788bd57bb6" translate="yes" xml:space="preserve">
          <source>For example, for strides=1 and padding=&quot;same&quot;:</source>
          <target state="translated">例如,对于strides=1和padding=&quot;相同&quot;。</target>
        </trans-unit>
        <trans-unit id="085e925d53c95cbefd7abeb57a30c1ff2277f50b" translate="yes" xml:space="preserve">
          <source>For example, for strides=1 and padding=&quot;valid&quot;:</source>
          <target state="translated">例如,对于 strides=1 和 padding=&quot;valid&quot;。</target>
        </trans-unit>
        <trans-unit id="eb7d3255ed5f8e3928e920d565d5aea04bdcc956" translate="yes" xml:space="preserve">
          <source>For example, for strides=2 and padding=&quot;valid&quot;:</source>
          <target state="translated">例如,对于 strides=2 和 padding=&quot;valid&quot;。</target>
        </trans-unit>
        <trans-unit id="9f5c38b8eb7488176cf43cc68fe176bcdaf5ad82" translate="yes" xml:space="preserve">
          <source>For example, for system with 8 logical devices, if &lt;code&gt;tensor&lt;/code&gt; is an image tensor with shape (batch_size, width, height, channel) and &lt;code&gt;partition_dimensions&lt;/code&gt; is [1, 2, 4, 1], then &lt;code&gt;tensor&lt;/code&gt; will be split 2 in width dimension and 4 way in height dimension and the split tensor values will be fed into 8 logical devices.</source>
          <target state="translated">例如，对于具有8个逻辑设备的系统，如果 &lt;code&gt;tensor&lt;/code&gt; 是形状为（batch_size，宽度，高度，通道）的图像张量，而 &lt;code&gt;partition_dimensions&lt;/code&gt; 为[ 1、2、4、1 ]，则 &lt;code&gt;tensor&lt;/code&gt; 将在宽度尺寸上分割为2，并且高度尺寸的4种方式和分开的张量值将被馈送到8个逻辑设备中。</target>
        </trans-unit>
        <trans-unit id="04995a90d2cbb2770c2b48eb75173d51eb847e39" translate="yes" xml:space="preserve">
          <source>For example, given a tensor of shape &lt;code&gt;(A, B, C, D)&lt;/code&gt;;</source>
          <target state="translated">例如，给定一个形状为 &lt;code&gt;(A, B, C, D)&lt;/code&gt; 的张量；</target>
        </trans-unit>
        <trans-unit id="e1b94d04ee53deb5a3f4899863cd8936a9a93808" translate="yes" xml:space="preserve">
          <source>For example, given an input of shape &lt;code&gt;[1, 1, 1, 4]&lt;/code&gt;, data_format = &quot;NHWC&quot; and block_size = 2:</source>
          <target state="translated">例如，给定形状为 &lt;code&gt;[1, 1, 1, 4]&lt;/code&gt; 1，1，1，4 ]的输入，data_format =&amp;ldquo; NHWC&amp;rdquo;和block_size = 2：</target>
        </trans-unit>
        <trans-unit id="73901e6b47ecbf656dbf0c63bc23506a1582b4f9" translate="yes" xml:space="preserve">
          <source>For example, given an input of shape &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt;, data_format = &quot;NHWC&quot; and block_size = 2:</source>
          <target state="translated">例如，给定形状为 &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; 1、2、2、1 ]的输入，data_format =&amp;ldquo; NHWC&amp;rdquo;和block_size = 2：</target>
        </trans-unit>
        <trans-unit id="9e72f264d4068a89cde912a017b35e1218d4d07d" translate="yes" xml:space="preserve">
          <source>For example, given the following datasets:</source>
          <target state="translated">例如,给定以下数据集:</target>
        </trans-unit>
        <trans-unit id="36e6a7cc02c6b3197df385da6bc03f401a87598e" translate="yes" xml:space="preserve">
          <source>For example, given the following input:</source>
          <target state="translated">例如,给定以下输入:</target>
        </trans-unit>
        <trans-unit id="72fef8ba715160aa4ba1e8d1a7eac5b78987feac" translate="yes" xml:space="preserve">
          <source>For example, given this input:</source>
          <target state="translated">例如,给定这个输入。</target>
        </trans-unit>
        <trans-unit id="ccbd1974587f66c012f3ce45843b4a9f5f326074" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;axis = 1&lt;/code&gt; and the inputs are</source>
          <target state="translated">例如，如果 &lt;code&gt;axis = 1&lt;/code&gt; 并且输入为</target>
        </trans-unit>
        <trans-unit id="6b23a8e10aeea8f89169181db0354df162a5d3fd" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;concat_dim = 1&lt;/code&gt; and the inputs are</source>
          <target state="translated">例如，如果 &lt;code&gt;concat_dim = 1&lt;/code&gt; 且输入为</target>
        </trans-unit>
        <trans-unit id="12db4e70afdf1bc3643b5acdc6bad82dd0e10f2e" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;elems&lt;/code&gt; is &lt;code&gt;(t1, [t2, t3])&lt;/code&gt; and &lt;code&gt;initializer&lt;/code&gt; is &lt;code&gt;[i1, i2]&lt;/code&gt; then an appropriate signature for &lt;code&gt;fn&lt;/code&gt; in &lt;code&gt;python2&lt;/code&gt; is: &lt;code&gt;fn = lambda (acc_p1, acc_p2), (t1, [t2, t3]):&lt;/code&gt; and &lt;code&gt;fn&lt;/code&gt; must return a list, &lt;code&gt;[acc_n1, acc_n2]&lt;/code&gt;. An alternative correct signature for &lt;code&gt;fn&lt;/code&gt;, and the one that works in &lt;code&gt;python3&lt;/code&gt;, is: &lt;code&gt;fn = lambda a, t:&lt;/code&gt;, where &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;t&lt;/code&gt; correspond to the input tuples.</source>
          <target state="translated">例如，如果 &lt;code&gt;elems&lt;/code&gt; 的是 &lt;code&gt;(t1, [t2, t3])&lt;/code&gt; 和 &lt;code&gt;initializer&lt;/code&gt; 为 &lt;code&gt;[i1, i2]&lt;/code&gt; 然后一个合适的签名 &lt;code&gt;fn&lt;/code&gt; 在 &lt;code&gt;python2&lt;/code&gt; 是： &lt;code&gt;fn = lambda (acc_p1, acc_p2), (t1, [t2, t3]):&lt;/code&gt; 并且 &lt;code&gt;fn&lt;/code&gt; 必须返回列表 &lt;code&gt;[acc_n1, acc_n2]&lt;/code&gt; 。 &lt;code&gt;fn&lt;/code&gt; 的另一种正确签名（在 &lt;code&gt;python3&lt;/code&gt; 中工作）是： &lt;code&gt;fn = lambda a, t:&lt;/code&gt; ：，其中 &lt;code&gt;a&lt;/code&gt; 和 &lt;code&gt;t&lt;/code&gt; 对应于输入元组。</target>
        </trans-unit>
        <trans-unit id="cc61fc022fbf77e9b491b661c7505399625f7c88" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;labels&lt;/code&gt;=[a, b, c] and &lt;code&gt;predictions&lt;/code&gt;=[x, y, z], there are three pairs of differences are summed to compute the loss: loss = [ ((a-b) - (x-y)).^2 + ((a-c) - (x-z)).^2 + ((b-c) - (y-z)).^2 ] / 3</source>
          <target state="translated">例如，如果 &lt;code&gt;labels&lt;/code&gt; = [a，b，c]并且 &lt;code&gt;predictions&lt;/code&gt; = [x，y，z]，则将三对差异相加以计算损失：loss = [（（ab）-（xy））。 ^ 2 +（（（ac）-（xz））。^ 2 +（（bc）-（yz））。^ 2] / 3</target>
        </trans-unit>
        <trans-unit id="2baa9bbc1cf6bd691324f3eac32cd3df8cf8cd10" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input.dense_shape = [2, 3, 4]&lt;/code&gt; with non-empty values:</source>
          <target state="translated">例如，如果 &lt;code&gt;sp_input.dense_shape = [2, 3, 4]&lt;/code&gt; 且具有非空值：</target>
        </trans-unit>
        <trans-unit id="82ef36e97447aa968dcbc0b94c3a5abad62654fd" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[2, 3, 6]&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt;:</source>
          <target state="translated">例如，如果 &lt;code&gt;sp_input&lt;/code&gt; 具有形状 &lt;code&gt;[2, 3, 6]&lt;/code&gt; 2，3，6 ]和 &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="5fbb93d3efe7c28e2cd5aae402bb6c00323fbb4c" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[3, 5]&lt;/code&gt; and non-empty string values:</source>
          <target state="translated">例如，如果 &lt;code&gt;sp_input&lt;/code&gt; 具有形状 &lt;code&gt;[3, 5]&lt;/code&gt; 和非空字符串值：</target>
        </trans-unit>
        <trans-unit id="48e9053195f85a37348bd311aa5312c62f0d464f" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[4, 5]&lt;/code&gt; and 4 non-empty string values:</source>
          <target state="translated">例如，如果 &lt;code&gt;sp_input&lt;/code&gt; 具有形状 &lt;code&gt;[4, 5]&lt;/code&gt; 和4个非空字符串值：</target>
        </trans-unit>
        <trans-unit id="c8378e24e7a2aa8a60e4c9f1dd742f0e0c198be9" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[4, 5]&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt;:</source>
          <target state="translated">例如，如果 &lt;code&gt;sp_input&lt;/code&gt; 具有形状 &lt;code&gt;[4, 5]&lt;/code&gt; 和 &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="079ce847d3f4ddf3969ea935f3da66bee264e67a" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;values&lt;/code&gt; is [1, 3, 5, 7] and reduction=SUM_OVER_BATCH_SIZE, then the value of &lt;code&gt;result()&lt;/code&gt; is 4. If the &lt;code&gt;sample_weight&lt;/code&gt; is specified as [1, 1, 0, 0] then value of &lt;code&gt;result()&lt;/code&gt; would be 2.</source>
          <target state="translated">例如，如果 &lt;code&gt;values&lt;/code&gt; 是[1，3，5，7]和还原= SUM_OVER_BATCH_SIZE，则值 &lt;code&gt;result()&lt;/code&gt; 是4.如果 &lt;code&gt;sample_weight&lt;/code&gt; 指定为[1，1，0，0]，值 &lt;code&gt;result()&lt;/code&gt; 为2。</target>
        </trans-unit>
        <trans-unit id="74c85d63fadaf2c9b5598258a9c06918b60fbc1f" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [-1., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [0.6, -0.7, -0.5] the hinge metric value is 1.6.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[-1。，1.，1.]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[0.6，-0.7，-0.5]，则铰链度量值为1.6。</target>
        </trans-unit>
        <trans-unit id="042aca995b0f38a90ddefbc3e2a8e393512784fe" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [-1., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [0.6, -0.7, -0.5] the squared hinge metric value is 2.6.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[-1。，1.，1.]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[0.6，-0.7，-0.5]，则平方铰链度量值为2.6。</target>
        </trans-unit>
        <trans-unit id="d39413a8be385331298ca5abd733969e733cbbd9" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 0, 0] and &lt;code&gt;y_pred&lt;/code&gt; is [0, 0, 1, 1] then the false positives value is 2. If the weights were specified as [0, 0, 1, 0] then the false positives value would be 1.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 0，1，0，0 ]并且 &lt;code&gt;y_pred&lt;/code&gt; 为[ 0，0，1，1 ]，则假阳性值为2。如果权重指定为[ 0，0，1，0 ]则假阳性值为1。</target>
        </trans-unit>
        <trans-unit id="01fe7d4a63a14b4e23db71a05868b30fb525abd1" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 0, 0] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 1, 0, 0] then the true negatives value is 2. If the weights were specified as [0, 0, 1, 0] then the true negatives value would be 1.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 0，1，0，0 ]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[ 1，1，0，0 ]，那么真实的负值为2。如果权重指定为[ 0，0，1，0 ]那么真实的负值为1。</target>
        </trans-unit>
        <trans-unit id="3ef6e2ca3f9a644f49c6e0ccb7b4d3c7a6db0fc4" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [0, 1, 0, 0] then the false negatives value is 2. If the weights were specified as [0, 0, 1, 0] then the false negatives value would be 1.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 0，1，1，1 ]并且 &lt;code&gt;y_pred&lt;/code&gt; 为[ 0，1，0，0 ]，则假阴性值为2。如果权重指定为[ 0，0，1，0 ]则假阴性值将为1。</target>
        </trans-unit>
        <trans-unit id="3c8c09a433fcd3271d82f0d4f5f64556a950bbfa" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1, 1] then the precision value is 2/(2+1) ie. 0.66. If the weights were specified as [0, 0, 1, 0] then the precision value would be 1.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 0，1，1，1 ]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[ 1，0，1，1 ]，则精度值为2 /（2 + 1），即。0.66。如果权重指定为[0，0，1，0]，则精度值为1。</target>
        </trans-unit>
        <trans-unit id="fd7f6e92310398a605f77c3bad5f5cad2b0e6794" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1, 1] then the recall value is 2/(2+1) ie. 0.66. If the weights were specified as [0, 0, 1, 0] then the recall value would be 1.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 0，1，1，1 ]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[ 1，0，1，1 ]，则召回值为2 /（2 + 1），即。0.66。如果权重指定为[0，0，1，0]，则召回值将为1。</target>
        </trans-unit>
        <trans-unit id="878e23bb2323f6b8fb30fbec08a976993f265dc2" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1, 1] and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1, 1] then the true positives value is 2. If the weights were specified as [0, 0, 1, 0] then the true positives value would be 1.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 0，1，1，1 ]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[ 1，0，1，1 ]，那么正值是2。如果权重指定为[ 0，0，1，0 ]那么真实的肯定值为1。</target>
        </trans-unit>
        <trans-unit id="32b3cccbb70066b6b335a50381cd94d294b3c189" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0, 1, 1], and &lt;code&gt;y_pred&lt;/code&gt; is [1, 0, 1], the cosine similarity is 0.5.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 0，1，1 ]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[ 1，0，1 ]，则余弦相似度为0.5。</target>
        </trans-unit>
        <trans-unit id="0c5ba23e60dac33d6e6ff20e271aa3704cc01f45" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean absolute error is 3/4 (0.75).</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[0.，0.，1.，1.]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[1.，1.，1.，0.]，则平均绝对误差为3/4（0.75）。</target>
        </trans-unit>
        <trans-unit id="10a6bddbd7d48d043bb0ce687f4965fd964d600b" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean absolute percentage error is 5e+08.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[0.，0.，1.，1.]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[1.，1.，1.，0.]，则平均绝对百分比误差为5e + 08。</target>
        </trans-unit>
        <trans-unit id="1db7dfad0c8212945bcb0be81f790e3411e18049" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean squared error is 3/4 (0.75).</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[0.，0.，1.，1.]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[1.，1.，1.，0.]，则均方误差为3/4（0.75）。</target>
        </trans-unit>
        <trans-unit id="352820f40271575204f969d93b9125b9211bb111" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 1., 1., 0.] the mean squared logarithmic error is 0.36034.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[0.，0.，1.，1.]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[1.，1.，1.，0.]，则均方对数误差为0.36034。</target>
        </trans-unit>
        <trans-unit id="92f9d133578d098af3f012a74c5de6af734aaac1" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [0., 1., 1.], and &lt;code&gt;y_pred&lt;/code&gt; is [1., 0., 1.] the categorical hinge metric value is 1.0.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[0.，1.，1.]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[1.，0.，1.]，则分类铰链度量值为1.0。</target>
        </trans-unit>
        <trans-unit id="332538af5696bac076f524f2b4f5a405f689fdfc" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [1, 1, 0, 0] and &lt;code&gt;y_pred&lt;/code&gt; is [0.98, 1, 0, 0.6] then the binary accuracy is 3/4 or .75. If the weights were specified as [1, 0, 0, 1] then the binary accuracy would be 1/2 or .5.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[ 1、1、0、0 ]，而 &lt;code&gt;y_pred&lt;/code&gt; 为[ 0.98、1、0、0.6 ]，则二进制精度为3/4或.75。如果权重指定为[1、0、0、1]，则二进制精度将为1/2或.5。</target>
        </trans-unit>
        <trans-unit id="302da67695947e6cae183abb786ed1ed93793986" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [1, 2, 3, 4] and &lt;code&gt;y_pred&lt;/code&gt; is [0, 2, 3, 4] then the accuracy is 3/4 or .75. If the weights were specified as [1, 1, 0, 0] then the accuracy would be 1/2 or .5.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[1、2、3、4]，而 &lt;code&gt;y_pred&lt;/code&gt; 为[ 0、2、3、4 ]，则精度为3/4或.75。如果将权重指定为[1、1、0、0]，则精度将为1/2或.5。</target>
        </trans-unit>
        <trans-unit id="63dd4aed6e3f523156f4cc8450148bc3eb7f33cb" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [[0, 0, 1], [0, 1, 0]] and &lt;code&gt;y_pred&lt;/code&gt; is [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5. If the weights were specified as [0.7, 0.3] then the categorical accuracy would be .3. You can provide logits of classes as &lt;code&gt;y_pred&lt;/code&gt;, since argmax of logits and probabilities are same.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[[ 0，0，1 ]，[ &lt;code&gt;y_pred&lt;/code&gt; ]]并且y_pred为[[ 0.1，0.9，0.8 ]，[ 0.05，0.95，0 ]]，则分类精度为1 / 2或.5。如果权重指定为[0.7，0.3]，则分类准确度将为0.3。您可以将类的 &lt;code&gt;y_pred&lt;/code&gt; 提供为y_pred，因为logits和概率的argmax相同。</target>
        </trans-unit>
        <trans-unit id="03b61c36d51ef6615cbd7e2f828167a558e16b95" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;y_true&lt;/code&gt; is [[2], [1]] and &lt;code&gt;y_pred&lt;/code&gt; is [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5. If the weights were specified as [0.7, 0.3] then the categorical accuracy would be .3. You can provide logits of classes as &lt;code&gt;y_pred&lt;/code&gt;, since argmax of logits and probabilities are same.</source>
          <target state="translated">例如，如果 &lt;code&gt;y_true&lt;/code&gt; 为[[2]，[1]]，并且 &lt;code&gt;y_pred&lt;/code&gt; 为[[ 0.1、0.9、0.8 ]，[ 0.05、0.95、0 ]]，则分类精度为1/2或.5。如果权重指定为[0.7，0.3]，则分类准确度将为0.3。您可以将类的 &lt;code&gt;y_pred&lt;/code&gt; 提供为y_pred，因为logits和概率的argmax相同。</target>
        </trans-unit>
        <trans-unit id="8f13a7bb3ba4ef5812b22736a0c5aa5e4b5379d5" translate="yes" xml:space="preserve">
          <source>For example, if a Boolean flag was created whose long name was 'update' and whose short name was 'x', then this flag could be explicitly unset through either --noupdate or --nox.</source>
          <target state="translated">例如,如果创建了一个长名为 &quot;update &quot;而短名为 &quot;x &quot;的布尔标志,那么可以通过--noupdate或--nox显式地取消设置这个标志。</target>
        </trans-unit>
        <trans-unit id="cc9b6d5bd1871e9c4763dd68bc17d436b61c0322" translate="yes" xml:space="preserve">
          <source>For example, if an image is 100 x 200 pixels (height x width) and the bounding box is &lt;code&gt;[0.1, 0.2, 0.5, 0.9]&lt;/code&gt;, the upper-left and bottom-right coordinates of the bounding box will be &lt;code&gt;(40, 10)&lt;/code&gt; to &lt;code&gt;(100, 50)&lt;/code&gt; (in (x,y) coordinates).</source>
          <target state="translated">例如，如果图像为100 x 200像素（高x宽），并且边界框为 &lt;code&gt;[0.1, 0.2, 0.5, 0.9]&lt;/code&gt; ，则边界框的左上角和右下角坐标将为 &lt;code&gt;(40, 10)&lt;/code&gt; 到 &lt;code&gt;(100, 50)&lt;/code&gt; （在（x，y）坐标中）。</target>
        </trans-unit>
        <trans-unit id="159c6f90d773fa258aa2ceb1607894f00e000d7c" translate="yes" xml:space="preserve">
          <source>For example, if an image is 100 x 200 pixels (height x width) and the bounding box is &lt;code&gt;[0.1, 0.2, 0.5, 0.9]&lt;/code&gt;, the upper-left and bottom-right coordinates of the bounding box will be &lt;code&gt;(40, 10)&lt;/code&gt; to &lt;code&gt;(180, 50)&lt;/code&gt; (in (x,y) coordinates).</source>
          <target state="translated">例如，如果图像为100 x 200像素（高x宽），并且边界框为 &lt;code&gt;[0.1, 0.2, 0.5, 0.9]&lt;/code&gt; ，则边界框的左上角和右下角坐标将为 &lt;code&gt;(40, 10)&lt;/code&gt; 到 &lt;code&gt;(180, 50)&lt;/code&gt; （在（x，y）坐标中）。</target>
        </trans-unit>
        <trans-unit id="07684173fdbd40bd293343faca9d012ab8c45162" translate="yes" xml:space="preserve">
          <source>For example, if an instance of &lt;code&gt;StaticVocabularyTable&lt;/code&gt; is initialized with a string-to-id initializer that maps:</source>
          <target state="translated">例如，如果使用映射字符串的ID初始化程序初始化 &lt;code&gt;StaticVocabularyTable&lt;/code&gt; 的实例，则：</target>
        </trans-unit>
        <trans-unit id="eb86a4b81dfbe2a8d5b118b66c9ce83f3cdff0cb" translate="yes" xml:space="preserve">
          <source>For example, if each &lt;code&gt;indices[m]&lt;/code&gt; is scalar or vector, we have</source>
          <target state="translated">例如，如果每个 &lt;code&gt;indices[m]&lt;/code&gt; 是标量或向量，则我们有</target>
        </trans-unit>
        <trans-unit id="14f0ac91df308245997c838649986de3acfa389b" translate="yes" xml:space="preserve">
          <source>For example, if elements of the dataset are shaped &lt;code&gt;[B, a0, a1, ...]&lt;/code&gt;, where &lt;code&gt;B&lt;/code&gt; may vary for each input element, then for each element in the dataset, the unbatched dataset will contain &lt;code&gt;B&lt;/code&gt; consecutive elements of shape &lt;code&gt;[a0, a1, ...]&lt;/code&gt;.</source>
          <target state="translated">例如，如果数据集的元素的形状为 &lt;code&gt;[B, a0, a1, ...]&lt;/code&gt; ，其中 &lt;code&gt;B&lt;/code&gt; 对于每个输入元素可能有所不同，那么对于数据集中的每个元素，未批处理的数据集将包含 &lt;code&gt;B&lt;/code&gt; 个形状为 &lt;code&gt;[a0, a1, ...]&lt;/code&gt; B]的连续元素a0，a1，...]。</target>
        </trans-unit>
        <trans-unit id="b758388605970f47c42af062f7d7168a335bbc88" translate="yes" xml:space="preserve">
          <source>For example, if one expects a &lt;a href=&quot;../../../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt;&lt;code&gt;VarLenFeature&lt;/code&gt;&lt;code&gt;ft&lt;/code&gt; and three serialized &lt;code&gt;Example&lt;/code&gt;s are provided:</source>
          <target state="translated">例如，如果期望一个&lt;a href=&quot;../../../tf#float32&quot;&gt; &lt;code&gt;tf.float32&lt;/code&gt; &lt;/a&gt; &lt;code&gt;VarLenFeature&lt;/code&gt; &lt;code&gt;ft&lt;/code&gt; ，则提供三个序列化的 &lt;code&gt;Example&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="eb05669fcc3c2a0884538e3c5dcbdcad42ac9ef3" translate="yes" xml:space="preserve">
          <source>For example, if one expects a &lt;a href=&quot;../../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt;&lt;code&gt;VarLenFeature&lt;/code&gt;&lt;code&gt;ft&lt;/code&gt; and three serialized &lt;code&gt;Example&lt;/code&gt;s are provided:</source>
          <target state="translated">例如，如果期望一个&lt;a href=&quot;../../tf#float32&quot;&gt; &lt;code&gt;tf.float32&lt;/code&gt; &lt;/a&gt; &lt;code&gt;VarLenFeature&lt;/code&gt; &lt;code&gt;ft&lt;/code&gt; ，则提供三个序列化的 &lt;code&gt;Example&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="f8bdd2413e1c95149871ce390e2fbfac69482604" translate="yes" xml:space="preserve">
          <source>For example, if shape_x is [1, 2, 3] and shape_y is [5, 1, 3], the result is a Tensor whose value is [5, 2, 3].</source>
          <target state="translated">例如,如果shape_x是[1,2,3],shape_y是[5,1,3],结果是一个值是[5,2,3]的Tensor。</target>
        </trans-unit>
        <trans-unit id="8e1dfee76a0dd69d101ca2f4608dd28751a60789" translate="yes" xml:space="preserve">
          <source>For example, if shape_x is [1, 2, 3] and shape_y is [5, 1, 3], the result is a TensorShape whose value is [5, 2, 3].</source>
          <target state="translated">例如,如果shape_x是[1,2,3],shape_y是[5,1,3],结果是一个值为[5,2,3]的TensorShape。</target>
        </trans-unit>
        <trans-unit id="baed7d2d04b5d92ba9788e9979fc3b16b8e8b4dc" translate="yes" xml:space="preserve">
          <source>For example, if the handles represent an input, which is a &lt;code&gt;[2, 3]&lt;/code&gt; matrix representing two original &lt;code&gt;SparseTensor&lt;/code&gt; objects:</source>
          <target state="translated">例如，如果句柄表示一个输入，它是表示两个原始 &lt;code&gt;SparseTensor&lt;/code&gt; 对象的 &lt;code&gt;[2, 3]&lt;/code&gt; 矩阵：</target>
        </trans-unit>
        <trans-unit id="e2db8bec254cdfb9c2b8d35134ff51a3f64cd250" translate="yes" xml:space="preserve">
          <source>For example, if the input features are:</source>
          <target state="translated">例如,如果输入的特征是。</target>
        </trans-unit>
        <trans-unit id="0176458490bbd6de268b72418c42500856f34603" translate="yes" xml:space="preserve">
          <source>For example, if the input is</source>
          <target state="translated">例如,如果输入是</target>
        </trans-unit>
        <trans-unit id="6f37e7a6ce06d95b7008768ab5281188eb588a5d" translate="yes" xml:space="preserve">
          <source>For example, if the inputs are</source>
          <target state="translated">例如,如果输入是</target>
        </trans-unit>
        <trans-unit id="4a55df6baad5525fc85f361979567c6db417291a" translate="yes" xml:space="preserve">
          <source>For example, if the inputs are boundaries = [0, 10, 100] input = [[-5, 10000] [150, 10] [5, 100]]</source>
          <target state="translated">例如,如果输入是边界=[0,10,100]输入=[[-5,10000][150,10][5,100]]。</target>
        </trans-unit>
        <trans-unit id="2211633f9a2518e5f826b94adb19d9161763632d" translate="yes" xml:space="preserve">
          <source>For example, if the serialized input is a &lt;code&gt;[2 x 3]&lt;/code&gt; matrix representing two original &lt;code&gt;SparseTensor&lt;/code&gt; objects:</source>
          <target state="translated">例如，如果序列化的输入是 &lt;code&gt;[2 x 3]&lt;/code&gt; 矩阵，表示两个原始 &lt;code&gt;SparseTensor&lt;/code&gt; 对象：</target>
        </trans-unit>
        <trans-unit id="ec19dc8fbf4a531cb12fa3311a36ebe61ce15eb0" translate="yes" xml:space="preserve">
          <source>For example, if the serialized input is a &lt;code&gt;[2, 3]&lt;/code&gt; matrix representing two original &lt;code&gt;SparseTensor&lt;/code&gt; objects:</source>
          <target state="translated">例如，如果序列化的输入是表示两个原始 &lt;code&gt;SparseTensor&lt;/code&gt; 对象的 &lt;code&gt;[2, 3]&lt;/code&gt; 矩阵：</target>
        </trans-unit>
        <trans-unit id="a70f738ece73b26c4269166b69c29af52453cd5b" translate="yes" xml:space="preserve">
          <source>For example, if values is [1, 3, 5, 7] then the mean is 4. If the weights were specified as [1, 1, 0, 0] then the mean would be 2.</source>
          <target state="translated">例如,如果数值是[1,3,5,7],那么平均数是4,如果权重指定为[1,1,0,0],那么平均数是2。</target>
        </trans-unit>
        <trans-unit id="e8911ee7c4d9c2878cc8d50831034ed815f5e1c3" translate="yes" xml:space="preserve">
          <source>For example, if values is [1, 3, 5, 7] then the sum is 16. If the weights were specified as [1, 1, 0, 0] then the sum would be 4.</source>
          <target state="translated">例如,如果值是[1,3,5,7],那么总和是16。如果权重被指定为[1,1,0,0],那么总和就是4。</target>
        </trans-unit>
        <trans-unit id="9e1df8c42c0b9b864ddf4232778a736fd6146a8f" translate="yes" xml:space="preserve">
          <source>For example, if you had two iterators that marked the current position in a training dataset and a test dataset, you could choose which to use in each step as follows:</source>
          <target state="translated">例如,如果你有两个迭代器,分别标记训练数据集和测试数据集中的当前位置,你可以在每一步中选择使用哪个,如下所示。</target>
        </trans-unit>
        <trans-unit id="059fadcaec40fcaea26bdf57bd124c4c9b8acb79" translate="yes" xml:space="preserve">
          <source>For example, in a distributed-training setting, suppose we have a master seed and a replica ID. We want to fold the replica ID into the master seed to form a &quot;replica seed&quot; to be used by that replica later on, so that different replicas will generate different random numbers but the reproducibility of the whole system can still be controlled by the master seed:</source>
          <target state="translated">例如,在分布式训练环境中,假设我们有一个主种子和一个副本ID。我们希望将副本ID折叠到主种子中,形成一个 &quot;副本种子&quot;,供该副本以后使用,这样不同的副本会产生不同的随机数,但整个系统的可重复性仍然可以由主种子控制。</target>
        </trans-unit>
        <trans-unit id="f80318ab5209d9919d27fe805ac19a9c0931d496" translate="yes" xml:space="preserve">
          <source>For example, in the following code block:</source>
          <target state="translated">例如,在下面的代码块中。</target>
        </trans-unit>
        <trans-unit id="aa532f960a2ce1a036579c69315203f6c2651d89" translate="yes" xml:space="preserve">
          <source>For example, it can be used to implement the dynamic decoder of a seq2seq model.</source>
          <target state="translated">例如,它可以用来实现seq2seq模型的动态解码器。</target>
        </trans-unit>
        <trans-unit id="3e600c85cc6a4cecba36365c9dcfce62fdbeb235" translate="yes" xml:space="preserve">
          <source>For example, letting &lt;code&gt;{...}&lt;/code&gt; to represent a Dataset:</source>
          <target state="translated">例如，让 &lt;code&gt;{...}&lt;/code&gt; 代表数据集：</target>
        </trans-unit>
        <trans-unit id="bf659dc49fbc636a057c5bc8faf1b5475f6913de" translate="yes" xml:space="preserve">
          <source>For example, of loading images of a known size:</source>
          <target state="translated">例如,加载已知大小的图像的。</target>
        </trans-unit>
        <trans-unit id="e782088c1d829573c59eb47813c6583133dd6bf0" translate="yes" xml:space="preserve">
          <source>For example, running a &lt;code&gt;tf.QueueBase.enqueue&lt;/code&gt; operation may raise &lt;code&gt;AbortedError&lt;/code&gt; if a &lt;code&gt;tf.QueueBase.close&lt;/code&gt; operation previously ran.</source>
          <target state="translated">例如，运行 &lt;code&gt;tf.QueueBase.enqueue&lt;/code&gt; 操作可提高 &lt;code&gt;AbortedError&lt;/code&gt; 如果 &lt;code&gt;tf.QueueBase.close&lt;/code&gt; 运行之前运行。</target>
        </trans-unit>
        <trans-unit id="6fb766e4eb77cad3c4ed3c20934b9966a924fe5a" translate="yes" xml:space="preserve">
          <source>For example, running an operation that saves a file (e.g. &lt;code&gt;tf.train.Saver.save&lt;/code&gt;) could potentially raise this exception if an explicit filename for an existing file was passed.</source>
          <target state="translated">例如，如果传递了现有文件的显式文件名，则运行保存文件的操作（例如 &lt;code&gt;tf.train.Saver.save&lt;/code&gt; ）可能会引发此异常。</target>
        </trans-unit>
        <trans-unit id="18f700fd2ce897b85fe0dede4441f3a1eacfcf00" translate="yes" xml:space="preserve">
          <source>For example, running the &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; operation could raise &lt;code&gt;NotFoundError&lt;/code&gt; if it receives the name of a file that does not exist.</source>
          <target state="translated">例如，如果运行 &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; 操作接收到不存在的文件名，则可能引发 &lt;code&gt;NotFoundError&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="cfa313373d48902517bbb0ec4668f45e63a5050e" translate="yes" xml:space="preserve">
          <source>For example, running the &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; operation could raise &lt;code&gt;PermissionDeniedError&lt;/code&gt; if it receives the name of a file for which the user does not have the read file permission.</source>
          <target state="translated">例如，如果运行 &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; 操作接收到用户不具有读取文件权限的文件名，则可能引发 &lt;code&gt;PermissionDeniedError&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3f9fc30c26c26b9c0cc0d112a519a99605e0e840" translate="yes" xml:space="preserve">
          <source>For example, running the same function in two separate critical sections will not ensure serial execution:</source>
          <target state="translated">例如,在两个独立的关键部分运行同一个函数,将无法保证串行执行。</target>
        </trans-unit>
        <trans-unit id="bef67e884ee584f664d6ae2ff6b50fa0e2467597" translate="yes" xml:space="preserve">
          <source>For example, say we want to add 4 scattered elements to a rank-1 tensor to 8 elements. In Python, that addition would look like this:</source>
          <target state="translated">例如,假设我们想将4个散射元素添加到一个rank-1张量的8个元素中。在Python中,这个加法是这样的。</target>
        </trans-unit>
        <trans-unit id="1465860225753881464cf1173eca6c9061ef5e4f" translate="yes" xml:space="preserve">
          <source>For example, say we want to add 4 scattered elements to a rank-1 tensor to 8 elements. In Python, that update would look like this:</source>
          <target state="translated">例如,假设我们想将4个散射元素添加到一个rank-1张量的8个元素中。在Python中,这种更新是这样的。</target>
        </trans-unit>
        <trans-unit id="27f08ff4e75bc71a4d85d762bdd869d0c386d3d7" translate="yes" xml:space="preserve">
          <source>For example, say we want to subtract 4 scattered elements from a rank-1 tensor with 8 elements. In Python, that subtraction would look like this:</source>
          <target state="translated">例如,假设我们想从一个有 8 个元素的 rank-1 张量中减去 4 个散射元素。在 Python 中,这个减法是这样的。</target>
        </trans-unit>
        <trans-unit id="debc3020545312e69c35338b60b8ad1a5d0f1fc6" translate="yes" xml:space="preserve">
          <source>For example, say we want to subtract 4 scattered elements from a rank-1 tensor with 8 elements. In Python, that update would look like this:</source>
          <target state="translated">例如,假设我们想从一个有 8 个元素的 rank-1 张量中减去 4 个散射元素。在Python中,这种更新是这样的。</target>
        </trans-unit>
        <trans-unit id="56ffaf4007daaf44f9fa50fd0b3fcda03d228d5e" translate="yes" xml:space="preserve">
          <source>For example, say we want to update 4 scattered elements to a rank-1 tensor to 8 elements. In Python, that update would look like this:</source>
          <target state="translated">例如,假设我们想把4个散射元素更新为8个元素的rank-1张量。在Python中,这种更新是这样的。</target>
        </trans-unit>
        <trans-unit id="9818c958e44ded80c1b979231b05b2b1e699a832" translate="yes" xml:space="preserve">
          <source>For example, say you have a class A that compares only on its attribute x. Comparators other than &lt;strong&gt;lt&lt;/strong&gt; are omitted for brevity.</source>
          <target state="translated">例如，假设您有一个仅在属性x上进行比较的类A。为简洁起见，省略了&lt;strong&gt;lt&lt;/strong&gt;以外的比较器。</target>
        </trans-unit>
        <trans-unit id="0b868a0b995363e52f99179ab5b2eb1da4495ee3" translate="yes" xml:space="preserve">
          <source>For example, suppose &lt;code&gt;sp_input&lt;/code&gt; has shape &lt;code&gt;[5, 6]&lt;/code&gt; and non-empty values:</source>
          <target state="translated">例如，假设 &lt;code&gt;sp_input&lt;/code&gt; 具有形状 &lt;code&gt;[5, 6]&lt;/code&gt; 和非空值：</target>
        </trans-unit>
        <trans-unit id="4b8890d00c239dfe3d4938b6c67d2e0e8fe86301" translate="yes" xml:space="preserve">
          <source>For example, suppose that &lt;code&gt;data&lt;/code&gt; has data type &lt;a href=&quot;../tf#int32&quot;&gt;&lt;code&gt;tf.int32&lt;/code&gt;&lt;/a&gt; and shape (2, 3, 4), and that the fingerprint method is &lt;code&gt;farmhash64&lt;/code&gt;. In this case, the output shape is (2, 8), where 2 is the batch dimension size of &lt;code&gt;data&lt;/code&gt;, and 8 is the size of each fingerprint value in bytes. &lt;code&gt;output[0, :]&lt;/code&gt; is generated from 12 integers in &lt;code&gt;data[0, :, :]&lt;/code&gt; and similarly &lt;code&gt;output[1, :]&lt;/code&gt; is generated from other 12 integers in &lt;code&gt;data[1, :, :]&lt;/code&gt;.</source>
          <target state="translated">例如，假设 &lt;code&gt;data&lt;/code&gt; 数据类型为&lt;a href=&quot;../tf#int32&quot;&gt; &lt;code&gt;tf.int32&lt;/code&gt; &lt;/a&gt;且形状为（2，3，4），并且指纹方法为 &lt;code&gt;farmhash64&lt;/code&gt; 。在这种情况下，输出形状为（2，8），其中2是 &lt;code&gt;data&lt;/code&gt; 的批处理尺寸大小，而8是每个指纹值的大小（以字节为单位）。从 &lt;code&gt;data[0, :, :]&lt;/code&gt; 12个整数生成 &lt;code&gt;output[0, :]&lt;/code&gt; ，：]，类似地 &lt;code&gt;output[1, :]&lt;/code&gt; 从 &lt;code&gt;data[1, :, :]&lt;/code&gt; 其他12个整数生成output [1，：]。</target>
        </trans-unit>
        <trans-unit id="495460b2d49d23df61667d5a8e90f92bf6025daa" translate="yes" xml:space="preserve">
          <source>For example, suppose that &lt;code&gt;data&lt;/code&gt; has data type &lt;code&gt;DT_INT32&lt;/code&gt; and shape (2, 3, 4), and that the fingerprint method is &lt;code&gt;farmhash64&lt;/code&gt;. In this case, the output shape is (2, 8), where 2 is the batch dimension size of &lt;code&gt;data&lt;/code&gt;, and 8 is the size of each fingerprint value in bytes. &lt;code&gt;output[0, :]&lt;/code&gt; is generated from 12 integers in &lt;code&gt;data[0, :, :]&lt;/code&gt; and similarly &lt;code&gt;output[1, :]&lt;/code&gt; is generated from other 12 integers in &lt;code&gt;data[1, :, :]&lt;/code&gt;.</source>
          <target state="translated">例如，假设 &lt;code&gt;data&lt;/code&gt; 数据类型为 &lt;code&gt;DT_INT32&lt;/code&gt; 且形状为（2，3，4），并且指纹方法为 &lt;code&gt;farmhash64&lt;/code&gt; 。在这种情况下，输出形状为（2，8），其中2是 &lt;code&gt;data&lt;/code&gt; 的批处理尺寸大小，而8是每个指纹值的大小（以字节为单位）。从 &lt;code&gt;data[0, :, :]&lt;/code&gt; 12个整数生成 &lt;code&gt;output[0, :]&lt;/code&gt; ，：]，类似地 &lt;code&gt;output[1, :]&lt;/code&gt; 从 &lt;code&gt;data[1, :, :]&lt;/code&gt; 其他12个整数生成output [1，：]。</target>
        </trans-unit>
        <trans-unit id="eb886fc90913d3858a07b6c81699df2c93cbae46" translate="yes" xml:space="preserve">
          <source>For example, suppose the logical sum of two sparse operands is (densified):</source>
          <target state="translated">例如,假设两个稀疏操作数的逻辑和是(密化)。</target>
        </trans-unit>
        <trans-unit id="4589e17a235fe89004e5860f53c4fa2f48fab5f8" translate="yes" xml:space="preserve">
          <source>For example, suppose there are 2 TPU replicas: replica 0 receives input: &lt;code&gt;[[A, B]]&lt;/code&gt; replica 1 receives input: &lt;code&gt;[[C, D]]&lt;/code&gt;</source>
          <target state="translated">例如，假设有2个TPU副本：副本0接收输入： &lt;code&gt;[[A, B]]&lt;/code&gt; 副本1接收输入： &lt;code&gt;[[C, D]]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="da5af5e9268978110edfe81515e943cf23149b6d" translate="yes" xml:space="preserve">
          <source>For example, suppose there are 4 TPU instances: &lt;code&gt;[A, B, C, D]&lt;/code&gt;. Passing source_target_pairs=&lt;code&gt;[[0,1],[1,2],[2,3],[3,0]]&lt;/code&gt; gets the outputs: &lt;code&gt;[D, A, B, C]&lt;/code&gt;.</source>
          <target state="translated">例如，假设有4个TPU实例： &lt;code&gt;[A, B, C, D]&lt;/code&gt; 。传递source_target_pairs = &lt;code&gt;[[0,1],[1,2],[2,3],[3,0]]&lt;/code&gt; 获得输出： &lt;code&gt;[D, A, B, C]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7b1da1c1eaf2bc599840d6f5ba841c57a047114f" translate="yes" xml:space="preserve">
          <source>For example, suppose there are 8 TPU instances: &lt;code&gt;[A, B, C, D, E, F, G, H]&lt;/code&gt;. Passing group_assignment=&lt;code&gt;[[0,2,4,6],[1,3,5,7]]&lt;/code&gt; sets &lt;code&gt;A, C, E, G&lt;/code&gt; as group 0, and &lt;code&gt;B, D, F, H&lt;/code&gt; as group 1. Thus we get the outputs: &lt;code&gt;[A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H]&lt;/code&gt;.</source>
          <target state="translated">例如，假设有8个TPU实例： &lt;code&gt;[A, B, C, D, E, F, G, H]&lt;/code&gt; 。传递group_assignment = &lt;code&gt;[[0,2,4,6],[1,3,5,7]]&lt;/code&gt; 将 &lt;code&gt;A, C, E, G&lt;/code&gt; 为组0，并将 &lt;code&gt;B, D, F, H&lt;/code&gt; 为组1。得到输出： &lt;code&gt;[A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e241e14b323a360c93e117165ee51f625869bb65" translate="yes" xml:space="preserve">
          <source>For example, suppose we have a file 'my_file0.csv' with four CSV columns of different data types:</source>
          <target state="translated">例如,假设我们有一个文件'my_file0.csv',其中有四个不同数据类型的CSV列。</target>
        </trans-unit>
        <trans-unit id="803f7401710e9c763ad1dc8693918757b743ae6b" translate="yes" xml:space="preserve">
          <source>For example, the RMSprop optimizer for this simple model returns a list of three values-- the iteration count, followed by the root-mean-square value of the kernel and bias of the single Dense layer:</source>
          <target state="translated">例如,这个简单模型的RMSprop优化器会返回一个三个值的列表--迭代次数,然后是内核的均方根值和单Dense层的偏置。</target>
        </trans-unit>
        <trans-unit id="e264f201548e6c6b9b5c296149b210ac828d99c0" translate="yes" xml:space="preserve">
          <source>For example, the RMSprop optimizer for this simple model takes a list of three values-- the iteration count, followed by the root-mean-square value of the kernel and bias of the single Dense layer:</source>
          <target state="translated">例如,这个简单模型的RMSprop优化器需要一个三个值的列表--迭代次数,然后是内核的均方根值和单个Dense层的偏置。</target>
        </trans-unit>
        <trans-unit id="f6fbd097fdd11950b7cadc34f9682795f00f4e27" translate="yes" xml:space="preserve">
          <source>For example, the desired output for the following 4-by-4 kernel:</source>
          <target state="translated">例如,下面4乘4内核的期望输出。</target>
        </trans-unit>
        <trans-unit id="0636239203f94658f87029781558265ccc3966ab" translate="yes" xml:space="preserve">
          <source>For example, the desired output for the following 4-by-4 kernel::</source>
          <target state="translated">例如,以下4乘4内核的预期输出:。</target>
        </trans-unit>
        <trans-unit id="dd21ccc094cad8a87d4c4eacb04b552c571f6bf7" translate="yes" xml:space="preserve">
          <source>For example, the returned matrix &lt;code&gt;A&lt;/code&gt; can be used to right-multiply a spectrogram &lt;code&gt;S&lt;/code&gt; of shape &lt;code&gt;[frames, num_spectrogram_bins]&lt;/code&gt; of linear scale spectrum values (e.g. STFT magnitudes) to generate a &quot;mel spectrogram&quot; &lt;code&gt;M&lt;/code&gt; of shape &lt;code&gt;[frames, num_mel_bins]&lt;/code&gt;.</source>
          <target state="translated">例如，返回的矩阵 &lt;code&gt;A&lt;/code&gt; 可用于右乘谱图 &lt;code&gt;S&lt;/code&gt; 形状的 &lt;code&gt;[frames, num_spectrogram_bins]&lt;/code&gt; 线性刻度频谱值（例如STFT幅值），以产生一个&amp;ldquo;梅尔频谱&amp;rdquo; &lt;code&gt;M&lt;/code&gt; 形状的 &lt;code&gt;[frames, num_mel_bins]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="db3131b06d6d3d95a5212d36111977d0f86b08dc" translate="yes" xml:space="preserve">
          <source>For example, this error might be raised if a per-user quota is exhausted, or perhaps the entire file system is out of space.</source>
          <target state="translated">例如,如果每个用户的配额用完了,或者整个文件系统没有空间了,就会出现这个错误。</target>
        </trans-unit>
        <trans-unit id="54823754fbaf34b915d76fccb6e9c1dc44f28481" translate="yes" xml:space="preserve">
          <source>For example, this may be raised by running a &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; operation, if the file is truncated while it is being read.</source>
          <target state="translated">例如，如果在读取文件时文件被截断，则可以通过运行 &lt;code&gt;tf.WholeFileReader.read&lt;/code&gt; 操作来引发此问题。</target>
        </trans-unit>
        <trans-unit id="ba4a59b5af2c2bc4994c4eadbe6ed4b4b272e9f3" translate="yes" xml:space="preserve">
          <source>For example, this simple dense layer does not require any additional work to support mixed precision or float64. Keras automatically casts the inputs and variable to the appropriate dtype.</source>
          <target state="translated">例如,这个简单的密集层不需要任何额外的工作来支持混合精度或float64。Keras会自动将输入和变量投射到相应的dtype中。</target>
        </trans-unit>
        <trans-unit id="9b4b0afbf5ba933c3cb43f3500122fd6f86887fd" translate="yes" xml:space="preserve">
          <source>For example, to create a 4 x 4 linear operator combined of three 2 x 2 operators:</source>
          <target state="translated">例如,要创建一个由三个2×2运算符组合而成的4×4线性运算符。</target>
        </trans-unit>
        <trans-unit id="abbb5690c25366ae4f227979e99899132fb6b656" translate="yes" xml:space="preserve">
          <source>For example, to define a new Python op called &lt;code&gt;my_op&lt;/code&gt;:</source>
          <target state="translated">例如，定义一个名为 &lt;code&gt;my_op&lt;/code&gt; 的新Python op ：</target>
        </trans-unit>
        <trans-unit id="72eb7a551315d06a0972d21f1c1b460b5d38b044" translate="yes" xml:space="preserve">
          <source>For example, to define a new summary op called &lt;code&gt;my_op&lt;/code&gt;:</source>
          <target state="translated">例如，定义一个名为 &lt;code&gt;my_op&lt;/code&gt; 的新摘要op ：</target>
        </trans-unit>
        <trans-unit id="2965f0eb0a6433fd2e2e4ad410d8862a35002793" translate="yes" xml:space="preserve">
          <source>For example, to set the device filters for a parameter server cluster:</source>
          <target state="translated">例如,为参数服务器集群设置设备过滤器。</target>
        </trans-unit>
        <trans-unit id="66fdf1bdfa059fe195251be30a7a3ab0c36ff0bc" translate="yes" xml:space="preserve">
          <source>For example, user can select profiler nodes placed on gpu:0 with: &lt;code&gt;account_type_regexes=['.*gpu:0.*']&lt;/code&gt;</source>
          <target state="translated">例如，用户可以使用以下命令选择放置在gpu：0上的探查器节点： &lt;code&gt;account_type_regexes=['.*gpu:0.*']&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="386f9efb3adea5d954835eac08e3b8fcac5cfc82" translate="yes" xml:space="preserve">
          <source>For example, we can represent the following 2D &lt;code&gt;SparseTensor&lt;/code&gt;</source>
          <target state="translated">例如，我们可以表示以下2D &lt;code&gt;SparseTensor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="47f6cacac9bb0941442b9ab6365d7dd1f22cf231" translate="yes" xml:space="preserve">
          <source>For example, with &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt;, &lt;code&gt;Z&lt;/code&gt; each block circulant,</source>
          <target state="translated">例如，对于 &lt;code&gt;W&lt;/code&gt; ， &lt;code&gt;X&lt;/code&gt; ， &lt;code&gt;Y&lt;/code&gt; ， &lt;code&gt;Z&lt;/code&gt; 每个块循环，</target>
        </trans-unit>
        <trans-unit id="b91edd5cdc9ee891969b8b38deeabdcc71594122" translate="yes" xml:space="preserve">
          <source>For example, with &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt;, &lt;code&gt;Z&lt;/code&gt; each circulant,</source>
          <target state="translated">例如，对于 &lt;code&gt;W&lt;/code&gt; ， &lt;code&gt;X&lt;/code&gt; ， &lt;code&gt;Y&lt;/code&gt; ， &lt;code&gt;Z&lt;/code&gt; 每个循环，</target>
        </trans-unit>
        <trans-unit id="4d1e66a246a36b7e8a1cc0afa1a8ecb4016d097b" translate="yes" xml:space="preserve">
          <source>For example, with &lt;code&gt;new_vocab_file&lt;/code&gt; a text file containing each of the following elements on a single line: &lt;code&gt;[f0, f1, f2, f3]&lt;/code&gt;, old_vocab_file = [f1, f0, f3], &lt;code&gt;num_new_vocab = 3, new_vocab_offset = 1&lt;/code&gt;, the returned remapping would be &lt;code&gt;[0, -1, 2]&lt;/code&gt;.</source>
          <target state="translated">例如，对于 &lt;code&gt;new_vocab_file&lt;/code&gt; ,一个文本文件在一行上包含以下每个元素： &lt;code&gt;[f0, f1, f2, f3]&lt;/code&gt; ，old_vocab_file = [f1，f0，f3]， &lt;code&gt;num_new_vocab = 3, new_vocab_offset = 1&lt;/code&gt; ，返回的重映射将是 &lt;code&gt;[0, -1, 2]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="59bbe6de1d6b96b3f8288dbb5f70eca92be21e1f" translate="yes" xml:space="preserve">
          <source>For example, within a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;c = tf.matmul(a, b)&lt;/code&gt; creates an &lt;code&gt;Operation&lt;/code&gt; of type &quot;MatMul&quot; that takes tensors &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; as input, and produces &lt;code&gt;c&lt;/code&gt; as output.</source>
          <target state="translated">例如，在&lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; 中&lt;/a&gt;， &lt;code&gt;c = tf.matmul(a, b)&lt;/code&gt; 创建一个类型为&amp;ldquo; MatMul&amp;rdquo; 的 &lt;code&gt;Operation&lt;/code&gt; ，该操作将张量 &lt;code&gt;a&lt;/code&gt; 和 &lt;code&gt;b&lt;/code&gt; 作为输入，并生成 &lt;code&gt;c&lt;/code&gt; 作为输出。</target>
        </trans-unit>
        <trans-unit id="798a25ee68143b917f057d252e6a3be788b95a21" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;../../../../data/dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="translated">例如，可以使用&lt;a href=&quot;../../../../data/dataset#interleave&quot;&gt; &lt;code&gt;Dataset.interleave()&lt;/code&gt; &lt;/a&gt;并发处理许多输入文件：</target>
        </trans-unit>
        <trans-unit id="62bc270e8147fe9b0d27fc9ede5facea85ba5170" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;../../../data/dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="translated">例如，可以使用&lt;a href=&quot;../../../data/dataset#interleave&quot;&gt; &lt;code&gt;Dataset.interleave()&lt;/code&gt; &lt;/a&gt;并发处理许多输入文件：</target>
        </trans-unit>
        <trans-unit id="0a8cdf19717ec8bf5f04585f7d033f7a2610e6d2" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;../dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="translated">例如，可以使用&lt;a href=&quot;../dataset#interleave&quot;&gt; &lt;code&gt;Dataset.interleave()&lt;/code&gt; &lt;/a&gt;并发处理许多输入文件：</target>
        </trans-unit>
        <trans-unit id="5898266aaebf0c43713533e3d18bf9ec4db717f3" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="translated">例如，可以使用&lt;a href=&quot;dataset#interleave&quot;&gt; &lt;code&gt;Dataset.interleave()&lt;/code&gt; &lt;/a&gt;并发处理许多输入文件：</target>
        </trans-unit>
        <trans-unit id="6ded0202a2e44d8d69da3c4dc5a14b181602b6ff" translate="yes" xml:space="preserve">
          <source>For example, you can use &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#interleave&quot;&gt;&lt;code&gt;Dataset.interleave()&lt;/code&gt;&lt;/a&gt; to process many input files concurrently:</source>
          <target state="translated">例如，您可以使用&lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/data/Dataset#interleave&quot;&gt; &lt;code&gt;Dataset.interleave()&lt;/code&gt; &lt;/a&gt;并发处理许多输入文件：</target>
        </trans-unit>
        <trans-unit id="059c3e8cce263b2945a18ac90b2637e10a8026b1" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="translated">例如:</target>
        </trans-unit>
        <trans-unit id="a925ece6d9c348c8aa9316dcdeed531900dee368" translate="yes" xml:space="preserve">
          <source>For example: if &lt;code&gt;filepath&lt;/code&gt; is &lt;code&gt;weights.{epoch:02d}-{val_loss:.2f}.hdf5&lt;/code&gt;, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.</source>
          <target state="translated">例如：如果文件 &lt;code&gt;filepath&lt;/code&gt; 为 &lt;code&gt;weights.{epoch:02d}-{val_loss:.2f}.hdf5&lt;/code&gt; ，则模型检查点将与时代号一起保存，并在文件名中包含验证损失。</target>
        </trans-unit>
        <trans-unit id="617a3ed2e3e514be878c5bb15678122dfc4d8ecd" translate="yes" xml:space="preserve">
          <source>For f(*args, **kwargs), this supports gradients with respect to args or kwargs, but kwargs are currently only supported in eager-mode. Note that for keras layer and model objects, this is handled automatically.</source>
          <target state="translated">对于 f(*args,**kwargs),它支持相对于 args 或 kwargs 的梯度,但 kwargs 目前只在 eager 模式下支持。需要注意的是,对于 keras 层和模型对象,会自动处理。</target>
        </trans-unit>
        <trans-unit id="1e701a0677a91df738cbd270184ad84b85cb6a3f" translate="yes" xml:space="preserve">
          <source>For f(*args, **kwargs), this supports gradients with respect to args, or to gradients with respect to any variables residing in the kwarg 'variables'. Note that for keras layer and model objects, this is handled automatically.</source>
          <target state="translated">对于 f(*args,**kwargs),它支持相对于 args 的梯度,或者相对于 kwarg 'variables' 中的任何变量的梯度。需要注意的是,对于 keras 层和模型对象,这是自动处理的。</target>
        </trans-unit>
        <trans-unit id="f4b53b836d997d79180b7e3d91c8e783a2730a27" translate="yes" xml:space="preserve">
          <source>For floats, the default range is &lt;code&gt;[0, 1)&lt;/code&gt;. For ints, at least &lt;code&gt;maxval&lt;/code&gt; must be specified explicitly.</source>
          <target state="translated">对于浮点数，默认范围是 &lt;code&gt;[0, 1)&lt;/code&gt; 。对于整数，至少必须明确指定 &lt;code&gt;maxval&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="356031776c93a08469e52e6e9a422b36aba24087" translate="yes" xml:space="preserve">
          <source>For full-range (i.e. inclusive of both max and min) random integers, pass &lt;code&gt;minval=None&lt;/code&gt; and &lt;code&gt;maxval=None&lt;/code&gt; with an integer &lt;code&gt;dtype&lt;/code&gt;. For an integer dtype either both &lt;code&gt;minval&lt;/code&gt; and &lt;code&gt;maxval&lt;/code&gt; must be &lt;code&gt;None&lt;/code&gt; or neither may be &lt;code&gt;None&lt;/code&gt;. For example:</source>
          <target state="translated">对于全范围内的随机整数（即两个最大值和最小值的包），通 &lt;code&gt;minval=None&lt;/code&gt; 和 &lt;code&gt;maxval=None&lt;/code&gt; 与整数 &lt;code&gt;dtype&lt;/code&gt; 。对于整数 &lt;code&gt;minval&lt;/code&gt; ，minval和 &lt;code&gt;maxval&lt;/code&gt; 都必须为 &lt;code&gt;None&lt;/code&gt; ,或者都不可以为 &lt;code&gt;None&lt;/code&gt; 。例如：</target>
        </trans-unit>
        <trans-unit id="5a56bcc5ab9d5be952b7e9f40a7d23fa0400b6d0" translate="yes" xml:space="preserve">
          <source>For full-range random integers, pass &lt;code&gt;minval=None&lt;/code&gt; and &lt;code&gt;maxval=None&lt;/code&gt; with an integer &lt;code&gt;dtype&lt;/code&gt; (for integer dtypes, &lt;code&gt;minval&lt;/code&gt; and &lt;code&gt;maxval&lt;/code&gt; must be both &lt;code&gt;None&lt;/code&gt; or both not &lt;code&gt;None&lt;/code&gt;).</source>
          <target state="translated">对于全范围内的随机整数，通过 &lt;code&gt;minval=None&lt;/code&gt; 和 &lt;code&gt;maxval=None&lt;/code&gt; 与整数 &lt;code&gt;dtype&lt;/code&gt; （对于整数dtypes， &lt;code&gt;minval&lt;/code&gt; 和 &lt;code&gt;maxval&lt;/code&gt; 必须既 &lt;code&gt;None&lt;/code&gt; 或两者不是 &lt;code&gt;None&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="04d421a51ab8b8a27bf19870cac97753296986e8" translate="yes" xml:space="preserve">
          <source>For future expansion. The axis to compute the DCT along. Must be &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">为了将来的扩展。用于计算DCT的轴。必须为 &lt;code&gt;-1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8fd166b7a90884f7ea7652e9d0c336832f3c0f77" translate="yes" xml:space="preserve">
          <source>For future expansion. The length of the transform. Must be &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">为了将来的扩展。转换的长度。必须为 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e111c995974685355c526b35bd247aea54214a0f" translate="yes" xml:space="preserve">
          <source>For gamma greater than 1, the histogram will shift towards left and the output image will be darker than the input image. For gamma less than 1, the histogram will shift towards right and the output image will be brighter than the input image.</source>
          <target state="translated">伽玛值大于1时,直方图将向左移动,输出图像将比输入图像更暗。伽玛值小于1时,直方图将向右移动,输出图像将比输入图像更亮。</target>
        </trans-unit>
        <trans-unit id="b943cfdd2ff2928a3736e51095c0c36b03cbbceb" translate="yes" xml:space="preserve">
          <source>For greater flexibility, use &quot;Iterator&quot; and &quot;MakeIterator&quot; to define an iterator using an arbitrary subgraph, which may capture tensors (including fed values) as parameters, and which may be reset multiple times by rerunning &quot;MakeIterator&quot;.</source>
          <target state="translated">为了获得更大的灵活性,使用 &quot;Iterator &quot;和 &quot;MakeIterator &quot;来定义一个使用任意子图的迭代器,该迭代器可以捕获时值(包括馈送值)作为参数,并且可以通过重新运行 &quot;MakeIterator &quot;来多次重置。</target>
        </trans-unit>
        <trans-unit id="2a9f804d2c5657eeaad57f76da30d8419d9f80b2" translate="yes" xml:space="preserve">
          <source>For information about the valid syntax of device name strings, see the documentation in &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h&quot;&gt;&lt;code&gt;DeviceNameUtils&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">有关设备名称字符串的有效语法的信息，请参见&lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h&quot;&gt; &lt;code&gt;DeviceNameUtils&lt;/code&gt; 中&lt;/a&gt;的文档。</target>
        </trans-unit>
        <trans-unit id="e34ec3911430ce7f98ae14651feabc2f68db9179" translate="yes" xml:space="preserve">
          <source>For input dictionary &lt;code&gt;features&lt;/code&gt;, &lt;code&gt;features[key]&lt;/code&gt; is either &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;. If &lt;code&gt;Tensor&lt;/code&gt;, missing values can be represented by &lt;code&gt;-1&lt;/code&gt; for int and &lt;code&gt;''&lt;/code&gt; for string, which will be dropped by this feature column.</source>
          <target state="translated">对于输入字典 &lt;code&gt;features&lt;/code&gt; ， &lt;code&gt;features[key]&lt;/code&gt; 是 &lt;code&gt;Tensor&lt;/code&gt; 或 &lt;code&gt;SparseTensor&lt;/code&gt; 。如果使用 &lt;code&gt;Tensor&lt;/code&gt; ，则缺失值可以用 &lt;code&gt;-1&lt;/code&gt; 表示int，用 &lt;code&gt;''&lt;/code&gt; 表示字符串，这些值将被此功能列删除。</target>
        </trans-unit>
        <trans-unit id="972f34fd8ce79a7530b5410304e5c7ff8345495d" translate="yes" xml:space="preserve">
          <source>For instance, &lt;a href=&quot;iteratorspec&quot;&gt;&lt;code&gt;tf.data.IteratorSpec&lt;/code&gt;&lt;/a&gt; can be used to define a tf.function that takes &lt;a href=&quot;iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt; as an input argument:</source>
          <target state="translated">例如，&lt;a href=&quot;iteratorspec&quot;&gt; &lt;code&gt;tf.data.IteratorSpec&lt;/code&gt; &lt;/a&gt;可以用于定义一个以&lt;a href=&quot;iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;作为输入参数的tf.function：</target>
        </trans-unit>
        <trans-unit id="b6ac02ce36aad1c0613f5ac2778adacecfd565ae" translate="yes" xml:space="preserve">
          <source>For instance, &lt;a href=&quot;optionalspec&quot;&gt;&lt;code&gt;tf.OptionalSpec&lt;/code&gt;&lt;/a&gt; can be used to define a tf.function that takes &lt;a href=&quot;experimental/optional&quot;&gt;&lt;code&gt;tf.experimental.Optional&lt;/code&gt;&lt;/a&gt; as an input argument:</source>
          <target state="translated">例如，&lt;a href=&quot;optionalspec&quot;&gt; &lt;code&gt;tf.OptionalSpec&lt;/code&gt; &lt;/a&gt;可用于定义以&lt;a href=&quot;experimental/optional&quot;&gt; &lt;code&gt;tf.experimental.Optional&lt;/code&gt; &lt;/a&gt;作为输入参数的tf.function：</target>
        </trans-unit>
        <trans-unit id="dd184a755e96827d1f8c5b725d00ffce6156808d" translate="yes" xml:space="preserve">
          <source>For instance, if &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; are Keras tensors, it becomes possible to do: &lt;code&gt;model = Model(input=[a, b], output=c)&lt;/code&gt;</source>
          <target state="translated">例如，如果 &lt;code&gt;a&lt;/code&gt; ， &lt;code&gt;b&lt;/code&gt; 和 &lt;code&gt;c&lt;/code&gt; 是Keras张量，则可以执行以下操作： &lt;code&gt;model = Model(input=[a, b], output=c)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e5e4d4d23c7dda349004192ebc96c46b6465ca75" translate="yes" xml:space="preserve">
          <source>For instance, if &lt;code&gt;params&lt;/code&gt; is a 5x2 matrix:</source>
          <target state="translated">例如，如果 &lt;code&gt;params&lt;/code&gt; 是5x2矩阵：</target>
        </trans-unit>
        <trans-unit id="3d566a2f8f613dd39800087ce7bc50e2d5f86120" translate="yes" xml:space="preserve">
          <source>For instance, if a, b and c are Keras tensors, it becomes possible to do: &lt;code&gt;model = Model(input=[a, b], output=c)&lt;/code&gt;</source>
          <target state="translated">例如，如果a，b和c是Keras张量，则可以执行以下操作： &lt;code&gt;model = Model(input=[a, b], output=c)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0e53703556bacc5b9f2dd5c8a308f65648989002" translate="yes" xml:space="preserve">
          <source>For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are</source>
          <target state="translated">例如,如果params是一个10x20的矩阵,而sp_ids/sp_weights是</target>
        </trans-unit>
        <trans-unit id="cc75bd8580ca757aae48910bd54d05e3c0b7bbe2" translate="yes" xml:space="preserve">
          <source>For instance, if your dataset contains 10,000 elements but &lt;code&gt;buffer_size&lt;/code&gt; is set to 1,000, then &lt;code&gt;shuffle&lt;/code&gt; will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer.</source>
          <target state="translated">例如，如果您的数据集包含10,000个元素，但 &lt;code&gt;buffer_size&lt;/code&gt; 设置为1,000，则 &lt;code&gt;shuffle&lt;/code&gt; 最初将仅从缓冲区的前1,000个元素中选择一个随机元素。选择一个元素后，其缓冲区中的空间将由下一个（即1,001个）元素替换，并保留1,000个元素缓冲区。</target>
        </trans-unit>
        <trans-unit id="abc897209b2f98b7966665fa36a5eddbbc44f66d" translate="yes" xml:space="preserve">
          <source>For instance:</source>
          <target state="translated">例如:</target>
        </trans-unit>
        <trans-unit id="0a0b5cd490edef9c44f6a6d5414aa3f055e77d75" translate="yes" xml:space="preserve">
          <source>For invalid/unknown format arguments.</source>
          <target state="translated">对于无效的/未知的格式参数。</target>
        </trans-unit>
        <trans-unit id="0f9023a39798cc65b443278b72b316a68e41f333" translate="yes" xml:space="preserve">
          <source>For many models, each layer's policy will have the same compute dtype and variable dtype, which will typically be float32. In this case, we refer to the singular dtype as the layer's dtype, which can be queried by the property &lt;a href=&quot;../../layers/layer#dtype&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">对于许多模型，每个层的策略将具有相同的计算dtype和变量dtype，通常为float32。在这种情况下，我们将单数dtype称为图层的dtype，可以通过属性&lt;a href=&quot;../../layers/layer#dtype&quot;&gt; &lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt; &lt;/a&gt;进行查询。</target>
        </trans-unit>
        <trans-unit id="e88bb5e1430cab829924a15faf891ea4f1ef4619" translate="yes" xml:space="preserve">
          <source>For matrices (resp. higher rank input), computes the entries which is the nth-smallest value in each row (resp. vector along the last dimension). Thus,</source>
          <target state="translated">对于矩阵(或更高等级的输入),计算每行(或沿最后一维的向量)中第n个最小值的条目。因此。</target>
        </trans-unit>
        <trans-unit id="0a9115e76a0ba9659e12e140504c8f7f39148287" translate="yes" xml:space="preserve">
          <source>For matrices (resp. higher rank input), computes the top &lt;code&gt;k&lt;/code&gt; entries in each row (resp. vector along the last dimension). Thus,</source>
          <target state="translated">对于矩阵（分别为较高秩的输入），计算每行中的前 &lt;code&gt;k&lt;/code&gt; 个条目（沿最后一维的对应向量）。从而，</target>
        </trans-unit>
        <trans-unit id="f6f81428f9faf616b5f58bf1dfb8c2ee23290062" translate="yes" xml:space="preserve">
          <source>For more details on fractional max pooling, see this paper: &lt;a href=&quot;http://arxiv.org/abs/1412.6071&quot;&gt;Benjamin Graham, Fractional Max-Pooling&lt;/a&gt;</source>
          <target state="translated">有关分数最大池的更多详细信息，请参见本文：&lt;a href=&quot;http://arxiv.org/abs/1412.6071&quot;&gt;Benjamin Graham，分数最大池&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="21bd2ea7c74cf7f28ac3c97e52843c839e601f0f" translate="yes" xml:space="preserve">
          <source>For more details on fractional max pooling, see this paper: &lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;Benjamin Graham, Fractional Max-Pooling&lt;/a&gt;</source>
          <target state="translated">有关分数最大池的更多详细信息，请参见本文：&lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;本杰明&amp;middot;格雷厄姆（Benjamin Graham），分数最大池&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bdc341899055084bcb94f72be25a2efd912ef0ce" translate="yes" xml:space="preserve">
          <source>For more details on warm-start configuration, see &lt;a href=&quot;../../../estimator/warmstartsettings&quot;&gt;&lt;code&gt;tf.estimator.WarmStartSettings&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">有关热启动配置的更多详细信息，请参见&lt;a href=&quot;../../../estimator/warmstartsettings&quot;&gt; &lt;code&gt;tf.estimator.WarmStartSettings&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1e3c977af7155e901bdef759f3dc14b55e9fc4b7" translate="yes" xml:space="preserve">
          <source>For more details on warm-start configuration, see &lt;a href=&quot;warmstartsettings&quot;&gt;&lt;code&gt;tf.estimator.WarmStartSettings&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">有关热启动配置的更多详细信息，请参见&lt;a href=&quot;warmstartsettings&quot;&gt; &lt;code&gt;tf.estimator.WarmStartSettings&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="13a2417d18055bf8846c48234727817863de443c" translate="yes" xml:space="preserve">
          <source>For more details, see the documentation for &lt;code&gt;keras_style_scope&lt;/code&gt;.</source>
          <target state="translated">有关更多详细信息，请参见 &lt;code&gt;keras_style_scope&lt;/code&gt; 的文档。</target>
        </trans-unit>
        <trans-unit id="bc3a84c33cbfb26e5b4fe97277347db008f299e4" translate="yes" xml:space="preserve">
          <source>For more information about creating layers, see the guide &lt;a href=&quot;https://www.tensorflow.org/guide/keras/custom_layers_and_models&quot;&gt;Writing custom layers and models with Keras&lt;/a&gt;</source>
          <target state="translated">有关创建图层的更多信息，请参见指南&lt;a href=&quot;https://www.tensorflow.org/guide/keras/custom_layers_and_models&quot;&gt;《使用Keras编写自定义图层和模型》。&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="152f8ea26d1cff79ab2d01228bf1bdbd0f39e953" translate="yes" xml:space="preserve">
          <source>For more information on eager execution, see the &lt;a href=&quot;https://tensorflow.org/guide/eager&quot;&gt;Eager guide&lt;/a&gt;.</source>
          <target state="translated">有关急切执行的更多信息，请参见&lt;a href=&quot;https://tensorflow.org/guide/eager&quot;&gt;急切指南&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="900a1418668618874090d4e9686dce63aca4019d" translate="yes" xml:space="preserve">
          <source>For more information see: &lt;a href=&quot;https://github.com/catapult-project/catapult/blob/master/tracing/README.md&quot;&gt;https://github.com/catapult-project/catapult/blob/master/tracing/README.md&lt;/a&gt;</source>
          <target state="translated">有关更多信息，请参见：&lt;a href=&quot;https://github.com/catapult-project/catapult/blob/master/tracing/README.md&quot;&gt;https&lt;/a&gt; : //github.com/catapult-project/catapult/blob/master/tracing/README.md</target>
        </trans-unit>
        <trans-unit id="4a3c4bae8cff17665d7c40bbc999f6a1d5c25c78" translate="yes" xml:space="preserve">
          <source>For more information see: https://github.com/catapult-project/catapult/blob/master/tracing/README.md</source>
          <target state="translated">更多信息见:https://github.com/catapult-project/catapult/blob/master/tracing/README.md</target>
        </trans-unit>
        <trans-unit id="4a2de7b882a594ae2b76e69009622fd319f6d72c" translate="yes" xml:space="preserve">
          <source>For more information, please see &lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt;'s API docstring.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt;的API文档字符串。</target>
        </trans-unit>
        <trans-unit id="1c8bf9775f80fdadad83c8c4c855a86b67b010f7" translate="yes" xml:space="preserve">
          <source>For more information, please see &lt;a href=&quot;../../../distribute/cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt;'s API docstring.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;../../../distribute/cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt;的API文档字符串。</target>
        </trans-unit>
        <trans-unit id="f363dc145e0cc1796e063aa7c7c95c22e2b1d829" translate="yes" xml:space="preserve">
          <source>For more information, please see &lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt;'s API docstring.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt;的API文档字符串。</target>
        </trans-unit>
        <trans-unit id="f0a9d42be5d971abb321854a800de6f708fb0dd0" translate="yes" xml:space="preserve">
          <source>For more information, please see &lt;a href=&quot;cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt;'s API docstring.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt;的API文档字符串。</target>
        </trans-unit>
        <trans-unit id="b1a73ddb9ef63644514bdf8fb1c157f4573b5f92" translate="yes" xml:space="preserve">
          <source>For more information, please see &lt;a href=&quot;clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt;'s class doc.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;clusterresolver&quot;&gt; &lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt;的类文档。</target>
        </trans-unit>
        <trans-unit id="55bb2f27fa02e7cb1d336fbb0fd9c36f4d1660c5" translate="yes" xml:space="preserve">
          <source>For more information, please see &lt;a href=&quot;clusterresolver&quot;&gt;&lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt;'s class docstring.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;clusterresolver&quot;&gt; &lt;code&gt;tf.distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt;的类文档字符串。</target>
        </trans-unit>
        <trans-unit id="b43d393bddf0580f867617eb6c2e2f89c938fa23" translate="yes" xml:space="preserve">
          <source>For more information, see the &lt;a href=&quot;https://www.tensorflow.org/guide/autograph&quot;&gt;AutoGraph guide&lt;/a&gt;.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;https://www.tensorflow.org/guide/autograph&quot;&gt;AutoGraph指南&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e65c930b04240141dad57bca65273288271b2809" translate="yes" xml:space="preserve">
          <source>For more on Tensors, see the &lt;a href=&quot;https://tensorflow.org/guide/tensor&quot;&gt;guide&lt;/a&gt;.</source>
          <target state="translated">有关张量的更多信息，请参见&lt;a href=&quot;https://tensorflow.org/guide/tensor&quot;&gt;指南&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6ec21b841a665c40f4c5e83efe27648e19e46e51" translate="yes" xml:space="preserve">
          <source>For ops such as matrix multiplication, inputs and weights must be of the same float type. This function validates that all &lt;code&gt;tensors&lt;/code&gt; are the same type, validates that type is &lt;code&gt;dtype&lt;/code&gt; (if supplied), and returns the type. Type must be a floating point type. If neither &lt;code&gt;tensors&lt;/code&gt; nor &lt;code&gt;dtype&lt;/code&gt; is supplied, the function will return &lt;a href=&quot;../dtypes#float32&quot;&gt;&lt;code&gt;dtypes.float32&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">对于矩阵乘法之类的运算，输入和权重必须为相同的浮点类型。此函数验证所有 &lt;code&gt;tensors&lt;/code&gt; 都为同一类型，验证该类型为 &lt;code&gt;dtype&lt;/code&gt; （如果提供），然后返回该类型。类型必须是浮点类型。如果没有 &lt;code&gt;tensors&lt;/code&gt; 也不 &lt;code&gt;dtype&lt;/code&gt; 提供，该函数将返回&lt;a href=&quot;../dtypes#float32&quot;&gt; &lt;code&gt;dtypes.float32&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="825adbf912a447d1f0e6ca8ee392497c694816b6" translate="yes" xml:space="preserve">
          <source>For ops that have a well-defined gradient but are not yet implemented, no declaration should be made, and an error &lt;em&gt;must&lt;/em&gt; be thrown if an attempt to request its gradient is made.</source>
          <target state="translated">对于具有明确定义的渐变但尚未实现的操作，不应进行任何声明，并且如果尝试请求其渐变，则&lt;em&gt;必须&lt;/em&gt;引发错误。</target>
        </trans-unit>
        <trans-unit id="3c54552d8b9297a0500954f1e7088d433c083309" translate="yes" xml:space="preserve">
          <source>For positive numbers, this function computes log((input - 1)!) for every element in the tensor. &lt;code&gt;lgamma(5) = log((5-1)!) = log(4!) = log(24) = 3.1780539&lt;/code&gt;</source>
          <target state="translated">对于正数，此函数为张量中的每个元素计算log（（input-1）！）。 &lt;code&gt;lgamma(5) = log((5-1)!) = log(4!) = log(24) = 3.1780539&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="17614033a9da90968bc5248bce2e63241d0b5eef" translate="yes" xml:space="preserve">
          <source>For prediction, merges predictions and updates keys in prediction dict to a 2-tuple, &lt;code&gt;(head.name, prediction_key)&lt;/code&gt;. Merges &lt;code&gt;export_outputs&lt;/code&gt; such that by default the first head is served.</source>
          <target state="translated">对于预测，合并预测并将预测dict中的键更新为2个元组 &lt;code&gt;(head.name, prediction_key)&lt;/code&gt; 。合并 &lt;code&gt;export_outputs&lt;/code&gt; ，以便默认情况下提供第一个标题。</target>
        </trans-unit>
        <trans-unit id="367d3134a5e071179a22d4af24a5885a46b948f8" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">为了进行预测，导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; dict的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="d910d10e5e5c18870b7b9be467a883825361a57a" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">为了进行预测，导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; dict的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="85e499998a4aff01940823b0150823a9caaab4eb" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">为了进行预测，导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; dict的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;../export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="4f2dca7789ee2c5012c2ae28c6f51ef0341736b8" translate="yes" xml:space="preserve">
          <source>For prediction, the exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">为了进行预测，导出的 &lt;code&gt;MetaGraphDef&lt;/code&gt; 将为从 &lt;code&gt;model_fn&lt;/code&gt; 返回的 &lt;code&gt;export_outputs&lt;/code&gt; dict的每个元素提供一个 &lt;code&gt;SignatureDef&lt;/code&gt; ，并使用相同的键命名。这些密钥之一始终是 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; ，指示在服务请求未指定签名时将提供哪个签名。对于每个签名，输出由相应的&lt;a href=&quot;export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; &lt;/a&gt;提供，输入始终是 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 提供的输入接收器。</target>
        </trans-unit>
        <trans-unit id="51b640d64056e8e41f482c3d3c805d8ad85d361d" translate="yes" xml:space="preserve">
          <source>For python 2.x.</source>
          <target state="translated">对于python 2.x。</target>
        </trans-unit>
        <trans-unit id="6616ed4ca65ec91b81df8451d8cc7918059964cb" translate="yes" xml:space="preserve">
          <source>For regression: one-dimensional label.</source>
          <target state="translated">对于回归:一维标签。</target>
        </trans-unit>
        <trans-unit id="ebc60d85f1c75542a5be8407d74123940e50f678" translate="yes" xml:space="preserve">
          <source>For saving the input pipeline checkpoint alongside the model weights use &lt;a href=&quot;make_saveable_from_iterator&quot;&gt;&lt;code&gt;tf.data.experimental.make_saveable_from_iterator&lt;/code&gt;&lt;/a&gt; directly to create a &lt;code&gt;SaveableObject&lt;/code&gt; and add to the &lt;code&gt;SAVEABLE_OBJECTS&lt;/code&gt; collection. Note, however, that you will need to be careful not to restore the training iterator during eval. You can do that by not adding the iterator to the SAVEABLE_OBJECTS collector when building the eval graph.</source>
          <target state="translated">为了与模型权重一起保存输入管道检查点，&lt;a href=&quot;make_saveable_from_iterator&quot;&gt; &lt;code&gt;tf.data.experimental.make_saveable_from_iterator&lt;/code&gt; &lt;/a&gt;直接使用tf.data.experimental.make_saveable_from_iterator创建一个 &lt;code&gt;SaveableObject&lt;/code&gt; 并添加到 &lt;code&gt;SAVEABLE_OBJECTS&lt;/code&gt; 集合中。但是请注意，您将需要注意不要在评估期间还原训练迭代器。您可以通过在构建评估图时不将迭代器添加到SAVEABLE_OBJECTS收集器中来实现。</target>
        </trans-unit>
        <trans-unit id="6616597fc49d1e10b07181ff6fbd22315bce9b2f" translate="yes" xml:space="preserve">
          <source>For string data, one should expect &lt;code&gt;Fingerprint(data) != Fingerprint(ReduceJoin(data))&lt;/code&gt; in general.</source>
          <target state="translated">对于字符串数据，通常应该期望 &lt;code&gt;Fingerprint(data) != Fingerprint(ReduceJoin(data))&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4040772dee03e98d438db586092ddda710d40777" translate="yes" xml:space="preserve">
          <source>For string data, one should expect &lt;code&gt;tf.fingerprint(data) != tf.fingerprint(tf.string.reduce_join(data))&lt;/code&gt; in general.</source>
          <target state="translated">对于字符串数据， &lt;code&gt;tf.fingerprint(data) != tf.fingerprint(tf.string.reduce_join(data))&lt;/code&gt; 应该期望tf.fingerprint（data）！= tf.fingerprint（tf.string.reduce_join（data））。</target>
        </trans-unit>
        <trans-unit id="1aee93356a8ac03609dbb2efcc3b9bc6ffc3cf8f" translate="yes" xml:space="preserve">
          <source>For the above example, make_parse_example_spec would return the dict:</source>
          <target state="translated">对于上面的例子,make_parse_example_spec将返回dict。</target>
        </trans-unit>
        <trans-unit id="06ccd3d90a70db2dc3e63a184d4c540501fffaaf" translate="yes" xml:space="preserve">
          <source>For the advanced use cases like model parallelism, you can set &lt;code&gt;experimental_device_assignment&lt;/code&gt; argument when creating TPUStrategy to specify number of replicas and number of logical devices. Below is an example to initialize TPU system with 2 logical devices and 1 replica.</source>
          <target state="translated">对于模型并行性等高级用例，可以在创建TPUStrategy时设置 &lt;code&gt;experimental_device_assignment&lt;/code&gt; 参数来指定副本数和逻辑设备数。以下是使用2个逻辑设备和1个副本初始化TPU系统的示例。</target>
        </trans-unit>
        <trans-unit id="0235be247e65fa625cc59d166e2a6820d050e19f" translate="yes" xml:space="preserve">
          <source>For the content in &lt;code&gt;TF_CONFIG&lt;/code&gt;, assume that the training cluster spec looks like:</source>
          <target state="translated">对于 &lt;code&gt;TF_CONFIG&lt;/code&gt; 中的内容，假定训练集群规范如下所示：</target>
        </trans-unit>
        <trans-unit id="d988a3e29b8ed246ee76e0c2e493b1b397597de1" translate="yes" xml:space="preserve">
          <source>For the idea of warm starts here controlled by &lt;code&gt;num_periods&lt;/code&gt;, see [Loshchilov &amp;amp; Hutter, ICLR2016] SGDR: Stochastic Gradient Descent with Warm Restarts. &lt;a href=&quot;https://arxiv.org/abs/1608.03983&quot;&gt;https://arxiv.org/abs/1608.03983&lt;/a&gt;</source>
          <target state="translated">有关此处由 &lt;code&gt;num_periods&lt;/code&gt; 控制的暖启动的概念，请参见[Loshchilov＆Hutter，ICLR2016] SGDR：具有暖重启的随机梯度下降。&lt;a href=&quot;https://arxiv.org/abs/1608.03983&quot;&gt;https://arxiv.org/abs/1608.03983&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8f06a3bf9b1afd83f2dc01b9bce2b59a3031f004" translate="yes" xml:space="preserve">
          <source>For the idea of warm starts here controlled by &lt;code&gt;num_periods&lt;/code&gt;, see [Loshchilov &amp;amp; Hutter, ICLR2016] SGDR: Stochastic Gradient Descent with Warm Restarts. https://arxiv.org/abs/1608.03983</source>
          <target state="translated">有关此处由 &lt;code&gt;num_periods&lt;/code&gt; 控制的热启动的想法，请参见[Loshchilov＆Hutter，ICLR2016] SGDR：带热重启的随机梯度下降。https://arxiv.org/abs/1608.03983</target>
        </trans-unit>
        <trans-unit id="44813089d644664d33f4de2b9592fffa98ddb5ec" translate="yes" xml:space="preserve">
          <source>For the most part, layers will automatically support mixed precision and float64 without any additional work, due to the fact the base layer automatically casts inputs, creates variables of the correct type, and in the case of mixed precision, wraps variables with &lt;code&gt;AutoCastVariables&lt;/code&gt;.</source>
          <target state="translated">在大多数情况下，图层将自动支持混合精度和float64，而无需任何其他工作，这是因为基本层会自动强制转换输入，创建正确类型的变量，并且在混合精度的情况下，使用 &lt;code&gt;AutoCastVariables&lt;/code&gt; 包装变量。</target>
        </trans-unit>
        <trans-unit id="cd1f2c4cb29e01e87b19426efdde9e0733dd9a05" translate="yes" xml:space="preserve">
          <source>For the most part, the mapping between Proto field types and TensorFlow dtypes is straightforward. However, there are a few special cases:</source>
          <target state="translated">大多数情况下,Proto字段类型和TensorFlow dtypes之间的映射是直接的。然而,有一些特殊情况。</target>
        </trans-unit>
        <trans-unit id="c23aedef4b8e055530a87dad6ff1b4b7682cb7a9" translate="yes" xml:space="preserve">
          <source>For the purposes of this function, a valid ordered sequence type is one which can be indexed, has a length, and has an equality operator.</source>
          <target state="translated">在这个函数中,一个有效的有序序列类型是一个可以被索引的、有长度的、有平等操作符的类型。</target>
        </trans-unit>
        <trans-unit id="277400dd8bda8642b7e25a7ed51e2ae99e733ee3" translate="yes" xml:space="preserve">
          <source>For the replicas:</source>
          <target state="translated">对于复制品。</target>
        </trans-unit>
        <trans-unit id="0a61ac4581750cc1861ea15aab1f318fa5e0885d" translate="yes" xml:space="preserve">
          <source>For the variables and &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt;, a timestamped export directory below &lt;code&gt;export_dir_base&lt;/code&gt;, and writes a &lt;code&gt;SavedModel&lt;/code&gt; into it containing the &lt;code&gt;tf.MetaGraphDef&lt;/code&gt; for the given mode and its associated signatures.</source>
          <target state="translated">对于变量和 &lt;code&gt;tf.MetaGraphDefs&lt;/code&gt; ，在 &lt;code&gt;export_dir_base&lt;/code&gt; 下带有时间戳的导出目录，并向其中写入一个 &lt;code&gt;SavedModel&lt;/code&gt; ，其中包含给定模式的 &lt;code&gt;tf.MetaGraphDef&lt;/code&gt; 及其相关的签名。</target>
        </trans-unit>
        <trans-unit id="56c86fc9affcdc3686a615c6369da410c6e71b43" translate="yes" xml:space="preserve">
          <source>For this function to work, the stream must have a file descriptor that can be modified using &lt;code&gt;os.dup&lt;/code&gt; and &lt;code&gt;os.dup2&lt;/code&gt;, and the stream must support a &lt;code&gt;.flush()&lt;/code&gt; method. The default python sys.stdout and sys.stderr are examples of this. Note that this does not work in Colab or Jupyter notebooks, because those use alternate stdout streams.</source>
          <target state="translated">为了使此功能起作用，流必须具有可以使用 &lt;code&gt;os.dup&lt;/code&gt; 和 &lt;code&gt;os.dup2&lt;/code&gt; 进行修改的文件描述符，并且流必须支持 &lt;code&gt;.flush()&lt;/code&gt; 方法。默认的python sys.stdout和sys.stderr就是这样的示例。请注意，这在Colab或Jupyter笔记本电脑中不起作用，因为它们使用备用stdout流。</target>
        </trans-unit>
        <trans-unit id="ac41fbab77768e9b6192dc00dfce9e8a5ab1aa29" translate="yes" xml:space="preserve">
          <source>For training and evaluation, the &lt;code&gt;train_op&lt;/code&gt; is stored in an extra collection, and loss, metrics, and predictions are included in a &lt;code&gt;SignatureDef&lt;/code&gt; for the mode in question.</source>
          <target state="translated">为了进行训练和评估， &lt;code&gt;train_op&lt;/code&gt; 存储在一个额外的集合中，并且损耗，度量和预测都包含在该模式的 &lt;code&gt;SignatureDef&lt;/code&gt; 中。</target>
        </trans-unit>
        <trans-unit id="8cb90deddea49c5d8ea800cc7d640f23ce709e57" translate="yes" xml:space="preserve">
          <source>For training, &lt;code&gt;model_fn&lt;/code&gt; gets per-core batch size; &lt;code&gt;input_fn&lt;/code&gt; may get per-core or per-host batch size depending on &lt;code&gt;per_host_input_for_training&lt;/code&gt; in &lt;code&gt;TPUConfig&lt;/code&gt; (See docstring for TPUConfig for details).</source>
          <target state="translated">为了进行训练， &lt;code&gt;model_fn&lt;/code&gt; 获取每个核心的批处理大小； &lt;code&gt;input_fn&lt;/code&gt; 可能会获取每个内核或每个主机的批处理大小，具体取决于 &lt;code&gt;per_host_input_for_training&lt;/code&gt; 中的 &lt;code&gt;TPUConfig&lt;/code&gt; （有关详细信息，请参阅TPUConfig的文档字符串）。</target>
        </trans-unit>
        <trans-unit id="851eb999d65883da2e108c88c201473ef5f90761" translate="yes" xml:space="preserve">
          <source>For training, TensorFlow stores the tensors that are produced in the forward inference and are needed in back propagation. These tensors are a main source of memory consumption and often cause OOM errors when training on GPUs. When the flag swap_memory is true, we swap out these tensors from GPU to CPU. This for example allows us to train RNN models with very long sequences and large batches.</source>
          <target state="translated">在训练中,TensorFlow会存储前向推理中产生的、后向传播中需要的时子。这些时序器是内存消耗的主要来源,在GPU上训练时经常会造成OOM错误。当标志swap_memory为真时,我们就会把这些时序器从GPU换到CPU上。例如,这使得我们可以训练非常长的序列和大批量的RNN模型。</target>
        </trans-unit>
        <trans-unit id="686652c961bb116ce8005add3ae7ed8c5b4c585b" translate="yes" xml:space="preserve">
          <source>For training, sums losses of each head, calls &lt;code&gt;train_op_fn&lt;/code&gt; with this final loss.</source>
          <target state="translated">为了进行训练，将每个头部的损失相加， &lt;code&gt;train_op_fn&lt;/code&gt; 用此最终损失来调用train_op_fn。</target>
        </trans-unit>
        <trans-unit id="c963d2deb9cad268120d3bd485103d985f5495cf" translate="yes" xml:space="preserve">
          <source>For tutorial on the options, see &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md&quot;&gt;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md&lt;/a&gt;</source>
          <target state="translated">有关选项的教程，请参见&lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md&quot;&gt;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="249a8fecba276e5537d5687430c7832f6a097905" translate="yes" xml:space="preserve">
          <source>For tutorial on the options, see https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md</source>
          <target state="translated">有关选项的教程,请参见https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md。</target>
        </trans-unit>
        <trans-unit id="e0250883f7e36fe46e791c49d58341332e74601a" translate="yes" xml:space="preserve">
          <source>For usage example, please see: &lt;a href=&quot;https://www.tensorflow.org/guide/estimators#creating_estimators_from_keras_models&quot;&gt;Creating estimators from Keras Models&lt;/a&gt;.</source>
          <target state="translated">有关使用示例，请参见：&lt;a href=&quot;https://www.tensorflow.org/guide/estimators#creating_estimators_from_keras_models&quot;&gt;从Keras模型创建估算器&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="af78702967e9ea264023f8fbaf663f2a1adc42b5" translate="yes" xml:space="preserve">
          <source>For use with &lt;a href=&quot;ctc_loss&quot;&gt;&lt;code&gt;tf.nn.ctc_loss&lt;/code&gt;&lt;/a&gt; optional argument &lt;code&gt;unique&lt;/code&gt;: This op can be used to preprocess labels in input pipeline to for better speed/memory use computing the ctc loss on TPU.</source>
          <target state="translated">与&lt;a href=&quot;ctc_loss&quot;&gt; &lt;code&gt;tf.nn.ctc_loss&lt;/code&gt; &lt;/a&gt;可选参数 &lt;code&gt;unique&lt;/code&gt; 一起使用：此op可以用于预处理输入管道中的标签，以便在计算TPU上的ctc损失时更好地使用速度/内存。</target>
        </trans-unit>
        <trans-unit id="740b2ee4e4d8bf4808f11e53b605666e73b665e3" translate="yes" xml:space="preserve">
          <source>For variables placed in TPU device, which includes variables created inside TPUStrategy scope, outside compilation logic must not include variable read/write. For variables placed on host, which is the case when variables created via TPUEstimator, variable read/write is only allowed if the variable is not accessed by any other ops in the TPU computation. Variable read/write from outside compilation cluster is not visible from TPU computation and vice versa. Therefore, if outside compilation logic contains such host variables read/write ops and if the variables are accessed by TPU computation as well, then this may lead to deadlock.</source>
          <target state="translated">对于放置在TPU设备中的变量,包括在TPUStrategy范围内创建的变量,外部编译逻辑中不得包含变量读/写。对于放置在主机上的变量,也就是通过TPUEstimator创建的变量时,只有在TPU计算中的其他操作没有访问该变量时,才允许变量读/写。从编译集群外部读/写的变量在TPU计算中是不可见的,反之亦然。因此,如果外部编译逻辑中包含了这样的主机变量读/写操作,如果变量也被TPU计算访问,那么可能会导致死锁。</target>
        </trans-unit>
        <trans-unit id="34cca35024442a2daa7b2b0c02c66c45e14c3cb9" translate="yes" xml:space="preserve">
          <source>For x &amp;lt; 0, to avoid overflow in exp(-x), we reformulate the above</source>
          <target state="translated">对于x &amp;lt;0，为避免exp（-x）溢出，我们将上面的公式重新编写</target>
        </trans-unit>
        <trans-unit id="94cdf994803be6eb936ffe2768c49aa065f6d215" translate="yes" xml:space="preserve">
          <source>For x \in (-inf, inf) =&amp;gt; sigmoid(x) \in (0, 1)</source>
          <target state="translated">对于x \ in（-inf，inf）=&amp;gt; sigmoid（x）\ in（0，1）</target>
        </trans-unit>
        <trans-unit id="8dfe58b9051d5a627bc446c6f93be3012efd4568" translate="yes" xml:space="preserve">
          <source>Forces summary writer to send any buffered data to storage.</source>
          <target state="translated">强制摘要写入器发送任何缓冲数据到存储。</target>
        </trans-unit>
        <trans-unit id="d2dccd3937aceeadad57b5db753b0a63c00ec1a4" translate="yes" xml:space="preserve">
          <source>Format to use for saving sample images (if &lt;code&gt;save_to_dir&lt;/code&gt; is set).</source>
          <target state="translated">用于保存样本图像的格式（如果设置了 &lt;code&gt;save_to_dir&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="f9f17deb03f3afa151a329975529588281686220" translate="yes" xml:space="preserve">
          <source>Formats a string template using a list of tensors, abbreviating tensors by only printing the first and last &lt;code&gt;summarize&lt;/code&gt; elements of each dimension (recursively). If formatting only one tensor into a template, the tensor does not have to be wrapped in a list.</source>
          <target state="translated">使用张量列表格式化字符串模板，并仅通过打印（递归）每个维的第一个和最后一个 &lt;code&gt;summarize&lt;/code&gt; 元素来缩写张量。如果仅将一个张量格式化为模板，则不必将张量包装在列表中。</target>
        </trans-unit>
        <trans-unit id="45da02b6531e4ce47da0f14f7d9b458f2933c3d0" translate="yes" xml:space="preserve">
          <source>Formats a string template using a list of tensors, pretty-printing tensor summaries.</source>
          <target state="translated">使用一个张量列表形成一个字符串模板,漂亮地打印张量摘要。</target>
        </trans-unit>
        <trans-unit id="239f72546128721c29c8c3274ac9f9554ba33807" translate="yes" xml:space="preserve">
          <source>Formats a string template using a list of tensors.</source>
          <target state="translated">使用一个时序列表来形成一个字符串模板。</target>
        </trans-unit>
        <trans-unit id="aab407c990b5dd2317ab563c02f7afc3c37496b1" translate="yes" xml:space="preserve">
          <source>Formats both the test method name and the first line of its docstring.</source>
          <target state="translated">格式化测试方法名称和它的 docstring 的第一行。</target>
        </trans-unit>
        <trans-unit id="30411971a5c7c0c65716d7a2276bc0753edc1090" translate="yes" xml:space="preserve">
          <source>Formatting a multi-tensor template:</source>
          <target state="translated">多张模板的格式化。</target>
        </trans-unit>
        <trans-unit id="8e8e20d914a22b13e7830695a5885972e5f7dd9c" translate="yes" xml:space="preserve">
          <source>Formatting a single-tensor template:</source>
          <target state="translated">格式化单张模板。</target>
        </trans-unit>
        <trans-unit id="8d843afdf2e57d596f25990cb1c437eb7019adc0" translate="yes" xml:space="preserve">
          <source>Formula for calculating sigmoid(x): &lt;code&gt;y = 1 / (1 + exp(-x))&lt;/code&gt;.</source>
          <target state="translated">计算sigmoid（x）的公式： &lt;code&gt;y = 1 / (1 + exp(-x))&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7034cfa1d998a3b54fb5b3c3fa5754f76a68399a" translate="yes" xml:space="preserve">
          <source>Forward and inverse lookup pairs</source>
          <target state="translated">正向和反向查找对</target>
        </trans-unit>
        <trans-unit id="c50d21ebeb5eb1221d5f8c11b87f7e8ba73b2e5f" translate="yes" xml:space="preserve">
          <source>Forward-compatibility refers to scenarios where the producer of a TensorFlow model (a GraphDef or SavedModel) is compiled against a version of the TensorFlow library newer than what the consumer was compiled against. The &quot;producer&quot; is typically a Python program that constructs and trains a model while the &quot;consumer&quot; is typically another program that loads and serves the model.</source>
          <target state="translated">前向兼容性指的是TensorFlow模型的生产者(GraphDef或SavedModel)是针对TensorFlow库的一个新版本编译的,而不是针对消费者编译的。生产者 &quot;通常是一个构建和训练模型的Python程序,而 &quot;消费者 &quot;通常是另一个加载和服务模型的程序。</target>
        </trans-unit>
        <trans-unit id="d85bd4cd5990fd7543a86021751d93d42f1357b3" translate="yes" xml:space="preserve">
          <source>Forwarding the variables from the underlying optimizer.</source>
          <target state="translated">转发底层优化器的变量。</target>
        </trans-unit>
        <trans-unit id="210e7c1722192470315ce4c81eb0d4f008c48b3c" translate="yes" xml:space="preserve">
          <source>Forwards &lt;code&gt;data&lt;/code&gt; to the output port determined by &lt;code&gt;pred&lt;/code&gt;.</source>
          <target state="translated">将 &lt;code&gt;data&lt;/code&gt; 转发到由 &lt;code&gt;pred&lt;/code&gt; 确定的输出端口。</target>
        </trans-unit>
        <trans-unit id="ac10a67355b28b15b67e466f47812ba51acf7c5d" translate="yes" xml:space="preserve">
          <source>Forwards the &lt;code&gt;index&lt;/code&gt;th element of &lt;code&gt;inputs&lt;/code&gt; to &lt;code&gt;output&lt;/code&gt;.</source>
          <target state="translated">将 &lt;code&gt;inputs&lt;/code&gt; 的 &lt;code&gt;index&lt;/code&gt; th元素转发到 &lt;code&gt;output&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6864a45f002f5e6954a15ab9ef9c1a8ff52d9034" translate="yes" xml:space="preserve">
          <source>Forwards the input to the output.</source>
          <target state="translated">将输入转到输出。</target>
        </trans-unit>
        <trans-unit id="c39cbdd42c402f4cd1012035895e06b8964ff7a6" translate="yes" xml:space="preserve">
          <source>Forwards the ref tensor &lt;code&gt;data&lt;/code&gt; to the output port determined by &lt;code&gt;pred&lt;/code&gt;.</source>
          <target state="translated">将参考张量 &lt;code&gt;data&lt;/code&gt; 转发到由 &lt;code&gt;pred&lt;/code&gt; 确定的输出端口。</target>
        </trans-unit>
        <trans-unit id="f39668f24ce7de085f554eebee46e090e3244546" translate="yes" xml:space="preserve">
          <source>Forwards the value of an available tensor from &lt;code&gt;inputs&lt;/code&gt; to &lt;code&gt;output&lt;/code&gt;.</source>
          <target state="translated">将可用张量的值从 &lt;code&gt;inputs&lt;/code&gt; 转发到 &lt;code&gt;output&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6c89a9afa7f5354e4a63edd2e6c0d0b4901dd765" translate="yes" xml:space="preserve">
          <source>Four &lt;code&gt;Tensor&lt;/code&gt; objects of the same type as &lt;code&gt;x&lt;/code&gt;:</source>
          <target state="translated">与 &lt;code&gt;x&lt;/code&gt; 具有相同类型的四个 &lt;code&gt;Tensor&lt;/code&gt; 对象：</target>
        </trans-unit>
        <trans-unit id="0b64e890e12a034b5e89e178fdc9f76c74a27a3b" translate="yes" xml:space="preserve">
          <source>Fractional Max-Pooling: &lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;Graham, 2015&lt;/a&gt; (&lt;a href=&quot;https://arxiv.org/pdf/1412.6071.pdf&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="translated">最大分数池：&lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;格雷厄姆&lt;/a&gt;（Graham），2015（&lt;a href=&quot;https://arxiv.org/pdf/1412.6071.pdf&quot;&gt;pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="40d7d8597b074e3ac7474d10a611c554ad7fa982" translate="yes" xml:space="preserve">
          <source>Fractional average pooling is similar to Fractional max pooling in the pooling region generation step. The only difference is that after pooling regions are generated, a mean operation is performed instead of a max operation in each pooling region.</source>
          <target state="translated">小数平均池与小数最大池在池化区域生成步骤上是相似的。唯一不同的是,在生成集合区域后,对每个集合区域进行平均运算而不是最大运算。</target>
        </trans-unit>
        <trans-unit id="5041cde3f1a2533e4659d2586c2ffe569e1d7dcf" translate="yes" xml:space="preserve">
          <source>Fractional max pooling is slightly different than regular max pooling. In regular max pooling, you downsize an input set by taking the maximum value of smaller N x N subsections of the set (often 2x2), and try to reduce the set by a factor of N, where N is an integer. Fractional max pooling, as you might expect from the word &quot;fractional&quot;, means that the overall reduction ratio N does not have to be an integer.</source>
          <target state="translated">分数最大池与常规最大池略有不同。在常规的最大池化中,您通过取较小的N×N个子集(通常是2x2)的最大值来缩小输入集的大小,并尝试将集缩小一个N的因子,其中N是一个整数。分数最大池化,正如你从 &quot;分数 &quot;这个词中可以预料到的那样,意味着整体的减少比例N不必是一个整数。</target>
        </trans-unit>
        <trans-unit id="cdbefc98aa39ba4bd6f437fe41a59ea0b199db5e" translate="yes" xml:space="preserve">
          <source>FractionalAvgPool</source>
          <target state="translated">FractionalAvgPool</target>
        </trans-unit>
        <trans-unit id="c9267ec6a51ddbb51448594d4c2287cf4c0d1df0" translate="yes" xml:space="preserve">
          <source>FractionalAvgPoolGrad</source>
          <target state="translated">FractionalAvgPoolGrad</target>
        </trans-unit>
        <trans-unit id="0892d35605cdd9bd30150ab584d51683167ecba4" translate="yes" xml:space="preserve">
          <source>FractionalMaxPool</source>
          <target state="translated">FractionalMaxPool</target>
        </trans-unit>
        <trans-unit id="ca1d900edc749abee96c0d0dfa0680048bb9a35a" translate="yes" xml:space="preserve">
          <source>FractionalMaxPoolGrad</source>
          <target state="translated">FractionalMaxPoolGrad</target>
        </trans-unit>
        <trans-unit id="461d49107b929069fa49ed11a5d92526668968dc" translate="yes" xml:space="preserve">
          <source>FresnelCos</source>
          <target state="translated">FresnelCos</target>
        </trans-unit>
        <trans-unit id="555de53bb5c086444e4833777660b765a262a6ca" translate="yes" xml:space="preserve">
          <source>FresnelSin</source>
          <target state="translated">FresnelSin</target>
        </trans-unit>
        <trans-unit id="266f4adbdcbde038a6a989395a6469a033656f5f" translate="yes" xml:space="preserve">
          <source>From &lt;a href=&quot;http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf&quot;&gt;Gers et al., 2002&lt;/a&gt;:</source>
          <target state="translated">根据&lt;a href=&quot;http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf&quot;&gt;Gers等（2002年）&lt;/a&gt;：</target>
        </trans-unit>
        <trans-unit id="bd28230ef13373337ce1949fe5af0d799f846337" translate="yes" xml:space="preserve">
          <source>From &lt;a href=&quot;http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf&quot;&gt;Gers et al.&lt;/a&gt;:</source>
          <target state="translated">来自&lt;a href=&quot;http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf&quot;&gt;Gers等。&lt;/a&gt;：</target>
        </trans-unit>
        <trans-unit id="f121e219c269ca1dd88e0e15be45795cfb78de9b" translate="yes" xml:space="preserve">
          <source>From the specified 'num_bits' in the quantized output type, it determines minimum and maximum representable quantized values.</source>
          <target state="translated">根据量化输出类型中指定的'num_bits',它确定最小和最大的可表示量化值。</target>
        </trans-unit>
        <trans-unit id="4cdba04d7a9eac83a97bc8f1d7ed1afaf3de99f7" translate="yes" xml:space="preserve">
          <source>From these definitions, we see that</source>
          <target state="translated">从这些定义中,我们看到</target>
        </trans-unit>
        <trans-unit id="18752fdccfa3eb0aaa2135e8d0734a1264755927" translate="yes" xml:space="preserve">
          <source>Frozen TensorFlow GraphDef.</source>
          <target state="translated">Frozen TensorFlow GraphDef.</target>
        </trans-unit>
        <trans-unit id="e2b99f0a6d43df651b198f8a6d97f7cd7519e800" translate="yes" xml:space="preserve">
          <source>Full file name path to the checkpoint file.</source>
          <target state="translated">检查点文件的全文件名路径。</target>
        </trans-unit>
        <trans-unit id="90027b2158c0e9bc2fd007d047143a65b064bfe9" translate="yes" xml:space="preserve">
          <source>Full filepath of HDF5 file containing the tf.keras model.</source>
          <target state="translated">包含tf.keras模型的HDF5文件的完整文件路径。</target>
        </trans-unit>
        <trans-unit id="4ce670e0e4234ef3e699470703e6f834ee6fc5d0" translate="yes" xml:space="preserve">
          <source>Full filepath of file containing frozen GraphDef.</source>
          <target state="translated">包含冻结GraphDef的文件的完整文件路径。</target>
        </trans-unit>
        <trans-unit id="1e14411de008f7791c1053dac7870cb082e304ab" translate="yes" xml:space="preserve">
          <source>Full filepath of folder to dump the graphs at various stages of processing GraphViz .dot files. Preferred over --output_format=GRAPHVIZ_DOT in order to keep the requirements of the output file. (default None)</source>
          <target state="translated">在处理GraphViz .dot文件的各个阶段转储图形的文件夹的完整文件路径。优先于--output_format=GRAPHVIZ_DOT,以保持输出文件的要求。(默认为无)</target>
        </trans-unit>
        <trans-unit id="3aca6a2cadbde9796176b9f2bdc4ddaa5883a4b4" translate="yes" xml:space="preserve">
          <source>Fully-connected RNN where the output is to be fed back to input.</source>
          <target state="translated">完全连接的RNN,输出要反馈给输入。</target>
        </trans-unit>
        <trans-unit id="04613c353330a3b030cda37163970b74de725fdc" translate="yes" xml:space="preserve">
          <source>Function builder for a dnn logit_fn.</source>
          <target state="translated">dnn logit_fn的函数构建器。</target>
        </trans-unit>
        <trans-unit id="80bb380683226de01695aa870f90690f020ccf39" translate="yes" xml:space="preserve">
          <source>Function builder for a linear logit_fn.</source>
          <target state="translated">线性logit_fn的函数构建器。</target>
        </trans-unit>
        <trans-unit id="961134f334d4e3d099fd3b88ec79f66049e02609" translate="yes" xml:space="preserve">
          <source>Function corresponding to the input string or input function.</source>
          <target state="translated">与输入字符串或输入函数相对应的函数。</target>
        </trans-unit>
        <trans-unit id="84942f5d7faa1848468aa47bc1832cb4ffceb2fa" translate="yes" xml:space="preserve">
          <source>Function for &lt;code&gt;decode_bmp&lt;/code&gt;, &lt;code&gt;decode_gif&lt;/code&gt;, &lt;code&gt;decode_jpeg&lt;/code&gt;, and &lt;code&gt;decode_png&lt;/code&gt;.</source>
          <target state="translated">的函数 &lt;code&gt;decode_bmp&lt;/code&gt; ， &lt;code&gt;decode_gif&lt;/code&gt; ， &lt;code&gt;decode_jpeg&lt;/code&gt; 和 &lt;code&gt;decode_png&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="572d2bb02e89c8f3847c21f4dc5279a374c3627b" translate="yes" xml:space="preserve">
          <source>Function object.</source>
          <target state="translated">功能对象:</target>
        </trans-unit>
        <trans-unit id="b7e2223c959cab59ba23fe92444da8ee0470dc6a" translate="yes" xml:space="preserve">
          <source>Function or string</source>
          <target state="translated">函数或字符串</target>
        </trans-unit>
        <trans-unit id="3b4e76300f7233d9787f12ee14670f6240ff6bba" translate="yes" xml:space="preserve">
          <source>Function that joins arguments from threads that are given as PerReplica. It accepts &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; object as the first argument.</source>
          <target state="translated">连接来自PerReplica的线程中的参数的函数。它接受&lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;对象作为第一个参数。</target>
        </trans-unit>
        <trans-unit id="3888f1a7f7ad2a4d8e9abf43dddc4f56b91e55d9" translate="yes" xml:space="preserve">
          <source>Function that maps (input, num_spatial_dims, padding) -&amp;gt; output</source>
          <target state="translated">映射（输入，num_spatial_dims，填充）-&amp;gt;输出的函数</target>
        </trans-unit>
        <trans-unit id="29319f13ab18651cfb7537f6a5eddbd79ca1798f" translate="yes" xml:space="preserve">
          <source>Function that takes a scalar loss &lt;code&gt;Tensor&lt;/code&gt; and returns &lt;code&gt;train_op&lt;/code&gt;. Used if &lt;code&gt;optimizer&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">接受标量损失 &lt;code&gt;Tensor&lt;/code&gt; 并返回 &lt;code&gt;train_op&lt;/code&gt; 的函数。如果 &lt;code&gt;optimizer&lt;/code&gt; 为 &lt;code&gt;None&lt;/code&gt; ,则使用此参数。</target>
        </trans-unit>
        <trans-unit id="b91e979c56b6a5a95309b72332456efabd23f242" translate="yes" xml:space="preserve">
          <source>Function that takes a scalar loss &lt;code&gt;Tensor&lt;/code&gt; and returns an op to optimize the model with the loss in TRAIN mode. Used if &lt;code&gt;optimizer&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;. Exactly one of &lt;code&gt;train_op_fn&lt;/code&gt; and &lt;code&gt;optimizer&lt;/code&gt; must be set in TRAIN mode. By default, it is &lt;code&gt;None&lt;/code&gt; in other modes. If you want to optimize loss yourself, you can pass &lt;code&gt;lambda _: tf.no_op()&lt;/code&gt; and then use &lt;a href=&quot;estimatorspec#loss&quot;&gt;&lt;code&gt;EstimatorSpec.loss&lt;/code&gt;&lt;/a&gt; to compute and apply gradients.</source>
          <target state="translated">该函数采用标量损失 &lt;code&gt;Tensor&lt;/code&gt; 并返回一个op，以使用TRAIN模式下的损失优化模型。如果 &lt;code&gt;optimizer&lt;/code&gt; 为 &lt;code&gt;None&lt;/code&gt; ,则使用此参数。必须在TRAIN模式下设置 &lt;code&gt;train_op_fn&lt;/code&gt; 和 &lt;code&gt;optimizer&lt;/code&gt; 之一。默认情况下，在其他模式下为&amp;ldquo; &lt;code&gt;None&lt;/code&gt; 。如果您想自己优化损耗，可以传递 &lt;code&gt;lambda _: tf.no_op()&lt;/code&gt; ，然后使用&lt;a href=&quot;estimatorspec#loss&quot;&gt; &lt;code&gt;EstimatorSpec.loss&lt;/code&gt; &lt;/a&gt;来计算和应用渐变。</target>
        </trans-unit>
        <trans-unit id="8c8c9c9afc68cd4e3a21d1d0883f3c94b166cd76" translate="yes" xml:space="preserve">
          <source>Function to be called and extra positional args.</source>
          <target state="translated">要调用的函数和额外的位置参数。</target>
        </trans-unit>
        <trans-unit id="a9668555814ce219a8e6ead49b464c78c9faea18" translate="yes" xml:space="preserve">
          <source>Function to be called, or None to return a context.</source>
          <target state="translated">要调用的函数,或者None返回一个上下文。</target>
        </trans-unit>
        <trans-unit id="f38de77bb6b57ed6e07c1cd26484aa1832921c19" translate="yes" xml:space="preserve">
          <source>Function to call. Should take the variable as the first argument.</source>
          <target state="translated">要调用的函数。应将变量作为第一个参数。</target>
        </trans-unit>
        <trans-unit id="b46ccb902892f13f107bf66a75f9bf8327cbae4d" translate="yes" xml:space="preserve">
          <source>Function, that has signature of ()-&amp;gt;(dict of &lt;code&gt;features&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;)</source>
          <target state="translated">功能，即具有（签名） - &amp;gt;（的字典 &lt;code&gt;features&lt;/code&gt; ， &lt;code&gt;target&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="52f2894799ccb50c7b33084828e4f3851ea4df75" translate="yes" xml:space="preserve">
          <source>Function, that has signature of ()-&amp;gt;(dict of &lt;code&gt;features&lt;/code&gt;, &lt;code&gt;targets&lt;/code&gt;)</source>
          <target state="translated">功能方面，有）的签名（ - &amp;gt;（的字典 &lt;code&gt;features&lt;/code&gt; ， &lt;code&gt;targets&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="95e988de9fb50a5cd88d6853048b67ed3a399d7b" translate="yes" xml:space="preserve">
          <source>Function. The function created by this method should accept a &lt;a href=&quot;../../data/iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt;, and return a &lt;code&gt;dict&lt;/code&gt; containing values that will be passed to &lt;code&gt;tf.keras.Callbacks.on_test_batch_end&lt;/code&gt;.</source>
          <target state="translated">功能。此方法创建的函数应接受&lt;a href=&quot;../../data/iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;，并返回一个包含将传递到 &lt;code&gt;tf.keras.Callbacks.on_test_batch_end&lt;/code&gt; 的值的 &lt;code&gt;dict&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="327af3c4f94777b37a0d2449a5895e659cad6e23" translate="yes" xml:space="preserve">
          <source>Function. The function created by this method should accept a &lt;a href=&quot;../../data/iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt;, and return a &lt;code&gt;dict&lt;/code&gt; containing values that will be passed to &lt;code&gt;tf.keras.Callbacks.on_train_batch_end&lt;/code&gt;, such as &lt;code&gt;{'loss': 0.2, 'accuracy': 0.7}&lt;/code&gt;.</source>
          <target state="translated">功能。通过此方法创建的函数应接受&lt;a href=&quot;../../data/iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;，并返回一个包含将传递到 &lt;code&gt;tf.keras.Callbacks.on_train_batch_end&lt;/code&gt; 的值的 &lt;code&gt;dict&lt;/code&gt; ，例如 &lt;code&gt;{'loss': 0.2, 'accuracy': 0.7}&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="656c120741d962b4b4cb42d15057a960a5358b5f" translate="yes" xml:space="preserve">
          <source>Function. The function created by this method should accept a &lt;a href=&quot;../../data/iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt;, and return the outputs of the &lt;code&gt;Model&lt;/code&gt;.</source>
          <target state="translated">功能。通过此方法创建的函数应接受&lt;a href=&quot;../../data/iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;，并返回 &lt;code&gt;Model&lt;/code&gt; 的输出。</target>
        </trans-unit>
        <trans-unit id="41d1aa0470499deda211a11de3b081c451856666" translate="yes" xml:space="preserve">
          <source>Function. The function created by this method should accept a &lt;a href=&quot;../data/iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt;, and return a &lt;code&gt;dict&lt;/code&gt; containing values that will be passed to &lt;code&gt;tf.keras.Callbacks.on_test_batch_end&lt;/code&gt;.</source>
          <target state="translated">功能。此方法创建的函数应接受&lt;a href=&quot;../data/iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;，并返回一个包含将传递到 &lt;code&gt;tf.keras.Callbacks.on_test_batch_end&lt;/code&gt; 的值的 &lt;code&gt;dict&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3d2eb314244e720ce4ba2da84d3ecfb8e0c92f66" translate="yes" xml:space="preserve">
          <source>Function. The function created by this method should accept a &lt;a href=&quot;../data/iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt;, and return a &lt;code&gt;dict&lt;/code&gt; containing values that will be passed to &lt;code&gt;tf.keras.Callbacks.on_train_batch_end&lt;/code&gt;, such as &lt;code&gt;{'loss': 0.2, 'accuracy': 0.7}&lt;/code&gt;.</source>
          <target state="translated">功能。通过此方法创建的函数应接受&lt;a href=&quot;../data/iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;，并返回一个包含将传递到 &lt;code&gt;tf.keras.Callbacks.on_train_batch_end&lt;/code&gt; 的值的 &lt;code&gt;dict&lt;/code&gt; ，例如 &lt;code&gt;{'loss': 0.2, 'accuracy': 0.7}&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a8df0a9af5b857d1cf68b6c139f016618d2511fd" translate="yes" xml:space="preserve">
          <source>Function. The function created by this method should accept a &lt;a href=&quot;../data/iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt;, and return the outputs of the &lt;code&gt;Model&lt;/code&gt;.</source>
          <target state="translated">功能。通过此方法创建的函数应接受&lt;a href=&quot;../data/iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;，并返回 &lt;code&gt;Model&lt;/code&gt; 的输出。</target>
        </trans-unit>
        <trans-unit id="fd4d97811c7aafbd87d5d51e0c6c137634e57d76" translate="yes" xml:space="preserve">
          <source>Functional interface for the batch normalization layer from_config(Ioffe et al., 2015). (deprecated)</source>
          <target state="translated">批量归一化层from_config(Ioffe等,2015)的功能接口。(已废弃)</target>
        </trans-unit>
        <trans-unit id="88fcd90125004d28567d342c9f3165809fb40cbc" translate="yes" xml:space="preserve">
          <source>Functional interface for the batch normalization layer. (deprecated)</source>
          <target state="translated">批量归一化层的功能接口。(已废弃)</target>
        </trans-unit>
        <trans-unit id="3008e201e4f95d586e2d708853592636025c56ec" translate="yes" xml:space="preserve">
          <source>Functional interface for the depthwise separable 1D convolution layer. (deprecated)</source>
          <target state="translated">可深度分离的一维卷积层的功能接口。(已废弃)</target>
        </trans-unit>
        <trans-unit id="843524e6eccb65e6f3f97379f7de26c2a2f2da67" translate="yes" xml:space="preserve">
          <source>Functional interface for the depthwise separable 2D convolution layer. (deprecated)</source>
          <target state="translated">可深度分离的2D卷积层的功能接口。(已废弃)</target>
        </trans-unit>
        <trans-unit id="55f27b3100890ca22fc05334143ec1799a0365f4" translate="yes" xml:space="preserve">
          <source>Functional interface for transposed 2D convolution layer. (deprecated)</source>
          <target state="translated">转置二维卷积层的功能接口。(已废弃)</target>
        </trans-unit>
        <trans-unit id="cc0e25ff898bc600b9c3b618d6944b678eac556b" translate="yes" xml:space="preserve">
          <source>Functional interface for transposed 3D convolution layer. (deprecated)</source>
          <target state="translated">转置3D卷积层的功能接口。(已废弃)</target>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="translated">Functions</target>
        </trans-unit>
        <trans-unit id="abc7c3058aaf16961ae99141267b62b102b7362a" translate="yes" xml:space="preserve">
          <source>Functions are converted into new functions with converted code.</source>
          <target state="translated">函数转换为新函数,转换后的代码。</target>
        </trans-unit>
        <trans-unit id="7f53929fbbbf3598a8477b3e21c530968bf2b1e4" translate="yes" xml:space="preserve">
          <source>Functions used to extract and analyze stacks. Faster than Python libs.</source>
          <target state="translated">用于提取和分析堆栈的函数。比Python类库更快。</target>
        </trans-unit>
        <trans-unit id="1088f52ee06b617e019df677ae2d985ea8367ee8" translate="yes" xml:space="preserve">
          <source>Further, each thread starts with an empty variable scope. So if you wish to preserve name prefixes from a scope from the main thread, you should capture the main thread's scope and re-enter it in each thread. For e.g.</source>
          <target state="translated">此外,每个线程都以一个空的变量作用域开始。因此,如果你希望从主线程的作用域中保留名称前缀,你应该捕获主线程的作用域,并在每个线程中重新输入它。例如</target>
        </trans-unit>
        <trans-unit id="17d43e06d288fdecd9a150c3bd7e9213832b2bda" translate="yes" xml:space="preserve">
          <source>Furthermore, &lt;code&gt;fn&lt;/code&gt; may emit a different structure than its input. For example, &lt;code&gt;fn&lt;/code&gt; may look like: &lt;code&gt;fn = lambda t1: return (t1 + 1, t1 - 1)&lt;/code&gt;. In this case, the &lt;code&gt;dtype&lt;/code&gt; parameter is not optional: &lt;code&gt;dtype&lt;/code&gt; must be a type or (possibly nested) tuple of types matching the output of &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="translated">此外， &lt;code&gt;fn&lt;/code&gt; 可能会发出与其输入不同的结构。例如， &lt;code&gt;fn&lt;/code&gt; 可能看起来像： &lt;code&gt;fn = lambda t1: return (t1 + 1, t1 - 1)&lt;/code&gt; 。在这种情况下， &lt;code&gt;dtype&lt;/code&gt; 参数不是可选的： &lt;code&gt;dtype&lt;/code&gt; 必须是与 &lt;code&gt;fn&lt;/code&gt; 的输出匹配的类型或（可能是嵌套的）元组。</target>
        </trans-unit>
        <trans-unit id="8eca057ed1ad79a6c34545db8e733823a73dfbda" translate="yes" xml:space="preserve">
          <source>Furthermore, each component vector of &lt;code&gt;permutation&lt;/code&gt; must be of length &lt;code&gt;N&lt;/code&gt;, containing each of the integers {0, 1, ..., N - 1} exactly once, where &lt;code&gt;N&lt;/code&gt; is the number of rows of each component of the sparse matrix.</source>
          <target state="translated">此外， &lt;code&gt;permutation&lt;/code&gt; 每个分量向量必须具有长度 &lt;code&gt;N&lt;/code&gt; ，其长度恰好包含整数{0，1，...，N-1}中的每个整数一次，其中 &lt;code&gt;N&lt;/code&gt; 是稀疏矩阵的每个分量的行数。</target>
        </trans-unit>
        <trans-unit id="cac9ee53753b3ccba19a58872a949a03e0ed0a6d" translate="yes" xml:space="preserve">
          <source>Fused implementation of &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;batch&lt;/code&gt;. (deprecated)</source>
          <target state="translated">融合实现 &lt;code&gt;map&lt;/code&gt; 和 &lt;code&gt;batch&lt;/code&gt; 。（已弃用）</target>
        </trans-unit>
        <trans-unit id="8fa84725122a287d0cb8f17bda5fbaa9cfd37bea" translate="yes" xml:space="preserve">
          <source>FusedBatchNorm</source>
          <target state="translated">FusedBatchNorm</target>
        </trans-unit>
        <trans-unit id="f7b8da7deea4d0087270a594c3304c5206d3bf77" translate="yes" xml:space="preserve">
          <source>FusedBatchNormGrad</source>
          <target state="translated">FusedBatchNormGrad</target>
        </trans-unit>
        <trans-unit id="ff54a465b3ddf6aad5d7277a2960454bcdf5c7dd" translate="yes" xml:space="preserve">
          <source>FusedBatchNormGradV2</source>
          <target state="translated">FusedBatchNormGradV2</target>
        </trans-unit>
        <trans-unit id="efa2db95230d193fc0b2d1a7dbc258c4dc871a3a" translate="yes" xml:space="preserve">
          <source>FusedBatchNormGradV3</source>
          <target state="translated">FusedBatchNormGradV3</target>
        </trans-unit>
        <trans-unit id="2e082980a698cbd30bfdcc577a828bee3ef142c1" translate="yes" xml:space="preserve">
          <source>FusedBatchNormV2</source>
          <target state="translated">FusedBatchNormV2</target>
        </trans-unit>
        <trans-unit id="d4b44881964c817e28926bb8505ed4b17e43045a" translate="yes" xml:space="preserve">
          <source>FusedBatchNormV3</source>
          <target state="translated">FusedBatchNormV3</target>
        </trans-unit>
        <trans-unit id="9a5938911daebb6a70c3382e959fd759e820951a" translate="yes" xml:space="preserve">
          <source>FusedPadConv2D</source>
          <target state="translated">FusedPadConv2D</target>
        </trans-unit>
        <trans-unit id="a7fee6ae8ac515a2dfd04f006bf80f40a0d24a92" translate="yes" xml:space="preserve">
          <source>FusedResizeAndPadConv2D</source>
          <target state="translated">FusedResizeAndPadConv2D</target>
        </trans-unit>
        <trans-unit id="754a365f8fd6b9ceb366bc46267e7e7fae2e01b8" translate="yes" xml:space="preserve">
          <source>Future major versions of TensorFlow will allow gradients to flow into the labels input on backprop by default.</source>
          <target state="translated">TensorFlow未来的主要版本将默认允许梯度流进backprop上输入的标签。</target>
        </trans-unit>
        <trans-unit id="7dbebb53731d118027dc401234e5639569fa8c60" translate="yes" xml:space="preserve">
          <source>Fuzz factor.</source>
          <target state="translated">模糊因素。</target>
        </trans-unit>
        <trans-unit id="72267a6e30d52b94f9b577c3333196adb57b047d" translate="yes" xml:space="preserve">
          <source>GCE Credentials. If None, then we use default credentials from the oauth2client</source>
          <target state="translated">GCE证书。如果为 &quot;无&quot;,则使用oauth2client中的默认凭证。</target>
        </trans-unit>
        <trans-unit id="8ad91e9a8f5cd85998e81a80a35e120f1cc77d99" translate="yes" xml:space="preserve">
          <source>GCE Credentials. If nothing is specified, this defaults to GoogleCredentials.get_application_default().</source>
          <target state="translated">GCE Credentials.get_application_default()。如果没有指定任何内容,默认为GoogleCredentials.get_application_default()。</target>
        </trans-unit>
        <trans-unit id="51e841ad3b27b555240bd3208409784776b78d91" translate="yes" xml:space="preserve">
          <source>GIF images with frame or transparency compression are not supported. On Linux and MacOS systems, convert animated GIFs from compressed to uncompressed by running:</source>
          <target state="translated">不支持带有帧或透明度压缩的GIF图像。在Linux和MacOS系统上,通过运行以下程序将动画GIF从压缩转换为非压缩。</target>
        </trans-unit>
        <trans-unit id="9bcfc99bed88388ab08e19e25125b8df695b2ec4" translate="yes" xml:space="preserve">
          <source>GNU style allows mixing of flag and non-flag arguments. See &lt;a href=&quot;http://docs.python.org/library/getopt.html#getopt.gnu_getopt&quot;&gt;http://docs.python.org/library/getopt.html#getopt.gnu_getopt&lt;/a&gt;</source>
          <target state="translated">GNU样式允许将标志和非标志参数混合使用。请参阅&lt;a href=&quot;http://docs.python.org/library/getopt.html#getopt.gnu_getopt&quot;&gt;http://docs.python.org/library/getopt.html#getopt.gnu_getopt&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="50722eace7871bd3272fd82573850bdf2c8a1820" translate="yes" xml:space="preserve">
          <source>GNU style allows mixing of flag and non-flag arguments. See &lt;a href=&quot;https://docs.python.org/library/getopt.html#getopt.gnu_getopt&quot;&gt;http://docs.python.org/library/getopt.html#getopt.gnu_getopt&lt;/a&gt;</source>
          <target state="translated">GNU样式允许将标志和非标志参数混合使用。请参阅&lt;a href=&quot;https://docs.python.org/library/getopt.html#getopt.gnu_getopt&quot;&gt;http://docs.python.org/library/getopt.html#getopt.gnu_getopt&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bc2cb7021c13ea83cc3e049d7402c76b692e0416" translate="yes" xml:space="preserve">
          <source>GNU style allows mixing of flag and non-flag arguments. See http://docs.python.org/library/getopt.html#getopt.gnu_getopt</source>
          <target state="translated">GNU风格允许混合使用标志和非标志参数。参见http://docs.python.org/library/getopt.html#getopt.gnu_getopt</target>
        </trans-unit>
        <trans-unit id="f972014286a8ef98413380743e0166a16182293b" translate="yes" xml:space="preserve">
          <source>GRU convention (whether to apply reset gate after or before matrix multiplication). False = &quot;before&quot; (default), True = &quot;after&quot; (CuDNN compatible).</source>
          <target state="translated">GRU惯例(在矩阵乘法之后还是之前应用复位门)。False=&quot;之前&quot;(默认),True=&quot;之后&quot;(与CuDNN兼容)。</target>
        </trans-unit>
        <trans-unit id="f30369db80b8df66e066857b52ef066913f216c1" translate="yes" xml:space="preserve">
          <source>GRU convention (whether to apply reset gate after or before matrix multiplication). False = &quot;before&quot;, True = &quot;after&quot; (default and CuDNN compatible).</source>
          <target state="translated">GRU惯例(在矩阵乘法之后还是之前应用复位门)。False=&quot;之前&quot;,True=&quot;之后&quot;(默认和CuDNN兼容)。</target>
        </trans-unit>
        <trans-unit id="f27a3272df11e6421ae7abecb1025fb3c735f83f" translate="yes" xml:space="preserve">
          <source>GRUBlockCell</source>
          <target state="translated">GRUBlockCell</target>
        </trans-unit>
        <trans-unit id="8fb826d8ab1769785d7dd590b317670658d293c0" translate="yes" xml:space="preserve">
          <source>GRUBlockCellGrad</source>
          <target state="translated">GRUBlockCellGrad</target>
        </trans-unit>
        <trans-unit id="3c8a873ea949d50ad1aac033a294a578fd5c4e69" translate="yes" xml:space="preserve">
          <source>Gamma distribution.</source>
          <target state="translated">伽马分布。</target>
        </trans-unit>
        <trans-unit id="9f031510b482abd8e720846e8669696f7e91ec56" translate="yes" xml:space="preserve">
          <source>Gated Recurrent Unit - Cho et al. 2014.</source>
          <target state="translated">Gated Recurrent Unit-Cho et al.2014.</target>
        </trans-unit>
        <trans-unit id="69e499dfe689408aae1f951c32b8c1bbc6c2faf0" translate="yes" xml:space="preserve">
          <source>Gated Recurrent Unit cell (cf.</source>
          <target state="translated">门控复式单元格(比照)。</target>
        </trans-unit>
        <trans-unit id="705812755333cca60e8bb82127bf5e243f85b469" translate="yes" xml:space="preserve">
          <source>Gated Recurrent Unit cell.</source>
          <target state="translated">门的复式单元格。</target>
        </trans-unit>
        <trans-unit id="d85fb4eb9b5275137b92e9c14d3dd2b6f13641af" translate="yes" xml:space="preserve">
          <source>Gather</source>
          <target state="translated">Gather</target>
        </trans-unit>
        <trans-unit id="60f8851e1dff47acde3e681a835a618b6909d153" translate="yes" xml:space="preserve">
          <source>Gather ragged slices from &lt;code&gt;params&lt;/code&gt; axis &lt;code&gt;0&lt;/code&gt; according to &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="translated">根据 &lt;code&gt;indices&lt;/code&gt; 从 &lt;code&gt;params&lt;/code&gt; 轴 &lt;code&gt;0&lt;/code&gt; 收集参差不齐的切片。</target>
        </trans-unit>
        <trans-unit id="8b3a55dbaf071c80cf233d7df7f2695129eb5aa3" translate="yes" xml:space="preserve">
          <source>Gather slices from &lt;code&gt;params&lt;/code&gt; according to &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="translated">根据 &lt;code&gt;indices&lt;/code&gt; 从 &lt;code&gt;params&lt;/code&gt; 收集切片。</target>
        </trans-unit>
        <trans-unit id="c659ab9d2af864152ee3bccc51bb3c0d68f7ab80" translate="yes" xml:space="preserve">
          <source>Gather slices from &lt;code&gt;params&lt;/code&gt; axis &lt;code&gt;axis&lt;/code&gt; according to &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="translated">从收集切片 &lt;code&gt;params&lt;/code&gt; 轴 &lt;code&gt;axis&lt;/code&gt; 根据 &lt;code&gt;indices&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3d20e4a3a201cb2fbb73307001cac40611d72da6" translate="yes" xml:space="preserve">
          <source>Gather slices from &lt;code&gt;params&lt;/code&gt; into a Tensor with shape specified by &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="translated">从 &lt;code&gt;params&lt;/code&gt; 切片到张量的张量，形状由 &lt;code&gt;indices&lt;/code&gt; 指定。</target>
        </trans-unit>
        <trans-unit id="299d0ae5001a60c54f445823747df39bdc8fe265" translate="yes" xml:space="preserve">
          <source>Gather slices from params according to indices with leading batch dims. (deprecated)</source>
          <target state="translated">根据具有领先的批次dim的指数从参数中收集切片。(已废弃)</target>
        </trans-unit>
        <trans-unit id="f262790bfae9447f613388f0f2dfc06ee3e6e9af" translate="yes" xml:space="preserve">
          <source>Gather slices from params axis &lt;code&gt;axis&lt;/code&gt; according to &lt;code&gt;indices&lt;/code&gt;. &lt;code&gt;indices&lt;/code&gt; must be an integer tensor of any dimension (usually 0-D or 1-D).</source>
          <target state="translated">从PARAMS轴收集切片 &lt;code&gt;axis&lt;/code&gt; 根据 &lt;code&gt;indices&lt;/code&gt; 。 &lt;code&gt;indices&lt;/code&gt; 必须是任意维度的整数张量（通常为0-D或1-D）。</target>
        </trans-unit>
        <trans-unit id="9f385f50f48df2546a7fa47ac7842fb6cb974b02" translate="yes" xml:space="preserve">
          <source>Gather slices from params axis &lt;code&gt;axis&lt;/code&gt; according to indices.</source>
          <target state="translated">根据索引从参数轴 &lt;code&gt;axis&lt;/code&gt; 收集切片。</target>
        </trans-unit>
        <trans-unit id="e17db4db1be26624736cd7163c7e0a82b1dfd230" translate="yes" xml:space="preserve">
          <source>Gather slices from params axis axis according to indices.</source>
          <target state="translated">根据指数从params轴线上收集切片。</target>
        </trans-unit>
        <trans-unit id="73d587e4f9866c119bef7eb8951aad10a8ad7680" translate="yes" xml:space="preserve">
          <source>Gather slices from the variable pointed to by &lt;code&gt;resource&lt;/code&gt; according to &lt;code&gt;indices&lt;/code&gt;.</source>
          <target state="translated">根据 &lt;code&gt;indices&lt;/code&gt; 从 &lt;code&gt;resource&lt;/code&gt; 指向的变量中收集切片。</target>
        </trans-unit>
        <trans-unit id="9bc621ab1a08f4a178453d70596dcee1791211d7" translate="yes" xml:space="preserve">
          <source>Gather specific elements from the TensorArray into output &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">将TensorArray中的特定元素收集到输出 &lt;code&gt;value&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d75d7d6f79f6c643b60649fcc6961cd4aaf7d3ff" translate="yes" xml:space="preserve">
          <source>GatherNd</source>
          <target state="translated">GatherNd</target>
        </trans-unit>
        <trans-unit id="9bb2e60bbbfd1cff13478f3217fccff50b488e00" translate="yes" xml:space="preserve">
          <source>GatherV2</source>
          <target state="translated">GatherV2</target>
        </trans-unit>
        <trans-unit id="1b380773b6f24a5afe663b7e22de6423bb935598" translate="yes" xml:space="preserve">
          <source>Gating Gradients</source>
          <target state="translated">门控梯度</target>
        </trans-unit>
        <trans-unit id="44813df257901f45ff9b654c8ba3ddd39d5df9b6" translate="yes" xml:space="preserve">
          <source>Gaussian: &lt;code&gt;K(x, y) == exp(- square(x - y) / (2 * square(scale)))&lt;/code&gt;</source>
          <target state="translated">高斯： &lt;code&gt;K(x, y) == exp(- square(x - y) / (2 * square(scale)))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f72dabec415cca8805069ec0515ea199976c6048" translate="yes" xml:space="preserve">
          <source>General case:</source>
          <target state="translated">一般案件:</target>
        </trans-unit>
        <trans-unit id="6368188d3687992a62f99d6b7334f52aaac43948" translate="yes" xml:space="preserve">
          <source>Generalization of &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt; to axis different than 0. (deprecated)</source>
          <target state="translated">将&lt;a href=&quot;scatter_update&quot;&gt; &lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt; 泛化&lt;/a&gt;为不同于0的轴。（不建议使用）</target>
        </trans-unit>
        <trans-unit id="eb11ae4a716352e80393f10cd2fbf3c5ef996fc6" translate="yes" xml:space="preserve">
          <source>Generally a single example in training data is described with FeatureColumns. At the first layer of the model, this column oriented data should be converted to a single &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">通常，使用FeatureColumns描述一个训练数据示例。在模型的第一层，此面向列的数据应转换为单个 &lt;code&gt;Tensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7c63e0117b37d1fc0d3a2fdf6f89aed5b55248ac" translate="yes" xml:space="preserve">
          <source>Generally a single example in training data is described with FeatureColumns. At the first layer of the model, this column-oriented data should be converted to a single &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">通常，使用FeatureColumns描述训练数据中的一个示例。在模型的第一层，应将此面向列的数据转换为单个 &lt;code&gt;Tensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8de3a173a70a93846ce03fd16984e4335207f7a1" translate="yes" xml:space="preserve">
          <source>Generally it is best if the shard operator is used early in the dataset pipeline. For example, when reading from a set of TFRecord files, shard before converting the dataset to input samples. This avoids reading every file on every worker. The following is an example of an efficient sharding strategy within a complete pipeline:</source>
          <target state="translated">一般来说,最好在数据集流水线的早期使用shard操作符。例如,当从一组TFRecord文件中读取时,在将数据集转换为输入样本之前先进行shard操作。这样可以避免在每个worker上读取每个文件。下面是一个在完整流水线中高效分片策略的例子。</target>
        </trans-unit>
        <trans-unit id="e2dd4981d0a29e58e9fcc5b1a49943c316b64754" translate="yes" xml:space="preserve">
          <source>Generate a &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.kaiser.html&quot;&gt;Kaiser window&lt;/a&gt;.</source>
          <target state="translated">生成一个&lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.kaiser.html&quot;&gt;Kaiser窗口&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="90b4629b3e84cf9ddd69d1cfdd41ef3ba86e8a84" translate="yes" xml:space="preserve">
          <source>Generate a &lt;a href=&quot;https://en.wikipedia.org/wiki/Kaiser_window#Kaiser%E2%80%93Bessel-derived_(KBD)_window&quot;&gt;Kaiser Bessel derived window&lt;/a&gt;.</source>
          <target state="translated">生成&lt;a href=&quot;https://en.wikipedia.org/wiki/Kaiser_window#Kaiser%E2%80%93Bessel-derived_(KBD)_window&quot;&gt;Kaiser Bessel派生窗口&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="11d7cd9f12caac64f12dc084266511c05d1e68e5" translate="yes" xml:space="preserve">
          <source>Generate a &lt;a href=&quot;https://en.wikipedia.org/wiki/Modified_discrete_cosine_transform#Window_functions&quot;&gt;Vorbis power complementary window&lt;/a&gt;.</source>
          <target state="translated">生成&lt;a href=&quot;https://en.wikipedia.org/wiki/Modified_discrete_cosine_transform#Window_functions&quot;&gt;Vorbis功率互补窗口&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="34347d3edc6f1c3feaba292295a44f85ae9283b4" translate="yes" xml:space="preserve">
          <source>Generate a &lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows&quot;&gt;Hamming&lt;/a&gt; window.</source>
          <target state="translated">生成一个&lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows&quot;&gt;汉明&lt;/a&gt;窗。</target>
        </trans-unit>
        <trans-unit id="279c13b7205ad932f6fc77bc4c11a570af2e0643" translate="yes" xml:space="preserve">
          <source>Generate a &lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows&quot;&gt;Hann window&lt;/a&gt;.</source>
          <target state="translated">生成一个&lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows&quot;&gt;Hann窗口&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ac32a415109d1780683dc87c835b4bf44b9e214f" translate="yes" xml:space="preserve">
          <source>Generate a SignatureDef proto for inclusion in a MetaGraphDef.</source>
          <target state="translated">生成一个SignatureDef proto,以便包含在MetaGraphDef中。</target>
        </trans-unit>
        <trans-unit id="c002c4b3ce23a9d11b517e557ca82ee3b02cef6f" translate="yes" xml:space="preserve">
          <source>Generate a glob pattern matching all sharded file names.</source>
          <target state="translated">生成一个匹配所有碎片文件名的glob模式。</target>
        </trans-unit>
        <trans-unit id="2b79e30cedbd9d694f0b8690f5c2126451ebafb1" translate="yes" xml:space="preserve">
          <source>Generate a pprof profile gzip file.</source>
          <target state="translated">生成一个pprof配置文件gzip文件。</target>
        </trans-unit>
        <trans-unit id="ffe3bd416f54a13ea7f1d20611db6869a2732c01" translate="yes" xml:space="preserve">
          <source>Generate a sharded filename. The filename is printf formatted as</source>
          <target state="translated">生成一个碎片文件名。文件名的打印格式为</target>
        </trans-unit>
        <trans-unit id="a1371c069157738d08a42f8452b9b9196d90ec61" translate="yes" xml:space="preserve">
          <source>Generate a single randomly distorted bounding box for an image.</source>
          <target state="translated">为图像生成一个随机扭曲的边界框。</target>
        </trans-unit>
        <trans-unit id="ac024cfebf615ec9550fa9639992f999e3b2ee72" translate="yes" xml:space="preserve">
          <source>Generate a single randomly distorted bounding box for an image. (deprecated)</source>
          <target state="translated">为图像生成一个随机扭曲的边界框。(已废弃)</target>
        </trans-unit>
        <trans-unit id="a513f309f426925500e16fda01716dda1ec01c9d" translate="yes" xml:space="preserve">
          <source>Generate a timeline json file.</source>
          <target state="translated">生成一个时间轴json文件。</target>
        </trans-unit>
        <trans-unit id="a4b61b9eadd182e79e8d7ca8f5436072061f5cd0" translate="yes" xml:space="preserve">
          <source>Generate batches of tensor image data with real-time data augmentation.</source>
          <target state="translated">通过实时数据增强生成批量的张量图像数据。</target>
        </trans-unit>
        <trans-unit id="8e985d2b987cc5cfe48af402ebd8ddad192ec795" translate="yes" xml:space="preserve">
          <source>Generate bounding box proposals from encoded bounding boxes.</source>
          <target state="translated">从编码的界框中生成界框建议。</target>
        </trans-unit>
        <trans-unit id="c0ad06dc54e9b19d8f565750f7f75ca4b2cfa07b" translate="yes" xml:space="preserve">
          <source>Generate class predictions for the input samples.</source>
          <target state="translated">为输入样本生成类预测。</target>
        </trans-unit>
        <trans-unit id="e88196696cce2f195fee6d21c523e69e11454eb0" translate="yes" xml:space="preserve">
          <source>Generate class predictions for the input samples. (deprecated)</source>
          <target state="translated">为输入样本生成类预测。(已废弃)</target>
        </trans-unit>
        <trans-unit id="a7093df80f13988f753b4ffb41362fefaef5f111" translate="yes" xml:space="preserve">
          <source>Generate samples of the specified shape.</source>
          <target state="translated">生成指定形状的样品。</target>
        </trans-unit>
        <trans-unit id="576d0866bf17ce5f09b194820a38f8952d6e4b06" translate="yes" xml:space="preserve">
          <source>Generate the bucket boundaries for each feature based on accumulated summaries.</source>
          <target state="translated">根据积累的总结,生成每个特征的桶边界。</target>
        </trans-unit>
        <trans-unit id="9e9203d473bfc408cbd4f794fe904486104787f9" translate="yes" xml:space="preserve">
          <source>Generate the set of all classes.</source>
          <target state="translated">生成所有类的集合。</target>
        </trans-unit>
        <trans-unit id="23f698bd99350dfeeb28f80c4b7d56c43289deab" translate="yes" xml:space="preserve">
          <source>GenerateBoundingBoxProposals</source>
          <target state="translated">GenerateBoundingBoxProposals</target>
        </trans-unit>
        <trans-unit id="3b1c4b8d98e609c7742c5fa5ed5d888e187de455" translate="yes" xml:space="preserve">
          <source>GenerateVocabRemapping</source>
          <target state="translated">GenerateVocabRemapping</target>
        </trans-unit>
        <trans-unit id="dd09a6e5d58951f89fcc802fecad98e6223e4700" translate="yes" xml:space="preserve">
          <source>Generates &lt;a href=&quot;../distributedvalues&quot;&gt;&lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt;&lt;/a&gt; from &lt;code&gt;value_fn&lt;/code&gt;.</source>
          <target state="translated">生成&lt;a href=&quot;../distributedvalues&quot;&gt; &lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt; &lt;/a&gt;从 &lt;code&gt;value_fn&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9836cccd1541d8044f475f870ee2ee77b1a6027f" translate="yes" xml:space="preserve">
          <source>Generates &lt;a href=&quot;distributedvalues&quot;&gt;&lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt;&lt;/a&gt; from &lt;code&gt;value_fn&lt;/code&gt;.</source>
          <target state="translated">生成&lt;a href=&quot;distributedvalues&quot;&gt; &lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt; &lt;/a&gt;从 &lt;code&gt;value_fn&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f43bcd2870c5432e0a747c0e7e61691f6c6d69d4" translate="yes" xml:space="preserve">
          <source>Generates a &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; from image files in a directory.</source>
          <target state="translated">从目录中的图像文件生成&lt;a href=&quot;../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6f6d1ff08babf239e90da6e16be908dfc487e187" translate="yes" xml:space="preserve">
          <source>Generates a &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; from text files in a directory.</source>
          <target state="translated">从目录中的文本文件生成&lt;a href=&quot;../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="377bb61844f7989feb179e9255bc056adafe1698" translate="yes" xml:space="preserve">
          <source>Generates a &lt;code&gt;SaverDef&lt;/code&gt; representation of this saver.</source>
          <target state="translated">生成此保护程序的 &lt;code&gt;SaverDef&lt;/code&gt; 表示形式。</target>
        </trans-unit>
        <trans-unit id="ebd6ec5178119ea6a1811d87dd13d57c9a6db943" translate="yes" xml:space="preserve">
          <source>Generates a MultiDeviceIterator resource from its provided string handle.</source>
          <target state="translated">从它提供的字符串句柄中生成一个MultiDeviceIterator资源。</target>
        </trans-unit>
        <trans-unit id="45ca970a93e98f0a96c6dd41425b7de72d75abbf" translate="yes" xml:space="preserve">
          <source>Generates a checkpoint state proto.</source>
          <target state="translated">生成一个检查点状态原件。</target>
        </trans-unit>
        <trans-unit id="2af4bf65e2bb4f1d1dd68fd49dd2b53aac1939ec" translate="yes" xml:space="preserve">
          <source>Generates a feature cross from a list of tensors, and returns it as a</source>
          <target state="translated">从Tensors列表中生成一个特征交叉,并以一个</target>
        </trans-unit>
        <trans-unit id="825f6429255ba775713386b0d2f3a17166359e07" translate="yes" xml:space="preserve">
          <source>Generates a window function that can be used in &lt;code&gt;inverse_stft&lt;/code&gt;.</source>
          <target state="translated">生成可在 &lt;code&gt;inverse_stft&lt;/code&gt; 中使用的窗口函数。</target>
        </trans-unit>
        <trans-unit id="47b0fd38944f765d01ecdf4f5dde5c9129216b79" translate="yes" xml:space="preserve">
          <source>Generates a word rank-based probabilistic sampling table.</source>
          <target state="translated">生成一个基于词秩的概率抽样表。</target>
        </trans-unit>
        <trans-unit id="1eaf3ef20aca17d2ddd855b709da877935b5c644" translate="yes" xml:space="preserve">
          <source>Generates class probability predictions for the input samples.</source>
          <target state="translated">生成输入样本的类概率预测。</target>
        </trans-unit>
        <trans-unit id="acbdf4f7e996764e39f5a1d460a1590720b7ffed" translate="yes" xml:space="preserve">
          <source>Generates class probability predictions for the input samples. (deprecated)</source>
          <target state="translated">为输入样本生成类概率预测。(已废弃)</target>
        </trans-unit>
        <trans-unit id="649bbae2e63ab9a653a1bbb3ef6140122196b569" translate="yes" xml:space="preserve">
          <source>Generates evenly-spaced values in an interval along a given axis.</source>
          <target state="translated">在给定的轴线上生成间隔均匀的数值。</target>
        </trans-unit>
        <trans-unit id="12a10bcf16b64dd9017853e6b82862f0dc5c5e73" translate="yes" xml:space="preserve">
          <source>Generates feature cross from a list of tensors.</source>
          <target state="translated">从Tensors列表中生成特征交叉。</target>
        </trans-unit>
        <trans-unit id="c2e65b80cc8c5def122f20b61b5d83b821ccc7ce" translate="yes" xml:space="preserve">
          <source>Generates fingerprint values of &lt;code&gt;data&lt;/code&gt;.</source>
          <target state="translated">生成 &lt;code&gt;data&lt;/code&gt; 指纹值。</target>
        </trans-unit>
        <trans-unit id="e89a59f26ad8f607008d022c7aae25b086f3ec9e" translate="yes" xml:space="preserve">
          <source>Generates fingerprint values.</source>
          <target state="translated">生成指纹值。</target>
        </trans-unit>
        <trans-unit id="dbdf2df393e7c5b28c8c46b716424d6d5f6d05e3" translate="yes" xml:space="preserve">
          <source>Generates hashed feature cross from a list of tensors.</source>
          <target state="translated">从Tensors列表中生成哈希特征交叉。</target>
        </trans-unit>
        <trans-unit id="ecd2cd43082dd2fa1d698670c924b8a9339f3115" translate="yes" xml:space="preserve">
          <source>Generates hashed sparse cross from a list of sparse and dense tensors.</source>
          <target state="translated">从稀疏和密集时序列表中生成哈希稀疏交叉。</target>
        </trans-unit>
        <trans-unit id="39625478ffa83ceceb283552bff4daf578ea3d67" translate="yes" xml:space="preserve">
          <source>Generates labels for candidate sampling with a learned unigram distribution.</source>
          <target state="translated">用学习到的unigram分布为候选样本生成标签。</target>
        </trans-unit>
        <trans-unit id="494f1bcb0d30b701f7c55dd7dbcf0c95bbc04be8" translate="yes" xml:space="preserve">
          <source>Generates labels for candidate sampling with a log-uniform distribution.</source>
          <target state="translated">为具有对数均匀分布的候选样本生成标签。</target>
        </trans-unit>
        <trans-unit id="4d38f8146d8f4aa0acc79c3ad874070501094862" translate="yes" xml:space="preserve">
          <source>Generates labels for candidate sampling with a uniform distribution.</source>
          <target state="translated">为统一分布的候选人抽样生成标签。</target>
        </trans-unit>
        <trans-unit id="d830604723f094db9bc24fb88a7e02736a2c3056" translate="yes" xml:space="preserve">
          <source>Generates output predictions for the input samples.</source>
          <target state="translated">生成输入样本的输出预测。</target>
        </trans-unit>
        <trans-unit id="b249d65bf0f914d4110d91f913e1300c01aa2889" translate="yes" xml:space="preserve">
          <source>Generates parsing spec for tf.parse_example to be used with classifiers.</source>
          <target state="translated">生成tf.parse_example的解析规范,用于分类器。</target>
        </trans-unit>
        <trans-unit id="1aae58a59256b1fc205171c419f649a6e0c1ac2c" translate="yes" xml:space="preserve">
          <source>Generates parsing spec for tf.parse_example to be used with regressors.</source>
          <target state="translated">为 tf.parse_example 生成解析规范,以便与回归器一起使用。</target>
        </trans-unit>
        <trans-unit id="7d0f6811f98e9f7451ddd47d27cbbd2d502a54ba" translate="yes" xml:space="preserve">
          <source>Generates points from the Sobol sequence.</source>
          <target state="translated">从Sobol序列生成点。</target>
        </trans-unit>
        <trans-unit id="a2df3b2c3bfd14ecb54ef8d497e84f89bbccb46c" translate="yes" xml:space="preserve">
          <source>Generates predictions for the input samples from a data generator. (deprecated)</source>
          <target state="translated">从数据生成器中生成输入样本的预测。(已废弃)</target>
        </trans-unit>
        <trans-unit id="f0b782326dc1552a60227a419a223dd58df3f275" translate="yes" xml:space="preserve">
          <source>Generates random parameters for a transformation.</source>
          <target state="translated">为变换生成随机参数。</target>
        </trans-unit>
        <trans-unit id="29c08e7ff9dc1d9fd5830b7df9e2c9f201d13165" translate="yes" xml:space="preserve">
          <source>Generates seeds for stateless random ops.</source>
          <target state="translated">生成无状态随机操作的种子。</target>
        </trans-unit>
        <trans-unit id="929055b21af18b1410a5ef9e6f627e2fe967eded" translate="yes" xml:space="preserve">
          <source>Generates skipgram word pairs.</source>
          <target state="translated">生成skipgram词对。</target>
        </trans-unit>
        <trans-unit id="c717f055df49ec5bd1aa8121ba707a81fd38bcab" translate="yes" xml:space="preserve">
          <source>Generates sparse cross from a list of sparse and dense tensors.</source>
          <target state="translated">从一个稀疏和密集的时序列表中生成稀疏交叉。</target>
        </trans-unit>
        <trans-unit id="eee7e06216ccc809aac0d41b4d65812d7279baab" translate="yes" xml:space="preserve">
          <source>Generates the RaggedTensor &lt;code&gt;row_splits&lt;/code&gt; corresponding to a segmentation.</source>
          <target state="translated">生成与分段对应的RaggedTensor &lt;code&gt;row_splits&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9c8ebc23fb3d11a9fa1612cc64fdaa5515b59f5b" translate="yes" xml:space="preserve">
          <source>Generates the segmentation corresponding to a RaggedTensor &lt;code&gt;row_splits&lt;/code&gt;.</source>
          <target state="translated">生成与RaggedTensor &lt;code&gt;row_splits&lt;/code&gt; 对应的分段。</target>
        </trans-unit>
        <trans-unit id="847054fadb60634ee2f52424f471fb76a80ae831" translate="yes" xml:space="preserve">
          <source>Generates values in an interval.</source>
          <target state="translated">在一个区间内生成数值。</target>
        </trans-unit>
        <trans-unit id="f83f1b24a7b8176a12bbd8754dc347723cff3a26" translate="yes" xml:space="preserve">
          <source>GeneratorDataset</source>
          <target state="translated">GeneratorDataset</target>
        </trans-unit>
        <trans-unit id="dd2f789a1badf7c47aa6e96fdc59fb1ae83e7fe2" translate="yes" xml:space="preserve">
          <source>Generic entry point script.</source>
          <target state="translated">通用入口点脚本。</target>
        </trans-unit>
        <trans-unit id="2c95b2ae6664568cd6a269ff2188bf2127d2b537" translate="yes" xml:space="preserve">
          <source>Get a dictionary describing TensorFlow's build environment.</source>
          <target state="translated">获取一个描述TensorFlow构建环境的字典。</target>
        </trans-unit>
        <trans-unit id="0d7e04da7f8fb8474d86e3fc36734ea9ac641c99" translate="yes" xml:space="preserve">
          <source>Get a direct path to the data files colocated with the script.</source>
          <target state="translated">获取与脚本一起存放的数据文件的直接路径。</target>
        </trans-unit>
        <trans-unit id="25e90702cc2a6266a80ebe5d73070c2394a2d997" translate="yes" xml:space="preserve">
          <source>Get a partitioner for VariableScope to keep shards below &lt;code&gt;max_shard_bytes&lt;/code&gt;.</source>
          <target state="translated">获取VariableScope的分区程序，以使碎片保持在 &lt;code&gt;max_shard_bytes&lt;/code&gt; 以下。</target>
        </trans-unit>
        <trans-unit id="59040295d5cb452ad25fbe2e72127aba826b97ef" translate="yes" xml:space="preserve">
          <source>Get a root directory containing all the data attributes in the build rule.</source>
          <target state="translated">获取一个包含构建规则中所有数据属性的根目录。</target>
        </trans-unit>
        <trans-unit id="bb88a5384f5bc20bdadfdbaa3c133110e4b6085f" translate="yes" xml:space="preserve">
          <source>Get experimental optimizer options.</source>
          <target state="translated">获得实验性的优化器选项。</target>
        </trans-unit>
        <trans-unit id="a2113882a890fee2c46d1a70f2c5138bd06f0eb7" translate="yes" xml:space="preserve">
          <source>Get from cache or create a default operation.</source>
          <target state="translated">从缓存中获取或创建一个默认操作。</target>
        </trans-unit>
        <trans-unit id="b670781c96420a037469ad0934765b418deb4d2f" translate="yes" xml:space="preserve">
          <source>Get if JIT compilation is enabled.</source>
          <target state="translated">获取是否启用JIT编译。</target>
        </trans-unit>
        <trans-unit id="69a0067636164f576df746229abb6b9aaceb5ae6" translate="yes" xml:space="preserve">
          <source>Get if device placements are logged.</source>
          <target state="translated">获取设备放置是否被记录。</target>
        </trans-unit>
        <trans-unit id="498721b0192fabfcd02ce495785bf7613c9f7cee" translate="yes" xml:space="preserve">
          <source>Get if memory growth is enabled for a &lt;code&gt;PhysicalDevice&lt;/code&gt;.</source>
          <target state="translated">获取是否为 &lt;code&gt;PhysicalDevice&lt;/code&gt; 启用了内存增长。</target>
        </trans-unit>
        <trans-unit id="58ef7dbc31c00f8af4807e08acd0430c855e1d84" translate="yes" xml:space="preserve">
          <source>Get if soft device placement is enabled.</source>
          <target state="translated">获取是否启用软设备放置。</target>
        </trans-unit>
        <trans-unit id="c9c7c6ec42a6b32f83fcca563a931ba4fbe0ed3b" translate="yes" xml:space="preserve">
          <source>Get number of threads used for parallelism between independent operations.</source>
          <target state="translated">获取独立操作之间并行使用的线程数。</target>
        </trans-unit>
        <trans-unit id="80b95985b48aaafa3e792986341c8b4ff88eead6" translate="yes" xml:space="preserve">
          <source>Get number of threads used within an individual op for parallelism.</source>
          <target state="translated">获取单个操作中并行使用的线程数。</target>
        </trans-unit>
        <trans-unit id="6fc794e6fd1f995204b4b699515f189ad3b79ac8" translate="yes" xml:space="preserve">
          <source>Get the &lt;code&gt;TensorShape&lt;/code&gt; representing the shape of the dense tensor.</source>
          <target state="translated">获取代表密集张量形状的 &lt;code&gt;TensorShape&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="53ea60d80b4295960ae12cbdab1a207aed855693" translate="yes" xml:space="preserve">
          <source>Get the KL-divergence KL(distribution_a || distribution_b). (deprecated)</source>
          <target state="translated">获取KL-divergence KL(distribution_a || distribution_b)。(已废弃)</target>
        </trans-unit>
        <trans-unit id="0bf696fef5a21374d09e8355388763caa023a426" translate="yes" xml:space="preserve">
          <source>Get the Master string to be used for the session.</source>
          <target state="translated">获取会话要使用的主字符串。</target>
        </trans-unit>
        <trans-unit id="108dacf621a6cd835ace3ba57aa80d2b5e19236d" translate="yes" xml:space="preserve">
          <source>Get the compilation flags for custom operators.</source>
          <target state="translated">获取自定义运算符的编译标志。</target>
        </trans-unit>
        <trans-unit id="b7741d8625c9ab518a4a96df253f1b4a18258c89" translate="yes" xml:space="preserve">
          <source>Get the current size of the TensorArray.</source>
          <target state="translated">获取TensorArray的当前大小。</target>
        </trans-unit>
        <trans-unit id="3ae51f237cd7e7c81a09e6f89ce59cb258772427" translate="yes" xml:space="preserve">
          <source>Get the directory containing the TensorFlow C++ header files.</source>
          <target state="translated">获取包含TensorFlow C++头文件的目录。</target>
        </trans-unit>
        <trans-unit id="359b660afd7e217497634736e8bd4bb55153be9c" translate="yes" xml:space="preserve">
          <source>Get the directory containing the TensorFlow framework library.</source>
          <target state="translated">获取包含TensorFlow框架库的目录。</target>
        </trans-unit>
        <trans-unit id="1b86ea9f05146578b1054be5bc6cba1a144e94aa" translate="yes" xml:space="preserve">
          <source>Get the dropout mask for RNN cell's input.</source>
          <target state="translated">获取RNN单元输入的滤波掩码。</target>
        </trans-unit>
        <trans-unit id="ac67fd4c2118b549293e874899270e15a2f87c37" translate="yes" xml:space="preserve">
          <source>Get the embedding results.</source>
          <target state="translated">获取嵌入结果。</target>
        </trans-unit>
        <trans-unit id="650bdecea08ce6ef81b38eabb82f7de00f8d7991" translate="yes" xml:space="preserve">
          <source>Get the global step tensor.</source>
          <target state="translated">获取全局阶梯张量。</target>
        </trans-unit>
        <trans-unit id="fc3b1d0c5d3365a3eaff90c6cf36385cdaa1ba29" translate="yes" xml:space="preserve">
          <source>Get the link flags for custom operators.</source>
          <target state="translated">获取自定义运营商的链接标志。</target>
        </trans-unit>
        <trans-unit id="e5b8a3ccddd79a33c1a86a133a701f8165f54b2b" translate="yes" xml:space="preserve">
          <source>Get the list of visible physical devices.</source>
          <target state="translated">获取可见的物理设备列表。</target>
        </trans-unit>
        <trans-unit id="921a66e34ee4a58c84a0efa213945cee146717d6" translate="yes" xml:space="preserve">
          <source>Get the path to the specified file in the data dependencies.</source>
          <target state="translated">获取数据依赖关系中指定文件的路径。</target>
        </trans-unit>
        <trans-unit id="b6dd8217ee8de67bf5164159422b42d807287473" translate="yes" xml:space="preserve">
          <source>Get the recurrent dropout mask for RNN cell.</source>
          <target state="translated">获取RNN单元的循环滤波掩码。</target>
        </trans-unit>
        <trans-unit id="c31cddaa67a87523e9d1624fa98876319984d178" translate="yes" xml:space="preserve">
          <source>Get the tensor of type &lt;code&gt;dtype&lt;/code&gt; by feeding a tensor handle.</source>
          <target state="translated">送入张量手柄以获取 &lt;code&gt;dtype&lt;/code&gt; 类型的张量。</target>
        </trans-unit>
        <trans-unit id="c3cd44016bc9caf57517296a543e5f07cc70b58f" translate="yes" xml:space="preserve">
          <source>Get the value of the tensor from a tensor handle. The tensor is produced in a previous run() and stored in the state of the session.</source>
          <target state="translated">从张量句柄中获取张量的值。张量值是在之前的run()中产生的,并存储在会话的状态中。</target>
        </trans-unit>
        <trans-unit id="0b696c4e43749193b332192827a0f793184a5d68" translate="yes" xml:space="preserve">
          <source>Get the value of the tensor specified by its handle.</source>
          <target state="translated">获取其句柄指定的张量值。</target>
        </trans-unit>
        <trans-unit id="35948203feb263f7dc9fb059f6619c9f87908726" translate="yes" xml:space="preserve">
          <source>Get the virtual device configuration for a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">获取&lt;a href=&quot;physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; &lt;/a&gt;的虚拟设备配置。</target>
        </trans-unit>
        <trans-unit id="0644eda96e6748128f29f7007c63dd9693a38f23" translate="yes" xml:space="preserve">
          <source>Get this scope's global variables.</source>
          <target state="translated">获取这个作用域的全局变量。</target>
        </trans-unit>
        <trans-unit id="887d65a3c67be69818d4fa832142026519a1083d" translate="yes" xml:space="preserve">
          <source>Get this scope's local variables.</source>
          <target state="translated">获取这个作用域的局部变量。</target>
        </trans-unit>
        <trans-unit id="a308585ffe5c9c1e87f02af3bd65c090f3a450c2" translate="yes" xml:space="preserve">
          <source>Get this scope's trainable variables.</source>
          <target state="translated">获取这个作用域的可训练变量。</target>
        </trans-unit>
        <trans-unit id="057e2633d0656b1fb510dea575a522fc49d9405f" translate="yes" xml:space="preserve">
          <source>Get this scope's variables.</source>
          <target state="translated">获取这个范围的变量。</target>
        </trans-unit>
        <trans-unit id="5795bd8bcbae0c5fe909ec39b6d58c353b7d8911" translate="yes" xml:space="preserve">
          <source>Get unique labels and indices for batched labels for &lt;a href=&quot;ctc_loss&quot;&gt;&lt;code&gt;tf.nn.ctc_loss&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">为&lt;a href=&quot;ctc_loss&quot;&gt; &lt;code&gt;tf.nn.ctc_loss&lt;/code&gt; &lt;/a&gt;获取批处理标签的唯一标签和索引。</target>
        </trans-unit>
        <trans-unit id="ad80c7ad74f9cfd40d20ded5dcca808ac13dcbc8" translate="yes" xml:space="preserve">
          <source>GetSessionHandle</source>
          <target state="translated">GetSessionHandle</target>
        </trans-unit>
        <trans-unit id="2179dea7e98769d4809990545d7093de795b9aae" translate="yes" xml:space="preserve">
          <source>GetSessionHandleV2</source>
          <target state="translated">GetSessionHandleV2</target>
        </trans-unit>
        <trans-unit id="a40b5c806adbe4a5fe6b4c1812438a81bf678aa7" translate="yes" xml:space="preserve">
          <source>GetSessionTensor</source>
          <target state="translated">GetSessionTensor</target>
        </trans-unit>
        <trans-unit id="e5f58f3a07d14b9e0032e44d6a23fe568ceffa8e" translate="yes" xml:space="preserve">
          <source>Gets a numpy-style shape tuple giving the dataset dimensions.</source>
          <target state="translated">获取一个numpy风格的形状元组,给出数据集的尺寸。</target>
        </trans-unit>
        <trans-unit id="16edd56dc8f500661a54f70ff8aa5d3642a74f3d" translate="yes" xml:space="preserve">
          <source>Gets an existing &lt;em&gt;local&lt;/em&gt; variable or creates a new one.</source>
          <target state="translated">获取现有的&lt;em&gt;局部&lt;/em&gt;变量或创建一个新的&lt;em&gt;局部&lt;/em&gt;变量。</target>
        </trans-unit>
        <trans-unit id="8363344ba8552991690effa2b825a04c73499304" translate="yes" xml:space="preserve">
          <source>Gets an existing variable with these parameters or create a new one.</source>
          <target state="translated">获取一个带有这些参数的现有变量或创建一个新变量。</target>
        </trans-unit>
        <trans-unit id="c705ed15a7fab0aed052398593737c16839589c3" translate="yes" xml:space="preserve">
          <source>Gets an existing variable with this name or create a new one.</source>
          <target state="translated">获取现有的这个名称的变量,或者创建一个新的变量。</target>
        </trans-unit>
        <trans-unit id="e6eb4b621d4c64dca0de29b3b8a401e1cd6303ba" translate="yes" xml:space="preserve">
          <source>Gets batch at position &lt;code&gt;index&lt;/code&gt;.</source>
          <target state="translated">在位置 &lt;code&gt;index&lt;/code&gt; 获得批次。</target>
        </trans-unit>
        <trans-unit id="9241f5d7bcc0a690cd669562fcda23fde5204e95" translate="yes" xml:space="preserve">
          <source>Gets model input details.</source>
          <target state="translated">获取模型输入细节。</target>
        </trans-unit>
        <trans-unit id="7cb340e682cc8a13364fea269654750b9f7ffa8f" translate="yes" xml:space="preserve">
          <source>Gets model output details.</source>
          <target state="translated">获取模型输出详情。</target>
        </trans-unit>
        <trans-unit id="12c82d522842fce5b68907e9a09973a0aa4e2bf3" translate="yes" xml:space="preserve">
          <source>Gets next element for the provided shard number.</source>
          <target state="translated">获取所提供的碎片编号的下一个元素。</target>
        </trans-unit>
        <trans-unit id="1176b88ed9f974924ce3c2aed58b5efc5abf028f" translate="yes" xml:space="preserve">
          <source>Gets parameters for this estimator.</source>
          <target state="translated">获取该估计器的参数。</target>
        </trans-unit>
        <trans-unit id="bf1b6d34570c76b9b641b4a8fdf7b56eacc074a4" translate="yes" xml:space="preserve">
          <source>Gets tensor details for every tensor with valid tensor details.</source>
          <target state="translated">获取每个有效张量细节的张量细节。</target>
        </trans-unit>
        <trans-unit id="3f6f5f2772b01d65cdb20576211da5d66d43f685" translate="yes" xml:space="preserve">
          <source>Gets the &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; representing the shape of the dense tensor.</source>
          <target state="translated">获取表示密集张量形状的&lt;a href=&quot;tensorshape&quot;&gt; &lt;code&gt;tf.TensorShape&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5649b7730a87257a8bf757eb14d5d260e4d8989f" translate="yes" xml:space="preserve">
          <source>Gets the checkpoint state given the provided checkpoint_dir and looks for a corresponding TensorFlow 2 (preferred) or TensorFlow 1.x checkpoint path. The latest_filename argument is only applicable if you are saving checkpoint using &lt;code&gt;v1.Saver.save&lt;/code&gt;</source>
          <target state="translated">在提供给定的checkpoint_dir的情况下获取检查点状态，并查找对应的TensorFlow 2（首选）或TensorFlow 1.x检查点路径。只有使用 &lt;code&gt;v1.Saver.save&lt;/code&gt; 保存检查点时，latest_filename参数才适用。</target>
        </trans-unit>
        <trans-unit id="edf919a5da9968403435a8f5bed01d1084154593" translate="yes" xml:space="preserve">
          <source>Gets the crossed output from a partial list/tuple of inputs.</source>
          <target state="translated">从部分输入列表/元组中获取交叉输出。</target>
        </trans-unit>
        <trans-unit id="0911c623c2e60904843307f59585e7a371b0bc73" translate="yes" xml:space="preserve">
          <source>Gets the current device policy.</source>
          <target state="translated">获取当前设备策略。</target>
        </trans-unit>
        <trans-unit id="84ad69761c8ff8c302a3208721f28483a943e063" translate="yes" xml:space="preserve">
          <source>Gets the datatype of the dataset.</source>
          <target state="translated">获取数据集的数据类型。</target>
        </trans-unit>
        <trans-unit id="c0ad71d1c926ecf4a236b3b9ed68592ba6894254" translate="yes" xml:space="preserve">
          <source>Gets the list of losses from the loss_collection.</source>
          <target state="translated">从 loss_collection 中获取损失列表。</target>
        </trans-unit>
        <trans-unit id="d33e19f642cb6ca8f7cdb89e56c9383004a73014" translate="yes" xml:space="preserve">
          <source>Gets the list of regularization losses.</source>
          <target state="translated">获取正则化损失列表。</target>
        </trans-unit>
        <trans-unit id="3bbcd4bcf488d6f0e10e7505b28c43087a823f71" translate="yes" xml:space="preserve">
          <source>Gets the next output from the given iterator .</source>
          <target state="translated">从给定的迭代器中获取下一个输出。</target>
        </trans-unit>
        <trans-unit id="94576ff1b1b843455454082862a97d7ef6376959" translate="yes" xml:space="preserve">
          <source>Gets the next output from the given iterator as an Optional variant.</source>
          <target state="translated">从给定的迭代器中获取下一个输出,作为一个可选的变量。</target>
        </trans-unit>
        <trans-unit id="b6dcd4f1b64cdf911fd9f684928f1da25a6cfb7f" translate="yes" xml:space="preserve">
          <source>Gets the next output from the given iterator.</source>
          <target state="translated">从给定的迭代器中获取下一个输出。</target>
        </trans-unit>
        <trans-unit id="994bf13750cf00f44f9b6b4c9dfb6f0028020c70" translate="yes" xml:space="preserve">
          <source>Gets the number of dimensions (rank) of the dataset.</source>
          <target state="translated">获取数据集的维数(等级)。</target>
        </trans-unit>
        <trans-unit id="f23647c68125a7ba22ae0e3518d064d1d05de6f2" translate="yes" xml:space="preserve">
          <source>Gets the total dataset size (number of elements).</source>
          <target state="translated">获取数据集的总大小(元素数)。</target>
        </trans-unit>
        <trans-unit id="9e0adaeaa293d7d6a42173107240437868052b8a" translate="yes" xml:space="preserve">
          <source>Gets the total regularization loss.</source>
          <target state="translated">获取总的正则化损失。</target>
        </trans-unit>
        <trans-unit id="73109b21436d1124b271c6807ebab80e82f19d20" translate="yes" xml:space="preserve">
          <source>Gets the value of the input tensor (get a copy).</source>
          <target state="translated">获取输入张量的值(获取副本)。</target>
        </trans-unit>
        <trans-unit id="d0a97ae528a9e344d85b2bc74d446d4af8965e0a" translate="yes" xml:space="preserve">
          <source>Gets whether operations are executed synchronously or asynchronously.</source>
          <target state="translated">获取操作是同步执行还是异步执行。</target>
        </trans-unit>
        <trans-unit id="5442e2b64fa09764b9f593867e59a97292c84059" translate="yes" xml:space="preserve">
          <source>GitHub</source>
          <target state="translated">GitHub</target>
        </trans-unit>
        <trans-unit id="6d3e28aa7a51ffcbb882909d4507c0ef3ff3db70" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;A&lt;/code&gt; representing this &lt;code&gt;LinearOperator&lt;/code&gt;, if &lt;code&gt;A&lt;/code&gt; is positive definite self-adjoint, return &lt;code&gt;L&lt;/code&gt;, where &lt;code&gt;A = L L^T&lt;/code&gt;, i.e. the cholesky decomposition.</source>
          <target state="translated">鉴于 &lt;code&gt;A&lt;/code&gt; 表示此 &lt;code&gt;LinearOperator&lt;/code&gt; ，如果 &lt;code&gt;A&lt;/code&gt; 是正定的自伴随，返回 &lt;code&gt;L&lt;/code&gt; ，其中 &lt;code&gt;A = L L^T&lt;/code&gt; ，即，Cholesky分解。</target>
        </trans-unit>
        <trans-unit id="3011b88138f555206a8d8637777584fc499f20df" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;A&lt;/code&gt; representing this &lt;code&gt;LinearOperator&lt;/code&gt;, return &lt;code&gt;A*&lt;/code&gt;. Note that calling &lt;code&gt;self.adjoint()&lt;/code&gt; and &lt;code&gt;self.H&lt;/code&gt; are equivalent.</source>
          <target state="translated">给定 &lt;code&gt;A&lt;/code&gt; 表示此 &lt;code&gt;LinearOperator&lt;/code&gt; ，返回 &lt;code&gt;A*&lt;/code&gt; 。请注意，调用 &lt;code&gt;self.adjoint()&lt;/code&gt; 和 &lt;code&gt;self.H&lt;/code&gt; 是等效的。</target>
        </trans-unit>
        <trans-unit id="7004a0f51e6bcd7306d7fdb592b0811cb1a57ee7" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;A&lt;/code&gt; representing this &lt;code&gt;LinearOperator&lt;/code&gt;, return a &lt;code&gt;LinearOperator&lt;/code&gt; representing &lt;code&gt;A^-1&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;A&lt;/code&gt; 表示此 &lt;code&gt;LinearOperator&lt;/code&gt; ，返回一个表示 &lt;code&gt;A^-1&lt;/code&gt; 的 &lt;code&gt;LinearOperator&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5ed8e56b64256346a6878837d8ee1cfda9085e69" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;diagonal&lt;/code&gt;, this operation returns a tensor with the same shape and values as &lt;code&gt;input&lt;/code&gt;, except for the main diagonal of the innermost matrices. These will be overwritten by the values in &lt;code&gt;diagonal&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;input&lt;/code&gt; 和 &lt;code&gt;diagonal&lt;/code&gt; ，此操作将返回张量，其形状和值与 &lt;code&gt;input&lt;/code&gt; 相同，但最内层矩阵的主对角线除外。这些将被 &lt;code&gt;diagonal&lt;/code&gt; 的值覆盖。</target>
        </trans-unit>
        <trans-unit id="6d4eddf991c1d74f9a5d1d05bd85b438f60be0df" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;diagonal&lt;/code&gt;, this operation returns a tensor with the same shape and values as &lt;code&gt;input&lt;/code&gt;, except for the specified diagonals of the innermost matrices. These will be overwritten by the values in &lt;code&gt;diagonal&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;input&lt;/code&gt; 和 &lt;code&gt;diagonal&lt;/code&gt; ，此操作将返回张量，其形状和值与 &lt;code&gt;input&lt;/code&gt; 相同，但最内层矩阵的指定对角线除外。这些将被 &lt;code&gt;diagonal&lt;/code&gt; 的值覆盖。</target>
        </trans-unit>
        <trans-unit id="9752e3f5f130be65433c3b1f55a7c6eed51319fb" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;s0&lt;/code&gt; and &lt;code&gt;s1&lt;/code&gt;, tensors that represent shapes, compute &lt;code&gt;r0&lt;/code&gt;, the broadcasted shape. &lt;code&gt;s0&lt;/code&gt;, &lt;code&gt;s1&lt;/code&gt; and &lt;code&gt;r0&lt;/code&gt; are all integer vectors.</source>
          <target state="translated">给定 &lt;code&gt;s0&lt;/code&gt; 和 &lt;code&gt;s1&lt;/code&gt; ，表示形状的张量计算 &lt;code&gt;r0&lt;/code&gt; ，即广播的形状。 &lt;code&gt;s0&lt;/code&gt; ， &lt;code&gt;s1&lt;/code&gt; 和 &lt;code&gt;r0&lt;/code&gt; 都是整数向量。</target>
        </trans-unit>
        <trans-unit id="c4667868493e23c5d3be9c3d6e074ce011a1f942" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;tensor&lt;/code&gt;, this operation returns a new &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; that has the same values as &lt;code&gt;tensor&lt;/code&gt; in the same order, except with a new shape given by &lt;code&gt;shape&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;tensor&lt;/code&gt; ，此操作将返回一个新的&lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt;，该值与 &lt;code&gt;tensor&lt;/code&gt; 值具有相同的顺序，但具有由shape给定的新 &lt;code&gt;shape&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="be8be019b8aafa6e11f377f6a79a88780b77b43f" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;tensor&lt;/code&gt;, this operation returns a tensor that has the same values as &lt;code&gt;tensor&lt;/code&gt; with shape &lt;code&gt;shape&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;tensor&lt;/code&gt; ，此操作将返回一个张量，该张量的值与具有shape &lt;code&gt;shape&lt;/code&gt; &lt;code&gt;tensor&lt;/code&gt; 相同。</target>
        </trans-unit>
        <trans-unit id="cdee36245b530dadc7a33390b261e3595f491a32" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, compute &lt;code&gt;x * log1p(y)&lt;/code&gt;. This function safely returns zero when &lt;code&gt;x = 0&lt;/code&gt;, no matter what the value of &lt;code&gt;y&lt;/code&gt; is.</source>
          <target state="translated">给定 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; ，计算 &lt;code&gt;x * log1p(y)&lt;/code&gt; 。不管 &lt;code&gt;y&lt;/code&gt; 的值是多少，当 &lt;code&gt;x = 0&lt;/code&gt; ，此函数都会安全地返回零。</target>
        </trans-unit>
        <trans-unit id="270b80b5a40e2baf3fc36e77aed5580f95129897" translate="yes" xml:space="preserve">
          <source>Given &lt;code&gt;x&lt;/code&gt;, compute the inverse error function of &lt;code&gt;x&lt;/code&gt;. This function is the inverse of &lt;a href=&quot;erf&quot;&gt;&lt;code&gt;tf.math.erf&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">鉴于 &lt;code&gt;x&lt;/code&gt; ，计算的逆误差函数 &lt;code&gt;x&lt;/code&gt; 。此函数与&lt;a href=&quot;erf&quot;&gt; &lt;code&gt;tf.math.erf&lt;/code&gt; 相反&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9bd6c98f31a6efc0f5ca49049729b234a4e076d8" translate="yes" xml:space="preserve">
          <source>Given N one-dimensional coordinate arrays &lt;code&gt;*args&lt;/code&gt;, returns a list &lt;code&gt;outputs&lt;/code&gt; of N-D coordinate arrays for evaluating expressions on an N-D grid.</source>
          <target state="translated">给定N个一维坐标数组 &lt;code&gt;*args&lt;/code&gt; ，返回ND坐标数组的列表 &lt;code&gt;outputs&lt;/code&gt; ，用于评估ND网格上的表达式。</target>
        </trans-unit>
        <trans-unit id="f3b95972a12a7881c9c9398cac9152e479d5c1ef" translate="yes" xml:space="preserve">
          <source>Given a 4D input tensor ('NHWC' or 'NCHW' data formats) and a filter tensor of shape &lt;code&gt;[filter_height, filter_width, in_channels, channel_multiplier]&lt;/code&gt; containing &lt;code&gt;in_channels&lt;/code&gt; convolutional filters of depth 1, &lt;code&gt;depthwise_conv2d&lt;/code&gt; applies a different filter to each input channel (expanding from 1 channel to &lt;code&gt;channel_multiplier&lt;/code&gt; channels for each), then concatenates the results together. The output has &lt;code&gt;in_channels * channel_multiplier&lt;/code&gt; channels.</source>
          <target state="translated">给定一个4D输入张量（&amp;ldquo;NHWC&amp;rdquo;或&amp;ldquo;NCHW&amp;rdquo;的数据格式）和形状的过滤器张量 &lt;code&gt;[filter_height, filter_width, in_channels, channel_multiplier]&lt;/code&gt; 含有 &lt;code&gt;in_channels&lt;/code&gt; 深度1的卷积滤波器， &lt;code&gt;depthwise_conv2d&lt;/code&gt; 应用不同的过滤器到每个输入信道（扩（每个通道从1个通道到 &lt;code&gt;channel_multiplier&lt;/code&gt; 通道），然后将结果串联在一起。输出具有 &lt;code&gt;in_channels * channel_multiplier&lt;/code&gt; 通道。</target>
        </trans-unit>
        <trans-unit id="094ea9bf18f0c36eba450800d4c1f7a06e4be90d" translate="yes" xml:space="preserve">
          <source>Given a &lt;code&gt;diagonal&lt;/code&gt;, this operation returns a tensor with the &lt;code&gt;diagonal&lt;/code&gt; and everything else padded with zeros. The diagonal is computed as follows:</source>
          <target state="translated">给定 &lt;code&gt;diagonal&lt;/code&gt; ，此操作将返回一个带有 &lt;code&gt;diagonal&lt;/code&gt; 的张量，其他所有内容都填充零。对角线计算如下：</target>
        </trans-unit>
        <trans-unit id="66eaeaec1eb9cbadc921ae64470886d7ed3832d0" translate="yes" xml:space="preserve">
          <source>Given a &lt;code&gt;tensor&lt;/code&gt;, and a &lt;code&gt;bool&lt;/code&gt; tensor &lt;code&gt;dims&lt;/code&gt; representing the dimensions of &lt;code&gt;tensor&lt;/code&gt;, this operation reverses each dimension i of &lt;code&gt;tensor&lt;/code&gt; where &lt;code&gt;dims[i]&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">给定一个 &lt;code&gt;tensor&lt;/code&gt; ，和一个 &lt;code&gt;bool&lt;/code&gt; 张量 &lt;code&gt;dims&lt;/code&gt; 表示的尺寸 &lt;code&gt;tensor&lt;/code&gt; ，该操作反转的每个维度我 &lt;code&gt;tensor&lt;/code&gt; ，其中 &lt;code&gt;dims[i]&lt;/code&gt; 是 &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6147dea94829076776f7d46f24eec459f66088a0" translate="yes" xml:space="preserve">
          <source>Given a &lt;code&gt;tensor&lt;/code&gt;, and a &lt;code&gt;int32&lt;/code&gt; tensor &lt;code&gt;axis&lt;/code&gt; representing the set of dimensions of &lt;code&gt;tensor&lt;/code&gt; to reverse. This operation reverses each dimension &lt;code&gt;i&lt;/code&gt; for which there exists &lt;code&gt;j&lt;/code&gt; s.t. &lt;code&gt;axis[j] == i&lt;/code&gt;.</source>
          <target state="translated">给定一个 &lt;code&gt;tensor&lt;/code&gt; ，并且一个 &lt;code&gt;int32&lt;/code&gt; 张量 &lt;code&gt;axis&lt;/code&gt; 表示要反转的 &lt;code&gt;tensor&lt;/code&gt; 的尺寸集。此操作将存在 &lt;code&gt;j&lt;/code&gt; st &lt;code&gt;axis[j] == i&lt;/code&gt; 每个维度 &lt;code&gt;i&lt;/code&gt; 反转。</target>
        </trans-unit>
        <trans-unit id="1e040c53a91fa31be95603ab52d19f7c9b3eda7f" translate="yes" xml:space="preserve">
          <source>Given a Python slice &lt;code&gt;input[spec0, spec1, ..., specn]&lt;/code&gt;, this function will be called as follows.</source>
          <target state="translated">给定一个Python slice &lt;code&gt;input[spec0, spec1, ..., specn]&lt;/code&gt; ，此函数将如下调用。</target>
        </trans-unit>
        <trans-unit id="8cc9f63fb42e045b295452edd4ecb68aa07a8d87" translate="yes" xml:space="preserve">
          <source>Given a TensorSummary node_def, retrieve its SummaryDescription.</source>
          <target state="translated">给定一个 TensorSummary node_def,检索其 SummaryDescription。</target>
        </trans-unit>
        <trans-unit id="9dd17d0fb7fb4fa3b12e4e69ca28248800ac81b7" translate="yes" xml:space="preserve">
          <source>Given a list &lt;code&gt;x&lt;/code&gt; and a list &lt;code&gt;y&lt;/code&gt;, this operation returns a list &lt;code&gt;out&lt;/code&gt; that represents all values that are in &lt;code&gt;x&lt;/code&gt; but not in &lt;code&gt;y&lt;/code&gt;. The returned list &lt;code&gt;out&lt;/code&gt; is sorted in the same order that the numbers appear in &lt;code&gt;x&lt;/code&gt; (duplicates are preserved). This operation also returns a list &lt;code&gt;idx&lt;/code&gt; that represents the position of each &lt;code&gt;out&lt;/code&gt; element in &lt;code&gt;x&lt;/code&gt;. In other words:</source>
          <target state="translated">给定一个列表 &lt;code&gt;x&lt;/code&gt; 和一个列表 &lt;code&gt;y&lt;/code&gt; ，该操作返回一个列表 &lt;code&gt;out&lt;/code&gt; ，表示在所有值 &lt;code&gt;x&lt;/code&gt; ，但不 &lt;code&gt;y&lt;/code&gt; 。返回的列表 &lt;code&gt;out&lt;/code&gt; 在同一顺序的数字显示在排序 &lt;code&gt;x&lt;/code&gt; （副本被保存）。此操作还返回一个列表 &lt;code&gt;idx&lt;/code&gt; ，它表示每个 &lt;code&gt;out&lt;/code&gt; 元素在 &lt;code&gt;x&lt;/code&gt; 中的位置。换一种说法：</target>
        </trans-unit>
        <trans-unit id="5c5372b4dc12fe49c83eb4b2c2b91eba162834cd" translate="yes" xml:space="preserve">
          <source>Given a list of device names, this operation returns the index of the device this op runs. The length of the list is returned in two cases: (1) Device does not exist in the given device list. (2) It is in XLA compilation.</source>
          <target state="translated">给定一个设备名称的列表,这个操作返回这个操作运行的设备的索引。在两种情况下返回列表的长度。(1)设备不存在于给定的设备列表中。(2)它在XLA编译中。</target>
        </trans-unit>
        <trans-unit id="615eb60f085e28de1449f5a5508afeb187317b05" translate="yes" xml:space="preserve">
          <source>Given a list of string tensors of same shape, performs element-wise concatenation of the strings of the same index in all tensors.</source>
          <target state="translated">给定一个相同形状的字符串时序列表,对所有时序中相同索引的字符串进行逐元连接。</target>
        </trans-unit>
        <trans-unit id="2f469b77293ed1ff9f0eb63bb9dae24362157619" translate="yes" xml:space="preserve">
          <source>Given a list of tensors or ragged tensors with the same rank &lt;code&gt;R&lt;/code&gt; (&lt;code&gt;R &amp;gt;= axis&lt;/code&gt;), returns a rank-&lt;code&gt;R+1&lt;/code&gt;&lt;code&gt;RaggedTensor&lt;/code&gt;&lt;code&gt;result&lt;/code&gt; such that &lt;code&gt;result[i0...iaxis]&lt;/code&gt; is &lt;code&gt;[value[i0...iaxis] for value in values]&lt;/code&gt;.</source>
          <target state="translated">给定具有相同等级 &lt;code&gt;R&lt;/code&gt; （ &lt;code&gt;R &amp;gt;= axis&lt;/code&gt; ）的张量或参差不齐的张量的列表，返回等级R &lt;code&gt;R+1&lt;/code&gt; &lt;code&gt;RaggedTensor&lt;/code&gt; &lt;code&gt;result&lt;/code&gt; ，使得 &lt;code&gt;result[i0...iaxis]&lt;/code&gt; 为 &lt;code&gt;[value[i0...iaxis] for value in values]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="799df442e0baab2b82fd8e748615a45625ee8074" translate="yes" xml:space="preserve">
          <source>Given a path to new and old vocabulary files, returns a remapping Tensor of</source>
          <target state="translated">给定新旧词汇文件的路径,返回新旧词汇文件的重映射Tensor。</target>
        </trans-unit>
        <trans-unit id="68c5f2c079927408ee33cb3fc0df6461ed870433" translate="yes" xml:space="preserve">
          <source>Given a per-replica value returned by &lt;code&gt;experimental_run_v2&lt;/code&gt;, say a per-example loss, the batch will be divided across all the replicas. This function allows you to aggregate across replicas and optionally also across batch elements. For example, if you have a global batch size of 8 and 2 replicas, values for examples &lt;code&gt;[0, 1, 2, 3]&lt;/code&gt; will be on replica 0 and &lt;code&gt;[4, 5, 6, 7]&lt;/code&gt; will be on replica 1. By default, &lt;code&gt;reduce&lt;/code&gt; will just aggregate across replicas, returning &lt;code&gt;[0+4, 1+5, 2+6, 3+7]&lt;/code&gt;. This is useful when each replica is computing a scalar or some other value that doesn't have a &quot;batch&quot; dimension (like a gradient). More often you will want to aggregate across the global batch, which you can get by specifying the batch dimension as the &lt;code&gt;axis&lt;/code&gt;, typically &lt;code&gt;axis=0&lt;/code&gt;. In this case it would return a scalar &lt;code&gt;0+1+2+3+4+5+6+7&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;experimental_run_v2&lt;/code&gt; 返回的每个副本的值（例如，每个示例损失），批次将在所有副本之间分配。此功能使您可以跨副本聚合，也可以跨批元素聚合。例如，如果全局批处理大小为8和2个副本，则示例 &lt;code&gt;[0, 1, 2, 3]&lt;/code&gt; 将在副本0上， &lt;code&gt;[4, 5, 6, 7]&lt;/code&gt; 将在副本1上。默认情况下， &lt;code&gt;reduce&lt;/code&gt; 将仅跨副本进行聚合，返回 &lt;code&gt;[0+4, 1+5, 2+6, 3+7]&lt;/code&gt; 。当每个副本正在计算标量或其他没有&amp;ldquo;批&amp;rdquo;维（例如渐变）的值时，此功能很有用。通常，您会希望跨全局批次进行汇总，这可以通过将批次尺寸指定为 &lt;code&gt;axis&lt;/code&gt; 来获得，通常为 &lt;code&gt;axis=0&lt;/code&gt; 。在这种情况下，它将返回标量 &lt;code&gt;0+1+2+3+4+5+6+7&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fba44d6afcce2f9092396c74380f9a0d2335aa38" translate="yes" xml:space="preserve">
          <source>Given a per-replica value returned by &lt;code&gt;run&lt;/code&gt;, say a per-example loss, the batch will be divided across all the replicas. This function allows you to aggregate across replicas and optionally also across batch elements. For example, if you have a global batch size of 8 and 2 replicas, values for examples &lt;code&gt;[0, 1, 2, 3]&lt;/code&gt; will be on replica 0 and &lt;code&gt;[4, 5, 6, 7]&lt;/code&gt; will be on replica 1. By default, &lt;code&gt;reduce&lt;/code&gt; will just aggregate across replicas, returning &lt;code&gt;[0+4, 1+5, 2+6, 3+7]&lt;/code&gt;. This is useful when each replica is computing a scalar or some other value that doesn't have a &quot;batch&quot; dimension (like a gradient). More often you will want to aggregate across the global batch, which you can get by specifying the batch dimension as the &lt;code&gt;axis&lt;/code&gt;, typically &lt;code&gt;axis=0&lt;/code&gt;. In this case it would return a scalar &lt;code&gt;0+1+2+3+4+5+6+7&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;run&lt;/code&gt; 所返回的每个副本的值（例如，每个示例的损失），批次将在所有副本之间分配。此功能使您可以跨副本聚合，也可以跨批元素聚合。例如，如果全局批量大小为8和2个副本，则示例 &lt;code&gt;[0, 1, 2, 3]&lt;/code&gt; 将在副本0上， &lt;code&gt;[4, 5, 6, 7]&lt;/code&gt; 将在副本1上。默认情况下， &lt;code&gt;reduce&lt;/code&gt; 将仅跨副本进行聚合，返回 &lt;code&gt;[0+4, 1+5, 2+6, 3+7]&lt;/code&gt; 。当每个副本正在计算标量或其他没有&amp;ldquo;批&amp;rdquo;维（例如渐变）的值时，此功能很有用。通常，您会希望在全局批次中进行汇总，这可以通过将批次维度指定为 &lt;code&gt;axis&lt;/code&gt; ，通常 &lt;code&gt;axis=0&lt;/code&gt; 。在这种情况下，它将返回标量 &lt;code&gt;0+1+2+3+4+5+6+7&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d356be63c806d4a57d873a70be815c506a549419" translate="yes" xml:space="preserve">
          <source>Given a python function &lt;code&gt;func&lt;/code&gt; wrap this function as an operation in a TensorFlow function. &lt;code&gt;func&lt;/code&gt; must take numpy arrays as its arguments and return numpy arrays as its outputs.</source>
          <target state="translated">给定python函数 &lt;code&gt;func&lt;/code&gt; 将此函数包装为TensorFlow函数中的操作。 &lt;code&gt;func&lt;/code&gt; 必须将numpy数组作为其参数，并返回numpy数组作为其输出。</target>
        </trans-unit>
        <trans-unit id="3a5b52f136266fe244292b77181eab18685d5599" translate="yes" xml:space="preserve">
          <source>Given a python function &lt;code&gt;func&lt;/code&gt;, which takes numpy arrays as its arguments and returns numpy arrays as its outputs, wrap this function as an operation in a TensorFlow graph. The following snippet constructs a simple TensorFlow graph that invokes the &lt;code&gt;np.sinh()&lt;/code&gt; NumPy function as a operation in the graph:</source>
          <target state="translated">给定python函数 &lt;code&gt;func&lt;/code&gt; ，该函数将numpy数组作为其参数并返回numpy数组作为其输出，请将此函数包装为TensorFlow图中的操作。以下代码段构建了一个简单的TensorFlow图，该图调用 &lt;code&gt;np.sinh()&lt;/code&gt; NumPy函数作为图中的操作：</target>
        </trans-unit>
        <trans-unit id="04e5711a5b38ba52b6a8792b3c7feb0ca529ddd8" translate="yes" xml:space="preserve">
          <source>Given a quantized tensor described by &lt;code&gt;(input, input_min, input_max)&lt;/code&gt;, outputs a range that covers the actual values present in that tensor. This op is typically used to produce the &lt;code&gt;requested_output_min&lt;/code&gt; and &lt;code&gt;requested_output_max&lt;/code&gt; for &lt;code&gt;Requantize&lt;/code&gt;.</source>
          <target state="translated">给定一个由 &lt;code&gt;(input, input_min, input_max)&lt;/code&gt; 描述的量化张量，输出一个覆盖该张量中存在的实际值的范围。此运算典型地用于生产 &lt;code&gt;requested_output_min&lt;/code&gt; 和 &lt;code&gt;requested_output_max&lt;/code&gt; 为 &lt;code&gt;Requantize&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d3da234c855426da94c463431671a4c43997129c" translate="yes" xml:space="preserve">
          <source>Given a single tensor (&lt;code&gt;tensor&lt;/code&gt;), this operation returns a tensor of the same type and shape as &lt;code&gt;tensor&lt;/code&gt; with all elements set to 1. Optionally, you can specify a new type (&lt;code&gt;dtype&lt;/code&gt;) for the returned tensor.</source>
          <target state="translated">给定单个张量（ &lt;code&gt;tensor&lt;/code&gt; ），此操作将返回与张量具有相同类型和形状的 &lt;code&gt;tensor&lt;/code&gt; 且所有元素都设置为1。您可以为返回的张量指定新类型（ &lt;code&gt;dtype&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="cef540646f64962527a87cdc8b09906dde5432ac" translate="yes" xml:space="preserve">
          <source>Given a single tensor (&lt;code&gt;tensor&lt;/code&gt;), this operation returns a tensor of the same type and shape as &lt;code&gt;tensor&lt;/code&gt; with all elements set to 1. Optionally, you can use &lt;code&gt;dtype&lt;/code&gt; to specify a new type for the returned tensor.</source>
          <target state="translated">给定一个张量（ &lt;code&gt;tensor&lt;/code&gt; ），此操作将返回与张量具有相同类型和形状的 &lt;code&gt;tensor&lt;/code&gt; 且所有元素都设置为1。您可以选择使用 &lt;code&gt;dtype&lt;/code&gt; 为返回的张量指定新类型。</target>
        </trans-unit>
        <trans-unit id="f197c0d34900084408842c4f3cb206307ffb52c6" translate="yes" xml:space="preserve">
          <source>Given a single tensor (&lt;code&gt;tensor&lt;/code&gt;), this operation returns a tensor of the same type and shape as &lt;code&gt;tensor&lt;/code&gt; with all elements set to zero. Optionally, you can use &lt;code&gt;dtype&lt;/code&gt; to specify a new type for the returned tensor.</source>
          <target state="translated">给定一个张量（ &lt;code&gt;tensor&lt;/code&gt; ），此操作将返回与张量具有相同类型和形状的 &lt;code&gt;tensor&lt;/code&gt; 并且所有元素都设置为零。（可选）您可以使用 &lt;code&gt;dtype&lt;/code&gt; 为返回的张量指定新类型。</target>
        </trans-unit>
        <trans-unit id="f6c0b6671463b416e1fcd6a6f255b3952b13ff6a" translate="yes" xml:space="preserve">
          <source>Given a single tensor or array-like object (&lt;code&gt;input&lt;/code&gt;), this operation returns a tensor of the same type and shape as &lt;code&gt;input&lt;/code&gt; with all elements set to zero. Optionally, you can use &lt;code&gt;dtype&lt;/code&gt; to specify a new type for the returned tensor.</source>
          <target state="translated">给定单个张量或类似数组的对象（ &lt;code&gt;input&lt;/code&gt; ），此操作将返回与 &lt;code&gt;input&lt;/code&gt; 具有相同类型和形状的张量，且所有元素均设置为零。（可选）您可以使用 &lt;code&gt;dtype&lt;/code&gt; 为返回的张量指定新类型。</target>
        </trans-unit>
        <trans-unit id="10b69b4dd5bbe2b5280497f7bc6c2252eeb11d35" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt; of complex numbers, this operation returns a tensor of complex numbers that are the complex conjugate of each element in &lt;code&gt;input&lt;/code&gt;. The complex numbers in &lt;code&gt;input&lt;/code&gt; must be of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part.</source>
          <target state="translated">给定一个复数张量 &lt;code&gt;input&lt;/code&gt; ，此操作将返回一个复数张量，该张量是 &lt;code&gt;input&lt;/code&gt; 中每个元素的复共轭。 &lt;code&gt;input&lt;/code&gt; 的复数必须采用\（a + bj \）的形式，其中&lt;em&gt;a&lt;/em&gt;是实部，&lt;em&gt;b&lt;/em&gt;是虚部。</target>
        </trans-unit>
        <trans-unit id="f4a15667395d38500d3dfc23e818236844897a6a" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt; of complex numbers, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the argument of each element in &lt;code&gt;input&lt;/code&gt;. All elements in &lt;code&gt;input&lt;/code&gt; must be complex numbers of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part.</source>
          <target state="translated">给定一个复数张量 &lt;code&gt;input&lt;/code&gt; ，此操作将返回一个 &lt;code&gt;float&lt;/code&gt; 类型的张量，该张量是 &lt;code&gt;input&lt;/code&gt; 中每个元素的参数。 &lt;code&gt;input&lt;/code&gt; 所有元素必须是形式为\（a + bj \）的复数，其中&lt;em&gt;a&lt;/em&gt;是实部，&lt;em&gt;b&lt;/em&gt;是虚部。</target>
        </trans-unit>
        <trans-unit id="af4da35de23a457876e5d3da3d8ccad06ca104b4" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt; of complex numbers, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the imaginary part of each element in &lt;code&gt;input&lt;/code&gt;. All elements in &lt;code&gt;input&lt;/code&gt; must be complex numbers of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part returned by this operation.</source>
          <target state="translated">给定复数张量 &lt;code&gt;input&lt;/code&gt; ，此操作将返回 &lt;code&gt;float&lt;/code&gt; 类型的张量，该张量是 &lt;code&gt;input&lt;/code&gt; 中每个元素的虚部。 &lt;code&gt;input&lt;/code&gt; 所有元素必须是形式为\（a + bj \）的复数，其中&lt;em&gt;a&lt;/em&gt;是实数部分，&lt;em&gt;b&lt;/em&gt;是此操作返回的虚数部分。</target>
        </trans-unit>
        <trans-unit id="7ffbcbe2d85ffbf7da6ee324f57a57f9317dabd2" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt; of complex numbers, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the real part of each element in &lt;code&gt;input&lt;/code&gt;. All elements in &lt;code&gt;input&lt;/code&gt; must be complex numbers of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part returned by this operation and &lt;em&gt;b&lt;/em&gt; is the imaginary part.</source>
          <target state="translated">给定一个复数张量 &lt;code&gt;input&lt;/code&gt; ，此操作将返回一个 &lt;code&gt;float&lt;/code&gt; 类型的张量，该张量是 &lt;code&gt;input&lt;/code&gt; 中每个元素的实部。 &lt;code&gt;input&lt;/code&gt; 所有元素必须是\（a + bj \）形式的复数，其中&lt;em&gt;a&lt;/em&gt;是此操作返回的实数部分，&lt;em&gt;b&lt;/em&gt;是虚数部分。</target>
        </trans-unit>
        <trans-unit id="806e510667c18a0441a9ae34cf672593b9c2613d" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation inserts a dimension of 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt;'s shape. The dimension index &lt;code&gt;axis&lt;/code&gt; starts at zero; if you specify a negative number for &lt;code&gt;axis&lt;/code&gt; it is counted backward from the end.</source>
          <target state="translated">给定的张量 &lt;code&gt;input&lt;/code&gt; ，此操作在尺寸索引插入的1维 &lt;code&gt;axis&lt;/code&gt; 的 &lt;code&gt;input&lt;/code&gt; 的形状。尺寸索引 &lt;code&gt;axis&lt;/code&gt; 从零开始；如果 &lt;code&gt;axis&lt;/code&gt; 指定负数，则从末尾算起。</target>
        </trans-unit>
        <trans-unit id="d963425876592189628da6b7e7e5ed87ffb5d763" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation inserts a dimension of length 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt;'s shape. The dimension index follows Python indexing rules: It's zero-based, a negative index it is counted backward from the end.</source>
          <target state="translated">给定的张量 &lt;code&gt;input&lt;/code&gt; ，此操作在尺寸索引插入长度1的尺寸 &lt;code&gt;axis&lt;/code&gt; 的 &lt;code&gt;input&lt;/code&gt; 的形状。维度索引遵循Python索引规则：从零开始，它是一个负索引，从末尾开始倒数。</target>
        </trans-unit>
        <trans-unit id="1431dbed06794c8031819f2ace8f4c705283bdec" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation inserts a dimension of length 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt;'s shape. The dimension index follows python indexing rules: It's zero-based, a negative index it is counted backward from the end.</source>
          <target state="translated">给定的张量 &lt;code&gt;input&lt;/code&gt; ，此操作在尺寸索引插入长度1的尺寸 &lt;code&gt;axis&lt;/code&gt; 的 &lt;code&gt;input&lt;/code&gt; 的形状。维度索引遵循python索引规则：从零开始，它是一个负索引，从末尾开始倒数。</target>
        </trans-unit>
        <trans-unit id="c286503b096f71983bf3319ebce75fc3df581ded" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation inserts a dimension of size 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt;'s shape. The dimension index &lt;code&gt;axis&lt;/code&gt; starts at zero; if you specify a negative number for &lt;code&gt;axis&lt;/code&gt; it is counted backward from the end.</source>
          <target state="translated">给定的张量 &lt;code&gt;input&lt;/code&gt; ，此操作在尺寸索引插入大小为1的尺寸 &lt;code&gt;axis&lt;/code&gt; 的 &lt;code&gt;input&lt;/code&gt; 形状的。尺寸索引 &lt;code&gt;axis&lt;/code&gt; 从零开始；如果 &lt;code&gt;axis&lt;/code&gt; 指定负数，则从末尾算起。</target>
        </trans-unit>
        <trans-unit id="3a1fb94877fc4770061be1a2b9c38bdc7f0532ee" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of the same type with all dimensions of size 1 removed. If you don't want to remove all size 1 dimensions, you can remove specific size 1 dimensions by specifying &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="translated">给定张量 &lt;code&gt;input&lt;/code&gt; ，此操作将返回相同类型的张量，并删除尺寸为1的所有尺寸。如果您不想删除所有尺寸为1的尺寸，则可以通过指定 &lt;code&gt;axis&lt;/code&gt; 来删除尺寸为1的特定尺寸。</target>
        </trans-unit>
        <trans-unit id="bbca199d5d5cd792b1dd02ead4c9b8f3ef441f45" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the argument of each element in &lt;code&gt;input&lt;/code&gt; considered as a complex number.</source>
          <target state="translated">给定的张量 &lt;code&gt;input&lt;/code&gt; ，此操作返回类型的张量 &lt;code&gt;float&lt;/code&gt; 即在每个元件的参数 &lt;code&gt;input&lt;/code&gt; 视为一个复数。</target>
        </trans-unit>
        <trans-unit id="f3c9874b7bb8857da64e590211bda623bc98b5d1" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the imaginary part of each element in &lt;code&gt;input&lt;/code&gt; considered as a complex number. If &lt;code&gt;input&lt;/code&gt; is real, a tensor of all zeros is returned.</source>
          <target state="translated">给定的张量 &lt;code&gt;input&lt;/code&gt; ，此操作返回类型的张量 &lt;code&gt;float&lt;/code&gt; 即在各元素的虚部 &lt;code&gt;input&lt;/code&gt; 视为一个复数。如果 &lt;code&gt;input&lt;/code&gt; 为实数，则返回全零的张量。</target>
        </trans-unit>
        <trans-unit id="becaf7789b114f2fb84f8a1c908f9499f6b0068e" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; that is the real part of each element in &lt;code&gt;input&lt;/code&gt; considered as a complex number.</source>
          <target state="translated">给定的张量 &lt;code&gt;input&lt;/code&gt; ，此操作返回类型的张量 &lt;code&gt;float&lt;/code&gt; 即在各元素的实部 &lt;code&gt;input&lt;/code&gt; 视为一个复数。</target>
        </trans-unit>
        <trans-unit id="a4adc764f5b83b917078bf968adc81577aa08658" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;input&lt;/code&gt;, this operation returns a tensor that has the same buffer data as &lt;code&gt;input&lt;/code&gt; with datatype &lt;code&gt;type&lt;/code&gt;.</source>
          <target state="translated">给定张量 &lt;code&gt;input&lt;/code&gt; ，此操作将返回一个张量，该张量具有与数据 &lt;code&gt;type&lt;/code&gt; 为type的 &lt;code&gt;input&lt;/code&gt; 相同的缓冲区数据。</target>
        </trans-unit>
        <trans-unit id="44c0e89f9a11fab2d9da2eab4b6ba9dad61347c2" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;inputs&lt;/code&gt;, moments are calculated and normalization is performed across the axes specified in &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="translated">给定张量 &lt;code&gt;inputs&lt;/code&gt; ，将计算矩，并在轴中指定的 &lt;code&gt;axis&lt;/code&gt; 进行归一化。</target>
        </trans-unit>
        <trans-unit id="b01a7ab9f6ce08221630a8a12ac493ef6aa5e0f2" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;real&lt;/code&gt; representing the real part of a complex number, and a tensor &lt;code&gt;imag&lt;/code&gt; representing the imaginary part of a complex number, this operation returns complex numbers elementwise of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; represents the &lt;code&gt;real&lt;/code&gt; part and &lt;em&gt;b&lt;/em&gt; represents the &lt;code&gt;imag&lt;/code&gt; part.</source>
          <target state="translated">给定张量 &lt;code&gt;real&lt;/code&gt; 表示复数的实部，并且张量 &lt;code&gt;imag&lt;/code&gt; 表示复数的虚部，此操作以元素\（a + bj \）的形式返回复数，其中&lt;em&gt;a&lt;/em&gt;表示 &lt;code&gt;real&lt;/code&gt; 部，而&lt;em&gt;b&lt;/em&gt;代表 &lt;code&gt;imag&lt;/code&gt; 部分。</target>
        </trans-unit>
        <trans-unit id="4cde684e0bf3170cd69db48357176ad6f8be05bf" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;sp_input&lt;/code&gt;, this operation inserts a dimension of 1 at the dimension index &lt;code&gt;axis&lt;/code&gt; of &lt;code&gt;sp_input&lt;/code&gt;'s shape. The dimension index &lt;code&gt;axis&lt;/code&gt; starts at zero; if you specify a negative number for &lt;code&gt;axis&lt;/code&gt; it is counted backwards from the end.</source>
          <target state="translated">给定的张量 &lt;code&gt;sp_input&lt;/code&gt; ，这种操作在尺寸索引插入的1维 &lt;code&gt;axis&lt;/code&gt; 的 &lt;code&gt;sp_input&lt;/code&gt; 的形状。尺寸索引 &lt;code&gt;axis&lt;/code&gt; 从零开始；如果 &lt;code&gt;axis&lt;/code&gt; 指定负数，则从末尾算起。</target>
        </trans-unit>
        <trans-unit id="c7e431d8c1e8a94cc9f6ddda87a3198f535026e6" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;t&lt;/code&gt;, and a maximum clip value &lt;code&gt;clip_norm&lt;/code&gt;, this operation normalizes &lt;code&gt;t&lt;/code&gt; so that its L2-norm is less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;, along the dimensions given in &lt;code&gt;axes&lt;/code&gt;. Specifically, in the default case where all dimensions are used for calculation, if the L2-norm of &lt;code&gt;t&lt;/code&gt; is already less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;, then &lt;code&gt;t&lt;/code&gt; is not modified. If the L2-norm is greater than &lt;code&gt;clip_norm&lt;/code&gt;, then this operation returns a tensor of the same type and shape as &lt;code&gt;t&lt;/code&gt; with its values set to:</source>
          <target state="translated">给定张量 &lt;code&gt;t&lt;/code&gt; 和最大裁剪值 &lt;code&gt;clip_norm&lt;/code&gt; ，此操作将 &lt;code&gt;t&lt;/code&gt; 标准化以使其L2范数沿 &lt;code&gt;axes&lt;/code&gt; 给定的尺寸小于或等于 &lt;code&gt;clip_norm&lt;/code&gt; 。具体来说，在所有尺寸均用于计算的默认情况下，如果 &lt;code&gt;t&lt;/code&gt; 的L2-范数已经小于或等于 &lt;code&gt;clip_norm&lt;/code&gt; ，则不会修改 &lt;code&gt;t&lt;/code&gt; 。如果L2-norm大于 &lt;code&gt;clip_norm&lt;/code&gt; ，则此操作返回与 &lt;code&gt;t&lt;/code&gt; 具有相同类型和形状的张量，其值设置为：</target>
        </trans-unit>
        <trans-unit id="0fb66188586afb5dfa9ed28d0d11ecbbd9aa6324" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;t&lt;/code&gt;, and a maximum clip value &lt;code&gt;clip_norm&lt;/code&gt;, this operation normalizes &lt;code&gt;t&lt;/code&gt; so that its average L2-norm is less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;. Specifically, if the average L2-norm is already less than or equal to &lt;code&gt;clip_norm&lt;/code&gt;, then &lt;code&gt;t&lt;/code&gt; is not modified. If the average L2-norm is greater than &lt;code&gt;clip_norm&lt;/code&gt;, then this operation returns a tensor of the same type and shape as &lt;code&gt;t&lt;/code&gt; with its values set to:</source>
          <target state="translated">给定张量 &lt;code&gt;t&lt;/code&gt; 和最大裁剪值 &lt;code&gt;clip_norm&lt;/code&gt; ，此操作将 &lt;code&gt;t&lt;/code&gt; 标准化，以使其平均L2-norm小于或等于 &lt;code&gt;clip_norm&lt;/code&gt; 。具体来说，如果平均L2-norm已经小于或等于 &lt;code&gt;clip_norm&lt;/code&gt; ，则不会修改 &lt;code&gt;t&lt;/code&gt; 。如果平均L2-norm大于 &lt;code&gt;clip_norm&lt;/code&gt; ，则此操作返回与 &lt;code&gt;t&lt;/code&gt; 具有相同类型和形状的张量，其值设置为：</target>
        </trans-unit>
        <trans-unit id="7007bafda729e071b7b16ae3d3a78dcbb3100276" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;t&lt;/code&gt;, this operation returns a tensor of the same type and shape as &lt;code&gt;t&lt;/code&gt; with its values clipped to &lt;code&gt;clip_value_min&lt;/code&gt; and &lt;code&gt;clip_value_max&lt;/code&gt;. Any values less than &lt;code&gt;clip_value_min&lt;/code&gt; are set to &lt;code&gt;clip_value_min&lt;/code&gt;. Any values greater than &lt;code&gt;clip_value_max&lt;/code&gt; are set to &lt;code&gt;clip_value_max&lt;/code&gt;.</source>
          <target state="translated">给定张量 &lt;code&gt;t&lt;/code&gt; ，此操作将返回与 &lt;code&gt;t&lt;/code&gt; 具有相同类型和形状的张量，其值将被裁剪为 &lt;code&gt;clip_value_min&lt;/code&gt; 和 &lt;code&gt;clip_value_max&lt;/code&gt; 。任何小于 &lt;code&gt;clip_value_min&lt;/code&gt; 的值都设置为 &lt;code&gt;clip_value_min&lt;/code&gt; 。任何大于 &lt;code&gt;clip_value_max&lt;/code&gt; 的值都设置为 &lt;code&gt;clip_value_max&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4d793504d9a2641fdc838d8a324aa0f0d9bef081" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;x&lt;/code&gt; and a tensor &lt;code&gt;y&lt;/code&gt;, this operation computes \(x^y\) for corresponding elements in &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. For example:</source>
          <target state="translated">给定张量 &lt;code&gt;x&lt;/code&gt; 和张量 &lt;code&gt;y&lt;/code&gt; ，此操作为 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 中的对应元素计算\（x ^ y \）。例如：</target>
        </trans-unit>
        <trans-unit id="1d97acda758edb9bf66a685f144f3b117ce1c753" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;x&lt;/code&gt; of complex numbers, this operation returns a tensor of type &lt;code&gt;float32&lt;/code&gt; or &lt;code&gt;float64&lt;/code&gt; that is the absolute value of each element in &lt;code&gt;x&lt;/code&gt;. All elements in &lt;code&gt;x&lt;/code&gt; must be complex numbers of the form \(a + bj\). The absolute value is computed as \( \sqrt{a^2 + b^2}\). For example:</source>
          <target state="translated">给定一个复数张量 &lt;code&gt;x&lt;/code&gt; ，此操作将返回 &lt;code&gt;float32&lt;/code&gt; 或 &lt;code&gt;float64&lt;/code&gt; 类型的张量，该张量是 &lt;code&gt;x&lt;/code&gt; 中每个元素的绝对值。 &lt;code&gt;x&lt;/code&gt; 中的所有元素必须是\（a + bj \）形式的复数。绝对值计算为\（\ sqrt {a ^ 2 + b ^ 2} \）。例如：</target>
        </trans-unit>
        <trans-unit id="f9f18c0deb0b747c5c85a2f0f9afacc8bc3635a6" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;x&lt;/code&gt; of complex numbers, this operation returns a tensor of type &lt;code&gt;float32&lt;/code&gt; or &lt;code&gt;float64&lt;/code&gt; that is the absolute value of each element in &lt;code&gt;x&lt;/code&gt;. For a complex number \(a + bj\), its absolute value is computed as \(\sqrt{a^2</source>
          <target state="translated">给定一个复数张量 &lt;code&gt;x&lt;/code&gt; ，此操作将返回 &lt;code&gt;float32&lt;/code&gt; 或 &lt;code&gt;float64&lt;/code&gt; 类型的张量，该张量是 &lt;code&gt;x&lt;/code&gt; 中每个元素的绝对值。对于复数\（a + bj \），其绝对值计算为\（\ sqrt {a ^ 2</target>
        </trans-unit>
        <trans-unit id="355cf8ae9246c456614b457edc04fdaeb78e33b1" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;x&lt;/code&gt; of complex numbers, this operation returns a tensor of type &lt;code&gt;float&lt;/code&gt; or &lt;code&gt;double&lt;/code&gt; that is the absolute value of each element in &lt;code&gt;x&lt;/code&gt;. All elements in &lt;code&gt;x&lt;/code&gt; must be complex numbers of the form \(a + bj\). The absolute value is computed as \( \sqrt{a^2 + b^2}\).</source>
          <target state="translated">给定一个复数张量 &lt;code&gt;x&lt;/code&gt; ，此操作将返回 &lt;code&gt;float&lt;/code&gt; 或 &lt;code&gt;double&lt;/code&gt; 类型的张量，该张量是 &lt;code&gt;x&lt;/code&gt; 中每个元素的绝对值。 &lt;code&gt;x&lt;/code&gt; 中的所有元素必须是\（a + bj \）形式的复数。绝对值计算为\（\ sqrt {a ^ 2 + b ^ 2} \）。</target>
        </trans-unit>
        <trans-unit id="20000a209981bca529c2a5888aeb027dca5cb186" translate="yes" xml:space="preserve">
          <source>Given a tensor &lt;code&gt;x&lt;/code&gt;, this operation returns a tensor containing the absolute value of each element in &lt;code&gt;x&lt;/code&gt;. For example, if x is an input element and y is an output element, this operation computes \(y = |x|\).</source>
          <target state="translated">给定张量 &lt;code&gt;x&lt;/code&gt; ，此操作将返回一个张量，其中包含 &lt;code&gt;x&lt;/code&gt; 中每个元素的绝对值。例如，如果x是输入元素，而y是输出元素，则此运算将计算\（y = | x | \）。</target>
        </trans-unit>
        <trans-unit id="bd81862ba7b8de323d4dc65742b6a0e0fc609451" translate="yes" xml:space="preserve">
          <source>Given a tensor of integer or floating-point values, this operation returns a tensor of the same type, where each element contains the absolute value of the corresponding element in the input.</source>
          <target state="translated">给定一个整数或浮点值的张量,这个操作返回一个相同类型的张量,其中每个元素包含输入中相应元素的绝对值。</target>
        </trans-unit>
        <trans-unit id="322b12c73859d8a9e4e7944b435ecab925a5124e" translate="yes" xml:space="preserve">
          <source>Given a tuple or list of tensors &lt;code&gt;t_list&lt;/code&gt;, and a clipping ratio &lt;code&gt;clip_norm&lt;/code&gt;, this operation returns a list of clipped tensors &lt;code&gt;list_clipped&lt;/code&gt; and the global norm (&lt;code&gt;global_norm&lt;/code&gt;) of all tensors in &lt;code&gt;t_list&lt;/code&gt;. Optionally, if you've already computed the global norm for &lt;code&gt;t_list&lt;/code&gt;, you can specify the global norm with &lt;code&gt;use_norm&lt;/code&gt;.</source>
          <target state="translated">给出一个数组或张量清单 &lt;code&gt;t_list&lt;/code&gt; 和裁剪比例 &lt;code&gt;clip_norm&lt;/code&gt; ，该操作返回裁剪张量清单 &lt;code&gt;list_clipped&lt;/code&gt; 和全球规范（ &lt;code&gt;global_norm&lt;/code&gt; 在所有张量） &lt;code&gt;t_list&lt;/code&gt; 。可选地，如果您已经计算了 &lt;code&gt;t_list&lt;/code&gt; 的全局范数，则可以使用 &lt;code&gt;use_norm&lt;/code&gt; 指定全局范数。</target>
        </trans-unit>
        <trans-unit id="fb5b0e16debf84a9c22080f3acaefe368e00fdb9" translate="yes" xml:space="preserve">
          <source>Given a tuple or list of tensors &lt;code&gt;t_list&lt;/code&gt;, this operation returns the global norm of the elements in all tensors in &lt;code&gt;t_list&lt;/code&gt;. The global norm is computed as:</source>
          <target state="translated">给定张量 &lt;code&gt;t_list&lt;/code&gt; 的元组或列表，此操作将返回 &lt;code&gt;t_list&lt;/code&gt; 中所有张量中元素的全局范数。全局规范的计算公式为：</target>
        </trans-unit>
        <trans-unit id="73d8bb2fac3b21f66c499488e5209e33bb02392c" translate="yes" xml:space="preserve">
          <source>Given an &lt;code&gt;IndexedSlices&lt;/code&gt; instance &lt;code&gt;a&lt;/code&gt;, returns another &lt;code&gt;IndexedSlices&lt;/code&gt; that contains a subset of the slices of &lt;code&gt;a&lt;/code&gt;. Only the slices at indices not specified in &lt;code&gt;mask_indices&lt;/code&gt; are returned.</source>
          <target state="translated">给定一个 &lt;code&gt;IndexedSlices&lt;/code&gt; 实例 &lt;code&gt;a&lt;/code&gt; ，返回另一个 &lt;code&gt;IndexedSlices&lt;/code&gt; 包含的切片的一个子集 &lt;code&gt;a&lt;/code&gt; 。仅返回在 &lt;code&gt;mask_indices&lt;/code&gt; 中未指定索引处的切片。</target>
        </trans-unit>
        <trans-unit id="4876f0e9062c0cf2e7752902c9a4b28f41eb1e86" translate="yes" xml:space="preserve">
          <source>Given an &lt;code&gt;input&lt;/code&gt; shaped &lt;code&gt;[s0, s1, ..., s_n]&lt;/code&gt;, the output is a &lt;code&gt;uint8&lt;/code&gt; tensor shaped &lt;code&gt;[s0, s1, ..., s_n / 8]&lt;/code&gt;.</source>
          <target state="translated">给定一个 &lt;code&gt;input&lt;/code&gt; 形 &lt;code&gt;[s0, s1, ..., s_n]&lt;/code&gt; ，输出是 &lt;code&gt;uint8&lt;/code&gt; 张量形 &lt;code&gt;[s0, s1, ..., s_n / 8]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6eb4a575261e442800cb08021cae257d7dca9d5e" translate="yes" xml:space="preserve">
          <source>Given an arbitrary function, wrap it so that it does variable sharing.</source>
          <target state="translated">给定一个任意函数,将其封装,使其实现变量共享。</target>
        </trans-unit>
        <trans-unit id="18296fc4ebda93cac42fe65939317a047745ed5f" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape &lt;code&gt;[batch, in_height, in_width, in_channels]&lt;/code&gt; and a filter / kernel tensor of shape &lt;code&gt;[filter_height, filter_width, in_channels, channel_multiplier]&lt;/code&gt;, containing &lt;code&gt;in_channels&lt;/code&gt; convolutional filters of depth 1, &lt;code&gt;depthwise_conv2d&lt;/code&gt; applies a different filter to each input channel (expanding from 1 channel to &lt;code&gt;channel_multiplier&lt;/code&gt; channels for each), then concatenates the results together. Thus, the output has &lt;code&gt;in_channels * channel_multiplier&lt;/code&gt; channels.</source>
          <target state="translated">给定形状的输入张量 &lt;code&gt;[batch, in_height, in_width, in_channels]&lt;/code&gt; 和滤波器/形状的内核张量 &lt;code&gt;[filter_height, filter_width, in_channels, channel_multiplier]&lt;/code&gt; ，含有 &lt;code&gt;in_channels&lt;/code&gt; 深度1的卷积滤波器， &lt;code&gt;depthwise_conv2d&lt;/code&gt; 应用不同的过滤器到每个输入信道（将每个通道从1个通道扩展到 &lt;code&gt;channel_multiplier&lt;/code&gt; 通道），然后将结果连接在一起。因此，输出具有 &lt;code&gt;in_channels * channel_multiplier&lt;/code&gt; 通道。</target>
        </trans-unit>
        <trans-unit id="3e370c68e5555d480a5c4df80fb0a1826a44057c" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape &lt;code&gt;[batch, in_height, in_width, in_channels]&lt;/code&gt; and a filter / kernel tensor of shape &lt;code&gt;[filter_height, filter_width, in_channels, out_channels]&lt;/code&gt;, this op performs the following:</source>
          <target state="translated">给定形状的输入张量 &lt;code&gt;[batch, in_height, in_width, in_channels]&lt;/code&gt; 和滤波器/形状的内核张量 &lt;code&gt;[filter_height, filter_width, in_channels, out_channels]&lt;/code&gt; ，此运算执行以下内容：</target>
        </trans-unit>
        <trans-unit id="1fab9d674065ff486a1c44d98d6d558e38ce4d8f" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape &lt;code&gt;batch_shape + [in_height, in_width, in_channels]&lt;/code&gt; and a filter / kernel tensor of shape &lt;code&gt;[filter_height, filter_width, in_channels, out_channels]&lt;/code&gt;, this op performs the following:</source>
          <target state="translated">给定形状的输入张量 &lt;code&gt;batch_shape + [in_height, in_width, in_channels]&lt;/code&gt; 和滤波器/内核形状的张量 &lt;code&gt;[filter_height, filter_width, in_channels, out_channels]&lt;/code&gt; ，此运算执行以下内容：</target>
        </trans-unit>
        <trans-unit id="ed20cb19f30785b7a38934894a0dbee86a0b0123" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape &lt;code&gt;batch_shape + [in_width, in_channels]&lt;/code&gt; if &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;NWC&quot;&lt;/code&gt;, or &lt;code&gt;batch_shape + [in_channels, in_width]&lt;/code&gt; if &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;NCW&quot;&lt;/code&gt;, and a filter / kernel tensor of shape &lt;code&gt;[filter_width, in_channels, out_channels]&lt;/code&gt;, this op reshapes the arguments to pass them to &lt;code&gt;conv2d&lt;/code&gt; to perform the equivalent convolution operation.</source>
          <target state="translated">给定形状的输入张量 &lt;code&gt;batch_shape + [in_width, in_channels]&lt;/code&gt; 如果 &lt;code&gt;data_format&lt;/code&gt; 是 &lt;code&gt;&quot;NWC&quot;&lt;/code&gt; ，或 &lt;code&gt;batch_shape + [in_channels, in_width]&lt;/code&gt; 如果 &lt;code&gt;data_format&lt;/code&gt; 是 &lt;code&gt;&quot;NCW&quot;&lt;/code&gt; ，和一过滤器/核形状的张量 &lt;code&gt;[filter_width, in_channels, out_channels]&lt;/code&gt; ，此op重塑参数以将其传递给 &lt;code&gt;conv2d&lt;/code&gt; 以执行等效的卷积操作。</target>
        </trans-unit>
        <trans-unit id="b1c915a4b13f35d33a94d06e3847c2365262d62c" translate="yes" xml:space="preserve">
          <source>Given an input tensor of shape [batch, in_width, in_channels] if data_format is &quot;NWC&quot;, or [batch, in_channels, in_width] if data_format is &quot;NCW&quot;, and a filter / kernel tensor of shape [filter_width, in_channels, out_channels], this op reshapes the arguments to pass them to conv2d to perform the equivalent convolution operation.</source>
          <target state="translated">给定一个形状为[batch,in_width,in_channels]的输入张量(如果data_format为 &quot;NWC&quot;),或者[batch,in_channels,in_width]的输入张量(如果data_format为 &quot;NCW&quot;),以及一个形状为[filter_width,in_channels,out_channels]的滤波/内核张量,这个操作会重构参数,将其传递给conv2d,以执行等价卷积操作。</target>
        </trans-unit>
        <trans-unit id="2eb289cc3c5755f35510bd201bb3c7ba0da0f131" translate="yes" xml:space="preserve">
          <source>Given an input tensor, the function computes inverse hyperbolic cosine of every element. Input range is &lt;code&gt;[1, inf]&lt;/code&gt;. It returns &lt;code&gt;nan&lt;/code&gt; if the input lies outside the range.</source>
          <target state="translated">给定输入张量，该函数将计算每个元素的反双曲余弦值。输入范围是 &lt;code&gt;[1, inf]&lt;/code&gt; 。如果输入超出范围，则返回 &lt;code&gt;nan&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c2276090897040e0aeeaafa324236781f22316e6" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes cosine of every element in the tensor. Input range is &lt;code&gt;(-inf, inf)&lt;/code&gt; and output range is &lt;code&gt;[-1,1]&lt;/code&gt;. If input lies outside the boundary, &lt;code&gt;nan&lt;/code&gt; is returned.</source>
          <target state="translated">给定输入张量，此函数将计算张量中每个元素的余弦值。输入范围是 &lt;code&gt;(-inf, inf)&lt;/code&gt; ，输出范围是 &lt;code&gt;[-1,1]&lt;/code&gt; 。如果输入超出边界，则返回 &lt;code&gt;nan&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6d70ae953868ca523f92404dffa44551095f71ef" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes hyperbolic cosine of every element in the tensor. Input range is &lt;code&gt;[-inf, inf]&lt;/code&gt; and output range is &lt;code&gt;[1, inf]&lt;/code&gt;.</source>
          <target state="translated">给定输入张量，此函数将计算张量中每个元素的双曲余弦值。输入范围是 &lt;code&gt;[-inf, inf]&lt;/code&gt; ，输出范围是 &lt;code&gt;[1, inf]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1b488ce799eb3a33791cfbd59693b393988e595b" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes hyperbolic sine of every element in the tensor. Input range is &lt;code&gt;[-inf,inf]&lt;/code&gt; and output range is &lt;code&gt;[-inf,inf]&lt;/code&gt;.</source>
          <target state="translated">给定输入张量，此函数将计算张量中每个元素的双曲正弦值。输入范围为 &lt;code&gt;[-inf,inf]&lt;/code&gt; ，输出范围为 &lt;code&gt;[-inf,inf]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="59df85e0619df189d8729fee687f600a54d01480" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes hyperbolic tangent of every element in the tensor. Input range is &lt;code&gt;[-inf, inf]&lt;/code&gt; and output range is &lt;code&gt;[-1,1]&lt;/code&gt;.</source>
          <target state="translated">给定输入张量，此函数将计算张量中每个元素的双曲正切值。输入范围是 &lt;code&gt;[-inf, inf]&lt;/code&gt; ，输出范围是 &lt;code&gt;[-1,1]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c73b448fa482aa6531301716ace98c25a05fd5d3" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes inverse hyperbolic sine for every element in the tensor. Both input and output has a range of &lt;code&gt;[-inf, inf]&lt;/code&gt;.</source>
          <target state="translated">给定输入张量，此函数为张量中的每个元素计算反双曲正弦值。输入和输出的范围均为 &lt;code&gt;[-inf, inf]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c25eb5c30ec69042f14f0a07e82e62d1882abacc" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes inverse hyperbolic tangent for every element in the tensor. Input range is &lt;code&gt;[-1,1]&lt;/code&gt; and output range is &lt;code&gt;[-inf, inf]&lt;/code&gt;. If input is &lt;code&gt;-1&lt;/code&gt;, output will be &lt;code&gt;-inf&lt;/code&gt; and if the input is &lt;code&gt;1&lt;/code&gt;, output will be &lt;code&gt;inf&lt;/code&gt;. Values outside the range will have &lt;code&gt;nan&lt;/code&gt; as output.</source>
          <target state="translated">给定输入张量，此函数为张量中的每个元素计算反双曲正切值。输入范围为 &lt;code&gt;[-1,1]&lt;/code&gt; ，输出范围为 &lt;code&gt;[-inf, inf]&lt;/code&gt; 。如果输入为 &lt;code&gt;-1&lt;/code&gt; ，则输出将为 &lt;code&gt;-inf&lt;/code&gt; ；如果输入为 &lt;code&gt;1&lt;/code&gt; ，则输出将为 &lt;code&gt;inf&lt;/code&gt; 。超出范围的值将使用 &lt;code&gt;nan&lt;/code&gt; 作为输出。</target>
        </trans-unit>
        <trans-unit id="ea097a1f54202798e40231d72b57eb14a2329e8c" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes sine of every element in the tensor. Input range is &lt;code&gt;(-inf, inf)&lt;/code&gt; and output range is &lt;code&gt;[-1,1]&lt;/code&gt;.</source>
          <target state="translated">给定输入张量，此函数将计算张量中每个元素的正弦值。输入范围是 &lt;code&gt;(-inf, inf)&lt;/code&gt; ，输出范围是 &lt;code&gt;[-1,1]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d62f8cf300097a0e2129f20828fbd0e2b4cd35f3" translate="yes" xml:space="preserve">
          <source>Given an input tensor, this function computes tangent of every element in the tensor. Input range is &lt;code&gt;(-inf, inf)&lt;/code&gt; and output range is &lt;code&gt;(-inf, inf)&lt;/code&gt;. If input lies outside the boundary, &lt;code&gt;nan&lt;/code&gt; is returned.</source>
          <target state="translated">给定输入张量，此函数计算张量中每个元素的切线。输入范围是 &lt;code&gt;(-inf, inf)&lt;/code&gt; ，输出范围是 &lt;code&gt;(-inf, inf)&lt;/code&gt; 。如果输入超出边界，则返回 &lt;code&gt;nan&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8f8bd7293b2216f6c9572d5c819802c515a646af" translate="yes" xml:space="preserve">
          <source>Given one-dimensional $z = [z_1,...,z_K]$, we define</source>
          <target state="translated">给定一维的$z=[z_1,...,z_K]$,我们定义了</target>
        </trans-unit>
        <trans-unit id="08d07ac5e8ef80d326d4f12521ff24313fbce652" translate="yes" xml:space="preserve">
          <source>Given one-dimensional &lt;code&gt;z = [z_0,...,z_{K-1}]&lt;/code&gt;, we define</source>
          <target state="translated">给定一维 &lt;code&gt;z = [z_0,...,z_{K-1}]&lt;/code&gt; ，我们定义</target>
        </trans-unit>
        <trans-unit id="48fec20fa93f6484a4d59eef4d5240def79def02" translate="yes" xml:space="preserve">
          <source>Given operation-specific seed, &lt;code&gt;op_seed&lt;/code&gt;, this helper function returns two seeds derived from graph-level and op-level seeds. Many random operations internally use the two seeds to allow user to change the seed globally for a graph, or for only specific operations.</source>
          <target state="translated">给定特定于操作的种子 &lt;code&gt;op_seed&lt;/code&gt; ，此辅助函数将返回两个来自图级种子和op级种子的种子。许多随机操作在内部使用这两个种子来允许用户全局更改图形或仅特定操作的种子。</target>
        </trans-unit>
        <trans-unit id="3c4cfb563b251c993c875f25d14c9e568e980107" translate="yes" xml:space="preserve">
          <source>Given random variable &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;p in [0, 1]&lt;/code&gt;, the &lt;code&gt;quantile&lt;/code&gt; is:</source>
          <target state="translated">给定 &lt;code&gt;p in [0, 1]&lt;/code&gt; 随机变量 &lt;code&gt;X&lt;/code&gt; 和p， &lt;code&gt;quantile&lt;/code&gt; 为：</target>
        </trans-unit>
        <trans-unit id="11ff9e9f8b087477a5e4158b4134eac9b64e6878" translate="yes" xml:space="preserve">
          <source>Given random variable &lt;code&gt;X&lt;/code&gt;, the cumulative distribution function &lt;code&gt;cdf&lt;/code&gt; is:</source>
          <target state="translated">给定随机变量 &lt;code&gt;X&lt;/code&gt; ，累积分布函数 &lt;code&gt;cdf&lt;/code&gt; 为：</target>
        </trans-unit>
        <trans-unit id="fa3f3691f019bbd881a265ec5bccfb1211e3ad29" translate="yes" xml:space="preserve">
          <source>Given random variable &lt;code&gt;X&lt;/code&gt;, the survival function is defined:</source>
          <target state="translated">给定随机变量 &lt;code&gt;X&lt;/code&gt; ，生存函数定义为：</target>
        </trans-unit>
        <trans-unit id="55eaa8e915c7da17162d07889c59a5355bf928ae" translate="yes" xml:space="preserve">
          <source>Given that some ops may be partially supported, the optimal way to determine if a model's operations are supported is by converting using the TensorFlow Lite converter.</source>
          <target state="translated">考虑到一些操作可能被部分支持,确定一个模型的操作是否被支持的最佳方法是使用TensorFlow Lite转换器进行转换。</target>
        </trans-unit>
        <trans-unit id="9f078ae5dde89ed67ae2cd1d678f26fb93674467" translate="yes" xml:space="preserve">
          <source>Given the blockwise &lt;code&gt;n + 1&lt;/code&gt;-by-&lt;code&gt;n + 1&lt;/code&gt; linear operator:</source>
          <target state="translated">鉴于按块 &lt;code&gt;n + 1&lt;/code&gt; -by- &lt;code&gt;n + 1&lt;/code&gt; 线性算子：</target>
        </trans-unit>
        <trans-unit id="0153812f9d215780555e110de846d070c2d1cb32" translate="yes" xml:space="preserve">
          <source>Given the tensor &lt;code&gt;values&lt;/code&gt;, this operation returns a rank 1 &lt;code&gt;Tensor&lt;/code&gt; representing the indices of a histogram into which each element of &lt;code&gt;values&lt;/code&gt; would be binned. The bins are equal width and determined by the arguments &lt;code&gt;value_range&lt;/code&gt; and &lt;code&gt;nbins&lt;/code&gt;.</source>
          <target state="translated">给定张 &lt;code&gt;values&lt;/code&gt; ，此操作将返回一个1级张量，该 &lt;code&gt;Tensor&lt;/code&gt; 表示直方图的索引，每个 &lt;code&gt;values&lt;/code&gt; 元素将被合并到该索引中。垃圾箱的宽度相等，由参数 &lt;code&gt;value_range&lt;/code&gt; 和 &lt;code&gt;nbins&lt;/code&gt; 确定。</target>
        </trans-unit>
        <trans-unit id="a9c47520102d0ea0d116c89df4867da9b1a8141e" translate="yes" xml:space="preserve">
          <source>Given the tensor &lt;code&gt;values&lt;/code&gt;, this operation returns a rank 1 histogram counting the number of entries in &lt;code&gt;values&lt;/code&gt; that fall into every bin. The bins are equal width and determined by the arguments &lt;code&gt;value_range&lt;/code&gt; and &lt;code&gt;nbins&lt;/code&gt;.</source>
          <target state="translated">给定张 &lt;code&gt;values&lt;/code&gt; ，此操作将返回一个1级直方图，该直方图对落入每个bin中的 &lt;code&gt;values&lt;/code&gt; 中的条目数进行计数。垃圾箱的宽度相等，由参数 &lt;code&gt;value_range&lt;/code&gt; 和 &lt;code&gt;nbins&lt;/code&gt; 确定。</target>
        </trans-unit>
        <trans-unit id="13c5e2fbdbba7fa42de391b57a0a7d1e5d7df7f6" translate="yes" xml:space="preserve">
          <source>Given the tensor &lt;code&gt;values&lt;/code&gt;, this operation returns a rank 1 histogram counting the number of entries in &lt;code&gt;values&lt;/code&gt; that fell into every bin. The bins are equal width and determined by the arguments &lt;code&gt;value_range&lt;/code&gt; and &lt;code&gt;nbins&lt;/code&gt;.</source>
          <target state="translated">给定张 &lt;code&gt;values&lt;/code&gt; ，此操作将返回一个1级直方图，该直方图计算落入每个bin 中的 &lt;code&gt;values&lt;/code&gt; 中的条目数。垃圾箱的宽度相等，由参数 &lt;code&gt;value_range&lt;/code&gt; 和 &lt;code&gt;nbins&lt;/code&gt; 确定。</target>
        </trans-unit>
        <trans-unit id="54fcfc2408cd2e19b0afb43ec166a6b0b45677c6" translate="yes" xml:space="preserve">
          <source>Given two &lt;code&gt;Example&lt;/code&gt; input protos in &lt;code&gt;serialized&lt;/code&gt;:</source>
          <target state="translated">给定两个 &lt;code&gt;serialized&lt;/code&gt; &lt;code&gt;Example&lt;/code&gt; 输入原型：</target>
        </trans-unit>
        <trans-unit id="a71b5320e03ef99e09301587e5062ffa0d505637" translate="yes" xml:space="preserve">
          <source>Gives a guarantee to the TF runtime that the input tensor is a constant.</source>
          <target state="translated">给TF运行时一个保证,即输入张量是一个常数。</target>
        </trans-unit>
        <trans-unit id="802a77a26d08463b8d182d4841500cc36b1bdeb1" translate="yes" xml:space="preserve">
          <source>Gives the log-likelihood loss between the prediction and the target under the assumption that the target has a Poisson distribution. Caveat: By default, this is not the exact loss, but the loss minus a constant term [log(z!)]. That has no effect for optimization, but does not play well with relative loss comparisons. To compute an approximation of the log factorial term, specify compute_full_loss=True to enable Stirling's Approximation.</source>
          <target state="translated">给出在假设目标具有泊松分布的情况下,预测和目标之间的对数似然损失。注意:默认情况下,这不是精确的损失,而是损失减去一个常数项 [log(z!)]。这对优化没有任何影响,但对相对损失的比较没有起到很好的作用。要计算对数阶乘项的近似值,请指定 compute_full_loss=True 来启用 Stirling's Approximation。</target>
        </trans-unit>
        <trans-unit id="3b375b50d76db2f1ab6e919b12e87eb3c07c7837" translate="yes" xml:space="preserve">
          <source>Global Average pooling operation for 3D data.</source>
          <target state="translated">3D数据的全局平均池操作。</target>
        </trans-unit>
        <trans-unit id="490733d038a485e20b685885b26cd8e1c21ac8a1" translate="yes" xml:space="preserve">
          <source>Global Max pooling operation for 3D data.</source>
          <target state="translated">3D数据的全局最大池化操作。</target>
        </trans-unit>
        <trans-unit id="c372dfcc5aacad73c8ba932360de7dad2d1ce972" translate="yes" xml:space="preserve">
          <source>Global average pooling operation for spatial data.</source>
          <target state="translated">空间数据的全局平均汇集操作。</target>
        </trans-unit>
        <trans-unit id="fc8c9db4015232abf19ef2f9a55435d1ea95b1de" translate="yes" xml:space="preserve">
          <source>Global average pooling operation for temporal data.</source>
          <target state="translated">时态数据的全局平均池操作。</target>
        </trans-unit>
        <trans-unit id="167efa62c3642366c4057325e9b1f061b9517117" translate="yes" xml:space="preserve">
          <source>Global dictionary of names to classes (&lt;code&gt;_GLOBAL_CUSTOM_OBJECTS&lt;/code&gt;).</source>
          <target state="translated">名称到类的全局字典（ &lt;code&gt;_GLOBAL_CUSTOM_OBJECTS&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="3b675d73c44ef2c3b5ff3ee1aee82f62c38a94d3" translate="yes" xml:space="preserve">
          <source>Global id, i.e., this field, is tracking the index of the node among ALL nodes in the cluster. It is uniquely assigned. For example, for the cluster spec given above, the global ids are assigned as:</source>
          <target state="translated">全局id,即这个字段,是跟踪该节点在集群中所有节点中的索引。它是唯一分配的。例如,对于上面给出的集群规格,全局id被分配为:。</target>
        </trans-unit>
        <trans-unit id="861ea43bf3e08cfa679688d9126f736408dcc945" translate="yes" xml:space="preserve">
          <source>Global max pooling operation for 1D temporal data.</source>
          <target state="translated">对一维时空数据进行全局最大池化操作。</target>
        </trans-unit>
        <trans-unit id="fbaffaa9e612328e1415352ab08beb6396bb657c" translate="yes" xml:space="preserve">
          <source>Global max pooling operation for spatial data.</source>
          <target state="translated">空间数据的全局最大池化操作。</target>
        </trans-unit>
        <trans-unit id="f0f40685c4fd8079767cd3b5779589f20e7497c4" translate="yes" xml:space="preserve">
          <source>Global max pooling operation for temporal data.</source>
          <target state="translated">时态数据的全局最大池化操作。</target>
        </trans-unit>
        <trans-unit id="d590e8790e10ef3fdf0c5c3d8ed595c657758ce9" translate="yes" xml:space="preserve">
          <source>Global step tensor.</source>
          <target state="translated">全局阶梯张量。</target>
        </trans-unit>
        <trans-unit id="fa3649b2772ac1189dcef2f8c64d20be93fd805b" translate="yes" xml:space="preserve">
          <source>Global variables are variables that are shared across machines in a distributed environment. The &lt;code&gt;Variable()&lt;/code&gt; constructor or &lt;code&gt;get_variable()&lt;/code&gt; automatically adds new variables to the graph collection &lt;code&gt;GraphKeys.GLOBAL_VARIABLES&lt;/code&gt;. This convenience function returns the contents of that collection.</source>
          <target state="translated">全局变量是在分布式环境中的计算机之间共享的变量。该 &lt;code&gt;Variable()&lt;/code&gt; 构造函数或 &lt;code&gt;get_variable()&lt;/code&gt; 会自动添加新的变数图表收集 &lt;code&gt;GraphKeys.GLOBAL_VARIABLES&lt;/code&gt; 。此便捷功能返回该集合的内容。</target>
        </trans-unit>
        <trans-unit id="1e368decdd07f40f158c5a306bc7f03b270de34b" translate="yes" xml:space="preserve">
          <source>Globs for the checkpoints pointed to by &lt;code&gt;checkpoint_paths&lt;/code&gt;. If the files exist, use their mtime as the checkpoint timestamp.</source>
          <target state="translated">在检查站的水珠被指出 &lt;code&gt;checkpoint_paths&lt;/code&gt; 。如果文件存在，则将其mtime用作检查点时间戳。</target>
        </trans-unit>
        <trans-unit id="a9111e714242062acf83be49c369c220ccfcf860" translate="yes" xml:space="preserve">
          <source>Globs for the checkpoints pointed to by &lt;code&gt;checkpoint_prefixes&lt;/code&gt;. If the files exist, collect their mtime. Both V2 and V1 checkpoints are considered, in that priority.</source>
          <target state="translated">在检查站的水珠被指出 &lt;code&gt;checkpoint_prefixes&lt;/code&gt; 。如果文件存在，请收集其mtime。优先考虑V2和V1检查点。</target>
        </trans-unit>
        <trans-unit id="01cc712ba5777037862cf425ce81901fb067f024" translate="yes" xml:space="preserve">
          <source>Grace period for stopping:</source>
          <target state="translated">停止的宽限期。</target>
        </trans-unit>
        <trans-unit id="adb359f1f87c794c325871e029c1af140effe5ec" translate="yes" xml:space="preserve">
          <source>Grace period handling: When &lt;code&gt;request_stop()&lt;/code&gt; is called, threads are given 'stop_grace_period_secs' seconds to terminate. If any of them is still alive after that period expires, a &lt;code&gt;RuntimeError&lt;/code&gt; is raised. Note that if an &lt;code&gt;exc_info&lt;/code&gt; was passed to &lt;code&gt;request_stop()&lt;/code&gt; then it is raised instead of that &lt;code&gt;RuntimeError&lt;/code&gt;.</source>
          <target state="translated">宽限期处理：调用 &lt;code&gt;request_stop()&lt;/code&gt; 时，线程将被给予'stop_grace_period_secs'秒以终止。如果在该时间段到期后它们中的任何一个仍然存活，则会引发 &lt;code&gt;RuntimeError&lt;/code&gt; 。请注意，如果将 &lt;code&gt;exc_info&lt;/code&gt; 传递给 &lt;code&gt;request_stop()&lt;/code&gt; ，则会引发它而不是那个 &lt;code&gt;RuntimeError&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5149e7b8f8d0f76a4477a7c343a2d7e6cb51a37d" translate="yes" xml:space="preserve">
          <source>Grace period, in seconds, given to running threads to stop when &lt;code&gt;stop()&lt;/code&gt; is called. Defaults to 120 seconds.</source>
          <target state="translated">宽限期（以秒为单位），用于在调用 &lt;code&gt;stop()&lt;/code&gt; 时停止运行的线程。默认为120秒。</target>
        </trans-unit>
        <trans-unit id="2c61a1c122223903dabaecda115cd172b19ae575" translate="yes" xml:space="preserve">
          <source>Gradient Boosted Trees: Model understanding</source>
          <target state="translated">梯度提升树。模型理解</target>
        </trans-unit>
        <trans-unit id="328b1e9ac6d673a9731be1b0fee1aa7f2b9bd86a" translate="yes" xml:space="preserve">
          <source>Gradient descent (with momentum) optimizer.</source>
          <target state="translated">梯度下降(含动量)优化器。</target>
        </trans-unit>
        <trans-unit id="0ccf5db0029889f6fecb177b4847ffd92845592b" translate="yes" xml:space="preserve">
          <source>Gradient for batch normalization.</source>
          <target state="translated">批量归一化的梯度。</target>
        </trans-unit>
        <trans-unit id="da1029b1e9a2a07b646e912fc9a9abfeaf36bbac" translate="yes" xml:space="preserve">
          <source>Gradient of Unbatch.</source>
          <target state="translated">梯度的未批。</target>
        </trans-unit>
        <trans-unit id="70f9c4b00a1e9a42e50af0c5886037373d5b1dd7" translate="yes" xml:space="preserve">
          <source>Gradient op for &lt;code&gt;MirrorPad&lt;/code&gt; op. This op folds a mirror-padded tensor.</source>
          <target state="translated">&lt;code&gt;MirrorPad&lt;/code&gt; 操作的渐变操作。这个op折叠了一个镜像填充的张量。</target>
        </trans-unit>
        <trans-unit id="194bbc5ad5da84e49dad69cbb4f32f23b69a3786" translate="yes" xml:space="preserve">
          <source>GradientTapes can be nested to compute higher-order derivatives. For example,</source>
          <target state="translated">GradientTapes可以嵌套计算高阶导数。例如:</target>
        </trans-unit>
        <trans-unit id="418595e6c8a1cac41ef43f912bdb79ac95f52c7f" translate="yes" xml:space="preserve">
          <source>Gradients for Local Response Normalization.</source>
          <target state="translated">局部响应归一化的梯度。</target>
        </trans-unit>
        <trans-unit id="18ab0670f94b562da8b866c0ee514e88a5366f1c" translate="yes" xml:space="preserve">
          <source>Gradients for batch normalization.</source>
          <target state="translated">梯度进行批量归一化。</target>
        </trans-unit>
        <trans-unit id="9c2ad4a85cafc13c2d1c2d3a2971b83be82a10c3" translate="yes" xml:space="preserve">
          <source>GraphDef containing a simplified version of the original.</source>
          <target state="translated">包含原始简化版的GraphDef。</target>
        </trans-unit>
        <trans-unit id="f1121f5d0ae3561a0535bf5eed70bebc9b4c573d" translate="yes" xml:space="preserve">
          <source>GraphDef object holding the network.</source>
          <target state="translated">拥有网络的GraphDef对象。</target>
        </trans-unit>
        <trans-unit id="88f6daec0a60e7783e784d139db2e8caa801c093" translate="yes" xml:space="preserve">
          <source>Graphically the output tensors are:</source>
          <target state="translated">从图形上看,输出的腾博会登录是。</target>
        </trans-unit>
        <trans-unit id="29346dfd9c70ea134e70f14b812447401491ea5b" translate="yes" xml:space="preserve">
          <source>Graphically this is equivalent to doing</source>
          <target state="translated">从图形上看,这相当于做</target>
        </trans-unit>
        <trans-unit id="20a2426b7947c82cb1587611210e101486083cc8" translate="yes" xml:space="preserve">
          <source>Graphs are used by &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s to represent the function's computations. Each graph contains a set of &lt;a href=&quot;operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt; objects, which represent units of computation; and &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects, which represent the units of data that flow between operations.</source>
          <target state="translated">&lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; s 使用图形表示函数的计算。每个图包含一组&lt;a href=&quot;operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt;对象，它们表示计算单位；和&lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt;对象，其表示数据的操作之间流动的单位。</target>
        </trans-unit>
        <trans-unit id="c0c7d8111372100880daccbc5bf26be1b2464f9e" translate="yes" xml:space="preserve">
          <source>Greater</source>
          <target state="translated">Greater</target>
        </trans-unit>
        <trans-unit id="f20c1c201cbb34ee5875869c7087a3e926efb3b7" translate="yes" xml:space="preserve">
          <source>GreaterEqual</source>
          <target state="translated">GreaterEqual</target>
        </trans-unit>
        <trans-unit id="e5695443f7cf0378e67e28d423fc90003e20fdde" translate="yes" xml:space="preserve">
          <source>Greedily selects a subset of bounding boxes in descending order of score,</source>
          <target state="translated">贪婪地按分数从高到低的顺序选择一个子集的边界框。</target>
        </trans-unit>
        <trans-unit id="58294451a76b10d6330ff549e0a6d209d1f0896b" translate="yes" xml:space="preserve">
          <source>Greedily selects a subset of bounding boxes in descending order of score.</source>
          <target state="translated">贪婪地按分数从高到低的顺序选择一个子集的边界框。</target>
        </trans-unit>
        <trans-unit id="e8494d1512cc20a8fe1e52f4aa1865ea4363ab3f" translate="yes" xml:space="preserve">
          <source>Ground truth values.</source>
          <target state="translated">地真理值。</target>
        </trans-unit>
        <trans-unit id="9cc2972f01b075253d91c217637ce9f71f2218ce" translate="yes" xml:space="preserve">
          <source>Ground truth values. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt;, except sparse loss functions such as sparse categorical crossentropy where shape = &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt;</source>
          <target state="translated">基本真理值。shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt; ，但稀疏损失函数（例如，稀疏分类交叉熵）在shape = &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c43440e34d61ec903c57a53c805f205165dc5754" translate="yes" xml:space="preserve">
          <source>Ground truth values. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt;.</source>
          <target state="translated">基本真理值。shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="38b0e82be14566bde59466131197fef45b274db7" translate="yes" xml:space="preserve">
          <source>Ground-truth targets to pass to &lt;code&gt;Model&lt;/code&gt;.</source>
          <target state="translated">真相目标传递给 &lt;code&gt;Model&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e75eb9da321613dade49081fbb0f38725be295e1" translate="yes" xml:space="preserve">
          <source>Group objects into a training checkpoint.</source>
          <target state="translated">将对象分成一个训练检查点。</target>
        </trans-unit>
        <trans-unit id="6115c228a89d1f90769cafcbd1ad268a88285c91" translate="yes" xml:space="preserve">
          <source>Group tensors together.</source>
          <target state="translated">将张力器组合在一起。</target>
        </trans-unit>
        <trans-unit id="3e4946272ebd6af7ba4e43d36dac49e1f14d4e7c" translate="yes" xml:space="preserve">
          <source>GroupByReducerDataset</source>
          <target state="translated">GroupByReducerDataset</target>
        </trans-unit>
        <trans-unit id="be8d30eb5632b02cf8f150f0a09be3b235ef07eb" translate="yes" xml:space="preserve">
          <source>GroupByWindowDataset</source>
          <target state="translated">GroupByWindowDataset</target>
        </trans-unit>
        <trans-unit id="e354b4454dd166bc154614760aa397bafa913cb1" translate="yes" xml:space="preserve">
          <source>Groups trackable objects, saving and restoring them.</source>
          <target state="translated">对可跟踪对象进行分组,保存和恢复它们。</target>
        </trans-unit>
        <trans-unit id="9d7f80cd70980946ed16aeb04c9d084b9966606a" translate="yes" xml:space="preserve">
          <source>GuaranteeConst</source>
          <target state="translated">GuaranteeConst</target>
        </trans-unit>
        <trans-unit id="7ad9a6bc86d23788bf2c1d40a823516a6f0ed768" translate="yes" xml:space="preserve">
          <source>HALF_TO_EVEN: this is the default round_mode.</source>
          <target state="translated">HALF_TO_EVEN:这是默认的round_mode。</target>
        </trans-unit>
        <trans-unit id="920da21317add9910b40605a155029f67d570159" translate="yes" xml:space="preserve">
          <source>HALF_UP: round towards positive. In this mode 7.5 rounds up to 8 and -7.5 rounds up to -7.</source>
          <target state="translated">HALF_UP:向正数进位。在此模式下,7.5进位到8,-7.5进位到-7。</target>
        </trans-unit>
        <trans-unit id="29d6a74360835e2659133e31def98e713b027ad9" translate="yes" xml:space="preserve">
          <source>HSVToRGB</source>
          <target state="translated">HSVToRGB</target>
        </trans-unit>
        <trans-unit id="11ef29d704891a60b088172f8178a63b75138495" translate="yes" xml:space="preserve">
          <source>Hard sigmoid activation function.</source>
          <target state="translated">硬性乙状腺激活功能。</target>
        </trans-unit>
        <trans-unit id="89d0493bf3e9638199b6b1d86f1632bbe9719ae3" translate="yes" xml:space="preserve">
          <source>Has Gradient</source>
          <target state="translated">具有渐变性</target>
        </trans-unit>
        <trans-unit id="a7f2a37788a5eae46019711a7835ecdefc241070" translate="yes" xml:space="preserve">
          <source>HashTable</source>
          <target state="translated">HashTable</target>
        </trans-unit>
        <trans-unit id="acf8fdc7f2d880260a7d0b7da811515282e4330f" translate="yes" xml:space="preserve">
          <source>HashTableV2</source>
          <target state="translated">HashTableV2</target>
        </trans-unit>
        <trans-unit id="b62d591ef71e520dcc0fd2d5494b2b952c2c9902" translate="yes" xml:space="preserve">
          <source>Hasim Sak, Andrew Senior, and Francoise Beaufays. &quot;Long short-term memory recurrent neural network architectures for large scale acoustic modeling.&quot; INTERSPEECH, 2014.</source>
          <target state="translated">Hasim Sak、Andrew Senior和Francoise Beaufays。&quot;Long short-term memory recurrent neural network architectures for large scale acoustic modeling.&quot; INTERSPEECH,2014年。</target>
        </trans-unit>
        <trans-unit id="7acbb15ccffab6beca727a0d69870bfb5c290df1" translate="yes" xml:space="preserve">
          <source>Have a &lt;code&gt;go_backwards&lt;/code&gt;, &lt;code&gt;return_sequences&lt;/code&gt; and &lt;code&gt;return_state&lt;/code&gt; attribute (with the same semantics as for the &lt;code&gt;RNN&lt;/code&gt; class).</source>
          <target state="translated">具有 &lt;code&gt;go_backwards&lt;/code&gt; ， &lt;code&gt;return_sequences&lt;/code&gt; 和 &lt;code&gt;return_state&lt;/code&gt; 属性（具有与 &lt;code&gt;RNN&lt;/code&gt; 类相同的语义）。</target>
        </trans-unit>
        <trans-unit id="b06caab1d8003a14cb6c5ee52eb330ca47603350" translate="yes" xml:space="preserve">
          <source>Have an &lt;code&gt;input_spec&lt;/code&gt; attribute.</source>
          <target state="translated">具有 &lt;code&gt;input_spec&lt;/code&gt; 属性。</target>
        </trans-unit>
        <trans-unit id="8dd6a3bb0aa8fcc99cb2926cb3630295183067dd" translate="yes" xml:space="preserve">
          <source>Having access to such information is useful when user needs to run specific code according to task types. For example,</source>
          <target state="translated">当用户需要根据任务类型运行特定的代码时,访问这些信息是非常有用的。例如:</target>
        </trans-unit>
        <trans-unit id="c4021193208114328b08be8cf728a91eb62ae42b" translate="yes" xml:space="preserve">
          <source>He et al., 2015</source>
          <target state="translated">He等人,2015年</target>
        </trans-unit>
        <trans-unit id="2579614b073edd33dff24698cc0ed7a9d8d9b2ff" translate="yes" xml:space="preserve">
          <source>He normal initializer.</source>
          <target state="translated">他正常的初始化器。</target>
        </trans-unit>
        <trans-unit id="c820b6e271aeb8c0992aef844f7e9688ee27c3ff" translate="yes" xml:space="preserve">
          <source>He uniform variance scaling initializer.</source>
          <target state="translated">他统一方差缩放初始化器。</target>
        </trans-unit>
        <trans-unit id="b2a0825f5cf85b0813ba4a932833d3b427e828d7" translate="yes" xml:space="preserve">
          <source>Head sits on top of the model network and handles computing the outputs of the network. Given logits (or output of a hidden layer), a Head knows how to compute predictions, loss, train_op, metrics and export outputs. It is meant to:</source>
          <target state="translated">Head位于模型网络之上,负责计算网络的输出。给定logits(或隐藏层的输出),Head知道如何计算预测、损失、train_op、度量和输出。它的目的是。</target>
        </trans-unit>
        <trans-unit id="110183a1eb73ab34fd4a98c264cc9d76f023cc2a" translate="yes" xml:space="preserve">
          <source>Heartbeats may be sent periodically to indicate the coordinator is still active, to retrieve the current worker status and to expedite shutdown when necessary.</source>
          <target state="translated">可定期发送心跳,以表示协调器仍在活动,必要时检索当前工人状态,并加快关机。</target>
        </trans-unit>
        <trans-unit id="065c2e0bd4aa8ce24245293e18fcb73620f8829e" translate="yes" xml:space="preserve">
          <source>Height of output image.</source>
          <target state="translated">输出图像的高度。</target>
        </trans-unit>
        <trans-unit id="02e0e2ad93d9b9dfcf2dfc29c4e34a5e7ed6029e" translate="yes" xml:space="preserve">
          <source>Height of the result.</source>
          <target state="translated">结果的高度。</target>
        </trans-unit>
        <trans-unit id="724391cae7df3c6f2f078aa757c3203246f50dfa" translate="yes" xml:space="preserve">
          <source>Helpers to manipulate a tensor graph in python.</source>
          <target state="translated">在python中操作张量图的助手。</target>
        </trans-unit>
        <trans-unit id="a9a20ef1cc1f4b45d357341f3d6bf25221e22949" translate="yes" xml:space="preserve">
          <source>Hence, the &lt;code&gt;SparseTensor&lt;/code&gt; result has exactly the same non-zero indices and shape.</source>
          <target state="translated">因此， &lt;code&gt;SparseTensor&lt;/code&gt; 结果具有完全相同的非零索引和形状。</target>
        </trans-unit>
        <trans-unit id="67314232dbebd248ae3b761c240375d141928549" translate="yes" xml:space="preserve">
          <source>Hence, to ensure stability and avoid overflow, the implementation uses this equivalent formulation</source>
          <target state="translated">因此,为了保证稳定性,避免溢出,在实施中采用了这样的等价公式</target>
        </trans-unit>
        <trans-unit id="15496dff970b77a7dd905044c63378f4105e5937" translate="yes" xml:space="preserve">
          <source>Here is a code example for using &lt;code&gt;AdditiveAttention&lt;/code&gt; in a CNN+Attention network:</source>
          <target state="translated">这是在CNN + Attention网络中使用 &lt;code&gt;AdditiveAttention&lt;/code&gt; 的代码示例：</target>
        </trans-unit>
        <trans-unit id="af1e9525f99564803e6dc214d93b54de55e718e8" translate="yes" xml:space="preserve">
          <source>Here is a code example for using &lt;code&gt;Attention&lt;/code&gt; in a CNN+Attention network:</source>
          <target state="translated">这是在CNN + Attention网络中使用 &lt;code&gt;Attention&lt;/code&gt; 的代码示例：</target>
        </trans-unit>
        <trans-unit id="c2e3cf832e96b3ad2b7cfe3cb8d1e7045a255de6" translate="yes" xml:space="preserve">
          <source>Here is a table of the (roughly) expected first order behavior:</source>
          <target state="translated">下面是一个(大致)预期的一阶行为的表格。</target>
        </trans-unit>
        <trans-unit id="0dcb732b904f60bb8f4fb4132ab1bc7ce4c1dc40" translate="yes" xml:space="preserve">
          <source>Here is an example embedding of two features for a DNNClassifier model:</source>
          <target state="translated">这里是一个DNNClassifier模型的两个特征嵌入的例子。</target>
        </trans-unit>
        <trans-unit id="b92188d0e4470161bf6ef1be354a49527229f664" translate="yes" xml:space="preserve">
          <source>Here is an example of a standard reader function a user can define. This function enables both dataset shuffling and parallel reading of datasets:</source>
          <target state="translated">这里是一个用户可以定义的标准读取器函数的例子。这个函数可以实现数据集的洗牌和数据集的并行读取。</target>
        </trans-unit>
        <trans-unit id="b5a139c16bbbe2e00002f4ebb6bf2d7cf0a12e13" translate="yes" xml:space="preserve">
          <source>Here is an example to create a linear model with crosses of string features:</source>
          <target state="translated">下面是一个创建线性模型与字符串特征交叉的例子。</target>
        </trans-unit>
        <trans-unit id="464c6369ff2a08fe078373832f4183bb8de964e9" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;code&gt;embedding_column&lt;/code&gt; with model_fn:</source>
          <target state="translated">这是将 &lt;code&gt;embedding_column&lt;/code&gt; 与model_fn结合使用的示例：</target>
        </trans-unit>
        <trans-unit id="bd511335f37b0684a350a25bab28497fe427dcb9" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;code&gt;shared_embedding_columns&lt;/code&gt; with model_fn:</source>
          <target state="translated">这是将 &lt;code&gt;shared_embedding_columns&lt;/code&gt; 与model_fn 结合使用的示例：</target>
        </trans-unit>
        <trans-unit id="e0362ba3fd11b51dc2dbcaf3363290ca8a7b99e6" translate="yes" xml:space="preserve">
          <source>Here is simplified model_fn to build a DNN regression model.</source>
          <target state="translated">这里简化了model_fn来建立DNN回归模型。</target>
        </trans-unit>
        <trans-unit id="bb290e88257943f8b204cd2522934a4d03f0b94a" translate="yes" xml:space="preserve">
          <source>Here the expectation is that the &lt;code&gt;input_fn_*&lt;/code&gt; functions passed to train and evaluate return a pair (dict, label_tensor) where dict has &lt;code&gt;example_id_column&lt;/code&gt; as &lt;code&gt;key&lt;/code&gt; whose value is a &lt;code&gt;Tensor&lt;/code&gt; of shape [batch_size] and dtype string. num_loss_partitions defines sigma' in eq (11) of [3]. Convergence of (global) loss is guaranteed if &lt;code&gt;num_loss_partitions&lt;/code&gt; is larger or equal to the product &lt;code&gt;(#concurrent train ops/per worker) x (#workers)&lt;/code&gt;. Larger values for &lt;code&gt;num_loss_partitions&lt;/code&gt; lead to slower convergence. The recommended value for &lt;code&gt;num_loss_partitions&lt;/code&gt; in &lt;a href=&quot;../../estimator&quot;&gt;&lt;code&gt;tf.estimator&lt;/code&gt;&lt;/a&gt; (where currently there is one process per worker) is the number of workers running the train steps. It defaults to 1 (single machine). &lt;code&gt;num_table_shards&lt;/code&gt; defines the number of shards for the internal state table, typically set to match the number of parameter servers for large data sets.</source>
          <target state="translated">这里的期望是传递给训练和评估的 &lt;code&gt;input_fn_*&lt;/code&gt; 函数返回一对（dict，label_tensor），其中dict以 &lt;code&gt;example_id_column&lt;/code&gt; 作为 &lt;code&gt;key&lt;/code&gt; 其值是形状为[batch_size] 的 &lt;code&gt;Tensor&lt;/code&gt; 和dtype字符串。 num_loss_partitions在[3]的等式（11）中定义sigma'。如果 &lt;code&gt;num_loss_partitions&lt;/code&gt; 大于或等于乘积 &lt;code&gt;(#concurrent train ops/per worker) x (#workers)&lt;/code&gt; ，则（全局）损失的收敛性得到保证。 &lt;code&gt;num_loss_partitions&lt;/code&gt; 的值越大，收敛越慢。 &lt;code&gt;num_loss_partitions&lt;/code&gt; 中&lt;a href=&quot;../../estimator&quot;&gt; &lt;code&gt;tf.estimator&lt;/code&gt; &lt;/a&gt;的建议值（当前每个工人只有一个过程）是运行火车台阶的工人数量。默认为1（单机）。 &lt;code&gt;num_table_shards&lt;/code&gt; 定义内部状态表的分片数量，通常设置为与大型数据集的参数服务器数量匹配。</target>
        </trans-unit>
        <trans-unit id="6fd075a1cf6908e13f7823aaaf120524aec476bf" translate="yes" xml:space="preserve">
          <source>Here the partial derivatives &lt;code&gt;g&lt;/code&gt; evaluate to &lt;code&gt;[1.0, 1.0]&lt;/code&gt;, compared to the total derivatives &lt;code&gt;tf.gradients(a + b, [a, b])&lt;/code&gt;, which take into account the influence of &lt;code&gt;a&lt;/code&gt; on &lt;code&gt;b&lt;/code&gt; and evaluate to &lt;code&gt;[3.0, 1.0]&lt;/code&gt;. Note that the above is equivalent to:</source>
          <target state="translated">与总导数 &lt;code&gt;tf.gradients(a + b, [a, b])&lt;/code&gt; 相比，此处偏导数 &lt;code&gt;g&lt;/code&gt; 的取值为 &lt;code&gt;[1.0, 1.0]&lt;/code&gt; 1.0，1.0]，考虑了 &lt;code&gt;a&lt;/code&gt; 对 &lt;code&gt;b&lt;/code&gt; 的影响并取值为 &lt;code&gt;[3.0, 1.0]&lt;/code&gt; 3.0，1.0 ]。请注意，以上等同于：</target>
        </trans-unit>
        <trans-unit id="49c2e9085ffe62b7af2e00831b5211eb57d553ec" translate="yes" xml:space="preserve">
          <source>Here we check that this operator is &lt;em&gt;exactly&lt;/em&gt; equal to its hermitian transpose.</source>
          <target state="translated">在这里，我们检查该运算符是否&lt;em&gt;完全&lt;/em&gt;等于其厄米转置。</target>
        </trans-unit>
        <trans-unit id="5f52f6e66184e816627dceffc4afecf746fff88d" translate="yes" xml:space="preserve">
          <source>Here we consider NASNet-A, the highest performance model that was found for the CIFAR-10 dataset, and then extended to ImageNet 2012 dataset, obtaining state of the art performance on CIFAR-10 and ImageNet 2012. Only the NASNet-A models, and their respective weights, which are suited for ImageNet 2012 are provided.</source>
          <target state="translated">在这里,我们考虑的是在CIFAR-10数据集上发现的性能最高的模型NASNet-A,然后扩展到ImageNet 2012数据集,在CIFAR-10和ImageNet 2012上获得了最先进的性能。本文只提供适合ImageNet 2012的NASNet-A模型及其各自的权重。</target>
        </trans-unit>
        <trans-unit id="8a715d375560e6afb15b0e0d6332a8c3f5a410ac" translate="yes" xml:space="preserve">
          <source>Here's a basic example: a layer with two variables, &lt;code&gt;w&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, that returns &lt;code&gt;y = w . x + b&lt;/code&gt;. It shows how to implement &lt;code&gt;build()&lt;/code&gt; and &lt;code&gt;call()&lt;/code&gt;. Variables set as attributes of a layer are tracked as weights of the layers (in &lt;code&gt;layer.weights&lt;/code&gt;).</source>
          <target state="translated">这是一个基本示例：具有两个变量 &lt;code&gt;w&lt;/code&gt; 和 &lt;code&gt;b&lt;/code&gt; 的层，返回 &lt;code&gt;y = w . x + b&lt;/code&gt; 。它显示了如何实现 &lt;code&gt;build()&lt;/code&gt; 和 &lt;code&gt;call()&lt;/code&gt; 。设置为图层属性的变量将作为图层的权重（在 &lt;code&gt;layer.weights&lt;/code&gt; 中）进行跟踪。</target>
        </trans-unit>
        <trans-unit id="27c376c1d7316f3407dd139c89bd36e269d0b657" translate="yes" xml:space="preserve">
          <source>Here's a simple example: a random normal initializer.</source>
          <target state="translated">这里有一个简单的例子:随机法线初始化器。</target>
        </trans-unit>
        <trans-unit id="66a65bf97c24fbc1825d0d9c6cb98cb1aafb52a0" translate="yes" xml:space="preserve">
          <source>Here, 'types' means the profiler nodes' properties. Profiler by default consider device name (e.g. /job:xx/.../device:GPU:0) and operation type (e.g. MatMul) as profiler nodes' properties. User can also associate customized 'types' to profiler nodes through OpLogProto proto.</source>
          <target state="translated">这里的 &quot;类型 &quot;指的是profiler节点的属性。Profiler默认将设备名称(如/job:xx/.../device:GPU:0)和操作类型(如MatMul)作为剖析器节点的属性。用户也可以通过OpLogProto proto将自定义的 &quot;类型 &quot;关联到剖析器节点。</target>
        </trans-unit>
        <trans-unit id="17b2af2adfe30a3aef16e7ccfa94f34d6e4b3818" translate="yes" xml:space="preserve">
          <source>Here, a snapshot of &lt;code&gt;v&lt;/code&gt; is captured in &lt;code&gt;value&lt;/code&gt;; and then &lt;code&gt;v&lt;/code&gt; is updated. The snapshot value is returned.</source>
          <target state="translated">这里， &lt;code&gt;v&lt;/code&gt; 的快照被捕获为 &lt;code&gt;value&lt;/code&gt; ；然后 &lt;code&gt;v&lt;/code&gt; 被更新。返回快照值。</target>
        </trans-unit>
        <trans-unit id="ece63641c90490d540658510825631e924c7c84b" translate="yes" xml:space="preserve">
          <source>Here, adding &lt;code&gt;use_resource=True&lt;/code&gt; when constructing the variable will fix any nondeterminism issues:</source>
          <target state="translated">此处，在构造变量时添加 &lt;code&gt;use_resource=True&lt;/code&gt; 将解决所有不确定性问题：</target>
        </trans-unit>
        <trans-unit id="94f786d71b2cb60eeb24aa9948d9d1f390afdf17" translate="yes" xml:space="preserve">
          <source>Here, positive definite means that the quadratic form &lt;code&gt;x^H A x&lt;/code&gt; has positive real part for all nonzero &lt;code&gt;x&lt;/code&gt;. Note that we do not require the operator to be self-adjoint to be positive definite.</source>
          <target state="translated">在此，正定表示所有非零 &lt;code&gt;x&lt;/code&gt; 的二次形式 &lt;code&gt;x^H A x&lt;/code&gt; 具有正实部。注意，我们不要求运算符必须是自伴的，才能是正定的。</target>
        </trans-unit>
        <trans-unit id="51f5cbd0286b6bc2be5272d73eef56b1e6b7773c" translate="yes" xml:space="preserve">
          <source>Here, the input has a batch of 1 and each batch element has shape &lt;code&gt;[1, 1, 4]&lt;/code&gt;, the corresponding output will have 2x2 elements and will have a depth of 1 channel (1 = &lt;code&gt;4 / (block_size * block_size)&lt;/code&gt;). The output element shape is &lt;code&gt;[2, 2, 1]&lt;/code&gt;.</source>
          <target state="translated">在这里，输入的批次为1，每个批次元素的形状为 &lt;code&gt;[1, 1, 4]&lt;/code&gt; 1，1，4 ]，相应的输出将具有2x2元素，并且深度为1通道（1 = &lt;code&gt;4 / (block_size * block_size)&lt;/code&gt; ）。输出元素的形状为 &lt;code&gt;[2, 2, 1]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2cace8ea6c5a3f6f36376df736083d35d45c704d" translate="yes" xml:space="preserve">
          <source>Here, the input has a batch of 1 and each batch element has shape &lt;code&gt;[2, 2, 1]&lt;/code&gt;, the corresponding output will have a single element (i.e. width and height are both 1) and will have a depth of 4 channels (1 * block_size * block_size). The output element shape is &lt;code&gt;[1, 1, 4]&lt;/code&gt;.</source>
          <target state="translated">在这里，输入的批次为1，每个批次元素的形状为 &lt;code&gt;[2, 2, 1]&lt;/code&gt; ，相应的输出将具有单个元素（即，宽度和高度均为1），深度为4通道（1 * block_size * block_size）。输出元素的形状为 &lt;code&gt;[1, 1, 4]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0cd54db7611e23329deb591ac691703bafcd3e97" translate="yes" xml:space="preserve">
          <source>Hierarchical level of the Ophint node, a number.</source>
          <target state="translated">Ophint节点的层级,一个数字。</target>
        </trans-unit>
        <trans-unit id="9ecfb1194a3a379261dd07bbb066a5568e6506a9" translate="yes" xml:space="preserve">
          <source>Hinton, 2012</source>
          <target state="translated">Hinton,2012年</target>
        </trans-unit>
        <trans-unit id="61b43f0b6cf6e4d96507128fea4cd7b8a90efe5a" translate="yes" xml:space="preserve">
          <source>Hints for collective operations like AllReduce.</source>
          <target state="translated">AllReduce等集体操作的提示。</target>
        </trans-unit>
        <trans-unit id="7d3bab4ff1c30c8ba838d1595446d9004c083483" translate="yes" xml:space="preserve">
          <source>HistogramFixedWidth</source>
          <target state="translated">HistogramFixedWidth</target>
        </trans-unit>
        <trans-unit id="a53dafd06d1ebe965ea309d8c08e1156b67e2e5e" translate="yes" xml:space="preserve">
          <source>HistogramSummary</source>
          <target state="translated">HistogramSummary</target>
        </trans-unit>
        <trans-unit id="e8876b9619eb77ec487c16beae68d94edd272b99" translate="yes" xml:space="preserve">
          <source>Holds a defined flag.</source>
          <target state="translated">持有定义的旗帜。</target>
        </trans-unit>
        <trans-unit id="f41c0836949b26db8a72f139bb0d93a63f27a5d8" translate="yes" xml:space="preserve">
          <source>Holds a list of enqueue operations for a queue, each to be run in a thread.</source>
          <target state="translated">保存一个队列的enqueue操作列表,每个操作都要在一个线程中运行。</target>
        </trans-unit>
        <trans-unit id="82f1d229094d8c503d561ee75fa7b2f6ebb2010b" translate="yes" xml:space="preserve">
          <source>Holds state in the form of a tensor that persists across steps.</source>
          <target state="translated">以跨步的张量形式保持状态。</target>
        </trans-unit>
        <trans-unit id="a7ec66187a04150d0757954c1018dca525f600f5" translate="yes" xml:space="preserve">
          <source>Hook method for deconstructing the class fixture after running all tests in the class.</source>
          <target state="translated">在类中运行所有测试后,用于解构类夹具的钩子方法。</target>
        </trans-unit>
        <trans-unit id="aed79b3c251b0477f07982fb328ebad89154bf47" translate="yes" xml:space="preserve">
          <source>Hook method for deconstructing the test fixture after testing it.</source>
          <target state="translated">钩子法在测试夹具后对其进行解构。</target>
        </trans-unit>
        <trans-unit id="d3376d91b293e2ef0e2b7a2f9d722cde34fcb75c" translate="yes" xml:space="preserve">
          <source>Hook method for setting up class fixture before running tests in the class.</source>
          <target state="translated">钩子方法,用于在类中运行测试前设置类的固定装置。</target>
        </trans-unit>
        <trans-unit id="2f3856f3bee2218da00682ea5300db8d8a163355" translate="yes" xml:space="preserve">
          <source>Hook method for setting up the test fixture before exercising it.</source>
          <target state="translated">钩法在行使前设置测试夹具。</target>
        </trans-unit>
        <trans-unit id="8b036bc6887a5488ae47380e1e40457b96130270" translate="yes" xml:space="preserve">
          <source>Hook that counts steps per second.</source>
          <target state="translated">钩子,每秒计算步数。</target>
        </trans-unit>
        <trans-unit id="c583828ba4633b5282cbe15aa8308cd7a4ae402f" translate="yes" xml:space="preserve">
          <source>Hook that requests stop at a specified step.</source>
          <target state="translated">钩子,请求停止在指定的步骤。</target>
        </trans-unit>
        <trans-unit id="694af7941c3209602c7a59e4452f1ab6fd0ed608" translate="yes" xml:space="preserve">
          <source>Hook to extend calls to MonitoredSession.run().</source>
          <target state="translated">用于扩展对MonitoredSession.run()的调用的钩子。</target>
        </trans-unit>
        <trans-unit id="5e1bd302daecf16d1f3450073dcb3bb5f7b9e87f" translate="yes" xml:space="preserve">
          <source>Hook to run evaluation in training without a checkpoint.</source>
          <target state="translated">钩在训练中运行评估,不设检查点。</target>
        </trans-unit>
        <trans-unit id="094e7dc095dce31db8b2d945d9b4e16d81e5603c" translate="yes" xml:space="preserve">
          <source>Hooks can use this function to request stop of iterations. &lt;code&gt;MonitoredSession&lt;/code&gt; checks whether this is called or not.</source>
          <target state="translated">挂钩可以使用此功能来请求停止迭代。 &lt;code&gt;MonitoredSession&lt;/code&gt; 检查是否调用了此方法。</target>
        </trans-unit>
        <trans-unit id="9b63e3c3d34964d61b02e9af3acc454228fbfd58" translate="yes" xml:space="preserve">
          <source>Hooks interact with the &lt;code&gt;run_with_hooks()&lt;/code&gt; call inside the &lt;code&gt;step_fn&lt;/code&gt; as they do with a &lt;code&gt;MonitoredSession.run&lt;/code&gt; call.</source>
          <target state="translated">钩与互动 &lt;code&gt;run_with_hooks()&lt;/code&gt; 的调用内 &lt;code&gt;step_fn&lt;/code&gt; 因为他们做了 &lt;code&gt;MonitoredSession.run&lt;/code&gt; 电话。</target>
        </trans-unit>
        <trans-unit id="d8fa61e89297f89e6206a39ad26727e4b2370a10" translate="yes" xml:space="preserve">
          <source>Horizontal coordinate of the top-left corner of the result in the input.</source>
          <target state="translated">输入结果的左上角的水平坐标。</target>
        </trans-unit>
        <trans-unit id="a54dcdd14e5ce50144dff46fc76cb90c2aac998a" translate="yes" xml:space="preserve">
          <source>How a layer uses its policy's compute dtype</source>
          <target state="translated">层如何使用其策略的计算dtype。</target>
        </trans-unit>
        <trans-unit id="8f2288d55767c1f8629065632e650bab29069f12" translate="yes" xml:space="preserve">
          <source>How a layer uses its policy's variable dtype</source>
          <target state="translated">一层如何使用它的策略变量dtype?</target>
        </trans-unit>
        <trans-unit id="fd6f229db07ef1c3400e9df85c28b2f4cdc8a8b7" translate="yes" xml:space="preserve">
          <source>How identities that are created are named.</source>
          <target state="translated">创建的身份如何命名。</target>
        </trans-unit>
        <trans-unit id="56338367b61d14699e1f7174329b84eb9405e3d2" translate="yes" xml:space="preserve">
          <source>How often to apply decay.</source>
          <target state="translated">多久施用一次衰减。</target>
        </trans-unit>
        <trans-unit id="18377df79aa141396de4dd094b00a669cf41e8fd" translate="yes" xml:space="preserve">
          <source>How often to keep checkpoints. Defaults to 10,000 hours.</source>
          <target state="translated">多久保留一次检查点。默认为10,000小时。</target>
        </trans-unit>
        <trans-unit id="a2d47c5b2670b24370374b073fdcc8981f93f9f3" translate="yes" xml:space="preserve">
          <source>How to choose:</source>
          <target state="translated">如何选择。</target>
        </trans-unit>
        <trans-unit id="e3b73487529c5d6e94a503e64f0fdd72a394754d" translate="yes" xml:space="preserve">
          <source>How to gate the computation of gradients. Can be &lt;code&gt;GATE_NONE&lt;/code&gt;, &lt;code&gt;GATE_OP&lt;/code&gt;, or &lt;code&gt;GATE_GRAPH&lt;/code&gt;.</source>
          <target state="translated">如何控制梯度的计算。可以是 &lt;code&gt;GATE_NONE&lt;/code&gt; ， &lt;code&gt;GATE_OP&lt;/code&gt; 或 &lt;code&gt;GATE_GRAPH&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a70232ceb55af558f2ee0aaffe46fc01d689778f" translate="yes" xml:space="preserve">
          <source>How to handle text to bytes encoding errors. Only used if &lt;code&gt;content&lt;/code&gt; is text.</source>
          <target state="translated">如何处理文本到字节的编码错误。仅在 &lt;code&gt;content&lt;/code&gt; 为文本时使用。</target>
        </trans-unit>
        <trans-unit id="b43d30453d0ca08342c32b5bf9b8ce3e75e7c394" translate="yes" xml:space="preserve">
          <source>How to set &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; arguments:</source>
          <target state="translated">如何设置&lt;a href=&quot;../session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt;参数：</target>
        </trans-unit>
        <trans-unit id="16612609ea0121d74a2ebf85615c5cd0d97d528b" translate="yes" xml:space="preserve">
          <source>How to use float64 in a Keras model</source>
          <target state="translated">如何在Keras模型中使用float64?</target>
        </trans-unit>
        <trans-unit id="5207d3c1fa3b2863bdee0225b56cf4e73f598a8c" translate="yes" xml:space="preserve">
          <source>How to use mixed precision in a Keras model</source>
          <target state="translated">如何在Keras模型中使用混合精度?</target>
        </trans-unit>
        <trans-unit id="e91f1ba40e84a0d707e3f45076f0f821dd55b6b7" translate="yes" xml:space="preserve">
          <source>How to write a layer that supports mixed precision and float64.</source>
          <target state="translated">如何编写一个支持混合精度和float64的层。</target>
        </trans-unit>
        <trans-unit id="cb1a3d087cf7ab9ae32a2d72ddafa8d585fa12c7" translate="yes" xml:space="preserve">
          <source>However, &lt;code&gt;broadcast_to&lt;/code&gt; does not carry with it any such benefits. The newly-created tensor takes the full memory of the broadcasted shape. (In a graph context, &lt;code&gt;broadcast_to&lt;/code&gt; might be fused to subsequent operation and then be optimized away, however.)</source>
          <target state="translated">但是， &lt;code&gt;broadcast_to&lt;/code&gt; 并没有带来任何这种好处。新创建的张量将占用广播形状的全部内存。（在图形上下文中， &lt;code&gt;broadcast_to&lt;/code&gt; 可能会与后续操作融合，然后被优化掉。）</target>
        </trans-unit>
        <trans-unit id="95c24f970b239a2e8ff2902447bb8c0e66d29239" translate="yes" xml:space="preserve">
          <source>However, a few other options are available:</source>
          <target state="translated">不过,也有一些其他的选择。</target>
        </trans-unit>
        <trans-unit id="906c66a75c112f0781943a37770b2aadd044fd08" translate="yes" xml:space="preserve">
          <source>However, in the case of the &lt;code&gt;BatchNormalization&lt;/code&gt; layer, &lt;strong&gt;setting &lt;code&gt;trainable = False&lt;/code&gt; on the layer means that the layer will be subsequently run in inference mode&lt;/strong&gt; (meaning that it will use the moving mean and the moving variance to normalize the current batch, rather than using the mean and variance of the current batch).</source>
          <target state="translated">但是，对于 &lt;code&gt;BatchNormalization&lt;/code&gt; 层，&lt;strong&gt;在该层上&lt;/strong&gt;&lt;strong&gt;设置 &lt;code&gt;trainable = False&lt;/code&gt; &lt;/strong&gt;trainable &lt;strong&gt;= False&lt;/strong&gt;&lt;strong&gt;意味着该层随后将以推理模式运行&lt;/strong&gt;（这意味着它将使用移动平均值和移动方差对当前批次进行归一化，而不是使用当前批次的均值和方差）。</target>
        </trans-unit>
        <trans-unit id="66a412ca5b09706643cf60849a60f29942f3b139" translate="yes" xml:space="preserve">
          <source>However, it is slower than &lt;code&gt;clip_by_norm()&lt;/code&gt; because all the parameters must be ready before the clipping operation can be performed.</source>
          <target state="translated">但是，它比 &lt;code&gt;clip_by_norm()&lt;/code&gt; 慢，因为在执行剪切操作之前必须准备好所有参数。</target>
        </trans-unit>
        <trans-unit id="6a7bc5ae946d568d89cd6bbe9faf1d5289b758f4" translate="yes" xml:space="preserve">
          <source>However, reducing using the above operator leads to a different computation tree (logs are taken repeatedly instead of only at the end), and the maximum is only computed pairwise instead of over the entire prefix. In general, this leads to a different and slightly less precise computation.</source>
          <target state="translated">然而,使用上面的运算符进行还原会导致不同的计算树(日志被反复取而不是只在最后取),而且最大值只是成对地计算,而不是在整个前缀上计算。一般来说,这导致了不同的计算,而且计算的精确性稍差。</target>
        </trans-unit>
        <trans-unit id="1596f4749baf86a816336887cccc4e62582c58ee" translate="yes" xml:space="preserve">
          <source>However, sometimes the container orchestration framework will set TF_CONFIG for you. In this case, you can just create an instance without passing in any arguments. You can find an example here to let Kuburnetes set TF_CONFIG for you: https://github.com/tensorflow/ecosystem/tree/master/kubernetes. Then you can use it with &lt;a href=&quot;../strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; as:</source>
          <target state="translated">但是，有时容器编排框架会为您设置TF_CONFIG。在这种情况下，您可以直接创建实例，而无需传入任何参数。您可以在此处找到让Kuburnetes为您设置TF_CONFIG的示例：https：//github.com/tensorflow/ecosystem/tree/master/kubernetes。然后，您可以将其与&lt;a href=&quot;../strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;一起使用：</target>
        </trans-unit>
        <trans-unit id="ee99d120cbadc6a5aa63deb6ecfc26724317acd1" translate="yes" xml:space="preserve">
          <source>However, the number of GPUs available to the runtime may change during runtime initialization due to marking certain devices as not visible or configuring multiple logical devices.</source>
          <target state="translated">然而,在运行时初始化过程中,由于将某些设备标记为不可见或配置多个逻辑设备,运行时可用的GPU数量可能会发生变化。</target>
        </trans-unit>
        <trans-unit id="f330c6ff1769454cb3a71f75c7d58d68fb24630a" translate="yes" xml:space="preserve">
          <source>However, when adding new features, one may want to unittest it before the forward compatibility window expires. This context manager enables such tests. For example:</source>
          <target state="translated">然而,当添加新功能时,人们可能希望在前向兼容性窗口到期前对其进行单元测试。这个上下文管理器可以实现这样的测试。例如:</target>
        </trans-unit>
        <trans-unit id="f0583a3e5e448e8509f2cf39238e0ea21adde84e" translate="yes" xml:space="preserve">
          <source>Hyper parameters</source>
          <target state="translated">超参数</target>
        </trans-unit>
        <trans-unit id="8c1ccbcd79a014503a1fc750addadaf475655020" translate="yes" xml:space="preserve">
          <source>Hyper parameters can be overwritten through user code:</source>
          <target state="translated">超参数可以通过用户代码进行覆盖。</target>
        </trans-unit>
        <trans-unit id="dfe3cc7ab7e1d07c07d6f364735a8a458edbcaf8" translate="yes" xml:space="preserve">
          <source>Hyperbolic tangent activation function.</source>
          <target state="translated">双曲正切激活函数。</target>
        </trans-unit>
        <trans-unit id="a15138d06876fc00149292405bf57e4204d00bbe" translate="yes" xml:space="preserve">
          <source>Hyperparameters</source>
          <target state="translated">Hyperparameters</target>
        </trans-unit>
        <trans-unit id="11ed6513569e71d14e0b5bbc27bbc91abe780c3c" translate="yes" xml:space="preserve">
          <source>Hyperparameters can be overwritten through user code:</source>
          <target state="translated">超参数可以通过用户代码进行覆盖。</target>
        </trans-unit>
        <trans-unit id="5d739908e6b1d9515c7de084c3e63bb329523667" translate="yes" xml:space="preserve">
          <source>I.e. if we have (y1, y2, ..., y_M) = f(x1, x2, ..., x_N), then, g is (dL/dx1, dL/dx2, ..., dL/dx_N) = g(x1, x2, ..., x_N, dL/dy1, dL/dy2, ..., dL/dy_M),</source>
          <target state="translated">即如果我们有(y1,y2,...,y_M)=f(x1,x2,...,x_N),那么,g就是(dL/dx1,dL/dx2,...,dL/dx_N)=g(x1,x2,...,x_N,dL/dy1,dL/dy2,...,dL/dy_M)。</target>
        </trans-unit>
        <trans-unit id="caae1c164e99fd3cee75315d0e4ac958059c8bec" translate="yes" xml:space="preserve">
          <source>I.e. returns: &lt;code&gt;output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta&lt;/code&gt;</source>
          <target state="translated">即返回： &lt;code&gt;output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ebc94333451747193def37a773f19cfc358efe8b" translate="yes" xml:space="preserve">
          <source>I.e., \(y = -x\).</source>
          <target state="translated">即:(y=-x/)。</target>
        </trans-unit>
        <trans-unit id="d175ea7778bab88b107391a5a5e9565e50febd2b" translate="yes" xml:space="preserve">
          <source>I.e., \(y = 1 / \sqrt{x}\).</source>
          <target state="translated">即:/n-</target>
        </trans-unit>
        <trans-unit id="3c2e39388106824c1d86c17eb18e27d101f691e9" translate="yes" xml:space="preserve">
          <source>I.e., \(y = 1 / x\).</source>
          <target state="translated">即:/n-</target>
        </trans-unit>
        <trans-unit id="311b2c8a6cdecac50bdfa3324556c4c9ed69923b" translate="yes" xml:space="preserve">
          <source>I.e., \(y = \log_e (1 + x)\).</source>
          <target state="translated">即(y=log_e (1+x))。</target>
        </trans-unit>
        <trans-unit id="aa71ce7ff4ae1b412d0ee6bf849a4d32aa4d9b69" translate="yes" xml:space="preserve">
          <source>I.e., \(y = \log_e x\).</source>
          <target state="translated">即:(y=log_e x)。</target>
        </trans-unit>
        <trans-unit id="8fbd8a894d77699447894ea0b5205e8c3734a34e" translate="yes" xml:space="preserve">
          <source>I.e., \(y = \sqrt{x} = x^{1/2}\).</source>
          <target state="translated">即:/n-</target>
        </trans-unit>
        <trans-unit id="86e7c2902521071ed978a52a237380dc3ce4ceb1" translate="yes" xml:space="preserve">
          <source>I.e., \(y = x * x = x^2\).</source>
          <target state="translated">即(y=x*x=x^2)。</target>
        </trans-unit>
        <trans-unit id="568335e65a798d6ef3d2eab1d09d072f51075401" translate="yes" xml:space="preserve">
          <source>I.e., the size of the outermost dimension of the tensor.</source>
          <target state="translated">即张量最外维的大小。</target>
        </trans-unit>
        <trans-unit id="6299f86715c93d989aa9695775a3b9287f113675" translate="yes" xml:space="preserve">
          <source>IFFT</source>
          <target state="translated">IFFT</target>
        </trans-unit>
        <trans-unit id="022dd53bc823f3ac17a82c70736b4706025937f5" translate="yes" xml:space="preserve">
          <source>IFFT2D</source>
          <target state="translated">IFFT2D</target>
        </trans-unit>
        <trans-unit id="fc55a7fb0443a8e9116055588513b592013129a2" translate="yes" xml:space="preserve">
          <source>IFFT3D</source>
          <target state="translated">IFFT3D</target>
        </trans-unit>
        <trans-unit id="e8e744aedc2c7c5589c77a5398c1f0d6581e556f" translate="yes" xml:space="preserve">
          <source>IMDB sentiment classification dataset.</source>
          <target state="translated">IMDB情感分类数据集。</target>
        </trans-unit>
        <trans-unit id="cd887c07fd5e921ac521a8f68bba0d58f4244bf2" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the &lt;a href=&quot;../../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementation being used, and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times (once for each replica).</source>
          <target state="translated">重要说明：取决于所使用的&lt;a href=&quot;../../../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;实现，以及是否启用了急切执行， &lt;code&gt;fn&lt;/code&gt; 可以被调用一次或多次（每个副本一次）。</target>
        </trans-unit>
        <trans-unit id="2ed0fee938570d32f30307cc8d274895cf578884" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementation being used, and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times (once for each replica).</source>
          <target state="translated">重要说明：取决于所使用的&lt;a href=&quot;../../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;实现，以及是否启用了急切执行， &lt;code&gt;fn&lt;/code&gt; 可以被调用一次或多次（每个副本一次）。</target>
        </trans-unit>
        <trans-unit id="a0b212e63aab3a82a290c7dc71cb4e212928f7d0" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;../../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="translated">重要说明：取决于&lt;a href=&quot;../../../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;的实现以及是否启用了急切执行， &lt;code&gt;fn&lt;/code&gt; 可能被调用一次或多次（每个副本一次）。</target>
        </trans-unit>
        <trans-unit id="a856b464d5ae55c9c4b023a3135a60ea8e61e4aa" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="translated">重要说明：取决于&lt;a href=&quot;../../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;的实现以及是否启用了急切执行， &lt;code&gt;fn&lt;/code&gt; 可能被调用一次或多次（每个副本一次）。</target>
        </trans-unit>
        <trans-unit id="115e1c114d9f3681f99e56d6543c4b81c3fc3d32" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;../strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="translated">重要说明：取决于&lt;a href=&quot;../strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;的实现以及是否启用了急切执行， &lt;code&gt;fn&lt;/code&gt; 可能被调用一次或多次（每个副本一次）。</target>
        </trans-unit>
        <trans-unit id="89f04e8da8a966a33aa44bfaa2ea3036d7113c48" translate="yes" xml:space="preserve">
          <source>IMPORTANT: Depending on the implementation of &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; and whether eager execution is enabled, &lt;code&gt;fn&lt;/code&gt; may be called one or more times ( once for each replica).</source>
          <target state="translated">重要说明：取决于&lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;的实现以及是否启用了急切执行， &lt;code&gt;fn&lt;/code&gt; 可能被调用一次或多次（每个副本一次）。</target>
        </trans-unit>
        <trans-unit id="3af46570ffb6dae63862cdf22039cbe1fe550b02" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="translated">重要说明：与使用全局批处理大小的 &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 不同，&lt;a href=&quot;../../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;返回的 &lt;code&gt;dataset_fn&lt;/code&gt; 应该具有每个副本的批处理大小。这可以使用 &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt; 进行计算。</target>
        </trans-unit>
        <trans-unit id="387e6943d94be6545861c405c7eedd2b318559f0" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="translated">重要说明：与使用全局批处理大小的 &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 不同，&lt;a href=&quot;../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;返回的 &lt;code&gt;dataset_fn&lt;/code&gt; 应该具有每个副本的批处理大小。这可以使用 &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt; 进行计算。</target>
        </trans-unit>
        <trans-unit id="371527ec937092bce8c5302761968a912dfa40b4" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="translated">重要说明：与使用全局批处理大小的 &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 不同，&lt;a href=&quot;../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;返回的 &lt;code&gt;dataset_fn&lt;/code&gt; 应该具有每个副本的批处理大小。这可以使用 &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt; 进行计算。</target>
        </trans-unit>
        <trans-unit id="2ad1bd30c735d96ef3bf70ea7676440f0a17a75f" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; returned by &lt;code&gt;dataset_fn&lt;/code&gt; should have a per-replica batch size, unlike &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;, which uses the global batch size. This may be computed using &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt;.</source>
          <target state="translated">重要说明：与使用全局批处理大小的 &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 不同，&lt;a href=&quot;../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;返回的 &lt;code&gt;dataset_fn&lt;/code&gt; 应该具有每个副本的批处理大小。这可以使用 &lt;code&gt;input_context.get_per_replica_batch_size&lt;/code&gt; 进行计算。</target>
        </trans-unit>
        <trans-unit id="d6a0418b361073a5e7f1934efa7924dff3340f39" translate="yes" xml:space="preserve">
          <source>IMPORTANT: The ordering of communications must be identical in all replicas.</source>
          <target state="translated">重要:所有副本中的通信顺序必须相同。</target>
        </trans-unit>
        <trans-unit id="94ef35d6e06d69b9a685928876f94b41c52dc1b8" translate="yes" xml:space="preserve">
          <source>INT8 precision and calibration with pre-built engines</source>
          <target state="translated">INT8精度和预制发动机校准</target>
        </trans-unit>
        <trans-unit id="02f4e09badaa8dec60af1a67b17355e9f8784a58" translate="yes" xml:space="preserve">
          <source>IRFFT</source>
          <target state="translated">IRFFT</target>
        </trans-unit>
        <trans-unit id="cd7b29bbdbb4febdf272a0721f00f37ac64b2660" translate="yes" xml:space="preserve">
          <source>IRFFT2D</source>
          <target state="translated">IRFFT2D</target>
        </trans-unit>
        <trans-unit id="505b56d0dfad67f6287be15698ed8d2d0a478343" translate="yes" xml:space="preserve">
          <source>IRFFT3D</source>
          <target state="translated">IRFFT3D</target>
        </trans-unit>
        <trans-unit id="b7fb9aff273f4e7c1abf394ced0a28207f4c3ff0" translate="yes" xml:space="preserve">
          <source>Id of the logical core to which the tensor will be assigned.</source>
          <target state="translated">将分配张量的逻辑核心的ID。</target>
        </trans-unit>
        <trans-unit id="7e5a975b6add84fd53e3710a9ceac15eb06663b7" translate="yes" xml:space="preserve">
          <source>Identity</source>
          <target state="translated">Identity</target>
        </trans-unit>
        <trans-unit id="d80b904d270ef375a1087a947ac36d152e92b4cb" translate="yes" xml:space="preserve">
          <source>Identity op for gradient debugging.</source>
          <target state="translated">梯度调试的身份操作。</target>
        </trans-unit>
        <trans-unit id="bcb6f3d33c4ea39559275c930a1a34976ca902d4" translate="yes" xml:space="preserve">
          <source>Identity transformation that models performance.</source>
          <target state="translated">身份转换,模型性能。</target>
        </trans-unit>
        <trans-unit id="a76eeb09e71e8d2d0f23e62506c812d22c2249b1" translate="yes" xml:space="preserve">
          <source>IdentityN</source>
          <target state="translated">IdentityN</target>
        </trans-unit>
        <trans-unit id="e4b9406c08cb428e87ba5ea8a378f561e51f4001" translate="yes" xml:space="preserve">
          <source>IdentityReader</source>
          <target state="translated">IdentityReader</target>
        </trans-unit>
        <trans-unit id="a0979d88b1fbcd35635c010eeafb5d1b3fed8a90" translate="yes" xml:space="preserve">
          <source>IdentityReaderV2</source>
          <target state="translated">IdentityReaderV2</target>
        </trans-unit>
        <trans-unit id="751c68a3471b1c791efaee0a8e7c24ea0c266efd" translate="yes" xml:space="preserve">
          <source>If</source>
          <target state="translated">If</target>
        </trans-unit>
        <trans-unit id="c1c674b793716e07ef9b792eb875da397416ebb5" translate="yes" xml:space="preserve">
          <source>If &quot;ortho&quot;, orthonormal inverse DCT4 is performed, if it is None, a regular dct4 followed by scaling of &lt;code&gt;1/frame_length&lt;/code&gt; is performed.</source>
          <target state="translated">如果为&amp;ldquo;正交&amp;rdquo;，则执行正交逆DCT4，如果为&amp;ldquo;无&amp;rdquo;，则执行常规dct4，然后按比例缩放 &lt;code&gt;1/frame_length&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6b472357b902f890e4087773a365cdaed808b715" translate="yes" xml:space="preserve">
          <source>If &quot;shape&quot; is None, the resulting tensor proto represents the numpy array precisely.</source>
          <target state="translated">如果 &quot;shape &quot;是None,产生的张量proto将精确地表示numpy数组。</target>
        </trans-unit>
        <trans-unit id="94418d02e3456ba7719cd5581956e1dd1bf97adf" translate="yes" xml:space="preserve">
          <source>If &quot;values&quot; is a python scalar or a python list, make_tensor_proto first convert it to numpy ndarray. If dtype is None, the conversion tries its best to infer the right numpy data type. Otherwise, the resulting numpy array has a compatible data type with the given dtype.</source>
          <target state="translated">如果 &quot;values &quot;是一个python标量或者python list,make_tensor_proto首先将其转换为numpy ndarray。如果dtype为None,则转换过程会尽力推断出正确的numpy数据类型。否则,得到的numpy数组的数据类型与给定的dtype兼容。</target>
        </trans-unit>
        <trans-unit id="ce8cd0fc85fc9a1e3f9b8136172f9b19c9148972" translate="yes" xml:space="preserve">
          <source>If 'graph_def' is not a graph_pb2.GraphDef proto.</source>
          <target state="translated">如果'graph_def'不是 graph_pb2.GraphDef proto。</target>
        </trans-unit>
        <trans-unit id="abc290220c1d811dd5249ce87700169b77049924" translate="yes" xml:space="preserve">
          <source>If 3-D, the shape is &lt;code&gt;[height, width, channels]&lt;/code&gt;, and the Tensor represents one image. If 4-D, the shape is &lt;code&gt;[batch_size, height, width, channels]&lt;/code&gt;, and the Tensor represents &lt;code&gt;batch_size&lt;/code&gt; images.</source>
          <target state="translated">如果是3-D，则形状为 &lt;code&gt;[height, width, channels]&lt;/code&gt; ，并且Tensor代表一幅图像。如果是4-D，则形状为 &lt;code&gt;[batch_size, height, width, channels]&lt;/code&gt; ，并且Tensor表示 &lt;code&gt;batch_size&lt;/code&gt; 图像。</target>
        </trans-unit>
        <trans-unit id="d1d182960fbca1d39b731de95605b52d11d64a48" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;0 &amp;lt; min &amp;lt; max&lt;/code&gt;: &lt;code&gt;min_adj = 0&lt;/code&gt; and &lt;code&gt;max_adj = max - min&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;0 &amp;lt; min &amp;lt; max&lt;/code&gt; ： &lt;code&gt;min_adj = 0&lt;/code&gt; 且 &lt;code&gt;max_adj = max - min&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2291e4d4d0493fe7acb48d2007a3752b8f7b2d33" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;A&lt;/code&gt; is block circulant, with block sizes &lt;code&gt;N0, N1&lt;/code&gt; (&lt;code&gt;N0 * N1 = N&lt;/code&gt;): &lt;code&gt;A&lt;/code&gt; has a block circulant structure, composed of &lt;code&gt;N0 x N0&lt;/code&gt; blocks, with each block an &lt;code&gt;N1 x N1&lt;/code&gt; circulant matrix.</source>
          <target state="translated">如果 &lt;code&gt;A&lt;/code&gt; 为块循环，块大小为 &lt;code&gt;N0, N1&lt;/code&gt; （ &lt;code&gt;N0 * N1 = N&lt;/code&gt; ）： &lt;code&gt;A&lt;/code&gt; 具有由 &lt;code&gt;N0 x N0&lt;/code&gt; 个块组成的块循环结构，每个块都有 &lt;code&gt;N1 x N1&lt;/code&gt; 个循环矩阵。</target>
        </trans-unit>
        <trans-unit id="d3f8efbf3d9e6147ecaa064f2b05f3a2250d33f3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;A&lt;/code&gt; is nested block circulant, with block sizes &lt;code&gt;N0, N1, N2&lt;/code&gt; (&lt;code&gt;N0 * N1 * N2 = N&lt;/code&gt;): &lt;code&gt;A&lt;/code&gt; has a block structure, composed of &lt;code&gt;N0 x N0&lt;/code&gt; blocks, with each block an &lt;code&gt;N1 x N1&lt;/code&gt; block circulant matrix.</source>
          <target state="translated">如果 &lt;code&gt;A&lt;/code&gt; 为嵌套块循环，块大小为 &lt;code&gt;N0, N1, N2&lt;/code&gt; （ &lt;code&gt;N0 * N1 * N2 = N&lt;/code&gt; ）： &lt;code&gt;A&lt;/code&gt; 具有由 &lt;code&gt;N0 x N0&lt;/code&gt; 块组成的块结构，每个块都有 &lt;code&gt;N1 x N1&lt;/code&gt; 块循环矩阵。</target>
        </trans-unit>
        <trans-unit id="be595307418539e13ef1fb9321c103ad2f7818c8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt; (default) raise an error if there are no variables in the graph. Otherwise, construct the saver anyway and make it a no-op.</source>
          <target state="translated">如果为 &lt;code&gt;False&lt;/code&gt; （默认），则在图形中没有变量的情况下引发错误。否则，无论如何都要构造保护程序并将其设为无操作。</target>
        </trans-unit>
        <trans-unit id="76019b2232667e78369e47c4fc4d6fef16616868" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, allows the variable to be initialized with a value of unknown shape. If &lt;code&gt;True&lt;/code&gt;, the default, the shape of &lt;code&gt;initial_value&lt;/code&gt; must be known.</source>
          <target state="translated">如果为 &lt;code&gt;False&lt;/code&gt; ，则允许使用未知形状的值初始化变量。如果为 &lt;code&gt;True&lt;/code&gt; （默认值），则必须知道 &lt;code&gt;initial_value&lt;/code&gt; 的形状。</target>
        </trans-unit>
        <trans-unit id="1ce446f25db0af92e41fafc3bf4dab8c93e6763a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, raises an error if any of the threads are still alive after &lt;code&gt;stop_grace_period_secs&lt;/code&gt;.</source>
          <target state="translated">如果为 &lt;code&gt;False&lt;/code&gt; ，则在 &lt;code&gt;stop_grace_period_secs&lt;/code&gt; 之后任何线程仍处于活动状态时，将引发错误。</target>
        </trans-unit>
        <trans-unit id="12c5ee09ddeadea58c00f27a5fe9253ffe07db54" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, yields the whole batch as returned by the &lt;code&gt;model_fn&lt;/code&gt; instead of decomposing the batch into individual elements. This is useful if &lt;code&gt;model_fn&lt;/code&gt; returns some tensors whose first dimension is not equal to the batch size.</source>
          <target state="translated">如果为 &lt;code&gt;False&lt;/code&gt; ，则产生由 &lt;code&gt;model_fn&lt;/code&gt; 返回的整个批次，而不是将批次分解为单个元素。如果 &lt;code&gt;model_fn&lt;/code&gt; 返回一些张量，这些张量的第一维不等于批处理大小，则此方法很有用。</target>
        </trans-unit>
        <trans-unit id="25587966a8e2f216b6da2cdce4060125a4291eb7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;H.shape = [N0, N1, N2]&lt;/code&gt;, (&lt;code&gt;N0 * N1 * N2 = N&lt;/code&gt;): Loosely speaking, matrix multiplication is equal to the action of a Fourier multiplier: &lt;code&gt;A u = IDFT3[ H DFT3[u] ]&lt;/code&gt;. Precisely speaking, given &lt;code&gt;[N, R]&lt;/code&gt; matrix &lt;code&gt;u&lt;/code&gt;, let &lt;code&gt;DFT3[u]&lt;/code&gt; be the &lt;code&gt;[N0, N1, N2, R]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; defined by re-shaping &lt;code&gt;u&lt;/code&gt; to &lt;code&gt;[N0, N1, N2, R]&lt;/code&gt; and taking a three dimensional DFT across the first three dimensions. Let &lt;code&gt;IDFT3&lt;/code&gt; be the inverse of &lt;code&gt;DFT3&lt;/code&gt;. Matrix multiplication may be expressed columnwise:</source>
          <target state="translated">如果 &lt;code&gt;H.shape = [N0, N1, N2]&lt;/code&gt; ，（ &lt;code&gt;N0 * N1 * N2 = N&lt;/code&gt; ）：宽松地说，矩阵乘法等于傅立叶乘法器的作用： &lt;code&gt;A u = IDFT3[ H DFT3[u] ]&lt;/code&gt; 。确切地说，给定 &lt;code&gt;[N, R]&lt;/code&gt; 矩阵 &lt;code&gt;u&lt;/code&gt; ，令 &lt;code&gt;DFT3[u]&lt;/code&gt; 为通过将 &lt;code&gt;u&lt;/code&gt; 重塑为 &lt;code&gt;[N0, N1, N2, R]&lt;/code&gt; 并取三维来定义的 &lt;code&gt;[N0, N1, N2, R]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 在前三个维度上进行DFT。让 &lt;code&gt;IDFT3&lt;/code&gt; 是逆 &lt;code&gt;DFT3&lt;/code&gt; 。矩阵乘法可以按列表示：</target>
        </trans-unit>
        <trans-unit id="7e381afea75d47e56f3608744fb4bdb4a6e5cfdf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;H.shape = [N0, N1]&lt;/code&gt;, (&lt;code&gt;N0 * N1 = N&lt;/code&gt;): Loosely speaking, matrix multiplication is equal to the action of a Fourier multiplier: &lt;code&gt;A u = IDFT2[ H DFT2[u] ]&lt;/code&gt;. Precisely speaking, given &lt;code&gt;[N, R]&lt;/code&gt; matrix &lt;code&gt;u&lt;/code&gt;, let &lt;code&gt;DFT2[u]&lt;/code&gt; be the &lt;code&gt;[N0, N1, R]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; defined by re-shaping &lt;code&gt;u&lt;/code&gt; to &lt;code&gt;[N0, N1, R]&lt;/code&gt; and taking a two dimensional DFT across the first two dimensions. Let &lt;code&gt;IDFT2&lt;/code&gt; be the inverse of &lt;code&gt;DFT2&lt;/code&gt;. Matrix multiplication may be expressed columnwise:</source>
          <target state="translated">如果 &lt;code&gt;H.shape = [N0, N1]&lt;/code&gt; ，（ &lt;code&gt;N0 * N1 = N&lt;/code&gt; ）：宽松地说，矩阵乘法等于傅立叶乘法器的作用： &lt;code&gt;A u = IDFT2[ H DFT2[u] ]&lt;/code&gt; 。准确地说，给定 &lt;code&gt;[N, R]&lt;/code&gt; 矩阵 &lt;code&gt;u&lt;/code&gt; ，令 &lt;code&gt;DFT2[u]&lt;/code&gt; 为通过将 &lt;code&gt;u&lt;/code&gt; 重塑为 &lt;code&gt;[N0, N1, R]&lt;/code&gt; 并在第一个二维二维DFT上定义的 &lt;code&gt;[N0, N1, R]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 二维。令 &lt;code&gt;IDFT2&lt;/code&gt; 为 &lt;code&gt;DFT2&lt;/code&gt; 的逆。矩阵乘法可以按列表示：</target>
        </trans-unit>
        <trans-unit id="4bbcbab5946b02f4bd8339afde5bc909bf23760f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;L&lt;/code&gt; is non-singular, solves and determinants are available. Solves/determinants both involve a solve/determinant of a &lt;code&gt;K x K&lt;/code&gt; system. In the event that L and D are self-adjoint positive-definite, and U = V, this can be done using a Cholesky factorization. The user should set the &lt;code&gt;is_X&lt;/code&gt; matrix property hints, which will trigger the appropriate code path.</source>
          <target state="translated">如果 &lt;code&gt;L&lt;/code&gt; 为非奇异值，则可以使用求解和行列式。求解器/行列式都涉及 &lt;code&gt;K x K&lt;/code&gt; 系统的求解器/行列式。如果L和D是自伴正定的，且U = V，则可以使用Cholesky分解进行。用户应设置 &lt;code&gt;is_X&lt;/code&gt; 矩阵属性提示，这将触发适当的代码路径。</target>
        </trans-unit>
        <trans-unit id="9426460040356d10df11f6a515a1e8a979f481d4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;M = N&lt;/code&gt;, determinants and solves are done using the matrix determinant lemma and Woodbury identities, and thus require L and D to be non-singular.</source>
          <target state="translated">如果 &lt;code&gt;M = N&lt;/code&gt; ，则使用矩阵行列式引理和伍德伯里恒等式完成行列式和求解，因此要求L和D为非奇异值。</target>
        </trans-unit>
        <trans-unit id="ad6839f42ef3ffc050c2206365782e56e109f3df" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;M=N&lt;/code&gt;, &lt;code&gt;operator.determinant()&lt;/code&gt; is &lt;code&gt;O(N^3)&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;M=N&lt;/code&gt; ， &lt;code&gt;operator.determinant()&lt;/code&gt; 为 &lt;code&gt;O(N^3)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7d2680f7f302962db3beec63891212a96a0cde62" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;M=N&lt;/code&gt;, &lt;code&gt;operator.solve(x)&lt;/code&gt; is &lt;code&gt;O(N^3 * R)&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;M=N&lt;/code&gt; ， &lt;code&gt;operator.solve(x)&lt;/code&gt; 为 &lt;code&gt;O(N^3 * R)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="135f5e4b5839b28e49cfbf03c1f2e3688968e292" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, this column's graph operations will fail for out-of-range inputs. Otherwise, this value must be in the range &lt;code&gt;[0, num_buckets)&lt;/code&gt;, and will replace out-of-range inputs.</source>
          <target state="translated">如果为 &lt;code&gt;None&lt;/code&gt; ，则对于超出范围的输入，此列的图形操作将失败。否则，此值必须在 &lt;code&gt;[0, num_buckets)&lt;/code&gt; 范围内，并将替换超出范围的输入。</target>
        </trans-unit>
        <trans-unit id="ef95464404d2b393bbdf4fc6ab3d0ee4bd75e4aa" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;SLICED&lt;/code&gt;, &lt;code&gt;input_fn&lt;/code&gt; is only invoked once on host 0 and the tensors are broadcasted to all other replicas. Unlike per_host_input_for_training=BROADCAST, each replica will only get a slice of the data instead of a whole copy. If &lt;code&gt;PER_HOST_V1&lt;/code&gt;, the behaviour is determined by per_host_input_for_training.</source>
          <target state="translated">如果 &lt;code&gt;SLICED&lt;/code&gt; ， &lt;code&gt;input_fn&lt;/code&gt; 仅在主机0调用一次和张量被广播给所有其他副本。与per_host_input_for_training = BROADCAST不同，每个副本将仅获取数据的一部分，而不是整个副本。如果为 &lt;code&gt;PER_HOST_V1&lt;/code&gt; ，则该行为由per_host_input_for_training确定。</target>
        </trans-unit>
        <trans-unit id="e41171d0e9385cb32976695c17de0293dfc81335" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;T&lt;/code&gt; is smaller than &lt;code&gt;type&lt;/code&gt;, the operator requires that the rightmost dimension be equal to sizeof(&lt;code&gt;type&lt;/code&gt;)/sizeof(&lt;code&gt;T&lt;/code&gt;). The shape then goes from [..., sizeof(&lt;code&gt;type&lt;/code&gt;)/sizeof(&lt;code&gt;T&lt;/code&gt;)] to [...].</source>
          <target state="translated">如果 &lt;code&gt;T&lt;/code&gt; 小于 &lt;code&gt;type&lt;/code&gt; ，则运算符要求最右边的尺寸等于sizeof（ &lt;code&gt;type&lt;/code&gt; ）/ sizeof（ &lt;code&gt;T&lt;/code&gt; ）。然后形状从[...，sizeof（ &lt;code&gt;type&lt;/code&gt; ）/ sizeof（ &lt;code&gt;T&lt;/code&gt; ）]变为[...]。</target>
        </trans-unit>
        <trans-unit id="f079c69e69a4356b0afc3a68a04e8a9df020a45f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; also add the variable to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; (see &lt;a href=&quot;../../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ,则还将变量添加到图形集合 &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; （请参阅&lt;a href=&quot;../../../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="e4ea3bdb19c685aaba0fdcffcc4245ede4dfe76e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; also add the variable to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; (see &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ,则还将变量添加到图形集合 &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; （请参阅&lt;a href=&quot;../../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="a01f60da247392cdad0c9e7a8e6ffe0d9121cf14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; ignores threads that remain running after a grace period when joining threads via the coordinator, instead of raising a RuntimeError.</source>
          <target state="translated">如果 &lt;code&gt;True&lt;/code&gt; 忽略通过协调器加入线程时在宽限期之后仍在运行的线程，而不是引发RuntimeError。</target>
        </trans-unit>
        <trans-unit id="946aecac475452eb0ed096696a58e4ebd59858f4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; then left and right singular vectors will be computed and returned in &lt;code&gt;u&lt;/code&gt; and &lt;code&gt;v&lt;/code&gt;, respectively. Otherwise, only the singular values will be computed, which can be significantly faster.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将分别计算 &lt;code&gt;u&lt;/code&gt; 和 &lt;code&gt;v&lt;/code&gt; 中的左奇数矢量和右奇异矢量。否则，将仅计算奇异值，这可能会更快。</target>
        </trans-unit>
        <trans-unit id="4a21cfe2fdb7abc2b66d47b4c832133c76184e58" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; use Nesterov Momentum. See (Sutskever et al., 2013). This implementation always computes gradients at the value of the variable(s) passed to the optimizer. Using Nesterov Momentum makes the variable(s) track the values called &lt;code&gt;theta_t + mu*v_t&lt;/code&gt; in the paper. This implementation is an approximation of the original formula, valid for high values of momentum. It will compute the &quot;adjusted gradient&quot; in NAG by assuming that the new gradient will be estimated by the current average gradient plus the product of momentum and the change in the average gradient.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ,请使用Nesterov动量。参见（Sutskever等人，2013）。此实现始终以传递给优化器的变量的值来计算梯度。使用Nesterov Momentum，变量可以跟踪论文中称为 &lt;code&gt;theta_t + mu*v_t&lt;/code&gt; 的值。该实现是原始公式的近似值，适用于高动量值。通过假设新的梯度将由当前平均梯度加上动量与平均梯度变化的乘积来估算，它将在NAG中计算&amp;ldquo;调整后的梯度&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="86237982c3c43c35aa2590c7e6ebaefaedebe548" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; use locks for update operations.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ,请使用锁进行更新操作。</target>
        </trans-unit>
        <trans-unit id="94436823001587bebe4bff18b8f99b1bbfb1c438" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; is conjugated and transposed before multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在乘法之前对 &lt;code&gt;a&lt;/code&gt; 进行共轭和转置。</target>
        </trans-unit>
        <trans-unit id="a642a7ec441e51ecf27e357c6a9696cb5e000375" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; is transposed before multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在乘法之前对 &lt;code&gt;a&lt;/code&gt; 进行转置。</target>
        </trans-unit>
        <trans-unit id="7ddf60234d5af08780027290ae88b8168ae65fce" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; is treated as a sparse matrix.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将 &lt;code&gt;a&lt;/code&gt; 视为稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="52ec93076c6b1fffbc6ade7b8f68a02b7f68971d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; is treated as a sparse matrix. Notice, this &lt;strong&gt;does not support &lt;a href=&quot;../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;, it just makes optimizations that assume most values in &lt;code&gt;a&lt;/code&gt; are zero. See &lt;a href=&quot;../../sparse/sparse_dense_matmul&quot;&gt;&lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt;&lt;/a&gt; for some support for &lt;a href=&quot;../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt; multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将 &lt;code&gt;a&lt;/code&gt; 视为稀疏矩阵。注意，这&lt;strong&gt;不支持&lt;a href=&quot;../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;&lt;/strong&gt;，它只是进行优化，假设 &lt;code&gt;a&lt;/code&gt; 中的大多数值为零。有关对&lt;a href=&quot;../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;乘法的某些支持，请参见&lt;a href=&quot;../../sparse/sparse_dense_matmul&quot;&gt; &lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c1697ff3ee8a41dc246673fdb0bd9e9711e59c23" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; is treated as a sparse matrix. Notice, this &lt;strong&gt;does not support &lt;a href=&quot;../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;, it just makes optimizations that assume most values in &lt;code&gt;a&lt;/code&gt; are zero. See &lt;a href=&quot;../sparse/sparse_dense_matmul&quot;&gt;&lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt;&lt;/a&gt; for some support for &lt;a href=&quot;../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt; multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将 &lt;code&gt;a&lt;/code&gt; 视为稀疏矩阵。注意，这&lt;strong&gt;不支持&lt;a href=&quot;../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;&lt;/strong&gt;，它只是进行优化，假设 &lt;code&gt;a&lt;/code&gt; 中的大多数值为零。有关对&lt;a href=&quot;../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;乘法的某些支持，请参见&lt;a href=&quot;../sparse/sparse_dense_matmul&quot;&gt; &lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a1c9b8fad2ab98bd05073e40df3f5a02c810f953" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; is treated as a sparse matrix. Notice, this &lt;strong&gt;does not support &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;, it just makes optimizations that assume most values in &lt;code&gt;a&lt;/code&gt; are zero. See &lt;a href=&quot;sparse/sparse_dense_matmul&quot;&gt;&lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt;&lt;/a&gt; for some support for &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt; multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将 &lt;code&gt;a&lt;/code&gt; 视为稀疏矩阵。注意，这&lt;strong&gt;不支持&lt;a href=&quot;sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;&lt;/strong&gt;，它只是进行优化，假设 &lt;code&gt;a&lt;/code&gt; 中的大多数值为零。有关对&lt;a href=&quot;sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;乘法的某些支持，请参见&lt;a href=&quot;sparse/sparse_dense_matmul&quot;&gt; &lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8fad0a3980be272448053a98b2a7116e7f60c91f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; is conjugated and transposed before multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在乘法之前将 &lt;code&gt;b&lt;/code&gt; 进行共轭和转置。</target>
        </trans-unit>
        <trans-unit id="7ad4472b4b3225d0732d75b312044bfcf48b0406" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; is transposed before multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则 &lt;code&gt;b&lt;/code&gt; 在相乘之前进行转置。</target>
        </trans-unit>
        <trans-unit id="126790682ab49a5c3034dfafbd64f261a4ad3a9d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; is treated as a sparse matrix.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则 &lt;code&gt;b&lt;/code&gt; 被视为稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="4cf6a577f44625697505a42af18c8b69cd849768" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; is treated as a sparse matrix. Notice, this &lt;strong&gt;does not support &lt;a href=&quot;../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;, it just makes optimizations that assume most values in &lt;code&gt;a&lt;/code&gt; are zero. See &lt;a href=&quot;../../sparse/sparse_dense_matmul&quot;&gt;&lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt;&lt;/a&gt; for some support for &lt;a href=&quot;../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt; multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则 &lt;code&gt;b&lt;/code&gt; 被视为稀疏矩阵。注意，这&lt;strong&gt;不支持&lt;a href=&quot;../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;&lt;/strong&gt;，它只是进行优化，假设 &lt;code&gt;a&lt;/code&gt; 中的大多数值为零。有关对&lt;a href=&quot;../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;乘法的某些支持，请参见&lt;a href=&quot;../../sparse/sparse_dense_matmul&quot;&gt; &lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2ec845c050d819112e3b46bf32f89021852b963a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; is treated as a sparse matrix. Notice, this &lt;strong&gt;does not support &lt;a href=&quot;../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;, it just makes optimizations that assume most values in &lt;code&gt;a&lt;/code&gt; are zero. See &lt;a href=&quot;../sparse/sparse_dense_matmul&quot;&gt;&lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt;&lt;/a&gt; for some support for &lt;a href=&quot;../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt; multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则 &lt;code&gt;b&lt;/code&gt; 被视为稀疏矩阵。注意，这&lt;strong&gt;不支持&lt;a href=&quot;../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;&lt;/strong&gt;，它只是进行优化，假设 &lt;code&gt;a&lt;/code&gt; 中的大多数值为零。有关对&lt;a href=&quot;../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;乘法的某些支持，请参见&lt;a href=&quot;../sparse/sparse_dense_matmul&quot;&gt; &lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b6d14d22c43ea44883e43139147e76fb5ad9623b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; is treated as a sparse matrix. Notice, this &lt;strong&gt;does not support &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;, it just makes optimizations that assume most values in &lt;code&gt;a&lt;/code&gt; are zero. See &lt;a href=&quot;sparse/sparse_dense_matmul&quot;&gt;&lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt;&lt;/a&gt; for some support for &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt; multiplication.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则 &lt;code&gt;b&lt;/code&gt; 被视为稀疏矩阵。注意，这&lt;strong&gt;不支持&lt;a href=&quot;sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;&lt;/strong&gt;，它只是进行优化，假设 &lt;code&gt;a&lt;/code&gt; 中的大多数值为零。有关对&lt;a href=&quot;sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;乘法的某些支持，请参见&lt;a href=&quot;sparse/sparse_dense_matmul&quot;&gt; &lt;code&gt;tf.sparse.sparse_dense_matmul&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="222a09a0e7fe887672fd52c4d3f159ce40c5fb29" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;rhs&lt;/code&gt; is conjugated before solving.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在求解之前将 &lt;code&gt;rhs&lt;/code&gt; 共轭。</target>
        </trans-unit>
        <trans-unit id="7ee0c3e2e6c4ac6e6797a5a36bf9ecf84d41c2a9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;rhs&lt;/code&gt; is transposed before solving (has no effect if the shape of rhs is [..., M]).</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在求解前将转置 &lt;code&gt;rhs&lt;/code&gt; （如果rhs的形状为[...，M]则无效）。</target>
        </trans-unit>
        <trans-unit id="233ae30a7f5e91029f31b27ee857d509b29f2bd2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, GradientTapes automatically watch uses of this variable. Defaults to &lt;code&gt;True&lt;/code&gt;, unless &lt;code&gt;synchronization&lt;/code&gt; is set to &lt;code&gt;ON_READ&lt;/code&gt;, in which case it defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则GradientTapes自动监视此变量的使用。默认为 &lt;code&gt;True&lt;/code&gt; ，除非将 &lt;code&gt;synchronization&lt;/code&gt; 设置为 &lt;code&gt;ON_READ&lt;/code&gt; ，在这种情况下，默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0afa1955aa77eeb749a18ccebe78b8eeaccc2307" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, allows restoring parameters from a checkpoint where the variables have a different shape.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则允许从变量形状不同的检查点恢复参数。</target>
        </trans-unit>
        <trans-unit id="601907c4d4c0839c609aedb534e7cdab5256c862" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, also adds the variable to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;. This collection is used as the default list of variables to use by the &lt;code&gt;Optimizer&lt;/code&gt; classes. Defaults to &lt;code&gt;True&lt;/code&gt;, unless &lt;code&gt;synchronization&lt;/code&gt; is set to &lt;code&gt;ON_READ&lt;/code&gt;, in which case it defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则还将变量添加到图形集合 &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; 中。该集合用作 &lt;code&gt;Optimizer&lt;/code&gt; 类使用的默认变量列表。默认为 &lt;code&gt;True&lt;/code&gt; ，除非将 &lt;code&gt;synchronization&lt;/code&gt; 设置为 &lt;code&gt;ON_READ&lt;/code&gt; ，在这种情况下，默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="337cb0d0d34855011c664db8787f193704be415a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, and the batch size does not evenly divide the input dataset size, the final smaller batch will be dropped. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，并且批大小没有均匀地划分输入数据集的大小，则最终的较小批将被删除。默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="db81e1cd0261358201cfc92220de12fd4f7d7ec2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, clip the input before casting (if necessary).</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在投射之前剪切输入（如有必要）。</target>
        </trans-unit>
        <trans-unit id="08c017b75b4c5c09adcc12047e395b03c28e54e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, defer adding the save and restore ops to the &lt;code&gt;build()&lt;/code&gt; call. In that case &lt;code&gt;build()&lt;/code&gt; should be called before finalizing the graph or using the saver.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则推迟将保存和恢复操作添加到 &lt;code&gt;build()&lt;/code&gt; 调用中。在这种情况下，应在最终确定图形或使用保护程序之前调用 &lt;code&gt;build()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="535bc3ef8bbf4f69fb7a9e1d93a9c142b1ce157b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, for &lt;code&gt;PER_HOST_V1&lt;/code&gt;, the &lt;code&gt;input_fn&lt;/code&gt; is invoked once on each host, and the number of hosts must be smaller or equal to the number of replicas. For PER_HOST_V2, the &lt;code&gt;input_fn&lt;/code&gt; is invoked once for each host (if the number of hosts is less than the number of replicas) or replica (if the number of replicas is less than the number of hosts. With the per-core input pipeline configuration, it is invoked once for each core. With a global batch size &lt;code&gt;train_batch_size&lt;/code&gt; in &lt;code&gt;TPUEstimator&lt;/code&gt; constructor, the batch size for each shard is &lt;code&gt;train_batch_size&lt;/code&gt; // #hosts in the &lt;code&gt;True&lt;/code&gt; or &lt;code&gt;PER_HOST_V1&lt;/code&gt; mode. In &lt;code&gt;PER_HOST_V2&lt;/code&gt; mode, it is &lt;code&gt;train_batch_size&lt;/code&gt; // #cores. In &lt;code&gt;BROADCAST&lt;/code&gt; mode, &lt;code&gt;input_fn&lt;/code&gt; is only invoked once on host 0 and the tensors are broadcasted to all other replicas. The batch size equals to &lt;code&gt;train_batch_size&lt;/code&gt;. With the per-core input pipeline configuration, the shard batch size is also &lt;code&gt;train_batch_size&lt;/code&gt; // #cores. Note: per_host_input_for_training==PER_SHARD_V1 only supports mode.TRAIN.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则对于 &lt;code&gt;PER_HOST_V1&lt;/code&gt; ，将在每个主机上调用一次 &lt;code&gt;input_fn&lt;/code&gt; ，并且主机数必须小于或等于副本数。对于PER_HOST_V2，每个主机（如果主机数小于副本数）或副本（如果副本数小于主机数）对每个主机调用一次 &lt;code&gt;input_fn&lt;/code&gt; 。对于每核输入管道配置，它被调用一次为每个核心。随着全球批量大小 &lt;code&gt;train_batch_size&lt;/code&gt; 在 &lt;code&gt;TPUEstimator&lt;/code&gt; 构造，每个碎片批量大小是 &lt;code&gt;train_batch_size&lt;/code&gt; 在// #hosts &lt;code&gt;True&lt;/code&gt; 或 &lt;code&gt;PER_HOST_V1&lt;/code&gt; 模式，在 &lt;code&gt;PER_HOST_V2&lt;/code&gt; 模式，它是 &lt;code&gt;train_batch_size&lt;/code&gt; // #cores。在 &lt;code&gt;BROADCAST&lt;/code&gt; 模式下，仅在主机0上调用一次 &lt;code&gt;input_fn&lt;/code&gt; ,并且将张量广播到所有其他副本。批处理大小等于 &lt;code&gt;train_batch_size&lt;/code&gt; 。使用每核输入管道配置，分片批大小也为 &lt;code&gt;train_batch_size&lt;/code&gt; // #cores。注意：per_host_input_for_training == PER_SHARD_V1仅支持mode.TRAIN。</target>
        </trans-unit>
        <trans-unit id="0aef50b292b594a6da14b09ab9760986efee383b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, it will take care of initialization and recovery the underlying TensorFlow session. If &lt;code&gt;False&lt;/code&gt;, it will wait on a chief to initialize or recover the TensorFlow session.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，它将负责初始化和恢复基础的TensorFlow会话。如果为 &lt;code&gt;False&lt;/code&gt; ，它将等待负责人初始化或恢复TensorFlow会话。</target>
        </trans-unit>
        <trans-unit id="15f6b2b84877ffa96ce2cbae90c18e832c6f120f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, loss and metric results are returned as a dict, with each key being the name of the metric. If &lt;code&gt;False&lt;/code&gt;, they are returned as a list.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将损失和度量标准结果作为字典返回，每个键都是度量标准的名称。如果为 &lt;code&gt;False&lt;/code&gt; ，则将它们作为列表返回。</target>
        </trans-unit>
        <trans-unit id="aa358cb3159f218d18da7d37c8763834650bf5be" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, perform exclusive cumprod.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则执行排他的cumprod。</target>
        </trans-unit>
        <trans-unit id="c3b84bbb819fc7e0f87eb08a15090a3df3ad9ab9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, perform exclusive cumsum.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则执行独占求和。</target>
        </trans-unit>
        <trans-unit id="66ec1c96eb14414e0c3909fcc072eace78950c80" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, perform exclusive cumulative log-sum-exp.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则执行排他的累积log-sum-exp。</target>
        </trans-unit>
        <trans-unit id="3abf56f37d62111bf5ebd198630f4ea32ea9ada1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, performs the cumulative log-sum-exp in the reverse direction.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则反向执行累积log-sum-exp。</target>
        </trans-unit>
        <trans-unit id="318211393bec4a40ac0da76a23ca5015e45c8c8c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, reading performance will be improved at the cost of non-deterministic ordering. If &lt;code&gt;False&lt;/code&gt;, the order of elements produced is deterministic prior to shuffling (elements are still randomized if &lt;code&gt;shuffle=True&lt;/code&gt;. Note that if the seed is set, then order of elements after shuffling is deterministic). Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将以不确定的顺序为代价来提高阅读性能。如果为 &lt;code&gt;False&lt;/code&gt; ，则在重排之前产生的元素顺序是确定的（如果 &lt;code&gt;shuffle=True&lt;/code&gt; ,元素仍然是随机的。请注意，如果设置了种子，则在重排之后元素的顺序是确定性的）。默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a8bb62dc74d88b8edaeb47f43964e47a5b518e53" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, save the GraphDebugInfo to a separate file, which in the same directory of filename and with &lt;code&gt;_debug&lt;/code&gt; added before the file extend.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将GraphDebugInfo保存到一个单独的文件，该文件位于文件名的同一目录中，并在文件扩展前添加 &lt;code&gt;_debug&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bf43d23f0ecd7bdfeb8cb8e4485edfa32ad1b03c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, save the GraphDebugInfo to a separate file, which in the same directory of filename and with &lt;code&gt;_debug&lt;/code&gt; added before the file extension.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将GraphDebugInfo保存到一个单独的文件，该文件位于文件名的同一目录中，并在文件扩展名之前添加 &lt;code&gt;_debug&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="10baa9814ddfe2f402edcc6e487d3d143fa6aa42" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, save the GraphDebugInfo to a separate file, which in the same directory of save_path and with &lt;code&gt;_debug&lt;/code&gt; added before the file extension. This is only enabled when &lt;code&gt;write_meta_graph&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将GraphDebugInfo保存到一个单独的文件，该文件位于save_path的同一目录中，并在文件扩展名之前添加 &lt;code&gt;_debug&lt;/code&gt; 。仅在 &lt;code&gt;write_meta_graph&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; 时启用</target>
        </trans-unit>
        <trans-unit id="a4f90c2fb6fb2ab19be5872f2da029643e688f02" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, shard the checkpoints, one per device.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将检查点分片（每个设备一个）。</target>
        </trans-unit>
        <trans-unit id="46d0c23c1b4c7f7cadb0bffb6e4cbfd1627119d5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, the TensorArray will be colocated on the same device as the Tensor used on its first write (write operations include &lt;code&gt;write&lt;/code&gt;, &lt;code&gt;unstack&lt;/code&gt;, and &lt;code&gt;split&lt;/code&gt;). If &lt;code&gt;False&lt;/code&gt;, the TensorArray will be placed on the device determined by the device context available during its initialization.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则TensorArray将与首次写入时使用的Tensor位于同一设备上（写入操作包括 &lt;code&gt;write&lt;/code&gt; ， &lt;code&gt;unstack&lt;/code&gt; 和 &lt;code&gt;split&lt;/code&gt; ）。如果为 &lt;code&gt;False&lt;/code&gt; ，则TensorArray将放置在设备上，该设备由初始化期间可用的设备上下文确定。</target>
        </trans-unit>
        <trans-unit id="8363894bad226438c506c5e40b7faccc3671fdb4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, the metrics returned will be only for this batch. If &lt;code&gt;False&lt;/code&gt;, the metrics will be statefully accumulated across batches.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则返回的指标仅适用于该批次。如果为 &lt;code&gt;False&lt;/code&gt; ，则指标将有状态地在批次之间累积。</target>
        </trans-unit>
        <trans-unit id="8aa06177b2b04511f6d7ed4e6e71f5849438d5e3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, use locking during the assignment.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在分配过程中使用锁定。</target>
        </trans-unit>
        <trans-unit id="9d87a800a10420bfc89f6cb43f1131e20ba5d176" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, use locking during the operation.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则在操作期间使用锁定。</target>
        </trans-unit>
        <trans-unit id="b927ef95a6c43e52135bc483aa864c92121f05e6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, we create an auxiliary name scope with the scope. If &lt;code&gt;False&lt;/code&gt;, we don't create it. Note that the argument is not inherited, and it only takes effect for once when creating. You should only use it for re-entering a premade variable scope.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则使用该范围创建一个辅助名称范围。如果为 &lt;code&gt;False&lt;/code&gt; ，则不创建它。请注意，该参数不是继承的，并且在创建时仅一次生效。您仅应将其用于重新输入预制变量作用域。</target>
        </trans-unit>
        <trans-unit id="1fcc0fa67fe23a49a5d74cb9655d9b3cb4f63ad8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, will create a scalar variable to scale the attention scores.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，将创建一个标量变量来缩放注意力得分。</target>
        </trans-unit>
        <trans-unit id="92385bcfeb82ed0fc98270c8ee3478c21cbd2b7b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, will create a variable to scale the attention scores.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，将创建一个变量来缩放注意力得分。</target>
        </trans-unit>
        <trans-unit id="149c7fd8624dc8d2ba3ca596d6014d881674a0a6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, will write relative paths to the checkpoint state file. This is needed if the user wants to copy the checkpoint directory and reload from the copied directory.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将相对路径写入检查点状态文件。如果用户要复制检查点目录并从复制的目录重新加载，则需要这样做。</target>
        </trans-unit>
        <trans-unit id="db8d9750c81e42e1484a51545102b5ed2e5301a0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, writes the &lt;code&gt;MetaGraphDef&lt;/code&gt; as an ASCII proto.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将 &lt;code&gt;MetaGraphDef&lt;/code&gt; 编写为ASCII原型。</target>
        </trans-unit>
        <trans-unit id="53f2411ed105fdc9115bbd2f5c44470569e72920" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, writes the graph as an ASCII proto.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将图形写为ASCII原型。</target>
        </trans-unit>
        <trans-unit id="673940925e4bc982f03f7524775bd28a417c9a4e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, writes the meta_graph as an ASCII proto.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则将meta_graph写为ASCII原型。</target>
        </trans-unit>
        <trans-unit id="2b23962326191d9b25f9cdcce5f98485e099e80d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, zero debias moving-averages that are initialized with tensors.</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则使用张量初始化的零去偏移移动平均值。</target>
        </trans-unit>
        <trans-unit id="29d6ce24d2935a15c7b87ceecd4d7f07ec4715cd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are unexpectedly close at all elements.</source>
          <target state="translated">如果 &lt;code&gt;a&lt;/code&gt; 和 &lt;code&gt;b&lt;/code&gt; 意外关闭所有元素。</target>
        </trans-unit>
        <trans-unit id="080af896ac284ed3da9331039d890d8b9e9a6b6e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;a&lt;/code&gt; is an invalid types.</source>
          <target state="translated">如果 &lt;code&gt;a&lt;/code&gt; 为无效类型。</target>
        </trans-unit>
        <trans-unit id="76a2c5482f070a2a6296eb33a6b159ce01fd5df8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;a&lt;/code&gt; is determined statically to have &lt;code&gt;rank &amp;lt; 2&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;a&lt;/code&gt; 被静态确定为 &lt;code&gt;rank &amp;lt; 2&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="64972012cfa9f1bb68627595da20410a52e6b063" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;a&lt;/code&gt; is sparse and &lt;code&gt;b&lt;/code&gt; is dense.</source>
          <target state="translated">如果 &lt;code&gt;a&lt;/code&gt; 稀疏而 &lt;code&gt;b&lt;/code&gt; 致密。</target>
        </trans-unit>
        <trans-unit id="2c7a904e6acee7cc058932afbbd9186b0a891454" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;adjoint_a == false&lt;/code&gt;: &lt;code&gt;A&lt;/code&gt; should be sorted in lexicographically increasing order. Use &lt;a href=&quot;reorder&quot;&gt;&lt;code&gt;sparse.reorder&lt;/code&gt;&lt;/a&gt; if you're not sure.</source>
          <target state="translated">如果 &lt;code&gt;adjoint_a == false&lt;/code&gt; ： &lt;code&gt;A&lt;/code&gt; 应该按字典顺序升序排序。如果不确定，请使用&lt;a href=&quot;reorder&quot;&gt; &lt;code&gt;sparse.reorder&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="07af4a9ac21faf4286799bc8a4a85745861cc3f1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;adjoint_a == true&lt;/code&gt;: &lt;code&gt;A&lt;/code&gt; should be sorted in order of increasing dimension 1 (i.e., &quot;column major&quot; order instead of &quot;row major&quot; order).</source>
          <target state="translated">如果 &lt;code&gt;adjoint_a == true&lt;/code&gt; ： &lt;code&gt;A&lt;/code&gt; 应按维度1递增的顺序进行排序（即&amp;ldquo;大列&amp;rdquo;顺序而不是&amp;ldquo;大列&amp;rdquo;顺序）。</target>
        </trans-unit>
        <trans-unit id="bcbc484ef4b22bd434aebfe0c60fc098a6f45998" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;all_model_checkpoint_timestamps&lt;/code&gt; was provided but its length does not match &lt;code&gt;all_model_checkpoint_paths&lt;/code&gt;.</source>
          <target state="translated">如果提供了 &lt;code&gt;all_model_checkpoint_timestamps&lt;/code&gt; 但其长度与 &lt;code&gt;all_model_checkpoint_paths&lt;/code&gt; 不匹配。</target>
        </trans-unit>
        <trans-unit id="110ff3780b3515c9d733eede8bbe4c3bc9825cee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;all_reduce&lt;/code&gt; is called in any replica, it must be called in all replicas. The nested structure and &lt;code&gt;Tensor&lt;/code&gt; shapes must be identical in all replicas.</source>
          <target state="translated">如果在任何副本中调用 &lt;code&gt;all_reduce&lt;/code&gt; ，则必须在所有副本中调用。所有副本中的嵌套结构和 &lt;code&gt;Tensor&lt;/code&gt; 形状必须相同。</target>
        </trans-unit>
        <trans-unit id="17b9b3019bf6883d5abf33ab706045e5053f610a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;allow_smaller_final_batch&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, a smaller batch value than &lt;code&gt;batch_size&lt;/code&gt; is returned when the queue is closed and there are not enough elements to fill the batch, otherwise the pending elements are discarded. In addition, all output tensors' static shapes, as accessed via the &lt;code&gt;shape&lt;/code&gt; property will have a first &lt;code&gt;Dimension&lt;/code&gt; value of &lt;code&gt;None&lt;/code&gt;, and operations that depend on fixed batch_size would fail.</source>
          <target state="translated">如果 &lt;code&gt;allow_smaller_final_batch&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ，则在关闭队列并且没有足够的元素可填充批处理时，返回小于 &lt;code&gt;batch_size&lt;/code&gt; 的批处理值，否则将丢弃待处理的元素。此外，通过 &lt;code&gt;shape&lt;/code&gt; 属性访问的所有输出张量的静态形状的第一个 &lt;code&gt;Dimension&lt;/code&gt; 值将为 &lt;code&gt;None&lt;/code&gt; ，并且依赖于固定batch_size的操作将失败。</target>
        </trans-unit>
        <trans-unit id="7780a6b8fb5ede22db5a5df81a148367147b9033" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;alpha&lt;/code&gt; &amp;gt; 1.0, proportionally increases the number of filters in each layer.</source>
          <target state="translated">如果 &lt;code&gt;alpha&lt;/code&gt; &amp;gt; 1.0，则按比例增加每层中的滤镜数量。</target>
        </trans-unit>
        <trans-unit id="4a4fea5dc80e9ef14ab6ba19796973e718278379" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;alpha&lt;/code&gt; &amp;lt; 1.0, proportionally decreases the number of filters in each layer.</source>
          <target state="translated">如果 &lt;code&gt;alpha&lt;/code&gt; &amp;lt;1.0，则按比例减少每层中的滤镜数量。</target>
        </trans-unit>
        <trans-unit id="f53e0917886b19aa677a91e75faea069c634a903" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;alpha&lt;/code&gt; = 1, default number of filters from the paper are used at each layer.</source>
          <target state="translated">如果 &lt;code&gt;alpha&lt;/code&gt; = 1，则在每一层使用纸张的默认过滤器数量。</target>
        </trans-unit>
        <trans-unit id="dd7fbda9d4e5df2aaf326a8208be66bf6fd7816b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;as_ref&lt;/code&gt; is true, the function must return a &lt;code&gt;Tensor&lt;/code&gt; reference, such as a &lt;code&gt;Variable&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;as_ref&lt;/code&gt; 为true，则该函数必须返回 &lt;code&gt;Tensor&lt;/code&gt; 引用，例如 &lt;code&gt;Variable&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ebdc4f6453f07fa10351f671954a8d9cfc7adb0f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis == 0&lt;/code&gt; then the i'th tensor in &lt;code&gt;output&lt;/code&gt; is the slice &lt;code&gt;value[i, :, :, :]&lt;/code&gt; and each tensor in &lt;code&gt;output&lt;/code&gt; will have shape &lt;code&gt;(B, C, D)&lt;/code&gt;. (Note that the dimension unpacked along is gone, unlike &lt;code&gt;split&lt;/code&gt;).</source>
          <target state="translated">如果 &lt;code&gt;axis == 0&lt;/code&gt; 则 &lt;code&gt;output&lt;/code&gt; 的第i个张量是切片 &lt;code&gt;value[i, :, :, :]&lt;/code&gt; :::：]， &lt;code&gt;output&lt;/code&gt; 每个张量将具有 &lt;code&gt;(B, C, D)&lt;/code&gt; 形状。（请注意，与 &lt;code&gt;split&lt;/code&gt; 不同，未打包的尺寸已消失）。</target>
        </trans-unit>
        <trans-unit id="88a0b065f0f00041a252be5ef4e010c2b3761be1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis == 1&lt;/code&gt; then the i'th tensor in &lt;code&gt;output&lt;/code&gt; is the slice &lt;code&gt;value[:, i, :, :]&lt;/code&gt; and each tensor in &lt;code&gt;output&lt;/code&gt; will have shape &lt;code&gt;(A, C, D)&lt;/code&gt;. Etc.</source>
          <target state="translated">如果 &lt;code&gt;axis == 1&lt;/code&gt; 则 &lt;code&gt;output&lt;/code&gt; 的第i个张量是切片 &lt;code&gt;value[:, i, :, :]&lt;/code&gt; 并且 &lt;code&gt;output&lt;/code&gt; 每个张量将具有形状 &lt;code&gt;(A, C, D)&lt;/code&gt; 。等等。</target>
        </trans-unit>
        <trans-unit id="82c15a867116f27864f6d455e86bfd0be8b87837" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; has no entries, all dimensions are reduced, and a tensor with a single element is returned.</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 没有条目，则减小所有尺寸，并返回带有单个元素的张量。</target>
        </trans-unit>
        <trans-unit id="9a8ec21ac4d58f6a8479a92f2f74cef6e393ea5c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; has no entries, all dimensions are reduced, and a tensor with a single element is returned. Additionally, the axes can be negative, similar to the indexing rules in Python.</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 没有条目，则减小所有尺寸，并返回带有单个元素的张量。此外，轴可以是负数，类似于Python中的索引规则。</target>
        </trans-unit>
        <trans-unit id="e616056a6e0ccb8800df513352231e77e4264ea6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. &lt;code&gt;norm(tensor, ord=ord)&lt;/code&gt; is equivalent to &lt;code&gt;norm(reshape(tensor, [-1]), ord=ord)&lt;/code&gt;. If &lt;code&gt;axis&lt;/code&gt; is a Python integer, the input is considered a batch of vectors, and &lt;code&gt;axis&lt;/code&gt; determines the axis in &lt;code&gt;tensor&lt;/code&gt; over which to compute vector norms. If &lt;code&gt;axis&lt;/code&gt; is a 2-tuple of Python integers it is considered a batch of matrices and &lt;code&gt;axis&lt;/code&gt; determines the axes in &lt;code&gt;tensor&lt;/code&gt; over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass &lt;code&gt;axis=[-2,-1]&lt;/code&gt; instead of &lt;code&gt;axis=None&lt;/code&gt; to make sure that matrix norms are computed.</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 为 &lt;code&gt;None&lt;/code&gt; （默认值），则输入被视为向量，并且在张量的整​​个值集中计算单个向量范数，即 &lt;code&gt;norm(tensor, ord=ord)&lt;/code&gt; 等同于 &lt;code&gt;norm(reshape(tensor, [-1]), ord=ord)&lt;/code&gt; 。如果 &lt;code&gt;axis&lt;/code&gt; 是Python整数，则将输入视为一批向量，并且 &lt;code&gt;axis&lt;/code&gt; 确定以 &lt;code&gt;tensor&lt;/code&gt; 为单位的轴，以在该轴上计算向量范数。如果 &lt;code&gt;axis&lt;/code&gt; 是Python整数的2元组，则将其视为一批矩阵，而 &lt;code&gt;axis&lt;/code&gt; 确定 &lt;code&gt;tensor&lt;/code&gt; 的轴计算矩阵范数。支持负索引。示例：如果在运行时传递的张量可以是矩阵或一批矩阵，请传递 &lt;code&gt;axis=[-2,-1]&lt;/code&gt; 而不是 &lt;code&gt;axis=None&lt;/code&gt; 以确保计算矩阵范数。</target>
        </trans-unit>
        <trans-unit id="6c3c0b53459dfc2bb4beb0a0adb6072980b26e14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is None, all dimensions are reduced, and a tensor with a single element is returned.</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 为None，则缩小所有尺寸，并返回带有单个元素的张量。</target>
        </trans-unit>
        <trans-unit id="ac361bdaf1da22febee0c7b1b9dcb906feac6283" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is not specified.</source>
          <target state="translated">如果未指定 &lt;code&gt;axis&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2a8f7fa2efde73fc9bf0b0a2fab7a317d0c8657d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is out of bounds.</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 超出范围。</target>
        </trans-unit>
        <trans-unit id="1ab6e2ed9ca8b4fd5956248951445d47d21eba68" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is out of range &lt;code&gt;[-(D+1), D]&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 超出 &lt;code&gt;[-(D+1), D]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="40347027eb7341be1932ae7ecf56cb946b07b101" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is out of the range [-(R+1), R+1).</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 不在[-（R + 1），R + 1）范围内。</target>
        </trans-unit>
        <trans-unit id="6786f976b5b7018002f788d4d5b77f161184adfa" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis&lt;/code&gt; is out of the range [-R, R).</source>
          <target state="translated">如果 &lt;code&gt;axis&lt;/code&gt; 超出范围[-R，R）。</target>
        </trans-unit>
        <trans-unit id="4602049d19408d9325e5ff8f12f74035055b93a7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;backward_layer&lt;/code&gt; has mismatched properties compared to &lt;code&gt;layer&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;backward_layer&lt;/code&gt; 与 &lt;code&gt;layer&lt;/code&gt; 相比具有不匹配的属性。</target>
        </trans-unit>
        <trans-unit id="c1210be14982a956118b83d39f36a2c3bc225338" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;batch_shape&lt;/code&gt; initialization arg is &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="translated">如果 &lt;code&gt;batch_shape&lt;/code&gt; 初始化arg为 &lt;code&gt;None&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="0b34f5f9c6902112fe4d7b168dfca4894759e293" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;batch_shape&lt;/code&gt; initialization arg is provided, and static checks cannot rule out the need to broadcast:</source>
          <target state="translated">如果提供了 &lt;code&gt;batch_shape&lt;/code&gt; 初始化arg，则静态检查不能排除广播的需要：</target>
        </trans-unit>
        <trans-unit id="40f813420f57b9339e0284fe5e7d670f07e9a1e7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;batch_shape&lt;/code&gt; is determined statically to not be 1-D, or negative.</source>
          <target state="translated">如果将 &lt;code&gt;batch_shape&lt;/code&gt; 静态确定为不是一维或负数。</target>
        </trans-unit>
        <trans-unit id="750b252479a4a7304dd25d5ac4c741266f546400" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;boundaries&lt;/code&gt; is not a sorted list or tuple.</source>
          <target state="translated">如果 &lt;code&gt;boundaries&lt;/code&gt; 不是排序列表或元组。</target>
        </trans-unit>
        <trans-unit id="f327c86c6539bbf453fac30f2d63b53e09b0f775" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;branch_fns&lt;/code&gt; is a list but does not contain 2-tuples or callables.</source>
          <target state="translated">如果 &lt;code&gt;branch_fns&lt;/code&gt; 是一个列表，但不包含2元组或可调用项。</target>
        </trans-unit>
        <trans-unit id="ea26f65ae79b93de117abe34d6db208470fe3a9b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;branch_fns&lt;/code&gt; is not a list/dictionary.</source>
          <target state="translated">如果 &lt;code&gt;branch_fns&lt;/code&gt; 不是列表/字典。</target>
        </trans-unit>
        <trans-unit id="4e0014fe3e6f4ed6ff2b3d6fdd0d4f70bafb4a1a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;by_name&lt;/code&gt; is False weights are loaded based on the network's topology. This means the architecture should be the same as when the weights were saved. Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.</source>
          <target state="translated">如果 &lt;code&gt;by_name&lt;/code&gt; 为False，则根据网络拓扑加载权重。这意味着架构应与保存权重时的架构相同。请注意，拓扑顺序中不会考虑没有权重的图层，因此只要没有权重，添加或删除图层就可以了。</target>
        </trans-unit>
        <trans-unit id="15a8bafdca0abb98187bac49dd0616a9d631c410" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;by_name&lt;/code&gt; is True, weights are loaded into layers only if they share the same name. This is useful for fine-tuning or transfer-learning models where some of the layers have changed.</source>
          <target state="translated">如果 &lt;code&gt;by_name&lt;/code&gt; 为True，则仅当权重共享相同的名称时才将其加载到图层中。这对于其中某些层已更改的微调或转移学习模型很有用。</target>
        </trans-unit>
        <trans-unit id="845594347374dd00bfd7e659fdc63e7e3d5b4f06" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;bytes_or_text&lt;/code&gt; is not a binary or unicode string.</source>
          <target state="translated">如果 &lt;code&gt;bytes_or_text&lt;/code&gt; 不是二进制或unicode字符串。</target>
        </trans-unit>
        <trans-unit id="8eec2900c2fb0f0251b678a361ecad074ba0af19" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cancel_pending_enqueues&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, all pending requests will also be canceled.</source>
          <target state="translated">如果 &lt;code&gt;cancel_pending_enqueues&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ，那么所有待处理的请求也将被取消。</target>
        </trans-unit>
        <trans-unit id="0da424a258741377ad7f1b3412ace95e1b7e087b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;categorical_column&lt;/code&gt; is not CategoricalColumn type.</source>
          <target state="translated">如果 &lt;code&gt;categorical_column&lt;/code&gt; 不是CategoricalColumn类型。</target>
        </trans-unit>
        <trans-unit id="2cb637aa705c546a113e41afd5c758c47dd8f823" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cell&lt;/code&gt; is not an instance of RNNCell, or &lt;code&gt;loop_fn&lt;/code&gt; is not a &lt;code&gt;callable&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;cell&lt;/code&gt; 不是RNNCell的实例，或者 &lt;code&gt;loop_fn&lt;/code&gt; 不是 &lt;code&gt;callable&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7d8fa2cfd25e1b41a79e7e3b6b4253739977bfe6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cell&lt;/code&gt; is not an instance of RNNCell.</source>
          <target state="translated">如果 &lt;code&gt;cell&lt;/code&gt; 不是RNNCell的实例。</target>
        </trans-unit>
        <trans-unit id="2c005314f14b9be4b12102c1d51d0d8b497fafda" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cell_fw&lt;/code&gt; or &lt;code&gt;cell_bw&lt;/code&gt; is not an instance of &lt;code&gt;RNNCell&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;cell_fw&lt;/code&gt; 或 &lt;code&gt;cell_bw&lt;/code&gt; 不是一个实例 &lt;code&gt;RNNCell&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d24f152ba9fe436f35ebbbc28f22afb95d7ac755" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ckpt_dir_or_file&lt;/code&gt; resolves to a directory with multiple checkpoints, reader for the latest checkpoint is returned.</source>
          <target state="translated">如果 &lt;code&gt;ckpt_dir_or_file&lt;/code&gt; 解析到具有多个检查点的目录，则返回最新检查点的阅读器。</target>
        </trans-unit>
        <trans-unit id="d2998b18d77ff28c7539e06d755706c8cf0700ef" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ckpt_dir_or_file&lt;/code&gt; resolves to a directory with no checkpoints.</source>
          <target state="translated">如果 &lt;code&gt;ckpt_dir_or_file&lt;/code&gt; 解析为没有检查点的目录。</target>
        </trans-unit>
        <trans-unit id="20bd49990b5cf72ae3b08662dd38487aaacb7b14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate precision by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is above the threshold and/or in the top-k highest predictions, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is indeed a correct label.</source>
          <target state="translated">如果指定了 &lt;code&gt;class_id&lt;/code&gt; ，我们将通过仅考虑批次中 &lt;code&gt;class_id&lt;/code&gt; 高于阈值和/或排名前k位的最高预测中的条目，并计算 &lt;code&gt;class_id&lt;/code&gt; 实际上是正确标签的分数来计算精度。</target>
        </trans-unit>
        <trans-unit id="594da24c877b56fce6dcc330d36e921550f67631" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate precision by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is in the top-k highest &lt;code&gt;predictions&lt;/code&gt;, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is indeed a correct label. If &lt;code&gt;class_id&lt;/code&gt; is not specified, we'll calculate precision as how often on average a class among the top-k classes with the highest predicted values of a batch entry is correct and can be found in the label for that entry.</source>
          <target state="translated">如果指定了 &lt;code&gt;class_id&lt;/code&gt; ，我们将仅考虑 &lt;code&gt;class_id&lt;/code&gt; 在前k个最高 &lt;code&gt;predictions&lt;/code&gt; 中的批次中的条目，并计算 &lt;code&gt;class_id&lt;/code&gt; 实际上是正确标签的分数，从而计算精度。如果未指定 &lt;code&gt;class_id&lt;/code&gt; ，我们将计算精度，因为批处理条目的预测值最高的前k个类中的一个类平均正确的频率可以在该条目的标签中找到。</target>
        </trans-unit>
        <trans-unit id="a2fed35668157bd216f9480f06ebfb465420b146" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate recall by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is in the label, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is above the threshold and/or in the top-k predictions.</source>
          <target state="translated">如果指定了 &lt;code&gt;class_id&lt;/code&gt; ，我们将通过仅考虑批次中标签为 &lt;code&gt;class_id&lt;/code&gt; 的条目，并计算 &lt;code&gt;class_id&lt;/code&gt; 高于阈值和/或在前k个预测中的条目中的分数来计算召回率。</target>
        </trans-unit>
        <trans-unit id="0598665208e329d2285f13959a4c8a0be2108783" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;class_id&lt;/code&gt; is specified, we calculate recall by considering only the entries in the batch for which &lt;code&gt;class_id&lt;/code&gt; is in the label, and computing the fraction of them for which &lt;code&gt;class_id&lt;/code&gt; is in the top-k &lt;code&gt;predictions&lt;/code&gt;. If &lt;code&gt;class_id&lt;/code&gt; is not specified, we'll calculate recall as how often on average a class among the labels of a batch entry is in the top-k &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="translated">如果指定了 &lt;code&gt;class_id&lt;/code&gt; ，我们将通过仅考虑批次中标签为 &lt;code&gt;class_id&lt;/code&gt; 的条目并计算其top-k &lt;code&gt;predictions&lt;/code&gt; 中的 &lt;code&gt;class_id&lt;/code&gt; 的分数来计算召回率。如果未指定 &lt;code&gt;class_id&lt;/code&gt; ，则我们将召回率计算为批次条目标签中的某个类别平均在前k个 &lt;code&gt;predictions&lt;/code&gt; 中的频率。</target>
        </trans-unit>
        <trans-unit id="8ed0b9e3e88d8fb4c9485f67ff031b4dbc5fc2f1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;clip_norm &amp;gt; global_norm&lt;/code&gt; then the entries in &lt;code&gt;t_list&lt;/code&gt; remain as they are, otherwise they're all shrunk by the global ratio.</source>
          <target state="translated">如果 &lt;code&gt;clip_norm &amp;gt; global_norm&lt;/code&gt; &lt;code&gt;t_list&lt;/code&gt; ，则t_list中的条目将保持原样，否则它们将被全局比率缩小。</target>
        </trans-unit>
        <trans-unit id="7e9530f81d1e38f5cf65209f508156d9b6769612" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cluster&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, and &lt;code&gt;ps_tasks&lt;/code&gt; is 0, the returned function is a no-op. Otherwise, the value of &lt;code&gt;ps_tasks&lt;/code&gt; is derived from &lt;code&gt;cluster&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;cluster&lt;/code&gt; 为 &lt;code&gt;None&lt;/code&gt; ，并且 &lt;code&gt;ps_tasks&lt;/code&gt; 为0，则返回的函数为no-op。否则， &lt;code&gt;ps_tasks&lt;/code&gt; 的值是从 &lt;code&gt;cluster&lt;/code&gt; 派生的。</target>
        </trans-unit>
        <trans-unit id="d6d7bf46850010a12ccc4b12b47b4fc474e27898" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cluster&lt;/code&gt; is not a dictionary mapping strings to lists of strings, and not a &lt;a href=&quot;clusterdef&quot;&gt;&lt;code&gt;tf.train.ClusterDef&lt;/code&gt;&lt;/a&gt; protobuf.</source>
          <target state="translated">如果 &lt;code&gt;cluster&lt;/code&gt; 不是字典，则&lt;a href=&quot;clusterdef&quot;&gt; &lt;code&gt;tf.train.ClusterDef&lt;/code&gt; &lt;/a&gt;字符串映射到字符串列表，而不是tf.train.ClusterDef protobuf。</target>
        </trans-unit>
        <trans-unit id="39cf1c8eecb1ef7b4ac070aaa23d0ecfa7f82a3b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;combiner&lt;/code&gt; is not one of {&quot;mean&quot;, &quot;sqrtn&quot;, &quot;sum&quot;}.</source>
          <target state="translated">如果 &lt;code&gt;combiner&lt;/code&gt; 不是{&amp;ldquo; mean&amp;rdquo;，&amp;ldquo; sqrtn&amp;rdquo;，&amp;ldquo; sum&amp;rdquo;}中的一个。</target>
        </trans-unit>
        <trans-unit id="065bbd8103d747b51b68745d23b95f48f33acad0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;condition&lt;/code&gt; evaluates to false, print the list of tensors in &lt;code&gt;data&lt;/code&gt;. &lt;code&gt;summarize&lt;/code&gt; determines how many entries of the tensors to print.</source>
          <target state="translated">如果 &lt;code&gt;condition&lt;/code&gt; 评估为false，则在 &lt;code&gt;data&lt;/code&gt; 中打印张量列表。 &lt;code&gt;summarize&lt;/code&gt; 确定要打印多少张量条目。</target>
        </trans-unit>
        <trans-unit id="dc7c3e5a0b26f7d25559f77e68ccbfaa5c98f33a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;condition&lt;/code&gt; is a vector and &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are higher rank matrices, then it chooses which row (outer dimension) to copy from &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If &lt;code&gt;condition&lt;/code&gt; has the same shape as &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, then it chooses which element to copy from &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;condition&lt;/code&gt; 是向量，并且 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 是较高秩的矩阵，则它将选择要从 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 复制的行（外部维）。如果 &lt;code&gt;condition&lt;/code&gt; 与 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 的形状相同，则它从 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 中选择要复制的元素。</target>
        </trans-unit>
        <trans-unit id="852f5ef307e7bc28b2850a54f24a33882b85de2d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;control_inputs&lt;/code&gt; is not a list of &lt;code&gt;Operation&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt; objects.</source>
          <target state="translated">如果 &lt;code&gt;control_inputs&lt;/code&gt; 不是 &lt;code&gt;Operation&lt;/code&gt; 或 &lt;code&gt;Tensor&lt;/code&gt; 对象的列表。</target>
        </trans-unit>
        <trans-unit id="dc07b7d3b7d37ada7c331d72e2d06fb75d39fe59" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;core_assignment&lt;/code&gt; is not a rank 3 numpy array.</source>
          <target state="translated">如果 &lt;code&gt;core_assignment&lt;/code&gt; 不是3级numpy数组。</target>
        </trans-unit>
        <trans-unit id="85cf61e910d69324c4a7ef790c66d6a2dfd03048" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ctc_merge_repeated&lt;/code&gt; is set False, then deep within the CTC calculation, repeated non-blank labels will not be merged and are interpreted as individual labels. This is a simplified (non-standard) version of CTC.</source>
          <target state="translated">如果 &lt;code&gt;ctc_merge_repeated&lt;/code&gt; 设置为False，则在CTC计算的深处，重复的非空白标签将不会合并，并被解释为单个标签。这是CTC的简化（非标准）版本。</target>
        </trans-unit>
        <trans-unit id="47f2aad48c2d0f196f9ea6e64ee4554117907144" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cycle&lt;/code&gt; is True then a multiple of &lt;code&gt;decay_steps&lt;/code&gt; is used, the first one that is bigger than &lt;code&gt;global_steps&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;cycle&lt;/code&gt; 为True，则使用倍数 &lt;code&gt;decay_steps&lt;/code&gt; ，第一个大于 &lt;code&gt;global_steps&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5e96124e7a04b42a83269b91d81e7e32583e381c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;cycle&lt;/code&gt; is True then a multiple of &lt;code&gt;decay_steps&lt;/code&gt; is used, the first one that is bigger than &lt;code&gt;step&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;cycle&lt;/code&gt; 为True，那么将使用 &lt;code&gt;decay_steps&lt;/code&gt; 的倍数，第一个大于 &lt;code&gt;step&lt;/code&gt; 的值。</target>
        </trans-unit>
        <trans-unit id="ed08d044f4ced3eb43b5b5b9c435daedbc9bccbf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, cropped_rows, cropped_cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, channels, cropped_rows, cropped_cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c5b04849f3239ff7f2aed6311abff3cbd6b35af1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, dim1, dim2, dim3)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, channels, dim1, dim2, dim3)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f34c9b34734b9df20fbf8e979f546c9c4cc5baf4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, padded_rows, padded_cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, channels, padded_rows, padded_cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="18824f32ee3435a0aaf0ab5c308c42f192295a0b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, rows, cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, channels, rows, cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d97ca997b91aa66ba4112051e89b9fd1d11e0319" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e6ed1bb95109cbf4e1521d123414f77ee773a64c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, channels, upsampled_rows, upsampled_cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, channels, upsampled_rows, upsampled_cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4b398a294c2ee1defa640c1a2420cb9d283d80b8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cfcc85522ec5786f0f0111cb911348fd3d60aa41" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5b26f95b56877033c8096f8c21ee90b92dfad7a9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="40a4fb20ae2e104be54b9c38059d00d6af133ad2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="13dbf77e04457c4f4f2d2b1bf44035da08c15b02" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, channels, cropped_rows, cropped_cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch_size, channels, cropped_rows, cropped_cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="16c3b7ad97b58254a0f880dcb00666665f89ea7c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, channels, dim1, dim2, dim3)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（批处理大小 &lt;code&gt;(batch_size, channels, dim1, dim2, dim3)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1fb7c8889c720e09fcfeff626a329d774fcc3a0b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, channels, padded_rows, padded_cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch_size, channels, padded_rows, padded_cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e50baf564ca14e56683795ce398dfeea230ae434" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, channels, rows, cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（批处理大小 &lt;code&gt;(batch_size, channels, rows, cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9212d130a38e7aa9a9cc4c3069720d3b8a25dbdf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（批处理大小 &lt;code&gt;(batch_size, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8c965d4cefe52be58f4541312fd3e5d23c6fe18f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, channels, upsampled_rows, upsampled_cols)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（批处理大小 &lt;code&gt;(batch_size, channels, upsampled_rows, upsampled_cols)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6e386532c5fd8c2d8fa779b964ec07b7f0be40ed" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch_size, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ba4f67f214014ed4451c10d24c0e147e61468aaf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt;: &lt;code&gt;(batch_size, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;data_format&lt;/code&gt; 为 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; ：（ &lt;code&gt;(batch_size, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)&lt;/code&gt;</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
