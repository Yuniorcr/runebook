<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="16c88bb46cbf5ef3f448ca4fe755467e88b5e578" translate="yes" xml:space="preserve">
          <source>This is different from &lt;a href=&quot;../tensors#torch.Tensor.repeat&quot;&gt;&lt;code&gt;torch.Tensor.repeat()&lt;/code&gt;&lt;/a&gt; but similar to &lt;code&gt;numpy.repeat&lt;/code&gt;.</source>
          <target state="translated">这与&lt;a href=&quot;../tensors#torch.Tensor.repeat&quot;&gt; &lt;code&gt;torch.Tensor.repeat()&lt;/code&gt; &lt;/a&gt;不同，但与 &lt;code&gt;numpy.repeat&lt;/code&gt; 相似。</target>
        </trans-unit>
        <trans-unit id="db053cd2631236023d48272222af395e026941e8" translate="yes" xml:space="preserve">
          <source>This is equivalent to &lt;code&gt;self.log_pob(input).argmax(dim=1)&lt;/code&gt;, but is more efficient in some cases.</source>
          <target state="translated">这等效于 &lt;code&gt;self.log_pob(input).argmax(dim=1)&lt;/code&gt; ，但是在某些情况下更有效。</target>
        </trans-unit>
        <trans-unit id="374b7dab14fec694b4f5430f4c9e29dd3262cee0" translate="yes" xml:space="preserve">
          <source>This is equivalent to concatenation along the first axis after all 1-D tensors have been reshaped by &lt;a href=&quot;torch.atleast_2d#torch.atleast_2d&quot;&gt;&lt;code&gt;torch.atleast_2d()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这等效于通过&lt;a href=&quot;torch.atleast_2d#torch.atleast_2d&quot;&gt; &lt;code&gt;torch.atleast_2d()&lt;/code&gt; &lt;/a&gt;重整了所有1-D张量后沿第一个轴的串联。</target>
        </trans-unit>
        <trans-unit id="b6ef108509ff368b6991089b8608a37aca821f0d" translate="yes" xml:space="preserve">
          <source>This is equivalent to concatenation along the first axis for 1-D tensors, and along the second axis for all other tensors.</source>
          <target state="translated">这就相当于沿第一轴对一维时序进行连接,沿第二轴对所有其他时序进行连接。</target>
        </trans-unit>
        <trans-unit id="c5b9e7c481799905ba918331b66fdb7b66a8da08" translate="yes" xml:space="preserve">
          <source>This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped by &lt;a href=&quot;torch.atleast_3d#torch.atleast_3d&quot;&gt;&lt;code&gt;torch.atleast_3d()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这等效于通过&lt;a href=&quot;torch.atleast_3d#torch.atleast_3d&quot;&gt; &lt;code&gt;torch.atleast_3d()&lt;/code&gt; &lt;/a&gt;重塑了1-D和2-D张量后沿第三轴的串联。</target>
        </trans-unit>
        <trans-unit id="c60beaf37836d9a93c155f39fdfc6ecdf807a30e" translate="yes" xml:space="preserve">
          <source>This is equivalent with &lt;a href=&quot;#torch.nn.Module.train&quot;&gt;&lt;code&gt;self.train(False)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这等效于&lt;a href=&quot;#torch.nn.Module.train&quot;&gt; &lt;code&gt;self.train(False)&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d6810c532f9495d317b56fc8164ab42f154df6d1" translate="yes" xml:space="preserve">
          <source>This is equivalent with &lt;a href=&quot;torch.nn.module#torch.nn.Module.train&quot;&gt;&lt;code&gt;self.train(False)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这等效于&lt;a href=&quot;torch.nn.module#torch.nn.Module.train&quot;&gt; &lt;code&gt;self.train(False)&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="14aba227b9dce4ab34682734cfe12d5fc9a3b9e5" translate="yes" xml:space="preserve">
          <source>This is in contrast to Sutskever et. al. and other frameworks which employ an update of the form</source>
          <target state="translated">这与Sutskever等人和其他框架采用更新的形式形成对比。</target>
        </trans-unit>
        <trans-unit id="60444d425f826d3c68c2b033a78fb2f503cd684c" translate="yes" xml:space="preserve">
          <source>This is likely less than the amount shown in &lt;code&gt;nvidia-smi&lt;/code&gt; since some unused memory can be held by the caching allocator and some context needs to be created on GPU. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-memory-management&quot;&gt;Memory management&lt;/a&gt; for more details about GPU memory management.</source>
          <target state="translated">这可能少于 &lt;code&gt;nvidia-smi&lt;/code&gt; 中显示的数量，因为缓存分配器可以保留一些未使用的内存，并且需要在GPU上创建一些上下文。有关GPU内存管理的更多详细信息，请参阅&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-memory-management&quot;&gt;内存&lt;/a&gt;管理。</target>
        </trans-unit>
        <trans-unit id="c37867c00b5ddfbf25d4de90fb71189dbd82b435" translate="yes" xml:space="preserve">
          <source>This is mainly useful for changing the shape of the result of &lt;a href=&quot;#torch.distributions.independent.Independent.log_prob&quot;&gt;&lt;code&gt;log_prob()&lt;/code&gt;&lt;/a&gt;. For example to create a diagonal Normal distribution with the same shape as a Multivariate Normal distribution (so they are interchangeable), you can:</source>
          <target state="translated">这主要用于更改&lt;a href=&quot;#torch.distributions.independent.Independent.log_prob&quot;&gt; &lt;code&gt;log_prob()&lt;/code&gt; &lt;/a&gt;结果的形状。例如，要创建与多变量正态分布具有相同形状的对角正态分布（因此它们是可互换的），您可以：</target>
        </trans-unit>
        <trans-unit id="89d9637a7ca542b85a68e4470c388a54ccbbc2a4" translate="yes" xml:space="preserve">
          <source>This is not bijective and cannot be used for HMC. However this acts mostly coordinate-wise (except for the final normalization), and thus is appropriate for coordinate-wise optimization algorithms.</source>
          <target state="translated">这不是双目性的,不能用于HMC。然而这主要是坐标作用(除了最后的归一化),因此适用于坐标优化算法。</target>
        </trans-unit>
        <trans-unit id="18f227b9fbcb58581a48e62cc2b1e4b0a1736273" translate="yes" xml:space="preserve">
          <source>This is recommended because the tracer may witness tensor creation on a specific device, so casting an already-loaded model may have unexpected effects. Casting the model &lt;em&gt;before&lt;/em&gt; saving it ensures that the tracer has the correct device information.</source>
          <target state="translated">推荐这样做是因为跟踪器可能会在特定设备上见证张量的创建，因此强制转换已加载的模型可能会产生意想不到的效果。&lt;em&gt;在&lt;/em&gt;保存模型&lt;em&gt;之前&lt;/em&gt;对其进行转换，以确保跟踪器具有正确的设备信息。</target>
        </trans-unit>
        <trans-unit id="61139b0235e460eab7709588bf0db5fef3c1ed33" translate="yes" xml:space="preserve">
          <source>This is supported for &lt;a href=&quot;#module-attributes&quot;&gt;module attributes&lt;/a&gt; class attribute annotations but not for functions</source>
          <target state="translated">&lt;a href=&quot;#module-attributes&quot;&gt;模块属性&lt;/a&gt;类属性注释支持此功能，但函数不支持</target>
        </trans-unit>
        <trans-unit id="5d93a3f447e3870288983d617bf3d5ca0babcaca" translate="yes" xml:space="preserve">
          <source>This is the default method, meaning that &lt;code&gt;init_method&lt;/code&gt; does not have to be specified (or can be &lt;code&gt;env://&lt;/code&gt;).</source>
          <target state="translated">这是默认方法，这意味着不必指定 &lt;code&gt;init_method&lt;/code&gt; （或可以为 &lt;code&gt;env://&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="b773fd2df4f9d314a4e612fca433c54f4b6db8e8" translate="yes" xml:space="preserve">
          <source>This is the default strategy (except for macOS and OS X where it&amp;rsquo;s not supported).</source>
          <target state="translated">这是默认策略（不支持不支持的macOS和OS X）。</target>
        </trans-unit>
        <trans-unit id="b58bf6260a34528b9c54af5a74ed650426bd462d" translate="yes" xml:space="preserve">
          <source>This is the functional version of the DataParallel module.</source>
          <target state="translated">这是DataParallel模块的功能版本。</target>
        </trans-unit>
        <trans-unit id="28e50c155d4263693358c9685af859f0b288737a" translate="yes" xml:space="preserve">
          <source>This is the most common case, and corresponds to fetching a minibatch of data and collating them into batched samples, i.e., containing Tensors with one dimension being the batch dimension (usually the first).</source>
          <target state="translated">这是最常见的情况,对应的是获取一个小批量的数据,并将其整理成批量样本,即包含一个维度为批量维度的Tensors(通常是第一个)。</target>
        </trans-unit>
        <trans-unit id="9f2aa90c9ddd953d8134c3b2013f0dd5a5e04793" translate="yes" xml:space="preserve">
          <source>This is the quantized equivalent of &lt;a href=&quot;generated/torch.nn.elu#torch.nn.ELU&quot;&gt;&lt;code&gt;ELU&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.elu#torch.nn.ELU&quot;&gt; &lt;code&gt;ELU&lt;/code&gt; &lt;/a&gt;的量化等效项。</target>
        </trans-unit>
        <trans-unit id="051cad7dbbb9111a95c9efe4f04cfeb331282a9e" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;BatchNorm2d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt; &lt;code&gt;BatchNorm2d&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="ea4fe276ddec4ebc483841a1170deaf100cb0956" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.batchnorm3d#torch.nn.BatchNorm3d&quot;&gt;&lt;code&gt;BatchNorm3d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.batchnorm3d#torch.nn.BatchNorm3d&quot;&gt; &lt;code&gt;BatchNorm3d&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="e5ce0ce0859be0cbdcd66ae4d96e1834e80fb440" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.groupnorm#torch.nn.GroupNorm&quot;&gt;&lt;code&gt;GroupNorm&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.groupnorm#torch.nn.GroupNorm&quot;&gt; &lt;code&gt;GroupNorm&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="4fd9da5ac2b1219bc045ac6f1d4efc7962f29b18" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.hardswish#torch.nn.Hardswish&quot;&gt;&lt;code&gt;Hardswish&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.hardswish#torch.nn.Hardswish&quot;&gt; &lt;code&gt;Hardswish&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="81ee4b5a559a55d776be5e5ad40fea15e08c77c3" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.instancenorm1d#torch.nn.InstanceNorm1d&quot;&gt;&lt;code&gt;InstanceNorm1d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.instancenorm1d#torch.nn.InstanceNorm1d&quot;&gt; &lt;code&gt;InstanceNorm1d&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="306614a03d85542a417f30827501dbc097b0e4e2" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.instancenorm2d#torch.nn.InstanceNorm2d&quot;&gt;&lt;code&gt;InstanceNorm2d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.instancenorm2d#torch.nn.InstanceNorm2d&quot;&gt; &lt;code&gt;InstanceNorm2d&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="5c54c49dfa0b1be230f77c6acfc8832f75ff793b" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.instancenorm3d#torch.nn.InstanceNorm3d&quot;&gt;&lt;code&gt;InstanceNorm3d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.instancenorm3d#torch.nn.InstanceNorm3d&quot;&gt; &lt;code&gt;InstanceNorm3d&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="1ab22dac0481c7e9d72041caf66a8d6e6bce24a3" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;generated/torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt; &lt;code&gt;LayerNorm&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="1c1757bb112d3facda0c6b8d39d0c0a08d49265a" translate="yes" xml:space="preserve">
          <source>This is the quantized version of &lt;a href=&quot;nn.functional#torch.nn.functional.hardswish&quot;&gt;&lt;code&gt;hardswish()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;nn.functional#torch.nn.functional.hardswish&quot;&gt; &lt;code&gt;hardswish()&lt;/code&gt; &lt;/a&gt;的量化版本。</target>
        </trans-unit>
        <trans-unit id="c6493b5bad0951f0b43e4846b14cd1a429b62cc1" translate="yes" xml:space="preserve">
          <source>This is the reverse operation of the manner described in &lt;a href=&quot;#torch.Tensor.gather&quot;&gt;&lt;code&gt;gather()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;#torch.Tensor.gather&quot;&gt; &lt;code&gt;gather()&lt;/code&gt; &lt;/a&gt;描述的方式的相反操作。</target>
        </trans-unit>
        <trans-unit id="5295faab37629f799f6e6fbb1e9825a33f998b68" translate="yes" xml:space="preserve">
          <source>This is the second value returned by &lt;a href=&quot;torch.max#torch.max&quot;&gt;&lt;code&gt;torch.max()&lt;/code&gt;&lt;/a&gt;. See its documentation for the exact semantics of this method.</source>
          <target state="translated">这是&lt;a href=&quot;torch.max#torch.max&quot;&gt; &lt;code&gt;torch.max()&lt;/code&gt; &lt;/a&gt;返回的第二个值。有关此方法的确切语义，请参见其文档。</target>
        </trans-unit>
        <trans-unit id="19c006dca5dfcf6b24613e9eb4ec7d4564e3ffde" translate="yes" xml:space="preserve">
          <source>This is the second value returned by &lt;a href=&quot;torch.min#torch.min&quot;&gt;&lt;code&gt;torch.min()&lt;/code&gt;&lt;/a&gt;. See its documentation for the exact semantics of this method.</source>
          <target state="translated">这是&lt;a href=&quot;torch.min#torch.min&quot;&gt; &lt;code&gt;torch.min()&lt;/code&gt; &lt;/a&gt;返回的第二个值。有关此方法的确切语义，请参见其文档。</target>
        </trans-unit>
        <trans-unit id="ea4ca9f34dc42157c431ad05a09921e13d264890" translate="yes" xml:space="preserve">
          <source>This is the second value returned by &lt;a href=&quot;torch.sort#torch.sort&quot;&gt;&lt;code&gt;torch.sort()&lt;/code&gt;&lt;/a&gt;. See its documentation for the exact semantics of this method.</source>
          <target state="translated">这是&lt;a href=&quot;torch.sort#torch.sort&quot;&gt; &lt;code&gt;torch.sort()&lt;/code&gt; &lt;/a&gt;返回的第二个值。有关此方法的确切语义，请参见其文档。</target>
        </trans-unit>
        <trans-unit id="f4162fd55661c8ae3715301b7e45fb9d304f83a8" translate="yes" xml:space="preserve">
          <source>This is typically passed to an optimizer.</source>
          <target state="translated">这通常被传递给优化器。</target>
        </trans-unit>
        <trans-unit id="8881d58b1f068203ff9ef6d05a7b8193f5aad690" translate="yes" xml:space="preserve">
          <source>This is typically used to register a buffer that should not to be considered a model parameter. For example, BatchNorm&amp;rsquo;s &lt;code&gt;running_mean&lt;/code&gt; is not a parameter, but is part of the module&amp;rsquo;s state. Buffers, by default, are persistent and will be saved alongside parameters. This behavior can be changed by setting &lt;code&gt;persistent&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;. The only difference between a persistent buffer and a non-persistent buffer is that the latter will not be a part of this module&amp;rsquo;s &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这通常用于注册不应被视为模型参数的缓冲区。例如，BatchNorm的 &lt;code&gt;running_mean&lt;/code&gt; 不是参数，而是模块状态的一部分。默认情况下，缓冲区是持久性的，并将与参数一起保存。可以通过将 &lt;code&gt;persistent&lt;/code&gt; 设置为 &lt;code&gt;False&lt;/code&gt; 来更改此行为。持久缓冲区和非持久缓冲区之间的唯一区别是，后者不会成为该模块的&lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;的一部分。</target>
        </trans-unit>
        <trans-unit id="bc05416a2fcfa2651cf566b1804c2fef547cfa8c" translate="yes" xml:space="preserve">
          <source>This is typically used to register a buffer that should not to be considered a model parameter. For example, BatchNorm&amp;rsquo;s &lt;code&gt;running_mean&lt;/code&gt; is not a parameter, but is part of the module&amp;rsquo;s state. Buffers, by default, are persistent and will be saved alongside parameters. This behavior can be changed by setting &lt;code&gt;persistent&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;. The only difference between a persistent buffer and a non-persistent buffer is that the latter will not be a part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这通常用于注册不应被视为模型参数的缓冲区。例如，BatchNorm的 &lt;code&gt;running_mean&lt;/code&gt; 不是参数，而是模块状态的一部分。默认情况下，缓冲区是持久性的，并将与参数一起保存。可以通过将 &lt;code&gt;persistent&lt;/code&gt; 设置为 &lt;code&gt;False&lt;/code&gt; 来更改此行为。持久缓冲区和非持久缓冲区之间的唯一区别是，后者不会成为该模块的&lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;的一部分。</target>
        </trans-unit>
        <trans-unit id="cdf0d415e18e8e03494fb14369b3744608b2dde4" translate="yes" xml:space="preserve">
          <source>This is typically used to register a buffer that should not to be considered a model parameter. For example, BatchNorm&amp;rsquo;s &lt;code&gt;running_mean&lt;/code&gt; is not a parameter, but is part of the module&amp;rsquo;s state. Buffers, by default, are persistent and will be saved alongside parameters. This behavior can be changed by setting &lt;code&gt;persistent&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;. The only difference between a persistent buffer and a non-persistent buffer is that the latter will not be a part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这通常用于注册不应被视为模型参数的缓冲区。例如，BatchNorm的 &lt;code&gt;running_mean&lt;/code&gt; 不是参数，而是模块状态的一部分。默认情况下，缓冲区是持久性的，并将与参数一起保存。可以通过将 &lt;code&gt;persistent&lt;/code&gt; 设置为 &lt;code&gt;False&lt;/code&gt; 来更改此行为。持久缓冲区和非持久缓冲区之间的唯一区别是，后者不会成为该模块的&lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;的一部分。</target>
        </trans-unit>
        <trans-unit id="387b12018432b2012dd14d16de801f3f2b4ba6be" translate="yes" xml:space="preserve">
          <source>This is typically used to register a buffer that should not to be considered a model parameter. For example, BatchNorm&amp;rsquo;s &lt;code&gt;running_mean&lt;/code&gt; is not a parameter, but is part of the module&amp;rsquo;s state. Buffers, by default, are persistent and will be saved alongside parameters. This behavior can be changed by setting &lt;code&gt;persistent&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;. The only difference between a persistent buffer and a non-persistent buffer is that the latter will not be a part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这通常用于注册不应被视为模型参数的缓冲区。例如，BatchNorm的 &lt;code&gt;running_mean&lt;/code&gt; 不是参数，而是模块状态的一部分。默认情况下，缓冲区是持久性的，并将与参数一起保存。可以通过将 &lt;code&gt;persistent&lt;/code&gt; 设置为 &lt;code&gt;False&lt;/code&gt; 来更改此行为。持久缓冲区和非持久缓冲区之间的唯一区别是，后者不会成为该模块的&lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;的一部分。</target>
        </trans-unit>
        <trans-unit id="e9103d955a0e478fd4fc8f34beda0ed1c416c5a7" translate="yes" xml:space="preserve">
          <source>This is used by the &lt;code&gt;quantization&lt;/code&gt; utility functions to add the quant and dequant modules, before &lt;code&gt;convert&lt;/code&gt; function &lt;code&gt;QuantStub&lt;/code&gt; will just be observer, it observes the input tensor, after &lt;code&gt;convert&lt;/code&gt;, &lt;code&gt;QuantStub&lt;/code&gt; will be swapped to &lt;code&gt;nnq.Quantize&lt;/code&gt; which does actual quantization. Similarly for &lt;code&gt;DeQuantStub&lt;/code&gt;.</source>
          <target state="translated">这是使用的 &lt;code&gt;quantization&lt;/code&gt; 效用函数添加定量和dequant模块，前 &lt;code&gt;convert&lt;/code&gt; 功能 &lt;code&gt;QuantStub&lt;/code&gt; 也只是观察者，其观察输入张量，经过 &lt;code&gt;convert&lt;/code&gt; ， &lt;code&gt;QuantStub&lt;/code&gt; 将被交换到 &lt;code&gt;nnq.Quantize&lt;/code&gt; 这不实际的量化。对于 &lt;code&gt;DeQuantStub&lt;/code&gt; 也是如此。</target>
        </trans-unit>
        <trans-unit id="7feb7536faa55e8682dba21d0a2c61b1c664ec04" translate="yes" xml:space="preserve">
          <source>This is used e.g. for indices returned from a max &lt;code&gt;Function&lt;/code&gt;.</source>
          <target state="translated">例如，这用于从max &lt;code&gt;Function&lt;/code&gt; 返回的索引。</target>
        </trans-unit>
        <trans-unit id="18ae6606a0b9fa5a1d8375a29d5adf1260f68aa6" translate="yes" xml:space="preserve">
          <source>This is used for measuring the error of a reconstruction in for example an auto-encoder. Note that the targets</source>
          <target state="translated">它用于测量重构的误差,例如自动编码器。请注意,目标</target>
        </trans-unit>
        <trans-unit id="44bcfdd8636d4fef63e74c75c8c5e2e8049a6723" translate="yes" xml:space="preserve">
          <source>This is used for measuring the error of a reconstruction in for example an auto-encoder. Note that the targets &lt;code&gt;t[i]&lt;/code&gt; should be numbers between 0 and 1.</source>
          <target state="translated">这用于在例如自动编码器中测量重构的误差。请注意，目标 &lt;code&gt;t[i]&lt;/code&gt; 应为0到1之间的数字。</target>
        </trans-unit>
        <trans-unit id="82ff1110b5f2f18a81804af99bb7a1033487ea4f" translate="yes" xml:space="preserve">
          <source>This is useful for implementing efficient sub-pixel convolution with a stride of</source>
          <target state="translated">这对于实现高效的子像素卷积,以步幅的</target>
        </trans-unit>
        <trans-unit id="055744440e1ad514287a476301fa832544763a8f" translate="yes" xml:space="preserve">
          <source>This is useful for parameterizing positive definite matrices in terms of their Cholesky factorization.</source>
          <target state="translated">这对于用正定矩阵的Cholesky因式进行参数化很有用。</target>
        </trans-unit>
        <trans-unit id="0b3e0c96ed0785872533b5ba8bff1ae227ce271e" translate="yes" xml:space="preserve">
          <source>This layer uses statistics computed from input data in both training and evaluation modes.</source>
          <target state="translated">该层使用在训练和评估模式下从输入数据计算的统计数据。</target>
        </trans-unit>
        <trans-unit id="e61f8043e790e86849febfe55d39af2c5aac3218" translate="yes" xml:space="preserve">
          <source>This loss combines a &lt;code&gt;Sigmoid&lt;/code&gt; layer and the &lt;code&gt;BCELoss&lt;/code&gt; in one single class.</source>
          <target state="translated">这种损耗将 &lt;code&gt;Sigmoid&lt;/code&gt; 层和 &lt;code&gt;BCELoss&lt;/code&gt; 合并为一个类别。</target>
        </trans-unit>
        <trans-unit id="940b923ef28b8c58cfd52fc019408d07c1f8a33f" translate="yes" xml:space="preserve">
          <source>This loss combines a &lt;code&gt;Sigmoid&lt;/code&gt; layer and the &lt;code&gt;BCELoss&lt;/code&gt; in one single class. This version is more numerically stable than using a plain &lt;code&gt;Sigmoid&lt;/code&gt; followed by a &lt;code&gt;BCELoss&lt;/code&gt; as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability.</source>
          <target state="translated">这种损耗将 &lt;code&gt;Sigmoid&lt;/code&gt; 层和 &lt;code&gt;BCELoss&lt;/code&gt; 合并为一个类别。此版本比使用普通的 &lt;code&gt;Sigmoid&lt;/code&gt; 和 &lt;code&gt;BCELoss&lt;/code&gt; 的版本在数值上更稳定，因为通过将操作组合到一层中，我们利用了log-sum-exp技巧来实现数值稳定性。</target>
        </trans-unit>
        <trans-unit id="b85bf08f0c04a7b3a3773bc9f4c6784cf3720ebd" translate="yes" xml:space="preserve">
          <source>This may allow for better optimizations (such as constant folding etc.) by backends/runtimes that execute these graphs. If unspecified (default None), then the behavior is chosen automatically as follows. If operator_export_type is OperatorExportTypes.ONNX, the behavior is equivalent to setting this argument to False. For other values of operator_export_type, the behavior is equivalent to setting this argument to True. Note that for ONNX opset version &amp;lt; 9, initializers MUST be part of graph inputs. Therefore, if opset_version argument is set to a 8 or lower, this argument will be ignored.</source>
          <target state="translated">通过执行这些图形的后端/运行时，这可以允许进行更好的优化（例如恒定折叠等）。如果未指定（默认为&amp;ldquo;无&amp;rdquo;），则按以下方式自动选择行为。如果operator_export_type为OperatorExportTypes.ONNX，则该行为等效于将此参数设置为False。对于operator_export_type的其他值，此行为等效于将此参数设置为True。请注意，对于版本低于9的ONNX opset，初始化程序必须是图形输入的一部分。因此，如果opset_version参数设置为8或更低，则该参数将被忽略。</target>
        </trans-unit>
        <trans-unit id="26f1b287bc5579a8caeed012280a7b3f3a9f07cb" translate="yes" xml:space="preserve">
          <source>This means that &lt;code&gt;model.base&lt;/code&gt;&amp;rsquo;s parameters will use the default learning rate of &lt;code&gt;1e-2&lt;/code&gt;, &lt;code&gt;model.classifier&lt;/code&gt;&amp;rsquo;s parameters will use a learning rate of &lt;code&gt;1e-3&lt;/code&gt;, and a momentum of &lt;code&gt;0.9&lt;/code&gt; will be used for all parameters.</source>
          <target state="translated">这意味着 &lt;code&gt;model.base&lt;/code&gt; 的参数将使用默认学习率 &lt;code&gt;1e-2&lt;/code&gt; ， &lt;code&gt;model.classifier&lt;/code&gt; 的参数将使用学习率 &lt;code&gt;1e-3&lt;/code&gt; ，而动量 &lt;code&gt;0.9&lt;/code&gt; 将用于所有参数。</target>
        </trans-unit>
        <trans-unit id="0b5f23050e1225367270ed2f80d8587f70aa2118" translate="yes" xml:space="preserve">
          <source>This message indicates to us that the computation differed between when we first traced it and when we traced it with the &lt;code&gt;check_inputs&lt;/code&gt;. Indeed, the loop within the body of &lt;code&gt;loop_in_traced_fn&lt;/code&gt; depends on the shape of the input &lt;code&gt;x&lt;/code&gt;, and thus when we try another &lt;code&gt;x&lt;/code&gt; with a different shape, the trace differs.</source>
          <target state="translated">此消息向我们表明，在我们第一次跟踪它和使用 &lt;code&gt;check_inputs&lt;/code&gt; 跟踪它的时间之间，计算有所不同。实际上， &lt;code&gt;loop_in_traced_fn&lt;/code&gt; 主体中的循环取决于输入 &lt;code&gt;x&lt;/code&gt; 的形状，因此，当我们尝试另一个形状不同的 &lt;code&gt;x&lt;/code&gt; 时，轨迹也不同。</target>
        </trans-unit>
        <trans-unit id="6b6071e9753ecc5843a463c244f78990925791d4" translate="yes" xml:space="preserve">
          <source>This method assumes that the file system supports locking using &lt;code&gt;fcntl&lt;/code&gt; - most local systems and NFS support it.</source>
          <target state="translated">此方法假定文件系统支持使用 &lt;code&gt;fcntl&lt;/code&gt; 进行锁定-大多数本地系统和NFS支持该锁定。</target>
        </trans-unit>
        <trans-unit id="56fec11901471926f8e8051da013976d59b168bf" translate="yes" xml:space="preserve">
          <source>This method can only be called on a coalesced sparse tensor. See &lt;code&gt;Tensor.coalesce()&lt;/code&gt; for details.</source>
          <target state="translated">只能在合并的稀疏张量上调用此方法。有关详细信息，请参见 &lt;code&gt;Tensor.coalesce()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ab188eb8949a2274bed5b2cb6c64d4adfb8be156" translate="yes" xml:space="preserve">
          <source>This method computes the complex-to-complex discrete Fourier transform. Ignoring the batch dimensions, it computes the following expression:</source>
          <target state="translated">本方法计算复数到复数的离散傅里叶变换。忽略批次维度,它计算出以下表达式。</target>
        </trans-unit>
        <trans-unit id="9b6b6de7677cc3f29ad4b4bb71322ca8119f722c" translate="yes" xml:space="preserve">
          <source>This method computes the complex-to-complex inverse discrete Fourier transform. Ignoring the batch dimensions, it computes the following expression:</source>
          <target state="translated">本方法计算复数到复数的反离散傅立叶变换。忽略批次维度,它计算出以下表达式。</target>
        </trans-unit>
        <trans-unit id="07d469ff88f699ae509e6d44562a14e49142eb33" translate="yes" xml:space="preserve">
          <source>This method computes the complex-to-real inverse discrete Fourier transform. It is mathematically equivalent with &lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt; with differences only in formats of the input and output.</source>
          <target state="translated">此方法计算复数到实数的离散傅里叶逆变换。从数学&lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt; &lt;code&gt;ifft()&lt;/code&gt; &lt;/a&gt;它与ifft（）等效，只是输入和输出的格式有所不同。</target>
        </trans-unit>
        <trans-unit id="f0df83d3e836abc896e3d3ef88cddff7fe41858c" translate="yes" xml:space="preserve">
          <source>This method computes the real-to-complex discrete Fourier transform. It is mathematically equivalent with &lt;a href=&quot;torch.fft#torch.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt; with differences only in formats of the input and output.</source>
          <target state="translated">此方法计算实数到复杂的离散傅里叶变换。它在数学上等同于&lt;a href=&quot;torch.fft#torch.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;，只是输入和输出的格式有所不同。</target>
        </trans-unit>
        <trans-unit id="cdf0174c78d429d9d5f3575a0eab21bb4e7cb40a" translate="yes" xml:space="preserve">
          <source>This method is helpful for freezing part of the module for finetuning or training parts of a model individually (e.g., GAN training).</source>
          <target state="translated">这种方法有助于冻结部分模块,以便对模型的部分进行微调或单独训练(例如,GAN训练)。</target>
        </trans-unit>
        <trans-unit id="ca8069362a7e2b0181c1b2a91e97eec6d51986a6" translate="yes" xml:space="preserve">
          <source>This method is implemented using the Singular Value Decomposition.</source>
          <target state="translated">本方法采用奇异值分解法实现。</target>
        </trans-unit>
        <trans-unit id="a51d9e13859426129477705a920dac6fd0c48f90" translate="yes" xml:space="preserve">
          <source>This method modifies the module in-place.</source>
          <target state="translated">本方法可以就地修改模块。</target>
        </trans-unit>
        <trans-unit id="44d70c89b433cfca3df93bd2dca81609164685a8" translate="yes" xml:space="preserve">
          <source>This method sets the parameters&amp;rsquo; &lt;code&gt;requires_grad&lt;/code&gt; attributes in-place.</source>
          <target state="translated">此方法就地设置参数的 &lt;code&gt;requires_grad&lt;/code&gt; 属性。</target>
        </trans-unit>
        <trans-unit id="ba184c175718a9033afc302007ca57b3b2566fe2" translate="yes" xml:space="preserve">
          <source>This method supports 1D, 2D and 3D complex-to-complex transforms, indicated by &lt;code&gt;signal_ndim&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; must be a tensor with last dimension of size 2, representing the real and imaginary components of complex numbers, and should have at least &lt;code&gt;signal_ndim + 1&lt;/code&gt; dimensions with optionally arbitrary number of leading batch dimensions. If &lt;code&gt;normalized&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, this normalizes the result by dividing it with</source>
          <target state="translated">此方法支持1D，2D和3D复数到复数转换，由 &lt;code&gt;signal_ndim&lt;/code&gt; 指示。 &lt;code&gt;input&lt;/code&gt; 必须是张量，最后一个尺寸为2，表示复数的实数和虚数分量，并且至少应具有 &lt;code&gt;signal_ndim + 1&lt;/code&gt; 维，并且可以选择任意数量的前导批处理维。如果将 &lt;code&gt;normalized&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; ，则通过将结果除以将其标准化</target>
        </trans-unit>
        <trans-unit id="4d0394dd315af559db4d9ad47ffb52f54e5c2212" translate="yes" xml:space="preserve">
          <source>This method supports 1D, 2D and 3D real-to-complex transforms, indicated by &lt;code&gt;signal_ndim&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; must be a tensor with at least &lt;code&gt;signal_ndim&lt;/code&gt; dimensions with optionally arbitrary number of leading batch dimensions. If &lt;code&gt;normalized&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, this normalizes the result by dividing it with</source>
          <target state="translated">此方法支持1D，2D和3D实数到复杂的变换，由 &lt;code&gt;signal_ndim&lt;/code&gt; 指示。 &lt;code&gt;input&lt;/code&gt; 必须是至少具有 &lt;code&gt;signal_ndim&lt;/code&gt; 尺寸且可以选择任意数量的前导批处理尺寸的张量。如果将 &lt;code&gt;normalized&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; ，则通过将结果除以将其标准化</target>
        </trans-unit>
        <trans-unit id="75583911adf2f93140c081540537180003c155f0" translate="yes" xml:space="preserve">
          <source>This method will always create the file and try its best to clean up and remove the file at the end of the program. In other words, each initialization with the file init method will need a brand new empty file in order for the initialization to succeed. If the same file used by the previous initialization (which happens not to get cleaned up) is used again, this is unexpected behavior and can often cause deadlocks and failures. Therefore, even though this method will try its best to clean up the file, if the auto-delete happens to be unsuccessful, it is your responsibility to ensure that the file is removed at the end of the training to prevent the same file to be reused again during the next time. This is especially important if you plan to call &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; multiple times on the same file name. In other words, if the file is not removed/cleaned up and you call &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; again on that file, failures are expected. The rule of thumb here is that, make sure that the file is non-existent or empty every time &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">此方法将始终创建文件，并尽力在程序末尾清理并删除文件。换句话说，使用文件init方法进行的每次初始化都需要一个全新的空文件，以使初始化成功。如果再次使用先前初始化使用的同一文件（碰巧不会被清除），则这是意外行为，通常会导致死锁和失败。因此，即使此方法将尽最大努力清除文件，但如果自动删除碰巧失败，您有责任确保在培训结束时将文件删除，以防止同一文件被删除。在下一次再次重用。如果您计划调用&lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;init_process_group()&lt;/code&gt; ,&lt;/a&gt;则这一点尤其重要。同一文件名多次。换句话说，如果未删除/清除文件，而您对该文件再次调用&lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;init_process_group()&lt;/code&gt; &lt;/a&gt;，则可能会失败。经验法则是，确保每次调用&lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;init_process_group()&lt;/code&gt; &lt;/a&gt;时文件都不存在或为空。</target>
        </trans-unit>
        <trans-unit id="36d7188a05dab83ac9defa225d250cd47190ba2f" translate="yes" xml:space="preserve">
          <source>This method will read the configuration from environment variables, allowing one to fully customize how the information is obtained. The variables to be set are:</source>
          <target state="translated">该方法将从环境变量中读取配置,允许人们完全自定义信息的获取方式。需要设置的变量有:</target>
        </trans-unit>
        <trans-unit id="57da4e0220bd8e9709ab47673f34882d1449aae9" translate="yes" xml:space="preserve">
          <source>This mode can be used to export any operator (ATen or non-ATen) that is not registered and supported in ONNX. Exported falls through and exports the operator as is, as custom op. Exporting custom operators enables users to register and implement the operator as part of their runtime backend.</source>
          <target state="translated">该模式可用于导出任何未在 ONNX 中注册和支持的操作符(ATen 或非 ATen)。导出落空并按原样导出操作符,作为自定义操作符。 导出自定义操作符使用户能够注册并实现操作符,作为其运行时后端的一部分。</target>
        </trans-unit>
        <trans-unit id="da76922486c33377aa2791af6603164e435bb6ab" translate="yes" xml:space="preserve">
          <source>This mode is used to export all operators as ATen ops, and avoid conversion to ONNX.</source>
          <target state="translated">该模式用于将所有操作员输出为ATen操作,避免转换为ONNX。</target>
        </trans-unit>
        <trans-unit id="d9d848a6942846852bedaf5aea8e5e5bd3995b73" translate="yes" xml:space="preserve">
          <source>This mode is used to export all operators as regular ONNX operators. This is the default &lt;code&gt;operator_export_type&lt;/code&gt; mode.</source>
          <target state="translated">此模式用于将所有运算符导出为常规ONNX运算符。这是默认的 &lt;code&gt;operator_export_type&lt;/code&gt; 模式。</target>
        </trans-unit>
        <trans-unit id="9cf96f197fff58f45fdefadd1ad233845146b8c4" translate="yes" xml:space="preserve">
          <source>This mode should be enabled only for debugging as the different tests will slow down your program execution.</source>
          <target state="translated">该模式应该只在调试时启用,因为不同的测试会减慢你的程序执行速度。</target>
        </trans-unit>
        <trans-unit id="15b7320d744a4575a9e6699705096be13d718c1b" translate="yes" xml:space="preserve">
          <source>This module allows parameters with non-rowmajor-contiguous strides. For example, your model may contain some parameters whose &lt;code&gt;torch.memory_format&lt;/code&gt; is &lt;code&gt;torch.contiguous_format&lt;/code&gt; and others whose format is &lt;code&gt;torch.channels_last&lt;/code&gt;. However, corresponding parameters in different processes must have the same strides.</source>
          <target state="translated">该模块允许参数具有非行主要连续步幅。例如，您的模型可能包含一些参数，这些参数的 &lt;code&gt;torch.memory_format&lt;/code&gt; 为 &lt;code&gt;torch.contiguous_format&lt;/code&gt; ,而其他一些参数的格式为 &lt;code&gt;torch.channels_last&lt;/code&gt; 。但是，不同过程中的相应参数必须具有相同的跨度。</target>
        </trans-unit>
        <trans-unit id="db9962266fa6ecf5ecb4337d45f21434962d46f1" translate="yes" xml:space="preserve">
          <source>This module also contains any parameters that the original module had as well.</source>
          <target state="translated">这个模块也包含了原模块的任何参数。</target>
        </trans-unit>
        <trans-unit id="5790600450f4acb47de56be8f01d6569e2e765da" translate="yes" xml:space="preserve">
          <source>This module also supports mixed-precision distributed training. This means that your model can have different types of parameters such as mixed types of &lt;code&gt;fp16&lt;/code&gt; and &lt;code&gt;fp32&lt;/code&gt;, the gradient reduction on these mixed types of parameters will just work fine.</source>
          <target state="translated">该模块还支持混合精度分布式培训。这意味着，你的模型可以有不同类型的参数，如混合型的 &lt;code&gt;fp16&lt;/code&gt; 和 &lt;code&gt;fp32&lt;/code&gt; ，这些混合类型的参数，只会做工精细的梯度下降。</target>
        </trans-unit>
        <trans-unit id="aaad9c62985785aa5e132959be1bf299d5f15d45" translate="yes" xml:space="preserve">
          <source>This module assumes all parameters are registered in the model by the time it is created. No parameters should be added nor removed later. Same applies to buffers.</source>
          <target state="translated">本模块假设在创建模型时,所有参数都已在模型中注册。不应添加或删除任何参数。缓冲区也是如此。</target>
        </trans-unit>
        <trans-unit id="56c78b422ae4f13f13cfea0f3331ef6b5469addb" translate="yes" xml:space="preserve">
          <source>This module assumes all parameters are registered in the model of each distributed processes are in the same order. The module itself will conduct gradient &lt;code&gt;allreduce&lt;/code&gt; following the reverse order of the registered parameters of the model. In other words, it is users&amp;rsquo; responsibility to ensure that each distributed process has the exact same model and thus the exact same parameter registration order.</source>
          <target state="translated">该模块假定所有参数在模型中注册的每个分布式过程均以相同的顺序进行。模块本身将按照模型注册参数的相反顺序进行梯度 &lt;code&gt;allreduce&lt;/code&gt; 。换句话说，确保每个分布式过程具有完全相同的模型并因此具有完全相同的参数注册顺序是用户的责任。</target>
        </trans-unit>
        <trans-unit id="a2fc61472d65b92ddda57c12782f0c49ee43ce07" translate="yes" xml:space="preserve">
          <source>This module can be seen as the gradient of Conv1d with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation).</source>
          <target state="translated">这个模块可以看作是Conv1d相对于其输入的梯度。它也被称为分式卷积或解卷(虽然它不是实际的解卷操作)。</target>
        </trans-unit>
        <trans-unit id="51bd62541eadcc8d3cc881058d8a71b8bed71b7f" translate="yes" xml:space="preserve">
          <source>This module can be seen as the gradient of Conv2d with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation).</source>
          <target state="translated">这个模块可以看作是Conv2d相对于其输入的梯度。它也被称为分式卷积或反卷积(虽然它不是实际的反卷积操作)。</target>
        </trans-unit>
        <trans-unit id="03c2d1d66e7773d2c26345cff96e3404e927c5ec" translate="yes" xml:space="preserve">
          <source>This module can be seen as the gradient of Conv3d with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation).</source>
          <target state="translated">这个模块可以看作是Conv3d相对于其输入的梯度。它也被称为分式卷积或解卷积(虽然它不是一个实际的解卷操作)。</target>
        </trans-unit>
        <trans-unit id="8a37a41f99ccf18be289e494dc942de371c38958" translate="yes" xml:space="preserve">
          <source>This module currently does not support custom distributed collective operations in the forward pass, such as &lt;code&gt;SyncBatchNorm&lt;/code&gt; or other custom defined collectives in the model&amp;rsquo;s forward pass.</source>
          <target state="translated">此模块当前不支持前向传递中的自定义分布式集合操作，例如 &lt;code&gt;SyncBatchNorm&lt;/code&gt; 或模型的前向传递中的其他自定义定义的集合。</target>
        </trans-unit>
        <trans-unit id="e4e13a3367c83e826e07b89f6231cff61b5213ab" translate="yes" xml:space="preserve">
          <source>This module doesn&amp;rsquo;t work directly with NLLLoss, which expects the Log to be computed between the Softmax and itself. Use &lt;code&gt;LogSoftmax&lt;/code&gt; instead (it&amp;rsquo;s faster and has better numerical properties).</source>
          <target state="translated">该模块不能直接与NLLLoss一起使用，后者希望Log是在Softmax及其自身之间计算的。请改用 &lt;code&gt;LogSoftmax&lt;/code&gt; （速度更快，并且具有更好的数值属性）。</target>
        </trans-unit>
        <trans-unit id="b724d7ccdd2d4a2fad1d30f042a783b90f3e1b70" translate="yes" xml:space="preserve">
          <source>This module doesn&amp;rsquo;t work with &lt;a href=&quot;../autograd#torch.autograd.grad&quot;&gt;&lt;code&gt;torch.autograd.grad()&lt;/code&gt;&lt;/a&gt; (i.e. it will only work if gradients are to be accumulated in &lt;code&gt;.grad&lt;/code&gt; attributes of parameters).</source>
          <target state="translated">该模块不适用于&lt;a href=&quot;../autograd#torch.autograd.grad&quot;&gt; &lt;code&gt;torch.autograd.grad()&lt;/code&gt; &lt;/a&gt;（即，仅当要在参数的 &lt;code&gt;.grad&lt;/code&gt; 属性中累积渐变时，该模块才有效）。</target>
        </trans-unit>
        <trans-unit id="b31e8020fcc76734bdb0706e9d94b6fab41f09de" translate="yes" xml:space="preserve">
          <source>This module implements the combined (fused) modules conv + relu which can be then quantized.</source>
          <target state="translated">该模块实现了组合(融合)模块conv+relu,然后可以量化。</target>
        </trans-unit>
        <trans-unit id="abb55caf7c23cacd70b75be7b8534a2288b0ddd0" translate="yes" xml:space="preserve">
          <source>This module implements the functions you call directly to convert your model from FP32 to quantized form. For example the &lt;a href=&quot;#torch.quantization.prepare&quot;&gt;&lt;code&gt;prepare()&lt;/code&gt;&lt;/a&gt; is used in post training quantization to prepares your model for the calibration step and &lt;a href=&quot;#torch.quantization.convert&quot;&gt;&lt;code&gt;convert()&lt;/code&gt;&lt;/a&gt; actually converts the weights to int8 and replaces the operations with their quantized counterparts. There are other helper functions for things like quantizing the input to your model and performing critical fusions like conv+relu.</source>
          <target state="translated">该模块实现您直接调用的功能，以将模型从FP32转换为量化形式。例如，&lt;a href=&quot;#torch.quantization.prepare&quot;&gt; &lt;code&gt;prepare()&lt;/code&gt; &lt;/a&gt;用于训练后量化，以为校准步骤准备模型，&lt;a href=&quot;#torch.quantization.convert&quot;&gt; &lt;code&gt;convert()&lt;/code&gt; &lt;/a&gt;实际上将权重转换为int8，并用其量化的对应项替换操作。还有其他帮助程序功能，例如对模型的输入进行量化以及执行conv + relu等关键融合。</target>
        </trans-unit>
        <trans-unit id="a5f06261e4042915626c1433e6142f8f0b72218a" translate="yes" xml:space="preserve">
          <source>This module implements the quantized implementations of fused operations like conv + relu.</source>
          <target state="translated">该模块实现了conv+relu等融合运算的量化实现。</target>
        </trans-unit>
        <trans-unit id="fe84855e7e341d93fbb671f10f878fe740d68b6a" translate="yes" xml:space="preserve">
          <source>This module implements the quantized versions of the nn layers such as ~`torch.nn.Conv2d` and &lt;code&gt;torch.nn.ReLU&lt;/code&gt;.</source>
          <target state="translated">这个模块实现了nn层的量化版本，例如〜`torch.nn.Conv2d`和 &lt;code&gt;torch.nn.ReLU&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1cc16ec4495bf63da75c9357c640897793fcbd84" translate="yes" xml:space="preserve">
          <source>This module implements the versions of those fused operations needed for quantization aware training.</source>
          <target state="translated">该模块实现了量化感知训练所需的那些融合操作的版本。</target>
        </trans-unit>
        <trans-unit id="cd564c5f343a0b5d3e2281d9491b97ab89a390d6" translate="yes" xml:space="preserve">
          <source>This module implements versions of the key nn modules &lt;strong&gt;Conv2d()&lt;/strong&gt; and &lt;strong&gt;Linear()&lt;/strong&gt; which run in FP32 but with rounding applied to simulate the effect of INT8 quantization.</source>
          <target state="translated">此模块实现了关键nn模块&lt;strong&gt;Conv2d（）&lt;/strong&gt;和&lt;strong&gt;Linear（）的&lt;/strong&gt;版本，这些模块在FP32中运行，但应用了舍入以模拟INT8量化的效果。</target>
        </trans-unit>
        <trans-unit id="2d28957208d801ad4a8275f10517753872c57b97" translate="yes" xml:space="preserve">
          <source>This module is often used to retrieve word embeddings using indices. The input to the module is a list of indices, and the embedding matrix, and the output is the corresponding word embeddings.</source>
          <target state="translated">该模块常用于利用索引检索词嵌入。该模块的输入是一个索引列表,以及嵌入矩阵,输出是相应的词嵌入。</target>
        </trans-unit>
        <trans-unit id="a56a23f8f5587064fad32f9351698184c9934864" translate="yes" xml:space="preserve">
          <source>This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.</source>
          <target state="translated">该模块常用于存储词嵌入,并利用索引进行检索。该模块的输入是一个索引列表,输出是相应的词嵌入。</target>
        </trans-unit>
        <trans-unit id="8c517186ab821b45b2c9090ee2862c5050c7fd67" translate="yes" xml:space="preserve">
          <source>This module provides an RPC-based distributed autograd framework that can be used for applications such as model parallel training. In short, applications may send and receive gradient recording tensors over RPC. In the forward pass, we record when gradient recording tensors are sent over RPC and during the backward pass we use this information to perform a distributed backward pass using RPC. For more details see &lt;a href=&quot;rpc/distributed_autograd#distributed-autograd-design&quot;&gt;Distributed Autograd Design&lt;/a&gt;.</source>
          <target state="translated">该模块提供了一个基于RPC的分布式autograd框架，该框架可用于模型并行训练等应用程序。简而言之，应用程序可以通过RPC发送和接收梯度记录张量。在前向传递中，我们记录何时通过RPC发送梯度记录张量，而在后向传递过程中，我们使用此信息使用RPC执行分布式后向传递。有关更多详细信息，请参见&lt;a href=&quot;rpc/distributed_autograd#distributed-autograd-design&quot;&gt;Distributed Autograd Design&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="87af39490036eebaa3381d1990a65c31f6408fae" translate="yes" xml:space="preserve">
          <source>This module returns a &lt;code&gt;NamedTuple&lt;/code&gt; with &lt;code&gt;output&lt;/code&gt; and &lt;code&gt;loss&lt;/code&gt; fields. See further documentation for details.</source>
          <target state="translated">此模块返回带有 &lt;code&gt;output&lt;/code&gt; 和 &lt;code&gt;loss&lt;/code&gt; 字段的 &lt;code&gt;NamedTuple&lt;/code&gt; 。有关详细信息，请参见其他文档。</target>
        </trans-unit>
        <trans-unit id="59e9905faed8adfff4eeb0ecdbe57c1cac83f3a4" translate="yes" xml:space="preserve">
          <source>This module supports &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat32&lt;/a&gt;.</source>
          <target state="translated">该模块支持&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat32&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c9c9e1a196eef3e1f967008237f4372d9edc34d7" translate="yes" xml:space="preserve">
          <source>This module works only with the multi-process, single-device usage of &lt;a href=&quot;#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt;&lt;/a&gt;, which means that a single process works on a single GPU.</source>
          <target state="translated">此模块仅适用于&lt;a href=&quot;#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt; &lt;/a&gt;的多进程单设备使用，这意味着单个进程可在单个GPU上运行。</target>
        </trans-unit>
        <trans-unit id="0f30baa501fa38b25a8509424e2193e61d72c032" translate="yes" xml:space="preserve">
          <source>This observer computes the quantization parameters based on the moving averages of minimums and maximums of the incoming tensors. The module records the average minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters.</source>
          <target state="translated">该观测器根据传入张力器的最小值和最大值的移动平均数来计算量化参数。该模块记录传入时子的平均最小值和最大值,并使用该统计量计算量化参数。</target>
        </trans-unit>
        <trans-unit id="29203fffadc612cba8aabcec105c43163d833d44" translate="yes" xml:space="preserve">
          <source>This observer uses the tensor min/max statistics to compute the per channel quantization parameters. The module records the running minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters.</source>
          <target state="translated">该观测器使用张量最小/最大统计来计算每个通道的量化参数。该模块记录传入张量的最小和最大运行值,并使用该统计值计算量化参数。</target>
        </trans-unit>
        <trans-unit id="b2adf96c5dd76cc8a637924002f78629974574c7" translate="yes" xml:space="preserve">
          <source>This observer uses the tensor min/max statistics to compute the quantization parameters. The module records the running minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters.</source>
          <target state="translated">该观测器使用张量最小/最大统计来计算量化参数。该模块记录传入张量的最小和最大运行值,并使用该统计量计算量化参数。</target>
        </trans-unit>
        <trans-unit id="31368b5a919564a12c569127df416d6acb1973be" translate="yes" xml:space="preserve">
          <source>This op should be disambiguated with &lt;a href=&quot;torch.logsumexp#torch.logsumexp&quot;&gt;&lt;code&gt;torch.logsumexp()&lt;/code&gt;&lt;/a&gt; which performs a reduction on a single tensor.</source>
          <target state="translated">这个操作应该与&lt;a href=&quot;torch.logsumexp#torch.logsumexp&quot;&gt; &lt;code&gt;torch.logsumexp()&lt;/code&gt; &lt;/a&gt;消除歧义，该方法在单个张量上执行归约。</target>
        </trans-unit>
        <trans-unit id="3256e874629b9e3bf7609aa4774907058a898427" translate="yes" xml:space="preserve">
          <source>This operation is not differentiable.</source>
          <target state="translated">这种操作是无法区分的。</target>
        </trans-unit>
        <trans-unit id="f253d72c955897e96cbe7e655ade3b1e375b9508" translate="yes" xml:space="preserve">
          <source>This operation is useful for explicit broadcasting by names (see examples).</source>
          <target state="translated">这个操作对于通过名字进行显式广播很有用(见例子)。</target>
        </trans-unit>
        <trans-unit id="be6c030e3433204ea07b32a8e6ce714fff330e3a" translate="yes" xml:space="preserve">
          <source>This operator supports &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat32&lt;/a&gt;.</source>
          <target state="translated">该运算符支持&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat32&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f6cbc4c392cdef9bca907c34e1833c252683a82b" translate="yes" xml:space="preserve">
          <source>This optimizer doesn&amp;rsquo;t support per-parameter options and parameter groups (there can be only one).</source>
          <target state="translated">该优化器不支持每个参数的选项和参数组（只能有一个）。</target>
        </trans-unit>
        <trans-unit id="aa1075ffa7fba27cc0d195af9a6f5444b94b97ce" translate="yes" xml:space="preserve">
          <source>This package adds support for CUDA tensor types, that implement the same function as CPU tensors, but they utilize GPUs for computation.</source>
          <target state="translated">这个软件包增加了对CUDA张量类型的支持,它们实现了与CPU张量相同的功能,但它们利用GPU进行计算。</target>
        </trans-unit>
        <trans-unit id="836145aa5caebff4eaffcf9dc94e2f473ff1df15" translate="yes" xml:space="preserve">
          <source>This package provides a &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; type that encapsulates an asynchronous execution and a set of utility functions to simplify operations on &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; objects. Currently, the &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; type is primarily used by the &lt;a href=&quot;rpc#distributed-rpc-framework&quot;&gt;Distributed RPC Framework&lt;/a&gt;.</source>
          <target state="translated">该程序包提供了一个&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;类型，该类型封装了异步执行和一组实用程序函数，以简化对&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;对象的操作。当前，&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;类型主要由&lt;a href=&quot;rpc#distributed-rpc-framework&quot;&gt;Distributed RPC Framework使用&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="510d5659f81fbb2c92add3848324ac3e769287d8" translate="yes" xml:space="preserve">
          <source>This requires &lt;code&gt;scipy&lt;/code&gt; to be installed</source>
          <target state="translated">这需要安装 &lt;code&gt;scipy&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="70b5dd9eee5d2e3ba91077407f335c67991b22b8" translate="yes" xml:space="preserve">
          <source>This scheduler is not chainable.</source>
          <target state="translated">这个调度器是不可连锁的。</target>
        </trans-unit>
        <trans-unit id="a42db487ec40ca84c9d3c3617737b87da6c0e14d" translate="yes" xml:space="preserve">
          <source>This section contains the higher level API for the autograd that builds on the basic API above and allows you to compute jacobians, hessians, etc.</source>
          <target state="translated">本节包含了更高层次的自变量API,它建立在上述基本API的基础上,允许你计算雅克比、赫斯等。</target>
        </trans-unit>
        <trans-unit id="7d1f42ea5265cdd17159cef860e2867af1a5fed2" translate="yes" xml:space="preserve">
          <source>This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can skip this section. There are two main changes to the TorchScript API with PyTorch 1.2.</source>
          <target state="translated">本节详细介绍了 PyTorch 1.2 中对 TorchScript 的修改。如果您是 TorchScript 的新手,可以跳过本节。PyTorch 1.2 中的 TorchScript API 有两个主要变化。</target>
        </trans-unit>
        <trans-unit id="65513dd85adae4947833e9b405731c9c92f7268c" translate="yes" xml:space="preserve">
          <source>This section provides a brief overview into how different sharing strategies work. Note that it applies only to CPU tensor - CUDA tensors will always use the CUDA API, as that&amp;rsquo;s the only way they can be shared.</source>
          <target state="translated">本节简要概述了不同的共享策略如何工作。请注意，它仅适用于CPU张量-CUDA张量将始终使用CUDA API，因为这是可以共享它们的唯一方法。</target>
        </trans-unit>
        <trans-unit id="26517401ee04a7507f48917c7c6d007aa588bc0d" translate="yes" xml:space="preserve">
          <source>This separate serialization means that you should take two steps to ensure you are compatible with Windows while using multi-process data loading:</source>
          <target state="translated">这种单独的序列化意味着你应该采取两个步骤来确保在使用多进程数据加载时与Windows兼容。</target>
        </trans-unit>
        <trans-unit id="4a73b78954115d8ec831d20a068a6d8ccc312011" translate="yes" xml:space="preserve">
          <source>This strategy will use file descriptors as shared memory handles. Whenever a storage is moved to shared memory, a file descriptor obtained from &lt;code&gt;shm_open&lt;/code&gt; is cached with the object, and when it&amp;rsquo;s going to be sent to other processes, the file descriptor will be transferred (e.g. via UNIX sockets) to it. The receiver will also cache the file descriptor and &lt;code&gt;mmap&lt;/code&gt; it, to obtain a shared view onto the storage data.</source>
          <target state="translated">此策略将使用文件描述符作为共享内存句柄。每当将存储移动到共享内存时，将从 &lt;code&gt;shm_open&lt;/code&gt; 获得的文件描述符都与该对象一起缓存，并且在将其发送到其他进程时，该文件描述符将（例如通过UNIX套接字）传输到该对象。接收器还将缓存文件描述符并对其进行 &lt;code&gt;mmap&lt;/code&gt; ，以获取存储数据上的共享视图。</target>
        </trans-unit>
        <trans-unit id="18d6cf184b4d322d9e59ed200a7c995c7651fa42" translate="yes" xml:space="preserve">
          <source>This strategy will use file names given to &lt;code&gt;shm_open&lt;/code&gt; to identify the shared memory regions. This has a benefit of not requiring the implementation to cache the file descriptors obtained from it, but at the same time is prone to shared memory leaks. The file can&amp;rsquo;t be deleted right after its creation, because other processes need to access it to open their views. If the processes fatally crash, or are killed, and don&amp;rsquo;t call the storage destructors, the files will remain in the system. This is very serious, because they keep using up the memory until the system is restarted, or they&amp;rsquo;re freed manually.</source>
          <target state="translated">该策略将使用赋予 &lt;code&gt;shm_open&lt;/code&gt; 的文件名来标识共享内存区域。这样做的好处是不需要实现缓存从中获取的文件描述符，但是同时容易发生共享内存泄漏。文件创建后无法立即删除，因为其他进程需要访问该文件才能打开其视图。如果进程致命崩溃或被杀死，并且不调用存储析构函数，则文件将保留在系统中。这是非常严重的，因为在系统重新启动之前，它们一直消耗着内存，或者手动释放了它们。</target>
        </trans-unit>
        <trans-unit id="792e85a6083fd7bff7900d359e6ad50e4d63f9a7" translate="yes" xml:space="preserve">
          <source>This subset is restricted:</source>
          <target state="translated">这个子集是有限制的。</target>
        </trans-unit>
        <trans-unit id="fabd02d487546b940bc53aa8b39e79347651d21b" translate="yes" xml:space="preserve">
          <source>This transform arises as an iterated sigmoid transform in a stick-breaking construction of the &lt;code&gt;Dirichlet&lt;/code&gt; distribution: the first logit is transformed via sigmoid to the first probability and the probability of everything else, and then the process recurses.</source>
          <target state="translated">这种变换以 &lt;code&gt;Dirichlet&lt;/code&gt; 分布的折断构造中的迭代S形变换形式出现：第一个logit通过S形变换成第一个概率和所有其他概率，然后过程重复进行。</target>
        </trans-unit>
        <trans-unit id="f610c707a33d251ea07e96805fc742b6f94fb773" translate="yes" xml:space="preserve">
          <source>This will call &lt;a href=&quot;optim#torch.optim.Optimizer.step&quot;&gt;&lt;code&gt;torch.optim.Optimizer.step()&lt;/code&gt;&lt;/a&gt; on each worker containing parameters to be optimized, and will block until all workers return. The provided &lt;code&gt;context_id&lt;/code&gt; will be used to retrieve the corresponding &lt;a href=&quot;#torch.distributed.autograd.context&quot;&gt;&lt;code&gt;context&lt;/code&gt;&lt;/a&gt; that contains the gradients that should be applied to the parameters.</source>
          <target state="translated">这将在每个包含要优化的参数的工作程序上调用&lt;a href=&quot;optim#torch.optim.Optimizer.step&quot;&gt; &lt;code&gt;torch.optim.Optimizer.step()&lt;/code&gt; &lt;/a&gt;，并将阻塞直到所有工作程序返回为止。提供的 &lt;code&gt;context_id&lt;/code&gt; 将用于检索包含应应用于参数的渐变的相应&lt;a href=&quot;#torch.distributed.autograd.context&quot;&gt; &lt;code&gt;context&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="71b21a25c294ca711bdf2a3235c7d1f311e30f3a" translate="yes" xml:space="preserve">
          <source>This will mark outputs as not requiring gradients, increasing the efficiency of backward computation. You still need to accept a gradient for each output in &lt;code&gt;backward()&lt;/code&gt;, but it&amp;rsquo;s always going to be a zero tensor with the same shape as the shape of a corresponding output.</source>
          <target state="translated">这会将输出标记为不需要渐变，从而提高了向后计算的效率。您仍然需要在 &lt;code&gt;backward()&lt;/code&gt; 为每个输出接受一个渐变，但是它始终是零张量，其形状与相应输出的形状相同。</target>
        </trans-unit>
        <trans-unit id="c51f7b72279e26fd7cf66d9d61e7f7204bf3b26a" translate="yes" xml:space="preserve">
          <source>Threshold</source>
          <target state="translated">Threshold</target>
        </trans-unit>
        <trans-unit id="4c8543e85c70d9042806658de48a8eae05e8c630" translate="yes" xml:space="preserve">
          <source>Threshold is defined as:</source>
          <target state="translated">阈值定义为:</target>
        </trans-unit>
        <trans-unit id="a2ed3cfe5a92d0e9667b7a33a4666b01b859c7a8" translate="yes" xml:space="preserve">
          <source>Thresholds each element of the input Tensor.</source>
          <target state="translated">输入Tensor的每个元素的阈值。</target>
        </trans-unit>
        <trans-unit id="880f2f41d4783f36e126ec98db6135c252954795" translate="yes" xml:space="preserve">
          <source>To achieve this, developers need to touch the source code of PyTorch. Please follow the &lt;a href=&quot;https://github.com/pytorch/pytorch#from-source&quot;&gt;instructions&lt;/a&gt; for installing PyTorch from source. If the wanted operator is standardized in ONNX, it should be easy to add support for exporting such operator (adding a symbolic function for the operator). To confirm whether the operator is standardized or not, please check the &lt;a href=&quot;https://github.com/onnx/onnx/blob/master/docs/Operators.md&quot;&gt;ONNX operator list&lt;/a&gt;.</source>
          <target state="translated">为此，开发人员需要触摸PyTorch的源代码。请按照&lt;a href=&quot;https://github.com/pytorch/pytorch#from-source&quot;&gt;说明&lt;/a&gt;从源代码安装PyTorch。如果在ONNX中对所需的运算符进行了标准化，则应该很容易添加对导出此类运算符的支持（为该运算符添加符号功能）。要确认操作员是否标准化，请检查&lt;a href=&quot;https://github.com/onnx/onnx/blob/master/docs/Operators.md&quot;&gt;ONNX操作员列表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b5aa3a35df66cb08f05248ae2964bf5546e98afe" translate="yes" xml:space="preserve">
          <source>To align a tensor to a specific order, use &lt;a href=&quot;#torch.Tensor.align_to&quot;&gt;&lt;code&gt;align_to()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">要将张量对齐到特定顺序，请使用&lt;a href=&quot;#torch.Tensor.align_to&quot;&gt; &lt;code&gt;align_to()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="42a1cb8b698578c9fe48bbb02d735034e28323f6" translate="yes" xml:space="preserve">
          <source>To avoid exporting a variable scalar tensor as a fixed value constant as part of the ONNX model, please avoid use of &lt;code&gt;torch.Tensor.item()&lt;/code&gt;. Torch supports implicit cast of single-element tensors to numbers. E.g.:</source>
          <target state="translated">为避免将可变标量张量作为固定值常量导出为ONNX模型的一部分，请避免使用 &lt;code&gt;torch.Tensor.item()&lt;/code&gt; 。火炬支持将单元素张量隐式转换为数字。例如：</target>
        </trans-unit>
        <trans-unit id="e33cac23c601d0b5ef35b2617bd1e0b84d5ac6c7" translate="yes" xml:space="preserve">
          <source>To be able to save a module, it must not make any calls to native Python functions. This means that all submodules must be subclasses of &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; as well.</source>
          <target state="translated">为了能够保存模块，它不能对本地Python函数进行任何调用。这意味着所有子模块也必须是&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 的&lt;/a&gt;子类。</target>
        </trans-unit>
        <trans-unit id="517547cd8d7cdf6793257301cea557fd580f4509" translate="yes" xml:space="preserve">
          <source>To change an existing tensor&amp;rsquo;s &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; and/or &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, consider using &lt;a href=&quot;#torch.Tensor.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt; method on the tensor.</source>
          <target state="translated">要更改现有张量的&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;和/或&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，请考虑在张量上使用&lt;a href=&quot;#torch.Tensor.to&quot;&gt; &lt;code&gt;to()&lt;/code&gt; &lt;/a&gt;方法。</target>
        </trans-unit>
        <trans-unit id="cccb194237ee7a6be8a8fca8580f1ea27dde7026" translate="yes" xml:space="preserve">
          <source>To compile a method other than &lt;code&gt;forward&lt;/code&gt; (and recursively compile anything it calls), add the &lt;a href=&quot;../jit#torch.jit.export&quot;&gt;&lt;code&gt;@torch.jit.export&lt;/code&gt;&lt;/a&gt; decorator to the method. To opt out of compilation use &lt;a href=&quot;torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;@torch.jit.unused&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">要编译除 &lt;code&gt;forward&lt;/code&gt; 以外的方法（并递归编译它调用的任何内容），请在该方法中添加&lt;a href=&quot;../jit#torch.jit.export&quot;&gt; &lt;code&gt;@torch.jit.export&lt;/code&gt; &lt;/a&gt;装饰器。要选择退出编译，请使用&lt;a href=&quot;torch.jit.ignore#torch.jit.ignore&quot;&gt; &lt;code&gt;@torch.jit.ignore&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;torch.jit.unused#torch.jit.unused&quot;&gt; &lt;code&gt;@torch.jit.unused&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="13132861c718e28cce4e074280b9a030df11d21a" translate="yes" xml:space="preserve">
          <source>To compile a method other than &lt;code&gt;forward&lt;/code&gt; that is not called from &lt;code&gt;forward&lt;/code&gt;, add &lt;code&gt;@torch.jit.export&lt;/code&gt;.</source>
          <target state="translated">要编译比其他的方法 &lt;code&gt;forward&lt;/code&gt; 不是从所谓的 &lt;code&gt;forward&lt;/code&gt; ，加 &lt;code&gt;@torch.jit.export&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1f8e9d3b1e59225987eeef2681c83b1bcdde57d0" translate="yes" xml:space="preserve">
          <source>To compile the sources, the default system compiler (&lt;code&gt;c++&lt;/code&gt;) is used, which can be overridden by setting the &lt;code&gt;CXX&lt;/code&gt; environment variable. To pass additional arguments to the compilation process, &lt;code&gt;extra_cflags&lt;/code&gt; or &lt;code&gt;extra_ldflags&lt;/code&gt; can be provided. For example, to compile your extension with optimizations, pass &lt;code&gt;extra_cflags=['-O3']&lt;/code&gt;. You can also use &lt;code&gt;extra_cflags&lt;/code&gt; to pass further include directories.</source>
          <target state="translated">要编译源代码，请使用默认的系统编译器（ &lt;code&gt;c++&lt;/code&gt; ），可以通过设置 &lt;code&gt;CXX&lt;/code&gt; 环境变量来覆盖它。要将其他参数传递给编译过程，可以提供 &lt;code&gt;extra_cflags&lt;/code&gt; 或 &lt;code&gt;extra_ldflags&lt;/code&gt; 。例如，要使用优化功能编译扩展，请传递 &lt;code&gt;extra_cflags=['-O3']&lt;/code&gt; 。您还可以使用 &lt;code&gt;extra_cflags&lt;/code&gt; 传递进一步的包含目录。</target>
        </trans-unit>
        <trans-unit id="e66cd2fec20ece4ce742fe906879dd31b4bc3e7a" translate="yes" xml:space="preserve">
          <source>To compute log-probabilities for all classes, the &lt;code&gt;log_prob&lt;/code&gt; method can be used.</source>
          <target state="translated">要计算所有类的对数概率，可以使用 &lt;code&gt;log_prob&lt;/code&gt; 方法。</target>
        </trans-unit>
        <trans-unit id="77b8f89ffdd6b5d01dd6f264735e5d9852b97a53" translate="yes" xml:space="preserve">
          <source>To construct an &lt;a href=&quot;#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer&lt;/code&gt;&lt;/a&gt; you have to give it an iterable containing the parameters (all should be &lt;code&gt;Variable&lt;/code&gt; s) to optimize. Then, you can specify optimizer-specific options such as the learning rate, weight decay, etc.</source>
          <target state="translated">要构建一个&lt;a href=&quot;#torch.optim.Optimizer&quot;&gt; &lt;code&gt;Optimizer&lt;/code&gt; &lt;/a&gt;您必须给它提供一个包含参数的可迭代器（所有参数都应该是 &lt;code&gt;Variable&lt;/code&gt; ）以进行优化。然后，您可以指定特定于优化程序的选项，例如学习率，权重衰减等。</target>
        </trans-unit>
        <trans-unit id="d8b9882386102437caf895d70f81d6894ddf1097" translate="yes" xml:space="preserve">
          <source>To counter the problem of shared memory file leaks, &lt;a href=&quot;#module-torch.multiprocessing&quot;&gt;&lt;code&gt;torch.multiprocessing&lt;/code&gt;&lt;/a&gt; will spawn a daemon named &lt;code&gt;torch_shm_manager&lt;/code&gt; that will isolate itself from the current process group, and will keep track of all shared memory allocations. Once all processes connected to it exit, it will wait a moment to ensure there will be no new connections, and will iterate over all shared memory files allocated by the group. If it finds that any of them still exist, they will be deallocated. We&amp;rsquo;ve tested this method and it proved to be robust to various failures. Still, if your system has high enough limits, and &lt;code&gt;file_descriptor&lt;/code&gt; is a supported strategy, we do not recommend switching to this one.</source>
          <target state="translated">为了解决共享内存文件泄漏的问题，&lt;a href=&quot;#module-torch.multiprocessing&quot;&gt; &lt;code&gt;torch.multiprocessing&lt;/code&gt; &lt;/a&gt;将产生一个名为 &lt;code&gt;torch_shm_manager&lt;/code&gt; 的守护程序，该守护程序会将自己与当前进程组隔离开来，并将跟踪所有共享内存分配。一旦连接到它的所有进程退出，它将等待片刻以确保没有新的连接，并将遍历该组分配的所有共享内存文件。如果发现其中任何一个仍然存在，它们将被释放。我们已经测试了这种方法，并证明了它对各种故障的抵抗能力。不过，如果您的系统有足够高的限制，并且 &lt;code&gt;file_descriptor&lt;/code&gt; 是受支持的策略，我们不建议您切换到该策略。</target>
        </trans-unit>
        <trans-unit id="bcee88acc8b939fa9c28961779b7b64da43214ae" translate="yes" xml:space="preserve">
          <source>To create a tensor with pre-existing data, use &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">要使用预先存在的数据创建张量，请使用&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;torch.tensor()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="427cce7803261872f64a384400396e0d1af0bda9" translate="yes" xml:space="preserve">
          <source>To create a tensor with similar type but different size as another tensor, use &lt;code&gt;tensor.new_*&lt;/code&gt; creation ops.</source>
          <target state="translated">要创建与其他张量具有相似类型但大小不同的张量，请使用 &lt;code&gt;tensor.new_*&lt;/code&gt; creation ops。</target>
        </trans-unit>
        <trans-unit id="ed5a59600ac4cfd9c95f09892fb740465f6d0959" translate="yes" xml:space="preserve">
          <source>To create a tensor with specific size, use &lt;code&gt;torch.*&lt;/code&gt; tensor creation ops (see &lt;a href=&quot;torch#tensor-creation-ops&quot;&gt;Creation Ops&lt;/a&gt;).</source>
          <target state="translated">要创建具有特定大小的张量，请使用 &lt;code&gt;torch.*&lt;/code&gt; 张量创建操作（请参阅&lt;a href=&quot;torch#tensor-creation-ops&quot;&gt;创建操作&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="a84b4146d0aefbfce9733ab7943da8a8972fc9bd" translate="yes" xml:space="preserve">
          <source>To create a tensor with the same size (and similar types) as another tensor, use &lt;code&gt;torch.*_like&lt;/code&gt; tensor creation ops (see &lt;a href=&quot;torch#tensor-creation-ops&quot;&gt;Creation Ops&lt;/a&gt;).</source>
          <target state="translated">要创建与另一个张量具有相同大小（和相似类型）的张量，请使用 &lt;code&gt;torch.*_like&lt;/code&gt; 张量创建操作（请参见&lt;a href=&quot;torch#tensor-creation-ops&quot;&gt;Creation Ops&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="e323c9fb04b24bbe21e136c6130c8b1036dfb2e1" translate="yes" xml:space="preserve">
          <source>To decide which (CPU-only-mode or CUDA-mode) autograd profiler output to look at, you should first check if your script is CPU-bound (&amp;ldquo;CPU total time is much greater than CUDA total time&amp;rdquo;). If it is CPU-bound, looking at the results of the CPU-mode autograd profiler will help. If on the other hand your script spends most of its time executing on the GPU, then it makes sense to start looking for responsible CUDA operators in the output of the CUDA-mode autograd profiler.</source>
          <target state="translated">要确定要查看哪个（仅CPU模式或CUDA模式）autograd profiler输出，您应该首先检查脚本是否受CPU限制（&amp;ldquo; CPU总时间远大于CUDA总时间&amp;rdquo;）。如果它是CPU绑定的，则查看CPU模式的autograd profiler的结果将有所帮助。另一方面，如果您的脚本将其大部分时间都花在GPU上执行，则有必要在CUDA-mode autograd profiler的输出中开始寻找负责任的CUDA运算符。</target>
        </trans-unit>
        <trans-unit id="1d6487001340d96dfbd24e0dfe67d91d448bd378" translate="yes" xml:space="preserve">
          <source>To enable &lt;code&gt;backend == Backend.MPI&lt;/code&gt;, PyTorch needs to be built from source on a system that supports MPI.</source>
          <target state="translated">要启用 &lt;code&gt;backend == Backend.MPI&lt;/code&gt; ，需要在支持MPI的系统上从源代码构建PyTorch。</target>
        </trans-unit>
        <trans-unit id="928a8a1dba70cf38d7b64d41e9f2de79497ca1b2" translate="yes" xml:space="preserve">
          <source>To enable asynchronous execution, applications must pass the function object returned by this decorator to RPC APIs. If RPC detected attributes installed by this decorator, it knows that this function returns a &lt;code&gt;Future&lt;/code&gt; object and will handle that accordingly. However, this does not mean this decorator has to be outmost one when defining a function. For example, when combined with &lt;code&gt;@staticmethod&lt;/code&gt; or &lt;code&gt;@classmethod&lt;/code&gt;, &lt;code&gt;@rpc.functions.async_execution&lt;/code&gt; needs to be the inner decorator to allow the target function be recognized as a static or class function. This target function can still execute asynchronously because, when accessed, the static or class method preserves attributes installed by &lt;code&gt;@rpc.functions.async_execution&lt;/code&gt;.</source>
          <target state="translated">要启用异步执行，应用程序必须将此装饰器返回的功能对象传递给RPC API。如果RPC检测到此装饰器安装的属性，则它将知道此函数返回 &lt;code&gt;Future&lt;/code&gt; 对象，并将对此进行相应处理。但是，这并不意味着在定义一个函数时，此修饰符必须是最外层的。例如，当与 &lt;code&gt;@staticmethod&lt;/code&gt; 或 &lt;code&gt;@classmethod&lt;/code&gt; 结合使用时， &lt;code&gt;@rpc.functions.async_execution&lt;/code&gt; 必须是内部修饰符，才能将目标函数识别为静态或类函数。该目标函数仍然可以异步执行，因为在访问时，静态方法或类方法会保留 &lt;code&gt;@rpc.functions.async_execution&lt;/code&gt; 安装的属性。。</target>
        </trans-unit>
        <trans-unit id="16234789078f98ba40aad60005ffa95f2e9e8ac6" translate="yes" xml:space="preserve">
          <source>To ensure that the correct number of threads is used, set_num_threads must be called before running eager, JIT or autograd code.</source>
          <target state="translated">为了确保使用正确的线程数,在运行eager、JIT或autograd代码之前必须调用set_num_threads。</target>
        </trans-unit>
        <trans-unit id="2cd4366390e742467d09cd376578959df8585e90" translate="yes" xml:space="preserve">
          <source>To export a raw ir.</source>
          <target state="translated">要导出一个原始虹膜。</target>
        </trans-unit>
        <trans-unit id="13a45cf8b5a671e88848c78052e09b8b9f6c109f" translate="yes" xml:space="preserve">
          <source>To fallback on unsupported ATen operators in ONNX. Supported operators are exported to ONNX regularly. In the following example, aten::triu is not supported in ONNX. Exporter falls back on this operator.</source>
          <target state="translated">在ONNX中回退不支持的ATen操作员。支持的运算符会定期输出到 ONNX 中。在以下示例中,ONNX 不支持 aten::triu。出口商将使用该操作符。</target>
        </trans-unit>
        <trans-unit id="64ba89c98e2ef72ba75fa028267bbaa3251bdd0e" translate="yes" xml:space="preserve">
          <source>To find out if a &lt;a href=&quot;#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; is a complex data type, the property &lt;a href=&quot;generated/torch.is_complex#torch.is_complex&quot;&gt;&lt;code&gt;is_complex&lt;/code&gt;&lt;/a&gt; can be used, which returns &lt;code&gt;True&lt;/code&gt; if the data type is a complex data type.</source>
          <target state="translated">要确定&lt;a href=&quot;#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;是否为复杂数据类型，可以使用&lt;a href=&quot;generated/torch.is_complex#torch.is_complex&quot;&gt; &lt;code&gt;is_complex&lt;/code&gt; &lt;/a&gt;属性，如果数据类型为复杂数据类型，则该属性返回 &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4bde254844ec10d73414a4f9097cbf8e8d5d1c09" translate="yes" xml:space="preserve">
          <source>To find out if a &lt;a href=&quot;#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; is a floating point data type, the property &lt;a href=&quot;generated/torch.is_floating_point#torch.is_floating_point&quot;&gt;&lt;code&gt;is_floating_point&lt;/code&gt;&lt;/a&gt; can be used, which returns &lt;code&gt;True&lt;/code&gt; if the data type is a floating point data type.</source>
          <target state="translated">要确定&lt;a href=&quot;#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;是否为浮点数据类型，可以使用&lt;a href=&quot;generated/torch.is_floating_point#torch.is_floating_point&quot;&gt; &lt;code&gt;is_floating_point&lt;/code&gt; &lt;/a&gt;属性，如果数据类型为浮点数据类型，则该属性返回 &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="48e44e1c5bae8e339aa29cc00850c62cff2a0ea7" translate="yes" xml:space="preserve">
          <source>To help users explore without referring to documentation back and forth, we strongly recommend repo owners make function help messages clear and succinct. It&amp;rsquo;s also helpful to include a minimal working example.</source>
          <target state="translated">为了帮助用户探索而又不来回参考文档，我们强烈建议回购所有者使功能帮助消息清晰明了。包含一个最小的工作示例也很有帮助。</target>
        </trans-unit>
        <trans-unit id="e334bd6959cf3a682b73059d2817327b2e249b8f" translate="yes" xml:space="preserve">
          <source>To iterate over the full Cartesian product use &lt;code&gt;itertools.product(m.enumerate_support())&lt;/code&gt;.</source>
          <target state="translated">要遍历整个笛卡尔积，请使用 &lt;code&gt;itertools.product(m.enumerate_support())&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6e370e4d333aa52e5158136385c8ce683abfc7e1" translate="yes" xml:space="preserve">
          <source>To load an extension, a Ninja build file is emitted, which is used to compile the given sources into a dynamic library. This library is subsequently loaded into the current Python process as a module and returned from this function, ready for use.</source>
          <target state="translated">要加载一个扩展,需要发出一个Ninja build文件,用来将给定的源代码编译成一个动态库。这个库随后会作为一个模块加载到当前的Python进程中,并从这个函数中返回,随时可以使用。</target>
        </trans-unit>
        <trans-unit id="0f1500bbb514e4eeb3d360549b7085361d0903f1" translate="yes" xml:space="preserve">
          <source>To look up what optional arguments this module offers:</source>
          <target state="translated">查询本模块提供的可选参数。</target>
        </trans-unit>
        <trans-unit id="efe5a1ff1c27c51217ed9e88d6d14c167e44ae98" translate="yes" xml:space="preserve">
          <source>To make it easier to understand, here is a small example:</source>
          <target state="translated">为了便于理解,这里举个小例子。</target>
        </trans-unit>
        <trans-unit id="4861c71c5547ba6da8095cee191825540e015436" translate="yes" xml:space="preserve">
          <source>To make writing TorchScript more convenient, we allow script code to refer to Python values in the surrounding scope. For instance, any time there is a reference to &lt;code&gt;torch&lt;/code&gt;, the TorchScript compiler is actually resolving it to the &lt;code&gt;torch&lt;/code&gt; Python module when the function is declared. These Python values are not a first class part of TorchScript. Instead they are de-sugared at compile-time into the primitive types that TorchScript supports. This depends on the dynamic type of the Python valued referenced when compilation occurs. This section describes the rules that are used when accessing Python values in TorchScript.</source>
          <target state="translated">为了使编写TorchScript更加方便，我们允许脚本代码引用周围范围中的Python值。例如，任何时候只要有 &lt;code&gt;torch&lt;/code&gt; 的引用，在声明函数时，TorchScript编译器实际上就会将其解析为 &lt;code&gt;torch&lt;/code&gt; Python模块。这些Python值不是TorchScript的一流部分。而是在编译时将它们还原为TorchScript支持的原始类型。这取决于编译发生时引用的Python值的动态类型。本节介绍在TorchScript中访问Python值时使用的规则。</target>
        </trans-unit>
        <trans-unit id="56b4b291b8193f650ab440b4d0108041657026e3" translate="yes" xml:space="preserve">
          <source>To obtain repeatable results, reset the seed for the pseudorandom number generator</source>
          <target state="translated">为了获得可重复的结果,重新设置伪随机数发生器的种子。</target>
        </trans-unit>
        <trans-unit id="693cb0335aff5d84a8ad039de675ef1c71894064" translate="yes" xml:space="preserve">
          <source>To prevent underflow, &amp;ldquo;gradient scaling&amp;rdquo; multiplies the network&amp;rsquo;s loss(es) by a scale factor and invokes a backward pass on the scaled loss(es). Gradients flowing backward through the network are then scaled by the same factor. In other words, gradient values have a larger magnitude, so they don&amp;rsquo;t flush to zero.</source>
          <target state="translated">为了防止下溢，&amp;ldquo;梯度缩放&amp;rdquo;将网络的损耗乘以比例因子，并在缩放后的损耗上调用反向传递。然后，通过网络反向流动的渐变将按相同的因子进行缩放。换句话说，梯度值具有较大的幅度，因此它们不会刷新为零。</target>
        </trans-unit>
        <trans-unit id="cdaaaf6ab8e173c9d7ceb41b8dea6cb46e09c870" translate="yes" xml:space="preserve">
          <source>To print customized extra information, you should re-implement this method in your own modules. Both single-line and multi-line strings are acceptable.</source>
          <target state="translated">要打印自定义的额外信息,你应该在你自己的模块中重新实现这个方法。单行和多行字符串都可以接受。</target>
        </trans-unit>
        <trans-unit id="ff43c0b33f5574b95fded09d54e409788745cf85" translate="yes" xml:space="preserve">
          <source>To run the exported script with &lt;a href=&quot;https://caffe2.ai/&quot;&gt;caffe2&lt;/a&gt;, you will need to install &lt;code&gt;caffe2&lt;/code&gt;: If you don&amp;rsquo;t have one already, Please &lt;a href=&quot;https://caffe2.ai/docs/getting-started.html&quot;&gt;follow the install instructions&lt;/a&gt;.</source>
          <target state="translated">要使用&lt;a href=&quot;https://caffe2.ai/&quot;&gt;caffe2&lt;/a&gt;运行导出的脚本，您将需要安装 &lt;code&gt;caffe2&lt;/code&gt; ：如果尚未安装caffe2，请&lt;a href=&quot;https://caffe2.ai/docs/getting-started.html&quot;&gt;按照安装说明进行操作&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c62b3cc0b531750df7ee34e20beaf808665f78f8" translate="yes" xml:space="preserve">
          <source>To specify the scale, it takes either the &lt;code&gt;size&lt;/code&gt; or the &lt;code&gt;scale_factor&lt;/code&gt; as it&amp;rsquo;s constructor argument.</source>
          <target state="translated">要指定比例，它采用 &lt;code&gt;size&lt;/code&gt; 或 &lt;code&gt;scale_factor&lt;/code&gt; 作为其构造函数参数。</target>
        </trans-unit>
        <trans-unit id="8bc8fb9e3000235214e485d36fb9186012476b04" translate="yes" xml:space="preserve">
          <source>To stop the compiler from compiling a method, add &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;@torch.jit.unused&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;@ignore&lt;/code&gt; leaves the</source>
          <target state="translated">要停止编译器编译方法，请添加&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt; &lt;code&gt;@torch.jit.ignore&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt; &lt;code&gt;@torch.jit.unused&lt;/code&gt; &lt;/a&gt;。 &lt;code&gt;@ignore&lt;/code&gt; 离开</target>
        </trans-unit>
        <trans-unit id="83e075942db53d26dad4b0cea801b6df02d892d5" translate="yes" xml:space="preserve">
          <source>To take a batch diagonal, pass in dim1=-2, dim2=-1.</source>
          <target state="translated">要取批对角线,传入dim1=-2,dim2=-1。</target>
        </trans-unit>
        <trans-unit id="06d7e723aad8726de16a32b689408fd5f6a39bff" translate="yes" xml:space="preserve">
          <source>To trace a specific method on a module, see &lt;a href=&quot;generated/torch.jit.trace_module#torch.jit.trace_module&quot;&gt;&lt;code&gt;torch.jit.trace_module&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">要跟踪模块上的特定方法，请参见&lt;a href=&quot;generated/torch.jit.trace_module#torch.jit.trace_module&quot;&gt; &lt;code&gt;torch.jit.trace_module&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="513b8c269a49217eb8a34177b8e8cfe4d36acacc" translate="yes" xml:space="preserve">
          <source>To use &lt;a href=&quot;#module-torch.optim&quot;&gt;&lt;code&gt;torch.optim&lt;/code&gt;&lt;/a&gt; you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients.</source>
          <target state="translated">要使用&lt;a href=&quot;#module-torch.optim&quot;&gt; &lt;code&gt;torch.optim&lt;/code&gt; ,&lt;/a&gt;您必须构造一个优化器对象，该对象将保持当前状态并根据计算出的梯度更新参数。</target>
        </trans-unit>
        <trans-unit id="7cbbf69a127d5627b468752b233e45c932bef649" translate="yes" xml:space="preserve">
          <source>To use &lt;code&gt;DistributedDataParallel&lt;/code&gt; on a host with N GPUs, you should spawn up &lt;code&gt;N&lt;/code&gt; processes, ensuring that each process exclusively works on a single GPU from 0 to N-1. This can be done by either setting &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; for every process or by calling:</source>
          <target state="translated">要在具有N个GPU的主机上使用 &lt;code&gt;DistributedDataParallel&lt;/code&gt; ，应生成 &lt;code&gt;N&lt;/code&gt; 个进程，以确保每个进程在0到N-1的单个GPU上独占工作。可以通过为每个进程设置 &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; 或调用以下命令来完成此操作：</target>
        </trans-unit>
        <trans-unit id="55e1a9559362bb4b36c706d26afd5c7744bfa4b4" translate="yes" xml:space="preserve">
          <source>To use a &lt;code&gt;nn.ModuleList&lt;/code&gt; inside a compiled method, it must be marked constant by adding the name of the attribute to the &lt;code&gt;__constants__&lt;/code&gt; list for the type. For loops over a &lt;code&gt;nn.ModuleList&lt;/code&gt; will unroll the body of the loop at compile time, with each member of the constant module list.</source>
          <target state="translated">要在已编译方法中使用 &lt;code&gt;nn.ModuleList&lt;/code&gt; ，必须通过将属性名称添加到类型的 &lt;code&gt;__constants__&lt;/code&gt; 列表中将其标记为常量。对于 &lt;code&gt;nn.ModuleList&lt;/code&gt; 上的循环，将在编译时展开循环的主体，并使用常量模块列表的每个成员。</target>
        </trans-unit>
        <trans-unit id="527375a7ef1d0e262542dedd5c0253dc05250f0d" translate="yes" xml:space="preserve">
          <source>To use these functions the torch.fft module must be imported since its name conflicts with the &lt;a href=&quot;generated/torch.fft#torch.fft&quot;&gt;&lt;code&gt;torch.fft()&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">要使用这些功能，必须导入torch.fft模块，因为其名称与&lt;a href=&quot;generated/torch.fft#torch.fft&quot;&gt; &lt;code&gt;torch.fft()&lt;/code&gt; &lt;/a&gt;函数冲突。</target>
        </trans-unit>
        <trans-unit id="43427ba5c0a00d9ec53c4149e3f5de362381fec9" translate="yes" xml:space="preserve">
          <source>To use this to enable training with uneven inputs across processes, simply wrap this context manager around your training loop. No further modifications to the model or data loading is required.</source>
          <target state="translated">要使用此功能来实现跨流程的不均匀输入的培训,只需将此上下文管理器围绕您的培训循环。无需进一步修改模型或数据加载。</target>
        </trans-unit>
        <trans-unit id="6239832323d9bb66e30c43f099010c4cf674fbce" translate="yes" xml:space="preserve">
          <source>To utilize &lt;em&gt;script-based&lt;/em&gt; exporter for capturing the dynamic loop, we can write the loop in script, and call it from the regular nn.Module:</source>
          <target state="translated">为了利用&lt;em&gt;基于脚本的&lt;/em&gt;导出器捕获动态循环，我们可以在脚本中编写循环，然后从常规nn.Module中调用它：</target>
        </trans-unit>
        <trans-unit id="111ccaae56ca75ec4b6793420aa1331efeccd7da" translate="yes" xml:space="preserve">
          <source>Top-1 error</source>
          <target state="translated">前1名错误</target>
        </trans-unit>
        <trans-unit id="f1240994c38def01302ee353c1f3e6ab783c6922" translate="yes" xml:space="preserve">
          <source>Top-5 error</source>
          <target state="translated">5大错误</target>
        </trans-unit>
        <trans-unit id="ce0f1f9bf9ba00bef8a66791462d63e5a977f58e" translate="yes" xml:space="preserve">
          <source>Top-level quantization APIs</source>
          <target state="translated">顶层量化API</target>
        </trans-unit>
        <trans-unit id="ecebe7e89f3537ec9d48a23fefb140aef1ac7e73" translate="yes" xml:space="preserve">
          <source>Torch defines 10 tensor types with CPU and GPU variants which are as follows:</source>
          <target state="translated">Torch定义了10种张量类型,有CPU和GPU变体,具体如下。</target>
        </trans-unit>
        <trans-unit id="2270c240add89c3f53429a527826adf7f8c68848" translate="yes" xml:space="preserve">
          <source>Torch hub works by importing the package as if it was installed. There&amp;rsquo;re some side effects introduced by importing in Python. For example, you can see new items in Python caches &lt;code&gt;sys.modules&lt;/code&gt; and &lt;code&gt;sys.path_importer_cache&lt;/code&gt; which is normal Python behavior.</source>
          <target state="translated">Torch集线器通过导入软件包来工作，就像安装软件包一样。在Python中导入会带来一些副作用。例如，您可以在Python缓存 &lt;code&gt;sys.modules&lt;/code&gt; 和 &lt;code&gt;sys.path_importer_cache&lt;/code&gt; 中看到新项目，这是正常的Python行为。</target>
        </trans-unit>
        <trans-unit id="e678d1ba0a8c71917974dd6b809d475b07d566ed" translate="yes" xml:space="preserve">
          <source>Torch mobile supports &lt;code&gt;torch.mobile_optimizer.optimize_for_mobile&lt;/code&gt; utility to run a list of optimization pass with modules in eval mode. The method takes the following parameters: a torch.jit.ScriptModule object, a blacklisting optimization set and a preserved method list</source>
          <target state="translated">Torch Mobile支持 &lt;code&gt;torch.mobile_optimizer.optimize_for_mobile&lt;/code&gt; 实用程序，以在eval模式下运行带有模块的优化过程列表。该方法具有以下参数：torch.jit.ScriptModule对象，列入黑名单的优化集和保留的方法列表</target>
        </trans-unit>
        <trans-unit id="03340697e5da4f35bf9335b934c01e6bb269d07d" translate="yes" xml:space="preserve">
          <source>Torch supports sparse tensors in COO(rdinate) format, which can efficiently store and process tensors for which the majority of elements are zeros.</source>
          <target state="translated">Torch支持COO(rdinate)格式的稀疏时序,它可以有效地存储和处理大部分元素为零的时序。</target>
        </trans-unit>
        <trans-unit id="efa8e2bf58145beaa70cc1139b800b0cc73441ae" translate="yes" xml:space="preserve">
          <source>TorchElastic</source>
          <target state="translated">TorchElastic</target>
        </trans-unit>
        <trans-unit id="3b90040dd3c7ea550e3ae7ebb31cbbf38c50d775" translate="yes" xml:space="preserve">
          <source>TorchScript</source>
          <target state="translated">TorchScript</target>
        </trans-unit>
        <trans-unit id="604c8e5563e16356b9e1a864727a3495aaa4b8f6" translate="yes" xml:space="preserve">
          <source>TorchScript Classes</source>
          <target state="translated">TorchScript类</target>
        </trans-unit>
        <trans-unit id="5d73d728706f6b5bfb8bc6488f8b896532317b47" translate="yes" xml:space="preserve">
          <source>TorchScript Enums</source>
          <target state="translated">TorchScript Enums</target>
        </trans-unit>
        <trans-unit id="2d3d498afcd6dbfb2767a5e73bfdf3c641826801" translate="yes" xml:space="preserve">
          <source>TorchScript Language</source>
          <target state="translated">TorchScript语言</target>
        </trans-unit>
        <trans-unit id="655dca0ad6a50c42b950785617112aa26c2b7ea8" translate="yes" xml:space="preserve">
          <source>TorchScript Language Reference</source>
          <target state="translated">TorchScript语言参考</target>
        </trans-unit>
        <trans-unit id="4ca55dbce27b090f25e1beef5f42bc0b74a3e196" translate="yes" xml:space="preserve">
          <source>TorchScript Unsupported Pytorch Constructs</source>
          <target state="translated">TorchScript 不支持的 Pytorch 构造。</target>
        </trans-unit>
        <trans-unit id="f37751da08a275fc84f6719af858bb6fca4efcaa" translate="yes" xml:space="preserve">
          <source>TorchScript also has a representation at a lower level than the code pretty- printer, in the form of IR graphs.</source>
          <target state="translated">TorchScript还有一个比代码pretty-printer更低级的表现形式,即IR图。</target>
        </trans-unit>
        <trans-unit id="1f6a6dd855f78002eaa186408d37b5a14d38fb6e" translate="yes" xml:space="preserve">
          <source>TorchScript also provides a way to use constants that are defined in Python. These can be used to hard-code hyper-parameters into the function, or to define universal constants. There are two ways of specifying that a Python value should be treated as a constant.</source>
          <target state="translated">TorchScript 还提供了一种使用 Python 中定义的常量的方法。这些常量可以用来将超参数硬编码到函数中,或者定义通用常量。有两种方法可以指定一个Python值应该被视为常量。</target>
        </trans-unit>
        <trans-unit id="252b708f15ebb50ba55ac0b5f321607abb84f702" translate="yes" xml:space="preserve">
          <source>TorchScript can call Python functions. This functionality is very useful when incrementally converting a model to TorchScript. The model can be moved function-by-function to TorchScript, leaving calls to Python functions in place. This way you can incrementally check the correctness of the model as you go.</source>
          <target state="translated">TorchScript 可以调用 Python 函数。这个功能在将模型逐步转换为 TorchScript 时非常有用。模型可以被逐个函数移动到 TorchScript 中,留下对 Python 函数的调用。这样您就可以边走边逐步检查模型的正确性。</target>
        </trans-unit>
        <trans-unit id="0e634a60c8e32dbe73734d8f74e5fc62a8bbd892" translate="yes" xml:space="preserve">
          <source>TorchScript can lookup attributes on modules. &lt;code&gt;Builtin functions&lt;/code&gt; like &lt;code&gt;torch.add&lt;/code&gt; are accessed this way. This allows TorchScript to call functions defined in other modules.</source>
          <target state="translated">TorchScript可以在模块上查找属性。像 &lt;code&gt;torch.add&lt;/code&gt; 这样的 &lt;code&gt;Builtin functions&lt;/code&gt; 可以通过这种方式访问​​。这使TorchScript可以调用其他模块中定义的函数。</target>
        </trans-unit>
        <trans-unit id="05a14206c4e373e5e12c57e024877cf642631ecf" translate="yes" xml:space="preserve">
          <source>TorchScript class support is experimental. Currently it is best suited for simple record-like types (think a &lt;code&gt;NamedTuple&lt;/code&gt; with methods attached).</source>
          <target state="translated">TorchScript类支持是实验性的。当前，它最适合简单的类似记录的类型（想一想带有附加方法的 &lt;code&gt;NamedTuple&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="40d12a53eedc122f7c1c26cc26562fe87abc6002" translate="yes" xml:space="preserve">
          <source>TorchScript classes are statically typed. Members can only be declared by assigning to self in the &lt;code&gt;__init__()&lt;/code&gt; method.</source>
          <target state="translated">TorchScript类是静态类型的。成员只能通过在 &lt;code&gt;__init__()&lt;/code&gt; 方法中分配给self来声明。</target>
        </trans-unit>
        <trans-unit id="6fd4fa394dbd8f52548eb83a0ab865caf3d46d44" translate="yes" xml:space="preserve">
          <source>TorchScript does not support &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#bytes&quot;&gt;&lt;code&gt;bytes&lt;/code&gt;&lt;/a&gt; so this type is not used</source>
          <target state="translated">TorchScript不支持&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#bytes&quot;&gt; &lt;code&gt;bytes&lt;/code&gt; &lt;/a&gt;因此不使用此类型</target>
        </trans-unit>
        <trans-unit id="95d83676fd42ab283c45a040ec05adf9e17c4b2a" translate="yes" xml:space="preserve">
          <source>TorchScript does not support all features and types of the &lt;a href=&quot;https://docs.python.org/3/library/typing.html#module-typing&quot;&gt;&lt;code&gt;typing&lt;/code&gt;&lt;/a&gt; module. Some of these are more fundamental things that are unlikely to be added in the future while others may be added if there is enough user demand to make it a priority.</source>
          <target state="translated">TorchScript不支持&lt;a href=&quot;https://docs.python.org/3/library/typing.html#module-typing&quot;&gt; &lt;code&gt;typing&lt;/code&gt; &lt;/a&gt;模块的所有功能和类型。其中一些是最基本的东西，将来不太可能添加，而如果用户有足够的需求使其成为优先事项，则可以添加其他一些东西。</target>
        </trans-unit>
        <trans-unit id="155bc1507dbbed5e44c922d48bd933f969683779" translate="yes" xml:space="preserve">
          <source>TorchScript is a statically typed subset of Python that can either be written directly (using the &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;@torch.jit.script&lt;/code&gt;&lt;/a&gt; decorator) or generated automatically from Python code via tracing. When using tracing, code is automatically converted into this subset of Python by recording only the actual operators on tensors and simply executing and discarding the other surrounding Python code.</source>
          <target state="translated">TorchScript是Python的静态类型子集，可以直接编写（使用&lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;@torch.jit.script&lt;/code&gt; &lt;/a&gt;装饰器），也可以通过跟踪从Python代码自动生成。使用跟踪时，通过仅记录张量上的实际运算符并简单地执行和丢弃其他周围的Python代码，代码会自动转换为Python的此子集。</target>
        </trans-unit>
        <trans-unit id="6e3be4ae1ba105244947e696b16b923455648d05" translate="yes" xml:space="preserve">
          <source>TorchScript is a statically typed subset of Python, so many Python features apply directly to TorchScript. See the full &lt;a href=&quot;jit_language_reference#language-reference&quot;&gt;TorchScript Language Reference&lt;/a&gt; for details.</source>
          <target state="translated">TorchScript是Python的静态类型子集，因此许多Python功能直接应用于TorchScript。有关详细信息，请参见完整的《&lt;a href=&quot;jit_language_reference#language-reference&quot;&gt;TorchScript语言参考&lt;/a&gt;》。</target>
        </trans-unit>
        <trans-unit id="b80f73ada7844bf2ed31f70d01150d3e0f521094" translate="yes" xml:space="preserve">
          <source>TorchScript is a way to create serializable and optimizable models from PyTorch code. Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency.</source>
          <target state="translated">TorchScript是一种从PyTorch代码创建可序列化和可优化模型的方法。任何TorchScript程序都可以从Python进程中保存,并在没有Python依赖的进程中加载。</target>
        </trans-unit>
        <trans-unit id="f3730c4db0b9ee76825d3365cc7e6ee5d81c09f3" translate="yes" xml:space="preserve">
          <source>TorchScript provides a code pretty-printer for all &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; instances. This pretty-printer gives an interpretation of the script method&amp;rsquo;s code as valid Python syntax. For example:</source>
          <target state="translated">TorchScript为所有&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;实例提供了一个代码漂亮的打印机。这个漂亮的打印机将脚本方法的代码解释为有效的Python语法。例如：</target>
        </trans-unit>
        <trans-unit id="6f800d70869c5af16f03f352efad0babdc4a4cee" translate="yes" xml:space="preserve">
          <source>TorchScript support in RPC is a prototype feature and subject to change. Since v1.5.0, &lt;code&gt;torch.distributed.rpc&lt;/code&gt; supports calling TorchScript functions as RPC target functions, and this will help improve parallelism on the callee side as executing TorchScript functions does not require GIL.</source>
          <target state="translated">RPC中对TorchScript的支持是一项原型功能，并且可能会发生变化。从v1.5.0开始， &lt;code&gt;torch.distributed.rpc&lt;/code&gt; 支持将TorchScript函数作为RPC目标函数调用，这将有助于改善被调用方的并行性，因为执行TorchScript函数不需要GIL。</target>
        </trans-unit>
        <trans-unit id="7d483bee6192edebb2157f5cffc7ebe0cf7bf9b5" translate="yes" xml:space="preserve">
          <source>TorchScript supports a subset of Python&amp;rsquo;s variable resolution (i.e. scoping) rules. Local variables behave the same as in Python, except for the restriction that a variable must have the same type along all paths through a function. If a variable has a different type on different branches of an if statement, it is an error to use it after the end of the if statement.</source>
          <target state="translated">TorchScript支持Python的可变分辨率（即作用域）规则的子集。局部变量的行为与Python中的相同，不同之处在于，在通过函数的所有路径上，变量必须具有相同的类型。如果变量在if语句的不同分支上具有不同的类型，则在if语句结束后使用它是错误的。</target>
        </trans-unit>
        <trans-unit id="439e6a570c3e92811a193d2bb2eb0c532aac85c2" translate="yes" xml:space="preserve">
          <source>TorchScript supports a subset of the tensor and neural network functions that PyTorch provides. Most methods on Tensor as well as functions in the &lt;code&gt;torch&lt;/code&gt; namespace, all functions in &lt;code&gt;torch.nn.functional&lt;/code&gt; and most modules from &lt;code&gt;torch.nn&lt;/code&gt; are supported in TorchScript.</source>
          <target state="translated">TorchScript支持PyTorch提供的张量和神经网络功能的子集。Tensor上的大多数方法以及 &lt;code&gt;torch&lt;/code&gt; 命名空间中的函数， &lt;code&gt;torch.nn.functional&lt;/code&gt; 中的所有函数以及torch.nn中的大多数模块在 &lt;code&gt;torch.nn&lt;/code&gt; 中受支持。</target>
        </trans-unit>
        <trans-unit id="85815975862ed9b632ab9ab2cb6516181e624194" translate="yes" xml:space="preserve">
          <source>TorchScript supports the following types of statements:</source>
          <target state="translated">TorchScript支持以下类型的语句。</target>
        </trans-unit>
        <trans-unit id="237a371f4a7260a3005de6488e3d8470546b5ec9" translate="yes" xml:space="preserve">
          <source>TorchScript supports the use of most PyTorch functions and many Python built-ins. See &lt;a href=&quot;jit_builtin_functions#builtin-functions&quot;&gt;TorchScript Builtins&lt;/a&gt; for a full reference of supported functions.</source>
          <target state="translated">TorchScript支持大多数PyTorch函数和许多Python内置函数的使用。有关支持的功能的完整参考，请参见&lt;a href=&quot;jit_builtin_functions#builtin-functions&quot;&gt;TorchScript内置&lt;/a&gt;函数。</target>
        </trans-unit>
        <trans-unit id="f626090730ab6e08eee60582294fe0a9f90efe3d" translate="yes" xml:space="preserve">
          <source>TorchScript uses a static single assignment (SSA) intermediate representation (IR) to represent computation. The instructions in this format consist of ATen (the C++ backend of PyTorch) operators and other primitive operators, including control flow operators for loops and conditionals. As an example:</source>
          <target state="translated">TorchScript使用静态单一赋值(SSA)中间表示法(IR)来表示计算。这种格式的指令由 ATen(PyTorch 的 C++后端)运算符和其他基元运算符组成,包括循环和条件的控制流运算符。举个例子。</target>
        </trans-unit>
        <trans-unit id="ee07cfab05a06e606f9327817d635689c5cd9b5d" translate="yes" xml:space="preserve">
          <source>TorchScript will refine the type of a variable of type &lt;code&gt;Optional[T]&lt;/code&gt; when a comparison to &lt;code&gt;None&lt;/code&gt; is made inside the conditional of an if-statement or checked in an &lt;code&gt;assert&lt;/code&gt;. The compiler can reason about multiple &lt;code&gt;None&lt;/code&gt; checks that are combined with &lt;code&gt;and&lt;/code&gt;, &lt;code&gt;or&lt;/code&gt;, and &lt;code&gt;not&lt;/code&gt;. Refinement will also occur for else blocks of if-statements that are not explicitly written.</source>
          <target state="translated">在if语句的条件内或在 &lt;code&gt;assert&lt;/code&gt; 中检查与 &lt;code&gt;None&lt;/code&gt; 的比较时，TorchScript将优化 &lt;code&gt;Optional[T]&lt;/code&gt; 类型的变量的类型。编译器可以推断出与 &lt;code&gt;and&lt;/code&gt; ， &lt;code&gt;or&lt;/code&gt; 和 &lt;code&gt;not&lt;/code&gt; 相结合的多个 &lt;code&gt;None&lt;/code&gt; 检查。对于未明确编写的if语句的else块，也会进行优化。</target>
        </trans-unit>
        <trans-unit id="db3578de30ac281698832393e03259941ecc59a4" translate="yes" xml:space="preserve">
          <source>TorchServe</source>
          <target state="translated">TorchServe</target>
        </trans-unit>
        <trans-unit id="174786ece7d01b50c5a292bbe7c461a354fd217b" translate="yes" xml:space="preserve">
          <source>TorchVision support</source>
          <target state="translated">支持TorchVision</target>
        </trans-unit>
        <trans-unit id="eb01e02a87150ef514202bea3337f1bbd7e6a429" translate="yes" xml:space="preserve">
          <source>Total norm of the parameters (viewed as a single vector).</source>
          <target state="translated">参数的总规范(作为一个单一的向量来看)。</target>
        </trans-unit>
        <trans-unit id="117b4c950645374477e1f2b2a96517111745fe19" translate="yes" xml:space="preserve">
          <source>Trace a function and return an executable or &lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; that will be optimized using just-in-time compilation.</source>
          <target state="translated">跟踪一个函数并返回将使用即时编译进行优化的可执行文件或&lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4cae3f60263770c81b066cebd1a77d6ae0c2a925" translate="yes" xml:space="preserve">
          <source>Trace a function and return an executable or &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; that will be optimized using just-in-time compilation. Tracing is ideal for code that operates only on &lt;code&gt;Tensor&lt;/code&gt;s and lists, dictionaries, and tuples of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="translated">跟踪一个函数并返回将使用即时编译进行优化的可执行文件或&lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt;。跟踪是理想的才动作代码 &lt;code&gt;Tensor&lt;/code&gt; S和列表，字典和元组的 &lt;code&gt;Tensor&lt;/code&gt; 秒。</target>
        </trans-unit>
        <trans-unit id="20f26cd87e3024b30b8eeb8b74edbe9cdd81f4b6" translate="yes" xml:space="preserve">
          <source>Trace a module and return an executable &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; that will be optimized using just-in-time compilation.</source>
          <target state="translated">跟踪模块并返回可执行的&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;，该脚本将使用即时编译进行优化。</target>
        </trans-unit>
        <trans-unit id="3bad49a27d3b91711b9d48661ccd1bb2133d17d3" translate="yes" xml:space="preserve">
          <source>Trace a module and return an executable &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; that will be optimized using just-in-time compilation. When a module is passed to &lt;a href=&quot;torch.jit.trace#torch.jit.trace&quot;&gt;&lt;code&gt;torch.jit.trace&lt;/code&gt;&lt;/a&gt;, only the &lt;code&gt;forward&lt;/code&gt; method is run and traced. With &lt;code&gt;trace_module&lt;/code&gt;, you can specify a dictionary of method names to example inputs to trace (see the &lt;code&gt;inputs&lt;/code&gt;) argument below.</source>
          <target state="translated">跟踪模块并返回可执行的&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;，该脚本将使用即时编译进行优化。将模块传递到&lt;a href=&quot;torch.jit.trace#torch.jit.trace&quot;&gt; &lt;code&gt;torch.jit.trace&lt;/code&gt; 时&lt;/a&gt;，仅运行和跟踪 &lt;code&gt;forward&lt;/code&gt; 方法。使用 &lt;code&gt;trace_module&lt;/code&gt; ，您可以指定方法名称的字典，以作为示例输入来跟踪下面的参数（请参阅 &lt;code&gt;inputs&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="d93ef3f27cd83786d560cf0e7159be09c5658df2" translate="yes" xml:space="preserve">
          <source>Traced functions can call script functions. This is useful when a small part of a model requires some control-flow even though most of the model is just a feed-forward network. Control-flow inside of a script function called by a traced function is preserved correctly.</source>
          <target state="translated">跟踪函数可以调用脚本函数。当模型的一小部分需要一些控制流时,即使模型的大部分只是一个前馈网络,这也很有用。被跟踪函数调用的脚本函数内部的控制流会被正确地保留下来。</target>
        </trans-unit>
        <trans-unit id="0fce73bbb5357ac93c61680e5f58be84db277c7b" translate="yes" xml:space="preserve">
          <source>Tracer</source>
          <target state="translated">Tracer</target>
        </trans-unit>
        <trans-unit id="d09bb53da249750b0b3b27f27eabe9dbddadc0ed" translate="yes" xml:space="preserve">
          <source>Tracer Warnings</source>
          <target state="translated">示踪剂警告</target>
        </trans-unit>
        <trans-unit id="bf933c3083c5a6cb4cedac1b1e0c22d6553dab1d" translate="yes" xml:space="preserve">
          <source>Tracing Edge Cases</source>
          <target state="translated">追踪边缘案例</target>
        </trans-unit>
        <trans-unit id="c5153b07a6f011eb8b3585b8b94ddfea62a7a0ce" translate="yes" xml:space="preserve">
          <source>Tracing of control flow that is dependent on inputs (e.g. tensor shapes)</source>
          <target state="translated">追踪依赖于输入的控制流(如张量形状)。</target>
        </trans-unit>
        <trans-unit id="656eeb39a9810745d15b70b8f4cca3cf416cf8d6" translate="yes" xml:space="preserve">
          <source>Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment)</source>
          <target state="translated">追踪张量视图的原地操作(例如,在赋值的左侧进行索引)。</target>
        </trans-unit>
        <trans-unit id="e793ff03e25bf5dd4f85e642caecdeee487a3a73" translate="yes" xml:space="preserve">
          <source>Tracing only correctly records functions and modules which are not data dependent (e.g., do not have conditionals on data in tensors) and do not have any untracked external dependencies (e.g., perform input/output or access global variables). Tracing only records operations done when the given function is run on the given tensors. Therefore, the returned &lt;code&gt;ScriptModule&lt;/code&gt; will always run the same traced graph on any input. This has some important implications when your module is expected to run different sets of operations, depending on the input and/or the module state. For example,</source>
          <target state="translated">跟踪仅正确记录不依赖数据的功能和模块（例如，对张量中的数据没有条件）并且不包含任何未跟踪的外部依赖项（例如，执行输入/输出或访问全局变量）。跟踪仅记录在给定张量上运行给定函数时完成的操作。因此，返回的 &lt;code&gt;ScriptModule&lt;/code&gt; 将始终在任何输入上运行相同的跟踪图。当期望模块根据输入和/或模块状态运行不同的操作集时，这具有重要意义。例如，</target>
        </trans-unit>
        <trans-unit id="1289e51c253ed91b441a90b66b33a5a7cc2af8cf" translate="yes" xml:space="preserve">
          <source>Tracing vs Scripting</source>
          <target state="translated">追踪与脚本</target>
        </trans-unit>
        <trans-unit id="4de8ec680853c82acd4d7ddcd35ef7c092a558c3" translate="yes" xml:space="preserve">
          <source>Tracing will not record any control-flow like if-statements or loops. When this control-flow is constant across your module, this is fine and it often inlines the control-flow decisions. But sometimes the control-flow is actually part of the model itself. For instance, a recurrent network is a loop over the (possibly dynamic) length of an input sequence.</source>
          <target state="translated">追踪不会记录任何控制流,比如if语句或循环。当这个控制流在你的模块中是恒定的,这是很好的,它通常会内联控制流的决定。但有时控制流实际上是模型本身的一部分。例如,一个循环网络是对一个输入序列的(可能是动态的)长度进行循环。</target>
        </trans-unit>
        <trans-unit id="b6fe7f5e79177b05f6d251ecb9c162d45455045d" translate="yes" xml:space="preserve">
          <source>Training</source>
          <target state="translated">Training</target>
        </trans-unit>
        <trans-unit id="9799ca804afd728925d42f0fad8bc4ebafb48be1" translate="yes" xml:space="preserve">
          <source>Transform from unconstrained matrices to lower-triangular matrices with nonnegative diagonal entries.</source>
          <target state="translated">从无约束矩阵转化为具有非负对角线项的下三角矩阵。</target>
        </trans-unit>
        <trans-unit id="2028c39f00230fbfeeb2cd068176cf529f49e2ed" translate="yes" xml:space="preserve">
          <source>Transform from unconstrained space to the simplex of one additional dimension via a stick-breaking process.</source>
          <target state="translated">通过破棒过程,从无约束空间转化为一个额外维度的简单化空间。</target>
        </trans-unit>
        <trans-unit id="69c694e67b533e546676316ef1f032d5873aac31" translate="yes" xml:space="preserve">
          <source>Transform from unconstrained space to the simplex via</source>
          <target state="translated">从无约束空间到简单空间的转换,通过</target>
        </trans-unit>
        <trans-unit id="8e9519c4f24f7581be45723ce541214099b89154" translate="yes" xml:space="preserve">
          <source>Transform functor that applies a sequence of transforms &lt;code&gt;tseq&lt;/code&gt; component-wise to each submatrix at &lt;code&gt;dim&lt;/code&gt; in a way compatible with &lt;a href=&quot;generated/torch.stack#torch.stack&quot;&gt;&lt;code&gt;torch.stack()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">变换应用于变换的序列函子 &lt;code&gt;tseq&lt;/code&gt; 逐个分量的每个子矩阵在 &lt;code&gt;dim&lt;/code&gt; 的方式兼容&lt;a href=&quot;generated/torch.stack#torch.stack&quot;&gt; &lt;code&gt;torch.stack()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7f966e79d9dc111e8433e53a94b6d1fe7a4bd63c" translate="yes" xml:space="preserve">
          <source>Transform functor that applies a sequence of transforms &lt;code&gt;tseq&lt;/code&gt; component-wise to each submatrix at &lt;code&gt;dim&lt;/code&gt;, of length &lt;code&gt;lengths[dim]&lt;/code&gt;, in a way compatible with &lt;a href=&quot;generated/torch.cat#torch.cat&quot;&gt;&lt;code&gt;torch.cat()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">变换应用于变换的序列函子 &lt;code&gt;tseq&lt;/code&gt; 逐个分量的每个子矩阵在 &lt;code&gt;dim&lt;/code&gt; 的长度， &lt;code&gt;lengths[dim]&lt;/code&gt; ，在具有兼容的方式&lt;a href=&quot;generated/torch.cat#torch.cat&quot;&gt; &lt;code&gt;torch.cat()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bd1a4c11c8705b74a20ba32754ab9f1d32f26cf3" translate="yes" xml:space="preserve">
          <source>Transform via the mapping</source>
          <target state="translated">通过映射进行转换</target>
        </trans-unit>
        <trans-unit id="186888187095080b876d7340f9103c9cc0aaf2ee" translate="yes" xml:space="preserve">
          <source>Transform via the pointwise affine mapping</source>
          <target state="translated">通过点状非线性映射进行变换</target>
        </trans-unit>
        <trans-unit id="b14aa86e0c434d274e86855b383dde3e3e75a076" translate="yes" xml:space="preserve">
          <source>TransformedDistribution</source>
          <target state="translated">TransformedDistribution</target>
        </trans-unit>
        <trans-unit id="68c170c0011cf476eed353d994b12887940cfc96" translate="yes" xml:space="preserve">
          <source>Transformer</source>
          <target state="translated">Transformer</target>
        </trans-unit>
        <trans-unit id="6e42fdb55f8e197d60cafca548c1e82579acbea4" translate="yes" xml:space="preserve">
          <source>Transformer Layers</source>
          <target state="translated">变压器层</target>
        </trans-unit>
        <trans-unit id="ef303bb941bf717e2006e7273f0810b07b78b045" translate="yes" xml:space="preserve">
          <source>TransformerDecoder</source>
          <target state="translated">TransformerDecoder</target>
        </trans-unit>
        <trans-unit id="39490c0e215073daec405a4b72d513bc1f4fb82e" translate="yes" xml:space="preserve">
          <source>TransformerDecoder is a stack of N decoder layers</source>
          <target state="translated">TransformerDecoder是N个解码层的堆栈</target>
        </trans-unit>
        <trans-unit id="92f20fa7687824fdbb370a6b475f6eeb6f79194b" translate="yes" xml:space="preserve">
          <source>TransformerDecoderLayer</source>
          <target state="translated">TransformerDecoderLayer</target>
        </trans-unit>
        <trans-unit id="98ae4e9bf414c9fe8b37e6dbc99426a1c7335c2f" translate="yes" xml:space="preserve">
          <source>TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.</source>
          <target state="translated">TransformerDecoderLayer由自适应、多头适应和前馈网络组成。</target>
        </trans-unit>
        <trans-unit id="04a4a3c2fb795f7db70756477e2d518c4a892786" translate="yes" xml:space="preserve">
          <source>TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network. This standard decoder layer is based on the paper &amp;ldquo;Attention Is All You Need&amp;rdquo;. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000-6010. Users may modify or implement in a different way during application.</source>
          <target state="translated">TransformerDecoderLayer由自组织，多头组织和前馈网络组成。这个标准的解码器层基于论文&amp;ldquo;注意就是您所需要的&amp;rdquo;。Ashish Vaswani，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion Jones，Aidan N Gomez，Lukasz Kaiser和Illia Polosukhin。2017年。您只需要关注即可。《神经信息处理系统的发展》，第6000-6010页。用户可以在应用过程中以不同的方式修改或实现。</target>
        </trans-unit>
        <trans-unit id="32d7343edd3b94812b03b1cdf834b1b16cc2a3fc" translate="yes" xml:space="preserve">
          <source>TransformerEncoder</source>
          <target state="translated">TransformerEncoder</target>
        </trans-unit>
        <trans-unit id="933db464a961834a0fb72e3b98e0d537c401c215" translate="yes" xml:space="preserve">
          <source>TransformerEncoder is a stack of N encoder layers</source>
          <target state="translated">TransformerEncoder是一个由N个编码器层组成的堆栈。</target>
        </trans-unit>
        <trans-unit id="2a732f60462f98f99de0f8f387f8c71e6c32aba7" translate="yes" xml:space="preserve">
          <source>TransformerEncoderLayer</source>
          <target state="translated">TransformerEncoderLayer</target>
        </trans-unit>
        <trans-unit id="7b3ae5e9124dac923ef7ce7bbf1287aa019083f2" translate="yes" xml:space="preserve">
          <source>TransformerEncoderLayer is made up of self-attn and feedforward network.</source>
          <target state="translated">TransformerEncoderLayer由自适应网络和前馈网络组成。</target>
        </trans-unit>
        <trans-unit id="0c8dccb3d09a0f9d0d9b17ea9825251d663f04d4" translate="yes" xml:space="preserve">
          <source>TransformerEncoderLayer is made up of self-attn and feedforward network. This standard encoder layer is based on the paper &amp;ldquo;Attention Is All You Need&amp;rdquo;. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000-6010. Users may modify or implement in a different way during application.</source>
          <target state="translated">TransformerEncoderLayer由自检和前馈网络组成。这个标准的编码器层基于&amp;ldquo;注意就是您所需要的&amp;rdquo;一文。Ashish Vaswani，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion Jones，Aidan N Gomez，Lukasz Kaiser和Illia Polosukhin。2017年。您只需要关注即可。《神经信息处理系统的发展》，第6000-6010页。用户可以在应用过程中以不同的方式修改或实现。</target>
        </trans-unit>
        <trans-unit id="06b62690eb29918ca38e1018a11381720478cf29" translate="yes" xml:space="preserve">
          <source>Traverse the modules and save all observers into dict. This is mainly used for quantization accuracy debug :param mod: the top module we want to save all observers :param prefix: the prefix for the current module :param target_dict: the dictionary used to save all the observers</source>
          <target state="translated">遍历各个模块,并将所有的观察者保存到dict中。这主要用于量化精度调试 :param mod:我们要保存所有观测者的顶级模块 :param prefix:当前模块的前缀 :param target_dict:用于保存所有观测者的字典。</target>
        </trans-unit>
        <trans-unit id="4cec3758c8a59b886f1bbcffd16de3c1f5af9091" translate="yes" xml:space="preserve">
          <source>Tries to join one or more processes in this spawn context. If one of them exited with a non-zero exit status, this function kills the remaining processes and raises an exception with the cause of the first process exiting.</source>
          <target state="translated">试图加入此产卵上下文中的一个或多个进程。如果其中一个进程以非零退出状态退出,该函数将杀死其余进程,并引发一个异常,说明第一个进程退出的原因。</target>
        </trans-unit>
        <trans-unit id="a9cb51a530db6f55c97c4e0720722c1b583dafb7" translate="yes" xml:space="preserve">
          <source>TripletMarginLoss</source>
          <target state="translated">TripletMarginLoss</target>
        </trans-unit>
        <trans-unit id="858db382b48e5cc5988f431f28f1130330c1eaf1" translate="yes" xml:space="preserve">
          <source>TripletMarginWithDistanceLoss</source>
          <target state="translated">TripletMarginWithDistanceLoss</target>
        </trans-unit>
        <trans-unit id="88b33e4e12f75ac8bf792aebde41f1a090f3a612" translate="yes" xml:space="preserve">
          <source>True</source>
          <target state="translated">True</target>
        </trans-unit>
        <trans-unit id="56d8a88a6680e193e3cef0877ab543f4d2d36e12" translate="yes" xml:space="preserve">
          <source>True if all differences satisfy allclose condition</source>
          <target state="translated">如果所有的差异都满足allclose条件,则为真</target>
        </trans-unit>
        <trans-unit id="6692b9e66830b65bbf15ff9de3c8b1af8bfbc5eb" translate="yes" xml:space="preserve">
          <source>Tuple Construction</source>
          <target state="translated">元组结构</target>
        </trans-unit>
        <trans-unit id="2c809de45543797accbb7ba7433a5877747ac289" translate="yes" xml:space="preserve">
          <source>Tuple of Tensor containing the padded sequence, and a Tensor containing the list of lengths of each sequence in the batch. Batch elements will be re-ordered as they were ordered originally when the batch was passed to &lt;code&gt;pack_padded_sequence&lt;/code&gt; or &lt;code&gt;pack_sequence&lt;/code&gt;.</source>
          <target state="translated">张量元组包含填充序列，而张量包含批处理中每个序列的长度列表。批处理元素将按照将批处理传递给 &lt;code&gt;pack_padded_sequence&lt;/code&gt; 或 &lt;code&gt;pack_sequence&lt;/code&gt; 时的原始顺序进行重新排序。</target>
        </trans-unit>
        <trans-unit id="654171647baa6be8557a5d627cf35c7075ebb257" translate="yes" xml:space="preserve">
          <source>Tutorials</source>
          <target state="translated">Tutorials</target>
        </trans-unit>
        <trans-unit id="19fd25590b1f3de52164e96d6a585a4ae3f02132" translate="yes" xml:space="preserve">
          <source>Two names &lt;em&gt;match&lt;/em&gt; if they are equal (string equality) or if at least one is &lt;code&gt;None&lt;/code&gt;. Nones are essentially a special &amp;ldquo;wildcard&amp;rdquo; name.</source>
          <target state="translated">如果两个名称相等（字符串相等），或者至少一个为 &lt;code&gt;None&lt;/code&gt; ,则两个名称&lt;em&gt;匹配&lt;/em&gt;。从本质上讲，无是一个特殊的&amp;ldquo;通配符&amp;rdquo;名称。</target>
        </trans-unit>
        <trans-unit id="3deb7456519697ecf4eefc455516c969a3681bae" translate="yes" xml:space="preserve">
          <source>Type</source>
          <target state="translated">Type</target>
        </trans-unit>
        <trans-unit id="74a99ad458c9adf9d415d4bdb125da11688a37f7" translate="yes" xml:space="preserve">
          <source>Type Info</source>
          <target state="translated">类型信息</target>
        </trans-unit>
        <trans-unit id="58cf557846d7f65d34e8a92739eef2665164fad4" translate="yes" xml:space="preserve">
          <source>Type aliases</source>
          <target state="translated">类型别名</target>
        </trans-unit>
        <trans-unit id="c96d0a66889e478977efae5dbe9bb76dea1e1106" translate="yes" xml:space="preserve">
          <source>Type mismatch errors &lt;em&gt;in&lt;/em&gt; an autocast-enabled region are a bug; if this is what you observe, please file an issue.</source>
          <target state="translated">&lt;em&gt;在&lt;/em&gt;启用自动广播的区域中的类型不匹配错误是一个错误；如果这是您所观察到的，请提出问题。</target>
        </trans-unit>
        <trans-unit id="93b9e289e2842469d001eccf7ad5d79f3c302dc9" translate="yes" xml:space="preserve">
          <source>Types</source>
          <target state="translated">Types</target>
        </trans-unit>
        <trans-unit id="c0d285234eb927c53c2fc1dda528e04061e0d90d" translate="yes" xml:space="preserve">
          <source>Types produced by &lt;a href=&quot;https://docs.python.org/3/library/collections.html#collections.namedtuple&quot;&gt;&lt;code&gt;collections.namedtuple&lt;/code&gt;&lt;/a&gt; can be used in TorchScript.</source>
          <target state="translated">&lt;a href=&quot;https://docs.python.org/3/library/collections.html#collections.namedtuple&quot;&gt; &lt;code&gt;collections.namedtuple&lt;/code&gt; &lt;/a&gt;产生的类型可以在TorchScript中使用。</target>
        </trans-unit>
        <trans-unit id="e041e0fe9045d1072a9765e6e123108f2940daba" translate="yes" xml:space="preserve">
          <source>Typically, in SWA the learning rate is set to a high constant value. &lt;code&gt;SWALR&lt;/code&gt; is a learning rate scheduler that anneals the learning rate to a fixed value, and then keeps it constant. For example, the following code creates a scheduler that linearly anneals the learning rate from its initial value to 0.05 in 5 epochs within each parameter group:</source>
          <target state="translated">通常，在SWA中，学习率设置为较高的恒定值。 &lt;code&gt;SWALR&lt;/code&gt; 是一种学习率调度程序，可将学习率退火为固定值，然后使其保持恒定。例如，以下代码创建一个调度程序，该调度程序在每个参数组内的5个时间段内将学习速率从其初始值线性地退火为0.05：</target>
        </trans-unit>
        <trans-unit id="b2c7c0caa10a0cca5ea7d69e54018ae0c0389dd6" translate="yes" xml:space="preserve">
          <source>U</source>
          <target state="translated">U</target>
        </trans-unit>
        <trans-unit id="4e5f249d2049283bfab86474c53e19434fabe07e" translate="yes" xml:space="preserve">
          <source>URL specifying how to initialize the process group. Default is &lt;code&gt;env://&lt;/code&gt;</source>
          <target state="translated">指定如何初始化进程组的URL。默认为 &lt;code&gt;env://&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9016840b6ab501762ae42c3bc2d77284127ecd9d" translate="yes" xml:space="preserve">
          <source>Unflatten</source>
          <target state="translated">Unflatten</target>
        </trans-unit>
        <trans-unit id="22753787538a4df3368517dc3a28771d6a6bd1c2" translate="yes" xml:space="preserve">
          <source>Unflattens a tensor dim expanding it to a desired shape.</source>
          <target state="translated">展开一个张量dim,将其扩展到所需的形状。</target>
        </trans-unit>
        <trans-unit id="ffd6987181a5e9a56284c36d90107b63ec0ad279" translate="yes" xml:space="preserve">
          <source>Unflattens a tensor dim expanding it to a desired shape. For use with &lt;code&gt;Sequential&lt;/code&gt;.</source>
          <target state="translated">使张量调暗变平，将其扩展到所需的形状。与 &lt;code&gt;Sequential&lt;/code&gt; 一起使用。</target>
        </trans-unit>
        <trans-unit id="02d85ea4efaa0d1ca099f19843e9be07e28b954d" translate="yes" xml:space="preserve">
          <source>Unfold</source>
          <target state="translated">Unfold</target>
        </trans-unit>
        <trans-unit id="27c8f884a26740cbb923c350e9fa436fb8314b34" translate="yes" xml:space="preserve">
          <source>Unfortunately, the concrete &lt;code&gt;subset&lt;/code&gt; that was used is lost. For more information see &lt;a href=&quot;https://github.com/pytorch/vision/issues/1439&quot;&gt;this discussion&lt;/a&gt; or &lt;a href=&quot;https://github.com/pytorch/vision/pull/1965&quot;&gt;these experiments&lt;/a&gt;.</source>
          <target state="translated">不幸的是，所使用的具体 &lt;code&gt;subset&lt;/code&gt; 丢失了。有关更多信息，请参见此&lt;a href=&quot;https://github.com/pytorch/vision/issues/1439&quot;&gt;讨论&lt;/a&gt;或&lt;a href=&quot;https://github.com/pytorch/vision/pull/1965&quot;&gt;这些实验&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7a4ec9e5c0816d2c18ff0c058bf903c94688d657" translate="yes" xml:space="preserve">
          <source>Unfortunately, there&amp;rsquo;s no way to force nvprof to flush the data it collected to disk, so for CUDA profiling one has to use this context manager to annotate nvprof traces and wait for the process to exit before inspecting them. Then, either NVIDIA Visual Profiler (nvvp) can be used to visualize the timeline, or &lt;a href=&quot;#torch.autograd.profiler.load_nvprof&quot;&gt;&lt;code&gt;torch.autograd.profiler.load_nvprof()&lt;/code&gt;&lt;/a&gt; can load the results for inspection e.g. in Python REPL.</source>
          <target state="translated">不幸的是，没有办法强制nvprof将收集到的数据刷新到磁盘，因此对于CUDA分析，必须使用此上下文管理器注释nvprof跟踪并等待进程退出后再检查它们。然后，可以使用NVIDIA Visual Profiler（nvvp）可视化时间轴，或者&lt;a href=&quot;#torch.autograd.profiler.load_nvprof&quot;&gt; &lt;code&gt;torch.autograd.profiler.load_nvprof()&lt;/code&gt; &lt;/a&gt;可以加载结果以进行检查，例如在Python REPL中。</target>
        </trans-unit>
        <trans-unit id="e96b0da8b763233f21fa51e37813da0eba866185" translate="yes" xml:space="preserve">
          <source>Uniform</source>
          <target state="translated">Uniform</target>
        </trans-unit>
        <trans-unit id="2786d7c847a0723edc813cd593fabc9e06192fcd" translate="yes" xml:space="preserve">
          <source>Unless otherwise specified, this function should not modify the &lt;code&gt;.grad&lt;/code&gt; field of the parameters.</source>
          <target state="translated">除非另有说明，否则此函数不应修改参数的 &lt;code&gt;.grad&lt;/code&gt; 字段。</target>
        </trans-unit>
        <trans-unit id="b69bc99e876e93b97ea0728c1acca97b14bbffef" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;#torch.Tensor.expand&quot;&gt;&lt;code&gt;expand()&lt;/code&gt;&lt;/a&gt;, this function copies the tensor&amp;rsquo;s data.</source>
          <target state="translated">与&lt;a href=&quot;#torch.Tensor.expand&quot;&gt; &lt;code&gt;expand()&lt;/code&gt; &lt;/a&gt;不同，此函数复制张量的数据。</target>
        </trans-unit>
        <trans-unit id="ef5392b685d4622304e5dfc150347ec19f0ee0af" translate="yes" xml:space="preserve">
          <source>Unlike Batch Normalization and Instance Normalization, which applies scalar scale and bias for each entire channel/plane with the &lt;code&gt;affine&lt;/code&gt; option, Layer Normalization applies per-element scale and bias with &lt;code&gt;elementwise_affine&lt;/code&gt;.</source>
          <target state="translated">与批处理归一化和实例归一化不同，后者使用 &lt;code&gt;affine&lt;/code&gt; 选项对每个整个通道/平面应用标量缩放和偏差，而层归一化则通过 &lt;code&gt;elementwise_affine&lt;/code&gt; 应用每个元素的缩放和偏差。</target>
        </trans-unit>
        <trans-unit id="8607cd4c09ad49a23e91f63072337c8e4b9af158" translate="yes" xml:space="preserve">
          <source>Unlike CPU tensors, the sending process is required to keep the original tensor as long as the receiving process retains a copy of the tensor. The refcounting is implemented under the hood but requires users to follow the next best practices.</source>
          <target state="translated">与CPU张量不同的是,只要接收进程保留一份张量的副本,发送进程就需要保留原始张量。重新计算是在引擎盖下实现的,但需要用户遵循接下来的最佳实践。</target>
        </trans-unit>
        <trans-unit id="2498c971c849991894b17969e87a3329f48f1d2d" translate="yes" xml:space="preserve">
          <source>Unlike Python, each variable in TorchScript function must have a single static type. This makes it easier to optimize TorchScript functions.</source>
          <target state="translated">与Python不同,TorchScript函数中的每个变量都必须有一个单一的静态类型。这使得TorchScript函数的优化更加容易。</target>
        </trans-unit>
        <trans-unit id="3d7bdd35d7e8961eff68645ed326f054b5482c52" translate="yes" xml:space="preserve">
          <source>Unlikely to be implemented</source>
          <target state="translated">不太可能实施</target>
        </trans-unit>
        <trans-unit id="a5b6f222f736f9cef541160a005848fe4ef77888" translate="yes" xml:space="preserve">
          <source>Unlikely to be implemented (however &lt;a href=&quot;https://docs.python.org/3/library/typing.html#typing.Optional&quot;&gt;&lt;code&gt;typing.Optional&lt;/code&gt;&lt;/a&gt; is supported)</source>
          <target state="translated">不太可能实现（但是可以&lt;a href=&quot;https://docs.python.org/3/library/typing.html#typing.Optional&quot;&gt; &lt;code&gt;typing.Optional&lt;/code&gt; &lt;/a&gt;支持可选）</target>
        </trans-unit>
        <trans-unit id="01773bdc2e10d2279820d7115b2522610a09e4f3" translate="yes" xml:space="preserve">
          <source>Unpacks the data and pivots from a LU factorization of a tensor.</source>
          <target state="translated">解开数据的包装,并从张量的LU因式化中枢入手。</target>
        </trans-unit>
        <trans-unit id="a7afe79ac1105fe133bbed5120636913c111a929" translate="yes" xml:space="preserve">
          <source>Unsupported Typing Constructs</source>
          <target state="translated">不支持的输入结构</target>
        </trans-unit>
        <trans-unit id="b2d1fe571301d72d9191816bf953a47985e426ec" translate="yes" xml:space="preserve">
          <source>Update the &lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt;&lt;code&gt;ModuleDict&lt;/code&gt;&lt;/a&gt; with the key-value pairs from a mapping or an iterable, overwriting existing keys.</source>
          <target state="translated">使用来自映射或可迭代，覆盖现有键的键值对更新&lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt; &lt;code&gt;ModuleDict&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4eca5c6565cbf1cfd8391f002e24b24767bdf27d" translate="yes" xml:space="preserve">
          <source>Update the &lt;a href=&quot;#torch.nn.ParameterDict&quot;&gt;&lt;code&gt;ParameterDict&lt;/code&gt;&lt;/a&gt; with the key-value pairs from a mapping or an iterable, overwriting existing keys.</source>
          <target state="translated">使用来自映射或可迭代的键值对的&lt;a href=&quot;#torch.nn.ParameterDict&quot;&gt; &lt;code&gt;ParameterDict&lt;/code&gt; &lt;/a&gt;更新，覆盖现有键。</target>
        </trans-unit>
        <trans-unit id="b985b6244019737115cb9e96cf752b208328d084" translate="yes" xml:space="preserve">
          <source>Updates the scale factor.</source>
          <target state="translated">更新比例因子。</target>
        </trans-unit>
        <trans-unit id="e9f4cec65260954e7a90830aa6f73b90e5c8817f" translate="yes" xml:space="preserve">
          <source>Upsample</source>
          <target state="translated">Upsample</target>
        </trans-unit>
        <trans-unit id="0b472c3013e4cd26ac1f5f84d9b57c5b6b4ca455" translate="yes" xml:space="preserve">
          <source>Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.</source>
          <target state="translated">对给定的多通道1D(时间)、2D(空间)或3D(体积)数据进行采样。</target>
        </trans-unit>
        <trans-unit id="55dfe2d567c845d264928977c08cd8d377265025" translate="yes" xml:space="preserve">
          <source>Upsamples the input to either the given &lt;code&gt;size&lt;/code&gt; or the given &lt;code&gt;scale_factor&lt;/code&gt;</source>
          <target state="translated">将输入上采样到给定 &lt;code&gt;size&lt;/code&gt; 或给定 &lt;code&gt;scale_factor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c9b84912595a004dd92417c63046087231bc7d36" translate="yes" xml:space="preserve">
          <source>Upsamples the input, using bilinear upsampling.</source>
          <target state="translated">使用双线性上采样对输入进行升频。</target>
        </trans-unit>
        <trans-unit id="a31dc0017d79484c9069d06f3ac78a206e41dbfa" translate="yes" xml:space="preserve">
          <source>Upsamples the input, using nearest neighbours&amp;rsquo; pixel values.</source>
          <target state="translated">使用最近的邻居的像素值对输入进行上采样。</target>
        </trans-unit>
        <trans-unit id="fef8a1cac9f9d013e57f5acb6da8a9f36cede8d1" translate="yes" xml:space="preserve">
          <source>UpsamplingBilinear2d</source>
          <target state="translated">UpsamplingBilinear2d</target>
        </trans-unit>
        <trans-unit id="2a7960d23688a71e6707ef6d16f626ed000e779c" translate="yes" xml:space="preserve">
          <source>UpsamplingNearest2d</source>
          <target state="translated">UpsamplingNearest2d</target>
        </trans-unit>
        <trans-unit id="96d06615a1d6c33a776a3eb6549cbfd22dbce234" translate="yes" xml:space="preserve">
          <source>Usage of this function is discouraged in favor of &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt;. In most cases it&amp;rsquo;s better to use &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; environmental variable.</source>
          <target state="translated">不鼓励使用此功能，而建议使用&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;。在大多数情况下，最好使用 &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; 环境变量。</target>
        </trans-unit>
        <trans-unit id="680c6c9f314b68f86ff46d8fdf9a289c7fb0c343" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#torch.Tensor.align_as&quot;&gt;&lt;code&gt;align_as()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.Tensor.align_to&quot;&gt;&lt;code&gt;align_to()&lt;/code&gt;&lt;/a&gt; to align tensor dimensions by name to a specified ordering. This is useful for performing &amp;ldquo;broadcasting by names&amp;rdquo;.</source>
          <target state="translated">使用&lt;a href=&quot;#torch.Tensor.align_as&quot;&gt; &lt;code&gt;align_as()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;#torch.Tensor.align_to&quot;&gt; &lt;code&gt;align_to()&lt;/code&gt; &lt;/a&gt;通过名称将张量尺寸对齐到指定顺序。这对于执行&amp;ldquo;按名称广播&amp;rdquo;很有用。</target>
        </trans-unit>
        <trans-unit id="66804d0e4e83078e14bfdbaa37e395675103792c" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#torch.Tensor.align_to&quot;&gt;&lt;code&gt;align_to()&lt;/code&gt;&lt;/a&gt; to permute large amounts of dimensions without mentioning all of them as in required by &lt;a href=&quot;tensors#torch.Tensor.permute&quot;&gt;&lt;code&gt;permute()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">使用&lt;a href=&quot;#torch.Tensor.align_to&quot;&gt; &lt;code&gt;align_to()&lt;/code&gt; &lt;/a&gt;来排列大量的尺寸不提他们都在所要求的&lt;a href=&quot;tensors#torch.Tensor.permute&quot;&gt; &lt;code&gt;permute()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ede9bff88acacf3e23cc669406c39e0d8aba75b8" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#torch.Tensor.item&quot;&gt;&lt;code&gt;torch.Tensor.item()&lt;/code&gt;&lt;/a&gt; to get a Python number from a tensor containing a single value:</source>
          <target state="translated">使用&lt;a href=&quot;#torch.Tensor.item&quot;&gt; &lt;code&gt;torch.Tensor.item()&lt;/code&gt; &lt;/a&gt;从包含单个值的张量中获取Python数字：</target>
        </trans-unit>
        <trans-unit id="e75b6839717cab84ecfa02664778f32a2c198780" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; to access the dimension names of a tensor and &lt;a href=&quot;#torch.Tensor.rename&quot;&gt;&lt;code&gt;rename()&lt;/code&gt;&lt;/a&gt; to rename named dimensions.</source>
          <target state="translated">使用&lt;a href=&quot;#torch.Tensor.names&quot;&gt; &lt;code&gt;names&lt;/code&gt; &lt;/a&gt;访问张量的维名称，并使用&lt;a href=&quot;#torch.Tensor.rename&quot;&gt; &lt;code&gt;rename()&lt;/code&gt; &lt;/a&gt;重命名命名的维。</target>
        </trans-unit>
        <trans-unit id="b5d22900f5f0642196ebec69d6c5572874ee7c1b" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;tensors#torch.Tensor.flatten&quot;&gt;&lt;code&gt;flatten()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.Tensor.unflatten&quot;&gt;&lt;code&gt;unflatten()&lt;/code&gt;&lt;/a&gt; to flatten and unflatten dimensions, respectively. These methods are more verbose than &lt;a href=&quot;tensors#torch.Tensor.view&quot;&gt;&lt;code&gt;view()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensors#torch.Tensor.reshape&quot;&gt;&lt;code&gt;reshape()&lt;/code&gt;&lt;/a&gt;, but have more semantic meaning to someone reading the code.</source>
          <target state="translated">使用&lt;a href=&quot;tensors#torch.Tensor.flatten&quot;&gt; &lt;code&gt;flatten()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.Tensor.unflatten&quot;&gt; &lt;code&gt;unflatten()&lt;/code&gt; &lt;/a&gt;分别展平和展平尺寸。这些方法比&lt;a href=&quot;tensors#torch.Tensor.view&quot;&gt; &lt;code&gt;view()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;tensors#torch.Tensor.reshape&quot;&gt; &lt;code&gt;reshape()&lt;/code&gt; &lt;/a&gt;更为冗长，但是对阅读代码的人来说具有更多的语义含义。</target>
        </trans-unit>
        <trans-unit id="b67226dee210381a9009b14565e54ae65d2034d5" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;torch.cuda.current_stream()&lt;/code&gt; if no stream is specified.</source>
          <target state="translated">如果未指定流，请使用 &lt;code&gt;torch.cuda.current_stream()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="641cc18d21edd9671570b1c6c598d26a3e5396f4" translate="yes" xml:space="preserve">
          <source>Use Gloo, unless you have specific reasons to use MPI.</source>
          <target state="translated">使用Gloo,除非你有特定的理由使用MPI。</target>
        </trans-unit>
        <trans-unit id="4b4d173cba748d683c0210fec722f5787173d83a" translate="yes" xml:space="preserve">
          <source>Use NCCL, since it currently provides the best distributed GPU training performance, especially for multiprocess single-node or multi-node distributed training. If you encounter any problem with NCCL, use Gloo as the fallback option. (Note that Gloo currently runs slower than NCCL for GPUs.)</source>
          <target state="translated">使用NCCL,因为它目前提供了最好的分布式GPU训练性能,特别是对于多进程单节点或多节点分布式训练。如果你在使用NCCL时遇到任何问题,请使用Gloo作为后备选项。(请注意,Gloo目前的GPU运行速度比NCCL慢。)</target>
        </trans-unit>
        <trans-unit id="9b1bf082bc9bf3ac7914e6187c00d474a91fb73a" translate="yes" xml:space="preserve">
          <source>Use NCCL, since it&amp;rsquo;s the only backend that currently supports InfiniBand and GPUDirect.</source>
          <target state="translated">使用NCCL，因为它是当前唯一支持InfiniBand和GPUDirect的后端。</target>
        </trans-unit>
        <trans-unit id="5e1700010ee503b77904278f8d396bfe42da63c7" translate="yes" xml:space="preserve">
          <source>Use external data format</source>
          <target state="translated">使用外部数据格式</target>
        </trans-unit>
        <trans-unit id="9d0232b01e54b3a2e55b622100adbb68b4edb340" translate="yes" xml:space="preserve">
          <source>Use of Python Values</source>
          <target state="translated">Python值的使用</target>
        </trans-unit>
        <trans-unit id="73922dca1fc1eb81dc09b31de16429c2bad893e0" translate="yes" xml:space="preserve">
          <source>Use the Gloo backend for distributed &lt;strong&gt;CPU&lt;/strong&gt; training.</source>
          <target state="translated">使用Gloo后端进行分布式&lt;strong&gt;CPU&lt;/strong&gt;培训。</target>
        </trans-unit>
        <trans-unit id="fc3648b93e2309e15d382b23a53006e5ccb31b40" translate="yes" xml:space="preserve">
          <source>Use the NCCL backend for distributed &lt;strong&gt;GPU&lt;/strong&gt; training</source>
          <target state="translated">使用NCCL后端进行分布式&lt;strong&gt;GPU&lt;/strong&gt;培训</target>
        </trans-unit>
        <trans-unit id="9ca66ca0ae6872cefb7cdaba9a1b1d7c4fb946f1" translate="yes" xml:space="preserve">
          <source>Used to infer dtype for python complex numbers. The default complex dtype is set to &lt;code&gt;torch.complex128&lt;/code&gt; if default floating point dtype is &lt;code&gt;torch.float64&lt;/code&gt;, otherwise it&amp;rsquo;s set to &lt;code&gt;torch.complex64&lt;/code&gt;</source>
          <target state="translated">用于推断python复数的dtype。如果默认浮点 &lt;code&gt;torch.float64&lt;/code&gt; 为torch.float64，则默认的complex &lt;code&gt;torch.complex128&lt;/code&gt; 设置为torch.complex128，否则将其设置为 &lt;code&gt;torch.complex64&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fac6c061fc6d273aebc0e9ab0c99f04ae81e1097" translate="yes" xml:space="preserve">
          <source>User Share RRef with Owner as Argument</source>
          <target state="translated">用户以所有者为参数共享RRef</target>
        </trans-unit>
        <trans-unit id="a20f912ad88b795f826c479ed261f676c30da2f7" translate="yes" xml:space="preserve">
          <source>User Share RRef with Owner as Return Value</source>
          <target state="translated">以所有者为返回值的用户共享RRef</target>
        </trans-unit>
        <trans-unit id="a7e43a6c0dede8cc47d9e15900c78d9da28530c0" translate="yes" xml:space="preserve">
          <source>User Share RRef with User</source>
          <target state="translated">用户与用户共享RRef</target>
        </trans-unit>
        <trans-unit id="78d0e495aa5431e6e0a8139c0666804c17a54940" translate="yes" xml:space="preserve">
          <source>User extensions can register their own location tags and tagging and deserialization methods using &lt;code&gt;torch.serialization.register_package()&lt;/code&gt;.</source>
          <target state="translated">用户扩展可以使用 &lt;code&gt;torch.serialization.register_package()&lt;/code&gt; 注册自己的位置标签以及标记和反序列化方法。</target>
        </trans-unit>
        <trans-unit id="a2628232b96e27d1cfe74641b5e5eef1e4a68d67" translate="yes" xml:space="preserve">
          <source>Users can force a reload by calling &lt;code&gt;hub.load(..., force_reload=True)&lt;/code&gt;. This will delete the existing github folder and downloaded weights, reinitialize a fresh download. This is useful when updates are published to the same branch, users can keep up with the latest release.</source>
          <target state="translated">用户可以通过调用 &lt;code&gt;hub.load(..., force_reload=True)&lt;/code&gt; 来强制重新加载。这将删除现有的github文件夹和下载的权重，重新初始化新的下载。当更新发布到同一分支时，此功能很有用，用户可以跟上最新版本。</target>
        </trans-unit>
        <trans-unit id="a0dfaf311b141161fd5f1c71366b90c3c330831f" translate="yes" xml:space="preserve">
          <source>Users may use customized &lt;code&gt;collate_fn&lt;/code&gt; to achieve custom batching, e.g., collating along a dimension other than the first, padding sequences of various lengths, or adding support for custom data types.</source>
          <target state="translated">用户可以使用定制的 &lt;code&gt;collate_fn&lt;/code&gt; 来实现定制批处理，例如，沿着除第一个维度以外的其他尺寸进行校对，各种长度的填充序列或添加对定制数据类型的支持。</target>
        </trans-unit>
        <trans-unit id="36a0e861f968553beec79e7c334a566865bdb40a" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;torch.cuda.current_stream()&lt;/code&gt; if no stream is specified. The stream&amp;rsquo;s device must match the event&amp;rsquo;s device.</source>
          <target state="translated">如果未指定流，则使用 &lt;code&gt;torch.cuda.current_stream()&lt;/code&gt; 。流的设备必须与事件的设备匹配。</target>
        </trans-unit>
        <trans-unit id="daa3e4bf690e79b2d584e60908e08290c5eeab22" translate="yes" xml:space="preserve">
          <source>Using &lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril&quot;&gt;&lt;code&gt;scale_tril&lt;/code&gt;&lt;/a&gt; will be more efficient: all computations internally are based on &lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril&quot;&gt;&lt;code&gt;scale_tril&lt;/code&gt;&lt;/a&gt;. If &lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix&quot;&gt;&lt;code&gt;covariance_matrix&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix&quot;&gt;&lt;code&gt;precision_matrix&lt;/code&gt;&lt;/a&gt; is passed instead, it is only used to compute the corresponding lower triangular matrices using a Cholesky decomposition.</source>
          <target state="translated">使用&lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril&quot;&gt; &lt;code&gt;scale_tril&lt;/code&gt; &lt;/a&gt;会更有效：内部的所有计算都基于&lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril&quot;&gt; &lt;code&gt;scale_tril&lt;/code&gt; &lt;/a&gt;。如果改为传递&lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix&quot;&gt; &lt;code&gt;covariance_matrix&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix&quot;&gt; &lt;code&gt;precision_matrix&lt;/code&gt; &lt;/a&gt;，则仅使用Cholesky分解将其用于计算相应的下三角矩阵。</target>
        </trans-unit>
        <trans-unit id="df3d36e2101db7508ee9c65bba6c79f4162eb560" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;DistributedDataParallel&lt;/code&gt; in conjunction with the &lt;a href=&quot;../rpc#distributed-rpc-framework&quot;&gt;Distributed RPC Framework&lt;/a&gt; is experimental and subject to change.</source>
          <target state="translated">将 &lt;code&gt;DistributedDataParallel&lt;/code&gt; 与&lt;a href=&quot;../rpc#distributed-rpc-framework&quot;&gt;Distributed RPC Framework&lt;/a&gt;结合使用是实验性的，并且可能会发生变化。</target>
        </trans-unit>
        <trans-unit id="6f8c8c4de2dead884cf1cd1b1efe492df15bdbf3" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;torch.jit.trace&lt;/code&gt; and &lt;code&gt;torch.jit.trace_module&lt;/code&gt;, you can turn an existing module or Python function into a TorchScript &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;. You must provide example inputs, and we run the function, recording the operations performed on all the tensors.</source>
          <target state="translated">使用 &lt;code&gt;torch.jit.trace&lt;/code&gt; 和 &lt;code&gt;torch.jit.trace_module&lt;/code&gt; ，可以将现有模块或Python函数转换为TorchScript &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;。您必须提供示例输入，然后我们运行该函数，记录在所有张量上执行的操作。</target>
        </trans-unit>
        <trans-unit id="016141762b3eda50d55b6434765c656b21e2c21e" translate="yes" xml:space="preserve">
          <source>Using GPU tensors as arguments or return values of &lt;code&gt;func&lt;/code&gt; is not supported since we don&amp;rsquo;t support sending GPU tensors over the wire. You need to explicitly copy GPU tensors to CPU before using them as arguments or return values of &lt;code&gt;func&lt;/code&gt;.</source>
          <target state="translated">不支持将GPU张量用作参数或 &lt;code&gt;func&lt;/code&gt; 的返回值，因为我们不支持通过网络发送GPU张量。在将它们用作参数或返回 &lt;code&gt;func&lt;/code&gt; 的值之前，需要将GPU张量显式复制到CPU 。</target>
        </trans-unit>
        <trans-unit id="40f8083d709ef1dfeba3266d73cd40bc2120c4c0" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;dim&lt;/code&gt; argument to compute matrix norms:</source>
          <target state="translated">使用 &lt;code&gt;dim&lt;/code&gt; 参数计算矩阵范数：</target>
        </trans-unit>
        <trans-unit id="34eeb9d75aa34a25cf342ae4a398eead839c1594" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;dim&lt;/code&gt; argument to compute vector norms:</source>
          <target state="translated">使用 &lt;code&gt;dim&lt;/code&gt; 参数计算向量范数：</target>
        </trans-unit>
        <trans-unit id="46e68d726011984151416846f828c085d1a8cabd" translate="yes" xml:space="preserve">
          <source>Using this method with &lt;code&gt;create_graph=True&lt;/code&gt; will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using &lt;code&gt;autograd.grad&lt;/code&gt; when creating the graph to avoid this. If you have to use this function, make sure to reset the &lt;code&gt;.grad&lt;/code&gt; fields of your parameters to &lt;code&gt;None&lt;/code&gt; after use to break the cycle and avoid the leak.</source>
          <target state="translated">将此方法与 &lt;code&gt;create_graph=True&lt;/code&gt; 一起使用将在参数及其渐变之间创建参考循环，这可能会导致内存泄漏。我们建议在创建图形时使用 &lt;code&gt;autograd.grad&lt;/code&gt; 以避免这种情况。如果必须使用此功能，请确保在使用后将参数的 &lt;code&gt;.grad&lt;/code&gt; 字段重置为&amp;ldquo; &lt;code&gt;None&lt;/code&gt; ，以中断循环并避免泄漏。</target>
        </trans-unit>
        <trans-unit id="892e242741e1c766ef8440ce7e813adfc429718b" translate="yes" xml:space="preserve">
          <source>Usually the input comes from &lt;code&gt;nn.Conv2d&lt;/code&gt; modules.</source>
          <target state="translated">通常，输入来自 &lt;code&gt;nn.Conv2d&lt;/code&gt; 模块。</target>
        </trans-unit>
        <trans-unit id="62c50ebd5d624de117b146ade6f9d5575d770fc3" translate="yes" xml:space="preserve">
          <source>Usually the input comes from &lt;code&gt;nn.Conv3d&lt;/code&gt; modules.</source>
          <target state="translated">通常，输入来自 &lt;code&gt;nn.Conv3d&lt;/code&gt; 模块。</target>
        </trans-unit>
        <trans-unit id="18fdc5ee8b1f8fba8dabaa933373c0483ab7fad7" translate="yes" xml:space="preserve">
          <source>Utilities</source>
          <target state="translated">Utilities</target>
        </trans-unit>
        <trans-unit id="f16cdccb3faaa5e67faa6fdb65caa5cf29d51cbb" translate="yes" xml:space="preserve">
          <source>Utility functions</source>
          <target state="translated">实用功能</target>
        </trans-unit>
        <trans-unit id="ad96fcc3041d4053b9449ab4a648c6341e2217d7" translate="yes" xml:space="preserve">
          <source>Utility functions in other modules</source>
          <target state="translated">其他模块的实用功能</target>
        </trans-unit>
        <trans-unit id="1c41457151932f1c1abddf366a843f91dd5ea098" translate="yes" xml:space="preserve">
          <source>Utility pruning method that does not prune any units but generates the pruning parametrization with a mask of ones.</source>
          <target state="translated">实用的修剪方法,不修剪任何单元,而是用1的掩模生成修剪参数。</target>
        </trans-unit>
        <trans-unit id="c9ee5681d3c59f7541c27a38b67edf46259e187b" translate="yes" xml:space="preserve">
          <source>V</source>
          <target state="translated">V</target>
        </trans-unit>
        <trans-unit id="1eafbd543ea2d8baa3df59414ec62e236836b78c" translate="yes" xml:space="preserve">
          <source>V. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses: &lt;a href=&quot;http://www.bmva.org/bmvc/2016/papers/paper119/index.html&quot;&gt;http://www.bmva.org/bmvc/2016/papers/paper119/index.html&lt;/a&gt;</source>
          <target state="translated">V.Balntas等人：学习具有三重态损失的浅层卷积特征描述符：&lt;a href=&quot;http://www.bmva.org/bmvc/2016/papers/paper119/index.html&quot;&gt;http&lt;/a&gt; ://www.bmva.org/bmvc/2016/papers/paper119/index.html</target>
        </trans-unit>
        <trans-unit id="2badedb167ecf8f97a1ffcdd2817401074fa728e" translate="yes" xml:space="preserve">
          <source>VGG</source>
          <target state="translated">VGG</target>
        </trans-unit>
        <trans-unit id="76dc2de0cc7c95272fc67f826f2dc5fa09c8ded2" translate="yes" xml:space="preserve">
          <source>VGG 11-layer model (configuration &amp;ldquo;A&amp;rdquo;) from &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">来自&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;用于大型图像识别的非常深度卷积网络&amp;rdquo;的&lt;/a&gt;VGG 11层模型（配置&amp;ldquo; A&amp;rdquo;）</target>
        </trans-unit>
        <trans-unit id="efac66ad38738b85f5ef46a914f1b2bede87a54e" translate="yes" xml:space="preserve">
          <source>VGG 11-layer model (configuration &amp;ldquo;A&amp;rdquo;) with batch normalization &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">具有批量归一化功能的VGG 11层模型（配置&amp;ldquo; A&amp;rdquo;）&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;用于大规模图像识别的超深度卷积网络&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8ab10add11dcdf5fb182aad6d9f35aa59134c466" translate="yes" xml:space="preserve">
          <source>VGG 13-layer model (configuration &amp;ldquo;B&amp;rdquo;) &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">VGG 13层模型（配置&amp;ldquo; B&amp;rdquo;）&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;用于大规模图像识别的非常深的卷积网络&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c68abe1f69acd7242c26b04b450c20879de247dc" translate="yes" xml:space="preserve">
          <source>VGG 13-layer model (configuration &amp;ldquo;B&amp;rdquo;) with batch normalization &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">具有批量归一化功能的&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;&lt;/a&gt; VGG深层卷积网络用于大规模图像识别&amp;rdquo;的VGG 13层模型（配置&amp;ldquo; B&amp;rdquo;）</target>
        </trans-unit>
        <trans-unit id="7df2c09a84b7ee83b6d8493aa3dccf2e12cc714a" translate="yes" xml:space="preserve">
          <source>VGG 16-layer model (configuration &amp;ldquo;D&amp;rdquo;) &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">VGG 16层模型（配置&amp;ldquo; D&amp;rdquo;）&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;用于大规模图像识别的非常深的卷积网络&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4979b51da2376b295925fa358ed83201a60846eb" translate="yes" xml:space="preserve">
          <source>VGG 16-layer model (configuration &amp;ldquo;D&amp;rdquo;) with batch normalization &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">具有批量归一化功能的&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;&lt;/a&gt; VGG深层卷积网络用于大规模图像识别&amp;rdquo;的VGG 16层模型（配置&amp;ldquo; D&amp;rdquo;）</target>
        </trans-unit>
        <trans-unit id="734385d469c0b7b16d39310aab3a223999973e9e" translate="yes" xml:space="preserve">
          <source>VGG 19-layer model (configuration &amp;ldquo;E&amp;rdquo;) &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">VGG 19层模型（配置&amp;ldquo; E&amp;rdquo;）&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;用于大规模图像识别的非常深的卷积网络&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b468de2d615302723a63a19cf8ef07ba2f87d240" translate="yes" xml:space="preserve">
          <source>VGG 19-layer model (configuration &amp;lsquo;E&amp;rsquo;) with batch normalization &lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;Very Deep Convolutional Networks For Large-Scale Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">具有批量归一化功能的VGG 19层模型（配置&amp;ldquo; E&amp;rdquo;）&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;&amp;ldquo;用于大规模图像识别的超深度卷积网络&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22dca5ed30facb9e021b2a416131b71d9addd5df" translate="yes" xml:space="preserve">
          <source>VGG-11</source>
          <target state="translated">VGG-11</target>
        </trans-unit>
        <trans-unit id="59c5eb8db8735266b63e11d68abfe0513f53e937" translate="yes" xml:space="preserve">
          <source>VGG-11 with batch normalization</source>
          <target state="translated">VGG-11,批量标准化</target>
        </trans-unit>
        <trans-unit id="275a0abbe0e323332b36f91fd1e0bbabaa98823b" translate="yes" xml:space="preserve">
          <source>VGG-13</source>
          <target state="translated">VGG-13</target>
        </trans-unit>
        <trans-unit id="00e8568346d410021e9a56f3b1b1f1983ac75021" translate="yes" xml:space="preserve">
          <source>VGG-13 with batch normalization</source>
          <target state="translated">VGG-13,批量标准化</target>
        </trans-unit>
        <trans-unit id="3fa5851c47708aca43af1f031237ec76652d5fb8" translate="yes" xml:space="preserve">
          <source>VGG-16</source>
          <target state="translated">VGG-16</target>
        </trans-unit>
        <trans-unit id="6794221fe94aa99e89cd4a3fc469cd560c5b1798" translate="yes" xml:space="preserve">
          <source>VGG-16 with batch normalization</source>
          <target state="translated">VGG-16,带批量标准化</target>
        </trans-unit>
        <trans-unit id="e33f8119a3d18ad4bc21aa5913ffff22adbc62fa" translate="yes" xml:space="preserve">
          <source>VGG-19</source>
          <target state="translated">VGG-19</target>
        </trans-unit>
        <trans-unit id="6a06101d542844efc9851734dd33c0a3fcfb9071" translate="yes" xml:space="preserve">
          <source>VGG-19 with batch normalization</source>
          <target state="translated">VGG-19,批量标准化</target>
        </trans-unit>
        <trans-unit id="08ab4ecc000363002865da057bb07b708354e689" translate="yes" xml:space="preserve">
          <source>Valid operation names:</source>
          <target state="translated">有效的操作名称。</target>
        </trans-unit>
        <trans-unit id="8ab2f6ea14647497320511c9699ad1fa98390d6e" translate="yes" xml:space="preserve">
          <source>Value associated with &lt;code&gt;key&lt;/code&gt; if &lt;code&gt;key&lt;/code&gt; is in the store.</source>
          <target state="translated">如果 &lt;code&gt;key&lt;/code&gt; 在商店中，则与 &lt;code&gt;key&lt;/code&gt; 关联的值。</target>
        </trans-unit>
        <trans-unit id="8f65e3050b4aa23d2b9ffeafc8ef420283f1bc31" translate="yes" xml:space="preserve">
          <source>Values looked up as attributes of a module are assumed to be constant:</source>
          <target state="translated">作为模块属性查询的值被认为是恒定的。</target>
        </trans-unit>
        <trans-unit id="766a55330fbdeceea3990ed650f19ff9d7ebc2b2" translate="yes" xml:space="preserve">
          <source>Vandermonde matrix. If increasing is False, the first column is</source>
          <target state="translated">Vandermonde矩阵。如果递增为False,则第一列为</target>
        </trans-unit>
        <trans-unit id="2363c9d67b7ae2a0e8fa492fb3e5e19109b5b856" translate="yes" xml:space="preserve">
          <source>Variable (deprecated)</source>
          <target state="translated">变量(已废弃)</target>
        </trans-unit>
        <trans-unit id="8993fc586517fabcc3d0fce5c92e800dc4e3de15" translate="yes" xml:space="preserve">
          <source>Variable Resolution</source>
          <target state="translated">可变分辨率</target>
        </trans-unit>
        <trans-unit id="ac018db1f7b00972061adff843d37497d8ee153c" translate="yes" xml:space="preserve">
          <source>Variables</source>
          <target state="translated">Variables</target>
        </trans-unit>
        <trans-unit id="b1c39119660f33e5be726c1652639e668fcdfcd8" translate="yes" xml:space="preserve">
          <source>Verifies that the given compiler is ABI-compatible with PyTorch.</source>
          <target state="translated">验证给定的编译器是否与 PyTorch 兼容。</target>
        </trans-unit>
        <trans-unit id="991eeb7d6acd3a1b90daf8e907ad4a1126fbf67e" translate="yes" xml:space="preserve">
          <source>Via a string and device ordinal:</source>
          <target state="translated">通过字符串和设备序号。</target>
        </trans-unit>
        <trans-unit id="78f371ae51565c626e223c43a305351baadcdfcb" translate="yes" xml:space="preserve">
          <source>Via a string:</source>
          <target state="translated">通过一个字符串。</target>
        </trans-unit>
        <trans-unit id="3eb4e2b65c3b6adcd10d477d9e1ded0579505479" translate="yes" xml:space="preserve">
          <source>Video classification</source>
          <target state="translated">视频分类</target>
        </trans-unit>
        <trans-unit id="61ad6c7f7397fbdc6a6513e489917c12a6953f11" translate="yes" xml:space="preserve">
          <source>View this tensor as the same size as &lt;code&gt;other&lt;/code&gt;. &lt;code&gt;self.view_as(other)&lt;/code&gt; is equivalent to &lt;code&gt;self.view(other.size())&lt;/code&gt;.</source>
          <target state="translated">将此张量查看为与 &lt;code&gt;other&lt;/code&gt; 张量相同的大小。 &lt;code&gt;self.view_as(other)&lt;/code&gt; 等同于 &lt;code&gt;self.view(other.size())&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="68b460da28c94fa06be12e6f2242c79c2eca8bd2" translate="yes" xml:space="preserve">
          <source>Vision Layers</source>
          <target state="translated">视觉层</target>
        </trans-unit>
        <trans-unit id="8cd7ed1352bc6bdd613ec698de479a989aa9357b" translate="yes" xml:space="preserve">
          <source>Vision functions</source>
          <target state="translated">视觉功能</target>
        </trans-unit>
        <trans-unit id="2b4b5f5947eec0464172de099ad91010e86ae87b" translate="yes" xml:space="preserve">
          <source>VonMises</source>
          <target state="translated">VonMises</target>
        </trans-unit>
        <trans-unit id="e2415cb7f63df0c9de23362326ad3c37a9adfc96" translate="yes" xml:space="preserve">
          <source>W</source>
          <target state="translated">W</target>
        </trans-unit>
        <trans-unit id="46965f2770b3f862f5982cb5b877918de164026c" translate="yes" xml:space="preserve">
          <source>W_{out} = (W_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]}</source>
          <target state="translated">W_{out}=(W_{in}-1)xtimes \text{stride[1]}-2 xtimes \text{padding[1]}+\text{kernel_size[1]}</target>
        </trans-unit>
        <trans-unit id="5b7347a76af1465d2b26baeed335756321992f36" translate="yes" xml:space="preserve">
          <source>W_{out} = (W_{in} - 1) \times \text{stride[2]} - 2 \times \text{padding[2]} + \text{kernel\_size[2]}</source>
          <target state="translated">W_{out}=(W_{in}-1)xtimes \text{stride[2]}-2 xtimes \text{padding[2]}+\text{kernel_size[2]}</target>
        </trans-unit>
        <trans-unit id="06cfb3f342da0b25161bf11f15bf2d81bfb676a7" translate="yes" xml:space="preserve">
          <source>W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1</source>
          <target state="translated">W_{out}=(W_{in}-1)遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数</target>
        </trans-unit>
        <trans-unit id="144094cbaa937780b12d5cb8356e1fc4a6c692aa" translate="yes" xml:space="preserve">
          <source>W_{out} = (W_{in} - 1) \times \text{stride}[2] - 2 \times \text{padding}[2] + \text{dilation}[2] \times (\text{kernel\_size}[2] - 1) + \text{output\_padding}[2] + 1</source>
          <target state="translated">W_{out}=(W_{in}-1)遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 (遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数 遍数</target>
        </trans-unit>
        <trans-unit id="23da97705d0e8d5a571139859c1eefc7a25b59f7" translate="yes" xml:space="preserve">
          <source>W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}</source>
          <target state="translated">W_{out}=W_{in}+text{padding\left}+text{padding\right}。</target>
        </trans-unit>
        <trans-unit id="bf2c9a7a90367be7032bd4f58614c0c9ad3779f8" translate="yes" xml:space="preserve">
          <source>W_{out} = W_{in} \times \text{upscale\_factor}</source>
          <target state="translated">W_{out}=W_{in}遍地开花 遍地开花</target>
        </trans-unit>
        <trans-unit id="c5a97d192d1067a74706f036b87ed2b96b8d5895" translate="yes" xml:space="preserve">
          <source>W_{out} = \left\lfloor W_{in} \times \text{scale\_factor} \right\rfloor</source>
          <target state="translated">W_{out}=左右楼层 W_{in}左右楼层</target>
        </trans-unit>
        <trans-unit id="dd2204cd0212ab9c7330f7c2e6a0b40cae1ae693" translate="yes" xml:space="preserve">
          <source>W_{out} = \left\lfloor\frac{W_{in} + 2 * \text{padding[1]} - \text{dilation[1]} \times (\text{kernel\_size[1]} - 1) - 1}{\text{stride[1]}} + 1\right\rfloor</source>
          <target state="translated">W_{out}=\left\lfloor\frac{W_{in}+2*\text{padding[1]}-\text{dilation[1]}\times (text{kernel_size[1]}-1)-1}{text{stride[1]}}+1\right\rfloor</target>
        </trans-unit>
        <trans-unit id="876c8e0e601e7178678d337712548c5cc7269f61" translate="yes" xml:space="preserve">
          <source>W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[1] - \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor</source>
          <target state="translated">W_{out}=左/右/地板/frac{W_{in}+2次/text{padding}[1]-text{dilation}[1]/times (text{kernel_size}[1]-1)-1}{text{stride}[1]}+1次/right\rfloor。</target>
        </trans-unit>
        <trans-unit id="6e0657f1536a7a37c826480069677e9010835607" translate="yes" xml:space="preserve">
          <source>W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[1] - \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor</source>
          <target state="translated">W_{out}=\left\lfloor\frac{W_{in}+2 \times \text{padding}[1]-\text{kernel_size}[1]}{text{stride}[1]}+1 \right\rfloor</target>
        </trans-unit>
        <trans-unit id="a11c0191402c7be2c31a4ea7dcec53e255776ef6" translate="yes" xml:space="preserve">
          <source>W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2] \times (\text{kernel\_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor</source>
          <target state="translated">W_{out}=左/右/地板/frac{W_{in}+2次 填充物{padding}[2]-填充物{dilation}[2]填充物(text{kernel_size}[2]-1)-1}{text{stride}[2]}+1次右/地板。</target>
        </trans-unit>
        <trans-unit id="b4191f6bab2de7c1a0f2413fa95cad94e0003ac5" translate="yes" xml:space="preserve">
          <source>W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{kernel\_size}[2]}{\text{stride}[2]} + 1\right\rfloor</source>
          <target state="translated">W_{out}=\left\lfloor\frac{W_{in}+2 \times \text{padding}[2]-\text{kernel_size}[2]}{text{stride}[2]}+1 \right\rfloor</target>
        </trans-unit>
        <trans-unit id="90b3ee06862d0af7ed835a4f57d3b9839c234435" translate="yes" xml:space="preserve">
          <source>W_{out} = \left\lfloor\frac{W_{in} - \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor</source>
          <target state="translated">W_{out}=\left\lfloor\frac{W_{in}-\text{kernel\_size}[1]}{text{stride}[1]}+1right\rfloor</target>
        </trans-unit>
        <trans-unit id="206613fe29a3beacd4aa9146df44d435eeec070f" translate="yes" xml:space="preserve">
          <source>Wait for all the kernels in this stream to complete.</source>
          <target state="translated">等待这个流中所有的内核完成。</target>
        </trans-unit>
        <trans-unit id="a3b76987c40f20668517b915def98113b24efd97" translate="yes" xml:space="preserve">
          <source>Waits for all kernels in all streams on a CUDA device to complete.</source>
          <target state="translated">等待CUDA设备上所有流中的所有内核完成。</target>
        </trans-unit>
        <trans-unit id="02d96942e51e668861c82b6ad6a1888bbaffdfc3" translate="yes" xml:space="preserve">
          <source>Waits for all provided futures to be complete, and returns the list of completed values.</source>
          <target state="translated">等待所有提供的期货完成,并返回已完成值的列表。</target>
        </trans-unit>
        <trans-unit id="0a15d8c4d33065db8154fb49b0e2d2a98624af19" translate="yes" xml:space="preserve">
          <source>Waits for each key in &lt;code&gt;keys&lt;/code&gt; to be added to the store, and throws an exception if the keys have not been set by the supplied &lt;code&gt;timeout&lt;/code&gt;.</source>
          <target state="translated">对于在每个键中等待 &lt;code&gt;keys&lt;/code&gt; 被添加到存储，并且如果键没有被所提供的设置抛出异常 &lt;code&gt;timeout&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="24a824e1b1fcd89978ae586133c59626ca034951" translate="yes" xml:space="preserve">
          <source>Waits for each key in &lt;code&gt;keys&lt;/code&gt; to be added to the store. If not all keys are set before the &lt;code&gt;timeout&lt;/code&gt; (set during store initialization), then &lt;code&gt;wait&lt;/code&gt; will throw an exception.</source>
          <target state="translated">在每个键等待 &lt;code&gt;keys&lt;/code&gt; 被添加到存储中。如果不是在 &lt;code&gt;timeout&lt;/code&gt; 之前设置了所有键（在商店初始化期间设置），则 &lt;code&gt;wait&lt;/code&gt; 将引发异常。</target>
        </trans-unit>
        <trans-unit id="bf737f8268ade30b29f4e304a6f74e8dc126217a" translate="yes" xml:space="preserve">
          <source>Waits for the event to complete.</source>
          <target state="translated">等待事件完成。</target>
        </trans-unit>
        <trans-unit id="ff9074c4aa9ff896546792138df1d27c0f9655c8" translate="yes" xml:space="preserve">
          <source>Waits until the completion of all work currently captured in this event. This prevents the CPU thread from proceeding until the event completes.</source>
          <target state="translated">等待到该事件中当前捕获的所有工作完成。这样可以防止CPU线程继续工作,直到事件完成。</target>
        </trans-unit>
        <trans-unit id="e9c45563358e813f157ba81b33143542165ba84e" translate="yes" xml:space="preserve">
          <source>Warning</source>
          <target state="translated">Warning</target>
        </trans-unit>
        <trans-unit id="322f5a9cd5158cc9dec2b3e7da850004249c9e4e" translate="yes" xml:space="preserve">
          <source>We accumulate the gradients in the appropriate &lt;a href=&quot;#torch.distributed.autograd.context&quot;&gt;&lt;code&gt;torch.distributed.autograd.context&lt;/code&gt;&lt;/a&gt; on each of the nodes. The autograd context to be used is looked up given the &lt;code&gt;context_id&lt;/code&gt; that is passed in when &lt;a href=&quot;#torch.distributed.autograd.backward&quot;&gt;&lt;code&gt;torch.distributed.autograd.backward()&lt;/code&gt;&lt;/a&gt; is called. If there is no valid autograd context corresponding to the given ID, we throw an error. You can retrieve the accumulated gradients using the &lt;a href=&quot;#torch.distributed.autograd.get_gradients&quot;&gt;&lt;code&gt;get_gradients()&lt;/code&gt;&lt;/a&gt; API.</source>
          <target state="translated">我们在每个节点上的适当&lt;a href=&quot;#torch.distributed.autograd.context&quot;&gt; &lt;code&gt;torch.distributed.autograd.context&lt;/code&gt; 中&lt;/a&gt;累积渐变。给定在调用&lt;a href=&quot;#torch.distributed.autograd.backward&quot;&gt; &lt;code&gt;torch.distributed.autograd.backward()&lt;/code&gt; &lt;/a&gt;时传递的 &lt;code&gt;context_id&lt;/code&gt; ，可以查找要使用的autograd上下文。如果没有与给定ID对应的有效autograd上下文，则抛出错误。您可以使用&lt;a href=&quot;#torch.distributed.autograd.get_gradients&quot;&gt; &lt;code&gt;get_gradients()&lt;/code&gt; &lt;/a&gt; API检索累积的梯度。</target>
        </trans-unit>
        <trans-unit id="db56b28279fe3aea1467a7671b69e8c448f2218c" translate="yes" xml:space="preserve">
          <source>We adopt the same interface as &lt;a href=&quot;generated/torch.nn.linear#torch.nn.Linear&quot;&gt;&lt;code&gt;torch.nn.Linear&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">我们采用与&lt;a href=&quot;generated/torch.nn.linear#torch.nn.Linear&quot;&gt; &lt;code&gt;torch.nn.Linear&lt;/code&gt; &lt;/a&gt;相同的接口。</target>
        </trans-unit>
        <trans-unit id="3f8d51566ad98edb597de3ba663338465830f744" translate="yes" xml:space="preserve">
          <source>We adopt the same interface as &lt;a href=&quot;torch.nn.quantized#torch.nn.quantized.Conv2d&quot;&gt;&lt;code&gt;torch.nn.quantized.Conv2d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">我们采用与&lt;a href=&quot;torch.nn.quantized#torch.nn.quantized.Conv2d&quot;&gt; &lt;code&gt;torch.nn.quantized.Conv2d&lt;/code&gt; &lt;/a&gt;相同的接口。</target>
        </trans-unit>
        <trans-unit id="2e48e5f00566ef4a4b3bcb10eab8d225acffc2e4" translate="yes" xml:space="preserve">
          <source>We adopt the same interface as &lt;a href=&quot;torch.nn.quantized#torch.nn.quantized.Conv3d&quot;&gt;&lt;code&gt;torch.nn.quantized.Conv3d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">我们采用与&lt;a href=&quot;torch.nn.quantized#torch.nn.quantized.Conv3d&quot;&gt; &lt;code&gt;torch.nn.quantized.Conv3d&lt;/code&gt; &lt;/a&gt;相同的接口。</target>
        </trans-unit>
        <trans-unit id="a3fb7d904d476590d98359b7241880b1be2f9a76" translate="yes" xml:space="preserve">
          <source>We adopt the same interface as &lt;a href=&quot;torch.nn.quantized#torch.nn.quantized.Linear&quot;&gt;&lt;code&gt;torch.nn.quantized.Linear&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">我们采用与&lt;a href=&quot;torch.nn.quantized#torch.nn.quantized.Linear&quot;&gt; &lt;code&gt;torch.nn.quantized.Linear&lt;/code&gt; &lt;/a&gt;相同的接口。</target>
        </trans-unit>
        <trans-unit id="9fb0293b1874dcfe3feb591ccd49a1edaf2d5f3f" translate="yes" xml:space="preserve">
          <source>We adopt the same interface as &lt;code&gt;torch.nn.Conv2d&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d&quot;&gt;https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d&lt;/a&gt; for documentation.</source>
          <target state="translated">我们采用与 &lt;code&gt;torch.nn.Conv2d&lt;/code&gt; 相同的界面，有关文档，请参阅&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d&quot;&gt;https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="27cfadeddc9160f1498530cc3eb1f719bfd8434a" translate="yes" xml:space="preserve">
          <source>We adopt the same interface as &lt;code&gt;torch.nn.Linear&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&lt;/a&gt; for documentation.</source>
          <target state="translated">我们采用与 &lt;code&gt;torch.nn.Linear&lt;/code&gt; 相同的界面，有关文档，请参阅&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5105f862983064b0cf7594afba8d668c8f56e9ff" translate="yes" xml:space="preserve">
          <source>We allow mixing tracing and scripting. You can compose tracing and scripting to suit the particular requirements of a part of a model. Checkout this example:</source>
          <target state="translated">我们允许混合跟踪和脚本。您可以组成跟踪和脚本,以适应模型一部分的特殊要求。请看这个例子。</target>
        </trans-unit>
        <trans-unit id="6defebafebb2e25f76bcf411ab1ec455c032f365" translate="yes" xml:space="preserve">
          <source>We also do not support the following subsystems, though some may work out of the box:</source>
          <target state="translated">我们也不支持以下子系统,尽管有些子系统可能在开箱即用。</target>
        </trans-unit>
        <trans-unit id="3fa9a188f6de578d3bee11e42ad3ca8321060293" translate="yes" xml:space="preserve">
          <source>We can fix this by modifying the code to not use the in-place update, but rather build up the result tensor out-of-place with &lt;code&gt;torch.cat&lt;/code&gt;:</source>
          <target state="translated">我们可以通过修改代码来解决此问题，以不使用就地更新，而是使用 &lt;code&gt;torch.cat&lt;/code&gt; 来错位构建结果张量：</target>
        </trans-unit>
        <trans-unit id="7aac442ad82fddd2074ccf19e4043ee60a7cdfb0" translate="yes" xml:space="preserve">
          <source>We combined the interface of &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;BatchNorm2d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">我们结合了&lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;Conv2d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt; &lt;code&gt;BatchNorm2d&lt;/code&gt; &lt;/a&gt;的接口。</target>
        </trans-unit>
        <trans-unit id="4304f8e1f80a53c4c4788f88c99ef4dcb6d0bc02" translate="yes" xml:space="preserve">
          <source>We combined the interface of &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;torch.nn.Conv2d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;torch.nn.BatchNorm2d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.relu#torch.nn.ReLU&quot;&gt;&lt;code&gt;torch.nn.ReLU&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">我们结合了&lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;torch.nn.Conv2d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt; &lt;code&gt;torch.nn.BatchNorm2d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.relu#torch.nn.ReLU&quot;&gt; &lt;code&gt;torch.nn.ReLU&lt;/code&gt; &lt;/a&gt;的接口。</target>
        </trans-unit>
        <trans-unit id="94fba3bcda49d77ec84730c68d223d594ab23cb3" translate="yes" xml:space="preserve">
          <source>We combined the interface of &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;torch.nn.Conv2d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;torch.nn.BatchNorm2d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">我们结合了&lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;torch.nn.Conv2d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt; &lt;code&gt;torch.nn.BatchNorm2d&lt;/code&gt; &lt;/a&gt;的接口。</target>
        </trans-unit>
        <trans-unit id="a068c518b2d5e22e14c479569a01c9c9d06bceec" translate="yes" xml:space="preserve">
          <source>We highly recommend taking a look at the original paper for more details.</source>
          <target state="translated">我们强烈建议大家看一下原文,了解更多详情。</target>
        </trans-unit>
        <trans-unit id="86ad4838215218ac000a7d87b4b48e01c6961c5f" translate="yes" xml:space="preserve">
          <source>We provide models for action recognition pre-trained on Kinetics-400. They have all been trained with the scripts provided in &lt;code&gt;references/video_classification&lt;/code&gt;.</source>
          <target state="translated">我们提供在Kinetics-400上经过预训练的动作识别模型。他们都已经使用 &lt;code&gt;references/video_classification&lt;/code&gt; 中提供的脚本进行了培训。</target>
        </trans-unit>
        <trans-unit id="e921c07692e5a21fc62c5f94070c73cf433f0bb7" translate="yes" xml:space="preserve">
          <source>We provide pre-trained models, using the PyTorch &lt;a href=&quot;../model_zoo#module-torch.utils.model_zoo&quot;&gt;&lt;code&gt;torch.utils.model_zoo&lt;/code&gt;&lt;/a&gt;. These can be constructed by passing &lt;code&gt;pretrained=True&lt;/code&gt;:</source>
          <target state="translated">我们使用PyTorch &lt;a href=&quot;../model_zoo#module-torch.utils.model_zoo&quot;&gt; &lt;code&gt;torch.utils.model_zoo&lt;/code&gt; &lt;/a&gt;提供预训练的模型。这些可以通过传递 &lt;code&gt;pretrained=True&lt;/code&gt; 来构造：</target>
        </trans-unit>
        <trans-unit id="62c9fd377e2aad0f66ac5c26c69e0a5867347f36" translate="yes" xml:space="preserve">
          <source>We provide tools to incrementally transition a model from a pure Python program to a TorchScript program that can be run independently from Python, such as in a standalone C++ program. This makes it possible to train models in PyTorch using familiar tools in Python and then export the model via TorchScript to a production environment where Python programs may be disadvantageous for performance and multi-threading reasons.</source>
          <target state="translated">我们提供的工具可以将一个模型从一个纯Python程序逐步过渡到一个可以独立于Python运行的TorchScript程序,例如在一个独立的C++程序中。这使得在PyTorch中使用熟悉的Python工具训练模型成为可能,然后通过TorchScript将模型输出到生产环境中,而在生产环境中,Python程序可能会因为性能和多线程原因而处于不利地位。</target>
        </trans-unit>
        <trans-unit id="bd73422aa80da87d8ae75185414e27781227d850" translate="yes" xml:space="preserve">
          <source>We use the provided roots to discover the autograd graph and compute appropriate dependencies. This method blocks until the entire autograd computation is done.</source>
          <target state="translated">我们使用提供的根来发现autograd图,并计算相应的依赖关系。这个方法会阻塞,直到整个autograd计算完成。</target>
        </trans-unit>
        <trans-unit id="7ea805e8dac2601210cb6d8d378a9d7e2e8c1197" translate="yes" xml:space="preserve">
          <source>Weibull</source>
          <target state="translated">Weibull</target>
        </trans-unit>
        <trans-unit id="48996658259127412cd98e4a4e7b4a204e6d1b0a" translate="yes" xml:space="preserve">
          <source>Weight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This replaces the parameter specified by &lt;code&gt;name&lt;/code&gt; (e.g. &lt;code&gt;'weight'&lt;/code&gt;) with two parameters: one specifying the magnitude (e.g. &lt;code&gt;'weight_g'&lt;/code&gt;) and one specifying the direction (e.g. &lt;code&gt;'weight_v'&lt;/code&gt;). Weight normalization is implemented via a hook that recomputes the weight tensor from the magnitude and direction before every &lt;code&gt;forward()&lt;/code&gt; call.</source>
          <target state="translated">权重归一化是一种重新参数化，可将权重张量的大小与其方向解耦。这用两个参数替换了 &lt;code&gt;name&lt;/code&gt; 指定的参数（例如 &lt;code&gt;'weight'&lt;/code&gt; ）：一个参数指定了幅度（例如 &lt;code&gt;'weight_g'&lt;/code&gt; ）和一个指定了方向（例如 &lt;code&gt;'weight_v'&lt;/code&gt; ）。权重归一化是通过钩子实现的，该钩子在每次 &lt;code&gt;forward()&lt;/code&gt; 调用之前从幅度和方向重新计算权重张量。</target>
        </trans-unit>
        <trans-unit id="d53879f401fe4a3643952a897298dc95fdaf8d7e" translate="yes" xml:space="preserve">
          <source>Weight:</source>
          <target state="translated">Weight:</target>
        </trans-unit>
        <trans-unit id="769bb19e615b7f8e2809e5882e2d05a18f57a531" translate="yes" xml:space="preserve">
          <source>When</source>
          <target state="translated">When</target>
        </trans-unit>
        <trans-unit id="d4a914f8dcec6b172849d1c8fb16401fbdbb7604" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;align_corners = True&lt;/code&gt;, 2D affine transforms on 1D data and 3D affine transforms on 2D data (that is, when one of the spatial dimensions has unit size) are ill-defined, and not an intended use case. This is not a problem when &lt;code&gt;align_corners = False&lt;/code&gt;. Up to version 1.2.0, all grid points along a unit dimension were considered arbitrarily to be at &lt;code&gt;-1&lt;/code&gt;. From version 1.3.0, under &lt;code&gt;align_corners = True&lt;/code&gt; all grid points along a unit dimension are considered to be at &lt;code&gt;`0&lt;/code&gt; (the center of the input image).</source>
          <target state="translated">当 &lt;code&gt;align_corners = True&lt;/code&gt; ，对1D数据的2D仿射变换和对2D数据的3D仿射变换（即，当一个空间维度具有单位大小时）定义不明确，而不是预期的用例。当 &lt;code&gt;align_corners = False&lt;/code&gt; 时，这不是问题。在版本1.2.0之前，单位维度上的所有网格点都被任意认为是 &lt;code&gt;-1&lt;/code&gt; 。从版本1.3.0开始，在 &lt;code&gt;align_corners = True&lt;/code&gt; 下，单位维度上的所有网格点都被视为在 &lt;code&gt;`0&lt;/code&gt; （输入图像的中心）。</target>
        </trans-unit>
        <trans-unit id="71f1f4c1d858ca7758a6c256f77db87995af50dc" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;align_corners = True&lt;/code&gt;, the grid positions depend on the pixel size relative to the input image size, and so the locations sampled by &lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt;&lt;code&gt;grid_sample()&lt;/code&gt;&lt;/a&gt; will differ for the same input given at different resolutions (that is, after being upsampled or downsampled). The default behavior up to version 1.2.0 was &lt;code&gt;align_corners = True&lt;/code&gt;. Since then, the default behavior has been changed to &lt;code&gt;align_corners = False&lt;/code&gt;, in order to bring it in line with the default for &lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;interpolate()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">当 &lt;code&gt;align_corners = True&lt;/code&gt; ，网格位置取决于相对于输入图像大小的像素大小，因此对于以不同分辨率（即在上采样或下采样后）给出的同一输入，&lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt; &lt;code&gt;grid_sample()&lt;/code&gt; &lt;/a&gt;采样的位置将有所不同。直到版本1.2.0，默认行为是 &lt;code&gt;align_corners = True&lt;/code&gt; 。从那时起，默认行为已更改为 &lt;code&gt;align_corners = False&lt;/code&gt; ，以使其与&lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt; &lt;code&gt;interpolate()&lt;/code&gt; &lt;/a&gt;的默认行为保持一致。</target>
        </trans-unit>
        <trans-unit id="393f1e49e22eb1a104936dd30d39047e787303b1" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;batch_size&lt;/code&gt; (default &lt;code&gt;1&lt;/code&gt;) is not &lt;code&gt;None&lt;/code&gt;, the data loader yields batched samples instead of individual samples. &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;drop_last&lt;/code&gt; arguments are used to specify how the data loader obtains batches of dataset keys. For map-style datasets, users can alternatively specify &lt;code&gt;batch_sampler&lt;/code&gt;, which yields a list of keys at a time.</source>
          <target state="translated">当 &lt;code&gt;batch_size&lt;/code&gt; （默认值 &lt;code&gt;1&lt;/code&gt; ）不为 &lt;code&gt;None&lt;/code&gt; 时，数据加载器将生成批处理的样本，而不是单个样本。 &lt;code&gt;batch_size&lt;/code&gt; 和 &lt;code&gt;drop_last&lt;/code&gt; 参数用于指定数据加载器如何获取数据集密钥的批处理。对于地图样式的数据集，用户可以选择指定 &lt;code&gt;batch_sampler&lt;/code&gt; ，一次生成一个键列表。</target>
        </trans-unit>
        <trans-unit id="19d86416250dfee41099689ccdc474523b9de05a" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;compute_uv&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt;, backward cannot be performed since &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; from the forward pass is required for the backward operation.</source>
          <target state="translated">当 &lt;code&gt;compute_uv&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; 时，由于向后操作需要来自前向传递的 &lt;code&gt;U&lt;/code&gt; 和 &lt;code&gt;V&lt;/code&gt; ，因此无法执行向后。</target>
        </trans-unit>
        <trans-unit id="2e150d7511a776c744a811c73ef08944e9bb6434" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;dim&lt;/code&gt; is given, a squeeze operation is done only in the given dimension. If &lt;code&gt;input&lt;/code&gt; is of shape:</source>
          <target state="translated">如果指定了 &lt;code&gt;dim&lt;/code&gt; ，则仅在给定维度上执行挤压操作。如果 &lt;code&gt;input&lt;/code&gt; 的形状：</target>
        </trans-unit>
        <trans-unit id="b1120f7dfd992f23bbea9418ec57a1af2fe9af61" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;exponent&lt;/code&gt; is a scalar value, the operation applied is:</source>
          <target state="translated">当 &lt;code&gt;exponent&lt;/code&gt; 为标量值时，应用的运算为：</target>
        </trans-unit>
        <trans-unit id="66481b64a8fde71d4312aa50639d9ce101db880a" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;exponent&lt;/code&gt; is a tensor, the operation applied is:</source>
          <target state="translated">当 &lt;code&gt;exponent&lt;/code&gt; 是张量时，应用的运算为：</target>
        </trans-unit>
        <trans-unit id="25f39b6b9d40581f69f611ee72f68c18106be3d1" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;exponent&lt;/code&gt; is a tensor, the shapes of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;exponent&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">当 &lt;code&gt;exponent&lt;/code&gt; 是张量时， &lt;code&gt;input&lt;/code&gt; 和 &lt;code&gt;exponent&lt;/code&gt; 的形状必须是可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播的&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2903dec45ead9638a2d9f01c40302928711917b1" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;groups == in_channels&lt;/code&gt; and &lt;code&gt;out_channels == K * in_channels&lt;/code&gt;, where &lt;code&gt;K&lt;/code&gt; is a positive integer, this operation is also termed in literature as depthwise convolution.</source>
          <target state="translated">当 &lt;code&gt;groups == in_channels&lt;/code&gt; 和 &lt;code&gt;out_channels == K * in_channels&lt;/code&gt; ，其中 &lt;code&gt;K&lt;/code&gt; 为正整数，此操作在文献中也称为深度卷积。</target>
        </trans-unit>
        <trans-unit id="c1b8e1328795e35aa33cb3682bf9e0a128163cf6" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;input&lt;/code&gt; is on CUDA, &lt;a href=&quot;#torch.nonzero&quot;&gt;&lt;code&gt;torch.nonzero()&lt;/code&gt;&lt;/a&gt; causes host-device synchronization.</source>
          <target state="translated">当 &lt;code&gt;input&lt;/code&gt; 在CUDA上时，&lt;a href=&quot;#torch.nonzero&quot;&gt; &lt;code&gt;torch.nonzero()&lt;/code&gt; &lt;/a&gt;导致主机设备同步。</target>
        </trans-unit>
        <trans-unit id="9fd8de791261b8fe5e3fd820c55e05ef945d4e88" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;module&lt;/code&gt; returns a scalar (i.e., 0-dimensional tensor) in &lt;code&gt;forward()&lt;/code&gt;, this wrapper will return a vector of length equal to number of devices used in data parallelism, containing the result from each device.</source>
          <target state="translated">当 &lt;code&gt;module&lt;/code&gt; 在 &lt;code&gt;forward()&lt;/code&gt; 中返回标量（即0维张量）时，此包装器将返回一个向量，该向量的长度等于数据并行性中使用的设备数，其中包含每个设备的结果。</target>
        </trans-unit>
        <trans-unit id="14811e48d579473d679dcda9d3180b5365c2423a" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;other&lt;/code&gt; is a tensor, the shape of &lt;code&gt;other&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with the shape of the underlying tensor</source>
          <target state="translated">当 &lt;code&gt;other&lt;/code&gt; 是张量时， &lt;code&gt;other&lt;/code&gt; 的形状必须与基础张量的形状一起&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6d6234d9ff0cd3ff058351e570bff6a3e90e8d1e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;other&lt;/code&gt; is a tensor, the shapes of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">当 &lt;code&gt;other&lt;/code&gt; 是张量时， &lt;code&gt;input&lt;/code&gt; 和 &lt;code&gt;other&lt;/code&gt; 的形状必须是可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播的&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2b23daf961076c6f771f3b98153804afb65cab2e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;size&lt;/code&gt; is given, it is the output size of the image &lt;code&gt;(h, w)&lt;/code&gt;.</source>
          <target state="translated">当 &lt;code&gt;size&lt;/code&gt; 给出，它是图像的输出尺寸 &lt;code&gt;(h, w)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d240a83215b54cebb671916345cdadc2427a5a89" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;some&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt;, the gradients on &lt;code&gt;U[..., :, min(m, n):]&lt;/code&gt; and &lt;code&gt;V[..., :, min(m, n):]&lt;/code&gt; will be ignored in backward as those vectors can be arbitrary bases of the subspaces.</source>
          <target state="translated">当 &lt;code&gt;some&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; 时， &lt;code&gt;U[..., :, min(m, n):]&lt;/code&gt; 和 &lt;code&gt;V[..., :, min(m, n):]&lt;/code&gt; 和U [...，：，min（m，n）：]上的梯度将被向后忽略，因为这些向量可以是子空间的任意基数。</target>
        </trans-unit>
        <trans-unit id="85caf16edf789cb76e0cd678a0b93ec725f0105b" translate="yes" xml:space="preserve">
          <source>When a model is trained on &lt;code&gt;M&lt;/code&gt; nodes with &lt;code&gt;batch=N&lt;/code&gt;, the gradient will be &lt;code&gt;M&lt;/code&gt; times smaller when compared to the same model trained on a single node with &lt;code&gt;batch=M*N&lt;/code&gt; (because the gradients between different nodes are averaged). You should take this into consideration when you want to obtain a mathematically equivalent training process compared to the local training counterpart.</source>
          <target state="translated">当在具有 &lt;code&gt;batch=N&lt;/code&gt; 的 &lt;code&gt;M&lt;/code&gt; 个节点上训练模型时，与在具有 &lt;code&gt;batch=M*N&lt;/code&gt; 的单个节点上训练的相同模型相比，梯度将小 &lt;code&gt;M&lt;/code&gt; 倍（因为对不同节点之间的梯度进行了平均）。与本地培训对象相比，当您要获得数学上等效的培训过程时，应考虑到这一点。</target>
        </trans-unit>
        <trans-unit id="794b9d3ddf3eff59a51409ca459125a99df4910e" translate="yes" xml:space="preserve">
          <source>When a non-sparse &lt;code&gt;param&lt;/code&gt; receives a non-sparse gradient during &lt;a href=&quot;#torch.autograd.backward&quot;&gt;&lt;code&gt;torch.autograd.backward()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.Tensor.backward&quot;&gt;&lt;code&gt;torch.Tensor.backward()&lt;/code&gt;&lt;/a&gt;&lt;code&gt;param.grad&lt;/code&gt; is accumulated as follows.</source>
          <target state="translated">当非稀疏 &lt;code&gt;param&lt;/code&gt; 期间接收非稀疏梯度&lt;a href=&quot;#torch.autograd.backward&quot;&gt; &lt;code&gt;torch.autograd.backward()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;#torch.Tensor.backward&quot;&gt; &lt;code&gt;torch.Tensor.backward()&lt;/code&gt; &lt;/a&gt; &lt;code&gt;param.grad&lt;/code&gt; 如下积累。</target>
        </trans-unit>
        <trans-unit id="746e7941b779e1590393a8195388add16038ba46" translate="yes" xml:space="preserve">
          <source>When a subclass is used with &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt;, each item in the dataset will be yielded from the &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; iterator. When &lt;code&gt;num_workers &amp;gt; 0&lt;/code&gt;, each worker process will have a different copy of the dataset object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. &lt;a href=&quot;#torch.utils.data.get_worker_info&quot;&gt;&lt;code&gt;get_worker_info()&lt;/code&gt;&lt;/a&gt;, when called in a worker process, returns information about the worker. It can be used in either the dataset&amp;rsquo;s &lt;code&gt;__iter__()&lt;/code&gt; method or the &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; &amp;lsquo;s &lt;code&gt;worker_init_fn&lt;/code&gt; option to modify each copy&amp;rsquo;s behavior.</source>
          <target state="translated">当子类与&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; 一起&lt;/a&gt;使用时，数据集中的每个项目都将由&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;迭代器产生。当 &lt;code&gt;num_workers &amp;gt; 0&lt;/code&gt; ，每个工作进程将具有数据集对象的不同副本，因此通常需要独立配置每个副本，以避免从工作进程返回重复的数据。在工作进程中调用&lt;a href=&quot;#torch.utils.data.get_worker_info&quot;&gt; &lt;code&gt;get_worker_info()&lt;/code&gt; &lt;/a&gt;时，返回有关工作程序的信息。可以在数据集的 &lt;code&gt;__iter__()&lt;/code&gt; 方法或&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;worker_init_fn&lt;/code&gt; 选项中使用它来修改每个副本的行为。</target>
        </trans-unit>
        <trans-unit id="4794503b3573f4db7c79a8a74163748fdeea10ab" translate="yes" xml:space="preserve">
          <source>When both &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;batch_sampler&lt;/code&gt; are &lt;code&gt;None&lt;/code&gt; (default value for &lt;code&gt;batch_sampler&lt;/code&gt; is already &lt;code&gt;None&lt;/code&gt;), automatic batching is disabled. Each sample obtained from the &lt;code&gt;dataset&lt;/code&gt; is processed with the function passed as the &lt;code&gt;collate_fn&lt;/code&gt; argument.</source>
          <target state="translated">当两个 &lt;code&gt;batch_size&lt;/code&gt; 和 &lt;code&gt;batch_sampler&lt;/code&gt; 是 &lt;code&gt;None&lt;/code&gt; （默认值 &lt;code&gt;batch_sampler&lt;/code&gt; 已经 &lt;code&gt;None&lt;/code&gt; ），自动配料被禁用。从 &lt;code&gt;dataset&lt;/code&gt; 获得的每个样本都将作为 &lt;code&gt;collate_fn&lt;/code&gt; 参数传递的函数进行处理。</target>
        </trans-unit>
        <trans-unit id="83b686ad466f2edcefa11e742fdd44b512b0dd23" translate="yes" xml:space="preserve">
          <source>When called in a worker, this returns an object guaranteed to have the following attributes:</source>
          <target state="translated">当在worker中调用时,这将返回一个保证具有以下属性的对象。</target>
        </trans-unit>
        <trans-unit id="b6402d4d143ce0d83ed8c31ca1e7c6b83b35fb53" translate="yes" xml:space="preserve">
          <source>When called in the main process, this returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">在主流程中调用时，此方法返回 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bc06fbb059ebdabdac77c068a81b8512376f9ddd" translate="yes" xml:space="preserve">
          <source>When called with &lt;code&gt;dims&lt;/code&gt; of the list form, the given dimensions will be contracted in place of the last</source>
          <target state="translated">当以列表形式的 &lt;code&gt;dims&lt;/code&gt; 形式调用时，给定的尺寸将收缩，而不是最后一个尺寸</target>
        </trans-unit>
        <trans-unit id="8f0991d5226cadceec16a5e2277a3d90d9a71503" translate="yes" xml:space="preserve">
          <source>When called with a non-negative integer argument &lt;code&gt;dims&lt;/code&gt; =</source>
          <target state="translated">当使用非负整数参数调用时， &lt;code&gt;dims&lt;/code&gt; =</target>
        </trans-unit>
        <trans-unit id="6abce014373fbb8ba1a8a6700a958f442096752d" translate="yes" xml:space="preserve">
          <source>When combined with TorchScript decorators, this decorator must be the outmost one.</source>
          <target state="translated">当与TorchScript装饰器组合时,这个装饰器必须是最多的一个。</target>
        </trans-unit>
        <trans-unit id="01692078c2de1ab235032349659ea1bad48180a7" translate="yes" xml:space="preserve">
          <source>When combined with static or class method, this decorator must be the inner one.</source>
          <target state="translated">当与静态方法或类方法结合时,这个装饰符必须是内部的。</target>
        </trans-unit>
        <trans-unit id="02e71c552b6cfbf5a63e34935049e68d7d217f7f" translate="yes" xml:space="preserve">
          <source>When creating a new &lt;a href=&quot;#torch.autograd.Function&quot;&gt;&lt;code&gt;Function&lt;/code&gt;&lt;/a&gt;, the following methods are available to &lt;code&gt;ctx&lt;/code&gt;.</source>
          <target state="translated">创建新&lt;a href=&quot;#torch.autograd.Function&quot;&gt; &lt;code&gt;Function&lt;/code&gt; &lt;/a&gt;， &lt;code&gt;ctx&lt;/code&gt; 可使用以下方法。</target>
        </trans-unit>
        <trans-unit id="24460dec44dc8e232523a0b3b6cffc083f18ab5b" translate="yes" xml:space="preserve">
          <source>When data is a tensor &lt;code&gt;x&lt;/code&gt;, &lt;a href=&quot;#torch.Tensor.new_tensor&quot;&gt;&lt;code&gt;new_tensor()&lt;/code&gt;&lt;/a&gt; reads out &amp;lsquo;the data&amp;rsquo; from whatever it is passed, and constructs a leaf variable. Therefore &lt;code&gt;tensor.new_tensor(x)&lt;/code&gt; is equivalent to &lt;code&gt;x.clone().detach()&lt;/code&gt; and &lt;code&gt;tensor.new_tensor(x, requires_grad=True)&lt;/code&gt; is equivalent to &lt;code&gt;x.clone().detach().requires_grad_(True)&lt;/code&gt;. The equivalents using &lt;code&gt;clone()&lt;/code&gt; and &lt;code&gt;detach()&lt;/code&gt; are recommended.</source>
          <target state="translated">当数据是张量 &lt;code&gt;x&lt;/code&gt; 时，&lt;a href=&quot;#torch.Tensor.new_tensor&quot;&gt; &lt;code&gt;new_tensor()&lt;/code&gt; &lt;/a&gt;从传递的任何数据中读出&amp;ldquo;数据&amp;rdquo;，并构造一个叶子变量。因此 &lt;code&gt;tensor.new_tensor(x)&lt;/code&gt; 等同于 &lt;code&gt;x.clone().detach()&lt;/code&gt; 而 &lt;code&gt;tensor.new_tensor(x, requires_grad=True)&lt;/code&gt; 等同于 &lt;code&gt;x.clone().detach().requires_grad_(True)&lt;/code&gt; 。推荐使用 &lt;code&gt;clone()&lt;/code&gt; 和 &lt;code&gt;detach()&lt;/code&gt; 的等效项。</target>
        </trans-unit>
        <trans-unit id="44313813a50d98d5898f4bddc561c8a3109b1400" translate="yes" xml:space="preserve">
          <source>When data is a tensor &lt;code&gt;x&lt;/code&gt;, &lt;a href=&quot;#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt; reads out &amp;lsquo;the data&amp;rsquo; from whatever it is passed, and constructs a leaf variable. Therefore &lt;code&gt;torch.tensor(x)&lt;/code&gt; is equivalent to &lt;code&gt;x.clone().detach()&lt;/code&gt; and &lt;code&gt;torch.tensor(x, requires_grad=True)&lt;/code&gt; is equivalent to &lt;code&gt;x.clone().detach().requires_grad_(True)&lt;/code&gt;. The equivalents using &lt;code&gt;clone()&lt;/code&gt; and &lt;code&gt;detach()&lt;/code&gt; are recommended.</source>
          <target state="translated">当数据是张量 &lt;code&gt;x&lt;/code&gt; 时，&lt;a href=&quot;#torch.tensor&quot;&gt; &lt;code&gt;torch.tensor()&lt;/code&gt; &lt;/a&gt;从传递的任何数据中读取&amp;ldquo;数据&amp;rdquo;，并构造一个叶子变量。因此， &lt;code&gt;torch.tensor(x)&lt;/code&gt; 等效于 &lt;code&gt;x.clone().detach()&lt;/code&gt; 并且 &lt;code&gt;torch.tensor(x, requires_grad=True)&lt;/code&gt; 等效于 &lt;code&gt;x.clone().detach().requires_grad_(True)&lt;/code&gt; 。推荐使用 &lt;code&gt;clone()&lt;/code&gt; 和 &lt;code&gt;detach()&lt;/code&gt; 的等效项。</target>
        </trans-unit>
        <trans-unit id="4d87a694539e44d9bb0922817749f14565db02a2" translate="yes" xml:space="preserve">
          <source>When drawn without replacement, &lt;code&gt;num_samples&lt;/code&gt; must be lower than number of non-zero elements in &lt;code&gt;input&lt;/code&gt; (or the min number of non-zero elements in each row of &lt;code&gt;input&lt;/code&gt; if it is a matrix).</source>
          <target state="translated">当不需更换绘制， &lt;code&gt;num_samples&lt;/code&gt; 必须大于非零中的元素数目较低 &lt;code&gt;input&lt;/code&gt; （或分钟数的每行中非零元素的 &lt;code&gt;input&lt;/code&gt; ，如果它是一个矩阵）。</target>
        </trans-unit>
        <trans-unit id="0bdf0c7df4d55ef87659ffa5921e0c1608596af5" translate="yes" xml:space="preserve">
          <source>When entering an autocast-enabled region, Tensors may be any type. You should not call &lt;code&gt;.half()&lt;/code&gt; on your model(s) or inputs when using autocasting.</source>
          <target state="translated">进入启用自动广播的区域时，张量可以是任何类型。使用自动广播时，请勿在模型或输入上调用 &lt;code&gt;.half()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="52b1d0543e21755317d78418469b43a9d3b74143" translate="yes" xml:space="preserve">
          <source>When fetching from &lt;a href=&quot;#iterable-style-datasets&quot;&gt;iterable-style datasets&lt;/a&gt; with &lt;a href=&quot;#multi-process-data-loading&quot;&gt;multi-processing&lt;/a&gt;, the &lt;code&gt;drop_last&lt;/code&gt; argument drops the last non-full batch of each worker&amp;rsquo;s dataset replica.</source>
          <target state="translated">从具有&lt;a href=&quot;#multi-process-data-loading&quot;&gt;多个处理的&lt;/a&gt;&lt;a href=&quot;#iterable-style-datasets&quot;&gt;可迭代样式的数据集中&lt;/a&gt;获取数据时， &lt;code&gt;drop_last&lt;/code&gt; 参数将删除每个工作人员的数据集副本的最后一个非完整批次。</target>
        </trans-unit>
        <trans-unit id="aeab232209859fdb56ecfdd5e27289109b3779cd" translate="yes" xml:space="preserve">
          <source>When given an image of &lt;code&gt;Channels x Height x Width&lt;/code&gt;, it will apply &lt;code&gt;Softmax&lt;/code&gt; to each location</source>
          <target state="translated">给定 &lt;code&gt;Channels x Height x Width&lt;/code&gt; 的图像时，它将对每个位置应用 &lt;code&gt;Softmax&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="722286111baf501df8f66886a8878dbc93c4e6e4" translate="yes" xml:space="preserve">
          <source>When last_epoch=-1, sets initial lr as lr. Notice that because the schedule is defined recursively, the learning rate can be simultaneously modified outside this scheduler by other operators. If the learning rate is set solely by this scheduler, the learning rate at each step becomes:</source>
          <target state="translated">当last_epoch=-1时,设置初始lr为lr。注意,由于这个调度器是递归定义的,所以学习率可以在这个调度器之外同时被其他运算符修改。如果学习率仅由这个调度器设置,那么每一步的学习率就变成。</target>
        </trans-unit>
        <trans-unit id="9635ed5ff58b5f10f0a861bfe4da315b19a3d9ec" translate="yes" xml:space="preserve">
          <source>When manually importing this backend and invoking &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt;&lt;/a&gt; with the corresponding backend name, the &lt;code&gt;torch.distributed&lt;/code&gt; package runs on the new backend.</source>
          <target state="translated">手动导入&lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt; &lt;/a&gt;并调用具有相应后端名称的torch.distributed.init_process_group（）时， &lt;code&gt;torch.distributed&lt;/code&gt; 程序包将在新后端上运行。</target>
        </trans-unit>
        <trans-unit id="6c58952c2db520eb2d0c000e5b5179ffccb22124" translate="yes" xml:space="preserve">
          <source>When passed to the &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;torch.jit.script&lt;/code&gt;&lt;/a&gt; function, a &lt;code&gt;torch.nn.Module&lt;/code&gt;&amp;rsquo;s data is copied to a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; and the TorchScript compiler compiles the module. The module&amp;rsquo;s &lt;code&gt;forward&lt;/code&gt; is compiled by default. Methods called from &lt;code&gt;forward&lt;/code&gt; are lazily compiled in the order they are used in &lt;code&gt;forward&lt;/code&gt;, as well as any &lt;code&gt;@torch.jit.export&lt;/code&gt; methods.</source>
          <target state="translated">传递到&lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;torch.jit.script&lt;/code&gt; &lt;/a&gt;函数后， &lt;code&gt;torch.nn.Module&lt;/code&gt; 的数据将复制到&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 中&lt;/a&gt;，然后TorchScript编译器将编译该模块。默认情况下，模块的 &lt;code&gt;forward&lt;/code&gt; 编译。方法从所谓的 &lt;code&gt;forward&lt;/code&gt; 在他们所使用的顺序编译懒洋洋地 &lt;code&gt;forward&lt;/code&gt; ，以及任何 &lt;code&gt;@torch.jit.export&lt;/code&gt; 方法。</target>
        </trans-unit>
        <trans-unit id="98975218294f0d2cf1d9e027d0c9f18c335eccc0" translate="yes" xml:space="preserve">
          <source>When running on CUDA, &lt;code&gt;row * col&lt;/code&gt; must be less than</source>
          <target state="translated">在CUDA上运行时， &lt;code&gt;row * col&lt;/code&gt; 必须小于</target>
        </trans-unit>
        <trans-unit id="6442e147505eb082b7d915b41a9300ebc0cdaab5" translate="yes" xml:space="preserve">
          <source>When scale_factor is specified, if recompute_scale_factor=True, scale_factor is used to compute the output_size which will then be used to infer new scales for the interpolation. The default behavior for recompute_scale_factor changed to False in 1.6.0, and scale_factor is used in the interpolation calculation.</source>
          <target state="translated">当指定了scale_factor时,如果recompute_scale_factor=True,scale_factor将被用来计算output_size,然后用来推断新的尺度进行内插。在1.6.0中,recompute_scale_factor的默认行为改为False,scale_factor被用于内插计算。</target>
        </trans-unit>
        <trans-unit id="6134dc991dfe53224afc4b25750c288358d06db2" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;divisor&lt;/code&gt; tensor contains no zero elements, then &lt;code&gt;fold&lt;/code&gt; and &lt;code&gt;unfold&lt;/code&gt; operations are inverses of each other (up to constant divisor).</source>
          <target state="translated">当 &lt;code&gt;divisor&lt;/code&gt; 张量不包含零元素时， &lt;code&gt;fold&lt;/code&gt; 和 &lt;code&gt;unfold&lt;/code&gt; 操作是彼此相反的（直到恒定的除数）。</target>
        </trans-unit>
        <trans-unit id="ea57553addc94dbd66c0aab4dca41d371d835f2e" translate="yes" xml:space="preserve">
          <source>When the dtypes of inputs to an arithmetic operation (&lt;code&gt;add&lt;/code&gt;, &lt;code&gt;sub&lt;/code&gt;, &lt;code&gt;div&lt;/code&gt;, &lt;code&gt;mul&lt;/code&gt;) differ, we promote by finding the minimum dtype that satisfies the following rules:</source>
          <target state="translated">当算术运算的输入dtypes（ &lt;code&gt;add&lt;/code&gt; ， &lt;code&gt;sub&lt;/code&gt; ， &lt;code&gt;div&lt;/code&gt; ， &lt;code&gt;mul&lt;/code&gt; ）不同时，我们通过找到满足以下规则的最小dtype来进行提升：</target>
        </trans-unit>
        <trans-unit id="b36d5c15d9cebdd9841a3cbecf930ef5be3e8fb3" translate="yes" xml:space="preserve">
          <source>When the input Tensor is a sparse tensor then the unspecifed values are treated as &lt;code&gt;-inf&lt;/code&gt;.</source>
          <target state="translated">当输入Tensor是稀疏张量时，未指定的值将被视为 &lt;code&gt;-inf&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0306aa2f6b60a04c04ba2bb3e8bec0e8ed79e4a2" translate="yes" xml:space="preserve">
          <source>When the probability density function is differentiable with respect to its parameters, we only need &lt;code&gt;sample()&lt;/code&gt; and &lt;code&gt;log_prob()&lt;/code&gt; to implement REINFORCE:</source>
          <target state="translated">当概率密度函数的参数可区分时，我们仅需要 &lt;code&gt;sample()&lt;/code&gt; 和 &lt;code&gt;log_prob()&lt;/code&gt; 即可实现REINFORCE：</target>
        </trans-unit>
        <trans-unit id="adc8c2e11d80dad257b6a86b35591121148d959c" translate="yes" xml:space="preserve">
          <source>When the shapes do not match, the shape of &lt;a href=&quot;torch.mean#torch.mean&quot;&gt;&lt;code&gt;mean&lt;/code&gt;&lt;/a&gt; is used as the shape for the returned output tensor</source>
          <target state="translated">当形状不匹配时，将&lt;a href=&quot;torch.mean#torch.mean&quot;&gt; &lt;code&gt;mean&lt;/code&gt; &lt;/a&gt;形状用作返回的输出张量的形状</target>
        </trans-unit>
        <trans-unit id="0836fba3472a07dd87c4cfcc80c3a0f1b5a7eda0" translate="yes" xml:space="preserve">
          <source>When used in a &lt;code&gt;worker_init_fn&lt;/code&gt; passed over to &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt;, this method can be useful to set up each worker process differently, for instance, using &lt;code&gt;worker_id&lt;/code&gt; to configure the &lt;code&gt;dataset&lt;/code&gt; object to only read a specific fraction of a sharded dataset, or use &lt;code&gt;seed&lt;/code&gt; to seed other libraries used in dataset code (e.g., NumPy).</source>
          <target state="translated">在传递给&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;worker_init_fn&lt;/code&gt; 中使用时，此方法可用于不同地设置每个工作进程，例如，使用 &lt;code&gt;worker_id&lt;/code&gt; 将 &lt;code&gt;dataset&lt;/code&gt; 对象配置为仅读取分片数据集的特定部分，或使用 &lt;code&gt;seed&lt;/code&gt; 为其他种子设定种子数据集代码中使用的库（例如NumPy）。</target>
        </trans-unit>
        <trans-unit id="7a635c724cadbffe9cd8e217f6606360c059e6c0" translate="yes" xml:space="preserve">
          <source>When using &lt;a href=&quot;#torch.utils.cpp_extension.BuildExtension&quot;&gt;&lt;code&gt;BuildExtension&lt;/code&gt;&lt;/a&gt;, it is allowed to supply a dictionary for &lt;code&gt;extra_compile_args&lt;/code&gt; (rather than the usual list) that maps from languages (&lt;code&gt;cxx&lt;/code&gt; or &lt;code&gt;nvcc&lt;/code&gt;) to a list of additional compiler flags to supply to the compiler. This makes it possible to supply different flags to the C++ and CUDA compiler during mixed compilation.</source>
          <target state="translated">使用&lt;a href=&quot;#torch.utils.cpp_extension.BuildExtension&quot;&gt; &lt;code&gt;BuildExtension&lt;/code&gt; 时&lt;/a&gt;，可以提供 &lt;code&gt;extra_compile_args&lt;/code&gt; 的字典（而不是通常的列表），该字典从语言（ &lt;code&gt;cxx&lt;/code&gt; 或 &lt;code&gt;nvcc&lt;/code&gt; ）映射到其他编译器标志列表，以提供给编译器。这样就可以在混合编译期间向C ++和CUDA编译器提供不同的标志。</target>
        </trans-unit>
        <trans-unit id="eb9c51be75e99cadf6963fd3f79e89b1c37968c6" translate="yes" xml:space="preserve">
          <source>When using an &lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt;&lt;code&gt;IterableDataset&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;#multi-process-data-loading&quot;&gt;multi-process data loading&lt;/a&gt;. The same dataset object is replicated on each worker process, and thus the replicas must be configured differently to avoid duplicated data. See &lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt;&lt;code&gt;IterableDataset&lt;/code&gt;&lt;/a&gt; documentations for how to achieve this.</source>
          <target state="translated">在将&lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt; &lt;code&gt;IterableDataset&lt;/code&gt; &lt;/a&gt;用于&lt;a href=&quot;#multi-process-data-loading&quot;&gt;多进程数据加载时&lt;/a&gt;。在每个工作进程上都复制相同的数据集对象，因此必须对副本进行不同的配置，以避免重复的数据。有关如何实现此目的，请参阅&lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt; &lt;code&gt;IterableDataset&lt;/code&gt; &lt;/a&gt;文档。</target>
        </trans-unit>
        <trans-unit id="7635dd8102bfabbafa2a3b5c97436e5cb54d9ba1" translate="yes" xml:space="preserve">
          <source>When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/randomness.html&quot;&gt;Reproducibility&lt;/a&gt; for background.</source>
          <target state="translated">当使用CUDA后端时，此操作可能会在其向后传递中引起不确定的行为，这种行为很难关闭。请参阅有关可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/randomness.html&quot;&gt;重现性&lt;/a&gt;的说明作为背景。</target>
        </trans-unit>
        <trans-unit id="54dc7a473943cf2733a6d4da75adee3f4a210bcf" translate="yes" xml:space="preserve">
          <source>When viewing a profile created using &lt;a href=&quot;#torch.autograd.profiler.emit_nvtx&quot;&gt;&lt;code&gt;emit_nvtx&lt;/code&gt;&lt;/a&gt; in the Nvidia Visual Profiler, correlating each backward-pass op with the corresponding forward-pass op can be difficult. To ease this task, &lt;a href=&quot;#torch.autograd.profiler.emit_nvtx&quot;&gt;&lt;code&gt;emit_nvtx&lt;/code&gt;&lt;/a&gt; appends sequence number information to the ranges it generates.</source>
          <target state="translated">当在Nvidia Visual Profiler中查看使用&lt;a href=&quot;#torch.autograd.profiler.emit_nvtx&quot;&gt; &lt;code&gt;emit_nvtx&lt;/code&gt; &lt;/a&gt;创建的配置文件时，将每个后向操作与相应的前向操作关联起来可能很困难。为了简化此任务，&lt;a href=&quot;#torch.autograd.profiler.emit_nvtx&quot;&gt; &lt;code&gt;emit_nvtx&lt;/code&gt; &lt;/a&gt;将序列号信息附加到它生成的范围中。</target>
        </trans-unit>
        <trans-unit id="79561f3cf985a5e4719b8247ff531adef7e29706" translate="yes" xml:space="preserve">
          <source>When writing TorchScript directly using &lt;code&gt;@torch.jit.script&lt;/code&gt; decorator, the programmer must only use the subset of Python supported in TorchScript. This section documents what is supported in TorchScript as if it were a language reference for a stand alone language. Any features of Python not mentioned in this reference are not part of TorchScript. See &lt;code&gt;Builtin Functions&lt;/code&gt; for a complete reference of available Pytorch tensor methods, modules, and functions.</source>
          <target state="translated">使用 &lt;code&gt;@torch.jit.script&lt;/code&gt; 装饰器直接编写TorchScript时，程序员必须仅使用TorchScript支持的Python子集。本节记录了TorchScript支持的功能，就像它是独立语言的语言参考一样。本参考中未提及的Python的任何功能都不是TorchScript的一部分。有关可用的Pytorch张量方法，模块和功能的完整参考，请参见 &lt;code&gt;Builtin Functions&lt;/code&gt; 函数。</target>
        </trans-unit>
        <trans-unit id="50bf66ea03e8d3f7a8a4f3f33c0d423a99cbb251" translate="yes" xml:space="preserve">
          <source>When you call &lt;a href=&quot;#torch.load&quot;&gt;&lt;code&gt;torch.load()&lt;/code&gt;&lt;/a&gt; on a file which contains GPU tensors, those tensors will be loaded to GPU by default. You can call &lt;code&gt;torch.load(.., map_location='cpu')&lt;/code&gt; and then &lt;code&gt;load_state_dict()&lt;/code&gt; to avoid GPU RAM surge when loading a model checkpoint.</source>
          <target state="translated">当您在包含GPU张量的文件上调用&lt;a href=&quot;#torch.load&quot;&gt; &lt;code&gt;torch.load()&lt;/code&gt; &lt;/a&gt;时，默认情况下，这些张量将被加载到GPU。您可以先调用 &lt;code&gt;torch.load(.., map_location='cpu')&lt;/code&gt; ，然后 &lt;code&gt;load_state_dict()&lt;/code&gt; 以避免在加载模型检查点时GPU RAM激增。</target>
        </trans-unit>
        <trans-unit id="d4b9a73359398be175a62d4f2cbf23eca1eb7394" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;n = prod(s)&lt;/code&gt; is the logical FFT size. Calling the backward transform (&lt;a href=&quot;#torch.fft.ifftn&quot;&gt;&lt;code&gt;ifftn()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.ifftn&quot;&gt;&lt;code&gt;ifftn()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="translated">其中 &lt;code&gt;n = prod(s)&lt;/code&gt; 是逻辑FFT大小。以相同的归一化模式调用后向变换（&lt;a href=&quot;#torch.fft.ifftn&quot;&gt; &lt;code&gt;ifftn()&lt;/code&gt; &lt;/a&gt;）将在两个变换之间应用 &lt;code&gt;1/n&lt;/code&gt; 的总体归一化。这是使&lt;a href=&quot;#torch.fft.ifftn&quot;&gt; &lt;code&gt;ifftn()&lt;/code&gt; &lt;/a&gt;完全相反的要求。</target>
        </trans-unit>
        <trans-unit id="540833bd1b024f45b94c5fe10bdcce398da41e2a" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;n = prod(s)&lt;/code&gt; is the logical FFT size. Calling the backward transform (&lt;a href=&quot;#torch.fft.irfftn&quot;&gt;&lt;code&gt;irfftn()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.irfftn&quot;&gt;&lt;code&gt;irfftn()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="translated">其中 &lt;code&gt;n = prod(s)&lt;/code&gt; 是逻辑FFT大小。以相同的归一化模式调用后向变换（&lt;a href=&quot;#torch.fft.irfftn&quot;&gt; &lt;code&gt;irfftn()&lt;/code&gt; &lt;/a&gt;）将在两个变换之间应用 &lt;code&gt;1/n&lt;/code&gt; 的总体归一化。这是使&lt;a href=&quot;#torch.fft.irfftn&quot;&gt; &lt;code&gt;irfftn()&lt;/code&gt; &lt;/a&gt;完全相反的要求。</target>
        </trans-unit>
        <trans-unit id="4fa609678777cb0f1d2bea5c36804f3e7f699ab3" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;n = prod(s)&lt;/code&gt; is the logical IFFT size. Calling the forward transform (&lt;a href=&quot;#torch.fft.fftn&quot;&gt;&lt;code&gt;fftn()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.ifftn&quot;&gt;&lt;code&gt;ifftn()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="translated">其中 &lt;code&gt;n = prod(s)&lt;/code&gt; 是逻辑IFFT大小。以相同的归一化模式调用前向变换（&lt;a href=&quot;#torch.fft.fftn&quot;&gt; &lt;code&gt;fftn()&lt;/code&gt; &lt;/a&gt;）将在两个变换之间应用 &lt;code&gt;1/n&lt;/code&gt; 的总体归一化。这是使&lt;a href=&quot;#torch.fft.ifftn&quot;&gt; &lt;code&gt;ifftn()&lt;/code&gt; &lt;/a&gt;完全相反的要求。</target>
        </trans-unit>
        <trans-unit id="983301015460563605882b2d43f60b6f31ca13f7" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;n = prod(s)&lt;/code&gt; is the logical IFFT size. Calling the forward transform (&lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.irfftn&quot;&gt;&lt;code&gt;irfftn()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="translated">其中 &lt;code&gt;n = prod(s)&lt;/code&gt; 是逻辑IFFT大小。以相同的归一化模式调用前向变换（&lt;a href=&quot;#torch.fft.rfftn&quot;&gt; &lt;code&gt;rfftn()&lt;/code&gt; &lt;/a&gt;）将在两个变换之间应用 &lt;code&gt;1/n&lt;/code&gt; 的总体归一化。这是使&lt;a href=&quot;#torch.fft.irfftn&quot;&gt; &lt;code&gt;irfftn()&lt;/code&gt; &lt;/a&gt;完全相反的要求。</target>
        </trans-unit>
        <trans-unit id="dcabf659c01386b96c4252ad5247bb9f50b66574" translate="yes" xml:space="preserve">
          <source>Where are my downloaded models saved?</source>
          <target state="translated">我下载的模型保存在哪里?</target>
        </trans-unit>
        <trans-unit id="017d4a3464bb8236ca4dfe2a53c2f262d76de8ab" translate="yes" xml:space="preserve">
          <source>Which backend to use?</source>
          <target state="translated">用哪个后台?</target>
        </trans-unit>
        <trans-unit id="3631991286d3139c1de9a41ef4982f8e5d886ce2" translate="yes" xml:space="preserve">
          <source>Which produces:</source>
          <target state="translated">这就产生了:</target>
        </trans-unit>
        <trans-unit id="a68a67a970d91d390715c4a5723442211582200e" translate="yes" xml:space="preserve">
          <source>While Loops</source>
          <target state="translated">While Loops</target>
        </trans-unit>
        <trans-unit id="48f3d5bde3297b3b923d0f7759d754056d7f6c40" translate="yes" xml:space="preserve">
          <source>While it is assumed that &lt;code&gt;A&lt;/code&gt; is symmetric, &lt;code&gt;A.grad&lt;/code&gt; is not. To make sure that &lt;code&gt;A.grad&lt;/code&gt; is symmetric, so that &lt;code&gt;A - t * A.grad&lt;/code&gt; is symmetric in first-order optimization routines, prior to running &lt;code&gt;lobpcg&lt;/code&gt; we do the following symmetrization map: &lt;code&gt;A -&amp;gt; (A + A.t()) / 2&lt;/code&gt;. The map is performed only when the &lt;code&gt;A&lt;/code&gt; requires gradients.</source>
          <target state="translated">虽然假定 &lt;code&gt;A&lt;/code&gt; 是对称的，但 &lt;code&gt;A.grad&lt;/code&gt; 不是。为了确保 &lt;code&gt;A.grad&lt;/code&gt; 是对称的，以便 &lt;code&gt;A - t * A.grad&lt;/code&gt; 在一阶优化例程中是对称的，在运行 &lt;code&gt;lobpcg&lt;/code&gt; 之前，我们执行以下对称化映射： &lt;code&gt;A -&amp;gt; (A + A.t()) / 2&lt;/code&gt; 。仅当 &lt;code&gt;A&lt;/code&gt; 需要渐变时才执行贴图。</target>
        </trans-unit>
        <trans-unit id="f69597c76f979c6f47613f7588234a4093ae500a" translate="yes" xml:space="preserve">
          <source>While it should always give you a valid decomposition, it may not give you the same one across platforms - it will depend on your LAPACK implementation.</source>
          <target state="translated">虽然它应该总是给你一个有效的分解,但在不同的平台上它可能不会给你相同的分解--这将取决于你的LAPACK实现。</target>
        </trans-unit>
        <trans-unit id="90f928cf1ec6eb30bffa5d56a4ee00f33a26ccf6" translate="yes" xml:space="preserve">
          <source>While mathematically equivalent to log(softmax(x)), doing these two operations separately is slower, and numerically unstable. This function uses an alternative formulation to compute the output and gradient correctly.</source>
          <target state="translated">虽然在数学上等同于 log(softmax(x)),但分别进行这两个运算速度较慢,而且在数值上不稳定。这个函数使用另一种公式来正确计算输出和梯度。</target>
        </trans-unit>
        <trans-unit id="adfc4c1cf043279d74d69b96592d62572f9a8648" translate="yes" xml:space="preserve">
          <source>Wide ResNet</source>
          <target state="translated">广泛的ResNet</target>
        </trans-unit>
        <trans-unit id="eec7e605ef42b4a1da3f9a4494e1414462efb313" translate="yes" xml:space="preserve">
          <source>Wide ResNet-101-2</source>
          <target state="translated">Wide ResNet-101-2</target>
        </trans-unit>
        <trans-unit id="ac86db1353b797ed1c0d73605a56146ab6cb1914" translate="yes" xml:space="preserve">
          <source>Wide ResNet-101-2 model from &lt;a href=&quot;https://arxiv.org/pdf/1605.07146.pdf&quot;&gt;&amp;ldquo;Wide Residual Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">来自&lt;a href=&quot;https://arxiv.org/pdf/1605.07146.pdf&quot;&gt;&amp;ldquo;广泛残留网络&amp;rdquo;的&lt;/a&gt;广泛ResNet-101-2模型</target>
        </trans-unit>
        <trans-unit id="b631c349f7132ef6c2a8879b09c961b30fce8aba" translate="yes" xml:space="preserve">
          <source>Wide ResNet-50-2</source>
          <target state="translated">广义ResNet-50-2</target>
        </trans-unit>
        <trans-unit id="726f31b3e4c15ecbbc898cae3f9e8f73a3460020" translate="yes" xml:space="preserve">
          <source>Wide ResNet-50-2 model from &lt;a href=&quot;https://arxiv.org/pdf/1605.07146.pdf&quot;&gt;&amp;ldquo;Wide Residual Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">来自&lt;a href=&quot;https://arxiv.org/pdf/1605.07146.pdf&quot;&gt;&amp;ldquo;广泛残留网络&amp;rdquo;的&lt;/a&gt;广泛ResNet-50-2模型</target>
        </trans-unit>
        <trans-unit id="d2b826d3f7d8e2201135c671569ea283afb245af" translate="yes" xml:space="preserve">
          <source>Will result in:</source>
          <target state="translated">将导致。</target>
        </trans-unit>
        <trans-unit id="8fa871c4385dea4733bc80aea73b5f5364e4ef06" translate="yes" xml:space="preserve">
          <source>Windows FAQ</source>
          <target state="translated">窗口常见问题</target>
        </trans-unit>
        <trans-unit id="8ac66d0e68a85c8d292fec91f6cbcf0bd809b4e9" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;align_corners = True&lt;/code&gt;, the linearly interpolating modes (&lt;code&gt;bilinear&lt;/code&gt;) don&amp;rsquo;t proportionally align the output and input pixels, and thus the output values can depend on the input size. This was the default behavior for these modes up to version 0.3.1. Since then, the default behavior is &lt;code&gt;align_corners = False&lt;/code&gt;. See &lt;a href=&quot;generated/torch.nn.upsample#torch.nn.Upsample&quot;&gt;&lt;code&gt;Upsample&lt;/code&gt;&lt;/a&gt; for concrete examples on how this affects the outputs.</source>
          <target state="translated">如果 &lt;code&gt;align_corners = True&lt;/code&gt; ，则线性插值模式（ &lt;code&gt;bilinear&lt;/code&gt; ）不会按比例对齐输出像素和输入像素，因此输出值可能取决于输入大小。这是这些模式（0.3.1版之前）的默认行为。从那时起，默认行为是 &lt;code&gt;align_corners = False&lt;/code&gt; 。有关如何影响输出的具体示例，请参见上&lt;a href=&quot;generated/torch.nn.upsample#torch.nn.Upsample&quot;&gt; &lt;code&gt;Upsample&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="05c8bfe5d3e24898d75d1b114e7f0550313f9961" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;align_corners = True&lt;/code&gt;, the linearly interpolating modes (&lt;code&gt;linear&lt;/code&gt;, &lt;code&gt;bilinear&lt;/code&gt;, &lt;code&gt;bicubic&lt;/code&gt;, and &lt;code&gt;trilinear&lt;/code&gt;) don&amp;rsquo;t proportionally align the output and input pixels, and thus the output values can depend on the input size. This was the default behavior for these modes up to version 0.3.1. Since then, the default behavior is &lt;code&gt;align_corners = False&lt;/code&gt;. See below for concrete examples on how this affects the outputs.</source>
          <target state="translated">在 &lt;code&gt;align_corners = True&lt;/code&gt; ，线性插值模式（ &lt;code&gt;linear&lt;/code&gt; ， &lt;code&gt;bilinear&lt;/code&gt; ， &lt;code&gt;bicubic&lt;/code&gt; 和 &lt;code&gt;trilinear&lt;/code&gt; ）不会按比例对齐输出像素和输入像素，因此输出值可能取决于输入大小。这是这些模式（0.3.1版之前）的默认行为。从那时起，默认行为是 &lt;code&gt;align_corners = False&lt;/code&gt; 。有关如何影响输出的具体示例，请参见下文。</target>
        </trans-unit>
        <trans-unit id="9b1242167a707b16c47db2fe5f3c0130b4361833" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;align_corners = True&lt;/code&gt;, the linearly interpolating modes (&lt;code&gt;linear&lt;/code&gt;, &lt;code&gt;bilinear&lt;/code&gt;, and &lt;code&gt;trilinear&lt;/code&gt;) don&amp;rsquo;t proportionally align the output and input pixels, and thus the output values can depend on the input size. This was the default behavior for these modes up to version 0.3.1. Since then, the default behavior is &lt;code&gt;align_corners = False&lt;/code&gt;. See &lt;a href=&quot;generated/torch.nn.upsample#torch.nn.Upsample&quot;&gt;&lt;code&gt;Upsample&lt;/code&gt;&lt;/a&gt; for concrete examples on how this affects the outputs.</source>
          <target state="translated">如果 &lt;code&gt;align_corners = True&lt;/code&gt; ，则线性插值模式（ &lt;code&gt;linear&lt;/code&gt; ， &lt;code&gt;bilinear&lt;/code&gt; 和 &lt;code&gt;trilinear&lt;/code&gt; ）不会按比例对齐输出像素和输入像素，因此输出值可能取决于输入大小。这是这些模式（0.3.1版之前）的默认行为。从那时起，默认行为是 &lt;code&gt;align_corners = False&lt;/code&gt; 。有关如何影响输出的具体示例，请参见上&lt;a href=&quot;generated/torch.nn.upsample#torch.nn.Upsample&quot;&gt; &lt;code&gt;Upsample&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="343e3c563441d98e78b2af38a8ee16b2107d4b5b" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;mode='bicubic'&lt;/code&gt;, it&amp;rsquo;s possible to cause overshoot, in other words it can produce negative values or values greater than 255 for images. Explicitly call &lt;code&gt;result.clamp(min=0, max=255)&lt;/code&gt; if you want to reduce the overshoot when displaying the image.</source>
          <target state="translated">使用 &lt;code&gt;mode='bicubic'&lt;/code&gt; ，可能会导致过冲，换句话说，它可能会为图像生成负值或大于255的值。如果要减少显示图像时的过冲，请明确调用 &lt;code&gt;result.clamp(min=0, max=255)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="670f4308b71dfa44f0ce3d603252c9a80431b7a1" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;padding_idx&lt;/code&gt; set, the embedding vector at &lt;code&gt;padding_idx&lt;/code&gt; is initialized to all zeros. However, note that this vector can be modified afterwards, e.g., using a customized initialization method, and thus changing the vector used to pad the output. The gradient for this vector from &lt;a href=&quot;#torch.nn.Embedding&quot;&gt;&lt;code&gt;Embedding&lt;/code&gt;&lt;/a&gt; is always zero.</source>
          <target state="translated">随着 &lt;code&gt;padding_idx&lt;/code&gt; 集，在嵌入矢量 &lt;code&gt;padding_idx&lt;/code&gt; 被初始化为全零。但是，请注意，此向量可以在以后进行修改，例如，使用定制的初始化方法，从而更改用于填充输出的向量。来自&amp;ldquo;&lt;a href=&quot;#torch.nn.Embedding&quot;&gt; &lt;code&gt;Embedding&lt;/code&gt; &lt;/a&gt;矢量的梯度始终为零。</target>
        </trans-unit>
        <trans-unit id="245747fecda85d5b71d626b9e2eb04627690bcb2" translate="yes" xml:space="preserve">
          <source>With &lt;em&gt;trace-based&lt;/em&gt; exporter, we get the result ONNX graph which unrolls the for loop:</source>
          <target state="translated">使用&lt;em&gt;基于跟踪的&lt;/em&gt;导出器，我们得到的结果为ONNX图，该图展开了for循环：</target>
        </trans-unit>
        <trans-unit id="19fffb59deac1debbb0ed0b605bbe04aebbddb29" translate="yes" xml:space="preserve">
          <source>With the default arguments it uses the Euclidean norm over vectors along dimension</source>
          <target state="translated">使用默认参数时,它使用沿维度的向量上的欧氏法则</target>
        </trans-unit>
        <trans-unit id="6aa512cf7aad097706fd2890b5de1202e2c6a97c" translate="yes" xml:space="preserve">
          <source>Within a Python process, the &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;Global Interpreter Lock (GIL)&lt;/a&gt; prevents true fully parallelizing Python code across threads. To avoid blocking computation code with data loading, PyTorch provides an easy switch to perform multi-process data loading by simply setting the argument &lt;code&gt;num_workers&lt;/code&gt; to a positive integer.</source>
          <target state="translated">在Python进程中，&lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;全局解释器锁（GIL）&lt;/a&gt;防止跨线程真正地完全并行化Python代码。为了避免在加载数据时阻塞计算代码，PyTorch提供了一个简单的开关，只需将参数 &lt;code&gt;num_workers&lt;/code&gt; 设置为正整数即可执行多进程数据加载。</target>
        </trans-unit>
        <trans-unit id="67793521614b6b44f958c708ad8988aeadfd2309" translate="yes" xml:space="preserve">
          <source>Without specifying the output length to &lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;, the output will not round-trip properly because the input is odd-length in the last dimension:</source>
          <target state="translated">如果不将输出长度指定为&lt;a href=&quot;#torch.fft.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;，则输出将无法正确往返，因为输入的最后一个维度是奇数长度：</target>
        </trans-unit>
        <trans-unit id="4263d953681d9ae30565f30202d1492e42e9e8ac" translate="yes" xml:space="preserve">
          <source>Without specifying the output length to &lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;, the output will not round-trip properly because the input is odd-length:</source>
          <target state="translated">如果不将输出长度指定为&lt;a href=&quot;#torch.fft.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;，则输出将无法正确往返，因为输入的长度为奇数：</target>
        </trans-unit>
        <trans-unit id="2f5f94e39ac0f29eec4ef83cffba8ff93856c6cc" translate="yes" xml:space="preserve">
          <source>Workers are shut down once the end of the iteration is reached, or when the iterator becomes garbage collected.</source>
          <target state="translated">一旦达到迭代结束,或者迭代器变成垃圾收集器时,就会关闭工人。</target>
        </trans-unit>
        <trans-unit id="275f19f1f1857e51454ed2397868a56594f54c36" translate="yes" xml:space="preserve">
          <source>Working with &lt;code&gt;collate_fn&lt;/code&gt;</source>
          <target state="translated">使用 &lt;code&gt;collate_fn&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7322e6cb1692d568f796bae37f8f8678f8c44133" translate="yes" xml:space="preserve">
          <source>Wrap most of you main script&amp;rsquo;s code within &lt;code&gt;if __name__ == '__main__':&lt;/code&gt; block, to make sure it doesn&amp;rsquo;t run again (most likely generating error) when each worker process is launched. You can place your dataset and &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; instance creation logic here, as it doesn&amp;rsquo;t need to be re-executed in workers.</source>
          <target state="translated">&lt;code&gt;if __name__ == '__main__':&lt;/code&gt; 块，请将您的大部分主脚本代码包装起来，以确保在启动每个工作进程时它不会再次运行（很可能会产生错误）。您可以在此处放置数据集和&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;实例创建逻辑，因为它不需要在worker中重新执行。</target>
        </trans-unit>
        <trans-unit id="1ecad6be71c469e57d25325f17d76f3b6c7e6652" translate="yes" xml:space="preserve">
          <source>Wrap the leaf child module in QuantWrapper if it has a valid qconfig Note that this function will modify the children of module inplace and it can return a new module which wraps the input module as well.</source>
          <target state="translated">如果叶子模块有一个有效的qconfig,就用QuantWrapper包装它 注意,这个函数会修改模块的子模块的位置,也可以返回一个新的模块,把输入模块也包装起来。</target>
        </trans-unit>
        <trans-unit id="5375f310fdbbbaceba22e923b5eb13a5f74fab7f" translate="yes" xml:space="preserve">
          <source>Wrapper around a &lt;code&gt;torch._C.Future&lt;/code&gt; which encapsulates an asynchronous execution of a callable, e.g. &lt;a href=&quot;rpc#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt;. It also exposes a set of APIs to add callback functions and set results.</source>
          <target state="translated">围绕着 &lt;code&gt;torch._C.Future&lt;/code&gt; 的包装，该包装封装了可调用对象的异步执行，例如&lt;a href=&quot;rpc#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt;。它还公开了一组API，用于添加回调函数和设置结果。</target>
        </trans-unit>
        <trans-unit id="8df13c46adfe3a050db797a249e788f92b1e60e7" translate="yes" xml:space="preserve">
          <source>Wrapper around a CUDA event.</source>
          <target state="translated">围绕CUDA事件的封装器。</target>
        </trans-unit>
        <trans-unit id="821f73849dcef0ef5418016b1e5d009bb01173fa" translate="yes" xml:space="preserve">
          <source>Wrapper around a CUDA stream.</source>
          <target state="translated">围绕CUDA流的封装器。</target>
        </trans-unit>
        <trans-unit id="65acb3d4bdbad8b7e153886b6b2199ad76a756c8" translate="yes" xml:space="preserve">
          <source>Wrapper class for quantized operations.</source>
          <target state="translated">量化操作的封装类。</target>
        </trans-unit>
        <trans-unit id="8e2dfc8a3e67da8b6e1ca8fafe3e8afa2b3f0620" translate="yes" xml:space="preserve">
          <source>Wrapper that allows creation of class factories.</source>
          <target state="translated">允许创建类工厂的封装器。</target>
        </trans-unit>
        <trans-unit id="843c52018e11fda7799dc5989f496736df1f7d7b" translate="yes" xml:space="preserve">
          <source>Wraps another sampler to yield a mini-batch of indices.</source>
          <target state="translated">包裹另一个取样器,产生一批迷你的指数。</target>
        </trans-unit>
        <trans-unit id="2a31ffa99fd6d35b029d1f439707a5bd7c9b4da8" translate="yes" xml:space="preserve">
          <source>Writes all values from the tensor &lt;code&gt;src&lt;/code&gt; into &lt;code&gt;self&lt;/code&gt; at the indices specified in the &lt;code&gt;index&lt;/code&gt; tensor. For each value in &lt;code&gt;src&lt;/code&gt;, its output index is specified by its index in &lt;code&gt;src&lt;/code&gt; for &lt;code&gt;dimension != dim&lt;/code&gt; and by the corresponding value in &lt;code&gt;index&lt;/code&gt; for &lt;code&gt;dimension = dim&lt;/code&gt;.</source>
          <target state="translated">写入所有值从张量 &lt;code&gt;src&lt;/code&gt; 到 &lt;code&gt;self&lt;/code&gt; 在指定索引 &lt;code&gt;index&lt;/code&gt; 张量。对于中的每个值 &lt;code&gt;src&lt;/code&gt; ，它的输出索引由其在索引指定 &lt;code&gt;src&lt;/code&gt; 为 &lt;code&gt;dimension != dim&lt;/code&gt; 并且通过在相应的值 &lt;code&gt;index&lt;/code&gt; 为 &lt;code&gt;dimension = dim&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5adf3c6baa6091132b20eef0ff93f0984499afa5" translate="yes" xml:space="preserve">
          <source>Writes entries directly to event files in the log_dir to be consumed by TensorBoard.</source>
          <target state="translated">将条目直接写入log_dir中的事件文件,以便被TensorBoard消耗。</target>
        </trans-unit>
        <trans-unit id="c032adc1ff629c9b66f22749ad667e6beadf144b" translate="yes" xml:space="preserve">
          <source>X</source>
          <target state="translated">X</target>
        </trans-unit>
        <trans-unit id="29822901b44f81c6464586704f28915142f932bc" translate="yes" xml:space="preserve">
          <source>X (Tensor): tensor of eigenvectors of size</source>
          <target state="translated">X(张量):大小为特征向量的张量。</target>
        </trans-unit>
        <trans-unit id="030b21a9a5ef307806a06b78be434c1972173393" translate="yes" xml:space="preserve">
          <source>X[\omega_1, \dots, \omega_d] = X^*[N_1 - \omega_1, \dots, N_d - \omega_d],</source>
          <target state="translated">X[\omega_1,\dots,\omega_d]=X^*[N_1-\omega_1,\dots,N_d-\omega_d]。</target>
        </trans-unit>
        <trans-unit id="ed1d6f505827ea7067cb8c300c0904dbfa5fbd7a" translate="yes" xml:space="preserve">
          <source>X[\omega_1, \dots, \omega_d] = \frac{1}{\prod_{i=1}^d N_i} \sum_{n_1=0}^{N_1-1} \dots \sum_{n_d=0}^{N_d-1} x[n_1, \dots, n_d] e^{\ j\ 2 \pi \sum_{i=0}^d \frac{\omega_i n_i}{N_i}},</source>
          <target state="translated">X[\omega_1,\dots,\omega_d]=\frac{1}{\prod_{i=1}^d N_i}\sum_{n_1=0}^{N_1-1}\dots \sum_{n_d=0}^{N_d-1}x[n_1,\dots,n_d]e^{/j/2 \pi \sum_{i=0}^d \frac{\omega_i n_i}{N_i}}。</target>
        </trans-unit>
        <trans-unit id="746d94247ac643f86d1ee17dab642515e2ff9085" translate="yes" xml:space="preserve">
          <source>X[\omega_1, \dots, \omega_d] = \sum_{n_1=0}^{N_1-1} \dots \sum_{n_d=0}^{N_d-1} x[n_1, \dots, n_d] e^{-j\ 2 \pi \sum_{i=0}^d \frac{\omega_i n_i}{N_i}},</source>
          <target state="translated">X[\omega_1,\dots,\omega_d]=\sum_{n_1=0}^{N_1-1}\dots \sum_{n_d=0}^{N_d-1}x[n_1,\dots,n_d]e^{-j/2 \pi \sum_{i=0}^d \frac{\omega_i n_i}{N_i}}。</target>
        </trans-unit>
        <trans-unit id="a14f6ead4d7bc2b1f74caf9a0cc9b1f3d45fbb66" translate="yes" xml:space="preserve">
          <source>X[m, \omega] = X[m, \text{n\_fft} - \omega]^*</source>
          <target state="translated">X[m,\omega]=X[m,\text{n\fft}-\omega]^*</target>
        </trans-unit>
        <trans-unit id="4e6854a6a1b525f353a271b3c9b646d1b5c28d3f" translate="yes" xml:space="preserve">
          <source>X[m, \omega] = \sum_{k = 0}^{\text{win\_length-1}}% \text{window}[k]\ \text{input}[m \times \text{hop\_length} + k]\ % \exp\left(- j \frac{2 \pi \cdot \omega k}{\text{win\_length}}\right),</source>
          <target state="translated">X[m,\omega]=\sum_{k=0}^{text{win_length-1}}% \text{window}[k]\text{input}[m xtimes \text{hop_length}+k]% \expleft(-j \frac{2 \pi \cdot \omega k}{\text{win_length}}/right)。</target>
        </trans-unit>
        <trans-unit id="14ebad2cda6dcca683250b526859348822d9d5c8" translate="yes" xml:space="preserve">
          <source>Yes, this is supported now for ONNX opset version &amp;gt;= 11. E.g.:</source>
          <target state="translated">是的，&amp;gt; = 11的ONNX opset版本现在支持此功能。例如：</target>
        </trans-unit>
        <trans-unit id="5684cedf8d1212771db72a004af08859ca152372" translate="yes" xml:space="preserve">
          <source>Yes, this is supported now for ONNX opset version &amp;gt;= 11. ONNX introduced the concept of Sequence in opset 11. Similar to list, Sequence is a data type that contains arbitrary number of Tensors. Associated operators are also introduced in ONNX, such as SequenceInsert, SequenceAt, etc. However, in-place list append within loops is not exportable to ONNX. To implement this, please use inplace add operator. E.g.:</source>
          <target state="translated">是的，现在&amp;gt; = 11的ONNX opset版本支持此功能。ONNX在opset 11中引入了Sequence的概念。与list相似，Sequence是一种数据类型，其中包含任意数量的Tensor。ONNX中还引入了关联的运算符，例如SequenceInsert，SequenceAt等。但是，循环内的就地列表追加无法导出到ONNX。要实现这一点，请使用inplace add运算符。例如：</target>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="translated">Yields</target>
        </trans-unit>
        <trans-unit id="7c19fb2e314a3137e93fb758f531465aacc3456b" translate="yes" xml:space="preserve">
          <source>You can also construct hybrid sparse tensors, where only the first n dimensions are sparse, and the rest of the dimensions are dense.</source>
          <target state="translated">你也可以构造混合稀疏时子,其中只有前n个维度是稀疏的,其余维度是密集的。</target>
        </trans-unit>
        <trans-unit id="d617602dcc62272743d7a795be368e5ffbe5433d" translate="yes" xml:space="preserve">
          <source>You can also run the exported model with &lt;a href=&quot;https://github.com/microsoft/onnxruntime&quot;&gt;ONNX Runtime&lt;/a&gt;, you will need to install &lt;code&gt;ONNX Runtime&lt;/code&gt;: please &lt;a href=&quot;https://github.com/microsoft/onnxruntime#installation&quot;&gt;follow these instructions&lt;/a&gt;.</source>
          <target state="translated">您也可以使用&lt;a href=&quot;https://github.com/microsoft/onnxruntime&quot;&gt;ONNX Runtime&lt;/a&gt;运行导出的模型，您将需要安装 &lt;code&gt;ONNX Runtime&lt;/code&gt; ：请&lt;a href=&quot;https://github.com/microsoft/onnxruntime#installation&quot;&gt;按照以下说明进行操作&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="18be7e0f13bf0aca1a5c2348aa103f8bb566787e" translate="yes" xml:space="preserve">
          <source>You can also use cosine annealing to a fixed value instead of linear annealing by setting &lt;code&gt;anneal_strategy=&quot;cos&quot;&lt;/code&gt;.</source>
          <target state="translated">您还可以通过设置 &lt;code&gt;anneal_strategy=&quot;cos&quot;&lt;/code&gt; 将余弦退火用于固定值，而不是线性退火。</target>
        </trans-unit>
        <trans-unit id="c8c75fa187b181f202978d8a86ab28cca3e9eb36" translate="yes" xml:space="preserve">
          <source>You can also verify the protobuf using the &lt;a href=&quot;https://github.com/onnx/onnx/&quot;&gt;ONNX&lt;/a&gt; library. You can install &lt;code&gt;ONNX&lt;/code&gt; with conda:</source>
          <target state="translated">您还可以使用&lt;a href=&quot;https://github.com/onnx/onnx/&quot;&gt;ONNX&lt;/a&gt;库验证protobuf 。您可以使用 &lt;code&gt;ONNX&lt;/code&gt; 安装ONNX：</target>
        </trans-unit>
        <trans-unit id="ec539497ce517be7d2c9354eae2288ab7aed0f7d" translate="yes" xml:space="preserve">
          <source>You can construct a model with random weights by calling its constructor:</source>
          <target state="translated">你可以通过调用它的构造函数来构造一个具有随机权重的模型。</target>
        </trans-unit>
        <trans-unit id="1400fef33661543c72061ceed7d3f9e9ebc487ea" translate="yes" xml:space="preserve">
          <source>You can create your own registry by creating a new &lt;a href=&quot;#torch.distributions.constraint_registry.ConstraintRegistry&quot;&gt;&lt;code&gt;ConstraintRegistry&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">您可以通过创建新的&lt;a href=&quot;#torch.distributions.constraint_registry.ConstraintRegistry&quot;&gt; &lt;code&gt;ConstraintRegistry&lt;/code&gt; &lt;/a&gt;对象来创建自己的注册表。</target>
        </trans-unit>
        <trans-unit id="decdc18078675c119e9394b80151d2e753fa566c" translate="yes" xml:space="preserve">
          <source>You can still pass options as keyword arguments. They will be used as defaults, in the groups that didn&amp;rsquo;t override them. This is useful when you only want to vary a single option, while keeping all others consistent between parameter groups.</source>
          <target state="translated">您仍然可以将选项作为关键字参数传递。在未覆盖它们的组中，它们将用作默认值。当您只想改变一个选项，同时使所有其他参数在参数组之间保持一致时，这很有用。</target>
        </trans-unit>
        <trans-unit id="3431a2a1d98df776e7494a8e2a5ab89115af9a01" translate="yes" xml:space="preserve">
          <source>You can use both tensors and storages as arguments. If a given object is not allocated on a GPU, this is a no-op.</source>
          <target state="translated">你可以同时使用 tensors 和 storages 作为参数。如果一个给定的对象没有在GPU上分配,这就是一个无操作。</target>
        </trans-unit>
        <trans-unit id="cc736ac07ea8c62fb5b125af6be01955a2077643" translate="yes" xml:space="preserve">
          <source>You must either provide a value for total_steps or provide a value for both epochs and steps_per_epoch.</source>
          <target state="translated">你必须为 total_steps 提供一个值,或者为 epochs 和 steps_per_epoch 提供一个值。</target>
        </trans-unit>
        <trans-unit id="762890e45c5b225da275ae73984ed756702605c8" translate="yes" xml:space="preserve">
          <source>You should never try to change your model&amp;rsquo;s parameters after wrapping up your model with &lt;code&gt;DistributedDataParallel&lt;/code&gt;. Because, when wrapping up your model with &lt;code&gt;DistributedDataParallel&lt;/code&gt;, the constructor of &lt;code&gt;DistributedDataParallel&lt;/code&gt; will register the additional gradient reduction functions on all the parameters of the model itself at the time of construction. If you change the model&amp;rsquo;s parameters afterwards, gradient redunction functions no longer match the correct set of parameters.</source>
          <target state="translated">在用 &lt;code&gt;DistributedDataParallel&lt;/code&gt; 封装模型之后，永远不要尝试更改模型的参数。因为，结束了与你的模型时 &lt;code&gt;DistributedDataParallel&lt;/code&gt; 的构造 &lt;code&gt;DistributedDataParallel&lt;/code&gt; 将登记于模型本身的所有参数在施工时的附加梯度降低功能。如果之后更改了模型的参数，则梯度重新结合函数将不再与正确的参数集匹配。</target>
        </trans-unit>
        <trans-unit id="ccd4aee0db1253438f0c3a9d3c74816b28340f08" translate="yes" xml:space="preserve">
          <source>You&amp;rsquo;ll generally want to use &lt;a href=&quot;torch.qr#torch.qr&quot;&gt;&lt;code&gt;torch.qr()&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">通常，您通常要使用&lt;a href=&quot;torch.qr#torch.qr&quot;&gt; &lt;code&gt;torch.qr()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f259809289921b4be91b7ff0e29bbdb10551660f" translate="yes" xml:space="preserve">
          <source>Your models should also subclass this class.</source>
          <target state="translated">你的模型也应该子类这个类。</target>
        </trans-unit>
        <trans-unit id="93d450611dc79948223d0cdb9f4a99610848c9d6" translate="yes" xml:space="preserve">
          <source>ZeroPad2d</source>
          <target state="translated">ZeroPad2d</target>
        </trans-unit>
        <trans-unit id="90bc5acc0a3b091bfe56eb668e9c84ac53428130" translate="yes" xml:space="preserve">
          <source>[* \times \text{normalized\_shape}[0] \times \text{normalized\_shape}[1] \times \ldots \times \text{normalized\_shape}[-1]]</source>
          <target state="translated">[* \times \text{normalized\_shape}[0] \times \text{normalized\_shape}[1] \times \ldots \times \text{normalized\_shape}[-1]]</target>
        </trans-unit>
        <trans-unit id="b61210c8825bb88613c060ba48aae051333bd30a" translate="yes" xml:space="preserve">
          <source>[-1, 1]</source>
          <target state="translated">[-1, 1]</target>
        </trans-unit>
        <trans-unit id="ae17aa1eaf46c89eecaf929c74d8fda9a55db49b" translate="yes" xml:space="preserve">
          <source>[0, 1)</source>
          <target state="translated">[0, 1)</target>
        </trans-unit>
        <trans-unit id="c49d95c97e6b97b46f0fa87c4c3d5517b2dd2ac1" translate="yes" xml:space="preserve">
          <source>[0, C-1]</source>
          <target state="translated">[0, C-1]</target>
        </trans-unit>
        <trans-unit id="c00ab2adc7412d84a0750550969f7439fdbed02f" translate="yes" xml:space="preserve">
          <source>[0] a pretty-printed representation (as valid Python syntax) of the internal graph for the &lt;code&gt;forward&lt;/code&gt; method. See &lt;code&gt;code&lt;/code&gt;. [1] a ConstMap following the CONSTANT.cN format of the output in [0]. The indices in the [0] output are keys to the underlying constant&amp;rsquo;s values.</source>
          <target state="translated">[0] &lt;code&gt;forward&lt;/code&gt; 方法的内部图形的精美打印表示形式（作为有效的Python语法）。参见 &lt;code&gt;code&lt;/code&gt; 。[1]遵循[0]中输出的CONSTANT.cN格式的ConstMap。[0]输出中的索引是基础常量值的键。</target>
        </trans-unit>
        <trans-unit id="bc47f02dcecd076fd210f14fb47e8772c796bc8d" translate="yes" xml:space="preserve">
          <source>[1] D. W. Griffin and J. S. Lim, &amp;ldquo;Signal estimation from modified short-time Fourier transform,&amp;rdquo; IEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984.</source>
          <target state="translated">[1] DW Griffin和JS Lim，&amp;ldquo;来自改进的短时傅立叶变换的信号估计&amp;rdquo;，IEEE Trans。ASSP，第32卷，第2期，第236-243页，1984年4月。</target>
        </trans-unit>
        <trans-unit id="6682e58cfacdff6355a8741ff44261abb6d30565" translate="yes" xml:space="preserve">
          <source>[1] The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables (Maddison et al, 2017)</source>
          <target state="translated">[1]具体分布：离散随机变量的连续松弛（Maddison等，2017）</target>
        </trans-unit>
        <trans-unit id="1abd3a692f41e45de17752978fa303a578688034" translate="yes" xml:space="preserve">
          <source>[1] The continuous Bernoulli: fixing a pervasive error in variational autoencoders, Loaiza-Ganem G and Cunningham JP, NeurIPS 2019. &lt;a href=&quot;https://arxiv.org/abs/1907.06845&quot;&gt;https://arxiv.org/abs/1907.06845&lt;/a&gt;</source>
          <target state="translated">[1]所述的连续伯努利：固定在变自动编码，洛艾萨-Ganem G和坎宁安JP，NeurIPS一个普遍的误差2019 &lt;a href=&quot;https://arxiv.org/abs/1907.06845&quot;&gt;https://arxiv.org/abs/1907.06845&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d064e85a047a7b9150d33ff887f20a63a320452" translate="yes" xml:space="preserve">
          <source>[2] Categorical Reparametrization with Gumbel-Softmax (Jang et al, 2017)</source>
          <target state="translated">[2]使用Gumbel-Softmax进行分类重新参数化（Jang等，2017）</target>
        </trans-unit>
        <trans-unit id="9390898997c65a41ca007de79555abfa5f0ba5df" translate="yes" xml:space="preserve">
          <source>[DuerschEtal2018] Jed A. Duersch, Meiyue Shao, Chao Yang, Ming Gu. (2018) A Robust and Efficient Implementation of LOBPCG. SIAM J. Sci. Comput., 40(5), C655-C676. (22 pages) &lt;a href=&quot;https://epubs.siam.org/doi/abs/10.1137/17M1129830&quot;&gt;https://epubs.siam.org/doi/abs/10.1137/17M1129830&lt;/a&gt;</source>
          <target state="translated">[DuerschEtal2018] Jed A.Duersch，邵美月，朝阳，顾明。（2018）LOBPCG的稳健高效实施。暹罗科学 计算，40（5），C655-C676。（22页）&lt;a href=&quot;https://epubs.siam.org/doi/abs/10.1137/17M1129830&quot;&gt;https://epubs.siam.org/doi/abs/10.1137/17M1129830&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f08253d232026d76249c2db42c2940e24ba3bacf" translate="yes" xml:space="preserve">
          <source>[Knyazev2001] Andrew V. Knyazev. (2001) Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method. SIAM J. Sci. Comput., 23(2), 517-541. (25 pages) &lt;a href=&quot;https://epubs.siam.org/doi/abs/10.1137/S1064827500366124&quot;&gt;https://epubs.siam.org/doi/abs/10.1137/S1064827500366124&lt;/a&gt;</source>
          <target state="translated">[Knyazev2001] Andrew V. Knyazev。（2001）向最佳的预处理的本征求解器：局部最佳的块预处理的共轭梯度方法。暹罗科学 计算，23（2），517-541。（25页）&lt;a href=&quot;https://epubs.siam.org/doi/abs/10.1137/S1064827500366124&quot;&gt;https://epubs.siam.org/doi/abs/10.1137/S1064827500366124&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ff64b4c2d43518023be089f31430ef90034f605e" translate="yes" xml:space="preserve">
          <source>[StathopoulosEtal2002] Andreas Stathopoulos and Kesheng Wu. (2002) A Block Orthogonalization Procedure with Constant Synchronization Requirements. SIAM J. Sci. Comput., 23(6), 2165-2182. (18 pages) &lt;a href=&quot;https://epubs.siam.org/doi/10.1137/S1064827500370883&quot;&gt;https://epubs.siam.org/doi/10.1137/S1064827500370883&lt;/a&gt;</source>
          <target state="translated">[StathopoulosEtal2002] Andreas Stathopoulos和Wu Kesheng。（2002）具有恒定同步要求的块正交化程序。暹罗科学 计算，23（6），2165-2182。（18页）&lt;a href=&quot;https://epubs.siam.org/doi/10.1137/S1064827500370883&quot;&gt;https://epubs.siam.org/doi/10.1137/S1064827500370883&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f1e9b6692d359e3ebb28163afd3f06ce34d6b2df" translate="yes" xml:space="preserve">
          <source>[[-1.1819, -0.8899], [ 1.5813, 0.2274]]], names=(&amp;lsquo;A&amp;rsquo;, &amp;lsquo;B1&amp;rsquo;, &amp;lsquo;B2&amp;rsquo;))</source>
          <target state="translated">[[-1.1819，-0.8899]，[1.5813，0.2274]]]，名称=（'A'，'B1'，'B2'））</target>
        </trans-unit>
        <trans-unit id="38ac8c676253501b3fb6819ff9373ce6cfe5b055" translate="yes" xml:space="preserve">
          <source>\ ^*</source>
          <target state="translated">\ ^*</target>
        </trans-unit>
        <trans-unit id="b9bb5838f4fb69b64d3191210035a54a11128eeb" translate="yes" xml:space="preserve">
          <source>\Delta\theta = \alpha r \frac{\partial\log p(a|\pi^\theta(s))}{\partial\theta}</source>
          <target state="translated">\Delta\theta = \alpha r \frac{\partial\log p(a|\pi^\theta(s))}{\partial\theta}</target>
        </trans-unit>
        <trans-unit id="80a1cbf9743b017c73b23f243284395f0c518670" translate="yes" xml:space="preserve">
          <source>\Gamma(\cdot)</source>
          <target state="translated">\Gamma(\cdot)</target>
        </trans-unit>
        <trans-unit id="15e33ea71862e7b6632cf90aebb8ab938c698f9d" translate="yes" xml:space="preserve">
          <source>\Phi(x)</source>
          <target state="translated">\Phi(x)</target>
        </trans-unit>
        <trans-unit id="2a6c118642891e41137cb68e1346d34dabbd128c" translate="yes" xml:space="preserve">
          <source>\Vert x \Vert _p = \left( \sum_{i=1}^n \vert x_i \vert ^ p \right) ^ {1/p}.</source>
          <target state="translated">\Vert x \Vert _p = \left( \sum_{i=1}^n \vert x_i \vert ^ p \right) ^ {1/p}.</target>
        </trans-unit>
        <trans-unit id="f7c665b45932a814215e979bc2611080b4948e68" translate="yes" xml:space="preserve">
          <source>\alpha</source>
          <target state="translated">\alpha</target>
        </trans-unit>
        <trans-unit id="1eafe1d2e67a6ccfd6c43fcc6a7aba05feb684c2" translate="yes" xml:space="preserve">
          <source>\alpha = 1.6732632423543772848170429916717</source>
          <target state="translated">\alpha = 1.6732632423543772848170429916717</target>
        </trans-unit>
        <trans-unit id="e9b40d7ba0060d884943279a8f77be052be116fb" translate="yes" xml:space="preserve">
          <source>\alpha/(\sqrt{v} + \epsilon)</source>
          <target state="translated">\alpha/(\sqrt{v} + \epsilon)</target>
        </trans-unit>
        <trans-unit id="cbe1c5b26860bdd639e58977c2072d9b65aece25" translate="yes" xml:space="preserve">
          <source>\alpha=1.6732632423543772848170429916717</source>
          <target state="translated">\alpha=1.6732632423543772848170429916717</target>
        </trans-unit>
        <trans-unit id="553ba8e7e5ec0531ddcc7d2c4cd048f424b3f52f" translate="yes" xml:space="preserve">
          <source>\begin{aligned} \eta_t &amp;amp; = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 + \cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right), &amp;amp; T_{cur} \neq (2k+1)T_{max}; \\ \eta_{t+1} &amp;amp; = \eta_{t} + \frac{1}{2}(\eta_{max} - \eta_{min}) \left(1 - \cos\left(\frac{1}{T_{max}}\pi\right)\right), &amp;amp; T_{cur} = (2k+1)T_{max}. \end{aligned}</source>
          <target state="translated">\ begin {aligned} \ eta_t＆= \ eta_ {min} + \ frac {1} {2}（\ eta_ {max}-\ eta_ {min}）\ left（1 + \ cos \ left（\ frac {T_ {cur}} {T_ {max}} \ pi \ right）\ right）和T_ {cur} \ neq（2k + 1）T_ {max}; \\ \ eta_ {t + 1}＆= \ eta_ {t} + \ frac {1} {2}（\ eta_ {max}-\ eta_ {min}）\ left（1-\ cos \ left（\ frac {1} {T_ {max}} \ pi \ right）\ right），和T_ {cur} =（2k + 1）T_ {max}。\ end {aligned}</target>
        </trans-unit>
        <trans-unit id="a6518676c0b93d25520b42e7f84e6cb06eb90098" translate="yes" xml:space="preserve">
          <source>\begin{aligned} \text{if Symmetric:}&amp;amp;\\ &amp;amp;s = 2 \max(|x_\text{min}|, x_\text{max}) / \left( Q_\text{max} - Q_\text{min} \right) \\ &amp;amp;z = \begin{cases} 0 &amp;amp; \text{if dtype is qint8} \\ 128 &amp;amp; \text{otherwise} \end{cases}\\ \text{Otherwise:}&amp;amp;\\ &amp;amp;s = \left( x_\text{max} - x_\text{min} \right ) / \left( Q_\text{max} - Q_\text{min} \right ) \\ &amp;amp;z = Q_\text{min} - \text{round}(x_\text{min} / s) \end{aligned}</source>
          <target state="translated">\ begin {aligned} \ text {如果对称：}＆\\＆s = 2 \ max（| x_ \ text {min} |，x_ \ text {max}）/ \ left（Q_ \ text {max}-Q_ \ text {min} \ right）\\＆z = \ begin {cases} 0＆\ text {如果dtype为qint8} \\ 128＆\ text {否则} \ end {cases} \\ \ text {Otherwise：}＆\\ \＆s = \ left（x_ \ text {max}-x_ \ text {min} \ right）/ \ left（Q_ \ text {max}-Q_ \ text {min} \ right）\\＆z = Q_ \ text { min}-\ text {round}（x_ \ text {min} / s）\ end {aligned}</target>
        </trans-unit>
        <trans-unit id="eef3f6c4a900c50c6ccae139e6900e18ddc9222e" translate="yes" xml:space="preserve">
          <source>\begin{aligned} \text{out}(N_i, C_j, d, h, w) ={} &amp;amp; \max_{k=0, \ldots, kD-1} \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \\ &amp;amp; \text{input}(N_i, C_j, \text{stride[0]} \times d + k, \text{stride[1]} \times h + m, \text{stride[2]} \times w + n) \end{aligned}</source>
          <target state="translated">\ begin {aligned} \ text {out}（N_i，C_j，d，h，w）= {}＆\ max_ {k = 0，\ ldots，kD-1} \ max_ {m = 0，\ ldots，kH -1} \ max_ {n = 0，\ ldots，kW-1} \\＆\ text {input}（N_i，C_j，\ text {stride [0]} \ times d + k，\ text {stride [1 ]} \ times h + m，\ text {stride [2]} \ times w + n）\ end {aligned}</target>
        </trans-unit>
        <trans-unit id="3444423e4aa6a27dc2d4e17fde867139b4f23a7b" translate="yes" xml:space="preserve">
          <source>\begin{aligned} \text{out}(N_i, C_j, d, h, w) ={} &amp;amp; \sum_{k=0}^{kD-1} \sum_{m=0}^{kH-1} \sum_{n=0}^{kW-1} \\ &amp;amp; \frac{\text{input}(N_i, C_j, \text{stride}[0] \times d + k, \text{stride}[1] \times h + m, \text{stride}[2] \times w + n)} {kD \times kH \times kW} \end{aligned}</source>
          <target state="translated">\ begin {aligned} \ text {out}（N_i，C_j，d，h，w）= {}＆\ sum_ {k = 0} ^ {kD-1} \ sum_ {m = 0} ^ {kH-1 } \ sum_ {n = 0} ^ {kW-1} \\＆\ frac {\ text {input}（N_i，C_j，\ text {stride} [0] \ times d + k，\ text {stride} [ 1] \ times h + m，\ text {stride} [2] \ times w + n）} {kD \ times kH \ times kW} \ end {aligned}</target>
        </trans-unit>
        <trans-unit id="9b5fbddfbbd75f7006abb89ad6964ec0f13538c7" translate="yes" xml:space="preserve">
          <source>\begin{aligned} out(N_i, C_j, h, w) ={} &amp;amp; \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \\ &amp;amp; \text{input}(N_i, C_j, \text{stride[0]} \times h + m, \text{stride[1]} \times w + n) \end{aligned}</source>
          <target state="translated">\ begin {aligned} out（N_i，C_j，h，w）= {}＆\ max_ {m = 0，\ ldots，kH-1} \ max_ {n = 0，\ ldots，kW-1} \\＆ \ text {input}（N_i，C_j，\ text {stride [0]} \ times h + m，\ text {stride [1]} \ times w + n）\ end {aligned}</target>
        </trans-unit>
        <trans-unit id="68934623d4a064db7240ac0ed4e63262bd5a88d3" translate="yes" xml:space="preserve">
          <source>\begin{aligned} v_{t+1} &amp;amp; = \mu * v_{t} + \text{lr} * g_{t+1}, \\ p_{t+1} &amp;amp; = p_{t} - v_{t+1}. \end{aligned}</source>
          <target state="translated">\ begin {aligned} v_ {t + 1}＆= \ mu * v_ {t} + \ text {lr} * g_ {t + 1}，\\ p_ {t + 1}＆= p_ {t}-v_ {t + 1}。\ end {aligned}</target>
        </trans-unit>
        <trans-unit id="e5d65e65e32d2c2c154e2f6af937b11f165a63e3" translate="yes" xml:space="preserve">
          <source>\begin{aligned} v_{t+1} &amp;amp; = \mu * v_{t} + g_{t+1}, \\ p_{t+1} &amp;amp; = p_{t} - \text{lr} * v_{t+1}, \end{aligned}</source>
          <target state="translated">\ begin {aligned} v_ {t + 1}＆= \ mu * v_ {t} + g_ {t + 1}，\\ p_ {t + 1}＆= p_ {t}-\ text {lr} * v_ {t + 1}，\ end {aligned}</target>
        </trans-unit>
        <trans-unit id="4ea19e5cef880f790f54322d49c339a67ef7eba6" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} \\ i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\ f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\ g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\ o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\ c_t = f_t \odot c_{t-1} + i_t \odot g_t \\ h_t = o_t \odot \tanh(c_t) \\ \end{array}</source>
          <target state="translated">\begin{array}{ll} \\ i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\ f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\ g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\ o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\ c_t = f_t \odot c_{t-1} + i_t \odot g_t \\ h_t = o_t \odot \tanh(c_t) \\ \end{array}</target>
        </trans-unit>
        <trans-unit id="6b6cb34a158b8201fbf48f50465b1ece00a7eb5f" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} \min_X &amp;amp; \|AX-B\|_2. \end{array}</source>
          <target state="translated">\ begin {array} {ll} \ min_X和\ | AX-B \ | _2。\ end {array}</target>
        </trans-unit>
        <trans-unit id="9312cff9d66b9a6753766d98374f8fbc6cf98e2f" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} \min_X &amp;amp; \|X\|_2 &amp;amp; \text{subject to} &amp;amp; AX = B. \end{array}</source>
          <target state="translated">\ begin {array} {ll} \ min_X＆\ | X \ | _2＆\ text {subject to}＆AX =B。\ end {array}</target>
        </trans-unit>
        <trans-unit id="930f69e97734f3784bc6b17a4919f47bb6fa5660" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} i = \sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\ f = \sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\ g = \tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\ o = \sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\ c' = f * c + i * g \\ h' = o * \tanh(c') \\ \end{array}</source>
          <target state="translated">\ begin {array} {ll} i = \ sigma（W_ {ii} x + b_ {ii} + W_ {hi} h + b_ {hi}）\\ f = \ sigma（W_ {if} x + b_ { if} + W_ {hf} h + b_ {hf}）\\ g = \ tanh（W_ {ig} x + b_ {ig} + W_ {hg} h + b_ {hg}）\\ o = \ sigma（ W_ {io} x + b_ {io} + W_ {ho} h + b_ {ho}）\\ c'= f * c + i * g \\ h'= o * \ tanh（c'）\\ \结束{array}</target>
        </trans-unit>
        <trans-unit id="e6bea3b60c648ba0107ad5a273553cd4d585a9b3" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} r = \sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\ z = \sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\ n = \tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\ h' = (1 - z) * n + z * h \end{array}</source>
          <target state="translated">\begin{array}{ll} r = \sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\ z = \sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\ n = \tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\ h' = (1 - z) * n + z * h \end{array}</target>
        </trans-unit>
        <trans-unit id="e41fd097ab91cc853c05e5d0d9e0d37ff3dd7662" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\ z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\ n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\ h_t = (1 - z_t) * n_t + z_t * h_{(t-1)} \end{array}</source>
          <target state="translated">\begin{array}{ll} r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\ z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\ n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\ h_t = (1 - z_t) * n_t + z_t * h_{(t-1)} \end{array}</target>
        </trans-unit>
        <trans-unit id="083f0eacd92d5be23a46e2af20aa291d89fff082" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} x_\text{min} &amp;amp;= \begin{cases} \min(X) &amp;amp; \text{if~}x_\text{min} = \text{None} \\ \min\left(x_\text{min}, \min(X)\right) &amp;amp; \text{otherwise} \end{cases}\\ x_\text{max} &amp;amp;= \begin{cases} \max(X) &amp;amp; \text{if~}x_\text{max} = \text{None} \\ \max\left(x_\text{max}, \max(X)\right) &amp;amp; \text{otherwise} \end{cases}\\ \end{array}</source>
          <target state="translated">\ begin {array} {ll} x_ \ text {min}＆= \ begin {cases} \ min（X）＆\ text {if〜} x_ \ text {min} = \ text {None} \\ \ min \左（x_ \ text {min}，\ min（X）\ right）和\ text {otherwise} \ end {cases \\\ x_ \ text {max}＆= \ begin {cases} \ max（X）＆\ text {if〜} x_ \ text {max} = \ text {None} \\ \ max \ left（x_ \ text {max}，\ max（X）\ right）＆\ text {other} \ end {cases} \\ \ end {array}</target>
        </trans-unit>
        <trans-unit id="afd260a0e4c76fcb26f5d6cc69c2624609e9b929" translate="yes" xml:space="preserve">
          <source>\begin{array}{ll} x_\text{min} = \begin{cases} \min(X) &amp;amp; \text{if~}x_\text{min} = \text{None} \\ (1 - c) x_\text{min} + c \min(X) &amp;amp; \text{otherwise} \end{cases}\\ x_\text{max} = \begin{cases} \max(X) &amp;amp; \text{if~}x_\text{max} = \text{None} \\ (1 - c) x_\text{max} + c \max(X) &amp;amp; \text{otherwise} \end{cases}\\ \end{array}</source>
          <target state="translated">\\ begin {array} {ll} x_ \ text {min} = \ begin {cases} \ min（X）＆\ text {if〜} x_ \ text {min} = \ text {None} \\（1-c ）x_ \ text {min} + c \ min（X）＆\ text {otherwise} \ end {cases} \\ x_ \ text {max} = \ begin {cases} \ max（X）＆\ text {if〜 } x_ \ text {max} = \ text {None} \\（1-c）x_ \ text {max} + c \ max（X）＆\ text {否则} \ end {cases} \\ \ end {array }</target>
        </trans-unit>
        <trans-unit id="6499d503bfc00cadae1440b191c52a8632e2f8c4" translate="yes" xml:space="preserve">
          <source>\beta</source>
          <target state="translated">\beta</target>
        </trans-unit>
        <trans-unit id="6ceee6706c4f97ef457cd65c6ed19732a4a4c7e0" translate="yes" xml:space="preserve">
          <source>\delta^{(l-1)}_t</source>
          <target state="translated">\delta^{(l-1)}_t</target>
        </trans-unit>
        <trans-unit id="986673ab936df8ce1454d7dc93297bd7bbc51c4b" translate="yes" xml:space="preserve">
          <source>\ell(a, p, n) = L = \{l_1,\dots,l_N\}^\top, \quad l_i = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}</source>
          <target state="translated">\ell(a, p, n) = L = \{l_1,\dots,l_N\}^\top, \quad l_i = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}</target>
        </trans-unit>
        <trans-unit id="4d38ace96b9720e15bef838db0ce85ef5b456092" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - w_n \left[ y_n \cdot \log \sigma(x_n) + (1 - y_n) \cdot \log (1 - \sigma(x_n)) \right],</source>
          <target state="translated">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - w_n \left[ y_n \cdot \log \sigma(x_n) + (1 - y_n) \cdot \log (1 - \sigma(x_n)) \right],</target>
        </trans-unit>
        <trans-unit id="ec2ad56a41af8d7cfc9a26f61f048cf6cbd7e78d" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right],</source>
          <target state="translated">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right],</target>
        </trans-unit>
        <trans-unit id="de7b2379237fe388c3459990f0a508ab1bd86588" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - w_{y_n} x_{n,y_n}, \quad w_{c} = \text{weight}[c] \cdot \mathbb{1}\{c \not= \text{ignore\_index}\},</source>
          <target state="translated">\ ell（x，y）= L = \ {l_1，\ dots，l_N \} ^ \ top，\ quad l_n =-w_ {y_n} x_ {n，y_n}，\ quad w_ {c} = \ text {权重} [c] \ cdot \ mathbb {1} \ {c \ not = \ text {ignore \ _index} \}，</target>
        </trans-unit>
        <trans-unit id="f6a58890a57b18854cfa1707f659a4fd6ff6e4cb" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = \left( x_n - y_n \right)^2,</source>
          <target state="translated">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = \left( x_n - y_n \right)^2,</target>
        </trans-unit>
        <trans-unit id="bbe073a5e1335cf9e8392124ee3bc939a82d8704" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = \left| x_n - y_n \right|,</source>
          <target state="translated">\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = \left| x_n - y_n \right|,</target>
        </trans-unit>
        <trans-unit id="295ee7beff5d61b430ac876642e47ec1ac559795" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = \begin{cases} \operatorname{mean}(L), &amp;amp; \text{if reduction} = \text{'mean';} \\ \operatorname{sum}(L), &amp;amp; \text{if reduction} = \text{'sum'.} \end{cases}</source>
          <target state="translated">\ ell（x，y）= \ begin {cases} \ operatorname {mean}（L），＆\ text {if reduction} = \ text {'mean';} \\ \ operatorname {sum}（L），＆ \ text {如果减少} = \ text {'sum'。} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="4d5ca23779a198f768fff42eaa5060e03279277c" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = \begin{cases} \operatorname{mean}(L), &amp;amp; \text{if reduction} = \text{'mean';}\\ \operatorname{sum}(L), &amp;amp; \text{if reduction} = \text{'sum'.} \end{cases}</source>
          <target state="translated">\ ell（x，y）= \ begin {cases} \ operatorname {mean}（L），＆\ text {if reduction} = \ text {'mean';} \\ \ operatorname {sum}（L），＆ \ text {如果减少} = \ text {'sum'。} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="3c1589dd2fb19090831cbb7f520baedd8d65a3e4" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = \begin{cases} \operatorname{mean}(L), &amp;amp; \text{if reduction} = \text{`mean';}\\ \operatorname{sum}(L), &amp;amp; \text{if reduction} = \text{`sum'.} \end{cases}</source>
          <target state="translated">\ ell（x，y）= \ begin {cases} \ operatorname {mean}（L），＆\ text {if reduction} = \ text {`mean';} \\ \ operatorname {sum}（L），＆ \ text {如果减少} = \ text {`sum'。} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="8ba1942b6f9513bd39cc8cb1f1c52037ed6d49d3" translate="yes" xml:space="preserve">
          <source>\ell(x, y) = \begin{cases} \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &amp;amp; \text{if reduction} = \text{'mean';}\\ \sum_{n=1}^N l_n, &amp;amp; \text{if reduction} = \text{'sum'.} \end{cases}</source>
          <target state="translated">\ ell（x，y）= \ begin {cases} \ sum_ {n = 1} ^ N \ frac {1} {\ sum_ {n = 1} ^ N w_ {y_n}} l_n和\ text {如果归约} = \ text {'mean';} \\ \ sum_ {n = 1} ^ N l_n，＆\ text {if reduction} = \ text {'sum'。} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="5a3a211a3bdfba5d642037c3946f715f2ce73187" translate="yes" xml:space="preserve">
          <source>\ell_c(x, y) = L_c = \{l_{1,c},\dots,l_{N,c}\}^\top, \quad l_{n,c} = - w_{n,c} \left[ p_c y_{n,c} \cdot \log \sigma(x_{n,c}) + (1 - y_{n,c}) \cdot \log (1 - \sigma(x_{n,c})) \right],</source>
          <target state="translated">\ ell_c（x，y）= L_c = \ {l_ {1，c}，\ dots，l_ {N，c} \} ^ \ top，\ quad l_ {n，c} =-w_ {n，c} \ left [p_c y_ {n，c} \ cdot \ log \ sigma（x_ {n，c}）+（1-y_ {n，c}）\ cdot \ log（1-\ sigma（x_ {n，c }）） \正确的]，</target>
        </trans-unit>
        <trans-unit id="38c29fec2dd06380b3c75f2ad0de63a4841510db" translate="yes" xml:space="preserve">
          <source>\eta_t = \eta_{min}</source>
          <target state="translated">\eta_t = \eta_{min}</target>
        </trans-unit>
        <trans-unit id="669aeacd1d773163fae893a8ca1bc6fee6ec98cc" translate="yes" xml:space="preserve">
          <source>\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 + \cos\left(\frac{T_{cur}}{T_{i}}\pi\right)\right)</source>
          <target state="translated">\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 + \cos\left(\frac{T_{cur}}{T_{i}}\pi\right)\right)</target>
        </trans-unit>
        <trans-unit id="4c0a99b42d5ab2de0c04cb285ece308fea6df103" translate="yes" xml:space="preserve">
          <source>\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 + \cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right)</source>
          <target state="translated">\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 + \cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right)</target>
        </trans-unit>
        <trans-unit id="ce41fe8b1089f12f8148fc05ab4748c0e9ba7592" translate="yes" xml:space="preserve">
          <source>\eta_t=\eta_{max}</source>
          <target state="translated">\eta_t=\eta_{max}</target>
        </trans-unit>
        <trans-unit id="2e3b3cc9e60fd68fa21c6331d4f52b4c13f61075" translate="yes" xml:space="preserve">
          <source>\eta_{max}</source>
          <target state="translated">\eta_{max}</target>
        </trans-unit>
        <trans-unit id="c04fbcdd9308d49d4c2300f2ebbb1e83c44e8b83" translate="yes" xml:space="preserve">
          <source>\exp(\text{input}) - \text{target} * \text{input}</source>
          <target state="translated">\exp(\text{input}) - \text{target} * \text{input}</target>
        </trans-unit>
        <trans-unit id="cd47433a58e73b2601de69c1a9744b288212fb5f" translate="yes" xml:space="preserve">
          <source>\exp(\text{input}) - \text{target}*\text{input}</source>
          <target state="translated">\exp(\text{input}) - \text{target}*\text{input}</target>
        </trans-unit>
        <trans-unit id="fe43eb66c8bdd27010ca6db1c98281c7d4c4731f" translate="yes" xml:space="preserve">
          <source>\exp^A = \sum_{k=0}^\infty A^k / k!.</source>
          <target state="translated">\exp^A = \sum_{k=0}^\infty A^k / k!.</target>
        </trans-unit>
        <trans-unit id="14f6d7074093dd4d9ef81de502fd654605e4bb67" translate="yes" xml:space="preserve">
          <source>\forall i = d, \dots, d+k-1</source>
          <target state="translated">\forall i = d, \dots, d+k-1</target>
        </trans-unit>
        <trans-unit id="6aed51b4bd21bf9aaad2932aa936dab4bdd62611" translate="yes" xml:space="preserve">
          <source>\frac{1}{1-p}</source>
          <target state="translated">\frac{1}{1-p}</target>
        </trans-unit>
        <trans-unit id="037205eaa442691656469a316bf2dff320c2f572" translate="yes" xml:space="preserve">
          <source>\frac{1}{2} N (N - 1)</source>
          <target state="translated">\frac{1}{2} N (N - 1)</target>
        </trans-unit>
        <trans-unit id="64c94d13eeb330b494061e86538db66574ad0f7d" translate="yes" xml:space="preserve">
          <source>\frac{1}{3}</source>
          <target state="translated">\frac{1}{3}</target>
        </trans-unit>
        <trans-unit id="5947a169159fe867f85f3fd8b9690019b48152f5" translate="yes" xml:space="preserve">
          <source>\frac{1}{8}</source>
          <target state="translated">\frac{1}{8}</target>
        </trans-unit>
        <trans-unit id="f81c864ea46e4c42b16663b744993f9011be95f2" translate="yes" xml:space="preserve">
          <source>\frac{300}{100}=3</source>
          <target state="translated">\frac{300}{100}=3</target>
        </trans-unit>
        <trans-unit id="436bcf2181eea8fe79cdb015a5567ca1b8d69652" translate="yes" xml:space="preserve">
          <source>\frac{5}{3}</source>
          <target state="translated">\frac{5}{3}</target>
        </trans-unit>
        <trans-unit id="a9c2bfb5b8138830fd93a3a13faef54bc4dc94a2" translate="yes" xml:space="preserve">
          <source>\frac{m}{2} \leq</source>
          <target state="translated">\frac{m}{2} \leq</target>
        </trans-unit>
        <trans-unit id="b8fb95020958e9f0b58822f35b35fb490054c02e" translate="yes" xml:space="preserve">
          <source>\frac{p - 1}{2}</source>
          <target state="translated">\frac{p - 1}{2}</target>
        </trans-unit>
        <trans-unit id="67833ee2012ec1c6254b6c009dc72bf0dc48aa6d" translate="yes" xml:space="preserve">
          <source>\gamma</source>
          <target state="translated">\gamma</target>
        </trans-unit>
        <trans-unit id="27634ea2c473bc36e59149a7f0c457ffb292325a" translate="yes" xml:space="preserve">
          <source>\hat{x}</source>
          <target state="translated">\hat{x}</target>
        </trans-unit>
        <trans-unit id="b9e47e1f86f68634e0d0a997d4ea3952fae1e892" translate="yes" xml:space="preserve">
          <source>\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t</source>
          <target state="translated">\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t</target>
        </trans-unit>
        <trans-unit id="770b7843ffee64a984041915fe8461fd98a76060" translate="yes" xml:space="preserve">
          <source>\in [0, \infty]</source>
          <target state="translated">\in [0, \infty]</target>
        </trans-unit>
        <trans-unit id="32c336e712ce8251fe81037413821c2c348ab43d" translate="yes" xml:space="preserve">
          <source>\inf</source>
          <target state="translated">\inf</target>
        </trans-unit>
        <trans-unit id="9b97f26fbeb1b84327c736de515f10980d9c7d68" translate="yes" xml:space="preserve">
          <source>\infty</source>
          <target state="translated">\infty</target>
        </trans-unit>
        <trans-unit id="b237071f96360004cf37b06340000864b59f54c3" translate="yes" xml:space="preserve">
          <source>\int y\,dx</source>
          <target state="translated">\int y\,dx</target>
        </trans-unit>
        <trans-unit id="a10251c74fceb1b1b9e9c45471b613f216beb4a9" translate="yes" xml:space="preserve">
          <source>\int_a^b f = -\int_b^a f</source>
          <target state="translated">\int_a^b f = -\int_b^a f</target>
        </trans-unit>
        <trans-unit id="b3931f1ce298c536432fd324b3a1ab4337120689" translate="yes" xml:space="preserve">
          <source>\lambda</source>
          <target state="translated">\lambda</target>
        </trans-unit>
        <trans-unit id="1b47c3b18de49455a713efe91ac03ec27aad59a5" translate="yes" xml:space="preserve">
          <source>\lbrace (i, i) \rbrace</source>
          <target state="translated">\lbrace (i, i) \rbrace</target>
        </trans-unit>
        <trans-unit id="0fa91d11567564172cce99f01e48d1e73a28bc31" translate="yes" xml:space="preserve">
          <source>\left[0, 1, 2, \dots, \left\lfloor \frac{\text{n\_fft}}{2} \right\rfloor + 1\right]</source>
          <target state="translated">\left[0, 1, 2, \dots, \left\lfloor \frac{\text{n\_fft}}{2} \right\rfloor + 1\right]</target>
        </trans-unit>
        <trans-unit id="89ca5f286a6835c142dd1390cd67d2698dca7bcb" translate="yes" xml:space="preserve">
          <source>\left[\text{-clip\_value}, \text{clip\_value}\right]</source>
          <target state="translated">\left[\text{-clip\_value}, \text{clip\_value}\right]</target>
        </trans-unit>
        <trans-unit id="6ceb7ce51c6d9da5e34a800614788f55dff712c0" translate="yes" xml:space="preserve">
          <source>\left\lceil \frac{\text{end} - \text{start}}{\text{step}} \right\rceil</source>
          <target state="translated">\left\lceil \frac{\text{end} - \text{start}}{\text{step}} \right\rceil</target>
        </trans-unit>
        <trans-unit id="a74c86baea5a7bb180947e759ccafb91eee50e79" translate="yes" xml:space="preserve">
          <source>\left\lfloor \frac{\text{end} - \text{start}}{\text{step}} \right\rfloor + 1</source>
          <target state="translated">\left\lfloor \frac{\text{end} - \text{start}}{\text{step}} \right\rfloor + 1</target>
        </trans-unit>
        <trans-unit id="ed56196dc362da2ecbc9244bc832a7311739bb3d" translate="yes" xml:space="preserve">
          <source>\left\lfloor\frac{\texttt{in\_features}}{\texttt{div\_value}^{idx}}\right\rfloor</source>
          <target state="translated">\left\lfloor\frac{\texttt{in\_features}}{\texttt{div\_value}^{idx}}\right\rfloor</target>
        </trans-unit>
        <trans-unit id="de0088faf4547f5a22dd4cd77b23209a7dd8113e" translate="yes" xml:space="preserve">
          <source>\left\lfloor\frac{\text{len(pad)}}{2}\right\rfloor</source>
          <target state="translated">\left\lfloor\frac{\text{len(pad)}}{2}\right\rfloor</target>
        </trans-unit>
        <trans-unit id="88061aa72baf92fe1d129c82b73d16c37a6af8f0" translate="yes" xml:space="preserve">
          <source>\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor</source>
          <target state="translated">\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor</target>
        </trans-unit>
        <trans-unit id="f0a9328764eddcc1a62bf8fbb7c249505ed2c539" translate="yes" xml:space="preserve">
          <source>\leq</source>
          <target state="translated">\leq</target>
        </trans-unit>
        <trans-unit id="49abff7af14753dc3cdab27a1bf7f8ed5f2c2fa1" translate="yes" xml:space="preserve">
          <source>\leq 256</source>
          <target state="translated">\leq 256</target>
        </trans-unit>
        <trans-unit id="a719b606b8fa813d6dc2397930551b66016965ba" translate="yes" xml:space="preserve">
          <source>\leq S</source>
          <target state="translated">\leq S</target>
        </trans-unit>
        <trans-unit id="f7d8821758716417ac6285ab84b0661734c3439c" translate="yes" xml:space="preserve">
          <source>\leq T</source>
          <target state="translated">\leq T</target>
        </trans-unit>
        <trans-unit id="9ca5d36772ef139985921c4d545788d48fddcf0c" translate="yes" xml:space="preserve">
          <source>\lfloor \frac{N_d}{2} \rfloor + 1</source>
          <target state="translated">\lfloor \frac{N_d}{2} \rfloor + 1</target>
        </trans-unit>
        <trans-unit id="bc0c94864255e5978415bf4d290dee47e2677194" translate="yes" xml:space="preserve">
          <source>\lfloor\frac{\text{input planes}}{sT}\rfloor</source>
          <target state="translated">\lfloor\frac{\text{input planes}}{sT}\rfloor</target>
        </trans-unit>
        <trans-unit id="9878e94e87e5bd7098242aa36f29f409bc60ed2b" translate="yes" xml:space="preserve">
          <source>\lim_{x\to 0} \frac{d}{dx} \log (x) = \infty</source>
          <target state="translated">\lim_{x\to 0} \frac{d}{dx} \log (x) = \infty</target>
        </trans-unit>
        <trans-unit id="26c67f72ffeaf83ec8c07ff1c00c57b7b4ce05e6" translate="yes" xml:space="preserve">
          <source>\lim_{x\to 0} \log (x) = -\infty</source>
          <target state="translated">\lim_{x\to 0} \log (x) = -\infty</target>
        </trans-unit>
        <trans-unit id="d92b1f0baf6824880fb434c0077a618ba265ea33" translate="yes" xml:space="preserve">
          <source>\log (0) = -\infty</source>
          <target state="translated">\log (0) = -\infty</target>
        </trans-unit>
        <trans-unit id="99e33ed0cf12197cde63048ced916ea73cbc9c3e" translate="yes" xml:space="preserve">
          <source>\log(0)</source>
          <target state="translated">\log(0)</target>
        </trans-unit>
        <trans-unit id="9f7859c28e08a9c15994c8896e613dd27080b6a5" translate="yes" xml:space="preserve">
          <source>\log(\Gamma_{p}(a)) = C + \displaystyle \sum_{i=1}^{p} \log\left(\Gamma\left(a - \frac{i - 1}{2}\right)\right)</source>
          <target state="translated">\ log（\ Gamma_ {p}（a））= C + \ displaystyle \ sum_ {i = 1} ^ {p} \ log \ left（\ Gamma \ left（a-\ frac {i-1} {2} \是的是的）</target>
        </trans-unit>
        <trans-unit id="c1e3a3daacbe46fc4916de547be4049f250f3288" translate="yes" xml:space="preserve">
          <source>\log(\text{Softmax}(x))</source>
          <target state="translated">\log(\text{Softmax}(x))</target>
        </trans-unit>
        <trans-unit id="322a0b1861bac0e7bc727021b82a0313c2a2b303" translate="yes" xml:space="preserve">
          <source>\log\left(e^x + e^y\right)</source>
          <target state="translated">\log\left(e^x + e^y\right)</target>
        </trans-unit>
        <trans-unit id="8783c75c38eec2ddd68cac88f7dc5ac00e806274" translate="yes" xml:space="preserve">
          <source>\log_2\left(2^x + 2^y\right)</source>
          <target state="translated">\log_2\left(2^x + 2^y\right)</target>
        </trans-unit>
        <trans-unit id="8935b97a0f600209c234abf4d224c5fe967c9fa1" translate="yes" xml:space="preserve">
          <source>\lvert \text{input} - \text{other} \rvert \leq \texttt{atol} + \texttt{rtol} \times \lvert \text{other} \rvert</source>
          <target state="translated">\lvert \text{input} - \text{other} \rvert \leq \texttt{atol} + \texttt{rtol} \times \lvert \text{other} \rvert</target>
        </trans-unit>
        <trans-unit id="52c49baa710d814dcf054568b203f1298d137cf7" translate="yes" xml:space="preserve">
          <source>\mathbf{L}</source>
          <target state="translated">\mathbf{L}</target>
        </trans-unit>
        <trans-unit id="eafd018e3a8aa85682e4f0b33612ce6efed642ca" translate="yes" xml:space="preserve">
          <source>\mathbf{W}_{SN} = \dfrac{\mathbf{W}}{\sigma(\mathbf{W})}, \sigma(\mathbf{W}) = \max_{\mathbf{h}: \mathbf{h} \ne 0} \dfrac{\|\mathbf{W} \mathbf{h}\|_2}{\|\mathbf{h}\|_2}</source>
          <target state="translated">\mathbf{W}_{SN} = \dfrac{\mathbf{W}}{\sigma(\mathbf{W})}, \sigma(\mathbf{W}) = \max_{\mathbf{h}: \mathbf{h} \ne 0} \dfrac{\|\mathbf{W} \mathbf{h}\|_2}{\|\mathbf{h}\|_2}</target>
        </trans-unit>
        <trans-unit id="0b4343943b1e977c3f21f3ea5b47966a6b6ad676" translate="yes" xml:space="preserve">
          <source>\mathbf{\Sigma}</source>
          <target state="translated">\mathbf{\Sigma}</target>
        </trans-unit>
        <trans-unit id="250361cfd8c9755de3dafc641e9f127bd071fcd2" translate="yes" xml:space="preserve">
          <source>\mathbf{\Sigma} = \mathbf{L}\mathbf{L}^\top</source>
          <target state="translated">\mathbf{\Sigma} = \mathbf{L}\mathbf{L}^\top</target>
        </trans-unit>
        <trans-unit id="4e7e4ed1e422b1e8789d9ac447a022c6ca481196" translate="yes" xml:space="preserve">
          <source>\mathbf{\Sigma}^{-1}</source>
          <target state="translated">\mathbf{\Sigma}^{-1}</target>
        </trans-unit>
        <trans-unit id="201a130976ca261c5bc7ef67511ced9f15d7653a" translate="yes" xml:space="preserve">
          <source>\mathbf{w} = g \dfrac{\mathbf{v}}{\|\mathbf{v}\|}</source>
          <target state="translated">\mathbf{w} = g \dfrac{\mathbf{v}}{\|\mathbf{v}\|}</target>
        </trans-unit>
        <trans-unit id="df511dffcdad49a67cd5945ee0ab7aef8bb4f9fc" translate="yes" xml:space="preserve">
          <source>\mathcal{N}(0, 0.01)</source>
          <target state="translated">\mathcal{N}(0, 0.01)</target>
        </trans-unit>
        <trans-unit id="8f3ba18912099017c093331676f6188e744efdac" translate="yes" xml:space="preserve">
          <source>\mathcal{N}(0, 1)</source>
          <target state="translated">\mathcal{N}(0, 1)</target>
        </trans-unit>
        <trans-unit id="50c7a47dd01b89919d5422d0295475337aab6ace" translate="yes" xml:space="preserve">
          <source>\mathcal{N}(0, \text{std}^2)</source>
          <target state="translated">\mathcal{N}(0, \text{std}^2)</target>
        </trans-unit>
        <trans-unit id="92c992916044275832483fbb98179a2d00ca4c1e" translate="yes" xml:space="preserve">
          <source>\mathcal{N}(\text{mean}, \text{std}^2)</source>
          <target state="translated">\mathcal{N}(\text{mean}, \text{std}^2)</target>
        </trans-unit>
        <trans-unit id="87b1ef0bb4d4a0924cc95ef538f83b2bb3e53e42" translate="yes" xml:space="preserve">
          <source>\mathcal{U}(-\sqrt{k}, \sqrt{k})</source>
          <target state="translated">\mathcal{U}(-\sqrt{k}, \sqrt{k})</target>
        </trans-unit>
        <trans-unit id="d7f6ed3e182dc030701ad2deb57bf7caa5b88d6f" translate="yes" xml:space="preserve">
          <source>\mathcal{U}(-\text{bound}, \text{bound})</source>
          <target state="translated">\mathcal{U}(-\text{bound}, \text{bound})</target>
        </trans-unit>
        <trans-unit id="325a9ed78efc110eaab4160ef2c97f9ac713df84" translate="yes" xml:space="preserve">
          <source>\mathcal{U}(-a, a)</source>
          <target state="translated">\mathcal{U}(-a, a)</target>
        </trans-unit>
        <trans-unit id="b28ca9812620dfef2c686761b7aa8334acb0312f" translate="yes" xml:space="preserve">
          <source>\mathcal{U}(0, 1)</source>
          <target state="translated">\mathcal{U}(0, 1)</target>
        </trans-unit>
        <trans-unit id="b9712b8b025515dc1dea5f46b97d3c4fe634d954" translate="yes" xml:space="preserve">
          <source>\mathcal{U}(\text{lower}, \text{upper})</source>
          <target state="translated">\mathcal{U}(\text{lower}, \text{upper})</target>
        </trans-unit>
        <trans-unit id="e216b98083013f9a980a8176c0057ec95ff5e691" translate="yes" xml:space="preserve">
          <source>\mathcal{U}(a, b)</source>
          <target state="translated">\mathcal{U}(a, b)</target>
        </trans-unit>
        <trans-unit id="2df7cbd2cee6b04f561cf080750aba56226af4cb" translate="yes" xml:space="preserve">
          <source>\mathrm{erfc}(x) = 1 - \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^2} dt</source>
          <target state="translated">\mathrm{erfc}(x) = 1 - \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^2} dt</target>
        </trans-unit>
        <trans-unit id="20a69b6b57674088939e407b3b5098441f752171" translate="yes" xml:space="preserve">
          <source>\mathrm{erfinv}(\mathrm{erf}(x)) = x</source>
          <target state="translated">\mathrm{erfinv}(\mathrm{erf}(x)) = x</target>
        </trans-unit>
        <trans-unit id="56d825970c3fb1fe7543e6c61686e2830fac7d9f" translate="yes" xml:space="preserve">
          <source>\mathrm{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^2} dt</source>
          <target state="translated">\mathrm{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^2} dt</target>
        </trans-unit>
        <trans-unit id="5cc0da2aee8ceedc2aa92a9553e40d60b942829b" translate="yes" xml:space="preserve">
          <source>\mathrm{rate}^k \frac{e^{-\mathrm{rate}}}{k!}</source>
          <target state="translated">\mathrm{rate}^k \frac{e^{-\mathrm{rate}}}{k!}</target>
        </trans-unit>
        <trans-unit id="3e9c0d2c84e11d8338d1dac942d5dede72bd1acf" translate="yes" xml:space="preserve">
          <source>\min(input.size(-1), input.size(-2))</source>
          <target state="translated">\min(input.size(-1), input.size(-2))</target>
        </trans-unit>
        <trans-unit id="3a4e56595df1d02f21e5c3ff7b0e9d80921858ff" translate="yes" xml:space="preserve">
          <source>\mu</source>
          <target state="translated">\mu</target>
        </trans-unit>
        <trans-unit id="c8e2d1a0bf50a27d43ade30cfb048d99feb31ad1" translate="yes" xml:space="preserve">
          <source>\odot</source>
          <target state="translated">\odot</target>
        </trans-unit>
        <trans-unit id="73b077a63e22815fe5c8ee82dab9894be842b19c" translate="yes" xml:space="preserve">
          <source>\omega</source>
          <target state="translated">\omega</target>
        </trans-unit>
        <trans-unit id="72166555a6db55785fc6fbe9a7c5bbe72be28db8" translate="yes" xml:space="preserve">
          <source>\otimes</source>
          <target state="translated">\otimes</target>
        </trans-unit>
        <trans-unit id="bd84e490efa5f32ec0f75c3ea25a6efc19cfaa88" translate="yes" xml:space="preserve">
          <source>\pi^\theta</source>
          <target state="translated">\pi^\theta</target>
        </trans-unit>
        <trans-unit id="6dc2ada78a76bad95d3b921558b1195549985eab" translate="yes" xml:space="preserve">
          <source>\prod(\text{kernel\_size})</source>
          <target state="translated">\prod(\text{kernel\_size})</target>
        </trans-unit>
        <trans-unit id="02cea321dbc3a3edfc9cc1780dfe84f694c585f0" translate="yes" xml:space="preserve">
          <source>\psi(x) = \frac{d}{dx} \ln\left(\Gamma\left(x\right)\right) = \frac{\Gamma'(x)}{\Gamma(x)}</source>
          <target state="translated">\psi(x) = \frac{d}{dx} \ln\left(\Gamma\left(x\right)\right) = \frac{\Gamma'(x)}{\Gamma(x)}</target>
        </trans-unit>
        <trans-unit id="b30c154a70c78f1c5dcecce58dde2e9ff4ec56aa" translate="yes" xml:space="preserve">
          <source>\psi^{(n)}(x) = \frac{d^{(n)}}{dx^{(n)}} \psi(x)</source>
          <target state="translated">\psi^{(n)}(x) = \frac{d^{(n)}}{dx^{(n)}} \psi(x)</target>
        </trans-unit>
        <trans-unit id="69c15416b63fd933850978302bcda59da879774e" translate="yes" xml:space="preserve">
          <source>\sigma</source>
          <target state="translated">\sigma</target>
        </trans-unit>
        <trans-unit id="bfe16f27ebc966df6f10ba356a1547b6e7242dd7" translate="yes" xml:space="preserve">
          <source>\sqrt{2}</source>
          <target state="translated">\sqrt{2}</target>
        </trans-unit>
        <trans-unit id="358161536f25000be6a773604fcf4a28afd7b7bd" translate="yes" xml:space="preserve">
          <source>\sqrt{\frac{2}{1 + \text{negative\_slope}^2}}</source>
          <target state="translated">\sqrt{\frac{2}{1 + \text{negative\_slope}^2}}</target>
        </trans-unit>
        <trans-unit id="64126f7d8d3d661d4e29a191268f98bf759903a3" translate="yes" xml:space="preserve">
          <source>\sqrt{\prod_{i=1}^K N_i}</source>
          <target state="translated">\sqrt{\prod_{i=1}^K N_i}</target>
        </trans-unit>
        <trans-unit id="976e9a0789eb95323325b92e6edc3b432c6754b8" translate="yes" xml:space="preserve">
          <source>\sqrt{\prod_{i=1}^d N_i}</source>
          <target state="translated">\sqrt{\prod_{i=1}^d N_i}</target>
        </trans-unit>
        <trans-unit id="9312c2748ccad7c25f8d92bc855a5a0b38989a51" translate="yes" xml:space="preserve">
          <source>\star</source>
          <target state="translated">\star</target>
        </trans-unit>
        <trans-unit id="3df82d7a797b96797b79d72f235bc018cb8155c9" translate="yes" xml:space="preserve">
          <source>\sum_{t=-\infty}^{\infty} |w|^2[n-t\times hop\_length] \cancel{=} 0</source>
          <target state="translated">\sum_{t=-\infty}^{\infty} |w|^2[n-t\times hop\_length] \cancel{=} 0</target>
        </trans-unit>
        <trans-unit id="a12be8b8923c0e92cce3f35968e39960bc665833" translate="yes" xml:space="preserve">
          <source>\tanh</source>
          <target state="translated">\tanh</target>
        </trans-unit>
        <trans-unit id="053658991aeb9a94a57c16cbe979538b3eca3b46" translate="yes" xml:space="preserve">
          <source>\texttt{n\_classes}</source>
          <target state="translated">\texttt{n\_classes}</target>
        </trans-unit>
        <trans-unit id="79df4825cae48291f72d91cc9840f2adcb2716c4" translate="yes" xml:space="preserve">
          <source>\texttt{result[i]}</source>
          <target state="translated">\texttt{result[i]}</target>
        </trans-unit>
        <trans-unit id="8a01c6904694a6040cbbe4d31b35e67c5fb8c5bc" translate="yes" xml:space="preserve">
          <source>\text{Bernoulli}(\texttt{p\_tensor[i]})</source>
          <target state="translated">\text{Bernoulli}(\texttt{p\_tensor[i]})</target>
        </trans-unit>
        <trans-unit id="248f05fb27cede89d993bc3bb9750c4fde2467c2" translate="yes" xml:space="preserve">
          <source>\text{Bernoulli}(\texttt{p})</source>
          <target state="translated">\text{Bernoulli}(\texttt{p})</target>
        </trans-unit>
        <trans-unit id="15ca5fa99d2411cc7a336f5df78382fd090360c9" translate="yes" xml:space="preserve">
          <source>\text{Bernoulli}(\texttt{self[i]})</source>
          <target state="translated">\text{Bernoulli}(\texttt{self[i]})</target>
        </trans-unit>
        <trans-unit id="f4308a3c6285dab040bdf907914e0906e5918d43" translate="yes" xml:space="preserve">
          <source>\text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))</source>
          <target state="translated">\text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))</target>
        </trans-unit>
        <trans-unit id="1c5fbaf107a1bd80dcb32b25718623eef6cabd9f" translate="yes" xml:space="preserve">
          <source>\text{ELU}(x) = \begin{cases} x, &amp;amp; \text{ if } x &amp;gt; 0\\ \alpha * (\exp(x) - 1), &amp;amp; \text{ if } x \leq 0 \end{cases}</source>
          <target state="translated">\ text {ELU}（x）= \ begin {cases} x，＆\ text {如果} x&amp;gt; 0 \\ \ alpha *（\ exp（x）-1），＆\ text {如果} x \ leq 0 \ end {cases}</target>
        </trans-unit>
        <trans-unit id="ee2c000c326328286929b5abe78d5f28ecc355ca" translate="yes" xml:space="preserve">
          <source>\text{ELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x) - 1))</source>
          <target state="translated">\text{ELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x) - 1))</target>
        </trans-unit>
        <trans-unit id="1ae2cb648d379e90a17c82c0bca8393180166a13" translate="yes" xml:space="preserve">
          <source>\text{GELU}(x) = x * \Phi(x)</source>
          <target state="translated">\text{GELU}(x) = x * \Phi(x)</target>
        </trans-unit>
        <trans-unit id="98d15f980c451db5bf1f8450a31ea12ac80b261b" translate="yes" xml:space="preserve">
          <source>\text{GLU}(a, b) = a \otimes \sigma(b)</source>
          <target state="translated">\text{GLU}(a, b) = a \otimes \sigma(b)</target>
        </trans-unit>
        <trans-unit id="2b0fd43cdc620c274316d22c100c5a1cedf8758f" translate="yes" xml:space="preserve">
          <source>\text{HardShrink}(x) = \begin{cases} x, &amp;amp; \text{ if } x &amp;gt; \lambda \\ x, &amp;amp; \text{ if } x &amp;lt; -\lambda \\ 0, &amp;amp; \text{ otherwise } \end{cases}</source>
          <target state="translated">\ text {HardShrink}（x）= \ begin {cases} x，＆\ text {如果} x&amp;gt; \ lambda \\ x，＆\ text {如果} x &amp;lt;-\ lambda \\ 0，＆\ text {否则} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="905f89b6d5fe72acb1c8befdbd1fbd394ccc9c79" translate="yes" xml:space="preserve">
          <source>\text{HardTanh}(x) = \begin{cases} 1 &amp;amp; \text{ if } x &amp;gt; 1 \\ -1 &amp;amp; \text{ if } x &amp;lt; -1 \\ x &amp;amp; \text{ otherwise } \\ \end{cases}</source>
          <target state="translated">\ text {HardTanh}（x）= \ begin {cases} 1＆\ text {如果} x&amp;gt; 1 \\ -1＆\ text {如果} x &amp;lt;-1 \\ x＆\ text {否则} \\ \结束{cases}</target>
        </trans-unit>
        <trans-unit id="c0b2885acfe7c1d78f13cbb375808a8a70622e9c" translate="yes" xml:space="preserve">
          <source>\text{Hardsigmoid}(x) = \begin{cases} 0 &amp;amp; \text{if~} x \le -3, \\ 1 &amp;amp; \text{if~} x \ge +3, \\ x / 6 + 1 / 2 &amp;amp; \text{otherwise} \end{cases}</source>
          <target state="translated">\ text {Hardsigmoid}（x）= \ begin {cases} 0＆\ text {if〜} x \ le -3，\\ 1＆\ text {if〜} x \ ge +3，\\ x / 6 + 1/2和\ text {否则} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="3707baa731a2a1d93fe314a962f04a7440710fa1" translate="yes" xml:space="preserve">
          <source>\text{Hardswish}(x) = \begin{cases} 0 &amp;amp; \text{if~} x \le -3, \\ x &amp;amp; \text{if~} x \ge +3, \\ x \cdot (x + 3) /6 &amp;amp; \text{otherwise} \end{cases}</source>
          <target state="translated">\ text {Hardswish}（x）= \ begin {cases} 0＆\ text {if〜} x \ le -3，\\ x＆\ text {if〜} x \ ge +3，\\ x \ cdot（ x + 3）/ 6＆\ text {否则} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="f4d15ebefe7344cee7608a90993d80b6ed04f631" translate="yes" xml:space="preserve">
          <source>\text{LeakyRELU}(x) = \begin{cases} x, &amp;amp; \text{ if } x \geq 0 \\ \text{negative\_slope} \times x, &amp;amp; \text{ otherwise } \end{cases}</source>
          <target state="translated">\ text {LeakyRELU}（x）= \ begin {cases} x，＆\ text {if} x \ geq 0 \\ \ text {negative \ _slope} \ times x，＆\ text {else} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="68988527b0b6237352fc1f66e3f8116ea81dd84a" translate="yes" xml:space="preserve">
          <source>\text{LeakyReLU}(x) = \max(0, x) + \text{negative\_slope} * \min(0, x)</source>
          <target state="translated">\text{LeakyReLU}(x) = \max(0, x) + \text{negative\_slope} * \min(0, x)</target>
        </trans-unit>
        <trans-unit id="51a86607b1de32af3fd6faa8dfe21281f15bc36b" translate="yes" xml:space="preserve">
          <source>\text{LogSigmoid}(x) = \log\left(\frac{ 1 }{ 1 + \exp(-x)}\right)</source>
          <target state="translated">\text{LogSigmoid}(x) = \log\left(\frac{ 1 }{ 1 + \exp(-x)}\right)</target>
        </trans-unit>
        <trans-unit id="a4939da8f3a870de43d45395bdbb72f415fd6a5c" translate="yes" xml:space="preserve">
          <source>\text{LogSigmoid}(x_i) = \log \left(\frac{1}{1 + \exp(-x_i)}\right)</source>
          <target state="translated">\text{LogSigmoid}(x_i) = \log \left(\frac{1}{1 + \exp(-x_i)}\right)</target>
        </trans-unit>
        <trans-unit id="a58af29fea78e99ffe2b4d0392c259d952558379" translate="yes" xml:space="preserve">
          <source>\text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)</source>
          <target state="translated">\text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)</target>
        </trans-unit>
        <trans-unit id="96135669cb29b74a14e76462df05bf97eef0ca84" translate="yes" xml:space="preserve">
          <source>\text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O \text{where} head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)</source>
          <target state="translated">\text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O \text{where} head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)</target>
        </trans-unit>
        <trans-unit id="ccbab99b824f6a91f1e1bf82a1a0fdaf575b1bb6" translate="yes" xml:space="preserve">
          <source>\text{PReLU}(x) = \begin{cases} x, &amp;amp; \text{ if } x \geq 0 \\ ax, &amp;amp; \text{ otherwise } \end{cases}</source>
          <target state="translated">\ text {PReLU}（x）= \ begin {cases} x，＆\ text {if} x \ geq 0 \\ ax，＆\ text {else} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="caa4e9686c6c337eb30002e3bdcb6a130c86d148" translate="yes" xml:space="preserve">
          <source>\text{PReLU}(x) = \max(0,x) + \text{weight} * \min(0,x)</source>
          <target state="translated">\text{PReLU}(x) = \max(0,x) + \text{weight} * \min(0,x)</target>
        </trans-unit>
        <trans-unit id="5b347087764b6a93bb6f3ca448de0809ea32466b" translate="yes" xml:space="preserve">
          <source>\text{PReLU}(x) = \max(0,x) + a * \min(0,x)</source>
          <target state="translated">\text{PReLU}(x) = \max(0,x) + a * \min(0,x)</target>
        </trans-unit>
        <trans-unit id="8ab73665e19333454b7dcdadd14407c6f4eaf162" translate="yes" xml:space="preserve">
          <source>\text{RReLU}(x) = \begin{cases} x &amp;amp; \text{if } x \geq 0 \\ ax &amp;amp; \text{ otherwise } \end{cases}</source>
          <target state="translated">\ text {RReLU}（x）= \ begin {cases} x＆\ text {if} x \ geq 0 \\ ax＆\ text {else} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="ca059eb696d6eaad86cfafe12af59ddef8aeb677" translate="yes" xml:space="preserve">
          <source>\text{ReLU6}(x) = \min(\max(0,x), 6)</source>
          <target state="translated">\text{ReLU6}(x) = \min(\max(0,x), 6)</target>
        </trans-unit>
        <trans-unit id="be84129fb353e250c9169d66a9b03062f62f4151" translate="yes" xml:space="preserve">
          <source>\text{ReLU6}(x) = \min(\max(x_0, x), q(6))</source>
          <target state="translated">\text{ReLU6}(x) = \min(\max(x_0, x), q(6))</target>
        </trans-unit>
        <trans-unit id="3bfab1dc2c67446ab1cfb128a9c2bc89afb1f336" translate="yes" xml:space="preserve">
          <source>\text{ReLU}</source>
          <target state="translated">\text{ReLU}</target>
        </trans-unit>
        <trans-unit id="08bf65cb7cffc00d2f4597ea4d30a22a63976e74" translate="yes" xml:space="preserve">
          <source>\text{ReLU}(x) = (x)^+ = \max(0, x)</source>
          <target state="translated">\text{ReLU}(x) = (x)^+ = \max(0, x)</target>
        </trans-unit>
        <trans-unit id="836fcdcc8abf1c798414718b995cf2a357c6c5a8" translate="yes" xml:space="preserve">
          <source>\text{ReLU}(x)= \max(x_0, x)</source>
          <target state="translated">\text{ReLU}(x)= \max(x_0, x)</target>
        </trans-unit>
        <trans-unit id="cab6677fddc14bf3ddd26b8fe4fe9e7d772b3259" translate="yes" xml:space="preserve">
          <source>\text{SELU}(x) = \text{scale} * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))</source>
          <target state="translated">\text{SELU}(x) = \text{scale} * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))</target>
        </trans-unit>
        <trans-unit id="0eacb9a4c9b22d795a671d9085d3576f65f88226" translate="yes" xml:space="preserve">
          <source>\text{SELU}(x) = scale * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))</source>
          <target state="translated">\ text {SELU}（x）=比例*（\ max（0，x）+ \ min（0，\ alpha *（\ exp（x）-1））））</target>
        </trans-unit>
        <trans-unit id="14b5832965c3a723de26aea464be1a7e1207b0e7" translate="yes" xml:space="preserve">
          <source>\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}</source>
          <target state="translated">\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}</target>
        </trans-unit>
        <trans-unit id="dd6633f7f328cd88d5fded389f4a69b2a11f8bed" translate="yes" xml:space="preserve">
          <source>\text{Sigmoid}(x) = \sigma(x) = \frac{1}{1 + \exp(-x)}</source>
          <target state="translated">\text{Sigmoid}(x) = \sigma(x) = \frac{1}{1 + \exp(-x)}</target>
        </trans-unit>
        <trans-unit id="fa68ac444b17ef606bcb6fc0587fbb0c08130721" translate="yes" xml:space="preserve">
          <source>\text{SoftShrinkage}(x) = \begin{cases} x - \lambda, &amp;amp; \text{ if } x &amp;gt; \lambda \\ x + \lambda, &amp;amp; \text{ if } x &amp;lt; -\lambda \\ 0, &amp;amp; \text{ otherwise } \end{cases}</source>
          <target state="translated">\ text {SoftShrinkage}（x）= \ begin {cases} x-\ lambda，＆\ text {如果} x&amp;gt; \ lambda \\ x + \ lambda，＆\ text {如果} x &amp;lt;-\ lambda \\ 0 ，＆\ text {否则} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="16ab4540ec544f6557be83896c80fd5ae2348d4a" translate="yes" xml:space="preserve">
          <source>\text{SoftSign}(x) = \frac{x}{ 1 + |x|}</source>
          <target state="translated">\text{SoftSign}(x) = \frac{x}{ 1 + |x|}</target>
        </trans-unit>
        <trans-unit id="b4e8d4178c0a5a0115f54178dd9083d36fddd624" translate="yes" xml:space="preserve">
          <source>\text{SoftSign}(x) = \frac{x}{1 + |x|}</source>
          <target state="translated">\text{SoftSign}(x) = \frac{x}{1 + |x|}</target>
        </trans-unit>
        <trans-unit id="a2f536bf3a8bd1033dd978de393c848edde7120d" translate="yes" xml:space="preserve">
          <source>\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}</source>
          <target state="translated">\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}</target>
        </trans-unit>
        <trans-unit id="5b81ade15ec338b468467f739fb0a7a9ffbb69c9" translate="yes" xml:space="preserve">
          <source>\text{Softmin}(x) = \text{Softmax}(-x)</source>
          <target state="translated">\text{Softmin}(x) = \text{Softmax}(-x)</target>
        </trans-unit>
        <trans-unit id="f07f1bdd8c02f9e56e3ec0dac4ae00ebee846aae" translate="yes" xml:space="preserve">
          <source>\text{Softmin}(x_{i}) = \frac{\exp(-x_i)}{\sum_j \exp(-x_j)}</source>
          <target state="translated">\text{Softmin}(x_{i}) = \frac{\exp(-x_i)}{\sum_j \exp(-x_j)}</target>
        </trans-unit>
        <trans-unit id="2b624f5a535d4c37714f3d81447e39c785f806f7" translate="yes" xml:space="preserve">
          <source>\text{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))</source>
          <target state="translated">\text{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))</target>
        </trans-unit>
        <trans-unit id="c0fd3a2a1e0641ec623557f2f43fda5f7c89dc6c" translate="yes" xml:space="preserve">
          <source>\text{Tanhshrink}(x) = x - \tanh(x)</source>
          <target state="translated">\text{Tanhshrink}(x) = x - \tanh(x)</target>
        </trans-unit>
        <trans-unit id="995fcea13ed41fcda67e8f62153baff1abf82a33" translate="yes" xml:space="preserve">
          <source>\text{Tanhshrink}(x) = x - \text{Tanh}(x)</source>
          <target state="translated">\text{Tanhshrink}(x) = x - \text{Tanh}(x)</target>
        </trans-unit>
        <trans-unit id="d0334b6a3fe1d679df6ff4bfb438db0b64230682" translate="yes" xml:space="preserve">
          <source>\text{Tanh}(x) = \tanh(x) = \frac{\exp(x) - \exp(-x)} {\exp(x) + \exp(-x)}</source>
          <target state="translated">\text{Tanh}(x) = \tanh(x) = \frac{\exp(x) - \exp(-x)} {\exp(x) + \exp(-x)}</target>
        </trans-unit>
        <trans-unit id="75a10715f4ce8ac09932b779e24b1a0a5468348f" translate="yes" xml:space="preserve">
          <source>\text{Tanh}(x) = \tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}</source>
          <target state="translated">\text{Tanh}(x) = \tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}</target>
        </trans-unit>
        <trans-unit id="f169080e8d1eb07929eead4219c50bde74fb23da" translate="yes" xml:space="preserve">
          <source>\text{batch1} \mathbin{@} \text{batch2}</source>
          <target state="translated">\text{batch1} \mathbin{@} \text{batch2}</target>
        </trans-unit>
        <trans-unit id="229245bb08fb0569d7993b5cea15398607e69900" translate="yes" xml:space="preserve">
          <source>\text{bound} = \text{gain} \times \sqrt{\frac{3}{\text{fan\_mode}}}</source>
          <target state="translated">\text{bound} = \text{gain} \times \sqrt{\frac{3}{\text{fan\_mode}}}</target>
        </trans-unit>
        <trans-unit id="31ee1b43627512c3204fd0ea19131e5c35c60dc9" translate="yes" xml:space="preserve">
          <source>\text{gamma}^{\text{cycle iterations}}</source>
          <target state="translated">\ text {gamma} ^ {\ text {cycle迭代}}</target>
        </trans-unit>
        <trans-unit id="3e2f5fb306be83947e6aad79d83c918b084bbee4" translate="yes" xml:space="preserve">
          <source>\text{in\_channels}</source>
          <target state="translated">\text{in\_channels}</target>
        </trans-unit>
        <trans-unit id="26c469932ffffddf5378f023f97a627052bcde45" translate="yes" xml:space="preserve">
          <source>\text{input} &amp;gt; \text{other}</source>
          <target state="translated">\text{input} &amp;gt; \text{other}</target>
        </trans-unit>
        <trans-unit id="c15cd245b2e6c1904e5b0a29dc06bb37cb23bb5e" translate="yes" xml:space="preserve">
          <source>\text{input} &amp;lt; \text{other}</source>
          <target state="translated">\text{input} &amp;lt; \text{other}</target>
        </trans-unit>
        <trans-unit id="f395bedc77d1db475982b0b075906a247b84c2eb" translate="yes" xml:space="preserve">
          <source>\text{input} - \text{target} * \log(\text{input}+\text{eps})</source>
          <target state="translated">\text{input} - \text{target} * \log(\text{input}+\text{eps})</target>
        </trans-unit>
        <trans-unit id="686d55b3f5e0392f4e8fcfd75b77c03037718ecf" translate="yes" xml:space="preserve">
          <source>\text{input} - \text{target}*\log(\text{input}+\text{eps})</source>
          <target state="translated">\text{input} - \text{target}*\log(\text{input}+\text{eps})</target>
        </trans-unit>
        <trans-unit id="6da1a408fc1384eb95e3208a559d3a3e0f03e99f" translate="yes" xml:space="preserve">
          <source>\text{input} = Q R</source>
          <target state="translated">\text{input} = Q R</target>
        </trans-unit>
        <trans-unit id="c4dd474d77793c7a92038a0755b05fe0ba4adf17" translate="yes" xml:space="preserve">
          <source>\text{input} = V \text{diag}(e) V^T</source>
          <target state="translated">\text{input} = V \text{diag}(e) V^T</target>
        </trans-unit>
        <trans-unit id="e721787652f4fc0b6f66950d386917c38d8957f8" translate="yes" xml:space="preserve">
          <source>\text{input} \geq \text{other}</source>
          <target state="translated">\text{input} \geq \text{other}</target>
        </trans-unit>
        <trans-unit id="3cbe8a936fc7cb3a9fdf09ad329713fbe61317e4" translate="yes" xml:space="preserve">
          <source>\text{input} \leq \text{other}</source>
          <target state="translated">\text{input} \leq \text{other}</target>
        </trans-unit>
        <trans-unit id="3901704e8ee508e9522d87ef1f88b52ef027532b" translate="yes" xml:space="preserve">
          <source>\text{input} \neq \text{other}</source>
          <target state="translated">\text{input} \neq \text{other}</target>
        </trans-unit>
        <trans-unit id="ccf6648a02673a0bbbd4f96889ba48888a0e40f4" translate="yes" xml:space="preserve">
          <source>\text{input}[i, j]</source>
          <target state="translated">\text{input}[i, j]</target>
        </trans-unit>
        <trans-unit id="47eeab2292dd874946bd7e66f27cc66b11eafc5e" translate="yes" xml:space="preserve">
          <source>\text{input}_{i}</source>
          <target state="translated">\text{input}_{i}</target>
        </trans-unit>
        <trans-unit id="dd2a901c455f604c6af98c920667ce74d801ef8c" translate="yes" xml:space="preserve">
          <source>\text{input}_{i} / \text{other}_{i}</source>
          <target state="translated">\text{input}_{i} / \text{other}_{i}</target>
        </trans-unit>
        <trans-unit id="c920fc92a2f279db08ab80d5217f4a1714bd40d6" translate="yes" xml:space="preserve">
          <source>\text{i}^{th}</source>
          <target state="translated">\text{i}^{th}</target>
        </trans-unit>
        <trans-unit id="6ca0545c1ccedc4ff77a3d4acb74e3770c0fbbdd" translate="yes" xml:space="preserve">
          <source>\text{kernel\_size[0]}, \text{kernel\_size[1]})</source>
          <target state="translated">\text{kernel\_size[0]}, \text{kernel\_size[1]})</target>
        </trans-unit>
        <trans-unit id="9229970eeb833df18b71461a132cd3b0ce98ef3a" translate="yes" xml:space="preserve">
          <source>\text{kernel\_size[0]}, \text{kernel\_size[1]}, \text{kernel\_size[2]})</source>
          <target state="translated">\text{kernel\_size[0]}, \text{kernel\_size[1]}, \text{kernel\_size[2]})</target>
        </trans-unit>
        <trans-unit id="15869cb2da85e3f8dc3a924d02c0d13f080d42d1" translate="yes" xml:space="preserve">
          <source>\text{kernel\_size})</source>
          <target state="translated">\text{kernel\_size})</target>
        </trans-unit>
        <trans-unit id="80b2d9d0a1aff139a212f622b578c27a2cb6c126" translate="yes" xml:space="preserve">
          <source>\text{k}^{th}</source>
          <target state="translated">\text{k}^{th}</target>
        </trans-unit>
        <trans-unit id="0f84b2b9c4507f4c38935799e7145beab872e3ff" translate="yes" xml:space="preserve">
          <source>\text{logcumsumexp}(x)_{ij} = \log \sum\limits_{j=0}^{i} \exp(x_{ij})</source>
          <target state="translated">\text{logcumsumexp}(x)_{ij} = \log \sum\limits_{j=0}^{i} \exp(x_{ij})</target>
        </trans-unit>
        <trans-unit id="e4fff2f19ba639fc2ee13a3cda790993ad87fdfe" translate="yes" xml:space="preserve">
          <source>\text{logsumexp}(x)_{i} = \log \sum_j \exp(x_{ij})</source>
          <target state="translated">\text{logsumexp}(x)_{i} = \log \sum_j \exp(x_{ij})</target>
        </trans-unit>
        <trans-unit id="e990f63d798552bb3d1da254e1d0c3c11424c266" translate="yes" xml:space="preserve">
          <source>\text{loss} = \frac{\sum^{N}_{i=1} loss(i, class[i])}{\sum^{N}_{i=1} weight[class[i]]}</source>
          <target state="translated">\text{loss} = \frac{\sum^{N}_{i=1} loss(i, class[i])}{\sum^{N}_{i=1} weight[class[i]]}</target>
        </trans-unit>
        <trans-unit id="65ca80a02b47d73c67e5a3e63c9b314787018d8d" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, class) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right) = -x[class] + \log\left(\sum_j \exp(x[j])\right)</source>
          <target state="translated">\text{loss}(x, class) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right) = -x[class] + \log\left(\sum_j \exp(x[j])\right)</target>
        </trans-unit>
        <trans-unit id="019a711532dd32707cd8b1b52a85f9dcf92bf993" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, class) = weight[class] \left(-x[class] + \log\left(\sum_j \exp(x[j])\right)\right)</source>
          <target state="translated">\text{loss}(x, class) = weight[class] \left(-x[class] + \log\left(\sum_j \exp(x[j])\right)\right)</target>
        </trans-unit>
        <trans-unit id="ffd0b22341cc6c018e0b5728d553ab798985dbfc" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, y) = \begin{cases} 1 - \cos(x_1, x_2), &amp;amp; \text{if } y = 1 \\ \max(0, \cos(x_1, x_2) - \text{margin}), &amp;amp; \text{if } y = -1 \end{cases}</source>
          <target state="translated">\ text {loss}（x，y）= \ begin {cases} 1-\ cos（x_1，x_2），＆\ text {if} y = 1 \\ \ max（0，\ cos（x_1，x_2）- \ text {margin}）和\ text {if} y = -1 \ end {cases}</target>
        </trans-unit>
        <trans-unit id="c59e75cdc56fc3f83b35cdb9f628a1f6dc39d344" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, y) = \frac{1}{n} \sum_{i} z_{i}</source>
          <target state="translated">\text{loss}(x, y) = \frac{1}{n} \sum_{i} z_{i}</target>
        </trans-unit>
        <trans-unit id="b06e3acda76e096ac3266b690a1f15f3c86a036c" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, y) = \frac{\sum_i \max(0, \text{margin} - x[y] + x[i]))^p}{\text{x.size}(0)}</source>
          <target state="translated">\text{loss}(x, y) = \frac{\sum_i \max(0, \text{margin} - x[y] + x[i]))^p}{\text{x.size}(0)}</target>
        </trans-unit>
        <trans-unit id="932b5db2aa0a39e3cde91ee0926767654acd252f" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, y) = \frac{\sum_i \max(0, w[y] * (\text{margin} - x[y] + x[i]))^p)}{\text{x.size}(0)}</source>
          <target state="translated">\ text {loss}（x，y）= \ frac {\ sum_i \ max（0，w [y] *（\ text {margin}-x [y] + x [i]））^ p）} {\文字{x.size}（0）}</target>
        </trans-unit>
        <trans-unit id="1be1a15f43a5fe29e30cefc8a77697b52665cc11" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, y) = \sum_i \frac{\log(1 + \exp(-y[i]*x[i]))}{\text{x.nelement}()}</source>
          <target state="translated">\text{loss}(x, y) = \sum_i \frac{\log(1 + \exp(-y[i]*x[i]))}{\text{x.nelement}()}</target>
        </trans-unit>
        <trans-unit id="be8b3997d164f84206bbdb59fc30b16e4df28e7b" translate="yes" xml:space="preserve">
          <source>\text{loss}(x, y) = \sum_{ij}\frac{\max(0, 1 - (x[y[j]] - x[i]))}{\text{x.size}(0)}</source>
          <target state="translated">\text{loss}(x, y) = \sum_{ij}\frac{\max(0, 1 - (x[y[j]] - x[i]))}{\text{x.size}(0)}</target>
        </trans-unit>
        <trans-unit id="ed773e5223ed4e8e7a2085c415f1e22caa9ee61a" translate="yes" xml:space="preserve">
          <source>\text{loss}(x1, x2, y) = \max(0, -y * (x1 - x2) + \text{margin})</source>
          <target state="translated">\text{loss}(x1, x2, y) = \max(0, -y * (x1 - x2) + \text{margin})</target>
        </trans-unit>
        <trans-unit id="1a70593a5153f0c40ba1299b72f0b57903179f3e" translate="yes" xml:space="preserve">
          <source>\text{other}_{i}</source>
          <target state="translated">\text{other}_{i}</target>
        </trans-unit>
        <trans-unit id="17f7519844253d6013b5ffbe16cec0f08dcc6ff0" translate="yes" xml:space="preserve">
          <source>\text{out} = -1 \times \text{input}</source>
          <target state="translated">\text{out} = -1 \times \text{input}</target>
        </trans-unit>
        <trans-unit id="90a41651feeb08c3eedd09a310ec016d8b14ad0c" translate="yes" xml:space="preserve">
          <source>\text{out} = \beta\ \text{input} + \alpha\ (\text{mat1}_i \mathbin{@} \text{mat2}_i)</source>
          <target state="translated">\text{out} = \beta\ \text{input} + \alpha\ (\text{mat1}_i \mathbin{@} \text{mat2}_i)</target>
        </trans-unit>
        <trans-unit id="bb3213012476cae8440fbe19a6e07cd71a7793bd" translate="yes" xml:space="preserve">
          <source>\text{out} = \beta\ \text{input} + \alpha\ (\text{mat} \mathbin{@} \text{vec})</source>
          <target state="translated">\text{out} = \beta\ \text{input} + \alpha\ (\text{mat} \mathbin{@} \text{vec})</target>
        </trans-unit>
        <trans-unit id="e949532f9deb6bd6d752ab7f572576835541d193" translate="yes" xml:space="preserve">
          <source>\text{out} = \beta\ \text{input} + \alpha\ (\text{vec1} \otimes \text{vec2})</source>
          <target state="translated">\text{out} = \beta\ \text{input} + \alpha\ (\text{vec1} \otimes \text{vec2})</target>
        </trans-unit>
        <trans-unit id="0358e27d2d15a38fee22f3930f0704830355a8e2" translate="yes" xml:space="preserve">
          <source>\text{out} = \text{abs} \cdot \cos(\text{angle}) + \text{abs} \cdot \sin(\text{angle}) \cdot j</source>
          <target state="translated">\text{out} = \text{abs} \cdot \cos(\text{angle}) + \text{abs} \cdot \sin(\text{angle}) \cdot j</target>
        </trans-unit>
        <trans-unit id="36eb11cd26daa728869e9dc0ff4a77afceb36308" translate="yes" xml:space="preserve">
          <source>\text{out} = \text{input} + \text{alpha} \times \text{other}</source>
          <target state="translated">\text{out} = \text{input} + \text{alpha} \times \text{other}</target>
        </trans-unit>
        <trans-unit id="256d0e45774d81cdb6896827af46bd880155747c" translate="yes" xml:space="preserve">
          <source>\text{out} = \text{input} + \text{other}</source>
          <target state="translated">\text{out} = \text{input} + \text{other}</target>
        </trans-unit>
        <trans-unit id="b32a02ba7ef69d1c7496b06c7c87e64e5599ad7d" translate="yes" xml:space="preserve">
          <source>\text{out}(N_i, C_j, l) = \frac{1}{k} \sum_{m=0}^{k-1} \text{input}(N_i, C_j, \text{stride} \times l + m)</source>
          <target state="translated">\ text {out}（N_i，C_j，l）= \ frac {1} {k} \ sum_ {m = 0} ^ {k-1} \ text {input}（N_i，C_j，\ text {stride} \乘以l + m）</target>
        </trans-unit>
        <trans-unit id="6ffc018e43b40a0d8b659cfa4eb86a17bb9a021a" translate="yes" xml:space="preserve">
          <source>\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) + \sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)</source>
          <target state="translated">\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) + \sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)</target>
        </trans-unit>
        <trans-unit id="1329f06a718ae43bb8cf775c59ab239d1fb3b8cd" translate="yes" xml:space="preserve">
          <source>\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) + \sum_{k = 0}^{C_{in} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)</source>
          <target state="translated">\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) + \sum_{k = 0}^{C_{in} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)</target>
        </trans-unit>
        <trans-unit id="43e8084d30aefee2bbf06206dd0a8ab14834163f" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \begin{cases} \text{x}_i &amp;amp; \text{if } \text{condition}_i \\ \text{y}_i &amp;amp; \text{otherwise} \\ \end{cases}</source>
          <target state="translated">\ text {out} _i = \ begin {cases} \ text {x} _i＆\ text {if} \ text {condition} _i \\ \ text {y} _i＆\ text {否则} \\ \ end {cases }</target>
        </trans-unit>
        <trans-unit id="887bfc6ee868fe88195f2b1a697c2be49d6ee9a3" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \beta\ \text{input}_i + \alpha\ (\text{batch1}_i \mathbin{@} \text{batch2}_i)</source>
          <target state="translated">\text{out}_i = \beta\ \text{input}_i + \alpha\ (\text{batch1}_i \mathbin{@} \text{batch2}_i)</target>
        </trans-unit>
        <trans-unit id="65617250468b820b83705d0c5a443bdbe573e367" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \frac{\text{input}_i}{\text{other}_i}</source>
          <target state="translated">\text{out}_i = \frac{\text{input}_i}{\text{other}_i}</target>
        </trans-unit>
        <trans-unit id="07bf2f98a46000c9d46f464978022925a2bd7e3f" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \text{input}_i + \text{value} \times \frac{\text{tensor1}_i}{\text{tensor2}_i}</source>
          <target state="translated">\text{out}_i = \text{input}_i + \text{value} \times \frac{\text{tensor1}_i}{\text{tensor2}_i}</target>
        </trans-unit>
        <trans-unit id="3da52d8260a7cb2e43645767f57dc80dcb7dfe10" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \text{input}_i + \text{value} \times \text{tensor1}_i \times \text{tensor2}_i</source>
          <target state="translated">\text{out}_i = \text{input}_i + \text{value} \times \text{tensor1}_i \times \text{tensor2}_i</target>
        </trans-unit>
        <trans-unit id="62f87f35ab6f8ad57797570d5573c2164ad3b265" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \text{input}_i \mathbin{@} \text{mat2}_i</source>
          <target state="translated">\text{out}_i = \text{input}_i \mathbin{@} \text{mat2}_i</target>
        </trans-unit>
        <trans-unit id="7a9589802a74e5f4ebdc7b3bf9edf66a572b8b2d" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \text{input}_i \times \text{other}_i</source>
          <target state="translated">\text{out}_i = \text{input}_i \times \text{other}_i</target>
        </trans-unit>
        <trans-unit id="598abd50041125894fc9d56c763e555dc53626ff" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \text{other} \times \text{input}_i</source>
          <target state="translated">\text{out}_i = \text{other} \times \text{input}_i</target>
        </trans-unit>
        <trans-unit id="f19bf9db2f65318c8d3279e96d9b9001602fb09a" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \text{self} ^ {\text{exponent}_i}</source>
          <target state="translated">\text{out}_i = \text{self} ^ {\text{exponent}_i}</target>
        </trans-unit>
        <trans-unit id="a7a2515cc1e93998b3a18636546dddfa38daeec0" translate="yes" xml:space="preserve">
          <source>\text{out}_i = \text{start}_i + \text{weight}_i \times (\text{end}_i - \text{start}_i)</source>
          <target state="translated">\text{out}_i = \text{start}_i + \text{weight}_i \times (\text{end}_i - \text{start}_i)</target>
        </trans-unit>
        <trans-unit id="0cb57186f10cc53449c5a3667b3e9e3171f06840" translate="yes" xml:space="preserve">
          <source>\text{out}_i = x_i ^ \text{exponent}</source>
          <target state="translated">\text{out}_i = x_i ^ \text{exponent}</target>
        </trans-unit>
        <trans-unit id="fc2ce21ca05c23e8481f3ba74137e106e861116a" translate="yes" xml:space="preserve">
          <source>\text{out}_i = x_i ^ {\text{exponent}_i}</source>
          <target state="translated">\text{out}_i = x_i ^ {\text{exponent}_i}</target>
        </trans-unit>
        <trans-unit id="199c9bafa2de3cddd25186555e3341b49eafa3be" translate="yes" xml:space="preserve">
          <source>\text{out}_i \sim \text{Poisson}(\text{input}_i)</source>
          <target state="translated">\text{out}_i \sim \text{Poisson}(\text{input}_i)</target>
        </trans-unit>
        <trans-unit id="ec5b93008f32dc9277b22a2479b439d557449a63" translate="yes" xml:space="preserve">
          <source>\text{out}_{i+1} = \text{out}_i + \text{step}.</source>
          <target state="translated">\text{out}_{i+1} = \text{out}_i + \text{step}.</target>
        </trans-unit>
        <trans-unit id="ebe2d70cc579db08dc5e67ffe414031300d09f4c" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = I_0(\text{input}_{i}) = \sum_{k=0}^{\infty} \frac{(\text{input}_{i}^2/4)^k}{(k!)^2}</source>
          <target state="translated">\text{out}_{i} = I_0(\text{input}_{i}) = \sum_{k=0}^{\infty} \frac{(\text{input}_{i}^2/4)^k}{(k!)^2}</target>
        </trans-unit>
        <trans-unit id="6b1003c5523ecc63d8ba6aacefacf06606afa128" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \cos(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \cos(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="f24a159b70e10e5357a57a49e58cd32d187c432a" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \cos^{-1}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \cos^{-1}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="21103602f770a5f7ee7fc1da1e89140f56599227" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \cosh(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \cosh(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="84def1c39988847c83528f8fb8f04adcd967d458" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \cosh^{-1}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \cosh^{-1}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="0f2819fdd8d29dbcba0965986f63a77a316be87c" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \frac{1}{1 + e^{-\text{input}_{i}}}</source>
          <target state="translated">\text{out}_{i} = \frac{1}{1 + e^{-\text{input}_{i}}}</target>
        </trans-unit>
        <trans-unit id="e639a53f131fc76fecc291100aefd605f12a0eda" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \frac{1}{\sqrt{\text{input}_{i}}}</source>
          <target state="translated">\text{out}_{i} = \frac{1}{\sqrt{\text{input}_{i}}}</target>
        </trans-unit>
        <trans-unit id="46ce5ca183590faeb94bd046c494af519bde768a" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \frac{1}{\text{input}_{i}}</source>
          <target state="translated">\text{out}_{i} = \frac{1}{\text{input}_{i}}</target>
        </trans-unit>
        <trans-unit id="4427bc0696c242442c6213bd5a82d54aee1a2769" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \left\lceil \text{input}_{i} \right\rceil = \left\lfloor \text{input}_{i} \right\rfloor + 1</source>
          <target state="translated">\text{out}_{i} = \left\lceil \text{input}_{i} \right\rceil = \left\lfloor \text{input}_{i} \right\rfloor + 1</target>
        </trans-unit>
        <trans-unit id="15280a01ee3fbee59abcbcd2395fe2dc53197b84" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \left\lfloor \text{input}_{i} \right\rfloor</source>
          <target state="translated">\text{out}_{i} = \left\lfloor \text{input}_{i} \right\rfloor</target>
        </trans-unit>
        <trans-unit id="8713f714ca9f011825a27f3a64b5103537d7c3a8" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \log \Gamma(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \log \Gamma(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="f106314a05b463158c27ca8e8540a802938b4b7b" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \operatorname{sgn}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \operatorname{sgn}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="6d66baddaec726fdba3a80fb59890298bae46f57" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \sin(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \sin(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="2029dbca4086f039d8d89647025660d63e959250" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \sin^{-1}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \sin^{-1}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="29f2eee43262fe3393a73b473efb38b2970a7d4d" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \sinh(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \sinh(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="4f9ac0337247d9d45d980c107144e23646dfd988" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \sinh^{-1}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \sinh^{-1}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="a48b925f8709a2a6a8ef052050d18b589d5123a2" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \sqrt{\text{input}_{i}^{2} + \text{other}_{i}^{2}}</source>
          <target state="translated">\text{out}_{i} = \sqrt{\text{input}_{i}^{2} + \text{other}_{i}^{2}}</target>
        </trans-unit>
        <trans-unit id="a6adf034e3ba47318aad9958d92aa5caaeae39a3" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \sqrt{\text{input}_{i}}</source>
          <target state="translated">\text{out}_{i} = \sqrt{\text{input}_{i}}</target>
        </trans-unit>
        <trans-unit id="3563e2ffc1ebfbc800c1dd7b12d56f17e2f84012" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \tan(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \tan(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="c84ff0d5cfb4e3368d70e9d3853ac2f7da77df34" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \tan^{-1}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \tan^{-1}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="339ee2ac3b749c3430c326bb801e434eb7dd88eb" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \tanh(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \tanh(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="0bbbd60b143b37df1c047a994b490f440b3b4a12" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \tanh^{-1}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \tanh^{-1}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="b2b840e12a553c229a2511c216662f4659dc95dc" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = \text{input}_{i} - \left\lfloor |\text{input}_{i}| \right\rfloor * \operatorname{sgn}(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = \text{input}_{i} - \left\lfloor |\text{input}_{i}| \right\rfloor * \operatorname{sgn}(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="07e6f589bfadaeb684ef52c979559ff70dd53446" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = angle(\text{input}_{i})</source>
          <target state="translated">\ text {out} _ {i} =角度（\ text {input} _ {i}）</target>
        </trans-unit>
        <trans-unit id="3208732ebcf3371420c5abc0afe1728e365bcaab" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = conj(\text{input}_{i})</source>
          <target state="translated">\text{out}_{i} = conj(\text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="b2990a218cc833a6ec80d5667b3951afb3dfc0ec" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} = |\text{input}_{i}|</source>
          <target state="translated">\text{out}_{i} = |\text{input}_{i}|</target>
        </trans-unit>
        <trans-unit id="c6aa4724db682413c4a0d9e7da789301bde04767" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} \sim \mathcal{N}(0, 1)</source>
          <target state="translated">\text{out}_{i} \sim \mathcal{N}(0, 1)</target>
        </trans-unit>
        <trans-unit id="19b54f107e367ae800728c182219b0a6d113a55d" translate="yes" xml:space="preserve">
          <source>\text{out}_{i} \sim \mathrm{Bernoulli}(p = \text{input}_{i})</source>
          <target state="translated">\text{out}_{i} \sim \mathrm{Bernoulli}(p = \text{input}_{i})</target>
        </trans-unit>
        <trans-unit id="0ff6f3181c37c49b168dc5bb2c5512278c4d8cdd" translate="yes" xml:space="preserve">
          <source>\text{out}_{{i+1}} = \text{out}_{i} + \text{step}</source>
          <target state="translated">\text{out}_{{i+1}} = \text{out}_{i} + \text{step}</target>
        </trans-unit>
        <trans-unit id="22972795246817e25ed6cd9e7f9534bb009c4be5" translate="yes" xml:space="preserve">
          <source>\text{padding\_back}</source>
          <target state="translated">\text{padding\_back}</target>
        </trans-unit>
        <trans-unit id="8f171d7dcd7097c55030a1f2855ec480075028b7" translate="yes" xml:space="preserve">
          <source>\text{padding\_bottom}</source>
          <target state="translated">\text{padding\_bottom}</target>
        </trans-unit>
        <trans-unit id="c61e815e96b628670818ef2117895748429c8232" translate="yes" xml:space="preserve">
          <source>\text{padding\_front}</source>
          <target state="translated">\text{padding\_front}</target>
        </trans-unit>
        <trans-unit id="db98a807cd5008387cbab3fe6e2aec41450b4604" translate="yes" xml:space="preserve">
          <source>\text{padding\_front}, \text{padding\_back})</source>
          <target state="translated">\text{padding\_front}, \text{padding\_back})</target>
        </trans-unit>
        <trans-unit id="71d180502f18ec5d773aee314a7a4111878c2b75" translate="yes" xml:space="preserve">
          <source>\text{padding\_left}</source>
          <target state="translated">\text{padding\_left}</target>
        </trans-unit>
        <trans-unit id="d6ccab1e4d0ca305991dad9a66b238c71e38726d" translate="yes" xml:space="preserve">
          <source>\text{padding\_right}</source>
          <target state="translated">\text{padding\_right}</target>
        </trans-unit>
        <trans-unit id="822c531daaae9a83e8cb9610863aa10968e367cb" translate="yes" xml:space="preserve">
          <source>\text{padding\_top}</source>
          <target state="translated">\text{padding\_top}</target>
        </trans-unit>
        <trans-unit id="c863b416ef996ee31809e50a0bf7888a3fdd7ad8" translate="yes" xml:space="preserve">
          <source>\text{padding\_top}, \text{padding\_bottom}</source>
          <target state="translated">\text{padding\_top}, \text{padding\_bottom}</target>
        </trans-unit>
        <trans-unit id="4dfb970fd31b03f94d4e4f1e23a1347628359b17" translate="yes" xml:space="preserve">
          <source>\text{padding\_top}, \text{padding\_bottom})</source>
          <target state="translated">\text{padding\_top}, \text{padding\_bottom})</target>
        </trans-unit>
        <trans-unit id="2940a7cd2f158af987520c8f34af379096300028" translate="yes" xml:space="preserve">
          <source>\text{scale} = 1.0507009873554804934193349852946</source>
          <target state="translated">\text{scale} = 1.0507009873554804934193349852946</target>
        </trans-unit>
        <trans-unit id="509bb45bc88eeba17ab4e18a7b0718847be009ba" translate="yes" xml:space="preserve">
          <source>\text{silu}(x) = x * \sigma(x), \text{where } \sigma(x) \text{ is the logistic sigmoid.}</source>
          <target state="translated">\ text {silu}（x）= x * \ sigma（x），\ text {其中} \ sigma（x）\ text {是逻辑Sigmoid。}</target>
        </trans-unit>
        <trans-unit id="19a93b01d26977b01f0022e9ad1395871a79c6d2" translate="yes" xml:space="preserve">
          <source>\text{similarity} = \dfrac{x_1 \cdot x_2}{\max(\Vert x_1 \Vert _2 \cdot \Vert x_2 \Vert _2, \epsilon)}</source>
          <target state="translated">\ text {相似性} = \ dfrac {x_1 \ cdot x_2} {\ max（\ Vert x_1 \ Vert _2 \ cdot \ Vert x_2 \ Vert _2，\ epsilon）}</target>
        </trans-unit>
        <trans-unit id="64fe2ce749a0723d9a9566b76783f0dec79a7cd9" translate="yes" xml:space="preserve">
          <source>\text{similarity} = \dfrac{x_1 \cdot x_2}{\max(\Vert x_1 \Vert _2 \cdot \Vert x_2 \Vert _2, \epsilon)}.</source>
          <target state="translated">\ text {相似性} = \ dfrac {x_1 \ cdot x_2} {\ max（\ Vert x_1 \ Vert _2 \ cdot \ Vert x_2 \ Vert _2，\ epsilon）}。</target>
        </trans-unit>
        <trans-unit id="1e184ebb3380e76e50f3e3cc8c8ba0cdbf171178" translate="yes" xml:space="preserve">
          <source>\text{spatial\_size}</source>
          <target state="translated">\text{spatial\_size}</target>
        </trans-unit>
        <trans-unit id="30d98357c0cf5aadd64e4c5685312bfb74e6ff43" translate="yes" xml:space="preserve">
          <source>\text{std} = \frac{\text{gain}}{\sqrt{\text{fan\_mode}}}</source>
          <target state="translated">\text{std} = \frac{\text{gain}}{\sqrt{\text{fan\_mode}}}</target>
        </trans-unit>
        <trans-unit id="0bba3586f43350ca4e47d9af0d460338cdf45084" translate="yes" xml:space="preserve">
          <source>\text{std} = \text{gain} \times \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}</source>
          <target state="translated">\text{std} = \text{gain} \times \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}</target>
        </trans-unit>
        <trans-unit id="8ee7a6294338ef4ec43db737a79e7a5c5827ad5d" translate="yes" xml:space="preserve">
          <source>\text{stride}[i] = \text{stride}[i+1] \times \text{size}[i+1]</source>
          <target state="translated">\text{stride}[i] = \text{stride}[i+1] \times \text{size}[i+1]</target>
        </trans-unit>
        <trans-unit id="9ae213028d9116087df1c48df38a24906070e968" translate="yes" xml:space="preserve">
          <source>\text{target} * \log(\text{target}) - \text{target} + 0.5 * \log(2 * \pi * \text{target})</source>
          <target state="translated">\text{target} * \log(\text{target}) - \text{target} + 0.5 * \log(2 * \pi * \text{target})</target>
        </trans-unit>
        <trans-unit id="40e87ce770ee226cb8037a67d055f5046fdf9036" translate="yes" xml:space="preserve">
          <source>\text{target} \sim \mathrm{Poisson}(\text{input}) \text{loss}(\text{input}, \text{target}) = \text{input} - \text{target} * \log(\text{input}) + \log(\text{target!})</source>
          <target state="translated">\ text {target} \ sim \ mathrm {泊松}（\ text {input}）\ text {loss}（\ text {input}，\ text {target}）= \ text {input}-\ text {target} * \ log（\ text {input}）+ \ log（\ text {target！}）</target>
        </trans-unit>
        <trans-unit id="ee61c683da63904db4a3e121bdf113933043f4d7" translate="yes" xml:space="preserve">
          <source>\text{target}*\log(\text{target}) - \text{target} + 0.5 * \log(2\pi\text{target}).</source>
          <target state="translated">\text{target}*\log(\text{target}) - \text{target} + 0.5 * \log(2\pi\text{target}).</target>
        </trans-unit>
        <trans-unit id="0f6bd28cfcaee12c0d20055b4b4afd7bf6b48113" translate="yes" xml:space="preserve">
          <source>\text{tensor1} / \text{tensor2}</source>
          <target state="translated">\text{tensor1} / \text{tensor2}</target>
        </trans-unit>
        <trans-unit id="075aa43f8957c1474a6931e41c96dcb7c5d686d6" translate="yes" xml:space="preserve">
          <source>\text{true eigenvector}[j + 1] = eigenvectors[:, j] - i \times eigenvectors[:, j + 1]</source>
          <target state="translated">\ text {true特征向量} [j + 1] =特征向量[：，j]-i \ times特征向量[：，j + 1]</target>
        </trans-unit>
        <trans-unit id="dbbcfbb1d0a265eefc03e882be62153c1a959077" translate="yes" xml:space="preserve">
          <source>\text{true eigenvector}[j] = eigenvectors[:, j] + i \times eigenvectors[:, j + 1]</source>
          <target state="translated">\ text {true eigenvector} [j] =特征向量[：，j] + i \ times特征向量[：，j + 1]</target>
        </trans-unit>
        <trans-unit id="63386bdc7be9c10bbab18ac478e13f97470e863e" translate="yes" xml:space="preserve">
          <source>\text{val}</source>
          <target state="translated">\text{val}</target>
        </trans-unit>
        <trans-unit id="d6db479a087e6e41362768b25784ba255c6716a3" translate="yes" xml:space="preserve">
          <source>\text{vec1} \otimes \text{vec2}</source>
          <target state="translated">\text{vec1} \otimes \text{vec2}</target>
        </trans-unit>
        <trans-unit id="64e1f89a912ee4486e65f62e989e6b10c06342f9" translate="yes" xml:space="preserve">
          <source>\text{win\_length} &amp;lt; \text{n\_fft}</source>
          <target state="translated">\text{win\_length} &amp;lt; \text{n\_fft}</target>
        </trans-unit>
        <trans-unit id="18afc597cccde66cf5c2fa4706aeb0646f3723b2" translate="yes" xml:space="preserve">
          <source>\text{window\_length} + 1</source>
          <target state="translated">\ text {窗口\ _length} + 1</target>
        </trans-unit>
        <trans-unit id="848da5fb0b7bd079124401e74232d55ffe67400b" translate="yes" xml:space="preserve">
          <source>\text{{heaviside}}(input, values) = \begin{cases} 0, &amp;amp; \text{if input &amp;lt; 0}\\ values, &amp;amp; \text{if input == 0}\\ 1, &amp;amp; \text{if input &amp;gt; 0} \end{cases}</source>
          <target state="translated">\ text {{heaviside}}（输入，值）= \ begin {cases} 0，＆\ text {如果输入&amp;lt;0} \\值，＆\ text {如果输入== 0} \\ 1 ,，＆\ text {如果输入&amp;gt; 0} \ end {cases}</target>
        </trans-unit>
        <trans-unit id="f6688d2b60281ad8fefcc0fea715a9f936e08052" translate="yes" xml:space="preserve">
          <source>\text{{out}}_i = \text{trunc} \left( \frac{{\text{{input}}_i}}{{\text{{other}}_i}} \right)</source>
          <target state="translated">\text{{out}}_i = \text{trunc} \left( \frac{{\text{{input}}_i}}{{\text{{other}}_i}} \right)</target>
        </trans-unit>
        <trans-unit id="b390b7373d30b8df651a5b7c8366caf960e3ef34" translate="yes" xml:space="preserve">
          <source>\text{{out}}_i = \text{{input}}_i - \text{{alpha}} \times \text{{other}}_i</source>
          <target state="translated">\text{{out}}_i = \text{{input}}_i - \text{{alpha}} \times \text{{other}}_i</target>
        </trans-unit>
        <trans-unit id="cb005d76f9f2e394a770c2562c2e150a413b3216" translate="yes" xml:space="preserve">
          <source>\theta</source>
          <target state="translated">\theta</target>
        </trans-unit>
        <trans-unit id="48eecc0a7bfa64d8c32f97e0fc816b2205b04bb8" translate="yes" xml:space="preserve">
          <source>\{0, \ldots, K-1\}</source>
          <target state="translated">\{0, \ldots, K-1\}</target>
        </trans-unit>
        <trans-unit id="86f7e437faa5a7fce15d1ddcb9eaeaea377667b8" translate="yes" xml:space="preserve">
          <source>a</source>
          <target state="translated">a</target>
        </trans-unit>
        <trans-unit id="985ea09fbb51e15e4429dc741d64e71fe6b0efab" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;PackedSequence&lt;/code&gt;&lt;/a&gt; object</source>
          <target state="translated">一个&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;PackedSequence&lt;/code&gt; &lt;/a&gt;对象</target>
        </trans-unit>
        <trans-unit id="d162d7e8bd1d5dda8190b029ffd491226ce6290d" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;tuple&lt;/code&gt; of three ints &amp;ndash; in which case, the first &lt;code&gt;int&lt;/code&gt; is used for the depth dimension, the second &lt;code&gt;int&lt;/code&gt; for the height dimension and the third &lt;code&gt;int&lt;/code&gt; for the width dimension</source>
          <target state="translated">三个int的 &lt;code&gt;tuple&lt;/code&gt; &amp;ndash;在这种情况下，第一个 &lt;code&gt;int&lt;/code&gt; 用于深度尺寸，第二个 &lt;code&gt;int&lt;/code&gt; 用于高度尺寸，第三个 &lt;code&gt;int&lt;/code&gt; 用于宽度尺寸</target>
        </trans-unit>
        <trans-unit id="5e87ba64be191e5fb677cabf542708af2183633d" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;tuple&lt;/code&gt; of two ints &amp;ndash; in which case, the first &lt;code&gt;int&lt;/code&gt; is used for the height dimension, and the second &lt;code&gt;int&lt;/code&gt; for the width dimension</source>
          <target state="translated">两个int的 &lt;code&gt;tuple&lt;/code&gt; &amp;ndash;在这种情况下，第一个 &lt;code&gt;int&lt;/code&gt; 用于高度尺寸，第二个 &lt;code&gt;int&lt;/code&gt; 用于宽度尺寸</target>
        </trans-unit>
        <trans-unit id="9af60a637080c119529287cf450a17dc51cdd322" translate="yes" xml:space="preserve">
          <source>a = \text{gain} \times \sqrt{\frac{6}{\text{fan\_in} + \text{fan\_out}}}</source>
          <target state="translated">a=text{gain}xtimes sqrt{\frac{6}{text{fan_in}+text{fan_out}}}}</target>
        </trans-unit>
        <trans-unit id="a18d36abd55ff2f8af389fa82ac5cf243f710013" translate="yes" xml:space="preserve">
          <source>a Tensor containing the result of module(input) located on output_device</source>
          <target state="translated">一个包含输出设备上模块(输入)结果的Tensor。</target>
        </trans-unit>
        <trans-unit id="890f00f76ee1d37642ba29392aeb8c4a40b22625" translate="yes" xml:space="preserve">
          <source>a Tensor of the same dimension and shape as the input with values in the range [-inf, 0)</source>
          <target state="translated">a 与输入相同维度和形状的张量,其值的范围为[-inf,0]。</target>
        </trans-unit>
        <trans-unit id="2003464995dec65fd9f3cf1a1961d2e3b1715419" translate="yes" xml:space="preserve">
          <source>a Tensor of the same dimension and shape as the input with values in the range [0, 1]</source>
          <target state="translated">a 与输入的尺寸和形状相同的张量,数值范围为[0,1]。</target>
        </trans-unit>
        <trans-unit id="6fae14cf3c01e74728e043358ac48d17d6d7ff1f" translate="yes" xml:space="preserve">
          <source>a Tensor of the same dimension and shape as the input, with values in the range [0, 1]</source>
          <target state="translated">a 与输入相同维度和形状的张量,数值范围为[0,1]。</target>
        </trans-unit>
        <trans-unit id="0fa1afd2e30272a3a23ae385fdbd6176134150f6" translate="yes" xml:space="preserve">
          <source>a class with the highest probability for each example</source>
          <target state="translated">一个班级,每个例子的概率都是最高的。</target>
        </trans-unit>
        <trans-unit id="45f2f8dde4763de997a5fc5976cf3a9430e5dc9f" translate="yes" xml:space="preserve">
          <source>a dictionary containing a whole state of the module</source>
          <target state="translated">包含模块整体状态的字典。</target>
        </trans-unit>
        <trans-unit id="00a9b884880389883482dc751408a90f0cb9ee68" translate="yes" xml:space="preserve">
          <source>a dictionary to specify dynamic axes of input/output, such that: - KEY: input and/or output names - VALUE: index of dynamic axes for given key and potentially the name to be used for exported dynamic axes. In general the value is defined according to one of the following ways or a combination of both: (1). A list of integers specifying the dynamic axes of provided input. In this scenario automated names will be generated and applied to dynamic axes of provided input/output during export. OR (2). An inner dictionary that specifies a mapping FROM the index of dynamic axis in corresponding input/output TO the name that is desired to be applied on such axis of such input/output during export.</source>
          <target state="translated">一个字典,用于指定输入/输出的动态轴,如。-KEY:输入和(或)输出名称-VALUE:给定键的动态轴索引,也可能是输出动态轴的名称。一般情况下,value是根据以下一种方式或两者的结合来定义的。(1).一个整数列表,指定所提供输入的动态轴。在这种情况下,在导出过程中,将自动生成并应用于所提供的输入/输出的动态轴的名称。或者 (2).一个内部字典,它指定了从相应输入/输出中的动态轴的索引到希望在输出过程中应用于该输入/输出的该轴的名称的映射。</target>
        </trans-unit>
        <trans-unit id="fc0ea09618fde72378f33c4a6ddb59c0e4510cd0" translate="yes" xml:space="preserve">
          <source>a function for tracing the iteration process. When specified, it is called at each iteration step with LOBPCG instance as an argument. The LOBPCG instance holds the full state of the iteration process in the following attributes:</source>
          <target state="translated">一个用于跟踪迭代过程的函数。当指定时,它在每个迭代步骤中被调用,参数为LOBPCG实例。LOBPCG实例以下列属性保存了迭代过程的全部状态。</target>
        </trans-unit>
        <trans-unit id="f41119365c981a28ba7e837a621a43e97595a3e6" translate="yes" xml:space="preserve">
          <source>a handle that can be used to remove the added hook by calling &lt;code&gt;handle.remove()&lt;/code&gt;</source>
          <target state="translated">一个可以通过调用 &lt;code&gt;handle.remove()&lt;/code&gt; 来删除添加的钩子的句柄</target>
        </trans-unit>
        <trans-unit id="ae26d64a3b3e80ec8246fb0560aeac16291f28f8" translate="yes" xml:space="preserve">
          <source>a list of available entrypoint names</source>
          <target state="translated">可用的入口点名称列表</target>
        </trans-unit>
        <trans-unit id="9f1c5e47605b815eb437073ec1603759477ea676" translate="yes" xml:space="preserve">
          <source>a reference to the execution of &lt;code&gt;func&lt;/code&gt;. The value &lt;code&gt;T&lt;/code&gt; can only be accessed by forcing completion of &lt;code&gt;func&lt;/code&gt; through &lt;code&gt;torch.jit.wait&lt;/code&gt;.</source>
          <target state="translated">对 &lt;code&gt;func&lt;/code&gt; 执行的引用。该值 &lt;code&gt;T&lt;/code&gt; 只能通过强制结束访问 &lt;code&gt;func&lt;/code&gt; 通过 &lt;code&gt;torch.jit.wait&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="33218b2df65cce0092049e58dd8bb1cb81e976cb" translate="yes" xml:space="preserve">
          <source>a single &lt;code&gt;int&lt;/code&gt; &amp;ndash; in which case the same value is used for the depth, height and width dimension</source>
          <target state="translated">单个 &lt;code&gt;int&lt;/code&gt; &amp;ndash;在这种情况下，深度，高度和宽度尺寸将使用相同的值</target>
        </trans-unit>
        <trans-unit id="850561b0cef31ac05a0c3f4be1e02622fadced9d" translate="yes" xml:space="preserve">
          <source>a single &lt;code&gt;int&lt;/code&gt; &amp;ndash; in which case the same value is used for the depth, height and width dimensions</source>
          <target state="translated">单个 &lt;code&gt;int&lt;/code&gt; &amp;ndash;在这种情况下，深度，高度和宽度尺寸使用相同的值</target>
        </trans-unit>
        <trans-unit id="a73b9f710ff83671961055a44ffd5cbbcae7d407" translate="yes" xml:space="preserve">
          <source>a single &lt;code&gt;int&lt;/code&gt; &amp;ndash; in which case the same value is used for the height and width dimension</source>
          <target state="translated">单个 &lt;code&gt;int&lt;/code&gt; &amp;ndash;在这种情况下，高度和宽度尺寸将使用相同的值</target>
        </trans-unit>
        <trans-unit id="13675467768e46f60e5b4830e00591213f355dd1" translate="yes" xml:space="preserve">
          <source>a single &lt;code&gt;int&lt;/code&gt; &amp;ndash; in which case the same value is used for the height and width dimensions</source>
          <target state="translated">单个 &lt;code&gt;int&lt;/code&gt; &amp;ndash;在这种情况下，高度和宽度尺寸将使用相同的值</target>
        </trans-unit>
        <trans-unit id="779476176932b5394791dab09ad1d1763eee6c5b" translate="yes" xml:space="preserve">
          <source>a tensor located on &lt;code&gt;destination&lt;/code&gt; device, that is a result of concatenating &lt;code&gt;tensors&lt;/code&gt; along &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">位于 &lt;code&gt;destination&lt;/code&gt; 设备上的张量，这是沿着 &lt;code&gt;dim&lt;/code&gt; 串联 &lt;code&gt;tensors&lt;/code&gt; 的结果。</target>
        </trans-unit>
        <trans-unit id="db8d55dadf017c53a5cb22f260f3267b482ce8b0" translate="yes" xml:space="preserve">
          <source>a tensor of shape &lt;code&gt;Size([max(input) + 1])&lt;/code&gt; if &lt;code&gt;input&lt;/code&gt; is non-empty, else &lt;code&gt;Size(0)&lt;/code&gt;</source>
          <target state="translated">如果 &lt;code&gt;input&lt;/code&gt; 为非空，则为一个 &lt;code&gt;Size([max(input) + 1])&lt;/code&gt; 为Size（[max（input）+ 1]）的张量，否则为 &lt;code&gt;Size(0)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a1ce48932d1afaa2c16e715f71dcc93e8712b7a3" translate="yes" xml:space="preserve">
          <source>a tuple containing &lt;code&gt;out&lt;/code&gt; tensors, each containing a chunk of &lt;code&gt;tensor&lt;/code&gt;.</source>
          <target state="translated">含有一个元组 &lt;code&gt;out&lt;/code&gt; 张量，每个都包含一大块 &lt;code&gt;tensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ab2e28106a5b9ebc089b8e609fd50c57563064f9" translate="yes" xml:space="preserve">
          <source>a tuple containing &lt;code&gt;out&lt;/code&gt; tensors, each containing a copy of &lt;code&gt;tensor&lt;/code&gt;.</source>
          <target state="translated">含有一个元组 &lt;code&gt;out&lt;/code&gt; 张量，每个包含的拷贝 &lt;code&gt;tensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3a204de89b91437261225e8faf7e8b031ac8eb66" translate="yes" xml:space="preserve">
          <source>a tuple containing chunks of &lt;code&gt;tensor&lt;/code&gt;, placed on &lt;code&gt;devices&lt;/code&gt;.</source>
          <target state="translated">一个包含 &lt;code&gt;tensor&lt;/code&gt; 大块的元组，放置在 &lt;code&gt;devices&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fc7fda381188f8a86d844f77a91f9092c0f7ea9a" translate="yes" xml:space="preserve">
          <source>a tuple containing copies of &lt;code&gt;tensor&lt;/code&gt;, placed on &lt;code&gt;devices&lt;/code&gt;.</source>
          <target state="translated">一个包含张 &lt;code&gt;tensor&lt;/code&gt; 副本的元组，放置在 &lt;code&gt;devices&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3cffaf9b9bcbb730e4c1694aa1ce58215c898bc4" translate="yes" xml:space="preserve">
          <source>above), and</source>
          <target state="translated">以上),以及</target>
        </trans-unit>
        <trans-unit id="82451b41fd7878180b6aa2b54e369cbec4e8032c" translate="yes" xml:space="preserve">
          <source>abs</source>
          <target state="translated">abs</target>
        </trans-unit>
        <trans-unit id="da4dbfbc4fdc56237451cf5e9f9933b2b64f1ba6" translate="yes" xml:space="preserve">
          <source>absolute</source>
          <target state="translated">absolute</target>
        </trans-unit>
        <trans-unit id="8379b4f061ef5249954793884b3e333722e3a581" translate="yes" xml:space="preserve">
          <source>according to the</source>
          <target state="translated">根据</target>
        </trans-unit>
        <trans-unit id="328f0742cf74e8ffdb253376b1803615055e215b" translate="yes" xml:space="preserve">
          <source>acos</source>
          <target state="translated">acos</target>
        </trans-unit>
        <trans-unit id="cae11b2912fc7a669ec8e6fd1ef1797da899527b" translate="yes" xml:space="preserve">
          <source>acosh() -&amp;gt; Tensor</source>
          <target state="translated">acosh（）-&amp;gt;张量</target>
        </trans-unit>
        <trans-unit id="43b9ab0810a93aacba6924ceb0586f3a5ded5277" translate="yes" xml:space="preserve">
          <source>acosh_() -&amp;gt; Tensor</source>
          <target state="translated">acosh_（）-&amp;gt;张量</target>
        </trans-unit>
        <trans-unit id="188c404e728c43b5646acbca5ba76bfe689b737f" translate="yes" xml:space="preserve">
          <source>across all input channels. If called with &lt;code&gt;nn.PReLU(nChannels)&lt;/code&gt;, a separate</source>
          <target state="translated">跨所有输入通道。如果使用 &lt;code&gt;nn.PReLU(nChannels)&lt;/code&gt; 调用，则单独</target>
        </trans-unit>
        <trans-unit id="6bb3255719c068be2327cb70a2b8e43a35888f5b" translate="yes" xml:space="preserve">
          <source>adaptive_avg_pool1d</source>
          <target state="translated">adaptive_avg_pool1d</target>
        </trans-unit>
        <trans-unit id="c61fa142ae65a4935debc614087fb58ff3a6df54" translate="yes" xml:space="preserve">
          <source>adaptive_avg_pool2d</source>
          <target state="translated">adaptive_avg_pool2d</target>
        </trans-unit>
        <trans-unit id="14ce4a9f26f8969b6890e407e6f51988efbeea4c" translate="yes" xml:space="preserve">
          <source>adaptive_avg_pool3d</source>
          <target state="translated">adaptive_avg_pool3d</target>
        </trans-unit>
        <trans-unit id="3aaf9eadafea10463817e8d201b7f07b7265e014" translate="yes" xml:space="preserve">
          <source>adaptive_max_pool1d</source>
          <target state="translated">adaptive_max_pool1d</target>
        </trans-unit>
        <trans-unit id="d3d98fd5af00d45465427af1e01b6955b7cc0483" translate="yes" xml:space="preserve">
          <source>adaptive_max_pool2d</source>
          <target state="translated">adaptive_max_pool2d</target>
        </trans-unit>
        <trans-unit id="a3a21897a04cb4aa98f34167bb5bef9a6168c500" translate="yes" xml:space="preserve">
          <source>adaptive_max_pool3d</source>
          <target state="translated">adaptive_max_pool3d</target>
        </trans-unit>
        <trans-unit id="58d1bbce297de3c304a9fefc3b483181872a5c6b" translate="yes" xml:space="preserve">
          <source>add</source>
          <target state="translated">add</target>
        </trans-unit>
        <trans-unit id="5a96c9fe756bb4bf51deba8e7d88183c67947c4a" translate="yes" xml:space="preserve">
          <source>add (nonzero alpha not supported)</source>
          <target state="translated">添加(不支持非零字母)</target>
        </trans-unit>
        <trans-unit id="d8cab2345ee84bff05fb1af92dc904a85a08122e" translate="yes" xml:space="preserve">
          <source>add_relu</source>
          <target state="translated">add_relu</target>
        </trans-unit>
        <trans-unit id="be4a7c50ca01a7fc792facb9bd955bb98f5efd0f" translate="yes" xml:space="preserve">
          <source>add_scalar</source>
          <target state="translated">add_scalar</target>
        </trans-unit>
        <trans-unit id="d22b6f87e06eb3844a28e850f32f0a7a889d92fe" translate="yes" xml:space="preserve">
          <source>addmm</source>
          <target state="translated">addmm</target>
        </trans-unit>
        <trans-unit id="015bd815072238008dba22c71b1f12d4a0e9ce46" translate="yes" xml:space="preserve">
          <source>affine_grid</source>
          <target state="translated">affine_grid</target>
        </trans-unit>
        <trans-unit id="8bde722d88ff10934184bb1cc67a307b1553065a" translate="yes" xml:space="preserve">
          <source>after a restart. Default: 1.</source>
          <target state="translated">重启后。默认值:1。</target>
        </trans-unit>
        <trans-unit id="186f4cfeddd96df3f01de118db573839422f502a" translate="yes" xml:space="preserve">
          <source>after restart, set</source>
          <target state="translated">重启后,设置</target>
        </trans-unit>
        <trans-unit id="5dc5329726e33c5c40a0fde2a6492a766965bdc3" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._Cat&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._Cat&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="cff8a9de6aa7fa5fc4f28c651af38f742f1fcebf" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._DependentProperty&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._DependentProperty&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="c6de7425cb1a6932219fdf4542beb8455ae1f2ce" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._GreaterThan&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._GreaterThan&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="27d8f16c0fa611de1e5b1506b6023adc7a8d2f87" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._GreaterThanEq&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._GreaterThanEq&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="4e2f7434e9b90fc50cc6286977410f04d80e91a9" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._HalfOpenInterval&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._HalfOpenInterval&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="91d112cab3026dc93f2178836f77313f2d104de5" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._IntegerInterval&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._IntegerInterval&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="6d32f64a8596e02e3341c04582c89898ba004bc0" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._Interval&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._Interval&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="6faf50bed58cc08be17966a6d90c9e06a9764c5f" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._LessThan&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._LessThan&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="5120abef070748d281f11bc2b98b4ec00cc7739e" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;torch.distributions.constraints._Stack&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.distributions.constraints._Stack&lt;/code&gt; 的别名</target>
        </trans-unit>
        <trans-unit id="a4f813ae14b83732a4864c611af5b3566fb3ec62" translate="yes" xml:space="preserve">
          <source>alias of &lt;code&gt;typing.Tuple&lt;/code&gt;</source>
          <target state="translated">类型的别名。 &lt;code&gt;typing.Tuple&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="068aa03cad6f28f79ba1111c747f21ad5b02ebe5" translate="yes" xml:space="preserve">
          <source>all_gather</source>
          <target state="translated">all_gather</target>
        </trans-unit>
        <trans-unit id="d02036fc361150eb3b815512675dec0cfae0d0f3" translate="yes" xml:space="preserve">
          <source>all_reduce</source>
          <target state="translated">all_reduce</target>
        </trans-unit>
        <trans-unit id="d26207411b688464018bef94d89557e73d634e59" translate="yes" xml:space="preserve">
          <source>all_to_all</source>
          <target state="translated">all_to_all</target>
        </trans-unit>
        <trans-unit id="a690d72de3b70e796e4e33522d5b7688578c24c7" translate="yes" xml:space="preserve">
          <source>allowable values are torch.qint8 and torch.quint8. The values of quant_min and quant_max should be chosen to be consistent with the dtype</source>
          <target state="translated">允许的值是 torch.qint8 和 torch.quint8。quant_min 和 quant_max 的值应该选择与 dtype</target>
        </trans-unit>
        <trans-unit id="d554177a50129be7b474c04ec4d6704a4b3ab4b7" translate="yes" xml:space="preserve">
          <source>along &lt;code&gt;dim&lt;/code&gt;, using the trapezoid rule.</source>
          <target state="translated">沿 &lt;code&gt;dim&lt;/code&gt; ，使用梯形法则。</target>
        </trans-unit>
        <trans-unit id="76cd6d3a1710d97fef46a230a4cc6240eb2a1380" translate="yes" xml:space="preserve">
          <source>along &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">沿 &lt;code&gt;dim&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6554d1a5e11c7976a696c18e79f0814b9396668a" translate="yes" xml:space="preserve">
          <source>along dimension &lt;code&gt;dim&lt;/code&gt; is transformed as</source>
          <target state="translated">沿维度 &lt;code&gt;dim&lt;/code&gt; 转换为</target>
        </trans-unit>
        <trans-unit id="be76331b95dfc399cd776d2fc68021e0db03cc4f" translate="yes" xml:space="preserve">
          <source>alpha</source>
          <target state="translated">alpha</target>
        </trans-unit>
        <trans-unit id="4b077706cb8a0c2ebeb6471729485bac1a733acf" translate="yes" xml:space="preserve">
          <source>alpha_dropout</source>
          <target state="translated">alpha_dropout</target>
        </trans-unit>
        <trans-unit id="cffa50a32cb13a240d705317bcec65dd1f31b6ad" translate="yes" xml:space="preserve">
          <source>and</source>
          <target state="translated">and</target>
        </trans-unit>
        <trans-unit id="ea11961808d60532cba9bb74eca2efc9028432b5" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;L&lt;/code&gt; represents a sequence length.</source>
          <target state="translated">和 &lt;code&gt;L&lt;/code&gt; 表示序列长度。</target>
        </trans-unit>
        <trans-unit id="51be83d9e5138cf7da772101995cb9cef885eb19" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;dim = i&lt;/code&gt;, then &lt;code&gt;index&lt;/code&gt; must be an</source>
          <target state="translated">和 &lt;code&gt;dim = i&lt;/code&gt; ，则 &lt;code&gt;index&lt;/code&gt; 必须为</target>
        </trans-unit>
        <trans-unit id="7274e61465c020300a30dd75f2b7c77288b1872f" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;grid&lt;/code&gt; with shape</source>
          <target state="translated">和形状的 &lt;code&gt;grid&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c3e9497e8d92dbb47e859e474f20c5ff68bc011d" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">和 &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="69906b9a4a5287952e8b1f59e1b066d2de6ab17e" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;out&lt;/code&gt; will be a matrix of size</source>
          <target state="translated">和 &lt;code&gt;out&lt;/code&gt; 将大小的矩阵</target>
        </trans-unit>
        <trans-unit id="bfbe811b15a7be917e54a7bd6d548093f12e6464" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;out&lt;/code&gt; will have the same size as &lt;code&gt;index&lt;/code&gt;.</source>
          <target state="translated">和 &lt;code&gt;out&lt;/code&gt; 将具有与 &lt;code&gt;index&lt;/code&gt; 相同的大小。</target>
        </trans-unit>
        <trans-unit id="e8884a6fb0ff6189ded0963ddb98c79c7d9aeb69" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;solution&lt;/code&gt; is the solution</source>
          <target state="translated">和 &lt;code&gt;solution&lt;/code&gt; 是溶液</target>
        </trans-unit>
        <trans-unit id="deb10848a6c3d0e28f26841e04fd508759c1568a" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;vec2&lt;/code&gt; is a vector of size</source>
          <target state="translated">和 &lt;code&gt;vec2&lt;/code&gt; 是大小的矢量</target>
        </trans-unit>
        <trans-unit id="8516d1daf3054c5229e8207676fe21041fa9e2b0" translate="yes" xml:space="preserve">
          <source>and a &lt;code&gt;Tensor&lt;/code&gt; label</source>
          <target state="translated">和 &lt;code&gt;Tensor&lt;/code&gt; 标签</target>
        </trans-unit>
        <trans-unit id="7a32db4530d76c7069a29b591cae084dc90bcd99" translate="yes" xml:space="preserve">
          <source>and a labels tensor</source>
          <target state="translated">和一个标签张量</target>
        </trans-unit>
        <trans-unit id="d9a100e0a04720d0e08f421ee521b4c07271e73c" translate="yes" xml:space="preserve">
          <source>and a margin with a value greater than</source>
          <target state="translated">和差值大于</target>
        </trans-unit>
        <trans-unit id="9bef7a9ca9492d76a989ba472a5134335b532cc1" translate="yes" xml:space="preserve">
          <source>and a matrix</source>
          <target state="translated">和矩阵</target>
        </trans-unit>
        <trans-unit id="994f7a70392302396190552425356c44897b163a" translate="yes" xml:space="preserve">
          <source>and all but the last dimension are the same shape as the input.</source>
          <target state="translated">并且除最后一个维度外,其他维度都与输入的形状相同。</target>
        </trans-unit>
        <trans-unit id="d3efa22a01fb352021085e134597a06af8fdcd21" translate="yes" xml:space="preserve">
          <source>and assumes</source>
          <target state="translated">并假设</target>
        </trans-unit>
        <trans-unit id="02e70de252e8382255cf467699d2e8c35f5e1033" translate="yes" xml:space="preserve">
          <source>and loading from an iterable-style dataset is roughly equivalent with:</source>
          <target state="translated">和从可迭代式数据集加载大致等同于。</target>
        </trans-unit>
        <trans-unit id="44fe67e18a7b0c61be3bcd65d4873d81ff165fe4" translate="yes" xml:space="preserve">
          <source>and multiple right-hand sides</source>
          <target state="translated">和多面手</target>
        </trans-unit>
        <trans-unit id="6b843bb82aff68f312d79ab6cf03a56ace808f2d" translate="yes" xml:space="preserve">
          <source>and one of the following modes is used: - &lt;code&gt;linear&lt;/code&gt; - &lt;code&gt;bilinear&lt;/code&gt; - &lt;code&gt;bicubic&lt;/code&gt; - &lt;code&gt;trilinear&lt;/code&gt;</source>
          <target state="translated">并使用以下模式之一：- &lt;code&gt;linear&lt;/code&gt; - &lt;code&gt;bilinear&lt;/code&gt; - &lt;code&gt;bicubic&lt;/code&gt; - &lt;code&gt;trilinear&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="34c169d448724e62adaa41082c03ac52ab54fff0" translate="yes" xml:space="preserve">
          <source>and output</source>
          <target state="translated">和输出</target>
        </trans-unit>
        <trans-unit id="422022e7df4fc1e7e88e8f2a905326d532895a06" translate="yes" xml:space="preserve">
          <source>and restarts at step</source>
          <target state="translated">并在步骤中重新启动</target>
        </trans-unit>
        <trans-unit id="14b190aab2ad2654706b74c2be95acb6da7f2850" translate="yes" xml:space="preserve">
          <source>and scalar output</source>
          <target state="translated">和标量输出</target>
        </trans-unit>
        <trans-unit id="b34851d4c502e28d96eafba7331ab90e1898bc8d" translate="yes" xml:space="preserve">
          <source>and so forth. If increasing is True, the columns are</source>
          <target state="translated">以此类推。如果递增为真,则列</target>
        </trans-unit>
        <trans-unit id="146cd69984268e3dc94fa6880d4aabdda441d4be" translate="yes" xml:space="preserve">
          <source>and standard deviation</source>
          <target state="translated">和标准差</target>
        </trans-unit>
        <trans-unit id="5bba86a9b83c5aa670a1f3d4c691ac866067b19d" translate="yes" xml:space="preserve">
          <source>and target</source>
          <target state="translated">和目标</target>
        </trans-unit>
        <trans-unit id="9124e7eb2a80bd8e99f0ee162bc6c10019f76e56" translate="yes" xml:space="preserve">
          <source>and target tensor</source>
          <target state="translated">和目标张量</target>
        </trans-unit>
        <trans-unit id="adaffd67d43c3d4bd29c2d4e89911618672f35ec" translate="yes" xml:space="preserve">
          <source>and the LU factorization of A, in order as a namedtuple &lt;code&gt;solution, LU&lt;/code&gt;.</source>
          <target state="translated">和A的LU分解，以便作为命名元组 &lt;code&gt;solution, LU&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3c8e722a8235feec4386550dd50bdb353aabf9b3" translate="yes" xml:space="preserve">
          <source>and the elements of</source>
          <target state="translated">的内容</target>
        </trans-unit>
        <trans-unit id="6058dacca42ad9e7a4c0849aef311147f2ca8455" translate="yes" xml:space="preserve">
          <source>and the total loss functions is</source>
          <target state="translated">和总损失函数为</target>
        </trans-unit>
        <trans-unit id="0f0f37057f618e969e7c100dbe104d0a83309871" translate="yes" xml:space="preserve">
          <source>and vector</source>
          <target state="translated">和矢量</target>
        </trans-unit>
        <trans-unit id="f12fb281ea5401324cfef7c940cff938f57fc26a" translate="yes" xml:space="preserve">
          <source>and we will be able to step into the &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;@torch.jit.script&lt;/code&gt;&lt;/a&gt; function as a normal Python function. To disable the TorchScript compiler for a specific function, see &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">并且我们将能够像普通的Python函数一样进入&lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;@torch.jit.script&lt;/code&gt; &lt;/a&gt;函数。要为特定功能禁用TorchScript编译器，请参阅&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt; &lt;code&gt;@torch.jit.ignore&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="29748c4ec2f5a11f19b122c91c764f2c283a295d" translate="yes" xml:space="preserve">
          <source>and x2 has shape</source>
          <target state="translated">而x2的形状是</target>
        </trans-unit>
        <trans-unit id="abe7ad204a8ebc99e055716a1499632a1e21a7ef" translate="yes" xml:space="preserve">
          <source>and zero point</source>
          <target state="translated">和零点</target>
        </trans-unit>
        <trans-unit id="11a9215ec620218c8e8d409263469091431ff0d4" translate="yes" xml:space="preserve">
          <source>angle</source>
          <target state="translated">angle</target>
        </trans-unit>
        <trans-unit id="4ad4ad16aa212e130ee9bd5ac32ae35842a975fe" translate="yes" xml:space="preserve">
          <source>arange</source>
          <target state="translated">arange</target>
        </trans-unit>
        <trans-unit id="a538840857b54aaa96ea8ec3ac8fb4a13708f87e" translate="yes" xml:space="preserve">
          <source>arbitrary shapes with a total of</source>
          <target state="translated">的任意形状,共有</target>
        </trans-unit>
        <trans-unit id="86c852d13e59fa71b388491fc4ce6baa16edb892" translate="yes" xml:space="preserve">
          <source>are assumed to be 1 and not referenced from</source>
          <target state="translated">假设为1,且不参考来自于</target>
        </trans-unit>
        <trans-unit id="e4876ebe475fcdaae7801e2c6555b7737319caff" translate="yes" xml:space="preserve">
          <source>are computed as:</source>
          <target state="translated">计算公式为:</target>
        </trans-unit>
        <trans-unit id="f920c82e9a5117ed628937a9379bf48075b0898c" translate="yes" xml:space="preserve">
          <source>are learnable affine transform parameters of &lt;code&gt;normalized_shape&lt;/code&gt; if &lt;code&gt;elementwise_affine&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;. The standard-deviation is calculated via the biased estimator, equivalent to &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;elementwise_affine&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ，则是 &lt;code&gt;normalized_shape&lt;/code&gt; 的可学习仿射变换参数。通过偏差估计器计算标准偏差，等效于 &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e538aee8f67210d75bc513a9c556cb3f2c22456c" translate="yes" xml:space="preserve">
          <source>are learnable parameter vectors of size &lt;code&gt;C&lt;/code&gt; (where &lt;code&gt;C&lt;/code&gt; is the input size) if &lt;code&gt;affine&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;. The standard-deviation is calculated via the biased estimator, equivalent to &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;affine&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ,则是大小为 &lt;code&gt;C&lt;/code&gt; 的可学习参数向量（其中 &lt;code&gt;C&lt;/code&gt; 为输入大小）。通过偏差估计器计算标准偏差，等效于 &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="425eb1a701280f929d1aa755a3bd9afffe042bd8" translate="yes" xml:space="preserve">
          <source>are learnable parameter vectors of size &lt;code&gt;C&lt;/code&gt; (where &lt;code&gt;C&lt;/code&gt; is the input size). By default, the elements of</source>
          <target state="translated">是大小为 &lt;code&gt;C&lt;/code&gt; 的可学习参数向量（其中 &lt;code&gt;C&lt;/code&gt; 为输入大小）。默认情况下，</target>
        </trans-unit>
        <trans-unit id="86f4f24ef6637d895465729e95b5618cb38c12be" translate="yes" xml:space="preserve">
          <source>are learnable parameter vectors of size C (where C is the input size) if &lt;code&gt;affine&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;. The standard-deviation is calculated via the biased estimator, equivalent to &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;affine&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ,则是大小为C的可学习参数向量（其中C为输入大小）。通过偏差估计器计算标准偏差，等效于 &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8ff6a70926b2f700851f7fc8c20c594a8e76e9c3" translate="yes" xml:space="preserve">
          <source>are learnable per-channel affine transform parameter vectors of size &lt;code&gt;num_channels&lt;/code&gt; if &lt;code&gt;affine&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;. The standard-deviation is calculated via the biased estimator, equivalent to &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;affine&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ,则是可学习的大小为 &lt;code&gt;num_channels&lt;/code&gt; 的每通道仿射变换参数向量。通过偏差估计器计算标准偏差，等效于 &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="75bf5f4b4eb9c04180b6f81312057902bb428ee6" translate="yes" xml:space="preserve">
          <source>are returned because the real-to-complex Fourier transform satisfies the conjugate symmetry, i.e.,</source>
          <target state="translated">因为实数到复数的傅里叶变换满足共轭对称性,即。</target>
        </trans-unit>
        <trans-unit id="b9344438a3a3542ca4e36035afaf2dc5ecaf2be7" translate="yes" xml:space="preserve">
          <source>are sampled from</source>
          <target state="translated">采样自</target>
        </trans-unit>
        <trans-unit id="2865bbee8d449f1d185c550ec6b590c22b6957d4" translate="yes" xml:space="preserve">
          <source>are set to 0. The standard-deviation is calculated via the biased estimator, equivalent to &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt;.</source>
          <target state="translated">设置为0。通过偏差估计器计算标准偏差，等效于 &lt;code&gt;torch.var(input, unbiased=False)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8ee644b4632f03c7ed8cd56a6d8d3b0a6de1f9ba" translate="yes" xml:space="preserve">
          <source>are set to 1 and the elements of</source>
          <target state="translated">设为1,并且</target>
        </trans-unit>
        <trans-unit id="07c77f1bda818de0208d523f8899b3173d0eae6a" translate="yes" xml:space="preserve">
          <source>are tensors of arbitrary shapes with a total of</source>
          <target state="translated">是任意形状的时序,共有</target>
        </trans-unit>
        <trans-unit id="d1792693a82797275a29dc724b1fdb08fe5cef51" translate="yes" xml:space="preserve">
          <source>are the dimensions of the matrix.</source>
          <target state="translated">是矩阵的维度。</target>
        </trans-unit>
        <trans-unit id="eb06c7309fb6a43a67a1cdf5bde8c81dbe8d348d" translate="yes" xml:space="preserve">
          <source>are the input, forget, cell, and output gates, respectively.</source>
          <target state="translated">分别是输入、忘记、单元和输出门。</target>
        </trans-unit>
        <trans-unit id="1ab04c3136643cd3b0d7e5db6c93dfabb34510d0" translate="yes" xml:space="preserve">
          <source>are the minimum and maximum of the quantized data type.</source>
          <target state="translated">是量化数据类型的最小值和最大值。</target>
        </trans-unit>
        <trans-unit id="1d1f1537fbffe574251e7df78749efa3f5feee9a" translate="yes" xml:space="preserve">
          <source>are the only supported values.</source>
          <target state="translated">是唯一支持的值。</target>
        </trans-unit>
        <trans-unit id="8ef8bf39209d2f2fce9681f8054b40e4806ff7f6" translate="yes" xml:space="preserve">
          <source>are the parameters,</source>
          <target state="translated">是参数。</target>
        </trans-unit>
        <trans-unit id="9b2535542a411be559b351451bde244b4f033b2f" translate="yes" xml:space="preserve">
          <source>are the reset, update, and new gates, respectively.</source>
          <target state="translated">分别是复位门、更新门和新门。</target>
        </trans-unit>
        <trans-unit id="05b98babf9d8d0da7974d92dffc5a3f4ea246a9c" translate="yes" xml:space="preserve">
          <source>are then computed as:</source>
          <target state="translated">然后计算为:</target>
        </trans-unit>
        <trans-unit id="d4665f1e2ffa54be784f9b474fe768613b821365" translate="yes" xml:space="preserve">
          <source>argmax</source>
          <target state="translated">argmax</target>
        </trans-unit>
        <trans-unit id="4538ebc5d50e576bcdd8095d274394500be1d3e0" translate="yes" xml:space="preserve">
          <source>argmin</source>
          <target state="translated">argmin</target>
        </trans-unit>
        <trans-unit id="0a960f0a485739de9ec7e0394dd5e46da6afde09" translate="yes" xml:space="preserve">
          <source>as below</source>
          <target state="translated">如下</target>
        </trans-unit>
        <trans-unit id="908b35dcf789b151ab044796ae0006bab35551e6" translate="yes" xml:space="preserve">
          <source>as described above</source>
          <target state="translated">如上所述</target>
        </trans-unit>
        <trans-unit id="98d3a6b6e515d500e9df2fee1f684162fcc532ee" translate="yes" xml:space="preserve">
          <source>as explicit separate matrices.</source>
          <target state="translated">作为明确的独立矩阵。</target>
        </trans-unit>
        <trans-unit id="196302a3f9515657b0c55dab8c474613624309d3" translate="yes" xml:space="preserve">
          <source>as the &lt;code&gt;target&lt;/code&gt; for each value of a 1D tensor of size &lt;code&gt;minibatch&lt;/code&gt;; if &lt;code&gt;ignore_index&lt;/code&gt; is specified, this criterion also accepts this class index (this index may not necessarily be in the class range).</source>
          <target state="translated">作为 &lt;code&gt;minibatch&lt;/code&gt; 的一维张量的每个值的 &lt;code&gt;target&lt;/code&gt; ; 如果指定了 &lt;code&gt;ignore_index&lt;/code&gt; ，则此条件也接受该类索引（此索引可能不一定在类范围内）。</target>
        </trans-unit>
        <trans-unit id="c3e04b10767441eb9b4b0a57a2d62cbb77d5cdad" translate="yes" xml:space="preserve">
          <source>as vec norm when dim is None</source>
          <target state="translated">当dim为None时,作为vec norm</target>
        </trans-unit>
        <trans-unit id="73688580af35401988ca63c730bbff475def44d3" translate="yes" xml:space="preserve">
          <source>as:</source>
          <target state="translated">as:</target>
        </trans-unit>
        <trans-unit id="6480588dae849f3cd69c8be01b990f84ce70a375" translate="yes" xml:space="preserve">
          <source>as_strided</source>
          <target state="translated">as_strided</target>
        </trans-unit>
        <trans-unit id="f6b3e9a1435d3f432e7a6b9003583871fcb26de3" translate="yes" xml:space="preserve">
          <source>asin</source>
          <target state="translated">asin</target>
        </trans-unit>
        <trans-unit id="0217022a2cbba3beab97d37baf8f0e78d8404ee5" translate="yes" xml:space="preserve">
          <source>asynchronous operation - when &lt;code&gt;async_op&lt;/code&gt; is set to True. The collective operation function returns a distributed request object. In general, you don&amp;rsquo;t need to create it manually and it is guaranteed to support two methods:</source>
          <target state="translated">异步操作-当 &lt;code&gt;async_op&lt;/code&gt; 设置为True时。集合操作函数返回一个分布式请求对象。通常，您不需要手动创建它，并且可以保证支持以下两种方法：</target>
        </trans-unit>
        <trans-unit id="0366fd6a49c84920645a67d8439d5e2e6075abe4" translate="yes" xml:space="preserve">
          <source>at each cycle iteration.</source>
          <target state="translated">在每个周期迭代时。</target>
        </trans-unit>
        <trans-unit id="f077504d04fa1bc96b042497b434fd33fabdf43d" translate="yes" xml:space="preserve">
          <source>atan</source>
          <target state="translated">atan</target>
        </trans-unit>
        <trans-unit id="12dad2bbce60ee2bc83c285aa39dca395465f305" translate="yes" xml:space="preserve">
          <source>atol</source>
          <target state="translated">atol</target>
        </trans-unit>
        <trans-unit id="cfacbf356c29ecafbd9f709c475179843abdd31e" translate="yes" xml:space="preserve">
          <source>attn_mask: 2D mask</source>
          <target state="translated">attn_mask:二维掩码</target>
        </trans-unit>
        <trans-unit id="cc13d40f3fdefe8666e6601dc54517fbb0641b8a" translate="yes" xml:space="preserve">
          <source>attn_output:</source>
          <target state="translated">attn_output:</target>
        </trans-unit>
        <trans-unit id="4cac88fb84e0dd512ca9b04f9392aa70146ed77a" translate="yes" xml:space="preserve">
          <source>attn_output_weights:</source>
          <target state="translated">attn_output_weights:</target>
        </trans-unit>
        <trans-unit id="87792e7cfa548e657093e5c536428e801de627fe" translate="yes" xml:space="preserve">
          <source>avg_pool1d</source>
          <target state="translated">avg_pool1d</target>
        </trans-unit>
        <trans-unit id="8454dbf5a788a4fc7b69874c4fe549fff6d01e4a" translate="yes" xml:space="preserve">
          <source>avg_pool2d</source>
          <target state="translated">avg_pool2d</target>
        </trans-unit>
        <trans-unit id="99a1901d4567084ff3e326ca553c35a49cbcc708" translate="yes" xml:space="preserve">
          <source>avg_pool3d</source>
          <target state="translated">avg_pool3d</target>
        </trans-unit>
        <trans-unit id="e9d71f5ee7c92d6dc9e92ffdad17b8bd49418f98" translate="yes" xml:space="preserve">
          <source>b</source>
          <target state="translated">b</target>
        </trans-unit>
        <trans-unit id="ab598131b37324cb1420d88178e195226078e8ec" translate="yes" xml:space="preserve">
          <source>b_{c} = a_{c}\left(k + \frac{\alpha}{n} \sum_{c'=\max(0, c-n/2)}^{\min(N-1,c+n/2)}a_{c'}^2\right)^{-\beta}</source>
          <target state="translated">b_{c}=a_{c}left(k+\frac{alpha}{n}{sum_{c'=\max(0,c-n/2)}^{/min(N-1,c+n/2)}a_{c'}^2right)^{-\beta}。</target>
        </trans-unit>
        <trans-unit id="07949b7c55cab1a81db23f348c3409b06fc9ee75" translate="yes" xml:space="preserve">
          <source>baddbmm</source>
          <target state="translated">baddbmm</target>
        </trans-unit>
        <trans-unit id="779455ee3bde8494d9629b353e17b19e92357ba8" translate="yes" xml:space="preserve">
          <source>barrier</source>
          <target state="translated">barrier</target>
        </trans-unit>
        <trans-unit id="1405df66cbe219b0bf6355bc3d60361a8376b6b4" translate="yes" xml:space="preserve">
          <source>base</source>
          <target state="translated">base</target>
        </trans-unit>
        <trans-unit id="115bac8f958d7eaf610aede34fad2562c346e505" translate="yes" xml:space="preserve">
          <source>batch size</source>
          <target state="translated">批量</target>
        </trans-unit>
        <trans-unit id="31442bf4302dd7b34e796318f57912b743ccccf0" translate="yes" xml:space="preserve">
          <source>batch1</source>
          <target state="translated">batch1</target>
        </trans-unit>
        <trans-unit id="1d1b6777e9c5a97a6a039ea824d68ee915cc1491" translate="yes" xml:space="preserve">
          <source>batch2</source>
          <target state="translated">batch2</target>
        </trans-unit>
        <trans-unit id="b30c0788a62514c66ada13cce11022313c9e5df0" translate="yes" xml:space="preserve">
          <source>batch_norm</source>
          <target state="translated">batch_norm</target>
        </trans-unit>
        <trans-unit id="793787e7648c00d5d9f56d9f3ee2a1d2314216d8" translate="yes" xml:space="preserve">
          <source>being an orthogonal matrix or batch of orthogonal matrices and</source>
          <target state="translated">是一个正交矩阵或一批正交矩阵,而</target>
        </trans-unit>
        <trans-unit id="b50848b7bdcbc01d3b72f5bb1ce5b7a00a5aad61" translate="yes" xml:space="preserve">
          <source>being an upper triangular matrix or batch of upper triangular matrices.</source>
          <target state="translated">是一个上三角矩阵或一批上三角矩阵。</target>
        </trans-unit>
        <trans-unit id="4928df7f06c7ee461e27540fb51dac9bf4b670ad" translate="yes" xml:space="preserve">
          <source>beta is an optional parameter that defaults to 1.</source>
          <target state="translated">beta是一个可选参数,默认为1。</target>
        </trans-unit>
        <trans-unit id="736c1fbfd886e877040ee4134960bc63ce05262d" translate="yes" xml:space="preserve">
          <source>between two distributions.</source>
          <target state="translated">两种分布之间。</target>
        </trans-unit>
        <trans-unit id="e1e8289afa6b54e410bc2304308fe48e83a8ef02" translate="yes" xml:space="preserve">
          <source>bias</source>
          <target state="translated">bias</target>
        </trans-unit>
        <trans-unit id="5b74ed2accf3a37671aad25b7b91bed84cad9a6e" translate="yes" xml:space="preserve">
          <source>bias:</source>
          <target state="translated">bias:</target>
        </trans-unit>
        <trans-unit id="a1ceb3e5387c09cb212ce6ee3c3c1a476297155d" translate="yes" xml:space="preserve">
          <source>bilinear</source>
          <target state="translated">bilinear</target>
        </trans-unit>
        <trans-unit id="2e1157f96f8af393a261e4d71a43aa637f30cb60" translate="yes" xml:space="preserve">
          <source>binary answer to whether &lt;code&gt;module&lt;/code&gt; is pruned.</source>
          <target state="translated">是否修剪 &lt;code&gt;module&lt;/code&gt; 二进制答案。</target>
        </trans-unit>
        <trans-unit id="74c77efd9714f8e8eecdc286f7d29c392001890c" translate="yes" xml:space="preserve">
          <source>binary_cross_entropy</source>
          <target state="translated">binary_cross_entropy</target>
        </trans-unit>
        <trans-unit id="b6c72f603883e86a6cb8021afc246ea5ec1382f5" translate="yes" xml:space="preserve">
          <source>binary_cross_entropy_with_logits</source>
          <target state="translated">binary_cross_entropy_with_logits</target>
        </trans-unit>
        <trans-unit id="0569ae912e387dbc988dee842bf17cdd4e437f63" translate="yes" xml:space="preserve">
          <source>bits</source>
          <target state="translated">bits</target>
        </trans-unit>
        <trans-unit id="b3334e38fd49d5a88ca98cd30878d427a4ddbf06" translate="yes" xml:space="preserve">
          <source>bitshift</source>
          <target state="translated">bitshift</target>
        </trans-unit>
        <trans-unit id="e4e1043a1b984700e67896c1396be3aa962489d5" translate="yes" xml:space="preserve">
          <source>blank=0</source>
          <target state="translated">blank=0</target>
        </trans-unit>
        <trans-unit id="4d46077c78ecf87402848fc9f920b72cde953b02" translate="yes" xml:space="preserve">
          <source>bound</source>
          <target state="translated">bound</target>
        </trans-unit>
        <trans-unit id="7717af821763c86c1249c0045aa20cfbed718b66" translate="yes" xml:space="preserve">
          <source>box AP</source>
          <target state="translated">盒式AP</target>
        </trans-unit>
        <trans-unit id="aa06eab1f6ebf63aafea56f4652eca504ae7b58f" translate="yes" xml:space="preserve">
          <source>boxes (&lt;code&gt;FloatTensor[N, 4]&lt;/code&gt;): the ground-truth boxes in &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; format, with values between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;H&lt;/code&gt; and &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;W&lt;/code&gt;</source>
          <target state="translated">框（ &lt;code&gt;FloatTensor[N, 4]&lt;/code&gt; ）：实地框，格式为 &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; ，值介于 &lt;code&gt;0&lt;/code&gt; 和 &lt;code&gt;H&lt;/code&gt; 之间以及 &lt;code&gt;0&lt;/code&gt; 和 &lt;code&gt;W&lt;/code&gt; 之间</target>
        </trans-unit>
        <trans-unit id="bf13e93de62c26c00d7b1d7846899f810d8062c3" translate="yes" xml:space="preserve">
          <source>boxes (&lt;code&gt;FloatTensor[N, 4]&lt;/code&gt;): the ground-truth boxes in &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; format, with values of &lt;code&gt;x&lt;/code&gt; between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;W&lt;/code&gt; and values of &lt;code&gt;y&lt;/code&gt; between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;H&lt;/code&gt;</source>
          <target state="translated">盒（ &lt;code&gt;FloatTensor[N, 4]&lt;/code&gt; ）：在地面实况盒 &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; 的格式，具有值 &lt;code&gt;x&lt;/code&gt; 之间 &lt;code&gt;0&lt;/code&gt; 和 &lt;code&gt;W&lt;/code&gt; 的和值 &lt;code&gt;y&lt;/code&gt; 之间 &lt;code&gt;0&lt;/code&gt; 和 &lt;code&gt;H&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4523bad4432d4b614f44a286645e98445b5fdb92" translate="yes" xml:space="preserve">
          <source>boxes (&lt;code&gt;FloatTensor[N, 4]&lt;/code&gt;): the predicted boxes in &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; format, with values between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;H&lt;/code&gt; and &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;W&lt;/code&gt;</source>
          <target state="translated">box（ &lt;code&gt;FloatTensor[N, 4]&lt;/code&gt; ）：预测的框，格式为 &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; ，值介于 &lt;code&gt;0&lt;/code&gt; 和 &lt;code&gt;H&lt;/code&gt; 之间以及 &lt;code&gt;0&lt;/code&gt; 和 &lt;code&gt;W&lt;/code&gt; 之间</target>
        </trans-unit>
        <trans-unit id="99db80efa8d4fb3770cb46ce8d01afcb432bd25a" translate="yes" xml:space="preserve">
          <source>boxes (&lt;code&gt;FloatTensor[N, 4]&lt;/code&gt;): the predicted boxes in &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; format, with values of &lt;code&gt;x&lt;/code&gt; between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;W&lt;/code&gt; and values of &lt;code&gt;y&lt;/code&gt; between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;H&lt;/code&gt;</source>
          <target state="translated">box（ &lt;code&gt;FloatTensor[N, 4]&lt;/code&gt; ）：预测的框，格式为 &lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt; ， &lt;code&gt;x&lt;/code&gt; 的值在 &lt;code&gt;0&lt;/code&gt; 到 &lt;code&gt;W&lt;/code&gt; 之间， &lt;code&gt;y&lt;/code&gt; 的值在 &lt;code&gt;0&lt;/code&gt; 到 &lt;code&gt;H&lt;/code&gt; 之间</target>
        </trans-unit>
        <trans-unit id="b58ccb7871e0261dfe6de9e4f5274543ebbebeb8" translate="yes" xml:space="preserve">
          <source>broadcast</source>
          <target state="translated">broadcast</target>
        </trans-unit>
        <trans-unit id="8ab478517af17507ee846089a366bb3e5480b24d" translate="yes" xml:space="preserve">
          <source>but slower. Default: &lt;em&gt;False&lt;/em&gt;. See &lt;a href=&quot;https://arxiv.org/pdf/1707.06990.pdf&quot;&gt;&amp;ldquo;paper&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">但慢一点。默认值：&lt;em&gt;False&lt;/em&gt;。见&lt;a href=&quot;https://arxiv.org/pdf/1707.06990.pdf&quot;&gt;&amp;ldquo;纸&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="408158643ed564c72fa0921826f8294d71ccbf7c" translate="yes" xml:space="preserve">
          <source>by</source>
          <target state="translated">by</target>
        </trans-unit>
        <trans-unit id="3e8a60d5f4e9887048f1c82dc39ab1673602aa1e" translate="yes" xml:space="preserve">
          <source>by summing the overlapping values. Similar to &lt;a href=&quot;torch.nn.unfold#torch.nn.Unfold&quot;&gt;&lt;code&gt;Unfold&lt;/code&gt;&lt;/a&gt;, the arguments must satisfy</source>
          <target state="translated">通过对重叠值求和。与&amp;ldquo;&lt;a href=&quot;torch.nn.unfold#torch.nn.Unfold&quot;&gt; &lt;code&gt;Unfold&lt;/code&gt; &lt;/a&gt;类似，参数必须满足</target>
        </trans-unit>
        <trans-unit id="84a516841ba77a5b4648de2cd0dfcb30ea46dbb4" translate="yes" xml:space="preserve">
          <source>c</source>
          <target state="translated">c</target>
        </trans-unit>
        <trans-unit id="7ba642b78cae54611d3ce19d3a3b9315a889b623" translate="yes" xml:space="preserve">
          <source>c &amp;gt; 1</source>
          <target state="translated">c &amp;gt; 1</target>
        </trans-unit>
        <trans-unit id="a695701dc8bcc878e55225bb88a2be5e0250b7f9" translate="yes" xml:space="preserve">
          <source>c = (u u^T)^{{-1}} b</source>
          <target state="translated">c=(u u^T)^{{-1}}b。</target>
        </trans-unit>
        <trans-unit id="325406a6e81b2954fe93c1849e849987a40ad22c" translate="yes" xml:space="preserve">
          <source>c = (u^T u)^{{-1}} b</source>
          <target state="translated">c=(u^T u)^{{-1}}b。</target>
        </trans-unit>
        <trans-unit id="9db33fa0cd63d5bcc994a2d10aee7aa1c6cf5234" translate="yes" xml:space="preserve">
          <source>c = 1</source>
          <target state="translated">c=1</target>
        </trans-unit>
        <trans-unit id="75e4c1ce919ca4246ccdfcf0f90143995bdcf09e" translate="yes" xml:space="preserve">
          <source>c_t</source>
          <target state="translated">c_t</target>
        </trans-unit>
        <trans-unit id="52a612a982a939b9f63856d2f4f4f8c12f2509f8" translate="yes" xml:space="preserve">
          <source>can be adjusted using &lt;code&gt;min_val&lt;/code&gt; and &lt;code&gt;max_val&lt;/code&gt;.</source>
          <target state="translated">可以使用 &lt;code&gt;min_val&lt;/code&gt; 和 &lt;code&gt;max_val&lt;/code&gt; 进行调整。</target>
        </trans-unit>
        <trans-unit id="4d83e8bdc70262378c30c2dddd5537deeb8a96c5" translate="yes" xml:space="preserve">
          <source>can be avoided if one sets &lt;code&gt;reduction = 'sum'&lt;/code&gt;.</source>
          <target state="translated">如果一组 &lt;code&gt;reduction = 'sum'&lt;/code&gt; 可以避免。</target>
        </trans-unit>
        <trans-unit id="90bd565efaf349a2fc8e4dc779050d0325ec50a1" translate="yes" xml:space="preserve">
          <source>can be avoided if sets &lt;code&gt;reduction = 'sum'&lt;/code&gt;.</source>
          <target state="translated">如果集合 &lt;code&gt;reduction = 'sum'&lt;/code&gt; 可以避免。</target>
        </trans-unit>
        <trans-unit id="3c65ddc9ba0e2d191602d3c173ef6a188ce419ee" translate="yes" xml:space="preserve">
          <source>can be precisely described as:</source>
          <target state="translated">可以准确描述为:</target>
        </trans-unit>
        <trans-unit id="8634627c53b593a107a2ce1c2b724bc47ea5e431" translate="yes" xml:space="preserve">
          <source>can be used to compute normalized (unit length) eigenvectors of corresponding eigenvalues as follows. If the corresponding &lt;code&gt;eigenvalues[j]&lt;/code&gt; is a real number, column &lt;code&gt;eigenvectors[:, j]&lt;/code&gt; is the eigenvector corresponding to &lt;code&gt;eigenvalues[j]&lt;/code&gt;. If the corresponding &lt;code&gt;eigenvalues[j]&lt;/code&gt; and &lt;code&gt;eigenvalues[j + 1]&lt;/code&gt; form a complex conjugate pair, then the true eigenvectors can be computed as</source>
          <target state="translated">可以用于计算相应特征值的归一化（单位长度）特征向量，如下所示。如果对应的 &lt;code&gt;eigenvalues[j]&lt;/code&gt; 是实数，则列 &lt;code&gt;eigenvectors[:, j]&lt;/code&gt; 是对应于 &lt;code&gt;eigenvalues[j]&lt;/code&gt; 的特征向量。如果相应的 &lt;code&gt;eigenvalues[j]&lt;/code&gt; 和 &lt;code&gt;eigenvalues[j + 1]&lt;/code&gt; 形成复共轭对，则可以将真实特征向量计算为</target>
        </trans-unit>
        <trans-unit id="9d989e8d27dc9e0ec3389fc855f142c3d40f0c50" translate="yes" xml:space="preserve">
          <source>cat</source>
          <target state="translated">cat</target>
        </trans-unit>
        <trans-unit id="613af80c25dfbc9ef75ce605280571b9a518d632" translate="yes" xml:space="preserve">
          <source>ceil</source>
          <target state="translated">ceil</target>
        </trans-unit>
        <trans-unit id="8cc51bda059df43f07da456966946b85e1e39fed" translate="yes" xml:space="preserve">
          <source>celu</source>
          <target state="translated">celu</target>
        </trans-unit>
        <trans-unit id="a4ab4f21160cf5b0a8b70fd62605f209cd8eb378" translate="yes" xml:space="preserve">
          <source>clamp</source>
          <target state="translated">clamp</target>
        </trans-unit>
        <trans-unit id="0b03af5027f5174c31ba5792d65334dc4b86d0c4" translate="yes" xml:space="preserve">
          <source>clamp_max</source>
          <target state="translated">clamp_max</target>
        </trans-unit>
        <trans-unit id="c71e6f6650b2c00996a576acfebb2e5c2c9133bc" translate="yes" xml:space="preserve">
          <source>clamp_min</source>
          <target state="translated">clamp_min</target>
        </trans-unit>
        <trans-unit id="af6ab064a94fb3e9fd590a99e474c2ed6fe59e97" translate="yes" xml:space="preserve">
          <source>clear()</source>
          <target state="translated">clear()</target>
        </trans-unit>
        <trans-unit id="dde02ec247dcb158d65d0da1bdd9301502952f4f" translate="yes" xml:space="preserve">
          <source>clip_value</source>
          <target state="translated">clip_value</target>
        </trans-unit>
        <trans-unit id="5dc3fded50a44a781130cc74e32147cfb27fb2b1" translate="yes" xml:space="preserve">
          <source>colors:</source>
          <target state="translated">colors:</target>
        </trans-unit>
        <trans-unit id="ec3d37cfb39e6ddfa966aa2a0e1cc364f09c1aac" translate="yes" xml:space="preserve">
          <source>columns (when specified) or &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">列（指定时）或 &lt;code&gt;1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d8f2c317f524276e700bfcb20a9ddc27b06eedc5" translate="yes" xml:space="preserve">
          <source>columns of &lt;code&gt;input&lt;/code&gt; are linearly independent. This behavior will propably change once QR supports pivoting.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 列是线性独立的。一旦QR支持旋转，此行为将适当改变。</target>
        </trans-unit>
        <trans-unit id="a3ed4cce473629e46512b31377e0c26f8c611bf9" translate="yes" xml:space="preserve">
          <source>columns represent the principal directions</source>
          <target state="translated">列代表主要方向</target>
        </trans-unit>
        <trans-unit id="805682fdf2befd0f72b7d16894fd58f0d033c065" translate="yes" xml:space="preserve">
          <source>columns.</source>
          <target state="translated">columns.</target>
        </trans-unit>
        <trans-unit id="49ba358c3272c2db40fc6ab2c103669678628b68" translate="yes" xml:space="preserve">
          <source>concat</source>
          <target state="translated">concat</target>
        </trans-unit>
        <trans-unit id="afad9a69767e7c24ecda5af9187202e1b4b070b2" translate="yes" xml:space="preserve">
          <source>condition</source>
          <target state="translated">condition</target>
        </trans-unit>
        <trans-unit id="f607ae1e89eb5c8e88a5312b0347f07cd629f09e" translate="yes" xml:space="preserve">
          <source>conduct; niter must be a nonnegative integer, and defaults to 2</source>
          <target state="translated">conduct;niter必须是一个非负的整数,默认为2。</target>
        </trans-unit>
        <trans-unit id="0713af050ff5d1185e252e762af4f2837f6692ed" translate="yes" xml:space="preserve">
          <source>containing the window</source>
          <target state="translated">窗口</target>
        </trans-unit>
        <trans-unit id="d75270e5e6de30e18e4c2d9c2c4833c4b41b71ea" translate="yes" xml:space="preserve">
          <source>contains the eigenvalues of</source>
          <target state="translated">的特征值,包含</target>
        </trans-unit>
        <trans-unit id="edf1afc933ef93b4de4eecc542db49d0c5ac72fd" translate="yes" xml:space="preserve">
          <source>contains the solution. If</source>
          <target state="translated">包含解决方案。如果</target>
        </trans-unit>
        <trans-unit id="963bb6a82e1a90627d6c03382ec4d1cf449f21be" translate="yes" xml:space="preserve">
          <source>conv1d</source>
          <target state="translated">conv1d</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
