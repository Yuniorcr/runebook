<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="360796ce4b88f8a72813e93a376d34c0228713ee" translate="yes" xml:space="preserve">
          <source>Add histogram to summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b6b7d6099858bcb255707e61a495522a0414994" translate="yes" xml:space="preserve">
          <source>Add image data to summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a392c90962df4acfb05e6d0ec46fd5a47980ff9d" translate="yes" xml:space="preserve">
          <source>Add meshes or 3D point clouds to TensorBoard. The visualization is based on Three.js, so it allows users to interact with the rendered object. Besides the basic definitions such as vertices, faces, users can further provide camera parameter, lighting condition, etc. Please check &lt;a href=&quot;https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene&quot;&gt;https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene&lt;/a&gt; for advanced usage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a9584fc26e356ef39ba9497c010651d8eae52d2" translate="yes" xml:space="preserve">
          <source>Add observer for the leaf child of the module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="701a19440eea643652da7e69f517b8c3d995eacc" translate="yes" xml:space="preserve">
          <source>Add scalar data to summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a54b0b6b6b02f66bd6beaecffa1d99a5f7eb192" translate="yes" xml:space="preserve">
          <source>Add text data to summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c77f8dadb528de130d984e34a450fb3582dda9aa" translate="yes" xml:space="preserve">
          <source>Add video data to summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8afe6f3185ed76e023f80393638df4f157d48f52" translate="yes" xml:space="preserve">
          <source>Adding export support for operators is an &lt;em&gt;advance usage&lt;/em&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c9c6ec239352be639e5bda7f0d0b398caeb9237" translate="yes" xml:space="preserve">
          <source>Adding support for operators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e032cc35826dbb2a4a560c47d8b0573e59463ab" translate="yes" xml:space="preserve">
          <source>Additional args:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b02695e3612016d107e21b0824bdec94963550bb" translate="yes" xml:space="preserve">
          <source>Additionally accepts an optional &lt;code&gt;reduce&lt;/code&gt; argument that allows specification of an optional reduction operation, which is applied to all values in the tensor &lt;code&gt;src&lt;/code&gt; into &lt;code&gt;self&lt;/code&gt; at the indicies specified in the &lt;code&gt;index&lt;/code&gt;. For each value in &lt;code&gt;src&lt;/code&gt;, the reduction operation is applied to an index in &lt;code&gt;self&lt;/code&gt; which is specified by its index in &lt;code&gt;src&lt;/code&gt; for &lt;code&gt;dimension != dim&lt;/code&gt; and by the corresponding value in &lt;code&gt;index&lt;/code&gt; for &lt;code&gt;dimension = dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9baa44eaf376e383c39686ddc11f7bd15a1ea88" translate="yes" xml:space="preserve">
          <source>Adds a buffer to the module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="677c1d2632a65843e9a01046b892b48b9f5176ac" translate="yes" xml:space="preserve">
          <source>Adds a child module to the current module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96b77db46874289e2dd12b6bc9489ce00f46440a" translate="yes" xml:space="preserve">
          <source>Adds a child pruning &lt;code&gt;method&lt;/code&gt; to the container.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9bccaca3fe9322a4122d15d5e4fdb25202c0320" translate="yes" xml:space="preserve">
          <source>Adds a parameter to the module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fc7b19e96d1e48b76f041d88e6e8c8791a06fa6" translate="yes" xml:space="preserve">
          <source>Adds all values from the tensor &lt;code&gt;other&lt;/code&gt; into &lt;code&gt;self&lt;/code&gt; at the indices specified in the &lt;code&gt;index&lt;/code&gt; tensor in a similar fashion as &lt;a href=&quot;#torch.Tensor.scatter_&quot;&gt;&lt;code&gt;scatter_()&lt;/code&gt;&lt;/a&gt;. For each value in &lt;code&gt;src&lt;/code&gt;, it is added to an index in &lt;code&gt;self&lt;/code&gt; which is specified by its index in &lt;code&gt;src&lt;/code&gt; for &lt;code&gt;dimension != dim&lt;/code&gt; and by the corresponding value in &lt;code&gt;index&lt;/code&gt; for &lt;code&gt;dimension = dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8562c008b76c53309d3a0973a409f19d43babb11" translate="yes" xml:space="preserve">
          <source>Adds many scalar data to summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8058a9f23e00e9bb14b6abf55b56e8a8543f9c29" translate="yes" xml:space="preserve">
          <source>Adds precision recall curve. Plotting a precision-recall curve lets you understand your model&amp;rsquo;s performance under different threshold settings. With this function, you provide the ground truth labeling (T/F) and prediction confidence (usually the output of your model) for each target. The TensorBoard UI will let you choose the threshold interactively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd54948ee53264250bb1b351262b4ccb8986d94e" translate="yes" xml:space="preserve">
          <source>Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab685d43fc5e49c46e526f76f07f3d59e811972e" translate="yes" xml:space="preserve">
          <source>Adds the scalar &lt;code&gt;other&lt;/code&gt; to each element of the input &lt;code&gt;input&lt;/code&gt; and returns a new resulting tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2b204082818c243f404c5bfdc3dc16bbc32640c" translate="yes" xml:space="preserve">
          <source>After a class is defined, it can be used in both TorchScript and Python interchangeably like any other TorchScript type:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd74631d206c5c267345dcc56490ab6ea1c83f20" translate="yes" xml:space="preserve">
          <source>After an enum is defined, it can be used in both TorchScript and Python interchangeably like any other TorchScript type. The type of the values of an enum must be &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, or &lt;code&gt;str&lt;/code&gt;. All values must be of the same type; heterogenous types for enum values are not supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="587806098e59106c8c783b918f92e7fc29e4d2ab" translate="yes" xml:space="preserve">
          <source>After fetching a list of samples using the indices from sampler, the function passed as the &lt;code&gt;collate_fn&lt;/code&gt; argument is used to collate lists of samples into batches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c52a739b9d98878e44d92e91256235a6d294431c" translate="yes" xml:space="preserve">
          <source>After the call &lt;code&gt;tensor&lt;/code&gt; is going to be bitwise identical in all processes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3dd860a8580060d82d526ad04c5badbd57df94f" translate="yes" xml:space="preserve">
          <source>After the call, all 16 tensors on the two nodes will have the all-reduced value of 16</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e03f01ec1cb89a34bde4816ebeb0fe756b9b7364" translate="yes" xml:space="preserve">
          <source>After the call, all &lt;code&gt;tensor&lt;/code&gt; in &lt;code&gt;tensor_list&lt;/code&gt; is going to be bitwise identical in all processes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ae05a9ce240652b1911853b65ddd62f9764383c" translate="yes" xml:space="preserve">
          <source>AlexNet</source>
          <target state="translated">AlexNet</target>
        </trans-unit>
        <trans-unit id="ca5a1956913984160d31d9bf92ec542323ba8065" translate="yes" xml:space="preserve">
          <source>AlexNet model architecture from the &lt;a href=&quot;https://arxiv.org/abs/1404.5997&quot;&gt;&amp;ldquo;One weird trick&amp;hellip;&amp;rdquo;&lt;/a&gt; paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52fc4196dd42d00268d82ad7f69953e231b88729" translate="yes" xml:space="preserve">
          <source>Alexnet</source>
          <target state="translated">Alexnet</target>
        </trans-unit>
        <trans-unit id="67e15eb99dc0e473c962d6a494d00e048e9f6fc6" translate="yes" xml:space="preserve">
          <source>Algorithms</source>
          <target state="translated">Algorithms</target>
        </trans-unit>
        <trans-unit id="c4836f5ef10696c1523f7a542472a979fa86940f" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;#torch.Tensor.clamp&quot;&gt;&lt;code&gt;clamp()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="251f8be41a3289fe0ff13ca86e83184aaa6d1685" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;#torch.Tensor.clamp_&quot;&gt;&lt;code&gt;clamp_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b1674d7e68b7ce19ae1eac32e5f2d61ba39a3fa" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b806d3eb44bb5995d21b017162c333c30909bfd1" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;#torch.Tensor.numel&quot;&gt;&lt;code&gt;numel()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8003ce6f6a4824ac7e86312aee5a809819964394" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.abs#torch.abs&quot;&gt;&lt;code&gt;abs()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae0811ab2275dcf323f302291b8578862167855b" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.abs#torch.abs&quot;&gt;&lt;code&gt;torch.abs()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dff47f32b9bc388203bf7e97dfa096239e9aa4fa" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.acos#torch.acos&quot;&gt;&lt;code&gt;torch.acos()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27f71b5c7ea505c6db6e7c3f268907cac51983c8" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.acosh#torch.acosh&quot;&gt;&lt;code&gt;torch.acosh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8915eae6d7b9ee1bf0b6f73f5bcf701208d83a87" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.asin#torch.asin&quot;&gt;&lt;code&gt;torch.asin()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12a1bcfe361d7554bc235392cdf072ae77235de7" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.asinh#torch.asinh&quot;&gt;&lt;code&gt;torch.asinh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21de09801d295b9e55c5ca95a97e6b707bdd91c4" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.atan#torch.atan&quot;&gt;&lt;code&gt;torch.atan()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f42b48abe60c1061b77c3d37b15698be8fee9c90" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.atanh#torch.atanh&quot;&gt;&lt;code&gt;torch.atanh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b913a66219f4d1a88ba91e403c72efb7f3ef3abb" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.clamp#torch.clamp&quot;&gt;&lt;code&gt;torch.clamp()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ba0bdfda926bfb5d618f4ee65334d6fb8eb1eee" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.div#torch.div&quot;&gt;&lt;code&gt;torch.div()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="346a30cebac1d8f7c67c1c3a7f4f3bc3613f3f76" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.ge#torch.ge&quot;&gt;&lt;code&gt;torch.ge()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b313b53bc520608d37513795d2fb79da1dd596f1" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.gt#torch.gt&quot;&gt;&lt;code&gt;torch.gt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd6c12495884b27e735c199934fdc7b613fa577d" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.le#torch.le&quot;&gt;&lt;code&gt;torch.le()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="982d40969f8de3053b6a7ba2029aed4446d9284b" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.lt#torch.lt&quot;&gt;&lt;code&gt;torch.lt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d9a228af380b06ff04ec79aacc440723157779f" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.mul#torch.mul&quot;&gt;&lt;code&gt;torch.mul()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93282bf10a2917c15fe551a51f5161e90b61877f" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.ne#torch.ne&quot;&gt;&lt;code&gt;torch.ne()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c53bd5a9189ae9c36a9718c39849a71cf4795d9" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.neg#torch.neg&quot;&gt;&lt;code&gt;torch.neg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84a5bea4d6c5059fe64ceca353dc77a1a8d6f0c7" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.sub#torch.sub&quot;&gt;&lt;code&gt;torch.sub()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07f60a052509a04e4581fb6abfc90937c2c71d1e" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;generated/torch.trunc#torch.trunc&quot;&gt;&lt;code&gt;torch.trunc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d26757f4ad01130675ba8ea2672c12a2db5b8aab" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.abs#torch.abs&quot;&gt;&lt;code&gt;torch.abs()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1445190c40314f7662b67191fe5caef59adeec0" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.acos#torch.acos&quot;&gt;&lt;code&gt;torch.acos()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7d58a750debce958ceee5c25ad01617693d3ea2" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.acosh#torch.acosh&quot;&gt;&lt;code&gt;torch.acosh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3aec840f94f18b783a10543e6249d4a95dd33cf1" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.asin#torch.asin&quot;&gt;&lt;code&gt;torch.asin()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="606d0a5ac071a495928d8903629e0d3c2c53055d" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.asinh#torch.asinh&quot;&gt;&lt;code&gt;torch.asinh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dee63cafa3f7f5b85ddbc8fc58438f4ee2396691" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.atan#torch.atan&quot;&gt;&lt;code&gt;torch.atan()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c0014cc8ab298138389abb57c1b96765b473b42" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.atanh#torch.atanh&quot;&gt;&lt;code&gt;torch.atanh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23c4daa625a3c02d837a48a43fcee80a5cf020be" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.clamp#torch.clamp&quot;&gt;&lt;code&gt;torch.clamp()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cc182b7bdf6fcacb622e0e829ca673368ffde7e" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.div#torch.div&quot;&gt;&lt;code&gt;torch.div()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caa996e0ac1f8de7d67f7455447758713ba8feee" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.ge#torch.ge&quot;&gt;&lt;code&gt;torch.ge()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="392a801bbfecc8b02cebb4cb713410918e491a2f" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.gt#torch.gt&quot;&gt;&lt;code&gt;torch.gt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b13ac85fa2f8f4adaad80131c925608d0b684eb" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.le#torch.le&quot;&gt;&lt;code&gt;torch.le()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b6841b18d2b1421ff7068e9ab0cf0387e0beeda" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.lt#torch.lt&quot;&gt;&lt;code&gt;torch.lt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bb2a8621505158fea7a3e7e83a0736217506d1f" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.mul#torch.mul&quot;&gt;&lt;code&gt;torch.mul()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eaccfa1051feb57b0d0c06ee1f7f0ca18ed2f48" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.ne#torch.ne&quot;&gt;&lt;code&gt;torch.ne()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80bfac967c271e4287120446d7e735504a25deee" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.neg#torch.neg&quot;&gt;&lt;code&gt;torch.neg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63adb787982c4f010005f5042a7176ac57a5c3dd" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.sub#torch.sub&quot;&gt;&lt;code&gt;torch.sub()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="004a1c4ca4c726826c71b8d3f3c668a30c19eca5" translate="yes" xml:space="preserve">
          <source>Alias for &lt;a href=&quot;torch.trunc#torch.trunc&quot;&gt;&lt;code&gt;torch.trunc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7b4372e3de7ce07bac66d661704328db6f955a4" translate="yes" xml:space="preserve">
          <source>Alias for field number 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbef6b362c3d3509157f18014e4e5a25eb4e07ea" translate="yes" xml:space="preserve">
          <source>Alias for field number 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb7d09e2006a3aec07c13d82496b6f2adb24a1f7" translate="yes" xml:space="preserve">
          <source>Alias for field number 2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2116d748feb69a3af8d3d3f32852bff649bb421e" translate="yes" xml:space="preserve">
          <source>Alias for field number 3</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8d021883b0a18d7d212863e386fe9e4590e884d" translate="yes" xml:space="preserve">
          <source>Alias of &lt;a href=&quot;generated/torch.det#torch.det&quot;&gt;&lt;code&gt;torch.det()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50e05f8a73a607a4d8a0fae45b49062e73a2e308" translate="yes" xml:space="preserve">
          <source>Alias of &lt;a href=&quot;generated/torch.outer#torch.outer&quot;&gt;&lt;code&gt;torch.outer()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47e1617de19cb0d4a15c8e0fcabf777055dd3bb7" translate="yes" xml:space="preserve">
          <source>Alias of &lt;a href=&quot;torch.outer#torch.outer&quot;&gt;&lt;code&gt;torch.outer()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e010f721821118294a0c5b2474248233557907a" translate="yes" xml:space="preserve">
          <source>All &lt;code&gt;Tensor&lt;/code&gt; s keep track of in-place operations applied to them, and if the implementation detects that a tensor was saved for backward in one of the functions, but it was modified in-place afterwards, an error will be raised once backward pass is started. This ensures that if you&amp;rsquo;re using in-place functions and not seeing any errors, you can be sure that the computed gradients are correct.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="199b1c80b5c9c67ba6a90eb5f4a37f1d39d57d4e" translate="yes" xml:space="preserve">
          <source>All CUDA kernels queued within its context will be enqueued on a selected stream.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d50263b9330ad372189eff67c5c8da79c613de2" translate="yes" xml:space="preserve">
          <source>All RNN modules accept packed sequences as inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0378c5b2171bc1b88405ce471d2eb658bdba38cd" translate="yes" xml:space="preserve">
          <source>All Tensors that have &lt;a href=&quot;#torch.Tensor.requires_grad&quot;&gt;&lt;code&gt;requires_grad&lt;/code&gt;&lt;/a&gt; which is &lt;code&gt;False&lt;/code&gt; will be leaf Tensors by convention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcd80e614fd3639e154329146ec9d72471b9fa7b" translate="yes" xml:space="preserve">
          <source>All Tensors that have &lt;a href=&quot;autograd#torch.Tensor.requires_grad&quot;&gt;&lt;code&gt;requires_grad&lt;/code&gt;&lt;/a&gt; which is &lt;code&gt;False&lt;/code&gt; will be leaf Tensors by convention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fae256c49cab7960ddc648f6bae5910cd2d3503e" translate="yes" xml:space="preserve">
          <source>All TorchVision models, except for quantized versions, are exportable to ONNX. More details can be found in &lt;a href=&quot;torchvision/models&quot;&gt;TorchVision&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dce89529d95dc69f4c1f1ca05bfc2111d81383b" translate="yes" xml:space="preserve">
          <source>All arguments are forwarded to the &lt;code&gt;setuptools.Extension&lt;/code&gt; constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11ff807dac1aacbdf6348e8f37bb396417fac326" translate="yes" xml:space="preserve">
          <source>All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite &lt;code&gt;__getitem__()&lt;/code&gt;, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite &lt;code&gt;__len__()&lt;/code&gt;, which is expected to return the size of the dataset by many &lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;&lt;code&gt;Sampler&lt;/code&gt;&lt;/a&gt; implementations and the default options of &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82dec6743296a8c3a95df2231d58c66c783ae2bd" translate="yes" xml:space="preserve">
          <source>All datasets that represent an iterable of data samples should subclass it. Such form of datasets is particularly useful when data come from a stream.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c7fdd1a2c6981ce3b8e5aa9cb3e2ddd838235f0" translate="yes" xml:space="preserve">
          <source>All dimension names of &lt;code&gt;self&lt;/code&gt; must be present in &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; may contain additional names that are not in &lt;code&gt;self.names&lt;/code&gt;; the output tensor has a size-one dimension for each of those new names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1576ac96be05f9aa6b0251d2e542e4b0f488bd8b" translate="yes" xml:space="preserve">
          <source>All dimension names of &lt;code&gt;self&lt;/code&gt; must be present in &lt;code&gt;other.names&lt;/code&gt;. &lt;code&gt;other&lt;/code&gt; may contain named dimensions that are not in &lt;code&gt;self.names&lt;/code&gt;; the output tensor has a size-one dimension for each of those new names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91188b536d6c07689225e8b91d26aa659eef6d49" translate="yes" xml:space="preserve">
          <source>All elements must be greater than</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa3a1109ed903de03a2630b0856e9124664ffc41" translate="yes" xml:space="preserve">
          <source>All functions must be valid TorchScript functions (including &lt;code&gt;__init__()&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e460db881180d9a3276146d738dac2c41672c148" translate="yes" xml:space="preserve">
          <source>All future work submitted to this stream will wait until all kernels submitted to a given stream at the time of call complete.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5ff4adfb04564464a64a43c245685fb2b5d3919" translate="yes" xml:space="preserve">
          <source>All inputs should have matching shapes, dtype, and layout. The output tensor will be of the same shape, dtype, and layout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8102d7ae18041c98a7f876840a19500755dde277" translate="yes" xml:space="preserve">
          <source>All modules, no matter their device, are always loaded onto the CPU during loading. This is different from &lt;a href=&quot;torch.load#torch.load&quot;&gt;&lt;code&gt;torch.load()&lt;/code&gt;&lt;/a&gt;&amp;rsquo;s semantics and may change in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="391810af4c5adb65a3bbe96665345a54a154a4ff" translate="yes" xml:space="preserve">
          <source>All of &lt;code&gt;dims&lt;/code&gt; must be consecutive in order in the &lt;code&gt;self&lt;/code&gt; tensor, but not necessary contiguous in memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c24f14499bb0bd88c18f05a4fe7875666f28f6d" translate="yes" xml:space="preserve">
          <source>All of the dims of &lt;code&gt;self&lt;/code&gt; must be named in order to use this method. The resulting tensor is a view on the original tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d9325f5f71bde68b50e39d98dd2b2fc4b9b3f89" translate="yes" xml:space="preserve">
          <source>All operations that support named tensors propagate names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b60bcfd2d0b2dce7638e7cd3bf4d7879477608de" translate="yes" xml:space="preserve">
          <source>All optimizers implement a &lt;a href=&quot;#torch.optim.Optimizer.step&quot;&gt;&lt;code&gt;step()&lt;/code&gt;&lt;/a&gt; method, that updates the parameters. It can be used in two ways:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c773fd48da7cc8c1f4621a11671c67f1f6303a0c" translate="yes" xml:space="preserve">
          <source>All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using &lt;code&gt;mean = [0.485, 0.456, 0.406]&lt;/code&gt; and &lt;code&gt;std = [0.229, 0.224, 0.225]&lt;/code&gt;. You can use the following transform to normalize:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec2e3e9eabe115169e1deab63808ca48a84df052" translate="yes" xml:space="preserve">
          <source>All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB videos of shape (3 x T x H x W), where H and W are expected to be 112, and T is a number of video frames in a clip. The images have to be loaded in to a range of [0, 1] and then normalized using &lt;code&gt;mean = [0.43216, 0.394666, 0.37645]&lt;/code&gt; and &lt;code&gt;std = [0.22803, 0.22145, 0.216989]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7463404aa8619413edebf6ff4257cb99add42cba" translate="yes" xml:space="preserve">
          <source>All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from. If this fails (e.g. because the run time system doesn&amp;rsquo;t have certain devices), an exception is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b8a41c0d78fe02aeede8e4c39fabb850893cedd" translate="yes" xml:space="preserve">
          <source>All subclasses should overwrite &lt;code&gt;__iter__()&lt;/code&gt;, which would return an iterator of samples in this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4fb70a59932061a3d80fc551911560fa69384f6" translate="yes" xml:space="preserve">
          <source>All summed &lt;code&gt;dim&lt;/code&gt; are squeezed (see &lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting an output tensor having &lt;code&gt;dim&lt;/code&gt; fewer dimensions than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bd30243e5faf7879695a6c25ee7d928afafccc6" translate="yes" xml:space="preserve">
          <source>All tensors need to be of the same size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="647c455337c3b30ca33d7810c4e9c4f5a9641226" translate="yes" xml:space="preserve">
          <source>All the weights and biases are initialized from</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="970c0ae90b9eb34e0cb6a356cf47964705868146" translate="yes" xml:space="preserve">
          <source>Allows the model to jointly attend to information from different representation subspaces.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5702cc92d2bcf7e780dcdf99f53eee4b5e88684e" translate="yes" xml:space="preserve">
          <source>Allows the model to jointly attend to information from different representation subspaces. See reference: Attention Is All You Need</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcb917dff27ba02ff781ce514dcf9c4e2df73ba5" translate="yes" xml:space="preserve">
          <source>Alpha Dropout is a type of Dropout that maintains the self-normalizing property. For an input with zero mean and unit standard deviation, the output of Alpha Dropout maintains the original mean and standard deviation of the input. Alpha Dropout goes hand-in-hand with SELU activation function, which ensures that the outputs have zero mean and unit standard deviation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="468dc142cbb278c344ed57a0c2341d7dabf6044d" translate="yes" xml:space="preserve">
          <source>AlphaDropout</source>
          <target state="translated">AlphaDropout</target>
        </trans-unit>
        <trans-unit id="697ae46b13c17cf9f965bf8eeb7388f2f2599380" translate="yes" xml:space="preserve">
          <source>Also by default, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default &lt;code&gt;momentum&lt;/code&gt; of 0.1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bf20b1915a4ba9029b2263ed8aac08cdcf55753" translate="yes" xml:space="preserve">
          <source>Also functions as a decorator. (Make sure to instantiate with parenthesis.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51924beeca0c98eba05c19c63804e09424b9e355" translate="yes" xml:space="preserve">
          <source>Also known as Glorot initialization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99d08174dc1487c12f409bf77bbf4a6a16dc84ad" translate="yes" xml:space="preserve">
          <source>Also known as He initialization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9319f57915da9aa68da62d35edfd64135450d0d5" translate="yes" xml:space="preserve">
          <source>Also note that &lt;code&gt;len(input_tensor_lists)&lt;/code&gt;, and the size of each element in &lt;code&gt;input_tensor_lists&lt;/code&gt; (each element is a list, therefore &lt;code&gt;len(input_tensor_lists[i])&lt;/code&gt;) need to be the same for all the distributed processes calling this function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a0c3f7b9176b92a14d4b6b5cc0f2c401a31947c" translate="yes" xml:space="preserve">
          <source>Also note that &lt;code&gt;len(output_tensor_lists)&lt;/code&gt;, and the size of each element in &lt;code&gt;output_tensor_lists&lt;/code&gt; (each element is a list, therefore &lt;code&gt;len(output_tensor_lists[i])&lt;/code&gt;) need to be the same for all the distributed processes calling this function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c8280a06795f9ac5918243b5469526506807f31" translate="yes" xml:space="preserve">
          <source>Although CUDA versions &amp;gt;= 11 support more than two levels of priorities, in PyTorch, we only support two levels of priorities.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="043751522414e7c9aaee8aec5948d07968c78350" translate="yes" xml:space="preserve">
          <source>Although the recipe for forward pass needs to be defined within this function, one should call the &lt;a href=&quot;#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a16ed36f1048b1b7e767b2e1655943a9aa7dfbb6" translate="yes" xml:space="preserve">
          <source>An &lt;code&gt;RRef&lt;/code&gt; (Remote REFerence) is a reference to a value of some type &lt;code&gt;T&lt;/code&gt; (e.g. &lt;code&gt;Tensor&lt;/code&gt;) on a remote worker. This handle keeps the referenced remote value alive on the owner, but there is no implication that the value will be transferred to the local worker in the future. RRefs can be used in multi-machine training by holding references to &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Module&quot;&gt;nn.Modules&lt;/a&gt; that exist on other workers, and calling the appropriate functions to retrieve or modify their parameters during training. See &lt;a href=&quot;rpc/rref#remote-reference-protocol&quot;&gt;Remote Reference Protocol&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="366e57ddf274ce33b825366c8f324bc7720a8851" translate="yes" xml:space="preserve">
          <source>An Elman RNN cell with tanh or ReLU non-linearity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a352f479f8560e5a2c03ce7b4e08fa3e11c8ded" translate="yes" xml:space="preserve">
          <source>An Elman RNN cell with tanh or ReLU non-linearity. A dynamic quantized RNNCell module with floating point tensor as inputs and outputs. Weights are quantized to 8 bits. We adopt the same interface as &lt;code&gt;torch.nn.RNNCell&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.RNNCell&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.RNNCell&lt;/a&gt; for documentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecda50e6fe26ce22d999e9c65fbfaac432da6710" translate="yes" xml:space="preserve">
          <source>An EventList containing FunctionEventAvg objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89afc3eab800778902526ed4786c65d7f4ca6494" translate="yes" xml:space="preserve">
          <source>An abstract class representing a &lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;&lt;code&gt;Dataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cda80fd86e845c48c7faf0e81a98aca3de57ab49" translate="yes" xml:space="preserve">
          <source>An abstract structure encapsulating the options passed into the RPC backend. An instance of this class can be passed in to &lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt;&lt;code&gt;init_rpc()&lt;/code&gt;&lt;/a&gt; in order to initialize RPC with specific configurations, such as the RPC timeout and &lt;code&gt;init_method&lt;/code&gt; to be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34f08a969a81be9fad81ba44cfa1144a898067e4" translate="yes" xml:space="preserve">
          <source>An additional dimension of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; is appended in the returned tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="619ad847534358910127729afc029b7953abcecf" translate="yes" xml:space="preserve">
          <source>An empty dict is assumed have type &lt;code&gt;Dict[str, Tensor]&lt;/code&gt;. The types of other dict literals are derived from the type of the members. See &lt;a href=&quot;#default-types&quot;&gt;Default Types&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1a0eecf8a5a6cdc72f4e0da994b510481da5a4d" translate="yes" xml:space="preserve">
          <source>An empty list is assumed have type &lt;code&gt;List[Tensor]&lt;/code&gt;. The types of other list literals are derived from the type of the members. See &lt;a href=&quot;#default-types&quot;&gt;Default Types&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d84c564cad7cf9fb4e3caa453c3a49e8beeae54d" translate="yes" xml:space="preserve">
          <source>An empty list is assumed to be &lt;code&gt;List[Tensor]&lt;/code&gt; and empty dicts &lt;code&gt;Dict[str, Tensor]&lt;/code&gt;. To instantiate an empty list or dict of other types, use &lt;code&gt;Python 3 type hints&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc24c0a7e765c257ec2c1deb32cf9b9b1bc99fd5" translate="yes" xml:space="preserve">
          <source>An empty sparse tensor can be constructed by specifying its size:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17f91bb7684b57d410e71c667849b986b1e265c6" translate="yes" xml:space="preserve">
          <source>An enum class of available backends.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a60c11218c3c0643831cc9fba424f6f68723b504" translate="yes" xml:space="preserve">
          <source>An enum-like class for available reduction operations: &lt;code&gt;SUM&lt;/code&gt;, &lt;code&gt;PRODUCT&lt;/code&gt;, &lt;code&gt;MIN&lt;/code&gt;, &lt;code&gt;MAX&lt;/code&gt;, &lt;code&gt;BAND&lt;/code&gt;, &lt;code&gt;BOR&lt;/code&gt;, and &lt;code&gt;BXOR&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5d6691fbcb10d6ab33410657c5bcc031006a7f4" translate="yes" xml:space="preserve">
          <source>An enum-like class of available backends: GLOO, NCCL, MPI, and other registered backends.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c399f6bcf61d242f357b89e04dfba538f2cb230b" translate="yes" xml:space="preserve">
          <source>An example for the usage of &lt;a href=&quot;#torch.distributions.transformed_distribution.TransformedDistribution&quot;&gt;&lt;code&gt;TransformedDistribution&lt;/code&gt;&lt;/a&gt; would be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="519ac03d4f41ca6837697ea6c98bf8c921545893" translate="yes" xml:space="preserve">
          <source>An example of such normalization can be found in the imagenet example &lt;a href=&quot;https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L101&quot;&gt;here&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c1ceedb1dedcde4e24919af77558ac6f1600e4d" translate="yes" xml:space="preserve">
          <source>An example where &lt;code&gt;transform_to&lt;/code&gt; and &lt;code&gt;biject_to&lt;/code&gt; differ is &lt;code&gt;constraints.simplex&lt;/code&gt;: &lt;code&gt;transform_to(constraints.simplex)&lt;/code&gt; returns a &lt;a href=&quot;#torch.distributions.transforms.SoftmaxTransform&quot;&gt;&lt;code&gt;SoftmaxTransform&lt;/code&gt;&lt;/a&gt; that simply exponentiates and normalizes its inputs; this is a cheap and mostly coordinate-wise operation appropriate for algorithms like SVI. In contrast, &lt;code&gt;biject_to(constraints.simplex)&lt;/code&gt; returns a &lt;a href=&quot;#torch.distributions.transforms.StickBreakingTransform&quot;&gt;&lt;code&gt;StickBreakingTransform&lt;/code&gt;&lt;/a&gt; that bijects its input down to a one-fewer-dimensional space; this a more expensive less numerically stable transform but is needed for algorithms like HMC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44802d0d5256af16bcf81baadaa0893f0644e7bc" translate="yes" xml:space="preserve">
          <source>An integral output tensor cannot accept a floating point tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d42c640da9c089ad44c78deb2cd826d6b0df3f8" translate="yes" xml:space="preserve">
          <source>An iterable Dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="498090423a5e476802043e5808dfa44461e23184" translate="yes" xml:space="preserve">
          <source>An iterable-style dataset is an instance of a subclass of &lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt;&lt;code&gt;IterableDataset&lt;/code&gt;&lt;/a&gt; that implements the &lt;code&gt;__iter__()&lt;/code&gt; protocol, and represents an iterable over data samples. This type of datasets is particularly suitable for cases where random reads are expensive or even improbable, and where the batch size depends on the fetched data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ada1c75faa68087ab2e8ec52c71f9a5f98fa8946" translate="yes" xml:space="preserve">
          <source>An torch.Generator object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="042787a30d514e644feadd2d89eacccefc21c5e7" translate="yes" xml:space="preserve">
          <source>Anomaly detection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef94106a43404d867533b831248eaa8963699ea0" translate="yes" xml:space="preserve">
          <source>Another initialization method makes use of a file system that is shared and visible from all machines in a group, along with a desired &lt;code&gt;world_size&lt;/code&gt;. The URL should start with &lt;code&gt;file://&lt;/code&gt; and contain a path to a non-existent file (in an existing directory) on a shared file system. File-system initialization will automatically create that file if it doesn&amp;rsquo;t exist, but will not delete the file. Therefore, it is your responsibility to make sure that the file is cleaned up before the next &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; call on the same file path/name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5194d861e34e463cbb383549f2be7e4afdfdb33" translate="yes" xml:space="preserve">
          <source>Any functions executed during the backward pass are also decorated with &lt;code&gt;seq=&amp;lt;N&amp;gt;&lt;/code&gt;. During default backward (with &lt;code&gt;create_graph=False&lt;/code&gt;) this information is irrelevant, and in fact, &lt;code&gt;N&lt;/code&gt; may simply be 0 for all such functions. Only the top-level ranges associated with backward Function objects&amp;rsquo; &lt;code&gt;apply()&lt;/code&gt; methods are useful, as a way to correlate these Function objects with the earlier forward pass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1eec009a2337c1a488dd1b74c1aff7cc1d139bf1" translate="yes" xml:space="preserve">
          <source>Any other functionality from the &lt;a href=&quot;https://docs.python.org/3/library/typing.html#module-typing&quot;&gt;&lt;code&gt;typing&lt;/code&gt;&lt;/a&gt; module not explitily listed in this documentation is unsupported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9267fbcc5ac03c112f491ee9bc7bbb21bb5ae1c5" translate="yes" xml:space="preserve">
          <source>Append the given callback function to this &lt;code&gt;Future&lt;/code&gt;, which will be run when the &lt;code&gt;Future&lt;/code&gt; is completed. Multiple callbacks can be added to the same &lt;code&gt;Future&lt;/code&gt;, and will be invoked in the same order as they were added. The callback must take one argument, which is the reference to this &lt;code&gt;Future&lt;/code&gt;. The callback function can use the &lt;code&gt;Future.wait()&lt;/code&gt; API to get the value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3f60044b06335eb6c4230e3c39f5e0218445878" translate="yes" xml:space="preserve">
          <source>Appendix</source>
          <target state="translated">Appendix</target>
        </trans-unit>
        <trans-unit id="c87f37c9f3693b628e726dc6f101341b952d29db" translate="yes" xml:space="preserve">
          <source>Appends a given module to the end of the list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="379011982516fbdbffaea6138d56d674a94f5e18" translate="yes" xml:space="preserve">
          <source>Appends a given parameter at the end of the list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b249ec6f74bf6c17017438ecc23770483a688cc" translate="yes" xml:space="preserve">
          <source>Appends modules from a Python iterable to the end of the list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e68b1f2c86ef40318501ff9b078b446cee7c813" translate="yes" xml:space="preserve">
          <source>Appends parameters from a Python iterable to the end of the list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="378aa8a7eda72c52086938707b31878d8a635ee4" translate="yes" xml:space="preserve">
          <source>Applied element-wise, as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47ea67db7d24ea56bb6efc03577734231d9fa58e" translate="yes" xml:space="preserve">
          <source>Applies 2D average-pooling operation in</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26a3eb8c50568931de48e1e7fa354baa87e37c44" translate="yes" xml:space="preserve">
          <source>Applies 3D average-pooling operation in</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="897491bacd3642b7742fd85de111604a2b1e2139" translate="yes" xml:space="preserve">
          <source>Applies &lt;code&gt;callable&lt;/code&gt; for each element in &lt;code&gt;self&lt;/code&gt; tensor and the given &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; and stores the results in &lt;code&gt;self&lt;/code&gt; tensor. &lt;code&gt;self&lt;/code&gt; tensor and the given &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="854151a01bba98f938fa936327548dc77fb47b3f" translate="yes" xml:space="preserve">
          <source>Applies &lt;code&gt;fn&lt;/code&gt; recursively to every submodule (as returned by &lt;code&gt;.children()&lt;/code&gt;) as well as self. Typical use includes initializing the parameters of a model (see also &lt;a href=&quot;../nn.init#nn-init-doc&quot;&gt;torch.nn.init&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3ce1d7a64849414112d779b273ff91d45596516" translate="yes" xml:space="preserve">
          <source>Applies Alpha Dropout over the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13e7aada5fd7c3d78fcf6b9c0d54d77028725d8c" translate="yes" xml:space="preserve">
          <source>Applies Batch Normalization for each channel across a batch of data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29f9114f73a8742a5df31f7a4732b3ef2d2fa5ed" translate="yes" xml:space="preserve">
          <source>Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D inputs with optional additional channel dimension) as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77df134b3c1dec023ae7933dc984fdf0b9a37d0b" translate="yes" xml:space="preserve">
          <source>Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5008d35280faa701906a5c7bb40531dff590ddb" translate="yes" xml:space="preserve">
          <source>Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebba8e6ee8c679b795f34839517e1330fe0f6cd0" translate="yes" xml:space="preserve">
          <source>Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c0b063a3d01c57a39497f55e2c1c93c68f9edde" translate="yes" xml:space="preserve">
          <source>Applies Group Normalization over a mini-batch of inputs as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1803.08494&quot;&gt;Group Normalization&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ddcab60a314dad6ac4e8205f6d0bbe42d633f04" translate="yes" xml:space="preserve">
          <source>Applies Instance Normalization for each channel in each data sample in a batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8eba97c1edce80ebe5a8f2d8c4ea438567d2707c" translate="yes" xml:space="preserve">
          <source>Applies Instance Normalization over a 3D input (a mini-batch of 1D inputs with optional additional channel dimension) as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1607.08022&quot;&gt;Instance Normalization: The Missing Ingredient for Fast Stylization&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c1378db79ff8ef5bf285d891bdde624c5ed8210" translate="yes" xml:space="preserve">
          <source>Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1607.08022&quot;&gt;Instance Normalization: The Missing Ingredient for Fast Stylization&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="331da363e42c71d65e839afe96ad5dce770a5331" translate="yes" xml:space="preserve">
          <source>Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1607.08022&quot;&gt;Instance Normalization: The Missing Ingredient for Fast Stylization&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b97189b49bbea1acf1c1f0194b9ab27dea9973b9" translate="yes" xml:space="preserve">
          <source>Applies Layer Normalization for last certain number of dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="835e00e544806b9f13082cf66ead874e6019f00b" translate="yes" xml:space="preserve">
          <source>Applies Layer Normalization over a mini-batch of inputs as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1607.06450&quot;&gt;Layer Normalization&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aeb29e205e308a59093be0d4988fa5cd74bac086" translate="yes" xml:space="preserve">
          <source>Applies SoftMax over features to each spatial location.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68727ddc338094e31b998534ceb0a7cd1e1f8321" translate="yes" xml:space="preserve">
          <source>Applies a 1D adaptive average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d6edcf464a5fa2406d025e84b2ed153de9c75ee" translate="yes" xml:space="preserve">
          <source>Applies a 1D adaptive max pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8f3289d5daff81c1311cb6f2ca1629e42cafa4f" translate="yes" xml:space="preserve">
          <source>Applies a 1D average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c27388a69cba70f821eaba1e90c8524f7a152d3" translate="yes" xml:space="preserve">
          <source>Applies a 1D convolution over a quantized 1D input composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="322ebd47033ac7c9c030a4056a89e60da48e7a7e" translate="yes" xml:space="preserve">
          <source>Applies a 1D convolution over a quantized input signal composed of several quantized input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcfb7d54383b0ff98c06cfb1f40c5d85baf1b8d7" translate="yes" xml:space="preserve">
          <source>Applies a 1D convolution over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba598dc972597d5f42702090e4175518b59bd582" translate="yes" xml:space="preserve">
          <source>Applies a 1D max pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e7aac7c6517399757e4cbb358ae6fceeed56898" translate="yes" xml:space="preserve">
          <source>Applies a 1D power-average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bfc842196843fc0db2f2d55709b870df2c8219f" translate="yes" xml:space="preserve">
          <source>Applies a 1D power-average pooling over an input signal composed of several input planes. If the sum of all inputs to the power of &lt;code&gt;p&lt;/code&gt; is zero, the gradient is set to zero as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96ca07ea2e411b1ba9e96092e82956074c9632be" translate="yes" xml:space="preserve">
          <source>Applies a 1D transposed convolution operator over an input image composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b460f2239dd693e787bc347edd22db345631a88" translate="yes" xml:space="preserve">
          <source>Applies a 1D transposed convolution operator over an input signal composed of several input planes, sometimes also called &amp;ldquo;deconvolution&amp;rdquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa89da022829347e9eb20aeec1fec7371b510238" translate="yes" xml:space="preserve">
          <source>Applies a 2D adaptive average pooling over a quantized input signal composed of several quantized input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2990176eebf3f395560769ef6ba618123ba3cbdc" translate="yes" xml:space="preserve">
          <source>Applies a 2D adaptive average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f9f8906e50a1a40da69b6542725773d5f97b476" translate="yes" xml:space="preserve">
          <source>Applies a 2D adaptive max pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d576b7f4a24ec8fd4a5244faa85b001a714e4b2b" translate="yes" xml:space="preserve">
          <source>Applies a 2D average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4eef15eebd1e3c58ec128ae4ac04428c46e00ff5" translate="yes" xml:space="preserve">
          <source>Applies a 2D bilinear upsampling to an input signal composed of several input channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47468ad50007cdb83f448361561cc024fef32584" translate="yes" xml:space="preserve">
          <source>Applies a 2D convolution over a quantized 2D input composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f8605d5715138e74b1fe2f63f6110cb337b8e9e" translate="yes" xml:space="preserve">
          <source>Applies a 2D convolution over a quantized input signal composed of several quantized input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01f53bdcdfe76a89f9da101eca78388d0e3db80b" translate="yes" xml:space="preserve">
          <source>Applies a 2D convolution over an input image composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d7022a0fdb1e618b639247856e6903aab3855e6" translate="yes" xml:space="preserve">
          <source>Applies a 2D convolution over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5648bdd82e29b0ec766dab1d7ea5bd15fb57316" translate="yes" xml:space="preserve">
          <source>Applies a 2D fractional max pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dcf07079bf5dd6c28cbfd49dde4f39b4bf6b35b" translate="yes" xml:space="preserve">
          <source>Applies a 2D max pooling over a quantized input signal composed of several quantized input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a476032b7da8421b8000aa56e627562cba0b8e78" translate="yes" xml:space="preserve">
          <source>Applies a 2D max pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16be7a5fb7dca84029d9fea2edb8b4f2f0ee57f8" translate="yes" xml:space="preserve">
          <source>Applies a 2D nearest neighbor upsampling to an input signal composed of several input channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41e06a057945b6ec3fbb4344ac26327e886f585c" translate="yes" xml:space="preserve">
          <source>Applies a 2D power-average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d69ec22c35e226c6aa2b1af68d48e3fa60401801" translate="yes" xml:space="preserve">
          <source>Applies a 2D power-average pooling over an input signal composed of several input planes. If the sum of all inputs to the power of &lt;code&gt;p&lt;/code&gt; is zero, the gradient is set to zero as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa4b7ef410c54190539113762f6eeb2a66bf418c" translate="yes" xml:space="preserve">
          <source>Applies a 2D transposed convolution operator over an input image composed of several input planes, sometimes also called &amp;ldquo;deconvolution&amp;rdquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b43e206b10ee89d84a5a812651aa838b543004e7" translate="yes" xml:space="preserve">
          <source>Applies a 2D transposed convolution operator over an input image composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5d643fce9e39e07cff6793421bc79eff19c89aa" translate="yes" xml:space="preserve">
          <source>Applies a 3D adaptive average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae56276da0a49f342cfd4b640808d55b08117aa7" translate="yes" xml:space="preserve">
          <source>Applies a 3D adaptive max pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37570017fc80764b6133f223b871fd527ef1696c" translate="yes" xml:space="preserve">
          <source>Applies a 3D average pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af8bbac2d382374f13d6575cf2d20a9ea3e1524d" translate="yes" xml:space="preserve">
          <source>Applies a 3D convolution over a quantized 3D input composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2ec5baf08b4d035b1c172c872a14f1141d860e8" translate="yes" xml:space="preserve">
          <source>Applies a 3D convolution over a quantized input signal composed of several quantized input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6f649a7867c44dcfc76acf042b1d45c5f149502" translate="yes" xml:space="preserve">
          <source>Applies a 3D convolution over an input image composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51acb800dbe635481a7193d943f2c4fdf6f9b633" translate="yes" xml:space="preserve">
          <source>Applies a 3D convolution over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5c65698b496aec798c667f51e238522d8ca0853" translate="yes" xml:space="preserve">
          <source>Applies a 3D max pooling over an input signal composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="330c7c56dc877c7532afe521797eaa31d71f0cd0" translate="yes" xml:space="preserve">
          <source>Applies a 3D transposed convolution operator over an input image composed of several input planes, sometimes also called &amp;ldquo;deconvolution&amp;rdquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ceaf63b96a331eabb115beb8c3e00540f6c5ffc" translate="yes" xml:space="preserve">
          <source>Applies a 3D transposed convolution operator over an input image composed of several input planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65ce4bde72c1f78502a6398b7865adc72e50ac02" translate="yes" xml:space="preserve">
          <source>Applies a 3D transposed convolution operator over an input image composed of several input planes. The transposed convolution operator multiplies each input value element-wise by a learnable kernel, and sums over the outputs from all input feature planes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66c150b86ae084c85a0e9289376927637ec64e05" translate="yes" xml:space="preserve">
          <source>Applies a bilinear transformation to the incoming data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ff756a7c7cfe8cec72e517aee9af4136e1371be" translate="yes" xml:space="preserve">
          <source>Applies a linear transformation to the incoming data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ff337dc0db982c6291a92a0d7e5b13fd2dbe747" translate="yes" xml:space="preserve">
          <source>Applies a linear transformation to the incoming quantized data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2436507aea812ee14f1556396ee7b6b4cbdbe1d" translate="yes" xml:space="preserve">
          <source>Applies a multi-layer Elman RNN with</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc4223d58e32410e3d29e09ef9a1db009d298cd1" translate="yes" xml:space="preserve">
          <source>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02da21c27e34ce09b75309eefe898e142b0a5cb5" translate="yes" xml:space="preserve">
          <source>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7660fbeb32f57e21a2dce8c33a454664d3adf995" translate="yes" xml:space="preserve">
          <source>Applies a softmax followed by a logarithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16d6a0fbab19784fd6044224005fc862384c1a6c" translate="yes" xml:space="preserve">
          <source>Applies a softmax function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3511c68e1b0c335caf44167160bac43a1d7fe51a" translate="yes" xml:space="preserve">
          <source>Applies a softmin function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfc3d07eb38a8451b3b1a0481d05e3ce6d35b93e" translate="yes" xml:space="preserve">
          <source>Applies alpha dropout to the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7a232c41e3f6477e97dc6f5c3a6a2571c32c1b2" translate="yes" xml:space="preserve">
          <source>Applies element-wise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="113342e492fe7e12d769f5fd51f90c782c13aba3" translate="yes" xml:space="preserve">
          <source>Applies element-wise the function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f558b6f91b1db6ba6cd7e44d550b3b8856e30ab7" translate="yes" xml:space="preserve">
          <source>Applies element-wise,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdcea2507c8f3d67607511bd4053b83de34dceec" translate="yes" xml:space="preserve">
          <source>Applies element-wise, the function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6f0771cea3151fdc337ea7709543dfa37058eea" translate="yes" xml:space="preserve">
          <source>Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dfd4a4a091440af428452b6ccfc1c2f2eb1887c" translate="yes" xml:space="preserve">
          <source>Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension. Applies normalization across channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ed90484b4c8624d14fcf12a0e8edf257e35f7b9" translate="yes" xml:space="preserve">
          <source>Applies pruning reparametrization to the tensor corresponding to the parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; without actually pruning any units.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="459126de8057e720ba86989e3d80f97bc3223f0e" translate="yes" xml:space="preserve">
          <source>Applies quantized rectified linear unit function element-wise:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdc304cf2ec7d610cd24075ed2e43e1a79d41759" translate="yes" xml:space="preserve">
          <source>Applies spectral normalization to a parameter in the given module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2134b29fbca7ca9ac873ada1558b714c901876b0" translate="yes" xml:space="preserve">
          <source>Applies the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a78621f5f34b400e9542d53a0ce88e233a0027bb" translate="yes" xml:space="preserve">
          <source>Applies the Gaussian Error Linear Units function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26cda85cebacaa2f55fa0de1b622a487073b568a" translate="yes" xml:space="preserve">
          <source>Applies the HardTanh function element-wise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f634982a2632889413c5e4a92650f28c9bdade" translate="yes" xml:space="preserve">
          <source>Applies the HardTanh function element-wise. See &lt;a href=&quot;generated/torch.nn.hardtanh#torch.nn.Hardtanh&quot;&gt;&lt;code&gt;Hardtanh&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95b3d284066a600a911ef55c57442d7f4b86507f" translate="yes" xml:space="preserve">
          <source>Applies the Softmax function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0,1] and sum to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01834f69d8e2aaf053d85470251564527cc332f1" translate="yes" xml:space="preserve">
          <source>Applies the Softmin function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range &lt;code&gt;[0, 1]&lt;/code&gt; and sum to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e581807715bdab40e3c6fa2d722c3f49a2fef542" translate="yes" xml:space="preserve">
          <source>Applies the element-wise function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c91f96c06647ec0aa46ecdb47707667cb0cb30c3" translate="yes" xml:space="preserve">
          <source>Applies the element-wise function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20e17ca8da87d2e89b6ddbe8ec999295cc6de103" translate="yes" xml:space="preserve">
          <source>Applies the function &lt;code&gt;callable&lt;/code&gt; to each element in the tensor, replacing each element with the value returned by &lt;code&gt;callable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f92865eb288d8379f17f76a886fec1e420e13a3" translate="yes" xml:space="preserve">
          <source>Applies the hard shrinkage function element-wise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56fce9ee97b2fb62286ad99c1ca046ac1d4d2b2c" translate="yes" xml:space="preserve">
          <source>Applies the hard shrinkage function element-wise:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec160fe4b0b150b142f63859285de9f24ee55b53" translate="yes" xml:space="preserve">
          <source>Applies the hardswish function, element-wise, as described in the paper:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="936f4f75c2b9f6e3826efbb88a4e51ae2ab84f70" translate="yes" xml:space="preserve">
          <source>Applies the latest &lt;code&gt;method&lt;/code&gt; by computing the new partial masks and returning its combination with the &lt;code&gt;default_mask&lt;/code&gt;. The new partial mask should be computed on the entries or channels that were not zeroed out by the &lt;code&gt;default_mask&lt;/code&gt;. Which portions of the tensor &lt;code&gt;t&lt;/code&gt; the new mask will be calculated from depends on the &lt;code&gt;PRUNING_TYPE&lt;/code&gt; (handled by the type handler):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d91ea3d6a32f01c8496b5becb21a5b21016d757" translate="yes" xml:space="preserve">
          <source>Applies the randomized leaky rectified liner unit function, element-wise, as described in the paper:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82d1c6b2a1ee5d5cde8c89bdcc2746329c59171c" translate="yes" xml:space="preserve">
          <source>Applies the rectified linear unit function element-wise. See &lt;a href=&quot;#torch.nn.quantized.ReLU&quot;&gt;&lt;code&gt;ReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbd19df946d0f4bb7fc4682300e73774ba71feab" translate="yes" xml:space="preserve">
          <source>Applies the rectified linear unit function element-wise. See &lt;a href=&quot;generated/torch.nn.relu#torch.nn.ReLU&quot;&gt;&lt;code&gt;ReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78f0af302507bc331ec744dca018a734a0627b7b" translate="yes" xml:space="preserve">
          <source>Applies the rectified linear unit function element-wise:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43edbfe54e1d38b1a754c8ddb026e3655a93da7b" translate="yes" xml:space="preserve">
          <source>Applies the silu function, element-wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0e7dde2fc1c92ff1943988e21d9ce05bb8c8f04" translate="yes" xml:space="preserve">
          <source>Applies the soft shrinkage function elementwise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e5fad00eee592f1c4a5342fdc927299a5993172" translate="yes" xml:space="preserve">
          <source>Applies the soft shrinkage function elementwise:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f3fa5f7feb89ef4634370ab877a48de7ffe1ed7" translate="yes" xml:space="preserve">
          <source>Applies weight normalization to a parameter in the given module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adb3943666d494e8bd63152770abcc75d5223bd5" translate="yes" xml:space="preserve">
          <source>Applying &lt;a href=&quot;torch.diag_embed#torch.diag_embed&quot;&gt;&lt;code&gt;torch.diag_embed()&lt;/code&gt;&lt;/a&gt; to the output of this function with the same arguments yields a diagonal matrix with the diagonal entries of the input. However, &lt;a href=&quot;torch.diag_embed#torch.diag_embed&quot;&gt;&lt;code&gt;torch.diag_embed()&lt;/code&gt;&lt;/a&gt; has different default dimensions, so those need to be explicitly specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09ebc50e43a0da169dba1646717349a905de80e9" translate="yes" xml:space="preserve">
          <source>Applying &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;torch.diagonal()&lt;/code&gt;&lt;/a&gt; to the output of this function with the same arguments yields a matrix identical to input. However, &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;torch.diagonal()&lt;/code&gt;&lt;/a&gt; has different default dimensions, so those need to be explicitly specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d22103e4c9027e5c172cbf43f3dd7371a41d32a7" translate="yes" xml:space="preserve">
          <source>Arbitrary positional and keyword inputs are allowed to be passed into DataParallel but some types are specially handled. tensors will be &lt;strong&gt;scattered&lt;/strong&gt; on dim specified (default 0). tuple, list and dict types will be shallow copied. The other types will be shared among different threads and can be corrupted if written to in the model&amp;rsquo;s forward pass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6075aed00d09ffa3057c99d13847e6be9606a66" translate="yes" xml:space="preserve">
          <source>Args:</source>
          <target state="translated">Args:</target>
        </trans-unit>
        <trans-unit id="511f2c74f69da56453fcefe6e26731eae720fb15" translate="yes" xml:space="preserve">
          <source>Args: &lt;code&gt;mod&lt;/code&gt; a float module, either produced by torch.quantization utilities or directly from user</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="155bff5864cb1f24be13ad5ed169f780a903d97c" translate="yes" xml:space="preserve">
          <source>Arguments can also be &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0478ca5f4c068ca3ac12f9474f6a15865ce9053" translate="yes" xml:space="preserve">
          <source>Arguments:</source>
          <target state="translated">Arguments:</target>
        </trans-unit>
        <trans-unit id="3839352701cd3d321f8924d7921c49d951abf8f7" translate="yes" xml:space="preserve">
          <source>Arguments::</source>
          <target state="translated">Arguments::</target>
        </trans-unit>
        <trans-unit id="6104f39ed22a2cd32e98536a3447a01c4b9f4781" translate="yes" xml:space="preserve">
          <source>Arithmetic Operators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0e74bbb76aa26e443aa08680a9aad05da89267b" translate="yes" xml:space="preserve">
          <source>Art B. Owen. Scrambling Sobol and Niederreiter-Xing points. Journal of Complexity, 14(4):466-489, December 1998.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44e38ee54f654b08e43c3403586961f50c567585" translate="yes" xml:space="preserve">
          <source>As a result of these changes, the following items are considered deprecated and should not appear in new code:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f1d874b6f85d0af8d36d263ad9bfb71343abc57" translate="yes" xml:space="preserve">
          <source>As a special case, when &lt;code&gt;input&lt;/code&gt; has zero dimensions and a nonzero scalar value, it is treated as a one-dimensional tensor with one element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50ba4ee86165b9263342121969588460e8e3d7d0" translate="yes" xml:space="preserve">
          <source>As a subset of Python, any valid TorchScript function is also a valid Python function. This makes it possible to &lt;code&gt;disable TorchScript&lt;/code&gt; and debug the function using standard Python tools like &lt;code&gt;pdb&lt;/code&gt;. The reverse is not true: there are many valid Python programs that are not valid TorchScript programs. Instead, TorchScript focuses specifically on the features of Python that are needed to represent neural network models in PyTorch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6cd63f503882dea2536baff15dc121bd94a50a6" translate="yes" xml:space="preserve">
          <source>As above, but the sample points are spaced uniformly at a distance of &lt;code&gt;dx&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4514250ef4bd2637a52c6977efbe9cd977631d0f" translate="yes" xml:space="preserve">
          <source>As described in the paper &lt;a href=&quot;https://arxiv.org/abs/1411.4280&quot;&gt;Efficient Object Localization Using Convolutional Networks&lt;/a&gt; , if adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then i.i.d. dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99099b94ea4fc98fc5c41ec54e22d892cee1ab67" translate="yes" xml:space="preserve">
          <source>As of 0.4, this function does not support an &lt;code&gt;out&lt;/code&gt; keyword. As an alternative, the old &lt;code&gt;torch.ones_like(input, out=output)&lt;/code&gt; is equivalent to &lt;code&gt;torch.ones(input.size(), out=output)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fb950c139664617530977c05541f892b77d98f6" translate="yes" xml:space="preserve">
          <source>As of 0.4, this function does not support an &lt;code&gt;out&lt;/code&gt; keyword. As an alternative, the old &lt;code&gt;torch.zeros_like(input, out=output)&lt;/code&gt; is equivalent to &lt;code&gt;torch.zeros(input.size(), out=output)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d301eba7fb8fca354fa028e6aad9db923bee3a2" translate="yes" xml:space="preserve">
          <source>As of PyTorch v1.7, Windows support for the distributed package only covers collective communications with Gloo backend, &lt;code&gt;FileStore&lt;/code&gt;, and &lt;code&gt;DistributedDataParallel&lt;/code&gt;. Therefore, the &lt;code&gt;init_method&lt;/code&gt; argument in &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; must point to a file. This works for both local and shared file systems:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80184e7d134febd3ee09d8016449ea572c67e780" translate="yes" xml:space="preserve">
          <source>As with &lt;a href=&quot;torch.nn.nllloss#torch.nn.NLLLoss&quot;&gt;&lt;code&gt;NLLLoss&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;input&lt;/code&gt; given is expected to contain &lt;em&gt;log-probabilities&lt;/em&gt; and is not restricted to a 2D Tensor. The targets are interpreted as &lt;em&gt;probabilities&lt;/em&gt; by default, but could be considered as &lt;em&gt;log-probabilities&lt;/em&gt; with &lt;code&gt;log_target&lt;/code&gt; set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99266bbca47ea9ff5e29020debec6a9680d5bf7a" translate="yes" xml:space="preserve">
          <source>As with image classification models, all pre-trained models expect input images normalized in the same way. The images have to be loaded in to a range of &lt;code&gt;[0, 1]&lt;/code&gt; and then normalized using &lt;code&gt;mean = [0.485, 0.456, 0.406]&lt;/code&gt; and &lt;code&gt;std = [0.229, 0.224, 0.225]&lt;/code&gt;. They have been trained on images resized such that their minimum size is 520.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b593995c88f61a609044a01e37e8e4ccc22e065" translate="yes" xml:space="preserve">
          <source>Assumptions</source>
          <target state="translated">Assumptions</target>
        </trans-unit>
        <trans-unit id="855f8e40c74ae8a51a99a06c8a2a032f398b5ed4" translate="yes" xml:space="preserve">
          <source>Async work handle, if async_op is set to True. None, if not async_op or if not part of the group</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a78338cab2cb5c76c6ab7df23e81a35449f6df4f" translate="yes" xml:space="preserve">
          <source>Async work handle, if async_op is set to True. None, if not async_op or if not part of the group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4042af2d84df423621c1b7387da3334c7f85d192" translate="yes" xml:space="preserve">
          <source>Async work handle, if async_op is set to True. None, otherwise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1889aec46759ffe70c5c9ddb3fee3b5ee5713f7b" translate="yes" xml:space="preserve">
          <source>At groups= &lt;code&gt;in_channels&lt;/code&gt;, each input channel is convolved with its own set of filters (of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6510deaa2781bdfd17b677974666275b9af08554" translate="yes" xml:space="preserve">
          <source>At groups= &lt;code&gt;in_channels&lt;/code&gt;, each input channel is convolved with its own set of filters, of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d3f19004934696d7b2d6e8d06f0e3a963b23772" translate="yes" xml:space="preserve">
          <source>At groups= &lt;code&gt;in_channels&lt;/code&gt;, each input channel is convolved with its own set of filters, of size:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcb1bde7e11ed9170bfe340f3dbc5867346695da" translate="yes" xml:space="preserve">
          <source>At groups=1, all inputs are convolved to all outputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9d6240328fee5db3b7a1921b6420e8a8acf15ff" translate="yes" xml:space="preserve">
          <source>At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da760faa855b591ad5bebacae023465206f25e52" translate="yes" xml:space="preserve">
          <source>At p =</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac85559223d37e290d1c1660fd99f2a4cf5904d9" translate="yes" xml:space="preserve">
          <source>At p = 1, one gets Sum Pooling (which is proportional to Average Pooling)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dbb94515aba090ad21fcfa70bd96411862efa24" translate="yes" xml:space="preserve">
          <source>At p = 1, one gets Sum Pooling (which is proportional to average pooling)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba60e6b895acf11e04420dfecb408950d41fdcb0" translate="yes" xml:space="preserve">
          <source>At the heart of PyTorch data loading utility is the &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt;&lt;/a&gt; class. It represents a Python iterable over a dataset, with support for</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74e0b9c80dca267a78a89ad68a2f6c73241b5973" translate="yes" xml:space="preserve">
          <source>Attention</source>
          <target state="translated">Attention</target>
        </trans-unit>
        <trans-unit id="9b0aef7ef75761256026f8850aa6308137966a97" translate="yes" xml:space="preserve">
          <source>Attribute Lookup On Python Modules</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6652617f2c799eb11ee727b16c5646c48af6905" translate="yes" xml:space="preserve">
          <source>Attributes</source>
          <target state="translated">Attributes</target>
        </trans-unit>
        <trans-unit id="cde0319b4a4a6d08df1fd51fb49e58f04a817a7e" translate="yes" xml:space="preserve">
          <source>Attributes of a ScriptModule can be marked constant by annotating them with &lt;code&gt;Final[T]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="effc3797a92fafe90a0f719052ebdd67ab00baf2" translate="yes" xml:space="preserve">
          <source>Attributes: Same as torch.nn.quantized.Conv3d</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e326babbae1150bc97146fd07419454c68ba8c11" translate="yes" xml:space="preserve">
          <source>Autocast Op Reference</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b3dcde733ca512dd4a6b9b1a49fa5f26623a298" translate="yes" xml:space="preserve">
          <source>Autocasting</source>
          <target state="translated">Autocasting</target>
        </trans-unit>
        <trans-unit id="78965d92bd603a457514f5c8bd35fc06957dafd3" translate="yes" xml:space="preserve">
          <source>Autograd currently supports named tensors in a limited manner: autograd ignores names on all tensors. Gradient computation is still correct but we lose the safety that names give us.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03567b4fb2f83cc2c2baad9124a8e9bc1b24aeed" translate="yes" xml:space="preserve">
          <source>Autograd includes a profiler that lets you inspect the cost of different operators inside your model - both on the CPU and GPU. There are two modes implemented at the moment - CPU-only using &lt;a href=&quot;#torch.autograd.profiler.profile&quot;&gt;&lt;code&gt;profile&lt;/code&gt;&lt;/a&gt;. and nvprof based (registers both CPU and GPU activity) using &lt;a href=&quot;#torch.autograd.profiler.emit_nvtx&quot;&gt;&lt;code&gt;emit_nvtx&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cead4310cfb62879040be96cb0226da15307414" translate="yes" xml:space="preserve">
          <source>Autograd is supported, see &lt;a href=&quot;#named-tensors-autograd-doc&quot;&gt;Autograd support&lt;/a&gt;. Because gradients are currently unnamed, optimizers may work but are untested.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fc85b24b64820e5c1a91ec86a7fdeb96b65e6ed" translate="yes" xml:space="preserve">
          <source>Autograd mechanics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6a465a4bfe05284d5084187d5372a6d8da9b829" translate="yes" xml:space="preserve">
          <source>Autograd recording during the forward pass</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7807d41b89e768682ae049c6166592980a550e48" translate="yes" xml:space="preserve">
          <source>Autograd support</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b8005aa270f8147e0440468e241bd00f96800bc" translate="yes" xml:space="preserve">
          <source>Automatic Mixed Precision examples</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56280d27e59e4f9a79ed74f7e14cd8c0e581e855" translate="yes" xml:space="preserve">
          <source>Automatic Mixed Precision package - torch.cuda.amp</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f3dc77bfd956e56fcd5b8e898b3fabd32b08034" translate="yes" xml:space="preserve">
          <source>Automatic Trace Checking</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16c312b664ed41d040921c5ac59416706fca528b" translate="yes" xml:space="preserve">
          <source>Automatic batching (default)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b27a774aecaec8b1c217a82557d2af8c10933cc" translate="yes" xml:space="preserve">
          <source>Automatic differentiation package - torch.autograd</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b29f65429a1d343b4fb7640c7ef2b8fc40202a32" translate="yes" xml:space="preserve">
          <source>Available for Python &amp;gt;= 3.4.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feed24a7c6df28036011e42f91dd99e7f26aa307" translate="yes" xml:space="preserve">
          <source>Averages all events.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85ece30f6d8af988432cf40fa8753c609179aa8c" translate="yes" xml:space="preserve">
          <source>Averages all function events over their keys.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1def506ac3e846cb4c938843152cd0b9bba71135" translate="yes" xml:space="preserve">
          <source>AvgPool1d</source>
          <target state="translated">AvgPool1d</target>
        </trans-unit>
        <trans-unit id="c673cdd08db86374f9ff97d13da9945ad47b1180" translate="yes" xml:space="preserve">
          <source>AvgPool2d</source>
          <target state="translated">AvgPool2d</target>
        </trans-unit>
        <trans-unit id="fc7fc296c7e1f04112232fe8a9e0e82d5c7f190f" translate="yes" xml:space="preserve">
          <source>AvgPool3d</source>
          <target state="translated">AvgPool3d</target>
        </trans-unit>
        <trans-unit id="6da0341102c44a220c312de3110fd1209e71eaf5" translate="yes" xml:space="preserve">
          <source>Ax = b</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec" translate="yes" xml:space="preserve">
          <source>B</source>
          <target state="translated">B</target>
        </trans-unit>
        <trans-unit id="a9d087c32e7ca877fdba43990aa26038f88f00de" translate="yes" xml:space="preserve">
          <source>B \times P \times M</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db6d439058d0e22e68b29c790c70d29e6828be28" translate="yes" xml:space="preserve">
          <source>B \times P \times R</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dfbff36e0eaece5eff122157b4277846a87f5f4" translate="yes" xml:space="preserve">
          <source>B \times R \times M</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45bdfdeb5092f65ada4a9a1c95c08cee2ffa142d" translate="yes" xml:space="preserve">
          <source>BAND</source>
          <target state="translated">BAND</target>
        </trans-unit>
        <trans-unit id="0ef786803f54f9a9e02024a654989e60c7f87b66" translate="yes" xml:space="preserve">
          <source>BCELoss</source>
          <target state="translated">BCELoss</target>
        </trans-unit>
        <trans-unit id="c174768efb833ed7a3edebffb9950a4f61c4c940" translate="yes" xml:space="preserve">
          <source>BCEWithLogitsLoss</source>
          <target state="translated">BCEWithLogitsLoss</target>
        </trans-unit>
        <trans-unit id="2c89bbb2577ddfe977123efaba3737f659629fff" translate="yes" xml:space="preserve">
          <source>BLAS and LAPACK Operations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aefcf5c188e5bba658f180d7b47a0379fa5e70c" translate="yes" xml:space="preserve">
          <source>BOR</source>
          <target state="translated">BOR</target>
        </trans-unit>
        <trans-unit id="bd606f52a5ad5bc6c6cc894b3accba4125210f66" translate="yes" xml:space="preserve">
          <source>BXOR</source>
          <target state="translated">BXOR</target>
        </trans-unit>
        <trans-unit id="e758ca64563fdd62965a2b97b76d555b1a70d938" translate="yes" xml:space="preserve">
          <source>Backend</source>
          <target state="translated">Backend</target>
        </trans-unit>
        <trans-unit id="b3776d63ad7b7a84bfe20d9c6d4a53a2b25d0e43" translate="yes" xml:space="preserve">
          <source>Backends</source>
          <target state="translated">Backends</target>
        </trans-unit>
        <trans-unit id="82921ea0c75d2b9e5a6aaafaf19c2a51a8ee3c26" translate="yes" xml:space="preserve">
          <source>Backends that come with PyTorch</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64dd60fe1a049fe6db3eb1369dec2e42bf428e21" translate="yes" xml:space="preserve">
          <source>Background</source>
          <target state="translated">Background</target>
        </trans-unit>
        <trans-unit id="4c7660dd341e52619271ac35d19b4aa963dcdc89" translate="yes" xml:space="preserve">
          <source>Backward through &lt;a href=&quot;#torch.det&quot;&gt;&lt;code&gt;det()&lt;/code&gt;&lt;/a&gt; internally uses SVD results when &lt;code&gt;input&lt;/code&gt; is not invertible. In this case, double backward through &lt;a href=&quot;#torch.det&quot;&gt;&lt;code&gt;det()&lt;/code&gt;&lt;/a&gt; will be unstable in when &lt;code&gt;input&lt;/code&gt; doesn&amp;rsquo;t have distinct singular values. See &lt;a href=&quot;torch.svd#torch.svd&quot;&gt;&lt;code&gt;svd()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c28a70ba3b665ff380843011cb9bf4004fe6ce27" translate="yes" xml:space="preserve">
          <source>Backward through &lt;a href=&quot;#torch.logdet&quot;&gt;&lt;code&gt;logdet()&lt;/code&gt;&lt;/a&gt; internally uses SVD results when &lt;code&gt;input&lt;/code&gt; is not invertible. In this case, double backward through &lt;a href=&quot;#torch.logdet&quot;&gt;&lt;code&gt;logdet()&lt;/code&gt;&lt;/a&gt; will be unstable in when &lt;code&gt;input&lt;/code&gt; doesn&amp;rsquo;t have distinct singular values. See &lt;a href=&quot;torch.svd#torch.svd&quot;&gt;&lt;code&gt;svd()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28943ec2b2ba443d9dbd186c1f96eafcfe632579" translate="yes" xml:space="preserve">
          <source>Backward through &lt;a href=&quot;#torch.slogdet&quot;&gt;&lt;code&gt;slogdet()&lt;/code&gt;&lt;/a&gt; internally uses SVD results when &lt;code&gt;input&lt;/code&gt; is not invertible. In this case, double backward through &lt;a href=&quot;#torch.slogdet&quot;&gt;&lt;code&gt;slogdet()&lt;/code&gt;&lt;/a&gt; will be unstable in when &lt;code&gt;input&lt;/code&gt; doesn&amp;rsquo;t have distinct singular values. See &lt;a href=&quot;torch.svd#torch.svd&quot;&gt;&lt;code&gt;svd()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb44593f48eb0328822a985f5aa285528658fb23" translate="yes" xml:space="preserve">
          <source>Bartlett window function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="919b23578508277c7be92184e7175d68ef74ae7e" translate="yes" xml:space="preserve">
          <source>Base class for all Samplers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f6ce4f7d8508e7be7e4cda0e650d850c9905e8a" translate="yes" xml:space="preserve">
          <source>Base class for all neural network modules.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa2e98de019e1d429d4b048d107e89660df3590b" translate="yes" xml:space="preserve">
          <source>Base class for all optimizers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3756aaad75fa5f15b1e3570c38539a1b4fa27093" translate="yes" xml:space="preserve">
          <source>Base class for all store implementations, such as the 3 provided by PyTorch distributed: (&lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt;&lt;code&gt;TCPStore&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributed.FileStore&quot;&gt;&lt;code&gt;FileStore&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;#torch.distributed.HashStore&quot;&gt;&lt;code&gt;HashStore&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fa48cad7c036a5d05a3d1ee3ac94a5b6b79fa80" translate="yes" xml:space="preserve">
          <source>Base observer Module. Any observer implementation should derive from this class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb7f5bac791ae3c9dcca099683932046b2428b2e" translate="yes" xml:space="preserve">
          <source>BasePruningMethod</source>
          <target state="translated">BasePruningMethod</target>
        </trans-unit>
        <trans-unit id="173d42bdad4a08f4dc4a342a93191085b664cf61" translate="yes" xml:space="preserve">
          <source>Bases: &lt;a href=&quot;#torch.distributions.distribution.Distribution&quot;&gt;&lt;code&gt;torch.distributions.distribution.Distribution&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6b8b8e70456b968792e96e115e64852d9f96501" translate="yes" xml:space="preserve">
          <source>Bases: &lt;a href=&quot;#torch.distributions.exp_family.ExponentialFamily&quot;&gt;&lt;code&gt;torch.distributions.exp_family.ExponentialFamily&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a86b5e13aaeb2e61798bec3653ac860d7b6fac71" translate="yes" xml:space="preserve">
          <source>Bases: &lt;a href=&quot;#torch.distributions.gamma.Gamma&quot;&gt;&lt;code&gt;torch.distributions.gamma.Gamma&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f37aa8ac66020a1c6c2b5aa83188590e63bd8613" translate="yes" xml:space="preserve">
          <source>Bases: &lt;a href=&quot;#torch.distributions.transformed_distribution.TransformedDistribution&quot;&gt;&lt;code&gt;torch.distributions.transformed_distribution.TransformedDistribution&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68ca77158d1716ec91be76868bd9ad42dd2154e8" translate="yes" xml:space="preserve">
          <source>Bases: &lt;a href=&quot;https://docs.python.org/3/library/functions.html#object&quot;&gt;&lt;code&gt;object&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7070665795a3b04470b95d5347795e00aee639f7" translate="yes" xml:space="preserve">
          <source>Basic name inference rules</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fcebeefad3cdbbf8733aa928160dec7dc90c1a1" translate="yes" xml:space="preserve">
          <source>Basics</source>
          <target state="translated">Basics</target>
        </trans-unit>
        <trans-unit id="16f46715e1716fa628885ccd95ddf80183d01012" translate="yes" xml:space="preserve">
          <source>Batch sizes represent the number elements at each sequence step in the batch, not the varying sequence lengths passed to &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;pack_padded_sequence()&lt;/code&gt;&lt;/a&gt;. For instance, given data &lt;code&gt;abc&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; the &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;PackedSequence&lt;/code&gt;&lt;/a&gt; would contain data &lt;code&gt;axbc&lt;/code&gt; with &lt;code&gt;batch_sizes=[2,1,1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="640ed9b96cb507644eb24c180e159849e7025eaa" translate="yes" xml:space="preserve">
          <source>BatchNorm</source>
          <target state="translated">BatchNorm</target>
        </trans-unit>
        <trans-unit id="c7c537e5e7d31a4a94ee4f8e5ebc01c365e0771a" translate="yes" xml:space="preserve">
          <source>BatchNorm1d</source>
          <target state="translated">BatchNorm1d</target>
        </trans-unit>
        <trans-unit id="539a37ce419a6050de06321e52ac8941c6a520dd" translate="yes" xml:space="preserve">
          <source>BatchNorm2d</source>
          <target state="translated">BatchNorm2d</target>
        </trans-unit>
        <trans-unit id="4036bb17e086d06a41c9d03825932c8325ec759f" translate="yes" xml:space="preserve">
          <source>BatchNorm3d</source>
          <target state="translated">BatchNorm3d</target>
        </trans-unit>
        <trans-unit id="58a700d3fc7db1c024d5e6e31878faaaa556887d" translate="yes" xml:space="preserve">
          <source>Because named tensors can coexist with unnamed tensors, refining names gives a nice way to write named-tensor-aware code that works with both named and unnamed tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a3a2aefc4920597d8297a1ff6ee9586d1d76c12" translate="yes" xml:space="preserve">
          <source>Because of the similarity of APIs we do not document most of this package contents, and we recommend referring to very good docs of the original module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85ad6aa0a04066bce002e177e5b44f0e8ada2c9c" translate="yes" xml:space="preserve">
          <source>Because the Batch Normalization is done for each channel in the &lt;code&gt;C&lt;/code&gt; dimension, computing statistics on &lt;code&gt;(N, +)&lt;/code&gt; slices, it&amp;rsquo;s common terminology to call this Volumetric Batch Normalization or Spatio-temporal Batch Normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd602c285d639d22638df01e41486fc6be835af0" translate="yes" xml:space="preserve">
          <source>Because the Batch Normalization is done over the &lt;code&gt;C&lt;/code&gt; dimension, computing statistics on &lt;code&gt;(N, D, H, W)&lt;/code&gt; slices, it&amp;rsquo;s common terminology to call this Volumetric Batch Normalization or Spatio-temporal Batch Normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3a6337703c27cf2e6ddd618d4baf0da4204696b" translate="yes" xml:space="preserve">
          <source>Because the Batch Normalization is done over the &lt;code&gt;C&lt;/code&gt; dimension, computing statistics on &lt;code&gt;(N, H, W)&lt;/code&gt; slices, it&amp;rsquo;s common terminology to call this Spatial Batch Normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="288d84de2a904a705b5e7ec68955d71169bacf13" translate="yes" xml:space="preserve">
          <source>Because the Batch Normalization is done over the &lt;code&gt;C&lt;/code&gt; dimension, computing statistics on &lt;code&gt;(N, L)&lt;/code&gt; slices, it&amp;rsquo;s common terminology to call this Temporal Batch Normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0da3b2b883ef3b23c37366196cd69afd8c187cdd" translate="yes" xml:space="preserve">
          <source>Because the signal is Hermitian in the time-domain, the result will be real in the frequency domain. Note that some input frequencies must be real-valued to satisfy the Hermitian property. In these cases the imaginary component will be ignored. For example, any imaginary component in &lt;code&gt;input[0]&lt;/code&gt; would result in one or more complex frequency terms which cannot be represented in a real output and so will always be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e29f922f6839735f3a19bbe923a21ab693afacc" translate="yes" xml:space="preserve">
          <source>Because your script will be profiled, please ensure that it exits in a finite amount of time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="956a144b3d9996462b7b18cbedf9997fc2011650" translate="yes" xml:space="preserve">
          <source>Before going further, more details on TensorBoard can be found at &lt;a href=&quot;https://www.tensorflow.org/tensorboard/&quot;&gt;https://www.tensorflow.org/tensorboard/&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b23ce245f346d21fc21404045956dd5e7ec60de" translate="yes" xml:space="preserve">
          <source>Before using RPC and distributed autograd primitives, initialization must take place. To initialize the RPC framework we need to use &lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt;&lt;code&gt;init_rpc()&lt;/code&gt;&lt;/a&gt; which would initialize the RPC framework, RRef framework and distributed autograd.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e921d24df994f442d57e133126d10fb2ac6e163" translate="yes" xml:space="preserve">
          <source>Below is an example of running a TorchScript function using RPC.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc8bffef30a767db701efa64dcad8d3b22a3cf6c" translate="yes" xml:space="preserve">
          <source>Bernoulli</source>
          <target state="translated">Bernoulli</target>
        </trans-unit>
        <trans-unit id="ad9db732260b1d62e536980667c87db0f86fe3e4" translate="yes" xml:space="preserve">
          <source>Bernoulli trials, the first</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01f8c251cc6790b547148a802d152b484b1bf377" translate="yes" xml:space="preserve">
          <source>Besides the GLOO/MPI/NCCL backends, PyTorch distributed supports third-party backends through a run-time register mechanism. For references on how to develop a third-party backend through C++ Extension, please refer to &lt;a href=&quot;https://pytorch.org/tutorials/advanced/cpp_extension.html&quot;&gt;Tutorials - Custom C++ and CUDA Extensions&lt;/a&gt; and &lt;code&gt;test/cpp_extensions/cpp_c10d_extension.cpp&lt;/code&gt;. The capability of third-party backends are decided by their own implementations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f03b60f7e52b7ce49ed1e4f9fa511c452a2185bb" translate="yes" xml:space="preserve">
          <source>Beta</source>
          <target state="translated">Beta</target>
        </trans-unit>
        <trans-unit id="7190fb74ee81a83c8faf5a8c92b9ef9ebbf6afa2" translate="yes" xml:space="preserve">
          <source>Beta distribution parameterized by &lt;a href=&quot;#torch.distributions.beta.Beta.concentration1&quot;&gt;&lt;code&gt;concentration1&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributions.beta.Beta.concentration0&quot;&gt;&lt;code&gt;concentration0&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e26ae344044922af518669ed7912f3779c4b00f9" translate="yes" xml:space="preserve">
          <source>Bias:</source>
          <target state="translated">Bias:</target>
        </trans-unit>
        <trans-unit id="a8b51aa01c82ba019a69245f557ba6ce284edd3e" translate="yes" xml:space="preserve">
          <source>Bilinear</source>
          <target state="translated">Bilinear</target>
        </trans-unit>
        <trans-unit id="054debc367aa35026cc5f23e63b04983a105cd4a" translate="yes" xml:space="preserve">
          <source>Binary arithmetic ops: &lt;a href=&quot;name_inference#unifies-names-from-inputs-doc&quot;&gt;Unifies names from inputs&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f22fc461ba15be26425f3495add8c55aef51c91e" translate="yes" xml:space="preserve">
          <source>Binomial</source>
          <target state="translated">Binomial</target>
        </trans-unit>
        <trans-unit id="5200f1acde5b24e6b432770b7da7700cd60a0c9b" translate="yes" xml:space="preserve">
          <source>Blackman window function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f52a562e394a39a60e84e9b3ac335fc3bd698d8" translate="yes" xml:space="preserve">
          <source>Block until the value of this &lt;code&gt;Future&lt;/code&gt; is ready.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2959d258f8603010c5e64b30d6b389ff4f7e543" translate="yes" xml:space="preserve">
          <source>Blocking call that copies the value of the RRef from the owner to the local node and returns it. If the current node is the owner, returns a reference to the local value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b76ff4906f33c2dd97ddd929b9662ba8cac6174c" translate="yes" xml:space="preserve">
          <source>Boolean</source>
          <target state="translated">Boolean</target>
        </trans-unit>
        <trans-unit id="8bdc4a42a8aebafd81e1c9ebefc552e2af4c86e0" translate="yes" xml:space="preserve">
          <source>Both &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; must have integer types.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f1c331482420b1dcc09832ffc768fcc272a654b" translate="yes" xml:space="preserve">
          <source>Both parameters and persistent buffers (e.g. running averages) are included. Keys are corresponding parameter and buffer names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbb16819919dac69a8f12c76f83bc60666b08a4a" translate="yes" xml:space="preserve">
          <source>Break and Continue</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7263f9de457f4107fd587921961d9e2a1123f9c7" translate="yes" xml:space="preserve">
          <source>Broadcasting semantics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fa441232eb833209908a5491f939a27366f7f1a" translate="yes" xml:space="preserve">
          <source>Broadcasts a sequence tensors to the specified GPUs. Small tensors are first coalesced into a buffer to reduce the number of synchronizations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e2b086a05d88dd9ed966250318444cafc6508f3" translate="yes" xml:space="preserve">
          <source>Broadcasts a tensor to specified GPU devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0e07d9c87aab6412703456e09b86450b239d9d4" translate="yes" xml:space="preserve">
          <source>Broadcasts the given tensors according to &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;Broadcasting semantics&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ef2cb9c843900d814506b00e103fcfa6e5a1790" translate="yes" xml:space="preserve">
          <source>Broadcasts the tensor to the whole group with multiple GPU tensors per node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cd98b60116d9de3db535a744915ab8ea6c752e2" translate="yes" xml:space="preserve">
          <source>Broadcasts the tensor to the whole group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d0d383693b784a550085e06cd3563d333282d5c" translate="yes" xml:space="preserve">
          <source>Buffers can be accessed as attributes using given names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="072f59c8f878e682443386c6e7570c90195dbc31" translate="yes" xml:space="preserve">
          <source>Built-in Functions and Modules</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2faa9e18e8bd0f32f4bea2db29afed6e0ae12775" translate="yes" xml:space="preserve">
          <source>By default collectives operate on the default group (also called the world) and require all processes to enter the distributed function call. However, some workloads can benefit from more fine-grained communication. This is where distributed groups come into play. &lt;a href=&quot;#torch.distributed.new_group&quot;&gt;&lt;code&gt;new_group()&lt;/code&gt;&lt;/a&gt; function can be used to create new groups, with arbitrary subsets of all processes. It returns an opaque group handle that can be given as a &lt;code&gt;group&lt;/code&gt; argument to all collectives (collectives are distributed functions to exchange information in certain well-known programming patterns).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa6f8066d9ec2654575e0a2dde8cde52f9a324b9" translate="yes" xml:space="preserve">
          <source>By default, &lt;code&gt;dim&lt;/code&gt; is the last dimension of the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06e2dff3c96eaf47ae009ba6e54dc225888930ea" translate="yes" xml:space="preserve">
          <source>By default, &lt;code&gt;torch.optim.swa_utils.AveragedModel&lt;/code&gt; computes a running equal average of the parameters that you provide, but you can also use custom averaging functions with the &lt;code&gt;avg_fn&lt;/code&gt; parameter. In the following example &lt;code&gt;ema_model&lt;/code&gt; computes an exponential moving average.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbd6c7669b0b5fa4b44c256ffe1ad2c51d96bac8" translate="yes" xml:space="preserve">
          <source>By default, all parameters to a TorchScript function are assumed to be Tensor. To specify that an argument to a TorchScript function is another type, it is possible to use MyPy-style type annotations using the types listed above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3269c80ab5ee7ca74422e9e598672c0d5563eb7c" translate="yes" xml:space="preserve">
          <source>By default, both the NCCL and Gloo backends will try to find the right network interface to use. If the automatically detected interface is not correct, you can override it using the following environment variables (applicable to the respective backend):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4858611fd19a2d108e1171bb6e36531524a98b7" translate="yes" xml:space="preserve">
          <source>By default, each worker will have its PyTorch seed set to &lt;code&gt;base_seed + worker_id&lt;/code&gt;, where &lt;code&gt;base_seed&lt;/code&gt; is a long generated by main process using its RNG (thereby, consuming a RNG state mandatorily). However, seeds for other libraries may be duplicated upon initializing workers (e.g., NumPy), causing each worker to return identical random numbers. (See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/faq.html#dataloader-workers-random-seed&quot;&gt;this section&lt;/a&gt; in FAQ.).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a47868a7f38c8661f0bf65ea44d4c34b8a4bf540" translate="yes" xml:space="preserve">
          <source>By default, the Ninja backend uses #CPUS + 2 workers to build the extension. This may use up too many resources on some systems. One can control the number of workers by setting the &lt;code&gt;MAX_JOBS&lt;/code&gt; environment variable to a non-negative number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d1c0495670db55861d9901a2985f3df3c09c53d" translate="yes" xml:space="preserve">
          <source>By default, the directory to which the build file is emitted and the resulting library compiled to is &lt;code&gt;&amp;lt;tmp&amp;gt;/torch_extensions/&amp;lt;name&amp;gt;&lt;/code&gt;, where &lt;code&gt;&amp;lt;tmp&amp;gt;&lt;/code&gt; is the temporary folder on the current platform and &lt;code&gt;&amp;lt;name&amp;gt;&lt;/code&gt; the name of the extension. This location can be overridden in two ways. First, if the &lt;code&gt;TORCH_EXTENSIONS_DIR&lt;/code&gt; environment variable is set, it replaces &lt;code&gt;&amp;lt;tmp&amp;gt;/torch_extensions&lt;/code&gt; and all extensions will be compiled into subfolders of this directory. Second, if the &lt;code&gt;build_directory&lt;/code&gt; argument to this function is supplied, it overrides the entire path, i.e. the library will be compiled into that folder directly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="836a1bf0b7e01bddc495fceffa973ccc50f2cdd2" translate="yes" xml:space="preserve">
          <source>By default, this layer uses instance statistics computed from input data in both training and evaluation modes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0d34afff9ec6083c3b3dad548be8255d68d92ca" translate="yes" xml:space="preserve">
          <source>By default, this returns the peak allocated memory since the beginning of this program. &lt;code&gt;reset_peak_stats()&lt;/code&gt; can be used to reset the starting point in tracking this metric. For example, these two functions can measure the peak allocated memory usage of each iteration in a training loop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27248360b06b99273d17a1100cf62c5ed9fc9c4e" translate="yes" xml:space="preserve">
          <source>By default, this returns the peak cached memory since the beginning of this program. &lt;code&gt;reset_peak_stats()&lt;/code&gt; can be used to reset the starting point in tracking this metric. For example, these two functions can measure the peak cached memory amount of each iteration in a training loop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="260db48b6c19b12ad8aaa2c223fbe53f044c91eb" translate="yes" xml:space="preserve">
          <source>By default, we decode byte strings as &lt;code&gt;utf-8&lt;/code&gt;. This is to avoid a common error case &lt;code&gt;UnicodeDecodeError: 'ascii' codec can't decode byte 0x...&lt;/code&gt; when loading files saved by Python 2 in Python 3. If this default is incorrect, you may use an extra &lt;code&gt;encoding&lt;/code&gt; keyword argument to specify how these objects should be loaded, e.g., &lt;code&gt;encoding='latin1'&lt;/code&gt; decodes them to strings using &lt;code&gt;latin1&lt;/code&gt; encoding, and &lt;code&gt;encoding='bytes'&lt;/code&gt; keeps them as byte arrays which can be decoded later with &lt;code&gt;byte_array.decode(...)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b3e53bd55890d668be711af0b27d6b4e4085bb4" translate="yes" xml:space="preserve">
          <source>By default, we don&amp;rsquo;t clean up files after loading it. Hub uses the cache by default if it already exists in the directory returned by &lt;a href=&quot;#torch.hub.get_dir&quot;&gt;&lt;code&gt;get_dir()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d31b2b62d5a7017f58599071410bf4ed9eb8d68" translate="yes" xml:space="preserve">
          <source>By default, with &lt;code&gt;dim=0&lt;/code&gt;, the norm is computed independently per output channel/plane. To compute a norm over the entire weight tensor, use &lt;code&gt;dim=None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32096c2e0eff33d844ee6d675407ace18289357d" translate="yes" xml:space="preserve">
          <source>C</source>
          <target state="translated">C</target>
        </trans-unit>
        <trans-unit id="eaef64b3192bf8d5502eee309124b228be2379ec" translate="yes" xml:space="preserve">
          <source>C = \log(\pi) \times \frac{p (p - 1)}{4}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ee9f8327170df1bedff8fda035491204285f3c3" translate="yes" xml:space="preserve">
          <source>C = \text{number of classes (including blank)}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f46c4b42af8b2196cc344f07319e812268c3c0dd" translate="yes" xml:space="preserve">
          <source>C \times \prod(\text{kernel\_size})</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc2b4216164cfb01ac45112054b3fedda8b56c86" translate="yes" xml:space="preserve">
          <source>C++</source>
          <target state="translated">C++</target>
        </trans-unit>
        <trans-unit id="a3d883aa22c9b3cbe1562cc3d62c063468b9a196" translate="yes" xml:space="preserve">
          <source>C=\text{num\_channels}</source>
          <target state="translated">C=\text{num\_channels}</target>
        </trans-unit>
        <trans-unit id="798a57343d5fc6a0cf122924f6ca62852b64f4a6" translate="yes" xml:space="preserve">
          <source>CELU</source>
          <target state="translated">CELU</target>
        </trans-unit>
        <trans-unit id="ff221d4752ce05f5a91bbf1d28b78a7bf7e2ddaa" translate="yes" xml:space="preserve">
          <source>CPU</source>
          <target state="translated">CPU</target>
        </trans-unit>
        <trans-unit id="d2b3baf18b41b52a701d4019f7ffaa284e02f53a" translate="yes" xml:space="preserve">
          <source>CPU hosts with Ethernet interconnect</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfea39d4ef79843c8c035774adc370d11a93b4e8" translate="yes" xml:space="preserve">
          <source>CPU hosts with InfiniBand interconnect</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aca0030d1b8e86f8e968a622d4b61c5e238ad1fa" translate="yes" xml:space="preserve">
          <source>CPU tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1adcc1c5aae9ba0bc68cde14e7017456258e8921" translate="yes" xml:space="preserve">
          <source>CPU threading and TorchScript inference</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c435b722f2bc9152d11b1225cc3099efa162504" translate="yes" xml:space="preserve">
          <source>CTCLoss</source>
          <target state="translated">CTCLoss</target>
        </trans-unit>
        <trans-unit id="b793fde9f05fa7373de2fa5fbd4dcb147eafd14e" translate="yes" xml:space="preserve">
          <source>CUDA events are synchronization markers that can be used to monitor the device&amp;rsquo;s progress, to accurately measure timing, and to synchronize CUDA streams.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ab6d957380a70ab72c7926a9d4fae8cf48ecf35" translate="yes" xml:space="preserve">
          <source>CUDA semantics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f5da429aac783fd0a3a0da898da1913e428656f" translate="yes" xml:space="preserve">
          <source>CUDA support with mixed compilation is provided. Simply pass CUDA source files (&lt;code&gt;.cu&lt;/code&gt; or &lt;code&gt;.cuh&lt;/code&gt;) along with other sources. Such files will be detected and compiled with nvcc rather than the C++ compiler. This includes passing the CUDA lib64 directory as a library directory, and linking &lt;code&gt;cudart&lt;/code&gt;. You can pass additional flags to nvcc via &lt;code&gt;extra_cuda_cflags&lt;/code&gt;, just like with &lt;code&gt;extra_cflags&lt;/code&gt; for C++. Various heuristics for finding the CUDA install directory are used, which usually work fine. If not, setting the &lt;code&gt;CUDA_HOME&lt;/code&gt; environment variable is the safest option.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56a1c421d119a488bb14d44dd6891b51aea087b0" translate="yes" xml:space="preserve">
          <source>Caching is useful for transforms whose inverses are either expensive or numerically unstable. Note that care must be taken with memoized values since the autograd graph may be reversed. For example while the following works with or without caching:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5abf962ed164e31df7bbd04bfe694578c153b51d" translate="yes" xml:space="preserve">
          <source>Caching logic</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8a73f7e1b281ff72f0cd1f11baf202568648a12" translate="yes" xml:space="preserve">
          <source>Calculates determinant of a square matrix or batches of square matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b469ab85777119e331c0d2b40b68cd19ac71da49" translate="yes" xml:space="preserve">
          <source>Calculates log determinant of a square matrix or batches of square matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbc9fd03c3e295de099741d45013bec1bd5703f7" translate="yes" xml:space="preserve">
          <source>Calculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the probability of possible alignments of input to target, producing a loss value which is differentiable with respect to each input node. The alignment of input to target is assumed to be &amp;ldquo;many-to-one&amp;rdquo;, which limits the length of the target sequence such that it must be</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b95dc9e720785341df91a709dd18edb57e422e8" translate="yes" xml:space="preserve">
          <source>Calculates pointwise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19a076a6c7df9171545ad04fdc2cc5f305e06b38" translate="yes" xml:space="preserve">
          <source>Calculates the learning rate at batch index. This function treats &lt;code&gt;self.last_epoch&lt;/code&gt; as the last batch index.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f73e5660ccb505df5953e1fbed92e6c8a064be1" translate="yes" xml:space="preserve">
          <source>Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afbe6768e28de20bd0669bfb42db4b0e5335e016" translate="yes" xml:space="preserve">
          <source>Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor. Please look at &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse&quot;&gt;Moore-Penrose inverse&lt;/a&gt; for more details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf3fa1ed9287f3a31249968ae80488bbbc90709d" translate="yes" xml:space="preserve">
          <source>Calculates the sign and log absolute value of the determinant(s) of a square matrix or batches of square matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc5cae9078b78a08c10f30abb3ba9b5b22cfef54" translate="yes" xml:space="preserve">
          <source>Callables prefixed with underscore are considered as helper functions which won&amp;rsquo;t show up in &lt;a href=&quot;#torch.hub.list&quot;&gt;&lt;code&gt;torch.hub.list()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c42beef7db382c9ae158419c3ebc5c8310023f1" translate="yes" xml:space="preserve">
          <source>Calling &lt;code&gt;hub.set_dir(&amp;lt;PATH_TO_HUB_DIR&amp;gt;)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="265655dd73dcd39520c5cd9a954e45b04d35e8a1" translate="yes" xml:space="preserve">
          <source>Calling &lt;code&gt;torch.kaiser_window(L, B, periodic=True)&lt;/code&gt; is equivalent to calling &lt;code&gt;torch.kaiser_window(L + 1, B, periodic=False)[:-1])&lt;/code&gt;. The &lt;code&gt;periodic&lt;/code&gt; argument is intended as a helpful shorthand to produce a periodic window as input to functions like &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;torch.stft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d622de7b9cec6af9b50c591c0762f95f6cf23f1" translate="yes" xml:space="preserve">
          <source>Calling a submodule directly (e.g. &lt;code&gt;self.resnet(input)&lt;/code&gt;) is equivalent to calling its &lt;code&gt;forward&lt;/code&gt; method (e.g. &lt;code&gt;self.resnet.forward(input)&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b7d84e5b4532eb537ef53414226540774bd94f3" translate="yes" xml:space="preserve">
          <source>Calling the backward transform (&lt;a href=&quot;#torch.fft.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57076e248ecf298e1219a0fa6ecf299084bfedd8" translate="yes" xml:space="preserve">
          <source>Calling the backward transform (&lt;a href=&quot;#torch.fft.ihfft&quot;&gt;&lt;code&gt;ihfft()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.ihfft&quot;&gt;&lt;code&gt;ihfft()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6550668f3134865d4fd7ecb672c8b13821a60616" translate="yes" xml:space="preserve">
          <source>Calling the backward transform (&lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="393935e7b8f54e6c891a458a9a0a5b90620581df" translate="yes" xml:space="preserve">
          <source>Calling the forward transform (&lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c4696c3c77b6fbb0767ee074a0b08401ad5fd2b" translate="yes" xml:space="preserve">
          <source>Calling the forward transform (&lt;a href=&quot;#torch.fft.hfft&quot;&gt;&lt;code&gt;hfft()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.ihfft&quot;&gt;&lt;code&gt;ihfft()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0f807127c82b5c379fa18d9be9a714272f46e17" translate="yes" xml:space="preserve">
          <source>Calling the forward transform (&lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;) with the same normalization mode will apply an overall normalization of &lt;code&gt;1/n&lt;/code&gt; between the two transforms. This is required to make &lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt; the exact inverse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76582af9585743776e20d4bdf66734ecbe7e7ff9" translate="yes" xml:space="preserve">
          <source>Calls to &lt;code&gt;builtin functions&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb07741ad617617e9abda7e3d52fee63a305a121" translate="yes" xml:space="preserve">
          <source>Calls to methods of builtin types like tensor: &lt;code&gt;x.mm(y)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc7e70542d9259610f72ca817bd3eb6584edd2c8" translate="yes" xml:space="preserve">
          <source>Calls to other script functions:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6867b70db2065294481ad42aed53ba49e6355b8" translate="yes" xml:space="preserve">
          <source>Can also be used for higher dimension inputs, such as 2D images, by providing an input of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="221c9205ab30df3bd1004805355ca477c455a15b" translate="yes" xml:space="preserve">
          <source>Can only be called once and before any inter-op parallel work is started (e.g. JIT execution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3805fd56c2af8071d51bc53ae0a92fdcb58807db" translate="yes" xml:space="preserve">
          <source>Casting Examples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7500c883cdd17fa4172ea83911ebf91a32625de" translate="yes" xml:space="preserve">
          <source>Casts</source>
          <target state="translated">Casts</target>
        </trans-unit>
        <trans-unit id="26538798d0973ae83ca7715b676794ed3b172f33" translate="yes" xml:space="preserve">
          <source>Casts all floating point parameters and buffers to &lt;code&gt;bfloat16&lt;/code&gt; datatype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6c764881902912eb6ba271fb55ce5179af34673" translate="yes" xml:space="preserve">
          <source>Casts all floating point parameters and buffers to &lt;code&gt;double&lt;/code&gt; datatype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78461ae0a43c2d54b7c9efa684628bba9ad1c1ed" translate="yes" xml:space="preserve">
          <source>Casts all floating point parameters and buffers to &lt;code&gt;half&lt;/code&gt; datatype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="661d47897b8e53cbd52a45424e86044636652304" translate="yes" xml:space="preserve">
          <source>Casts all floating point parameters and buffers to float datatype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4724f395a64ded08f676d2e9e0393dcb0f712246" translate="yes" xml:space="preserve">
          <source>Casts all parameters and buffers to &lt;code&gt;dst_type&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79f02a31265abcb1bb988f26d0c498d397fdd789" translate="yes" xml:space="preserve">
          <source>Casts this storage to bfloat16 type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd487dabbd2c7187cd079ec504def8aaf3a7b571" translate="yes" xml:space="preserve">
          <source>Casts this storage to bool type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6694cf255316b894b3ad2697cc3b38ec9452ca42" translate="yes" xml:space="preserve">
          <source>Casts this storage to byte type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="151ff3570c6883e5b0af6409a5ae071d0e154dbc" translate="yes" xml:space="preserve">
          <source>Casts this storage to char type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3e9e6a46615473165fa7e0ec3e61fb30d1e8866" translate="yes" xml:space="preserve">
          <source>Casts this storage to complex double type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="510b5fa8a83cea216c27cd3b246f5ff67c971a64" translate="yes" xml:space="preserve">
          <source>Casts this storage to complex float type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e339cd7fb3f62430cb2f45b27e9e325c9fd432f" translate="yes" xml:space="preserve">
          <source>Casts this storage to double type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46bf8db49512235eab20518ddd006bc28b925a2c" translate="yes" xml:space="preserve">
          <source>Casts this storage to float type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63e25d02d152bfc3b6809c0d00d52a9786a45699" translate="yes" xml:space="preserve">
          <source>Casts this storage to half type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dd4507b920a808cec77926ae75ebeb4c2c63230" translate="yes" xml:space="preserve">
          <source>Casts this storage to int type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afab2e0bade340b8cecdf6e13b386611e22e2730" translate="yes" xml:space="preserve">
          <source>Casts this storage to long type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4ce7dd1afcf534c203c4afd8fc54fe512dfe75d" translate="yes" xml:space="preserve">
          <source>Casts this storage to short type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8528ae94e2e148afb1dc7ce9973ecc62392671c1" translate="yes" xml:space="preserve">
          <source>Categorical</source>
          <target state="translated">Categorical</target>
        </trans-unit>
        <trans-unit id="0b7b85a2968dc04c734a5094885d58f3c06a57c0" translate="yes" xml:space="preserve">
          <source>Cauchy</source>
          <target state="translated">Cauchy</target>
        </trans-unit>
        <trans-unit id="795a0c324ff1f130803359d377842d67e3339ceb" translate="yes" xml:space="preserve">
          <source>Change if autograd should record operations on parameters in this module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="771633aa9e4ffd6ed00dfc406fa17e09d36a9380" translate="yes" xml:space="preserve">
          <source>Change if autograd should record operations on this tensor: sets this tensor&amp;rsquo;s &lt;a href=&quot;autograd#torch.Tensor.requires_grad&quot;&gt;&lt;code&gt;requires_grad&lt;/code&gt;&lt;/a&gt; attribute in-place. Returns this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df974d2905d5cd175e8ce062cca16506fc69a1da" translate="yes" xml:space="preserve">
          <source>Channel dim is the 2nd dim of input. When input has dims &amp;lt; 2, then there is no channel dim and the number of channels = 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="239e4420c7d4084b23404d4d0c56239ffc4eca05" translate="yes" xml:space="preserve">
          <source>Check gradients computed via small finite differences against analytical gradients w.r.t. tensors in &lt;code&gt;inputs&lt;/code&gt; that are of floating point or complex type and with &lt;code&gt;requires_grad=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82aa07bbbf68e1780a5f4ead49b824c7cc4f5648" translate="yes" xml:space="preserve">
          <source>Check gradients of gradients computed via small finite differences against analytical gradients w.r.t. tensors in &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;grad_outputs&lt;/code&gt; that are of floating point or complex type and with &lt;code&gt;requires_grad=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56ff021269456a017773120e4ed3d4af95c8ae59" translate="yes" xml:space="preserve">
          <source>Check whether &lt;code&gt;module&lt;/code&gt; is pruned by looking for &lt;code&gt;forward_pre_hooks&lt;/code&gt; in its modules that inherit from the &lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4c8690ed4ddc9de7d901e88e48d1d54b0026ac9" translate="yes" xml:space="preserve">
          <source>Check whether &lt;code&gt;module&lt;/code&gt; is pruned by looking for &lt;code&gt;forward_pre_hooks&lt;/code&gt; in its modules that inherit from the &lt;code&gt;BasePruningMethod&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3a48ae8d9eebbbcfe68f114073dd271c96bf314" translate="yes" xml:space="preserve">
          <source>Check whether it&amp;rsquo;s in the middle of the ONNX export. This function returns True in the middle of torch.onnx.export(). torch.onnx.export should be executed with single thread.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e151686a765ce214247b375cc4d7aa1c97e4e14f" translate="yes" xml:space="preserve">
          <source>Checking if the default process group has been initialized</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b37b3cf9158406adf7b90792ec9193ec0e0c1df6" translate="yes" xml:space="preserve">
          <source>Checkpoint a model or part of the model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95fac7ec70656fe8c623fe8fbf3c5c04c9b16115" translate="yes" xml:space="preserve">
          <source>Checkpointing doesn&amp;rsquo;t work with &lt;a href=&quot;autograd#torch.autograd.grad&quot;&gt;&lt;code&gt;torch.autograd.grad()&lt;/code&gt;&lt;/a&gt;, but only with &lt;a href=&quot;autograd#torch.autograd.backward&quot;&gt;&lt;code&gt;torch.autograd.backward()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f51f71651c6e78eb334ceb82bf5f372ed3b9e12e" translate="yes" xml:space="preserve">
          <source>Checkpointing is implemented by rerunning a forward-pass segment for each checkpointed segment during backward. This can cause persistent states like the RNG state to be advanced than they would without checkpointing. By default, checkpointing includes logic to juggle the RNG state such that checkpointed passes making use of RNG (through dropout for example) have deterministic output as compared to non-checkpointed passes. The logic to stash and restore RNG states can incur a moderate performance hit depending on the runtime of checkpointed operations. If deterministic output compared to non-checkpointed passes is not required, supply &lt;code&gt;preserve_rng_state=False&lt;/code&gt; to &lt;code&gt;checkpoint&lt;/code&gt; or &lt;code&gt;checkpoint_sequential&lt;/code&gt; to omit stashing and restoring the RNG state during each checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="332b6971e8e3a29969ff874b4073e4272d2a843f" translate="yes" xml:space="preserve">
          <source>Checkpointing works by trading compute for memory. Rather than storing all intermediate activations of the entire computation graph for computing backward, the checkpointed part does &lt;strong&gt;not&lt;/strong&gt; save intermediate activations, and instead recomputes them in backward pass. It can be applied on any part of a model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="893f0f558202bc0518489f883166ffe50bb8bd4d" translate="yes" xml:space="preserve">
          <source>Checks if all the work submitted has been completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="945f252428f14d3ff3238e766e3368cedac5589e" translate="yes" xml:space="preserve">
          <source>Checks if all work currently captured by event has completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="635284a98c9a3f2f5e6091ab87ff16c33d35a6cc" translate="yes" xml:space="preserve">
          <source>Checks if any sent CUDA tensors could be cleaned from the memory. Force closes shared memory file used for reference counting if there is no active counters. Useful when the producer process stopped actively sending tensors and want to release unused memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39f6e80dd8c8ac31e71117491def641d00a288d1" translate="yes" xml:space="preserve">
          <source>Checks if tensor is in shared memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19004c9ecdb08358c5474afc574d3f10f8cf3c71" translate="yes" xml:space="preserve">
          <source>Checks if the MPI backend is available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2d9da2e3f6bd1dd91d87846cd5b419112d24146" translate="yes" xml:space="preserve">
          <source>Checks if the NCCL backend is available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f4ac26af6f73e2c8bc1f384efba8f7bd4839e87" translate="yes" xml:space="preserve">
          <source>Chi2</source>
          <target state="translated">Chi2</target>
        </trans-unit>
        <trans-unit id="56268a6e36c10e47601c6c33d1ee9618154a6c67" translate="yes" xml:space="preserve">
          <source>Choosing the network interface to use</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9eaceff91c313f7cab180625e8b4dd09baebd23" translate="yes" xml:space="preserve">
          <source>Clamp all elements in &lt;code&gt;input&lt;/code&gt; into the range &lt;code&gt;[&lt;/code&gt;&lt;a href=&quot;generated/torch.min#torch.min&quot;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.max#torch.max&quot;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt;&lt;code&gt;]&lt;/code&gt; and return a resulting tensor:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="378e42a306697a4dd63aa3dd31b3c55c600db5d2" translate="yes" xml:space="preserve">
          <source>Clamp all elements in &lt;code&gt;input&lt;/code&gt; into the range &lt;code&gt;[&lt;/code&gt;&lt;a href=&quot;torch.min#torch.min&quot;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;torch.max#torch.max&quot;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt;&lt;code&gt;]&lt;/code&gt; and return a resulting tensor:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfe592b543afcbd470b6fcfa84bfb4061fbeb434" translate="yes" xml:space="preserve">
          <source>Clamps all elements in &lt;code&gt;input&lt;/code&gt; to be larger or equal &lt;a href=&quot;torch.min#torch.min&quot;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7bab3a95a3c2fe6a5a776d67024bda46c058f02" translate="yes" xml:space="preserve">
          <source>Clamps all elements in &lt;code&gt;input&lt;/code&gt; to be smaller or equal &lt;a href=&quot;torch.max#torch.max&quot;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8943ee6c6160fec8979faa9096fac2e19ce7bfd" translate="yes" xml:space="preserve">
          <source>Classes must be new-style classes, as we use &lt;code&gt;__new__()&lt;/code&gt; to construct them with pybind11.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b6b05a782b6d150aaf1e98e0fdbbcbc865ca9be" translate="yes" xml:space="preserve">
          <source>Classes that inherit from &lt;code&gt;torch.jit.ScriptModule&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94c2a3189e7f7885455350c4c7a8df2d0d6ad1d1" translate="yes" xml:space="preserve">
          <source>Classification</source>
          <target state="translated">Classification</target>
        </trans-unit>
        <trans-unit id="140c2943a67faf9ddd529fa9ef19fca05ebb9209" translate="yes" xml:space="preserve">
          <source>Clears the cuFFT plan cache.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="026a5307ef4b381234e9524521b9341950a6f9cf" translate="yes" xml:space="preserve">
          <source>Clip acc@1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7ba9ed0f0f5ac74d1bfd4abe70aaeb95921f947" translate="yes" xml:space="preserve">
          <source>Clip acc@5</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75ccb1e878d6b2fcd6f1473f8a7c353d6b2e4806" translate="yes" xml:space="preserve">
          <source>Clips gradient norm of an iterable of parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="990a2e75895b3d0ccfe4b20a82d20496b3e8ee0f" translate="yes" xml:space="preserve">
          <source>Clips gradient of an iterable of parameters at specified value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4abb632898cd5f62fe263afaf95d739031ecab2" translate="yes" xml:space="preserve">
          <source>Closure use is not currently supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b8f8ed2e1db909d591f68c446a99d83144eb890" translate="yes" xml:space="preserve">
          <source>Code running on Node 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a4d07ff7beaaa363e77cbea9319ab7a99ad01d0" translate="yes" xml:space="preserve">
          <source>Code running on Node 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfa7c14251111856333ef843853b74b24bdf052b" translate="yes" xml:space="preserve">
          <source>Collective functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43092611315cdcde3137662c72b15d7a3a889e75" translate="yes" xml:space="preserve">
          <source>Collects the provided &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; objects into a single combined &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; that is completed when all of the sub-futures are completed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce079595058d15f2351c808e0ae1b284bea0c578" translate="yes" xml:space="preserve">
          <source>Combines an array of sliding local blocks into a large containing tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46488d0a373ab0b6babd0f93cccfb474321ae981" translate="yes" xml:space="preserve">
          <source>Combining Distributed DataParallel with Distributed RPC Framework</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c170217f39333026f4f3aa0323fa905552560ec9" translate="yes" xml:space="preserve">
          <source>Common environment variables</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="086cb07d3ecde2b840e1f458bfa9fda481174a5f" translate="yes" xml:space="preserve">
          <source>Common linear algebra operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4f955c58ceb08791953e5d03b53e986ad69907d" translate="yes" xml:space="preserve">
          <source>Commonly used ones include the following for debugging purposes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4beeb1b54292a1c6c080f3d414574b83eca3b2f1" translate="yes" xml:space="preserve">
          <source>Communication collectives</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfd58ee3a270f3a931009900e1008d549bbd7453" translate="yes" xml:space="preserve">
          <source>Community</source>
          <target state="translated">Community</target>
        </trans-unit>
        <trans-unit id="e0c1faa1db1f49518cfef07ea955debfa4db607f" translate="yes" xml:space="preserve">
          <source>Compare against the full output from &lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ccc8d4186f8b576455c6bf986c275fa4e1ca508" translate="yes" xml:space="preserve">
          <source>Compare against the full output from &lt;a href=&quot;#torch.fft.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9194e4e84d8475d85c26bc6d3d0aabdb9a3cfba" translate="yes" xml:space="preserve">
          <source>Compared against the full output from &lt;a href=&quot;#torch.fft.fftn&quot;&gt;&lt;code&gt;fftn()&lt;/code&gt;&lt;/a&gt;, we have all elements up to the Nyquist frequency.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25acda77b0bc6b058bd349dd6f4a271e2a967bfe" translate="yes" xml:space="preserve">
          <source>Comparison Operators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64e945410bd38eb8bc541fa4fe0d1a5601a0a7ba" translate="yes" xml:space="preserve">
          <source>Comparison Ops</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c73def212afdc811169afd7e77aebfbeecb5facc" translate="yes" xml:space="preserve">
          <source>Complex Numbers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="258ac8f61c6506a35c0dfc4029a4818ba9555f2a" translate="yes" xml:space="preserve">
          <source>Complex values are infinite when their real or imaginary part is infinite.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20602cb78c6ade6e08a8e69fafec22e07a7a725f" translate="yes" xml:space="preserve">
          <source>Complex-to-complex Discrete Fourier Transform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7075fa71ba5aa25f75795b49f1a3a1c5779af40" translate="yes" xml:space="preserve">
          <source>Complex-to-complex Inverse Discrete Fourier Transform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfb4fe1390cd2aa35fb926daaca343f331617fd7" translate="yes" xml:space="preserve">
          <source>Complex-to-real Inverse Discrete Fourier Transform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5269e04efa4004aaf8887ad9e476bf6a875cd697" translate="yes" xml:space="preserve">
          <source>Composes multiple transforms in a chain. The transforms being composed are responsible for caching.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27aacbfb281b15263d3c0a945d248f0f178b79f9" translate="yes" xml:space="preserve">
          <source>Compute Kullback-Leibler divergence</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49a3dcb8dae28aaaa8933d10f9d1fc99995fdb01" translate="yes" xml:space="preserve">
          <source>Compute combinations of length</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c47a0f87804b817e8011c46890b198b5bc4d108" translate="yes" xml:space="preserve">
          <source>Compute the scale and zero point the same way as in the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad88b5c709893b3c20a622a8af743326fc15e581" translate="yes" xml:space="preserve">
          <source>Computes</source>
          <target state="translated">Computes</target>
        </trans-unit>
        <trans-unit id="b29ddfa9b93c0c21e2cd9673bf929a7688cb085a" translate="yes" xml:space="preserve">
          <source>Computes &lt;code&gt;input&lt;/code&gt; divided by &lt;code&gt;other&lt;/code&gt;, elementwise, and rounds each quotient towards zero. Equivalently, it truncates the quotient(s):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3181f8cc8e8fa272eef8d4d3ff7058798e00f63" translate="yes" xml:space="preserve">
          <source>Computes a QR decomposition of &lt;code&gt;input&lt;/code&gt;, but without constructing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f69a85669ba4f546c3f6c75d8d8a225191c83e6a" translate="yes" xml:space="preserve">
          <source>Computes a partial inverse of &lt;a href=&quot;torch.nn.maxpool1d#torch.nn.MaxPool1d&quot;&gt;&lt;code&gt;MaxPool1d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf04c1ac66a51bee90d0426e3c8106a0e4185416" translate="yes" xml:space="preserve">
          <source>Computes a partial inverse of &lt;a href=&quot;torch.nn.maxpool2d#torch.nn.MaxPool2d&quot;&gt;&lt;code&gt;MaxPool2d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f360cd6902e1a0579d80b170c5497449c1afe016" translate="yes" xml:space="preserve">
          <source>Computes a partial inverse of &lt;a href=&quot;torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt;&lt;code&gt;MaxPool3d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26e6d25fb90ed6ad09263d6546b96e18a94d0c3e" translate="yes" xml:space="preserve">
          <source>Computes a partial inverse of &lt;code&gt;MaxPool1d&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18c31c026887e211a21e3dc7927a9d793872976e" translate="yes" xml:space="preserve">
          <source>Computes a partial inverse of &lt;code&gt;MaxPool2d&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85ab6bb517a0364e7f136e092fa61b3c016286ff" translate="yes" xml:space="preserve">
          <source>Computes a partial inverse of &lt;code&gt;MaxPool3d&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7cc19759037b27ca2d7fb79591e62353c0937a7" translate="yes" xml:space="preserve">
          <source>Computes and returns a mask for the input tensor &lt;code&gt;t&lt;/code&gt;. Starting from a base &lt;code&gt;default_mask&lt;/code&gt; (which should be a mask of ones if the tensor has not been pruned yet), generate a mask to apply on top of the &lt;code&gt;default_mask&lt;/code&gt; by zeroing out the channels along the specified dim with the lowest Ln-norm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40d80ee71e511c62ded894cfa5f39bc5b20875f0" translate="yes" xml:space="preserve">
          <source>Computes and returns a mask for the input tensor &lt;code&gt;t&lt;/code&gt;. Starting from a base &lt;code&gt;default_mask&lt;/code&gt; (which should be a mask of ones if the tensor has not been pruned yet), generate a random mask to apply on top of the &lt;code&gt;default_mask&lt;/code&gt; according to the specific pruning method recipe.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65434598b41da121b29ca65831d67382801ae0c7" translate="yes" xml:space="preserve">
          <source>Computes and returns a mask for the input tensor &lt;code&gt;t&lt;/code&gt;. Starting from a base &lt;code&gt;default_mask&lt;/code&gt; (which should be a mask of ones if the tensor has not been pruned yet), generate a random mask to apply on top of the &lt;code&gt;default_mask&lt;/code&gt; by randomly zeroing out channels along the specified dim of the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="180bc7b0d8de7293424fe248fc89cd2c995f979c" translate="yes" xml:space="preserve">
          <source>Computes and returns a pruned version of input tensor &lt;code&gt;t&lt;/code&gt; according to the pruning rule specified in &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.compute_mask&quot;&gt;&lt;code&gt;compute_mask()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a3fb50e3449e8908990f0c00a969ef20d83c411" translate="yes" xml:space="preserve">
          <source>Computes and returns a pruned version of input tensor &lt;code&gt;t&lt;/code&gt; according to the pruning rule specified in &lt;a href=&quot;#torch.nn.utils.prune.LnStructured.compute_mask&quot;&gt;&lt;code&gt;compute_mask()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9efff4b9b21781ca7329ebc9ab81c9ec882d85a1" translate="yes" xml:space="preserve">
          <source>Computes and returns a pruned version of input tensor &lt;code&gt;t&lt;/code&gt; according to the pruning rule specified in &lt;a href=&quot;#torch.nn.utils.prune.PruningContainer.compute_mask&quot;&gt;&lt;code&gt;compute_mask()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f99800562bd522721e9ea1fa3102c89a24cca75f" translate="yes" xml:space="preserve">
          <source>Computes and returns a pruned version of input tensor &lt;code&gt;t&lt;/code&gt; according to the pruning rule specified in &lt;a href=&quot;#torch.nn.utils.prune.RandomStructured.compute_mask&quot;&gt;&lt;code&gt;compute_mask()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28c95a2d472ee12c714c4dae6bc27475d57d2a6e" translate="yes" xml:space="preserve">
          <source>Computes and returns a pruned version of input tensor &lt;code&gt;t&lt;/code&gt; according to the pruning rule specified in &lt;code&gt;compute_mask()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7251032ff2b6d46923b585e413559af8bf29d269" translate="yes" xml:space="preserve">
          <source>Computes and returns the sum of gradients of outputs w.r.t. the inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ad7888f31836fca25fd59e8bf8deaf0775bd8bb" translate="yes" xml:space="preserve">
          <source>Computes batched the p-norm distance between each pair of the two collections of row vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2e6dd93c4230ac985c6eeef22bb5e42799d351c" translate="yes" xml:space="preserve">
          <source>Computes element-wise equality</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23c55c6419438b7d4003d50aab0fa866dc6b754c" translate="yes" xml:space="preserve">
          <source>Computes log probabilities for all</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bffd347218e0b14edb14dc921db35164acedc246" translate="yes" xml:space="preserve">
          <source>Computes sums or means of &amp;lsquo;bags&amp;rsquo; of embeddings, without instantiating the intermediate embeddings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7d9c1eb8347c9d1cc0af2b2b967716bd8c4ae77" translate="yes" xml:space="preserve">
          <source>Computes sums, means or maxes of &lt;code&gt;bags&lt;/code&gt; of embeddings, without instantiating the intermediate embeddings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b71f4915a8b78a90bf71f4feb80ae5bf3e75096c" translate="yes" xml:space="preserve">
          <source>Computes the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff498bc657a9c74488608c0ce73fd38063feeafe" translate="yes" xml:space="preserve">
          <source>Computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_gamma_function&quot;&gt;multivariate log-gamma function&lt;/a&gt;) with dimension</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76557cba93a25c6c86c33cc0d82d4b6080c0ca6f" translate="yes" xml:space="preserve">
          <source>Computes the Cholesky decomposition of a symmetric positive-definite matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81b53a3d90c63815ad24683a8c1c69a90d47d01e" translate="yes" xml:space="preserve">
          <source>Computes the Heaviside step function for each element in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d07d50a47d9ca8fe0d585f7aa291a49089343e4" translate="yes" xml:space="preserve">
          <source>Computes the Heaviside step function for each element in &lt;code&gt;input&lt;/code&gt;. The Heaviside step function is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="275e74bec95b0ab85103e19b6d6479c703706e12" translate="yes" xml:space="preserve">
          <source>Computes the Kaiser window with window length &lt;code&gt;window_length&lt;/code&gt; and shape parameter &lt;code&gt;beta&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="622fda98680f4721949b3e2bf9b78a14c34deb65" translate="yes" xml:space="preserve">
          <source>Computes the LU factorization of a matrix or batches of matrices &lt;code&gt;A&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ec07270d301f5370c046b7066eb8663a8f402a1" translate="yes" xml:space="preserve">
          <source>Computes the LU factorization of a matrix or batches of matrices &lt;code&gt;A&lt;/code&gt;. Returns a tuple containing the LU factorization and pivots of &lt;code&gt;A&lt;/code&gt;. Pivoting is done if &lt;code&gt;pivot&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c3fba3f6161937ff4ae86bdb0e983d0c0fdda0b" translate="yes" xml:space="preserve">
          <source>Computes the N dimensional discrete Fourier transform of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5852120d66c32f7c318de497ae26eeb74f1de763" translate="yes" xml:space="preserve">
          <source>Computes the N dimensional inverse discrete Fourier transform of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efd57d1e36575205366c8a3b4753ee576bd1a231" translate="yes" xml:space="preserve">
          <source>Computes the N-dimensional discrete Fourier transform of real &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a21392e07d8e832fdaaf1fc616e555a310a70752" translate="yes" xml:space="preserve">
          <source>Computes the QR decomposition of a matrix or a batch of matrices &lt;code&gt;input&lt;/code&gt;, and returns a namedtuple (Q, R) of tensors such that</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d476f44296e977553528b2efe494b3789b4d6cc8" translate="yes" xml:space="preserve">
          <source>Computes the absolute value of each element in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da0e0333ca7d69a3bf51d86eddafcf5537f32ee1" translate="yes" xml:space="preserve">
          <source>Computes the base two exponential function of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="833d30840f6f79f8ac884e63624d72a29fe2aedb" translate="yes" xml:space="preserve">
          <source>Computes the batchwise pairwise distance between vectors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b81b9d06afde312e3c1de6fa3003c1826f20a144" translate="yes" xml:space="preserve">
          <source>Computes the bitwise AND of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="724c0661558717da97da9f13301714db62123db8" translate="yes" xml:space="preserve">
          <source>Computes the bitwise AND of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;. The input tensor must be of integral or Boolean types. For bool tensors, it computes the logical AND.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c385fff8361fd76237dd3d0d310601e4ded675d" translate="yes" xml:space="preserve">
          <source>Computes the bitwise NOT of the given input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d34002186774eda6ff1544d9bb235cb5b5e464f1" translate="yes" xml:space="preserve">
          <source>Computes the bitwise NOT of the given input tensor. The input tensor must be of integral or Boolean types. For bool tensors, it computes the logical NOT.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1676d4cae5deb51721032154a09c9a5c26471fe8" translate="yes" xml:space="preserve">
          <source>Computes the bitwise OR of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db7eb5bd0ae610915cc8f5aaa985b610903472f9" translate="yes" xml:space="preserve">
          <source>Computes the bitwise OR of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;. The input tensor must be of integral or Boolean types. For bool tensors, it computes the logical OR.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a7aa82e188d57e1be91dd1e59e101918adf2efe" translate="yes" xml:space="preserve">
          <source>Computes the bitwise XOR of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88579c44bdc54edf5679b9534b4247fa5a02a043" translate="yes" xml:space="preserve">
          <source>Computes the bitwise XOR of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;. The input tensor must be of integral or Boolean types. For bool tensors, it computes the logical XOR.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a3e45b925774a34d85da6c0c7b80c7c01e6ba8d" translate="yes" xml:space="preserve">
          <source>Computes the complementary error function of each element of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="159a12e467808284be4f45386c2f19ec971818e9" translate="yes" xml:space="preserve">
          <source>Computes the complementary error function of each element of &lt;code&gt;input&lt;/code&gt;. The complementary error function is defined as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8d67586d06368678f0e647fdffb8c00b8bde78b" translate="yes" xml:space="preserve">
          <source>Computes the cumulative distribution function by inverting the transform(s) and computing the score of the base distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1983c92beb407d56255dcc00b5fe7b66872fc6d6" translate="yes" xml:space="preserve">
          <source>Computes the dot product (inner product) of two tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a5b212f2d4dd5a8260512297de68c3095e68cab" translate="yes" xml:space="preserve">
          <source>Computes the dot product (inner product) of two tensors. The vdot(a, b) function handles complex numbers differently than dot(a, b). If the first argument is complex, the complex conjugate of the first argument is used for the calculation of the dot product.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e16561fbcf4a6c2f2dd9afb54001a93a98731fdc" translate="yes" xml:space="preserve">
          <source>Computes the eigenvalues and eigenvectors of a real square matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52f9bd141b84eda92242b06f7f6d290a253966b4" translate="yes" xml:space="preserve">
          <source>Computes the element-wise angle (in radians) of the given &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47dc21f5f4986e27abb977788d16b590a07a71d6" translate="yes" xml:space="preserve">
          <source>Computes the element-wise conjugate of the given &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a964097a08f63a42878b22585751fd92a8682df" translate="yes" xml:space="preserve">
          <source>Computes the element-wise conjugate of the given &lt;code&gt;input&lt;/code&gt; tensor. If :attr`input` has a non-complex dtype, this function just returns &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e315d5a6fd3a46bc729f0eda3f3fb92b601c50b" translate="yes" xml:space="preserve">
          <source>Computes the element-wise greatest common divisor (GCD) of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91ee032a4ff000ec84d35b04317442f4984e6937" translate="yes" xml:space="preserve">
          <source>Computes the element-wise least common multiple (LCM) of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e7b021553644e46362536880a5431b72a0587b9" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical AND of the given input tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68b2bf2409a8b5d2be8906244e0a49294d2e9679" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical AND of the given input tensors. Zeros are treated as &lt;code&gt;False&lt;/code&gt; and nonzeros are treated as &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a94b7ab9f10124804e19d264d7207840dc6728d2" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical NOT of the given input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="117610e848f679548feba89108c832e6e9a20124" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical NOT of the given input tensor. If not specified, the output tensor will have the bool dtype. If the input tensor is not a bool tensor, zeros are treated as &lt;code&gt;False&lt;/code&gt; and non-zeros are treated as &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9572b2dd91b0d03ca02c1394c350df1174a646b0" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical OR of the given input tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="256665a803b61ee6a430a86e174d4bca0ee69abe" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical OR of the given input tensors. Zeros are treated as &lt;code&gt;False&lt;/code&gt; and nonzeros are treated as &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c172a20dd69ad22bb7b0a4de9500f73f3c3f98b9" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical XOR of the given input tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8837d2e60640bc8199344497981535b4ce62699" translate="yes" xml:space="preserve">
          <source>Computes the element-wise logical XOR of the given input tensors. Zeros are treated as &lt;code&gt;False&lt;/code&gt; and nonzeros are treated as &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b73dd1c77581f85619be2c0a672fa472582b7ef0" translate="yes" xml:space="preserve">
          <source>Computes the element-wise maximum of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c821156c5be7a7c6ec010c82496a8862539fc670" translate="yes" xml:space="preserve">
          <source>Computes the element-wise minimum of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b3693910cf57f242c4267e044d56aef8263e01c" translate="yes" xml:space="preserve">
          <source>Computes the element-wise remainder of division.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9003dd6b7c6711ac836cacfed24f4e0435a56aec" translate="yes" xml:space="preserve">
          <source>Computes the error function of each element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29774d569920339acd042c100fd75031d60d53ac" translate="yes" xml:space="preserve">
          <source>Computes the error function of each element. The error function is defined as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2434be214f6e5985b87d4c052539ff329a7f0314" translate="yes" xml:space="preserve">
          <source>Computes the fractional portion of each element in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb83638df4a6cb7d822fc5fb54ba573a3cd29240" translate="yes" xml:space="preserve">
          <source>Computes the gradient of current tensor w.r.t. graph leaves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce4470aa5bf338d4ad1d1c606fbb7a81df3b9429" translate="yes" xml:space="preserve">
          <source>Computes the histogram of a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28063e348dc010ab497d4b723f1ef5afa57d8d1a" translate="yes" xml:space="preserve">
          <source>Computes the inverse cosine of each element in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e87d84d689f558075500c51085bf75e2883ed115" translate="yes" xml:space="preserve">
          <source>Computes the inverse cumulative distribution function using transform(s) and computing the score of the base distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8f61c7d805f4a069d9c46e57aa8a4eda42a714f" translate="yes" xml:space="preserve">
          <source>Computes the inverse error function of each element of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac7da6502603da8eebb2a12646d0b0cbe100d072" translate="yes" xml:space="preserve">
          <source>Computes the inverse error function of each element of &lt;code&gt;input&lt;/code&gt;. The inverse error function is defined in the range</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0fc6a3f3385283ab40e97e09d370d8da0903b9c" translate="yes" xml:space="preserve">
          <source>Computes the inverse of &lt;a href=&quot;#torch.fft.hfft&quot;&gt;&lt;code&gt;hfft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f42895543a1b54cd19094b1bf3f3033fd72a6293" translate="yes" xml:space="preserve">
          <source>Computes the inverse of &lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8157bbb847ce3db3aa43a43004aeed9105153b04" translate="yes" xml:space="preserve">
          <source>Computes the inverse of &lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="751c20273a8826ac2930fa4c66f27dae7e42581e" translate="yes" xml:space="preserve">
          <source>Computes the inverse of a symmetric positive-definite matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa6955d637d20e846385cffc851f7eba38902835" translate="yes" xml:space="preserve">
          <source>Computes the log det jacobian &lt;code&gt;log |dy/dx|&lt;/code&gt; given input and output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ad2395a52ab42ac3844b6eab85a745737496c2b" translate="yes" xml:space="preserve">
          <source>Computes the logarithm of the gamma function on &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ab463de8fae2192880ba9572b3595b33254233d" translate="yes" xml:space="preserve">
          <source>Computes the logarithmic derivative of the gamma function on &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53d62470ba220fb7afc0e820b9e1d137675f35a7" translate="yes" xml:space="preserve">
          <source>Computes the one dimensional Fourier transform of real-valued &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df866b02f2fffb4ec82fb366d91cc209748d5c59" translate="yes" xml:space="preserve">
          <source>Computes the one dimensional discrete Fourier transform of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2bd9739508dd66799ff1e51b1381c47e1c1143b" translate="yes" xml:space="preserve">
          <source>Computes the one dimensional discrete Fourier transform of a Hermitian symmetric &lt;code&gt;input&lt;/code&gt; signal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c827fe5b069aea41e126efde791986643cae21d" translate="yes" xml:space="preserve">
          <source>Computes the one dimensional inverse discrete Fourier transform of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b12e2ad844db4fa1d8dc61bc76b5cc7fede08ebb" translate="yes" xml:space="preserve">
          <source>Computes the orthogonal matrix &lt;code&gt;Q&lt;/code&gt; of a QR factorization, from the &lt;code&gt;(input, input2)&lt;/code&gt; tuple returned by &lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a50e0c97fa82cb476bece9bdcb5b778a06bbe5b" translate="yes" xml:space="preserve">
          <source>Computes the orthogonal matrix &lt;code&gt;Q&lt;/code&gt; of a QR factorization, from the &lt;code&gt;(input, input2)&lt;/code&gt; tuple returned by &lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4aeca69a4a2b0bea72290f1b36d08fba25dfffc" translate="yes" xml:space="preserve">
          <source>Computes the p-norm distance between every pair of row vectors in the input. This is identical to the upper triangular portion, excluding the diagonal, of &lt;code&gt;torch.norm(input[:, None] - input, dim=2, p=p)&lt;/code&gt;. This function will be faster if the rows are contiguous.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52fb62cb631b335790a2488186d42d7739c05544" translate="yes" xml:space="preserve">
          <source>Computes the solution to the least squares and least norm problems for a full rank matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc93b1c0376d6ee7ab14503b3b1f5781ffb751f1" translate="yes" xml:space="preserve">
          <source>Computes the sum of gradients of given tensors w.r.t. graph leaves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf99caa72d6917de8396ddac94469751042f2b03" translate="yes" xml:space="preserve">
          <source>Computes the zeroth order modified Bessel function of the first kind for each element of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbcbb3162b2e52eeda82ef5d679b6c19cdfaf1b5" translate="yes" xml:space="preserve">
          <source>Computing dependencies</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ad79ab6353b1eee8ebbc085e10d17c4fcfb024f" translate="yes" xml:space="preserve">
          <source>Concat</source>
          <target state="translated">Concat</target>
        </trans-unit>
        <trans-unit id="4ddddf59160aed751a5f07007a03c044d9753ba8" translate="yes" xml:space="preserve">
          <source>Concatenates a sequence of tensors along a new dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b32473fe5755da0d831ffcfc10b7cdd982c9092" translate="yes" xml:space="preserve">
          <source>Concatenates the given sequence of &lt;code&gt;seq&lt;/code&gt; tensors in the given dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9ec200f382eb7e2b6f899132d934e4d406c3bcb" translate="yes" xml:space="preserve">
          <source>Concatenates the given sequence of &lt;code&gt;seq&lt;/code&gt; tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c06ff30c05c7117f8cd03376fe398c72a9caaba3" translate="yes" xml:space="preserve">
          <source>Concrete observers should follow the same API. In forward, they will update the statistics of the observed Tensor. And they should provide a &lt;code&gt;calculate_qparams&lt;/code&gt; function that computes the quantization parameters given the collected statistics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f8d364de32d6d9b96e9b370a225d6dab6d594c7" translate="yes" xml:space="preserve">
          <source>Concurrent calls to &lt;a href=&quot;#torch.distributed.optim.DistributedOptimizer.step&quot;&gt;&lt;code&gt;step()&lt;/code&gt;&lt;/a&gt;, either from the same or different clients, will be serialized on each worker &amp;ndash; as each worker&amp;rsquo;s optimizer can only work on one set of gradients at a time. However, there is no guarantee that the full forward-backward-optimizer sequence will execute for one client at a time. This means that the gradients being applied may not correspond to the latest forward pass executed on a given worker. Also, there is no guaranteed ordering across workers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30e59e381077a379cb9607bde3a4a42eb3f45ab9" translate="yes" xml:space="preserve">
          <source>Consider a batched &lt;code&gt;input&lt;/code&gt; tensor containing sliding local blocks, e.g., patches of images, of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f6c99c148a673c2e06016f795e6fb113b6d25b3" translate="yes" xml:space="preserve">
          <source>Consider a batched &lt;code&gt;input&lt;/code&gt; tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41c82c00063d59cec7ac15ce301400bc6cba5a1e" translate="yes" xml:space="preserve">
          <source>Considering the specific case of Momentum, the update can be written as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3d8f578f82ef706b4638b32cc8ac9d832c7f7c7" translate="yes" xml:space="preserve">
          <source>ConstantPad1d</source>
          <target state="translated">ConstantPad1d</target>
        </trans-unit>
        <trans-unit id="998c295145e82549d2f17c1a6ba6c23bef09837b" translate="yes" xml:space="preserve">
          <source>ConstantPad2d</source>
          <target state="translated">ConstantPad2d</target>
        </trans-unit>
        <trans-unit id="4a15d68828e68d36dcfe86ffe64b4e4f826c7f8a" translate="yes" xml:space="preserve">
          <source>ConstantPad3d</source>
          <target state="translated">ConstantPad3d</target>
        </trans-unit>
        <trans-unit id="0a41b38808acdf43af00c5eb932dd87575946224" translate="yes" xml:space="preserve">
          <source>ConstantPadNd</source>
          <target state="translated">ConstantPadNd</target>
        </trans-unit>
        <trans-unit id="0f386d7e7881b32fa39cb7b62bdb15c0f3a4c0e1" translate="yes" xml:space="preserve">
          <source>Constants</source>
          <target state="translated">Constants</target>
        </trans-unit>
        <trans-unit id="cba7185d08d214544898ab239c21fb5414c4fc69" translate="yes" xml:space="preserve">
          <source>Constants can be marked with a &lt;code&gt;Final&lt;/code&gt; class annotation instead of adding the name of the member to &lt;code&gt;__constants__&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e93ee8b7e4549e7e136ce0f0147ddef90f905dc" translate="yes" xml:space="preserve">
          <source>Construct 18 layer Resnet3D model as in &lt;a href=&quot;https://arxiv.org/abs/1711.11248&quot;&gt;https://arxiv.org/abs/1711.11248&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58c6f5a95316e94c0311dfa74a05b94384191ff6" translate="yes" xml:space="preserve">
          <source>Constructing averaged models</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33ba182b915c42fbc2d5adcf6ef39b2978c20cad" translate="yes" xml:space="preserve">
          <source>Constructing it</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14faa516e57e5e69781808c4221cf6c62dc83c10" translate="yes" xml:space="preserve">
          <source>Constructor for 18 layer Mixed Convolution network as in &lt;a href=&quot;https://arxiv.org/abs/1711.11248&quot;&gt;https://arxiv.org/abs/1711.11248&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="243abd8ffcbf23837c06014609b82a14c78192f1" translate="yes" xml:space="preserve">
          <source>Constructor for the 18 layer deep R(2+1)D network as in &lt;a href=&quot;https://arxiv.org/abs/1711.11248&quot;&gt;https://arxiv.org/abs/1711.11248&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25ef738c9d86e2fc8c4436c90a8dc11de37e7492" translate="yes" xml:space="preserve">
          <source>Constructor, forward method, and differentiation of the output (or a function of the output of this module) are distributed synchronization points. Take that into account in case different processes might be executing different code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3591588e6daf80e91783781c9de4873426a6c50" translate="yes" xml:space="preserve">
          <source>Constructs a DeepLabV3 model with a ResNet-101 backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b9d4f7f98afc347ec7829b73a659d20e47f4656" translate="yes" xml:space="preserve">
          <source>Constructs a DeepLabV3 model with a ResNet-50 backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8efeef3cc601befcf295dbb51e707b10b91e402" translate="yes" xml:space="preserve">
          <source>Constructs a Faster R-CNN model with a ResNet-50-FPN backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63a7411b909e98e9e117a9221e16319404fd9e0b" translate="yes" xml:space="preserve">
          <source>Constructs a Fully-Convolutional Network model with a ResNet-101 backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40a8ca8c7bf720c8a0f63021a990b502e7b406b0" translate="yes" xml:space="preserve">
          <source>Constructs a Fully-Convolutional Network model with a ResNet-50 backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c44ff1a6ea4f78ec6e55eb5a4dd0b0381511fd66" translate="yes" xml:space="preserve">
          <source>Constructs a Keypoint R-CNN model with a ResNet-50-FPN backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bac8f59a0445e0c89aaa35b2ecaf7957f6cbc76" translate="yes" xml:space="preserve">
          <source>Constructs a Mask R-CNN model with a ResNet-50-FPN backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed68461c0a66e54bb8577296b733b09ee8628e1f" translate="yes" xml:space="preserve">
          <source>Constructs a MobileNetV2 architecture from &lt;a href=&quot;https://arxiv.org/abs/1801.04381&quot;&gt;&amp;ldquo;MobileNetV2: Inverted Residuals and Linear Bottlenecks&amp;rdquo;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa58d20a53a578ca582a51e6082babe2633522d9" translate="yes" xml:space="preserve">
          <source>Constructs a RetinaNet model with a ResNet-50-FPN backbone.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c060b450d2f139169d01201742e2de6bd6813c33" translate="yes" xml:space="preserve">
          <source>Constructs a ShuffleNetV2 with 0.5x output channels, as described in &lt;a href=&quot;https://arxiv.org/abs/1807.11164&quot;&gt;&amp;ldquo;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&amp;rdquo;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1b1411f7ad7f2a9785e3f797d1ed1dca55c0522" translate="yes" xml:space="preserve">
          <source>Constructs a ShuffleNetV2 with 1.0x output channels, as described in &lt;a href=&quot;https://arxiv.org/abs/1807.11164&quot;&gt;&amp;ldquo;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&amp;rdquo;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="946788267a37fd704ae9ab9be9bb919471421254" translate="yes" xml:space="preserve">
          <source>Constructs a ShuffleNetV2 with 1.5x output channels, as described in &lt;a href=&quot;https://arxiv.org/abs/1807.11164&quot;&gt;&amp;ldquo;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&amp;rdquo;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3079515cd84378d124e9d68610779cdd6cd48ea" translate="yes" xml:space="preserve">
          <source>Constructs a ShuffleNetV2 with 2.0x output channels, as described in &lt;a href=&quot;https://arxiv.org/abs/1807.11164&quot;&gt;&amp;ldquo;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&amp;rdquo;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17f894712d4813d2bb2bfed6f1251b3bc7ad7f28" translate="yes" xml:space="preserve">
          <source>Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute value &lt;a href=&quot;generated/torch.abs#torch.abs&quot;&gt;&lt;code&gt;abs&lt;/code&gt;&lt;/a&gt; and angle &lt;a href=&quot;generated/torch.angle#torch.angle&quot;&gt;&lt;code&gt;angle&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21791c63e7cf531ba91fa49b8e8790ebd26c8e28" translate="yes" xml:space="preserve">
          <source>Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute value &lt;a href=&quot;torch.abs#torch.abs&quot;&gt;&lt;code&gt;abs&lt;/code&gt;&lt;/a&gt; and angle &lt;a href=&quot;torch.angle#torch.angle&quot;&gt;&lt;code&gt;angle&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f22df20de166bd700f665def840237abc20c0b1" translate="yes" xml:space="preserve">
          <source>Constructs a complex tensor with its real part equal to &lt;a href=&quot;generated/torch.real#torch.real&quot;&gt;&lt;code&gt;real&lt;/code&gt;&lt;/a&gt; and its imaginary part equal to &lt;a href=&quot;generated/torch.imag#torch.imag&quot;&gt;&lt;code&gt;imag&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cbc2c2e6f7677b79f4e49073177abc0eaf5c360" translate="yes" xml:space="preserve">
          <source>Constructs a complex tensor with its real part equal to &lt;a href=&quot;torch.real#torch.real&quot;&gt;&lt;code&gt;real&lt;/code&gt;&lt;/a&gt; and its imaginary part equal to &lt;a href=&quot;torch.imag#torch.imag&quot;&gt;&lt;code&gt;imag&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f93f080d3b4b5a3e3dc0939299e73f9681c6cfa7" translate="yes" xml:space="preserve">
          <source>Constructs a sparse tensors in COO(rdinate) format with non-zero elements at the given &lt;code&gt;indices&lt;/code&gt; with the given &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be72a7a131ec1a761dd654077e838e6f0e7ea737" translate="yes" xml:space="preserve">
          <source>Constructs a sparse tensors in COO(rdinate) format with non-zero elements at the given &lt;code&gt;indices&lt;/code&gt; with the given &lt;code&gt;values&lt;/code&gt;. A sparse tensor can be &lt;code&gt;uncoalesced&lt;/code&gt;, in that case, there are duplicate coordinates in the indices, and the value at that index is the sum of all duplicate value entries: &lt;a href=&quot;https://pytorch.org/docs/stable/sparse.html&quot;&gt;torch.sparse&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e69f365d19e40e598e945db7b7eaf81602d0597" translate="yes" xml:space="preserve">
          <source>Constructs a tensor with &lt;code&gt;data&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26d1a380017a1ee5db1ae9f2be051aa31298d8a4" translate="yes" xml:space="preserve">
          <source>Container holding a sequence of pruning methods for iterative pruning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecedca4e6711cc4546829104ac643201429f438a" translate="yes" xml:space="preserve">
          <source>Container holding a sequence of pruning methods for iterative pruning. Keeps track of the order in which pruning methods are applied and handles combining successive pruning calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e040a458f46532a90ec69fa0b4bfc33ba151c98b" translate="yes" xml:space="preserve">
          <source>Containers</source>
          <target state="translated">Containers</target>
        </trans-unit>
        <trans-unit id="a5f7ef3dcfb494670b1f12c053712004a30a5030" translate="yes" xml:space="preserve">
          <source>Containers are assumed to have type &lt;code&gt;Tensor&lt;/code&gt; and be non-optional (see &lt;code&gt;Default Types&lt;/code&gt; for more information). Previously, &lt;code&gt;torch.jit.annotate&lt;/code&gt; was used to tell the TorchScript compiler what the type should be. Python 3 style type hints are now supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c965d220340a70f3a925cd031cea31e23574727b" translate="yes" xml:space="preserve">
          <source>Context manager that makes every autograd operation emit an NVTX range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67a3ce3e7cefceac3d4c664550d90fc678be467d" translate="yes" xml:space="preserve">
          <source>Context manager that manages autograd profiler state and holds a summary of results. Under the hood it just records events of functions being executed in C++ and exposes those events to Python. You can wrap any code into it and it will only report runtime of PyTorch functions. Note: profiler is thread local and is automatically propagated into the async tasks</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b40e97ec64197b261ed2c352a763baa4c6268be" translate="yes" xml:space="preserve">
          <source>Context method mixins</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69cef769a134b0d4a56c19cba61f8a8ed316d60c" translate="yes" xml:space="preserve">
          <source>Context object to wrap forward and backward passes when using distributed autograd. The &lt;code&gt;context_id&lt;/code&gt; generated in the &lt;code&gt;with&lt;/code&gt; statement is required to uniquely identify a distributed backward pass on all workers. Each worker stores metadata associated with this &lt;code&gt;context_id&lt;/code&gt;, which is required to correctly execute a distributed autograd pass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34579070906cfe3afb9639eadd970c899029c8ca" translate="yes" xml:space="preserve">
          <source>Context-manager that changes the current device to that of given object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4802d234013bb6f1339b5d9be21cf85859570968" translate="yes" xml:space="preserve">
          <source>Context-manager that changes the selected device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05fa9ad5bb0946657dbbab246393aea9c7883c54" translate="yes" xml:space="preserve">
          <source>Context-manager that disabled gradient calculation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10cdc0b206fae92706049769655993622c2c5fd2" translate="yes" xml:space="preserve">
          <source>Context-manager that enable anomaly detection for the autograd engine.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98ceadd98235bb51cb8307cf83dd7c6d79e59720" translate="yes" xml:space="preserve">
          <source>Context-manager that enables gradient calculation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da467a4306f8a33fc27d4f7cbea22fc9876c9e5b" translate="yes" xml:space="preserve">
          <source>Context-manager that selects a given stream.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8479c988b868dfa3b4c887d081e83a92acf0bb43" translate="yes" xml:space="preserve">
          <source>Context-manager that sets gradient calculation to on or off.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc43ee1ff31732f8dd825fad1558c5ab44a47fa2" translate="yes" xml:space="preserve">
          <source>Context-manager that sets the anomaly detection for the autograd engine on or off.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fee61d743d1ceafef226afc45bfff28d600d1ec" translate="yes" xml:space="preserve">
          <source>ContinuousBernoulli</source>
          <target state="translated">ContinuousBernoulli</target>
        </trans-unit>
        <trans-unit id="4fbe3836d5db9ff249ce993c595d3f0f979273c3" translate="yes" xml:space="preserve">
          <source>Conv</source>
          <target state="translated">Conv</target>
        </trans-unit>
        <trans-unit id="0f579280c2328a913d6d725180603d671f003e1c" translate="yes" xml:space="preserve">
          <source>Conv1d</source>
          <target state="translated">Conv1d</target>
        </trans-unit>
        <trans-unit id="40b3c3b8c860add6637a732716bb59fe0a472372" translate="yes" xml:space="preserve">
          <source>Conv2d</source>
          <target state="translated">Conv2d</target>
        </trans-unit>
        <trans-unit id="11775e3bcd7c158060f3c37b634846211f59b0a8" translate="yes" xml:space="preserve">
          <source>Conv3d</source>
          <target state="translated">Conv3d</target>
        </trans-unit>
        <trans-unit id="7bd21924a004fee82a9b59ee3da28ba6cf10e0cd" translate="yes" xml:space="preserve">
          <source>ConvBn1d</source>
          <target state="translated">ConvBn1d</target>
        </trans-unit>
        <trans-unit id="b49eb764a64698e64c0e874c6a40f0bd980f5854" translate="yes" xml:space="preserve">
          <source>ConvBn2d</source>
          <target state="translated">ConvBn2d</target>
        </trans-unit>
        <trans-unit id="f2a4cf1ba0285a54525c0f0bced1d81a716af040" translate="yes" xml:space="preserve">
          <source>ConvBnReLU1d</source>
          <target state="translated">ConvBnReLU1d</target>
        </trans-unit>
        <trans-unit id="9a62f54f222bf04d2c6e425b49c602b198a2f54e" translate="yes" xml:space="preserve">
          <source>ConvBnReLU2d</source>
          <target state="translated">ConvBnReLU2d</target>
        </trans-unit>
        <trans-unit id="02be55e7a33c6df1aae2e7f342fb637e9ac77c6b" translate="yes" xml:space="preserve">
          <source>ConvReLU1d</source>
          <target state="translated">ConvReLU1d</target>
        </trans-unit>
        <trans-unit id="ee43a211652ce7b140d6ac846ff3539f57bfe4ce" translate="yes" xml:space="preserve">
          <source>ConvReLU2d</source>
          <target state="translated">ConvReLU2d</target>
        </trans-unit>
        <trans-unit id="9c9f7992fc4e6c43d3ef3ba68725dbe4ae51d5e7" translate="yes" xml:space="preserve">
          <source>ConvReLU3d</source>
          <target state="translated">ConvReLU3d</target>
        </trans-unit>
        <trans-unit id="afca9fffa388b0f4407644f89fc3d2572519c33f" translate="yes" xml:space="preserve">
          <source>ConvTranspose1d</source>
          <target state="translated">ConvTranspose1d</target>
        </trans-unit>
        <trans-unit id="fc42d54df990ea8e2fd96576309fbe506686556e" translate="yes" xml:space="preserve">
          <source>ConvTranspose2d</source>
          <target state="translated">ConvTranspose2d</target>
        </trans-unit>
        <trans-unit id="aa70f25fef0f0928f03585abe233d18e1b7a43bf" translate="yes" xml:space="preserve">
          <source>ConvTranspose3d</source>
          <target state="translated">ConvTranspose3d</target>
        </trans-unit>
        <trans-unit id="bf6b6d744534af31ad6085d41b063c70edf02466" translate="yes" xml:space="preserve">
          <source>Convenience method that creates a &lt;code&gt;setuptools.Extension&lt;/code&gt; with the bare minimum (but often sufficient) arguments to build a C++ extension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e35177ef47547c230ba4dcc90eda6d927bb9e5a" translate="yes" xml:space="preserve">
          <source>Convenience method that creates a &lt;code&gt;setuptools.Extension&lt;/code&gt; with the bare minimum (but often sufficient) arguments to build a CUDA/C++ extension. This includes the CUDA include path, library path and runtime library.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a0770a286742ba2629162d473ed7de8b93bc405" translate="yes" xml:space="preserve">
          <source>Convert one vector to the parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be41e2cca6d10c1b2760ba9429806df5479848bc" translate="yes" xml:space="preserve">
          <source>Convert parameters to one vector</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01733ec2af89cb05f3440f813cca55cd11cb2b18" translate="yes" xml:space="preserve">
          <source>Convert the data into a &lt;code&gt;torch.Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6906a54aac4ab7e793a9985a2b6c90ca5f574d9a" translate="yes" xml:space="preserve">
          <source>Convert the data into a &lt;code&gt;torch.Tensor&lt;/code&gt;. If the data is already a &lt;code&gt;Tensor&lt;/code&gt; with the same &lt;code&gt;dtype&lt;/code&gt; and &lt;code&gt;device&lt;/code&gt;, no copy will be performed, otherwise a new &lt;code&gt;Tensor&lt;/code&gt; will be returned with computational graph retained if data &lt;code&gt;Tensor&lt;/code&gt; has &lt;code&gt;requires_grad=True&lt;/code&gt;. Similarly, if the data is an &lt;code&gt;ndarray&lt;/code&gt; of the corresponding &lt;code&gt;dtype&lt;/code&gt; and the &lt;code&gt;device&lt;/code&gt; is the cpu, no copy will be performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="294b48683ec8d036ef223113fe45f4c4409c00f1" translate="yes" xml:space="preserve">
          <source>Converts a float model to dynamic (i.e. weights-only) quantized model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5490b3bea11fc41ac534c3f667531da495228f6a" translate="yes" xml:space="preserve">
          <source>Converts a float tensor to a per-channel quantized tensor with given scales and zero points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8473a264e544b1bee1239b9dbf9ad1a93b701b5" translate="yes" xml:space="preserve">
          <source>Converts a float tensor to a quantized tensor with given scale and zero point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e8ec30d2295e5cc0c009208c53acb2a3f05bb56" translate="yes" xml:space="preserve">
          <source>Converts submodules in input module to a different module according to &lt;code&gt;mapping&lt;/code&gt; by calling &lt;code&gt;from_float&lt;/code&gt; method on the target module class. And remove qconfig at the end if remove_qconfig is set to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7757dbf24e068e638ad997ae9c4d2e07adceb8c8" translate="yes" xml:space="preserve">
          <source>Convolution Layers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be084db8daa3740ea18a2c2e59749d4c0010cf94" translate="yes" xml:space="preserve">
          <source>Convolution functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="989f24495d4e5092a0b9ea78596dc97ffbe13f9f" translate="yes" xml:space="preserve">
          <source>Conv{1,2,3}D</source>
          <target state="translated">Conv{1,2,3}D</target>
        </trans-unit>
        <trans-unit id="1737f5913c8956ac817ace6ab2658a389afc44d8" translate="yes" xml:space="preserve">
          <source>Copies elements from &lt;code&gt;source&lt;/code&gt; into &lt;code&gt;self&lt;/code&gt; tensor at positions where the &lt;code&gt;mask&lt;/code&gt; is True. The shape of &lt;code&gt;mask&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with the shape of the underlying tensor. The &lt;code&gt;source&lt;/code&gt; should have at least as many elements as the number of ones in &lt;code&gt;mask&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ffea1905ca53aaa0c2e1dd04c44cfd1d1d610e9" translate="yes" xml:space="preserve">
          <source>Copies parameters and buffers from &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; into this module and its descendants. If &lt;code&gt;strict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the keys of &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; must exactly match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b20573e90f9dd7fefb1d1ba5fccbebf327c4350e" translate="yes" xml:space="preserve">
          <source>Copies parameters and buffers from &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; into this module and its descendants. If &lt;code&gt;strict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the keys of &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; must exactly match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aa7f8afed131bd721ebda279fdf8b30aaa83be9" translate="yes" xml:space="preserve">
          <source>Copies parameters and buffers from &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; into this module and its descendants. If &lt;code&gt;strict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the keys of &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; must exactly match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fbe05d7c19e34a099d5b27aecd7e50cc995055f" translate="yes" xml:space="preserve">
          <source>Copies parameters and buffers from &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; into this module and its descendants. If &lt;code&gt;strict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the keys of &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; must exactly match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c58511363c704a11c0530ab36e516cead0a26399" translate="yes" xml:space="preserve">
          <source>Copies the elements from &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; into the positions specified by indices. For the purpose of indexing, the &lt;code&gt;self&lt;/code&gt; tensor is treated as if it were a 1-D tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31514897cedc5e7c028b472351d6c9c6b226eacf" translate="yes" xml:space="preserve">
          <source>Copies the elements from &lt;code&gt;src&lt;/code&gt; into &lt;code&gt;self&lt;/code&gt; tensor and returns &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b302a58928c86985fd5405fb9b12e6f3b385a56d" translate="yes" xml:space="preserve">
          <source>Copies the elements of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; into the &lt;code&gt;self&lt;/code&gt; tensor by selecting the indices in the order given in &lt;code&gt;index&lt;/code&gt;. For example, if &lt;code&gt;dim == 0&lt;/code&gt; and &lt;code&gt;index[i] == j&lt;/code&gt;, then the &lt;code&gt;i&lt;/code&gt;th row of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; is copied to the &lt;code&gt;j&lt;/code&gt;th row of &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b91c805903c6cb0b3510a18d72ca193bc741d244" translate="yes" xml:space="preserve">
          <source>Copies the storage to pinned memory, if it&amp;rsquo;s not already pinned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="278e4ebde33e7e777180bcca75800abdc23470b8" translate="yes" xml:space="preserve">
          <source>Copies the tensor to pinned memory, if it&amp;rsquo;s not already pinned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="361dead9429b7e599e4930ab20d7e7621cc46eae" translate="yes" xml:space="preserve">
          <source>Core statistics:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbf794aba20b276c8548169896a15590fe109e14" translate="yes" xml:space="preserve">
          <source>CosineEmbeddingLoss</source>
          <target state="translated">CosineEmbeddingLoss</target>
        </trans-unit>
        <trans-unit id="38519b5b3e654f4e1b794c35fd7670bb326f9738" translate="yes" xml:space="preserve">
          <source>CosineSimilarity</source>
          <target state="translated">CosineSimilarity</target>
        </trans-unit>
        <trans-unit id="09bf9d0f08c3cee1a60852d335fb4cf2f77d1281" translate="yes" xml:space="preserve">
          <source>Count the frequency of each value in an array of non-negative ints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa674450dd813dec8a084d834fc97c369ca9a763" translate="yes" xml:space="preserve">
          <source>Counts the number of non-zero values in the tensor &lt;code&gt;input&lt;/code&gt; along the given &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0da99e01ab08d505f8e3aacba31f722f60ab5af" translate="yes" xml:space="preserve">
          <source>Counts the number of non-zero values in the tensor &lt;code&gt;input&lt;/code&gt; along the given &lt;code&gt;dim&lt;/code&gt;. If no dim is specified then all non-zeros in the tensor are counted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bd108ea71b4b5faec418d13c1eaaf112af7d5fc" translate="yes" xml:space="preserve">
          <source>Create a block diagonal matrix from provided tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c794a7007c1ced08b83ca3f0fb4e8db7a3266ce0" translate="yes" xml:space="preserve">
          <source>Create a dynamic quantized module from a float module or qparams_dict</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="661a797fdd966423deb47c56a841ce6d565626a3" translate="yes" xml:space="preserve">
          <source>Create a helper proxy to easily launch a &lt;code&gt;remote&lt;/code&gt; using the owner of the RRef as the destination to run functions on the object referenced by this RRef. More specifically, &lt;code&gt;rref.remote().func_name(*args, **kwargs)&lt;/code&gt; is the same as the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b873bdb21fd500fbd503a0fa2ae31f161f0a0486" translate="yes" xml:space="preserve">
          <source>Create a helper proxy to easily launch an &lt;code&gt;rpc_async&lt;/code&gt; using the owner of the RRef as the destination to run functions on the object referenced by this RRef. More specifically, &lt;code&gt;rref.rpc_async().func_name(*args, **kwargs)&lt;/code&gt; is the same as the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b2c6a8315871636ff748acb6e7ca0ce33cac24a" translate="yes" xml:space="preserve">
          <source>Create a helper proxy to easily launch an &lt;code&gt;rpc_sync&lt;/code&gt; using the owner of the RRef as the destination to run functions on the object referenced by this RRef. More specifically, &lt;code&gt;rref.rpc_sync().func_name(*args, **kwargs)&lt;/code&gt; is the same as the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c6bb577e26b7162d7d6c68e8046a3fec50e1ed2" translate="yes" xml:space="preserve">
          <source>Create a qat module from a float module or qparams_dict</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="608ebd71f80f5c1a22f515709f259847e91c3798" translate="yes" xml:space="preserve">
          <source>Create a quantized module from a float module or qparams_dict</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25224bf405304e1ab57eac3f4ba2017fad81ac0a" translate="yes" xml:space="preserve">
          <source>Create a symbolic function named &lt;code&gt;symbolic&lt;/code&gt; in the corresponding Function class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05e63a314a968dccb93df86ac820277d35c3b513" translate="yes" xml:space="preserve">
          <source>Create a view of an existing &lt;code&gt;torch.Tensor&lt;/code&gt;&lt;code&gt;input&lt;/code&gt; with specified &lt;code&gt;size&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt; and &lt;code&gt;storage_offset&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b77a1bd9ce30851f58a1b21fe4ac8853dde6d2a8" translate="yes" xml:space="preserve">
          <source>Create special chart by collecting charts tags in &amp;lsquo;scalars&amp;rsquo;. Note that this function can only be called once for each SummaryWriter() object. Because it only provides metadata to tensorboard, the function can be called before or after the training loop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad7ae06b82cbf41685a6d0a8499d7c2be99cffa5" translate="yes" xml:space="preserve">
          <source>Create the histogram of the incoming inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4594b741f646db69f78e37c46423c0ff117e55e" translate="yes" xml:space="preserve">
          <source>Creates Embedding instance from given 2-dimensional FloatTensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6e25ee28f09c0ec7810655de85d0843eaddac29" translate="yes" xml:space="preserve">
          <source>Creates EmbeddingBag instance from given 2-dimensional FloatTensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ab70bdf8d978808ae2341155ab591efacf83cbe" translate="yes" xml:space="preserve">
          <source>Creates a &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;&lt;code&gt;Tensor&lt;/code&gt;&lt;/a&gt; from a &lt;a href=&quot;https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray&quot;&gt;&lt;code&gt;numpy.ndarray&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="380a5b530b50dcf602f5ae20b20833a1876b83b8" translate="yes" xml:space="preserve">
          <source>Creates a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;Tensor&lt;/code&gt;&lt;/a&gt; from a &lt;a href=&quot;https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray&quot;&gt;&lt;code&gt;numpy.ndarray&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ff7109193ed0423f307bf24dbf6b88c15e440c1" translate="yes" xml:space="preserve">
          <source>Creates a &lt;code&gt;SummaryWriter&lt;/code&gt; that will write out events and summaries to the event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba6567ea492c95adff11560e78e65d6f2fa6dfe4" translate="yes" xml:space="preserve">
          <source>Creates a &lt;code&gt;setuptools.Extension&lt;/code&gt; for C++.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b766aaed745dd6ce4f2529c6188fca66de086dd4" translate="yes" xml:space="preserve">
          <source>Creates a &lt;code&gt;setuptools.Extension&lt;/code&gt; for CUDA/C++.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3354489ddc8254e60320b0bc37db8d7b82c9d9c" translate="yes" xml:space="preserve">
          <source>Creates a Bernoulli distribution parameterized by &lt;a href=&quot;#torch.distributions.bernoulli.Bernoulli.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.bernoulli.Bernoulli.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt; (but not both).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58f0d733886ad515c8d42aceb08240a1f3daf7d2" translate="yes" xml:space="preserve">
          <source>Creates a Binomial distribution parameterized by &lt;code&gt;total_count&lt;/code&gt; and either &lt;a href=&quot;#torch.distributions.binomial.Binomial.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.binomial.Binomial.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt; (but not both). &lt;code&gt;total_count&lt;/code&gt; must be broadcastable with &lt;a href=&quot;#torch.distributions.binomial.Binomial.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;#torch.distributions.binomial.Binomial.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="719b609f965a9077ede6ab6190b76d01527929f0" translate="yes" xml:space="preserve">
          <source>Creates a Chi2 distribution parameterized by shape parameter &lt;a href=&quot;#torch.distributions.chi2.Chi2.df&quot;&gt;&lt;code&gt;df&lt;/code&gt;&lt;/a&gt;. This is exactly equivalent to &lt;code&gt;Gamma(alpha=0.5*df, beta=0.5)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1aa6f05fdf77d536ae15b48713329d9043bf42ff" translate="yes" xml:space="preserve">
          <source>Creates a Dirichlet distribution parameterized by concentration &lt;code&gt;concentration&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d283176d9c3cbc5838d89065f1a04eb5cd11ce7" translate="yes" xml:space="preserve">
          <source>Creates a Exponential distribution parameterized by &lt;code&gt;rate&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99602cffe1f166e20c0a8e58347d9e329ce816ad" translate="yes" xml:space="preserve">
          <source>Creates a Fisher-Snedecor distribution parameterized by &lt;code&gt;df1&lt;/code&gt; and &lt;code&gt;df2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d042259ebf83e1f39612d0d46ecb014811b94bfd" translate="yes" xml:space="preserve">
          <source>Creates a Gamma distribution parameterized by shape &lt;code&gt;concentration&lt;/code&gt; and &lt;code&gt;rate&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fcc365d0f990b9958aa880a339a219e17e17273" translate="yes" xml:space="preserve">
          <source>Creates a Geometric distribution parameterized by &lt;a href=&quot;#torch.distributions.geometric.Geometric.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt;, where &lt;a href=&quot;#torch.distributions.geometric.Geometric.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; is the probability of success of Bernoulli trials. It represents the probability that in</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f986bba11240572671f561e08bcb8f571d37c585" translate="yes" xml:space="preserve">
          <source>Creates a Laplace distribution parameterized by &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4adb5e5fdc76653b710744984dd086c968ee39fd" translate="yes" xml:space="preserve">
          <source>Creates a LogitRelaxedBernoulli distribution parameterized by &lt;a href=&quot;#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt; (but not both), which is the logit of a RelaxedBernoulli distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15a0c995e1894ed35a375aec8d89951825601652" translate="yes" xml:space="preserve">
          <source>Creates a Multinomial distribution parameterized by &lt;code&gt;total_count&lt;/code&gt; and either &lt;a href=&quot;#torch.distributions.multinomial.Multinomial.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.multinomial.Multinomial.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt; (but not both). The innermost dimension of &lt;a href=&quot;#torch.distributions.multinomial.Multinomial.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; indexes over categories. All other dimensions index over batches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3924f533e522b7cb260639c31a007a0e461a496" translate="yes" xml:space="preserve">
          <source>Creates a Negative Binomial distribution, i.e. distribution of the number of successful independent and identical Bernoulli trials before &lt;code&gt;total_count&lt;/code&gt; failures are achieved. The probability of success of each Bernoulli trial is &lt;a href=&quot;#torch.distributions.negative_binomial.NegativeBinomial.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="500755127f28d6a568f776f9aef009f0a35b4dde" translate="yes" xml:space="preserve">
          <source>Creates a Poisson distribution parameterized by &lt;code&gt;rate&lt;/code&gt;, the rate parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a83a7cc2ac442a11cbf1dc1e134a50d3c260f42e" translate="yes" xml:space="preserve">
          <source>Creates a RelaxedBernoulli distribution, parametrized by &lt;a href=&quot;#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature&quot;&gt;&lt;code&gt;temperature&lt;/code&gt;&lt;/a&gt;, and either &lt;a href=&quot;#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt; (but not both). This is a relaxed version of the &lt;code&gt;Bernoulli&lt;/code&gt; distribution, so the values are in (0, 1), and has reparametrizable samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1a742732148726c845a736e718e0b42ae326d5a" translate="yes" xml:space="preserve">
          <source>Creates a RelaxedOneHotCategorical distribution parametrized by &lt;a href=&quot;#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature&quot;&gt;&lt;code&gt;temperature&lt;/code&gt;&lt;/a&gt;, and either &lt;a href=&quot;#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt;. This is a relaxed version of the &lt;code&gt;OneHotCategorical&lt;/code&gt; distribution, so its samples are on simplex, and are reparametrizable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c20c969a8d2e6e99e36b8641b0c9149ce07f5be" translate="yes" xml:space="preserve">
          <source>Creates a Student&amp;rsquo;s t-distribution parameterized by degree of freedom &lt;code&gt;df&lt;/code&gt;, mean &lt;code&gt;loc&lt;/code&gt; and scale &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="956c67cb0f1c70fdb976dabf9f583b2950425b18" translate="yes" xml:space="preserve">
          <source>Creates a categorical distribution parameterized by either &lt;a href=&quot;#torch.distributions.categorical.Categorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.categorical.Categorical.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt; (but not both).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20a8f67a767e2c70110f0eacd788bdca79dafc4f" translate="yes" xml:space="preserve">
          <source>Creates a continuous Bernoulli distribution parameterized by &lt;a href=&quot;#torch.distributions.continuous_bernoulli.ContinuousBernoulli.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.continuous_bernoulli.ContinuousBernoulli.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt; (but not both).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ccb6b54dc9399c2c85ab56d56ee522676eba886" translate="yes" xml:space="preserve">
          <source>Creates a criterion that measures the Binary Cross Entropy between the target and the output:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d34756a1f2c85c7f54f427b38b59a7f138b4091" translate="yes" xml:space="preserve">
          <source>Creates a criterion that measures the loss given input tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b30adb8efde8fc483debf3f678fe0a50c0f3a700" translate="yes" xml:space="preserve">
          <source>Creates a criterion that measures the loss given inputs</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db68393122ce4917cd40e5341fb476ef56ce47be" translate="yes" xml:space="preserve">
          <source>Creates a criterion that measures the mean absolute error (MAE) between each element in the input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc0bceb74569c8f166528464397135db651de1e9" translate="yes" xml:space="preserve">
          <source>Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c567813437a56bca1c0ee05ac4bbbc7a9a0f0b86" translate="yes" xml:space="preserve">
          <source>Creates a criterion that measures the triplet loss given an input tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54c0c219984f4a50b8cfc1212d879c396ddab80a" translate="yes" xml:space="preserve">
          <source>Creates a criterion that measures the triplet loss given input tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ab7e1fd5db78a2e9eadeb7c1fe0ccb243aebcd4" translate="yes" xml:space="preserve">
          <source>Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f6e83829c9a9db048daa12ae2ef6905382cf541" translate="yes" xml:space="preserve">
          <source>Creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74a30cc1dfda2e2ca6b72fcb42e123c4afa11917" translate="yes" xml:space="preserve">
          <source>Creates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38862788d574ffd77ba587c5570ecdb676e04e5f" translate="yes" xml:space="preserve">
          <source>Creates a criterion that optimizes a two-class classification logistic loss between input tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4196579876a20368dab571bd9df29f488cfb987" translate="yes" xml:space="preserve">
          <source>Creates a criterion that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="416d9c5bdd3061ae8e8917cecda26e9fe1f6412a" translate="yes" xml:space="preserve">
          <source>Creates a criterion that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise. It is less sensitive to outliers than the &lt;code&gt;MSELoss&lt;/code&gt; and in some cases prevents exploding gradients (e.g. see &lt;code&gt;Fast R-CNN&lt;/code&gt; paper by Ross Girshick). Also known as the Huber loss:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f5f49121121fa1e6abb3edd3d6d453965003b41" translate="yes" xml:space="preserve">
          <source>Creates a half-Cauchy distribution parameterized by &lt;code&gt;scale&lt;/code&gt; where:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4deb8f0f5867e5b62231478b068c257636c7c149" translate="yes" xml:space="preserve">
          <source>Creates a half-normal distribution parameterized by &lt;code&gt;scale&lt;/code&gt; where:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7674fe00de59675dc7589881d3e4f40957fcf6b1" translate="yes" xml:space="preserve">
          <source>Creates a log-normal distribution parameterized by &lt;a href=&quot;#torch.distributions.log_normal.LogNormal.loc&quot;&gt;&lt;code&gt;loc&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributions.log_normal.LogNormal.scale&quot;&gt;&lt;code&gt;scale&lt;/code&gt;&lt;/a&gt; where:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abf49ecc79a512b11706abef3bf65667a788d341" translate="yes" xml:space="preserve">
          <source>Creates a multivariate normal (also called Gaussian) distribution parameterized by a mean vector and a covariance matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e6e658a2c1f4f9bb64225bec1cd132cf3dc92f9" translate="yes" xml:space="preserve">
          <source>Creates a multivariate normal distribution with covariance matrix having a low-rank form parameterized by &lt;code&gt;cov_factor&lt;/code&gt; and &lt;code&gt;cov_diag&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ebf98c1eaeed448f01f072825db935178bbb990" translate="yes" xml:space="preserve">
          <source>Creates a new distributed group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb830598128131448f4401b8c4fa79f95497434a" translate="yes" xml:space="preserve">
          <source>Creates a normal (also called Gaussian) distribution parameterized by &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="073fb44c832f84ccfa42ff94accd75b4dd72e7da" translate="yes" xml:space="preserve">
          <source>Creates a one-dimensional tensor of size &lt;code&gt;steps&lt;/code&gt; whose values are evenly spaced from</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="350152525d5dacc5decf599c92018f7fa5823d28" translate="yes" xml:space="preserve">
          <source>Creates a one-dimensional tensor of size &lt;code&gt;steps&lt;/code&gt; whose values are evenly spaced from &lt;code&gt;start&lt;/code&gt; to &lt;code&gt;end&lt;/code&gt;, inclusive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f41c69b98f8c4bce082aab055bcac8455947a3e" translate="yes" xml:space="preserve">
          <source>Creates a one-dimensional tensor of size &lt;code&gt;steps&lt;/code&gt; whose values are evenly spaced from &lt;code&gt;start&lt;/code&gt; to &lt;code&gt;end&lt;/code&gt;, inclusive. That is, the value are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c05b957d45d9e4908a05a11e87943ceb8347e92e" translate="yes" xml:space="preserve">
          <source>Creates a one-hot categorical distribution parameterized by &lt;a href=&quot;#torch.distributions.one_hot_categorical.OneHotCategorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributions.one_hot_categorical.OneHotCategorical.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9962e59b2ab133d8c3b2267ae38553f28f8a79bd" translate="yes" xml:space="preserve">
          <source>Creates a quantized module from a float module or qparams_dict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2147eb4da2cad834986bf746aeef9a006067d0f" translate="yes" xml:space="preserve">
          <source>Creates a tensor of size &lt;code&gt;size&lt;/code&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed2b3c6c1dcd8ed54d69945a6e4acc25f855c267" translate="yes" xml:space="preserve">
          <source>Creates a tensor of size &lt;code&gt;size&lt;/code&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;. The tensor&amp;rsquo;s dtype is inferred from &lt;code&gt;fill_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f064b3e975b58c920e1056343b0cd452f5ecab" translate="yes" xml:space="preserve">
          <source>Creates a tensor whose diagonals of certain 2D planes (specified by &lt;code&gt;dim1&lt;/code&gt; and &lt;code&gt;dim2&lt;/code&gt;) are filled by &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4e06d7745c58e373370f1d2833461757426df92" translate="yes" xml:space="preserve">
          <source>Creates a tensor whose diagonals of certain 2D planes (specified by &lt;code&gt;dim1&lt;/code&gt; and &lt;code&gt;dim2&lt;/code&gt;) are filled by &lt;code&gt;input&lt;/code&gt;. To facilitate creating batched diagonal matrices, the 2D planes formed by the last two dimensions of the returned tensor are chosen by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54d06cd8eb770a4665e06b480e41c18b35882c33" translate="yes" xml:space="preserve">
          <source>Creates an asynchronous task executing &lt;code&gt;func&lt;/code&gt; and a reference to the value of the result of this execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a528098d6266957ce08cc5436471c4e687e167c2" translate="yes" xml:space="preserve">
          <source>Creates an asynchronous task executing &lt;code&gt;func&lt;/code&gt; and a reference to the value of the result of this execution. &lt;code&gt;fork&lt;/code&gt; will return immediately, so the return value of &lt;code&gt;func&lt;/code&gt; may not have been computed yet. To force completion of the task and access the return value invoke &lt;code&gt;torch.jit.wait&lt;/code&gt; on the Future. &lt;code&gt;fork&lt;/code&gt; invoked with a &lt;code&gt;func&lt;/code&gt; which returns &lt;code&gt;T&lt;/code&gt; is typed as &lt;code&gt;torch.jit.Future[T]&lt;/code&gt;. &lt;code&gt;fork&lt;/code&gt; calls can be arbitrarily nested, and may be invoked with positional and keyword arguments. Asynchronous execution will only occur when run in TorchScript. If run in pure python, &lt;code&gt;fork&lt;/code&gt; will not execute in parallel. &lt;code&gt;fork&lt;/code&gt; will also not execute in parallel when invoked while tracing, however the &lt;code&gt;fork&lt;/code&gt; and &lt;code&gt;wait&lt;/code&gt; calls will be captured in the exported IR Graph. .. warning:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c73fcf2c3b7a88652c30df05d4a49be7a9a3a82" translate="yes" xml:space="preserve">
          <source>Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bf69af350942e6f19285c4071e0d9bc1d0390fb" translate="yes" xml:space="preserve">
          <source>Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers. Used as a keyword argument in many &lt;a href=&quot;../torch#inplace-random-sampling&quot;&gt;In-place random sampling&lt;/a&gt; functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db27514dc4a87b77455deb1f68ac2812f51084a" translate="yes" xml:space="preserve">
          <source>Creating TorchScript Code</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14dc9f6dca53e0df6aaf4e5eb53a7efa6593aab3" translate="yes" xml:space="preserve">
          <source>Creating named tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="733cbb78a0d286a0935c6c571466400a11828907" translate="yes" xml:space="preserve">
          <source>Creation Ops</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d66fef2dd7f330ad8c7b2de8229080af12ec8719" translate="yes" xml:space="preserve">
          <source>Creation of this class requires that &lt;code&gt;torch.distributed&lt;/code&gt; to be already initialized, by calling &lt;a href=&quot;../distributed#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="711f625ceb8a65f44028c4e7b7e4e818fc7445a7" translate="yes" xml:space="preserve">
          <source>CrossEntropyLoss</source>
          <target state="translated">CrossEntropyLoss</target>
        </trans-unit>
        <trans-unit id="5eec0b5e11526f784758a0afbe48baade8e71e9e" translate="yes" xml:space="preserve">
          <source>Current implementation of &lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; introduces memory overhead, thus it might lead to unexpectedly high memory usage in the applications with many tiny tensors. If this is your case, consider using one large structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96c1a2df528a935c7c808490ba7a2921d055775f" translate="yes" xml:space="preserve">
          <source>Current implementation packs weights on every call, which has penalty on performance. If you want to avoid the overhead, use &lt;a href=&quot;#torch.nn.quantized.Linear&quot;&gt;&lt;code&gt;Linear&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="392192a4ae05351b1f7b21e538ff3e8ca534e67d" translate="yes" xml:space="preserve">
          <source>Currently &lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt;&lt;code&gt;SyncBatchNorm&lt;/code&gt;&lt;/a&gt; only supports &lt;code&gt;DistributedDataParallel&lt;/code&gt; (DDP) with single GPU per process. Use &lt;a href=&quot;#torch.nn.SyncBatchNorm.convert_sync_batchnorm&quot;&gt;&lt;code&gt;torch.nn.SyncBatchNorm.convert_sync_batchnorm()&lt;/code&gt;&lt;/a&gt; to convert &lt;code&gt;BatchNorm*D&lt;/code&gt; layer to &lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt;&lt;code&gt;SyncBatchNorm&lt;/code&gt;&lt;/a&gt; before wrapping Network with DDP.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a78ac4f002658abaaa21040baac2a600bf544edc" translate="yes" xml:space="preserve">
          <source>Currently in the CUDA implementation and the CPU implementation when dim is specified, &lt;code&gt;torch.unique&lt;/code&gt; always sort the tensor at the beginning regardless of the &lt;code&gt;sort&lt;/code&gt; argument. Sorting could be slow, so if your input tensor is already sorted, it is recommended to use &lt;a href=&quot;torch.unique_consecutive#torch.unique_consecutive&quot;&gt;&lt;code&gt;torch.unique_consecutive()&lt;/code&gt;&lt;/a&gt; which avoids the sorting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8a61a0d816f8b21bf7f4b46f888c832b03676e2" translate="yes" xml:space="preserve">
          <source>Currently spatial and volumetric upsampling are supported (i.e. expected inputs are 4 or 5 dimensional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a9d7a3e06793c263711ce33ba0ffdc49d409027" translate="yes" xml:space="preserve">
          <source>Currently supported operations and subsystems</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b05bf74a2646cf7882607d1b6e8f3921b3f2124" translate="yes" xml:space="preserve">
          <source>Currently temporal, spatial and volumetric sampling are supported, i.e. expected inputs are 3-D, 4-D or 5-D in shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af454dd72bdbaa9839806374d040bd77db038329" translate="yes" xml:space="preserve">
          <source>Currently temporal, spatial and volumetric upsampling are supported, i.e. expected inputs are 3-D, 4-D or 5-D in shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d49c5e3f020c5093dc8a1df7be3b5947455c7de6" translate="yes" xml:space="preserve">
          <source>Currently three initialization methods are supported:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecab6b4c3bf958fdadbd30836155137da6ef98e2" translate="yes" xml:space="preserve">
          <source>Currently valid scalar and tensor combination are 1. Scalar of floating dtype and torch.double 2. Scalar of integral dtype and torch.long 3. Scalar of complex dtype and torch.complex128</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cf55afa31790d6a153e9124662c9ad715c264be" translate="yes" xml:space="preserve">
          <source>Currently, only 3-D output tensors (unfolded batched image-like tensors) are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf7422cb9205f4ada47421ece107faeeaf3ef476" translate="yes" xml:space="preserve">
          <source>Currently, only 4-D input tensors (batched image-like tensors) are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="804337292e10b528ce9da39728466ea21dd2d93d" translate="yes" xml:space="preserve">
          <source>Currently, only 4-D output tensors (batched image-like tensors) are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55e4dc48ed51c13b29c9e279e5505c0a895f1cb1" translate="yes" xml:space="preserve">
          <source>Currently, only spatial (4-D) and volumetric (5-D) &lt;code&gt;input&lt;/code&gt; are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16e0def02ff49d292a9c6c0ee9ab56bbab51c7e1" translate="yes" xml:space="preserve">
          <source>Custom averaging strategies</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b674ceb20a7250912a1c130e2165e5889d62f4ab" translate="yes" xml:space="preserve">
          <source>Custom operators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3461dd173d30fce828765c425b88ef7516427e68" translate="yes" xml:space="preserve">
          <source>CustomFromMask</source>
          <target state="translated">CustomFromMask</target>
        </trans-unit>
        <trans-unit id="e93172f8decb4286fa3d5ed1a6b28a8e5bb1dd99" translate="yes" xml:space="preserve">
          <source>Cyclical learning rate policy changes the learning rate after every batch. &lt;code&gt;step&lt;/code&gt; should be called after a batch has been used for training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50c9e8d5fc98727b4bbc93cf5d64a68db647f04f" translate="yes" xml:space="preserve">
          <source>D</source>
          <target state="translated">D</target>
        </trans-unit>
        <trans-unit id="eb3635e47f534f46cf856ff7cd245f64d37e6d18" translate="yes" xml:space="preserve">
          <source>DCGAN</source>
          <target state="translated">DCGAN</target>
        </trans-unit>
        <trans-unit id="17ba820b5bcd55a78cfd53d227f66dc3adcb9245" translate="yes" xml:space="preserve">
          <source>D_{out} = (D_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11e96ca0ef0a7d1c0968f6c0aa661473e65963b1" translate="yes" xml:space="preserve">
          <source>D_{out} = (D_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8db0974bd119b8e244f7c9a0fbb5cd60340ca9b" translate="yes" xml:space="preserve">
          <source>D_{out} = D_{in} + \text{padding\_front} + \text{padding\_back}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="343f5280293229b193ab7d6cc2f6fecb4a2a501b" translate="yes" xml:space="preserve">
          <source>D_{out} = \left\lfloor D_{in} \times \text{scale\_factor} \right\rfloor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5daaf33316a5a1e996b64f9e865fa2c06a216412" translate="yes" xml:space="preserve">
          <source>D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a58eeddbe8ce176e982a4bd5546958165921baf4" translate="yes" xml:space="preserve">
          <source>D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58d17582a05d81dbc970a2fb5dde4c86c385cf6c" translate="yes" xml:space="preserve">
          <source>Danger</source>
          <target state="translated">Danger</target>
        </trans-unit>
        <trans-unit id="543cf269e3398d54432632170f9d8a44ec8a82d9" translate="yes" xml:space="preserve">
          <source>Data Loading Order and Sampler</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faa811b7a6757fc89dec83a4445037d0b6d29fe4" translate="yes" xml:space="preserve">
          <source>Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee503fe5765b8d9456bf21def7f9e06d2b12ebb6" translate="yes" xml:space="preserve">
          <source>Data type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e3a2e3c18839bb47fb3084db81d051ea2d9e572" translate="yes" xml:space="preserve">
          <source>DataParallel</source>
          <target state="translated">DataParallel</target>
        </trans-unit>
        <trans-unit id="f41afa14a2956bd6dee2529d81450b9fde84c7bb" translate="yes" xml:space="preserve">
          <source>DataParallel Layers (multi-GPU, distributed)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c2866ebc153b9ba5ee12510871be4ea8e2d66ad" translate="yes" xml:space="preserve">
          <source>DataParallel functions (multi-GPU, distributed)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f795ae6a697849179693a4d0d952f51dfe274a9" translate="yes" xml:space="preserve">
          <source>Dataset Types</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a759fa5cf358fa4e839fa020614e6a71debce953" translate="yes" xml:space="preserve">
          <source>Dataset as a concatenation of multiple datasets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eac6174468e8a6ce464f86a0d629040e97fe409" translate="yes" xml:space="preserve">
          <source>Dataset for chainning multiple &lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt;&lt;code&gt;IterableDataset&lt;/code&gt;&lt;/a&gt; s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63231ef80d6022f27be0ddfb59b1c8c16d68db48" translate="yes" xml:space="preserve">
          <source>Dataset is assumed to be of constant size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6935d46588944d8c25616ca6972db5257d686341" translate="yes" xml:space="preserve">
          <source>Dataset wrapping tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75c05e642a4a82474f0ded1d73a7d77a7cab17de" translate="yes" xml:space="preserve">
          <source>DeQuantize</source>
          <target state="translated">DeQuantize</target>
        </trans-unit>
        <trans-unit id="895b27c88016513d278a0ce3dc0663fae3829d58" translate="yes" xml:space="preserve">
          <source>Debugging</source>
          <target state="translated">Debugging</target>
        </trans-unit>
        <trans-unit id="2d9ba523f6bd6f1366ef31447c6896de739c5ebc" translate="yes" xml:space="preserve">
          <source>Debugging this script with &lt;code&gt;pdb&lt;/code&gt; works except for when we invoke the &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;@torch.jit.script&lt;/code&gt;&lt;/a&gt; function. We can globally disable JIT, so that we can call the &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;@torch.jit.script&lt;/code&gt;&lt;/a&gt; function as a normal Python function and not compile it. If the above script is called &lt;code&gt;disable_jit_example.py&lt;/code&gt;, we can invoke it like so:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20487077b8cc9537e212490b180a9c77a92fedaf" translate="yes" xml:space="preserve">
          <source>Debugging utilities</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdeed230ed1d975e42532ba4eb68e61538b14c37" translate="yes" xml:space="preserve">
          <source>Decays the learning rate of each parameter group by gamma every epoch. When last_epoch=-1, sets initial lr as lr.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68df60584336645f5d49c32e82cf477c01c234ca" translate="yes" xml:space="preserve">
          <source>Decays the learning rate of each parameter group by gamma every step_size epochs. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65627d1ff3ccfff17f931ea2b13d4278cbbe2474" translate="yes" xml:space="preserve">
          <source>Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f7b680b643589b9ed8668bf524f99287df6399c" translate="yes" xml:space="preserve">
          <source>Decodes a DLPack to a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dceee5b011b77632a7ffb29ac384f66f1112b455" translate="yes" xml:space="preserve">
          <source>Decorator to register a pairwise function with &lt;a href=&quot;#torch.distributions.kl.kl_divergence&quot;&gt;&lt;code&gt;kl_divergence()&lt;/code&gt;&lt;/a&gt;. Usage:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbe3208131f8562d117c292d268d2f8db716693e" translate="yes" xml:space="preserve">
          <source>DeepLabV3</source>
          <target state="translated">DeepLabV3</target>
        </trans-unit>
        <trans-unit id="67529023df524563878c2ac2647a317ad8500070" translate="yes" xml:space="preserve">
          <source>DeepLabV3 ResNet101</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="617f04b5a03ab100dd0d3e0e5532b5eb50903269" translate="yes" xml:space="preserve">
          <source>DeepLabV3 ResNet50</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2b8f3a731cc6350b5d6b3c7afddb1acf6006314" translate="yes" xml:space="preserve">
          <source>DeepLabV3 ResNet50, ResNet101</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c8189f5b90e5b1272f55bc887fde7008a4bafdf" translate="yes" xml:space="preserve">
          <source>Default Types</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d116b23402cf7d0664bd12bb48874727780a4ac" translate="yes" xml:space="preserve">
          <source>Default evaluation function takes a torch.utils.data.Dataset or a list of input Tensors and run the model on the dataset</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f410bf7d7a6034879436d17d9eeb5c8f8ee302f3" translate="yes" xml:space="preserve">
          <source>Default gradient layouts</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e51881f10b051af0af29bc3e379261ed831a6098" translate="yes" xml:space="preserve">
          <source>Default is &lt;code&gt;&quot;backward&quot;&lt;/code&gt; (no normalization).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e0fda91e6a2713611da6dc3cb2473efcd25b651" translate="yes" xml:space="preserve">
          <source>Default is &lt;code&gt;&quot;backward&quot;&lt;/code&gt; (normalize by &lt;code&gt;1/n&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e4f64360906e7f1452e75f1085dc507b2bff801" translate="yes" xml:space="preserve">
          <source>Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8bdbcf95f1b2c543f6b5f2c72d836f7c5b5704" translate="yes" xml:space="preserve">
          <source>Defaults to zero if not provided. where</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c57e9446082424cd876b20c90b07486b438b9b9" translate="yes" xml:space="preserve">
          <source>Define the symbolic function in &lt;code&gt;torch/onnx/symbolic_opset&amp;lt;version&amp;gt;.py&lt;/code&gt;, for example &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic_opset9.py&quot;&gt;torch/onnx/symbolic_opset9.py&lt;/a&gt;. Make sure the function has the same name as the ATen operator/function defined in &lt;code&gt;VariableType.h&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cec63288c88c513e15dd89936be8dc37543d14b" translate="yes" xml:space="preserve">
          <source>Defines a formula for differentiating the operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7773324d0fbb19d2b097125eeec23bba37fd9fae" translate="yes" xml:space="preserve">
          <source>Defines the computation performed at every call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fdfda877e82e2aeb2ae17e08e28fcbd6d18a121" translate="yes" xml:space="preserve">
          <source>Deletes the key-value pair associated with &lt;code&gt;key&lt;/code&gt; from the store. Returns &lt;code&gt;true&lt;/code&gt; if the key was successfully deleted, and &lt;code&gt;false&lt;/code&gt; if it was not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa7b4a50c0e0f2cffa01451426972ab2f487a9dd" translate="yes" xml:space="preserve">
          <source>DenseNet</source>
          <target state="translated">DenseNet</target>
        </trans-unit>
        <trans-unit id="8b2ff8d2942b70f38d615ed1e52ba52e2285edab" translate="yes" xml:space="preserve">
          <source>Densenet-121</source>
          <target state="translated">Densenet-121</target>
        </trans-unit>
        <trans-unit id="d26e787bd56b9c7aab1c534a7f7ead9ab4b12d73" translate="yes" xml:space="preserve">
          <source>Densenet-121 model from &lt;a href=&quot;https://arxiv.org/pdf/1608.06993.pdf&quot;&gt;&amp;ldquo;Densely Connected Convolutional Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc79947b23872b66c941b9c7a01bd0904908a8d9" translate="yes" xml:space="preserve">
          <source>Densenet-161</source>
          <target state="translated">Densenet-161</target>
        </trans-unit>
        <trans-unit id="8079b2939275d34b5b7b870ad8e0a1f7fe8edd0d" translate="yes" xml:space="preserve">
          <source>Densenet-161 model from &lt;a href=&quot;https://arxiv.org/pdf/1608.06993.pdf&quot;&gt;&amp;ldquo;Densely Connected Convolutional Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8e6fd5af55a790890421b436f68cbc8406a0b19" translate="yes" xml:space="preserve">
          <source>Densenet-169</source>
          <target state="translated">Densenet-169</target>
        </trans-unit>
        <trans-unit id="7480a230cf176343f7e3077f6904ede5855a19d8" translate="yes" xml:space="preserve">
          <source>Densenet-169 model from &lt;a href=&quot;https://arxiv.org/pdf/1608.06993.pdf&quot;&gt;&amp;ldquo;Densely Connected Convolutional Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc80ee1a1bf823e3bf3be2c3a3194f577392f377" translate="yes" xml:space="preserve">
          <source>Densenet-201</source>
          <target state="translated">Densenet-201</target>
        </trans-unit>
        <trans-unit id="7124ecd6d83a80564dc1ba72e45a576f118ac991" translate="yes" xml:space="preserve">
          <source>Densenet-201 model from &lt;a href=&quot;https://arxiv.org/pdf/1608.06993.pdf&quot;&gt;&amp;ldquo;Densely Connected Convolutional Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a89d9b0077197cdfbba3a66cddb06012c599011" translate="yes" xml:space="preserve">
          <source>Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-correlation&quot;&gt;cross-correlation&lt;/a&gt;, and not a full &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-correlation&quot;&gt;cross-correlation&lt;/a&gt;. It is up to the user to add proper padding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a0685deb3b8e4521a47904d7970aabb4610a92a" translate="yes" xml:space="preserve">
          <source>Depending on the custom operator, you can export it as one or a combination of existing ONNX ops. You can also export it as a custom op in ONNX as well. In that case, you can specify the custom domain and version (custom opset) using the &lt;code&gt;custom_opsets&lt;/code&gt; dictionary at export. If not explicitly specified, the custom opset version is set to 1 by default. Using custom ONNX ops, you will need to extend the backend of your choice with matching custom ops implementation, e.g. &lt;a href=&quot;https://caffe2.ai/docs/custom-operators.html&quot;&gt;Caffe2 custom ops&lt;/a&gt;, &lt;a href=&quot;https://github.com/microsoft/onnxruntime/blob/master/docs/AddingCustomOp.md&quot;&gt;ONNX Runtime custom ops&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ab688461ca113091fd169e55e7c9e66deb886f0" translate="yes" xml:space="preserve">
          <source>Deprecated enum-like class for reduction operations: &lt;code&gt;SUM&lt;/code&gt;, &lt;code&gt;PRODUCT&lt;/code&gt;, &lt;code&gt;MIN&lt;/code&gt;, and &lt;code&gt;MAX&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4995eb29b7f6d3dc7cac42d9f08dad19e95a9dfa" translate="yes" xml:space="preserve">
          <source>Deprecated; see &lt;a href=&quot;#torch.cuda.max_memory_reserved&quot;&gt;&lt;code&gt;max_memory_reserved()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e046da60da747b4d87f8d67259afaf6b9fe07bf5" translate="yes" xml:space="preserve">
          <source>Deprecated; see &lt;a href=&quot;#torch.cuda.memory_reserved&quot;&gt;&lt;code&gt;memory_reserved()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15cdb030ac617cabaf72e8f3099d5d7b07f0d492" translate="yes" xml:space="preserve">
          <source>Dequantize stub module, before calibration, this is same as identity, this will be swapped as &lt;code&gt;nnq.DeQuantize&lt;/code&gt; in &lt;code&gt;convert&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44fd5a225ad67410d4630aa610f55ced5a7a7c71" translate="yes" xml:space="preserve">
          <source>Dequantizes an incoming tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a6b986891e70c721e528fb3141e3feb4bc76505" translate="yes" xml:space="preserve">
          <source>Derived classes should implement one or both of &lt;code&gt;_call()&lt;/code&gt; or &lt;code&gt;_inverse()&lt;/code&gt;. Derived classes that set &lt;code&gt;bijective=True&lt;/code&gt; should also implement &lt;a href=&quot;#torch.distributions.transforms.Transform.log_abs_det_jacobian&quot;&gt;&lt;code&gt;log_abs_det_jacobian()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="516c22b47b1fe91311a530710a5d3d144b2ada06" translate="yes" xml:space="preserve">
          <source>Describe an instantaneous event that occurred at some point.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e0a2537499a2a7aaa95e9b6ce35838ddd92db58" translate="yes" xml:space="preserve">
          <source>Describes how to dynamically quantize a layer or a part of the network by providing settings (observer classes) for weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd0e609a210b25ce30494d69de9681e62976242f" translate="yes" xml:space="preserve">
          <source>Describes how to quantize a layer or a part of the network by providing settings (observer classes) for activations and weights respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55f8ebc805e65b5b71ddafdae390e3be2bcd69af" translate="yes" xml:space="preserve">
          <source>Description</source>
          <target state="translated">Description</target>
        </trans-unit>
        <trans-unit id="5966dbc5c4d197355b50f3dc66783c2fa78a5226" translate="yes" xml:space="preserve">
          <source>Design Notes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe406308e1df41bfda74c701d4a66a5af72c8b6" translate="yes" xml:space="preserve">
          <source>Design Reasoning</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91441a05e70cda570458aad59617766bb3ed7236" translate="yes" xml:space="preserve">
          <source>Detaches the Tensor from the graph that created it, making it a leaf. Views cannot be detached in-place.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e01337242e0297823f889a52bc9dad47f00c9ad" translate="yes" xml:space="preserve">
          <source>Determines if a type conversion is allowed under PyTorch casting rules described in the type promotion &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2244fb2618c9d05384c145a55a7a5a37bf99078" translate="yes" xml:space="preserve">
          <source>Determines if a type conversion is allowed under PyTorch casting rules described in the type promotion &lt;a href=&quot;tensor_attributes#type-promotion-doc&quot;&gt;documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5a74a6df09278b88cb6ea23b7d7f2570c33babf" translate="yes" xml:space="preserve">
          <source>Device</source>
          <target state="translated">Device</target>
        </trans-unit>
        <trans-unit id="1c1f67e2f072a5af5bf17679821b62f151e69437" translate="yes" xml:space="preserve">
          <source>Dict Construction</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4461566599c5b88c3897f351e4ae4b0ddc655116" translate="yes" xml:space="preserve">
          <source>Different from the standard SVD, the size of returned matrices depend on the specified rank and q values as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abe2291b9a77a8ae7585fd7e4b1df0a06016b998" translate="yes" xml:space="preserve">
          <source>Dimension names may contain characters or underscore. Furthermore, a dimension name must be a valid Python variable name (i.e., does not start with underscore).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6f1bd13e9cbff9087ce39dcba569ea9ce48c700" translate="yes" xml:space="preserve">
          <source>Dirichlet</source>
          <target state="translated">Dirichlet</target>
        </trans-unit>
        <trans-unit id="e1cf09d41f0116a87479fbe7f5ef39aeac24297b" translate="yes" xml:space="preserve">
          <source>Disable JIT for Debugging</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35a71645b1a4bfec2d328e91748bd5d190545dea" translate="yes" xml:space="preserve">
          <source>Disable automatic batching</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dae5511126cad0d55eede647161bef3c8ecf5358" translate="yes" xml:space="preserve">
          <source>Disables denormal floating numbers on CPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c513ea041a153d26658bb6cf95f8c77cf39ac2f0" translate="yes" xml:space="preserve">
          <source>Disabling gradient calculation is useful for inference, when you are sure that you will not call &lt;a href=&quot;../autograd#torch.Tensor.backward&quot;&gt;&lt;code&gt;Tensor.backward()&lt;/code&gt;&lt;/a&gt;. It will reduce memory consumption for computations that would otherwise have &lt;code&gt;requires_grad=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2f39154ff5c9f1589f29bf3daf21678e81210ff" translate="yes" xml:space="preserve">
          <source>Disabling gradient calculation is useful for inference, when you are sure that you will not call &lt;code&gt;Tensor.backward()&lt;/code&gt;. It will reduce memory consumption for computations that would otherwise have &lt;code&gt;requires_grad=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9c83b5259f966caf231a71b3ad8e69e880665ed" translate="yes" xml:space="preserve">
          <source>Discrete Fourier transforms and related functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="938004e21f3f3e82099132266fc1891a7f13de20" translate="yes" xml:space="preserve">
          <source>Distance Functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cde45ececcca1e1adb41659d3d28a0420087495" translate="yes" xml:space="preserve">
          <source>Distance functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="303a9c010db654973c68f36cc8c79b5ce73fe308" translate="yes" xml:space="preserve">
          <source>Distributed Autograd Context</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="310713a581eec3788cf900c68063e38885f001bd" translate="yes" xml:space="preserve">
          <source>Distributed Autograd Design</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa35316634dcb2108118798dd9f61f3d3f7fbb66" translate="yes" xml:space="preserve">
          <source>Distributed Autograd Framework</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec9dd95759950a78e8ade825f089a889c2eb7fab" translate="yes" xml:space="preserve">
          <source>Distributed Backward Pass</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aba915801825e438dbb9e75721a94e96b234ba7d" translate="yes" xml:space="preserve">
          <source>Distributed Data Parallel</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef10fda1ae05d95a37d1371a4a918aad1148a2da" translate="yes" xml:space="preserve">
          <source>Distributed Key-Value Store</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34eb6d25d260c57a8faa37ee402539b363513315" translate="yes" xml:space="preserve">
          <source>Distributed Optimizer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75f572c75699c1008b8a3d33982f73a57479f298" translate="yes" xml:space="preserve">
          <source>Distributed Pipeline Parallel</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dfffd4675ffa868d517cf4ad2d7b981131e1dbd" translate="yes" xml:space="preserve">
          <source>Distributed RPC Framework</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3de08dea5da9f0cffd62432ca7da9726c39e218" translate="yes" xml:space="preserve">
          <source>Distributed communication package - torch.distributed</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67b250f513d5c0c4bc692b9447f357fc7ef369ea" translate="yes" xml:space="preserve">
          <source>DistributedDataParallel</source>
          <target state="translated">DistributedDataParallel</target>
        </trans-unit>
        <trans-unit id="ec463333beac30f92377ae176f21cc4eb4b46520" translate="yes" xml:space="preserve">
          <source>DistributedOptimizer takes remote references to parameters scattered across workers and applies the given optimizer locally for each parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d3c457cbe3e35739086346e0a4048653efa42e7" translate="yes" xml:space="preserve">
          <source>Distribution</source>
          <target state="translated">Distribution</target>
        </trans-unit>
        <trans-unit id="c0fd2f6b48b7ad3974231443cb830eddeebb455e" translate="yes" xml:space="preserve">
          <source>Distribution is the abstract base class for probability distributions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56af6c440851565952f28972260908c667af4940" translate="yes" xml:space="preserve">
          <source>Divides (&amp;ldquo;unscales&amp;rdquo;) the optimizer&amp;rsquo;s gradient tensors by the scale factor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4468b3425489b998cab9185522d9f737628cd1d" translate="yes" xml:space="preserve">
          <source>Divides each element of the input &lt;code&gt;input&lt;/code&gt; by the corresponding element of &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33968e4e64500a95f8035e27727c823cadd48d34" translate="yes" xml:space="preserve">
          <source>Do cartesian product of the given sequence of tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="721f0d8eda69e29b574fd64fe0f6c7674a1a6f89" translate="yes" xml:space="preserve">
          <source>Do cartesian product of the given sequence of tensors. The behavior is similar to python&amp;rsquo;s &lt;code&gt;itertools.product&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4d30aee7a62cbfdaa3d84814f5fc6534da714e2" translate="yes" xml:space="preserve">
          <source>Do quantization aware training and output a quantized model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcb94671187d8e10ddb359c9decbb94311e20300" translate="yes" xml:space="preserve">
          <source>Docstring of the function works as a help message. It explains what does the model do and what are the allowed positional/keyword arguments. It&amp;rsquo;s highly recommended to add a few examples here.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96f57a29074dff5e315a68cd23e9cc22e3995e9f" translate="yes" xml:space="preserve">
          <source>Does a linear interpolation of two tensors &lt;code&gt;start&lt;/code&gt; (given by &lt;code&gt;input&lt;/code&gt;) and &lt;code&gt;end&lt;/code&gt; based on a scalar or tensor &lt;code&gt;weight&lt;/code&gt; and returns the resulting &lt;code&gt;out&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8782c3b2687a1a4eba3fb6aace40c73bfe021afc" translate="yes" xml:space="preserve">
          <source>Does nothing if the CUDA state is already initialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="525c9a2be6af3422648e9f02a6746e9df12f182d" translate="yes" xml:space="preserve">
          <source>Don&amp;rsquo;t pass received tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e06ffaf662b8ea46a067dea9fb380262a87db6a2" translate="yes" xml:space="preserve">
          <source>Down/up samples the input to either the given &lt;code&gt;size&lt;/code&gt; or the given &lt;code&gt;scale_factor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e61af53453cf013b5be43bae97307de95bad250e" translate="yes" xml:space="preserve">
          <source>Download object at the given URL to a local path.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="361a0dc66d29b16c754d93724204f2ac9044c37d" translate="yes" xml:space="preserve">
          <source>Draws binary random numbers (0 or 1) from a Bernoulli distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99a0d2b3ff3d729e26380413abca3d7df775cdde" translate="yes" xml:space="preserve">
          <source>Dropout</source>
          <target state="translated">Dropout</target>
        </trans-unit>
        <trans-unit id="132aa5f9595506ef0ca296d6be570b1e4aa7acb2" translate="yes" xml:space="preserve">
          <source>Dropout Layers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15a66e933b5615cb5433ce9102df020458b34bcb" translate="yes" xml:space="preserve">
          <source>Dropout functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfe20a4021b31e2ea913c19efd2987a230ac723c" translate="yes" xml:space="preserve">
          <source>Dropout2d</source>
          <target state="translated">Dropout2d</target>
        </trans-unit>
        <trans-unit id="830971c9b2da3b705ee96a71f9d0d4e5128e9bb7" translate="yes" xml:space="preserve">
          <source>Dropout3d</source>
          <target state="translated">Dropout3d</target>
        </trans-unit>
        <trans-unit id="a7c8e330062301237ad2aac63813f57bd9bb1e14" translate="yes" xml:space="preserve">
          <source>Due to limited dynamic range of half datatype, performing this operation in half precision may cause the first element of result to overflow for certain inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36b5672884c133b8c278456fa603d4322ce8f54a" translate="yes" xml:space="preserve">
          <source>Due to the asynchronous nature of CUDA kernels, when running against CUDA code, the cProfile output and CPU-mode autograd profilers may not show correct timings: the reported CPU time reports the amount of time used to launch the kernels but does not include the time the kernel spent executing on a GPU unless the operation does a synchronize. Ops that do synchronize appear to be extremely expensive under regular CPU-mode profilers. In these case where timings are incorrect, the CUDA-mode autograd profiler may be helpful.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa6e674ff3a01dbf141329517674a02a51f4e055" translate="yes" xml:space="preserve">
          <source>Due to the conjugate symmetry, &lt;code&gt;input&lt;/code&gt; do not need to contain the full complex frequency values. Roughly half of the values will be sufficient, as is the case when &lt;code&gt;input&lt;/code&gt; is given by &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;rfft(signal, onesided=True)&lt;/code&gt;. In such case, set the &lt;code&gt;onesided&lt;/code&gt; argument of this method to &lt;code&gt;True&lt;/code&gt;. Moreover, the original signal shape information can sometimes be lost, optionally set &lt;code&gt;signal_sizes&lt;/code&gt; to be the size of the original signal (without the batch dimensions if in batched mode) to recover it with correct shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f628f956c51a607f601ca3a9c65aebac60f6d34" translate="yes" xml:space="preserve">
          <source>Duplicate modules are returned only once. In the following example, &lt;code&gt;l&lt;/code&gt; will be returned only once.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50fa35c3d84d578bb945e995330eef7c63dcf91c" translate="yes" xml:space="preserve">
          <source>During backward, only gradients at &lt;code&gt;nnz&lt;/code&gt; locations of &lt;code&gt;input&lt;/code&gt; will propagate back. Note that the gradients of &lt;code&gt;input&lt;/code&gt; is coalesced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e08ad58135bf66f71d67cdf9e3eb42be9cdd416" translate="yes" xml:space="preserve">
          <source>During evaluation the module simply computes an identity function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c42cc58336b9bff21da008fbb38ac485f6938f2c" translate="yes" xml:space="preserve">
          <source>During inference, the model requires only the input tensors, and returns the post-processed predictions as a &lt;code&gt;List[Dict[Tensor]]&lt;/code&gt;, one for each input image. The fields of the &lt;code&gt;Dict&lt;/code&gt; are as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d654e950cd9f5e68da4c08caa15327df6055306" translate="yes" xml:space="preserve">
          <source>During the forward pass, each function range is decorated with &lt;code&gt;seq=&amp;lt;N&amp;gt;&lt;/code&gt;. &lt;code&gt;seq&lt;/code&gt; is a running counter, incremented each time a new backward Function object is created and stashed for backward. Thus, the &lt;code&gt;seq=&amp;lt;N&amp;gt;&lt;/code&gt; annotation associated with each forward function range tells you that if a backward Function object is created by this forward function, the backward object will receive sequence number N. During the backward pass, the top-level range wrapping each C++ backward Function&amp;rsquo;s &lt;code&gt;apply()&lt;/code&gt; call is decorated with &lt;code&gt;stashed seq=&amp;lt;M&amp;gt;&lt;/code&gt;. &lt;code&gt;M&lt;/code&gt; is the sequence number that the backward object was created with. By comparing &lt;code&gt;stashed seq&lt;/code&gt; numbers in backward with &lt;code&gt;seq&lt;/code&gt; numbers in forward, you can track down which forward op created each backward Function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="899a3b765d6ee8d823d5852dbea555348e22fa78" translate="yes" xml:space="preserve">
          <source>During training, it randomly masks some of the elements of the input tensor with probability &lt;em&gt;p&lt;/em&gt; using samples from a bernoulli distribution. The elements to masked are randomized on every forward call, and scaled and shifted to maintain zero mean and unit standard deviation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ddb72e8fb2bca4bbdd9cee1bd0f4124ba674fe1" translate="yes" xml:space="preserve">
          <source>During training, randomly zeroes some of the elements of the input tensor with probability &lt;code&gt;p&lt;/code&gt; using samples from a Bernoulli distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e07f3de383a6b909b32c2c8420ab783da80d74b" translate="yes" xml:space="preserve">
          <source>During training, randomly zeroes some of the elements of the input tensor with probability &lt;code&gt;p&lt;/code&gt; using samples from a Bernoulli distribution. Each channel will be zeroed out independently on every forward call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e72931d7ae530922c7186be0d18873ff29d42369" translate="yes" xml:space="preserve">
          <source>During training, the model expects both the input tensors, as well as a targets (list of dictionary), containing:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0184adedf913b076626646d3f52c3b49c39ad6d" translate="yes" xml:space="preserve">
          <source>E</source>
          <target state="translated">E</target>
        </trans-unit>
        <trans-unit id="a466f9bd6da8a16be528d1b97b22f8b80c50fc61" translate="yes" xml:space="preserve">
          <source>E (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db547439274fed58f2b9ee57841dc8931b457c07" translate="yes" xml:space="preserve">
          <source>ELU</source>
          <target state="translated">ELU</target>
        </trans-unit>
        <trans-unit id="c4cf619f3157e4a678ac53e564134cffe6210613" translate="yes" xml:space="preserve">
          <source>Each &lt;code&gt;torch.Tensor&lt;/code&gt; has a &lt;a href=&quot;#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c0427e3aafaddc6d9583e9cefbad6140b6d07cf" translate="yes" xml:space="preserve">
          <source>Each element of the tensor &lt;code&gt;input&lt;/code&gt; is multiplied by the corresponding element of the Tensor &lt;code&gt;other&lt;/code&gt;. The resulting tensor is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="728738a25fa4324927c05f66f2cfc30782cc84df" translate="yes" xml:space="preserve">
          <source>Each element of the tensor &lt;code&gt;other&lt;/code&gt; is multiplied by the scalar &lt;code&gt;alpha&lt;/code&gt; and added to each element of the tensor &lt;code&gt;input&lt;/code&gt;. The resulting tensor is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ea1bfa1407efaeb9ea4478b91f07efe596058d3" translate="yes" xml:space="preserve">
          <source>Each element will be masked independently on every forward call with probability &lt;code&gt;p&lt;/code&gt; using samples from a Bernoulli distribution. The elements to be masked are randomized on every forward call, and scaled and shifted to maintain zero mean and unit variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e969c5beedf78b6dd5c2c5d126246b66ca00cf2" translate="yes" xml:space="preserve">
          <source>Each parameter&amp;rsquo;s gradient (&lt;code&gt;.grad&lt;/code&gt; attribute) should be unscaled before the optimizer updates the parameters, so the scale factor does not interfere with the learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04229e567ec03d81b5712793e639928468412520" translate="yes" xml:space="preserve">
          <source>Each process contains an independent Python interpreter, eliminating the extra interpreter overhead and &amp;ldquo;GIL-thrashing&amp;rdquo; that comes from driving several execution threads, model replicas, or GPUs from a single Python process. This is especially important for models that make heavy use of the Python runtime, including models with recurrent layers or many small components.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c11c2aae826827df9743912100e743d6a724614" translate="yes" xml:space="preserve">
          <source>Each process maintains its own optimizer and performs a complete optimization step with each iteration. While this may appear redundant, since the gradients have already been gathered together and averaged across processes and are thus the same for every process, this means that no parameter broadcast step is needed, reducing time spent transferring tensors between nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25ddc73f3c685d39e655eadbdd24861cccbd855c" translate="yes" xml:space="preserve">
          <source>Each process scatters list of input tensors to all processes in a group and return gathered list of tensors in output list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e01a4afade34e5c383597dd828cf5ce98ca5f574" translate="yes" xml:space="preserve">
          <source>Each process will receive exactly one tensor and store its data in the &lt;code&gt;tensor&lt;/code&gt; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14f825720650e629375c55e6473f7e4c1fd8e6fb" translate="yes" xml:space="preserve">
          <source>Each sample will be retrieved by indexing tensors along the first dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a930fc3f8ffe54e36efcacdd772fc5e7328c868c" translate="yes" xml:space="preserve">
          <source>Each tensor has an associated &lt;code&gt;torch.Storage&lt;/code&gt;, which holds its data. The tensor class also provides multi-dimensional, &lt;a href=&quot;https://en.wikipedia.org/wiki/Stride_of_an_array&quot;&gt;strided&lt;/a&gt; view of a storage and defines numeric operations on it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0df7dd6db96e14d83140e8da4324d11663fe359e" translate="yes" xml:space="preserve">
          <source>Each tensor in &lt;code&gt;output_tensor_list&lt;/code&gt; should reside on a separate GPU, as should each list of tensors in &lt;code&gt;input_tensor_lists&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96aad5e1712347cedb5784e57172eb768752a304" translate="yes" xml:space="preserve">
          <source>Efficient softmax approximation as described in &lt;a href=&quot;https://arxiv.org/abs/1609.04309&quot;&gt;Efficient softmax approximation for GPUs by Edouard Grave, Armand Joulin, Moustapha Ciss&amp;eacute;, David Grangier, and Herv&amp;eacute; J&amp;eacute;gou&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f39713bdb9925bfb39803109379a2aa9f81732f8" translate="yes" xml:space="preserve">
          <source>Either the inplace modified module with submodules wrapped in &lt;code&gt;QuantWrapper&lt;/code&gt; based on qconfig or a new &lt;code&gt;QuantWrapper&lt;/code&gt; module which wraps the input module, the latter case only happens when the input module is a leaf module and we want to quantize it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8078d924b19f64b223a6df8142a489104063237" translate="yes" xml:space="preserve">
          <source>Either:</source>
          <target state="translated">Either:</target>
        </trans-unit>
        <trans-unit id="cba1a5641f37d31826ff43a90ac27303cd2de000" translate="yes" xml:space="preserve">
          <source>Element-wise arctangent of</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0ce0d75b4a69f8d83fed56dda584bc104824e33" translate="yes" xml:space="preserve">
          <source>Elements lower than min and higher than max are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="279868256307295ed763af9335611205d2a9e0e9" translate="yes" xml:space="preserve">
          <source>Eliminates all but the first element from every consecutive group of equivalent elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65e872502ba89d481aa8b75804d63958258d47d9" translate="yes" xml:space="preserve">
          <source>Embedding</source>
          <target state="translated">Embedding</target>
        </trans-unit>
        <trans-unit id="fb52acf7809d84b49f20c1e0c2aeb4d9421e883d" translate="yes" xml:space="preserve">
          <source>Embedding (no optional arguments supported)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad4c45718740fb7fd09a983448014fcde632287c" translate="yes" xml:space="preserve">
          <source>EmbeddingBag</source>
          <target state="translated">EmbeddingBag</target>
        </trans-unit>
        <trans-unit id="f25f65444d58a4000e445a3586674f2f0a1c519b" translate="yes" xml:space="preserve">
          <source>EmbeddingBag also supports per-sample weights as an argument to the forward pass. This scales the output of the Embedding before performing a weighted reduction as specified by &lt;code&gt;mode&lt;/code&gt;. If &lt;code&gt;per_sample_weights`&lt;/code&gt; is passed, the only supported &lt;code&gt;mode&lt;/code&gt; is &lt;code&gt;&quot;sum&quot;&lt;/code&gt;, which computes a weighted sum according to &lt;code&gt;per_sample_weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a184f78683775965d53e63c45e77c29a82cb431" translate="yes" xml:space="preserve">
          <source>Enables .grad attribute for non-leaf Tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97e857cbb6b3eaaffa99455ab0a6561f4d2333be" translate="yes" xml:space="preserve">
          <source>Enables gradient calculation, if it has been disabled via &lt;a href=&quot;#torch.autograd.no_grad&quot;&gt;&lt;code&gt;no_grad&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.autograd.set_grad_enabled&quot;&gt;&lt;code&gt;set_grad_enabled&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ba6db1c18e6b89f8ae8769b517165aebdeeb5e7" translate="yes" xml:space="preserve">
          <source>Enables gradient calculation, if it has been disabled via &lt;a href=&quot;torch.no_grad#torch.no_grad&quot;&gt;&lt;code&gt;no_grad&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.set_grad_enabled#torch.set_grad_enabled&quot;&gt;&lt;code&gt;set_grad_enabled&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="129b2e35235ca3917459fbda73dccc7c7ba4bb9f" translate="yes" xml:space="preserve">
          <source>Ensures that the tensor memory is not reused for another tensor until all current work queued on &lt;code&gt;stream&lt;/code&gt; are complete.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02f525cd5d7591c6c78960a007006cf272db0f53" translate="yes" xml:space="preserve">
          <source>Entrypoint function can either return a model(nn.module), or auxiliary tools to make the user workflow smoother, e.g. tokenizers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0dd14c2fc526f82985ca8c8a3a6e1c3b85b6488" translate="yes" xml:space="preserve">
          <source>Environment variable initialization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="089481a55a3bf2c4a369d848036bccebf8abe33b" translate="yes" xml:space="preserve">
          <source>Equivalent to input[:,::-1]. Requires the array to be at least 2-D.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b4933d2950181258ba9867fa0e789a6fac6c0e2" translate="yes" xml:space="preserve">
          <source>Equivalent to input[::-1,&amp;hellip;]. Requires the array to be at least 1-D.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c1eedde4e72567b3c48e7393929af1241088b7e" translate="yes" xml:space="preserve">
          <source>Errors such as timeouts for the &lt;code&gt;remote&lt;/code&gt; API are handled on a best-effort basis. This means that when remote calls initiated by &lt;code&gt;remote&lt;/code&gt; fail, such as with a timeout error, we take a best-effort approach to error handling. This means that errors are handled and set on the resulting RRef on an asynchronous basis. If the RRef has not been used by the application before this handling (such as &lt;code&gt;to_here&lt;/code&gt; or fork call), then future uses of the &lt;code&gt;RRef&lt;/code&gt; will appropriately raise errors. However, it is possible that the user application will use the &lt;code&gt;RRef&lt;/code&gt; before the errors are handled. In this case, errors may not be raised as they have not yet been handled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2352230ae4369b2400cd9a8b59625450e193a06a" translate="yes" xml:space="preserve">
          <source>Estimate</source>
          <target state="translated">Estimate</target>
        </trans-unit>
        <trans-unit id="9f5d3b9ce4cb19a213d647b445b4900659d33a6d" translate="yes" xml:space="preserve">
          <source>Evaluates module(input) in parallel across the GPUs given in device_ids.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b74f76cd70090d77d5d968780f896243c537f02" translate="yes" xml:space="preserve">
          <source>Every &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; has a corresponding storage of the same data type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c95c4e1c7a1060f504484945d50cad58c391f52" translate="yes" xml:space="preserve">
          <source>Every Sampler subclass has to provide an &lt;code&gt;__iter__()&lt;/code&gt; method, providing a way to iterate over indices of dataset elements, and a &lt;code&gt;__len__()&lt;/code&gt; method that returns the length of the returned iterators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88cdbf2ac191cecaae2230a964d90524ead7b613" translate="yes" xml:space="preserve">
          <source>Every collective operation function supports the following two kinds of operations:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25ee794140785458589b1f0dd87ed4991a86d45f" translate="yes" xml:space="preserve">
          <source>Every operation performed on &lt;code&gt;Tensor&lt;/code&gt; s creates a new function object, that performs the computation, and records that it happened. The history is retained in the form of a DAG of functions, with edges denoting data dependencies (&lt;code&gt;input &amp;lt;- output&lt;/code&gt;). Then, when backward is called, the graph is processed in the topological ordering, by calling &lt;a href=&quot;#torch.autograd.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt; methods of each &lt;a href=&quot;#torch.autograd.Function&quot;&gt;&lt;code&gt;Function&lt;/code&gt;&lt;/a&gt; object, and passing returned gradients on to next &lt;a href=&quot;#torch.autograd.Function&quot;&gt;&lt;code&gt;Function&lt;/code&gt;&lt;/a&gt; s.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d3ee82a911f61025ee027bbb14528d9be81be1b" translate="yes" xml:space="preserve">
          <source>Every tensor that&amp;rsquo;s been modified in-place in a call to &lt;code&gt;forward()&lt;/code&gt; should be given to this function, to ensure correctness of our checks. It doesn&amp;rsquo;t matter whether the function is called before or after modification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cac312ad37989d865266909c5b6681a3176edc55" translate="yes" xml:space="preserve">
          <source>Everything in a user defined &lt;a href=&quot;torchscript-class&quot;&gt;TorchScript Class&lt;/a&gt; is exported by default, functions can be decorated with &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; if needed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1753c80d644f128cefa2284b014d868b991b9d9" translate="yes" xml:space="preserve">
          <source>Exactly one of &lt;code&gt;devices&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; must be specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="502159c89a8ff9154570557bd71a328efcce5727" translate="yes" xml:space="preserve">
          <source>Exactly one of &lt;code&gt;devices&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; must be specified. When &lt;code&gt;out&lt;/code&gt; is specified, &lt;code&gt;chunk_sizes&lt;/code&gt; must not be specified and will be inferred from sizes of &lt;code&gt;out&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f01ed56a1e32a05e5ef96e4d779f34784af9a96" translate="yes" xml:space="preserve">
          <source>Example</source>
          <target state="translated">Example</target>
        </trans-unit>
        <trans-unit id="b3c7ccbaed13d7cf475ac0a8540d9af04a1abfba" translate="yes" xml:space="preserve">
          <source>Example (a type mismatch)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb18992fbb684cb9203c712439d9448a7d50b7c9" translate="yes" xml:space="preserve">
          <source>Example (an exported and ignored method in a module):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fb80256910d817ce9141fdd4451ee10894ec35c" translate="yes" xml:space="preserve">
          <source>Example (calling a script function in a traced function):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5bcda1a3bfb1af96df6dd020d0588805d88feba" translate="yes" xml:space="preserve">
          <source>Example (calling a traced function in script):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9488ed97f58e814938180bd3de0fc03a37f8d8c1" translate="yes" xml:space="preserve">
          <source>Example (fork a free function):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d40b7fb2ebedc8ff715bb44861bcfbdc43fa817" translate="yes" xml:space="preserve">
          <source>Example (fork a module method):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c61fd1aa74a0dc25c5318d75c242307960c7041c" translate="yes" xml:space="preserve">
          <source>Example (refining types on parameters and locals):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f3b97fb80872ca69d304fba5bcdeedcdbea8e85" translate="yes" xml:space="preserve">
          <source>Example (scripting a function):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de4e7f540085eb6296ec8260ef53372b15064ca1" translate="yes" xml:space="preserve">
          <source>Example (scripting a module with traced submodules):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5b0acb6ce867883478ae6d5579cfda80cbb9404" translate="yes" xml:space="preserve">
          <source>Example (scripting a simple module with a Parameter):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98fb0963dfe59db2efb10e03278c046397333fb9" translate="yes" xml:space="preserve">
          <source>Example (tracing a function):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dad6a76da0fc25a19704212a257d6379a12034b" translate="yes" xml:space="preserve">
          <source>Example (tracing a module with multiple methods):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07f0e6f11243b3ae74d74b1d28cef8c785cb16fa" translate="yes" xml:space="preserve">
          <source>Example (tracing an existing module):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68ede4837476671e511c48828e0de48f7b06d426" translate="yes" xml:space="preserve">
          <source>Example (type annotations for Python 3):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87a104ad2463311906e75683079bbad94a4fd5c2" translate="yes" xml:space="preserve">
          <source>Example (using &lt;code&gt;@torch.jit.export&lt;/code&gt; on a method):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1c7a00dbf049f876c9759d8441a029ed8e2f4ac" translate="yes" xml:space="preserve">
          <source>Example (using &lt;code&gt;@torch.jit.ignore(drop=True)&lt;/code&gt; on a method):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f45fe2e88f095f6547360c930d8119bf8c200149" translate="yes" xml:space="preserve">
          <source>Example (using &lt;code&gt;@torch.jit.ignore&lt;/code&gt; on a method):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee3db4aefed96eb801a5613278d0970a19c709cc" translate="yes" xml:space="preserve">
          <source>Example (using &lt;code&gt;@torch.jit.unused&lt;/code&gt; on a method):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15234a3935f9814be4e208815ad355afc291f504" translate="yes" xml:space="preserve">
          <source>Example (using a traced module):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73cb14b980b72004cbdbfb86fac47cf40133628b" translate="yes" xml:space="preserve">
          <source>Example 1: splitting workload across all workers in &lt;code&gt;__iter__()&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="877513517da6d71b899179494c7d8cfcf56d5921" translate="yes" xml:space="preserve">
          <source>Example 2: splitting workload across all workers using &lt;code&gt;worker_init_fn&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49895a4623d5b4a9344031509b184da5a2c67818" translate="yes" xml:space="preserve">
          <source>Example. if we have the following shape for inputs and outputs:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c63737abd7347a7ae582cb9fbdf37d6c0e5b251e" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="translated">Example:</target>
        </trans-unit>
        <trans-unit id="8ec20a84a991e14aeedf10c8e4e9247bf2c9315c" translate="yes" xml:space="preserve">
          <source>Example: End-to-end AlexNet from PyTorch to ONNX</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="038d2f8486ff39be2d765514d254dcc770c02da8" translate="yes" xml:space="preserve">
          <source>Example: Suppose the last window is: &lt;code&gt;[17, 18, 0, 0, 0]&lt;/code&gt; vs &lt;code&gt;[18, 0, 0, 0, 0]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6104a08ed7eb335488d3ea3f93c6210a1cc4746c" translate="yes" xml:space="preserve">
          <source>Example::</source>
          <target state="translated">Example::</target>
        </trans-unit>
        <trans-unit id="eb01bf04c9a0e8a71c45816513df424f1c7ffedb" translate="yes" xml:space="preserve">
          <source>Examples</source>
          <target state="translated">Examples</target>
        </trans-unit>
        <trans-unit id="fb3447b632f6a431215776dcf254a01001a40c4f" translate="yes" xml:space="preserve">
          <source>Examples:</source>
          <target state="translated">Examples:</target>
        </trans-unit>
        <trans-unit id="de3e24010b1050a8265462ab7e8f3a95c00717ea" translate="yes" xml:space="preserve">
          <source>Examples::</source>
          <target state="translated">Examples::</target>
        </trans-unit>
        <trans-unit id="8cc1b49841e2eac10bc692d1dee6f79c0d6dc0f7" translate="yes" xml:space="preserve">
          <source>Expand this tensor to the same size as &lt;code&gt;other&lt;/code&gt;. &lt;code&gt;self.expand_as(other)&lt;/code&gt; is equivalent to &lt;code&gt;self.expand(other.size())&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7381344dd49d389b0f60204fb4dbd8a7ee76371e" translate="yes" xml:space="preserve">
          <source>Expanding a tensor does not allocate new memory, but only creates a new view on the existing tensor where a dimension of size one is expanded to a larger size by setting the &lt;code&gt;stride&lt;/code&gt; to 0. Any dimension of size 1 can be expanded to an arbitrary value without allocating new memory.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
