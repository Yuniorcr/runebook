<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="eb5589e94e3540a14e8e7b3fac4f8fdf408c5f2f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.frac#torch.frac&quot;&gt;&lt;code&gt;torch.frac()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.frac#torch.frac&quot;&gt; &lt;code&gt;torch.frac()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fe3455e99f31e058dbdc692b113c1359d89488d7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.gather#torch.gather&quot;&gt;&lt;code&gt;torch.gather()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.gather#torch.gather&quot;&gt; &lt;code&gt;torch.gather()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a5d4ce8f33e2308a786a65897ca2b53b361ed230" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.gcd#torch.gcd&quot;&gt;&lt;code&gt;torch.gcd()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.gcd#torch.gcd&quot;&gt; &lt;code&gt;torch.gcd()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="47e2863133f746b04949765203596816d2a569fd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ge#torch.ge&quot;&gt;&lt;code&gt;torch.ge()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.ge#torch.ge&quot;&gt; &lt;code&gt;torch.ge()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="dc3905a5552f33afb11f303bb93b1f92da393e87" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt; &lt;code&gt;torch.geqrf()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d0f396c7008d561476ffb59f26b17018bc84fa73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ger#torch.ger&quot;&gt;&lt;code&gt;torch.ger()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.ger#torch.ger&quot;&gt; &lt;code&gt;torch.ger()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="29a71ad0e5b1620b27e713b79b570ee4a9882fbd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.greater#torch.greater&quot;&gt;&lt;code&gt;torch.greater()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.greater#torch.greater&quot;&gt; &lt;code&gt;torch.greater()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2aa63e3e1cb9df927bb8622309466c088861e7c1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.greater_equal#torch.greater_equal&quot;&gt;&lt;code&gt;torch.greater_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.greater_equal#torch.greater_equal&quot;&gt; &lt;code&gt;torch.greater_equal()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="22d16c3e505067a772ddee47e68d0c5e9efdf1ea" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.gt#torch.gt&quot;&gt;&lt;code&gt;torch.gt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.gt#torch.gt&quot;&gt; &lt;code&gt;torch.gt()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f797b96d9a976433ee5e82f85c212bf9cc6c07aa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.heaviside#torch.heaviside&quot;&gt;&lt;code&gt;torch.heaviside()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.heaviside#torch.heaviside&quot;&gt; &lt;code&gt;torch.heaviside()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f4c88cbc91c3b48e1204ec2fc29b766aaa6e3c59" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.histc#torch.histc&quot;&gt;&lt;code&gt;torch.histc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.histc#torch.histc&quot;&gt; &lt;code&gt;torch.histc()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f24053f673f97bf0cebaec0ddd1ab96fa9d420f2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.hypot#torch.hypot&quot;&gt;&lt;code&gt;torch.hypot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.hypot#torch.hypot&quot;&gt; &lt;code&gt;torch.hypot()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5a27de95d9ce95538faa35bfb5a5044535b471e7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.i0#torch.i0&quot;&gt;&lt;code&gt;torch.i0()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.i0#torch.i0&quot;&gt; &lt;code&gt;torch.i0()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="55baf0c2297883aeca1f8032e140f1dce62c7f54" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ifft#torch.ifft&quot;&gt;&lt;code&gt;torch.ifft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.ifft#torch.ifft&quot;&gt; &lt;code&gt;torch.ifft()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dbd53ee94265f26254d53b09c2158dbdc7c06b75" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.index_select#torch.index_select&quot;&gt;&lt;code&gt;torch.index_select()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.index_select#torch.index_select&quot;&gt; &lt;code&gt;torch.index_select()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="91cb515b356d2c52d4004829619ffcf0284a140c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.inverse#torch.inverse&quot;&gt;&lt;code&gt;torch.inverse()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.inverse#torch.inverse&quot;&gt; &lt;code&gt;torch.inverse()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1921c02b416a3c35ca9a7616e742bedc37f85261" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.irfft#torch.irfft&quot;&gt;&lt;code&gt;torch.irfft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.irfft#torch.irfft&quot;&gt; &lt;code&gt;torch.irfft()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0a61d72d732d7b3d2bfcfab031758abf3bd3f2bf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isclose#torch.isclose&quot;&gt;&lt;code&gt;torch.isclose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.isclose#torch.isclose&quot;&gt; &lt;code&gt;torch.isclose()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6d43646aed73f0e63bb4282297ddeb0953661084" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isfinite#torch.isfinite&quot;&gt;&lt;code&gt;torch.isfinite()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.isfinite#torch.isfinite&quot;&gt; &lt;code&gt;torch.isfinite()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7f01c4969936eb94939bfba08517f9dc5d3c9b65" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isinf#torch.isinf&quot;&gt;&lt;code&gt;torch.isinf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.isinf#torch.isinf&quot;&gt; &lt;code&gt;torch.isinf()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c15049f87e6457b76bc4c833aad4e86fc330a9a4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isnan#torch.isnan&quot;&gt;&lt;code&gt;torch.isnan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.isnan#torch.isnan&quot;&gt; &lt;code&gt;torch.isnan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b0c99b8516b26410ede0975c9d5e8303e6a56d72" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isneginf#torch.isneginf&quot;&gt;&lt;code&gt;torch.isneginf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.isneginf#torch.isneginf&quot;&gt; &lt;code&gt;torch.isneginf()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c45c9bc98276b87a137a720f4ab4cbfc8bccf9d9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isposinf#torch.isposinf&quot;&gt;&lt;code&gt;torch.isposinf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.isposinf#torch.isposinf&quot;&gt; &lt;code&gt;torch.isposinf()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bff4ba1100e12cf9a28654669a565681a03dd913" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isreal#torch.isreal&quot;&gt;&lt;code&gt;torch.isreal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.isreal#torch.isreal&quot;&gt; &lt;code&gt;torch.isreal()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dcf71e098da4b8c28d983651980d01f5b1a6049b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.istft#torch.istft&quot;&gt;&lt;code&gt;torch.istft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.istft#torch.istft&quot;&gt; &lt;code&gt;torch.istft()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0f606579981b49ec0a8206d550a759168fd92964" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.kthvalue#torch.kthvalue&quot;&gt;&lt;code&gt;torch.kthvalue()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.kthvalue#torch.kthvalue&quot;&gt; &lt;code&gt;torch.kthvalue()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0d8ba07cef0e3cd2ee953932e7401cfd0248e444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lcm#torch.lcm&quot;&gt;&lt;code&gt;torch.lcm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.lcm#torch.lcm&quot;&gt; &lt;code&gt;torch.lcm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d6699a864923ddee28ba56b38069aaab083349df" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.le#torch.le&quot;&gt;&lt;code&gt;torch.le()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.le#torch.le&quot;&gt; &lt;code&gt;torch.le()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="32c678d238915a61f701966540f011fe2fc9cbc1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lerp#torch.lerp&quot;&gt;&lt;code&gt;torch.lerp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.lerp#torch.lerp&quot;&gt; &lt;code&gt;torch.lerp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e1d6db8a3f3362c5bfd61e84e72244e0ee6bf8e9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.less#torch.less&quot;&gt;&lt;code&gt;torch.less()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.less#torch.less&quot;&gt; &lt;code&gt;torch.less()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e8eea9085bfaff6760dd93361241db5a26d61c2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.less_equal#torch.less_equal&quot;&gt;&lt;code&gt;torch.less_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.less_equal#torch.less_equal&quot;&gt; &lt;code&gt;torch.less_equal()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1cd2d05d4cdb6e340422b7b49a0f18ef4af47558" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lgamma#torch.lgamma&quot;&gt;&lt;code&gt;torch.lgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.lgamma#torch.lgamma&quot;&gt; &lt;code&gt;torch.lgamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7caa6f91635bb60ab80ed9ca2541683e873e5da4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log#torch.log&quot;&gt;&lt;code&gt;torch.log()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.log#torch.log&quot;&gt; &lt;code&gt;torch.log()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="73a23f7411ea79d1413155727db906f0562b2082" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log10#torch.log10&quot;&gt;&lt;code&gt;torch.log10()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.log10#torch.log10&quot;&gt; &lt;code&gt;torch.log10()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a8dc5bc392cc9737d55c7a288ffae377a0f80b8e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log1p#torch.log1p&quot;&gt;&lt;code&gt;torch.log1p()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.log1p#torch.log1p&quot;&gt; &lt;code&gt;torch.log1p()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b442c9296b5b51dc12a6d62a9e946bae4e4cace4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log2#torch.log2&quot;&gt;&lt;code&gt;torch.log2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.log2#torch.log2&quot;&gt; &lt;code&gt;torch.log2()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="82580a23e0c28a78662f5e93ee563089d4043db8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logaddexp#torch.logaddexp&quot;&gt;&lt;code&gt;torch.logaddexp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.logaddexp#torch.logaddexp&quot;&gt; &lt;code&gt;torch.logaddexp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7856ea9cc5c5b34b3fad25b3ceb90619e2bcf1a1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logaddexp2#torch.logaddexp2&quot;&gt;&lt;code&gt;torch.logaddexp2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.logaddexp2#torch.logaddexp2&quot;&gt; &lt;code&gt;torch.logaddexp2()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d244fcdaec339fa07bf0c8b02d8e5206a3756511" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logcumsumexp#torch.logcumsumexp&quot;&gt;&lt;code&gt;torch.logcumsumexp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.logcumsumexp#torch.logcumsumexp&quot;&gt; &lt;code&gt;torch.logcumsumexp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e64767e412c54452d0e93a4095d3fb5a34e4a87d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logdet#torch.logdet&quot;&gt;&lt;code&gt;torch.logdet()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.logdet#torch.logdet&quot;&gt; &lt;code&gt;torch.logdet()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dae45426090891d1953ee3ad38c045f8a0fceedc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_and#torch.logical_and&quot;&gt;&lt;code&gt;torch.logical_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.logical_and#torch.logical_and&quot;&gt; &lt;code&gt;torch.logical_and()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d20544f0f1149d37dc67d5b4c2ec2fcf87602aaf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_not#torch.logical_not&quot;&gt;&lt;code&gt;torch.logical_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.logical_not#torch.logical_not&quot;&gt; &lt;code&gt;torch.logical_not()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7f1dd2cde87434261bce6932056bcd2beea83bc0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_or#torch.logical_or&quot;&gt;&lt;code&gt;torch.logical_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.logical_or#torch.logical_or&quot;&gt; &lt;code&gt;torch.logical_or()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="64c77ca5d503f49a2495909f4b01e01b4e55a15f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_xor#torch.logical_xor&quot;&gt;&lt;code&gt;torch.logical_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.logical_xor#torch.logical_xor&quot;&gt; &lt;code&gt;torch.logical_xor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e9fec990c19512cd7cbc5c7730d590537da8787a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logit#torch.logit&quot;&gt;&lt;code&gt;torch.logit()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.logit#torch.logit&quot;&gt; &lt;code&gt;torch.logit()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7682310645eb1b3d8a10df47deccb4b498fc4809" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logsumexp#torch.logsumexp&quot;&gt;&lt;code&gt;torch.logsumexp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.logsumexp#torch.logsumexp&quot;&gt; &lt;code&gt;torch.logsumexp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f577c3338ec6045533458e8c6be36ac9572aed9e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lstsq#torch.lstsq&quot;&gt;&lt;code&gt;torch.lstsq()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.lstsq#torch.lstsq&quot;&gt; &lt;code&gt;torch.lstsq()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e411f1ff349b11bfd836c08df5971026b855e59a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lt#torch.lt&quot;&gt;&lt;code&gt;torch.lt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.lt#torch.lt&quot;&gt; &lt;code&gt;torch.lt()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="578639cb9fc16b15aa6b7e1967466fe9b09ff42d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lu#torch.lu&quot;&gt;&lt;code&gt;torch.lu()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.lu#torch.lu&quot;&gt; &lt;code&gt;torch.lu()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c96a4514c11416811fe9f9b86d4dd2e1d0e4e1cd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lu_solve#torch.lu_solve&quot;&gt;&lt;code&gt;torch.lu_solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.lu_solve#torch.lu_solve&quot;&gt; &lt;code&gt;torch.lu_solve()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8c6b2883c1c8d2d0de37ea2c95e5b1fa94069b4d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.masked_select#torch.masked_select&quot;&gt;&lt;code&gt;torch.masked_select()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.masked_select#torch.masked_select&quot;&gt; &lt;code&gt;torch.masked_select()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c4dc4224536b289cdb91dd6eb3b784c8632062f7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.matmul#torch.matmul&quot;&gt;&lt;code&gt;torch.matmul()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.matmul#torch.matmul&quot;&gt; &lt;code&gt;torch.matmul()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="18b30626e1ae4fc77dd2baf1eea08d60901e4a44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.matrix_exp#torch.matrix_exp&quot;&gt;&lt;code&gt;torch.matrix_exp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.matrix_exp#torch.matrix_exp&quot;&gt; &lt;code&gt;torch.matrix_exp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8ceb6fc4ba32f1c6513652ba41e7ed5365209b9d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.matrix_power#torch.matrix_power&quot;&gt;&lt;code&gt;torch.matrix_power()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.matrix_power#torch.matrix_power&quot;&gt; &lt;code&gt;torch.matrix_power()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e3d3a41458bccec6e7e87d98e4ad75ec5c4237fb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.max#torch.max&quot;&gt;&lt;code&gt;torch.max()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.max#torch.max&quot;&gt; &lt;code&gt;torch.max()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="689831f5600395b5cce9e382345788eac42fd2b3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.maximum#torch.maximum&quot;&gt;&lt;code&gt;torch.maximum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.maximum#torch.maximum&quot;&gt; &lt;code&gt;torch.maximum()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="75cde60dd542a6062dc76781c6f95cef4726b299" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mean#torch.mean&quot;&gt;&lt;code&gt;torch.mean()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.mean#torch.mean&quot;&gt; &lt;code&gt;torch.mean()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="106c7cf7d53f462e1efa14592e3a206e193353ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.median#torch.median&quot;&gt;&lt;code&gt;torch.median()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.median#torch.median&quot;&gt; &lt;code&gt;torch.median()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="45e4b29591dc1fd5fe60cf3f1a2528339eb79d7a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.min#torch.min&quot;&gt;&lt;code&gt;torch.min()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.min#torch.min&quot;&gt; &lt;code&gt;torch.min()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="71ff8dd28d5ec4bba7fa90d123381bf318d57316" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.minimum#torch.minimum&quot;&gt;&lt;code&gt;torch.minimum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.minimum#torch.minimum&quot;&gt; &lt;code&gt;torch.minimum()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f88fe431125507817f53eadcab5b7cf0486d3c3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mm#torch.mm&quot;&gt;&lt;code&gt;torch.mm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.mm#torch.mm&quot;&gt; &lt;code&gt;torch.mm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="89a5d4426d8c3c83f76b02d2a04a8fa74cd9c984" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mode#torch.mode&quot;&gt;&lt;code&gt;torch.mode()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.mode#torch.mode&quot;&gt; &lt;code&gt;torch.mode()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="480d2c05ebbc86790a491b5029a1882724ab97f9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.movedim#torch.movedim&quot;&gt;&lt;code&gt;torch.movedim()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.movedim#torch.movedim&quot;&gt; &lt;code&gt;torch.movedim()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9e47d65e128408a5146c2909f05667f8df18f4de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mul#torch.mul&quot;&gt;&lt;code&gt;torch.mul()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.mul#torch.mul&quot;&gt; &lt;code&gt;torch.mul()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="346834db1e953738900b156dccde72730c321179" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.multinomial#torch.multinomial&quot;&gt;&lt;code&gt;torch.multinomial()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.multinomial#torch.multinomial&quot;&gt; &lt;code&gt;torch.multinomial()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2abc253dc35a3f16344ec6f7c0d4b4f3f6f389c0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.multiply#torch.multiply&quot;&gt;&lt;code&gt;torch.multiply()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.multiply#torch.multiply&quot;&gt; &lt;code&gt;torch.multiply()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bd83a3f33cb0434d70d1281178c10f4d4186288c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mv#torch.mv&quot;&gt;&lt;code&gt;torch.mv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.mv#torch.mv&quot;&gt; &lt;code&gt;torch.mv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c7ada1c677f5eab787ec7f543df6913243851e42" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mvlgamma#torch.mvlgamma&quot;&gt;&lt;code&gt;torch.mvlgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.mvlgamma#torch.mvlgamma&quot;&gt; &lt;code&gt;torch.mvlgamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="96ec4016de71e2ca1618c82409f4cbcb9c612e86" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nanquantile#torch.nanquantile&quot;&gt;&lt;code&gt;torch.nanquantile()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.nanquantile#torch.nanquantile&quot;&gt; &lt;code&gt;torch.nanquantile()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="eda1f1134fb78245db2a5b46d9c8dcff19e60476" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nansum#torch.nansum&quot;&gt;&lt;code&gt;torch.nansum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.nansum#torch.nansum&quot;&gt; &lt;code&gt;torch.nansum()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2aaeb0cd2a053ef536d53c256571aadbdbf969ca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.narrow#torch.narrow&quot;&gt;&lt;code&gt;torch.narrow()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.narrow#torch.narrow&quot;&gt; &lt;code&gt;torch.narrow()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="32b6bd21755f0280c169e12a964b6d0d8f9f944d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ne#torch.ne&quot;&gt;&lt;code&gt;torch.ne()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.ne#torch.ne&quot;&gt; &lt;code&gt;torch.ne()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ef00c00cfc229955de1af61e47329e20da955299" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.neg#torch.neg&quot;&gt;&lt;code&gt;torch.neg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.neg#torch.neg&quot;&gt; &lt;code&gt;torch.neg()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c59bed38407778d4b3b65157e276bcba44fa481e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.negative#torch.negative&quot;&gt;&lt;code&gt;torch.negative()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.negative#torch.negative&quot;&gt; &lt;code&gt;torch.negative()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ab18f54431cb99ac38d5579314003713c8aef19f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nextafter#torch.nextafter&quot;&gt;&lt;code&gt;torch.nextafter()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.nextafter#torch.nextafter&quot;&gt; &lt;code&gt;torch.nextafter()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="211dc318b0ac18e597f00d3389f89e2fa69af8fd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptiveavgpool1d#torch.nn.AdaptiveAvgPool1d&quot;&gt;&lt;code&gt;AdaptiveAvgPool1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.adaptiveavgpool1d#torch.nn.AdaptiveAvgPool1d&quot;&gt; &lt;code&gt;AdaptiveAvgPool1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c297648804959d7e566eb6462302a062556e0a26" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptiveavgpool2d#torch.nn.AdaptiveAvgPool2d&quot;&gt;&lt;code&gt;AdaptiveAvgPool2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.adaptiveavgpool2d#torch.nn.AdaptiveAvgPool2d&quot;&gt; &lt;code&gt;AdaptiveAvgPool2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9e3e0fe3b85f801c746e8e3435b99b12af2758cb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptiveavgpool3d#torch.nn.AdaptiveAvgPool3d&quot;&gt;&lt;code&gt;AdaptiveAvgPool3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.adaptiveavgpool3d#torch.nn.AdaptiveAvgPool3d&quot;&gt; &lt;code&gt;AdaptiveAvgPool3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="dcb4c522bcd653244a2b0e212d2a6c1dec943575" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptivemaxpool1d#torch.nn.AdaptiveMaxPool1d&quot;&gt;&lt;code&gt;AdaptiveMaxPool1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.adaptivemaxpool1d#torch.nn.AdaptiveMaxPool1d&quot;&gt; &lt;code&gt;AdaptiveMaxPool1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9197dd28b388a9ad018e4140bcb03f05bef22fce" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptivemaxpool2d#torch.nn.AdaptiveMaxPool2d&quot;&gt;&lt;code&gt;AdaptiveMaxPool2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.adaptivemaxpool2d#torch.nn.AdaptiveMaxPool2d&quot;&gt; &lt;code&gt;AdaptiveMaxPool2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="671fa746ed1d96f6e5c409933c093bf281ece232" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptivemaxpool3d#torch.nn.AdaptiveMaxPool3d&quot;&gt;&lt;code&gt;AdaptiveMaxPool3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.adaptivemaxpool3d#torch.nn.AdaptiveMaxPool3d&quot;&gt; &lt;code&gt;AdaptiveMaxPool3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="06fcc12676bdce703006b9934a46a5d88c4ea69e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.alphadropout#torch.nn.AlphaDropout&quot;&gt;&lt;code&gt;AlphaDropout&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.alphadropout#torch.nn.AlphaDropout&quot;&gt; &lt;code&gt;AlphaDropout&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="299a82bba9fc9f3c48bfd00d90ea771941bb3509" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.avgpool1d#torch.nn.AvgPool1d&quot;&gt;&lt;code&gt;AvgPool1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.avgpool1d#torch.nn.AvgPool1d&quot;&gt; &lt;code&gt;AvgPool1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9e431c47012b760f030d5cd2cfeebdfaaa73e3a4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.avgpool2d#torch.nn.AvgPool2d&quot;&gt;&lt;code&gt;AvgPool2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.avgpool2d#torch.nn.AvgPool2d&quot;&gt; &lt;code&gt;AvgPool2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5d5e8ddb26e145fc6c6ccd8ea827c9249bd3e2c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.avgpool3d#torch.nn.AvgPool3d&quot;&gt;&lt;code&gt;AvgPool3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.avgpool3d#torch.nn.AvgPool3d&quot;&gt; &lt;code&gt;AvgPool3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b2f2febc074ac5ab0c26eb12dab1477a725d346c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.batchnorm1d#torch.nn.BatchNorm1d&quot;&gt;&lt;code&gt;BatchNorm1d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;BatchNorm2d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.batchnorm3d#torch.nn.BatchNorm3d&quot;&gt;&lt;code&gt;BatchNorm3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.batchnorm1d#torch.nn.BatchNorm1d&quot;&gt; &lt;code&gt;BatchNorm1d&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt; &lt;code&gt;BatchNorm2d&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/torch.nn.batchnorm3d#torch.nn.BatchNorm3d&quot;&gt; &lt;code&gt;BatchNorm3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="49181f1a5d0f855f350c509add5501b487b8de9a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.bceloss#torch.nn.BCELoss&quot;&gt;&lt;code&gt;BCELoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.bceloss#torch.nn.BCELoss&quot;&gt; &lt;code&gt;BCELoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f9b2acc69b3141658463c5b48ed119f653d953fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.bcewithlogitsloss#torch.nn.BCEWithLogitsLoss&quot;&gt;&lt;code&gt;BCEWithLogitsLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.bcewithlogitsloss#torch.nn.BCEWithLogitsLoss&quot;&gt; &lt;code&gt;BCEWithLogitsLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1e05c2119de76670ff15f68392d6126a185752ff" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.celu#torch.nn.CELU&quot;&gt;&lt;code&gt;CELU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.celu#torch.nn.CELU&quot;&gt; &lt;code&gt;CELU&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="46a2836ec87b23dd081f1f557c9d269b806abf39" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.constantpad2d#torch.nn.ConstantPad2d&quot;&gt;&lt;code&gt;torch.nn.ConstantPad2d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.reflectionpad2d#torch.nn.ReflectionPad2d&quot;&gt;&lt;code&gt;torch.nn.ReflectionPad2d&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/torch.nn.replicationpad2d#torch.nn.ReplicationPad2d&quot;&gt;&lt;code&gt;torch.nn.ReplicationPad2d&lt;/code&gt;&lt;/a&gt; for concrete examples on how each of the padding modes works. Constant padding is implemented for arbitrary dimensions. Replicate padding is implemented for padding the last 3 dimensions of 5D input tensor, or the last 2 dimensions of 4D input tensor, or the last dimension of 3D input tensor. Reflect padding is only implemented for padding the last 2 dimensions of 4D input tensor, or the last dimension of 3D input tensor.</source>
          <target state="translated">有关每种填充模式如何工作的具体示例，请参见&lt;a href=&quot;generated/torch.nn.constantpad2d#torch.nn.ConstantPad2d&quot;&gt; &lt;code&gt;torch.nn.ConstantPad2d&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/torch.nn.reflectionpad2d#torch.nn.ReflectionPad2d&quot;&gt; &lt;code&gt;torch.nn.ReflectionPad2d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.replicationpad2d#torch.nn.ReplicationPad2d&quot;&gt; &lt;code&gt;torch.nn.ReplicationPad2d&lt;/code&gt; &lt;/a&gt;。恒定填充用于任意尺寸。复制填充用于填充5D输入张量的最后3个维度，4D输入张量的最后2个维度或3D输入张量的最后一个维度。反射填充仅用于填充4D输入张量的最后2个维度或3D输入张量的最后一个维度。</target>
        </trans-unit>
        <trans-unit id="92e4bf1e1580e8ab1c867f9318919922f5d69097" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt; &lt;code&gt;Conv1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="fb3d45384af0f65dcc256fd4e526a226237028c3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; for other attributes.</source>
          <target state="translated">有关其他属性，请参见&lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt; &lt;code&gt;Conv1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1d1d57fe3bdff062ac6991806c22d029393fd38a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;Conv2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d165cb34672d664f9dd17ceb8fa4d5cf8092ba2a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; for other attributes.</source>
          <target state="translated">有关其他属性，请参见&lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;Conv2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="62b640305a360b502c1c6f7e2a7cc59219562d5b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt; &lt;code&gt;Conv3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="827a3d0d159d0163f089c1b8b07697a3b4d204b1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; for other attributes.</source>
          <target state="translated">有关其他属性，请参见&lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt; &lt;code&gt;Conv3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2c6215c6031dbc3057e738f03ebc6ccb657c175c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.convtranspose1d#torch.nn.ConvTranspose1d&quot;&gt;&lt;code&gt;ConvTranspose1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.convtranspose1d#torch.nn.ConvTranspose1d&quot;&gt; &lt;code&gt;ConvTranspose1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="92a07f307c29825975eb91630c55dc6f1ef73449" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.convtranspose2d#torch.nn.ConvTranspose2d&quot;&gt;&lt;code&gt;ConvTranspose2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.convtranspose2d#torch.nn.ConvTranspose2d&quot;&gt; &lt;code&gt;ConvTranspose2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="26d37ceb58b322f40fdbdfcf86ed7b27d34f3ea4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.convtranspose3d#torch.nn.ConvTranspose3d&quot;&gt;&lt;code&gt;ConvTranspose3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见&lt;a href=&quot;generated/torch.nn.convtranspose3d#torch.nn.ConvTranspose3d&quot;&gt; &lt;code&gt;ConvTranspose3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0ecbef13440cb7e3c72978fb3f953d0ea4a05dec" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.cosineembeddingloss#torch.nn.CosineEmbeddingLoss&quot;&gt;&lt;code&gt;CosineEmbeddingLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.cosineembeddingloss#torch.nn.CosineEmbeddingLoss&quot;&gt; &lt;code&gt;CosineEmbeddingLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="07cebd07469d5659a87059395414105b3f0a54c1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.crossentropyloss#torch.nn.CrossEntropyLoss&quot;&gt;&lt;code&gt;CrossEntropyLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.crossentropyloss#torch.nn.CrossEntropyLoss&quot;&gt; &lt;code&gt;CrossEntropyLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ed9307322caa5510dafcec4ab6a6439e46cca0ac" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.ctcloss#torch.nn.CTCLoss&quot;&gt;&lt;code&gt;CTCLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.ctcloss#torch.nn.CTCLoss&quot;&gt; &lt;code&gt;CTCLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="90c67074e8fb1e5903e2b6ceed293a19589c2504" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.dropout#torch.nn.Dropout&quot;&gt;&lt;code&gt;Dropout&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.dropout#torch.nn.Dropout&quot;&gt; &lt;code&gt;Dropout&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6b5e6bf0d87dc5eedbd14a70bf17165953b58726" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.dropout2d#torch.nn.Dropout2d&quot;&gt;&lt;code&gt;Dropout2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.dropout2d#torch.nn.Dropout2d&quot;&gt; &lt;code&gt;Dropout2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9181ef4cdcda4e21d4c1d578bf817479c3e73473" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.dropout3d#torch.nn.Dropout3d&quot;&gt;&lt;code&gt;Dropout3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.dropout3d#torch.nn.Dropout3d&quot;&gt; &lt;code&gt;Dropout3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e9638040580d53d7a62b5948dfef978c66524b9c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.elu#torch.nn.ELU&quot;&gt;&lt;code&gt;ELU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.elu#torch.nn.ELU&quot;&gt; &lt;code&gt;ELU&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9516b3d99ccc49e5403a54c4cd4186fa2ebff368" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt;&lt;code&gt;torch.nn.Embedding&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt; &lt;code&gt;torch.nn.Embedding&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b0ef85f5e373bd3344bdb431e1a684be4a2c111f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.embeddingbag#torch.nn.EmbeddingBag&quot;&gt;&lt;code&gt;torch.nn.EmbeddingBag&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.embeddingbag#torch.nn.EmbeddingBag&quot;&gt; &lt;code&gt;torch.nn.EmbeddingBag&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="87b8eae451b415ea1f7e39fa3cca366d80225aa8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.fold#torch.nn.Fold&quot;&gt;&lt;code&gt;torch.nn.Fold&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.fold#torch.nn.Fold&quot;&gt; &lt;code&gt;torch.nn.Fold&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a3f647c2cb1152f6be057eaec2f333adc27b7848" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hardshrink#torch.nn.Hardshrink&quot;&gt;&lt;code&gt;Hardshrink&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.hardshrink#torch.nn.Hardshrink&quot;&gt; &lt;code&gt;Hardshrink&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3e54bc653f24897904f35291d48d7a4d3e1b15dd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hardsigmoid#torch.nn.Hardsigmoid&quot;&gt;&lt;code&gt;Hardsigmoid&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.hardsigmoid#torch.nn.Hardsigmoid&quot;&gt; &lt;code&gt;Hardsigmoid&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8d8089dc9fcfe5932254ec4b47d12c1cbe02d107" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hardswish#torch.nn.Hardswish&quot;&gt;&lt;code&gt;Hardswish&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.hardswish#torch.nn.Hardswish&quot;&gt; &lt;code&gt;Hardswish&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="79e7f193eb69518b7c2bc43975107d6c9f8a543d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hingeembeddingloss#torch.nn.HingeEmbeddingLoss&quot;&gt;&lt;code&gt;HingeEmbeddingLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.hingeembeddingloss#torch.nn.HingeEmbeddingLoss&quot;&gt; &lt;code&gt;HingeEmbeddingLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a07f37d494d50f907a7a0be59a0004e665fc42f6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.instancenorm1d#torch.nn.InstanceNorm1d&quot;&gt;&lt;code&gt;InstanceNorm1d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.instancenorm2d#torch.nn.InstanceNorm2d&quot;&gt;&lt;code&gt;InstanceNorm2d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.instancenorm3d#torch.nn.InstanceNorm3d&quot;&gt;&lt;code&gt;InstanceNorm3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.instancenorm1d#torch.nn.InstanceNorm1d&quot;&gt; &lt;code&gt;InstanceNorm1d&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/torch.nn.instancenorm2d#torch.nn.InstanceNorm2d&quot;&gt; &lt;code&gt;InstanceNorm2d&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/torch.nn.instancenorm3d#torch.nn.InstanceNorm3d&quot;&gt; &lt;code&gt;InstanceNorm3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="cc584ec8326a5572f69ad2a713d36f3294777bbf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.kldivloss#torch.nn.KLDivLoss&quot;&gt;&lt;code&gt;KLDivLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.kldivloss#torch.nn.KLDivLoss&quot;&gt; &lt;code&gt;KLDivLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="82170e2aa45b79e0abc6968e9d7a135946023f5a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.l1loss#torch.nn.L1Loss&quot;&gt;&lt;code&gt;L1Loss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.l1loss#torch.nn.L1Loss&quot;&gt; &lt;code&gt;L1Loss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6d19657b2b5b68544134330ee366c7bfea1457eb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt; &lt;code&gt;LayerNorm&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2bef43e82a39e507cbf89ef28c4b26fd78760fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.leakyrelu#torch.nn.LeakyReLU&quot;&gt;&lt;code&gt;LeakyReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.leakyrelu#torch.nn.LeakyReLU&quot;&gt; &lt;code&gt;LeakyReLU&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2764126c51f5530622c4b4e091ebc79776ade07c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.localresponsenorm#torch.nn.LocalResponseNorm&quot;&gt;&lt;code&gt;LocalResponseNorm&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.localresponsenorm#torch.nn.LocalResponseNorm&quot;&gt; &lt;code&gt;LocalResponseNorm&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e31635636f40648e7e735d06a4392b7cebd2b258" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.logsigmoid#torch.nn.LogSigmoid&quot;&gt;&lt;code&gt;LogSigmoid&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.logsigmoid#torch.nn.LogSigmoid&quot;&gt; &lt;code&gt;LogSigmoid&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="412a8150cd54d51d6530e2d245b63346bf33130a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.logsoftmax#torch.nn.LogSoftmax&quot;&gt;&lt;code&gt;LogSoftmax&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.logsoftmax#torch.nn.LogSoftmax&quot;&gt; &lt;code&gt;LogSoftmax&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7f565430e626357bd4afefcb8e556e2cb25e9480" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.lppool1d#torch.nn.LPPool1d&quot;&gt;&lt;code&gt;LPPool1d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.lppool1d#torch.nn.LPPool1d&quot;&gt; &lt;code&gt;LPPool1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="35b0452fd507c2aa91e1da43aa355009dc166d13" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.lppool2d#torch.nn.LPPool2d&quot;&gt;&lt;code&gt;LPPool2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.lppool2d#torch.nn.LPPool2d&quot;&gt; &lt;code&gt;LPPool2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2cbda61d0da4455a2876aa2b87f22199f2f1cdb3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.marginrankingloss#torch.nn.MarginRankingLoss&quot;&gt;&lt;code&gt;MarginRankingLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.marginrankingloss#torch.nn.MarginRankingLoss&quot;&gt; &lt;code&gt;MarginRankingLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="898e6a57e299ae9b57ccd5993abb1ef8bd55140b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxpool1d#torch.nn.MaxPool1d&quot;&gt;&lt;code&gt;MaxPool1d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.maxpool1d#torch.nn.MaxPool1d&quot;&gt; &lt;code&gt;MaxPool1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b0dc529ce91ee71820fbf1ed9bed0661ddc036f6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxpool2d#torch.nn.MaxPool2d&quot;&gt;&lt;code&gt;MaxPool2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.maxpool2d#torch.nn.MaxPool2d&quot;&gt; &lt;code&gt;MaxPool2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b6be4f2f66ae6f0a242da37cad7e7f70f4a8e328" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt;&lt;code&gt;MaxPool3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt; &lt;code&gt;MaxPool3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e5de0ae10e2d087fd9d49043502233c22cd7d1ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxunpool1d#torch.nn.MaxUnpool1d&quot;&gt;&lt;code&gt;MaxUnpool1d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.maxunpool1d#torch.nn.MaxUnpool1d&quot;&gt; &lt;code&gt;MaxUnpool1d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="06bc4bd975e3b0441df74b337a9e03841cdc0854" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxunpool2d#torch.nn.MaxUnpool2d&quot;&gt;&lt;code&gt;MaxUnpool2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.maxunpool2d#torch.nn.MaxUnpool2d&quot;&gt; &lt;code&gt;MaxUnpool2d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="be3c23907ec483dcbebdd45f57208e45ff569446" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxunpool3d#torch.nn.MaxUnpool3d&quot;&gt;&lt;code&gt;MaxUnpool3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.maxunpool3d#torch.nn.MaxUnpool3d&quot;&gt; &lt;code&gt;MaxUnpool3d&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="787cf804e853557c82df78674a398c819b20b9c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.mseloss#torch.nn.MSELoss&quot;&gt;&lt;code&gt;MSELoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.mseloss#torch.nn.MSELoss&quot;&gt; &lt;code&gt;MSELoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="01976be184fbec1b413106ad9e281456840b581b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.multilabelmarginloss#torch.nn.MultiLabelMarginLoss&quot;&gt;&lt;code&gt;MultiLabelMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.multilabelmarginloss#torch.nn.MultiLabelMarginLoss&quot;&gt; &lt;code&gt;MultiLabelMarginLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7aa5a41923f45ec7053a3fcb00c51f4757953233" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.multilabelsoftmarginloss#torch.nn.MultiLabelSoftMarginLoss&quot;&gt;&lt;code&gt;MultiLabelSoftMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.multilabelsoftmarginloss#torch.nn.MultiLabelSoftMarginLoss&quot;&gt; &lt;code&gt;MultiLabelSoftMarginLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d1b726bdc0737f6680b51d100e20056a744ff1e6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.multimarginloss#torch.nn.MultiMarginLoss&quot;&gt;&lt;code&gt;MultiMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.multimarginloss#torch.nn.MultiMarginLoss&quot;&gt; &lt;code&gt;MultiMarginLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="729c99354cfb624e609e3f72dffceaad9cd0847c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.nllloss#torch.nn.NLLLoss&quot;&gt;&lt;code&gt;NLLLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.nllloss#torch.nn.NLLLoss&quot;&gt; &lt;code&gt;NLLLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8ee9817c275d3255a1242d0c82f69825ae4ec439" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.pairwisedistance#torch.nn.PairwiseDistance&quot;&gt;&lt;code&gt;torch.nn.PairwiseDistance&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.pairwisedistance#torch.nn.PairwiseDistance&quot;&gt; &lt;code&gt;torch.nn.PairwiseDistance&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="100c5c298a4adf254a044824d7e8f1c566ed72d4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.pixelshuffle#torch.nn.PixelShuffle&quot;&gt;&lt;code&gt;PixelShuffle&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.pixelshuffle#torch.nn.PixelShuffle&quot;&gt; &lt;code&gt;PixelShuffle&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="62b7addc0514a1405a79ca49e242813d820bc663" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.poissonnllloss#torch.nn.PoissonNLLLoss&quot;&gt;&lt;code&gt;PoissonNLLLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.poissonnllloss#torch.nn.PoissonNLLLoss&quot;&gt; &lt;code&gt;PoissonNLLLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="50b2df5a36c2945c6e24d5c71f419748722a3887" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.prelu#torch.nn.PReLU&quot;&gt;&lt;code&gt;PReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.prelu#torch.nn.PReLU&quot;&gt; &lt;code&gt;PReLU&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5978d8e05fcfe3f5b05baa41628058a1104f3a4e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.relu6#torch.nn.ReLU6&quot;&gt;&lt;code&gt;ReLU6&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.relu6#torch.nn.ReLU6&quot;&gt; &lt;code&gt;ReLU6&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7f52859f67be89a0431749df85025dfa79a6a4c5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.rrelu#torch.nn.RReLU&quot;&gt;&lt;code&gt;RReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.rrelu#torch.nn.RReLU&quot;&gt; &lt;code&gt;RReLU&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="852d4ca82259db7394eed56f5e5c7736dab64bcf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.selu#torch.nn.SELU&quot;&gt;&lt;code&gt;SELU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.selu#torch.nn.SELU&quot;&gt; &lt;code&gt;SELU&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="13f47034bf13462a634f77a02e2bd8afda50269b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.sigmoid#torch.nn.Sigmoid&quot;&gt;&lt;code&gt;Sigmoid&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.sigmoid#torch.nn.Sigmoid&quot;&gt; &lt;code&gt;Sigmoid&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="568ac6254f20261c85c9d016122513b35b9c681e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.silu#torch.nn.SiLU&quot;&gt;&lt;code&gt;SiLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.silu#torch.nn.SiLU&quot;&gt; &lt;code&gt;SiLU&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="dd919bcb7cd8684a3301f3776235810cef864477" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.smoothl1loss#torch.nn.SmoothL1Loss&quot;&gt;&lt;code&gt;SmoothL1Loss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.smoothl1loss#torch.nn.SmoothL1Loss&quot;&gt; &lt;code&gt;SmoothL1Loss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="aec2f6e607f94f542eec97b84c6a6b548899b489" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softmarginloss#torch.nn.SoftMarginLoss&quot;&gt;&lt;code&gt;SoftMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.softmarginloss#torch.nn.SoftMarginLoss&quot;&gt; &lt;code&gt;SoftMarginLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9c76fd9ca241b6dc4f7f601122680872738372dd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softmax#torch.nn.Softmax&quot;&gt;&lt;code&gt;Softmax&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.softmax#torch.nn.Softmax&quot;&gt; &lt;code&gt;Softmax&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6858b7405b4fb52e94900af334a9f8d7d36cdcef" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softmin#torch.nn.Softmin&quot;&gt;&lt;code&gt;Softmin&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.softmin#torch.nn.Softmin&quot;&gt; &lt;code&gt;Softmin&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3078ba39159561c5fdab61a5073beb5e6d358df8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softplus#torch.nn.Softplus&quot;&gt;&lt;code&gt;Softplus&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.softplus#torch.nn.Softplus&quot;&gt; &lt;code&gt;Softplus&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="169ff197b89985d58ad2ce1e9b54fb8b6c45231c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softshrink#torch.nn.Softshrink&quot;&gt;&lt;code&gt;Softshrink&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.softshrink#torch.nn.Softshrink&quot;&gt; &lt;code&gt;Softshrink&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="cdc172b1efd10ce5727c58366e9d3635597d6ae5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softsign#torch.nn.Softsign&quot;&gt;&lt;code&gt;Softsign&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.softsign#torch.nn.Softsign&quot;&gt; &lt;code&gt;Softsign&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="29958016ecc903cab7fa7360e164fabacfbf9cca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tanh#torch.nn.Tanh&quot;&gt;&lt;code&gt;Tanh&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.tanh#torch.nn.Tanh&quot;&gt; &lt;code&gt;Tanh&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a254e517f98f621d085febfde8c38a66e6d36e75" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tanhshrink#torch.nn.Tanhshrink&quot;&gt;&lt;code&gt;Tanhshrink&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.tanhshrink#torch.nn.Tanhshrink&quot;&gt; &lt;code&gt;Tanhshrink&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="35902a0c2cfa9e585fec0c3e3666693fec9dd4a9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.threshold#torch.nn.Threshold&quot;&gt;&lt;code&gt;Threshold&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;generated/torch.nn.threshold#torch.nn.Threshold&quot;&gt; &lt;code&gt;Threshold&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7ce6b129bc423f40aba54b0c2ce12c00beddaaaf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tripletmarginloss#torch.nn.TripletMarginLoss&quot;&gt;&lt;code&gt;TripletMarginLoss&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.tripletmarginloss#torch.nn.TripletMarginLoss&quot;&gt; &lt;code&gt;TripletMarginLoss&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e3fff4676883a1b11b9e2b38b57ad823ba8354c4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tripletmarginwithdistanceloss#torch.nn.TripletMarginWithDistanceLoss&quot;&gt;&lt;code&gt;TripletMarginWithDistanceLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.tripletmarginwithdistanceloss#torch.nn.TripletMarginWithDistanceLoss&quot;&gt; &lt;code&gt;TripletMarginWithDistanceLoss&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f6ce3d99c47d2a3129d44cea56b1d906e3f87b1a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.unfold#torch.nn.Unfold&quot;&gt;&lt;code&gt;torch.nn.Unfold&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;generated/torch.nn.unfold#torch.nn.Unfold&quot;&gt; &lt;code&gt;torch.nn.Unfold&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9788bdbd224f6b9c0bd977e955f549886daf1bcf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nonzero#torch.nonzero&quot;&gt;&lt;code&gt;torch.nonzero()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.nonzero#torch.nonzero&quot;&gt; &lt;code&gt;torch.nonzero()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2369f591ef4e6e16ec27b6f775edd376eeeaebaa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.norm#torch.norm&quot;&gt;&lt;code&gt;torch.norm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.norm#torch.norm&quot;&gt; &lt;code&gt;torch.norm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="56e7e5c8709e5c8e2f93b31866c6deb6c856253e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.not_equal#torch.not_equal&quot;&gt;&lt;code&gt;torch.not_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.not_equal#torch.not_equal&quot;&gt; &lt;code&gt;torch.not_equal()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5b9ce8340dc0317b49aade691cfc70799f4e8a00" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.numel#torch.numel&quot;&gt;&lt;code&gt;torch.numel()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.numel#torch.numel&quot;&gt; &lt;code&gt;torch.numel()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c4622b4f7c7ee0a0d13c8074a55141e4ff3229c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.orgqr#torch.orgqr&quot;&gt;&lt;code&gt;torch.orgqr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.orgqr#torch.orgqr&quot;&gt; &lt;code&gt;torch.orgqr()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d1edcc9509ea3d17ee6a647709ab6bf5071894e7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ormqr#torch.ormqr&quot;&gt;&lt;code&gt;torch.ormqr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.ormqr#torch.ormqr&quot;&gt; &lt;code&gt;torch.ormqr()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5ec140159032ba8d0085d266f44eb6db3c1a6341" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.outer#torch.outer&quot;&gt;&lt;code&gt;torch.outer()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.outer#torch.outer&quot;&gt; &lt;code&gt;torch.outer()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="87e19d2ae8154d45a564a41febb06c16a86567e9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.pinverse#torch.pinverse&quot;&gt;&lt;code&gt;torch.pinverse()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.pinverse#torch.pinverse&quot;&gt; &lt;code&gt;torch.pinverse()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7324cc21e0ad12841d92431a5e1818fae17672c9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.polygamma#torch.polygamma&quot;&gt;&lt;code&gt;torch.polygamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.polygamma#torch.polygamma&quot;&gt; &lt;code&gt;torch.polygamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="60b1f75853d0d1cd9cd5f0d2d089d7ee6125b0df" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.pow#torch.pow&quot;&gt;&lt;code&gt;torch.pow()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.pow#torch.pow&quot;&gt; &lt;code&gt;torch.pow()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3b8e7716730933beddce93ceeb9531967a7b8f33" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.prod#torch.prod&quot;&gt;&lt;code&gt;torch.prod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.prod#torch.prod&quot;&gt; &lt;code&gt;torch.prod()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b444d47f2174704778737bc705448fc08b1ec182" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.qr#torch.qr&quot;&gt;&lt;code&gt;torch.qr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.qr#torch.qr&quot;&gt; &lt;code&gt;torch.qr()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3c72437f61c64c17a7e0b66bf3ffe01e9afc41be" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.quantile#torch.quantile&quot;&gt;&lt;code&gt;torch.quantile()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.quantile#torch.quantile&quot;&gt; &lt;code&gt;torch.quantile()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="32fb1a354f8c66ea4a0848048572ffcf87e84e6f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rad2deg#torch.rad2deg&quot;&gt;&lt;code&gt;torch.rad2deg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.rad2deg#torch.rad2deg&quot;&gt; &lt;code&gt;torch.rad2deg()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bc4ab991cb3b46b0132c1ba3ff2b91cc0500fdf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.reciprocal#torch.reciprocal&quot;&gt;&lt;code&gt;torch.reciprocal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.reciprocal#torch.reciprocal&quot;&gt; &lt;code&gt;torch.reciprocal()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bfe7f00978e3613a7a554678c8956f4cb13251a3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.remainder#torch.remainder&quot;&gt;&lt;code&gt;torch.remainder()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.remainder#torch.remainder&quot;&gt; &lt;code&gt;torch.remainder()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="47bdb2571c3f363d76dceb91442f7ba7bc5f47c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.renorm#torch.renorm&quot;&gt;&lt;code&gt;torch.renorm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.renorm#torch.renorm&quot;&gt; &lt;code&gt;torch.renorm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="392bb5e2b00d5ad1124b111f4a08963b839d220b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.repeat_interleave#torch.repeat_interleave&quot;&gt;&lt;code&gt;torch.repeat_interleave()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.repeat_interleave#torch.repeat_interleave&quot;&gt; &lt;code&gt;torch.repeat_interleave()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5d77b448fa6a312c6a3af7702ed4407f9a96ffff" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt;&lt;code&gt;torch.reshape()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt; &lt;code&gt;torch.reshape()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="64c78ad14ae1246bf4029f36289f782990d17cc2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;torch.rfft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.rfft#torch.rfft&quot;&gt; &lt;code&gt;torch.rfft()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="edc899a0ae7fde4858b6a50cce775b0372b7653c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.roll#torch.roll&quot;&gt;&lt;code&gt;torch.roll()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.roll#torch.roll&quot;&gt; &lt;code&gt;torch.roll()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7815d433685f994781f0429772db78da8710e65c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rot90#torch.rot90&quot;&gt;&lt;code&gt;torch.rot90()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.rot90#torch.rot90&quot;&gt; &lt;code&gt;torch.rot90()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0947a333f5346f54b736a4223ca159d84235f8b5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.round#torch.round&quot;&gt;&lt;code&gt;torch.round()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.round#torch.round&quot;&gt; &lt;code&gt;torch.round()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f3f439c8c8008d964e1bcaba78d49e70b3cb5ee0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rsqrt#torch.rsqrt&quot;&gt;&lt;code&gt;torch.rsqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.rsqrt#torch.rsqrt&quot;&gt; &lt;code&gt;torch.rsqrt()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8f1a0ad46bcdd4a06fd3e3e914c5990d45babeaf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sigmoid#torch.sigmoid&quot;&gt;&lt;code&gt;torch.sigmoid()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.sigmoid#torch.sigmoid&quot;&gt; &lt;code&gt;torch.sigmoid()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d03b7125b49df42263bd14ed0db4426d77994382" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sign#torch.sign&quot;&gt;&lt;code&gt;torch.sign()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.sign#torch.sign&quot;&gt; &lt;code&gt;torch.sign()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0966c7edc653b2d2d7858c36c7f0e9e1d3aea910" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.signbit#torch.signbit&quot;&gt;&lt;code&gt;torch.signbit()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.signbit#torch.signbit&quot;&gt; &lt;code&gt;torch.signbit()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="241d2b853c66fa249e8726729a4ac39a10b2e697" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sin#torch.sin&quot;&gt;&lt;code&gt;torch.sin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.sin#torch.sin&quot;&gt; &lt;code&gt;torch.sin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="89a061ad1e618c20982077437a8a87568c9307c4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sinh#torch.sinh&quot;&gt;&lt;code&gt;torch.sinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.sinh#torch.sinh&quot;&gt; &lt;code&gt;torch.sinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a499f1efa1ffa37cdc83e453614c6da1a94917dc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.slogdet#torch.slogdet&quot;&gt;&lt;code&gt;torch.slogdet()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.slogdet#torch.slogdet&quot;&gt; &lt;code&gt;torch.slogdet()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b94d091f48db8b1ed862846a551122f839916ce3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.solve#torch.solve&quot;&gt;&lt;code&gt;torch.solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.solve#torch.solve&quot;&gt; &lt;code&gt;torch.solve()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a7969c92902441e24ef604b1fb7e01e1633b60a0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sort#torch.sort&quot;&gt;&lt;code&gt;torch.sort()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.sort#torch.sort&quot;&gt; &lt;code&gt;torch.sort()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ec7801816e74ec7a3d900fbf20c476c205206e5a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.split#torch.split&quot;&gt;&lt;code&gt;torch.split()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.split#torch.split&quot;&gt; &lt;code&gt;torch.split()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="39e5cf9eb721bd472b296db97e93a6ca162d7a75" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sqrt#torch.sqrt&quot;&gt;&lt;code&gt;torch.sqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.sqrt#torch.sqrt&quot;&gt; &lt;code&gt;torch.sqrt()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1e20283dbffe987cb9aa4c639a5d348b483031bd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.square#torch.square&quot;&gt;&lt;code&gt;torch.square()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.square#torch.square&quot;&gt; &lt;code&gt;torch.square()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4537022c26f4e739fc2002bc8948554d909b1ec0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b79329d6e4ba347ba65f0ebd150eb9025549e650" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.std#torch.std&quot;&gt;&lt;code&gt;torch.std()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.std#torch.std&quot;&gt; &lt;code&gt;torch.std()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8072306c8cd74c97cd95675a2ff3d6b6cdfaa602" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.stft#torch.stft&quot;&gt;&lt;code&gt;torch.stft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.stft#torch.stft&quot;&gt; &lt;code&gt;torch.stft()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="18ce7dc42c983592bcaecd4a3fc5855fdfc8d9ab" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sub#torch.sub&quot;&gt;&lt;code&gt;torch.sub()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.sub#torch.sub&quot;&gt; &lt;code&gt;torch.sub()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="af5eb1862625e7193f970d356cf7c80cbe6b8474" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.subtract#torch.subtract&quot;&gt;&lt;code&gt;torch.subtract()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.subtract#torch.subtract&quot;&gt; &lt;code&gt;torch.subtract()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="66057444812a0310739be9c55bf3b8e63f04f931" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sum#torch.sum&quot;&gt;&lt;code&gt;torch.sum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.sum#torch.sum&quot;&gt; &lt;code&gt;torch.sum()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bcf75355dab89c53d2da96f041aaf2f0acf7b6d2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.svd#torch.svd&quot;&gt;&lt;code&gt;torch.svd()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.svd#torch.svd&quot;&gt; &lt;code&gt;torch.svd()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dfa85538b9855279675cb6cbe04a9c51aa801f91" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.symeig#torch.symeig&quot;&gt;&lt;code&gt;torch.symeig()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.symeig#torch.symeig&quot;&gt; &lt;code&gt;torch.symeig()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4c1d54d9efffe6c88816f66acc03d8d8dfbcb987" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.t#torch.t&quot;&gt;&lt;code&gt;torch.t()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.t#torch.t&quot;&gt; &lt;code&gt;torch.t()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ed0de6f96e833610021fd49c3f7874b4e1addb21" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.take#torch.take&quot;&gt;&lt;code&gt;torch.take()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.take#torch.take&quot;&gt; &lt;code&gt;torch.take()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="99e605d53360cc080a69f4f5d980d95d7aa826ad" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.tan#torch.tan&quot;&gt;&lt;code&gt;torch.tan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.tan#torch.tan&quot;&gt; &lt;code&gt;torch.tan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e96f7967fc1e38f0303eea058aa618aef4fac2ef" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.tanh#torch.tanh&quot;&gt;&lt;code&gt;torch.tanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.tanh#torch.tanh&quot;&gt; &lt;code&gt;torch.tanh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="777022f41fcab6d3a8b8bc1104eab2f51f7b9171" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.topk#torch.topk&quot;&gt;&lt;code&gt;torch.topk()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.topk#torch.topk&quot;&gt; &lt;code&gt;torch.topk()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c49ff88894110989a51d17dc1b799b6a1d234266" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.trace#torch.trace&quot;&gt;&lt;code&gt;torch.trace()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.trace#torch.trace&quot;&gt; &lt;code&gt;torch.trace()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4dd4e10bc975adcbd79cbfba2536b23c1ca9fe5d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.transpose#torch.transpose&quot;&gt;&lt;code&gt;torch.transpose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.transpose#torch.transpose&quot;&gt; &lt;code&gt;torch.transpose()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2bade69272d3a8a621109ac0c3cebe47f8592ccf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.triangular_solve#torch.triangular_solve&quot;&gt;&lt;code&gt;torch.triangular_solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.triangular_solve#torch.triangular_solve&quot;&gt; &lt;code&gt;torch.triangular_solve()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f87e190394989d10b94b8ed6f12d07725726bba2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.tril#torch.tril&quot;&gt;&lt;code&gt;torch.tril()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.tril#torch.tril&quot;&gt; &lt;code&gt;torch.tril()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d172b311d0d769ff2c0ed9dd6ac700f12b7519eb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.triu#torch.triu&quot;&gt;&lt;code&gt;torch.triu()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.triu#torch.triu&quot;&gt; &lt;code&gt;torch.triu()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b7d12fec787dfa2633076e0c7bc951ad201eab36" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.true_divide#torch.true_divide&quot;&gt;&lt;code&gt;torch.true_divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.true_divide#torch.true_divide&quot;&gt; &lt;code&gt;torch.true_divide()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2e33491c2346b21653dcb58517e74623e00bc1cf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.trunc#torch.trunc&quot;&gt;&lt;code&gt;torch.trunc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.trunc#torch.trunc&quot;&gt; &lt;code&gt;torch.trunc()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1b23641ab143374e2f32432ecf86e4e46888de3d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unbind#torch.unbind&quot;&gt;&lt;code&gt;torch.unbind()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.unbind#torch.unbind&quot;&gt; &lt;code&gt;torch.unbind()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="19b180c6110b55208ea1c8b65bc50f246a5ff942" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unique#torch.unique&quot;&gt;&lt;code&gt;torch.unique()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.unique#torch.unique&quot;&gt; &lt;code&gt;torch.unique()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="54a43b1289dd07e0a5b73c772257b5c512989147" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unique_consecutive#torch.unique_consecutive&quot;&gt;&lt;code&gt;torch.unique_consecutive()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.unique_consecutive#torch.unique_consecutive&quot;&gt; &lt;code&gt;torch.unique_consecutive()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bd1faf4696524ab565ebe96977ff8f6d3996368c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unsqueeze#torch.unsqueeze&quot;&gt;&lt;code&gt;torch.unsqueeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.unsqueeze#torch.unsqueeze&quot;&gt; &lt;code&gt;torch.unsqueeze()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f4056678fae5769fa6b3f1cdb6156ce7a2397a43" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.var#torch.var&quot;&gt;&lt;code&gt;torch.var()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">见&lt;a href=&quot;generated/torch.var#torch.var&quot;&gt; &lt;code&gt;torch.var()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="916b508c9cb38c716d16bc8c991ff57f921295f9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.vdot#torch.vdot&quot;&gt;&lt;code&gt;torch.vdot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;generated/torch.vdot#torch.vdot&quot;&gt; &lt;code&gt;torch.vdot()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3b5ecc20fdf55d0eb2ca422795c8c3780a985baa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1602.07868&quot;&gt;https://arxiv.org/abs/1602.07868&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;https://arxiv.org/abs/1602.07868&quot;&gt;https://arxiv.org/abs/1602.07868&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0b9412e01247af2b574511c1ccac61f158442f0f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1606.08415&quot;&gt;Gaussian Error Linear Units (GELUs)&lt;/a&gt; where the SiLU (Sigmoid Linear Unit) was originally coined, and see &lt;a href=&quot;https://arxiv.org/abs/1702.03118&quot;&gt;Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1710.05941v1&quot;&gt;Swish: a Self-Gated Activation Function&lt;/a&gt; where the SiLU was experimented with later.</source>
          <target state="translated">请参阅&lt;a href=&quot;https://arxiv.org/abs/1606.08415&quot;&gt;高斯误差线性单位（GELUs）&lt;/a&gt;，其中最初创建了SiLU（Sigmoid线性单位），请参阅&lt;a href=&quot;https://arxiv.org/abs/1702.03118&quot;&gt;在增强学习&lt;/a&gt;和&lt;a href=&quot;https://arxiv.org/abs/1710.05941v1&quot;&gt;Swish中&lt;/a&gt;用于神经网络功能逼近的Sigmoid加权线性单位：自门控激活函数，其中对SiLU进行了实验之后。</target>
        </trans-unit>
        <trans-unit id="14f3ddc89b63e2e7ace4c43afa51eb155bb8b073" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1606.08415&quot;&gt;Gaussian Error Linear Units (GELUs)&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;https://arxiv.org/abs/1606.08415&quot;&gt;高斯误差线性单位（GELUs）&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bd1bf1046086c393add977bf1d0da3c9f0372ead" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1612.08083&quot;&gt;Language Modeling with Gated Convolutional Networks&lt;/a&gt;.</source>
          <target state="translated">请参见&lt;a href=&quot;https://arxiv.org/abs/1612.08083&quot;&gt;使用门控卷积网络进行语言建模&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="db07a2a989e739b25605b6e4d0716eb84e5dae0a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1802.05957&quot;&gt;Spectral Normalization for Generative Adversarial Networks&lt;/a&gt; .</source>
          <target state="translated">请参见&lt;a href=&quot;https://arxiv.org/abs/1802.05957&quot;&gt;生成对抗网络的谱归一化&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5a6dff82856c75a203e206e75be968948b922059" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/test/test_cpp_extensions.py&quot;&gt;the tests&lt;/a&gt; for good examples of using this function.</source>
          <target state="translated">有关使用此功能的良好示例，请参见&lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/test/test_cpp_extensions.py&quot;&gt;测试&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="04429ddfa22962a6b5135b0b2014ba16416b5a3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-memory-management&quot;&gt;Memory management&lt;/a&gt; for more details about GPU memory management.</source>
          <target state="translated">有关GPU内存管理的更多详细信息，请参阅&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-memory-management&quot;&gt;内存&lt;/a&gt;管理。</target>
        </trans-unit>
        <trans-unit id="17c133c8d2a0e8bbfe7a62feb9aac8d574c244ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://software.intel.com/en-us/node/521004&quot;&gt;LAPACK documentation for geqrf&lt;/a&gt; for further details.</source>
          <target state="translated">有关更多详细信息，请参见&lt;a href=&quot;https://software.intel.com/en-us/node/521004&quot;&gt;geqrf的LAPACK文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="21fd55c2238e14aca1f89595f1ab24153a2317e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;jit_unsupported#jit-unsupported&quot;&gt;TorchScript Unsupported Pytorch Constructs&lt;/a&gt; for a list of unsupported PyTorch functions and modules.</source>
          <target state="translated">有关&lt;a href=&quot;jit_unsupported#jit-unsupported&quot;&gt;不&lt;/a&gt;支持的PyTorch函数和模块的列表，请参见TorchScript不支持的Pytorch构造。</target>
        </trans-unit>
        <trans-unit id="867beb050ab38870ddc832eb3ecef0bd481ecc8d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;Named Tensors operator coverage&lt;/a&gt; for a full list of the supported torch and tensor operations. We do not yet support the following that is not covered by the link:</source>
          <target state="translated">有关受支持的割炬和张量操作的完整列表，请参见&amp;ldquo;&lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;命名张量&amp;rdquo;操作员范围&lt;/a&gt;。我们尚不支持以下链接未涵盖的内容：</target>
        </trans-unit>
        <trans-unit id="1babcf3a21d12db47391affdb4c96e1dd62be4d6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;nn.functional#torch.nn.functional.hardshrink&quot;&gt;&lt;code&gt;torch.nn.functional.hardshrink()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;nn.functional#torch.nn.functional.hardshrink&quot;&gt; &lt;code&gt;torch.nn.functional.hardshrink()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1db234df13e3a4d61ca75e6b5a3105bfac530a9e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;nn.functional#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt;&lt;/a&gt; for implementation details.</source>
          <target state="translated">有关实现的详细信息，请参见&lt;a href=&quot;nn.functional#torch.nn.functional.interpolate&quot;&gt; &lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b45b38436f82adea06622961c718c298fe2b5459" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.jit.save#torch.jit.save&quot;&gt;&lt;code&gt;torch.jit.save&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;torch.jit.save#torch.jit.save&quot;&gt; &lt;code&gt;torch.jit.save&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="906e8a62d5d0063bfb8aed76d72645065a77e807" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.jit.trace#torch.jit.trace&quot;&gt;&lt;code&gt;torch.jit.trace&lt;/code&gt;&lt;/a&gt; for more information on tracing.</source>
          <target state="translated">有关&lt;a href=&quot;torch.jit.trace#torch.jit.trace&quot;&gt; &lt;code&gt;torch.jit.trace&lt;/code&gt; &lt;/a&gt;的更多信息，请参见torch.jit.trace。</target>
        </trans-unit>
        <trans-unit id="777f4ad759227cc1de547b64fab825a56ffc273e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.maximum#torch.maximum&quot;&gt;&lt;code&gt;torch.maximum()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;torch.maximum#torch.maximum&quot;&gt; &lt;code&gt;torch.maximum()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ee5434d3ddff1ae2016c291b61569fbc56d53430" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.minimum#torch.minimum&quot;&gt;&lt;code&gt;torch.minimum()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;torch.minimum#torch.minimum&quot;&gt; &lt;code&gt;torch.minimum()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0be965581dce920964b073625fcdd3abb3431e9c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt; for details on conjugate symmetry.</source>
          <target state="translated">有关共轭对称性的详细信息，请参见&lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="72e0d158f46758840a4164068e9e82210cb8c350" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;AdaptiveAvgPool2d&lt;/code&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见 &lt;code&gt;AdaptiveAvgPool2d&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9940c6d70818d17787385090e557dd2c785cc737" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;AvgPool2d&lt;/code&gt; for details and output shape.</source>
          <target state="translated">有关详细信息和输出形状，请参见 &lt;code&gt;AvgPool2d&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f13aa780c2216fa1121984d0068e8f5c43a24fb7" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;FeatureAlphaDropout&lt;/code&gt; for details.</source>
          <target state="translated">有关详细信息，请参见 &lt;code&gt;FeatureAlphaDropout&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d51e9069af161e98bae58fb7454beeacc6c7dd49" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;MaxPool2d&lt;/code&gt; for details.</source>
          <target state="translated">有关详细信息，请参见 &lt;code&gt;MaxPool2d&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fe5ba62143f025d44dc65bfc7175cc40e26dc5a1" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;detect_anomaly&lt;/code&gt; above for details of the anomaly detection behaviour.</source>
          <target state="translated">有关异常检测行为的详细信息，请参见上面的 &lt;code&gt;detect_anomaly&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f8c535644744dd427c75006813886670b5ecbefc" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;torch.sgn()&lt;/code&gt;</source>
          <target state="translated">见 &lt;code&gt;torch.sgn()&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="translated">另见</target>
        </trans-unit>
        <trans-unit id="cf84761b907cce8756615b37c03c0de477c6797c" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.bernoulli&quot;&gt;&lt;code&gt;bernoulli()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.bernoulli#torch.bernoulli&quot;&gt;&lt;code&gt;torch.bernoulli()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">另请参见&lt;a href=&quot;#torch.Tensor.bernoulli&quot;&gt; &lt;code&gt;bernoulli()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.bernoulli#torch.bernoulli&quot;&gt; &lt;code&gt;torch.bernoulli()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6f81c151298858c7ededc5c4b44ed15fc0e739e1" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.dense_dim&quot;&gt;&lt;code&gt;Tensor.dense_dim()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">另请参见&lt;a href=&quot;#torch.Tensor.dense_dim&quot;&gt; &lt;code&gt;Tensor.dense_dim()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a95f7e982847b8fe1f244ef9a89f823deb4ea379" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.indices&quot;&gt;&lt;code&gt;Tensor.indices()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">另请参见&lt;a href=&quot;#torch.Tensor.indices&quot;&gt; &lt;code&gt;Tensor.indices()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5404c54976e3ca510ce12e37b5127349f618c641" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.sparse_dim&quot;&gt;&lt;code&gt;Tensor.sparse_dim()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">另请参见&lt;a href=&quot;#torch.Tensor.sparse_dim&quot;&gt; &lt;code&gt;Tensor.sparse_dim()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="54ff5675a07df4058683c73c3542b2001d40f9cf" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.values&quot;&gt;&lt;code&gt;Tensor.values()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">另请参见&lt;a href=&quot;#torch.Tensor.values&quot;&gt; &lt;code&gt;Tensor.values()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d7cb8cf286ca9cd05efe1662c9601fe839849b83" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;https://en.wikipedia.org/wiki/One-hot&quot;&gt;One-hot on Wikipedia&lt;/a&gt; .</source>
          <target state="translated">另请参阅&lt;a href=&quot;https://en.wikipedia.org/wiki/One-hot&quot;&gt;Wikipedia上的One-hot&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1b57d4272104e4b0612e05446cf15e6f3bd6c435" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;torch.nn.tripletmarginloss#torch.nn.TripletMarginLoss&quot;&gt;&lt;code&gt;TripletMarginLoss&lt;/code&gt;&lt;/a&gt;, which computes the triplet loss for input tensors using the</source>
          <target state="translated">另请参见&lt;a href=&quot;torch.nn.tripletmarginloss#torch.nn.TripletMarginLoss&quot;&gt; &lt;code&gt;TripletMarginLoss&lt;/code&gt; &lt;/a&gt;，它使用来计算输入张量的三重态损失。</target>
        </trans-unit>
        <trans-unit id="338b9a67a86b6e51ea1d6e3591262fbb1f90e795" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;torch.nn.tripletmarginwithdistanceloss#torch.nn.TripletMarginWithDistanceLoss&quot;&gt;&lt;code&gt;TripletMarginWithDistanceLoss&lt;/code&gt;&lt;/a&gt;, which computes the triplet margin loss for input tensors using a custom distance function.</source>
          <target state="translated">另请参见&lt;a href=&quot;torch.nn.tripletmarginwithdistanceloss#torch.nn.TripletMarginWithDistanceLoss&quot;&gt; &lt;code&gt;TripletMarginWithDistanceLoss&lt;/code&gt; &lt;/a&gt;，它使用自定义距离函数计算输入张量的三重边距损失。</target>
        </trans-unit>
        <trans-unit id="be5e1942829e9e077f50ab2375a2b7c88388f6d1" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;torch.nonzero#torch.nonzero&quot;&gt;&lt;code&gt;torch.nonzero()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">另请参见&lt;a href=&quot;torch.nonzero#torch.nonzero&quot;&gt; &lt;code&gt;torch.nonzero()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3944875c16171bc90184fc5b9486bebdfeaab438" translate="yes" xml:space="preserve">
          <source>See also: &lt;a href=&quot;../distributed#distributed-basics&quot;&gt;Basics&lt;/a&gt; and &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-nn-ddp-instead&quot;&gt;Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel&lt;/a&gt;. The same constraints on input as in &lt;a href=&quot;torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel&lt;/code&gt;&lt;/a&gt; apply.</source>
          <target state="translated">另请参阅：&lt;a href=&quot;../distributed#distributed-basics&quot;&gt;基础知识，&lt;/a&gt;并&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-nn-ddp-instead&quot;&gt;使用nn.parallel.DistributedDataParallel而不是multiprocessing或nn.DataParallel&lt;/a&gt;。输入的约束与&lt;a href=&quot;torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt; &lt;code&gt;torch.nn.DataParallel&lt;/code&gt; 中的&lt;/a&gt;约束相同。</target>
        </trans-unit>
        <trans-unit id="57828c6fcf489090610d5b402c9d6f3f4fda9c73" translate="yes" xml:space="preserve">
          <source>See also: &lt;a href=&quot;generated/torch.multinomial#torch.multinomial&quot;&gt;&lt;code&gt;torch.multinomial()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">另请参阅：&lt;a href=&quot;generated/torch.multinomial#torch.multinomial&quot;&gt; &lt;code&gt;torch.multinomial()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7eb108ecfdf49da8d98dacb8dde1315fef208724" translate="yes" xml:space="preserve">
          <source>See also: &lt;code&gt;saving-loading-tensors&lt;/code&gt;</source>
          <target state="translated">另请参阅： &lt;code&gt;saving-loading-tensors&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e8334cf7461d5baada537c0ffa23cfd90187f5e4" translate="yes" xml:space="preserve">
          <source>See also: &lt;code&gt;torch.distributions.Categorical()&lt;/code&gt; for specifications of &lt;a href=&quot;#torch.distributions.one_hot_categorical.OneHotCategorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributions.one_hot_categorical.OneHotCategorical.logits&quot;&gt;&lt;code&gt;logits&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参见： &lt;code&gt;torch.distributions.Categorical()&lt;/code&gt; 为规范&lt;a href=&quot;#torch.distributions.one_hot_categorical.OneHotCategorical.probs&quot;&gt; &lt;code&gt;probs&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.distributions.one_hot_categorical.OneHotCategorical.logits&quot;&gt; &lt;code&gt;logits&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6eaee759e08dae96ac3e7296ea90bee9503c008c" translate="yes" xml:space="preserve">
          <source>See below for examples.</source>
          <target state="translated">请看下面的例子。</target>
        </trans-unit>
        <trans-unit id="9f51e613b80a9cad0a8955652d10c4dc58a70617" translate="yes" xml:space="preserve">
          <source>See below for more details on the two behaviors.</source>
          <target state="translated">关于这两种行为的详细情况请看下文。</target>
        </trans-unit>
        <trans-unit id="4ddb6a37aae13cb0b24c2efb3a4dab06796b836f" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_8.html&quot;&gt;cuDNN 8 Release Notes&lt;/a&gt; for more information.</source>
          <target state="translated">有关更多信息，请参见&lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_8.html&quot;&gt;cuDNN 8发行说明&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8eeaf16a4b3b3eff601df5e984656d59eacad769" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-examples&quot;&gt;Automatic Mixed Precision examples&lt;/a&gt; for usage (along with gradient scaling) in more complex scenarios (e.g., gradient penalty, multiple models/losses, custom autograd functions).</source>
          <target state="translated">请参阅&amp;ldquo;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-examples&quot;&gt;自动混合精度&amp;rdquo;示例&lt;/a&gt;，以了解在更复杂的场景（例如，梯度损失，多种模型/损失，自定义自动梯度函数）中的用法（以及梯度缩放）。</target>
        </trans-unit>
        <trans-unit id="f064248b1c5b1747c5f3357f6ac931ae0fbb78e9" translate="yes" xml:space="preserve">
          <source>See the Note on extending the autograd engine for more details on how to use this class: &lt;a href=&quot;https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd&quot;&gt;https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd&lt;/a&gt;</source>
          <target state="translated">有关如何使用此类的更多详细信息，请参见有关扩展autograd引擎的注释：&lt;a href=&quot;https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd&quot;&gt;https&lt;/a&gt; ://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd</target>
        </trans-unit>
        <trans-unit id="a3f25968fb38aca8940c3474e1a28527b6999cfd" translate="yes" xml:space="preserve">
          <source>See the example below.</source>
          <target state="translated">请看下面的例子。</target>
        </trans-unit>
        <trans-unit id="81019ba57a197ef19b2f977fef5caa9379d67190" translate="yes" xml:space="preserve">
          <source>See: &lt;a href=&quot;https://arxiv.org/pdf/1505.00853.pdf&quot;&gt;https://arxiv.org/pdf/1505.00853.pdf&lt;/a&gt;</source>
          <target state="translated">参见：&lt;a href=&quot;https://arxiv.org/pdf/1505.00853.pdf&quot;&gt;https&lt;/a&gt; : //arxiv.org/pdf/1505.00853.pdf</target>
        </trans-unit>
        <trans-unit id="a0155b122fd91b7c13b804a1099ae2d088140dfb" translate="yes" xml:space="preserve">
          <source>Semantic Segmentation</source>
          <target state="translated">语义分割</target>
        </trans-unit>
        <trans-unit id="c75579406c3ae78822e3ffcc9e4cc60ff251dd2d" translate="yes" xml:space="preserve">
          <source>Sender rank -1, if not part of the group</source>
          <target state="translated">发件人等级-1,如果不属于该组。</target>
        </trans-unit>
        <trans-unit id="17a32bd6e1dfb35f3140b1db64642f975712c5d9" translate="yes" xml:space="preserve">
          <source>Sends a tensor asynchronously.</source>
          <target state="translated">异步发送张量。</target>
        </trans-unit>
        <trans-unit id="4c841aadee573fffcf4298f38f9bffb444801dab" translate="yes" xml:space="preserve">
          <source>Sends a tensor synchronously.</source>
          <target state="translated">同步发送张量。</target>
        </trans-unit>
        <trans-unit id="0edc0112db95758e96c3f9613104687a95e00afc" translate="yes" xml:space="preserve">
          <source>Sequential</source>
          <target state="translated">Sequential</target>
        </trans-unit>
        <trans-unit id="e7d74cd050fb66a4fa3c59e667aee9ae0ee10227" translate="yes" xml:space="preserve">
          <source>Sequential models execute a list of modules/functions in order (sequentially). Therefore, we can divide such a model in various segments and checkpoint each segment. All segments except the last will run in &lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt;&lt;code&gt;torch.no_grad()&lt;/code&gt;&lt;/a&gt; manner, i.e., not storing the intermediate activations. The inputs of each checkpointed segment will be saved for re-running the segment in the backward pass.</source>
          <target state="translated">顺序模型按顺序（顺序）执行模块/功能列表。因此，我们可以将这样的模型划分为不同的段，并在每个段上检查点。除最后一个段外，所有段都将以&lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt; &lt;code&gt;torch.no_grad()&lt;/code&gt; &lt;/a&gt;方式运行，即不存储中间激活。将保存每个检查点线段的输入，以便在后向传递中重新运行该线段。</target>
        </trans-unit>
        <trans-unit id="89282363da677473acdbf45f0831bde9f4d3b6c4" translate="yes" xml:space="preserve">
          <source>Serialization</source>
          <target state="translated">Serialization</target>
        </trans-unit>
        <trans-unit id="086bcd13e430cfb2d3607712e21df8c908da9204" translate="yes" xml:space="preserve">
          <source>Serialization semantics</source>
          <target state="translated">序列化语义</target>
        </trans-unit>
        <trans-unit id="49d31523ecd7343c1a446e5158bebd854caf4035" translate="yes" xml:space="preserve">
          <source>Set options for printing.</source>
          <target state="translated">设置打印的选项。</target>
        </trans-unit>
        <trans-unit id="da649b091863ea75252b37be60743b57866836c1" translate="yes" xml:space="preserve">
          <source>Set options for printing. Items shamelessly taken from NumPy</source>
          <target state="translated">设置打印的选项。项目无耻地从NumPy中获取。</target>
        </trans-unit>
        <trans-unit id="7f8fce6ab85b47c6992c9a753d4c65a4df880bed" translate="yes" xml:space="preserve">
          <source>Set the extra representation of the module</source>
          <target state="translated">设置模块的额外表现形式</target>
        </trans-unit>
        <trans-unit id="dd4c737e6e6f369967a01656e378372e2b057847" translate="yes" xml:space="preserve">
          <source>Set the learning rate of each parameter group using a cosine annealing schedule, where</source>
          <target state="translated">利用余弦退火计划设置各参数组的学习率,其中</target>
        </trans-unit>
        <trans-unit id="fb1d30c28b5d6e9bf862978770dcfc4108953994" translate="yes" xml:space="preserve">
          <source>Set the result for this &lt;code&gt;Future&lt;/code&gt;, which will mark this &lt;code&gt;Future&lt;/code&gt; as completed and trigger all attached callbacks. Note that a &lt;code&gt;Future&lt;/code&gt; cannot be marked completed twice.</source>
          <target state="translated">设置此 &lt;code&gt;Future&lt;/code&gt; 的结果，这会将此 &lt;code&gt;Future&lt;/code&gt; 标记为已完成并触发所有附加的回调。请注意， &lt;code&gt;Future&lt;/code&gt; 不能标记为已完成两次。</target>
        </trans-unit>
        <trans-unit id="2d01a2557701031cde3d1b8c62a166dbe983b48e" translate="yes" xml:space="preserve">
          <source>Set your device to local rank using either</source>
          <target state="translated">使用以下两种方法将您的设备设置为本地等级</target>
        </trans-unit>
        <trans-unit id="8f9ed8e87d1736694183486ee8b4775a705262ed" translate="yes" xml:space="preserve">
          <source>Sets gradients of all model parameters to zero. See similar function under &lt;a href=&quot;../optim#torch.optim.Optimizer&quot;&gt;&lt;code&gt;torch.optim.Optimizer&lt;/code&gt;&lt;/a&gt; for more context.</source>
          <target state="translated">将所有模型参数的梯度设置为零。有关更多上下文，请参见&lt;a href=&quot;../optim#torch.optim.Optimizer&quot;&gt; &lt;code&gt;torch.optim.Optimizer&lt;/code&gt; &lt;/a&gt;下的类似功能。</target>
        </trans-unit>
        <trans-unit id="d404cad224614646e396f2671954c99061ff4ca5" translate="yes" xml:space="preserve">
          <source>Sets the Generator state.</source>
          <target state="translated">设置发电机的状态。</target>
        </trans-unit>
        <trans-unit id="9111f7925b4f9859890d95207d49fc1a4c287f5d" translate="yes" xml:space="preserve">
          <source>Sets the current device.</source>
          <target state="translated">设置当前设备。</target>
        </trans-unit>
        <trans-unit id="599ca5f4725e8b4ae5c8a8c258bedbaa0ae4f7ca" translate="yes" xml:space="preserve">
          <source>Sets the default &lt;code&gt;torch.Tensor&lt;/code&gt; type to floating point tensor type &lt;code&gt;t&lt;/code&gt;.</source>
          <target state="translated">设置默认的 &lt;code&gt;torch.Tensor&lt;/code&gt; 。张量类型为浮点张量类型 &lt;code&gt;t&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="017579c4ce17f464667bcc54bc1a6e8591f854a8" translate="yes" xml:space="preserve">
          <source>Sets the default &lt;code&gt;torch.Tensor&lt;/code&gt; type to floating point tensor type &lt;code&gt;t&lt;/code&gt;. This type will also be used as default floating point type for type inference in &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">设置默认的 &lt;code&gt;torch.Tensor&lt;/code&gt; 。张量类型为浮点张量类型 &lt;code&gt;t&lt;/code&gt; 。此类型还将用作&lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;torch.tensor()&lt;/code&gt; 中&lt;/a&gt;类型推断的默认浮点类型。</target>
        </trans-unit>
        <trans-unit id="0194ba9213175f7befa0a141d39b82b09c76ae20" translate="yes" xml:space="preserve">
          <source>Sets the default floating point dtype to &lt;code&gt;d&lt;/code&gt;.</source>
          <target state="translated">将默认浮点dtype设置为 &lt;code&gt;d&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="552e257ff3a4ad554910ae569da22027db68a506" translate="yes" xml:space="preserve">
          <source>Sets the default floating point dtype to &lt;code&gt;d&lt;/code&gt;. This dtype is:</source>
          <target state="translated">将默认浮点dtype设置为 &lt;code&gt;d&lt;/code&gt; 。此dtype为：</target>
        </trans-unit>
        <trans-unit id="135e0facc67febcd6e6046179fa5ad6d5c7dfcb0" translate="yes" xml:space="preserve">
          <source>Sets the gradients of all optimized &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; s to zero.</source>
          <target state="translated">将所有优化的&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;的梯度设置为零。</target>
        </trans-unit>
        <trans-unit id="00a00aa79d426ae2b3c0c06d23ade776e4f0d645" translate="yes" xml:space="preserve">
          <source>Sets the learning rate of each parameter group according to cyclical learning rate policy (CLR). The policy cycles the learning rate between two boundaries with a constant frequency, as detailed in the paper &lt;a href=&quot;https://arxiv.org/abs/1506.01186&quot;&gt;Cyclical Learning Rates for Training Neural Networks&lt;/a&gt;. The distance between the two boundaries can be scaled on a per-iteration or per-cycle basis.</source>
          <target state="translated">根据周期性学习率策略（CLR）设置每个参数组的学习率。该策略以恒定的频率在两个边界之间循环学习率，如论文&lt;a href=&quot;https://arxiv.org/abs/1506.01186&quot;&gt;&amp;ldquo;训练神经网络的循环学习率&amp;rdquo;&lt;/a&gt;中所述。两个边界之间的距离可以在每个迭代或每个周期的基础上进行缩放。</target>
        </trans-unit>
        <trans-unit id="665434656af0e1a615df6cc92c6ecf52d30fbd49" translate="yes" xml:space="preserve">
          <source>Sets the learning rate of each parameter group according to the 1cycle learning rate policy. The 1cycle policy anneals the learning rate from an initial learning rate to some maximum learning rate and then from that maximum learning rate to some minimum learning rate much lower than the initial learning rate. This policy was initially described in the paper &lt;a href=&quot;https://arxiv.org/abs/1708.07120&quot;&gt;Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates&lt;/a&gt;.</source>
          <target state="translated">根据1cycle学习率策略设置每个参数组的学习率。1周期策略将学习速率从初始学习速率退火到某个最大学习速率，然后从该最大学习速率退火到某个远低于初始学习速率的最小学习速率。该策略最初在论文《&lt;a href=&quot;https://arxiv.org/abs/1708.07120&quot;&gt;超融合：使用大学习率的神经网络的快速训练》&lt;/a&gt;中进行了描述。</target>
        </trans-unit>
        <trans-unit id="03d13473984ea489da3481909e502cdf0dc06a49" translate="yes" xml:space="preserve">
          <source>Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr.</source>
          <target state="translated">将每个参数组的学习率设置为初始lr乘以给定函数。当last_epoch=-1时,设置初始lr为lr。</target>
        </trans-unit>
        <trans-unit id="03f12972542800069e5267c12cb43edb6f65202d" translate="yes" xml:space="preserve">
          <source>Sets the module in evaluation mode.</source>
          <target state="translated">将该模块设置为评估模式。</target>
        </trans-unit>
        <trans-unit id="bf6241075b09cc953edd0e9568c4cd5f5c88fe95" translate="yes" xml:space="preserve">
          <source>Sets the module in training mode.</source>
          <target state="translated">将该模块设置为训练模式。</target>
        </trans-unit>
        <trans-unit id="850e5cb239a66b02ec6c1c59e0300349c7abf33d" translate="yes" xml:space="preserve">
          <source>Sets the number of threads used for interop parallelism (e.g.</source>
          <target state="translated">设置用于互操作并行的线程数(如</target>
        </trans-unit>
        <trans-unit id="be8644f2249be95fe3ec1aaa39ce51051699b0f6" translate="yes" xml:space="preserve">
          <source>Sets the number of threads used for interop parallelism (e.g. in JIT interpreter) on CPU.</source>
          <target state="translated">设置CPU上用于互操作并行的线程数(如在JIT解释器中)。</target>
        </trans-unit>
        <trans-unit id="cf85722cd322795a8d83eb653874b27e33c5355c" translate="yes" xml:space="preserve">
          <source>Sets the number of threads used for intraop parallelism on CPU.</source>
          <target state="translated">设置CPU上用于操作内并行的线程数。</target>
        </trans-unit>
        <trans-unit id="9d725baae9b356dc9c5ed1aec81420b19033493b" translate="yes" xml:space="preserve">
          <source>Sets the random number generator state of all devices.</source>
          <target state="translated">设置所有设备的随机数发生器状态。</target>
        </trans-unit>
        <trans-unit id="0d3f74d91be66fe1c0dcf86ea77ec056f2a793db" translate="yes" xml:space="preserve">
          <source>Sets the random number generator state of the specified GPU.</source>
          <target state="translated">设置指定GPU的随机数发生器状态。</target>
        </trans-unit>
        <trans-unit id="97ab6a55939177c2033f769ee905c9c0419e2d5d" translate="yes" xml:space="preserve">
          <source>Sets the random number generator state.</source>
          <target state="translated">设置随机数发生器状态。</target>
        </trans-unit>
        <trans-unit id="ba56ea18f53dc2a28624660de79c9c1b82cce789" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers for the current GPU. It&amp;rsquo;s safe to call this function if CUDA is not available; in that case, it is silently ignored.</source>
          <target state="translated">设置用于为当前GPU生成随机数的种子。如果CUDA不可用，则可以安全地调用此函数。在这种情况下，它会被静默忽略。</target>
        </trans-unit>
        <trans-unit id="673ea6e5e56cccf50f89c4dcf1d57a9a886467da" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers on all GPUs. It&amp;rsquo;s safe to call this function if CUDA is not available; in that case, it is silently ignored.</source>
          <target state="translated">设置用于在所有GPU上生成随机数的种子。如果CUDA不可用，则可以安全地调用此函数。在这种情况下，它会被静默忽略。</target>
        </trans-unit>
        <trans-unit id="45382a699be8898ec2b2618f2defa7c97e636940" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers to a non-deterministic random number.</source>
          <target state="translated">将生成随机数的种子设置为非确定的随机数。</target>
        </trans-unit>
        <trans-unit id="7abac63ee55826e63cd8690359844f301cb36545" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers to a non-deterministic random number. Returns a 64 bit number used to seed the RNG.</source>
          <target state="translated">将生成随机数的种子设置为非确定的随机数。返回一个64位的数字,用于为RNG提供种子。</target>
        </trans-unit>
        <trans-unit id="d8cf00796144a8bf6bcaeca0922d063540aa0555" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers to a random number for the current GPU. It&amp;rsquo;s safe to call this function if CUDA is not available; in that case, it is silently ignored.</source>
          <target state="translated">将用于生成随机数的种子设置为当前GPU的随机数。如果CUDA不可用，则可以安全地调用此函数。在这种情况下，它会被静默忽略。</target>
        </trans-unit>
        <trans-unit id="29567c11f6e9503a646d0f30b8e295f5e5873021" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers to a random number on all GPUs. It&amp;rsquo;s safe to call this function if CUDA is not available; in that case, it is silently ignored.</source>
          <target state="translated">将用于生成随机数的种子设置为所有GPU上的随机数。如果CUDA不可用，则可以安全地调用此函数。在这种情况下，它会被静默忽略。</target>
        </trans-unit>
        <trans-unit id="82d234e8fcede91a904aeab469b5635a53af28cb" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers.</source>
          <target state="translated">设置生成随机数的种子。</target>
        </trans-unit>
        <trans-unit id="90135ab68f94754348a83b2e9a672e458fc27687" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers. Returns a &lt;code&gt;torch.Generator&lt;/code&gt; object.</source>
          <target state="translated">设置用于生成随机数的种子。返回 &lt;code&gt;torch.Generator&lt;/code&gt; 对象。</target>
        </trans-unit>
        <trans-unit id="ec7c3df03637450d6927de0719c85e704fa2352b" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers. Returns a &lt;code&gt;torch.Generator&lt;/code&gt; object. It is recommended to set a large seed, i.e. a number that has a good balance of 0 and 1 bits. Avoid having many 0 bits in the seed.</source>
          <target state="translated">设置用于生成随机数的种子。返回 &lt;code&gt;torch.Generator&lt;/code&gt; 对象。建议设置一个较大的种子，即一个具有0和1位平衡的数字。避免在种子中包含许多0位。</target>
        </trans-unit>
        <trans-unit id="1f7618c30e9d279fa17b2c4bdef606d408ddac63" translate="yes" xml:space="preserve">
          <source>Sets the store&amp;rsquo;s default timeout. This timeout is used during initialization and in &lt;code&gt;wait()&lt;/code&gt; and &lt;code&gt;get()&lt;/code&gt;.</source>
          <target state="translated">设置商店的默认超时。此超时在初始化期间以及在 &lt;code&gt;wait()&lt;/code&gt; 和 &lt;code&gt;get()&lt;/code&gt; 中使用。</target>
        </trans-unit>
        <trans-unit id="403c562468c4aed511a578286850fe13a038a13a" translate="yes" xml:space="preserve">
          <source>Sets the strategy for sharing CPU tensors.</source>
          <target state="translated">设置共享CPU tensors的策略。</target>
        </trans-unit>
        <trans-unit id="2fdbbd0a94629feee695b40b70eaf4cd936d83f2" translate="yes" xml:space="preserve">
          <source>Sets the underlying storage, size, and strides. If &lt;code&gt;source&lt;/code&gt; is a tensor, &lt;code&gt;self&lt;/code&gt; tensor will share the same storage and have the same size and strides as &lt;code&gt;source&lt;/code&gt;. Changes to elements in one tensor will be reflected in the other.</source>
          <target state="translated">设置基础存储空间，大小和跨度。如果 &lt;code&gt;source&lt;/code&gt; 是一个张量， &lt;code&gt;self&lt;/code&gt; 张量将共享相同的存储，并且具有相同的尺寸和进步的 &lt;code&gt;source&lt;/code&gt; 。一个张量中元素的变化将反映在另一个张量中。</target>
        </trans-unit>
        <trans-unit id="0bcd71b693d5fcc4b6051caa2db49bd3be5ace5c" translate="yes" xml:space="preserve">
          <source>Sets whether PyTorch operations must use &amp;ldquo;deterministic&amp;rdquo; algorithms.</source>
          <target state="translated">设置PyTorch操作是否必须使用&amp;ldquo;确定性&amp;rdquo;算法。</target>
        </trans-unit>
        <trans-unit id="1e8c135ec7a3af0dd0ffe1fe388882479c98805f" translate="yes" xml:space="preserve">
          <source>Sets whether PyTorch operations must use &amp;ldquo;deterministic&amp;rdquo; algorithms. That is, algorithms which, given the same input, and when run on the same software and hardware, always produce the same output. When True, operations will use deterministic algorithms when available, and if only nondeterministic algorithms are available they will throw a :class:RuntimeError when called.</source>
          <target state="translated">设置PyTorch操作是否必须使用&amp;ldquo;确定性&amp;rdquo;算法。也就是说，在给定相同输入且在相同软件和硬件上运行时，算法始终会产生相同输出。设置为True时，操作将在可用时使用确定性算法，如果只有不确定性算法可用，则它们将在调用时抛出：class：RuntimeError。</target>
        </trans-unit>
        <trans-unit id="8145a6b5d6477fdcd3f4ae8c4f2e54d4aea089cc" translate="yes" xml:space="preserve">
          <source>Sets whether to materialize output grad tensors. Default is true.</source>
          <target state="translated">设置是否将输出级数实体化。默认值为true。</target>
        </trans-unit>
        <trans-unit id="9f66b4449eb38b9763427d77c0a12d7806005f6b" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;return_complex&lt;/code&gt; explicitly will be required in a future PyTorch release. Set it to False to preserve the current behavior or True to return a complex output.</source>
          <target state="translated">在以后的PyTorch版本中，将需要显式设置 &lt;code&gt;return_complex&lt;/code&gt; 。将其设置为False可保留当前行为，将其设置为True可返回复杂的输出。</target>
        </trans-unit>
        <trans-unit id="50bf9fd4e5b67c599d58e411062b855bf1acfd69" translate="yes" xml:space="preserve">
          <source>Setting the argument &lt;code&gt;num_workers&lt;/code&gt; as a positive integer will turn on multi-process data loading with the specified number of loader worker processes.</source>
          <target state="translated">将参数 &lt;code&gt;num_workers&lt;/code&gt; 设置为正整数将打开具有指定数量的加载程序工作进程的多进程数据加载。</target>
        </trans-unit>
        <trans-unit id="cee805f166fb37a702f66bc6ef5dafcc4636a19c" translate="yes" xml:space="preserve">
          <source>Setting the environment variable &lt;code&gt;PYTORCH_JIT=0&lt;/code&gt; will disable all script and tracing annotations. If there is hard-to-debug error in one of your TorchScript models, you can use this flag to force everything to run using native Python. Since TorchScript (scripting and tracing) is disabled with this flag, you can use tools like &lt;code&gt;pdb&lt;/code&gt; to debug the model code. For example:</source>
          <target state="translated">设置环境变量 &lt;code&gt;PYTORCH_JIT=0&lt;/code&gt; 将禁用所有脚本和跟踪注释。如果您的TorchScript模型之一存在难以调试的错误，则可以使用此标志来强制一切都使用本机Python运行。由于使用此标志禁用了TorchScript（脚本编写和跟踪），因此可以使用 &lt;code&gt;pdb&lt;/code&gt; 之类的工具来调试模型代码。例如：</target>
        </trans-unit>
        <trans-unit id="14edb2c4ec235464bf2c2b8b3e2ce45c04e83a80" translate="yes" xml:space="preserve">
          <source>Shape:</source>
          <target state="translated">Shape:</target>
        </trans-unit>
        <trans-unit id="f03987f78c9ae43379f61461ae0064f0d5607ece" translate="yes" xml:space="preserve">
          <source>Shared file system, &lt;code&gt;init_method=&quot;file://////{machine_name}/{share_folder_name}/some_file&quot;&lt;/code&gt;</source>
          <target state="translated">共享文件系统 &lt;code&gt;init_method=&quot;file://////{machine_name}/{share_folder_name}/some_file&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="931e6a72bc22b9c481f30ac82befe23983a1c7aa" translate="yes" xml:space="preserve">
          <source>Shared file-system initialization</source>
          <target state="translated">共享文件系统初始化</target>
        </trans-unit>
        <trans-unit id="e27a0384e6eefcbae31d9ee40a6788234f717210" translate="yes" xml:space="preserve">
          <source>Sharing CUDA tensors</source>
          <target state="translated">共享CUDA tensors</target>
        </trans-unit>
        <trans-unit id="f1970dc9e6498a19bd933b2843bc57e2084c8cc4" translate="yes" xml:space="preserve">
          <source>Sharing CUDA tensors between processes is supported only in Python 3, using a &lt;code&gt;spawn&lt;/code&gt; or &lt;code&gt;forkserver&lt;/code&gt; start methods.</source>
          <target state="translated">仅在Python 3中使用 &lt;code&gt;spawn&lt;/code&gt; 或 &lt;code&gt;forkserver&lt;/code&gt; start方法支持在进程之间共享CUDA张量。</target>
        </trans-unit>
        <trans-unit id="8ca95d11aaeb17762db51cad4433dcf3e2614300" translate="yes" xml:space="preserve">
          <source>Sharing strategies</source>
          <target state="translated">分享战略</target>
        </trans-unit>
        <trans-unit id="fe846e8cff1382c632019e0d7be670d40fca4949" translate="yes" xml:space="preserve">
          <source>Short-time Fourier transform (STFT).</source>
          <target state="translated">短时傅里叶变换(STFT)。</target>
        </trans-unit>
        <trans-unit id="ba0ad92a63c363484c20c75c1280fe0b91b17b2c" translate="yes" xml:space="preserve">
          <source>Should be overridden by all subclasses.</source>
          <target state="translated">应该被所有子类覆盖。</target>
        </trans-unit>
        <trans-unit id="a37ae8778cd1020f5c30499fa7ea9a6181211f61" translate="yes" xml:space="preserve">
          <source>Show the docstring of entrypoint &lt;code&gt;model&lt;/code&gt;.</source>
          <target state="translated">显示入口点 &lt;code&gt;model&lt;/code&gt; 的文档字符串。</target>
        </trans-unit>
        <trans-unit id="7504f2364dcd93257f97f33b05a38d51614bd7fa" translate="yes" xml:space="preserve">
          <source>ShuffleNet V2</source>
          <target state="translated">ShuffleNet V2</target>
        </trans-unit>
        <trans-unit id="2f25ac460d78b88009ddd1aa94f79739535ca8b5" translate="yes" xml:space="preserve">
          <source>ShuffleNet v2</source>
          <target state="translated">ShuffleNet v2</target>
        </trans-unit>
        <trans-unit id="f2cac7f225122d558eb3c0591bdc2ae980f1b0b1" translate="yes" xml:space="preserve">
          <source>SiLU</source>
          <target state="translated">SiLU</target>
        </trans-unit>
        <trans-unit id="40cbe2acb9d6a109dfc4fb28692090f839183dea" translate="yes" xml:space="preserve">
          <source>Sigmoid</source>
          <target state="translated">Sigmoid</target>
        </trans-unit>
        <trans-unit id="5b7359698c3ea62e0fe6f50fc802ad6bb7e51d4a" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;torch.nn.Conv2d&lt;/code&gt;&lt;/a&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="translated">与&lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;torch.nn.Conv2d&lt;/code&gt; &lt;/a&gt;相似，其中FakeQuantize模块已初始化为默认值。</target>
        </trans-unit>
        <trans-unit id="7d16e4a78bd1e379e62b250638417164ecf26a8e" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;generated/torch.nn.linear#torch.nn.Linear&quot;&gt;&lt;code&gt;Linear&lt;/code&gt;&lt;/a&gt;, attributes will be randomly initialized at module creation time and will be overwritten later</source>
          <target state="translated">与&lt;a href=&quot;generated/torch.nn.linear#torch.nn.Linear&quot;&gt; &lt;code&gt;Linear&lt;/code&gt; &lt;/a&gt;类似，属性将在模块创建时随机初始化，稍后将被覆盖</target>
        </trans-unit>
        <trans-unit id="cb2775c2f284c5797e72dc4b9b56c7b83a742605" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;generated/torch.nn.linear#torch.nn.Linear&quot;&gt;&lt;code&gt;torch.nn.Linear&lt;/code&gt;&lt;/a&gt;, attributes will be randomly initialized at module creation time and will be overwritten later</source>
          <target state="translated">与&lt;a href=&quot;generated/torch.nn.linear#torch.nn.Linear&quot;&gt; &lt;code&gt;torch.nn.Linear&lt;/code&gt; &lt;/a&gt;相似，属性将在模块创建时随机初始化，稍后将被覆盖</target>
        </trans-unit>
        <trans-unit id="7c8d9b9716eb5e6f4a29b36c1d72924a394fd995" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;torch.nn.Conv2d&lt;/code&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="translated">与 &lt;code&gt;torch.nn.Conv2d&lt;/code&gt; 相似，其中FakeQuantize模块已初始化为默认值。</target>
        </trans-unit>
        <trans-unit id="d7172942fcac61201e57b0f8f8151549517ac9d8" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;torch.nn.Linear&lt;/code&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="translated">与 &lt;code&gt;torch.nn.Linear&lt;/code&gt; 相似，将FakeQuantize模块初始化为默认值。</target>
        </trans-unit>
        <trans-unit id="eb262cc11e95ba6ae1040b6fdf77b3aabdee1e50" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;torch.nn.intrinsic.LinearReLU&lt;/code&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="translated">与 &lt;code&gt;torch.nn.intrinsic.LinearReLU&lt;/code&gt; 相似，其中FakeQuantize模块已初始化为默认值。</target>
        </trans-unit>
        <trans-unit id="088b19f4865d3ae00ef9ed3545c87c4c39a038f5" translate="yes" xml:space="preserve">
          <source>Similar to the function above, but the means and standard deviations are shared among all drawn elements. The resulting tensor has size given by &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="translated">与上述功能类似，但均值和标准差在所有绘制的元素之间共享。结果张量的大小由 &lt;code&gt;size&lt;/code&gt; 给定。</target>
        </trans-unit>
        <trans-unit id="144ca09471d4e86a370dcd5e499624c907232699" translate="yes" xml:space="preserve">
          <source>Similar to the function above, but the means are shared among all drawn elements.</source>
          <target state="translated">与上面的函数类似,但手段是所有绘制的元素共享的。</target>
        </trans-unit>
        <trans-unit id="d7b2ad151fdc2daf79483df18949d1a193fac72e" translate="yes" xml:space="preserve">
          <source>Similar to the function above, but the standard-deviations are shared among all drawn elements.</source>
          <target state="translated">类似于上面的函数,但所有绘制的元素都共享标准差。</target>
        </trans-unit>
        <trans-unit id="35e4478885a3d3de0a23fd41d27cf9e8b3fd2526" translate="yes" xml:space="preserve">
          <source>Similarly, a variable is not allowed to be used if it is only &lt;em&gt;defined&lt;/em&gt; along some paths through the function.</source>
          <target state="translated">同样，如果仅沿通过函数的某些路径&lt;em&gt;定义&lt;/em&gt;变量，则不允许使用该变量。</target>
        </trans-unit>
        <trans-unit id="0ffdace347411406995002bee149d93b4c8d5097" translate="yes" xml:space="preserve">
          <source>Similarly, if you directly pass in a &lt;code&gt;store&lt;/code&gt; argument, it must be a &lt;code&gt;FileStore&lt;/code&gt; instance.</source>
          <target state="translated">同样，如果您直接传递 &lt;code&gt;store&lt;/code&gt; 参数，则该参数必须是 &lt;code&gt;FileStore&lt;/code&gt; 实例。</target>
        </trans-unit>
        <trans-unit id="9be5c47bd8d9e298dbec515a79abc57fb63bd041" translate="yes" xml:space="preserve">
          <source>Similarly, the directions can be separated in the packed case.</source>
          <target state="translated">同样,在包装箱中也可以分开方向。</target>
        </trans-unit>
        <trans-unit id="02a822df6b8073596762077fbb97fadeba9b1cf8" translate="yes" xml:space="preserve">
          <source>Simple Assignments</source>
          <target state="translated">简单作业</target>
        </trans-unit>
        <trans-unit id="b5faf41d66cbc35e2d464a122a6e9520effb835d" translate="yes" xml:space="preserve">
          <source>Simple end to end example</source>
          <target state="translated">简单的端到端例子</target>
        </trans-unit>
        <trans-unit id="605569f81b2cecc08a1e8d975481f24ac3831063" translate="yes" xml:space="preserve">
          <source>Simple example, using &lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; to enable clipping of unscaled gradients:</source>
          <target state="translated">一个简单的示例，使用&lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt; &lt;code&gt;unscale_()&lt;/code&gt; &lt;/a&gt;启用对非比例渐变的裁剪：</target>
        </trans-unit>
        <trans-unit id="4f6256b1a68c342ed7c517637989544d7f9e875b" translate="yes" xml:space="preserve">
          <source>Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor.</source>
          <target state="translated">简单地处理被修剪的参数和生成的 mask 之间的乘法。从模块中获取掩码和原始张量,并返回修剪后的张量版本。</target>
        </trans-unit>
        <trans-unit id="e9d02a1900249db21bb923f01100461e477f4a2a" translate="yes" xml:space="preserve">
          <source>Simulate the quantize and dequantize operations in training time. The output of this module is given by</source>
          <target state="translated">在训练时间内模拟量化和去量化操作。该模块的输出为</target>
        </trans-unit>
        <trans-unit id="d60674760461d218ee6d7f02184c2ead492c87d0" translate="yes" xml:space="preserve">
          <source>Since &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;stft()&lt;/code&gt;&lt;/a&gt; discards elements at the end of the signal if they do not fit in a frame, &lt;code&gt;istft&lt;/code&gt; may return a shorter signal than the original signal (can occur if &lt;code&gt;center&lt;/code&gt; is False since the signal isn&amp;rsquo;t padded).</source>
          <target state="translated">由于如果&lt;a href=&quot;torch.stft#torch.stft&quot;&gt; &lt;code&gt;stft()&lt;/code&gt; &lt;/a&gt;如果元素不适合一帧， &lt;code&gt;istft&lt;/code&gt; 在信号末尾丢弃元素，因此istft可能会返回比原始信号短的信号（如果 &lt;code&gt;center&lt;/code&gt; 为False，则可能会发生，因为没有填充信号）。</target>
        </trans-unit>
        <trans-unit id="b57ff46579e1243d4e5f8600a0a9241de5ac5737" translate="yes" xml:space="preserve">
          <source>Since SparseTensor._indices() is always a 2D tensor, the smallest sparse_dim = 1. Therefore, representation of a SparseTensor of sparse_dim = 0 is simply a dense tensor.</source>
          <target state="translated">由于SparseTensor._indices()总是一个二维张量,最小的sparse_dim=1。因此,sparse_dim=0的SparseTensor的表示方式只是一个致密张量。</target>
        </trans-unit>
        <trans-unit id="1e55bc14205c3b61b63018bcb70eae3ef124b8ad" translate="yes" xml:space="preserve">
          <source>Since eigenvalues and eigenvectors might be complex, backward pass is supported only for &lt;a href=&quot;torch.symeig#torch.symeig&quot;&gt;&lt;code&gt;torch.symeig()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">由于特征值和特征向量可能很复杂，因此仅对&lt;a href=&quot;torch.symeig#torch.symeig&quot;&gt; &lt;code&gt;torch.symeig()&lt;/code&gt; &lt;/a&gt;支持反向传递</target>
        </trans-unit>
        <trans-unit id="7cc899b4bce705836850ca654589c887f5fd6278" translate="yes" xml:space="preserve">
          <source>Since global structured pruning doesn&amp;rsquo;t make much sense unless the norm is normalized by the size of the parameter, we now limit the scope of global pruning to unstructured methods.</source>
          <target state="translated">由于除非通过参数的大小对规范进行规范化，否则全局结构化修剪没有多大意义，因此我们现在将全局修剪的范围限制为非结构化方法。</target>
        </trans-unit>
        <trans-unit id="67bd75f4f8766a48c7b96bda1b055c053f15aefe" translate="yes" xml:space="preserve">
          <source>Since the input matrix &lt;code&gt;input&lt;/code&gt; is supposed to be symmetric, only the upper triangular portion is used by default.</source>
          <target state="translated">由于假定输入矩阵 &lt;code&gt;input&lt;/code&gt; 是对称的，因此默认情况下仅使用上三角部分。</target>
        </trans-unit>
        <trans-unit id="9a190d7c173d1800801bb5236c42d4c18532c731" translate="yes" xml:space="preserve">
          <source>Since workers rely on Python &lt;a href=&quot;https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing&quot;&gt;&lt;code&gt;multiprocessing&lt;/code&gt;&lt;/a&gt;, worker launch behavior is different on Windows compared to Unix.</source>
          <target state="translated">由于工作程序依赖于Python&lt;a href=&quot;https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing&quot;&gt; &lt;code&gt;multiprocessing&lt;/code&gt; &lt;/a&gt;，因此与Unix相比，Windows上的工作程序启动行为有所不同。</target>
        </trans-unit>
        <trans-unit id="da8a1ea02e7c7de523fde6a9a1ed49139987cfb8" translate="yes" xml:space="preserve">
          <source>Single- and Multi-process Data Loading</source>
          <target state="translated">单进程和多进程数据加载</target>
        </trans-unit>
        <trans-unit id="21a1b9cf02c75eb1f1e22759af089802524d644f" translate="yes" xml:space="preserve">
          <source>Single-Node multi-process distributed training</source>
          <target state="translated">单节点多进程分布式训练</target>
        </trans-unit>
        <trans-unit id="1d2ab9ec1f053a991bd56f9ddd052665f52de541" translate="yes" xml:space="preserve">
          <source>Single-process data loading (default)</source>
          <target state="translated">单进程数据加载(默认</target>
        </trans-unit>
        <trans-unit id="f8df21c36569ccf0ecf10173294bd3bcb1ac958d" translate="yes" xml:space="preserve">
          <source>Slices the &lt;code&gt;self&lt;/code&gt; tensor along the selected dimension at the given index. This function returns a view of the original tensor with the given dimension removed.</source>
          <target state="translated">在给定索引处沿选定维度切片 &lt;code&gt;self&lt;/code&gt; 张量。此函数返回删除了给定尺寸的原始张量的视图。</target>
        </trans-unit>
        <trans-unit id="1388fcaebbfe7bba9af50141f343d91cd5010970" translate="yes" xml:space="preserve">
          <source>SmoothL1Loss</source>
          <target state="translated">SmoothL1Loss</target>
        </trans-unit>
        <trans-unit id="cf592edcfbdc177c81b474cbd6b83f6e29d0f7cc" translate="yes" xml:space="preserve">
          <source>So, it is recommended to always pass the signal length &lt;code&gt;n&lt;/code&gt;:</source>
          <target state="translated">因此，建议始终传递信号长度 &lt;code&gt;n&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="ec836ce94eae96d1e5118d150d4218a7f447e2e4" translate="yes" xml:space="preserve">
          <source>So, it is recommended to always pass the signal shape &lt;code&gt;s&lt;/code&gt;.</source>
          <target state="translated">因此，建议始终通过信号形状 &lt;code&gt;s&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5fdb4ccd6a62db91e946fc4d593f43a0eb0c2b97" translate="yes" xml:space="preserve">
          <source>SobolEngine</source>
          <target state="translated">SobolEngine</target>
        </trans-unit>
        <trans-unit id="5780e85860e3ef851155673787aae34395fdcb14" translate="yes" xml:space="preserve">
          <source>SoftMarginLoss</source>
          <target state="translated">SoftMarginLoss</target>
        </trans-unit>
        <trans-unit id="bace6f3ab809aca48a2c72d1f9a972334f596086" translate="yes" xml:space="preserve">
          <source>SoftPlus is a smooth approximation to the ReLU function and can be used to constrain the output of a machine to always be positive.</source>
          <target state="translated">SoftPlus是ReLU函数的平滑近似,可以用来约束机器的输出始终为正。</target>
        </trans-unit>
        <trans-unit id="4db38f97f455fc816850ffbe57a25de4b9b124c8" translate="yes" xml:space="preserve">
          <source>SoftShrinkage</source>
          <target state="translated">SoftShrinkage</target>
        </trans-unit>
        <trans-unit id="a2852636b9c2b8ea655bec2aa6ef18c0c81bce34" translate="yes" xml:space="preserve">
          <source>SoftSign</source>
          <target state="translated">SoftSign</target>
        </trans-unit>
        <trans-unit id="06a2c3db74f0f43566dbc7efd5bedd81dfa46888" translate="yes" xml:space="preserve">
          <source>Softmax</source>
          <target state="translated">Softmax</target>
        </trans-unit>
        <trans-unit id="38b81da3b6ab3b9be6104d3e4c422885eca96901" translate="yes" xml:space="preserve">
          <source>Softmax is defined as:</source>
          <target state="translated">Softmax定义为:</target>
        </trans-unit>
        <trans-unit id="0444b47cdcbeed809978f61fc222d1069a142d9c" translate="yes" xml:space="preserve">
          <source>Softmax2d</source>
          <target state="translated">Softmax2d</target>
        </trans-unit>
        <trans-unit id="29b7eb80efd3b1d65f2835df414e4222cab21ee1" translate="yes" xml:space="preserve">
          <source>Softmin</source>
          <target state="translated">Softmin</target>
        </trans-unit>
        <trans-unit id="af86abb7b472b1e8a9af01b4180064b037b78bf8" translate="yes" xml:space="preserve">
          <source>Softmin is defined as:</source>
          <target state="translated">软民的定义是:</target>
        </trans-unit>
        <trans-unit id="90ba42633b716cf810a9a32d70553b14c097c177" translate="yes" xml:space="preserve">
          <source>Softplus</source>
          <target state="translated">Softplus</target>
        </trans-unit>
        <trans-unit id="7bb40d05bf436ff810963d7ee11a5bc95644a2f9" translate="yes" xml:space="preserve">
          <source>Softshrink</source>
          <target state="translated">Softshrink</target>
        </trans-unit>
        <trans-unit id="2b10804bb8f17cdf24b14774ca1d70aa3ba213d6" translate="yes" xml:space="preserve">
          <source>Softsign</source>
          <target state="translated">Softsign</target>
        </trans-unit>
        <trans-unit id="73a65eb2cc67f9395fdddf23ed853dd71a26bf17" translate="yes" xml:space="preserve">
          <source>Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix</source>
          <target state="translated">解线性方程组,给定其Cholesky系数矩阵,将其正半定矩阵进行反演。</target>
        </trans-unit>
        <trans-unit id="ab02cfb3b2fcd0c1b4621d3c7cc39a469375c3ec" translate="yes" xml:space="preserve">
          <source>Solves a system of equations with a triangular coefficient matrix</source>
          <target state="translated">求解三角系数矩阵的方程组。</target>
        </trans-unit>
        <trans-unit id="5773ea0d4a0b0567ea2d9a3b38579ffd7e09e6ff" translate="yes" xml:space="preserve">
          <source>Some functions (for example, &lt;a href=&quot;https://docs.python.org/3/library/functions.html#zip&quot;&gt;&lt;code&gt;zip&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://docs.python.org/3/library/functions.html#enumerate&quot;&gt;&lt;code&gt;enumerate&lt;/code&gt;&lt;/a&gt;) can only operate on iterable types. Iterable types in TorchScript include &lt;code&gt;Tensor&lt;/code&gt;s, lists, tuples, dictionaries, strings, &lt;a href=&quot;generated/torch.nn.modulelist#torch.nn.ModuleList&quot;&gt;&lt;code&gt;torch.nn.ModuleList&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.moduledict#torch.nn.ModuleDict&quot;&gt;&lt;code&gt;torch.nn.ModuleDict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">某些功能（例如&lt;a href=&quot;https://docs.python.org/3/library/functions.html#zip&quot;&gt; &lt;code&gt;zip&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;https://docs.python.org/3/library/functions.html#enumerate&quot;&gt; &lt;code&gt;enumerate&lt;/code&gt; &lt;/a&gt;）只能对可迭代类型进行操作。TorchScript中的可迭代类型包括 &lt;code&gt;Tensor&lt;/code&gt; ，列表，元组，字典，字符串，&lt;a href=&quot;generated/torch.nn.modulelist#torch.nn.ModuleList&quot;&gt; &lt;code&gt;torch.nn.ModuleList&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.moduledict#torch.nn.ModuleDict&quot;&gt; &lt;code&gt;torch.nn.ModuleDict&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="cbbdc83ebf4a1410688a2167e77428899715f68d" translate="yes" xml:space="preserve">
          <source>Some input frequencies must be real-valued to satisfy the Hermitian property. In these cases the imaginary component will be ignored. For example, any imaginary component in the zero-frequency term cannot be represented in a real output and so will always be ignored.</source>
          <target state="translated">有些输入频率必须是实值,以满足赫米特特性。在这些情况下,虚分量将被忽略。例如,零频率项中的任何虚分量都不能在实数输出中表示,因此将始终被忽略。</target>
        </trans-unit>
        <trans-unit id="f5a5860f652baaa71e759f95e6546fb5a30df1fa" translate="yes" xml:space="preserve">
          <source>Some models use modules which have different training and evaluation behavior, such as batch normalization. To switch between these modes, use &lt;code&gt;model.train()&lt;/code&gt; or &lt;code&gt;model.eval()&lt;/code&gt; as appropriate. See &lt;a href=&quot;../generated/torch.nn.module#torch.nn.Module.train&quot;&gt;&lt;code&gt;train()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../generated/torch.nn.module#torch.nn.Module.eval&quot;&gt;&lt;code&gt;eval()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">某些模型使用的模块具有不同的训练和评估行为，例如批量归一化。要在这些模式之间切换，请根据需要使用 &lt;code&gt;model.train()&lt;/code&gt; 或 &lt;code&gt;model.eval()&lt;/code&gt; 。有关详细信息，请参见&lt;a href=&quot;../generated/torch.nn.module#torch.nn.Module.train&quot;&gt; &lt;code&gt;train()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;../generated/torch.nn.module#torch.nn.Module.eval&quot;&gt; &lt;code&gt;eval()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7b9a08f765d29fc2a0904578fe32193591816e48" translate="yes" xml:space="preserve">
          <source>Some ops not listed here (e.g., binary ops like &lt;code&gt;add&lt;/code&gt;) natively promote inputs without autocasting&amp;rsquo;s intervention. If inputs are a mixture of &lt;code&gt;float16&lt;/code&gt; and &lt;code&gt;float32&lt;/code&gt;, these ops run in &lt;code&gt;float32&lt;/code&gt; and produce &lt;code&gt;float32&lt;/code&gt; output, regardless of whether autocast is enabled.</source>
          <target state="translated">此处未列出的某些操作（例如，诸如 &lt;code&gt;add&lt;/code&gt; 之类的二进制操作）在没有自动广播的干预的情况下原生地促进了输入。如果输入是 &lt;code&gt;float16&lt;/code&gt; 和 &lt;code&gt;float32&lt;/code&gt; 的混合，则这些操作在 &lt;code&gt;float32&lt;/code&gt; 中运行并产生 &lt;code&gt;float32&lt;/code&gt; 输出，而不管是否启用了自动广播。</target>
        </trans-unit>
        <trans-unit id="72e33a4ea3969c9936cfbf0b72aacf8cc360fedb" translate="yes" xml:space="preserve">
          <source>Some optimization algorithms such as Conjugate Gradient and LBFGS need to reevaluate the function multiple times, so you have to pass in a closure that allows them to recompute your model. The closure should clear the gradients, compute the loss, and return it.</source>
          <target state="translated">一些优化算法,如共轭梯度和LBFGS需要多次重新评估函数,所以你必须传入一个闭包,让他们重新计算你的模型。这个闭包应该清除梯度,计算损失,然后返回它。</target>
        </trans-unit>
        <trans-unit id="ae4df2df1ef3b4db7bd9154e0c9f55f5890f0c7a" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as Brain Floating Point: use 1 sign, 8 exponent and 7 significand bits. Useful when range is important, since it has the same number of exponent bits as &lt;code&gt;float32&lt;/code&gt;</source>
          <target state="translated">有时也称为&amp;ldquo;脑浮点&amp;rdquo;：使用1个符号，8个指数和7个有效位。当范围很重要时很有用，因为它的位数与 &lt;code&gt;float32&lt;/code&gt; 相同</target>
        </trans-unit>
        <trans-unit id="78039ee874a9a5bb0eb3d37a1f02f096ee61bda5" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as Brain Floating Point: uses 1 sign, 8 exponent, and 7 significand bits. Useful when range is important, since it has the same number of exponent bits as &lt;code&gt;float32&lt;/code&gt;</source>
          <target state="translated">有时称为&amp;ldquo;脑浮点&amp;rdquo;：使用1个符号，8个指数和7个有效位。当范围很重要时很有用，因为它的位数与 &lt;code&gt;float32&lt;/code&gt; 相同</target>
        </trans-unit>
        <trans-unit id="ba80efc106bf3fdda88df0da58461971d3468eca" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand bits. Useful when precision is important at the expense of range.</source>
          <target state="translated">有时也称为二进制16:使用1个符号、5个指数和10个意义位。当以牺牲范围为代价而强调精度时,很有用。</target>
        </trans-unit>
        <trans-unit id="4633684bcdc43c53e1cfb801845c2325140c26e1" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand bits. Useful when precision is important.</source>
          <target state="translated">有时称为二进制16:使用1个符号,5个指数和10个意义位。当精度很重要的时候,很有用。</target>
        </trans-unit>
        <trans-unit id="3900f0b870b5719788e2d6646aafed691f38941e" translate="yes" xml:space="preserve">
          <source>Sorts the elements of the &lt;code&gt;input&lt;/code&gt; tensor along a given dimension in ascending order by value.</source>
          <target state="translated">沿给定维度按值按升序对 &lt;code&gt;input&lt;/code&gt; 张量的元素进行排序。</target>
        </trans-unit>
        <trans-unit id="6a085f98a6ae4bb57c97870bfd419ca83f17e143" translate="yes" xml:space="preserve">
          <source>Sources may omit two required parts of a typical non-inline C++ extension: the necessary header includes, as well as the (pybind11) binding code. More precisely, strings passed to &lt;code&gt;cpp_sources&lt;/code&gt; are first concatenated into a single &lt;code&gt;.cpp&lt;/code&gt; file. This file is then prepended with &lt;code&gt;#include
&amp;lt;torch/extension.h&amp;gt;&lt;/code&gt;.</source>
          <target state="translated">源代码可能会省略典型的非内联C ++扩展的两个必需部分：必需的标头包括以及（pybind11）绑定代码。更准确地说，首先将传递给 &lt;code&gt;cpp_sources&lt;/code&gt; 的字符串连接到单个 &lt;code&gt;.cpp&lt;/code&gt; 文件中。然后，此文件以 &lt;code&gt;#include &amp;lt;torch/extension.h&amp;gt;&lt;/code&gt; 开头。</target>
        </trans-unit>
        <trans-unit id="38317d08ad25b33e290bef6bc76c581c87c8620f" translate="yes" xml:space="preserve">
          <source>Sparse Layers</source>
          <target state="translated">稀疏层</target>
        </trans-unit>
        <trans-unit id="0e3084d96416ea178eaf45c018b3d6a666f048ab" translate="yes" xml:space="preserve">
          <source>Sparse functions</source>
          <target state="translated">稀疏函数</target>
        </trans-unit>
        <trans-unit id="ca9492470122675a4d013eba5c404de6d984fba7" translate="yes" xml:space="preserve">
          <source>SparseTensor has the following invariants:</source>
          <target state="translated">SparseTensor具有以下不变量。</target>
        </trans-unit>
        <trans-unit id="ad7f19daae9a456b6857c9e6506b86f3b2ab9c8d" translate="yes" xml:space="preserve">
          <source>SparseTensor._indices().shape = (sparse_dim, nnz)</source>
          <target state="translated">SparseTensor._indices().shape=(sparse_dim,nnz)</target>
        </trans-unit>
        <trans-unit id="018f02659b563c79f98ce5dc06e6c8ead57c92f3" translate="yes" xml:space="preserve">
          <source>SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:])</source>
          <target state="translated">SparseTensor._values().shape=(nnz,SparseTensor.shape[sparse_dim:])</target>
        </trans-unit>
        <trans-unit id="4ca5e4706f1046fd29382939145a442a4ce0eeb1" translate="yes" xml:space="preserve">
          <source>Spawn utility</source>
          <target state="translated">生成工具</target>
        </trans-unit>
        <trans-unit id="762ee18552488ab27f7d553d5bb224a9478ed209" translate="yes" xml:space="preserve">
          <source>Spawning a number of subprocesses to perform some function can be done by creating &lt;code&gt;Process&lt;/code&gt; instances and calling &lt;code&gt;join&lt;/code&gt; to wait for their completion. This approach works fine when dealing with a single subprocess but presents potential issues when dealing with multiple processes.</source>
          <target state="translated">可以通过创建 &lt;code&gt;Process&lt;/code&gt; 实例并调用 &lt;code&gt;join&lt;/code&gt; 等待其完成来生成大量子流程来执行某些功能。这种方法在处理单个子流程时效果很好，但是在处理多个流程时却存在潜在的问题。</target>
        </trans-unit>
        <trans-unit id="62f14e7f69f0c928f3521a52d4471e369748ed2e" translate="yes" xml:space="preserve">
          <source>Spawning subprocesses</source>
          <target state="translated">生成子程序</target>
        </trans-unit>
        <trans-unit id="c66cb2e22db24d665900e10960b23a14a873c2d2" translate="yes" xml:space="preserve">
          <source>Spawns &lt;code&gt;nprocs&lt;/code&gt; processes that run &lt;code&gt;fn&lt;/code&gt; with &lt;code&gt;args&lt;/code&gt;.</source>
          <target state="translated">产卵 &lt;code&gt;nprocs&lt;/code&gt; 运行过程 &lt;code&gt;fn&lt;/code&gt; 与 &lt;code&gt;args&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a2019fa476b609b73dfcc70b82b7767a098a7dbd" translate="yes" xml:space="preserve">
          <source>Specifically, in the forward pass, &lt;code&gt;function&lt;/code&gt; will run in &lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt;&lt;code&gt;torch.no_grad()&lt;/code&gt;&lt;/a&gt; manner, i.e., not storing the intermediate activations. Instead, the forward pass saves the inputs tuple and the &lt;code&gt;function&lt;/code&gt; parameter. In the backwards pass, the saved inputs and &lt;code&gt;function&lt;/code&gt; is retrieved, and the forward pass is computed on &lt;code&gt;function&lt;/code&gt; again, now tracking the intermediate activations, and then the gradients are calculated using these activation values.</source>
          <target state="translated">具体来说，在前向传递中， &lt;code&gt;function&lt;/code&gt; 将以&lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt; &lt;code&gt;torch.no_grad()&lt;/code&gt; &lt;/a&gt;方式运行，即不存储中间激活。相反，前向传递将保存输入元组和 &lt;code&gt;function&lt;/code&gt; 参数。在向后遍历中，检索保存的输入和 &lt;code&gt;function&lt;/code&gt; ，并再次对 &lt;code&gt;function&lt;/code&gt; 进行正向遍历，现在跟踪中间激活，然后使用这些激活值计算梯度。</target>
        </trans-unit>
        <trans-unit id="9fb7ff759e9a0b4f8cf21fa63ff4032c4ca275d1" translate="yes" xml:space="preserve">
          <source>Specify &lt;code&gt;init_method&lt;/code&gt; (a URL string) which indicates where/how to discover peers. Optionally specify &lt;code&gt;rank&lt;/code&gt; and &lt;code&gt;world_size&lt;/code&gt;, or encode all required parameters in the URL and omit them.</source>
          <target state="translated">指定 &lt;code&gt;init_method&lt;/code&gt; （URL字符串），它指示在何处/如何发现对等方。（可选）指定 &lt;code&gt;rank&lt;/code&gt; 和 &lt;code&gt;world_size&lt;/code&gt; ，或在URL中编码所有必需的参数并忽略它们。</target>
        </trans-unit>
        <trans-unit id="aaa6b0a968f0861818a7c60f3b1e30636bcfe285" translate="yes" xml:space="preserve">
          <source>Specify &lt;code&gt;store&lt;/code&gt;, &lt;code&gt;rank&lt;/code&gt;, and &lt;code&gt;world_size&lt;/code&gt; explicitly.</source>
          <target state="translated">明确指定 &lt;code&gt;store&lt;/code&gt; ， &lt;code&gt;rank&lt;/code&gt; 和 &lt;code&gt;world_size&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="729466c776095dc7f1dabe6031157b446a5540f2" translate="yes" xml:space="preserve">
          <source>Spectral Ops</source>
          <target state="translated">Spectral Ops</target>
        </trans-unit>
        <trans-unit id="2edd2d0e89ea6a8fb45d2a4b97947c90f7836312" translate="yes" xml:space="preserve">
          <source>Spectral normalization stabilizes the training of discriminators (critics) in Generative Adversarial Networks (GANs) by rescaling the weight tensor with spectral norm</source>
          <target state="translated">频谱归一化通过用频谱规范重新调整权重张量来稳定生成式对抗网络(GANs)中的判别器(批判器)的训练。</target>
        </trans-unit>
        <trans-unit id="7da9517b7a5b4892d14a9dd4e7bfc3bd2215ddfe" translate="yes" xml:space="preserve">
          <source>Splits a tensor into a specific number of chunks.</source>
          <target state="translated">将一个张量分割成特定数量的小块。</target>
        </trans-unit>
        <trans-unit id="15060a11c482f2d0d29c0ea280b19cfd35770c5a" translate="yes" xml:space="preserve">
          <source>Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor.</source>
          <target state="translated">将一个张量分割成特定数量的块。每个分块都是输入张量的一个视图。</target>
        </trans-unit>
        <trans-unit id="9e2be38fc2259b1dc48a946fa30b9de28430d8f6" translate="yes" xml:space="preserve">
          <source>Splits the tensor into chunks.</source>
          <target state="translated">将张量分割成块状。</target>
        </trans-unit>
        <trans-unit id="3a4c888de6c076a07c14ac6f6526916b6b64d375" translate="yes" xml:space="preserve">
          <source>Splits the tensor into chunks. Each chunk is a view of the original tensor.</source>
          <target state="translated">将张量分割成小块。每个分块都是原始张量的一个视图。</target>
        </trans-unit>
        <trans-unit id="6bb9feffd05f6ed4721f33c4d4bcd3050fc0acce" translate="yes" xml:space="preserve">
          <source>SqueezeNet</source>
          <target state="translated">SqueezeNet</target>
        </trans-unit>
        <trans-unit id="8e3b43524d2794940e994fbdb21d126a6c23a892" translate="yes" xml:space="preserve">
          <source>SqueezeNet 1.0</source>
          <target state="translated">SqueezeNet 1.0</target>
        </trans-unit>
        <trans-unit id="83d7283f405d03fc00d84f279e5aa4a9ad100122" translate="yes" xml:space="preserve">
          <source>SqueezeNet 1.1</source>
          <target state="translated">SqueezeNet 1.1</target>
        </trans-unit>
        <trans-unit id="e8ffcf5b4a1dac24c72399125fdd5187787b0df5" translate="yes" xml:space="preserve">
          <source>SqueezeNet 1.1 model from the &lt;a href=&quot;https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1&quot;&gt;official SqueezeNet repo&lt;/a&gt;. SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.</source>
          <target state="translated">SqueezeNet 1.1模型来自&lt;a href=&quot;https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1&quot;&gt;官方的SqueezeNet回购&lt;/a&gt;。SqueezeNet 1.1的计算量和参数比SqueezeNet 1.0少2.4倍，而又不牺牲准确性。</target>
        </trans-unit>
        <trans-unit id="5fe53423313b926c6b9706c2a81b42a519942948" translate="yes" xml:space="preserve">
          <source>SqueezeNet model architecture from the &lt;a href=&quot;https://arxiv.org/abs/1602.07360&quot;&gt;&amp;ldquo;SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &amp;lt;0.5MB model size&amp;rdquo;&lt;/a&gt; paper.</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/abs/1602.07360&quot;&gt;&amp;ldquo; SqueezeNet：AlexNet级别的精度，参数减少50倍，模型尺寸小于0.5MB&amp;rdquo;中的&lt;/a&gt;SqueezeNet模型体系结构。</target>
        </trans-unit>
        <trans-unit id="d061769f4cfb05ab146ba458ef5636f865a72a82" translate="yes" xml:space="preserve">
          <source>Stack tensors in sequence depthwise (along third axis).</source>
          <target state="translated">按深度顺序堆叠张力器(沿第三轴)。</target>
        </trans-unit>
        <trans-unit id="46e9e1e8c6989a91e6a1a0548e571225be43cbbf" translate="yes" xml:space="preserve">
          <source>Stack tensors in sequence horizontally (column wise).</source>
          <target state="translated">按水平方向(列)依次堆叠张力器。</target>
        </trans-unit>
        <trans-unit id="cd5277dc6eddb37c391be9a3629b9809479f61ec" translate="yes" xml:space="preserve">
          <source>Stack tensors in sequence vertically (row wise).</source>
          <target state="translated">依次垂直堆叠张力器(以行为单位)。</target>
        </trans-unit>
        <trans-unit id="7911bbae7aa66ed740b8a6ebf74df4fbffeb0338" translate="yes" xml:space="preserve">
          <source>State collector class for float operations.</source>
          <target state="translated">浮动操作的状态采集器类。</target>
        </trans-unit>
        <trans-unit id="5653cebc057d4791ce07031ad9286e729de6d691" translate="yes" xml:space="preserve">
          <source>Statements</source>
          <target state="translated">Statements</target>
        </trans-unit>
        <trans-unit id="19abb71cdc8040d0d69069e805acbb331fb10491" translate="yes" xml:space="preserve">
          <source>Step between two slices is given by &lt;code&gt;step&lt;/code&gt;.</source>
          <target state="translated">两个切片之间的 &lt;code&gt;step&lt;/code&gt; 由step给出。</target>
        </trans-unit>
        <trans-unit id="14f4390fa64c3d61f311b3d728a02a53224437ed" translate="yes" xml:space="preserve">
          <source>Step could be called after every batch update</source>
          <target state="translated">可以在每次批量更新后调用该步骤</target>
        </trans-unit>
        <trans-unit id="800f66cc7b49914c33ebebf4faf976e88aaac6fe" translate="yes" xml:space="preserve">
          <source>Stochastic Weight Averaging</source>
          <target state="translated">随机权重平均法</target>
        </trans-unit>
        <trans-unit id="a93d86688c50b7db5df06afe98e12c7eb843b764" translate="yes" xml:space="preserve">
          <source>Stores names for each of this tensor&amp;rsquo;s dimensions.</source>
          <target state="translated">存储每个张量尺寸的名称。</target>
        </trans-unit>
        <trans-unit id="9a96f51db31dc0b324375deea02a8cc1a060aba6" translate="yes" xml:space="preserve">
          <source>Strategy management</source>
          <target state="translated">战略管理</target>
        </trans-unit>
        <trans-unit id="b0f4aaebf484b2f55d024a76952eb003a0d189f2" translate="yes" xml:space="preserve">
          <source>Streams and events</source>
          <target state="translated">流和活动</target>
        </trans-unit>
        <trans-unit id="c3036c584463ccfc0fa687352917db10956640ab" translate="yes" xml:space="preserve">
          <source>Streams are per-device. If the selected stream is not on the current device, this function will also change the current device to match the stream.</source>
          <target state="translated">流是每个设备的。如果所选的流不在当前设备上,这个功能也会改变当前设备,使之与流相匹配。</target>
        </trans-unit>
        <trans-unit id="8c7ec55740528fa4d2910cfad7b5e1cae6e7da08" translate="yes" xml:space="preserve">
          <source>Stride is the jump necessary to go from one element to the next one in the specified dimension &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt;. A tuple of all strides is returned when no argument is passed in. Otherwise, an integer value is returned as the stride in the particular dimension &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">跨度是在指定尺寸&lt;a href=&quot;#torch.Tensor.dim&quot;&gt; &lt;code&gt;dim&lt;/code&gt; 中&lt;/a&gt;从一个元素到下一个元素所需的跳跃。当不传递任何参数时，将返回所有跨度的元组。否则，将返回整数值作为特定维&lt;a href=&quot;#torch.Tensor.dim&quot;&gt; &lt;code&gt;dim&lt;/code&gt; 中&lt;/a&gt;的跨度。</target>
        </trans-unit>
        <trans-unit id="aaae0d5e6cf55aab12950842f08c8cf9355bcef4" translate="yes" xml:space="preserve">
          <source>StudentT</source>
          <target state="translated">StudentT</target>
        </trans-unit>
        <trans-unit id="8234b01c9735ef16f8e122a86ac6b13bee795314" translate="yes" xml:space="preserve">
          <source>Submodules assigned in this way will be registered, and will have their parameters converted too when you call &lt;a href=&quot;#torch.nn.Module.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;, etc.</source>
          <target state="translated">以这种方式分配的子模块将被注册，并且在调用&lt;a href=&quot;#torch.nn.Module.to&quot;&gt; &lt;code&gt;to()&lt;/code&gt; &lt;/a&gt;等时也将对其参数进行转换。</target>
        </trans-unit>
        <trans-unit id="82a36013ba03c5404268ec4092f5e0e3210ace06" translate="yes" xml:space="preserve">
          <source>Subscripts and Slicing</source>
          <target state="translated">子目录和切片</target>
        </trans-unit>
        <trans-unit id="a822d1e4dad94b5aa9ace547ed1affaadebbf09a" translate="yes" xml:space="preserve">
          <source>Subset of a dataset at specified indices.</source>
          <target state="translated">数据集在指定指数上的子集。</target>
        </trans-unit>
        <trans-unit id="ae017f86a36a573c987d535dde17fe71055f3774" translate="yes" xml:space="preserve">
          <source>Subsystems</source>
          <target state="translated">Subsystems</target>
        </trans-unit>
        <trans-unit id="fb5f075e6679b4e2fffcc3ea921e3be776764746" translate="yes" xml:space="preserve">
          <source>Subtracts &lt;code&gt;other&lt;/code&gt;, scaled by &lt;code&gt;alpha&lt;/code&gt;, from &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">从 &lt;code&gt;input&lt;/code&gt; 减去 &lt;code&gt;other&lt;/code&gt; （按 &lt;code&gt;alpha&lt;/code&gt; 缩放）的值。</target>
        </trans-unit>
        <trans-unit id="61228272a4a7f9d4dd0cc2a12ad63a807870bdc6" translate="yes" xml:space="preserve">
          <source>Sum &lt;code&gt;this&lt;/code&gt; tensor to &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; must be broadcastable to &lt;code&gt;this&lt;/code&gt; tensor size.</source>
          <target state="translated">将 &lt;code&gt;this&lt;/code&gt; 张量求和到&lt;a href=&quot;#torch.Tensor.size&quot;&gt; &lt;code&gt;size&lt;/code&gt; &lt;/a&gt;。&lt;a href=&quot;#torch.Tensor.size&quot;&gt; &lt;code&gt;size&lt;/code&gt; &lt;/a&gt;必须可广播 &lt;code&gt;this&lt;/code&gt; 张量大小。</target>
        </trans-unit>
        <trans-unit id="5bbc7a7ed0ef03a5bd96699fe5d02cbbd0777b92" translate="yes" xml:space="preserve">
          <source>Sums tensors from multiple GPUs.</source>
          <target state="translated">对多个GPU的张力进行求和。</target>
        </trans-unit>
        <trans-unit id="a2a1c18ad4d1dc4a9dbab6435947b2aca87f5bcb" translate="yes" xml:space="preserve">
          <source>SuperResolution</source>
          <target state="translated">SuperResolution</target>
        </trans-unit>
        <trans-unit id="fe6c7185d6335e53d7798880272887b9e595250b" translate="yes" xml:space="preserve">
          <source>Supported constant Python types are</source>
          <target state="translated">支持的Python常量类型有</target>
        </trans-unit>
        <trans-unit id="6c9970da0829cd2d77d97494b716ecac47fb4272" translate="yes" xml:space="preserve">
          <source>Supported inputs are dense, sparse, and batches of dense matrices.</source>
          <target state="translated">支持的输入是密集、稀疏和成批的密集矩阵。</target>
        </trans-unit>
        <trans-unit id="a72acca9638828e6fcd59dd9d5146b8ffaac77cb" translate="yes" xml:space="preserve">
          <source>Supported operators</source>
          <target state="translated">支持的运营商</target>
        </trans-unit>
        <trans-unit id="d2212b71de8fd24dec99bf8599144400e7f7e95d" translate="yes" xml:space="preserve">
          <source>Supporting in-place operations in autograd is a hard matter, and we discourage their use in most cases. Autograd&amp;rsquo;s aggressive buffer freeing and reuse makes it very efficient and there are very few occasions when in-place operations actually lower memory usage by any significant amount. Unless you&amp;rsquo;re operating under heavy memory pressure, you might never need to use them.</source>
          <target state="translated">在autograd中支持就地操作很困难，并且在大多数情况下，我们不鼓励使用它们。Autograd积极的缓冲区释放和重用使其非常高效，并且在极少数情况下，就地操作实际上会显着降低内存使用量。除非您在沉重的内存压力下进行操作，否则可能永远不需要使用它们。</target>
        </trans-unit>
        <trans-unit id="7d88be7203e6e438cd32536d295a5ed587dd4a76" translate="yes" xml:space="preserve">
          <source>Supports &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcasting to a common shape&lt;/a&gt;, &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;type promotion&lt;/a&gt;, and integer, float, and complex inputs.</source>
          <target state="translated">支持&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播到通用形状&lt;/a&gt;，&lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;类型提升&lt;/a&gt;和整数，浮点和复杂输入。</target>
        </trans-unit>
        <trans-unit id="12a17f409a6267d331bbba640e585b7dceceb728" translate="yes" xml:space="preserve">
          <source>Supports &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcasting to a common shape&lt;/a&gt;, &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;type promotion&lt;/a&gt;, and integer, float, and complex inputs. Always promotes integer types to the default scalar type.</source>
          <target state="translated">支持&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播到通用形状&lt;/a&gt;，&lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;类型提升&lt;/a&gt;和整数，浮点和复杂输入。始终将整数类型提升为默认的标量类型。</target>
        </trans-unit>
        <trans-unit id="c515e39b10e558f93fb5480918ab7b6f80dd1a7c" translate="yes" xml:space="preserve">
          <source>Supports broadcasting to a common shape, type promotion, and integer and float inputs.</source>
          <target state="translated">支持向普通形状、类型推广、整数和浮点数输入广播。</target>
        </trans-unit>
        <trans-unit id="776e5bf297164498f6e5ef24869ccff8d9d007bf" translate="yes" xml:space="preserve">
          <source>Swaps the module if it has a quantized counterpart and it has an &lt;code&gt;observer&lt;/code&gt; attached.</source>
          <target state="translated">如果模块具有量化的对应项并且已附加 &lt;code&gt;observer&lt;/code&gt; ，则交换该模块。</target>
        </trans-unit>
        <trans-unit id="2b5fa2f5e7f20411e614b5e4239c9394a99b2a3f" translate="yes" xml:space="preserve">
          <source>Symbolic functions should be implemented in Python. All of these functions interact with Python methods which are implemented via C++-Python bindings, but intuitively the interface they provide looks like this:</source>
          <target state="translated">符号函数应该用Python来实现。所有这些函数都与Python方法交互,而Python方法是通过C++-Python绑定来实现的,但直观上它们提供的接口是这样的。</target>
        </trans-unit>
        <trans-unit id="dd8b7a9758c34d0bf6248878c673e14fd8037607" translate="yes" xml:space="preserve">
          <source>SyncBatchNorm</source>
          <target state="translated">SyncBatchNorm</target>
        </trans-unit>
        <trans-unit id="1dc553edb93ee2799123f5bdebb8f2d61aa9771e" translate="yes" xml:space="preserve">
          <source>Synchronizes all processes.</source>
          <target state="translated">同步所有进程。</target>
        </trans-unit>
        <trans-unit id="e32e1c40401ff0c5bb5e89fba4cab573a0ddefc7" translate="yes" xml:space="preserve">
          <source>Synchronizes with another stream.</source>
          <target state="translated">与另一个流同步。</target>
        </trans-unit>
        <trans-unit id="68f18accfbfac81fef2a2bc99a682b9a686206f1" translate="yes" xml:space="preserve">
          <source>Synchronous and asynchronous collective operations</source>
          <target state="translated">同步和异步的集体操作。</target>
        </trans-unit>
        <trans-unit id="c2c53d66948214258a26ca9ca845d7ac0c17f8e7" translate="yes" xml:space="preserve">
          <source>T</source>
          <target state="translated">T</target>
        </trans-unit>
        <trans-unit id="a55d4194696253efb0ce8eaeea351140c88a65da" translate="yes" xml:space="preserve">
          <source>T = \text{input length}</source>
          <target state="translated">T=text{输入长度}。</target>
        </trans-unit>
        <trans-unit id="26aecc925a999c69c46a16510ab79a1145705de8" translate="yes" xml:space="preserve">
          <source>T+X</source>
          <target state="translated">T+X</target>
        </trans-unit>
        <trans-unit id="a614078b58d53b0cc0d0d780950744eb6f8ae5a6" translate="yes" xml:space="preserve">
          <source>TCP initialization</source>
          <target state="translated">TCP初始化</target>
        </trans-unit>
        <trans-unit id="ae0cb888e5b3c4b34090835d26990b761f9663d6" translate="yes" xml:space="preserve">
          <source>T_{cur}</source>
          <target state="translated">T_{cur}</target>
        </trans-unit>
        <trans-unit id="728548804a0da830440ca32e7488e5d512871f39" translate="yes" xml:space="preserve">
          <source>T_{cur}=0</source>
          <target state="translated">T_{cur}=0</target>
        </trans-unit>
        <trans-unit id="3f5463cfd9bd0758a96ea8db117479b2314fff2b" translate="yes" xml:space="preserve">
          <source>T_{cur}=T_{i}</source>
          <target state="translated">T_{cur}=T_{i}</target>
        </trans-unit>
        <trans-unit id="97af24691624857deb13ae1ab91e6164cd26f2be" translate="yes" xml:space="preserve">
          <source>T_{i}</source>
          <target state="translated">T_{i}</target>
        </trans-unit>
        <trans-unit id="e80c75f58bfc00b9ae732035ef70cb00333f4a1c" translate="yes" xml:space="preserve">
          <source>Take in and process masked source/target sequences.</source>
          <target state="translated">接收和处理屏蔽的源/目标序列。</target>
        </trans-unit>
        <trans-unit id="945a1e1f48dcf43605fff2c03f1828ea5952eb79" translate="yes" xml:space="preserve">
          <source>Take the instruction &lt;code&gt;%rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10&lt;/code&gt; for example.</source>
          <target state="translated">以指令 &lt;code&gt;%rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10&lt;/code&gt; 为例。</target>
        </trans-unit>
        <trans-unit id="e94daa7e8a28b957c758019bcfa728a98c04545f" translate="yes" xml:space="preserve">
          <source>Takes LongTensor with index values of shape &lt;code&gt;(*)&lt;/code&gt; and returns a tensor of shape &lt;code&gt;(*, num_classes)&lt;/code&gt; that have zeros everywhere except where the index of last dimension matches the corresponding value of the input tensor, in which case it will be 1.</source>
          <target state="translated">接受带有形状 &lt;code&gt;(*)&lt;/code&gt; 索引值的LongTensor并返回一个形状 &lt;code&gt;(*, num_classes)&lt;/code&gt; 的张量，该张量在各处都为零，除非最后一维的索引与输入张量的对应值匹配，在这种情况下它将为1。</target>
        </trans-unit>
        <trans-unit id="7d3331f3bb652437bd8045860b4a682532d6d90a" translate="yes" xml:space="preserve">
          <source>Takes the inverse of the square matrix &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">取方阵 &lt;code&gt;input&lt;/code&gt; 的逆。</target>
        </trans-unit>
        <trans-unit id="537dfa1e7ebc0ec78b53314930b233f489d3f1c5" translate="yes" xml:space="preserve">
          <source>Takes the inverse of the square matrix &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; can be batches of 2D square tensors, in which case this function would return a tensor composed of individual inverses.</source>
          <target state="translated">取方阵 &lt;code&gt;input&lt;/code&gt; 的逆。 &lt;code&gt;input&lt;/code&gt; 可以是2D方形张量的批处理，在这种情况下，此函数将返回由各个逆组成的张量。</target>
        </trans-unit>
        <trans-unit id="b0ad657474446cfbcb32a233330ba630a430b967" translate="yes" xml:space="preserve">
          <source>Takes the power of each element in &lt;code&gt;input&lt;/code&gt; with &lt;code&gt;exponent&lt;/code&gt; and returns a tensor with the result.</source>
          <target state="translated">以 &lt;code&gt;exponent&lt;/code&gt; &lt;code&gt;input&lt;/code&gt; 中每个元素的幂，并返回张量与结果。</target>
        </trans-unit>
        <trans-unit id="a9d3154243fedb184083b9dcec0135d9da418872" translate="yes" xml:space="preserve">
          <source>Taking a real-valued frequency signal and bringing it into the time domain gives Hermitian symmetric output:</source>
          <target state="translated">将一个实值频率信号带入时域,得到赫米特对称输出。</target>
        </trans-unit>
        <trans-unit id="7ffacc7470da0fe6c6a8dae8d1ef37e2319cadeb" translate="yes" xml:space="preserve">
          <source>Taking an optimization step</source>
          <target state="translated">采取优化措施</target>
        </trans-unit>
        <trans-unit id="fd4e923c14f3ac2ab68ed029691caa5081fb04f7" translate="yes" xml:space="preserve">
          <source>Taking care of batch normalization</source>
          <target state="translated">照顾批次正常化</target>
        </trans-unit>
        <trans-unit id="19bff9fbbbadd7b339e0ee0ae1715d62fea9cae0" translate="yes" xml:space="preserve">
          <source>Tanh</source>
          <target state="translated">Tanh</target>
        </trans-unit>
        <trans-unit id="fa7acfd0630e85ee187c290a39277eaf9f5359da" translate="yes" xml:space="preserve">
          <source>Tanhshrink</source>
          <target state="translated">Tanhshrink</target>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="3032d3d269195493b60b2b5232d8a35ccf1cf179" translate="yes" xml:space="preserve">
          <source>Target_lengths: Tuple or tensor of size</source>
          <target state="translated">Target_lengths:大小的元组或张量。</target>
        </trans-unit>
        <trans-unit id="cce3202a79fe1345bd15442aee9a15d0666fb25f" translate="yes" xml:space="preserve">
          <source>Targets: Tensor of size</source>
          <target state="translated">目标。大小的张量</target>
        </trans-unit>
        <trans-unit id="680cb2d3fe397d144ed6bcd0531961c3a05ca6c0" translate="yes" xml:space="preserve">
          <source>Tensor</source>
          <target state="translated">Tensor</target>
        </trans-unit>
        <trans-unit id="7d374fa02b51c2a0bd017c85ffdbaad8aa59c748" translate="yes" xml:space="preserve">
          <source>Tensor Attributes</source>
          <target state="translated">张量属性</target>
        </trans-unit>
        <trans-unit id="47b8aa0b5113cdb5b15d1487280d5b3f9b245998" translate="yes" xml:space="preserve">
          <source>Tensor Views</source>
          <target state="translated">Tensor Views</target>
        </trans-unit>
        <trans-unit id="a7ecaeb20f986ea84c795703082ccf954c1b6a60" translate="yes" xml:space="preserve">
          <source>Tensor autograd functions</source>
          <target state="translated">Tensor自动识别功能</target>
        </trans-unit>
        <trans-unit id="7d5ce15cb1a252917b40c643e7a2eb6d5463df19" translate="yes" xml:space="preserve">
          <source>Tensor can be also expanded to a larger number of dimensions, and the new ones will be appended at the front. For the new dimensions, the size cannot be set to -1.</source>
          <target state="translated">Tensor也可以扩展到更多的维度,新的维度会附加在前面。对于新的维度,尺寸不能设置为-1。</target>
        </trans-unit>
        <trans-unit id="44e4866b0b5a5220d0057d20a02b4c4e9ccd49d7" translate="yes" xml:space="preserve">
          <source>Tensor iterating over dimension 0.</source>
          <target state="translated">张量在0维上迭代。</target>
        </trans-unit>
        <trans-unit id="968efb5c209c67b8c5e5cb36ab67b3d4543380ee" translate="yes" xml:space="preserve">
          <source>Tensor of shape batch_shape.</source>
          <target state="translated">batch_shape形状的张量。</target>
        </trans-unit>
        <trans-unit id="1f4edfd7fe26e893eda2475a21249dda3127731b" translate="yes" xml:space="preserve">
          <source>Tensor of size &lt;code&gt;T x B x *&lt;/code&gt; if &lt;code&gt;batch_first&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;. Tensor of size &lt;code&gt;B x T x *&lt;/code&gt; otherwise</source>
          <target state="translated">如果 &lt;code&gt;batch_first&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; ，则大小为 &lt;code&gt;T x B x *&lt;/code&gt; 的张量。大小的张量 &lt;code&gt;B x T x *&lt;/code&gt; 否则</target>
        </trans-unit>
        <trans-unit id="1f64e01f2c0bfc00c617fa5cfe062d17dd7881fa" translate="yes" xml:space="preserve">
          <source>TensorPipe Backend</source>
          <target state="translated">TensorPipe后端</target>
        </trans-unit>
        <trans-unit id="6fa30b4e43ae7ab6c13e5a62747d73bd4f6a50ff" translate="yes" xml:space="preserve">
          <source>Tensors</source>
          <target state="translated">Tensors</target>
        </trans-unit>
        <trans-unit id="3f3793b3bb16961a91ba80319c433489d751557f" translate="yes" xml:space="preserve">
          <source>Tensors may not have two named dimensions with the same name.</source>
          <target state="translated">天子不得有两个同名的维度。</target>
        </trans-unit>
        <trans-unit id="7a4ff50c90d4ae49393e7ddb58e4182969af3c75" translate="yes" xml:space="preserve">
          <source>Ternary Expressions</source>
          <target state="translated">三元表达式</target>
        </trans-unit>
        <trans-unit id="3aa34ed971590db58293e74b01ccf27489043c07" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; has its sign bit set (is less than zero) or not.</source>
          <target state="translated">测试 &lt;code&gt;input&lt;/code&gt; 每个元素是否设置了其符号位（小于零）。</target>
        </trans-unit>
        <trans-unit id="a5de15b26e6a795a7480af2f5882e1811d35f284" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; is infinite (positive or negative infinity) or not.</source>
          <target state="translated">测试 &lt;code&gt;input&lt;/code&gt; 每个元素是否为无限大（正无穷大或负无穷大）。</target>
        </trans-unit>
        <trans-unit id="a0285b21693b5a12974f50c902b26299554e6465" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; is negative infinity or not.</source>
          <target state="translated">测试 &lt;code&gt;input&lt;/code&gt; 每个元素是否为负无穷大。</target>
        </trans-unit>
        <trans-unit id="69536d45bf03029aac4041aa441f6044c68432e4" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; is positive infinity or not.</source>
          <target state="translated">测试 &lt;code&gt;input&lt;/code&gt; 每个元素是否为正无穷大。</target>
        </trans-unit>
        <trans-unit id="93ef0dd827103681fcee453b78be2ff14e1a261d" translate="yes" xml:space="preserve">
          <source>The</source>
          <target state="translated">The</target>
        </trans-unit>
        <trans-unit id="2312d5bb8d4ccdb5a8d40c96ff98fa570d836574" translate="yes" xml:space="preserve">
          <source>The 1-dimensional dot product version of this function does not support an &lt;code&gt;out&lt;/code&gt; parameter.</source>
          <target state="translated">此功能的一维点积产品版本不支持 &lt;code&gt;out&lt;/code&gt; 参数。</target>
        </trans-unit>
        <trans-unit id="f0763c643a0c9e64fc2e1987a16313347a5b7157" translate="yes" xml:space="preserve">
          <source>The 1.6 release of PyTorch switched &lt;code&gt;torch.save&lt;/code&gt; to use a new zipfile-based file format. &lt;code&gt;torch.load&lt;/code&gt; still retains the ability to load files in the old format. If for any reason you want &lt;code&gt;torch.save&lt;/code&gt; to use the old format, pass the kwarg &lt;code&gt;_use_new_zipfile_serialization=False&lt;/code&gt;.</source>
          <target state="translated">1.6版本PyTorch的切换 &lt;code&gt;torch.save&lt;/code&gt; 使用新的基于压缩文件的文件格式。 &lt;code&gt;torch.load&lt;/code&gt; 仍然保留以旧格式加载文件的功能。如果出于任何原因您希望 &lt;code&gt;torch.save&lt;/code&gt; 使用旧格式，请传递kwarg &lt;code&gt;_use_new_zipfile_serialization=False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="539ba0cb4053409de4820d1ae27b5ebc56acc073" translate="yes" xml:space="preserve">
          <source>The 1cycle learning rate policy changes the learning rate after every batch. &lt;code&gt;step&lt;/code&gt; should be called after a batch has been used for training.</source>
          <target state="translated">1cycle学习率策略会在每批之后更改学习率。一批用于培训后，应调用 &lt;code&gt;step&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a532bc29eaf3d25b0af52da2857f32bdfeed457d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt;th dimension of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; must have the same size as the length of &lt;code&gt;index&lt;/code&gt; (which must be a vector), and all other dimensions must match &lt;code&gt;self&lt;/code&gt;, or an error will be raised.</source>
          <target state="translated">&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt;的&lt;a href=&quot;#torch.Tensor.dim&quot;&gt; &lt;code&gt;dim&lt;/code&gt; &lt;/a&gt;维度必须与 &lt;code&gt;index&lt;/code&gt; 的长度（必须是向量）的长度相同，并且所有其他维度必须与 &lt;code&gt;self&lt;/code&gt; 匹配，否则会产生错误。</target>
        </trans-unit>
        <trans-unit id="cbb84ae310dddae342bffdaeaa243633f2a53249" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.quasirandom.SobolEngine&quot;&gt;&lt;code&gt;torch.quasirandom.SobolEngine&lt;/code&gt;&lt;/a&gt; is an engine for generating (scrambled) Sobol sequences. Sobol sequences are an example of low discrepancy quasi-random sequences.</source>
          <target state="translated">该&lt;a href=&quot;#torch.quasirandom.SobolEngine&quot;&gt; &lt;code&gt;torch.quasirandom.SobolEngine&lt;/code&gt; &lt;/a&gt;是用于生成（加扰）Sobol序列的发动机。Sobol序列是低差异准随机序列的一个示例。</target>
        </trans-unit>
        <trans-unit id="d2e5c436ae6a7b841286261fcf013451bf51db2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; argument in functions can generally be substituted with a string. This allows for fast prototyping of code.</source>
          <target state="translated">函数中的&lt;a href=&quot;#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;参数通常可以用字符串替换。这样可以实现代码的快速原型制作。</target>
        </trans-unit>
        <trans-unit id="f98c90dfa427c3d98ac8ee0cbb86e967d2daadab" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; contains a device type (&lt;code&gt;'cpu'&lt;/code&gt; or &lt;code&gt;'cuda'&lt;/code&gt;) and optional device ordinal for the device type. If the device ordinal is not present, this object will always represent the current device for the device type, even after &lt;a href=&quot;cuda#torch.cuda.set_device&quot;&gt;&lt;code&gt;torch.cuda.set_device()&lt;/code&gt;&lt;/a&gt; is called; e.g., a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; constructed with device &lt;code&gt;'cuda'&lt;/code&gt; is equivalent to &lt;code&gt;'cuda:X'&lt;/code&gt; where X is the result of &lt;a href=&quot;cuda#torch.cuda.current_device&quot;&gt;&lt;code&gt;torch.cuda.current_device()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">所述&lt;a href=&quot;#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;包含设备类型（ &lt;code&gt;'cpu'&lt;/code&gt; 或 &lt;code&gt;'cuda'&lt;/code&gt; 设备类型）和可选的设备的序号。如果不存在设备序号，则即使调用&lt;a href=&quot;cuda#torch.cuda.set_device&quot;&gt; &lt;code&gt;torch.cuda.set_device()&lt;/code&gt; &lt;/a&gt;，该对象也始终代表设备类型的当前设备。例如，使用设备 &lt;code&gt;'cuda'&lt;/code&gt; 构造的&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;等效于 &lt;code&gt;'cuda:X'&lt;/code&gt; ，其中X是&lt;a href=&quot;cuda#torch.cuda.current_device&quot;&gt; &lt;code&gt;torch.cuda.current_device()&lt;/code&gt; &lt;/a&gt;的结果。</target>
        </trans-unit>
        <trans-unit id="fb07fddc9a5d6fb2f9f535ebf9278f5523df3bef" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; supports both map-style and iterable-style datasets with single- or multi-process loading, customizing loading order and optional automatic batching (collation) and memory pinning.</source>
          <target state="translated">所述&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;支持地图风格和迭代式的数据集与单或多进程加载，定制加载顺序和可选的自动配料（对照）和存储器的钉扎。</target>
        </trans-unit>
        <trans-unit id="36716fd31e682e7596ade3d0fc033b9418b25151" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; annotation&amp;rsquo;s behavior changes in PyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function or method callable from code that is exported. To get this functionality back, use &lt;code&gt;@torch.jit.unused()&lt;/code&gt;. &lt;code&gt;@torch.jit.ignore&lt;/code&gt; is now equivalent to &lt;code&gt;@torch.jit.ignore(drop=False)&lt;/code&gt;. See &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;@torch.jit.unused&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">该&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt; &lt;code&gt;@torch.jit.ignore&lt;/code&gt; &lt;/a&gt;注解的行为PyTorch 1.2变化。在PyTorch 1.2之前，@ ignore装饰器用于使函数或方法可从导出的代码中调用。要恢复此功能，请使用 &lt;code&gt;@torch.jit.unused()&lt;/code&gt; 。 &lt;code&gt;@torch.jit.ignore&lt;/code&gt; 现在等效于 &lt;code&gt;@torch.jit.ignore(drop=False)&lt;/code&gt; 。有关详细信息，请参见&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt; &lt;code&gt;@torch.jit.ignore&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt; &lt;code&gt;@torch.jit.unused&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="629d16d00f1d4af587a0e984e39f346b9c762a9d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/torch.quasirandom.sobolengine#torch.quasirandom.SobolEngine&quot;&gt;&lt;code&gt;torch.quasirandom.SobolEngine&lt;/code&gt;&lt;/a&gt; is an engine for generating (scrambled) Sobol sequences.</source>
          <target state="translated">该&lt;a href=&quot;generated/torch.quasirandom.sobolengine#torch.quasirandom.SobolEngine&quot;&gt; &lt;code&gt;torch.quasirandom.SobolEngine&lt;/code&gt; &lt;/a&gt;是用于生成（加扰）Sobol序列的发动机。</target>
        </trans-unit>
        <trans-unit id="b29b06dcd5a85e7f1ec30bf4cac512a58a2b2613" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback-Leibler_divergence&quot;&gt;Kullback-Leibler divergence Loss&lt;/a&gt;</source>
          <target state="translated">在&lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback-Leibler_divergence&quot;&gt;相对熵损失&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9f5b85ebb4e0453454d4b99cfd4ca555eb171ffc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;multiprocessing#multiprocessing-doc&quot;&gt;Multiprocessing package - torch.multiprocessing&lt;/a&gt; package also provides a &lt;code&gt;spawn&lt;/code&gt; function in &lt;a href=&quot;multiprocessing#torch.multiprocessing.spawn&quot;&gt;&lt;code&gt;torch.multiprocessing.spawn()&lt;/code&gt;&lt;/a&gt;. This helper function can be used to spawn multiple processes. It works by passing in the function that you want to run and spawns N processes to run it. This can be used for multiprocess distributed training as well.</source>
          <target state="translated">的&lt;a href=&quot;multiprocessing#multiprocessing-doc&quot;&gt;多重处理包- torch.multiprocessing&lt;/a&gt;包还提供了一种 &lt;code&gt;spawn&lt;/code&gt; 在功能&lt;a href=&quot;multiprocessing#torch.multiprocessing.spawn&quot;&gt; &lt;code&gt;torch.multiprocessing.spawn()&lt;/code&gt; &lt;/a&gt;。此辅助函数可用于产生多个进程。它通过传入要运行的函数并产生N个进程来运行它而起作用。这也可以用于多进程分布式培训。</target>
        </trans-unit>
        <trans-unit id="9e1098da0df12b2fcc4a3fa80eabfd00f062a3e8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;torch.mean#torch.mean&quot;&gt;&lt;code&gt;mean&lt;/code&gt;&lt;/a&gt; is a tensor with the mean of each output element&amp;rsquo;s normal distribution</source>
          <target state="translated">的&lt;a href=&quot;torch.mean#torch.mean&quot;&gt; &lt;code&gt;mean&lt;/code&gt; &lt;/a&gt;与每个输出元件的正常分布的平均值的张量</target>
        </trans-unit>
        <trans-unit id="235814295d4fe94a904ed9a1a782c8eebf3b58c5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;torch.std#torch.std&quot;&gt;&lt;code&gt;std&lt;/code&gt;&lt;/a&gt; is a tensor with the standard deviation of each output element&amp;rsquo;s normal distribution</source>
          <target state="translated">该&lt;a href=&quot;torch.std#torch.std&quot;&gt; &lt;code&gt;std&lt;/code&gt; &lt;/a&gt;是与每个输出元件的正态分布的标准偏差的张量</target>
        </trans-unit>
        <trans-unit id="2fc3044dc4c4ace9a26403a7a793e46904198525" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;@torch.jit.script&lt;/code&gt; decorator will construct a &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; by compiling the body of the function.</source>
          <target state="translated">该 &lt;code&gt;@torch.jit.script&lt;/code&gt; 装饰将构造一个&lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt;通过编译函数体。</target>
        </trans-unit>
        <trans-unit id="b8a401f5a86feecc05362977ef403b66b5efedab" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;@torch.jit.script_method&lt;/code&gt; decorator</source>
          <target state="translated">该 &lt;code&gt;@torch.jit.script_method&lt;/code&gt; 装饰</target>
        </trans-unit>
        <trans-unit id="9011f0cf08e406be11c8a00cbbbc2003dbdb187f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Final&lt;/code&gt; type constructor can be used to mark members as &lt;code&gt;constant&lt;/code&gt;. If members are not marked constant, they will be copied to the resulting &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; as an attribute. Using &lt;code&gt;Final&lt;/code&gt; opens opportunities for optimization if the value is known to be fixed and gives additional type safety.</source>
          <target state="translated">的 &lt;code&gt;Final&lt;/code&gt; 类型构造函数可以被用于标记成员 &lt;code&gt;constant&lt;/code&gt; 。如果成员未标记为常量，则将它们作为属性复制到生成的&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;中。如果已知该值是固定的，那么使用 &lt;code&gt;Final&lt;/code&gt; 可以打开优化的机会，并提供额外的类型安全性。</target>
        </trans-unit>
        <trans-unit id="94d670ae23dc45d9238050515c460edb409b464f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;MixtureSameFamily&lt;/code&gt; distribution implements a (batch of) mixture distribution where all component are from different parameterizations of the same distribution type. It is parameterized by a &lt;code&gt;Categorical&lt;/code&gt; &amp;ldquo;selecting distribution&amp;rdquo; (over &lt;code&gt;k&lt;/code&gt; component) and a component distribution, i.e., a &lt;code&gt;Distribution&lt;/code&gt; with a rightmost batch shape (equal to &lt;code&gt;[k]&lt;/code&gt;) which indexes each (batch of) component.</source>
          <target state="translated">所述 &lt;code&gt;MixtureSameFamily&lt;/code&gt; 分布实现了一个（批）混合物分布，其中所有部件都从相同的分布类型的不同参数。它通过 &lt;code&gt;Categorical&lt;/code&gt; &amp;ldquo;选择分布&amp;rdquo;（在 &lt;code&gt;k&lt;/code&gt; 个成分上）和一个成分分布（即具有最右批形（等于 &lt;code&gt;[k]&lt;/code&gt; ）的 &lt;code&gt;Distribution&lt;/code&gt; ）对每个（批次）成分进行参数化。</target>
        </trans-unit>
        <trans-unit id="681a06025ef48d63b48a8f0ade5d434c9ed8e4d8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;None&lt;/code&gt; check must be within the if-statement&amp;rsquo;s condition; assigning a &lt;code&gt;None&lt;/code&gt; check to a variable and using it in the if-statement&amp;rsquo;s condition will not refine the types of variables in the check. Only local variables will be refined, an attribute like &lt;code&gt;self.x&lt;/code&gt; will not and must assigned to a local variable to be refined.</source>
          <target state="translated">在 &lt;code&gt;None&lt;/code&gt; 检查必须是if语句的条件中; 为变量分配 &lt;code&gt;None&lt;/code&gt; 检查并在if语句的条件下使用它不会优化检查中变量的类型。仅局部变量将被细化，诸如 &lt;code&gt;self.x&lt;/code&gt; 之类的属性将不会且必须分配给要细化的局部变量。</target>
        </trans-unit>
        <trans-unit id="c57db6f6aeb13e4c4808482871b866cd32a08ce8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SummaryWriter&lt;/code&gt; class provides a high-level API to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.</source>
          <target state="translated">该 &lt;code&gt;SummaryWriter&lt;/code&gt; 类提供了一个高层次的API来创建指定目录的事件文件，并添加摘要和事件给它。该类异步更新文件内容。这允许训练程序从训练循环中调用直接将数据添加到文件的方法，而不会减慢训练速度。</target>
        </trans-unit>
        <trans-unit id="965753cbd79a45739bc9ad1bc6ad8aab3c55f336" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;__constants__&lt;/code&gt; array</source>
          <target state="translated">的 &lt;code&gt;__constants__&lt;/code&gt; 阵列</target>
        </trans-unit>
        <trans-unit id="f242923c2659bf7bc5a464857040425ba312d13f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;__len__()&lt;/code&gt; method isn&amp;rsquo;t strictly required by &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt;, but is expected in any calculation involving the length of a &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">所述 &lt;code&gt;__len__()&lt;/code&gt; 方法并不严格要求&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;，但在涉及的长度的任何计算预计&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="eba7c266175279603efbf76b860806dfd23d6385" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;drop_last&lt;/code&gt; arguments essentially are used to construct a &lt;code&gt;batch_sampler&lt;/code&gt; from &lt;code&gt;sampler&lt;/code&gt;. For map-style datasets, the &lt;code&gt;sampler&lt;/code&gt; is either provided by user or constructed based on the &lt;code&gt;shuffle&lt;/code&gt; argument. For iterable-style datasets, the &lt;code&gt;sampler&lt;/code&gt; is a dummy infinite one. See &lt;a href=&quot;#data-loading-order-and-sampler&quot;&gt;this section&lt;/a&gt; on more details on samplers.</source>
          <target state="translated">该 &lt;code&gt;batch_size&lt;/code&gt; 时和 &lt;code&gt;drop_last&lt;/code&gt; 参数主要被用来构建一个 &lt;code&gt;batch_sampler&lt;/code&gt; 从 &lt;code&gt;sampler&lt;/code&gt; 。对于地图样式的数据集， &lt;code&gt;sampler&lt;/code&gt; 可以由用户提供，也可以根据 &lt;code&gt;shuffle&lt;/code&gt; 参数构造。对于可迭代样式的数据集， &lt;code&gt;sampler&lt;/code&gt; 是一个虚拟的无限采样器。有关采样器的更多详细信息，请参见&lt;a href=&quot;#data-loading-order-and-sampler&quot;&gt;本节&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a26eee2b4f8c5fa56dc0e1b6d51769e2674252ff" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;biject_to()&lt;/code&gt; registry is useful for Hamiltonian Monte Carlo, where samples from a probability distribution with constrained &lt;code&gt;.support&lt;/code&gt; are propagated in an unconstrained space, and algorithms are typically rotation invariant.:</source>
          <target state="translated">所述 &lt;code&gt;biject_to()&lt;/code&gt; 注册表是哈密顿蒙特卡洛，其中来自概率分布样品用约束有用 &lt;code&gt;.support&lt;/code&gt; 在无约束的空间中传播，并且算法通常旋转不变.:</target>
        </trans-unit>
        <trans-unit id="6d56e7b5edb09cb0ed4ea4637fa714f0dc8503dd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;biject_to&lt;/code&gt; and &lt;code&gt;transform_to&lt;/code&gt; objects can be extended by user-defined constraints and transforms using their &lt;code&gt;.register()&lt;/code&gt; method either as a function on singleton constraints:</source>
          <target state="translated">的 &lt;code&gt;biject_to&lt;/code&gt; 和 &lt;code&gt;transform_to&lt;/code&gt; 目的可以通过使用他们的用户定义的约束和变换被扩展 &lt;code&gt;.register()&lt;/code&gt; 方法既可以作为单上的约束的函数：</target>
        </trans-unit>
        <trans-unit id="44a5102b3b32f58d5c9c3eb95af7ab62d791ac38" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;callable&lt;/code&gt; should have the signature:</source>
          <target state="translated">该 &lt;code&gt;callable&lt;/code&gt; 应具备的特征：</target>
        </trans-unit>
        <trans-unit id="c4cd295b30506f6711ba85f58a42cc9115e197d2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;delete_key&lt;/code&gt; API is only supported by the &lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt;&lt;code&gt;TCPStore&lt;/code&gt;&lt;/a&gt;. Using this API with the &lt;a href=&quot;#torch.distributed.FileStore&quot;&gt;&lt;code&gt;FileStore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributed.HashStore&quot;&gt;&lt;code&gt;HashStore&lt;/code&gt;&lt;/a&gt; will result in an exception.</source>
          <target state="translated">该 &lt;code&gt;delete_key&lt;/code&gt; API仅受支持&lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt; &lt;code&gt;TCPStore&lt;/code&gt; &lt;/a&gt;。将此API与&lt;a href=&quot;#torch.distributed.FileStore&quot;&gt; &lt;code&gt;FileStore&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;#torch.distributed.HashStore&quot;&gt; &lt;code&gt;HashStore&lt;/code&gt; 一起使用&lt;/a&gt;将导致异常。</target>
        </trans-unit>
        <trans-unit id="79ae973263b72787a35d19a21f1d5ebc7a491f12" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;distributions&lt;/code&gt; package contains parameterizable probability distributions and sampling functions. This allows the construction of stochastic computation graphs and stochastic gradient estimators for optimization. This package generally follows the design of the &lt;a href=&quot;https://arxiv.org/abs/1711.10604&quot;&gt;TensorFlow Distributions&lt;/a&gt; package.</source>
          <target state="translated">的 &lt;code&gt;distributions&lt;/code&gt; 包中包含参数化概率分布和采样函数。这允许构建随机计算图和随机梯度估计器以进行优化。该软件包通常遵循&lt;a href=&quot;https://arxiv.org/abs/1711.10604&quot;&gt;TensorFlow Distributions&lt;/a&gt;软件包的设计。</target>
        </trans-unit>
        <trans-unit id="3e75f8845977efa943a8e24244efa0158e93fd55" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;grad_input&lt;/code&gt; and &lt;code&gt;grad_output&lt;/code&gt; may be tuples if the module has multiple inputs or outputs. The hook should not modify its arguments, but it can optionally return a new gradient with respect to input that will be used in place of &lt;code&gt;grad_input&lt;/code&gt; in subsequent computations. &lt;code&gt;grad_input&lt;/code&gt; will only correspond to the inputs given as positional arguments.</source>
          <target state="translated">的 &lt;code&gt;grad_input&lt;/code&gt; 和 &lt;code&gt;grad_output&lt;/code&gt; 可以是元组如果模块具有多个输入或输出。挂钩不应该修改其参数，但是可以选择相对于输入返回新的梯度，该梯度将在后续计算中代替 &lt;code&gt;grad_input&lt;/code&gt; 。 &lt;code&gt;grad_input&lt;/code&gt; 将仅对应于作为位置参数给出的输入。</target>
        </trans-unit>
        <trans-unit id="c418e4ba558348daf084f57cfc5ba8f635661eb0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;gradient_as_bucket_view&lt;/code&gt; mode does not yet work with Automatic Mixed Precision (AMP). AMP maintains stashed gradients that are used for unscaling gradients. With &lt;code&gt;gradient_as_bucket_view=True&lt;/code&gt;, these stashed gradients will point to communication buckets in the first iteration. In the next iteration, the communication buckets are mutated and thus these stashed gradients will be unexpectedly mutated as well, which might lead to wrong results.</source>
          <target state="translated">该 &lt;code&gt;gradient_as_bucket_view&lt;/code&gt; 模式尚不支持自动混精密（AMP）的工作。AMP保留用于渐变缩放的隐藏渐变。使用 &lt;code&gt;gradient_as_bucket_view=True&lt;/code&gt; 时，这些隐藏的渐变将在第一次迭代中指向通信存储段。在下一次迭代中，通信桶被突变，因此这些隐蔽的梯度也将被意外地突变，这可能导致错误的结果。</target>
        </trans-unit>
        <trans-unit id="1fd870aae016b2c00935c2fbc6c52d9270bae088" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; given through a forward call is expected to contain log-probabilities of each class. &lt;code&gt;input&lt;/code&gt; has to be a Tensor of size either</source>
          <target state="translated">通过前向调用给出的 &lt;code&gt;input&lt;/code&gt; 应包含每个类的对数概率。 &lt;code&gt;input&lt;/code&gt; 必须是大小的张量</target>
        </trans-unit>
        <trans-unit id="60f14a9d856acc735af342914f0ff8281b2528f6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; is expected to contain raw, unnormalized scores for each class.</source>
          <target state="translated">该 &lt;code&gt;input&lt;/code&gt; 预计将包含原始，非标准化的分数为每个类。</target>
        </trans-unit>
        <trans-unit id="6624e1abebb827c38014a043499dfb4fc7c338b8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; tensor should be a tensor containing probabilities to be used for drawing the binary random number. Hence, all values in &lt;code&gt;input&lt;/code&gt; have to be in the range:</source>
          <target state="translated">的 &lt;code&gt;input&lt;/code&gt; 张量应是用于绘制的二进制随机数包含概率的张量。因此， &lt;code&gt;input&lt;/code&gt; 所有值都必须在以下范围内：</target>
        </trans-unit>
        <trans-unit id="fb4a0ff705e3f1a46ebc8daed33e4bce289527c8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mask&lt;/code&gt; operates on the &lt;code&gt;self&lt;/code&gt; tensor, not on the given &lt;code&gt;source&lt;/code&gt; tensor.</source>
          <target state="translated">在 &lt;code&gt;mask&lt;/code&gt; 上运行 &lt;code&gt;self&lt;/code&gt; 张量，而不是在给定的 &lt;code&gt;source&lt;/code&gt; 张量。</target>
        </trans-unit>
        <trans-unit id="ad5a92992bc736ff5322b797aa0cf7673e44901d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;n_fft&lt;/code&gt;, &lt;code&gt;hop_length&lt;/code&gt;, &lt;code&gt;win_length&lt;/code&gt; are all the same which prevents the calculation of right padding. These additional values could be zeros or a reflection of the signal so providing &lt;code&gt;length&lt;/code&gt; could be useful. If &lt;code&gt;length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; then padding will be aggressively removed (some loss of signal).</source>
          <target state="translated">的 &lt;code&gt;n_fft&lt;/code&gt; ， &lt;code&gt;hop_length&lt;/code&gt; ， &lt;code&gt;win_length&lt;/code&gt; 都是其防止右填充的计算是相同的。这些附加值可能为零或信号的反射，因此提供 &lt;code&gt;length&lt;/code&gt; 可能会很有用。如果 &lt;code&gt;length&lt;/code&gt; 为&amp;ldquo; &lt;code&gt;None&lt;/code&gt; 则将积极删除填充（某些信号丢失）。</target>
        </trans-unit>
        <trans-unit id="e0ace9222bb0e305cbf096e49fb16c8bd736635b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;num_keys&lt;/code&gt; API is only supported by the &lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt;&lt;code&gt;TCPStore&lt;/code&gt;&lt;/a&gt;. Using this API with the &lt;a href=&quot;#torch.distributed.FileStore&quot;&gt;&lt;code&gt;FileStore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributed.HashStore&quot;&gt;&lt;code&gt;HashStore&lt;/code&gt;&lt;/a&gt; will result in an exception.</source>
          <target state="translated">该 &lt;code&gt;num_keys&lt;/code&gt; API仅受支持&lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt; &lt;code&gt;TCPStore&lt;/code&gt; &lt;/a&gt;。将此API与&lt;a href=&quot;#torch.distributed.FileStore&quot;&gt; &lt;code&gt;FileStore&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;#torch.distributed.HashStore&quot;&gt; &lt;code&gt;HashStore&lt;/code&gt; 一起使用&lt;/a&gt;将导致异常。</target>
        </trans-unit>
        <trans-unit id="8bd6f3dbf9c9f10c4e3b624b6d33b29b1f55e1ac" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument effectively adds &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; amount of zero padding to both sizes of the input. This is set so that when a &lt;a href=&quot;torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;#torch.nn.ConvTranspose1d&quot;&gt;&lt;code&gt;ConvTranspose1d&lt;/code&gt;&lt;/a&gt; are initialized with same parameters, they are inverses of each other in regard to the input and output shapes. However, when &lt;code&gt;stride &amp;gt; 1&lt;/code&gt;, &lt;a href=&quot;torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; maps multiple input shapes to the same output shape. &lt;code&gt;output_padding&lt;/code&gt; is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. Note that &lt;code&gt;output_padding&lt;/code&gt; is only used to find output shape, but does not actually add zero-padding to output.</source>
          <target state="translated">所述 &lt;code&gt;padding&lt;/code&gt; 参数有效地增加了 &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; 零填充的量与输入的两个尺寸。进行设置是为了在用相同的参数初始化&lt;a href=&quot;torch.nn.conv1d#torch.nn.Conv1d&quot;&gt; &lt;code&gt;Conv1d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.nn.ConvTranspose1d&quot;&gt; &lt;code&gt;ConvTranspose1d&lt;/code&gt; 时&lt;/a&gt;，它们在输入和输出形状方面彼此相反。但是，当 &lt;code&gt;stride &amp;gt; 1&lt;/code&gt; ，&lt;a href=&quot;torch.nn.conv1d#torch.nn.Conv1d&quot;&gt; &lt;code&gt;Conv1d&lt;/code&gt; &lt;/a&gt;会将多个输入形状映射到相同的输出形状。提供 &lt;code&gt;output_padding&lt;/code&gt; 可以通过有效地增加一侧的计算输出形状来解决这种歧义。请注意， &lt;code&gt;output_padding&lt;/code&gt; 仅用于查找输出形状，但实际上并未向输出添加零填充。</target>
        </trans-unit>
        <trans-unit id="5440e08e1ef68605bef85def7ab3c93778452300" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument effectively adds &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; amount of zero padding to both sizes of the input. This is set so that when a &lt;a href=&quot;torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;#torch.nn.ConvTranspose2d&quot;&gt;&lt;code&gt;ConvTranspose2d&lt;/code&gt;&lt;/a&gt; are initialized with same parameters, they are inverses of each other in regard to the input and output shapes. However, when &lt;code&gt;stride &amp;gt; 1&lt;/code&gt;, &lt;a href=&quot;torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; maps multiple input shapes to the same output shape. &lt;code&gt;output_padding&lt;/code&gt; is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. Note that &lt;code&gt;output_padding&lt;/code&gt; is only used to find output shape, but does not actually add zero-padding to output.</source>
          <target state="translated">所述 &lt;code&gt;padding&lt;/code&gt; 参数有效地增加了 &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; 零填充的量与输入的两个尺寸。进行设置是为了在用相同的参数初始化&lt;a href=&quot;torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;Conv2d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.nn.ConvTranspose2d&quot;&gt; &lt;code&gt;ConvTranspose2d&lt;/code&gt; 时&lt;/a&gt;，它们在输入和输出形状方面彼此相反。但是，当 &lt;code&gt;stride &amp;gt; 1&lt;/code&gt; ，&lt;a href=&quot;torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;Conv2d&lt;/code&gt; &lt;/a&gt;会将多个输入形状映射到相同的输出形状。提供 &lt;code&gt;output_padding&lt;/code&gt; 可以通过有效地增加一侧的计算输出形状来解决这种歧义。请注意， &lt;code&gt;output_padding&lt;/code&gt; 仅用于查找输出形状，但实际上并未向输出添加零填充。</target>
        </trans-unit>
        <trans-unit id="624a36cdb030302abd92f10a870506676fb58830" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument effectively adds &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; amount of zero padding to both sizes of the input. This is set so that when a &lt;a href=&quot;torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;#torch.nn.ConvTranspose3d&quot;&gt;&lt;code&gt;ConvTranspose3d&lt;/code&gt;&lt;/a&gt; are initialized with same parameters, they are inverses of each other in regard to the input and output shapes. However, when &lt;code&gt;stride &amp;gt; 1&lt;/code&gt;, &lt;a href=&quot;torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; maps multiple input shapes to the same output shape. &lt;code&gt;output_padding&lt;/code&gt; is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. Note that &lt;code&gt;output_padding&lt;/code&gt; is only used to find output shape, but does not actually add zero-padding to output.</source>
          <target state="translated">所述 &lt;code&gt;padding&lt;/code&gt; 参数有效地增加了 &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; 零填充的量与输入的两个尺寸。进行设置是为了在用相同的参数初始化&lt;a href=&quot;torch.nn.conv3d#torch.nn.Conv3d&quot;&gt; &lt;code&gt;Conv3d&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.nn.ConvTranspose3d&quot;&gt; &lt;code&gt;ConvTranspose3d&lt;/code&gt; 时&lt;/a&gt;，它们在输入和输出形状方面彼此相反。但是，当 &lt;code&gt;stride &amp;gt; 1&lt;/code&gt; ，&lt;a href=&quot;torch.nn.conv3d#torch.nn.Conv3d&quot;&gt; &lt;code&gt;Conv3d&lt;/code&gt; &lt;/a&gt;会将多个输入形状映射到相同的输出形状。提供 &lt;code&gt;output_padding&lt;/code&gt; 可以通过有效地增加一侧的计算输出形状来解决这种歧义。请注意， &lt;code&gt;output_padding&lt;/code&gt; 仅用于查找输出形状，但实际上并未向输出添加零填充。</target>
        </trans-unit>
        <trans-unit id="ac2a8aee0768d2dee229b10ae182a5bbe1013563" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt; and &lt;code&gt;dilation&lt;/code&gt; arguments specify how the sliding blocks are retrieved.</source>
          <target state="translated">该 &lt;code&gt;padding&lt;/code&gt; ， &lt;code&gt;stride&lt;/code&gt; 和 &lt;code&gt;dilation&lt;/code&gt; 参数指定的滑动块如何检索。</target>
        </trans-unit>
        <trans-unit id="9a86ce4705a9d8461e1968c13331ef942f95a281" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;remote&lt;/code&gt; API does not copy storages of argument tensors until sending them over the wire, which could be done by a different thread depending on the RPC backend type. The caller should make sure that the contents of those tensors stay intact until the returned RRef is confirmed by the owner, which can be checked using the &lt;a href=&quot;#torch.distributed.rpc.RRef.confirmed_by_owner&quot;&gt;&lt;code&gt;torch.distributed.rpc.RRef.confirmed_by_owner()&lt;/code&gt;&lt;/a&gt; API.</source>
          <target state="translated">该 &lt;code&gt;remote&lt;/code&gt; API不会复制参数张量的储存，直到通过线路，这可能是依赖于RPC后端类型不同的线程来完成送他们。调用者应确保在所有者确认返回的RRef之前，这些张量的内容保持不变，可以使用&lt;a href=&quot;#torch.distributed.rpc.RRef.confirmed_by_owner&quot;&gt; &lt;code&gt;torch.distributed.rpc.RRef.confirmed_by_owner()&lt;/code&gt; &lt;/a&gt; API进行检查。</target>
        </trans-unit>
        <trans-unit id="6d9f2b4532f5542083c83b1d9834f5f944e782fe" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;rpc_async&lt;/code&gt; API does not copy storages of argument tensors until sending them over the wire, which could be done by a different thread depending on the RPC backend type. The caller should make sure that the contents of those tensors stay intact until the returned &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; completes.</source>
          <target state="translated">该 &lt;code&gt;rpc_async&lt;/code&gt; API不会复制参数张量的储存，直到通过线路，这可能是依赖于RPC后端类型不同的线程来完成送他们。调用者应确保这些张量的内容保持不变，直到返回的&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;完成。</target>
        </trans-unit>
        <trans-unit id="3596722c9e70073957aeadba20c33b436e025428" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;spawn&lt;/code&gt; function below addresses these concerns and takes care of error propagation, out of order termination, and will actively terminate processes upon detecting an error in one of them.</source>
          <target state="translated">下面的 &lt;code&gt;spawn&lt;/code&gt; 功能解决了这些问题，并照顾了错误传播，乱序终止，并在检测到其中之一中的错误时主动终止了进程。</target>
        </trans-unit>
        <trans-unit id="8a7cdd56e507990bc132c8770c06d1f57641cbc2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;src&lt;/code&gt; tensor must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with the &lt;code&gt;self&lt;/code&gt; tensor. It may be of a different data type or reside on a different device.</source>
          <target state="translated">该 &lt;code&gt;src&lt;/code&gt; 张量必须&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;与 &lt;code&gt;self&lt;/code&gt; 张量。它可以是不同的数据类型，也可以驻留在不同的设备上。</target>
        </trans-unit>
        <trans-unit id="17a168b9f78b1ca48e7a2120cd057ee2f894411e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;target&lt;/code&gt; that this loss expects should be a class index in the range</source>
          <target state="translated">损失预期的 &lt;code&gt;target&lt;/code&gt; 应该是范围内的类别索引</target>
        </trans-unit>
        <trans-unit id="c1785ac75c5e40c0724177cfc6462e25d84d9b18" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.distributed&lt;/code&gt; package also provides a launch utility in &lt;code&gt;torch.distributed.launch&lt;/code&gt;. This helper utility can be used to launch multiple processes per node for distributed training.</source>
          <target state="translated">该 &lt;code&gt;torch.distributed&lt;/code&gt; 包还提供了一个启动程序 &lt;code&gt;torch.distributed.launch&lt;/code&gt; 。此帮助程序实用程序可用于为每个节点启动多个进程以进行分布式培训。</target>
        </trans-unit>
        <trans-unit id="72f50afcb54f84e9f4aac792b1e96785232d670d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.distributed&lt;/code&gt; package provides PyTorch support and communication primitives for multiprocess parallelism across several computation nodes running on one or more machines. The class &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt;&lt;/a&gt; builds on this functionality to provide synchronous distributed training as a wrapper around any PyTorch model. This differs from the kinds of parallelism provided by &lt;a href=&quot;multiprocessing&quot;&gt;Multiprocessing package - torch.multiprocessing&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel()&lt;/code&gt;&lt;/a&gt; in that it supports multiple network-connected machines and in that the user must explicitly launch a separate copy of the main training script for each process.</source>
          <target state="translated">所述 &lt;code&gt;torch.distributed&lt;/code&gt; 包提供跨在一个或多个计算机上运行的几个计算节点对多进程并行PyTorch支持与通信原语。类&lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt; &lt;/a&gt;建立在此功能的基础上，以提供同步的分布式训练作为任何PyTorch模型的包装器。这与&lt;a href=&quot;multiprocessing&quot;&gt;Multiprocessing软件包所&lt;/a&gt;提供的并行性类型不同-torch.multiprocessing和&lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt; &lt;code&gt;torch.nn.DataParallel()&lt;/code&gt; &lt;/a&gt;在于它支持多个与网络连接的机器，并且用户必须为每台机器显式启动主训练脚本的单独副本。过程。</target>
        </trans-unit>
        <trans-unit id="f1ce33b04ab70eff6a70899c7f72e87b970b8ffd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.futures&lt;/code&gt; package is a &lt;strong&gt;Prototype&lt;/strong&gt; feature and subject to change.</source>
          <target state="translated">该 &lt;code&gt;torch.futures&lt;/code&gt; 包是一个&lt;strong&gt;原型&lt;/strong&gt;功能，并可能发生变化。</target>
        </trans-unit>
        <trans-unit id="4ae3c23dcd7aaa1724a7bbfd85a5d075a7d8913b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.jit.Attribute&lt;/code&gt; wrapper class</source>
          <target state="translated">该 &lt;code&gt;torch.jit.Attribute&lt;/code&gt; 包装类</target>
        </trans-unit>
        <trans-unit id="cd6ab112f221ddabf781ca4bc22d2c58fdee3a44" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.jit.annotate&lt;/code&gt; function</source>
          <target state="translated">该 &lt;code&gt;torch.jit.annotate&lt;/code&gt; 功能</target>
        </trans-unit>
        <trans-unit id="addf386bae846dc433dd4589519a4e51ea1626e9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.layout&lt;/code&gt; class is in beta and subject to change.</source>
          <target state="translated">该 &lt;code&gt;torch.layout&lt;/code&gt; 类是处于测试阶段，可能发生变化。</target>
        </trans-unit>
        <trans-unit id="69af7e2fc3132014bb438bfe3f8c1bbddaee2ce2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.nn.Parameter&lt;/code&gt; wrapper and &lt;code&gt;register_buffer&lt;/code&gt; can be used to assign tensors to a module. Other values assigned to a module that is compiled will be added to the compiled module if their types can be inferred. All &lt;a href=&quot;#types&quot;&gt;types&lt;/a&gt; available in TorchScript can be used as module attributes. Tensor attributes are semantically the same as buffers. The type of empty lists and dictionaries and &lt;code&gt;None&lt;/code&gt; values cannot be inferred and must be specified via &lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;PEP 526-style&lt;/a&gt; class annotations. If a type cannot be inferred and is not explicilty annotated, it will not be added as an attribute to the resulting &lt;code&gt;ScriptModule&lt;/code&gt;.</source>
          <target state="translated">的 &lt;code&gt;torch.nn.Parameter&lt;/code&gt; 包装和 &lt;code&gt;register_buffer&lt;/code&gt; 可用于分配给张量的模块。如果可以推断出其他类型的值，则分配给已编译模块的其他值将添加到已编译模块中。TorchScript中可用的所有&lt;a href=&quot;#types&quot;&gt;类型&lt;/a&gt;都可以用作模块属性。张量属性在语义上与缓冲区相同。空列表和字典的类型以及 &lt;code&gt;None&lt;/code&gt; 值无法推断，必须通过&lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;PEP 526样式&lt;/a&gt;类注释指定。如果无法推断类型并且未对显式类型进行注释，则不会将其作为属性添加到生成的 &lt;code&gt;ScriptModule&lt;/code&gt; 中。</target>
        </trans-unit>
        <trans-unit id="dd928d04d4959114feb5d458396348030d86627d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;transform_to()&lt;/code&gt; registry is useful for performing unconstrained optimization on constrained parameters of probability distributions, which are indicated by each distribution&amp;rsquo;s &lt;code&gt;.arg_constraints&lt;/code&gt; dict. These transforms often overparameterize a space in order to avoid rotation; they are thus more suitable for coordinate-wise optimization algorithms like Adam:</source>
          <target state="translated">所述 &lt;code&gt;transform_to()&lt;/code&gt; 注册表是上的概率分布，这是由每个分布的指示的约束参数来执行无约束优化有用 &lt;code&gt;.arg_constraints&lt;/code&gt; 字典。为了避免旋转，这些变换通常对空间进行过参数化；因此，它们更适合于像Adam这样的坐标优化算法：</target>
        </trans-unit>
        <trans-unit id="1cee34c614aefb2bdef2c172499b9302c8a00b05" translate="yes" xml:space="preserve">
          <source>The API is 100% compatible with the original module - it&amp;rsquo;s enough to change &lt;code&gt;import multiprocessing&lt;/code&gt; to &lt;code&gt;import torch.multiprocessing&lt;/code&gt; to have all the tensors sent through the queues or shared via other mechanisms, moved to shared memory.</source>
          <target state="translated">该API与原始模块100％兼容-足以将 &lt;code&gt;import multiprocessing&lt;/code&gt; 更改为 &lt;code&gt;import torch.multiprocessing&lt;/code&gt; 以使所有张量通过队列发送或通过其他机制共享，并移至共享内存。</target>
        </trans-unit>
        <trans-unit id="fc46cba00894331ffa02531912b869b31d53f5a1" translate="yes" xml:space="preserve">
          <source>The Connectionist Temporal Classification loss.</source>
          <target state="translated">连接主义时空分类的损失。</target>
        </trans-unit>
        <trans-unit id="68d2c2ff975df64fa09115de4df3b92bf60905da" translate="yes" xml:space="preserve">
          <source>The FFT of a real signal is Hermitian-symmetric, &lt;code&gt;X[i] = conj(X[-i])&lt;/code&gt; so the output contains only the positive frequencies below the Nyquist frequency. To compute the full output, use &lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">实际信号的FFT是Hermitian对称的， &lt;code&gt;X[i] = conj(X[-i])&lt;/code&gt; 因此输出仅包含奈奎斯特频率以下的正频率。要计算完整输出，请使用&lt;a href=&quot;#torch.fft.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="554abbeeb98f672613a7ec23a19dc9e48ad28309" translate="yes" xml:space="preserve">
          <source>The FFT of a real signal is Hermitian-symmetric, &lt;code&gt;X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])&lt;/code&gt; so the full &lt;a href=&quot;#torch.fft.fftn&quot;&gt;&lt;code&gt;fftn()&lt;/code&gt;&lt;/a&gt; output contains redundant information. &lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt; instead omits the negative frequencies in the last dimension.</source>
          <target state="translated">实际信号的FFT是Hermitian对称的， &lt;code&gt;X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])&lt;/code&gt; 因此完整的&lt;a href=&quot;#torch.fft.fftn&quot;&gt; &lt;code&gt;fftn()&lt;/code&gt; &lt;/a&gt;输出包含冗余信息。&lt;a href=&quot;#torch.fft.rfftn&quot;&gt; &lt;code&gt;rfftn()&lt;/code&gt; &lt;/a&gt;会忽略最后一个维度中的负频率。</target>
        </trans-unit>
        <trans-unit id="7e13169ea1b51d49a8b92e863c0bf3126ef56123" translate="yes" xml:space="preserve">
          <source>The Fourier domain representation of any real signal satisfies the Hermitian property: &lt;code&gt;X[i] = conj(X[-i])&lt;/code&gt;. This function always returns both the positive and negative frequency terms even though, for real inputs, the negative frequencies are redundant. &lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt; returns the more compact one-sided representation where only the positive frequencies are returned.</source>
          <target state="translated">任何实信号的傅立叶域表示都满足Hermitian属性： &lt;code&gt;X[i] = conj(X[-i])&lt;/code&gt; 。该函数始终返回正和负频率项，即使对于实际输入，负频率是多余的。&lt;a href=&quot;#torch.fft.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt;返回更紧凑的单侧表示，其中仅返回正频率。</target>
        </trans-unit>
        <trans-unit id="c9fe021ce10d1cbbed575b9284c6f59da576001a" translate="yes" xml:space="preserve">
          <source>The Fourier domain representation of any real signal satisfies the Hermitian property: &lt;code&gt;X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])&lt;/code&gt;. This function always returns all positive and negative frequency terms even though, for real inputs, half of these values are redundant. &lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt; returns the more compact one-sided representation where only the positive frequencies of the last dimension are returned.</source>
          <target state="translated">任何实信号的傅立叶域表示都满足Hermitian属性： &lt;code&gt;X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])&lt;/code&gt; 。该功能始终返回所有正负频率项，即使对于实际输入，这些值中的一半是多余的。&lt;a href=&quot;#torch.fft.rfftn&quot;&gt; &lt;code&gt;rfftn()&lt;/code&gt; &lt;/a&gt;返回更紧凑的单面表示，其中仅返回最后一个维度的正频率。</target>
        </trans-unit>
        <trans-unit id="7ad0a191a9fee1e60e241897ad6f1ce3ecbb965d" translate="yes" xml:space="preserve">
          <source>The Kullback-Leibler divergence loss measure</source>
          <target state="translated">Kullback-Leibler发散损失测量法</target>
        </trans-unit>
        <trans-unit id="d60b9fe818a7402cdbe31175747d27cd34ed024b" translate="yes" xml:space="preserve">
          <source>The Nesterov version is analogously modified.</source>
          <target state="translated">内斯特洛夫的版本进行了类比修改。</target>
        </trans-unit>
        <trans-unit id="79342dbd5370ca7ac1b96027ceb5844371ecbc95" translate="yes" xml:space="preserve">
          <source>The ONNX exporter can be both &lt;em&gt;trace-based&lt;/em&gt; and &lt;em&gt;script-based&lt;/em&gt; exporter.</source>
          <target state="translated">该ONNX出口可以同时&lt;em&gt;跟踪为基础&lt;/em&gt;，并&lt;em&gt;基于脚本的&lt;/em&gt;出口国。</target>
        </trans-unit>
        <trans-unit id="c11a05ce23a6c40119d293ee087abf34796175d7" translate="yes" xml:space="preserve">
          <source>The ONNX graph C++ definition is in &lt;code&gt;torch/csrc/jit/ir/ir.h&lt;/code&gt;.</source>
          <target state="translated">ONNX图形C ++定义在 &lt;code&gt;torch/csrc/jit/ir/ir.h&lt;/code&gt; 中。</target>
        </trans-unit>
        <trans-unit id="0a8c3a370e79a6afd160a058933e30e88f62a863" translate="yes" xml:space="preserve">
          <source>The Process Group Backend will be deprecated soon, we recommend using the TensorPipe Backend instead.</source>
          <target state="translated">流程组后端即将被废弃,我们建议使用TensorPipe后端代替。</target>
        </trans-unit>
        <trans-unit id="c611b23c7d2afdcd9cdf21ee774e5b2b21bffaa1" translate="yes" xml:space="preserve">
          <source>The Process Group agent instantiates a process group from the &lt;a href=&quot;distributed#module-torch.distributed&quot;&gt;&lt;code&gt;distributed&lt;/code&gt;&lt;/a&gt; module and utilizes its point-to-point communication capabilities to send RPC messages. Internally, the process group uses &lt;a href=&quot;https://github.com/facebookincubator/gloo/&quot;&gt;the Gloo library&lt;/a&gt;.</source>
          <target state="translated">进程组代理从&lt;a href=&quot;distributed#module-torch.distributed&quot;&gt; &lt;code&gt;distributed&lt;/code&gt; &lt;/a&gt;模块实例化进程组，并利用其点对点通信功能发送RPC消息。在内部，进程组使用&lt;a href=&quot;https://github.com/facebookincubator/gloo/&quot;&gt;Gloo库&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a48f9bb3889d63ba5122c625f2532d0293bf1e9f" translate="yes" xml:space="preserve">
          <source>The RPC module can leverage different backends to perform the communication between the nodes. The backend to be used can be specified in the &lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt;&lt;code&gt;init_rpc()&lt;/code&gt;&lt;/a&gt; function, by passing a certain value of the &lt;a href=&quot;#torch.distributed.rpc.BackendType&quot;&gt;&lt;code&gt;BackendType&lt;/code&gt;&lt;/a&gt; enum. Regardless of what backend is used, the rest of the RPC API won&amp;rsquo;t change. Each backend also defines its own subclass of the &lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;&lt;code&gt;RpcBackendOptions&lt;/code&gt;&lt;/a&gt; class, an instance of which can also be passed to &lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt;&lt;code&gt;init_rpc()&lt;/code&gt;&lt;/a&gt; to configure the backend&amp;rsquo;s behavior.</source>
          <target state="translated">RPC模块可以利用不同的后端来执行节点之间的通信。通过传递&lt;a href=&quot;#torch.distributed.rpc.BackendType&quot;&gt; &lt;code&gt;BackendType&lt;/code&gt; &lt;/a&gt;枚举的某个值，可以在&lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt; &lt;code&gt;init_rpc()&lt;/code&gt; &lt;/a&gt;函数中指定要使用的后端。无论使用哪种后端，其余的RPC API都不会更改。每个后端还定义了自己的&lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt; &lt;code&gt;RpcBackendOptions&lt;/code&gt; &lt;/a&gt;类的子类，该类的实例也可以传递给&lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt; &lt;code&gt;init_rpc()&lt;/code&gt; &lt;/a&gt;来配置后端的行为。</target>
        </trans-unit>
        <trans-unit id="14ee5344d06a238323bb82692b3ba5195a694523" translate="yes" xml:space="preserve">
          <source>The RPC package also provides decorators which allow applications to specify how a given function should be treated on the callee side.</source>
          <target state="translated">RPC包还提供了装饰器,允许应用程序指定如何在callee端处理一个给定的函数。</target>
        </trans-unit>
        <trans-unit id="d97e45dd1ab295237092f3a7f655e6e94838339b" translate="yes" xml:space="preserve">
          <source>The RPC tutorials introduce users to the RPC framework, provide several example applications using &lt;a href=&quot;#distributed-rpc-framework&quot;&gt;torch.distributed.rpc&lt;/a&gt; APIs, and demonstrate how to use &lt;a href=&quot;https://pytorch.org/docs/stable/autograd.html#profiler&quot;&gt;the profiler&lt;/a&gt; to profile RPC-based workloads.</source>
          <target state="translated">RPC教程向用户介绍了RPC框架，提供了使用&lt;a href=&quot;#distributed-rpc-framework&quot;&gt;torch.distributed.rpc&lt;/a&gt; API的几个示例应用程序，并演示了如何使用&lt;a href=&quot;https://pytorch.org/docs/stable/autograd.html#profiler&quot;&gt;探查器探查&lt;/a&gt;基于RPC的工作负载。</target>
        </trans-unit>
        <trans-unit id="1362003f90d57874aad22424c41e2c89849947f1" translate="yes" xml:space="preserve">
          <source>The RRef design note covers the design of the &lt;a href=&quot;#rref&quot;&gt;RRef&lt;/a&gt; (Remote REFerence) protocol used to refer to values on remote workers by the framework.</source>
          <target state="translated">RRef设计说明涵盖了&lt;a href=&quot;#rref&quot;&gt;RRef&lt;/a&gt;（远程引用）协议的设计，该协议用于通过框架引用远程工作者的值。</target>
        </trans-unit>
        <trans-unit id="e195940e5abd6ebbfad00ac76917c59c49c9651e" translate="yes" xml:space="preserve">
          <source>The STFT computes the Fourier transform of short overlapping windows of the input. This giving frequency components of the signal as they change over time. The interface of this function is modeled after the &lt;a href=&quot;https://librosa.org/doc/latest/generated/librosa.stft.html&quot;&gt;librosa&lt;/a&gt; stft function.</source>
          <target state="translated">STFT计算输入的短重叠窗口的傅立叶变换。当信号的频率分量随时间变化时，这会给出信号的频率分量。该函数的接口以&lt;a href=&quot;https://librosa.org/doc/latest/generated/librosa.stft.html&quot;&gt;librosa&lt;/a&gt; stft函数为模型。</target>
        </trans-unit>
        <trans-unit id="56e279d91a2e6e157edb87095248831fbd79e513" translate="yes" xml:space="preserve">
          <source>The SummaryWriter class is your main entry to log data for consumption and visualization by TensorBoard. For example:</source>
          <target state="translated">SummaryWriter 类是您记录数据的主要入口,以便由 TensorBoard 消费和可视化。比如说</target>
        </trans-unit>
        <trans-unit id="e88b194ff4e6feceb2bfaaa1ec38472db3a49b02" translate="yes" xml:space="preserve">
          <source>The TensorPipe agent, which is the default, leverages &lt;a href=&quot;https://github.com/pytorch/tensorpipe&quot;&gt;the TensorPipe library&lt;/a&gt;, which provides a natively point-to-point communication primitive specifically suited for machine learning that fundamentally addresses some of the limitations of Gloo. Compared to Gloo, it has the advantage of being asynchronous, which allows a large number of transfers to occur simultaneously, each at their own speed, without blocking each other. It will only open pipes between pairs of nodes when needed, on demand, and when one node fails only its incident pipes will be closed, while all other ones will keep working as normal. In addition, it is able to support multiple different transports (TCP, of course, but also shared memory, NVLink, InfiniBand, &amp;hellip;) and can automatically detect their availability and negotiate the best transport to use for each pipe.</source>
          <target state="translated">TensorPipe代理是默认的，它利用&lt;a href=&quot;https://github.com/pytorch/tensorpipe&quot;&gt;TensorPipe库&lt;/a&gt;，它提供了本机点对点通信原语，特别适合于机器学习，从根本上解决了Gloo的某些局限性。与Gloo相比，它具有异步的优势，它允许大量的传输以自己的速度同时发生，而不会相互阻塞。它仅在需要时按需打开节点对之间的管道，而当一个节点发生故障时，仅其入射管道将被关闭，而所有其他管道将保持正常运行。此外，它还可以支持多种不同的传输方式（当然，TCP，还可以共享内存，NVLink，InfiniBand等），并可以自动检测其可用性并为每条管道协商最佳传输方式。</target>
        </trans-unit>
        <trans-unit id="d362a2db0f7abde4a8479b2b7feada60ead120fd" translate="yes" xml:space="preserve">
          <source>The TensorPipe backend has been introduced in PyTorch v1.6 and is being actively developed. At the moment, it only supports CPU tensors, with GPU support coming soon. It comes with a TCP-based transport, just like Gloo. It is also able to automatically chunk and multiplex large tensors over multiple sockets and threads in order to achieve very high bandwidths. The agent will be able to pick the best transport on its own, with no intervention required.</source>
          <target state="translated">TensorPipe 后端已经在 PyTorch v1.6 中引入,并正在积极开发中。目前,它只支持CPU tensors,很快就会支持GPU。它和Gloo一样,带有基于TCP的传输方式。它还能够在多个套接字和线程上自动分块和多路复用大的 tensors,以实现非常高的带宽。代理商将能够自行选择最佳的传输方式,无需干预。</target>
        </trans-unit>
        <trans-unit id="fe34bfd2269a025104eb8b4a08ae444d0c47f764" translate="yes" xml:space="preserve">
          <source>The TorchScript compiler needs to know the types of &lt;code&gt;module attributes&lt;/code&gt;. Most types can be inferred from the value of the member. Empty lists and dicts cannot have their types inferred and must have their types annotated with &lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;PEP 526-style&lt;/a&gt; class annotations. If a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute to the resulting &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">TorchScript编译器需要知道 &lt;code&gt;module attributes&lt;/code&gt; 的类型。大多数类型可以从成员的值推断出来。空列表和字典不能推断其类型，而必须用&lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;PEP 526样式&lt;/a&gt;类注释对其类型进行注释。如果无法推断类型并且未显式注释类型，则不会将其作为属性添加到生成的&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 中。&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="108ed42a68e399da0a184bd6d4468cb53c249801" translate="yes" xml:space="preserve">
          <source>The Variable API has been deprecated: Variables are no longer necessary to use autograd with tensors. Autograd automatically supports Tensors with &lt;code&gt;requires_grad&lt;/code&gt; set to &lt;code&gt;True&lt;/code&gt;. Below please find a quick guide on what has changed:</source>
          <target state="translated">不推荐使用Variable API：使用带有张量的autograd不再需要变量。Autograd自动支持与张量 &lt;code&gt;requires_grad&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 。请在下面找到有关更改的快速指南：</target>
        </trans-unit>
        <trans-unit id="d526d524819b552e08647a3450928e08c0be85f0" translate="yes" xml:space="preserve">
          <source>The accuracies of the pre-trained models evaluated on COCO val2017 are as follows</source>
          <target state="translated">在COCO val2017上评估的预训练模型的准确度如下表所示</target>
        </trans-unit>
        <trans-unit id="fd6ae7d26b925d9ddede1463aabdca8219c04ca1" translate="yes" xml:space="preserve">
          <source>The algorithm used for interpolation is determined by &lt;code&gt;mode&lt;/code&gt;.</source>
          <target state="translated">用于插值的算法由 &lt;code&gt;mode&lt;/code&gt; 决定。</target>
        </trans-unit>
        <trans-unit id="50402614be52e24dbcb07aaaf1f84990228308aa" translate="yes" xml:space="preserve">
          <source>The algorithm used for upsampling is determined by &lt;code&gt;mode&lt;/code&gt;.</source>
          <target state="translated">用于上采样的算法由 &lt;code&gt;mode&lt;/code&gt; 确定。</target>
        </trans-unit>
        <trans-unit id="9dbbacc61ab643f749eabb1318de7d252379ec8c" translate="yes" xml:space="preserve">
          <source>The algorithms available for upsampling are nearest neighbor and linear, bilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor, respectively.</source>
          <target state="translated">对于3D、4D和5D输入Tensor,可用的上采样算法分别是最近邻和线性、双线性、双立方和三线性。</target>
        </trans-unit>
        <trans-unit id="bdd6673496c6fd17d43bfb63694d67b1a23e7074" translate="yes" xml:space="preserve">
          <source>The approximate decimal resolution of this type, i.e., &lt;code&gt;10**-precision&lt;/code&gt;.</source>
          <target state="translated">此类型的近似十进制分辨率，即 &lt;code&gt;10**-precision&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="11e64a47029713e51445813986a3824ac2548079" translate="yes" xml:space="preserve">
          <source>The argument &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; controls which diagonal to consider. If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; = 0, all elements on and above the main diagonal are retained. A positive value excludes just as many diagonals above the main diagonal, and similarly a negative value includes just as many diagonals below the main diagonal. The main diagonal are the set of indices</source>
          <target state="translated">&lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt;参数控制要考虑的对角线。如果&lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt;= 0，则保留主对角线上和上方的所有元素。正值排除主要对角线上方的对角线，同样，负值排除主要对角线下方的对角线。主要对角线是索引集</target>
        </trans-unit>
        <trans-unit id="2720b921eb619ce89ed4f91beabc1047581eca82" translate="yes" xml:space="preserve">
          <source>The argument &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; controls which diagonal to consider. If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; = 0, all elements on and below the main diagonal are retained. A positive value includes just as many diagonals above the main diagonal, and similarly a negative value excludes just as many diagonals below the main diagonal. The main diagonal are the set of indices</source>
          <target state="translated">&lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt;参数控制要考虑的对角线。如果&lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt;= 0，则保留主对角线上和下方的所有元素。正值包括在主对角线上方的对角线，同样，负值排除在主对角线下方的对角线。主要对角线是索引集</target>
        </trans-unit>
        <trans-unit id="eff44d81484d8a3edd9c1b438e09ac7f19f85991" translate="yes" xml:space="preserve">
          <source>The argument &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; controls which diagonal to consider:</source>
          <target state="translated">&lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt;参数控制要考虑的对角线：</target>
        </trans-unit>
        <trans-unit id="5cfcdff9c158bfd56a616516f4454be040717f37" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;offset&lt;/code&gt; controls which diagonal to consider. If &lt;code&gt;offset&lt;/code&gt; = 0, all elements on and above the main diagonal are retained. A positive value excludes just as many diagonals above the main diagonal, and similarly a negative value includes just as many diagonals below the main diagonal. The main diagonal are the set of indices</source>
          <target state="translated">参数 &lt;code&gt;offset&lt;/code&gt; 控制要考虑的对角线。如果 &lt;code&gt;offset&lt;/code&gt; = 0，则保留主对角线上和上方的所有元素。正值排除主要对角线上方的对角线，同样，负值排除主要对角线下方的对角线。主要对角线是索引集</target>
        </trans-unit>
        <trans-unit id="d114863c5d0c0b07094ca0c20e0cd672c5d3f900" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;offset&lt;/code&gt; controls which diagonal to consider. If &lt;code&gt;offset&lt;/code&gt; = 0, all elements on and below the main diagonal are retained. A positive value includes just as many diagonals above the main diagonal, and similarly a negative value excludes just as many diagonals below the main diagonal. The main diagonal are the set of indices</source>
          <target state="translated">参数 &lt;code&gt;offset&lt;/code&gt; 控制要考虑的对角线。如果 &lt;code&gt;offset&lt;/code&gt; = 0，则保留主对角线上和下方的所有元素。正值包括在主对角线上方的对角线，同样，负值排除在主对角线下方的对角线。主要对角线是索引集</target>
        </trans-unit>
        <trans-unit id="19b889e5a4344dcdd3129928b40b0f46befb2501" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;offset&lt;/code&gt; controls which diagonal to consider:</source>
          <target state="translated">参数 &lt;code&gt;offset&lt;/code&gt; 控制要考虑的对角线：</target>
        </trans-unit>
        <trans-unit id="54707c812db6f29dfe9835066cfce0408bd514d9" translate="yes" xml:space="preserve">
          <source>The argument specifications are almost identical with &lt;a href=&quot;torch.fft#torch.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;. However, if &lt;code&gt;normalized&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, this instead returns the results multiplied by</source>
          <target state="translated">参数说明与&lt;a href=&quot;torch.fft#torch.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;几乎相同。但是，如果将 &lt;code&gt;normalized&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; ，则返回结果乘以</target>
        </trans-unit>
        <trans-unit id="3bf649a8dfc260fcc9e9737948bc65802a397444" translate="yes" xml:space="preserve">
          <source>The argument specifications are almost identical with &lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt;. Similar to &lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt;, if &lt;code&gt;normalized&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, this normalizes the result by multiplying it with</source>
          <target state="translated">参数说明与&lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt; &lt;code&gt;ifft()&lt;/code&gt; &lt;/a&gt;几乎相同。与&lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt; &lt;code&gt;ifft()&lt;/code&gt; &lt;/a&gt;相似，如果将 &lt;code&gt;normalized&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; ，则通过将结果乘以来对结果进行归一化</target>
        </trans-unit>
        <trans-unit id="dcab133c96e453facb95db0b7ee0dc8c72d699d6" translate="yes" xml:space="preserve">
          <source>The autocast state is thread-local. If you want it enabled in a new thread, the context manager or decorator must be invoked in that thread. This affects &lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt;&lt;/a&gt; when used with more than one GPU per process (see &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-multigpu&quot;&gt;Working with Multiple GPUs&lt;/a&gt;).</source>
          <target state="translated">自动广播状态是线程本地的。如果要在新线程中启用它，则必须在该线程中调用上下文管理器或装饰器。当每个进程&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-multigpu&quot;&gt;使用多个GPU&lt;/a&gt;时，这会影响&lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt; &lt;code&gt;torch.nn.DataParallel&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt; &lt;/a&gt;（请参阅使用多个GPU）。</target>
        </trans-unit>
        <trans-unit id="cf4c102338f979040fb6ff061754881df7061681" translate="yes" xml:space="preserve">
          <source>The backend of the given process group as a lower case string.</source>
          <target state="translated">给定流程组的后端为小写字符串。</target>
        </trans-unit>
        <trans-unit id="e19263dbfb8f739b55183f8eb835a3eac6ee2887" translate="yes" xml:space="preserve">
          <source>The backend options class for &lt;code&gt;ProcessGroupAgent&lt;/code&gt;, which is derived from &lt;code&gt;RpcBackendOptions&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;ProcessGroupAgent&lt;/code&gt; 的后端选项类，该类从 &lt;code&gt;RpcBackendOptions&lt;/code&gt; 派生。</target>
        </trans-unit>
        <trans-unit id="ced0f1f27d8dec6f68219ca478db12401a16eb9d" translate="yes" xml:space="preserve">
          <source>The backend options for &lt;code&gt;TensorPipeAgent&lt;/code&gt;, derived from &lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;&lt;code&gt;RpcBackendOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;TensorPipeAgent&lt;/code&gt; 的后端选项，派生自&lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt; &lt;code&gt;RpcBackendOptions&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="502ce5e4564798f5189d3ade0d0a77ccd7a4b686" translate="yes" xml:space="preserve">
          <source>The backward method does not support sparse and complex inputs. It works only when &lt;code&gt;B&lt;/code&gt; is not provided (i.e. &lt;code&gt;B == None&lt;/code&gt;). We are actively working on extensions, and the details of the algorithms are going to be published promptly.</source>
          <target state="translated">向后方法不支持稀疏和复杂的输入。它仅在未提供 &lt;code&gt;B&lt;/code&gt; 时才起作用（即 &lt;code&gt;B == None&lt;/code&gt; ）。我们正在积极地进行扩展，算法的细节将及时发布。</target>
        </trans-unit>
        <trans-unit id="55caae9ff73829418d2cf1f4b542673bb0f801f6" translate="yes" xml:space="preserve">
          <source>The backward passes of &lt;a href=&quot;nn.functional#torch.nn.functional.binary_cross_entropy&quot;&gt;&lt;code&gt;torch.nn.functional.binary_cross_entropy()&lt;/code&gt;&lt;/a&gt; (and &lt;a href=&quot;generated/torch.nn.bceloss#torch.nn.BCELoss&quot;&gt;&lt;code&gt;torch.nn.BCELoss&lt;/code&gt;&lt;/a&gt;, which wraps it) can produce gradients that aren&amp;rsquo;t representable in &lt;code&gt;float16&lt;/code&gt;. In autocast-enabled regions, the forward input may be &lt;code&gt;float16&lt;/code&gt;, which means the backward gradient must be representable in &lt;code&gt;float16&lt;/code&gt; (autocasting &lt;code&gt;float16&lt;/code&gt; forward inputs to &lt;code&gt;float32&lt;/code&gt; doesn&amp;rsquo;t help, because that cast must be reversed in backward). Therefore, &lt;code&gt;binary_cross_entropy&lt;/code&gt; and &lt;code&gt;BCELoss&lt;/code&gt; raise an error in autocast-enabled regions.</source>
          <target state="translated">&lt;a href=&quot;nn.functional#torch.nn.functional.binary_cross_entropy&quot;&gt; &lt;code&gt;torch.nn.functional.binary_cross_entropy()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.bceloss#torch.nn.BCELoss&quot;&gt; &lt;code&gt;torch.nn.BCELoss&lt;/code&gt; &lt;/a&gt;的向后传递（包装它）会产生无法在 &lt;code&gt;float16&lt;/code&gt; 中表示的渐变。在启用自动广播的区域中，前向输入可能是 &lt;code&gt;float16&lt;/code&gt; ，这意味着后向渐变必须在 &lt;code&gt;float16&lt;/code&gt; 中可以表示（将 &lt;code&gt;float16&lt;/code&gt; 的前向输入自动广播到 &lt;code&gt;float32&lt;/code&gt; 没有帮助，因为该转换必须在后向反转）。因此， &lt;code&gt;binary_cross_entropy&lt;/code&gt; 和 &lt;code&gt;BCELoss&lt;/code&gt; 在启用自动广播的区域中引发错误。</target>
        </trans-unit>
        <trans-unit id="977219b95a63d49a9a83d568761b5dea94f71247" translate="yes" xml:space="preserve">
          <source>The batch size should be larger than the number of GPUs used locally.</source>
          <target state="translated">批量大小应大于本地使用的GPU数量。</target>
        </trans-unit>
        <trans-unit id="23b97210326ef320e2d1633f1e69b26cc12a15dc" translate="yes" xml:space="preserve">
          <source>The batch size should be larger than the number of GPUs used.</source>
          <target state="translated">批量大小应大于使用的GPU数量。</target>
        </trans-unit>
        <trans-unit id="1822f0d582e28f7680fb7e40c87465297eaceb93" translate="yes" xml:space="preserve">
          <source>The behavior depends on the dimensionality of the tensors as follows:</source>
          <target state="translated">其行为取决于张力器的维度,如下所示。</target>
        </trans-unit>
        <trans-unit id="2f9d3a99640c5733b646d772d2660cd0aaa3e59f" translate="yes" xml:space="preserve">
          <source>The behavior of the model changes depending if it is in training or evaluation mode.</source>
          <target state="translated">模型的行为改变取决于它是处于训练还是评估模式。</target>
        </trans-unit>
        <trans-unit id="671bda2b5e08e92d9c6a9bee65efdef513a603fd" translate="yes" xml:space="preserve">
          <source>The boolean argument &lt;code&gt;eigenvectors&lt;/code&gt; defines computation of both eigenvectors and eigenvalues or eigenvalues only.</source>
          <target state="translated">布尔参数 &lt;code&gt;eigenvectors&lt;/code&gt; 定义特征向量和特征值或仅特征值的计算。</target>
        </trans-unit>
        <trans-unit id="a803e781482443f16488bb7ddd92d4c8599d93d8" translate="yes" xml:space="preserve">
          <source>The boolean option &lt;code&gt;sorted&lt;/code&gt; if &lt;code&gt;True&lt;/code&gt;, will make sure that the returned &lt;code&gt;k&lt;/code&gt; elements are themselves sorted</source>
          <target state="translated">如果为 &lt;code&gt;True&lt;/code&gt; ，则对布尔选项 &lt;code&gt;sorted&lt;/code&gt; ，以确保返回的 &lt;code&gt;k&lt;/code&gt; 个元素本身已排序</target>
        </trans-unit>
        <trans-unit id="7230c4dcc10bf6edcaa500d739b7ece219bab321" translate="yes" xml:space="preserve">
          <source>The caching allocator is aware of only the stream where a tensor was allocated. Due to the awareness, it already correctly manages the life cycle of tensors on only one stream. But if a tensor is used on a stream different from the stream of origin, the allocator might reuse the memory unexpectedly. Calling this method lets the allocator know which streams have used the tensor.</source>
          <target state="translated">缓存分配器只知道分配张量的流。由于这种意识,它已经正确地在一个流上管理张量的生命周期。但是如果张量被使用在与源流不同的流上,分配器可能会意外地重用内存。调用这个方法可以让分配器知道哪些流使用了张量。</target>
        </trans-unit>
        <trans-unit id="750a4192b0cf8d28e81899b152edaaa9a146f0c9" translate="yes" xml:space="preserve">
          <source>The case when</source>
          <target state="translated">的情况下</target>
        </trans-unit>
        <trans-unit id="40367078c772777ce16b0a9ed2c98fb39bfc9303" translate="yes" xml:space="preserve">
          <source>The centered version first appears in &lt;a href=&quot;https://arxiv.org/pdf/1308.0850v5.pdf&quot;&gt;Generating Sequences With Recurrent Neural Networks&lt;/a&gt;.</source>
          <target state="translated">居中版本首先出现在&lt;a href=&quot;https://arxiv.org/pdf/1308.0850v5.pdf&quot;&gt;用递归神经网络生成序列中&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="cae8914c78d70dfbfebc7267cb87ec8d54626689" translate="yes" xml:space="preserve">
          <source>The check between numerical and analytical gradients uses &lt;a href=&quot;generated/torch.allclose#torch.allclose&quot;&gt;&lt;code&gt;allclose()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">数值和解析梯度之间的检查使用&lt;a href=&quot;generated/torch.allclose#torch.allclose&quot;&gt; &lt;code&gt;allclose()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3dfe4da87960d20e13c57512ebae8f18f5cb935c" translate="yes" xml:space="preserve">
          <source>The checkpoint can be later loaded and inspected under &lt;code&gt;chrome://tracing&lt;/code&gt; URL.</source>
          <target state="translated">稍后可以在 &lt;code&gt;chrome://tracing&lt;/code&gt; URL下加载并检查该检查点。</target>
        </trans-unit>
        <trans-unit id="1a15a1c2561662d55e6adec5b59058d1e70d3911" translate="yes" xml:space="preserve">
          <source>The columns of the output matrix are elementwise powers of the input vector</source>
          <target state="translated">输出矩阵的列是输入向量的元素幂。</target>
        </trans-unit>
        <trans-unit id="21a375cae9200e37dd0602ab95738f8e9f8a4429" translate="yes" xml:space="preserve">
          <source>The computation for determinant and inverse of covariance matrix is avoided when &lt;code&gt;cov_factor.shape[1] &amp;lt;&amp;lt; cov_factor.shape[0]&lt;/code&gt; thanks to &lt;a href=&quot;https://en.wikipedia.org/wiki/Woodbury_matrix_identity&quot;&gt;Woodbury matrix identity&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_determinant_lemma&quot;&gt;matrix determinant lemma&lt;/a&gt;. Thanks to these formulas, we just need to compute the determinant and inverse of the small size &amp;ldquo;capacitance&amp;rdquo; matrix:</source>
          <target state="translated">由于&lt;a href=&quot;https://en.wikipedia.org/wiki/Woodbury_matrix_identity&quot;&gt;伍德伯里矩阵恒等式&lt;/a&gt;和&lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_determinant_lemma&quot;&gt;矩阵行列式引理，&lt;/a&gt;当 &lt;code&gt;cov_factor.shape[1] &amp;lt;&amp;lt; cov_factor.shape[0]&lt;/code&gt; 时，避免了协方差矩阵的行列式和逆计算。由于这些公式，我们只需要计算小尺寸&amp;ldquo;电容&amp;rdquo;矩阵的行列式和逆式：</target>
        </trans-unit>
        <trans-unit id="ce6592c2eac0498a5cc7f983f7cee34a07c28d68" translate="yes" xml:space="preserve">
          <source>The constructor of &lt;a href=&quot;#torch.torch.finfo&quot;&gt;&lt;code&gt;torch.finfo&lt;/code&gt;&lt;/a&gt; can be called without argument, in which case the class is created for the pytorch default dtype (as returned by &lt;a href=&quot;generated/torch.get_default_dtype#torch.get_default_dtype&quot;&gt;&lt;code&gt;torch.get_default_dtype()&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">可以不带参数地调用&lt;a href=&quot;#torch.torch.finfo&quot;&gt; &lt;code&gt;torch.finfo&lt;/code&gt; &lt;/a&gt;的构造函数，在这种情况下，该类是为pytorch默认dtype创建的（由&lt;a href=&quot;generated/torch.get_default_dtype#torch.get_default_dtype&quot;&gt; &lt;code&gt;torch.get_default_dtype()&lt;/code&gt; &lt;/a&gt;返回）。</target>
        </trans-unit>
        <trans-unit id="c4ae76d927f18889b6dd2cecc1dcf754fe0ab549" translate="yes" xml:space="preserve">
          <source>The contents of a tensor can be accessed and modified using Python&amp;rsquo;s indexing and slicing notation:</source>
          <target state="translated">张量的内容可以使用Python的索引和切片符号来访问和修改：</target>
        </trans-unit>
        <trans-unit id="c51b27c3ede61443058e137258f2eb8e4fb6bb72" translate="yes" xml:space="preserve">
          <source>The context can be used to retrieve tensors saved during the forward pass. It also has an attribute &lt;code&gt;ctx.needs_input_grad&lt;/code&gt; as a tuple of booleans representing whether each input needs gradient. E.g., &lt;a href=&quot;#torch.autograd.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt; will have &lt;code&gt;ctx.needs_input_grad[0] = True&lt;/code&gt; if the first input to &lt;a href=&quot;#torch.autograd.Function.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; needs gradient computated w.r.t. the output.</source>
          <target state="translated">上下文可用于检索在前向传递过程中保存的张量。它还具有属性 &lt;code&gt;ctx.needs_input_grad&lt;/code&gt; 作为布尔值的元组，表示每个输入是否需要渐变。例如，如果&lt;a href=&quot;#torch.autograd.Function.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;的第一个输入需要对输出进行梯度计算，则&lt;a href=&quot;#torch.autograd.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; &lt;/a&gt;将具有 &lt;code&gt;ctx.needs_input_grad[0] = True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d18c64aa54a70cac0b6ada6c6ee8aec0ef1f0917" translate="yes" xml:space="preserve">
          <source>The context can be used to store tensors that can be then retrieved during the backward pass.</source>
          <target state="translated">该上下文可用于存储时序器,然后在后向传递过程中进行检索。</target>
        </trans-unit>
        <trans-unit id="68f6bd6745cd407cbd762333af1947bd80a473cd" translate="yes" xml:space="preserve">
          <source>The context managers &lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt;&lt;code&gt;torch.no_grad()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.enable_grad#torch.enable_grad&quot;&gt;&lt;code&gt;torch.enable_grad()&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/torch.set_grad_enabled#torch.set_grad_enabled&quot;&gt;&lt;code&gt;torch.set_grad_enabled()&lt;/code&gt;&lt;/a&gt; are helpful for locally disabling and enabling gradient computation. See &lt;a href=&quot;autograd#locally-disable-grad&quot;&gt;Locally disabling gradient computation&lt;/a&gt; for more details on their usage. These context managers are thread local, so they won&amp;rsquo;t work if you send work to another thread using the &lt;code&gt;threading&lt;/code&gt; module, etc.</source>
          <target state="translated">上下文管理器&lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt; &lt;code&gt;torch.no_grad()&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/torch.enable_grad#torch.enable_grad&quot;&gt; &lt;code&gt;torch.enable_grad()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.set_grad_enabled#torch.set_grad_enabled&quot;&gt; &lt;code&gt;torch.set_grad_enabled()&lt;/code&gt; &lt;/a&gt;有助于局部禁用和启用梯度计算。有关其用法的更多详细信息，请参见&lt;a href=&quot;autograd#locally-disable-grad&quot;&gt;本地禁用梯度计算&lt;/a&gt;。这些上下文管理器是线程本地的，因此如果您使用 &lt;code&gt;threading&lt;/code&gt; 模块等将工作发送到另一个线程，它们将无法工作。</target>
        </trans-unit>
        <trans-unit id="6ca40d5babc478c27564467be749f0f09c316678" translate="yes" xml:space="preserve">
          <source>The correct interpretation of the Hermitian input depends on the length of the original data, as given by &lt;code&gt;n&lt;/code&gt;. This is because each input shape could correspond to either an odd or even length signal. By default, the signal is assumed to be even length and odd signals will not round-trip properly. So, it is recommended to always pass the signal length &lt;code&gt;n&lt;/code&gt;.</source>
          <target state="translated">对Hermitian输入的正确解释取决于原始数据的长度，如 &lt;code&gt;n&lt;/code&gt; 所示。这是因为每种输入形状可能对应于奇数或偶数长度的信号。默认情况下，假定信号为偶数长度，奇数信号将无法正确往返。因此，建议始终通过信号长度 &lt;code&gt;n&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="15f3e882aab04b4ad9da40b79636691c5dd75e80" translate="yes" xml:space="preserve">
          <source>The correct interpretation of the Hermitian input depends on the length of the original data, as given by &lt;code&gt;s&lt;/code&gt;. This is because each input shape could correspond to either an odd or even length signal. By default, the signal is assumed to be even length and odd signals will not round-trip properly. So, it is recommended to always pass the signal shape &lt;code&gt;s&lt;/code&gt;.</source>
          <target state="translated">对Hermitian输入的正确解释取决于 &lt;code&gt;s&lt;/code&gt; 给出的原始数据的长度。这是因为每种输入形状可能对应于奇数或偶数长度的信号。默认情况下，假定信号为偶数长度，奇数信号将无法正确往返。因此，建议始终通过信号形状 &lt;code&gt;s&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6651537fc75b50914667cdbdb45bc29550b4b400" translate="yes" xml:space="preserve">
          <source>The corresponding quantized module of &lt;code&gt;mod&lt;/code&gt;</source>
          <target state="translated">对应的 &lt;code&gt;mod&lt;/code&gt; 量化模块</target>
        </trans-unit>
        <trans-unit id="b2f2b30024847cce229c4bda1e1b5ab964a9eaf4" translate="yes" xml:space="preserve">
          <source>The criterion only considers a contiguous block of non-negative targets that starts at the front.</source>
          <target state="translated">该标准只考虑从前面开始的非负目标的连续块。</target>
        </trans-unit>
        <trans-unit id="e11b9195cb3521aafd237a69ce124b8d788f6886" translate="yes" xml:space="preserve">
          <source>The current implementation will not have the presented behavior for complex &lt;a href=&quot;#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; that perform many operations. In some failure cases, &lt;code&gt;grad_input&lt;/code&gt; and &lt;code&gt;grad_output&lt;/code&gt; will only contain the gradients for a subset of the inputs and outputs. For such &lt;a href=&quot;#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt;, you should use &lt;a href=&quot;../autograd#torch.Tensor.register_hook&quot;&gt;&lt;code&gt;torch.Tensor.register_hook()&lt;/code&gt;&lt;/a&gt; directly on a specific input or output to get the required gradients.</source>
          <target state="translated">对于执行许多操作的复杂&lt;a href=&quot;#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;，当前实现将不具有所呈现的行为。在某些故障情况下， &lt;code&gt;grad_input&lt;/code&gt; 和 &lt;code&gt;grad_output&lt;/code&gt; 将仅包含输入和输出的子集的梯度​​。对于此类&lt;a href=&quot;#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;，应直接在特定的输入或输出上使用&lt;a href=&quot;../autograd#torch.Tensor.register_hook&quot;&gt; &lt;code&gt;torch.Tensor.register_hook()&lt;/code&gt; &lt;/a&gt;以获取所需的渐变。</target>
        </trans-unit>
        <trans-unit id="e2bf74abb2f8760663c776314dd933141deb8a40" translate="yes" xml:space="preserve">
          <source>The current implementation will not have the presented behavior for complex &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; that perform many operations. In some failure cases, &lt;code&gt;grad_input&lt;/code&gt; and &lt;code&gt;grad_output&lt;/code&gt; will only contain the gradients for a subset of the inputs and outputs. For such &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt;, you should use &lt;a href=&quot;../autograd#torch.Tensor.register_hook&quot;&gt;&lt;code&gt;torch.Tensor.register_hook()&lt;/code&gt;&lt;/a&gt; directly on a specific input or output to get the required gradients.</source>
          <target state="translated">对于执行许多操作的复杂&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;，当前实现将不具有所呈现的行为。在某些故障情况下， &lt;code&gt;grad_input&lt;/code&gt; 和 &lt;code&gt;grad_output&lt;/code&gt; 将仅包含输入和输出的子集的梯度​​。对于此类&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;，应直接在特定的输入或输出上使用&lt;a href=&quot;../autograd#torch.Tensor.register_hook&quot;&gt; &lt;code&gt;torch.Tensor.register_hook()&lt;/code&gt; &lt;/a&gt;以获取所需的渐变。</target>
        </trans-unit>
        <trans-unit id="41f3fc6117e6365cbfdd81a5124ee1886a82a466" translate="yes" xml:space="preserve">
          <source>The current implementation will not have the presented behavior for complex &lt;code&gt;Module&lt;/code&gt; that perform many operations. In some failure cases, &lt;code&gt;grad_input&lt;/code&gt; and &lt;code&gt;grad_output&lt;/code&gt; will only contain the gradients for a subset of the inputs and outputs. For such &lt;code&gt;Module&lt;/code&gt;, you should use &lt;a href=&quot;../autograd#torch.Tensor.register_hook&quot;&gt;&lt;code&gt;torch.Tensor.register_hook()&lt;/code&gt;&lt;/a&gt; directly on a specific input or output to get the required gradients.</source>
          <target state="translated">对于执行许多操作的复杂 &lt;code&gt;Module&lt;/code&gt; ，当前实现将不具有所呈现的行为。在某些故障情况下， &lt;code&gt;grad_input&lt;/code&gt; 和 &lt;code&gt;grad_output&lt;/code&gt; 将仅包含输入和输出的子集的梯度​​。对于此类 &lt;code&gt;Module&lt;/code&gt; ，应直接在特定的输入或输出上使用&lt;a href=&quot;../autograd#torch.Tensor.register_hook&quot;&gt; &lt;code&gt;torch.Tensor.register_hook()&lt;/code&gt; &lt;/a&gt;以获取所需的渐变。</target>
        </trans-unit>
        <trans-unit id="c92e6421025a94114fff69d31efad27a7d187bee" translate="yes" xml:space="preserve">
          <source>The default behavior (letting &lt;code&gt;.grad&lt;/code&gt;s be &lt;code&gt;None&lt;/code&gt; before the first &lt;code&gt;backward()&lt;/code&gt;, such that their layout is created according to 1 or 2, and retained over time according to 3 or 4) is recommended for best performance. Calls to &lt;code&gt;model.zero_grad()&lt;/code&gt; or &lt;code&gt;optimizer.zero_grad()&lt;/code&gt; will not affect &lt;code&gt;.grad&lt;/code&gt; layouts.</source>
          <target state="translated">为了获得最佳性能，建议使用默认行为（在第一个 &lt;code&gt;backward()&lt;/code&gt; 之前将 &lt;code&gt;.grad&lt;/code&gt; 设置为 &lt;code&gt;None&lt;/code&gt; ，以便根据1或2创建其布局，并根据3或4保留其时间）。调用 &lt;code&gt;model.zero_grad()&lt;/code&gt; 或 &lt;code&gt;optimizer.zero_grad()&lt;/code&gt; 不会影响 &lt;code&gt;.grad&lt;/code&gt; 布局。</target>
        </trans-unit>
        <trans-unit id="0fcbf7f37e10aae7ed7b4feee2a1e7bd2fefc4c8" translate="yes" xml:space="preserve">
          <source>The default floating point dtype is initially &lt;code&gt;torch.float32&lt;/code&gt;.</source>
          <target state="translated">默认浮点 &lt;code&gt;torch.float32&lt;/code&gt; 最初是torch.float32。</target>
        </trans-unit>
        <trans-unit id="fed344676665a74468953d310a0df7afafaa24e3" translate="yes" xml:space="preserve">
          <source>The default floating point tensor type is initially &lt;code&gt;torch.FloatTensor&lt;/code&gt;.</source>
          <target state="translated">默认的浮点张量类型最初是 &lt;code&gt;torch.FloatTensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c712a8331c0e06f199c3cd7a844a65de36cd9e42" translate="yes" xml:space="preserve">
          <source>The default memory pinning logic only recognizes Tensors and maps and iterables containing Tensors. By default, if the pinning logic sees a batch that is a custom type (which will occur if you have a &lt;code&gt;collate_fn&lt;/code&gt; that returns a custom batch type), or if each element of your batch is a custom type, the pinning logic will not recognize them, and it will return that batch (or those elements) without pinning the memory. To enable memory pinning for custom batch or data type(s), define a &lt;code&gt;pin_memory()&lt;/code&gt; method on your custom type(s).</source>
          <target state="translated">默认的内存固定逻辑仅识别张量以及包含张量的映射和可迭代对象。默认情况下，如果固定逻辑看到一个自定义类型的批处理（如果您有一个返回自定义批处理类型的 &lt;code&gt;collate_fn&lt;/code&gt; 就会发生），或者如果该批处理的每个元素都是自定义类型，则固定逻辑将无法识别它们，它将返回该批处理（或那些元素）而无需固定内存。要为自定义批处理或数据类型启用内存固定，请在您的自定义类型上定义 &lt;code&gt;pin_memory()&lt;/code&gt; 方法。</target>
        </trans-unit>
        <trans-unit id="0dec0a713cccbf6f2a025c718d1183b7f17ecc48" translate="yes" xml:space="preserve">
          <source>The default values are designed for &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;grad_outputs&lt;/code&gt; of double precision. This check will likely fail if they are of less precision, e.g., &lt;code&gt;FloatTensor&lt;/code&gt;.</source>
          <target state="translated">默认值是为双精度的 &lt;code&gt;input&lt;/code&gt; 和 &lt;code&gt;grad_outputs&lt;/code&gt; 设计的。如果它们的精度较低，则检查可能会失败，例如 &lt;code&gt;FloatTensor&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7e78814d77915278208123d7230c026ea150426b" translate="yes" xml:space="preserve">
          <source>The default values are designed for &lt;code&gt;input&lt;/code&gt; of double precision. This check will likely fail if &lt;code&gt;input&lt;/code&gt; is of less precision, e.g., &lt;code&gt;FloatTensor&lt;/code&gt;.</source>
          <target state="translated">默认值是为双精度 &lt;code&gt;input&lt;/code&gt; 而设计的。如果 &lt;code&gt;input&lt;/code&gt; 的精度较低，例如 &lt;code&gt;FloatTensor&lt;/code&gt; ，则此检查可能会失败。</target>
        </trans-unit>
        <trans-unit id="a80bd362bedb3fcb6747d9fd75b4961eb0cdb1f6" translate="yes" xml:space="preserve">
          <source>The discrete Fourier transform is separable, so &lt;a href=&quot;#torch.fft.fftn&quot;&gt;&lt;code&gt;fftn()&lt;/code&gt;&lt;/a&gt; here is equivalent to two one-dimensional &lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt; calls:</source>
          <target state="translated">离散傅立叶变换是可分离的，因此这里的&lt;a href=&quot;#torch.fft.fftn&quot;&gt; &lt;code&gt;fftn()&lt;/code&gt; &lt;/a&gt;等效于两个一维的&lt;a href=&quot;#torch.fft.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;调用：</target>
        </trans-unit>
        <trans-unit id="68e62e57e835a4d91bc43ca48c95e3efa63535c9" translate="yes" xml:space="preserve">
          <source>The discrete Fourier transform is separable, so &lt;a href=&quot;#torch.fft.ifftn&quot;&gt;&lt;code&gt;ifftn()&lt;/code&gt;&lt;/a&gt; here is equivalent to two one-dimensional &lt;a href=&quot;#torch.fft.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt; calls:</source>
          <target state="translated">离散傅立叶变换是可分离的，因此，这里的&lt;a href=&quot;#torch.fft.ifftn&quot;&gt; &lt;code&gt;ifftn()&lt;/code&gt; &lt;/a&gt;等效于两个一维的&lt;a href=&quot;#torch.fft.ifft&quot;&gt; &lt;code&gt;ifft()&lt;/code&gt; &lt;/a&gt;调用：</target>
        </trans-unit>
        <trans-unit id="1984f4c44a0a732d169d5d6a5c5f08cad523bc50" translate="yes" xml:space="preserve">
          <source>The discrete Fourier transform is separable, so &lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt; here is equivalent to a combination of &lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">离散傅里叶变换是可分离的，因此&lt;a href=&quot;#torch.fft.rfftn&quot;&gt; &lt;code&gt;rfftn()&lt;/code&gt; &lt;/a&gt;等效于&lt;a href=&quot;#torch.fft.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.fft.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; 的组合&lt;/a&gt;：</target>
        </trans-unit>
        <trans-unit id="6def4e7a63f51a47c9f6b51fb1bb8c54875ce717" translate="yes" xml:space="preserve">
          <source>The distance swap is described in detail in the paper &lt;a href=&quot;http://www.bmva.org/bmvc/2016/papers/paper119/index.html&quot;&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/a&gt; by V. Balntas, E. Riba et al.</source>
          <target state="translated">V. Balntas，E。Riba等人在《&lt;a href=&quot;http://www.bmva.org/bmvc/2016/papers/paper119/index.html&quot;&gt;学习具有三重态损失&lt;/a&gt;的浅层卷积特征描述符》中详细描述了距离交换。</target>
        </trans-unit>
        <trans-unit id="e0ab87bc03e5a5294329af8c45b84a5da57986c5" translate="yes" xml:space="preserve">
          <source>The distributed RPC framework makes it easy to run functions remotely, supports referencing remote objects without copying the real data around, and provides autograd and optimizer APIs to transparently run backward and update parameters across RPC boundaries. These features can be categorized into four sets of APIs.</source>
          <target state="translated">分布式RPC框架可以方便地远程运行函数,支持引用远程对象而不需要到处复制真实数据,并提供自动生成和优化器API来透明地跨RPC边界运行回溯和更新参数。这些功能可以归纳为四组API。</target>
        </trans-unit>
        <trans-unit id="58cfec2b510135f93e0701fc204e248929b783f2" translate="yes" xml:space="preserve">
          <source>The distributed RPC framework provides mechanisms for multi-machine model training through a set of primitives to allow for remote communication, and a higher-level API to automatically differentiate models split across several machines.</source>
          <target state="translated">分布式RPC框架通过一组基元提供了多机器模型训练的机制,以允许远程通信,并提供了更高级别的API,以自动区分分裂在几台机器上的模型。</target>
        </trans-unit>
        <trans-unit id="10060f95e0764042598d146fc06132ab3dfae090" translate="yes" xml:space="preserve">
          <source>The distributed autograd design note covers the design of the RPC-based distributed autograd framework that is useful for applications such as model parallel training.</source>
          <target state="translated">分布式autograd设计说明涵盖了基于RPC的分布式autograd框架的设计,对模型并行训练等应用非常有用。</target>
        </trans-unit>
        <trans-unit id="dafbad2c73a3de536f4d90e5d5fa2fe3c91b9950" translate="yes" xml:space="preserve">
          <source>The distributed package comes with a distributed key-value store, which can be used to share information between processes in the group as well as to initialize the distributed pacakge in &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt;&lt;/a&gt; (by explicitly creating the store as an alternative to specifying &lt;code&gt;init_method&lt;/code&gt;.) There are 3 choices for Key-Value Stores: &lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt;&lt;code&gt;TCPStore&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributed.FileStore&quot;&gt;&lt;code&gt;FileStore&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;#torch.distributed.HashStore&quot;&gt;&lt;code&gt;HashStore&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">分布式程序包带有分布式键值存储，可用于在组中的进程之间共享信息，以及在&lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt; 中&lt;/a&gt;初始化分布式pacakge（通过显式创建存储来替代指定 &lt;code&gt;init_method&lt;/code&gt; 。）键值存储有3个选择：&lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt; &lt;code&gt;TCPStore&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;#torch.distributed.FileStore&quot;&gt; &lt;code&gt;FileStore&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.distributed.HashStore&quot;&gt; &lt;code&gt;HashStore&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0856f15ea144836b8b8d8118fc0a896821ee6c9d" translate="yes" xml:space="preserve">
          <source>The distribution is supported in [0, 1] and parameterized by &amp;lsquo;probs&amp;rsquo; (in (0,1)) or &amp;lsquo;logits&amp;rsquo; (real-valued). Note that, unlike the Bernoulli, &amp;lsquo;probs&amp;rsquo; does not correspond to a probability and &amp;lsquo;logits&amp;rsquo; does not correspond to log-odds, but the same names are used due to the similarity with the Bernoulli. See [1] for more details.</source>
          <target state="translated">该分布在[0，1]中受支持，并通过'probs'（在（0,1）中）或'logits'（实数值）进行参数化。请注意，与伯努利不同，&amp;ldquo;概率&amp;rdquo;不对应于概率，&amp;ldquo;对数&amp;rdquo;不对应于对数奇数，但是由于与伯努利的相似性，因此使用相同的名称。有关更多详细信息，请参见[1]。</target>
        </trans-unit>
        <trans-unit id="6db33b80979f7c8f4114d1e3c176aabac7ef279b" translate="yes" xml:space="preserve">
          <source>The dividend and divisor may contain both for integer and floating point numbers. The remainder has the same sign as the dividend &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">被除数和除数可以同时包含整数和浮点数。其余的与红利 &lt;code&gt;input&lt;/code&gt; 具有相同的符号。</target>
        </trans-unit>
        <trans-unit id="77ad1382d4823bfe1261c0964c88050a7ad3d117" translate="yes" xml:space="preserve">
          <source>The dividend and divisor may contain both for integer and floating point numbers. The remainder has the same sign as the divisor &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">被除数和除数可以同时包含整数和浮点数。其余与除数 &lt;code&gt;other&lt;/code&gt; 具有相同的符号。</target>
        </trans-unit>
        <trans-unit id="3c8c32198d8c41dc6ec53302edb97fbbfa15ce0d" translate="yes" xml:space="preserve">
          <source>The division by</source>
          <target state="translated">除以</target>
        </trans-unit>
        <trans-unit id="d4d19d774aea3434987d4b4cece2b5f99cec9991" translate="yes" xml:space="preserve">
          <source>The dlpack shares the tensors memory. Note that each dlpack can only be consumed once.</source>
          <target state="translated">dlpack共享tensors的内存。注意,每个dlpack只能消耗一次。</target>
        </trans-unit>
        <trans-unit id="a37e21cd1a669630ae636a9ca39104d114477d0e" translate="yes" xml:space="preserve">
          <source>The domain of the inverse hyperbolic cosine is &lt;code&gt;[1, inf)&lt;/code&gt; and values outside this range will be mapped to &lt;code&gt;NaN&lt;/code&gt;, except for &lt;code&gt;+ INF&lt;/code&gt; for which the output is mapped to &lt;code&gt;+ INF&lt;/code&gt;.</source>
          <target state="translated">反双曲余弦的域为 &lt;code&gt;[1, inf)&lt;/code&gt; ，此范围之外的值将映射到 &lt;code&gt;NaN&lt;/code&gt; ，除了 &lt;code&gt;+ INF&lt;/code&gt; 之外，其输出映射到 &lt;code&gt;+ INF&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b9eae4d9c836ec727b1fd15ef73922995c7e82e1" translate="yes" xml:space="preserve">
          <source>The domain of the inverse hyperbolic tangent is &lt;code&gt;(-1, 1)&lt;/code&gt; and values outside this range will be mapped to &lt;code&gt;NaN&lt;/code&gt;, except for the values &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;-1&lt;/code&gt; for which the output is mapped to &lt;code&gt;+/-INF&lt;/code&gt; respectively.</source>
          <target state="translated">反双曲正切的域是 &lt;code&gt;(-1, 1)&lt;/code&gt; ，此范围之外的值将映射到 &lt;code&gt;NaN&lt;/code&gt; ，除了分别将输出映射到 &lt;code&gt;+/-INF&lt;/code&gt; 的值 &lt;code&gt;1&lt;/code&gt; 和 &lt;code&gt;-1&lt;/code&gt; 之外。</target>
        </trans-unit>
        <trans-unit id="e24f7a4d115e62a42f56d551f1451d37a5e25266" translate="yes" xml:space="preserve">
          <source>The dynamic control flow is captured correctly. We can verify in backends with different loop range.</source>
          <target state="translated">正确捕捉动态控制流程。我们可以在不同循环范围的后台进行验证。</target>
        </trans-unit>
        <trans-unit id="a418864112d90d162f2d2d68264a78b5661b0c49" translate="yes" xml:space="preserve">
          <source>The eigenvalues are returned in ascending order. If &lt;code&gt;input&lt;/code&gt; is a batch of matrices, then the eigenvalues of each matrix in the batch is returned in ascending order.</source>
          <target state="translated">特征值以升序返回。如果 &lt;code&gt;input&lt;/code&gt; 是一批矩阵，则该批中每个矩阵的特征值将以升序返回。</target>
        </trans-unit>
        <trans-unit id="70c72529d7b55dc5ab2b127843a9a42c7179e611" translate="yes" xml:space="preserve">
          <source>The elements are sorted into equal width bins between &lt;a href=&quot;torch.min#torch.min&quot;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.max#torch.max&quot;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt;. If &lt;a href=&quot;torch.min#torch.min&quot;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.max#torch.max&quot;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt; are both zero, the minimum and maximum values of the data are used.</source>
          <target state="translated">元素被分类为&lt;a href=&quot;torch.min#torch.min&quot;&gt; &lt;code&gt;min&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;torch.max#torch.max&quot;&gt; &lt;code&gt;max&lt;/code&gt; &lt;/a&gt;之间相等宽度的单元格。如果&lt;a href=&quot;torch.min#torch.min&quot;&gt; &lt;code&gt;min&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;torch.max#torch.max&quot;&gt; &lt;code&gt;max&lt;/code&gt; &lt;/a&gt;均为零，则使用数据的最小值和最大值。</target>
        </trans-unit>
        <trans-unit id="ef67a3a1e1ceed752fed1303fe693fb7bb4731f9" translate="yes" xml:space="preserve">
          <source>The entry &lt;code&gt;Backend.UNDEFINED&lt;/code&gt; is present but only used as initial value of some fields. Users should neither use it directly nor assume its existence.</source>
          <target state="translated">存在条目 &lt;code&gt;Backend.UNDEFINED&lt;/code&gt; ，但仅用作某些字段的初始值。用户既不应直接使用它，也不应该假定它的存在。</target>
        </trans-unit>
        <trans-unit id="c0ed2b956d8f2913276ea868cc2cc1c195e28811" translate="yes" xml:space="preserve">
          <source>The example script above produces the graph:</source>
          <target state="translated">上面的例子脚本产生的图形。</target>
        </trans-unit>
        <trans-unit id="8850a69d0e77cfdf6128ac9dcc486c371b38e541" translate="yes" xml:space="preserve">
          <source>The export fails because PyTorch does not support exporting &lt;code&gt;elu&lt;/code&gt; operator. We find &lt;code&gt;virtual Tensor elu(const Tensor &amp;amp; input, Scalar alpha, bool inplace) const override;&lt;/code&gt; in &lt;code&gt;VariableType.h&lt;/code&gt;. This means &lt;code&gt;elu&lt;/code&gt; is an ATen operator. We check the &lt;a href=&quot;https://github.com/onnx/onnx/blob/master/docs/Operators.md&quot;&gt;ONNX operator list&lt;/a&gt;, and confirm that &lt;code&gt;Elu&lt;/code&gt; is standardized in ONNX. We add the following lines to &lt;code&gt;symbolic_opset9.py&lt;/code&gt;:</source>
          <target state="translated">导出失败，因为PyTorch不支持导出 &lt;code&gt;elu&lt;/code&gt; 运算符。我们发现 &lt;code&gt;virtual Tensor elu(const Tensor &amp;amp; input, Scalar alpha, bool inplace) const override;&lt;/code&gt; 在 &lt;code&gt;VariableType.h&lt;/code&gt; 中。这意味着 &lt;code&gt;elu&lt;/code&gt; 是ATen运营商。我们检查&lt;a href=&quot;https://github.com/onnx/onnx/blob/master/docs/Operators.md&quot;&gt;ONNX操作员列表&lt;/a&gt;，并确认 &lt;code&gt;Elu&lt;/code&gt; 已在ONNX中标准化。我们 &lt;code&gt;symbolic_opset9.py&lt;/code&gt; 添加到symbolic_opset9.py：</target>
        </trans-unit>
        <trans-unit id="eaaaa8926b11cbb1c679608a1678277381f47dca" translate="yes" xml:space="preserve">
          <source>The fact that gradients need to be computed for a Tensor do not mean that the &lt;a href=&quot;#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; attribute will be populated, see &lt;a href=&quot;#torch.Tensor.is_leaf&quot;&gt;&lt;code&gt;is_leaf&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">需要为张量计算梯度的事实并不意味着将填充&lt;a href=&quot;#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt;属性，有关更多详细信息，请参见&lt;a href=&quot;#torch.Tensor.is_leaf&quot;&gt; &lt;code&gt;is_leaf&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f9a2121d113f583a300c4eeb7ced28dd018af26f" translate="yes" xml:space="preserve">
          <source>The fact that gradients need to be computed for a Tensor do not mean that the &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; attribute will be populated, see &lt;a href=&quot;autograd#torch.Tensor.is_leaf&quot;&gt;&lt;code&gt;is_leaf&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">需要为张量计算梯度的事实并不意味着将填充&lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt;属性，有关更多详细信息，请参见&lt;a href=&quot;autograd#torch.Tensor.is_leaf&quot;&gt; &lt;code&gt;is_leaf&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="221c8b91c0e460724cf31fb2005c0c9e54071204" translate="yes" xml:space="preserve">
          <source>The first call to add for a given &lt;code&gt;key&lt;/code&gt; creates a counter associated with &lt;code&gt;key&lt;/code&gt; in the store, initialized to &lt;code&gt;amount&lt;/code&gt;. Subsequent calls to add with the same &lt;code&gt;key&lt;/code&gt; increment the counter by the specified &lt;code&gt;amount&lt;/code&gt;. Calling &lt;code&gt;add()&lt;/code&gt; with a key that has already been set in the store by &lt;code&gt;set()&lt;/code&gt; will result in an exception.</source>
          <target state="translated">为给定 &lt;code&gt;key&lt;/code&gt; 进行的首次添加调用将在商店中创建一个与 &lt;code&gt;key&lt;/code&gt; 相关联的计数器，并初始化为 &lt;code&gt;amount&lt;/code&gt; 。随后的调用使用相同的 &lt;code&gt;key&lt;/code&gt; 加法，计数器将增加指定的 &lt;code&gt;amount&lt;/code&gt; 。使用 &lt;code&gt;set()&lt;/code&gt; 已在商店中设置的键调用 &lt;code&gt;add()&lt;/code&gt; 会导致异常。</target>
        </trans-unit>
        <trans-unit id="d04a7a0c088c359fab554cd1a6049882b564ff2e" translate="yes" xml:space="preserve">
          <source>The first parameter is always the exported ONNX graph.</source>
          <target state="translated">第一个参数始终是导出的ONNX图形。</target>
        </trans-unit>
        <trans-unit id="26a3da676366966fcc7fbfc997f2f64e6ee31c9d" translate="yes" xml:space="preserve">
          <source>The first parameter is always the exported ONNX graph. Parameter names must EXACTLY match the names in &lt;code&gt;VariableType.h&lt;/code&gt;, because dispatch is done with keyword arguments.</source>
          <target state="translated">第一个参数始终是导出的ONNX图。参数名称必须与 &lt;code&gt;VariableType.h&lt;/code&gt; 中的名称完全匹配，因为分派是通过关键字参数完成的。</target>
        </trans-unit>
        <trans-unit id="5964988cdbc48443556dc471facbf25fa24c6e63" translate="yes" xml:space="preserve">
          <source>The following APIs allow users to remotely execute functions as well as create references (RRefs) to remote data objects. In these APIs, when passing a &lt;code&gt;Tensor&lt;/code&gt; as an argument or a return value, the destination worker will try to create a &lt;code&gt;Tensor&lt;/code&gt; with the same meta (i.e., shape, stride, etc.). We intentionally disallow transmitting CUDA tensors because it might crash if the device lists on source and destination workers do not match. In such cases, applications can always explicitly move the input tensors to CPU on the caller and move it to the desired devices on the callee if necessary.</source>
          <target state="translated">以下API允许用户远程执行功能以及创建对远程数据对象的引用（RRef）。在这些API中，当将 &lt;code&gt;Tensor&lt;/code&gt; 作为参数或返回值传递时，目标工作程序将尝试创建具有相同元数据（即形状，步幅等）的 &lt;code&gt;Tensor&lt;/code&gt; 。我们故意禁止传输CUDA张量，因为如果源和目标工作线程上的设备列表不匹配，它可能会崩溃。在这种情况下，应用程序始终可以将输入张量显式移动到调用方的CPU上，并在必要时将其移动到被调用方上的所需设备。</target>
        </trans-unit>
        <trans-unit id="0331e44de903db51dab5949d62e369ce763fc069" translate="yes" xml:space="preserve">
          <source>The following Python Expressions are supported.</source>
          <target state="translated">支持以下Python表达式。</target>
        </trans-unit>
        <trans-unit id="a58ae690d15d348f9e4dcb69eeff8937464b7b91" translate="yes" xml:space="preserve">
          <source>The following constraints are implemented:</source>
          <target state="translated">实施了以下制约因素:</target>
        </trans-unit>
        <trans-unit id="f123fb71a763a700ae8133c3cf978d6e15341a63" translate="yes" xml:space="preserve">
          <source>The following factory functions support named tensors:</source>
          <target state="translated">以下工厂函数支持命名时序。</target>
        </trans-unit>
        <trans-unit id="08607d57d85e6e823913a7de503035f5f9376e6f" translate="yes" xml:space="preserve">
          <source>The following lists describe the behavior of eligible ops in autocast-enabled regions. These ops always go through autocasting whether they are invoked as part of a &lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;torch.nn.Module&lt;/code&gt;&lt;/a&gt;, as a function, or as a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; method. If functions are exposed in multiple namespaces, they go through autocasting regardless of the namespace.</source>
          <target state="translated">以下列表描述了启用自动广播的区域中符合条件的操作的行为。无论它们是作为&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;torch.nn.Module&lt;/code&gt; 的&lt;/a&gt;一部分，作为函数还是作为&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;方法被调用，这些操作始终会进行自动广播。如果函数在多个名称空间中公开，则无论名称空间如何，它们都会进行自动广播。</target>
        </trans-unit>
        <trans-unit id="690193766b4768be386db05b742730b7dbdf34e9" translate="yes" xml:space="preserve">
          <source>The following methods are unique to &lt;a href=&quot;#torch.BoolTensor&quot;&gt;&lt;code&gt;torch.BoolTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">以下方法是&lt;a href=&quot;#torch.BoolTensor&quot;&gt; &lt;code&gt;torch.BoolTensor&lt;/code&gt; &lt;/a&gt;特有的。</target>
        </trans-unit>
        <trans-unit id="2fcc9561d17b3f2c0c3db2c65c4b45e1fd39309f" translate="yes" xml:space="preserve">
          <source>The following normally-nondeterministic operations will act deterministically when &lt;code&gt;d=True&lt;/code&gt;:</source>
          <target state="translated">当 &lt;code&gt;d=True&lt;/code&gt; 时，以下通常不确定的操作将确定性地起作用：</target>
        </trans-unit>
        <trans-unit id="6c856d87fb36615ab5d3e65d2705a558ef7fc7ab" translate="yes" xml:space="preserve">
          <source>The following normally-nondeterministic operations will throw a &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#RuntimeError&quot;&gt;&lt;code&gt;RuntimeError&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;d=True&lt;/code&gt;:</source>
          <target state="translated">当 &lt;code&gt;d=True&lt;/code&gt; 时，以下通常不确定的操作将引发&lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#RuntimeError&quot;&gt; &lt;code&gt;RuntimeError&lt;/code&gt; &lt;/a&gt;：</target>
        </trans-unit>
        <trans-unit id="10cc3c798c883edec11b18c9b813ac5a197463fe" translate="yes" xml:space="preserve">
          <source>The following operators are supported:</source>
          <target state="translated">支持以下运算符:</target>
        </trans-unit>
        <trans-unit id="116feb31ceb0c75370eb04add5159eb16382e56b" translate="yes" xml:space="preserve">
          <source>The function &lt;a href=&quot;#torch.fft&quot;&gt;&lt;code&gt;torch.fft()&lt;/code&gt;&lt;/a&gt; is deprecated and will be removed in PyTorch 1.8. Use the new &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; module functions, instead, by importing &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; and calling &lt;a href=&quot;../fft#torch.fft.fft&quot;&gt;&lt;code&gt;torch.fft.fft()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../fft#torch.fft.fftn&quot;&gt;&lt;code&gt;torch.fft.fftn()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">不推荐使用函数&lt;a href=&quot;#torch.fft&quot;&gt; &lt;code&gt;torch.fft()&lt;/code&gt; &lt;/a&gt;，并将在PyTorch 1.8中将其删除。而是使用新的&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;模块函数，方法是导入&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;并调用&lt;a href=&quot;../fft#torch.fft.fft&quot;&gt; &lt;code&gt;torch.fft.fft()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;../fft#torch.fft.fftn&quot;&gt; &lt;code&gt;torch.fft.fftn()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="18bbed5d4e21fbcafc8624ec507383dc653a9737" translate="yes" xml:space="preserve">
          <source>The function &lt;a href=&quot;#torch.ifft&quot;&gt;&lt;code&gt;torch.ifft()&lt;/code&gt;&lt;/a&gt; is deprecated and will be removed in a future PyTorch release. Use the new &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; module functions, instead, by importing &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; and calling &lt;a href=&quot;../fft#torch.fft.ifft&quot;&gt;&lt;code&gt;torch.fft.ifft()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../fft#torch.fft.ifftn&quot;&gt;&lt;code&gt;torch.fft.ifftn()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">不推荐使用函数&lt;a href=&quot;#torch.ifft&quot;&gt; &lt;code&gt;torch.ifft()&lt;/code&gt; &lt;/a&gt;，并将在以后的PyTorch版本中将其删除。而是使用新的&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;模块函数，方法是导入&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;并调用&lt;a href=&quot;../fft#torch.fft.ifft&quot;&gt; &lt;code&gt;torch.fft.ifft()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;../fft#torch.fft.ifftn&quot;&gt; &lt;code&gt;torch.fft.ifftn()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b1a40cf129fc842a7fe39cfe2023111384b05a6c" translate="yes" xml:space="preserve">
          <source>The function &lt;a href=&quot;#torch.irfft&quot;&gt;&lt;code&gt;torch.irfft()&lt;/code&gt;&lt;/a&gt; is deprecated and will be removed in a future PyTorch release. Use the new &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; module functions, instead, by importing &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; and calling &lt;a href=&quot;../fft#torch.fft.irfft&quot;&gt;&lt;code&gt;torch.fft.irfft()&lt;/code&gt;&lt;/a&gt; for one-sided input, or &lt;a href=&quot;../fft#torch.fft.ifft&quot;&gt;&lt;code&gt;torch.fft.ifft()&lt;/code&gt;&lt;/a&gt; for two-sided input.</source>
          <target state="translated">不推荐使用函数&lt;a href=&quot;#torch.irfft&quot;&gt; &lt;code&gt;torch.irfft()&lt;/code&gt; &lt;/a&gt;，并将在以后的PyTorch版本中将其删除。而是使用新的&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;模块函数，方法是导入&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;并为一侧输入调用&lt;a href=&quot;../fft#torch.fft.irfft&quot;&gt; &lt;code&gt;torch.fft.irfft()&lt;/code&gt; &lt;/a&gt;，或者为&lt;a href=&quot;../fft#torch.fft.ifft&quot;&gt; &lt;code&gt;torch.fft.ifft()&lt;/code&gt; &lt;/a&gt;输入调用torch.fft.ifft（）。</target>
        </trans-unit>
        <trans-unit id="a0db51d208a07883c44d7be8c9786454460ee522" translate="yes" xml:space="preserve">
          <source>The function &lt;a href=&quot;#torch.rfft&quot;&gt;&lt;code&gt;torch.rfft()&lt;/code&gt;&lt;/a&gt; is deprecated and will be removed in a future PyTorch release. Use the new &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; module functions, instead, by importing &lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt; and calling &lt;a href=&quot;../fft#torch.fft.rfft&quot;&gt;&lt;code&gt;torch.fft.rfft()&lt;/code&gt;&lt;/a&gt; for one-sided output, or &lt;a href=&quot;../fft#torch.fft.fft&quot;&gt;&lt;code&gt;torch.fft.fft()&lt;/code&gt;&lt;/a&gt; for two-sided output.</source>
          <target state="translated">不推荐使用函数&lt;a href=&quot;#torch.rfft&quot;&gt; &lt;code&gt;torch.rfft()&lt;/code&gt; &lt;/a&gt;，并将在以后的PyTorch版本中将其删除。而是使用新的&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;模块函数，方法是导入&lt;a href=&quot;../fft#torch-fft-module&quot;&gt;torch.fft&lt;/a&gt;并为一侧输出调用&lt;a href=&quot;../fft#torch.fft.rfft&quot;&gt; &lt;code&gt;torch.fft.rfft()&lt;/code&gt; &lt;/a&gt;或为&lt;a href=&quot;../fft#torch.fft.fft&quot;&gt; &lt;code&gt;torch.fft.fft()&lt;/code&gt; &lt;/a&gt;输出调用torch.fft.fft（）。</target>
        </trans-unit>
        <trans-unit id="10b975abfe7a8de3222390632564c8c39557329e" translate="yes" xml:space="preserve">
          <source>The function is called as &lt;code&gt;fn(i, *args)&lt;/code&gt;, where &lt;code&gt;i&lt;/code&gt; is the process index and &lt;code&gt;args&lt;/code&gt; is the passed through tuple of arguments.</source>
          <target state="translated">该函数称为 &lt;code&gt;fn(i, *args)&lt;/code&gt; ，其中 &lt;code&gt;i&lt;/code&gt; 是进程索引，而 &lt;code&gt;args&lt;/code&gt; 是传递的参数元组。</target>
        </trans-unit>
        <trans-unit id="78c07c2cfdea987b1b930691f54fd99adb7a7932" translate="yes" xml:space="preserve">
          <source>The function is defined as:</source>
          <target state="translated">该功能定义为:</target>
        </trans-unit>
        <trans-unit id="81e6543a378b1e27df259854cebe693b6ae023b6" translate="yes" xml:space="preserve">
          <source>The gated linear unit. Computes:</source>
          <target state="translated">门控线性单元。计算。</target>
        </trans-unit>
        <trans-unit id="e2ac4a47b4d32b1f56737b1e1c139ea56803b6cc" translate="yes" xml:space="preserve">
          <source>The graph is differentiated using the chain rule. If any of &lt;code&gt;tensors&lt;/code&gt; are non-scalar (i.e. their data has more than one element) and require gradient, then the Jacobian-vector product would be computed, in this case the function additionally requires specifying &lt;code&gt;grad_tensors&lt;/code&gt;. It should be a sequence of matching length, that contains the &amp;ldquo;vector&amp;rdquo; in the Jacobian-vector product, usually the gradient of the differentiated function w.r.t. corresponding tensors (&lt;code&gt;None&lt;/code&gt; is an acceptable value for all tensors that don&amp;rsquo;t need gradient tensors).</source>
          <target state="translated">该图使用链规则进行区分。如果任何 &lt;code&gt;tensors&lt;/code&gt; 是非标量的（即，它们的数据具有多个元素）并且需要梯度，则将计算雅可比矢量积，在这种情况下，该函数还需要指定 &lt;code&gt;grad_tensors&lt;/code&gt; 。它应该是一个匹配长度的序列，其中包含雅可比矢量积中的&amp;ldquo;矢量&amp;rdquo;，通常是微分函数与相应张量的梯度（对于不需要梯度张量的所有张量， &lt;code&gt;None&lt;/code&gt; 都是可接受的值）。</target>
        </trans-unit>
        <trans-unit id="c30476379351f558b5c5fb5c388947e81c5eddf9" translate="yes" xml:space="preserve">
          <source>The graph is differentiated using the chain rule. If the tensor is non-scalar (i.e. its data has more than one element) and requires gradient, the function additionally requires specifying &lt;code&gt;gradient&lt;/code&gt;. It should be a tensor of matching type and location, that contains the gradient of the differentiated function w.r.t. &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">该图使用链规则进行区分。如果张量是非标量的（即其数据具有多个元素）并且需要渐变，则该函数还需要指定 &lt;code&gt;gradient&lt;/code&gt; 。它应该是匹配类型和位置的张量，其中包含微分函数wrt &lt;code&gt;self&lt;/code&gt; 的梯度。</target>
        </trans-unit>
        <trans-unit id="e635ba31c5601250c0b5605418f5a52e38b9a9ea" translate="yes" xml:space="preserve">
          <source>The histogram is computed continuously, and the ranges per bin change with every new tensor observed.</source>
          <target state="translated">直方图是连续计算的,每观察到一个新的张量,每个bin的范围就会改变。</target>
        </trans-unit>
        <trans-unit id="4fce725259bdabadb8950b8c6e8b1cc9bdca5a28" translate="yes" xml:space="preserve">
          <source>The hook should not modify its argument, but it can optionally return a new gradient which will be used in place of &lt;a href=&quot;#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">挂钩不应该修改其参数，但可以选择返回一个新的渐变，该渐变将代替&lt;a href=&quot;#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="63a016154b7848c498c0189a691b12aee6391726" translate="yes" xml:space="preserve">
          <source>The hook should not modify its argument, but it can optionally return a new gradient which will be used in place of &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">挂钩不应该修改其参数，但可以选择返回一个新的渐变，该渐变将代替&lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d3b8c649dc7d5a1913425cba9308cbaac351ab8a" translate="yes" xml:space="preserve">
          <source>The hook will be called every time a gradient with respect to the Tensor is computed. The hook should have the following signature:</source>
          <target state="translated">每次计算相对于Tensor的梯度时,都会调用这个钩子。钩子应该有如下签名。</target>
        </trans-unit>
        <trans-unit id="91b8909b6b0301d53bc827787fcd07621d744139" translate="yes" xml:space="preserve">
          <source>The hook will be called every time after &lt;a href=&quot;#torch.nn.Module.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; has computed an output. It should have the following signature:</source>
          <target state="translated">每当&lt;a href=&quot;#torch.nn.Module.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;计算输出后，该挂钩都会被调用。它应该具有以下签名：</target>
        </trans-unit>
        <trans-unit id="ea6266d19428a156d329cc252aacfffb34135bcf" translate="yes" xml:space="preserve">
          <source>The hook will be called every time after &lt;code&gt;forward()&lt;/code&gt; has computed an output. It should have the following signature:</source>
          <target state="translated">每当 &lt;code&gt;forward()&lt;/code&gt; 计算输出后，该挂钩都会被调用。它应该具有以下签名：</target>
        </trans-unit>
        <trans-unit id="3027e825f33c77d15aef5c4a000dacdcd543639b" translate="yes" xml:space="preserve">
          <source>The hook will be called every time before &lt;a href=&quot;#torch.nn.Module.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; is invoked. It should have the following signature:</source>
          <target state="translated">该挂钩将在每次调用&lt;a href=&quot;#torch.nn.Module.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;之前被调用。它应该具有以下签名：</target>
        </trans-unit>
        <trans-unit id="658103272c0bdd847853bfee8c1acd84bd1873a4" translate="yes" xml:space="preserve">
          <source>The hook will be called every time before &lt;code&gt;forward()&lt;/code&gt; is invoked. It should have the following signature:</source>
          <target state="translated">该挂钩将在每次调用 &lt;code&gt;forward()&lt;/code&gt; 之前被调用。它应该具有以下签名：</target>
        </trans-unit>
        <trans-unit id="b7317d93b9ecea6baa18606aa1761b42a13618f5" translate="yes" xml:space="preserve">
          <source>The hook will be called every time the gradients with respect to module inputs are computed. The hook should have the following signature:</source>
          <target state="translated">每次计算模块输入的梯度时,都会调用这个钩子。钩子的签名如下。</target>
        </trans-unit>
        <trans-unit id="47b9323acd4c956c6840fecee45ba64f27f04f5f" translate="yes" xml:space="preserve">
          <source>The idea is that the clusters which are accessed frequently (like the first one, containing most frequent labels), should also be cheap to compute &amp;ndash; that is, contain a small number of assigned labels.</source>
          <target state="translated">这个想法是，频繁访问的集群（如第一个集群，包含最频繁的标签），也应该便宜计算-即，包含少量分配的标签。</target>
        </trans-unit>
        <trans-unit id="53da9964154c69f0225ac83d2e63e3e638d7b44d" translate="yes" xml:space="preserve">
          <source>The implementation here takes the square root of the gradient average before adding epsilon (note that TensorFlow interchanges these two operations). The effective learning rate is thus</source>
          <target state="translated">这里的实现是先取梯度平均值的平方根,然后再加上epsilon(注意TensorFlow将这两个操作互换)。因此,有效学习率为</target>
        </trans-unit>
        <trans-unit id="fd1e3da6ac802ac499dbc929d3c01e7d8d1e592e" translate="yes" xml:space="preserve">
          <source>The implementation is based on the Algorithm 5.1 from Halko et al, 2009.</source>
          <target state="translated">实现方式是基于Halko等人,2009年的算法5.1。</target>
        </trans-unit>
        <trans-unit id="b39161781b1b7b35ca70ad2826501e304e14740d" translate="yes" xml:space="preserve">
          <source>The implementation is based on: Bader, P.; Blanes, S.; Casas, F. Computing the Matrix Exponential with an Optimized Taylor Polynomial Approximation. Mathematics 2019, 7, 1174.</source>
          <target state="translated">实现的基础是。Bader,P.;Blanes,S.;Casas,F.Computing the Matrix Exponential with an Optimized Taylor Polynomial Approximation.Mathematics 2019,7,1174.</target>
        </trans-unit>
        <trans-unit id="b9e5eb34b5f671210df55afa7cf37ff9e10daa69" translate="yes" xml:space="preserve">
          <source>The implementation of SGD with Momentum/Nesterov subtly differs from Sutskever et. al. and implementations in some other frameworks.</source>
          <target state="translated">SGD与Momentum/Nesterov的实现与Sutskever等人和其他一些框架中的实现有微妙的不同。</target>
        </trans-unit>
        <trans-unit id="d9d89b5b4a75085b7eb81dcbff4669f9ff584606" translate="yes" xml:space="preserve">
          <source>The implementation of SVD on CPU uses the LAPACK routine &lt;code&gt;?gesdd&lt;/code&gt; (a divide-and-conquer algorithm) instead of &lt;code&gt;?gesvd&lt;/code&gt; for speed. Analogously, the SVD on GPU uses the MAGMA routine &lt;code&gt;gesdd&lt;/code&gt; as well.</source>
          <target state="translated">在CPU上SVD的实现使用LAPACK例程 &lt;code&gt;?gesdd&lt;/code&gt; （分而治之算法）而不是 &lt;code&gt;?gesvd&lt;/code&gt; 来提高速度。类似地，GPU上的SVD也使用MAGMA例程 &lt;code&gt;gesdd&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c05db592ff41dfc6119d9765d1f98df7bbeac593" translate="yes" xml:space="preserve">
          <source>The implementations of the models for object detection, instance segmentation and keypoint detection are efficient.</source>
          <target state="translated">对象检测、实例分割和关键点检测等模型的实现是高效的。</target>
        </trans-unit>
        <trans-unit id="2ee40d087e274de07c646cdfb7f973b9dab8f9cf" translate="yes" xml:space="preserve">
          <source>The inferred dtype for python floats in &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">python的推断&lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;torch.tensor()&lt;/code&gt; &lt;/a&gt;浮在torch.tensor（）中。</target>
        </trans-unit>
        <trans-unit id="6c9a1b1a8c22e228f94e607d9ba23a7a9895221c" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;window_length&lt;/code&gt; is a positive integer controlling the returned window size. &lt;code&gt;periodic&lt;/code&gt; flag determines whether the returned window trims off the last duplicate value from the symmetric window and is ready to be used as a periodic window with functions like &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;torch.stft()&lt;/code&gt;&lt;/a&gt;. Therefore, if &lt;code&gt;periodic&lt;/code&gt; is true, the</source>
          <target state="translated">输入的 &lt;code&gt;window_length&lt;/code&gt; 是控制返回的窗口大小的正整数。 &lt;code&gt;periodic&lt;/code&gt; 标志确定返回的窗口是否从对称窗口中修剪掉最后一个重复值，并准备好用作具有&lt;a href=&quot;torch.stft#torch.stft&quot;&gt; &lt;code&gt;torch.stft()&lt;/code&gt; 之&lt;/a&gt;类的定期窗口。因此，如果 &lt;code&gt;periodic&lt;/code&gt; 为真，则</target>
        </trans-unit>
        <trans-unit id="dffb8d48e1eff38cec4958715ef4e4bea17673f9" translate="yes" xml:space="preserve">
          <source>The input channels are separated into &lt;code&gt;num_groups&lt;/code&gt; groups, each containing &lt;code&gt;num_channels / num_groups&lt;/code&gt; channels. The mean and standard-deviation are calculated separately over the each group.</source>
          <target state="translated">输入通道分为 &lt;code&gt;num_groups&lt;/code&gt; 个组，每个组包含 &lt;code&gt;num_channels / num_groups&lt;/code&gt; 通道。在每个组中分别计算平均值和标准偏差。</target>
        </trans-unit>
        <trans-unit id="24d9bce9a9af270abcd63358a34e29c31cf80c6f" translate="yes" xml:space="preserve">
          <source>The input contains only the positional arguments given to the module. Keyword arguments won&amp;rsquo;t be passed to the hooks and only to the &lt;code&gt;forward&lt;/code&gt;. The hook can modify the input. User can either return a tuple or a single modified value in the hook. We will wrap the value into a tuple if a single value is returned(unless that value is already a tuple).</source>
          <target state="translated">输入仅包含提供给模块的位置参数。关键字参数将不会被传递到钩子只有到了 &lt;code&gt;forward&lt;/code&gt; 。挂钩可以修改输入。用户可以在挂钩中返回一个元组或一个修改后的值。如果返回单个值，我们将把该值包装到一个元组中（除非该值已经是一个元组）。</target>
        </trans-unit>
        <trans-unit id="501f21d86b3222c931438d1d37f49ef014fe1070" translate="yes" xml:space="preserve">
          <source>The input contains only the positional arguments given to the module. Keyword arguments won&amp;rsquo;t be passed to the hooks and only to the &lt;code&gt;forward&lt;/code&gt;. The hook can modify the output. It can modify the input inplace but it will not have effect on forward since this is called after &lt;a href=&quot;#torch.nn.Module.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">输入仅包含提供给模块的位置参数。关键字参数将不会被传递到钩子只有到了 &lt;code&gt;forward&lt;/code&gt; 。挂钩可以修改输出。它可以就地修改输入，但不会对正向产生影响，因为这是在调用&lt;a href=&quot;#torch.nn.Module.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;之后调用的。</target>
        </trans-unit>
        <trans-unit id="d84cfbddddc9e1c2d0a053623e51f4c9b23ed343" translate="yes" xml:space="preserve">
          <source>The input contains only the positional arguments given to the module. Keyword arguments won&amp;rsquo;t be passed to the hooks and only to the &lt;code&gt;forward&lt;/code&gt;. The hook can modify the output. It can modify the input inplace but it will not have effect on forward since this is called after &lt;code&gt;forward()&lt;/code&gt; is called.</source>
          <target state="translated">输入仅包含提供给模块的位置参数。关键字参数将不会被传递到钩子只有到了 &lt;code&gt;forward&lt;/code&gt; 。挂钩可以修改输出。它可以就地修改输入，但不会对正向产生影响，因为这是在调用 &lt;code&gt;forward()&lt;/code&gt; 之后调用的。</target>
        </trans-unit>
        <trans-unit id="e0bbaa069be68586598b46c411d0f2665ffc0e9d" translate="yes" xml:space="preserve">
          <source>The input data is assumed to be of the form &lt;code&gt;minibatch x channels x [optional depth] x [optional height] x width&lt;/code&gt;. Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.</source>
          <target state="translated">假定输入数据的格式为 &lt;code&gt;minibatch x channels x [optional depth] x [optional height] x width&lt;/code&gt; 。因此，对于空间输入，我们期望使用4D张量；对于体积输入，我们期望使用5D张量。</target>
        </trans-unit>
        <trans-unit id="855506544cad1eeac05a21efea97a3853e2dceb9" translate="yes" xml:space="preserve">
          <source>The input dimensions are interpreted in the form: &lt;code&gt;mini-batch x channels x [optional depth] x [optional height] x width&lt;/code&gt;.</source>
          <target state="translated">输入尺寸以以下形式解释： &lt;code&gt;mini-batch x channels x [optional depth] x [optional height] x width&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ff7b890633934634eb44c66753eb478acaced44e" translate="yes" xml:space="preserve">
          <source>The input is assumed to be a low-rank matrix.</source>
          <target state="translated">假设输入是一个低阶矩阵。</target>
        </trans-unit>
        <trans-unit id="aa72bb59a173177382b9660fee81f62bda47bdae" translate="yes" xml:space="preserve">
          <source>The input quantization parameters are propagated to the output.</source>
          <target state="translated">输入的量化参数被传播到输出。</target>
        </trans-unit>
        <trans-unit id="7c8e7facaf470e54c3381c46dad3dd11548e58de" translate="yes" xml:space="preserve">
          <source>The input quantization parameters propagate to the output.</source>
          <target state="translated">输入的量化参数传播到输出。</target>
        </trans-unit>
        <trans-unit id="9c93ac513b2302a4f83a43405b9a47bcb2309e67" translate="yes" xml:space="preserve">
          <source>The input to the model is expected to be a list of tensors, each of shape &lt;code&gt;[C, H, W]&lt;/code&gt;, one for each image, and should be in &lt;code&gt;0-1&lt;/code&gt; range. Different images can have different sizes.</source>
          <target state="translated">该模型的输入应该是张量列表，每个张量形状为 &lt;code&gt;[C, H, W]&lt;/code&gt; ，每个图像一个，并且应该在 &lt;code&gt;0-1&lt;/code&gt; 范围内。不同的图像可以具有不同的尺寸。</target>
        </trans-unit>
        <trans-unit id="33129e152019831a4d6451e1dcb0878f56c1bef2" translate="yes" xml:space="preserve">
          <source>The instance of this class can be used instead of the &lt;code&gt;torch.&lt;/code&gt; prefix for some operations. See example usage below.</source>
          <target state="translated">可以使用此类的实例代替 &lt;code&gt;torch.&lt;/code&gt; 一些操作的前缀。请参阅下面的示例用法。</target>
        </trans-unit>
        <trans-unit id="351e07f8a31af7d82fc6045df4c793836de62f62" translate="yes" xml:space="preserve">
          <source>The instance of this class can be used instead of the &lt;code&gt;torch.ops.quantized&lt;/code&gt; prefix. See example usage below.</source>
          <target state="translated">可以使用此类的实例代替 &lt;code&gt;torch.ops.quantized&lt;/code&gt; 前缀。请参阅下面的示例用法。</target>
        </trans-unit>
        <trans-unit id="6c3dcf3c5f75afd5957f352f9917b83b90088988" translate="yes" xml:space="preserve">
          <source>The interface for specifying operator definitions is a Prototype feature; adventurous users should note that the APIs will probably change in a future interface.</source>
          <target state="translated">指定操作符定义的接口是Prototype的一个功能;喜欢冒险的用户应该注意,API可能会在未来的接口中改变。</target>
        </trans-unit>
        <trans-unit id="3bb29d8ff742c3f78ac5a2da01f22239940307d9" translate="yes" xml:space="preserve">
          <source>The inverse of this function is &lt;a href=&quot;torch.fft#torch.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此函数的反函数是&lt;a href=&quot;torch.fft#torch.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3ff786d8f2651e07ce1136605dc8809d77fc8a6a" translate="yes" xml:space="preserve">
          <source>The inverse of this function is &lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此函数的反函数是&lt;a href=&quot;torch.ifft#torch.ifft&quot;&gt; &lt;code&gt;ifft()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bd26976415ff02dd321f8aabd58b78a55df77549" translate="yes" xml:space="preserve">
          <source>The inverse of this function is &lt;a href=&quot;torch.irfft#torch.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此函数的反函数是&lt;a href=&quot;torch.irfft#torch.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="51e2eb96b40c3aad396917c7dd98de9a6585beea" translate="yes" xml:space="preserve">
          <source>The inverse of this function is &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此函数的逆函数是&lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6f2e4deb4f5b0c2c822ac4f786f365c2a6921f20" translate="yes" xml:space="preserve">
          <source>The jvp is currently computed by using the backward of the backward (sometimes called the double backwards trick) as we don&amp;rsquo;t have support for forward mode AD in PyTorch at the moment.</source>
          <target state="translated">目前，jvp是使用向后的向后（有时称为&amp;ldquo;双重向后的技巧&amp;rdquo;）来计算的，因为我们目前在PyTorch中不支持正向模式AD。</target>
        </trans-unit>
        <trans-unit id="4b9e7887dd437999f146f02a0f60028f96d84bf3" translate="yes" xml:space="preserve">
          <source>The largest difference between TorchScript and the full Python language is that TorchScript only supports a small set of types that are needed to express neural net models. In particular, TorchScript supports:</source>
          <target state="translated">TorchScript与完整的Python语言最大的区别在于,TorchScript只支持表达神经网络模型所需的一小部分类型。特别是,TorchScript支持。</target>
        </trans-unit>
        <trans-unit id="3b1d6d882f09df5877abb8ef200d99a4552edbcc" translate="yes" xml:space="preserve">
          <source>The largest representable number.</source>
          <target state="translated">最大的可代表数。</target>
        </trans-unit>
        <trans-unit id="63b23adb215af0fe9eaa51ef9153973e0c53546f" translate="yes" xml:space="preserve">
          <source>The last term can be omitted or approximated with Stirling formula. The approximation is used for target values more than 1. For targets less or equal to 1 zeros are added to the loss.</source>
          <target state="translated">最后一项可以省略或用斯特林公式近似。近似值用于目标值大于1的情况,对于目标值小于或等于1的情况,损失上加0。</target>
        </trans-unit>
        <trans-unit id="08f3358598c31282b2114da38bcad5d74e704334" translate="yes" xml:space="preserve">
          <source>The locations are used in the order of</source>
          <target state="translated">地点按以下顺序使用</target>
        </trans-unit>
        <trans-unit id="9ebd3a640891ee47a9a38fbd56c89724e57e2af2" translate="yes" xml:space="preserve">
          <source>The loss can be described as:</source>
          <target state="translated">损失可以说是:</target>
        </trans-unit>
        <trans-unit id="f21bd0e4e809cda5ba13223c1dfb3494e56f4f3e" translate="yes" xml:space="preserve">
          <source>The loss function for</source>
          <target state="translated">损失函数</target>
        </trans-unit>
        <trans-unit id="86081d5fc32148129e542f3dc9192fb2857da205" translate="yes" xml:space="preserve">
          <source>The loss function for each pair of samples in the mini-batch is:</source>
          <target state="translated">迷你批中每对样品的损耗函数为:。</target>
        </trans-unit>
        <trans-unit id="bb7d036d43546cb725a6bf9bf29c5cc2076ac418" translate="yes" xml:space="preserve">
          <source>The loss function for each sample in the mini-batch is:</source>
          <target state="translated">迷你批中每个样品的损耗函数为:。</target>
        </trans-unit>
        <trans-unit id="48f8488012ce60a4d13e1aebd7fa0ba10061eaf3" translate="yes" xml:space="preserve">
          <source>The loss function for each sample is:</source>
          <target state="translated">每个样本的损失函数为:</target>
        </trans-unit>
        <trans-unit id="c43bc97db5e0527c42aa84dc0f06c5fb6d69ddbc" translate="yes" xml:space="preserve">
          <source>The loss function then becomes:</source>
          <target state="translated">损失函数就变成了。</target>
        </trans-unit>
        <trans-unit id="dbd64b8b1e6f8a768dc1cc623e35d46784438d27" translate="yes" xml:space="preserve">
          <source>The losses are averaged across observations for each minibatch. If the &lt;code&gt;weight&lt;/code&gt; argument is specified then this is a weighted average:</source>
          <target state="translated">对于每个小批量，损失是通过观察得到的平均值。如果指定了 &lt;code&gt;weight&lt;/code&gt; 参数，那么这是一个加权平均值：</target>
        </trans-unit>
        <trans-unit id="187e00ce183312dd132d6826870b8e0983ae12a8" translate="yes" xml:space="preserve">
          <source>The lower triangular part of the matrix is defined as the elements on and below the diagonal.</source>
          <target state="translated">矩阵的下三角部分被定义为对角线上和下的元素。</target>
        </trans-unit>
        <trans-unit id="cba1d04dc7071338e4468867933f6f030f4f19fd" translate="yes" xml:space="preserve">
          <source>The machine with rank 0 will be used to set up all connections.</source>
          <target state="translated">等级为0的机器将用于设置所有的连接。</target>
        </trans-unit>
        <trans-unit id="f6b0320b620362b6deb5bb70025cb38b632f6a57" translate="yes" xml:space="preserve">
          <source>The main trick for &lt;code&gt;hard&lt;/code&gt; is to do &lt;code&gt;y_hard - y_soft.detach() + y_soft&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;hard&lt;/code&gt; 的主要技巧是执行 &lt;code&gt;y_hard - y_soft.detach() + y_soft&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="61caa3335965d2f3a59a97a54b15a39417eaac38" translate="yes" xml:space="preserve">
          <source>The max-pooling operation is applied in</source>
          <target state="translated">最大池化操作应用在</target>
        </trans-unit>
        <trans-unit id="d65dca627767b86d15d82ece9fa3008acf19101f" translate="yes" xml:space="preserve">
          <source>The mean and standard-deviation are calculated per-dimension over all mini-batches of the same process groups.</source>
          <target state="translated">平均值和标准差是按同一工艺组的所有小批量计算的。</target>
        </trans-unit>
        <trans-unit id="c3242427612d3b3c3e0cb9845d6bf7db1596d5b9" translate="yes" xml:space="preserve">
          <source>The mean and standard-deviation are calculated per-dimension over the mini-batches and</source>
          <target state="translated">平均值和标准差是按小批量的尺寸计算的。</target>
        </trans-unit>
        <trans-unit id="5661df9ad4405c387ea95d88a69a9fe1650b1552" translate="yes" xml:space="preserve">
          <source>The mean and standard-deviation are calculated per-dimension separately for each object in a mini-batch.</source>
          <target state="translated">平均值和标准差是按微型批次中每个对象的尺寸分别计算的。</target>
        </trans-unit>
        <trans-unit id="29fab6215a0696acbd3e84d8cb442b324881c861" translate="yes" xml:space="preserve">
          <source>The mean and standard-deviation are calculated separately over the last certain number dimensions which have to be of the shape specified by &lt;code&gt;normalized_shape&lt;/code&gt;.</source>
          <target state="translated">平均值和标准偏差是在最后一定数量的维度上分别计算的，这些维度必须具有 &lt;code&gt;normalized_shape&lt;/code&gt; 指定的形状。</target>
        </trans-unit>
        <trans-unit id="8a930aa85422123ed7ce795a3af91990ae6ee8f7" translate="yes" xml:space="preserve">
          <source>The mean operation still operates over all the elements, and divides by</source>
          <target state="translated">平均数运算仍对所有元素进行运算,并除以</target>
        </trans-unit>
        <trans-unit id="619af861d215de1b87a6226cb50c28f6e623bb30" translate="yes" xml:space="preserve">
          <source>The median is not unique for &lt;code&gt;input&lt;/code&gt; tensors with an even number of elements in the dimension &lt;code&gt;dim&lt;/code&gt;. In this case the lower of the two medians is returned. To compute the mean of both medians in &lt;code&gt;input&lt;/code&gt;, use &lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt;&lt;code&gt;torch.quantile()&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;q=0.5&lt;/code&gt; instead.</source>
          <target state="translated">对于维度为 &lt;code&gt;dim&lt;/code&gt; 的偶数个元素的 &lt;code&gt;input&lt;/code&gt; 张量，中位数不是唯一的。在这种情况下，将返回两个中位数中的较低者。为了计算平均二者中位数的 &lt;code&gt;input&lt;/code&gt; ，使用&lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt; &lt;code&gt;torch.quantile()&lt;/code&gt; &lt;/a&gt;与 &lt;code&gt;q=0.5&lt;/code&gt; 代替。</target>
        </trans-unit>
        <trans-unit id="5d7cf56bfc5cedceb3ca00313d8c3d414937caef" translate="yes" xml:space="preserve">
          <source>The median is not unique for &lt;code&gt;input&lt;/code&gt; tensors with an even number of elements. In this case the lower of the two medians is returned. To compute the mean of both medians in &lt;code&gt;input&lt;/code&gt;, use &lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt;&lt;code&gt;torch.quantile()&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;q=0.5&lt;/code&gt; instead.</source>
          <target state="translated">对于具有偶数个元素的 &lt;code&gt;input&lt;/code&gt; 张量，中位数不是唯一的。在这种情况下，将返回两个中位数中的较低者。为了计算平均二者中位数的 &lt;code&gt;input&lt;/code&gt; ，使用&lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt; &lt;code&gt;torch.quantile()&lt;/code&gt; &lt;/a&gt;与 &lt;code&gt;q=0.5&lt;/code&gt; 代替。</target>
        </trans-unit>
        <trans-unit id="3568ef228089a375953fda3fd0c97aca0ace05a3" translate="yes" xml:space="preserve">
          <source>The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block. The number of channels in outer 1x1 convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048 channels, and in Wide ResNet-50-2 has 2048-1024-2048.</source>
          <target state="translated">该模型与ResNet相同,只是瓶颈通道数是每块中的两倍。外侧1x1卷的通道数相同,例如ResNet-50的最后一个块有2048-512-2048个通道,而宽ResNet-50-2有2048-1024-2048个通道。</target>
        </trans-unit>
        <trans-unit id="f15c86c9dfb63d5c112adb09bde9cb61a9fe3f2e" translate="yes" xml:space="preserve">
          <source>The model returns a &lt;code&gt;Dict[Tensor]&lt;/code&gt; during training, containing the classification and regression losses for both the RPN and the R-CNN, and the keypoint loss.</source>
          <target state="translated">该模型在训练期间返回 &lt;code&gt;Dict[Tensor]&lt;/code&gt; ，其中包含RPN和R-CNN的分类和回归损失以及关键点损失。</target>
        </trans-unit>
        <trans-unit id="065007e637ab5dd9f6a9a41f5c632d9aa1aa3f5e" translate="yes" xml:space="preserve">
          <source>The model returns a &lt;code&gt;Dict[Tensor]&lt;/code&gt; during training, containing the classification and regression losses for both the RPN and the R-CNN, and the mask loss.</source>
          <target state="translated">该模型在训练期间返回 &lt;code&gt;Dict[Tensor]&lt;/code&gt; ，其中包含RPN和R-CNN的分类和回归损失，以及模板损失。</target>
        </trans-unit>
        <trans-unit id="a0c3a4815182bd38a59e8d48bd1acda3676df3d3" translate="yes" xml:space="preserve">
          <source>The model returns a &lt;code&gt;Dict[Tensor]&lt;/code&gt; during training, containing the classification and regression losses for both the RPN and the R-CNN.</source>
          <target state="translated">该模型在训练期间返回 &lt;code&gt;Dict[Tensor]&lt;/code&gt; ，其中包含RPN和R-CNN的分类和回归损失。</target>
        </trans-unit>
        <trans-unit id="25fbe42f5bebb67d721733ebaa470925353914ab" translate="yes" xml:space="preserve">
          <source>The model returns a &lt;code&gt;Dict[Tensor]&lt;/code&gt; during training, containing the classification and regression losses.</source>
          <target state="translated">该模型在训练期间返回 &lt;code&gt;Dict[Tensor]&lt;/code&gt; ，其中包含分类和回归损失。</target>
        </trans-unit>
        <trans-unit id="f6df7f86985b4db8720a0303772bb804adf7b58b" translate="yes" xml:space="preserve">
          <source>The model will be attached with observer or fake quant modules, and qconfig will be propagated.</source>
          <target state="translated">模型将附加观察者或假量子模块,qconfig将被传播。</target>
        </trans-unit>
        <trans-unit id="32c7b059b3336b886e2737e75a7a90bf14890a11" translate="yes" xml:space="preserve">
          <source>The models expect a list of &lt;code&gt;Tensor[C, H, W]&lt;/code&gt;, in the range &lt;code&gt;0-1&lt;/code&gt;. The models internally resize the images so that they have a minimum size of &lt;code&gt;800&lt;/code&gt;. This option can be changed by passing the option &lt;code&gt;min_size&lt;/code&gt; to the constructor of the models.</source>
          <target state="translated">模型期望在 &lt;code&gt;0-1&lt;/code&gt; 范围内的 &lt;code&gt;Tensor[C, H, W]&lt;/code&gt; 列表。模型在内部调整图像的大小，以使其最小尺寸为 &lt;code&gt;800&lt;/code&gt; 。可以通过将选项 &lt;code&gt;min_size&lt;/code&gt; 传递给模型的构造函数来更改此选项。</target>
        </trans-unit>
        <trans-unit id="b8cd112b9466880b251d727f36c9b5a8099f6121" translate="yes" xml:space="preserve">
          <source>The models subpackage contains definitions for the following model architectures for detection:</source>
          <target state="translated">模型子包包含了以下用于检测的模型架构的定义。</target>
        </trans-unit>
        <trans-unit id="2fd7064c0a6dbdb00e5c05b4bcf7bb996635bfb3" translate="yes" xml:space="preserve">
          <source>The models subpackage contains definitions for the following model architectures for image classification:</source>
          <target state="translated">模型子包包含以下图像分类模型架构的定义。</target>
        </trans-unit>
        <trans-unit id="9a82a240d4b1d0867d7d72a1a3f555d48973b4c7" translate="yes" xml:space="preserve">
          <source>The models subpackage contains definitions for the following model architectures for semantic segmentation:</source>
          <target state="translated">模型子包包含了以下用于语义分割的模型架构的定义。</target>
        </trans-unit>
        <trans-unit id="18bc003911e615e5dba9603961f512f27acb297a" translate="yes" xml:space="preserve">
          <source>The models subpackage contains definitions of models for addressing different tasks, including: image classification, pixelwise semantic segmentation, object detection, instance segmentation, person keypoint detection and video classification.</source>
          <target state="translated">模型子包包含了解决不同任务的模型定义,包括:图像分类、像素语义分割、对象检测、实例分割、人物关键点检测和视频分类。</target>
        </trans-unit>
        <trans-unit id="3cf46d13a21b259a13e6ce62948cca48ddbc78f6" translate="yes" xml:space="preserve">
          <source>The modes available for resizing are: &lt;code&gt;nearest&lt;/code&gt;, &lt;code&gt;linear&lt;/code&gt; (3D-only), &lt;code&gt;bilinear&lt;/code&gt;, &lt;code&gt;bicubic&lt;/code&gt; (4D-only), &lt;code&gt;trilinear&lt;/code&gt; (5D-only), &lt;code&gt;area&lt;/code&gt;</source>
          <target state="translated">可用于调整大小的模式为： &lt;code&gt;nearest&lt;/code&gt; ， &lt;code&gt;linear&lt;/code&gt; （仅3D）， &lt;code&gt;bilinear&lt;/code&gt; ， &lt;code&gt;bicubic&lt;/code&gt; （仅4D）， &lt;code&gt;trilinear&lt;/code&gt; （仅5D）， &lt;code&gt;area&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="28d8cfd32d3249e2763e181ffc749144e0ea24a2" translate="yes" xml:space="preserve">
          <source>The modes available for upsampling are: &lt;code&gt;nearest&lt;/code&gt;, &lt;code&gt;linear&lt;/code&gt; (3D-only), &lt;code&gt;bilinear&lt;/code&gt;, &lt;code&gt;bicubic&lt;/code&gt; (4D-only), &lt;code&gt;trilinear&lt;/code&gt; (5D-only)</source>
          <target state="translated">可用于上采样的模式为： &lt;code&gt;nearest&lt;/code&gt; ， &lt;code&gt;linear&lt;/code&gt; （仅3D）， &lt;code&gt;bilinear&lt;/code&gt; ， &lt;code&gt;bicubic&lt;/code&gt; （仅4D）， &lt;code&gt;trilinear&lt;/code&gt; （仅5D）</target>
        </trans-unit>
        <trans-unit id="18b2caf95e73a1c791145d0b79ff330ee08dd6df" translate="yes" xml:space="preserve">
          <source>The module can be accessed as an attribute using the given name.</source>
          <target state="translated">该模块可以使用给定的名称作为属性访问。</target>
        </trans-unit>
        <trans-unit id="4279942bb80ec4b3ccf751b2de250bbb42e94404" translate="yes" xml:space="preserve">
          <source>The module is mainly for debug and records the tensor values during runtime.</source>
          <target state="translated">该模块主要用于调试,在运行时记录张量值。</target>
        </trans-unit>
        <trans-unit id="cbcdfca1ae0201a3feb424a59be4618b6c74eaeb" translate="yes" xml:space="preserve">
          <source>The module records the running histogram of tensor values along with min/max values. &lt;code&gt;calculate_qparams&lt;/code&gt; will calculate scale and zero_point.</source>
          <target state="translated">该模块记录张量值以及最小/最大值的运行直方图。 &lt;code&gt;calculate_qparams&lt;/code&gt; 将计算规模和zero_point。</target>
        </trans-unit>
        <trans-unit id="00f10b867e105cafb015ef514a5b43106e8a7867" translate="yes" xml:space="preserve">
          <source>The module&amp;rsquo;s &lt;code&gt;forward&lt;/code&gt; is compiled by default. Methods called from &lt;code&gt;forward&lt;/code&gt; are lazily compiled in the order they are used in &lt;code&gt;forward&lt;/code&gt;.</source>
          <target state="translated">默认情况下，模块的 &lt;code&gt;forward&lt;/code&gt; 编译。从 &lt;code&gt;forward&lt;/code&gt; 调用的方法按照 &lt;code&gt;forward&lt;/code&gt; 使用的顺序延迟编译。</target>
        </trans-unit>
        <trans-unit id="c8d325f814f94943441bf4453b4ce6fd4bb34555" translate="yes" xml:space="preserve">
          <source>The most important argument of &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; constructor is &lt;code&gt;dataset&lt;/code&gt;, which indicates a dataset object to load data from. PyTorch supports two different types of datasets:</source>
          <target state="translated">&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;构造函数最重要的参数是 &lt;code&gt;dataset&lt;/code&gt; ，它指示要从中加载数据的数据集对象。PyTorch支持两种不同类型的数据集：</target>
        </trans-unit>
        <trans-unit id="85f2f05d4d25b4d7e3119d033b3d3b1eb5b1a272" translate="yes" xml:space="preserve">
          <source>The moving average min/max is computed as follows</source>
          <target state="translated">移动平均线的最小/最大值计算如下</target>
        </trans-unit>
        <trans-unit id="1664b05e14f7fa9291ef99d0be2e3353189a5613" translate="yes" xml:space="preserve">
          <source>The multivariate normal distribution can be parameterized either in terms of a positive definite covariance matrix</source>
          <target state="translated">多变量正态分布可以用正定协方差矩阵进行参数化。</target>
        </trans-unit>
        <trans-unit id="f00cd6c1142679bd0fe1c3ebd4ca78600af96a2c" translate="yes" xml:space="preserve">
          <source>The name of the worker.</source>
          <target state="translated">工的名字。</target>
        </trans-unit>
        <trans-unit id="fba68059efcba7726021d64196e7ad3e2e4fcb96" translate="yes" xml:space="preserve">
          <source>The named tensor API is a prototype feature and subject to change.</source>
          <target state="translated">命名的张量API是一个原型功能,可能会发生变化。</target>
        </trans-unit>
        <trans-unit id="ed535f6a7c3020c739db9c59caec32bca959d97b" translate="yes" xml:space="preserve">
          <source>The named tensor API is experimental and subject to change.</source>
          <target state="translated">命名的张量API是实验性的,可能会改变。</target>
        </trans-unit>
        <trans-unit id="36555b023721ec5738f0c183a135318d3c9a4466" translate="yes" xml:space="preserve">
          <source>The negative log likelihood loss.</source>
          <target state="translated">负对数似然损失。</target>
        </trans-unit>
        <trans-unit id="80880349d7cc0a615947c8d7ecadbb60eab216c2" translate="yes" xml:space="preserve">
          <source>The negative log likelihood loss. It is useful to train a classification problem with &lt;code&gt;C&lt;/code&gt; classes.</source>
          <target state="translated">负对数似然损失。用 &lt;code&gt;C&lt;/code&gt; 类训练分类问题很有用。</target>
        </trans-unit>
        <trans-unit id="07e33a3c723549700a6c484c42061c0b83f6423c" translate="yes" xml:space="preserve">
          <source>The new backend derives from &lt;code&gt;c10d.ProcessGroup&lt;/code&gt; and registers the backend name and the instantiating interface through &lt;code&gt;torch.distributed.Backend.register_backend()&lt;/code&gt; when imported.</source>
          <target state="translated">新后端从 &lt;code&gt;c10d.ProcessGroup&lt;/code&gt; 派生，并在导入时通过 &lt;code&gt;torch.distributed.Backend.register_backend()&lt;/code&gt; 注册后端名称和实例化接口。</target>
        </trans-unit>
        <trans-unit id="5ef80d57536dd4f889b111944ebd026c0916a56b" translate="yes" xml:space="preserve">
          <source>The new usage looks like this:</source>
          <target state="translated">新的用法是这样的。</target>
        </trans-unit>
        <trans-unit id="bfa45b6345caf33366ff2d44c58d6e6325263da6" translate="yes" xml:space="preserve">
          <source>The norm is computed over all gradients together, as if they were concatenated into a single vector. Gradients are modified in-place.</source>
          <target state="translated">法线是在所有梯度上一起计算的,就像它们被连成一个向量一样。梯度是就地修改的。</target>
        </trans-unit>
        <trans-unit id="760d37d3c11fd75fa728a8e00ba020ac1e72a10c" translate="yes" xml:space="preserve">
          <source>The normalization parameters are different from the image classification ones, and correspond to the mean and std from Kinetics-400.</source>
          <target state="translated">归一化参数与图像分类参数不同,对应的是Kinetics-400的平均值和标准值。</target>
        </trans-unit>
        <trans-unit id="6b4b699c449424f5a0ee9c963faafecf0fd0d061" translate="yes" xml:space="preserve">
          <source>The number of bins (size 1) is one larger than the largest value in &lt;code&gt;input&lt;/code&gt; unless &lt;code&gt;input&lt;/code&gt; is empty, in which case the result is a tensor of size 0. If &lt;code&gt;minlength&lt;/code&gt; is specified, the number of bins is at least &lt;code&gt;minlength&lt;/code&gt; and if &lt;code&gt;input&lt;/code&gt; is empty, then the result is tensor of size &lt;code&gt;minlength&lt;/code&gt; filled with zeros. If &lt;code&gt;n&lt;/code&gt; is the value at position &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;out[n] += weights[i]&lt;/code&gt; if &lt;code&gt;weights&lt;/code&gt; is specified else &lt;code&gt;out[n] += 1&lt;/code&gt;.</source>
          <target state="translated">（尺寸1）段的数目大于最大值较大的一个 &lt;code&gt;input&lt;/code&gt; ，除非 &lt;code&gt;input&lt;/code&gt; 是空的，在这种情况下，结果是大小为0的张量如果 &lt;code&gt;minlength&lt;/code&gt; 指定，段的数目是至少 &lt;code&gt;minlength&lt;/code&gt; 并且如果 &lt;code&gt;input&lt;/code&gt; 为空，则结果是 &lt;code&gt;minlength&lt;/code&gt; 为minlength的张量填充为零。如果 &lt;code&gt;n&lt;/code&gt; 是位置 &lt;code&gt;i&lt;/code&gt; 处的值，则 &lt;code&gt;out[n] += weights[i]&lt;/code&gt; 如果指定 &lt;code&gt;out[n] += 1&lt;/code&gt; &lt;code&gt;weights&lt;/code&gt; 则out [n] + = 1。</target>
        </trans-unit>
        <trans-unit id="792cc1a58f0a3a46d19118877b6d13c493cb98ec" translate="yes" xml:space="preserve">
          <source>The number of bits occupied by the type.</source>
          <target state="translated">类型占用的位数。</target>
        </trans-unit>
        <trans-unit id="280e9a9c6268d27aec18f9552a0a0e023b3a5d6c" translate="yes" xml:space="preserve">
          <source>The number of keys present in the store.</source>
          <target state="translated">仓库中存在的钥匙数量。</target>
        </trans-unit>
        <trans-unit id="cb1db44aaa6eaf0c2b9f7e2d3594ec089fe36151" translate="yes" xml:space="preserve">
          <source>The number of threads in the thread-pool used by &lt;code&gt;TensorPipeAgent&lt;/code&gt; to execute requests.</source>
          <target state="translated">&lt;code&gt;TensorPipeAgent&lt;/code&gt; 用于执行请求的线程池中的线程数。</target>
        </trans-unit>
        <trans-unit id="20a68b367a08bf827b8cb29b9a7a5775403402ae" translate="yes" xml:space="preserve">
          <source>The number of threads in the thread-pool used by ProcessGroupAgent.</source>
          <target state="translated">ProcessGroupAgent使用的线程池中的线程数。</target>
        </trans-unit>
        <trans-unit id="25f85e0ff2381c99b81c5c68406ed2a516dd1318" translate="yes" xml:space="preserve">
          <source>The numerical properties of a &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; can be accessed through either the &lt;a href=&quot;#torch.torch.finfo&quot;&gt;&lt;code&gt;torch.finfo&lt;/code&gt;&lt;/a&gt; or the &lt;a href=&quot;#torch.torch.iinfo&quot;&gt;&lt;code&gt;torch.iinfo&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">可以通过&lt;a href=&quot;#torch.torch.finfo&quot;&gt; &lt;code&gt;torch.finfo&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;#torch.torch.iinfo&quot;&gt; &lt;code&gt;torch.iinfo&lt;/code&gt; &lt;/a&gt;访问&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;的数字属性。</target>
        </trans-unit>
        <trans-unit id="d8e759a2b7197a6d6914a25b2e4bccfa94711180" translate="yes" xml:space="preserve">
          <source>The operation applied is:</source>
          <target state="translated">应用的操作是:</target>
        </trans-unit>
        <trans-unit id="0b61e3d8bf7f65d3c8a372be2ffe4aa181113744" translate="yes" xml:space="preserve">
          <source>The operation is defined as:</source>
          <target state="translated">该操作定义为:</target>
        </trans-unit>
        <trans-unit id="416029866582b442a7cfd38c944f5ccc41de6ea3" translate="yes" xml:space="preserve">
          <source>The operator set above is sufficient to export the following models:</source>
          <target state="translated">上面设置的运算符足以导出以下模型。</target>
        </trans-unit>
        <trans-unit id="97549a235d386a02f6c874f871b2a3fc368e849a" translate="yes" xml:space="preserve">
          <source>The order of norm. inf refers to &lt;code&gt;float('inf')&lt;/code&gt;, numpy&amp;rsquo;s &lt;code&gt;inf&lt;/code&gt; object, or any equivalent object. The following norms can be calculated:</source>
          <target state="translated">规范的顺序。inf是指 &lt;code&gt;float('inf')&lt;/code&gt; ，numpy的 &lt;code&gt;inf&lt;/code&gt; 对象或任何等效对象。可以计算以下规范：</target>
        </trans-unit>
        <trans-unit id="587438e00b276c5c07c33c3b833d1847c428edb1" translate="yes" xml:space="preserve">
          <source>The original &lt;code&gt;module&lt;/code&gt; with the converted &lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt;&lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt;&lt;/a&gt; layers. If the original &lt;code&gt;module&lt;/code&gt; is a &lt;code&gt;BatchNorm*D&lt;/code&gt; layer, a new &lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt;&lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt;&lt;/a&gt; layer object will be returned instead.</source>
          <target state="translated">具有转换的&lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt; &lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt; &lt;/a&gt;层的原始 &lt;code&gt;module&lt;/code&gt; 。如果原始 &lt;code&gt;module&lt;/code&gt; 是 &lt;code&gt;BatchNorm*D&lt;/code&gt; 层，则将返回一个新的&lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt; &lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt; &lt;/a&gt;层对象。</target>
        </trans-unit>
        <trans-unit id="016c290cf6497163981ebcd1b0530771762971db" translate="yes" xml:space="preserve">
          <source>The original Adam algorithm was proposed in &lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam: A Method for Stochastic Optimization&lt;/a&gt;. The AdamW variant was proposed in &lt;a href=&quot;https://arxiv.org/abs/1711.05101&quot;&gt;Decoupled Weight Decay Regularization&lt;/a&gt;.</source>
          <target state="translated">最初的Adam算法是在&lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam：一种随机优化方法中&lt;/a&gt;提出的。AdamW变体在去&lt;a href=&quot;https://arxiv.org/abs/1711.05101&quot;&gt;耦权重衰减正则化中&lt;/a&gt;提出。</target>
        </trans-unit>
        <trans-unit id="1c43e721e428fefa0921064ef9d974f9d9c3710a" translate="yes" xml:space="preserve">
          <source>The original module with the spectral norm hook</source>
          <target state="translated">原始模块与光谱法则挂钩</target>
        </trans-unit>
        <trans-unit id="1c8ee61f168965198d32cd38694cc41b385bdcc7" translate="yes" xml:space="preserve">
          <source>The original module with the weight norm hook</source>
          <target state="translated">原有的带重量标准钩的模块</target>
        </trans-unit>
        <trans-unit id="1ad8002d2700baeb804ee6b717ba471c2750abdc" translate="yes" xml:space="preserve">
          <source>The other way to implement these stochastic/policy gradients would be to use the reparameterization trick from the &lt;code&gt;rsample()&lt;/code&gt; method, where the parameterized random variable can be constructed via a parameterized deterministic function of a parameter-free random variable. The reparameterized sample therefore becomes differentiable. The code for implementing the pathwise derivative would be as follows:</source>
          <target state="translated">实现这些随机/策略梯度的另一种方法是使用 &lt;code&gt;rsample()&lt;/code&gt; 方法中的重新参数化技巧，其中可以通过无参数随机变量的参数化确定性函数构造参数化随机变量。因此，重新参数化的样本变得可微。用于实现按路径导数的代码如下：</target>
        </trans-unit>
        <trans-unit id="a7c71aa7150538e239f1ed9763931d65c1aab1d1" translate="yes" xml:space="preserve">
          <source>The output is of size D x H x W, for any input size. The number of output features is equal to the number of input planes.</source>
          <target state="translated">对于任何输入尺寸,输出的尺寸为D×H×W。输出特征的数量等于输入平面的数量。</target>
        </trans-unit>
        <trans-unit id="8d13bc6b68893874e15ef23c3e8bf09f29542e58" translate="yes" xml:space="preserve">
          <source>The output is of size H x W, for any input size. The number of output features is equal to the number of input planes.</source>
          <target state="translated">对于任何输入尺寸,输出的尺寸为H×W。输出特征的数量等于输入平面的数量。</target>
        </trans-unit>
        <trans-unit id="dd1aa83704336b7c60e0ac15205527d8852065d5" translate="yes" xml:space="preserve">
          <source>The output of the &lt;code&gt;model&lt;/code&gt; callable when called with the given &lt;code&gt;*args&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt;.</source>
          <target state="translated">当使用给定的 &lt;code&gt;*args&lt;/code&gt; 和 &lt;code&gt;**kwargs&lt;/code&gt; 调用时， &lt;code&gt;model&lt;/code&gt; 的输出是可调用的。</target>
        </trans-unit>
        <trans-unit id="2624c3f93c8a5ba7f8db76475b9b2160784ad8be" translate="yes" xml:space="preserve">
          <source>The output size is H, for any input size. The number of output features is equal to the number of input planes.</source>
          <target state="translated">输出大小为H,对于任何输入大小。输出特征的数量等于输入平面的数量。</target>
        </trans-unit>
        <trans-unit id="aaed500780776d71aa7aa3beac0d23a2ad0bee52" translate="yes" xml:space="preserve">
          <source>The output tuple size must match the outputs of &lt;code&gt;forward&lt;/code&gt;.</source>
          <target state="translated">输出元组大小必须与 &lt;code&gt;forward&lt;/code&gt; 的输出匹配。</target>
        </trans-unit>
        <trans-unit id="69fc4cd3bd84d50752da22ec0fa2da75a028b6c8" translate="yes" xml:space="preserve">
          <source>The package needs to be initialized using the &lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt;&lt;/a&gt; function before calling any other methods. This blocks until all processes have joined.</source>
          <target state="translated">在调用任何其他方法之前，需要使用&lt;a href=&quot;#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt; &lt;/a&gt;函数对程序包进行初始化。这将阻塞，直到所有进程都已加入。</target>
        </trans-unit>
        <trans-unit id="a24470d7f3dafd97610b1a97cfc4e625080f5d77" translate="yes" xml:space="preserve">
          <source>The padding size by which to pad some dimensions of &lt;code&gt;input&lt;/code&gt; are described starting from the last dimension and moving forward.</source>
          <target state="translated">从最后一个尺寸开始并向前移动，描述了用于填充 &lt;code&gt;input&lt;/code&gt; 某些尺寸的填充尺寸。</target>
        </trans-unit>
        <trans-unit id="b3d894892755f58e334d42f2a6bb03ad3c9c1029" translate="yes" xml:space="preserve">
          <source>The parallelized &lt;code&gt;module&lt;/code&gt; must have its parameters and buffers on &lt;code&gt;device_ids[0]&lt;/code&gt; before running this &lt;a href=&quot;#torch.nn.DataParallel&quot;&gt;&lt;code&gt;DataParallel&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">在运行此&lt;a href=&quot;#torch.nn.DataParallel&quot;&gt; &lt;code&gt;DataParallel&lt;/code&gt; &lt;/a&gt;模块之前，并行化 &lt;code&gt;module&lt;/code&gt; 必须在 &lt;code&gt;device_ids[0]&lt;/code&gt; 上具有其参数和缓冲区。</target>
        </trans-unit>
        <trans-unit id="611179cf7c23e5fa87e86dc65fc6c2d7edcfcdbf" translate="yes" xml:space="preserve">
          <source>The parameter can be accessed as an attribute using given name.</source>
          <target state="translated">该参数可以通过给定的名称作为属性访问。</target>
        </trans-unit>
        <trans-unit id="3673b833c2a753da5c92e7b2bd7867575cba0695" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt; can either be:</source>
          <target state="translated">参数 &lt;code&gt;kernel_size&lt;/code&gt; ， &lt;code&gt;stride&lt;/code&gt; 可以是：</target>
        </trans-unit>
        <trans-unit id="bb60e522db72c109467c75d771e518ca64062c0c" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt; can each be an &lt;code&gt;int&lt;/code&gt; or a one-element tuple.</source>
          <target state="translated">参数 &lt;code&gt;kernel_size&lt;/code&gt; ， &lt;code&gt;stride&lt;/code&gt; ， &lt;code&gt;padding&lt;/code&gt; 可以是一个 &lt;code&gt;int&lt;/code&gt; 或一个元素的元组。</target>
        </trans-unit>
        <trans-unit id="df694fbe631671fb53535c127328a8f9b5ccfdfe" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt; can either be:</source>
          <target state="translated">参数 &lt;code&gt;kernel_size&lt;/code&gt; ， &lt;code&gt;stride&lt;/code&gt; ， &lt;code&gt;padding&lt;/code&gt; 可以是：</target>
        </trans-unit>
        <trans-unit id="0d35449e64c1f14944b10572266aa02084f0787f" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt;, &lt;code&gt;dilation&lt;/code&gt; can either be:</source>
          <target state="translated">参数 &lt;code&gt;kernel_size&lt;/code&gt; ， &lt;code&gt;stride&lt;/code&gt; ， &lt;code&gt;padding&lt;/code&gt; ， &lt;code&gt;dilation&lt;/code&gt; 可以是：</target>
        </trans-unit>
        <trans-unit id="16e542ef2d9e6480cf0213002d643e04ad39afd9" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt;, &lt;code&gt;output_padding&lt;/code&gt; can either be:</source>
          <target state="translated">参数 &lt;code&gt;kernel_size&lt;/code&gt; ， &lt;code&gt;stride&lt;/code&gt; ， &lt;code&gt;padding&lt;/code&gt; ， &lt;code&gt;output_padding&lt;/code&gt; 可以是：</target>
        </trans-unit>
        <trans-unit id="9df0d4116a648b1a73d8fd1ad856ffa0c5b125d9" translate="yes" xml:space="preserve">
          <source>The parameters represented by a single vector</source>
          <target state="translated">用一个向量表示的参数</target>
        </trans-unit>
        <trans-unit id="16c253cfff05379e83f73283d75913a9d3bc5eb0" translate="yes" xml:space="preserve">
          <source>The pivots returned by the function are 1-indexed. If &lt;code&gt;pivot&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the returned pivots is a tensor filled with zeros of the appropriate size.</source>
          <target state="translated">该函数返回的枢轴为1索引。如果 &lt;code&gt;pivot&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; ，则返回的枢轴是一个张量，该张量填充有适当大小的零。</target>
        </trans-unit>
        <trans-unit id="4600b83baa50f6eee75af80c6cdb275baf5a4820" translate="yes" xml:space="preserve">
          <source>The pre-trained models for detection, instance segmentation and keypoint detection are initialized with the classification models in torchvision.</source>
          <target state="translated">检测、实例分割和关键点检测的预训练模型都是用torchvision中的分类模型初始化的。</target>
        </trans-unit>
        <trans-unit id="bacc13981715b20b015df75a9953a0a7c1d88d4c" translate="yes" xml:space="preserve">
          <source>The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset. You can see more information on how the subset has been selected in &lt;code&gt;references/segmentation/coco_utils.py&lt;/code&gt;. The classes that the pre-trained model outputs are the following, in order:</source>
          <target state="translated">预训练模型已在Pascal VOC数据集中存在的20个类别的COCO train2017子集中进行了训练。您可以在 &lt;code&gt;references/segmentation/coco_utils.py&lt;/code&gt; 中查看有关如何选择该子集的更多信息。预训练模型输出的类依次为：</target>
        </trans-unit>
        <trans-unit id="5f5bcce5c35434b7def7a2c2abecc7855a7ff6ae" translate="yes" xml:space="preserve">
          <source>The process for obtaining the values of &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;std&lt;/code&gt; is roughly equivalent to:</source>
          <target state="translated">获取 &lt;code&gt;mean&lt;/code&gt; 和 &lt;code&gt;std&lt;/code&gt; 差值的过程大致等同于：</target>
        </trans-unit>
        <trans-unit id="2eeaf80bb67fd9965166125db5e39a93b156744c" translate="yes" xml:space="preserve">
          <source>The provided mean is the circular one.</source>
          <target state="translated">所提供的平均数是圆形的。</target>
        </trans-unit>
        <trans-unit id="9a5bce0d740da57838aed1d4d747fbb1351683c7" translate="yes" xml:space="preserve">
          <source>The provided variance is the circular one.</source>
          <target state="translated">提供的变乱是圆形的。</target>
        </trans-unit>
        <trans-unit id="cb1f1b1b62d82d262fa3ee527ff2235c6fe33cf0" translate="yes" xml:space="preserve">
          <source>The pseudo-inverse is not necessarily a continuous function in the elements of the matrix &lt;a href=&quot;https://epubs.siam.org/doi/10.1137/0117004&quot;&gt;[1]&lt;/a&gt;. Therefore, derivatives are not always existent, and exist for a constant rank only &lt;a href=&quot;https://www.jstor.org/stable/2156365&quot;&gt;[2]&lt;/a&gt;. However, this method is backprop-able due to the implementation by using SVD results, and could be unstable. Double-backward will also be unstable due to the usage of SVD internally. See &lt;a href=&quot;torch.svd#torch.svd&quot;&gt;&lt;code&gt;svd()&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">伪逆在矩阵&lt;a href=&quot;https://epubs.siam.org/doi/10.1137/0117004&quot;&gt;[1]&lt;/a&gt;的元素中不一定是连续函数。因此，导数并不总是存在的，并且仅以恒定等级存在&lt;a href=&quot;https://www.jstor.org/stable/2156365&quot;&gt;[2]&lt;/a&gt;。但是，由于使用SVD结果实现，因此该方法可向后传播，并且可能不稳定。由于内部使用了SVD，因此双向后退也会变得不稳定。有关更多详细信息，请参见&lt;a href=&quot;torch.svd#torch.svd&quot;&gt; &lt;code&gt;svd()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="df88bf331dfcd873fd61e2a961e2a4565dca71ab" translate="yes" xml:space="preserve">
          <source>The pseudo-inverse of &lt;code&gt;input&lt;/code&gt; of dimensions</source>
          <target state="translated">尺寸 &lt;code&gt;input&lt;/code&gt; 的伪逆</target>
        </trans-unit>
        <trans-unit id="801cd7b0289a0cab3f1164523d810bc285cdd10c" translate="yes" xml:space="preserve">
          <source>The published models should be at least in a branch/tag. It can&amp;rsquo;t be a random commit.</source>
          <target state="translated">发布的模型应至少在分支/标签中。不能是随机提交。</target>
        </trans-unit>
        <trans-unit id="5002f22d2309c888525404ef88b8a18252cac236" translate="yes" xml:space="preserve">
          <source>The quantization parameters are computed the same way as in &lt;code&gt;MinMaxObserver&lt;/code&gt;, with the difference that the running min/max values are stored per channel. Scales and zero points are thus computed per channel as well.</source>
          <target state="translated">量化参数的计算方法与 &lt;code&gt;MinMaxObserver&lt;/code&gt; 中的计算方法相同，不同之处在于，每个通道都存储运行中的最小值/最大值。因此，每个通道也可以计算比例和零点。</target>
        </trans-unit>
        <trans-unit id="37425d4454f834297b034206170c35abd72a213b" translate="yes" xml:space="preserve">
          <source>The quantization parameters are computed the same way as in &lt;code&gt;MovingAverageMinMaxObserver&lt;/code&gt;, with the difference that the running min/max values are stored per channel. Scales and zero points are thus computed per channel as well.</source>
          <target state="translated">量化参数的计算方法与 &lt;code&gt;MovingAverageMinMaxObserver&lt;/code&gt; 中的计算方法相同，不同之处在于，每个通道都存储运行中的最小值/最大值。因此，每个通道也可以计算比例和零点。</target>
        </trans-unit>
        <trans-unit id="346d775a68239ce50fc9c648f8e7ac9c30934f97" translate="yes" xml:space="preserve">
          <source>The range of the linear region</source>
          <target state="translated">线性区域的范围</target>
        </trans-unit>
        <trans-unit id="a67bc4760995b69a50ba7bb512777bd75a29786d" translate="yes" xml:space="preserve">
          <source>The rank of the process group -1, if not part of the group</source>
          <target state="translated">流程组的等级-1,如果不属于该组,则不属于该组。</target>
        </trans-unit>
        <trans-unit id="1640b5e94a24bbde9b57f55563952bd38f53f1c7" translate="yes" xml:space="preserve">
          <source>The real-to-complex Fourier transform results follow conjugate symmetry:</source>
          <target state="translated">实对复傅里叶变换结果遵循共轭对称性。</target>
        </trans-unit>
        <trans-unit id="f3326dbe4c730be437e49c0a1205659d772531b4" translate="yes" xml:space="preserve">
          <source>The regular implementation uses the (more common in PyTorch) &lt;code&gt;torch.long&lt;/code&gt; dtype.</source>
          <target state="translated">常规实现使用（在PyTorch中更常见） &lt;code&gt;torch.long&lt;/code&gt; dtype。</target>
        </trans-unit>
        <trans-unit id="f42ad6925b2f350139e05854ee56333bfbf81bfa" translate="yes" xml:space="preserve">
          <source>The relation of &lt;code&gt;(U, S, V)&lt;/code&gt; to PCA is as follows:</source>
          <target state="translated">的关系 &lt;code&gt;(U, S, V)&lt;/code&gt; 到PCA如下：</target>
        </trans-unit>
        <trans-unit id="946fd419edbe7367b996132ceeb5715b2129c56a" translate="yes" xml:space="preserve">
          <source>The rest of this section concerns the case with &lt;a href=&quot;#map-style-datasets&quot;&gt;map-style datasets&lt;/a&gt;. &lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;&lt;code&gt;torch.utils.data.Sampler&lt;/code&gt;&lt;/a&gt; classes are used to specify the sequence of indices/keys used in data loading. They represent iterable objects over the indices to datasets. E.g., in the common case with stochastic gradient decent (SGD), a &lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;&lt;code&gt;Sampler&lt;/code&gt;&lt;/a&gt; could randomly permute a list of indices and yield each one at a time, or yield a small number of them for mini-batch SGD.</source>
          <target state="translated">本节的其余部分涉及&lt;a href=&quot;#map-style-datasets&quot;&gt;地图样式数据集的情况&lt;/a&gt;。&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt; &lt;code&gt;torch.utils.data.Sampler&lt;/code&gt; &lt;/a&gt;类用于指定数据加载中使用的索引/键的顺序。它们代表数据集索引上的可迭代对象。例如，在具有随机梯度体面（SGD）的常见情况下，&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt; &lt;code&gt;Sampler&lt;/code&gt; &lt;/a&gt;可以随机排列一列索引，一次生成每个索引，或者为小批量SGD生成少量索引。</target>
        </trans-unit>
        <trans-unit id="0dee4722eb608774d930f39be3f46f18bcb0b430" translate="yes" xml:space="preserve">
          <source>The result will never require gradient.</source>
          <target state="translated">结果永远不需要梯度。</target>
        </trans-unit>
        <trans-unit id="6b0575a2f172061283c10c05f0db13db17166b95" translate="yes" xml:space="preserve">
          <source>The resulting &lt;code&gt;alexnet.onnx&lt;/code&gt; is a binary protobuf file which contains both the network structure and parameters of the model you exported (in this case, AlexNet). The keyword argument &lt;code&gt;verbose=True&lt;/code&gt; causes the exporter to print out a human-readable representation of the network:</source>
          <target state="translated">生成的 &lt;code&gt;alexnet.onnx&lt;/code&gt; 是一个二进制protobuf文件，其中包含您导出的模型的网络结构和参数（在本例中为AlexNet）。关键字参数 &lt;code&gt;verbose=True&lt;/code&gt; 使导出程序打印出人类可读的网络表示形式：</target>
        </trans-unit>
        <trans-unit id="3c02f08f3d1024ae629cdcc31caf60626bc7a365" translate="yes" xml:space="preserve">
          <source>The resulting &lt;code&gt;out&lt;/code&gt; tensor shares it&amp;rsquo;s underlying storage with the &lt;code&gt;input&lt;/code&gt; tensor, so changing the content of one would change the content of the other.</source>
          <target state="translated">结果 &lt;code&gt;out&lt;/code&gt; 张量与 &lt;code&gt;input&lt;/code&gt; 张量共享其基础存储，因此更改一个内容将更改另一个内容。</target>
        </trans-unit>
        <trans-unit id="6758477f8561982cc2515cdbf897a47792390375" translate="yes" xml:space="preserve">
          <source>The resulting recording of &lt;code&gt;nn.Module.forward&lt;/code&gt; or &lt;code&gt;nn.Module&lt;/code&gt; produces &lt;code&gt;ScriptModule&lt;/code&gt;.</source>
          <target state="translated">记录的 &lt;code&gt;nn.Module.forward&lt;/code&gt; 或 &lt;code&gt;nn.Module&lt;/code&gt; 产生 &lt;code&gt;ScriptModule&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="094611e344ec0108ea463a9054c21e208ca824dd" translate="yes" xml:space="preserve">
          <source>The resulting recording of a standalone function produces &lt;code&gt;ScriptFunction&lt;/code&gt;.</source>
          <target state="translated">独立函数的最终记录将产生 &lt;code&gt;ScriptFunction&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7e1976b95811fe3c223eccaa3dc30d2bb2ed6c6f" translate="yes" xml:space="preserve">
          <source>The return value of this function is a dictionary of statistics, each of which is a non-negative integer.</source>
          <target state="translated">这个函数的返回值是一个统计字典,每个统计字典都是一个非负的整数。</target>
        </trans-unit>
        <trans-unit id="14a7d916a182796f96dea780975d504da8d70e49" translate="yes" xml:space="preserve">
          <source>The returned &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object can come from &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;futures#torch.futures.Future.then&quot;&gt;&lt;code&gt;then()&lt;/code&gt;&lt;/a&gt;, or &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; constructor. The example below shows directly using the &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; returned by &lt;a href=&quot;futures#torch.futures.Future.then&quot;&gt;&lt;code&gt;then()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">返回的&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;对象可以来自&lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;futures#torch.futures.Future.then&quot;&gt; &lt;code&gt;then()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;构造函数。下面的示例直接显示了&lt;a href=&quot;futures#torch.futures.Future.then&quot;&gt; &lt;code&gt;then()&lt;/code&gt; &lt;/a&gt;返回的&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="35586b86275e1afc45c84727656b22c56c0dfc4c" translate="yes" xml:space="preserve">
          <source>The returned &lt;code&gt;out&lt;/code&gt; tensor only has values 0 or 1 and is of the same shape as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">返回的 &lt;code&gt;out&lt;/code&gt; 张量仅具有值0或1，是相同的形状的 &lt;code&gt;input&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0c1ca22658d19c73ead093d5a482f3f0748946cd" translate="yes" xml:space="preserve">
          <source>The returned Tensor&amp;rsquo;s data will be of size &lt;code&gt;T x B x *&lt;/code&gt;, where &lt;code&gt;T&lt;/code&gt; is the length of the longest sequence and &lt;code&gt;B&lt;/code&gt; is the batch size. If &lt;code&gt;batch_first&lt;/code&gt; is True, the data will be transposed into &lt;code&gt;B x T x *&lt;/code&gt; format.</source>
          <target state="translated">返回的Tensor数据大小为 &lt;code&gt;T x B x *&lt;/code&gt; ，其中 &lt;code&gt;T&lt;/code&gt; 是最长序列的长度，而 &lt;code&gt;B&lt;/code&gt; 是批处理大小。如果 &lt;code&gt;batch_first&lt;/code&gt; 为True，则数据将转置为 &lt;code&gt;B x T x *&lt;/code&gt; 格式。</target>
        </trans-unit>
        <trans-unit id="a86d643d348528641013d71d94cfc9c2436b5f5a" translate="yes" xml:space="preserve">
          <source>The returned matrices will always be transposed, irrespective of the strides of the input matrices. That is, they will have stride &lt;code&gt;(1, m)&lt;/code&gt; instead of &lt;code&gt;(m, 1)&lt;/code&gt;.</source>
          <target state="translated">无论输入矩阵的跨度如何，返回的矩阵将始终进行转置。也就是说，它们将具有 &lt;code&gt;(1, m)&lt;/code&gt; 而不是 &lt;code&gt;(m, 1)&lt;/code&gt; 步幅。</target>
        </trans-unit>
        <trans-unit id="e874ec4d7da2420c99c0303e4f7a958324a670ae" translate="yes" xml:space="preserve">
          <source>The returned tensor and &lt;code&gt;ndarray&lt;/code&gt; share the same memory. Modifications to the tensor will be reflected in the &lt;code&gt;ndarray&lt;/code&gt; and vice versa. The returned tensor is not resizable.</source>
          <target state="translated">返回的张量和 &lt;code&gt;ndarray&lt;/code&gt; 共享相同的内存。对张量的修改将反映在 &lt;code&gt;ndarray&lt;/code&gt; 中，反之亦然。返回的张量不可调整大小。</target>
        </trans-unit>
        <trans-unit id="93c4d85268a064ece907fbc8a5535a6f396d9a4e" translate="yes" xml:space="preserve">
          <source>The returned tensor does &lt;strong&gt;not&lt;/strong&gt; use the same storage as the original tensor</source>
          <target state="translated">返回的张量并&lt;strong&gt;没有&lt;/strong&gt;使用相同的存储与原张量</target>
        </trans-unit>
        <trans-unit id="52f5aa4074a60eef379e1658572f1bb6509ef7da" translate="yes" xml:space="preserve">
          <source>The returned tensor does &lt;strong&gt;not&lt;/strong&gt; use the same storage as the original tensor. If &lt;code&gt;out&lt;/code&gt; has a different shape than expected, we silently change it to the correct shape, reallocating the underlying storage if necessary.</source>
          <target state="translated">返回的张量并&lt;strong&gt;没有&lt;/strong&gt;使用相同的存储与原张量。如果 &lt;code&gt;out&lt;/code&gt; 的形状与预期的形状不同，我们将默默地将其更改为正确的形状，并在必要时重新分配基础存储。</target>
        </trans-unit>
        <trans-unit id="f46100c8ee7a830bab0c89e9873612006ce16b25" translate="yes" xml:space="preserve">
          <source>The returned tensor has the same number of dimensions as the original tensor (&lt;code&gt;input&lt;/code&gt;). The &lt;code&gt;dim&lt;/code&gt;th dimension has the same size as the length of &lt;code&gt;index&lt;/code&gt;; other dimensions have the same size as in the original tensor.</source>
          <target state="translated">返回的张量具有与原始张量（ &lt;code&gt;input&lt;/code&gt; ）相同的维数。在 &lt;code&gt;dim&lt;/code&gt; 第N维的尺寸与长度相同 &lt;code&gt;index&lt;/code&gt; ; 其他尺寸与原始张量中的尺寸相同。</target>
        </trans-unit>
        <trans-unit id="c72a07e12ac6ea766a45eac39941a4c32ee2a049" translate="yes" xml:space="preserve">
          <source>The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride, i.e., each new view dimension must either be a subspace of an original dimension, or only span across original dimensions</source>
          <target state="translated">返回的张量共享相同的数据,必须有相同数量的元素,但可能有不同的尺寸。为了使张量能够被查看,新的视图尺寸必须与它的原始尺寸和跨度兼容,也就是说,每个新的视图维度必须是一个原始维度的子空间,或者只跨越原始维度。</target>
        </trans-unit>
        <trans-unit id="e400aae54e1364ef7f0ae0e4394533a68ef83da8" translate="yes" xml:space="preserve">
          <source>The returned tensor shares the same underlying data with this tensor.</source>
          <target state="translated">返回的张量与这个张量共享相同的基础数据。</target>
        </trans-unit>
        <trans-unit id="172826726b64a692f9e7f61dbdcbf5a0b8b36f39" translate="yes" xml:space="preserve">
          <source>The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other.</source>
          <target state="translated">返回的张量与输入张量共享存储空间,因此改变其中一个的内容将改变另一个的内容。</target>
        </trans-unit>
        <trans-unit id="28c770021d54b212e8c62be1e09939a0369312ae" translate="yes" xml:space="preserve">
          <source>The rows of &lt;code&gt;input&lt;/code&gt; do not need to sum to one (in which case we use the values as weights), but must be non-negative, finite and have a non-zero sum.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 的行不必求和（在这种情况下，我们将这些值用作权重），但必须为非负数，有限且总和为非零。</target>
        </trans-unit>
        <trans-unit id="67ad32a77054c34abcbd23ca0d1823d1b895c487" translate="yes" xml:space="preserve">
          <source>The running minimum/maximum</source>
          <target state="translated">运行的最低/最高值</target>
        </trans-unit>
        <trans-unit id="a731d56c62ca577d4cbb49839358e51e33b8ca80" translate="yes" xml:space="preserve">
          <source>The sampling algorithm for the von Mises distribution is based on the following paper: Best, D. J., and Nicholas I. Fisher. &amp;ldquo;Efficient simulation of the von Mises distribution.&amp;rdquo; Applied Statistics (1979): 152-157.</source>
          <target state="translated">von Mises分布的采样算法基于以下论文：Best，DJ和Nicholas I. Fisher。&amp;ldquo;对冯&amp;middot;米塞斯分布的有效模拟。&amp;rdquo; 应用统计（1979）：152-157。</target>
        </trans-unit>
        <trans-unit id="4a088efcbb868e84088d5a0662d97d3ed3613744" translate="yes" xml:space="preserve">
          <source>The scale</source>
          <target state="translated">比例尺</target>
        </trans-unit>
        <trans-unit id="425de0e2446cb018a534e98b7c1b54edd4cbbc42" translate="yes" xml:space="preserve">
          <source>The scale and zero point are computed as follows:</source>
          <target state="translated">比例尺和零点的计算方法如下:</target>
        </trans-unit>
        <trans-unit id="0e92d877ce880170691af2f314602d7f6a781ea7" translate="yes" xml:space="preserve">
          <source>The scale and zero point are then computed as in &lt;code&gt;MinMaxObserver&lt;/code&gt;.</source>
          <target state="translated">然后像 &lt;code&gt;MinMaxObserver&lt;/code&gt; 一样计算比例和零点。</target>
        </trans-unit>
        <trans-unit id="9a5fb7f0444cbf25c6894566e5c0f368d5dfcf33" translate="yes" xml:space="preserve">
          <source>The search for the min/max values ensures the minimization of the quantization error with respect to the floating point model.</source>
          <target state="translated">对最小/最大值的搜索保证了量化误差相对于浮点模型的最小化。</target>
        </trans-unit>
        <trans-unit id="1eff8f651f1c1e81084414db9ad8e86ff7d386f5" translate="yes" xml:space="preserve">
          <source>The second argument can be a number or a tensor whose shape is &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with the first argument.</source>
          <target state="translated">第二个参数可以是数字或张量，其形状可与第一个参数一起&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8fc5e267a8ddd57a603f273d62b726d831286e07" translate="yes" xml:space="preserve">
          <source>The sections below describe in details the effects and usages of these options.</source>
          <target state="translated">下面的章节将详细介绍这些选项的效果和用途。</target>
        </trans-unit>
        <trans-unit id="35bad0572344e9ca340bcfea7b7e08eb1fb48094" translate="yes" xml:space="preserve">
          <source>The shape of the tensor is defined by the variable argument &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="translated">张量的形状由可变的参数 &lt;code&gt;size&lt;/code&gt; 定义。</target>
        </trans-unit>
        <trans-unit id="44ad26e34a9ec24516da93c641da630606e76045" translate="yes" xml:space="preserve">
          <source>The shapes of &lt;a href=&quot;torch.mean#torch.mean&quot;&gt;&lt;code&gt;mean&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.std#torch.std&quot;&gt;&lt;code&gt;std&lt;/code&gt;&lt;/a&gt; don&amp;rsquo;t need to match, but the total number of elements in each tensor need to be the same.</source>
          <target state="translated">&lt;a href=&quot;torch.mean#torch.mean&quot;&gt; &lt;code&gt;mean&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;torch.std#torch.std&quot;&gt; &lt;code&gt;std&lt;/code&gt; &lt;/a&gt;的形状不需要匹配，但是每个张量中元素的总数必须相同。</target>
        </trans-unit>
        <trans-unit id="7ab58315d98cc62bd1c43b5269219135f914a361" translate="yes" xml:space="preserve">
          <source>The shapes of &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;tensor1&lt;/code&gt;, and &lt;code&gt;tensor2&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">的形状&lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt;， &lt;code&gt;tensor1&lt;/code&gt; 和 &lt;code&gt;tensor2&lt;/code&gt; 必须&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="472d04a7b4ef19856846b867c2431ae86dfeee09" translate="yes" xml:space="preserve">
          <source>The shapes of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 和 &lt;code&gt;other&lt;/code&gt; 的形状必须是可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播的&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4bb8d54bf4e66fa1d51318971fbd84c5dd471f64" translate="yes" xml:space="preserve">
          <source>The shapes of &lt;code&gt;input&lt;/code&gt;, &lt;code&gt;tensor1&lt;/code&gt;, and &lt;code&gt;tensor2&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; ， &lt;code&gt;tensor1&lt;/code&gt; 和 &lt;code&gt;tensor2&lt;/code&gt; 的形状必须是可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播的&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3c2b5afb57ab65d651f6e8673ddc0bb16bc251d9" translate="yes" xml:space="preserve">
          <source>The shapes of &lt;code&gt;start&lt;/code&gt; and &lt;code&gt;end&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;. If &lt;code&gt;weight&lt;/code&gt; is a tensor, then the shapes of &lt;code&gt;weight&lt;/code&gt;, &lt;code&gt;start&lt;/code&gt;, and &lt;code&gt;end&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;start&lt;/code&gt; 和 &lt;code&gt;end&lt;/code&gt; 的形状必须是可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播的&lt;/a&gt;。如果 &lt;code&gt;weight&lt;/code&gt; 是张量，那么 &lt;code&gt;weight&lt;/code&gt; 的形状， &lt;code&gt;start&lt;/code&gt; 和 &lt;code&gt;end&lt;/code&gt; 必须是可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播的&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="30ae8ec04282dfa89f820e2638cc76a4c5308051" translate="yes" xml:space="preserve">
          <source>The shapes of the &lt;code&gt;mask&lt;/code&gt; tensor and the &lt;code&gt;input&lt;/code&gt; tensor don&amp;rsquo;t need to match, but they must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;mask&lt;/code&gt; 张量和 &lt;code&gt;input&lt;/code&gt; 张量的形状不需要匹配，但是它们必须是可&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播的&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="80ed96242b937c96d491a6608007e2c80ef6fbfe" translate="yes" xml:space="preserve">
          <source>The singular values are returned in descending order. If &lt;code&gt;input&lt;/code&gt; is a batch of matrices, then the singular values of each matrix in the batch is returned in descending order.</source>
          <target state="translated">奇异值以降序返回。如果 &lt;code&gt;input&lt;/code&gt; 是一批矩阵，则该批中每个矩阵的奇异值将按降序返回。</target>
        </trans-unit>
        <trans-unit id="86c71484bcb812cb0f2e7260fb264f82086dbacb" translate="yes" xml:space="preserve">
          <source>The size of the new matrix will be calculated to make the specified diagonal of the size of the last input dimension. Note that for &lt;code&gt;offset&lt;/code&gt; other than</source>
          <target state="translated">将计算新矩阵的大小，以使指定的对角线成为最后一个输入尺寸的大小。请注意，对于 &lt;code&gt;offset&lt;/code&gt; 比其他</target>
        </trans-unit>
        <trans-unit id="0739eb19e36226e98c11fd96e8291d8a209e3a7e" translate="yes" xml:space="preserve">
          <source>The smallest positive representable number.</source>
          <target state="translated">最小的正代表数。</target>
        </trans-unit>
        <trans-unit id="cf0617c3e175f01c2b40e71995108022f6b64f95" translate="yes" xml:space="preserve">
          <source>The smallest representable number (typically &lt;code&gt;-max&lt;/code&gt;).</source>
          <target state="translated">最小的可表示数字（通常为 &lt;code&gt;-max&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="27d91cd31d6556c601166e6b57bbeb8fc2cd13fe" translate="yes" xml:space="preserve">
          <source>The smallest representable number such that &lt;code&gt;1.0 + eps != 1.0&lt;/code&gt;.</source>
          <target state="translated">最小的可表示数字，例如 &lt;code&gt;1.0 + eps != 1.0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ff2ebfdbbf9420dca19c2e2c489305049c84e69e" translate="yes" xml:space="preserve">
          <source>The smallest representable number.</source>
          <target state="translated">最小的可代表数。</target>
        </trans-unit>
        <trans-unit id="6e4db462bf55509b809c59ea2298379ae2dba77f" translate="yes" xml:space="preserve">
          <source>The sources in &lt;code&gt;cuda_sources&lt;/code&gt; are concatenated into a separate &lt;code&gt;.cu&lt;/code&gt; file and prepended with &lt;code&gt;torch/types.h&lt;/code&gt;, &lt;code&gt;cuda.h&lt;/code&gt; and &lt;code&gt;cuda_runtime.h&lt;/code&gt; includes. The &lt;code&gt;.cpp&lt;/code&gt; and &lt;code&gt;.cu&lt;/code&gt; files are compiled separately, but ultimately linked into a single library. Note that no bindings are generated for functions in &lt;code&gt;cuda_sources&lt;/code&gt; per se. To bind to a CUDA kernel, you must create a C++ function that calls it, and either declare or define this C++ function in one of the &lt;code&gt;cpp_sources&lt;/code&gt; (and include its name in &lt;code&gt;functions&lt;/code&gt;).</source>
          <target state="translated">&lt;code&gt;cuda_sources&lt;/code&gt; 中的源被连接到一个单独的 &lt;code&gt;.cu&lt;/code&gt; 文件中，并以 &lt;code&gt;torch/types.h&lt;/code&gt; ， &lt;code&gt;cuda.h&lt;/code&gt; 和 &lt;code&gt;cuda_runtime.h&lt;/code&gt; include开头。的 &lt;code&gt;.cpp&lt;/code&gt; 和 &lt;code&gt;.cu&lt;/code&gt; 文件被单独编译，但最终链接到单个库中。请注意，在 &lt;code&gt;cuda_sources&lt;/code&gt; 本身中不会为函数生成任何绑定。要绑定到CUDA内核，您必须创建一个调用它的C ++函数，并在一个 &lt;code&gt;cpp_sources&lt;/code&gt; 中声明或定义此C ++函数（并在 &lt;code&gt;functions&lt;/code&gt; 包含其名称）。</target>
        </trans-unit>
        <trans-unit id="f06fdc0c2350c66f3a9d82727c760926c8016f15" translate="yes" xml:space="preserve">
          <source>The stashing logic saves and restores the RNG state for the current device and the device of all cuda Tensor arguments to the &lt;code&gt;run_fn&lt;/code&gt;. However, the logic has no way to anticipate if the user will move Tensors to a new device within the &lt;code&gt;run_fn&lt;/code&gt; itself. Therefore, if you move Tensors to a new device (&amp;ldquo;new&amp;rdquo; meaning not belonging to the set of [current device + devices of Tensor arguments]) within &lt;code&gt;run_fn&lt;/code&gt;, deterministic output compared to non-checkpointed passes is never guaranteed.</source>
          <target state="translated">隐藏逻辑将当前设备以及所有cuda Tensor参数的设备的RNG状态保存并恢复到 &lt;code&gt;run_fn&lt;/code&gt; 。但是，该逻辑无法预测用户是否会在 &lt;code&gt;run_fn&lt;/code&gt; 自身内部将张量移动到新设备。因此，如果在 &lt;code&gt;run_fn&lt;/code&gt; 中将Tensors移至新设备（&amp;ldquo; new&amp;rdquo;表示不属于[当前设备+ Tensor参数的设备的集合]的集合），则与非检查点传递相比，确定性输出将永远无法得到保证。</target>
        </trans-unit>
        <trans-unit id="b7f3ab8a2df042d6e3025c18a145e6e14f77af25" translate="yes" xml:space="preserve">
          <source>The sum operation still operates over all the elements, and divides by</source>
          <target state="translated">求和运算仍在所有元素上进行,并除以</target>
        </trans-unit>
        <trans-unit id="b2531e155fe9e77a5cfae31abf7b6f59ffb9fcaa" translate="yes" xml:space="preserve">
          <source>The support of third-party backend is experimental and subject to change.</source>
          <target state="translated">第三方后台的支持是试验性的,可能会有变化。</target>
        </trans-unit>
        <trans-unit id="2873a12c84aba239b7842369e12bb64236d9f288" translate="yes" xml:space="preserve">
          <source>The tensor will share the memory with the object represented in the dlpack. Note that each dlpack can only be consumed once.</source>
          <target state="translated">张量将与dlpack中表示的对象共享内存。注意每个dlpack只能使用一次。</target>
        </trans-unit>
        <trans-unit id="dc114e497003f25e6fca05f82fcba607f7d78078" translate="yes" xml:space="preserve">
          <source>The tensors &lt;code&gt;condition&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;.</source>
          <target state="translated">张量 &lt;code&gt;condition&lt;/code&gt; ， &lt;code&gt;x&lt;/code&gt; ， &lt;code&gt;y&lt;/code&gt; 必须&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ab7ff2ed427b3e162ddc9c1bc3618ade11c4bc8e" translate="yes" xml:space="preserve">
          <source>The torch package contains data structures for multi-dimensional tensors and mathematical operations over these are defined. Additionally, it provides many utilities for efficient serializing of Tensors and arbitrary types, and other useful utilities.</source>
          <target state="translated">torch包包含了多维Tensors的数据结构,并定义了对这些数据的数学运算。此外,它还提供了许多实用工具,用于有效地序列化Tensors和任意类型,以及其他有用的实用工具。</target>
        </trans-unit>
        <trans-unit id="437652102ffae6443117ed89a3eae4a8f5b41da3" translate="yes" xml:space="preserve">
          <source>The tracer produces warnings for several problematic patterns in traced computation. As an example, take a trace of a function that contains an in-place assignment on a slice (a view) of a Tensor:</source>
          <target state="translated">追踪器会对追踪计算中的一些问题模式发出警告。举个例子,以一个函数的跟踪为例,这个函数包含了一个在Tensor的片(视图)上的原位赋值。</target>
        </trans-unit>
        <trans-unit id="89850de90f112bfc18c8cdc61311b3872ebf2872" translate="yes" xml:space="preserve">
          <source>The tracer records the example inputs shape in the graph. In case the model should accept inputs of dynamic shape, you can utilize the parameter &lt;code&gt;dynamic_axes&lt;/code&gt; in export api.</source>
          <target state="translated">跟踪器将示例输入形状记录在图形中。如果模型应接受动态形状的输入，则可以在导出api中使用参数 &lt;code&gt;dynamic_axes&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="da3842947e505833ecf56e0071c7d1669aedc528" translate="yes" xml:space="preserve">
          <source>The underlying CUDA events are lazily initialized when the event is first recorded or exported to another process. After creation, only streams on the same device may record the event. However, streams on any device can wait on the event.</source>
          <target state="translated">当事件首次被记录或导出到另一个进程时,底层的CUDA事件被懒惰初始化。创建后,只有同一设备上的流可以记录该事件。但是,任何设备上的流都可以对事件进行等待。</target>
        </trans-unit>
        <trans-unit id="f2328cc72d77d5be4ac31362bf776708e1354f25" translate="yes" xml:space="preserve">
          <source>The unreduced (i.e. with &lt;code&gt;reduction&lt;/code&gt; set to &lt;code&gt;'none'&lt;/code&gt;) loss can be described as:</source>
          <target state="translated">未减少（即 &lt;code&gt;reduction&lt;/code&gt; 设置为 &lt;code&gt;'none'&lt;/code&gt; ）的损失可描述为：</target>
        </trans-unit>
        <trans-unit id="83a2adc9d7ff925b785017e994bf1c2dfff219e3" translate="yes" xml:space="preserve">
          <source>The unreduced loss (i.e., with &lt;code&gt;reduction&lt;/code&gt; set to &lt;code&gt;'none'&lt;/code&gt;) can be described as:</source>
          <target state="translated">未减少的损失（即 &lt;code&gt;reduction&lt;/code&gt; 设置为 &lt;code&gt;'none'&lt;/code&gt; ）可以描述为：</target>
        </trans-unit>
        <trans-unit id="55b435ee6855f1f093ca66cf72abe8bd2c30eb03" translate="yes" xml:space="preserve">
          <source>The upper triangular part of the matrix is defined as the elements on and above the diagonal.</source>
          <target state="translated">矩阵的上三角部分被定义为对角线上和上面的元素。</target>
        </trans-unit>
        <trans-unit id="04027d302afa8c6fa85d808794bef7b659457976" translate="yes" xml:space="preserve">
          <source>The use of &lt;code&gt;collate_fn&lt;/code&gt; is slightly different when automatic batching is enabled or disabled.</source>
          <target state="translated">启用或禁用自动批处理时， &lt;code&gt;collate_fn&lt;/code&gt; 的使用略有不同。</target>
        </trans-unit>
        <trans-unit id="8ff79d6204f8beff86c1883967aad41f978dae9c" translate="yes" xml:space="preserve">
          <source>The utility can be used for single-node distributed training, in which one or more processes per node will be spawned. The utility can be used for either CPU training or GPU training. If the utility is used for GPU training, each distributed process will be operating on a single GPU. This can achieve well-improved single-node training performance. It can also be used in multi-node distributed training, by spawning up multiple processes on each node for well-improved multi-node distributed training performance as well. This will especially be benefitial for systems with multiple Infiniband interfaces that have direct-GPU support, since all of them can be utilized for aggregated communication bandwidth.</source>
          <target state="translated">该实用程序可用于单节点分布式训练,其中每个节点将生成一个或多个进程。该实用程序可用于 CPU 训练或 GPU 训练。如果该实用程序用于 GPU 训练,则每个分布式进程将在单个 GPU 上运行。这可以实现很好地改善单节点训练性能。它也可以用于多节点分布式训练,通过在每个节点上生成多个进程来达到良好的多节点分布式训练性能。这对于有多个直接支持GPU的Infiniband接口的系统尤其有利,因为所有的接口都可以被用于聚合通信带宽。</target>
        </trans-unit>
        <trans-unit id="a8baea02cc4125823d2a9295d67b336747f5d060" translate="yes" xml:space="preserve">
          <source>The value held by this &lt;code&gt;Future&lt;/code&gt;. If the function (callback or RPC) creating the value has thrown an error, this &lt;code&gt;wait&lt;/code&gt; method will also throw an error.</source>
          <target state="translated">此 &lt;code&gt;Future&lt;/code&gt; 持有的价值。如果创建值的函数（回调或RPC）引发了错误，则此 &lt;code&gt;wait&lt;/code&gt; 方法也将引发错误。</target>
        </trans-unit>
        <trans-unit id="4c32d99e8bca557bc1750470ea69ae3bfb345050" translate="yes" xml:space="preserve">
          <source>The values of this class are lowercase strings, e.g., &lt;code&gt;&quot;gloo&quot;&lt;/code&gt;. They can be accessed as attributes, e.g., &lt;code&gt;Backend.NCCL&lt;/code&gt;.</source>
          <target state="translated">此类的值是小写字符串，例如 &lt;code&gt;&quot;gloo&quot;&lt;/code&gt; 。可以将它们作为属性访问，例如 &lt;code&gt;Backend.NCCL&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2d09c2230d5453858141229e7b0087efe234f737" translate="yes" xml:space="preserve">
          <source>The values of this class can be accessed as attributes, e.g., &lt;code&gt;ReduceOp.SUM&lt;/code&gt;. They are used in specifying strategies for reduction collectives, e.g., &lt;a href=&quot;#torch.distributed.reduce&quot;&gt;&lt;code&gt;reduce()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributed.all_reduce_multigpu&quot;&gt;&lt;code&gt;all_reduce_multigpu()&lt;/code&gt;&lt;/a&gt;, etc.</source>
          <target state="translated">此类的值可以作为属性访问，例如 &lt;code&gt;ReduceOp.SUM&lt;/code&gt; 。它们用于指定减少集合体的策略，例如&lt;a href=&quot;#torch.distributed.reduce&quot;&gt; &lt;code&gt;reduce()&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;#torch.distributed.all_reduce_multigpu&quot;&gt; &lt;code&gt;all_reduce_multigpu()&lt;/code&gt; &lt;/a&gt;等。</target>
        </trans-unit>
        <trans-unit id="539dcafbce59fbba03d94008a7b26e37638c0f1b" translate="yes" xml:space="preserve">
          <source>The world size of the process group -1, if not part of the group</source>
          <target state="translated">进程组的世界大小-1,如果不属于该组的话。</target>
        </trans-unit>
        <trans-unit id="a5d66dffec3f1eab9a22e5606deb2eaebb37f157" translate="yes" xml:space="preserve">
          <source>Then &lt;code&gt;dynamic axes&lt;/code&gt; can be defined either as:</source>
          <target state="translated">然后，可以将 &lt;code&gt;dynamic axes&lt;/code&gt; 定义为：</target>
        </trans-unit>
        <trans-unit id="cacf045e7460da89c00e2f44ce242ff34d557d4d" translate="yes" xml:space="preserve">
          <source>Then for any (supported) &lt;code&gt;input&lt;/code&gt; tensor the following equality holds:</source>
          <target state="translated">然后对于任何（受支持的） &lt;code&gt;input&lt;/code&gt; 张量，以下等式成立：</target>
        </trans-unit>
        <trans-unit id="61c6ce8b4e502ae0f9cf574180a84ce71379a45a" translate="yes" xml:space="preserve">
          <source>Then run the following code in two different processes:</source>
          <target state="translated">然后在两个不同的进程中运行以下代码。</target>
        </trans-unit>
        <trans-unit id="1ce92152c376045e006c7df7e500a93b25016945" translate="yes" xml:space="preserve">
          <source>Then, you can run:</source>
          <target state="translated">然后,你可以跑。</target>
        </trans-unit>
        <trans-unit id="9157fc1a5d0f6b3459cf4d13b451acd4e1ae988a" translate="yes" xml:space="preserve">
          <source>There are 2 main ways to initialize a process group:</source>
          <target state="translated">有2种主要的方式来初始化一个过程组。</target>
        </trans-unit>
        <trans-unit id="989aa62e15f82179c46dd7bca86e4177e7b7bf45" translate="yes" xml:space="preserve">
          <source>There are a few main ways to create a tensor, depending on your use case.</source>
          <target state="translated">根据你的用例,有几种主要的方法来创建张量。</target>
        </trans-unit>
        <trans-unit id="448eaecf17e019efecc19b1280b7ffb9043292f0" translate="yes" xml:space="preserve">
          <source>There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation:</source>
          <target state="translated">Tensors上还定义了一些就地随机抽样函数。点击查看它们的文档。</target>
        </trans-unit>
        <trans-unit id="4a50a4f02b41f0e4e7768bdf9e0d8e8e8f9ca103" translate="yes" xml:space="preserve">
          <source>There are known non-determinism issues for RNN functions on some versions of cuDNN and CUDA. You can enforce deterministic behavior by setting the following environment variables:</source>
          <target state="translated">在某些版本的 cuDNN 和 CUDA 上,RNN 函数存在已知的非确定性问题。您可以通过设置以下环境变量来强制执行确定性行为。</target>
        </trans-unit>
        <trans-unit id="94f93e5cb61707d9a9f9f8c1e8bae87549a0661b" translate="yes" xml:space="preserve">
          <source>There are more examples in &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic_opset9.py&quot;&gt;symbolic_opset9.py&lt;/a&gt;, &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic_opset10.py&quot;&gt;symbolic_opset10.py&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic_opset9.py&quot;&gt;symbolic_opset9.py&lt;/a&gt;和&lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic_opset10.py&quot;&gt;symbolic_opset10.py中&lt;/a&gt;还有更多示例。</target>
        </trans-unit>
        <trans-unit id="e7b2c38d0b8818a513a12fc7c7e90b9479638b6e" translate="yes" xml:space="preserve">
          <source>There are some edge cases that exist where the trace of a given Python function/module will not be representative of the underlying code. These cases can include:</source>
          <target state="translated">在一些边缘情况下,给定的 Python 函数/模块的跟踪不能代表底层代码。这些情况包括:</target>
        </trans-unit>
        <trans-unit id="7b0666c05baae6bc9dd7801107606ece55efb258" translate="yes" xml:space="preserve">
          <source>There are two main usages:</source>
          <target state="translated">主要有两种用法。</target>
        </trans-unit>
        <trans-unit id="7b78c278fc5d3de5d25f299a98858079b45aa6eb" translate="yes" xml:space="preserve">
          <source>There are two ways to initialize using TCP, both requiring a network address reachable from all processes and a desired &lt;code&gt;world_size&lt;/code&gt;. The first way requires specifying an address that belongs to the rank 0 process. This initialization method requires that all processes have manually specified ranks.</source>
          <target state="translated">有两种使用TCP进行初始化的方式，两种方式都需要所有进程都可以访问的网络地址以及所需的 &lt;code&gt;world_size&lt;/code&gt; 。第一种方法要求指定一个地址，该地址属于等级0进程。此初始化方法要求所有进程都具有手动指定的等级。</target>
        </trans-unit>
        <trans-unit id="f2b97adc02fc81457ca80fb753c694becd93e274" translate="yes" xml:space="preserve">
          <source>There is a subtlety in using the &lt;code&gt;pack sequence -&amp;gt; recurrent network -&amp;gt; unpack sequence&lt;/code&gt; pattern in a &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; wrapped in &lt;a href=&quot;#torch.nn.DataParallel&quot;&gt;&lt;code&gt;DataParallel&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/faq.html#pack-rnn-unpack-with-data-parallelism&quot;&gt;My recurrent network doesn&amp;rsquo;t work with data parallelism&lt;/a&gt; section in FAQ for details.</source>
          <target state="translated">在&lt;a href=&quot;#torch.nn.DataParallel&quot;&gt; &lt;code&gt;DataParallel&lt;/code&gt; 中&lt;/a&gt;包装的&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;中使用 &lt;code&gt;pack sequence -&amp;gt; recurrent network -&amp;gt; unpack sequence&lt;/code&gt; 打包序列模式有一个微妙之处。有关详细信息，请参见常见问题解答中的&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/faq.html#pack-rnn-unpack-with-data-parallelism&quot;&gt;我的循环网络不适用于数据并行性&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="6bedff7a4f5803a09c69737d429b263e4a4e07c0" translate="yes" xml:space="preserve">
          <source>Therefore, indexing &lt;code&gt;output&lt;/code&gt; at the last dimension (column dimension) gives all values within a certain block.</source>
          <target state="translated">因此，在最后一个维度（列维度）的索引 &lt;code&gt;output&lt;/code&gt; 将给出特定块内的所有值。</target>
        </trans-unit>
        <trans-unit id="220cff043cb62e0e4cb5366907ebd80ead3bf366" translate="yes" xml:space="preserve">
          <source>Therefore, to invert an &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;normalized&lt;/code&gt; and &lt;code&gt;onesided&lt;/code&gt; arguments should be set identically for &lt;a href=&quot;#torch.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;, and preferably a &lt;code&gt;signal_sizes&lt;/code&gt; is given to avoid size mismatch. See the example below for a case of size mismatch.</source>
          <target state="translated">因此，反转的&lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt;中， &lt;code&gt;normalized&lt;/code&gt; 和 &lt;code&gt;onesided&lt;/code&gt; 参数应该被相同地设定为&lt;a href=&quot;#torch.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;，并且优选 &lt;code&gt;signal_sizes&lt;/code&gt; 给出避免大小不匹配。有关大小不匹配的情况，请参见下面的示例。</target>
        </trans-unit>
        <trans-unit id="11de0478b61c8d1fd83658744b437989c835c987" translate="yes" xml:space="preserve">
          <source>These are the basic building block for graphs</source>
          <target state="translated">这些是图形的基本构件</target>
        </trans-unit>
        <trans-unit id="8ca4969bd4e4273b5349ab2f675d16c1de44f187" translate="yes" xml:space="preserve">
          <source>These backends include:</source>
          <target state="translated">这些后端包括:</target>
        </trans-unit>
        <trans-unit id="e0e365abd4e5be3113ea52d047c2f616e603945c" translate="yes" xml:space="preserve">
          <source>These ops don&amp;rsquo;t require a particular dtype for stability, but take multiple inputs and require that the inputs&amp;rsquo; dtypes match. If all of the inputs are &lt;code&gt;float16&lt;/code&gt;, the op runs in &lt;code&gt;float16&lt;/code&gt;. If any of the inputs is &lt;code&gt;float32&lt;/code&gt;, autocast casts all inputs to &lt;code&gt;float32&lt;/code&gt; and runs the op in &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">这些操作不需要特定的dtype来保持稳定性，但是需要多个输入并要求输入的dtypes匹配。如果所有输入均为 &lt;code&gt;float16&lt;/code&gt; ，则运算 &lt;code&gt;float16&lt;/code&gt; 将在float16中运行。如果任何输入为 &lt;code&gt;float32&lt;/code&gt; ，则自动广播将所有输入转换为 &lt;code&gt;float32&lt;/code&gt; 并在 &lt;code&gt;float32&lt;/code&gt; 中运行op 。</target>
        </trans-unit>
        <trans-unit id="150d61b0973e4711130a967de9e4414841dbc8c3" translate="yes" xml:space="preserve">
          <source>These options are configured by the constructor arguments of a &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt;, which has signature:</source>
          <target state="translated">这些选项由具有签名的&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;的构造函数参数配置：</target>
        </trans-unit>
        <trans-unit id="3dd026a9fc19a074410394c15ee56c930e5686d0" translate="yes" xml:space="preserve">
          <source>These types and features from the &lt;a href=&quot;https://docs.python.org/3/library/typing.html#module-typing&quot;&gt;&lt;code&gt;typing&lt;/code&gt;&lt;/a&gt; module are unavailble in TorchScript.</source>
          <target state="translated">&lt;a href=&quot;https://docs.python.org/3/library/typing.html#module-typing&quot;&gt; &lt;code&gt;typing&lt;/code&gt; &lt;/a&gt;模块中的这些类型和功能在TorchScript中不可用。</target>
        </trans-unit>
        <trans-unit id="aca9bd729c973c4d3bc4eb7f3f8d4e953c82edfd" translate="yes" xml:space="preserve">
          <source>These unroll the loop, generating a body for each member of the tuple. The body must type-check correctly for each member.</source>
          <target state="translated">这些展开循环,为元组的每个成员生成一个主体。该主体必须对每个成员进行正确的类型检查。</target>
        </trans-unit>
        <trans-unit id="5042b3fea81612a742984a1fb55be5b675720283" translate="yes" xml:space="preserve">
          <source>Third-party backends</source>
          <target state="translated">第三方后端</target>
        </trans-unit>
        <trans-unit id="f9ab4d0d07c5bfd671637ba9723d67603253bcae" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;momentum&lt;/code&gt; argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is</source>
          <target state="translated">该 &lt;code&gt;momentum&lt;/code&gt; 参数不同于优化程序类中使用的动量参数和传统的动量概念。从数学上讲，此处用于运行统计信息的更新规则是</target>
        </trans-unit>
        <trans-unit id="4d057f12e63c19fa40f83b9e371a09dbaf3641ca" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;setuptools.build_ext&lt;/code&gt; subclass takes care of passing the minimum required compiler flags (e.g. &lt;code&gt;-std=c++14&lt;/code&gt;) as well as mixed C++/CUDA compilation (and support for CUDA files in general).</source>
          <target state="translated">该 &lt;code&gt;setuptools.build_ext&lt;/code&gt; 子类负责传递所需的最低编译器标志（例如 &lt;code&gt;-std=c++14&lt;/code&gt; ）以及混合的C ++ / CUDA编译（并总体上支持CUDA文件）。</target>
        </trans-unit>
        <trans-unit id="48b0bfc66718d9ed75062a9f5d57a687fd7749c9" translate="yes" xml:space="preserve">
          <source>This API is in beta and may change in the near future.</source>
          <target state="translated">该API处于测试阶段,在不久的将来可能会改变。</target>
        </trans-unit>
        <trans-unit id="53d04b24e9fbd24d72acb9f431a964889b4c7cf6" translate="yes" xml:space="preserve">
          <source>This API is in beta. Even though the function signatures are very unlikely to change, major improvements to performances are planned before we consider this stable.</source>
          <target state="translated">这个API还处于测试阶段。尽管函数签名不太可能改变,但在我们考虑稳定之前,我们计划对性能进行重大改进。</target>
        </trans-unit>
        <trans-unit id="c994160251b3f47ef8b0dd185e96a7b1ad0ee446" translate="yes" xml:space="preserve">
          <source>This API works with user-provided functions that take only Tensors as input and return only Tensors. If your function takes other arguments that are not Tensors or Tensors that don&amp;rsquo;t have requires_grad set, you can use a lambda to capture them. For example, for a function &lt;code&gt;f&lt;/code&gt; that takes three inputs, a Tensor for which we want the jacobian, another tensor that should be considered constant and a boolean flag as &lt;code&gt;f(input, constant, flag=flag)&lt;/code&gt; you can use it as &lt;code&gt;functional.jacobian(lambda x: f(x, constant, flag=flag), input)&lt;/code&gt;.</source>
          <target state="translated">此API与用户提供的函数一起使用，这些函数仅将Tensors作为输入，仅返回Tensors。如果您的函数采用其他参数而不是Tensors或未设置require_grad的Tensors，则可以使用Lambda捕获它们。例如，对于一个具有三个输入的函数 &lt;code&gt;f&lt;/code&gt; ，一个我们想要其jacobian的张量，另一个应该被认为是常数的张量，以及一个作为 &lt;code&gt;f(input, constant, flag=flag)&lt;/code&gt; 的布尔标志，您可以将其用作 &lt;code&gt;functional.jacobian(lambda x: f(x, constant, flag=flag), input)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="33a32d5fcbf1c45d06b8358ae2591cd5047cff16" translate="yes" xml:space="preserve">
          <source>This allows better BC support for &lt;a href=&quot;#torch.nn.Module.load_state_dict&quot;&gt;&lt;code&gt;load_state_dict()&lt;/code&gt;&lt;/a&gt;. In &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt;, the version number will be saved as in the attribute &lt;code&gt;_metadata&lt;/code&gt; of the returned state dict, and thus pickled. &lt;code&gt;_metadata&lt;/code&gt; is a dictionary with keys that follow the naming convention of state dict. See &lt;code&gt;_load_from_state_dict&lt;/code&gt; on how to use this information in loading.</source>
          <target state="translated">这样可以更好地支持BC对&lt;a href=&quot;#torch.nn.Module.load_state_dict&quot;&gt; &lt;code&gt;load_state_dict()&lt;/code&gt; 的&lt;/a&gt;支持。在&lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; 中&lt;/a&gt;，版本号将被保存为返回状态dict的属性 &lt;code&gt;_metadata&lt;/code&gt; 中，并因此被腌制。 &lt;code&gt;_metadata&lt;/code&gt; 是一个字典，其中的键遵循状态dict的命名约定。有关如何在加载中使用此信息的信息，请参见 &lt;code&gt;_load_from_state_dict&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="09b607c5ebd52b97aa3c6cf95a474cc71af1ac47" translate="yes" xml:space="preserve">
          <source>This allows for different samples to have variable amounts of target classes.</source>
          <target state="translated">这使得不同的样本可以有不同数量的目标类。</target>
        </trans-unit>
        <trans-unit id="dc869bc2254cbb18e88bb0a8c7e186c575d69c2e" translate="yes" xml:space="preserve">
          <source>This also makes associated parameters and buffers different objects. So it should be called before constructing optimizer if the module will live on GPU while being optimized.</source>
          <target state="translated">这也使得相关的参数和缓冲器成为不同的对象。因此,如果模块在优化时将会在GPU上生存,那么应该在构建优化器之前调用它。</target>
        </trans-unit>
        <trans-unit id="cd79f292616deed21e20e4449558742671a5f03e" translate="yes" xml:space="preserve">
          <source>This argument enables export of large models to ONNX. Models larger than 2GB cannot be exported in one file because of the protobuf size limit. Users should set &lt;code&gt;use_external_data_format&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt; to successfully export such models.</source>
          <target state="translated">此参数可将大型模型导出到ONNX。由于protobuf大小限制，无法将大于2GB的模型导出到一个文件中。用户应将 &lt;code&gt;use_external_data_format&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 才能成功导出此类模型。</target>
        </trans-unit>
        <trans-unit id="37b077e70d126ef1c4f52c0e784fa4698cbe6a7d" translate="yes" xml:space="preserve">
          <source>This attribute is &lt;code&gt;None&lt;/code&gt; by default and becomes a Tensor the first time a call to &lt;a href=&quot;#torch.Tensor.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt; computes gradients for &lt;code&gt;self&lt;/code&gt;. The attribute will then contain the gradients computed and future calls to &lt;a href=&quot;#torch.Tensor.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt; will accumulate (add) gradients into it.</source>
          <target state="translated">默认情况下，此属性为 &lt;code&gt;None&lt;/code&gt; ，并且在第一次调用&lt;a href=&quot;#torch.Tensor.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; &lt;/a&gt;计算 &lt;code&gt;self&lt;/code&gt; 的梯度时，该属性将成为Tensor 。然后，该属性将包含计算出的渐变，将来对&lt;a href=&quot;#torch.Tensor.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; 的&lt;/a&gt;调用将向其中累积（添加）渐变。</target>
        </trans-unit>
        <trans-unit id="d9aed446ae3aa4dc28d8d65d1c929ff54cb2a74f" translate="yes" xml:space="preserve">
          <source>This attribute is &lt;code&gt;None&lt;/code&gt; by default and becomes a Tensor the first time a call to &lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt; computes gradients for &lt;code&gt;self&lt;/code&gt;. The attribute will then contain the gradients computed and future calls to &lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt; will accumulate (add) gradients into it.</source>
          <target state="translated">默认情况下，此属性为 &lt;code&gt;None&lt;/code&gt; ，并且在第一次调用&lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; &lt;/a&gt;计算 &lt;code&gt;self&lt;/code&gt; 的梯度时，该属性将成为Tensor 。然后，该属性将包含计算出的渐变，将来对&lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; 的&lt;/a&gt;调用将向其中累积（添加）渐变。</target>
        </trans-unit>
        <trans-unit id="27eaef81d3fd1f9e704b27f64a092d8671cfb020" translate="yes" xml:space="preserve">
          <source>This can be called as</source>
          <target state="translated">这可以被称为</target>
        </trans-unit>
        <trans-unit id="90fa23d66ed39d5f59f1b4a16b52b28d18188c72" translate="yes" xml:space="preserve">
          <source>This can be useful to display periodically during training, or when handling out-of-memory exceptions.</source>
          <target state="translated">这对于在训练期间定期显示,或者在处理内存外的异常时很有用。</target>
        </trans-unit>
        <trans-unit id="0c207d7ed4d817a917f51b1a12e087c64e12c094" translate="yes" xml:space="preserve">
          <source>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the &lt;a href=&quot;#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer&lt;/code&gt;&lt;/a&gt; as training progresses.</source>
          <target state="translated">当对预训练的网络进行微调时，这很有用，因为可以使冻结的层成为可训练的，并随着训练的进行将其添加到&lt;a href=&quot;#torch.optim.Optimizer&quot;&gt; &lt;code&gt;Optimizer&lt;/code&gt; &lt;/a&gt;中。</target>
        </trans-unit>
        <trans-unit id="36c9a312367d269d922b679dae091acec9f12a5e" translate="yes" xml:space="preserve">
          <source>This can be useful when there is a need to create classes with the same constructor arguments, but different instances.</source>
          <target state="translated">当需要创建具有相同构造函数参数但不同实例的类时,这很有用。</target>
        </trans-unit>
        <trans-unit id="e5eeeb2d9e42f39a239e76c72a9314e3136e5540" translate="yes" xml:space="preserve">
          <source>This can then be visualized with TensorBoard, which should be installable and runnable with:</source>
          <target state="translated">然后可以用TensorBoard将其可视化,TensorBoard应该是可以安装和运行的。</target>
        </trans-unit>
        <trans-unit id="2306bf42c44895d1fc76396938e439c137c2dffb" translate="yes" xml:space="preserve">
          <source>This class can be directly called to parse the string, e.g., &lt;code&gt;Backend(backend_str)&lt;/code&gt; will check if &lt;code&gt;backend_str&lt;/code&gt; is valid, and return the parsed lowercase string if so. It also accepts uppercase strings, e.g., &lt;code&gt;Backend(&quot;GLOO&quot;)&lt;/code&gt; returns &lt;code&gt;&quot;gloo&quot;&lt;/code&gt;.</source>
          <target state="translated">可以直接调用此类来解析字符串，例如， &lt;code&gt;Backend(backend_str)&lt;/code&gt; 将检查 &lt;code&gt;backend_str&lt;/code&gt; 是否有效，如果有效，则返回解析后的小写字符串。它还接受大写字符串，例如 &lt;code&gt;Backend(&quot;GLOO&quot;)&lt;/code&gt; 返回 &lt;code&gt;&quot;gloo&quot;&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5ef03a595a40d9415bbad765363aad2d964d5b16" translate="yes" xml:space="preserve">
          <source>This class does not provide a &lt;code&gt;forward&lt;/code&gt; hook. Instead, you must use one of the underlying functions (e.g. &lt;code&gt;add&lt;/code&gt;).</source>
          <target state="translated">此类不提供 &lt;code&gt;forward&lt;/code&gt; 挂钩。相反，您必须使用基础功能之一（例如 &lt;code&gt;add&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="c851561f849ef1eb6b901d2edf564052e34c6c02" translate="yes" xml:space="preserve">
          <source>This class has three built-in policies, as put forth in the paper:</source>
          <target state="translated">这个类有三个内置的政策,正如本文所提出的。</target>
        </trans-unit>
        <trans-unit id="3ddd34a2492252eba3a31d1accbd978513965aba" translate="yes" xml:space="preserve">
          <source>This class is an intermediary between the &lt;code&gt;Distribution&lt;/code&gt; class and distributions which belong to an exponential family mainly to check the correctness of the &lt;code&gt;.entropy()&lt;/code&gt; and analytic KL divergence methods. We use this class to compute the entropy and KL divergence using the AD framework and Bregman divergences (courtesy of: Frank Nielsen and Richard Nock, Entropies and Cross-entropies of Exponential Families).</source>
          <target state="translated">此类是 &lt;code&gt;Distribution&lt;/code&gt; 类别和属于指数族的分布之间的中介，主要用于检查 &lt;code&gt;.entropy()&lt;/code&gt; 和解析KL散度方法的正确性。我们使用此类使用AD框架和Bregman发散来计算熵和KL发散（由Frank Nielsen和Richard Nock提供，指数族的熵和交叉熵）。</target>
        </trans-unit>
        <trans-unit id="dc115d83b6af36150f881200c064c4d238e34462" translate="yes" xml:space="preserve">
          <source>This class is deprecated in favor of &lt;code&gt;interpolate()&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此类，而推荐使用 &lt;code&gt;interpolate()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c13ac423de7a3c762fee4c3a9510054ffdd5d384" translate="yes" xml:space="preserve">
          <source>This class is deprecated in favor of &lt;code&gt;interpolate()&lt;/code&gt;. It is equivalent to &lt;code&gt;nn.functional.interpolate(..., mode='bilinear', align_corners=True)&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此类，而推荐使用 &lt;code&gt;interpolate()&lt;/code&gt; 。它等效于 &lt;code&gt;nn.functional.interpolate(..., mode='bilinear', align_corners=True)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d90500fc17196cb70e7a700371ed43a1a87eeb32" translate="yes" xml:space="preserve">
          <source>This class is useful to assemble different existing dataset streams. The chainning operation is done on-the-fly, so concatenating large-scale datasets with this class will be efficient.</source>
          <target state="translated">这个类对于组装不同的现有数据集流很有用。链式操作是即时完成的,所以用这个类来连接大规模的数据集会很有效率。</target>
        </trans-unit>
        <trans-unit id="af734602c7eaf1931d607624127baafea2243648" translate="yes" xml:space="preserve">
          <source>This class is useful to assemble different existing datasets.</source>
          <target state="translated">这个类对组合不同的现有数据集很有用。</target>
        </trans-unit>
        <trans-unit id="f63c41dd97936df60be517dad06b50e25bfe14d0" translate="yes" xml:space="preserve">
          <source>This class uses &lt;a href=&quot;#torch.distributed.autograd.get_gradients&quot;&gt;&lt;code&gt;get_gradients()&lt;/code&gt;&lt;/a&gt; in order to retrieve the gradients for specific parameters.</source>
          <target state="translated">此类使用&lt;a href=&quot;#torch.distributed.autograd.get_gradients&quot;&gt; &lt;code&gt;get_gradients()&lt;/code&gt; &lt;/a&gt;来检索特定参数的梯度。</target>
        </trans-unit>
        <trans-unit id="1862d470ef8a5cd214866c60dc3b2e18ed9571b7" translate="yes" xml:space="preserve">
          <source>This collective blocks processes until the whole group enters this function, if async_op is False, or if async work handle is called on wait().</source>
          <target state="translated">如果async_op为False,或者在wait()上调用了async工作句柄,这个集体就会阻塞进程,直到整个组进入这个函数。</target>
        </trans-unit>
        <trans-unit id="43ff3e72065cb78dedbfc0cb5795ef6d313a86b8" translate="yes" xml:space="preserve">
          <source>This composition also works for &lt;code&gt;nn.Module&lt;/code&gt;s as well, where it can be used to generate a submodule using tracing that can be called from the methods of a script module.</source>
          <target state="translated">该组合也适用于 &lt;code&gt;nn.Module&lt;/code&gt; ，在这里它可以用于通过跟踪来生成子模块，该跟踪可以从脚本模块的方法中调用。</target>
        </trans-unit>
        <trans-unit id="d56b8d3c3a6cd08249ac0400c9bd4fa666010028" translate="yes" xml:space="preserve">
          <source>This container parallelizes the application of the given &lt;code&gt;module&lt;/code&gt; by splitting the input across the specified devices by chunking in the batch dimension (other objects will be copied once per device). In the forward pass, the module is replicated on each device, and each replica handles a portion of the input. During the backwards pass, gradients from each replica are summed into the original module.</source>
          <target state="translated">该容器通过按批处理维度分块在指定设备上划分输入来并行化给定 &lt;code&gt;module&lt;/code&gt; 的应用程序（其他对象将每个设备复制一次）。在前向传递中，模块在每个设备上复制，每个副本处理一部分输入。在向后传递过程中，每个副本的梯度被累加到原始模块中。</target>
        </trans-unit>
        <trans-unit id="3e99fa6e39b3592c4eea5075ef0e0720a6948ff1" translate="yes" xml:space="preserve">
          <source>This container parallelizes the application of the given module by splitting the input across the specified devices by chunking in the batch dimension. The module is replicated on each machine and each device, and each such replica handles a portion of the input. During the backwards pass, gradients from each node are averaged.</source>
          <target state="translated">这个容器通过在批处理维度上分块将输入分到指定的设备上,从而并行化给定模块的应用。该模块在每台机器和每个设备上复制,每个这样的副本都处理一部分输入。在后向传递过程中,对来自每个节点的梯度进行平均。</target>
        </trans-unit>
        <trans-unit id="c09652531ac8f4b111870bcb71b813e31279457c" translate="yes" xml:space="preserve">
          <source>This context manager is thread local; it will not affect computation in other threads.</source>
          <target state="translated">这个上下文管理器是线程本地的,它不会影响其他线程的计算。</target>
        </trans-unit>
        <trans-unit id="26ef7031b1f75f10e86902c0f567ce05a4ea44b5" translate="yes" xml:space="preserve">
          <source>This context manager will keep track of already-joined DDP processes, and &amp;ldquo;shadow&amp;rdquo; the forward and backward passes by inserting collective communication operations to match with the ones created by non-joined DDP processes. This will ensure each collective call has a corresponding call by already-joined DDP processes, preventing hangs or errors that would otherwise happen when training with uneven inputs across processes.</source>
          <target state="translated">该上下文管理器将跟踪已加入的DDP进程，并通过插入集体通信操作以使其与未加入的DDP进程创建的通信操作相匹配，来&amp;ldquo;遮挡&amp;rdquo;前进和后退过程。这将确保已加入DDP流程的每个集体呼叫都有一个相应的呼叫，从而避免了在跨流程进行不均匀输入训练时可能发生的挂起或错误。</target>
        </trans-unit>
        <trans-unit id="09d1e555fd19e686f48ac7306fa2525b334ba962" translate="yes" xml:space="preserve">
          <source>This criterion combines &lt;a href=&quot;generated/torch.nn.logsoftmax#torch.nn.LogSoftmax&quot;&gt;&lt;code&gt;nn.LogSoftmax()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.nllloss#torch.nn.NLLLoss&quot;&gt;&lt;code&gt;nn.NLLLoss()&lt;/code&gt;&lt;/a&gt; in one single class.</source>
          <target state="translated">此条件将&lt;a href=&quot;generated/torch.nn.logsoftmax#torch.nn.LogSoftmax&quot;&gt; &lt;code&gt;nn.LogSoftmax()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/torch.nn.nllloss#torch.nn.NLLLoss&quot;&gt; &lt;code&gt;nn.NLLLoss()&lt;/code&gt; 组合&lt;/a&gt;在一个类中。</target>
        </trans-unit>
        <trans-unit id="925d7f6dcda18d5ae787b2ea0d4e4cf02702d590" translate="yes" xml:space="preserve">
          <source>This criterion combines &lt;code&gt;log_softmax&lt;/code&gt; and &lt;code&gt;nll_loss&lt;/code&gt; in a single function.</source>
          <target state="translated">该标准将 &lt;code&gt;log_softmax&lt;/code&gt; 和 &lt;code&gt;nll_loss&lt;/code&gt; 组合在一个函数中。</target>
        </trans-unit>
        <trans-unit id="c7ea31e3bc10ddc7b5db55c0a7c9d23739bfa2db" translate="yes" xml:space="preserve">
          <source>This criterion combines &lt;code&gt;nn.LogSoftmax()&lt;/code&gt; and &lt;code&gt;nn.NLLLoss()&lt;/code&gt; in one single class.</source>
          <target state="translated">此条件将 &lt;code&gt;nn.LogSoftmax()&lt;/code&gt; 和 &lt;code&gt;nn.NLLLoss()&lt;/code&gt; 组合在一个类中。</target>
        </trans-unit>
        <trans-unit id="4a017ebd876454e242cede3ce02b356f5f295daa" translate="yes" xml:space="preserve">
          <source>This criterion expects a &lt;code&gt;target&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; of the same size as the &lt;code&gt;input&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">此标准要求 &lt;code&gt;target&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 的大小与 &lt;code&gt;input&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 的大小相同。</target>
        </trans-unit>
        <trans-unit id="c10376150f504915e5bd847798be0f3a52dc669c" translate="yes" xml:space="preserve">
          <source>This criterion expects a class index in the range</source>
          <target state="translated">这个标准要求类指数的范围是</target>
        </trans-unit>
        <trans-unit id="4c181079125dc2e25b97bd2d3da70b20b81a75a7" translate="yes" xml:space="preserve">
          <source>This decorator also works with RRef helpers, i.e., . &lt;a href=&quot;#torch.distributed.rpc.RRef.rpc_sync&quot;&gt;&lt;code&gt;torch.distributed.rpc.RRef.rpc_sync()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributed.rpc.RRef.rpc_async&quot;&gt;&lt;code&gt;torch.distributed.rpc.RRef.rpc_async()&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;#torch.distributed.rpc.RRef.remote&quot;&gt;&lt;code&gt;torch.distributed.rpc.RRef.remote()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">该装饰器还可以与RRef帮助器一起使用。&lt;a href=&quot;#torch.distributed.rpc.RRef.rpc_sync&quot;&gt; &lt;code&gt;torch.distributed.rpc.RRef.rpc_sync()&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;#torch.distributed.rpc.RRef.rpc_async&quot;&gt; &lt;code&gt;torch.distributed.rpc.RRef.rpc_async()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.distributed.rpc.RRef.remote&quot;&gt; &lt;code&gt;torch.distributed.rpc.RRef.remote()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ba581390e34d5e57c67e068b92dac8e4709b3ad6" translate="yes" xml:space="preserve">
          <source>This decorator indicates that a method on an &lt;code&gt;nn.Module&lt;/code&gt; is used as an entry point into a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; and should be compiled.</source>
          <target state="translated">此装饰器指示 &lt;code&gt;nn.Module&lt;/code&gt; 上的方法用作&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;的入口点，应进行编译。</target>
        </trans-unit>
        <trans-unit id="174b3d4b823448bf6302b0b53449be4c6d5ad12e" translate="yes" xml:space="preserve">
          <source>This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.</source>
          <target state="translated">这个装饰符向编译器表明,一个函数或方法应该被忽略,并作为一个 Python 函数留下。</target>
        </trans-unit>
        <trans-unit id="6d10437bc80b062c46cb5ff8be0bb49322ddb59f" translate="yes" xml:space="preserve">
          <source>This decorator indicates to the compiler that a function or method should be ignored and left as a Python function. This allows you to leave code in your model that is not yet TorchScript compatible. If called from TorchScript, ignored functions will dispatch the call to the Python interpreter. Models with ignored functions cannot be exported; use &lt;a href=&quot;torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;@torch.jit.unused&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">此装饰器向编译器指示应忽略函数或方法，而应将其保留为Python函数。这使您可以将代码保留在尚未与TorchScript兼容的模型中。如果从TorchScript调用，则忽略的函数会将调用分派给Python解释器。具有忽略功能的模型无法导出；使用&lt;a href=&quot;torch.jit.unused#torch.jit.unused&quot;&gt; &lt;code&gt;@torch.jit.unused&lt;/code&gt; &lt;/a&gt;代替。</target>
        </trans-unit>
        <trans-unit id="1508df53ef2be98f34c189e45c94ca9319ce75f2" translate="yes" xml:space="preserve">
          <source>This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.</source>
          <target state="translated">这个装饰符向编译器表明,一个函数或方法应该被忽略,而用引发异常来代替。</target>
        </trans-unit>
        <trans-unit id="75d6e9d0a82393986fc62b4441accfe0e14ee3a9" translate="yes" xml:space="preserve">
          <source>This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception. This allows you to leave code in your model that is not yet TorchScript compatible and still export your model.</source>
          <target state="translated">这个装饰符向编译器表明,一个函数或方法应该被忽略,并以引发异常来代替。这允许您在您的模型中留下还不兼容TorchScript的代码,但仍然可以导出您的模型。</target>
        </trans-unit>
        <trans-unit id="8952c5fbe2a12cf21923d9bc22bc2c081674eb1e" translate="yes" xml:space="preserve">
          <source>This defines</source>
          <target state="translated">这定义了</target>
        </trans-unit>
        <trans-unit id="04bcd4a4cb1d0ee1f357d9037605979a3155b988" translate="yes" xml:space="preserve">
          <source>This depends on the &lt;code&gt;spawn&lt;/code&gt; start method in Python&amp;rsquo;s &lt;code&gt;multiprocessing&lt;/code&gt; package.</source>
          <target state="translated">这取决于Python的 &lt;code&gt;multiprocessing&lt;/code&gt; 程序包中的 &lt;code&gt;spawn&lt;/code&gt; start方法。</target>
        </trans-unit>
        <trans-unit id="e40f466c8c675241a4989cdf735bce5f4ddce6bc" translate="yes" xml:space="preserve">
          <source>This directly calls the underlying LAPACK function &lt;code&gt;?orgqr&lt;/code&gt;. See &lt;a href=&quot;https://software.intel.com/en-us/mkl-developer-reference-c-orgqr&quot;&gt;LAPACK documentation for orgqr&lt;/a&gt; for further details.</source>
          <target state="translated">这将直接调用基础的LAPACK函数 &lt;code&gt;?orgqr&lt;/code&gt; 。有关更多详细信息，请参见&lt;a href=&quot;https://software.intel.com/en-us/mkl-developer-reference-c-orgqr&quot;&gt;orgqr的LAPACK文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9fb3c5a1f24bdd83af6fd14c07d4d7ef76ec7527" translate="yes" xml:space="preserve">
          <source>This directly calls the underlying LAPACK function &lt;code&gt;?ormqr&lt;/code&gt;. See &lt;a href=&quot;https://software.intel.com/en-us/mkl-developer-reference-c-ormqr&quot;&gt;LAPACK documentation for ormqr&lt;/a&gt; for further details.</source>
          <target state="translated">这将直接调用基础的LAPACK函数 &lt;code&gt;?ormqr&lt;/code&gt; 。有关更多详细信息，请参见&lt;a href=&quot;https://software.intel.com/en-us/mkl-developer-reference-c-ormqr&quot;&gt;orpqr的LAPACK文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1a44ae2c253871828f29057a792173301af10f61" translate="yes" xml:space="preserve">
          <source>This does two things: - Running the forward pass with detection enabled will allow the backward pass to print the traceback of the forward operation that created the failing backward function. - Any backward computation that generate &amp;ldquo;nan&amp;rdquo; value will raise an error.</source>
          <target state="translated">这有两件事：-在启用检测的情况下运行正向传递，将允许反向传递打印创建失败的反向函数的正向操作的回溯。-任何产生&amp;ldquo; nan&amp;rdquo;值的向后计算都会引发错误。</target>
        </trans-unit>
        <trans-unit id="d7d3fb60afba5b578d1ed91b3b2d20aba1664bb0" translate="yes" xml:space="preserve">
          <source>This error usually means that the method you are tracing uses a module&amp;rsquo;s parameters and you are passing the module&amp;rsquo;s method instead of the module instance (e.g. &lt;code&gt;my_module_instance.forward&lt;/code&gt; vs &lt;code&gt;my_module_instance&lt;/code&gt;).</source>
          <target state="translated">此错误通常意味着您正在跟踪的方法使用模块的参数，并且您正在传递模块的方法而不是模块实例（例如， &lt;code&gt;my_module_instance.forward&lt;/code&gt; 与 &lt;code&gt;my_module_instance&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="c753cc91ef9f274f764a4ae41747b732c7fe2261" translate="yes" xml:space="preserve">
          <source>This feature is in beta, and its design and implementation may change in the future.</source>
          <target state="translated">该功能还处于测试阶段,其设计和实现可能会在未来发生变化。</target>
        </trans-unit>
        <trans-unit id="b7614e828d8ac51033f6b1d436da1e7ec19a65d5" translate="yes" xml:space="preserve">
          <source>This function accepts any input that has at least two dimensions. You can apply it to pack the labels, and use the output of the RNN with them to compute the loss directly. A Tensor can be retrieved from a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;PackedSequence&lt;/code&gt;&lt;/a&gt; object by accessing its &lt;code&gt;.data&lt;/code&gt; attribute.</source>
          <target state="translated">此函数接受至少具有二维的任何输入。您可以将其应用于包装标签，并与它们一起使用RNN的输出直接计算损失。可以通过访问&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;PackedSequence&lt;/code&gt; &lt;/a&gt;对象的 &lt;code&gt;.data&lt;/code&gt; 属性来获取Tensor 。</target>
        </trans-unit>
        <trans-unit id="f5cfef34a5b604499ec2d99f480d0835ab4472fc" translate="yes" xml:space="preserve">
          <source>This function accumulates gradients in the leaves - you might need to zero &lt;code&gt;.grad&lt;/code&gt; attributes or set them to &lt;code&gt;None&lt;/code&gt; before calling it. See &lt;a href=&quot;#default-grad-layouts&quot;&gt;Default gradient layouts&lt;/a&gt; for details on the memory layout of accumulated gradients.</source>
          <target state="translated">此函数会在树叶中累积渐变-调用之前，您可能需要将 &lt;code&gt;.grad&lt;/code&gt; 属性设置为零或将其设置为 &lt;code&gt;None&lt;/code&gt; 。有关累积梯度的内存布局的详细信息，请参见&lt;a href=&quot;#default-grad-layouts&quot;&gt;默认梯度布局&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="97ac98bd75da52df5620120c1ca469a7f25204b3" translate="yes" xml:space="preserve">
          <source>This function accumulates gradients in the leaves - you might need to zero &lt;code&gt;.grad&lt;/code&gt; attributes or set them to &lt;code&gt;None&lt;/code&gt; before calling it. See &lt;a href=&quot;autograd#default-grad-layouts&quot;&gt;Default gradient layouts&lt;/a&gt; for details on the memory layout of accumulated gradients.</source>
          <target state="translated">此函数会在树叶中累积渐变-调用之前，您可能需要将 &lt;code&gt;.grad&lt;/code&gt; 属性设置为零或将其设置为 &lt;code&gt;None&lt;/code&gt; 。有关累积梯度的内存布局的详细信息，请参见&lt;a href=&quot;autograd#default-grad-layouts&quot;&gt;默认梯度布局&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5919d90354daacc619c8dc367427cc669c661c6e" translate="yes" xml:space="preserve">
          <source>This function behaves exactly like &lt;a href=&quot;#torch.utils.cpp_extension.load&quot;&gt;&lt;code&gt;load()&lt;/code&gt;&lt;/a&gt;, but takes its sources as strings rather than filenames. These strings are stored to files in the build directory, after which the behavior of &lt;a href=&quot;#torch.utils.cpp_extension.load_inline&quot;&gt;&lt;code&gt;load_inline()&lt;/code&gt;&lt;/a&gt; is identical to &lt;a href=&quot;#torch.utils.cpp_extension.load&quot;&gt;&lt;code&gt;load()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此函数的行为与&lt;a href=&quot;#torch.utils.cpp_extension.load&quot;&gt; &lt;code&gt;load()&lt;/code&gt; &lt;/a&gt;完全相同，但是将其源作为字符串而不是文件名使用。这些字符串存储到文件中生成目录，在这之后的行为&lt;a href=&quot;#torch.utils.cpp_extension.load_inline&quot;&gt; &lt;code&gt;load_inline()&lt;/code&gt; &lt;/a&gt;是相同的&lt;a href=&quot;#torch.utils.cpp_extension.load&quot;&gt; &lt;code&gt;load()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4742c80d8253ffcd737e46fcd5dffcfb774bfb9a" translate="yes" xml:space="preserve">
          <source>This function calculates all eigenvalues (and vectors) of &lt;code&gt;input&lt;/code&gt; such that</source>
          <target state="translated">此函数计算 &lt;code&gt;input&lt;/code&gt; 所有特征值（和向量），以便</target>
        </trans-unit>
        <trans-unit id="2e52ac392528ad63a53ea2de90d126a45274fb82" translate="yes" xml:space="preserve">
          <source>This function can be called in an interleaved way.</source>
          <target state="translated">这个函数可以用交错的方式调用。</target>
        </trans-unit>
        <trans-unit id="f591ac1d01d2706090dd5158a48cfafbf7078fcd" translate="yes" xml:space="preserve">
          <source>This function can calculate one of eight different types of matrix norms, or one of an infinite number of vector norms, depending on both the number of reduction dimensions and the value of the &lt;code&gt;ord&lt;/code&gt; parameter.</source>
          <target state="translated">此函数可以根据缩小维数的数量和 &lt;code&gt;ord&lt;/code&gt; 参数的值来计算八种不同类型的矩阵范数之一，或无限数量的矢量范数之一。</target>
        </trans-unit>
        <trans-unit id="a99e80c93a86e3189bf95a219e4fc70666128f91" translate="yes" xml:space="preserve">
          <source>This function changed signature at version 0.4.1. Calling with the previous signature may cause error or return incorrect result.</source>
          <target state="translated">这个函数在0.4.1版本时改变了签名。用以前的签名调用可能会导致错误或返回不正确的结果。</target>
        </trans-unit>
        <trans-unit id="2742ba18db0e477006e0d4a879a88ee8aaa73a1c" translate="yes" xml:space="preserve">
          <source>This function checks if all &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; satisfy the condition:</source>
          <target state="translated">此函数检查所有 &lt;code&gt;input&lt;/code&gt; 和 &lt;code&gt;other&lt;/code&gt; 输入是否满足条件：</target>
        </trans-unit>
        <trans-unit id="63c734a4df7eea8aea1bf4116fd041c2a840b41a" translate="yes" xml:space="preserve">
          <source>This function checks that backpropagating through the gradients computed to the given &lt;code&gt;grad_outputs&lt;/code&gt; are correct.</source>
          <target state="translated">此函数检查通过向给定 &lt;code&gt;grad_outputs&lt;/code&gt; 计算的梯度的反向传播是否正确。</target>
        </trans-unit>
        <trans-unit id="4ad58a0a805b7dcf7c19d64d7ab1a5b0774c3bf4" translate="yes" xml:space="preserve">
          <source>This function does exact same thing as &lt;a href=&quot;generated/torch.addmm#torch.addmm&quot;&gt;&lt;code&gt;torch.addmm()&lt;/code&gt;&lt;/a&gt; in the forward, except that it supports backward for sparse matrix &lt;code&gt;mat1&lt;/code&gt;. &lt;code&gt;mat1&lt;/code&gt; need to have &lt;code&gt;sparse_dim = 2&lt;/code&gt;. Note that the gradients of &lt;code&gt;mat1&lt;/code&gt; is a coalesced sparse tensor.</source>
          <target state="translated">此函数向前执行与&lt;a href=&quot;generated/torch.addmm#torch.addmm&quot;&gt; &lt;code&gt;torch.addmm()&lt;/code&gt; &lt;/a&gt;完全相同的操作，除了它为稀疏矩阵 &lt;code&gt;mat1&lt;/code&gt; 支持向后。 &lt;code&gt;mat1&lt;/code&gt; 需要具有 &lt;code&gt;sparse_dim = 2&lt;/code&gt; 。请注意， &lt;code&gt;mat1&lt;/code&gt; 的梯度是合并的稀疏张量。</target>
        </trans-unit>
        <trans-unit id="b687a9d19b48f08afdcc0c1bcf3778a2f67002f3" translate="yes" xml:space="preserve">
          <source>This function does not &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcast&lt;/a&gt;.</source>
          <target state="translated">此功能不&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6eaaf4ac25e2420bf8da7dbd7b25891750193e61" translate="yes" xml:space="preserve">
          <source>This function does not &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcast&lt;/a&gt;. For broadcasting matrix products, see &lt;a href=&quot;torch.matmul#torch.matmul&quot;&gt;&lt;code&gt;torch.matmul()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此功能不&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;广播&lt;/a&gt;。有关广播矩阵产品，请参见&lt;a href=&quot;torch.matmul#torch.matmul&quot;&gt; &lt;code&gt;torch.matmul()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1273ec3288d9debd903d3f9e04111f9b0d5a8d6b" translate="yes" xml:space="preserve">
          <source>This function does not check if the factorization was successful or not if &lt;code&gt;get_infos&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; since the status of the factorization is present in the third element of the return tuple.</source>
          <target state="translated">此函数不会检查分解是否成功，如果 &lt;code&gt;get_infos&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ,则因为返回的元组的第三个元素中存在分解的状态。</target>
        </trans-unit>
        <trans-unit id="68c688ded2e6ac8d7e4721168f69f94608270e24" translate="yes" xml:space="preserve">
          <source>This function does not optimize the given expression, so a different formula for the same computation may run faster or consume less memory. Projects like opt_einsum (&lt;a href=&quot;https://optimized-einsum.readthedocs.io/en/stable/&quot;&gt;https://optimized-einsum.readthedocs.io/en/stable/&lt;/a&gt;) can optimize the formula for you.</source>
          <target state="translated">此函数不会优化给定的表达式，因此用于相同计算的不同公式可能会运行得更快或消耗更少的内存。诸如opt_einsum（&lt;a href=&quot;https://optimized-einsum.readthedocs.io/en/stable/&quot;&gt;https://optimized-einsum.readthedocs.io/en/stable/&lt;/a&gt;）之类的项目可以为您优化公式。</target>
        </trans-unit>
        <trans-unit id="f44824ec132a2e35c26075b94e4bfe941180a2db" translate="yes" xml:space="preserve">
          <source>This function doesn&amp;rsquo;t work directly with NLLLoss, which expects the Log to be computed between the Softmax and itself. Use log_softmax instead (it&amp;rsquo;s faster and has better numerical properties).</source>
          <target state="translated">此函数不能直接与NLLLoss一起使用，后者希望Log在Softmax及其自身之间进行计算。请改用log_softmax（速度更快，并且具有更好的数值属性）。</target>
        </trans-unit>
        <trans-unit id="ba69951c62e61a879aa86b6caaae011ee277fff1" translate="yes" xml:space="preserve">
          <source>This function eagerly initializes CUDA.</source>
          <target state="translated">这个函数急切地初始化CUDA。</target>
        </trans-unit>
        <trans-unit id="12a2d17eb1ae0addb52aeb2b46ee9bc80c204ede" translate="yes" xml:space="preserve">
          <source>This function insert observer module to all leaf child module that has a valid qconfig attribute.</source>
          <target state="translated">该函数将观察者模块插入到所有具有有效qconfig属性的叶子模块。</target>
        </trans-unit>
        <trans-unit id="4c40534c7583c126c2b6a9ea9f9ce426b4120e2b" translate="yes" xml:space="preserve">
          <source>This function is a front-end to the following LOBPCG algorithms selectable via &lt;code&gt;method&lt;/code&gt; argument:</source>
          <target state="translated">此函数是以下LOBPCG算法的前端，可通过 &lt;code&gt;method&lt;/code&gt; 参数选择：</target>
        </trans-unit>
        <trans-unit id="773eb7977e3d589f5a2a946752611ffc03872d99" translate="yes" xml:space="preserve">
          <source>This function is deprecated and may be removed in a future release. It can be implemented using &lt;a href=&quot;torch.outer#torch.outer&quot;&gt;&lt;code&gt;torch.outer()&lt;/code&gt;&lt;/a&gt; as &lt;code&gt;alpha * torch.outer(vec1, vec2) + beta * input&lt;/code&gt; when &lt;code&gt;beta&lt;/code&gt; is not zero, and as &lt;code&gt;alpha * torch.outer(vec1, vec2)&lt;/code&gt; when &lt;code&gt;beta&lt;/code&gt; is zero.</source>
          <target state="translated">不建议使用此功能，将来的版本中可能会删除该功能。它可以使用来实现&lt;a href=&quot;torch.outer#torch.outer&quot;&gt; &lt;code&gt;torch.outer()&lt;/code&gt; &lt;/a&gt;作为 &lt;code&gt;alpha * torch.outer(vec1, vec2) + beta * input&lt;/code&gt; 时 &lt;code&gt;beta&lt;/code&gt; 不为零，并且作为 &lt;code&gt;alpha * torch.outer(vec1, vec2)&lt;/code&gt; 时 &lt;code&gt;beta&lt;/code&gt; 是零。</target>
        </trans-unit>
        <trans-unit id="ecdb962fda9e357b596ac207e636ee312e395193" translate="yes" xml:space="preserve">
          <source>This function is deprecated and will be removed in a future PyTorch release. Use &lt;a href=&quot;torch.outer#torch.outer&quot;&gt;&lt;code&gt;torch.outer()&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">该功能已被弃用，并将在以后的PyTorch发行版中删除。请改用&lt;a href=&quot;torch.outer#torch.outer&quot;&gt; &lt;code&gt;torch.outer()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="32ba15aae127598880c645601e7ae7f8189c6c82" translate="yes" xml:space="preserve">
          <source>This function is deprecated and will be removed in a future release because its behavior is inconsistent with Python&amp;rsquo;s range builtin. Instead, use &lt;a href=&quot;torch.arange#torch.arange&quot;&gt;&lt;code&gt;torch.arange()&lt;/code&gt;&lt;/a&gt;, which produces values in [start, end).</source>
          <target state="translated">不推荐使用此函数，并且在将来的版本中将删除该函数，因为其行为与Python的内置范围不一致。而是使用&lt;a href=&quot;torch.arange#torch.arange&quot;&gt; &lt;code&gt;torch.arange()&lt;/code&gt; &lt;/a&gt;，它在[start，end）中产生值。</target>
        </trans-unit>
        <trans-unit id="cd06f9dfe663c3caf3762160bc99450c126a39a9" translate="yes" xml:space="preserve">
          <source>This function is deprecated in favor of &lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt;&lt;/a&gt;. This is equivalent with &lt;code&gt;nn.functional.interpolate(...)&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此函数，而推荐使用&lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt; &lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt; &lt;/a&gt;。这等效于 &lt;code&gt;nn.functional.interpolate(...)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1632348f060a8b22bffa765800a936ba8981c455" translate="yes" xml:space="preserve">
          <source>This function is deprecated in favor of &lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt;&lt;/a&gt;. This is equivalent with &lt;code&gt;nn.functional.interpolate(..., mode='bilinear', align_corners=True)&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此函数，而推荐使用&lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt; &lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt; &lt;/a&gt;。这等效于 &lt;code&gt;nn.functional.interpolate(..., mode='bilinear', align_corners=True)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e11fc8a8842739d9e68d3ea9f36d243b26e33ee2" translate="yes" xml:space="preserve">
          <source>This function is deprecated in favor of &lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt;&lt;/a&gt;. This is equivalent with &lt;code&gt;nn.functional.interpolate(..., mode='nearest')&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此函数，而推荐使用&lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt; &lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt; &lt;/a&gt;。这等效于 &lt;code&gt;nn.functional.interpolate(..., mode='nearest')&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="409b1beff6de19c9e0fc8534a682b00b07c2667b" translate="yes" xml:space="preserve">
          <source>This function is deprecated in favor of &lt;a href=&quot;#torch.nn.quantized.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.quantized.functional.interpolate()&lt;/code&gt;&lt;/a&gt;. This is equivalent with &lt;code&gt;nn.quantized.functional.interpolate(...)&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此函数，而推荐使用&lt;a href=&quot;#torch.nn.quantized.functional.interpolate&quot;&gt; &lt;code&gt;torch.nn.quantized.functional.interpolate()&lt;/code&gt; &lt;/a&gt;。这相当于用 &lt;code&gt;nn.quantized.functional.interpolate(...)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f088ca0f34a9882f6e67d133eea7956f99a05c61" translate="yes" xml:space="preserve">
          <source>This function is deprecated in favor of &lt;a href=&quot;#torch.nn.quantized.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.quantized.functional.interpolate()&lt;/code&gt;&lt;/a&gt;. This is equivalent with &lt;code&gt;nn.quantized.functional.interpolate(..., mode='bilinear', align_corners=True)&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此函数，而推荐使用&lt;a href=&quot;#torch.nn.quantized.functional.interpolate&quot;&gt; &lt;code&gt;torch.nn.quantized.functional.interpolate()&lt;/code&gt; &lt;/a&gt;。这等效于 &lt;code&gt;nn.quantized.functional.interpolate(..., mode='bilinear', align_corners=True)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a1e1948ca54d505e36aa98bcd4ccf28bf3f09403" translate="yes" xml:space="preserve">
          <source>This function is deprecated in favor of &lt;a href=&quot;#torch.nn.quantized.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.quantized.functional.interpolate()&lt;/code&gt;&lt;/a&gt;. This is equivalent with &lt;code&gt;nn.quantized.functional.interpolate(..., mode='nearest')&lt;/code&gt;.</source>
          <target state="translated">不推荐使用此函数，而推荐使用&lt;a href=&quot;#torch.nn.quantized.functional.interpolate&quot;&gt; &lt;code&gt;torch.nn.quantized.functional.interpolate()&lt;/code&gt; &lt;/a&gt;。这等效于 &lt;code&gt;nn.quantized.functional.interpolate(..., mode='nearest')&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6111b83606e5f76d2d19a4fd63d2df2a457f3738" translate="yes" xml:space="preserve">
          <source>This function is different from &lt;a href=&quot;torch.unique#torch.unique&quot;&gt;&lt;code&gt;torch.unique()&lt;/code&gt;&lt;/a&gt; in the sense that this function only eliminates consecutive duplicate values. This semantics is similar to &lt;code&gt;std::unique&lt;/code&gt; in C++.</source>
          <target state="translated">该函数与&lt;a href=&quot;torch.unique#torch.unique&quot;&gt; &lt;code&gt;torch.unique()&lt;/code&gt; 的&lt;/a&gt;不同之处在于该函数仅消除连续的重复值。此语义类似于C ++中的 &lt;code&gt;std::unique&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c84bc16a342354e3160aa386d7ad206e77f3ce71" translate="yes" xml:space="preserve">
          <source>This function is different from &lt;a href=&quot;torch.unique_consecutive#torch.unique_consecutive&quot;&gt;&lt;code&gt;torch.unique_consecutive()&lt;/code&gt;&lt;/a&gt; in the sense that this function also eliminates non-consecutive duplicate values.</source>
          <target state="translated">该函数与&lt;a href=&quot;torch.unique_consecutive#torch.unique_consecutive&quot;&gt; &lt;code&gt;torch.unique_consecutive()&lt;/code&gt; 的&lt;/a&gt;不同之处在于，该函数还消除了非连续的重复值。</target>
        </trans-unit>
        <trans-unit id="42a1f69345a02122fc091a770868079bb8638971" translate="yes" xml:space="preserve">
          <source>This function is differentiable, so gradients will flow back from the result of this operation to &lt;code&gt;input&lt;/code&gt;. To create a tensor without an autograd relationship to &lt;code&gt;input&lt;/code&gt; see &lt;a href=&quot;../autograd#torch.Tensor.detach&quot;&gt;&lt;code&gt;detach()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此函数是可微的，因此渐变将从此操作的结果流回 &lt;code&gt;input&lt;/code&gt; 。要创建一个没有自动渐变关系的张量来 &lt;code&gt;input&lt;/code&gt; 请参见&lt;a href=&quot;../autograd#torch.Tensor.detach&quot;&gt; &lt;code&gt;detach()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0fb9aa5da82ff7de2350851193131992c19c52a8" translate="yes" xml:space="preserve">
          <source>This function is equivalent to &lt;code&gt;scipy.spatial.distance.cdist(input,&amp;rsquo;minkowski&amp;rsquo;, p=p)&lt;/code&gt; if</source>
          <target state="translated">此函数等同于 &lt;code&gt;scipy.spatial.distance.cdist(input,&amp;rsquo;minkowski&amp;rsquo;, p=p)&lt;/code&gt; ，如果</target>
        </trans-unit>
        <trans-unit id="cc680c0e90287ae914b5b4470b9652c693f1647a" translate="yes" xml:space="preserve">
          <source>This function is equivalent to &lt;code&gt;scipy.spatial.distance.pdist(input, &amp;lsquo;minkowski&amp;rsquo;, p=p)&lt;/code&gt; if</source>
          <target state="translated">此函数等同于 &lt;code&gt;scipy.spatial.distance.pdist(input, &amp;lsquo;minkowski&amp;rsquo;, p=p)&lt;/code&gt; ，如果</target>
        </trans-unit>
        <trans-unit id="ff6a78f486235a2c4ee2bb0612d674661defb9c5" translate="yes" xml:space="preserve">
          <source>This function is here for legacy reasons, may be removed from nn.Functional in the future.</source>
          <target state="translated">这个功能在这里是由于传统的原因,将来可能会从nn.Function中删除。</target>
        </trans-unit>
        <trans-unit id="4ffbcd1ffd822d93e92f3e882d1d47ebf27a02de" translate="yes" xml:space="preserve">
          <source>This function is implemented only for nonnegative integers</source>
          <target state="translated">这个函数只对非负整数执行。</target>
        </trans-unit>
        <trans-unit id="4af64360b4b0bf60d1db0c5268a216c0039ae031" translate="yes" xml:space="preserve">
          <source>This function is more accurate than &lt;a href=&quot;torch.log#torch.log&quot;&gt;&lt;code&gt;torch.log()&lt;/code&gt;&lt;/a&gt; for small values of &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">对于较小的 &lt;code&gt;input&lt;/code&gt; 值，此函数比&lt;a href=&quot;torch.log#torch.log&quot;&gt; &lt;code&gt;torch.log()&lt;/code&gt; &lt;/a&gt;更准确</target>
        </trans-unit>
        <trans-unit id="f9a118660ffcea349bb4668844a1f15351a99bbb" translate="yes" xml:space="preserve">
          <source>This function is not defined for &lt;code&gt;torch.cuda.Tensor&lt;/code&gt; yet.</source>
          <target state="translated">尚未为 &lt;code&gt;torch.cuda.Tensor&lt;/code&gt; 定义此功能。</target>
        </trans-unit>
        <trans-unit id="69c6cf6408f0b3c6058b2d09b95171f65a52d054" translate="yes" xml:space="preserve">
          <source>This function is often used in conjunction with &lt;a href=&quot;#torch.nn.functional.affine_grid&quot;&gt;&lt;code&gt;affine_grid()&lt;/code&gt;&lt;/a&gt; to build &lt;a href=&quot;https://arxiv.org/abs/1506.02025&quot;&gt;Spatial Transformer Networks&lt;/a&gt; .</source>
          <target state="translated">此功能通常与&lt;a href=&quot;#torch.nn.functional.affine_grid&quot;&gt; &lt;code&gt;affine_grid()&lt;/code&gt; &lt;/a&gt;结合使用以构建&lt;a href=&quot;https://arxiv.org/abs/1506.02025&quot;&gt;空间变压器网络&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3bda1093b38d267fe7d744a3f96bb51ca111b18d" translate="yes" xml:space="preserve">
          <source>This function is often used in conjunction with &lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt;&lt;code&gt;grid_sample()&lt;/code&gt;&lt;/a&gt; to build &lt;a href=&quot;https://arxiv.org/abs/1506.02025&quot;&gt;Spatial Transformer Networks&lt;/a&gt; .</source>
          <target state="translated">此函数通常与&lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt; &lt;code&gt;grid_sample()&lt;/code&gt; &lt;/a&gt;结合使用以构建&lt;a href=&quot;https://arxiv.org/abs/1506.02025&quot;&gt;空间变压器网络&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ff271211b68caf9a357a20a5285a2d8ec4fb66ee" translate="yes" xml:space="preserve">
          <source>This function is significantly slower than &lt;code&gt;vhp&lt;/code&gt; due to backward mode AD constraints. If your functions is twice continuously differentiable, then hvp = vhp.t(). So if you know that your function satisfies this condition, you should use vhp instead that is much faster with the current implementation.</source>
          <target state="translated">由于后向模式AD限制，此功能比 &lt;code&gt;vhp&lt;/code&gt; 明显慢。如果您的函数是两次连续可微的，则hvp = vhp.t（）。因此，如果知道您的函数满足此条件，则应使用vhp来代替当前实现。</target>
        </trans-unit>
        <trans-unit id="18b3cca742284c69f10463b509a01d9fefa6450b" translate="yes" xml:space="preserve">
          <source>This function is to be overridden by all subclasses.</source>
          <target state="translated">这个函数要被所有子类重写。</target>
        </trans-unit>
        <trans-unit id="83aed61e5e3f24098a9d4e00feeea5da8441abc7" translate="yes" xml:space="preserve">
          <source>This function now calls &lt;code&gt;reset_peak_memory_stats()&lt;/code&gt;, which resets /all/ peak memory stats.</source>
          <target state="translated">现在，此函数调用 &lt;code&gt;reset_peak_memory_stats()&lt;/code&gt; ，以重置/ all /峰值内存状态。</target>
        </trans-unit>
        <trans-unit id="d26ea75bdd03743d020bb8fd3f0b4f05e5fca44d" translate="yes" xml:space="preserve">
          <source>This function only works with CPU tensors and should not be used in code sections that require high performance.</source>
          <target state="translated">这个函数只适用于CPU张力器,不应该在需要高性能的代码部分使用。</target>
        </trans-unit>
        <trans-unit id="7ed8f6139c0d2640189a9321e1da51e7b538d228" translate="yes" xml:space="preserve">
          <source>This function produces deterministic (sub)gradients unlike &lt;code&gt;max(dim=0)&lt;/code&gt;</source>
          <target state="translated">与 &lt;code&gt;max(dim=0)&lt;/code&gt; 不同，此函数产生确定性（子）梯度</target>
        </trans-unit>
        <trans-unit id="49eba71d4c9b31d15ee67772326e88d1462e9393" translate="yes" xml:space="preserve">
          <source>This function produces deterministic (sub)gradients unlike &lt;code&gt;median(dim=0)&lt;/code&gt;</source>
          <target state="translated">与 &lt;code&gt;median(dim=0)&lt;/code&gt; 不同，此函数产生确定性（子）梯度</target>
        </trans-unit>
        <trans-unit id="d9251c4cd19a437c8f31a2c44be4bdf2e2282d65" translate="yes" xml:space="preserve">
          <source>This function produces deterministic (sub)gradients unlike &lt;code&gt;min(dim=0)&lt;/code&gt;</source>
          <target state="translated">与 &lt;code&gt;min(dim=0)&lt;/code&gt; 不同，此函数产生确定性（子）梯度</target>
        </trans-unit>
        <trans-unit id="7d3e2fb10adcbb7f259d94a424b7b3b695d7efa3" translate="yes" xml:space="preserve">
          <source>This function provides a way of computing multilinear expressions (i.e.</source>
          <target state="translated">这个函数提供了一种计算多线表达式(即</target>
        </trans-unit>
        <trans-unit id="6dd319ec8d2bd7cb7695497b2e2c0c7da18093d6" translate="yes" xml:space="preserve">
          <source>This function provides a way of computing multilinear expressions (i.e. sums of products) using the Einstein summation convention.</source>
          <target state="translated">该函数提供了一种使用爱因斯坦求和约定计算多线表达式(即积的和)的方法。</target>
        </trans-unit>
        <trans-unit id="464a58780f1e7ad5a78398d14f9e91d688f64e19" translate="yes" xml:space="preserve">
          <source>This function requires that all processes in the main group (i.e. all processes that are part of the distributed job) enter this function, even if they are not going to be members of the group. Additionally, groups should be created in the same order in all processes.</source>
          <target state="translated">这个功能要求主组中的所有进程(即属于分布式作业的所有进程)都要进入这个功能,即使它们不会成为组的成员。此外,在所有进程中应以相同的顺序创建组。</target>
        </trans-unit>
        <trans-unit id="a52b7a21105c565c661abb413198331f8bc8a45e" translate="yes" xml:space="preserve">
          <source>This function returns a Tensor of size &lt;code&gt;T x B x *&lt;/code&gt; or &lt;code&gt;B x T x *&lt;/code&gt; where &lt;code&gt;T&lt;/code&gt; is the length of the longest sequence. This function assumes trailing dimensions and type of all the Tensors in sequences are same.</source>
          <target state="translated">此函数返回张量为 &lt;code&gt;T x B x *&lt;/code&gt; 或 &lt;code&gt;B x T x *&lt;/code&gt; 的张量，其中 &lt;code&gt;T&lt;/code&gt; 是最长序列的长度。此函数假定序列中所有张量的尾随尺寸和类型相同。</target>
        </trans-unit>
        <trans-unit id="c177e0164ff9028b4584fc5df4d1e3daee9e253a" translate="yes" xml:space="preserve">
          <source>This function returns a handle with a method &lt;code&gt;handle.remove()&lt;/code&gt; that removes the hook from the module.</source>
          <target state="translated">该函数返回一个带有 &lt;code&gt;handle.remove()&lt;/code&gt; 方法的句柄，该方法将从模块中删除该钩子。</target>
        </trans-unit>
        <trans-unit id="a0496aaa431bc80a1684ef66937522b9d485ea0d" translate="yes" xml:space="preserve">
          <source>This function returns a namedtuple &lt;code&gt;(U, S, V)&lt;/code&gt; which is the nearly optimal approximation of a singular value decomposition of a centered matrix</source>
          <target state="translated">此函数返回一个命名元组 &lt;code&gt;(U, S, V)&lt;/code&gt; ，它是中心矩阵的奇异值分解的最佳近似</target>
        </trans-unit>
        <trans-unit id="eda5e94a6c116342560b85fa8d7ac690f3e68684" translate="yes" xml:space="preserve">
          <source>This function returns a namedtuple &lt;code&gt;(U, S, V)&lt;/code&gt; which is the singular value decomposition of a input real matrix or batches of real matrices &lt;code&gt;input&lt;/code&gt; such that</source>
          <target state="translated">此函数返回一个namedtuple &lt;code&gt;(U, S, V)&lt;/code&gt; ，它是输入实数矩阵或一批实数矩阵 &lt;code&gt;input&lt;/code&gt; 的奇异值分解，使得</target>
        </trans-unit>
        <trans-unit id="5aeb212c2592eaa5e981d2676890741ba536e05d" translate="yes" xml:space="preserve">
          <source>This function returns eigenvalues and eigenvectors of a real symmetric matrix &lt;code&gt;input&lt;/code&gt; or a batch of real symmetric matrices, represented by a namedtuple (eigenvalues, eigenvectors).</source>
          <target state="translated">此函数返回由一个命名元组（特征值，特征向量）表示的实对称矩阵 &lt;code&gt;input&lt;/code&gt; 或一批实对称矩阵的特征值和特征向量。</target>
        </trans-unit>
        <trans-unit id="2f955323e5a9f295f213a25f7ecc7dec98b5caa2" translate="yes" xml:space="preserve">
          <source>This function returns the solution to the system of linear equations represented by</source>
          <target state="translated">该函数返回用以下公式表示的线性方程组的解。</target>
        </trans-unit>
        <trans-unit id="e819ccb2e6403dc786009cdee93abaa1f0eeb18b" translate="yes" xml:space="preserve">
          <source>This function returns without waiting for &lt;code&gt;event&lt;/code&gt;: only future operations are affected.</source>
          <target state="translated">该函数返回而无需等待 &lt;code&gt;event&lt;/code&gt; ：仅影响以后的操作。</target>
        </trans-unit>
        <trans-unit id="bf880005934990f2038c1e6b5eb0e99c0dad47ad" translate="yes" xml:space="preserve">
          <source>This function returns without waiting for currently enqueued kernels in &lt;a href=&quot;#torch.cuda.stream&quot;&gt;&lt;code&gt;stream&lt;/code&gt;&lt;/a&gt;: only future operations are affected.</source>
          <target state="translated">此功能无需等待当前排队内核收益&lt;a href=&quot;#torch.cuda.stream&quot;&gt; &lt;code&gt;stream&lt;/code&gt; &lt;/a&gt;：只有未来的行动受到影响。</target>
        </trans-unit>
        <trans-unit id="7d7a84c0650abce4d3f9c668ace3ede1befabda4" translate="yes" xml:space="preserve">
          <source>This function&amp;rsquo;s name is a misnomer. It actually rounds the quotient towards zero instead of taking its floor. This behavior will be deprecated in a future PyTorch release.</source>
          <target state="translated">该函数的名称用词不当。实际上，它会将商数舍入为零，而不是取其底值。在以后的PyTorch版本中将不赞成使用此行为。</target>
        </trans-unit>
        <trans-unit id="c29a81af2b62737c72764612d782901c3f2eb4d7" translate="yes" xml:space="preserve">
          <source>This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g. &lt;a href=&quot;torch.nn.dropout#torch.nn.Dropout&quot;&gt;&lt;code&gt;Dropout&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;BatchNorm&lt;/code&gt;, etc.</source>
          <target state="translated">这仅对某些模块有任何影响。请参阅特定模块的文档，以了解其在培训/评估模式下的行为（如果受到影响）的详细信息，例如&lt;a href=&quot;torch.nn.dropout#torch.nn.Dropout&quot;&gt; &lt;code&gt;Dropout&lt;/code&gt; &lt;/a&gt;， &lt;code&gt;BatchNorm&lt;/code&gt; 等。</target>
        </trans-unit>
        <trans-unit id="a56c6998fe86297bbe85815fb835af9e00568e26" translate="yes" xml:space="preserve">
          <source>This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g. &lt;code&gt;Dropout&lt;/code&gt;, &lt;code&gt;BatchNorm&lt;/code&gt;, etc.</source>
          <target state="translated">这仅对某些模块有任何影响。请参阅特定模块的文档，以了解其在培训/评估模式下的行为（如果受到影响）的详细信息，例如 &lt;code&gt;Dropout&lt;/code&gt; ， &lt;code&gt;BatchNorm&lt;/code&gt; 等。</target>
        </trans-unit>
        <trans-unit id="4f8efe32a81509d5ad4a6e1e586b778004252c39" translate="yes" xml:space="preserve">
          <source>This has proven to be an effective technique for regularization and preventing the co-adaptation of neurons as described in the paper &lt;a href=&quot;https://arxiv.org/abs/1207.0580&quot;&gt;Improving neural networks by preventing co-adaptation of feature detectors&lt;/a&gt; .</source>
          <target state="translated">事实证明，这是一种有效的技术，可用于规范化和防止神经元的协同适应，如论文&lt;a href=&quot;https://arxiv.org/abs/1207.0580&quot;&gt;``通过防止特征检测器的协同适应来改善神经网络''&lt;/a&gt;所述。</target>
        </trans-unit>
        <trans-unit id="16cf55bdf2b28322a9b3129eb62ae4e3fc4f60f8" translate="yes" xml:space="preserve">
          <source>This implementation of an engine for Sobol sequences is capable of sampling sequences up to a maximum dimension of 1111. It uses direction numbers to generate these sequences, and these numbers have been adapted from &lt;a href=&quot;https://web.maths.unsw.edu.au/~fkuo/sobol/joe-kuo-old.1111&quot;&gt;here&lt;/a&gt;.</source>
          <target state="translated">Sobol序列引擎的这种实现方式能够对最大维度为1111的序列进行采样。它使用方向编号生成这些序列，并且这些编号已从&lt;a href=&quot;https://web.maths.unsw.edu.au/~fkuo/sobol/joe-kuo-old.1111&quot;&gt;此处&lt;/a&gt;进行了改编。</target>
        </trans-unit>
        <trans-unit id="695271e751e01b7a3e177cda22c6d8e9f50c985c" translate="yes" xml:space="preserve">
          <source>This implementation uses polar coordinates. The &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt; args can be any real number (to facilitate unconstrained optimization), but are interpreted as angles modulo 2 pi.</source>
          <target state="translated">此实现使用极坐标。在 &lt;code&gt;loc&lt;/code&gt; 和 &lt;code&gt;value&lt;/code&gt; ARGS可以是任何实数（以促进无约束最优化），但作为角度模2 PI被解释。</target>
        </trans-unit>
        <trans-unit id="218178424bb17bc6ad1e0c3396e3e36ddf25ff43" translate="yes" xml:space="preserve">
          <source>This implementation was adapted from the github repo: &lt;a href=&quot;https://github.com/bckenstler/CLR&quot;&gt;bckenstler/CLR&lt;/a&gt;</source>
          <target state="translated">该实现改编自github repo：&lt;a href=&quot;https://github.com/bckenstler/CLR&quot;&gt;bckenstler / CLR&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e5d17292f2576cd2e36da2cca0252f9780e064b5" translate="yes" xml:space="preserve">
          <source>This invariant is maintained throughout &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;PackedSequence&lt;/code&gt;&lt;/a&gt; class, and all functions that construct a &lt;code&gt;:class:PackedSequence&lt;/code&gt; in PyTorch (i.e., they only pass in tensors conforming to this constraint).</source>
          <target state="translated">这个不变量在&lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;PackedSequence&lt;/code&gt; &lt;/a&gt;类以及在PyTorch中构造一个 &lt;code&gt;:class:PackedSequence&lt;/code&gt; 的所有函数中保持（即，它们仅传递符合此约束的张量）。</target>
        </trans-unit>
        <trans-unit id="0dcba97fb0267a928459453464ca8f56762a0535" translate="yes" xml:space="preserve">
          <source>This is TorchScript&amp;rsquo;s compilation of the code for the &lt;code&gt;forward&lt;/code&gt; method. You can use this to ensure TorchScript (tracing or scripting) has captured your model code correctly.</source>
          <target state="translated">这是TorchScript对 &lt;code&gt;forward&lt;/code&gt; 方法的代码的编译。您可以使用它来确保TorchScript（跟踪或脚本编制）正确捕获了模型代码。</target>
        </trans-unit>
        <trans-unit id="78aa499d132d9b73782bab5e2924798d784eafb1" translate="yes" xml:space="preserve">
          <source>This is a &lt;strong&gt;Prototype&lt;/strong&gt; function.</source>
          <target state="translated">这是一个&lt;strong&gt;原型&lt;/strong&gt;功能。</target>
        </trans-unit>
        <trans-unit id="554d0b95763033953c158f9820e38365e62ff2d9" translate="yes" xml:space="preserve">
          <source>This is a generalized version of &lt;a href=&quot;torch.hann_window#torch.hann_window&quot;&gt;&lt;code&gt;torch.hann_window()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;torch.hann_window#torch.hann_window&quot;&gt; &lt;code&gt;torch.hann_window()&lt;/code&gt; &lt;/a&gt;的通用版本。</target>
        </trans-unit>
        <trans-unit id="27da13545c38e0ad916bfb253add6c85dbfec69d" translate="yes" xml:space="preserve">
          <source>This is a low-level function for calling LAPACK directly.</source>
          <target state="translated">这是一个直接调用LAPACK的低级函数。</target>
        </trans-unit>
        <trans-unit id="baa9ff1557d00c12989b3535b16426973504c66e" translate="yes" xml:space="preserve">
          <source>This is a low-level function for calling LAPACK directly. This function returns a namedtuple (a, tau) as defined in &lt;a href=&quot;https://software.intel.com/en-us/node/521004&quot;&gt;LAPACK documentation for geqrf&lt;/a&gt; .</source>
          <target state="translated">这是用于直接调用LAPACK的底层函数。此函数返回&lt;a href=&quot;https://software.intel.com/en-us/node/521004&quot;&gt;LAPACK文档中为geqrf&lt;/a&gt;定义的namedtuple（a，tau）。</target>
        </trans-unit>
        <trans-unit id="bed0909b657a7fcd560ee9c527be9120da241148" translate="yes" xml:space="preserve">
          <source>This is a low-level method. The storage is reinterpreted as C-contiguous, ignoring the current strides (unless the target size equals the current size, in which case the tensor is left unchanged). For most purposes, you will instead want to use &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;view()&lt;/code&gt;&lt;/a&gt;, which checks for contiguity, or &lt;a href=&quot;#torch.Tensor.reshape&quot;&gt;&lt;code&gt;reshape()&lt;/code&gt;&lt;/a&gt;, which copies data if needed. To change the size in-place with custom strides, see &lt;a href=&quot;#torch.Tensor.set_&quot;&gt;&lt;code&gt;set_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是一种低级方法。将存储重新解释为C连续的，而忽略当前步幅（除非目标大小等于当前大小，在这种情况下，张量保持不变）。对于大多数目的，您将改为使用&lt;a href=&quot;#torch.Tensor.view&quot;&gt; &lt;code&gt;view()&lt;/code&gt; &lt;/a&gt;（用于检查连续性）或&lt;a href=&quot;#torch.Tensor.reshape&quot;&gt; &lt;code&gt;reshape()&lt;/code&gt; (&lt;/a&gt;如果需要）来复制数据。要使用自定义步幅就地更改大小，请参见&lt;a href=&quot;#torch.Tensor.set_&quot;&gt; &lt;code&gt;set_()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f3b5e88eb67e346fdbdf0577eada21e1b383ed17" translate="yes" xml:space="preserve">
          <source>This is a no-op for storages already in shared memory and for CUDA storages, which do not need to be moved for sharing across processes. Storages in shared memory cannot be resized.</source>
          <target state="translated">对于已经在共享内存中的存储空间和CUDA存储空间来说,这是一个不需要移动以实现跨进程共享的操作。共享内存中的存储空间不能调整大小。</target>
        </trans-unit>
        <trans-unit id="f5b9f918ec25aa03605059dcc957950d2df96994" translate="yes" xml:space="preserve">
          <source>This is a no-op if the tensor is already of the correct type. This is equivalent to &lt;code&gt;self.type(tensor.type())&lt;/code&gt;</source>
          <target state="translated">如果张量已经是正确的类型，则这是无操作的。这等效于 &lt;code&gt;self.type(tensor.type())&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="be9417a8a097120c57731208ecd0b2e0d9e0a45b" translate="yes" xml:space="preserve">
          <source>This is a no-op if the underlying storage is already in shared memory and for CUDA tensors. Tensors in shared memory cannot be resized.</source>
          <target state="translated">如果底层存储已经在共享内存中,并且对于CUDA tensors来说,这是一个无操作。共享内存中的时标不能调整大小。</target>
        </trans-unit>
        <trans-unit id="584f2eb806dc59e0bb28f52080bdd509e138734b" translate="yes" xml:space="preserve">
          <source>This is a sequential container which calls the Conv 1d and Batch Norm 1d modules. During quantization this will be replaced with the corresponding fused module.</source>
          <target state="translated">这是一个顺序容器,它调用Conv 1d和Batch Norm 1d模块。在量化过程中,它将被相应的融合模块所取代。</target>
        </trans-unit>
        <trans-unit id="3187ce0a4f646a0f02690921fbe6d7114d95c7e3" translate="yes" xml:space="preserve">
          <source>This is a sequential container which calls the Conv 1d and ReLU modules. During quantization this will be replaced with the corresponding fused module.</source>
          <target state="translated">这是一个顺序容器,它调用Conv 1d和ReLU模块。在量化过程中,它将被相应的融合模块所取代。</target>
        </trans-unit>
        <trans-unit id="3a2d1424088d04fbdd7c029c2c5a864c5f132531" translate="yes" xml:space="preserve">
          <source>This is a sequential container which calls the Conv 1d, Batch Norm 1d, and ReLU modules. During quantization this will be replaced with the corresponding fused module.</source>
          <target state="translated">这是一个顺序容器,它调用Conv 1d、Batch Norm 1d和ReLU模块。在量化过程中,它将被相应的融合模块所取代。</target>
        </trans-unit>
        <trans-unit id="ee8eabed86139ec26051c16d9d19973c0fd6b09c" translate="yes" xml:space="preserve">
          <source>This is a sequential container which calls the Conv 2d and Batch Norm 2d modules. During quantization this will be replaced with the corresponding fused module.</source>
          <target state="translated">这是一个顺序容器,它调用Conv 2d和Batch Norm 2d模块。在量化过程中,它将被相应的融合模块所取代。</target>
        </trans-unit>
        <trans-unit id="12efc861b006501b2b4700d386ad4f25b9ff0f7e" translate="yes" xml:space="preserve">
          <source>This is a sequential container which calls the Conv 2d and ReLU modules. During quantization this will be replaced with the corresponding fused module.</source>
          <target state="translated">这是一个顺序容器,它调用Conv 2d和ReLU模块。在量化过程中,它将被相应的融合模块所取代。</target>
        </trans-unit>
        <trans-unit id="98a705e3678fe480b570b51f1f965a2f3d037e83" translate="yes" xml:space="preserve">
          <source>This is a sequential container which calls the Conv 2d, Batch Norm 2d, and ReLU modules. During quantization this will be replaced with the corresponding fused module.</source>
          <target state="translated">这是一个顺序容器,它调用Conv 2d、Batch Norm 2d和ReLU模块。在量化过程中,它将被相应的融合模块所取代。</target>
        </trans-unit>
        <trans-unit id="01f4b9cc31c6559249deff015369111df9aa6f57" translate="yes" xml:space="preserve">
          <source>This is a simplified version supported by most optimizers. The function can be called once the gradients are computed using e.g. &lt;code&gt;backward()&lt;/code&gt;.</source>
          <target state="translated">这是大多数优化程序支持的简化版本。一旦使用例如 &lt;code&gt;backward()&lt;/code&gt; 计算了梯度，就可以调用该函数。</target>
        </trans-unit>
        <trans-unit id="fd838137a8dd7616f8151e3b75e72da4794d6fa0" translate="yes" xml:space="preserve">
          <source>This is a variant of &lt;a href=&quot;generated/torch.quantile#torch.quantile&quot;&gt;&lt;code&gt;torch.quantile()&lt;/code&gt;&lt;/a&gt; that &amp;ldquo;ignores&amp;rdquo; &lt;code&gt;NaN&lt;/code&gt; values, computing the quantiles &lt;code&gt;q&lt;/code&gt; as if &lt;code&gt;NaN&lt;/code&gt; values in &lt;code&gt;input&lt;/code&gt; did not exist.</source>
          <target state="translated">这是&lt;a href=&quot;generated/torch.quantile#torch.quantile&quot;&gt; &lt;code&gt;torch.quantile()&lt;/code&gt; &lt;/a&gt;的变体，&amp;ldquo;忽略&amp;rdquo; &lt;code&gt;NaN&lt;/code&gt; 值，计算分位数 &lt;code&gt;q&lt;/code&gt; 就像 &lt;code&gt;input&lt;/code&gt; &lt;code&gt;NaN&lt;/code&gt; 值不存在一样。</target>
        </trans-unit>
        <trans-unit id="57134b77fa81442b10e02b41eaf3243756f7f5ee" translate="yes" xml:space="preserve">
          <source>This is a variant of &lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt;&lt;code&gt;torch.quantile()&lt;/code&gt;&lt;/a&gt; that &amp;ldquo;ignores&amp;rdquo; &lt;code&gt;NaN&lt;/code&gt; values, computing the quantiles &lt;code&gt;q&lt;/code&gt; as if &lt;code&gt;NaN&lt;/code&gt; values in &lt;code&gt;input&lt;/code&gt; did not exist. If all values in a reduced row are &lt;code&gt;NaN&lt;/code&gt; then the quantiles for that reduction will be &lt;code&gt;NaN&lt;/code&gt;. See the documentation for &lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt;&lt;code&gt;torch.quantile()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是&lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt; &lt;code&gt;torch.quantile()&lt;/code&gt; &lt;/a&gt;的变体，&amp;ldquo;忽略&amp;rdquo; &lt;code&gt;NaN&lt;/code&gt; 值，计算分位数 &lt;code&gt;q&lt;/code&gt; 就像 &lt;code&gt;input&lt;/code&gt; &lt;code&gt;NaN&lt;/code&gt; 值不存在一样。如果归约行中的所有值均为 &lt;code&gt;NaN&lt;/code&gt; ,则该归约的分位数将为 &lt;code&gt;NaN&lt;/code&gt; 。请参阅&lt;a href=&quot;torch.quantile#torch.quantile&quot;&gt; &lt;code&gt;torch.quantile()&lt;/code&gt; &lt;/a&gt;的文档。</target>
        </trans-unit>
        <trans-unit id="ae0e7bea21fe5aaecb615e30a54297c8a770a6eb" translate="yes" xml:space="preserve">
          <source>This is a very memory intensive optimizer (it requires additional &lt;code&gt;param_bytes * (history_size + 1)&lt;/code&gt; bytes). If it doesn&amp;rsquo;t fit in memory try reducing the history size, or use a different algorithm.</source>
          <target state="translated">这是一个非常占用内存的优化器（它需要额外的 &lt;code&gt;param_bytes * (history_size + 1)&lt;/code&gt; 字节）。如果它不适合内存，请尝试减小历史记录大小，或使用其他算法。</target>
        </trans-unit>
        <trans-unit id="994f42290c63351a1c873f9744cae43cb48288cc" translate="yes" xml:space="preserve">
          <source>This is a wrapper around &lt;code&gt;cudaEventSynchronize()&lt;/code&gt;: see &lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html&quot;&gt;CUDA Event documentation&lt;/a&gt; for more info.</source>
          <target state="translated">这是 &lt;code&gt;cudaEventSynchronize()&lt;/code&gt; 的包装：有关更多信息，请参见&lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html&quot;&gt;CUDA事件文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2d81e1e16ab1c2e5ec9a42a6d43cc837303bcaf0" translate="yes" xml:space="preserve">
          <source>This is a wrapper around &lt;code&gt;cudaStreamSynchronize()&lt;/code&gt;: see &lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html&quot;&gt;CUDA Stream documentation&lt;/a&gt; for more info.</source>
          <target state="translated">这是 &lt;code&gt;cudaStreamSynchronize()&lt;/code&gt; 的包装：有关更多信息，请参见&lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html&quot;&gt;CUDA Stream文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="13f3d83bdd2dfc81633c08aeb7934d3136f118c5" translate="yes" xml:space="preserve">
          <source>This is a wrapper around &lt;code&gt;cudaStreamWaitEvent()&lt;/code&gt;: see &lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html&quot;&gt;CUDA Stream documentation&lt;/a&gt; for more info.</source>
          <target state="translated">这是 &lt;code&gt;cudaStreamWaitEvent()&lt;/code&gt; 的包装：有关更多信息，请参见&lt;a href=&quot;https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html&quot;&gt;CUDA Stream文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="55c07d098e34194632b960dfc4bd298727835fac" translate="yes" xml:space="preserve">
          <source>This is always &lt;code&gt;True&lt;/code&gt; for CUDA tensors.</source>
          <target state="translated">这始终是 &lt;code&gt;True&lt;/code&gt; 的CUDA张量。</target>
        </trans-unit>
        <trans-unit id="afdc3cee342017a6e1562fe587b2298feb148739" translate="yes" xml:space="preserve">
          <source>This is bijective and appropriate for use in HMC; however it mixes coordinates together and is less appropriate for optimization.</source>
          <target state="translated">这是双目性的,适合在HMC中使用,但是它把坐标混在一起,不太适合优化。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
