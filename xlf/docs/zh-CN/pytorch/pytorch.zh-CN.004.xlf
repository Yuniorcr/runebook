<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="797ae6ccf0f3fa0fcbeb9b7b388baedb5b006fbf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Distributed Autograd&lt;/strong&gt; stitches together local autograd engines on all the workers involved in the forward pass, and automatically reach out to them during the backward pass to compute gradients. This is especially helpful if the forward pass needs to span multiple machines when conducting, e.g., distributed model parallel training, parameter-server training, etc. With this feature, user code no longer needs to worry about how to send gradients across RPC boundaries and in which order should the local autograd engines be launched, which can become quite complicated where there are nested and inter-dependent RPC calls in the forward pass.</source>
          <target state="translated">&lt;strong&gt;分布式Autograd&lt;/strong&gt;将在前进过程中涉及的所有工作人员上的本地autograd引擎缝合在一起，并在后退过程中自动与他们联系以计算梯度。如果正向传递在进行时需要跨越多台机器，例如分布式模型并行训练，参数服务器训练等，则这特别有用。借助此功能，用户代码不再需要担心如何跨RPC边界发送梯度和按照哪种顺序启动本地autograd引擎，如果在向前传递中存在嵌套且相互依赖的RPC调用，则可能会变得非常复杂。</target>
        </trans-unit>
        <trans-unit id="1bb7e35d8fadfa0ec492eaeee55b03e9a384fe57" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Distributed Optimizer&lt;/strong&gt;&amp;rsquo;s constructor takes a &lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer()&lt;/code&gt;&lt;/a&gt; (e.g., &lt;a href=&quot;optim#torch.optim.SGD&quot;&gt;&lt;code&gt;SGD()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;optim#torch.optim.Adagrad&quot;&gt;&lt;code&gt;Adagrad()&lt;/code&gt;&lt;/a&gt;, etc.) and a list of parameter RRefs, creates an &lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer()&lt;/code&gt;&lt;/a&gt; instance on each distinct RRef owner, and updates parameters accordingly when running &lt;code&gt;step()&lt;/code&gt;. When you have distributed forward and backward passes, parameters and gradients will be scattered across multiple workers, and hence it requires an optimizer on each of the involved workers. Distributed Optimizer wraps all those local optimizers into one, and provides a concise constructor and &lt;code&gt;step()&lt;/code&gt; API.</source>
          <target state="translated">&lt;strong&gt;分布式优化程序&lt;/strong&gt;的构造函数采用&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt; &lt;code&gt;Optimizer()&lt;/code&gt; &lt;/a&gt;（例如&lt;a href=&quot;optim#torch.optim.SGD&quot;&gt; &lt;code&gt;SGD()&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;optim#torch.optim.Adagrad&quot;&gt; &lt;code&gt;Adagrad()&lt;/code&gt; &lt;/a&gt;等）和参数RRef列表，在每个不同的RRef所有者上创建&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt; &lt;code&gt;Optimizer()&lt;/code&gt; &lt;/a&gt;实例，并在运行 &lt;code&gt;step()&lt;/code&gt; 时相应地更新参数（）。当您分配了前向和后向遍历时，参数和渐变将分散在多个工作程序中，因此需要对每个涉及的工作程序进行优化。分布式优化器将所有这些本地优化器包装为一个，并提供了简洁的构造函数和 &lt;code&gt;step()&lt;/code&gt; API。</target>
        </trans-unit>
        <trans-unit id="4f231e46f6260f0b30e89ac8d9edeea3e85af0b5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Double-backward&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;Double-backward&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="2d5f8bc4ac56cfd97f97d119eb653f063ce9a8c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Dropout removal&lt;/strong&gt; (blacklisting option &lt;code&gt;MobileOptimizerType::REMOVE_DROPOUT&lt;/code&gt;): This optimization pass removes &lt;code&gt;dropout&lt;/code&gt; and &lt;code&gt;dropout_&lt;/code&gt; nodes from this module when training is false.</source>
          <target state="translated">&lt;strong&gt;降去除&lt;/strong&gt;（黑名单选项 &lt;code&gt;MobileOptimizerType::REMOVE_DROPOUT&lt;/code&gt; ）：这个优化过程去除 &lt;code&gt;dropout&lt;/code&gt; 和 &lt;code&gt;dropout_&lt;/code&gt; 从该模块节点时，培训是假的。</target>
        </trans-unit>
        <trans-unit id="223393d322f23e3fe61df9bd2a6b6a80c0693ded" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Forward-backward correlation&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;前后相关&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="c3e372f6656879627d1504382a4b7846f22e788b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;GLOO_SOCKET_IFNAME&lt;/strong&gt;, for example &lt;code&gt;export GLOO_SOCKET_IFNAME=eth0&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;GLOO_SOCKET_IFNAME&lt;/strong&gt;，例如， &lt;code&gt;export GLOO_SOCKET_IFNAME=eth0&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1f6592a881a64ce2fc84fda7388b35a82d8e09ea" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;How to use this module:&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;如何使用此模块：&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="1f89fecb44ae27dd51a780204df3a0f0d43ccc86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Important Notices:&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;重要告示：&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="a9e3d7be29b190f07aadef5e37d2c8e47444424a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Important&lt;/strong&gt;: In contrast to the other models the inception_v3 expects tensors with a size of N x 3 x 299 x 299, so ensure your images are sized accordingly.</source>
          <target state="translated">&lt;strong&gt;重要说明&lt;/strong&gt;：与其他模型相比，inception_v3期望张量的大小为N x 3 x 299 x 299，因此请确保对图像进行相应调整。</target>
        </trans-unit>
        <trans-unit id="1df66398ad89ce8863dff1901f021a972d0a77b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Insert and Fold prepacked ops&lt;/strong&gt; (blacklisting option &lt;code&gt;MobileOptimizerType::INSERT_FOLD_PREPACK_OPS&lt;/code&gt;): This optimization pass rewrites the graph to replace 2D convolutions and linear ops with their prepacked counterparts. Prepacked ops are stateful ops in that, they require some state to be created, such as weight prepacking and use this state, i.e. prepacked weights, during op execution. XNNPACK is one such backend that provides prepacked ops, with kernels optimized for mobile platforms (such as ARM CPUs). Prepacking of weight enables efficient memory access and thus faster kernel execution. At the moment &lt;code&gt;optimize_for_mobile&lt;/code&gt; pass rewrites the graph to replace &lt;code&gt;Conv2D/Linear&lt;/code&gt; with 1) op that pre-packs weight for XNNPACK conv2d/linear ops and 2) op that takes pre-packed weight and activation as input and generates output activations. Since 1 needs to be done only once, we fold the weight pre-packing such that it is done only once at model load time. This pass of the &lt;code&gt;optimize_for_mobile&lt;/code&gt; does 1 and 2 and then folds, i.e. removes, weight pre-packing ops.</source>
          <target state="translated">&lt;strong&gt;插入和折叠预&lt;/strong&gt; &lt;code&gt;MobileOptimizerType::INSERT_FOLD_PREPACK_OPS&lt;/code&gt; &lt;strong&gt;操作&lt;/strong&gt;（黑名单选项MobileOptimizerType :: INSERT_FOLD_PREPACK_OPS）：此优化过程将图形重写为将二维卷积和线性操作替换为其预打包的对象。预包装操作是有状态操作，因为它们需要创建一些状态，例如重量预包装，并在操作执行期间使用此状态，即预包装重量。XNNPACK就是这样一种后端，它提供了预打包的操作，并为移动平台（例如ARM CPU）优化了内核。预先打包权重可实现有效的内存访问，从而加快内核执行速度。目前， &lt;code&gt;optimize_for_mobile&lt;/code&gt; 传递重写了图形以替换 &lt;code&gt;Conv2D/Linear&lt;/code&gt; 1）为XNNPACK conv2d / linear ops预包装重量的op和2）将预包装重量和激活作为输入并生成输出激活的op。由于1仅需要执行一次，因此我们将权重预包装折叠起来，以便在模型加载时仅执行一次。此所述的通 &lt;code&gt;optimize_for_mobile&lt;/code&gt; 确实1和2，然后折叠，即移除了，重量预包装OPS。</target>
        </trans-unit>
        <trans-unit id="c203022c4b7e41a789c0850a218035678246aafc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the packed LU factorization data</source>
          <target state="translated">&lt;strong&gt;LU_data&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;打包的LU分解数据</target>
        </trans-unit>
        <trans-unit id="b68de83e526debfd8f4bba73fb2af28a093a044c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the pivoted LU factorization of A from &lt;a href=&quot;torch.lu#torch.lu&quot;&gt;&lt;code&gt;torch.lu()&lt;/code&gt;&lt;/a&gt; of size</source>
          <target state="translated">&lt;strong&gt;LU_data&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;从大小为&lt;a href=&quot;torch.lu#torch.lu&quot;&gt; &lt;code&gt;torch.lu()&lt;/code&gt; &lt;/a&gt;的A的透视LU分解</target>
        </trans-unit>
        <trans-unit id="6c5a7f1d3cffe65ae015e850f4296ab899102cff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_pivots&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the packed LU factorization pivots</source>
          <target state="translated">&lt;strong&gt;LU_pivots&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;打包的LU分解枢轴</target>
        </trans-unit>
        <trans-unit id="8f3d2fa0664b850596925f91912a8226903a5e6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;LU_pivots&lt;/strong&gt; (&lt;em&gt;IntTensor&lt;/em&gt;) &amp;ndash; the pivots of the LU factorization from &lt;a href=&quot;torch.lu#torch.lu&quot;&gt;&lt;code&gt;torch.lu()&lt;/code&gt;&lt;/a&gt; of size</source>
          <target state="translated">&lt;strong&gt;LU_pivots&lt;/strong&gt;（&lt;em&gt;IntTensor&lt;/em&gt;）&amp;ndash;来自大小为&lt;a href=&quot;torch.lu#torch.lu&quot;&gt; &lt;code&gt;torch.lu()&lt;/code&gt; &lt;/a&gt;的LU分解的枢轴</target>
        </trans-unit>
        <trans-unit id="cde0f3c0abde6143690d2cb7605d91fbcc4fe6ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;N&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Number of columns in the output. If N is not specified, a square array is returned</source>
          <target state="translated">&lt;strong&gt;N&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输出中的列数。如果未指定N，则返回一个正方形数组</target>
        </trans-unit>
        <trans-unit id="04a56de9a19a514a1fcf10373351c67efd1b49d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;NCCL_SOCKET_IFNAME&lt;/strong&gt;, for example &lt;code&gt;export NCCL_SOCKET_IFNAME=eth0&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;NCCL_SOCKET_IFNAME&lt;/strong&gt;，例如， &lt;code&gt;export NCCL_SOCKET_IFNAME=eth0&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ec5bc033e1610e4a75f2543da0a843e4cbbadc81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Note&lt;/strong&gt; &amp;ndash; if kdim and vdim are None, they will be set to embed_dim such that</source>
          <target state="translated">&lt;strong&gt;注&lt;/strong&gt;&amp;ndash;如果kdim和vdim为None，则将它们设置为embed_dim，以便</target>
        </trans-unit>
        <trans-unit id="576aa905938e327a5ed4b8fede98a6c9f70e96e9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Propagate names&lt;/strong&gt;: &lt;em&gt;unify&lt;/em&gt; the names to select which one to propagate. In the case of &lt;code&gt;x + y&lt;/code&gt;, &lt;code&gt;unify('X', None) = 'X'&lt;/code&gt; because &lt;code&gt;'X'&lt;/code&gt; is more specific than &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;传播名称&lt;/strong&gt;：&lt;em&gt;统一&lt;/em&gt;名称以选择要传播的名称。在 &lt;code&gt;x + y&lt;/code&gt; 的情况下， &lt;code&gt;unify('X', None) = 'X'&lt;/code&gt; 因为 &lt;code&gt;'X'&lt;/code&gt; 比 &lt;code&gt;None&lt;/code&gt; 更具体。</target>
        </trans-unit>
        <trans-unit id="5ee6ef9bb908af00d480a75de89ef5668a859963" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Propagate names&lt;/strong&gt;: name inference propagates names to output tensors.</source>
          <target state="translated">&lt;strong&gt;传播名称&lt;/strong&gt;：名称推断将名称传播到输出张量。</target>
        </trans-unit>
        <trans-unit id="af407aa1e4067bd772f2d564ff50863c94343551" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;QR&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the details of the QR factorization</source>
          <target state="translated">&lt;strong&gt;QR&lt;/strong&gt;（&lt;em&gt;Tensor&lt;/em&gt;）：QR因式分解的详细信息</target>
        </trans-unit>
        <trans-unit id="6af63ab37345973eb43a4a5fd4d33de8547a1e3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ReLU/Hardtanh fusion&lt;/strong&gt;: XNNPACK ops support fusion of clamping. That is clamping of output activation is done as part of the kernel, including for 2D convolution and linear op kernels. Thus clamping effectively comes for free. Thus any op that can be expressed as clamping op, such as &lt;code&gt;ReLU&lt;/code&gt; or &lt;code&gt;hardtanh&lt;/code&gt;, can be fused with previous &lt;code&gt;Conv2D&lt;/code&gt; or &lt;code&gt;linear&lt;/code&gt; op in XNNPACK. This pass rewrites graph by finding &lt;code&gt;ReLU/hardtanh&lt;/code&gt; ops that follow XNNPACK &lt;code&gt;Conv2D/linear&lt;/code&gt; ops, written by the previous pass, and fuses them together.</source>
          <target state="translated">&lt;strong&gt;ReLU / Hardtanh融合&lt;/strong&gt;：XNNPACK操作支持夹持融合。也就是说，将输出激活的限制作为内核的一部分来完成，包括用于2D卷积和线性op内核。因此，有效的夹紧是免费的。因此，可以将表示为钳位操作的任何操作（例如 &lt;code&gt;ReLU&lt;/code&gt; 或 &lt;code&gt;hardtanh&lt;/code&gt; )与以前的 &lt;code&gt;Conv2D&lt;/code&gt; 或XNNPACK中的 &lt;code&gt;linear&lt;/code&gt; 操作融合。此遍通过查找上一遍编写的，遵循XNNPACK &lt;code&gt;Conv2D/linear&lt;/code&gt; ops的 &lt;code&gt;ReLU/hardtanh&lt;/code&gt; ops来重写图形，并将它们融合在一起。</target>
        </trans-unit>
        <trans-unit id="fa93a38017c6f0838a547724d9c4d119cf4afed6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Remote Procedure Call (RPC)&lt;/strong&gt; supports running a function on the specified destination worker with the given arguments and getting the return value back or creating a reference to the return value. There are three main RPC APIs: &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt;&lt;code&gt;rpc_sync()&lt;/code&gt;&lt;/a&gt; (synchronous), &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; (asynchronous), and &lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt;&lt;code&gt;remote()&lt;/code&gt;&lt;/a&gt; (asynchronous and returns a reference to the remote return value). Use the synchronous API if the user code cannot proceed without the return value. Otherwise, use the asynchronous API to get a future, and wait on the future when the return value is needed on the caller. The &lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt;&lt;code&gt;remote()&lt;/code&gt;&lt;/a&gt; API is useful when the requirement is to create something remotely but never need to fetch it to the caller. Imagine the case that a driver process is setting up a parameter server and a trainer. The driver can create an embedding table on the parameter server and then share the reference to the embedding table with the trainer, but itself will never use the embedding table locally. In this case, &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt;&lt;code&gt;rpc_sync()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; are no longer appropriate, as they always imply that the return value will be returned to the caller immediately or in the future.</source>
          <target state="translated">&lt;strong&gt;远程过程调用（RPC）&lt;/strong&gt;支持使用给定的参数在指定的目标工作&lt;strong&gt;程序上&lt;/strong&gt;运行一个函数，并返回返回值或创建对返回值的引用。共有三种主要的RPC API：&lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt; &lt;code&gt;rpc_sync()&lt;/code&gt; &lt;/a&gt;（同步），&lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt;（异步）和&lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt; &lt;code&gt;remote()&lt;/code&gt; &lt;/a&gt;（异步并返回对远程返回值的引用）。如果用户代码没有返回值就无法继续，请使用同步API。否则，请使用异步API获得未来，并在调用方需要返回值时等待未来。在&lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt; &lt;code&gt;remote()&lt;/code&gt; &lt;/a&gt;当要求是远程创建某些内容而无需将其提取给调用者时，API很有用。想象一下，驱动程序正在设置参数服务器和培训师的情况。驱动程序可以在参数服务器上创建嵌入表，然后与培训师共享对该嵌入表的引用，但是驱动程序本身永远不会在本地使用该嵌入表。在这种情况下，&lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt; &lt;code&gt;rpc_sync()&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt;不再适用，因为它们始终暗示着返回值将立即或在将来返回给调用方。</target>
        </trans-unit>
        <trans-unit id="5314a5e0f78e161be1308e7f0f36425e0e43560f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Remote Reference (RRef)&lt;/strong&gt; serves as a distributed shared pointer to a local or remote object. It can be shared with other workers and reference counting will be handled transparently. Each RRef only has one owner and the object only lives on that owner. Non-owner workers holding RRefs can get copies of the object from the owner by explicitly requesting it. This is useful when a worker needs to access some data object, but itself is neither the creator (the caller of &lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt;&lt;code&gt;remote()&lt;/code&gt;&lt;/a&gt;) or the owner of the object. The distributed optimizer, as we will discuss below, is one example of such use cases.</source>
          <target state="translated">&lt;strong&gt;远程引用（RRef）&lt;/strong&gt;充当指向本地或远程对象的分布式共享指针。它可以与其他工作人员共享，并且引用计数将透明地处理。每个RRef仅具有一个所有者，并且该对象仅位于该所有者上。持有RRef的非所有者工人可以通过显式请求从所有者那里获得对象的副本。当工作人员需要访问某些数据对象但它本身既不是对象的创建者（&lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt; &lt;code&gt;remote()&lt;/code&gt; &lt;/a&gt;的调用者）也不是对象的所有者时，这很有用。我们将在下面讨论的分布式优化器就是这种用例的一个例子。</target>
        </trans-unit>
        <trans-unit id="9ac1d5992a6fca7da1c35caf72d55ee459b83fab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Same dims as t.&lt;/strong&gt; (&lt;em&gt;applied.&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;与t相同。&lt;/strong&gt;（&lt;em&gt;应用。&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="962e703212f421c013940c950f0179bcfd7e5558" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Scripting a function&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;编写函数脚本&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="8db690c93c292d8d188cd36e3aadd7bd6d0213c5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;Scripting an nn.Module&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;编写nn.Module脚本&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="5a536ecf0100c4415f783288e8b43aa79628874b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;T_0&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of iterations for the first restart.</source>
          <target state="translated">&lt;strong&gt;T_0&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;第一次重启的迭代次数。</target>
        </trans-unit>
        <trans-unit id="174b928ff160a616fa4b90bde1a707315fe9b615" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;T_max&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Maximum number of iterations.</source>
          <target state="translated">&lt;strong&gt;T_max&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;最大迭代次数。</target>
        </trans-unit>
        <trans-unit id="e89669f1c5480ecb975d25c72f6bb5f8c0ebc0ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;T_mult&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A factor increases</source>
          <target state="translated">&lt;strong&gt;T_mult&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;因素增加</target>
        </trans-unit>
        <trans-unit id="bf58a23619e37e51e3cff098624c58ed88faeae4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;This should be called at most once, and only from inside the&lt;/strong&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;strong&gt;method.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;这应该最多调用一次，并且只能从&lt;/strong&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;strong&gt;方法&lt;/strong&gt;&lt;strong&gt;内部调用&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="1a2ef395099e9fb2d32689f2611c9515a234fb1a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;This should be called at most once, only from inside the&lt;/strong&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;strong&gt;method, and all arguments should be inputs.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;仅应从&lt;/strong&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;strong&gt;方法&lt;/strong&gt;&lt;strong&gt;内部调用一次&lt;/strong&gt;&lt;strong&gt;，并且所有参数都应作为输入。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="181ffcc34f961e9cbd7992b0842b4c0ee0183d30" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;This should be called at most once, only from inside the&lt;/strong&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;strong&gt;method, and all arguments should be outputs.&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;只能从&lt;/strong&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;strong&gt;方法&lt;/strong&gt;&lt;strong&gt;内部最多调用一次&lt;/strong&gt;&lt;strong&gt;，并且所有参数都应该是输出。&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="8b1571fb48f0f1c3d3c9ec13e2345e4633b9bb38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;This should be called only from inside the&lt;/strong&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;strong&gt;method&lt;/strong&gt;</source>
          <target state="translated">&lt;strong&gt;仅应从&lt;/strong&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;strong&gt;方法&lt;/strong&gt;&lt;strong&gt;内部调用此&lt;/strong&gt;&lt;strong&gt;方法&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="7b683203185b069345fba8db122634cd0d19dfbb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When automatic batching is disabled&lt;/strong&gt;, &lt;code&gt;collate_fn&lt;/code&gt; is called with each individual data sample, and the output is yielded from the data loader iterator. In this case, the default &lt;code&gt;collate_fn&lt;/code&gt; simply converts NumPy arrays in PyTorch tensors.</source>
          <target state="translated">&lt;strong&gt;禁用自动批处理后&lt;/strong&gt;， &lt;code&gt;collate_fn&lt;/code&gt; 每个单独的数据样本调用collat​​e_fn，并从数据加载器迭代器产生输出。在这种情况下，默认的 &lt;code&gt;collate_fn&lt;/code&gt; 简单地转换PyTorch张量中的NumPy数组。</target>
        </trans-unit>
        <trans-unit id="691205dbb08fc344913e2f7b21842e73d9efda0c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When automatic batching is disabled&lt;/strong&gt;, the default &lt;code&gt;collate_fn&lt;/code&gt; simply converts NumPy arrays into PyTorch Tensors, and keeps everything else untouched.</source>
          <target state="translated">&lt;strong&gt;禁用自动批处理后&lt;/strong&gt;，默认的 &lt;code&gt;collate_fn&lt;/code&gt; 会将NumPy数组简单地转换为PyTorch张量，并使其他所有内容保持不变。</target>
        </trans-unit>
        <trans-unit id="3d858374143f1dc8a1f62310d56d15bff7dbf021" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When automatic batching is enabled&lt;/strong&gt;, &lt;code&gt;collate_fn&lt;/code&gt; is called with a list of data samples at each time. It is expected to collate the input samples into a batch for yielding from the data loader iterator. The rest of this section describes behavior of the default &lt;code&gt;collate_fn&lt;/code&gt; in this case.</source>
          <target state="translated">&lt;strong&gt;当启用自动配料&lt;/strong&gt;， &lt;code&gt;collate_fn&lt;/code&gt; 调用与各时刻的数据样本的一个列表。期望将输入样本整理为一批，以便从数据加载器迭代器中获得收益。本节的其余部分描述了这种情况下默认 &lt;code&gt;collate_fn&lt;/code&gt; 行为。</target>
        </trans-unit>
        <trans-unit id="8f1531884e296514d90d800035577a8e1accf01f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When&lt;/strong&gt;&lt;code&gt;as_tuple&lt;/code&gt;&lt;strong&gt;is ``False`` (default)&lt;/strong&gt;:</source>
          <target state="translated">&lt;strong&gt;当&lt;/strong&gt; &lt;code&gt;as_tuple&lt;/code&gt; &lt;strong&gt;为``False''（默认值）时&lt;/strong&gt;：</target>
        </trans-unit>
        <trans-unit id="5ab18d59c167aab4a342a25877738485f51a7096" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;When&lt;/strong&gt;&lt;code&gt;as_tuple&lt;/code&gt;&lt;strong&gt;is ``True``&lt;/strong&gt;:</source>
          <target state="translated">&lt;strong&gt;当&lt;/strong&gt; &lt;code&gt;as_tuple&lt;/code&gt; &lt;strong&gt;为``True``时&lt;/strong&gt;：</target>
        </trans-unit>
        <trans-unit id="e7078285e2211f504ade0f00ffd2f939c57da6bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;X&lt;/strong&gt; (&lt;em&gt;tensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the input tensor of size</source>
          <target state="translated">&lt;strong&gt;X&lt;/strong&gt;（&lt;em&gt;张量&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;大小的输入张量</target>
        </trans-unit>
        <trans-unit id="b1b67d6a132e9c963db47428cb2379e1e546861a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;_extra_files&lt;/strong&gt; &amp;ndash; Map from filename to contents which will be stored as part of &lt;code&gt;f&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;_extra_files&lt;/strong&gt; &amp;ndash;从文件名映射到将作为 &lt;code&gt;f&lt;/code&gt; 的一部分存储的内容。</target>
        </trans-unit>
        <trans-unit id="a683a25cede5c84fac0359282cc1ba91c60e4ca5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;_extra_files&lt;/strong&gt; (&lt;em&gt;dictionary of filename to content&lt;/em&gt;) &amp;ndash; The extra filenames given in the map would be loaded and their content would be stored in the provided map.</source>
          <target state="translated">&lt;strong&gt;_extra_files&lt;/strong&gt;（&lt;em&gt;文件名到内容的字典&lt;/em&gt;）&amp;ndash;地图中给定的额外文件&lt;strong&gt;名将&lt;/strong&gt;被加载，其内容将存储在提供的地图中。</target>
        </trans-unit>
        <trans-unit id="d748636c83b33f2e9575e4d3e73b87eb583016ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;_instance&lt;/strong&gt; &amp;ndash; new instance provided by subclasses that need to override &lt;code&gt;.expand&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;_instance&lt;/strong&gt; &amp;ndash;子类提供的需要重写 &lt;code&gt;.expand&lt;/code&gt; 的新实例。</target>
        </trans-unit>
        <trans-unit id="9e611d50a4e099f661790454d298a621c6db3772" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;a&lt;/strong&gt; &amp;ndash; the lower bound of the uniform distribution</source>
          <target state="translated">&lt;strong&gt;a&lt;/strong&gt; &amp;ndash;均匀分布的下限</target>
        </trans-unit>
        <trans-unit id="6d6b643d3bc99d8356ba238e8f3bc442ddc42326" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;a&lt;/strong&gt; &amp;ndash; the negative slope of the rectifier used after this layer (only used with &lt;code&gt;'leaky_relu'&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;a&lt;/strong&gt; &amp;ndash;在该层之后使用的整流器的负斜率（仅与 &lt;code&gt;'leaky_relu'&lt;/code&gt; 一起使用）</target>
        </trans-unit>
        <trans-unit id="13e08f7f03b31160851ef342f7107a5a0a61cecd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;a&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Left tensor to contract</source>
          <target state="translated">&lt;strong&gt;a&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;左张量收缩</target>
        </trans-unit>
        <trans-unit id="c8973a7f97fc0beb9adb7e234c6f186d1a27f19c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;abbreviated&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to return an abbreviated summary (default: False).</source>
          <target state="translated">&lt;strong&gt;缩写&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;是否返回缩写摘要（默认：False）。</target>
        </trans-unit>
        <trans-unit id="48c6d9a7b5991de5ceb0f2f0002b9b581b68e5fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;abs&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The absolute value the complex tensor. Must be float or double.</source>
          <target state="translated">&lt;strong&gt;abs&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;复数张量的绝对值。必须为float或double。</target>
        </trans-unit>
        <trans-unit id="769675c7e81eef43f6366734f82732784d9c6c35" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;accumulate&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to accumulate into self</source>
          <target state="translated">&lt;strong&gt;积累&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔&lt;/a&gt;）&amp;ndash;是否积累到自我中</target>
        </trans-unit>
        <trans-unit id="06c11a2977c3992817e33b18690cf09337f0cacb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;activation&lt;/strong&gt; &amp;ndash; the activation function of encoder/decoder intermediate layer, relu or gelu (default=relu).</source>
          <target state="translated">&lt;strong&gt;激活&lt;/strong&gt;&amp;ndash;编码器/解码器中间层，relu或gelu（默认值= relu）的激活功能。</target>
        </trans-unit>
        <trans-unit id="923b9fe69988df8bf8cfd3d90e121105f87077db" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;activation&lt;/strong&gt; &amp;ndash; the activation function of intermediate layer, relu or gelu (default=relu).</source>
          <target state="translated">&lt;strong&gt;激活&lt;/strong&gt;&amp;ndash;中间层，relu或gelu的激活功能（默认值= relu）。</target>
        </trans-unit>
        <trans-unit id="761a00d8ce0801730293c2567fab0839a725bb91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;add_bias_kv&lt;/strong&gt; &amp;ndash; add bias to the key and value sequences at dim=0.</source>
          <target state="translated">&lt;strong&gt;add_bias_kv&lt;/strong&gt; &amp;ndash;在dim = 0处向键和值序列添加偏差。</target>
        </trans-unit>
        <trans-unit id="9907f733a01182c1fbfd28915afc66890b30f3df" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;add_zero_attn&lt;/strong&gt; &amp;ndash; add a new batch of zeros to the key and value sequences at dim=1.</source>
          <target state="translated">&lt;strong&gt;add_zero_attn&lt;/strong&gt; &amp;ndash;在dim = 1处将新的零批次添加到键和值序列中。</target>
        </trans-unit>
        <trans-unit id="25e60582f1deda7c8462bf51f20fc8de0b64b938" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable affine parameters, initialized the same way as done for batch normalization. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;仿射&lt;/strong&gt;&amp;ndash;一个布尔值，当设置为 &lt;code&gt;True&lt;/code&gt; 时，此模块具有可学习的仿射参数，其初始化方式与批量标准化相同。默认值： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4c8473b78a9df928d3a9e2a5c428e31960781087" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable affine parameters. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;仿射&lt;/strong&gt;&amp;ndash;一个布尔值，当设置为 &lt;code&gt;True&lt;/code&gt; 时，此模块具有可学习的仿射参数。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="643d4c7ac1c81e9da7cfa09a73aadce98fb242af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable per-channel affine parameters initialized to ones (for weights) and zeros (for biases). Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;仿射&lt;/strong&gt;&amp;ndash;一个布尔值，当设置为 &lt;code&gt;True&lt;/code&gt; 时，此模块具有可学习的每通道仿射参数，它们初始化为1（用于权重）和零（用于偏倚）。默认值： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="559454a2b31e0657d70c2b51eea7f95541808926" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Geometrically, we consider the pixels of the input and output as squares rather than points. If set to &lt;code&gt;True&lt;/code&gt;, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to &lt;code&gt;False&lt;/code&gt;, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation &lt;em&gt;independent&lt;/em&gt; of input size when &lt;code&gt;scale_factor&lt;/code&gt; is kept the same. This only has an effect when &lt;code&gt;mode&lt;/code&gt; is &lt;code&gt;'bilinear'&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;align_corners&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;在几何上，我们将输入和输出的像素视为正方形而不是点。如果设置为 &lt;code&gt;True&lt;/code&gt; ，则输入和输出张量将通过其角点像素的中心点对齐，并保留角点像素处的值。如果设置为 &lt;code&gt;False&lt;/code&gt; ，则输入和输出张量将按其角像素的角点对齐，并且插值对边界值使用边缘值填充，当 &lt;code&gt;scale_factor&lt;/code&gt; 保持相同时，使此操作&lt;em&gt;独立&lt;/em&gt;于输入大小。这仅在 &lt;code&gt;mode&lt;/code&gt; 为 &lt;code&gt;'bilinear'&lt;/code&gt; 时才有效。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="36cb44cb5ed893a7388ab1e5bafec71dbcb4bf49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Geometrically, we consider the pixels of the input and output as squares rather than points. If set to &lt;code&gt;True&lt;/code&gt;, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to &lt;code&gt;False&lt;/code&gt;, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation &lt;em&gt;independent&lt;/em&gt; of input size when &lt;code&gt;scale_factor&lt;/code&gt; is kept the same. This only has an effect when &lt;code&gt;mode&lt;/code&gt; is &lt;code&gt;'linear'&lt;/code&gt;, &lt;code&gt;'bilinear'&lt;/code&gt;, &lt;code&gt;'bicubic'&lt;/code&gt; or &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;align_corners&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;在几何上，我们将输入和输出的像素视为正方形而不是点。如果设置为 &lt;code&gt;True&lt;/code&gt; ，则输入和输出张量将通过其角点像素的中心点对齐，并保留角点像素处的值。如果设置为 &lt;code&gt;False&lt;/code&gt; ，则输入和输出张量将按其角像素的角点对齐，并且插值对边界值使用边缘值填充，当 &lt;code&gt;scale_factor&lt;/code&gt; 保持相同时，使此操作&lt;em&gt;独立&lt;/em&gt;于输入大小。这仅在 &lt;code&gt;mode&lt;/code&gt; 为 &lt;code&gt;'linear'&lt;/code&gt; ， &lt;code&gt;'bilinear'&lt;/code&gt; ， &lt;code&gt;'bicubic'&lt;/code&gt; 或 &lt;code&gt;'trilinear'&lt;/code&gt; 。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9cfac0e91a78176be96ddc6ef793ea60d709b2eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Geometrically, we consider the pixels of the input as squares rather than points. If set to &lt;code&gt;True&lt;/code&gt;, the extrema (&lt;code&gt;-1&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;) are considered as referring to the center points of the input&amp;rsquo;s corner pixels. If set to &lt;code&gt;False&lt;/code&gt;, they are instead considered as referring to the corner points of the input&amp;rsquo;s corner pixels, making the sampling more resolution agnostic. This option parallels the &lt;code&gt;align_corners&lt;/code&gt; option in &lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;interpolate()&lt;/code&gt;&lt;/a&gt;, and so whichever option is used here should also be used there to resize the input image before grid sampling. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;align_corners&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;在几何上，我们将输入的像素视为正方形而不是点。如果设置为 &lt;code&gt;True&lt;/code&gt; ，则极值（ &lt;code&gt;-1&lt;/code&gt; 和 &lt;code&gt;1&lt;/code&gt; ）被认为是参考输入角像素的中心点。如果将其设置为 &lt;code&gt;False&lt;/code&gt; ，则它们将被视为引用输入的角像素的角点，从而使采样与分辨率无关。此选项平行于 &lt;code&gt;align_corners&lt;/code&gt; 的选项&lt;a href=&quot;#torch.nn.functional.interpolate&quot;&gt; &lt;code&gt;interpolate()&lt;/code&gt; &lt;/a&gt;，所以任何可以用在这里也应采用有网格取样之前，调整输入图像。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="18bc31d486c6b3f3dc8b60be043591c427b7d925" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, consider &lt;code&gt;-1&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; to refer to the centers of the corner pixels rather than the image corners. Refer to &lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt;&lt;code&gt;grid_sample()&lt;/code&gt;&lt;/a&gt; for a more complete description. A grid generated by &lt;a href=&quot;#torch.nn.functional.affine_grid&quot;&gt;&lt;code&gt;affine_grid()&lt;/code&gt;&lt;/a&gt; should be passed to &lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt;&lt;code&gt;grid_sample()&lt;/code&gt;&lt;/a&gt; with the same setting for this option. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;align_corners&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则考虑 &lt;code&gt;-1&lt;/code&gt; 和 &lt;code&gt;1&lt;/code&gt; 指的是角点像素的中心，而不是图像角点。有关更完整的描述，请参考&lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt; &lt;code&gt;grid_sample()&lt;/code&gt; &lt;/a&gt;。由&lt;a href=&quot;#torch.nn.functional.affine_grid&quot;&gt; &lt;code&gt;affine_grid()&lt;/code&gt; &lt;/a&gt;生成的网格应使用与此选项相同的设置传递到&lt;a href=&quot;#torch.nn.functional.grid_sample&quot;&gt; &lt;code&gt;grid_sample()&lt;/code&gt; &lt;/a&gt;。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b7e8f77490dec1d2b29fdbb675f0df9b2418c385" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;align_corners&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the corner pixels of the input and output tensors are aligned, and thus preserving the values at those pixels. This only has effect when &lt;code&gt;mode&lt;/code&gt; is &lt;code&gt;'linear'&lt;/code&gt;, &lt;code&gt;'bilinear'&lt;/code&gt;, or &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;align_corners&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则输入和输出张量的角像素对齐，从而保留这些像素处的值。这仅在 &lt;code&gt;mode&lt;/code&gt; 为 &lt;code&gt;'linear'&lt;/code&gt; ， &lt;code&gt;'bilinear'&lt;/code&gt; 或 &lt;code&gt;'trilinear'&lt;/code&gt; 线性&amp;rdquo;时才有效。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4550e117269208de394cc0f647e9c83e2e6b506b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;allow_list&lt;/strong&gt; &amp;ndash; list of quantizable modules</source>
          <target state="translated">&lt;strong&gt;allow_list&lt;/strong&gt; &amp;ndash;可量化模块的列表</target>
        </trans-unit>
        <trans-unit id="61284d3bd86eb968f4704c5b682d247f9a471d42" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;allow_unused&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, specifying inputs that were not used when computing outputs (and therefore their grad is always zero) is an error. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;allow_unused&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;False&lt;/code&gt; ，则指定在计算输出时未使用的输入（因此，其grad始终为零）是错误的。默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0b7ed549d17ccf06c2a73555f8c110d2b2777c64" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash; multiplicative factor. Default: 0.0001</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash;乘法因子。默认值：0.0001</target>
        </trans-unit>
        <trans-unit id="0c7e987f8b1b60db336f8816506d789632b3a056" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash; the</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="9144dd58af56a7e78f94a1c6d24c0dd775ffa08a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; &amp;ndash; the alpha constant</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt; -alpha常数</target>
        </trans-unit>
        <trans-unit id="9d910a02ba4f1d9ff8786a89bc62f31022f71840" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Shape parameter of the distribution</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布的形状参数</target>
        </trans-unit>
        <trans-unit id="aaed323126d545c766d6b20c8792516dd1012883" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The coefficient</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;系数</target>
        </trans-unit>
        <trans-unit id="61214109be5b49c8fe2b57494c2492c111db371d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; power for eta update (default: 0.75)</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; eta更新的电源（默认值：0.75）</target>
        </trans-unit>
        <trans-unit id="2c0c6834bd8b3a27d9f0cb960885271d801e89bc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; smoothing constant (default: 0.99)</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;平滑常数（默认值：0.99）</target>
        </trans-unit>
        <trans-unit id="bef472f2822264f8844272a566f6ae7e013eac0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the scalar multiplier for &lt;code&gt;other&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;em&gt;Number&lt;/em&gt;）&amp;ndash; &lt;code&gt;other&lt;/code&gt; 的标量乘数</target>
        </trans-unit>
        <trans-unit id="eafad06cad281ac6182faa727319bec1cdc6e990" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;em&gt;Number &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;乘数</target>
        </trans-unit>
        <trans-unit id="c0c3d78d14051f159b2c380fbcdbccf7032cc7c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for &lt;code&gt;batch1 @ batch2&lt;/code&gt; (</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;em&gt;数字&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; &lt;code&gt;batch1 @ batch2&lt;/code&gt; 乘数（</target>
        </trans-unit>
        <trans-unit id="01962c7a9caccb6944e0dd97ce4d52d57152f949" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;alpha&lt;/strong&gt; (&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the scalar multiplier for &lt;code&gt;other&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;alpha&lt;/strong&gt;（&lt;em&gt;Scalar&lt;/em&gt;）&amp;ndash; &lt;code&gt;other&lt;/code&gt; 的标量乘数</target>
        </trans-unit>
        <trans-unit id="65c245be1540fcaab2e6ed5fa6d61bf7293f1117" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;amount&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The quantity by which the counter will be incremented.</source>
          <target state="translated">&lt;strong&gt;amount&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;计数器将递增的数量。</target>
        </trans-unit>
        <trans-unit id="a86a8ab17b48cd324b8df6130d66a8bfdd18e3f5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;amount&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; quantity of channels to prune. If &lt;code&gt;float&lt;/code&gt;, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If &lt;code&gt;int&lt;/code&gt;, it represents the absolute number of parameters to prune.</source>
          <target state="translated">&lt;strong&gt;数量&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;整数&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点数&lt;/a&gt;）&amp;ndash;修剪通道的数量。如果 &lt;code&gt;float&lt;/code&gt; ，则应在0.0到1.0之间，并且代表要修剪的参数的分数。如果为 &lt;code&gt;int&lt;/code&gt; ，则表示要修剪的参数的绝对数量。</target>
        </trans-unit>
        <trans-unit id="3a209b964ca3729de2ffee2abca2f378072e01b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;amount&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; quantity of parameters to prune. If &lt;code&gt;float&lt;/code&gt;, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If &lt;code&gt;int&lt;/code&gt;, it represents the absolute number of parameters to prune.</source>
          <target state="translated">&lt;strong&gt;数量&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;整数&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点数&lt;/a&gt;）&amp;ndash;要修剪的参数数量。如果 &lt;code&gt;float&lt;/code&gt; ，则应在0.0到1.0之间，并且代表要修剪的参数的分数。如果为 &lt;code&gt;int&lt;/code&gt; ，则表示要修剪的参数的绝对数量。</target>
        </trans-unit>
        <trans-unit id="9ce470aadb580314ab69ed9394de23b210bd77c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;amsgrad&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to use the AMSGrad variant of this algorithm from the paper &lt;a href=&quot;https://openreview.net/forum?id=ryQu7f-RZ&quot;&gt;On the Convergence of Adam and Beyond&lt;/a&gt; (default: False)</source>
          <target state="translated">&lt;strong&gt;amsgrad&lt;/strong&gt;（&lt;em&gt;boolean &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;是否使用《&lt;a href=&quot;https://openreview.net/forum?id=ryQu7f-RZ&quot;&gt;论亚当与超越的收敛&lt;/a&gt;》一文中的该算法的AMSGrad变体（默认值：False）</target>
        </trans-unit>
        <trans-unit id="412d2ada083b0f76466ad50fa67e45bff30d28be" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;angle&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The angle of the complex tensor. Must be same dtype as &lt;a href=&quot;torch.abs#torch.abs&quot;&gt;&lt;code&gt;abs&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;angle&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;复数张量的角度。dtype必须与&lt;a href=&quot;torch.abs#torch.abs&quot;&gt; &lt;code&gt;abs&lt;/code&gt; &lt;/a&gt;相同。</target>
        </trans-unit>
        <trans-unit id="fe4e9858755e2f94a973c152c11e6edad9884bd7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;anneal_strategy&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; {&amp;lsquo;cos&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;} Specifies the annealing strategy: &amp;ldquo;cos&amp;rdquo; for cosine annealing, &amp;ldquo;linear&amp;rdquo; for linear annealing. Default: &amp;lsquo;cos&amp;rsquo;</source>
          <target state="translated">&lt;strong&gt;anneal_strategy&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash; {'cos'，'linear'}指定退火策略：余弦退火为&amp;ldquo; cos&amp;rdquo;，线性退火为&amp;ldquo; linear&amp;rdquo;。默认值：&amp;ldquo; cos&amp;rdquo;</target>
        </trans-unit>
        <trans-unit id="476bb8fddaba867557b5e140f0e7347d124d9d38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; Any arguments.</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt; &amp;ndash;任何参数。</target>
        </trans-unit>
        <trans-unit id="f3296f07398c854ae12376a870bec69a75a03688" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; any argument (unused)</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt; &amp;ndash;任何参数（未使用）</target>
        </trans-unit>
        <trans-unit id="58fda4a765460c36ef0809232ca862a52a746df4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; arguments passed on to a subclass of &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt; &amp;ndash;传递给&lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod&quot;&gt; &lt;code&gt;BasePruningMethod&lt;/code&gt; &lt;/a&gt;的子类的参数</target>
        </trans-unit>
        <trans-unit id="7cf26c4412d3af55e77c722a46e12a3de8c0a087" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; arguments passed on to a subclass of &lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt; &amp;ndash;传递给&lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt; &lt;code&gt;BasePruningMethod&lt;/code&gt; &lt;/a&gt;的子类的参数</target>
        </trans-unit>
        <trans-unit id="06452ebbd4e53eb2a57ca1d68b73dffabe3a9e69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; arguments to pass to the optimizer constructor on each worker.</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt; &amp;ndash;传递给每个工作程序上的优化器构造函数的参数。</target>
        </trans-unit>
        <trans-unit id="527ad6571a32b831a6fa84b982cf26783e444b79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; &amp;ndash; tuple containing inputs to the &lt;code&gt;function&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt; &amp;ndash;包含 &lt;code&gt;function&lt;/code&gt; 输入的元组</target>
        </trans-unit>
        <trans-unit id="fa75d1d4cde2ad42292912372e00091b89a16d9f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Arguments passed to &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;传递给 &lt;code&gt;fn&lt;/code&gt; 的参数。</target>
        </trans-unit>
        <trans-unit id="bbbea77d989716da38960ac97dc3c1b13738a750" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the argument tuple for the &lt;code&gt;func&lt;/code&gt; invocation.</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash; &lt;code&gt;func&lt;/code&gt; 调用的参数tuple 。</target>
        </trans-unit>
        <trans-unit id="a6ccd94c0969142ac42560e759fc19e3bb7b28e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;args&lt;/strong&gt; (&lt;em&gt;tuple of arguments&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; the inputs to the model, e.g., such that &lt;code&gt;model(*args)&lt;/code&gt; is a valid invocation of the model. Any non-Tensor arguments will be hard-coded into the exported model; any Tensor arguments will become inputs of the exported model, in the order they occur in args. If args is a Tensor, this is equivalent to having called it with a 1-ary tuple of that Tensor. (Note: passing keyword arguments to the model is not currently supported. Give us a shout if you need it.)</source>
          <target state="translated">&lt;strong&gt;args&lt;/strong&gt;（&lt;em&gt;参数&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor的&lt;/a&gt;&lt;em&gt;元组&lt;/em&gt;）&amp;ndash;模型的输入，例如，使得 &lt;code&gt;model(*args)&lt;/code&gt; 是对模型的有效调用。任何非Tensor参数将被硬编码到导出的模型中；任何Tensor参数将按照在args中出现的顺序成为导出模型的输入。如果args是一个Tensor，则相当于用该Tensor的1元元组调用了它。（注意：当前不支持将关键字参数传递给模型。如果需要，请给我们喊叫。）</target>
        </trans-unit>
        <trans-unit id="16fdafe6c67075fc015e420e0bb0f8d630e5f4e5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;as torch.nn.quantized.Conv2d&lt;/strong&gt; (&lt;em&gt;Same&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;如torch.nn.quantized.Conv2d&lt;/strong&gt;（&lt;em&gt;相同&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="79c9815e7f5a48dc393a28760411256901b78dc1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;as torch.nn.quantized.Linear&lt;/strong&gt; (&lt;em&gt;Same&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;如torch.nn.quantized.Linear&lt;/strong&gt;（&lt;em&gt;相同&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="b96cfefc433ac6d54b2e6d75776bf06a2aa2c2ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;async_op&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether this op should be an async op</source>
          <target state="translated">&lt;strong&gt;async_op&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;此操作是否应为异步操作</target>
        </trans-unit>
        <trans-unit id="1ef0166b6388a4f0216cd0af7040aee2dea01134" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;async_op&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether this op should be an async op.</source>
          <target state="translated">&lt;strong&gt;async_op&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;此操作是否应为异步操作。</target>
        </trans-unit>
        <trans-unit id="3c393f84aad8fa71c90593f9038432da8c10f4ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;aten&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; [DEPRECATED. use operator_export_type] export the model in aten mode. If using aten mode, all the ops original exported by the functions in symbolic_opset&amp;lt;version&amp;gt;.py are exported as ATen ops.</source>
          <target state="translated">&lt;strong&gt;aten&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为False&lt;/em&gt;）&amp;ndash; [不推荐使用。使用operator_export_type]以aten模式导出模型。如果使用TEN模式，则由symbolic_opset &amp;lt;version&amp;gt; .py中的函数导出的所有原始ops都将作为ATen ops导出。</target>
        </trans-unit>
        <trans-unit id="1aa89f7b6b3c09ca31403919ee5c7ade6eca50cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;atol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; absolute tolerance</source>
          <target state="translated">&lt;strong&gt;atol&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;绝对公差</target>
        </trans-unit>
        <trans-unit id="d413d0f3f92358bb21c09129aebaafca7327d9cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;atol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; absolute tolerance. Default: 1e-08</source>
          <target state="translated">&lt;strong&gt;atol&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;绝对公差。默认值：1e-08</target>
        </trans-unit>
        <trans-unit id="3edeccc3509794121a4c8cbb0c9c3947569f0355" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;attn_mask&lt;/strong&gt; &amp;ndash; 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all the batches while a 3D mask allows to specify a different mask for the entries of each batch.</source>
          <target state="translated">&lt;strong&gt;attn_mask&lt;/strong&gt; &amp;ndash; 2D或3D蒙版，可避免注意某些位置。将为所有批次广播2D蒙版，而3D蒙版允许为每个批次的条目指定不同的蒙版。</target>
        </trans-unit>
        <trans-unit id="5b70ffd8c9aa3ced153863f4307b36931662a4e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;aux_logits&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, add an auxiliary branch that can improve training. Default: &lt;em&gt;True&lt;/em&gt;</source>
          <target state="translated">&lt;strong&gt;aux_logits&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为True，则添加一个辅助分支以改善训练。默认值：&lt;em&gt;True&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="b7f0d0ce983d8eb3de6cf4b329489cdf94ceff22" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;aux_logits&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, adds two auxiliary branches that can improve training. Default: &lt;em&gt;False&lt;/em&gt; when pretrained is True otherwise &lt;em&gt;True&lt;/em&gt;</source>
          <target state="translated">&lt;strong&gt;aux_logits&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为True，则添加两个可以改善训练的辅助分支。默认值：如果预训练为True，则为&lt;em&gt;False&lt;/em&gt;，否则为&lt;em&gt;True&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ef35e44897a61b67d11a6892ff916c7a17ffe70c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;averaging_constant&lt;/strong&gt; &amp;ndash; Averaging constant for min/max.</source>
          <target state="translated">&lt;strong&gt;averaging_constant&lt;/strong&gt; &amp;ndash;最小/最大的平均常数。</target>
        </trans-unit>
        <trans-unit id="a7ddd6c4129c6131d8812cc22b9dde600a187a20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;axis&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension on which apply per-channel quantization</source>
          <target state="translated">&lt;strong&gt;轴&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;每通道量化所应用的尺寸</target>
        </trans-unit>
        <trans-unit id="8531d8872ce2920e620f2844e86bbe33088a4efd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;b&lt;/strong&gt; &amp;ndash; the upper bound of the uniform distribution</source>
          <target state="translated">&lt;strong&gt;b&lt;/strong&gt; &amp;ndash;均匀分布的上限</target>
        </trans-unit>
        <trans-unit id="b8325c83f74f3a97ea28f95055f6ccadb9fe0420" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;b&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Right tensor to contract</source>
          <target state="translated">&lt;strong&gt;b&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;右张量收缩</target>
        </trans-unit>
        <trans-unit id="41ffccfc315d025808792ff986c6bf85fc3cfb20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;b&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the RHS tensor of size</source>
          <target state="translated">&lt;strong&gt;b&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash; RHS张量的大小</target>
        </trans-unit>
        <trans-unit id="bedd1fb2f39140f6b07702dfe6d9850270d68d48" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; &amp;ndash; Device type to use for running the result model (&amp;lsquo;CPU&amp;rsquo;(default) or &amp;lsquo;Vulkan&amp;rsquo;).</source>
          <target state="translated">&lt;strong&gt;后端&lt;/strong&gt;&amp;ndash;用于运行结果模型的设备类型（&amp;ldquo; CPU&amp;rdquo;（默认）或&amp;ldquo; Vulkan&amp;rdquo;）。</target>
        </trans-unit>
        <trans-unit id="857b931bd7b5bfc52eb0de68ac6430dc390f6af7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; (&lt;a href=&quot;#torch.distributed.rpc.BackendType&quot;&gt;BackendType&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The type of RPC backend implementation. Supported values include &lt;code&gt;BackendType.TENSORPIPE&lt;/code&gt; (the default) and &lt;code&gt;BackendType.PROCESS_GROUP&lt;/code&gt;. See &lt;a href=&quot;#rpc-backends&quot;&gt;Backends&lt;/a&gt; for more information.</source>
          <target state="translated">&lt;strong&gt;backend&lt;/strong&gt;（&lt;a href=&quot;#torch.distributed.rpc.BackendType&quot;&gt;BackendType &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; RPC后端实现的类型。支持的值包括 &lt;code&gt;BackendType.TENSORPIPE&lt;/code&gt; （默认值）和 &lt;code&gt;BackendType.PROCESS_GROUP&lt;/code&gt; 。有关更多信息，请参见&lt;a href=&quot;#rpc-backends&quot;&gt;后端&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2deecff901759888bdb71ea34d20b18f5d55de46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;#torch.distributed.Backend&quot;&gt;Backend&lt;/a&gt;) &amp;ndash; The backend to use. Depending on build-time configurations, valid values include &lt;code&gt;mpi&lt;/code&gt;, &lt;code&gt;gloo&lt;/code&gt;, and &lt;code&gt;nccl&lt;/code&gt;. This field should be given as a lowercase string (e.g., &lt;code&gt;&quot;gloo&quot;&lt;/code&gt;), which can also be accessed via &lt;a href=&quot;#torch.distributed.Backend&quot;&gt;&lt;code&gt;Backend&lt;/code&gt;&lt;/a&gt; attributes (e.g., &lt;code&gt;Backend.GLOO&lt;/code&gt;). If using multiple processes per machine with &lt;code&gt;nccl&lt;/code&gt; backend, each process must have exclusive access to every GPU it uses, as sharing GPUs between processes can result in deadlocks.</source>
          <target state="translated">&lt;strong&gt;后端&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;#torch.distributed.Backend&quot;&gt;后端&lt;/a&gt;）&amp;ndash;要使用的后端。根据构建时配置，有效值包括 &lt;code&gt;mpi&lt;/code&gt; ， &lt;code&gt;gloo&lt;/code&gt; 和 &lt;code&gt;nccl&lt;/code&gt; 。该字段应以小写字符串（例如 &lt;code&gt;&quot;gloo&quot;&lt;/code&gt; ）形式给出，也可以通过&lt;a href=&quot;#torch.distributed.Backend&quot;&gt; &lt;code&gt;Backend&lt;/code&gt; &lt;/a&gt;属性（例如 &lt;code&gt;Backend.GLOO&lt;/code&gt; ）进行访问。如果每台计算机使用带有 &lt;code&gt;nccl&lt;/code&gt; 后端的多个进程，则每个进程必须对其使用的每个GPU都具有独占访问权限，因为在进程之间共享GPU可能会导致死锁。</target>
        </trans-unit>
        <trans-unit id="611838a036cbfc666e9b5fee5ea917b77c462eae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;backend&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;#torch.distributed.Backend&quot;&gt;Backend&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The backend to use. Depending on build-time configurations, valid values are &lt;code&gt;gloo&lt;/code&gt; and &lt;code&gt;nccl&lt;/code&gt;. By default uses the same backend as the global group. This field should be given as a lowercase string (e.g., &lt;code&gt;&quot;gloo&quot;&lt;/code&gt;), which can also be accessed via &lt;a href=&quot;#torch.distributed.Backend&quot;&gt;&lt;code&gt;Backend&lt;/code&gt;&lt;/a&gt; attributes (e.g., &lt;code&gt;Backend.GLOO&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;后端&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;#torch.distributed.Backend&quot;&gt;Backend &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要使用的后端。根据构建时配置，有效值为 &lt;code&gt;gloo&lt;/code&gt; 和 &lt;code&gt;nccl&lt;/code&gt; 。默认情况下，使用与全局组相同的后端。该字段应以小写字符串（例如 &lt;code&gt;&quot;gloo&quot;&lt;/code&gt; ）形式给出，也可以通过&lt;a href=&quot;#torch.distributed.Backend&quot;&gt; &lt;code&gt;Backend&lt;/code&gt; &lt;/a&gt;属性（例如 &lt;code&gt;Backend.GLOO&lt;/code&gt; ）进行访问。</target>
        </trans-unit>
        <trans-unit id="dd1b20b89d2cc0ec5cb752e68d4f7968fe15164e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;base&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; base of the logarithm function. Default: &lt;code&gt;10.0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;base&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;对数函数的底数。默认值： &lt;code&gt;10.0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a732d69bc0c02255c6ebdddc229969991439ab4d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;base_distribution&lt;/strong&gt; (&lt;a href=&quot;#torch.distributions.distribution.Distribution&quot;&gt;torch.distributions.distribution.Distribution&lt;/a&gt;) &amp;ndash; a base distribution</source>
          <target state="translated">&lt;strong&gt;base_distribution&lt;/strong&gt;（&lt;a href=&quot;#torch.distributions.distribution.Distribution&quot;&gt;torch.distributions.distribution.Distribution&lt;/a&gt;）&amp;ndash;基本分发</target>
        </trans-unit>
        <trans-unit id="476a4762eae7b33d8cc5f0ed09807b11d346a607" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;base_lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Initial learning rate which is the lower boundary in the cycle for each parameter group.</source>
          <target state="translated">&lt;strong&gt;base_lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;初始学习率，它是每个参数组在循环中的下边界。</target>
        </trans-unit>
        <trans-unit id="45bfdd8de24999d7830386707112d1d252ec4ede" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;base_momentum&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Lower momentum boundaries in the cycle for each parameter group. Note that momentum is cycled inversely to learning rate; at the peak of a cycle, momentum is &amp;lsquo;base_momentum&amp;rsquo; and learning rate is &amp;lsquo;max_lr&amp;rsquo;. Default: 0.8</source>
          <target state="translated">&lt;strong&gt;base_momentum&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;每个参数组在循环中的较低动量边界。注意，动量与学习率成反比。在一个周期的峰值，动量是&amp;ldquo; base_momentum&amp;rdquo;，学习速率是&amp;ldquo; max_lr&amp;rdquo;。默认值：0.8</target>
        </trans-unit>
        <trans-unit id="372f4bc26c77679cdc93407eca357992bf64c343" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;base_momentum&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Lower momentum boundaries in the cycle for each parameter group. Note that momentum is cycled inversely to learning rate; at the peak of a cycle, momentum is &amp;lsquo;base_momentum&amp;rsquo; and learning rate is &amp;lsquo;max_lr&amp;rsquo;. Default: 0.85</source>
          <target state="translated">&lt;strong&gt;base_momentum&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;每个参数组在循环中的较低动量边界。注意，动量与学习率成反比。在一个周期的峰值，动量是&amp;ldquo; base_momentum&amp;rdquo;，学习速率是&amp;ldquo; max_lr&amp;rdquo;。默认值：0.85</target>
        </trans-unit>
        <trans-unit id="2d70c00dc7a0b2333944c557a49e48e57f71ef5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first batch of matrices to be multiplied</source>
          <target state="translated">&lt;strong&gt;batch1&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要相乘的第一批矩阵</target>
        </trans-unit>
        <trans-unit id="f6f89ac68899abcdeec75e50915476dc96eff70e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second batch of matrices to be multiplied</source>
          <target state="translated">&lt;strong&gt;batch2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要相乘的第二批矩阵</target>
        </trans-unit>
        <trans-unit id="7cf203097252d2e89f058a192c342938374bbb59" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, then the input and output tensors are provided as (batch, seq, feature). Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;batch_first&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则输入和输出张量按（batch，seq，feature）提供。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c2bb4ed84deb95504a0fd7b72a8e70cbe91a0c79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, then the input and output tensors are provided as &lt;code&gt;(batch, seq, feature)&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;batch_first&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则输入和输出张量按 &lt;code&gt;(batch, seq, feature)&lt;/code&gt; 。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="bb58228cb0588bbf40e1aa70f7aa94c4d87966f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the input is expected in &lt;code&gt;B x T x *&lt;/code&gt; format.</source>
          <target state="translated">&lt;strong&gt;batch_first&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则输入应为 &lt;code&gt;B x T x *&lt;/code&gt; 格式。</target>
        </trans-unit>
        <trans-unit id="97878838dd43a3b22c60de0a798485d3232a77f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the output will be in &lt;code&gt;B x T x *&lt;/code&gt; format.</source>
          <target state="translated">&lt;strong&gt;batch_first&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则输出将为 &lt;code&gt;B x T x *&lt;/code&gt; 格式。</target>
        </trans-unit>
        <trans-unit id="3ed5b9e169e5e04e47a2bda761131d2763152218" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_first&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output will be in &lt;code&gt;B x T x *&lt;/code&gt; if True, or in &lt;code&gt;T x B x *&lt;/code&gt; otherwise</source>
          <target state="translated">&lt;strong&gt;batch_first&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;） -输出将在 &lt;code&gt;B x T x *&lt;/code&gt; 如果为True，或在 &lt;code&gt;T x B x *&lt;/code&gt; 否则</target>
        </trans-unit>
        <trans-unit id="bfc93e33ec4c6682c210e0126029bc47f7bcc35b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_sampler&lt;/strong&gt; (&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;Sampler&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; like &lt;code&gt;sampler&lt;/code&gt;, but returns a batch of indices at a time. Mutually exclusive with &lt;code&gt;batch_size&lt;/code&gt;, &lt;code&gt;shuffle&lt;/code&gt;, &lt;code&gt;sampler&lt;/code&gt;, and &lt;code&gt;drop_last&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;batch_sampler&lt;/strong&gt;（&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;Sampler&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;与 &lt;code&gt;sampler&lt;/code&gt; 类似，但一次返回一批索引。与 &lt;code&gt;batch_size&lt;/code&gt; ， &lt;code&gt;shuffle&lt;/code&gt; ， &lt;code&gt;sampler&lt;/code&gt; 和 &lt;code&gt;drop_last&lt;/code&gt; 互斥。</target>
        </trans-unit>
        <trans-unit id="3c8f4e7015075fc57b0aafa91c8da1ccf8ea7f6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_shape&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;) &amp;ndash; the desired expanded size.</source>
          <target state="translated">&lt;strong&gt;batch_shape&lt;/strong&gt;（&lt;em&gt;torch.Size&lt;/em&gt;）&amp;ndash;所需的扩展大小。</target>
        </trans-unit>
        <trans-unit id="b5f6baf5327e101f2b921c13705c1ef97f75cfc4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Size of mini-batch.</source>
          <target state="translated">&lt;strong&gt;batch_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;迷你批处理的大小。</target>
        </trans-unit>
        <trans-unit id="bf77b09b13edd32fcb21c1fcbdf18d8a6268c85e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;batch_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; how many samples per batch to load (default: &lt;code&gt;1&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;batch_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;每个批次要加载多少个样本（默认值： &lt;code&gt;1&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="4a9f6fb92330f139eb9547e65e6c72e563c7f9e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; &amp;ndash; exponent. Default: 0.75</source>
          <target state="translated">&lt;strong&gt;Beta&lt;/strong&gt; &amp;ndash;指数。默认值：0.75</target>
        </trans-unit>
        <trans-unit id="ef999fec40e863a728ff14d8247d251aee96fa89" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; &amp;ndash; the</source>
          <target state="translated">&lt;strong&gt;Beta&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="0cf575cbd58c43c32309649550fcd836702cf2fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the threshold at which to change between L1 and L2 loss. This value defaults to 1.0.</source>
          <target state="translated">&lt;strong&gt;beta&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;指定在L1和L2损耗之间改变的阈值。此值默认为1.0。</target>
        </trans-unit>
        <trans-unit id="3c471f0e5d8fd5619e33288b2fd6dc3e2c59c406" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The coefficient</source>
          <target state="translated">&lt;strong&gt;beta&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;系数</target>
        </trans-unit>
        <trans-unit id="842828693822b4d9f2aa884edc9269cce4696288" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; shape parameter for the window.</source>
          <target state="translated">&lt;strong&gt;beta&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;窗口的形状参数。</target>
        </trans-unit>
        <trans-unit id="b11887536b01d5ee066bad51f6fc21a475d853cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for &lt;code&gt;input&lt;/code&gt; (</source>
          <target state="translated">&lt;strong&gt;beta&lt;/strong&gt;（&lt;em&gt;Number &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; &lt;code&gt;input&lt;/code&gt; 乘数（</target>
        </trans-unit>
        <trans-unit id="fa1cf47ccd539344b4c2e84e2076311ee96e5b1f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;beta&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for &lt;code&gt;mat&lt;/code&gt; (</source>
          <target state="translated">&lt;strong&gt;beta&lt;/strong&gt;（&lt;em&gt;数字&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; &lt;code&gt;mat&lt;/code&gt; 乘数（</target>
        </trans-unit>
        <trans-unit id="a24e7da699bda084e89f8e714c763a68a433a209" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;betas&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; coefficients used for computing running averages of gradient and its square</source>
          <target state="translated">&lt;strong&gt;betas&lt;/strong&gt;（&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;用于计算梯度及其平方的移动平均值的系数</target>
        </trans-unit>
        <trans-unit id="c878ef998237737758de6fede183a7e8e739ff80" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;betas&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))</source>
          <target state="translated">&lt;strong&gt;betas&lt;/strong&gt;（&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;用于计算梯度及其平方的移动平均值的系数（默认值：（0.9，0.999））</target>
        </trans-unit>
        <trans-unit id="fc78c217f09fc1013e5acbefa8a13316ec9a1fca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; &lt;strong&gt;non-quantized&lt;/strong&gt; bias tensor of shape</source>
          <target state="translated">&lt;strong&gt;偏差&lt;/strong&gt;&amp;ndash;形状的&lt;strong&gt;非量化&lt;/strong&gt;偏差张量</target>
        </trans-unit>
        <trans-unit id="5cf46533d930efcc3fd64418202381a80648d2fc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, then the layer does not use bias weights &lt;code&gt;b_ih&lt;/code&gt; and &lt;code&gt;b_hh&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;False&lt;/code&gt; ，则该层将不使用偏置权重 &lt;code&gt;b_ih&lt;/code&gt; 和 &lt;code&gt;b_hh&lt;/code&gt; 。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9a6cf6d24a3d1d4d2e99d86a09905c2dcc844ee4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; If set to &lt;code&gt;False&lt;/code&gt;, the layer will not learn an additive bias. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;偏倚&lt;/strong&gt;&amp;ndash;如果设置为 &lt;code&gt;False&lt;/code&gt; ，则图层将不会学习加性偏倚。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9166de183aefb5a5420210ed060a3775a566bedc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; If set to False, the layer will not learn an additive bias. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;偏差&lt;/strong&gt;-如果设置为False，则该图层将不会学习加法偏差。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="81d19585b9271c2697fbe2d0820cd2cd9a202b52" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; add bias as module parameter. Default: True.</source>
          <target state="translated">&lt;strong&gt;偏差&lt;/strong&gt;&amp;ndash;将偏差添加为模块参数。默认值：True。</target>
        </trans-unit>
        <trans-unit id="f1d7f9d42640778760e245fa86bc8ea0c619a3a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; optional bias of shape</source>
          <target state="translated">&lt;strong&gt;偏差&lt;/strong&gt;&amp;ndash;可选的形状偏差</target>
        </trans-unit>
        <trans-unit id="9e06c7b1cc26cfb4e243f63f4508fe3ad4aaecc3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; &amp;ndash; optional bias tensor of shape</source>
          <target state="translated">&lt;strong&gt;偏差&lt;/strong&gt;&amp;ndash;形状的可选偏差张量</target>
        </trans-unit>
        <trans-unit id="e03a417e197c4f988306955bf8e28f75e1103c81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, adds a learnable bias to the output. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;偏见&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则向输出添加可学习的偏见。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c804fd0b8536d52a938e789eaf231e2d8488e976" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bias&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; None or fp32 bias of type &lt;code&gt;torch.float&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;bias&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;无或 &lt;code&gt;torch.float&lt;/code&gt; 类型的fp32偏差</target>
        </trans-unit>
        <trans-unit id="a33731aa2d3126a1f9307fbc74003f4b76cba728" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bidirectional&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, becomes a bidirectional GRU. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;双向&lt;/strong&gt;&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则成为双向GRU。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f4d0b0c0ab949b4fb4278979fa4bb9deb02a9fbe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bidirectional&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, becomes a bidirectional LSTM. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;双向&lt;/strong&gt;-如果为 &lt;code&gt;True&lt;/code&gt; ，则变为双向LSTM。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d8771da0d807097f9c9e787cd58800e69ca9ba9e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bidirectional&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, becomes a bidirectional RNN. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;双向&lt;/strong&gt;&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则成为双向RNN。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b2bdb7d7d14d67274cdaee544d6984dd9b157097" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bins&lt;/strong&gt; &amp;ndash; Number of bins to use for the histogram</source>
          <target state="translated">&lt;strong&gt;bins&lt;/strong&gt; &amp;ndash;直方图使用的bin数</target>
        </trans-unit>
        <trans-unit id="7eb56a898db0c0dd4ebf0e179f5fd52a33dbbba3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bins&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of histogram bins</source>
          <target state="translated">&lt;strong&gt;bins&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;直方图箱数</target>
        </trans-unit>
        <trans-unit id="6d0079f1170ed85a5972e6fbc1007549726ed554" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bins&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; One of {&amp;lsquo;tensorflow&amp;rsquo;,&amp;rsquo;auto&amp;rsquo;, &amp;lsquo;fd&amp;rsquo;, &amp;hellip;}. This determines how the bins are made. You can find other options in: &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html&quot;&gt;https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;bins&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash; {'tensorflow'，'auto'，'fd'，...}中的一个。这决定了垃圾桶的制作方式。您可以在以下位置找到其他选项：&lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html&quot;&gt;https&lt;/a&gt; : //docs.scipy.org/doc/numpy/reference/genic/numpy.histogram.html</target>
        </trans-unit>
        <trans-unit id="be7c2ee257bfd0c3170743cdce62c675328d09dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;blank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Blank label. Default</source>
          <target state="translated">&lt;strong&gt;空白&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;空白标签。默认</target>
        </trans-unit>
        <trans-unit id="98d9784c554d3e6070ecb671487ffb5edf2addb7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;blank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; blank label. Default</source>
          <target state="translated">&lt;strong&gt;空白&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;空白标签。默认</target>
        </trans-unit>
        <trans-unit id="f468597461731cace7790edbc7b181778b52c95e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, &lt;a href=&quot;#torch.cuda.Event.wait&quot;&gt;&lt;code&gt;wait()&lt;/code&gt;&lt;/a&gt; will be blocking (default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;阻塞&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则&lt;a href=&quot;#torch.cuda.Event.wait&quot;&gt; &lt;code&gt;wait()&lt;/code&gt; &lt;/a&gt;将被阻塞（默认值： &lt;code&gt;False&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="124b59c3f64e2d2878e908f98928989224419b13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;boundaries&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D tensor, must contain a monotonically increasing sequence.</source>
          <target state="translated">&lt;strong&gt;边界&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;一维张量，必须包含一个单调递增的序列。</target>
        </trans-unit>
        <trans-unit id="5da31c2835927c49a7bcd45bbe610fbd0fda6d6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;broadcast_buffers&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag that enables syncing (broadcasting) buffers of the module at beginning of the &lt;code&gt;forward&lt;/code&gt; function. (default: &lt;code&gt;True&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;broadcast_buffers&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;在 &lt;code&gt;forward&lt;/code&gt; 功能开始时启用同步（广播）模块缓冲区的标志。（默认： &lt;code&gt;True&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="3d5abee92111d698306a568507b4404bca34ef32" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;bucket_cap_mb&lt;/strong&gt; &amp;ndash; &lt;code&gt;DistributedDataParallel&lt;/code&gt; will bucket parameters into multiple buckets so that gradient reduction of each bucket can potentially overlap with backward computation. &lt;code&gt;bucket_cap_mb&lt;/code&gt; controls the bucket size in MegaBytes (MB). (default: 25)</source>
          <target state="translated">&lt;strong&gt;bucket_cap_mb&lt;/strong&gt; &amp;ndash; &lt;code&gt;DistributedDataParallel&lt;/code&gt; 将参数存储到多个存储桶中，以便每个存储桶的梯度缩减可能与向后计算重叠。 &lt;code&gt;bucket_cap_mb&lt;/code&gt; 控制桶的大小，以兆字节（MB）为单位。（默认值：25）</target>
        </trans-unit>
        <trans-unit id="2a33ab96a8acd996a84aba710ffdc9e4c59ed291" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;buffer_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; maximum size of the buffer used for coalescing</source>
          <target state="translated">&lt;strong&gt;buffer_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;用于合并的缓冲区的最大大小</target>
        </trans-unit>
        <trans-unit id="2fa537aa1114daae5c6231d8a64de02ef3a1e4f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;build_directory&lt;/strong&gt; &amp;ndash; optional path to use as build workspace.</source>
          <target state="translated">&lt;strong&gt;build_directory&lt;/strong&gt; &amp;ndash;用作构建工作区的可选路径。</target>
        </trans-unit>
        <trans-unit id="c3141d5b804d7f3a2ff206cba71370ed4fb7cf6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_0&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the initial cell state for each element in the batch.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;c_0 &lt;/strong&gt; &lt;code&gt;(batch, hidden_size)&lt;/code&gt; ：张量，包含批处理中每个元素的初始单元状态。</target>
        </trans-unit>
        <trans-unit id="2cdfc2f84c394419e5070447dbe32bbe5a849b2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_0&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the initial cell state for each element in the batch.</source>
          <target state="translated">&lt;strong&gt;c_0&lt;/strong&gt;形状 &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt; ：张量，包含批次中每个元素的初始单元格状态。</target>
        </trans-unit>
        <trans-unit id="f9b02af500b7cb6986cf95c49ee08bafe6ac6c55" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_1&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the next cell state for each element in the batch</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;c_1 &lt;/strong&gt; &lt;code&gt;(batch, hidden_size)&lt;/code&gt; ：张量，包含批处理中每个元素的下一个单元格状态</target>
        </trans-unit>
        <trans-unit id="bc8b348167534518488e0ae2031d0338daba2877" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;c_n&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the cell state for &lt;code&gt;t = seq_len&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;c_n &lt;/strong&gt; &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt; ：包含 &lt;code&gt;t = seq_len&lt;/code&gt; 元状态的张量。</target>
        </trans-unit>
        <trans-unit id="7f3d6a6619594dae9f728601472ac26049551428" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cache_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Size of cache. If zero, no caching is done. If one, the latest single value is cached. Only 0 and 1 are supported.</source>
          <target state="translated">&lt;strong&gt;cache_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;缓存大小。如果为零，则不进行任何缓存。如果为1，则将缓存最新的单个值。仅支持0和1。</target>
        </trans-unit>
        <trans-unit id="b3afc2463b07a6cb3c6c5f91f7a5a9121d9323c6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;callback&lt;/strong&gt; (&lt;code&gt;Callable&lt;/code&gt;) &amp;ndash; a &lt;code&gt;Callable&lt;/code&gt; that takes this &lt;code&gt;Future&lt;/code&gt; as the only argument.</source>
          <target state="translated">&lt;strong&gt;callback&lt;/strong&gt;（ &lt;code&gt;Callable&lt;/code&gt; ）&amp;ndash;将此 &lt;code&gt;Future&lt;/code&gt; 作为唯一参数的 &lt;code&gt;Callable&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="158dc34f4b85c715ce37b97b602ff17aa31fafed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cast_inputs&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt; or None, optional, default=None) &amp;ndash; If not &lt;code&gt;None&lt;/code&gt;, when &lt;code&gt;forward&lt;/code&gt; runs in an autocast-enabled region, casts incoming floating-point CUDA Tensors to the target dtype (non-floating-point Tensors are not affected), then executes &lt;code&gt;forward&lt;/code&gt; with autocast disabled. If &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;forward&lt;/code&gt;&amp;rsquo;s internal ops execute with the current autocast state.</source>
          <target state="translated">&lt;strong&gt;cast_inputs&lt;/strong&gt;（ &lt;code&gt;torch.dtype&lt;/code&gt; 或None，可选，默认为None）&amp;ndash;如果不是 &lt;code&gt;None&lt;/code&gt; ，则在启用自动广播的区域中 &lt;code&gt;forward&lt;/code&gt; 运行时，将传入的浮点CUDA张量强制转换为目标dtype（非浮点张量不受影响） ），然后在禁用自动广播的情况下 &lt;code&gt;forward&lt;/code&gt; 执行。如果为 &lt;code&gt;None&lt;/code&gt; ，则 &lt;code&gt;forward&lt;/code&gt; 的内部操作将以当前的自动广播状态执行。</target>
        </trans-unit>
        <trans-unit id="a50ab6a8fd5d6ca7187e241b339e3ce04e06ad53" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</source>
          <target state="translated">&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则将使用 &lt;code&gt;ceil&lt;/code&gt; 而不是 &lt;code&gt;floor&lt;/code&gt; 来计算输出形状。这确保了输入张量中的每个元素都被一个滑动窗口覆盖。</target>
        </trans-unit>
        <trans-unit id="c8f8c031ecdef7a290512f2d2c0f3fb9843f10ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; in the formula to compute the output shape</source>
          <target state="translated">&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash;为True时，将在公式中使用 &lt;code&gt;ceil&lt;/code&gt; 而不是 &lt;code&gt;floor&lt;/code&gt; 来计算输出形状</target>
        </trans-unit>
        <trans-unit id="4607006703c79ed95d46d4bdf76b0c53e13b775b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; in the formula to compute the output shape. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash;为True时，将在公式中使用 &lt;code&gt;ceil&lt;/code&gt; 而不是 &lt;code&gt;floor&lt;/code&gt; 来计算输出形状。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="11fbe0576979d5cf6a08896bdf3211baf5a56d94" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; to compute the output shape</source>
          <target state="translated">&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash;为True时，将使用 &lt;code&gt;ceil&lt;/code&gt; 而不是 &lt;code&gt;floor&lt;/code&gt; 来计算输出形状</target>
        </trans-unit>
        <trans-unit id="b293b825d6cac1646ea030a31f09a3ccbb476cad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash; when True, will use &lt;code&gt;ceil&lt;/code&gt; instead of &lt;code&gt;floor&lt;/code&gt; to compute the output shape. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ceil_mode&lt;/strong&gt; &amp;ndash;为True时，将使用 &lt;code&gt;ceil&lt;/code&gt; 而不是 &lt;code&gt;floor&lt;/code&gt; 来计算输出形状。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="39ee4edbfa46d12a64c7dc2b9fa7acda768a096e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;center&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether &lt;code&gt;input&lt;/code&gt; was padded on both sides so that the</source>
          <target state="translated">&lt;strong&gt;center&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;是否在两侧都填充了 &lt;code&gt;input&lt;/code&gt; ，以便</target>
        </trans-unit>
        <trans-unit id="554e667848e98458fc2cceae44866e4bc318c449" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;center&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if True, center the input tensor, otherwise, assume that the input is centered.</source>
          <target state="translated">&lt;strong&gt;center&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为True，则使输入张量居中，否则，假设输入居中。</target>
        </trans-unit>
        <trans-unit id="f9f7299f6837ef46cae44a83afb72d7f43c0f17b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;center&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to pad &lt;code&gt;input&lt;/code&gt; on both sides so that the</source>
          <target state="translated">&lt;strong&gt;居中&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;是否在两侧都填充 &lt;code&gt;input&lt;/code&gt; ，以便</target>
        </trans-unit>
        <trans-unit id="e60f9d3649e78b261bdfd669e6452599a42743a3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;centered&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, compute the centered RMSProp, the gradient is normalized by an estimation of its variance</source>
          <target state="translated">&lt;strong&gt;居中&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则计算居中的RMSProp，则通过估算其方差来对梯度进行归一化</target>
        </trans-unit>
        <trans-unit id="f4ea6bf9c1eff8d3014f59d1fd1a0f38423eba97" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ch_axis&lt;/strong&gt; &amp;ndash; Channel axis</source>
          <target state="translated">&lt;strong&gt;ch_axis&lt;/strong&gt; &amp;ndash;通道轴</target>
        </trans-unit>
        <trans-unit id="901e29d2efd439abae8b39739b45f91fde3c2e1f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_hash&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If True, the filename part of the URL should follow the naming convention &lt;code&gt;filename-&amp;lt;sha256&amp;gt;.ext&lt;/code&gt; where &lt;code&gt;&amp;lt;sha256&amp;gt;&lt;/code&gt; is the first eight or more digits of the SHA256 hash of the contents of the file. The hash is used to ensure unique names and to verify the contents of the file. Default: False</source>
          <target state="translated">&lt;strong&gt;check_hash&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为True，则URL的文件名部分应遵循命名约定 &lt;code&gt;filename-&amp;lt;sha256&amp;gt;.ext&lt;/code&gt; ，其中 &lt;code&gt;&amp;lt;sha256&amp;gt;&lt;/code&gt; 是文件内容的SHA256哈希的前八位或更多位。哈希用于确保唯一的名称并验证文件的内容。默认值：False</target>
        </trans-unit>
        <trans-unit id="ef5504f62a92974b3ed5764b39be00b40da7ec96" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_inputs&lt;/strong&gt; (&lt;em&gt;list of dicts&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A list of dicts of input arguments that should be used to check the trace against what is expected. Each tuple is equivalent to a set of input arguments that would be specified in &lt;code&gt;inputs&lt;/code&gt;. For best results, pass in a set of checking inputs representative of the space of shapes and types of inputs you expect the network to see. If not specified, the original &lt;code&gt;inputs&lt;/code&gt; are used for checking</source>
          <target state="translated">&lt;strong&gt;check_inputs&lt;/strong&gt;（&lt;em&gt;字典列表&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输入参数的字典列表，用于根据预期检查跟踪。每个元组相当于一组会在中指定输入参数 &lt;code&gt;inputs&lt;/code&gt; 。为了获得最佳结果，请传递一组检查输入，这些输入代表您希望网络看到的形状和输入类型的空间。如果未指定，则使用原始 &lt;code&gt;inputs&lt;/code&gt; 进行检查</target>
        </trans-unit>
        <trans-unit id="c341222b235229269c7fc1f716c9a876b11bd749" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_inputs&lt;/strong&gt; (&lt;em&gt;list of tuples&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A list of tuples of input arguments that should be used to check the trace against what is expected. Each tuple is equivalent to a set of input arguments that would be specified in &lt;code&gt;example_inputs&lt;/code&gt;. For best results, pass in a set of checking inputs representative of the space of shapes and types of inputs you expect the network to see. If not specified, the original &lt;code&gt;example_inputs&lt;/code&gt; are used for checking</source>
          <target state="translated">&lt;strong&gt;check_inputs&lt;/strong&gt;（&lt;em&gt;元组列表&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输入自变量的元组列表，应使用这些参数来检查跟踪是否符合预期。每个元组等效于在 &lt;code&gt;example_inputs&lt;/code&gt; 中指定的一组输入参数。为了获得最佳结果，请传递一组检查输入，这些输入代表您希望网络看到的形状和输入类型的空间。如果未指定，则使用原始的 &lt;code&gt;example_inputs&lt;/code&gt; 进行检查</target>
        </trans-unit>
        <trans-unit id="5be047e7257e74bb986cba2cbddd77287afb54a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_reduction&lt;/strong&gt; &amp;ndash; This argument is deprecated.</source>
          <target state="translated">&lt;strong&gt;check_reduction&lt;/strong&gt; &amp;ndash;不推荐使用此参数。</target>
        </trans-unit>
        <trans-unit id="71817e8aa767be0ecdbf86860b68e14e0b17f973" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_sparse_nnz&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if True, gradcheck allows for SparseTensor input, and for any SparseTensor at input, gradcheck will perform check at nnz positions only.</source>
          <target state="translated">&lt;strong&gt;check_sparse_nnz&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为True，则gradcheck允许输入SparseTensor，并且对于输入的任何SparseTensor，gradcheck只会在nnz位置执行检查。</target>
        </trans-unit>
        <trans-unit id="5b901bf06f9dd61829b7a11e137cee91046aa7d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_tolerance&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Floating-point comparison tolerance to use in the checker procedure. This can be used to relax the checker strictness in the event that results diverge numerically for a known reason, such as operator fusion.</source>
          <target state="translated">&lt;strong&gt;check_tolerance&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;在检查器过程中使用的浮点比较公差。如果结果由于已知原因（例如，操作员融合）而在数值上出现差异，则可以使用此方法来放松检查器的严格性。</target>
        </trans-unit>
        <trans-unit id="7d4b51194efc0c3988804d99693826828fb517f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_trace&lt;/strong&gt; (&lt;code&gt;bool&lt;/code&gt;, optional) &amp;ndash; Check if the same inputs run through traced code produce the same outputs. Default: &lt;code&gt;True&lt;/code&gt;. You might want to disable this if, for example, your network contains non- deterministic ops or if you are sure that the network is correct despite a checker failure.</source>
          <target state="translated">&lt;strong&gt;check_trace&lt;/strong&gt;（ &lt;code&gt;bool&lt;/code&gt; ，可选）&amp;ndash;检查通过跟踪代码运行的相同输入是否产生相同的输出。默认值： &lt;code&gt;True&lt;/code&gt; 。例如，如果您的网络包含不确定性操作，或者即使检查程序失败，但您确定网络正确，则可能要禁用此功能。</target>
        </trans-unit>
        <trans-unit id="12c8d96002100fa26d3949cd31bda14104f0723b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;check_undefined_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;options&lt;/em&gt;) &amp;ndash; if True, check if undefined output grads are supported and treated as zeros</source>
          <target state="translated">&lt;strong&gt;check_undefined_grad&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;options&lt;/em&gt;）&amp;ndash;如果为True，则检查是否支持未定义的输出&lt;strong&gt;grads&lt;/strong&gt;并将其视为零</target>
        </trans-unit>
        <trans-unit id="e2a343bee8eb1432764513dd55cca2fafc51d5a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;chunk_sizes&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; sizes of chunks to be placed on each device. It should match &lt;code&gt;devices&lt;/code&gt; in length and sums to &lt;code&gt;tensor.size(dim)&lt;/code&gt;. If not specified, &lt;code&gt;tensor&lt;/code&gt; will be divided into equal chunks.</source>
          <target state="translated">&lt;strong&gt;chunk_sizes&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;每个设备上要放置的块的大小。它应该与 &lt;code&gt;devices&lt;/code&gt; 长度匹配，并且总和为 &lt;code&gt;tensor.size(dim)&lt;/code&gt; 。如果未指定， &lt;code&gt;tensor&lt;/code&gt; 将分为相等的块。</target>
        </trans-unit>
        <trans-unit id="9b22f20f0f0764fbf8ab51098534c41733587e08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;chunks&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of chunks to return</source>
          <target state="translated">&lt;strong&gt;chunks&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要返回的块数</target>
        </trans-unit>
        <trans-unit id="768622c9f916e93f3f54009c2cae67ec11e32f7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;clip_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; maximum allowed value of the gradients. The gradients are clipped in the range</source>
          <target state="translated">&lt;strong&gt;clip_value&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;渐变的最大允许值。渐变被限制在范围内</target>
        </trans-unit>
        <trans-unit id="469c227d8924eacf04bdee3cc8cf8084affddf1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;close&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag to automatically close the figure</source>
          <target state="translated">&lt;strong&gt;close&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;自动关闭图形的标志</target>
        </trans-unit>
        <trans-unit id="b862e2504262c8b48874fae9e7b1554d76bea967" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;closure&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;) &amp;ndash; A closure that reevaluates the model and returns the loss.</source>
          <target state="translated">&lt;strong&gt;闭合&lt;/strong&gt;（&lt;em&gt;可调用&lt;/em&gt;）&amp;ndash;重新评估模型并返回损失的闭合。</target>
        </trans-unit>
        <trans-unit id="dfbd8eaebd57f4eb3b5ef5282a6d03a48f71f6f4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;closure&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;) &amp;ndash; A closure that reevaluates the model and returns the loss. Optional for most optimizers.</source>
          <target state="translated">&lt;strong&gt;闭合&lt;/strong&gt;（&lt;em&gt;可调用&lt;/em&gt;）&amp;ndash;重新评估模型并返回损失的闭合。对于大多数优化程序而言是可选的。</target>
        </trans-unit>
        <trans-unit id="a3398e0f638605e68fc3a97d79281029232e5345" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;closure&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A closure that reevaluates the model and returns the loss.</source>
          <target state="translated">&lt;strong&gt;闭包&lt;/strong&gt;（&lt;em&gt;callable &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;一个闭包，可以重新评估模型并返回损失。</target>
        </trans-unit>
        <trans-unit id="cf87633936d5aa46fae578ecedd6b3692d516d64" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;col&lt;/strong&gt; (&lt;code&gt;int&lt;/code&gt;) &amp;ndash; number of columns in the 2-D matrix.</source>
          <target state="translated">&lt;strong&gt;col&lt;/strong&gt;（ &lt;code&gt;int&lt;/code&gt; ）&amp;ndash;二维矩阵中的列数。</target>
        </trans-unit>
        <trans-unit id="fc7488927fd2aeb973d91ad0ef3a00f2bc4856a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;collate_fn&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.</source>
          <target state="translated">&lt;strong&gt;collat​​e_fn&lt;/strong&gt;（&lt;em&gt;callable &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;合并样本列表，以形成张量的小批量。在从地图样式数据集中使用批量加载时使用。</target>
        </trans-unit>
        <trans-unit id="a942bb7a89546ea8db2e80c5772f25d6c0dc388d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;colors&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Colors for each vertex</source>
          <target state="translated">&lt;strong&gt;颜色&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;每个顶点的颜色</target>
        </trans-unit>
        <trans-unit id="af25ed4733fad11d3e062d79140e6b8c23a8a955" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;comment&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Comment log_dir suffix appended to the default &lt;code&gt;log_dir&lt;/code&gt;. If &lt;code&gt;log_dir&lt;/code&gt; is assigned, this argument has no effect.</source>
          <target state="translated">&lt;strong&gt;comment&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;注释log_dir后缀附加到默认 &lt;code&gt;log_dir&lt;/code&gt; 中。如果分配了 &lt;code&gt;log_dir&lt;/code&gt; ，则此参数无效。</target>
        </trans-unit>
        <trans-unit id="88100fd7e4f3c66560dd9b530a7164b8a95efdd5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;compiler&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The compiler executable name to check (e.g. &lt;code&gt;g++&lt;/code&gt;). Must be executable in a shell process.</source>
          <target state="translated">&lt;strong&gt;编译器&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;要检查的编译器可执行文件名称（例如 &lt;code&gt;g++&lt;/code&gt; ）。在Shell进程中必须是可执行的。</target>
        </trans-unit>
        <trans-unit id="ce333629967f987f8531534ac06dca279c4f44ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;component_distribution&lt;/strong&gt; &amp;ndash; &lt;code&gt;torch.distributions.Distribution&lt;/code&gt;-like instance. Right-most batch dimension indexes component.</source>
          <target state="translated">&lt;strong&gt;component_distribution&lt;/strong&gt; &amp;ndash; &lt;code&gt;torch.distributions.Distribution&lt;/code&gt; 的实例。最右边的批次尺寸索引组件。</target>
        </trans-unit>
        <trans-unit id="1808bd911df345d583c080a56c28591067ce66ed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;compute_mode&lt;/strong&gt; &amp;ndash; &amp;lsquo;use_mm_for_euclid_dist_if_necessary&amp;rsquo; - will use matrix multiplication approach to calculate euclidean distance (p = 2) if P &amp;gt; 25 or R &amp;gt; 25 &amp;lsquo;use_mm_for_euclid_dist&amp;rsquo; - will always use matrix multiplication approach to calculate euclidean distance (p = 2) &amp;lsquo;donot_use_mm_for_euclid_dist&amp;rsquo; - will never use matrix multiplication approach to calculate euclidean distance (p = 2) Default: use_mm_for_euclid_dist_if_necessary.</source>
          <target state="translated">&lt;strong&gt;compute_mode&lt;/strong&gt; &amp;ndash;'use_mm_for_euclid_dist_if_necessary'-如果P&amp;gt; 25或R&amp;gt; 25'use_mm_for_euclid_dist'，将使用矩阵乘法来计算欧式距离（p = 2）-将始终使用矩阵乘法来计算欧式距离（p = 2）'donot_use_mm_for_euclid -永远不会使用矩阵乘法方法来计算欧式距离（p = 2）默认值：use_mm_for_euclid_dist_if_necessary。</target>
        </trans-unit>
        <trans-unit id="0b7321414a4a3b3cf3f67b84bd0c573e753c0ef0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;compute_uv&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; option whether to compute &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; or not</source>
          <target state="translated">&lt;strong&gt;compute_uv&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;） -选项是否计算 &lt;code&gt;U&lt;/code&gt; 和 &lt;code&gt;V&lt;/code&gt; 或不</target>
        </trans-unit>
        <trans-unit id="29c6932263dd36cb2b649a7c4c8e4f226a6f5bc4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;concentration0&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 2nd concentration parameter of the distribution (often referred to as beta)</source>
          <target state="translated">&lt;strong&gt;浓度0&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;分布的第二浓度参数（通常称为&amp;beta;）</target>
        </trans-unit>
        <trans-unit id="2a9195b109082c62a5572bf77fe482e738e28674" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;concentration1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1st concentration parameter of the distribution (often referred to as alpha)</source>
          <target state="translated">&lt;strong&gt;浓度1&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;分布的第一浓度参数（通常称为alpha）</target>
        </trans-unit>
        <trans-unit id="b5a7d26c8f7b3912f3a21aa42dedc38581ee8d66" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;concentration&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Concentration parameter of distribution (k/shape).</source>
          <target state="translated">&lt;strong&gt;浓度&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;分布的浓度参数（k /形状）。</target>
        </trans-unit>
        <trans-unit id="984ded62b32cbb90dd847390d944952e565ae495" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;concentration&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; shape parameter of the distribution (often referred to as alpha)</source>
          <target state="translated">&lt;strong&gt;浓度&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;分布的形状参数（通常称为alpha）</target>
        </trans-unit>
        <trans-unit id="d7303d23f33521283575c763715361627138a4d0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;concentration&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; concentration parameter of the distribution (often referred to as alpha)</source>
          <target state="translated">&lt;strong&gt;浓度&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;浓度分布参数（通常称为alpha）</target>
        </trans-unit>
        <trans-unit id="12b35f47cab96aa46ad0ddf8952f6968e19886f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;concentration&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; concentration parameter</source>
          <target state="translated">&lt;strong&gt;浓度&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;火炬张量&lt;/a&gt;）&amp;ndash;浓度参数</target>
        </trans-unit>
        <trans-unit id="a0d3ed0a4c0c3905d8f35b9489a4566e61f37346" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;condition&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; When True (nonzero), yield x, otherwise yield y</source>
          <target state="translated">&lt;strong&gt;condition&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;）&amp;ndash;当为True（非零）时，产生x，否则产生y</target>
        </trans-unit>
        <trans-unit id="fb57365756ae0cedf43c6c254c4afd0d2edee70b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;config_dict&lt;/strong&gt; &amp;ndash; Dictionary with ThreeJS classes names and configuration.</source>
          <target state="translated">&lt;strong&gt;config_dict&lt;/strong&gt; -字典与ThreeJS类名称和配置。</target>
        </trans-unit>
        <trans-unit id="4fb4bebc6aedd7efbc4b85c9b49be4e8e72168db" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;constraint&lt;/strong&gt; (subclass of &lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt;) &amp;ndash; A subclass of &lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt;, or a singleton object of the desired class.</source>
          <target state="translated">&lt;strong&gt;约束&lt;/strong&gt;（子类&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;） -的一个子类&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;，或所需的类的单一对象。</target>
        </trans-unit>
        <trans-unit id="c4a1732a0f202d34ba93b1eb562af5be27bdd650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;context_id&lt;/strong&gt; &amp;ndash; the autograd context id for which we should run the optimizer step.</source>
          <target state="translated">&lt;strong&gt;context_id&lt;/strong&gt; &amp;ndash;我们应为其运行优化器步骤的autograd上下文ID。</target>
        </trans-unit>
        <trans-unit id="4d5613a1e6301637797b5ae54f8043e61724838c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;context_id&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The autograd context id for which we should retrieve the gradients.</source>
          <target state="translated">&lt;strong&gt;context_id&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;我们应为其检索梯度的autograd上下文ID。</target>
        </trans-unit>
        <trans-unit id="d7fa79442f8c4c5b203a624ad01080616555143b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cooldown&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of epochs to wait before resuming normal operation after lr has been reduced. Default: 0.</source>
          <target state="translated">&lt;strong&gt;cooldown&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;减少lr后恢复正常运行之前要等待的时期数。默认值：0</target>
        </trans-unit>
        <trans-unit id="7c83c6134b0a9c7b9806c160fd52a9c3b5ea1fc9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;count_include_pad&lt;/strong&gt; &amp;ndash; when True, will include the zero-padding in the averaging calculation</source>
          <target state="translated">&lt;strong&gt;count_include_pad&lt;/strong&gt; &amp;ndash;为True时，将在平均计算中包括零填充</target>
        </trans-unit>
        <trans-unit id="df61d9b0480a95d8ea4a65fcfd105e2c43cf5683" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;count_include_pad&lt;/strong&gt; &amp;ndash; when True, will include the zero-padding in the averaging calculation. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;count_include_pad&lt;/strong&gt; &amp;ndash;为True时，将在平均计算中包括零填充。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f406dbb58fb0db000240174c73ab3118ad8b663f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;counts&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): (optional) if &lt;code&gt;return_counts&lt;/code&gt; is True, there will be an additional returned tensor (same shape as output or output.size(dim), if dim was specified) representing the number of occurrences for each unique value or tensor.</source>
          <target state="translated">&lt;strong&gt;counts&lt;/strong&gt;（&lt;em&gt;Tensor&lt;/em&gt;）：（可选）如果 &lt;code&gt;return_counts&lt;/code&gt; 为True，则将存在一个额外的返回张量（与output或output.size（dim）相同的形状，如果指定了dim）则表示每个唯一值或张量的出现次数。</target>
        </trans-unit>
        <trans-unit id="721a11304d1853b3ab9748934df7f4a9fd94d7f7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cov_diag&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; diagonal part of low-rank form of covariance matrix with shape &lt;code&gt;batch_shape + event_shape&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;cov_diag&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状为 &lt;code&gt;batch_shape + event_shape&lt;/code&gt; 的协方差矩阵的低秩形式的对角线部分</target>
        </trans-unit>
        <trans-unit id="1ade6f9899c6b2f63d39e2774c383175ef06c9f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cov_factor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; factor part of low-rank form of covariance matrix with shape &lt;code&gt;batch_shape + event_shape + (rank,)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;cov_factor&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状为 &lt;code&gt;batch_shape + event_shape + (rank,)&lt;/code&gt; 的协方差矩阵的低秩形式的因子部分</target>
        </trans-unit>
        <trans-unit id="15c0f21c71f81443b531dc0333c4aa0c9ccb22d7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;covariance_matrix&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; positive-definite covariance matrix</source>
          <target state="translated">&lt;strong&gt;covariance_matrix&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;正定协方差矩阵</target>
        </trans-unit>
        <trans-unit id="88193fd13f9166e9983ecc78ecd953269b1f995e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cpp_sources&lt;/strong&gt; &amp;ndash; A string, or list of strings, containing C++ source code.</source>
          <target state="translated">&lt;strong&gt;cpp_sources&lt;/strong&gt; &amp;ndash;包含C ++源代码的字符串或字符串列表。</target>
        </trans-unit>
        <trans-unit id="db9eaf7dd847ebbdf9223f162c6efa88d22df730" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;create_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, both the output and result will be computed in a differentiable way. Note that when &lt;code&gt;strict&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the result can not require gradients or be disconnected from the inputs. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;create_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则将以可微分的方式来计算输出和结果。请注意，当 &lt;code&gt;strict&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; 时，结果将不需要渐变或与输入断开连接。默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0591761d9c26012b62edfc0b51c0801c2b3c9cac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;create_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, graph of the derivative will be constructed, allowing to compute higher order derivative products. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;create_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，将构造导数图，从而可以计算高阶导数乘积。默认值： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1df45c030ada5dacf28732656dae67b769b52be4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;create_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, graph of the derivative will be constructed, allowing to compute higher order derivative products. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;create_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，将构造导数图，从而可以计算高阶导数乘积。默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="74bd210617e0c27abaf4e4fd33cd8b31f80e3875" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;create_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the Hessian will be computed in a differentiable manner. Note that when &lt;code&gt;strict&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the result can not require gradients or be disconnected from the inputs. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;create_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则将以可微分的方式计算Hessian。请注意，当 &lt;code&gt;strict&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; 时，结果将不需要渐变或与输入断开连接。默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="30f1dcaaf70a34ead05956232ad7838aced8b6d1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;create_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the Jacobian will be computed in a differentiable manner. Note that when &lt;code&gt;strict&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the result can not require gradients or be disconnected from the inputs. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;create_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则将以可微分的方式计算雅可比行列式。请注意，当 &lt;code&gt;strict&lt;/code&gt; 为 &lt;code&gt;False&lt;/code&gt; 时，结果将不需要渐变或与输入断开连接。默认为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ff1cc36eddc3b5f962bb282dc8359cf8c6757bb3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cuda&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, includes CUDA-specific include paths.</source>
          <target state="translated">&lt;strong&gt;cuda&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则包含特定于CUDA的包含路径。</target>
        </trans-unit>
        <trans-unit id="9cc28cf38c3a669932c9eedb3625ab6b9d7054e3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cuda_sources&lt;/strong&gt; &amp;ndash; A string, or list of strings, containing CUDA source code.</source>
          <target state="translated">&lt;strong&gt;cuda_sources&lt;/strong&gt; &amp;ndash;包含CUDA源代码的字符串或字符串列表。</target>
        </trans-unit>
        <trans-unit id="e54fa7d57ec695fdbf3ba8aa44c0d4c97f847f91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;custom_decoder&lt;/strong&gt; &amp;ndash; custom decoder (default=None).</source>
          <target state="translated">&lt;strong&gt;custom_decoder&lt;/strong&gt; &amp;ndash;自定义解码器（默认=无）。</target>
        </trans-unit>
        <trans-unit id="2ca74733e312c67f2657fe95d1e444ee05127650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;custom_encoder&lt;/strong&gt; &amp;ndash; custom encoder (default=None).</source>
          <target state="translated">&lt;strong&gt;custom_encoder&lt;/strong&gt; &amp;ndash;自定义编码器（默认=无）。</target>
        </trans-unit>
        <trans-unit id="ef960edd24412f8d85098fcead2e50c82545528c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;custom_op_name&lt;/strong&gt; &amp;ndash; (temporary) specify this observer for an operator that doesn&amp;rsquo;t require any observation (Can be used in Graph Mode Passes for special case ops).</source>
          <target state="translated">&lt;strong&gt;custom_op_name&lt;/strong&gt; &amp;ndash;（临时）为不需要任何观察的运算符指定此观察器（可在&amp;ldquo;图形模式通过&amp;rdquo;中用于特殊情况的操作）。</target>
        </trans-unit>
        <trans-unit id="7780ca36c95ae6da024d6000ca0554d9dfacacc3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;custom_opsets&lt;/strong&gt; (&lt;em&gt;dict&amp;lt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;int&amp;gt;&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty dict&lt;/em&gt;) &amp;ndash; A dictionary to indicate custom opset domain and version at export. If model contains a custom opset, it is optional to specify the domain and opset version in the dictionary: - KEY: opset domain name - VALUE: opset version If the custom opset is not provided in this dictionary, opset version is set to 1 by default.</source>
          <target state="translated">&lt;strong&gt;custom_opsets&lt;/strong&gt;（&lt;em&gt;dict &amp;lt;string &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;int&amp;gt; &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为空dict&lt;/em&gt;）&amp;ndash;一个字典，用于指示导出时的自定义opset域和版本。如果模型包含自定义opset，则可以在字典中指定域和opset版本：-KEY：opset域名-VALUE：opset版本如果此字典中未提供自定义opset，则opset版本设置为1默认。</target>
        </trans-unit>
        <trans-unit id="9101a0b9856e2d4350718d233a9dcae3bf9c6f6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cutoffs&lt;/strong&gt; (&lt;em&gt;Sequence&lt;/em&gt;) &amp;ndash; Cutoffs used to assign targets to their buckets</source>
          <target state="translated">&lt;strong&gt;临界值&lt;/strong&gt;（&lt;em&gt;序列&lt;/em&gt;）&amp;ndash;用于将目标分配给其存储区的&lt;strong&gt;临界值&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="431606af74f6bc090820c363256988b947cbb9c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;cycle_momentum&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, momentum is cycled inversely to learning rate between &amp;lsquo;base_momentum&amp;rsquo; and &amp;lsquo;max_momentum&amp;rsquo;. Default: True</source>
          <target state="translated">&lt;strong&gt;cycle_momentum&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则动量与&amp;ldquo; base_momentum&amp;rdquo;和&amp;ldquo; max_momentum&amp;rdquo;之间的学习速率成反比。默认值：True</target>
        </trans-unit>
        <trans-unit id="52d9d339631301adfaf686280dfd334d7edccba5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash; the floating point dtype to make the default</source>
          <target state="translated">&lt;strong&gt;d&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;）&amp;ndash;浮点型dtype，使其成为默认值</target>
        </trans-unit>
        <trans-unit id="13964b8d48f242ad146568039b158f92e2df74ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt;) &amp;ndash; If True, force operations to be deterministic. If False, allow non-deterministic operations.</source>
          <target state="translated">&lt;strong&gt;d&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt;）&amp;ndash;如果为True，则强制进行确定性操作。如果为False，则允许进行不确定的操作。</target>
        </trans-unit>
        <trans-unit id="3da5f1488cc8bd47b1fccb5b95f3073259325116" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; path to a local folder to save downloaded models &amp;amp; weights.</source>
          <target state="translated">&lt;strong&gt;d&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;本地文件夹的路径，用于保存下载的模型和权重。</target>
        </trans-unit>
        <trans-unit id="16b912c0275c25fd63373867599edc3ab633da37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d_model&lt;/strong&gt; &amp;ndash; the number of expected features in the encoder/decoder inputs (default=512).</source>
          <target state="translated">&lt;strong&gt;d_model&lt;/strong&gt; &amp;ndash;编码器/解码器输入中的预期功能数（默认= 512）。</target>
        </trans-unit>
        <trans-unit id="15d1f07b9f1bfeb8b51357949749ed27cc1e3a54" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;d_model&lt;/strong&gt; &amp;ndash; the number of expected features in the input (required).</source>
          <target state="translated">&lt;strong&gt;d_model&lt;/strong&gt; &amp;ndash;输入中的预期&lt;strong&gt;要素&lt;/strong&gt;数量（必填）。</target>
        </trans-unit>
        <trans-unit id="e4f81741dff36d8528cc5514641a2dfac6bd1314" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;daemon&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; The spawned processes&amp;rsquo; daemon flag. If set to True, daemonic processes will be created.</source>
          <target state="translated">&lt;strong&gt;daemon&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;生成的进程的守护程序标志。如果设置为True，将创建守护进程。</target>
        </trans-unit>
        <trans-unit id="943dcf17840c35c0ee7c4bb503e78210818b2c15" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dampening&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; dampening for momentum (default: 0)</source>
          <target state="translated">&lt;strong&gt;阻尼&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;阻尼动量（默认值：0）</target>
        </trans-unit>
        <trans-unit id="1751a1c65282c1b2a3f97ccf6353f71f8348524a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; parameter tensor.</source>
          <target state="translated">&lt;strong&gt;data&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;参数张量。</target>
        </trans-unit>
        <trans-unit id="002b70001aea1b9d2d370c56a295bc0004d40317" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;data&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; Initial data for the tensor. Can be a list, tuple, NumPy &lt;code&gt;ndarray&lt;/code&gt;, scalar, and other types.</source>
          <target state="translated">&lt;strong&gt;data&lt;/strong&gt;（&lt;em&gt;array_like&lt;/em&gt;）&amp;ndash;张量的初始数据。可以是列表，元组，NumPy &lt;code&gt;ndarray&lt;/code&gt; ，标量和其他类型。</target>
        </trans-unit>
        <trans-unit id="057f28def548d5eeb6eab40e11d3fc6379b98957" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;data&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; The returned Tensor copies &lt;code&gt;data&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;data&lt;/strong&gt;（&lt;em&gt;array_like&lt;/em&gt;）&amp;ndash;返回的Tensor复制 &lt;code&gt;data&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="495c7caaee4a75dcd9104fe7126eb6bcb5260cb4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;data_source&lt;/strong&gt; (&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;) &amp;ndash; dataset to sample from</source>
          <target state="translated">&lt;strong&gt;data_source&lt;/strong&gt;（&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;）&amp;ndash;要从中采样的数据集</target>
        </trans-unit>
        <trans-unit id="f6cb5164bb06d6da92431aba395fa788fafdd491" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dataformats&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Image data format specification of the form NCHW, NHWC, CHW, HWC, HW, WH, etc.</source>
          <target state="translated">&lt;strong&gt;dataformats&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash; NCHW，NHWC，CHW，HWC，HW，WH等形式的图像数据格式规范</target>
        </trans-unit>
        <trans-unit id="c82013a890247925e2e1ad309f2b481e828a51d2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dataset&lt;/strong&gt; &amp;ndash; Dataset used for sampling.</source>
          <target state="translated">&lt;strong&gt;数据集&lt;/strong&gt;&amp;ndash;用于采样的&lt;strong&gt;数据&lt;/strong&gt;集。</target>
        </trans-unit>
        <trans-unit id="b27874c3d3a54e6026c9501857edee91c6f3d84c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dataset&lt;/strong&gt; (&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;) &amp;ndash; Dataset to be split</source>
          <target state="translated">&lt;strong&gt;数据集&lt;/strong&gt;（&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;）&amp;ndash;要拆分的数据集</target>
        </trans-unit>
        <trans-unit id="28a474719d5dfc1b87e383e8b939d2cee605e0b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dataset&lt;/strong&gt; (&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;) &amp;ndash; The whole Dataset</source>
          <target state="translated">&lt;strong&gt;数据集&lt;/strong&gt;（&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;）&amp;ndash;整个数据集</target>
        </trans-unit>
        <trans-unit id="c82d469055b33fc7c758db3c0e18df50ff5c1c68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dataset&lt;/strong&gt; (&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;) &amp;ndash; dataset from which to load the data.</source>
          <target state="translated">&lt;strong&gt;数据集&lt;/strong&gt;（&lt;a href=&quot;#torch.utils.data.Dataset&quot;&gt;Dataset&lt;/a&gt;）&amp;ndash;从中加载数据的数据集。</target>
        </trans-unit>
        <trans-unit id="f2821891aec8078ce9f410f88ee8adc0c1d56ac2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;datasets&lt;/strong&gt; (&lt;em&gt;iterable of IterableDataset&lt;/em&gt;) &amp;ndash; datasets to be chained together</source>
          <target state="translated">&lt;strong&gt;数据集&lt;/strong&gt;（&lt;em&gt;IterableDataset的iterable&lt;/em&gt;）&amp;ndash;要链接在一起的数据集</target>
        </trans-unit>
        <trans-unit id="ca48c96b9d7b4ef3f9a7801fcc260a515ab45c5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;datasets&lt;/strong&gt; (&lt;em&gt;sequence&lt;/em&gt;) &amp;ndash; List of datasets to be concatenated</source>
          <target state="translated">&lt;strong&gt;数据集&lt;/strong&gt;（&lt;em&gt;序列&lt;/em&gt;）&amp;ndash;要连接的数据集列表</target>
        </trans-unit>
        <trans-unit id="a8a0c46d88dac2ffef33068f3be232119d9b9ac2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;decoder_layer&lt;/strong&gt; &amp;ndash; an instance of the TransformerDecoderLayer() class (required).</source>
          <target state="translated">&lt;strong&gt;coder_layer&lt;/strong&gt; &amp;ndash; TransformerDecoderLayer（）类的实例（必需）。</target>
        </trans-unit>
        <trans-unit id="6debf1cc5a394619a93016d7ca366d8f9a4f042f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Base mask from previous pruning</source>
          <target state="translated">&lt;strong&gt;default_mask&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;先前修剪的基础蒙版</target>
        </trans-unit>
        <trans-unit id="02df0d48c6b8036586e726b50a5fbc9b6e1751a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Base mask from previous pruning iterations, that need to be respected after the new mask is applied. Same dims as &lt;code&gt;t&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;default_mask&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;先前修剪迭代中的基础遮罩，在应用新遮罩之后需要加以注意。与 &lt;code&gt;t&lt;/code&gt; 相同。</target>
        </trans-unit>
        <trans-unit id="5cf70b407f88539d3c6c856333c142253f1a21c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; mask from previous pruning iteration.</source>
          <target state="translated">&lt;strong&gt;default_mask&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;先前修剪迭代的掩码。</target>
        </trans-unit>
        <trans-unit id="25982b74713391159075b7c31f6a1999d645d6fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;default_mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones.</source>
          <target state="translated">&lt;strong&gt;default_mask&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;先前修剪迭代的掩码（如果有）。确定张量应作用于张量的哪一部分时要考虑。如果为None，则默认为1的掩码。</target>
        </trans-unit>
        <trans-unit id="11ad1e4667cafb8dae7d5e1e9a836f9d6bec1dbf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;defaults&lt;/strong&gt; &amp;ndash; (dict): a dict containing default values of optimization options (used when a parameter group doesn&amp;rsquo;t specify them).</source>
          <target state="translated">&lt;strong&gt;默认值&lt;/strong&gt;&amp;ndash;（dict）：包含优化选项默认值的dict（在参数组未指定默认值时使用）。</target>
        </trans-unit>
        <trans-unit id="d2c8995ad4fd81b344f11dc7dbecd0ebd8ded8d5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;descending&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls the sorting order (ascending or descending)</source>
          <target state="translated">&lt;strong&gt;降序&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;控制排序顺序（升序或降序）</target>
        </trans-unit>
        <trans-unit id="de9594f438e4acefd09174ebe985fcf079eb149b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;destination&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; Destination positions for each of the original dims. These must also be unique.</source>
          <target state="translated">&lt;strong&gt;destination&lt;/strong&gt;（&lt;em&gt;python：ints的&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;元组&lt;/em&gt;）&amp;ndash;每个原始昏暗的目标位置。这些也必须是唯一的。</target>
        </trans-unit>
        <trans-unit id="ad7a6d6fbe793b5fadf8461e7bff610a016520c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;destination&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a device on which the output will be placed (default: current device).</source>
          <target state="translated">&lt;strong&gt;destination&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;将在其上放置输出的设备（默认值：当前设备）。</target>
        </trans-unit>
        <trans-unit id="7cda7609bd326665fc6967cfb39795fe07d31662" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;destination&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output device. Can be CPU or CUDA. Default: the current CUDA device.</source>
          <target state="translated">&lt;strong&gt;目的地&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;STR &lt;/a&gt;&lt;em&gt;，或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;） -输出设备。可以是CPU或CUDA。默认值：当前CUDA设备。</target>
        </trans-unit>
        <trans-unit id="7b43c4caf374bfe5b5468766c5d19925926c2fdd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;deterministic&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; flag to choose between a faster non-deterministic calculation, or a slower deterministic calculation. This argument is only available for sparse-dense CUDA bmm. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;确定性&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;用于在较快的非确定性计算或较慢的确定性计算之间进行选择的标志。此参数仅适用于稀疏CUDA bmm。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5fc56af4e93713b99d1309a3048de2e1c75734c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; &amp;ndash; parent device, if any</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;&amp;ndash;父设备（如果有）</target>
        </trans-unit>
        <trans-unit id="67ab079c226c54c3f26e4ea0b6f9a1108b087a49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device for the generator.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;生成器所需的设备。</target>
        </trans-unit>
        <trans-unit id="7a7f07799c9cad3af3cab4816607f53086fcc521" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, defaults to the device of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回张量的所需设备。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则默认为 &lt;code&gt;input&lt;/code&gt; 的设备。</target>
        </trans-unit>
        <trans-unit id="5aed780ae1f47b9761fbfa7992f19ff1ad4f3e5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses the current device for the default tensor type (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). &lt;code&gt;device&lt;/code&gt; will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回张量的所需设备。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则使用当前设备作为默认张量类型（请参阅&lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt; &lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt; &lt;/a&gt;）。对于CPU张量类型， &lt;code&gt;device&lt;/code&gt; 将是CPU；对于CUDA张量类型，设备将是当前CUDA设备。</target>
        </trans-unit>
        <trans-unit id="0f17f4ea64a618a5f0fee4c7ea43e579c17cf49f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). &lt;code&gt;device&lt;/code&gt; will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回张量的所需设备。默认值：如果为None，则使用当前设备作为默认张量类型（请参阅&lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt; &lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt; &lt;/a&gt;）。对于CPU张量类型， &lt;code&gt;device&lt;/code&gt; 将是CPU；对于CUDA张量类型，设备将是当前CUDA设备。</target>
        </trans-unit>
        <trans-unit id="cf93823dec63265c654765453f246b1d85c3b014" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The destination GPU id. Defaults to the current device.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;目标GPU ID。默认为当前设备。</target>
        </trans-unit>
        <trans-unit id="2d93e973425e80658411f9bf156583443e90dc63" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if specified, all parameters will be copied to that device</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果指定，则所有参数都将复制到该设备</target>
        </trans-unit>
        <trans-unit id="a198ab22b8b6fb2b268e0d3eed8f405f9fdfeffb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The destination GPU device. Defaults to the current CUDA device.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;）&amp;ndash;目标GPU设备。默认为当前CUDA设备。</target>
        </trans-unit>
        <trans-unit id="f538c82c744a54f89979310b11620a36e4dfdc67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired device of returned tensor. Default: if None, same &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回张量的所需设备。默认值：如果为None，则与此张量相同的&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="fc2a360e77715b27e5f7a225d2304eaa4a281461" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; device index to select. It&amp;rsquo;s a no-op if this argument is a negative integer or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要选择的设备索引。如果此参数为负整数或 &lt;code&gt;None&lt;/code&gt; ,则为空。</target>
        </trans-unit>
        <trans-unit id="91dd5a21f322151d390c6042702ff47f9a8ffd50" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; selected device. This function is a no-op if this argument is negative.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;选定的设备。如果此参数为负，则此函数为空操作。</target>
        </trans-unit>
        <trans-unit id="35afd1472a6f1ba7d14224aac975eefd6b6cd2c5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The device to return the RNG state of. Default: &lt;code&gt;'cuda'&lt;/code&gt; (i.e., &lt;code&gt;torch.device('cuda')&lt;/code&gt;, the current CUDA device).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;返回其RNG状态的设备。默认值： &lt;code&gt;'cuda'&lt;/code&gt; （即，当前的CUDA设备 &lt;code&gt;torch.device('cuda')&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="524e3a5f4f0a371df8721e9a4a00a6dffbe17aeb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The device to set the RNG state. Default: &lt;code&gt;'cuda'&lt;/code&gt; (i.e., &lt;code&gt;torch.device('cuda')&lt;/code&gt;, the current CUDA device).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;用于设置RNG状态的设备。默认值： &lt;code&gt;'cuda'&lt;/code&gt; （即，当前的CUDA设备 &lt;code&gt;torch.device('cuda')&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="482efc8706169d17d3519e5e1b7705602388b088" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a device on which to allocate the stream. If &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default) or a negative integer, this will use the current device.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;在其上分配流的设备。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值）或负整数，则将使用当前设备。</target>
        </trans-unit>
        <trans-unit id="d6a7697a4d63a3d93b6fa7b16f26465afb5438a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; device for which to return the device capability. This function is a no-op if this argument is a negative integer. It uses the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要为其返回设备功能的设备。如果此参数为负整数，则此函数为空操作。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），它将使用&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给定的当前设备。</target>
        </trans-unit>
        <trans-unit id="b86cc0c543099aaa02324c1e0c85154f5ce025b7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; device for which to return the name. This function is a no-op if this argument is a negative integer. It uses the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要为其返回名称的设备。如果此参数为负整数，则此函数为空操作。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），它将使用&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给定的当前设备。</target>
        </trans-unit>
        <trans-unit id="91c6dae608999a0395dd544cb7f66f964ae5f6a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; device for which to synchronize. It uses the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要与其同步的设备。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），它将使用&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给定的当前设备。</target>
        </trans-unit>
        <trans-unit id="9b7a86c4ef24d2162b92ad5494ba8524c471e009" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; selected device. Returns printout for the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;选定的设备。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），则返回由&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给出的当前设备的打印输出。</target>
        </trans-unit>
        <trans-unit id="a31fcd7dc7985d0551b476dee1e819d3c43477ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; selected device. Returns statistic for the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;选定的设备。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），则返回由&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给出的当前设备的统计信息。</target>
        </trans-unit>
        <trans-unit id="e34164a99196939615beedb15b9c363033a2cce6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; selected device. Returns statistics for the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;选定的设备。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），则返回由&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给出的当前设备的统计信息。</target>
        </trans-unit>
        <trans-unit id="a2d3cbbf169d3884e013d34bd1d45cb9c47424c5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; selected device. Returns the currently selected &lt;a href=&quot;#torch.cuda.Stream&quot;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; for the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;选定的设备。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），则返回由&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给定的当前设备当前选择的&lt;a href=&quot;#torch.cuda.Stream&quot;&gt; &lt;code&gt;Stream&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f23edffe074fe5929a6957bc59ba6621e365b5d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; selected device. Returns the default &lt;a href=&quot;#torch.cuda.Stream&quot;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; for the current device, given by &lt;a href=&quot;#torch.cuda.current_device&quot;&gt;&lt;code&gt;current_device()&lt;/code&gt;&lt;/a&gt;, if &lt;a href=&quot;#torch.cuda.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;选定的设备。如果&lt;a href=&quot;#torch.cuda.device&quot;&gt; &lt;code&gt;device&lt;/code&gt; &lt;/a&gt;为 &lt;code&gt;None&lt;/code&gt; （默认值），则返回当前设备的默认&lt;a href=&quot;#torch.cuda.Stream&quot;&gt; &lt;code&gt;Stream&lt;/code&gt; &lt;/a&gt;，由&lt;a href=&quot;#torch.cuda.current_device&quot;&gt; &lt;code&gt;current_device()&lt;/code&gt; &lt;/a&gt;给出。</target>
        </trans-unit>
        <trans-unit id="16a3ba684b70277c97f3887a32acb68677e89ab5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device&lt;/strong&gt; (&lt;code&gt;torch.device&lt;/code&gt;) &amp;ndash; the desired device of the parameters and buffers in this module</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（ &lt;code&gt;torch.device&lt;/code&gt; ）&amp;ndash;该模块中参数和缓冲区的所需设备</target>
        </trans-unit>
        <trans-unit id="c13cbea5fe853ad61c4e5b6bdc300c90af893ea8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device_ids&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; CUDA devices (default: all devices)</source>
          <target state="translated">&lt;strong&gt;device_ids&lt;/strong&gt;（&lt;em&gt;python：int&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device的&lt;/a&gt;&lt;em&gt;列表&lt;/em&gt;）&amp;ndash; CUDA设备（默认：所有设备）</target>
        </trans-unit>
        <trans-unit id="784500a88b749be8a97a2a8383bb392bde957899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device_ids&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; CUDA devices. This should only be provided when the input module resides on a single CUDA device. For single-device modules, the i&amp;rsquo;th &lt;code&gt;module&lt;/code&gt; replica is placed on &lt;code&gt;device_ids[i]&lt;/code&gt;. For multi-device modules and CPU modules, &lt;code&gt;device_ids&lt;/code&gt; must be &lt;code&gt;None&lt;/code&gt; or an empty list, and input data for the forward pass must be placed on the correct device. (default: all visible devices for single-device modules)</source>
          <target state="translated">&lt;strong&gt;device_ids&lt;/strong&gt;（&lt;em&gt;python：int&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device的&lt;/a&gt;&lt;em&gt;列表&lt;/em&gt;）&amp;ndash; CUDA设备。仅当输入模块位于单个CUDA设备上时才应提供此选项。对于单设备模块，第i个 &lt;code&gt;module&lt;/code&gt; 副本位于 &lt;code&gt;device_ids[i]&lt;/code&gt; 。对于多设备模块和CPU模块， &lt;code&gt;device_ids&lt;/code&gt; 必须为 &lt;code&gt;None&lt;/code&gt; 或为空列表，并且用于正向传递的输入数据必须放置在正确的设备上。（默认值：单设备模块的所有可见设备）</target>
        </trans-unit>
        <trans-unit id="0098733514e18323929fd4ffb49500d3946fa6b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;device_ids&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; GPU ids on which to replicate module</source>
          <target state="translated">&lt;strong&gt;device_ids&lt;/strong&gt;（&lt;em&gt;python：int&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device的&lt;/a&gt;&lt;em&gt;列表&lt;/em&gt;）&amp;ndash;要在其上复制模块的GPU ID</target>
        </trans-unit>
        <trans-unit id="ec258b8275014fd9f0d8c348dbf61e0048a9ad02" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;devices&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; an iterable of GPU devices, among which to broadcast.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash; GPU设备的可迭代对象，在其中进行广播。</target>
        </trans-unit>
        <trans-unit id="a7e837b097fad62cc530d45bef4c54d08f43ec4b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;devices&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; an iterable of GPU devices, among which to broadcast.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;可迭代的GPU设备，在其中进行广播。</target>
        </trans-unit>
        <trans-unit id="bd2dc216feecb49d7c0df172557524a1ed810081" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;devices&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; an iterable of GPU devices, among which to scatter.</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; GPU设备的可迭代对象，其中分散。</target>
        </trans-unit>
        <trans-unit id="c0c9e9433e72da7d6b655bd1674af1bc6aa91348" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;devices&lt;/strong&gt; (&lt;em&gt;iterable of CUDA IDs&lt;/em&gt;) &amp;ndash; CUDA devices for which to fork the RNG. CPU RNG state is always forked. By default, &lt;a href=&quot;#torch.random.fork_rng&quot;&gt;&lt;code&gt;fork_rng()&lt;/code&gt;&lt;/a&gt; operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case. If you explicitly specify devices, this warning will be suppressed</source>
          <target state="translated">&lt;strong&gt;设备&lt;/strong&gt;（&lt;em&gt;可迭代CUDA ID&lt;/em&gt;）&amp;ndash;为其派生RNG的CUDA设备。CPU RNG状态始终为分叉。默认情况下，&lt;a href=&quot;#torch.random.fork_rng&quot;&gt; &lt;code&gt;fork_rng()&lt;/code&gt; &lt;/a&gt;可在所有设备上运行，但是如果您的计算机上有很多设备，则会发出警告，因为在这种情况下此函数运行非常缓慢。如果您明确指定设备，该警告将被取消</target>
        </trans-unit>
        <trans-unit id="fe51b377539155eb88fd8b7d5e4e63c39f630605" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;df1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; degrees of freedom parameter 1</source>
          <target state="translated">&lt;strong&gt;df1&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;自由度参数1</target>
        </trans-unit>
        <trans-unit id="b7e25e21d9c9f6a5a60f7b761df6e51f483ac598" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;df2&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; degrees of freedom parameter 2</source>
          <target state="translated">&lt;strong&gt;df2&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;自由度参数2</target>
        </trans-unit>
        <trans-unit id="26b0cdb742dd7e235595d1a04a5c3e4195cfa892" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;df&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; degrees of freedom</source>
          <target state="translated">&lt;strong&gt;df&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;自由度</target>
        </trans-unit>
        <trans-unit id="cfb7036f636ca1fdb18517254d9eaf9b37f51ea4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;df&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; shape parameter of the distribution</source>
          <target state="translated">&lt;strong&gt;df&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布的形状参数</target>
        </trans-unit>
        <trans-unit id="59e24ff6691679f07576485b92e551a387011363" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;diagonal&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the diagonal to consider</source>
          <target state="translated">&lt;strong&gt;对角线&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要考虑的对角线</target>
        </trans-unit>
        <trans-unit id="98d2682d358cdef81c41f9d22f56660c98f0fea5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; The stride between elements within a sliding window, must be &amp;gt; 0.</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;&amp;ndash;滑动窗口中元素之间的步幅必须&amp;gt; 0。</target>
        </trans-unit>
        <trans-unit id="0a8bcc8e1ce88b2cf0668486e8d5ccbcb8a4d458" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; a parameter that controls the stride of elements in the window</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;&amp;ndash;控制窗口中元素步幅的参数</target>
        </trans-unit>
        <trans-unit id="a8745aafd934cfa2f8a27f7eeb58f0f04b1c8c6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a one-element tuple &lt;code&gt;(dW,)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;&amp;ndash;内核元素之间的间距。可以是一个数字或一个元素的元组 &lt;code&gt;(dW,)&lt;/code&gt; 。默认值：1</target>
        </trans-unit>
        <trans-unit id="e4f0efe675d23b1d986e23b22d467d33af93c1ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dD, dH, dW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;&amp;ndash;内核元素之间的间距。可以是单个数字或元组 &lt;code&gt;(dD, dH, dW)&lt;/code&gt; 。默认值：1</target>
        </trans-unit>
        <trans-unit id="5cc549246c32f7e86fe8237813b71d731de4aeab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dH, dW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;&amp;ndash;内核元素之间的间距。可以是单个数字或元组 &lt;code&gt;(dH, dW)&lt;/code&gt; 。默认值：1</target>
        </trans-unit>
        <trans-unit id="717cd865c4cf98b3ffbd6b2307f6f4dbaebad0c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dT, dH, dW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;&amp;ndash;内核元素之间的间距。可以是单个数字或元组 &lt;code&gt;(dT, dH, dW)&lt;/code&gt; 。默认值：1</target>
        </trans-unit>
        <trans-unit id="9ca358d114492e5781f3c8bd655869b64df6739b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; &amp;ndash; the spacing between kernel elements. Can be a single number or a tuple &lt;code&gt;(dW,)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;&amp;ndash;内核元素之间的间距。可以是单个数字或元组 &lt;code&gt;(dW,)&lt;/code&gt; 。默认值：1</target>
        </trans-unit>
        <trans-unit id="b6d5af4910c01ee195d562c6b5a6bb2027740a67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Spacing between kernel elements. Default: 1</source>
          <target state="translated">&lt;strong&gt;膨胀&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;内核元素之间的间距。默认值：1</target>
        </trans-unit>
        <trans-unit id="abdfdeace9aacba2e41cd643c5ea0e49e917e957" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dilation&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a parameter that controls the stride of elements within the neighborhood. Default: 1</source>
          <target state="translated">&lt;strong&gt;dilation&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;一个参数，用于控制邻域内元素的跨度。默认值：1</target>
        </trans-unit>
        <trans-unit id="472af6ce02e71caf282798bb447e00270b529b2e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim0&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the first dimension to be transposed</source>
          <target state="translated">&lt;strong&gt;dim0&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要转置的第一个尺寸</target>
        </trans-unit>
        <trans-unit id="f765d8f8c40b94958f1eab1cc37007590593d31d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the second dimension to be transposed</source>
          <target state="translated">&lt;strong&gt;dim1&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要转置的第二维</target>
        </trans-unit>
        <trans-unit id="ba65b006661843062287a94ba12a78ac85885543" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; first dimension with respect to which to take diagonal. Default: -2.</source>
          <target state="translated">&lt;strong&gt;dim1&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;取对角线的第一个尺寸。默认值：-2。</target>
        </trans-unit>
        <trans-unit id="0dd1507c4f8260c289a9910df29cf487d663e95d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim1&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; first dimension with respect to which to take diagonal. Default: 0.</source>
          <target state="translated">&lt;strong&gt;dim1&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;取对角线的第一个尺寸。默认值：0</target>
        </trans-unit>
        <trans-unit id="83aa8a523aec2c1ab6551640eaf4cb51b830a4c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim2&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; second dimension with respect to which to take diagonal. Default: -1.</source>
          <target state="translated">&lt;strong&gt;dim2&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;取对角线的第二维。默认值：-1。</target>
        </trans-unit>
        <trans-unit id="a71ef13a1ad5cb6ea968b4d4719be6d5961ef225" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim2&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; second dimension with respect to which to take diagonal. Default: 1.</source>
          <target state="translated">&lt;strong&gt;dim2&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;取对角线的第二维。默认值：1。</target>
        </trans-unit>
        <trans-unit id="c9b4a2ca457fba9669e7f8ced2b7ed6c30268fd6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which LogSoftmax will be computed.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将用来计算LogSoftmax的维。</target>
        </trans-unit>
        <trans-unit id="34032d1dca3a055630ebba7923bebf4f47a22c38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which Softmax will be computed (so every slice along dim will sum to 1).</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将沿着其计算Softmax的尺寸（因此，沿着dim的每个切片的总和为1）。</target>
        </trans-unit>
        <trans-unit id="01189dd75e2eefc978065b5ff2c0b7f87388d39e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which Softmin will be computed (so every slice along dim will sum to 1).</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将计算Softmin的维度（因此，沿着dim的每个切片的总和为1）。</target>
        </trans-unit>
        <trans-unit id="842005dbd132f5ef7d384c1fccbadec279da8f7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which log_softmax will be computed.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;用来计算log_softmax的维。</target>
        </trans-unit>
        <trans-unit id="fb8ee0a50b62dc6ae83f365bac143af1c17f1fd6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which softmax will be computed.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将沿着其计算softmax的尺寸。</target>
        </trans-unit>
        <trans-unit id="01b7d7748905016190ad5e2bbe8293a9c597a66c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which softmax will be computed. Default: -1.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将沿着其计算softmax的尺寸。默认值：-1。</target>
        </trans-unit>
        <trans-unit id="2777bb64e36f761c1f00ee5be70a591e4cd2145d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; A dimension along which softmin will be computed (so every slice along dim will sum to 1).</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将计算softmin的维度（因此，沿着dim的每个切片的总和为1）。</target>
        </trans-unit>
        <trans-unit id="88bb112f612fa4c72a0f99f7a672d75b2554455b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The dimension along which to integrate. By default, use the last dimension.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;积分所沿的维度。默认情况下，使用最后一个尺寸。</target>
        </trans-unit>
        <trans-unit id="90f0ee8c3c7b4d5b8a5616f19077bcfded77ea98" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension along which to index</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;索引所依据的维度</target>
        </trans-unit>
        <trans-unit id="b8ce25c1fd3bbad54cc79c92db33a7f9d23196c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension along which to split the tensor</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;分割张量的尺寸</target>
        </trans-unit>
        <trans-unit id="3a9295ba14ea4badc07f27ea8db556fe8e515b0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension along which to split the tensor.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;分割张量的尺寸。</target>
        </trans-unit>
        <trans-unit id="2a971edb34aad20abc50873c653c145b3af96b2a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension on which to split the input. Default: -1</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;分割输入的维度。默认值：-1</target>
        </trans-unit>
        <trans-unit id="bf3801597d3facaa2cf443350498f58cd1324abb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension to insert. Has to be between 0 and the number of dimensions of concatenated tensors (inclusive)</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要插入的尺寸。必须在0到级联张量的维数之间（包括）</target>
        </trans-unit>
        <trans-unit id="2e66e4cf2db711439adae127683b487fd7e64123" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension to remove</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要移除的尺寸</target>
        </trans-unit>
        <trans-unit id="c917eaab2e1d73b163be73789e03b1bc35b48a89" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; index of the dim along which we define channels to prune.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;暗淡的索引，我们通过该索引定义修剪的通道。</target>
        </trans-unit>
        <trans-unit id="7285e77d113e976c86c60be543b1f43be38c5bdd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the axis along which to index</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;索引所沿的轴</target>
        </trans-unit>
        <trans-unit id="4e017cd401e156f255b917cbb7d73173fc5184a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension along which to narrow</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;缩小的尺寸</target>
        </trans-unit>
        <trans-unit id="7415821de8da0f78deed554d7e45d50759c33f0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension in which we index</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;我们索引的维度</target>
        </trans-unit>
        <trans-unit id="be8bc5d715865fc115635841b9517c75441ff8f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to apply unique. If &lt;code&gt;None&lt;/code&gt;, the unique of the flattened input is returned. default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;应用唯一的尺寸。如果为 &lt;code&gt;None&lt;/code&gt; ，则返回扁平化输入的唯一性。默认值： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4849740fe6ccbd59b0ec458f024b413bf6df7857" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to do the operation over</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;执行操作的尺寸</target>
        </trans-unit>
        <trans-unit id="9dfe268e0c2ab5c49cd99f8395aef6a384d8dd63" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;缩小的尺寸</target>
        </trans-unit>
        <trans-unit id="a0cd1da8b56960f63a95d25cf0421a937673e2ed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;缩小的尺寸。</target>
        </trans-unit>
        <trans-unit id="b8d7f0790b12bc35fd47df215177efe265599f93" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce. Default: 1</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;缩小的尺寸。默认值：1</target>
        </trans-unit>
        <trans-unit id="04661f26e0a90dbee7adeed063722879cc2dbedc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce. If &lt;code&gt;None&lt;/code&gt;, the argmax of the flattened input is returned.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;缩小的尺寸。如果为 &lt;code&gt;None&lt;/code&gt; ，则返回扁平化输入的argmax。</target>
        </trans-unit>
        <trans-unit id="406a26e14fe614e1dacddd572bc1dbd6bd5aa6a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to reduce. If &lt;code&gt;None&lt;/code&gt;, the argmin of the flattened input is returned.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;缩小的尺寸。如果为 &lt;code&gt;None&lt;/code&gt; ，则返回拼合输入的argmin。</target>
        </trans-unit>
        <trans-unit id="d3e09769491b63675c94e11c9dea885116b4a2fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to slice</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;切片的尺寸</target>
        </trans-unit>
        <trans-unit id="8317062bcf63e96ea89234edaf5254e1da5bcb47" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the dimension to slice over to get the sub-tensors</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;切片以获得次张量的尺寸</target>
        </trans-unit>
        <trans-unit id="c54f0ef48043a5bec2dfca3a0f530fb8661be4ca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the index at which to insert the singleton dimension</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;插入单例尺寸的索引</target>
        </trans-unit>
        <trans-unit id="d89796e28feb4305a6e51573710dca2759c32ff1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; a dimension or a list of dimensions to reduce. Default: reduce over all dims.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;em&gt;python：ints的&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;元组&lt;/em&gt;）&amp;ndash;一个要减小的尺寸或尺寸列表。默认值：减少所有暗淡。</target>
        </trans-unit>
        <trans-unit id="f1addd18afe889496111cce39db43031d3782741" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the dimension or dimensions to reduce.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;em&gt;python：ints的&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;元组&lt;/em&gt;）&amp;ndash;要减小的尺寸。</target>
        </trans-unit>
        <trans-unit id="74f088f545a1351da755347a9f47abc2c5b4f78d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dim or tuple of dims along which to count non-zeros.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;em&gt;python：ints的&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;tuple &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;暗淡的dim或元组，沿着它们计算非零。</target>
        </trans-unit>
        <trans-unit id="7ea1a19f10e224b77d5a38dec1768437b4ef777c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-tuple of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-list of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;dim&lt;/code&gt; is an int, vector norm will be calculated over the specified dimension. If &lt;code&gt;dim&lt;/code&gt; is a 2-tuple of ints, matrix norm will be calculated over the specified dimensions. If &lt;code&gt;dim&lt;/code&gt; is None, matrix norm will be calculated when the input tensor has two dimensions, and vector norm will be calculated when the input tensor has one dimension. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;暗淡&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;蟒的2元组：整数&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;蟒2-列表：整数&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;） -如果 &lt;code&gt;dim&lt;/code&gt; 是int，矢量范数将在指定的尺寸来计算。如果 &lt;code&gt;dim&lt;/code&gt; 是整数的2元组，则将在指定维上计算矩阵范数。如果 &lt;code&gt;dim&lt;/code&gt; 为None，则输入张量为二维时将计算矩阵范数，输入张量为一维时将计算向量范数。默认值： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b085e1cc1d870668a83baea40b3506508d9b0a8b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-tuple of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;2-list of python:ints&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If it is an int, vector norm will be calculated, if it is 2-tuple of ints, matrix norm will be calculated. If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension. If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.</source>
          <target state="translated">&lt;strong&gt;暗淡&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;蟒的2元组：整数&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;蟒2-列表：整数&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;） -如果它是一个int，矢量范数将被计算，如果是整数的2元组，矩阵范数将被计算。如果值为None，则当输入张量仅具有二维时，将计算矩阵范数，而当输入张量仅具有一维时，将计算矢量范数。如果输入张量具有两个以上的维，则矢量范数将应用于最后一个维。</target>
        </trans-unit>
        <trans-unit id="2bf5f25244b6a84fc607cb219deedd353fc0f81e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A dimension along which to chunk &lt;code&gt;tensor&lt;/code&gt;. Default: &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;沿其 &lt;code&gt;tensor&lt;/code&gt; 紧张量的尺寸。默认： &lt;code&gt;0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="39551d8784237f98effe67d5d4fa079ab6e2d66d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimension of vectors. Default: 1</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;向量的维数。默认值：1</target>
        </trans-unit>
        <trans-unit id="7c530107de3a1e8849bcffa15e8fece38f241cc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimension where cosine similarity is computed. Default: 1</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;计算余弦相似度的维。默认值：1</target>
        </trans-unit>
        <trans-unit id="9439b0c674bc7c434adc98d580848f39ed9d115e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to repeat values. By default, use the flattened input array, and return a flat output array.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;沿其重复值的尺寸。默认情况下，使用展平的输入数组，并返回展平的输出数组。</target>
        </trans-unit>
        <trans-unit id="c36ee04034363ccdd358a7c5f8322922bf781fba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional FFT.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;进行一维FFT的维数。</target>
        </trans-unit>
        <trans-unit id="45818af3fdbc4684e20729f70925408319f7b2e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional Hermitian FFT.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;采取一维Hermitian FFT的方向。</target>
        </trans-unit>
        <trans-unit id="e290320ee25d598ee056c54b55e12ed854c6dd23" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional Hermitian IFFT.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;采取一维Hermitian IFFT的方向。</target>
        </trans-unit>
        <trans-unit id="f5f98ff50ef003b2c77b0c55e3bf6a58a74600f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional IFFT.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;采取一维IFFT的方向。</target>
        </trans-unit>
        <trans-unit id="d4bb3ea939e2fa64fe7995582d47d53ee2e17ec4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional real FFT.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;采取一维实数FFT的方向。</target>
        </trans-unit>
        <trans-unit id="dea0a42312b17fe5fe3428922ce27d374ec46837" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The dimension along which to take the one dimensional real IFFT.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;采取一维实际IFFT的方向。</target>
        </trans-unit>
        <trans-unit id="0e62a9f3a5435dd4296d863ba5100409f37e345d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a dimension along which the tensors will be concatenated. Default: &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;将张量连接在一起的尺寸。默认： &lt;code&gt;0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d32f4b0a48eae0a94c40f8913aaafd8fc5b4e99b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; dimension corresponding to number of outputs, the default is &lt;code&gt;0&lt;/code&gt;, except for modules that are instances of ConvTranspose{1,2,3}d, when it is &lt;code&gt;1&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;对应于输出数量的尺寸，默认值为 &lt;code&gt;0&lt;/code&gt; ，除了作为ConvTranspose {1,2,3} d实例的模块，当它为 &lt;code&gt;1&lt;/code&gt; 时</target>
        </trans-unit>
        <trans-unit id="0ff766b40b5bcbfe08f64170324fb2f4d6bf84af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; dimension over which to compute the norm</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;计算范数的维</target>
        </trans-unit>
        <trans-unit id="a409409533f64a991397140f0cfeef5685c9fa1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if given, the input will be squeezed only in this dimension</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果给定，则仅在此维度上压缩输入</target>
        </trans-unit>
        <trans-unit id="05043e9f4aa7115561003ddcb8522351f1c5f51e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; index of the dim along which we define channels to prune. Default: -1.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;暗淡的索引，沿着该索引定义修剪的通道。默认值：-1。</target>
        </trans-unit>
        <trans-unit id="4945ffee136e1eca9138593201351feb8ce974a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the desired dimension in which stride is required</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;需要步幅的所需尺寸</target>
        </trans-unit>
        <trans-unit id="cd4c3985b4741ed95097721d4f15edc8c371b9f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension over which the tensors are concatenated</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;张量连接的尺寸</target>
        </trans-unit>
        <trans-unit id="e9ff0c74674eab95e6f6442b562b6f45f41a7a9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension to find the kth value along</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;查找第k个值的尺寸</target>
        </trans-unit>
        <trans-unit id="9422d28d87b196679cbb0c82259c774161568b6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension to sort along</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;要排序的维度</target>
        </trans-unit>
        <trans-unit id="28c1fc242c3e6d093897709fa5e6ddd3f6f9dd3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the dimension to take the cross-product in.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;取叉积的尺寸。</target>
        </trans-unit>
        <trans-unit id="fa74b5fd1d3a59aa2fc20f8e622f3d996cbd575d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimensions to be transformed. Default: all dimensions, or the last &lt;code&gt;len(s)&lt;/code&gt; dimensions if &lt;code&gt;s&lt;/code&gt; is given.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要转换的尺寸。默认值：所有尺寸，如果已指定 &lt;code&gt;s&lt;/code&gt; ,则为最后一个 &lt;code&gt;len(s)&lt;/code&gt; 尺寸。</target>
        </trans-unit>
        <trans-unit id="714e04567ca514a499d3251ac5bce29de688ec57" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Dimensions to be transformed. The last dimension must be the half-Hermitian compressed dimension. Default: all dimensions, or the last &lt;code&gt;len(s)&lt;/code&gt; dimensions if &lt;code&gt;s&lt;/code&gt; is given.</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要转换的尺寸。最后一个尺寸必须是半赫密特压缩尺寸。默认值：所有尺寸，如果已指定 &lt;code&gt;s&lt;/code&gt; ,则为最后一个 &lt;code&gt;len(s)&lt;/code&gt; 尺寸。</target>
        </trans-unit>
        <trans-unit id="1c73040a5128f371bcddeab377f515339135506e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Dimension to be unflattened</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;em&gt;Union &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;要展平的尺寸</target>
        </trans-unit>
        <trans-unit id="612979d2207bccfbcbdc71c971749078ecad7740" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Dimension to unflatten</source>
          <target state="translated">&lt;strong&gt;dim&lt;/strong&gt;（&lt;em&gt;Union &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;要展平的尺寸</target>
        </trans-unit>
        <trans-unit id="d9f96b0e996218b63b5f6697be8d86971ef5ef58" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dim_feedforward&lt;/strong&gt; &amp;ndash; the dimension of the feedforward network model (default=2048).</source>
          <target state="translated">&lt;strong&gt;dim_feedforward&lt;/strong&gt; &amp;ndash;前馈网络模型的尺寸（默认= 2048）。</target>
        </trans-unit>
        <trans-unit id="61d8fc5ddd343a37fbd282f3894946f478ef2ebb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dimension&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; dimension in which unfolding happens</source>
          <target state="translated">&lt;strong&gt;维度&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;展开发生的维度</target>
        </trans-unit>
        <trans-unit id="e3b04003348060ae8bd467525af95608436f8504" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dimension&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;) &amp;ndash; The dimensionality of the sequence to be drawn</source>
          <target state="translated">&lt;strong&gt;Dimensions&lt;/strong&gt;（&lt;em&gt;Int&lt;/em&gt;）&amp;ndash;要绘制的序列的维数</target>
        </trans-unit>
        <trans-unit id="d084aae186e1378df8faf988ddfde110dfb17385" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; Axis along which to roll</source>
          <target state="translated">&lt;strong&gt;dims&lt;/strong&gt;（&lt;em&gt;python：ints的&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;元组&lt;/em&gt;）&amp;ndash;滚动所沿的轴</target>
        </trans-unit>
        <trans-unit id="c317ee80d0d1d374392208d23e06bdc1d0a08445" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of two lists of python:integers&lt;/em&gt;) &amp;ndash; number of dimensions to contract or explicit lists of dimensions for &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; respectively</source>
          <target state="translated">&lt;strong&gt;变暗&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;：整数蟒两个列表的元组&lt;/em&gt;尺寸合同或尺寸的显式列表的数- ） &lt;code&gt;a&lt;/code&gt; 和 &lt;code&gt;b&lt;/code&gt; 分别</target>
        </trans-unit>
        <trans-unit id="391fb595ce6469da76a43990e1b4fedec4415935" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;em&gt;a list&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; axis to flip on</source>
          <target state="translated">&lt;strong&gt;变暗&lt;/strong&gt;（&lt;em&gt;列表&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;元组&lt;/a&gt;）&amp;ndash;要翻转的轴</target>
        </trans-unit>
        <trans-unit id="fa53309859ad0bb426190a8468616e70a2c2d3ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dims&lt;/strong&gt; (&lt;em&gt;a list&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; axis to rotate</source>
          <target state="translated">&lt;strong&gt;变暗&lt;/strong&gt;（&lt;em&gt;列表&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;元组&lt;/a&gt;）&amp;ndash;旋转轴</target>
        </trans-unit>
        <trans-unit id="4b48119f623a86e0e73cdb61d4b28812b330622a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;distance_function&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A nonnegative, real-valued function that quantifies the closeness of two tensors. If not specified, &lt;code&gt;nn.PairwiseDistance&lt;/code&gt; will be used. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;distance_function&lt;/strong&gt;（&lt;em&gt;callable &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;一个非负的实数值函数，用于量化两个张量的紧密度。如果未指定，将使用 &lt;code&gt;nn.PairwiseDistance&lt;/code&gt; 。默认值： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ac42c880b1e94d04cad8388a60263bbcb36b448f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;div_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Determines the initial learning rate via initial_lr = max_lr/div_factor Default: 25</source>
          <target state="translated">&lt;strong&gt;div_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;通过initial_lr = max_lr / div_factor确定初始学习率默认值：25</target>
        </trans-unit>
        <trans-unit id="d9fdd902ea3281b80f4ee9c58cfabafd6bc9880d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;div_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; value used as an exponent to compute sizes of the clusters. Default: 4.0</source>
          <target state="translated">&lt;strong&gt;div_value&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;用作计算集群大小的指数的值。默认值：4.0</target>
        </trans-unit>
        <trans-unit id="2ed00f6805ef09c53fd3940b48ac159868ff1969" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;divide_by_initial_world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, will divide gradients by the initial &lt;code&gt;world_size&lt;/code&gt; DDP training was launched with. If &lt;code&gt;False&lt;/code&gt;, will compute the effective world size (number of ranks that have not depleted their inputs yet) and divide gradients by that during allreduce. Set &lt;code&gt;divide_by_initial_world_size=True&lt;/code&gt; to ensure every input sample including the uneven inputs have equal weight in terms of how much they contribute to the global gradient. This is achieved by always dividing the gradient by the initial &lt;code&gt;world_size&lt;/code&gt; even when we encounter uneven inputs. If you set this to &lt;code&gt;False&lt;/code&gt;, we divide the gradient by the remaining number of nodes. This ensures parity with training on a smaller &lt;code&gt;world_size&lt;/code&gt; although it also means the uneven inputs would contribute more towards the global gradient. Typically, you would want to set this to &lt;code&gt;True&lt;/code&gt; for cases where the last few inputs of your training job are uneven. In extreme cases, where there is a large discrepancy in the number of inputs, setting this to &lt;code&gt;False&lt;/code&gt; might provide better results.</source>
          <target state="translated">&lt;strong&gt;split_by_initial_world_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则将梯度除以最初使用的 &lt;code&gt;world_size&lt;/code&gt; DDP训练开始。如果为 &lt;code&gt;False&lt;/code&gt; ，将计算有效的世界大小（尚未耗尽其输入的等级数），并在减少过程中将梯度除以有效的世界大小。设置 &lt;code&gt;divide_by_initial_world_size=True&lt;/code&gt; 以确保每个输入样本（包括不均匀输入）在权重对全局梯度的贡献方面均具有相同的权重。这是通过始终将梯度除以初始 &lt;code&gt;world_size&lt;/code&gt; 来实现的，即使遇到不均匀的输入也是如此。如果将此设置为 &lt;code&gt;False&lt;/code&gt; ，我们将梯度除以剩余的节点数。尽管这也意味着不均衡的投入将对全球梯度做出更大的贡献，但这可以确保与较小的 &lt;code&gt;world_size&lt;/code&gt; 上的培训保持一致。通常，对于培训工作的最后几个输入不均匀的情况，您可能希望将其设置为 &lt;code&gt;True&lt;/code&gt; 。在极端情况下，输入数量存在较大差异，将其设置为 &lt;code&gt;False&lt;/code&gt; 可能会提供更好的结果。</target>
        </trans-unit>
        <trans-unit id="049bcce7df5c629c4fad3f80f7fb581f440c0337" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;divisor_override&lt;/strong&gt; &amp;ndash; if specified, it will be used as divisor, otherwise &lt;code&gt;kernel_size&lt;/code&gt; will be used</source>
          <target state="translated">&lt;strong&gt;divisor_override&lt;/strong&gt; &amp;ndash;如果指定，它将用作除数，否则将使用 &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="853252d1cb8e53ec5f6c1f1eee0e317901dfd0af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;divisor_override&lt;/strong&gt; &amp;ndash; if specified, it will be used as divisor, otherwise size of the pooling region will be used. Default: None</source>
          <target state="translated">&lt;strong&gt;divisor_override&lt;/strong&gt; &amp;ndash;如果指定，它将用作除数，否则将使用池化区域的大小。默认值：无</target>
        </trans-unit>
        <trans-unit id="25dd43997ffb2286d38c5c4ea638d851750fdcd1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dlpack&lt;/strong&gt; &amp;ndash; a PyCapsule object with the dltensor</source>
          <target state="translated">&lt;strong&gt;dlpack&lt;/strong&gt; &amp;ndash;具有dltensor的PyCapsule对象</target>
        </trans-unit>
        <trans-unit id="79e803c5014bf096c8b936c68165b4355eadf0c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;do_constant_folding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; If True, the constant-folding optimization is applied to the model during export. Constant-folding optimization will replace some of the ops that have all constant inputs, with pre-computed constant nodes.</source>
          <target state="translated">&lt;strong&gt;do_constant_folding&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为False&lt;/em&gt;）&amp;ndash;如果为True，则在导出过程中将恒定折叠优化应用于模型。常量折叠优化将用预先计算的常量节点替换一些具有所有常量输入的操作。</target>
        </trans-unit>
        <trans-unit id="646458e97020d6122f679938c4abf38f5fbbe39e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;drop_last&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the sampler will drop the last batch if its size would be less than &lt;code&gt;batch_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;drop_last&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则采样器将在其大小小于 &lt;code&gt;batch_size&lt;/code&gt; 的情况下删除最后一批</target>
        </trans-unit>
        <trans-unit id="7c66830184f5687c6e020fb4f42341d30ed6c7ea" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;drop_last&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, then the sampler will drop the tail of the data to make it evenly divisible across the number of replicas. If &lt;code&gt;False&lt;/code&gt;, the sampler will add extra indices to make the data evenly divisible across the replicas. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;drop_last&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则采样器将删除数据的尾部，以使其在多个副本中均等地被整除。如果为 &lt;code&gt;False&lt;/code&gt; ，则采样器将添加额外的索引，以使数据在副本中均匀可分割。默认值： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2a7a53e8243b7f017759831c1f7997760e354a4f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;drop_last&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; set to &lt;code&gt;True&lt;/code&gt; to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If &lt;code&gt;False&lt;/code&gt; and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;drop_last&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;设置为 &lt;code&gt;True&lt;/code&gt; 以删除最后一个不完整的批次，如果该数据集大小不能被该批次大小整除。如果为 &lt;code&gt;False&lt;/code&gt; 并且数据集的大小不能被批次大小整除，则最后一批将较小。（默认： &lt;code&gt;False&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="93e1868e986f20e5fceebb1ba081741a9c11926d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; If non-zero, introduces a &lt;code&gt;Dropout&lt;/code&gt; layer on the outputs of each GRU layer except the last layer, with dropout probability equal to &lt;code&gt;dropout&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash;如果非零，则在除最后一层之外的每个GRU层的输出上引入一个 &lt;code&gt;Dropout&lt;/code&gt; 层，其丢弃概率等于 &lt;code&gt;dropout&lt;/code&gt; 。默认值：0</target>
        </trans-unit>
        <trans-unit id="f1651899fbda49e6928ea8a0d295e3cfc914c011" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; If non-zero, introduces a &lt;code&gt;Dropout&lt;/code&gt; layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to &lt;code&gt;dropout&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash;如果不为零，则在除最后一层之外的每个LSTM层的输出上引入一个 &lt;code&gt;Dropout&lt;/code&gt; 层，其丢弃概率等于 &lt;code&gt;dropout&lt;/code&gt; 。默认值：0</target>
        </trans-unit>
        <trans-unit id="96b84bd1caf45dc07546855562b7416fae84878a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; If non-zero, introduces a &lt;code&gt;Dropout&lt;/code&gt; layer on the outputs of each RNN layer except the last layer, with dropout probability equal to &lt;code&gt;dropout&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash;如果非零，则在除最后一层之外的每个RNN层的输出上引入一个 &lt;code&gt;Dropout&lt;/code&gt; 层，其丢弃概率等于 &lt;code&gt;dropout&lt;/code&gt; 。默认值：0</target>
        </trans-unit>
        <trans-unit id="5f96b6d7bf1dc804d0874288692d31f0b71cf772" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; a Dropout layer on attn_output_weights. Default: 0.0.</source>
          <target state="translated">&lt;strong&gt;差&lt;/strong&gt;-上attn_output_weights一个漏失层。默认值：0.0。</target>
        </trans-unit>
        <trans-unit id="ea212a4ef049bb5d0535242d99d1a83d7b9f7d0a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash; the dropout value (default=0.1).</source>
          <target state="translated">&lt;strong&gt;dropout&lt;/strong&gt; &amp;ndash;退出值（默认值= 0.1）。</target>
        </trans-unit>
        <trans-unit id="16fb29d21cd7a9ad4206efc9c506ce5a9cf98a02" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Destination rank</source>
          <target state="translated">&lt;strong&gt;dst&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;目标排名</target>
        </trans-unit>
        <trans-unit id="ebbff8f7d1835173bbe908168f4d760a0e927d2a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Destination rank.</source>
          <target state="translated">&lt;strong&gt;dst&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;目标排名。</target>
        </trans-unit>
        <trans-unit id="c997f09b2bb6f5bbe4285b29caa42aeff58eb4c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Destination rank (default is 0)</source>
          <target state="translated">&lt;strong&gt;dst&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;目标排名（默认为0）</target>
        </trans-unit>
        <trans-unit id="15d2bdadaa3b397c334c7c569c4166d8c09f9b73" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Full path where object will be saved, e.g. &lt;code&gt;/tmp/temporary_file&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;dst&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;保存对象的完整路径，例如 &lt;code&gt;/tmp/temporary_file&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1bb062fcb22edc7afbb4e01d163cf5831e179573" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst_tensor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Destination tensor rank within &lt;code&gt;tensor_list&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;dst_tensor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; &lt;code&gt;tensor_list&lt;/code&gt; 中的目标张量等级</target>
        </trans-unit>
        <trans-unit id="819196b391e0255903f0858db2143983b3dedb91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dst_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string&lt;/em&gt;) &amp;ndash; the desired type</source>
          <target state="translated">&lt;strong&gt;dst_type&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;类型&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;所需的类型</target>
        </trans-unit>
        <trans-unit id="cb25a7ac765f2f5fe4e4d54278609b6627eae92b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash; Quantized data type</source>
          <target state="translated">&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash;量化数据类型</target>
        </trans-unit>
        <trans-unit id="9a4c495b44f4761667112255e495ba6d941ec366" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash; data type of output Quantized Tensor</source>
          <target state="translated">&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash;输出量化张量的数据类型</target>
        </trans-unit>
        <trans-unit id="c1da9e6e49781bd49b10cf164e54cc534c373f2b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash; quantization data type to use. Default: &lt;code&gt;torch.quint8&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;dtype&lt;/strong&gt; &amp;ndash;要使用的量化数据类型。默认值： &lt;code&gt;torch.quint8&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e8b67954b83b4c9aa34630f43e704bf025dc94fd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash; the desired data type of returned tensor. Has to be one of the quantized dtypes: &lt;code&gt;torch.quint8&lt;/code&gt;, &lt;code&gt;torch.qint8&lt;/code&gt;, &lt;code&gt;torch.qint32&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;） -返回的张量的所希望的数据类型。必须是量化的dtypes之一： &lt;code&gt;torch.quint8&lt;/code&gt; ， &lt;code&gt;torch.qint8&lt;/code&gt; ， &lt;code&gt;torch.qint32&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3e55ae84264ba3b49b96fa73c9f49b02e373e50a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned Tensor. Default: if &lt;code&gt;None&lt;/code&gt;, defaults to the dtype of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -所需的数据返回张量的类型。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则默认为 &lt;code&gt;input&lt;/code&gt; 的dtype 。</target>
        </trans-unit>
        <trans-unit id="36bd900451348a91ef9ce9e64799f6d5a6c72b59" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: &lt;code&gt;torch.int64&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。默认值： &lt;code&gt;torch.int64&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1d58f90cb68e79cff8b96e7dc86dd4a2d5606995" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;torch.long&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ， &lt;code&gt;torch.long&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1d27c0b19831af56deba70f9352bc038b1e9a426" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, infers data type from &lt;code&gt;data&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则从 &lt;code&gt;data&lt;/code&gt; 推断数据类型。</target>
        </trans-unit>
        <trans-unit id="754f71e33b12e157331fb5bf10e0619a8ecbce0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses a global default (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则使用全局默认值（请参阅&lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt; &lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="5e1aa8968192882a073c78793ea32a16dd1c21d1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses a global default (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). If &lt;code&gt;dtype&lt;/code&gt; is not given, infer the data type from the other input arguments. If any of &lt;code&gt;start&lt;/code&gt;, &lt;code&gt;end&lt;/code&gt;, or &lt;code&gt;stop&lt;/code&gt; are floating-point, the &lt;code&gt;dtype&lt;/code&gt; is inferred to be the default dtype, see &lt;a href=&quot;torch.get_default_dtype#torch.get_default_dtype&quot;&gt;&lt;code&gt;get_default_dtype()&lt;/code&gt;&lt;/a&gt;. Otherwise, the &lt;code&gt;dtype&lt;/code&gt; is inferred to be &lt;code&gt;torch.int64&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则使用全局默认值（请参阅&lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt; &lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt; &lt;/a&gt;）。如果未给出 &lt;code&gt;dtype&lt;/code&gt; ，则从其他输入参数推断数据类型。如果 &lt;code&gt;start&lt;/code&gt; ， &lt;code&gt;end&lt;/code&gt; 或 &lt;code&gt;stop&lt;/code&gt; 中的任何一个都是浮点数，则将 &lt;code&gt;dtype&lt;/code&gt; 推断为默认&lt;a href=&quot;torch.get_default_dtype#torch.get_default_dtype&quot;&gt; &lt;code&gt;get_default_dtype()&lt;/code&gt; &lt;/a&gt;，请参见get_default_dtype（）。否则， &lt;code&gt;dtype&lt;/code&gt; 被推断为 &lt;code&gt;torch.int64&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3b423086bd082fcebc5a428940e93eeaaa4a7025" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, uses a global default (see &lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt;&lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt;&lt;/a&gt;). Only floating point types are supported.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则使用全局默认值（请参阅&lt;a href=&quot;torch.set_default_tensor_type#torch.set_default_tensor_type&quot;&gt; &lt;code&gt;torch.set_default_tensor_type()&lt;/code&gt; &lt;/a&gt;）。仅支持浮点类型。</target>
        </trans-unit>
        <trans-unit id="1f1237018b147643a39f3e093d71d66749f7520f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. Default: if None, infers data type from &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。默认值：如果为None，则从 &lt;code&gt;values&lt;/code&gt; 推断数据类型。</target>
        </trans-unit>
        <trans-unit id="242051541efaa2777f5472bfe169a3381046ea24" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. If specified, the input tensor is casted to :attr:&amp;rsquo;dtype&amp;rsquo; while performing the operation. Default: None.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。如果指定，则在执行操作时将输入张量强制转换为：attr：'dtype'。默认值：无。</target>
        </trans-unit>
        <trans-unit id="802bfb2cb709fdad8389996e31ce1fc046b7a6a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired data type of returned tensor. If specified, the input tensor is casted to &lt;code&gt;dtype&lt;/code&gt; before the operation is performed. This is useful for preventing data type overflows. Default: None.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所希望的数据类型。如果指定，则在执行操作之前将输入张量强制转换为 &lt;code&gt;dtype&lt;/code&gt; 。这对于防止数据类型溢出很有用。默认值：无。</target>
        </trans-unit>
        <trans-unit id="bf97cc7b5c225fd6d7e718d925da7641ae8dd16c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string&lt;/em&gt;) &amp;ndash; The desired type</source>
          <target state="translated">&lt;strong&gt;dtype&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;类型&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;所需的类型</target>
        </trans-unit>
        <trans-unit id="697b78c37ec8949c304299db02bbd09794133985" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired type of returned tensor. Default: if None, same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;，可选） -返回的张量的所期望的类型。默认值：如果为None，则与此张量相同的&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e6ad67e837a7a5413b747672aa87555a7798fda9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;) &amp;ndash; the desired floating point type of the floating point parameters and buffers in this module</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（ &lt;code&gt;torch.dtype&lt;/code&gt; ） -所需的浮点类型的浮点参数和缓冲液在该模块中的</target>
        </trans-unit>
        <trans-unit id="f854a7599c513f55feb63cd3cceed0c39260832a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; If specified, the input tensor is cast to &lt;code&gt;dtype&lt;/code&gt; before performing the operation, and the returned tensor&amp;rsquo;s type will be &lt;code&gt;dtype&lt;/code&gt;. If this argument is used in conjunction with the &lt;code&gt;out&lt;/code&gt; argument, the output tensor&amp;rsquo;s type must match this argument or a RuntimeError will be raised. This argument is not currently supported for &lt;code&gt;ord='nuc'&lt;/code&gt; or &lt;code&gt;ord='fro'&lt;/code&gt;. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（ &lt;code&gt;torch.dtype&lt;/code&gt; ，可选） -如果指定，输入张量转换为 &lt;code&gt;dtype&lt;/code&gt; 执行操作，并且返回的张量的类型将是前 &lt;code&gt;dtype&lt;/code&gt; 。如果将此参数与 &lt;code&gt;out&lt;/code&gt; 参数一起使用，则输出张量的类型必须与此参数匹配，否则将引发RuntimeError。 &lt;code&gt;ord='nuc'&lt;/code&gt; 或 &lt;code&gt;ord='fro'&lt;/code&gt; 目前不支持此参数。默认值： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cf0e16ba6689c6aefebe41b2f37216499a3bab49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; the desired data type of returned Tensor. Default: dtype of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（ &lt;code&gt;torch.dtype&lt;/code&gt; ，可选） -所需的数据返回张量的类型。默认值：dtype of &lt;code&gt;input&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ddf34144bdd895ef81d56a2e64c3a31dcfb71d3f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; the desired data type of returned tensor. If specified, the input tensor is casted to &lt;code&gt;dtype&lt;/code&gt; before the operation is performed. This is useful for preventing data type overflows. Default: None.</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（ &lt;code&gt;torch.dtype&lt;/code&gt; ，可选） -返回的张量的所希望的数据类型。如果指定，则在执行操作之前将输入张量强制转换为 &lt;code&gt;dtype&lt;/code&gt; 。这对于防止数据类型溢出很有用。默认值：无。</target>
        </trans-unit>
        <trans-unit id="b5aa3ffb5214bb07d706f4bff69889b064a67a58" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dtype&lt;/strong&gt; (&lt;code&gt;torch.dtype&lt;/code&gt;, optional) &amp;ndash; the desired data type of the returned tensor. Default: &lt;code&gt;torch.float32&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;D型&lt;/strong&gt;（ &lt;code&gt;torch.dtype&lt;/code&gt; ，可选） -返回的张量的所希望的数据类型。默认值： &lt;code&gt;torch.float32&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7c192f6abd14a8034e24d8a96ca7b9be11ad48f2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dx&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; The distance between points at which &lt;code&gt;y&lt;/code&gt; is sampled.</source>
          <target state="translated">&lt;strong&gt;dx&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;采样 &lt;code&gt;y&lt;/code&gt; 的点之间的距离。</target>
        </trans-unit>
        <trans-unit id="103894978c9b529418b87fd9904f3950e5930d8e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;dynamic_axes&lt;/strong&gt; (&lt;em&gt;dict&amp;lt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;dict&amp;lt;python:int&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;string&amp;gt;&amp;gt;&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;dict&amp;lt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;)&lt;/em&gt;&lt;em&gt;&amp;gt;&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty dict&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;dynamic_axes&lt;/strong&gt;（&lt;em&gt;dict &amp;lt;string &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;dict &amp;lt;python：int &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;string &amp;gt;&amp;gt;&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;dict &amp;lt;string &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;（&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;）&lt;/em&gt;&lt;em&gt;&amp;gt; &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为空dict&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="c4fbef8984bd074ea0df43f49dda2d6246584439" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;edgeitems&lt;/strong&gt; &amp;ndash; Number of array items in summary at beginning and end of each dimension (default = 3).</source>
          <target state="translated">&lt;strong&gt;edgeitems&lt;/strong&gt; &amp;ndash;每个维的开始和结束处摘要中数组项目的数量（默认= 3）。</target>
        </trans-unit>
        <trans-unit id="42415c6475a98e0f1fa07ebf4b124d7a8ce2a188" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvalues&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): Shape</source>
          <target state="translated">&lt;strong&gt;特征值&lt;/strong&gt;（&lt;em&gt;张量&lt;/em&gt;）：形状</target>
        </trans-unit>
        <trans-unit id="fdaa0feae05488ebb171b346905c4f5b577cb835" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; &lt;code&gt;True&lt;/code&gt; to compute both eigenvalues and eigenvectors; otherwise, only eigenvalues will be computed</source>
          <target state="translated">&lt;strong&gt;特征向量&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; 用于计算特征值和特征向量；否则，将仅计算特征值</target>
        </trans-unit>
        <trans-unit id="678dbd774fefa060e069a5a389a8baecab662449" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): If &lt;code&gt;eigenvectors=False&lt;/code&gt;, it&amp;rsquo;s an empty tensor. Otherwise, this tensor of shape</source>
          <target state="translated">&lt;strong&gt;eigenvectors&lt;/strong&gt;（&lt;em&gt;Tensor&lt;/em&gt;）：如果 &lt;code&gt;eigenvectors=False&lt;/code&gt; ，它是一个空张量。否则，这个张量的形状</target>
        </trans-unit>
        <trans-unit id="850ac1cd20b0b0fc94fb9c8edab9b43e67eaf290" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): Shape</source>
          <target state="translated">&lt;strong&gt;特征向量&lt;/strong&gt;（&lt;em&gt;张量&lt;/em&gt;）：形状</target>
        </trans-unit>
        <trans-unit id="ad4105465a171ee7fcc51139dea5abbe36639f29" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eigenvectors&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether eigenvectors have to be computed</source>
          <target state="translated">&lt;strong&gt;特征向量&lt;/strong&gt;（&lt;em&gt;布尔值&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;控制是否必须计算特征向量</target>
        </trans-unit>
        <trans-unit id="a63d80190229ce72c85a7e6560054704380577ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;elementwise_affine&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases). Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;elementwise_affine&lt;/strong&gt; &amp;ndash;一个布尔值，当设置为 &lt;code&gt;True&lt;/code&gt; 时，此模块具有可学习的每个元素的仿射参数，分别初始化为1（对于权重）和0（对于偏差）。默认值： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5d18cda3fe2834c321ed263a1762695dafaa4d1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embed_dim&lt;/strong&gt; &amp;ndash; total dimension of the model.</source>
          <target state="translated">&lt;strong&gt;embed_dim&lt;/strong&gt; &amp;ndash;模型的总尺寸。</target>
        </trans-unit>
        <trans-unit id="aa8b03fcaceb218feac127ba1ed55359bc28eca3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embedding_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the size of each embedding vector</source>
          <target state="translated">&lt;strong&gt;embedding_dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;每个嵌入向量的大小</target>
        </trans-unit>
        <trans-unit id="de1af4e04b664f6ae8d83d1e7d608531b740f185" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embeddings&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; FloatTensor containing weights for the Embedding. First dimension is being passed to Embedding as &lt;code&gt;num_embeddings&lt;/code&gt;, second as &lt;code&gt;embedding_dim&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;embeddings&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;包含嵌入权重的FloatTensor。第一维度被传递给嵌入作为 &lt;code&gt;num_embeddings&lt;/code&gt; ，第二作为 &lt;code&gt;embedding_dim&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="06e3728c866bf657f051e1739af9167591891b44" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;embeddings&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; FloatTensor containing weights for the EmbeddingBag. First dimension is being passed to EmbeddingBag as &amp;lsquo;num_embeddings&amp;rsquo;, second as &amp;lsquo;embedding_dim&amp;rsquo;.</source>
          <target state="translated">&lt;strong&gt;embeddings&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;包含EmbeddingBag权重的FloatTensor。第一维作为&amp;ldquo; num_embeddings&amp;rdquo;传递给EmbeddingBag，第二维作为&amp;ldquo; embedding_dim&amp;rdquo;传递。</target>
        </trans-unit>
        <trans-unit id="f0ff1217368a5b45df32d944d2dd475690d13d9f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enable&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to enable uneven input detection or not. Pass in &lt;code&gt;enable=False&lt;/code&gt; to disable in cases where you know that inputs are even across participating processes. Default is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;enable&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;是否启用不均匀输入检测。传中 &lt;code&gt;enable=False&lt;/code&gt; 在禁用的情况下，你知道的投入甚至是所有参与的过程。默认值为 &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c7081365cba99386e7771c337648ca106e830b0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enable_onnx_checker&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default True&lt;/em&gt;) &amp;ndash; If True the onnx model checker will be run as part of the export, to ensure the exported model is a valid ONNX model.</source>
          <target state="translated">&lt;strong&gt;enable_onnx_checker&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为True&lt;/em&gt;）&amp;ndash;如果为True，则onnx模型检查器将作为导出的一部分运行，以确保导出的模型是有效的ONNX模型。</target>
        </trans-unit>
        <trans-unit id="895e955089896ac371f4672b847c341ccc8b1ff3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enable_timing&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; indicates if the event should measure time (default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;enable_timing&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;指示事件是否应该测量时间（默认值： &lt;code&gt;False&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="986eeeac89dc84a2ea56e1c9bce5f0263e468fa8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enabled&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if &lt;code&gt;False&lt;/code&gt;, the RNG is not forked. This is a convenience argument for easily disabling the context manager without having to delete it and unindent your Python code under it.</source>
          <target state="translated">&lt;strong&gt;enabled&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;False&lt;/code&gt; ，则不分叉RNG。这是一个方便的参数，用于轻松禁用上下文管理器，而不必删除它并取消其下的Python代码的缩进。</target>
        </trans-unit>
        <trans-unit id="2d8edf33fd2314207965e2b072e477dab0fdf74b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enabled&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Setting this to False makes this context manager a no-op. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;enabled&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;将其设置为False会使此上下文管理器成为无操作对象。默认值： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="415c46eca69853c5e4dfa53b80ff975d44d8ac3f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enabled&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default=True&lt;/em&gt;) &amp;ndash; Setting &lt;code&gt;enabled=False&lt;/code&gt; makes this context manager a no-op. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;enabled&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;default = True&lt;/em&gt;）&amp;ndash;设置 &lt;code&gt;enabled=False&lt;/code&gt; 会使此上下文管理器成为禁止操作。默认值： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="736574f31db572913a04933de35e73418aa3b198" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enabled&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default=True&lt;/em&gt;) &amp;ndash; Whether autocasting should be enabled in the region.</source>
          <target state="translated">&lt;strong&gt;enabled&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;default = True&lt;/em&gt;）&amp;ndash;是否应在该区域中启用自动广播。</target>
        </trans-unit>
        <trans-unit id="8b5bbce56260acf11245d762cd1bb7f8add8801b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;encoder_layer&lt;/strong&gt; &amp;ndash; an instance of the TransformerEncoderLayer() class (required).</source>
          <target state="translated">&lt;strong&gt;coder_layer&lt;/strong&gt; &amp;ndash; TransformerEncoderLayer（）类的实例（必需）。</target>
        </trans-unit>
        <trans-unit id="d84a97832788a91df32af257307532f9760f3b9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor with the ending points</source>
          <target state="translated">&lt;strong&gt;end&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;具有终点的张量</target>
        </trans-unit>
        <trans-unit id="7d5c9c4c24dd3af3a29f20c653c917dfea2df720" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the ending value for the set of points</source>
          <target state="translated">&lt;strong&gt;end&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;点集的结束值</target>
        </trans-unit>
        <trans-unit id="6472482679cdc676a7850881f5d00cc512baada7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the ending value for the set of points</source>
          <target state="translated">&lt;strong&gt;end&lt;/strong&gt;（&lt;em&gt;Number&lt;/em&gt;）&amp;ndash;点集的结束值</target>
        </trans-unit>
        <trans-unit id="841fff8e784294f57ea3f8ba62be671371d870ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end_dim&lt;/strong&gt; &amp;ndash; last dim to flatten (default = -1).</source>
          <target state="translated">&lt;strong&gt;end_dim&lt;/strong&gt; &amp;ndash;最后变暗以变平（默认= -1）。</target>
        </trans-unit>
        <trans-unit id="c799ddd223af170e7b8eec13d7b2c9d7165d8603" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;end_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the last dim to flatten</source>
          <target state="translated">&lt;strong&gt;end_dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要变平的最后一个&lt;strong&gt;暗角&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="5a6422972f6f1ee1d35eb1fc402a56304ba9816a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enforce_sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, checks that the input contains sequences sorted by length in a decreasing order. If &lt;code&gt;False&lt;/code&gt;, this condition is not checked. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;force_sorted&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则检查输入是否包含按长度降序排列的序列。如果为 &lt;code&gt;False&lt;/code&gt; ，则不检查此条件。默认值： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f8c91d834d8c02f59864a331664c622e334c3693" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;enforce_sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the input is expected to contain sequences sorted by length in a decreasing order. If &lt;code&gt;False&lt;/code&gt;, the input will get sorted unconditionally. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;force_sorted&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔型&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）-如果为 &lt;code&gt;True&lt;/code&gt; ，则预期输入包含按长度降序排列的序列。如果为 &lt;code&gt;False&lt;/code&gt; ，则输入将无条件排序。默认值： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5baba4b5ccf6b68b45f524ad14b90f736f67183d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;epochs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The number of epochs to train for. This is used along with steps_per_epoch in order to infer the total number of steps in the cycle if a value for total_steps is not provided. Default: None</source>
          <target state="translated">&lt;strong&gt;纪元&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要训练的纪元数。如果未提供total_steps的值，则将其与steps_per_epoch一起使用以推断循环中的步骤总数。默认值：无</target>
        </trans-unit>
        <trans-unit id="d07cc920f4a588343d52b60256e017a7987131f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; &amp;ndash; a value added to the denominator for numerical stability. Default: 1e-5</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt; &amp;ndash;为分母增加数值的稳定性。默认值：1e-5</target>
        </trans-unit>
        <trans-unit id="f8684696132f475ee9f33febf9c44e66f038a87a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; &amp;ndash; a value added to the denominator for numerical stability. Default: &lt;code&gt;1e-5&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt; &amp;ndash;为分母增加数值的稳定性。默认值： &lt;code&gt;1e-5&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="83b2a550335cb37b45d5faa4c3779a2cd427c881" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored. Default: 1e-8.</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点数&lt;/a&gt;）&amp;ndash;应用于lr的最小衰减。如果新旧lr之间的差异小于eps，则忽略该更新。默认值：1e-8。</target>
        </trans-unit>
        <trans-unit id="ac6c5326b4eb0b53657544fec8194ff31859de16" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; small value to avoid division by zero. Default: 1e-12</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;避免被零除的较小值。默认值：1e-12</target>
        </trans-unit>
        <trans-unit id="a3071da796481042a1779ea93a5637a546557315" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Small value to avoid division by zero. Default: 1e-6</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;避免被零除的较小值。默认值：1e-6</target>
        </trans-unit>
        <trans-unit id="bfa6309f005abf8cb4486bcdb54e88aa5722cf1c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Small value to avoid division by zero. Default: 1e-8</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;避免被零除的较小值。默认值：1e-8</target>
        </trans-unit>
        <trans-unit id="a35a97bcd21164533c2c178f41069f2aca802198" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Small value to avoid evaluation of</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;较小的值，以避免评估</target>
        </trans-unit>
        <trans-unit id="3e84e8770e10ffa80ab0cd44b0a601016d1c45b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; epsilon for numerical stability in calculating norms</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; epsilon，用于在计算范数时保持数值稳定性</target>
        </trans-unit>
        <trans-unit id="93812852966ba66d19563befd8bfb79438fe404f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; perturbation for finite differences</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;有限差分的摄动</target>
        </trans-unit>
        <trans-unit id="23287961a644af8da325b62e474d3172bd5f3de4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; term added to the denominator to improve numerical stability (default: 1e-10)</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;分母中添加的项，以提高数值稳定性（默认值：1e-10）</target>
        </trans-unit>
        <trans-unit id="bfc881323872c2d4d8cd616814cd232147e55d20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; term added to the denominator to improve numerical stability (default: 1e-6)</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;分母中添加的项以提高数值稳定性（默认值：1e-6）</target>
        </trans-unit>
        <trans-unit id="e7750d8fa1fba824c2db7cdcb029debc400b1e1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; term added to the denominator to improve numerical stability (default: 1e-8)</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;分母中添加的项，以提高数值稳定性（默认值：1e-8）</target>
        </trans-unit>
        <trans-unit id="64bfcd7f406bb75e0a20d11554ef0afad32ae5c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the epsilon for input clamp bound. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;eps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输入钳位约束的epsilon。默认值： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7aa30076d7d518c87037ac60ab79f79f7490d2c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;equal_nan&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, then two &lt;code&gt;NaN&lt;/code&gt; s will be considered equal. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;equal_nan&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则将两个 &lt;code&gt;NaN&lt;/code&gt; 视为相等。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1f8913ade12e3dc4c4d8fd9b0228a8bcf2b585f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;equation&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; The equation is given in terms of lower case letters (indices) to be associated with each dimension of the operands and result. The left hand side lists the operands dimensions, separated by commas. There should be one index letter per tensor dimension. The right hand side follows after &lt;code&gt;-&amp;gt;&lt;/code&gt; and gives the indices for the output. If the &lt;code&gt;-&amp;gt;&lt;/code&gt; and right hand side are omitted, it implicitly defined as the alphabetically sorted list of all indices appearing exactly once in the left hand side. The indices not apprearing in the output are summed over after multiplying the operands entries. If an index appears several times for the same operand, a diagonal is taken. Ellipses &lt;code&gt;&amp;hellip;&lt;/code&gt; represent a fixed number of dimensions. If the right hand side is inferred, the ellipsis dimensions are at the beginning of the output.</source>
          <target state="translated">&lt;strong&gt;公式&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;公式以小写字母（索引）形式给出，与操作数和结果的每个维度相关联。左侧列出了操作数维，以逗号分隔。每个张量维应该有一个索引字母。右边紧跟在 &lt;code&gt;-&amp;gt;&lt;/code&gt; 之后，并给出输出的索引。如果省略了 &lt;code&gt;-&amp;gt;&lt;/code&gt; 和右侧，则将其隐式定义为所有索引的按字母顺序排序的列表，这些列表在左侧仅出现一次。在将操作数条目相乘后，将输出中不等于的索引相加。如果同一操作数的索引出现多次，则采用对角线。椭圆 &lt;code&gt;&amp;hellip;&lt;/code&gt; 代表固定数量的尺寸。如果推断出右侧，则省略号尺寸位于输出的开头。</target>
        </trans-unit>
        <trans-unit id="9795d90febecee64ae62240078c8b888a3529f0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eta_min&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Minimum learning rate. Default: 0.</source>
          <target state="translated">&lt;strong&gt;eta_min&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;最低学习率。默认值：0</target>
        </trans-unit>
        <trans-unit id="b8244af6c91eeea47bc27c5f4ae207a6917b58ea" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;eta_min&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Minimum learning rate. Default: 0.</source>
          <target state="translated">&lt;strong&gt;eta_min&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;最低学习率。默认值：0</target>
        </trans-unit>
        <trans-unit id="1433ae6bce90cf036177044e9c513b2c8d0f5f99" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;etas&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; pair of (etaminus, etaplis), that are multiplicative increase and decrease factors (default: (0.5, 1.2))</source>
          <target state="translated">&lt;strong&gt;etas&lt;/strong&gt;（&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;对（etaminus，etaplis），它们是可乘的递增和递减因子（默认值：（0.5，1.2））</target>
        </trans-unit>
        <trans-unit id="bbb3573c662548692515c0f7a10112191b156c96" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;event&lt;/strong&gt; (&lt;a href=&quot;#torch.cuda.Event&quot;&gt;Event&lt;/a&gt;) &amp;ndash; an event to wait for.</source>
          <target state="translated">&lt;strong&gt;事件&lt;/strong&gt;（&lt;a href=&quot;#torch.cuda.Event&quot;&gt;Event&lt;/a&gt;）&amp;ndash;等待的事件。</target>
        </trans-unit>
        <trans-unit id="2cb5a854faf1af97d1f14b26d87e6a2fa84d0c7b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;event&lt;/strong&gt; (&lt;a href=&quot;#torch.cuda.Event&quot;&gt;Event&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; event to record. If not given, a new one will be allocated.</source>
          <target state="translated">&lt;strong&gt;event&lt;/strong&gt;（&lt;a href=&quot;#torch.cuda.Event&quot;&gt;Event &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要记录的事件。如果未给出，将分配一个新的。</target>
        </trans-unit>
        <trans-unit id="62122c1e3a5ab3359886af99296a0aefc26ae410" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;event_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Optional size of &lt;code&gt;event_shape&lt;/code&gt;. This should be zero for univariate random variables, 1 for distributions over vectors, 2 for distributions over matrices, etc.</source>
          <target state="translated">&lt;strong&gt;event_dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;） &lt;code&gt;event_shape&lt;/code&gt; 可选大小。对于单变量随机变量，应为零；对于向量的分布，应为1；对于矩阵的分布，应为2。</target>
        </trans-unit>
        <trans-unit id="34f745bd094bd2de883ee47fbf1638e33919faba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;example_inputs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; A tuple of example inputs that will be passed to the function while tracing. The resulting trace can be run with inputs of different types and shapes assuming the traced operations support those types and shapes. &lt;code&gt;example_inputs&lt;/code&gt; may also be a single Tensor in which case it is automatically wrapped in a tuple.</source>
          <target state="translated">&lt;strong&gt;example_inputs&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;在跟踪时将传递给函数的示例输入的元组。假设跟踪的操作支持这些类型和形状，则可以使用不同类型和形状的输入来运行结果跟踪。 &lt;code&gt;example_inputs&lt;/code&gt; 也可以是单个Tensor，在这种情况下，它会自动包装在元组中。</target>
        </trans-unit>
        <trans-unit id="618d999c8d78a9676692412df718e533abdf676f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;example_outputs&lt;/strong&gt; (&lt;em&gt;tuple of Tensors&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default None&lt;/em&gt;) &amp;ndash; Model&amp;rsquo;s example outputs being exported. example_outputs must be provided when exporting a ScriptModule or TorchScript Function.</source>
          <target state="translated">&lt;strong&gt;example_outputs&lt;/strong&gt;（&lt;em&gt;张量元组&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为None&lt;/em&gt;）&amp;ndash;导出模型的示例输出。导出ScriptModule或TorchScript函数时，必须提供example_outputs。</target>
        </trans-unit>
        <trans-unit id="c2456379602b05045dca23f7f350a44c9fd9c512" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;expand&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to expand the support over the batch dims to match the distribution&amp;rsquo;s &lt;code&gt;batch_shape&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;expand&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;是否将支持范围扩展到批次 &lt;code&gt;batch_shape&lt;/code&gt; 以匹配分发的batch_shape。</target>
        </trans-unit>
        <trans-unit id="1a88c1284ab82b366b962ae9cc9b58fad7708160" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;exponent&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the exponent tensor</source>
          <target state="translated">&lt;strong&gt;指数&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;指数张量</target>
        </trans-unit>
        <trans-unit id="00243251e0e37f0ed072fb8db0c41a52c671837f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;exponent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tensor&lt;/em&gt;) &amp;ndash; the exponent value</source>
          <target state="translated">&lt;strong&gt;指数&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点数&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;张量&lt;/em&gt;）&amp;ndash;指数值</target>
        </trans-unit>
        <trans-unit id="fcb9c92fd7acb8cc56e2900598ba04b5be24aae8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;export_params&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default True&lt;/em&gt;) &amp;ndash; if specified, all parameters will be exported. Set this to False if you want to export an untrained model. In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by &lt;code&gt;model.state_dict().values()&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;export_params&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为True&lt;/em&gt;）&amp;ndash;如果指定，将导出所有参数。如果要导出未经训练的模型，请将其设置为False。在这种情况下，导出的模型将首先将其所有参数作为参数，其顺序由 &lt;code&gt;model.state_dict().values()&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f60c4eee6ac8bd3b83d115e58f8f9d5c6a1f285a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;export_raw_ir&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; [DEPRECATED. use operator_export_type] export the internal IR directly instead of converting it to ONNX ops.</source>
          <target state="translated">&lt;strong&gt;export_raw_ir&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为False&lt;/em&gt;）&amp;ndash; [不推荐使用。使用operator_export_type]直接导出内部IR，而不是将其转换为ONNX ops。</target>
        </trans-unit>
        <trans-unit id="e82a47709effdd4ed45378b2094bb76a83f236b5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;external_data_format&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; If True, then the model is exported in ONNX external data format, in which case some of the model parameters are stored in external binary files and not in the ONNX model file itself. See link for format details: &lt;a href=&quot;https://github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423&quot;&gt;https://github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423&lt;/a&gt; Also, in this case, argument &amp;lsquo;f&amp;rsquo; must be a string specifying the location of the model. The external binary files will be stored in the same location specified by the model location &amp;lsquo;f&amp;rsquo;. If False, then the model is stored in regular format, i.e. model and parameters are all in one file. This argument is ignored for all export types other than ONNX.</source>
          <target state="translated">&lt;strong&gt;external_data_format&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为False&lt;/em&gt;）&amp;ndash;如果为True，则以ONNX外部数据格式导出模型，在这种情况下，某些模型参数存储在外部二进制文件中，而不是ONNX模型文件本身中。有关格式的详细信息，请参见链接：&lt;a href=&quot;https://github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423&quot;&gt;https&lt;/a&gt; : //github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423另外，在这种情况下，参数'f'必须是指定模型位置的字符串。外部二进制文件将存储在模型位置&amp;ldquo; f&amp;rdquo;指定的相同位置。如果为False，则模型以常规格式存储，即模型和参数都在一个文件中。对于所有导出类型（ONNX除外），将忽略此参数。</target>
        </trans-unit>
        <trans-unit id="778fd667aea6cff6dc8d68bb20cefa3e389d87e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_cflags&lt;/strong&gt; &amp;ndash; optional list of compiler flags to forward to the build.</source>
          <target state="translated">&lt;strong&gt;extra_cflags&lt;/strong&gt; &amp;ndash;编译器标志的可选列表，以转发到构建。</target>
        </trans-unit>
        <trans-unit id="fcbab5a7fa61c6ed8414a66172d5505acca2751e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_cuda_cflags&lt;/strong&gt; &amp;ndash; optional list of compiler flags to forward to nvcc when building CUDA sources.</source>
          <target state="translated">&lt;strong&gt;extra_cuda_cflags&lt;/strong&gt; &amp;ndash;生成CUDA源时转发到nvcc的编译器标志的可选列表。</target>
        </trans-unit>
        <trans-unit id="5906d2861e5b04548eb15a5d2b6487f486e2e624" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_include_paths&lt;/strong&gt; &amp;ndash; optional list of include directories to forward to the build.</source>
          <target state="translated">&lt;strong&gt;extra_include_paths&lt;/strong&gt; &amp;ndash;包含目录的可选列表，以转发到构建。</target>
        </trans-unit>
        <trans-unit id="62224af2d822c58c7d8e8fba25c2a2dc1f3ef2cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;extra_ldflags&lt;/strong&gt; &amp;ndash; optional list of linker flags to forward to the build.</source>
          <target state="translated">&lt;strong&gt;extra_ldflags&lt;/strong&gt; &amp;ndash;链接标志的可选列表，以转发到构建。</target>
        </trans-unit>
        <trans-unit id="c6f0cc911afdf14389ad75575a9c9cbfa3c8ccfb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; A file-like object (has to implement write and flush) or a string containing a file name.</source>
          <target state="translated">&lt;strong&gt;f&lt;/strong&gt; &amp;ndash;类似于文件的对象（必须实现写入和刷新）或包含文件名的字符串。</target>
        </trans-unit>
        <trans-unit id="0bbf42a4b349b4674d2d35b2fcc87d253370be87" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement &lt;code&gt;read()&lt;/code&gt;, :meth`readline`, :meth`tell`, and :meth`seek`), or a string or os.PathLike object containing a file name</source>
          <target state="translated">&lt;strong&gt;f&lt;/strong&gt; &amp;ndash;类似于文件的对象（必须实现 &lt;code&gt;read()&lt;/code&gt; ，：meth`readline`，：meth`tell`和：meth`seek`）或包含文件名的字符串或os.PathLike对象</target>
        </trans-unit>
        <trans-unit id="54a2a51aa44ae289f486330a5f54f09e6f971a65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement fileno that returns a file descriptor) or a string containing a file name. A binary Protobuf will be written to this file.</source>
          <target state="translated">&lt;strong&gt;f&lt;/strong&gt; &amp;ndash;类似于文件的对象（必须实现返回文件描述符的fileno）或包含文件名的字符串。二进制Protobuf将被写入此文件。</target>
        </trans-unit>
        <trans-unit id="677757134bd8309ac15335a18ed7a21b22ef8fdd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement read, readline, tell, and seek), or a string containing a file name</source>
          <target state="translated">&lt;strong&gt;f&lt;/strong&gt; &amp;ndash;类似于文件的对象（必须实现读取，读取行，告诉和查找），或包含文件名的字符串</target>
        </trans-unit>
        <trans-unit id="df677cb77b7f5749b31ae401c7fa92ff2d7e7fe5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;f&lt;/strong&gt; &amp;ndash; a file-like object (has to implement write and flush) or a string or os.PathLike object containing a file name</source>
          <target state="translated">&lt;strong&gt;f&lt;/strong&gt; &amp;ndash;类似于文件的对象（必须实现写入和刷新），或者是包含文件名的字符串或os.PathLike对象</target>
        </trans-unit>
        <trans-unit id="635ef0bc301d974c0ff51acd3ba7ee21d88b4744" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;faces&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Indices of vertices within each triangle. (Optional)</source>
          <target state="translated">&lt;strong&gt;面&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;每个三角形内的顶点的索引。（选修的）</target>
        </trans-unit>
        <trans-unit id="7dac65f2926c30687b712331254bac0c325b018e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Factor by which the learning rate will be reduced. new_lr = lr * factor. Default: 0.1.</source>
          <target state="translated">&lt;strong&gt;factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;学习率降低的因数。new_lr = lr *因子。默认值：0.1</target>
        </trans-unit>
        <trans-unit id="6d42958804dd0465816b20a88c367eef0dbeec80" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;factorization&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the factorization of size</source>
          <target state="translated">&lt;strong&gt;因式分解&lt;/strong&gt;（&lt;em&gt;Tensor&lt;/em&gt;）：大小的因式分解</target>
        </trans-unit>
        <trans-unit id="d41e8bf5537d7429d4d9cda4345adcbe62552ea2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;factory&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;) &amp;ndash; A callable that inputs a constraint object and returns a &lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt;&lt;code&gt;Transform&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">&lt;strong&gt;factory&lt;/strong&gt;（&lt;em&gt;callable&lt;/em&gt;）&amp;ndash;输入约束对象并返回&lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt; &lt;code&gt;Transform&lt;/code&gt; &lt;/a&gt;对象的可调用对象。</target>
        </trans-unit>
        <trans-unit id="00769844b4ecc2fca40878cb1764ed386aa09fd9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;figure&lt;/strong&gt; (&lt;em&gt;matplotlib.pyplot.figure&lt;/em&gt;) &amp;ndash; Figure or a list of figures</source>
          <target state="translated">&lt;strong&gt;图&lt;/strong&gt;（&lt;em&gt;matplotlib.pyplot.figure&lt;/em&gt;）&amp;ndash;图或图列表</target>
        </trans-unit>
        <trans-unit id="62d218fbe21b9a87d144357ac35b2f10bb534799" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;file_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; path of the file in which to store the key-value pairs</source>
          <target state="translated">&lt;strong&gt;file_name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;存储键值对的文件的路径</target>
        </trans-unit>
        <trans-unit id="c3c0dee521e2626c0ae3dbbaa2f17cc80f80c2a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;file_name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; name for the downloaded file. Filename from &lt;code&gt;url&lt;/code&gt; will be used if not set.</source>
          <target state="translated">&lt;strong&gt;file_name&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;下载文件的名称。如果未设置，将使用 &lt;code&gt;url&lt;/code&gt; 中的文件名。</target>
        </trans-unit>
        <trans-unit id="57269f4bfae1f1ca10e35c956f9fd6e448de9061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;filename&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; file name to map</source>
          <target state="translated">&lt;strong&gt;filename&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;要映射的文件名</target>
        </trans-unit>
        <trans-unit id="95d303dabfba56a1b6870b6f2026c68bddc1be2f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;filename_suffix&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Suffix added to all event filenames in the log_dir directory. More details on filename construction in tensorboard.summary.writer.event_file_writer.EventFileWriter.</source>
          <target state="translated">&lt;strong&gt;filename_suffix&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;后缀添加到log_dir目录中的所有事件文件名中。在tensorboard.summary.writer.event_file_writer.EventFileWriter中有关文件名构造的更多详细信息。</target>
        </trans-unit>
        <trans-unit id="cdb4a6b44cef668e406b3d993df10539cc0f7054" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; &amp;ndash; the number to fill the output tensor with.</source>
          <target state="translated">&lt;strong&gt;fill_value&lt;/strong&gt; &amp;ndash;用来填充输出张量的数字。</target>
        </trans-unit>
        <trans-unit id="cc362ae2525be68e4bb10eb869fbbb29641c9bab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; (&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the fill value</source>
          <target state="translated">&lt;strong&gt;fill_value&lt;/strong&gt;（&lt;em&gt;Scalar&lt;/em&gt;）&amp;ndash;填充值</target>
        </trans-unit>
        <trans-unit id="81b7336ac76bc7cac5103fa2f7d2fd03ba164f85" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; (&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the value to fill the output tensor with.</source>
          <target state="translated">&lt;strong&gt;fill_value&lt;/strong&gt;（&lt;em&gt;Scalar&lt;/em&gt;）&amp;ndash;用来填充输出张量的值。</target>
        </trans-unit>
        <trans-unit id="2031b6ba05d0b93a6457f0efd37cfe00b19e577a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fill_value&lt;/strong&gt; (&lt;em&gt;scalar&lt;/em&gt;) &amp;ndash; the number to fill the output tensor with.</source>
          <target state="translated">&lt;strong&gt;fill_value&lt;/strong&gt;（&lt;em&gt;scalar&lt;/em&gt;）&amp;ndash;用来填充输出张量的数字。</target>
        </trans-unit>
        <trans-unit id="276eb8282c2d9e264a29a26b2d65090e55bac9ea" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;final_div_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Determines the minimum learning rate via min_lr = initial_lr/final_div_factor Default: 1e4</source>
          <target state="translated">&lt;strong&gt;final_div_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;通过min_lr = initial_lr / final_div_factor确定最小学习率默认值：1e4</target>
        </trans-unit>
        <trans-unit id="9096ebbb1f99e7416acc6998a05334d6d6397c19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;find_unused_parameters&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Traverse the autograd graph from all tensors contained in the return value of the wrapped module&amp;rsquo;s &lt;code&gt;forward&lt;/code&gt; function. Parameters that don&amp;rsquo;t receive gradients as part of this graph are preemptively marked as being ready to be reduced. Note that all &lt;code&gt;forward&lt;/code&gt; outputs that are derived from module parameters must participate in calculating loss and later the gradient computation. If they don&amp;rsquo;t, this wrapper will hang waiting for autograd to produce gradients for those parameters. Any outputs derived from module parameters that are otherwise unused can be detached from the autograd graph using &lt;code&gt;torch.Tensor.detach&lt;/code&gt;. (default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;find_unused_pa​​rameters&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;从包装模块的 &lt;code&gt;forward&lt;/code&gt; 函数的返回值中包含的所有张量遍历autograd图。在此图中未接收到渐变的参数会被抢先标记为已准备好进行还原。请注意，从模块参数派生的所有 &lt;code&gt;forward&lt;/code&gt; 输出必须参与计算损耗，然后再参与梯度计算。如果没有，则该包装程序将挂起，等待autograd为这些参数生成渐变。可以使用 &lt;code&gt;torch.Tensor.detach&lt;/code&gt; 将来自模块参数的其他未使用的输出与autograd图分离。（默认： &lt;code&gt;False&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="355396a4b2ab68b82f509c2d4c2526e2d2ba215d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;flush_secs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; How often, in seconds, to flush the pending events and summaries to disk. Default is every two minutes.</source>
          <target state="translated">&lt;strong&gt;flush_secs&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将挂起的事件和摘要刷新到磁盘的频率（以秒为单位）。默认值为每两分钟一次。</target>
        </trans-unit>
        <trans-unit id="d5d2a692102bf116db7e2c67b38b6073ed5ae103" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fn&lt;/strong&gt; (&lt;a href=&quot;#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; -&amp;gt; None) &amp;ndash; function to be applied to each submodule</source>
          <target state="translated">&lt;strong&gt;fn&lt;/strong&gt;（&lt;a href=&quot;#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; -&lt;/a&gt; &amp;gt; None）-要应用于每个子模块的功能</target>
        </trans-unit>
        <trans-unit id="ad87b9b261bd0e692ec81745b0251ab69e0c920a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fn&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; -&amp;gt; None) &amp;ndash; function to be applied to each submodule</source>
          <target state="translated">&lt;strong&gt;fn&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; -&lt;/a&gt; &amp;gt; None）-要应用于每个子模块的功能</target>
        </trans-unit>
        <trans-unit id="053dcf87d7e84dd407dec8695847c296ae6c0c48" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fn&lt;/strong&gt; (&lt;code&gt;Module&lt;/code&gt; -&amp;gt; None) &amp;ndash; function to be applied to each submodule</source>
          <target state="translated">&lt;strong&gt;fn&lt;/strong&gt;（ &lt;code&gt;Module&lt;/code&gt; - &amp;gt; None）-要应用于每个子模块的功能</target>
        </trans-unit>
        <trans-unit id="5b64b5eb22d75d1654b2b39949b562dd2fc7ec84" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fn&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;fn&lt;/strong&gt;（&lt;em&gt;函数&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="8ef37f45041ae6f49569ea35c632856c2fd1d15d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;force_reload&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to discard the existing cache and force a fresh download. Default is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;force_reload&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;是否放弃现有缓存并强制进行新的下载。默认值为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="dc70a2bb2f4ed4bcf5ecccaecd8c2e734de9391d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;force_reload&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to force a fresh download of the github repo unconditionally. Does not have any effect if &lt;code&gt;source = 'local'&lt;/code&gt;. Default is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;force_reload&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;是否无条件强制重新下载github存储库。如果 &lt;code&gt;source = 'local'&lt;/code&gt; 则没有任何效果。默认值为 &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="83c137929bf36e8aef1d6a6cc8426a81216a787f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Frames per second</source>
          <target state="translated">&lt;strong&gt;fps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;每秒帧数</target>
        </trans-unit>
        <trans-unit id="bde664f21923dc747ecb17124d60a563c8fc2b2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;freeze&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the tensor does not get updated in the learning process. Equivalent to &lt;code&gt;embedding.weight.requires_grad = False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;冻结&lt;/strong&gt;（&lt;em&gt;布尔值&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则在学习过程中不会更新张量。等效于 &lt;code&gt;embedding.weight.requires_grad = False&lt;/code&gt; 。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d3fd0568363b2aa7dd7b7c7e651d3c4c84a69bed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;freeze&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the tensor does not get updated in the learning process. Equivalent to &lt;code&gt;embeddingbag.weight.requires_grad = False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;冻结&lt;/strong&gt;（&lt;em&gt;布尔值&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则在学习过程中不会更新张量。等效于 &lt;code&gt;embeddingbag.weight.requires_grad = False&lt;/code&gt; 。默认值： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8ba291fa349a86b63b98c719b0de8e1e3a0b2ccd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;from&lt;/strong&gt; (&lt;em&gt;dpython:type&lt;/em&gt;) &amp;ndash; The original &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;from&lt;/strong&gt;（&lt;em&gt;dpython：type&lt;/em&gt;）&amp;ndash;原始的&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="46bb4df94b1ad85e11557fbf62e5528ed469cf66" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;full&lt;/strong&gt; &amp;ndash; whether to compute full loss, i. e. to add the Stirling approximation term. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;满&lt;/strong&gt;&amp;ndash;是否计算满损，即添加斯特林近似项。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="75533226793ba470c8b0b1c360399ebe87a93520" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;full&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;完整&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔型&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="65a3ef606b557f50e8baa66a8411c285745d744f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;) &amp;ndash; a callable function, such as Python callables, builtin operators (e.g. &lt;a href=&quot;generated/torch.add#torch.add&quot;&gt;&lt;code&gt;add()&lt;/code&gt;&lt;/a&gt;) and annotated TorchScript functions.</source>
          <target state="translated">&lt;strong&gt;func&lt;/strong&gt;（&lt;em&gt;callable&lt;/em&gt;）&amp;ndash;可调用的函数，例如Python可调用函数，内置运算符（例如&lt;a href=&quot;generated/torch.add#torch.add&quot;&gt; &lt;code&gt;add()&lt;/code&gt; &lt;/a&gt;）和带注释的TorchScript函数。</target>
        </trans-unit>
        <trans-unit id="eab18ced6b9533ad0e16e9973e883f1659631001" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; A Python function or &lt;code&gt;torch.nn.Module&lt;/code&gt; that will be invoked. If executed in TorchScript, it will execute asynchronously, otherwise it will not. Traced invocations of fork will be captured in the IR.</source>
          <target state="translated">&lt;strong&gt;func&lt;/strong&gt;（&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;）&amp;ndash;将被调用的Python函数或 &lt;code&gt;torch.nn.Module&lt;/code&gt; 。如果在TorchScript中执行，它将异步执行，否则将异步执行。跟踪的fork调用将在IR中捕获。</target>
        </trans-unit>
        <trans-unit id="1e13542d19949849cdfa6d1ca4a6a3c14a44f62f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; A Python function or &lt;code&gt;torch.nn.Module&lt;/code&gt; that will be run with &lt;code&gt;example_inputs&lt;/code&gt;. &lt;code&gt;func&lt;/code&gt; arguments and return values must be tensors or (possibly nested) tuples that contain tensors. When a module is passed &lt;code&gt;torch.jit.trace&lt;/code&gt;, only the &lt;code&gt;forward&lt;/code&gt; method is run and traced (see &lt;a href=&quot;torch.jit.trace_module#torch.jit.trace_module&quot;&gt;&lt;code&gt;torch.jit.trace&lt;/code&gt;&lt;/a&gt; for details).</source>
          <target state="translated">&lt;strong&gt;func&lt;/strong&gt;（&lt;em&gt;可调用&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;）&amp;ndash;将与 &lt;code&gt;example_inputs&lt;/code&gt; 一起运行的Python函数或 &lt;code&gt;torch.nn.Module&lt;/code&gt; 。 &lt;code&gt;func&lt;/code&gt; 参数和返回值必须是张量或包含张量的（可能是嵌套的）元组。当模块传递 &lt;code&gt;torch.jit.trace&lt;/code&gt; ，仅运行和跟踪 &lt;code&gt;forward&lt;/code&gt; 方法（有关详细信息，请参见&lt;a href=&quot;torch.jit.trace_module#torch.jit.trace_module&quot;&gt; &lt;code&gt;torch.jit.trace&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="56b0f0644254436da01524968b169f5b50136a6f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;) &amp;ndash; a Python function that takes Tensor inputs and returns a Tensor or a tuple of Tensors</source>
          <target state="translated">&lt;strong&gt;func&lt;/strong&gt;（&lt;em&gt;function&lt;/em&gt;）&amp;ndash;一个Python函数，接受Tensor输入并返回Tensor或Tensors元组</target>
        </trans-unit>
        <trans-unit id="4bcf898e9ca65627609a065cb0b080712aa4c22c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;) &amp;ndash; a Python function that takes Tensor inputs and returns a Tensor with a single element.</source>
          <target state="translated">&lt;strong&gt;func&lt;/strong&gt;（&lt;em&gt;function&lt;/em&gt;）&amp;ndash;一个Python函数，它接受Tensor输入并返回带有单个元素的Tensor。</target>
        </trans-unit>
        <trans-unit id="73a52f765d84ab66ab0e999764fd5ec7c3392353" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;func&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;) &amp;ndash; a Python function that takes Tensor inputs and returns a tuple of Tensors or a Tensor.</source>
          <target state="translated">&lt;strong&gt;func&lt;/strong&gt;（&lt;em&gt;function&lt;/em&gt;）&amp;ndash;一个Python函数，接受Tensor输入并返回Tensor或Tensor的元组。</target>
        </trans-unit>
        <trans-unit id="76d83916ad9f858f16111887e3f6267b2fca5fed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;function&lt;/strong&gt; &amp;ndash; describes what to run in the forward pass of the model or part of the model. It should also know how to handle the inputs passed as the tuple. For example, in LSTM, if user passes &lt;code&gt;(activation, hidden)&lt;/code&gt;, &lt;code&gt;function&lt;/code&gt; should correctly use the first input as &lt;code&gt;activation&lt;/code&gt; and the second input as &lt;code&gt;hidden&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;功能&lt;/strong&gt;&amp;ndash;描述在模型的正向传递中或模型的一部分中运行的内容。它还应该知道如何处理作为元组传递的输入。例如，在LSTM中，如果用户通过 &lt;code&gt;(activation, hidden)&lt;/code&gt; ，则 &lt;code&gt;function&lt;/code&gt; 应正确使用第一个输入作为 &lt;code&gt;activation&lt;/code&gt; ，第二个输入作为 &lt;code&gt;hidden&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1961467ba2825e1c559db8b59ff1bdbcbb0ec039" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;functions&lt;/strong&gt; &amp;ndash; A &lt;a href=&quot;generated/torch.nn.sequential#torch.nn.Sequential&quot;&gt;&lt;code&gt;torch.nn.Sequential&lt;/code&gt;&lt;/a&gt; or the list of modules or functions (comprising the model) to run sequentially.</source>
          <target state="translated">&lt;strong&gt;功能&lt;/strong&gt;&amp;ndash;要顺序运行的&lt;a href=&quot;generated/torch.nn.sequential#torch.nn.Sequential&quot;&gt; &lt;code&gt;torch.nn.Sequential&lt;/code&gt; &lt;/a&gt;或模块或功能列表（包含模型）。</target>
        </trans-unit>
        <trans-unit id="2fb5cc79b41c4d978a0a328aa05327cc1e203720" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;functions&lt;/strong&gt; &amp;ndash; A list of function names for which to generate function bindings. If a dictionary is given, it should map function names to docstrings (which are otherwise just the function names).</source>
          <target state="translated">&lt;strong&gt;functions&lt;/strong&gt; &amp;ndash;要为其生成函数绑定的函数名称列表。如果提供了字典，则应将函数名称映射到文档字符串（否则仅是函数名称）。</target>
        </trans-unit>
        <trans-unit id="2894bf837b3fe8e5a6a993314a795c3b92f661d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;fuser_func&lt;/strong&gt; &amp;ndash; Function that takes in a list of modules and outputs a list of fused modules of the same length. For example, fuser_func([convModule, BNModule]) returns the list [ConvBNModule, nn.Identity()] Defaults to torch.quantization.fuse_known_modules</source>
          <target state="translated">&lt;strong&gt;fuser_func&lt;/strong&gt; &amp;ndash;接收模块列表并输出相同长度的融合模块列表的功能。例如，fuser_func（[convModule，BNModule]）返回列表[ConvBNModule，nn.Identity（）]默认为torch.quantization.fuse_known_modules</target>
        </trans-unit>
        <trans-unit id="cb85d27a8748aad626d3af5de9e7af60b244f74d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;futures&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; a list of &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">&lt;strong&gt;期货&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;列表&lt;/a&gt;）&amp;ndash;&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;对象的列表。</target>
        </trans-unit>
        <trans-unit id="7a7221601ceeb930d343f7319c8db14fe03b3e16" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;futures&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; a list of &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; objects.</source>
          <target state="translated">&lt;strong&gt;期货&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;列表&lt;/a&gt;）&amp;ndash;&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;对象的列表。</target>
        </trans-unit>
        <trans-unit id="ba355c7f4beca0e0d4bf68bb3971593069c56322" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gain&lt;/strong&gt; &amp;ndash; an optional scaling factor</source>
          <target state="translated">&lt;strong&gt;增益&lt;/strong&gt;&amp;ndash;可选比例因子</target>
        </trans-unit>
        <trans-unit id="b04565ecc2229736f50e2b26ed78404ea530d53b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gain&lt;/strong&gt; &amp;ndash; optional scaling factor</source>
          <target state="translated">&lt;strong&gt;增益&lt;/strong&gt;&amp;ndash;可选比例因子</target>
        </trans-unit>
        <trans-unit id="9537c0304197566d9a64aed9da630fcabb6dfaf8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gamma&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Constant in &amp;lsquo;exp_range&amp;rsquo; scaling function: gamma**(cycle iterations) Default: 1.0</source>
          <target state="translated">&lt;strong&gt;gamma&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;'exp_range'缩放函数中的常数：gamma **（循环迭代）默认值：1.0</target>
        </trans-unit>
        <trans-unit id="a6e1b932343255f06ce86199fe2520eefcb597e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gamma&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Multiplicative factor of learning rate decay.</source>
          <target state="translated">&lt;strong&gt;gamma&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;学习率衰减的乘数。</target>
        </trans-unit>
        <trans-unit id="b7d26412c35f8aaae0db5c942f3ecafc6d5b994e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gamma&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Multiplicative factor of learning rate decay. Default: 0.1.</source>
          <target state="translated">&lt;strong&gt;gamma&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;学习率衰减的乘数。默认值：0.1</target>
        </trans-unit>
        <trans-unit id="b03754a8da7ef008224ed892c921fb9371f0c076" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gather_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)</source>
          <target state="translated">&lt;strong&gt;collect_list&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;用于收集数据的适当大小的张量列表（默认为None，必须在目标等级上指定）</target>
        </trans-unit>
        <trans-unit id="8ae62591eb58ac1c4da89608590832d7178cb467" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gen_non_contig_grad_outputs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;grad_outputs&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;gen_non_contig_grad_outputs&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the randomly generated gradient outputs are made to be noncontiguous</source>
          <target state="translated">&lt;strong&gt;gen_non_contig_grad_outputs&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果 &lt;code&gt;grad_outputs&lt;/code&gt; 为 &lt;code&gt;None&lt;/code&gt; 且 &lt;code&gt;gen_non_contig_grad_outputs&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ，则使随机生成的梯度输出为非连续的</target>
        </trans-unit>
        <trans-unit id="d39d3171bd8a988de4ba0ad35fb1fb1306606f7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;generator&lt;/strong&gt; (&lt;a href=&quot;generated/torch.generator#torch.Generator&quot;&gt;Generator&lt;/a&gt;) &amp;ndash; Generator used for the random permutation.</source>
          <target state="translated">&lt;strong&gt;generator&lt;/strong&gt;（&lt;a href=&quot;generated/torch.generator#torch.Generator&quot;&gt;生成器&lt;/a&gt;）&amp;ndash;用于随机排列的生成器。</target>
        </trans-unit>
        <trans-unit id="d8f474eedb1de962668babbc241de79afb189c26" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;generator&lt;/strong&gt; (&lt;a href=&quot;generated/torch.generator#torch.Generator&quot;&gt;Generator&lt;/a&gt;) &amp;ndash; Generator used in sampling.</source>
          <target state="translated">&lt;strong&gt;生成器&lt;/strong&gt;（&lt;a href=&quot;generated/torch.generator#torch.Generator&quot;&gt;Generator&lt;/a&gt;）&amp;ndash;用于采样的生成器。</target>
        </trans-unit>
        <trans-unit id="f5579060ab76636341f5dfd97c022a89f302b7cf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;generator&lt;/strong&gt; (&lt;a href=&quot;torch.generator#torch.Generator&quot;&gt;&lt;code&gt;torch.Generator&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; a pseudorandom number generator for sampling</source>
          <target state="translated">&lt;strong&gt;生成器&lt;/strong&gt;（&lt;a href=&quot;torch.generator#torch.Generator&quot;&gt; &lt;code&gt;torch.Generator&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;用于采样的伪随机数生成器</target>
        </trans-unit>
        <trans-unit id="06014c6b4c4693a7e3fbaf2b2a37ca8411e8162c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;get_infos&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if set to &lt;code&gt;True&lt;/code&gt;, returns an info IntTensor. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;get_infos&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果设置为 &lt;code&gt;True&lt;/code&gt; ，则返回一个信息IntTensor。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="713f3c8adc9b7748672962092ba1c2254277918b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;github&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; a string with format &amp;ldquo;repo_owner/repo_name[:tag_name]&amp;rdquo; with an optional tag/branch. The default branch is &lt;code&gt;master&lt;/code&gt; if not specified. Example: &amp;lsquo;pytorch/vision[:hub]&amp;rsquo;</source>
          <target state="translated">&lt;strong&gt;github&lt;/strong&gt;（&lt;em&gt;string&lt;/em&gt;）&amp;ndash;格式为&amp;ldquo; repo_owner / repo_name [：tag_name]&amp;rdquo;的字符串，带有可选的标签/分支。如果未指定，则默认分支为 &lt;code&gt;master&lt;/code&gt; 。示例：&amp;ldquo; pytorch / vision [：hub]&amp;rdquo;</target>
        </trans-unit>
        <trans-unit id="270e6272159af8294641789a5ae5029a0175a0a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;github&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; a string with format &amp;lt;repo_owner/repo_name[:tag_name]&amp;gt; with an optional tag/branch. The default branch is &lt;code&gt;master&lt;/code&gt; if not specified. Example: &amp;lsquo;pytorch/vision[:hub]&amp;rsquo;</source>
          <target state="translated">&lt;strong&gt;github&lt;/strong&gt;（&lt;em&gt;string&lt;/em&gt;）&amp;ndash;格式为&amp;lt;repo_owner / repo_name [：tag_name]&amp;gt;的字符串，带有可选的标签/分支。如果未指定，则默认分支为 &lt;code&gt;master&lt;/code&gt; 。示例：&amp;ldquo; pytorch / vision [：hub]&amp;rdquo;</target>
        </trans-unit>
        <trans-unit id="34a7ff872bd23abb0450fda48dac267f7a245b6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;global_step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Global step value to record</source>
          <target state="translated">&lt;strong&gt;global_step&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要记录的全局步长值</target>
        </trans-unit>
        <trans-unit id="59b52c7e39a474423f9fda9eb51f75f802a681a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;graceful&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to do a graceful shutdown or not. If True, this will 1) wait until there is no pending system messages for &lt;code&gt;UserRRefs&lt;/code&gt; and delete them; 2) block until all local and remote RPC processes have reached this method and wait for all outstanding work to complete.</source>
          <target state="translated">&lt;strong&gt;graceful&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;是否执行正常关机。如果为True，则将：1）等待，直到没有 &lt;code&gt;UserRRefs&lt;/code&gt; 挂起系统消息并将其删除；2）阻塞，直到所有本地和远程RPC进程都达到此方法，然后等待所有未完成的工作完成。</target>
        </trans-unit>
        <trans-unit id="3d7c0034720f0f5384aa3c778777a63be7c08866" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;grad_outputs&lt;/strong&gt; (&lt;em&gt;sequence of Tensor&lt;/em&gt;) &amp;ndash; The &amp;ldquo;vector&amp;rdquo; in the Jacobian-vector product. Usually gradients w.r.t. each output. None values can be specified for scalar Tensors or ones that don&amp;rsquo;t require grad. If a None value would be acceptable for all grad_tensors, then this argument is optional. Default: None.</source>
          <target state="translated">&lt;strong&gt;grad_outputs&lt;/strong&gt;（&lt;em&gt;张量序列&lt;/em&gt;）&amp;ndash;雅可比矢量积中的&amp;ldquo;矢量&amp;rdquo;。通常，每个输出都有梯度。不能为标量张量或不需要等级的张量指定任何值。如果所有grad_tensor都可接受None值，则此参数是可选的。默认值：无。</target>
        </trans-unit>
        <trans-unit id="787019ca25e342b192fc0fe32846b61af4cbf80c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;grad_outputs&lt;/strong&gt; (&lt;em&gt;tuple of Tensor&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The gradients with respect to the function&amp;rsquo;s outputs.</source>
          <target state="translated">&lt;strong&gt;grad_outputs&lt;/strong&gt;（&lt;em&gt;Tensor&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor的&lt;/a&gt;&lt;em&gt;元组&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;相对于函数输出的渐变。</target>
        </trans-unit>
        <trans-unit id="c3a7adf281106800948e615e1796c2800710f153" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;grad_tensors&lt;/strong&gt; (&lt;em&gt;sequence of&lt;/em&gt;&lt;em&gt; (&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/constants.html#None&quot;&gt;None&lt;/a&gt;&lt;em&gt;)&lt;/em&gt;) &amp;ndash; The &amp;ldquo;vector&amp;rdquo; in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors. None values can be specified for scalar Tensors or ones that don&amp;rsquo;t require grad. If a None value would be acceptable for all grad_tensors, then this argument is optional.</source>
          <target state="translated">&lt;strong&gt;grad_tensors&lt;/strong&gt;（&lt;em&gt;（&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/constants.html#None&quot;&gt;None &lt;/a&gt;&lt;em&gt;）的&lt;/em&gt;&lt;em&gt;序列&lt;/em&gt;）&amp;ndash;雅可比矢量积中的&amp;ldquo;矢量&amp;rdquo;，通常是通过相应张量的每个元素进行渐变的。不能为标量张量或不需要等级的张量指定任何值。如果所有grad_tensor都可接受None值，则此参数是可选的。&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="799013c067a407e423f9d42197eba6a2384dd6a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gradient&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/constants.html#None&quot;&gt;None&lt;/a&gt;) &amp;ndash; Gradient w.r.t. the tensor. If it is a tensor, it will be automatically converted to a Tensor that does not require grad unless &lt;code&gt;create_graph&lt;/code&gt; is True. None values can be specified for scalar Tensors or ones that don&amp;rsquo;t require grad. If a None value would be acceptable then this argument is optional.</source>
          <target state="translated">&lt;strong&gt;梯度&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;张量&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/constants.html#None&quot;&gt;无&lt;/a&gt;）-张量的梯度。如果是张量，除非 &lt;code&gt;create_graph&lt;/code&gt; 为True ，否则它将自动转换为不需要grad的张量。不能为标量张量或不需要等级的张量指定任何值。如果None值可以接受，那么此参数是可选的。</target>
        </trans-unit>
        <trans-unit id="ed3816b6dfbefeff09bce5c08bcf032810a5e596" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gradient&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/constants.html#None&quot;&gt;None&lt;/a&gt;) &amp;ndash; Gradient w.r.t. the tensor. If it is a tensor, it will be automatically converted to a Tensor that does not require grad unless &lt;code&gt;create_graph&lt;/code&gt; is True. None values can be specified for scalar Tensors or ones that don&amp;rsquo;t require grad. If a None value would be acceptable then this argument is optional.</source>
          <target state="translated">&lt;strong&gt;梯度&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/constants.html#None&quot;&gt;无&lt;/a&gt;）-张量的梯度。如果是张量，除非 &lt;code&gt;create_graph&lt;/code&gt; 为True ，否则它将自动转换为不需要grad的张量。不能为标量张量或不需要等级的张量指定任何值。如果None值可以接受，那么此参数是可选的。</target>
        </trans-unit>
        <trans-unit id="b29df415efb0eea8f8662bee6b939588b9b78efb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;gradient_as_bucket_view&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; This is a prototype feature and subject to changes. When set to &lt;code&gt;True&lt;/code&gt;, gradients will be views pointing to different offsets of &lt;code&gt;allreduce&lt;/code&gt; communication buckets. This can reduce peak memory usage, where the saved memory size will be equal to the total gradients size. Moreover, it avoids the overhead of copying between gradients and &lt;code&gt;allreduce&lt;/code&gt; communication buckets. When gradients are views, &lt;code&gt;detach_()&lt;/code&gt; cannot be called on the gradients. If hitting such errors, please fix it by referring to the &lt;a href=&quot;../optim#torch.optim.Optimizer.zero_grad&quot;&gt;&lt;code&gt;zero_grad()&lt;/code&gt;&lt;/a&gt; function in &lt;code&gt;torch/optim/optimizer.py&lt;/code&gt; as a solution.</source>
          <target state="translated">&lt;strong&gt;gradient_as_bucket_view&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;这是原型功能，可能会发生变化。当设置为 &lt;code&gt;True&lt;/code&gt; 时，渐变将是指向所有 &lt;code&gt;allreduce&lt;/code&gt; 通信桶的不同偏移量的视图。这样可以减少峰值内存使用量，其中已保存的内存大小将等于总渐变大小。而且，它避免了在梯度之间进行复制的开销，并 &lt;code&gt;allreduce&lt;/code&gt; 通信桶。当渐变是视图时，不能在渐变上调用 &lt;code&gt;detach_()&lt;/code&gt; 。如果遇到此类错误，请通过参考 &lt;code&gt;torch/optim/optimizer.py&lt;/code&gt; 中的&lt;a href=&quot;../optim#torch.optim.Optimizer.zero_grad&quot;&gt; &lt;code&gt;zero_grad()&lt;/code&gt; &lt;/a&gt;函数来解决此问题。</target>
        </trans-unit>
        <trans-unit id="b2b0bcce70df29844281ac614b0f8a39a0dfcd19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;grid&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; flow-field of shape</source>
          <target state="translated">&lt;strong&gt;网格&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;形状的流场</target>
        </trans-unit>
        <trans-unit id="4db1041ae201d7e927245f12103bcee3afeae410" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group&lt;/strong&gt; (&lt;em&gt;ProcessGroup&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The process group to work on</source>
          <target state="translated">&lt;strong&gt;组&lt;/strong&gt;（&lt;em&gt;ProcessGroup &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要处理的过程组</target>
        </trans-unit>
        <trans-unit id="1110361e162f3be4aa9b1a7cde1a491603596b93" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group&lt;/strong&gt; (&lt;em&gt;ProcessGroup&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The process group to work on.</source>
          <target state="translated">&lt;strong&gt;group&lt;/strong&gt;（&lt;em&gt;ProcessGroup &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要处理的流程组。</target>
        </trans-unit>
        <trans-unit id="6db70a258153314cde5304ac47d562305e99552a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group&lt;/strong&gt; (&lt;em&gt;ProcessGroup&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The process group to work on. The default is the general main process group. If another specific group is specified, the calling process must be part of &lt;code&gt;group&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;group&lt;/strong&gt;（&lt;em&gt;ProcessGroup &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要处理的流程组。默认值为常规主流程组。如果指定了另一个特定的组，则调用过程必须是 &lt;code&gt;group&lt;/code&gt; 的一部分。</target>
        </trans-unit>
        <trans-unit id="011a95e14d4b56ac5f95b65e4e55d911eaae7b11" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group_by_input_shapes&lt;/strong&gt; &amp;ndash; group entries by</source>
          <target state="translated">&lt;strong&gt;group_by_input_shapes&lt;/strong&gt; &amp;ndash;按组分组</target>
        </trans-unit>
        <trans-unit id="76f6d63e480e5617ce79eca4ba9df6a70f24cb2d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group_by_stack_n&lt;/strong&gt; &amp;ndash; group by top n stack trace entries</source>
          <target state="translated">&lt;strong&gt;group_by_stack_n&lt;/strong&gt; &amp;ndash;按前n个堆栈跟踪条目分组</target>
        </trans-unit>
        <trans-unit id="85aa3c312919cb9842e6de299fa1fb86a7f7ea49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;group_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;deprecated&lt;/em&gt;) &amp;ndash; Group name.</source>
          <target state="translated">&lt;strong&gt;group_name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;不推荐使用&lt;/em&gt;）&amp;ndash;组名。</target>
        </trans-unit>
        <trans-unit id="f26fa12d9d61e6585a36de452da97d2ffce8b34d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;groups&lt;/strong&gt; &amp;ndash; split input into groups,</source>
          <target state="translated">&lt;strong&gt;组&lt;/strong&gt;&amp;ndash;将输入分成组，</target>
        </trans-unit>
        <trans-unit id="81c8b7e8acb12c23d521a687adf35816ef4ff39c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;groups&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Number of blocked connections from input channels to output channels. Default: 1</source>
          <target state="translated">&lt;strong&gt;组&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;从输入通道到输出通道的阻塞连接数。默认值：1</target>
        </trans-unit>
        <trans-unit id="3936cb9ca5f3782dc3736b1eb2710d73d6c56d73" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;groups&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; number of groups in the conv layer (default: 1)</source>
          <target state="translated">&lt;strong&gt;组&lt;/strong&gt;（&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;转换层中的组数（默认值：1）</target>
        </trans-unit>
        <trans-unit id="c9313fa876c33968ef38e2bc5ed5adcaf010be99" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h&amp;rsquo;&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the next hidden state for each element in the batch</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;h' &lt;/strong&gt; &lt;code&gt;(batch, hidden_size)&lt;/code&gt; ：张量，包含批次中每个元素的下一个隐藏状态</target>
        </trans-unit>
        <trans-unit id="1592eedf3bb9a47887176fd782c28510508c7820" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_0&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;h_0 &lt;/strong&gt; &lt;code&gt;(batch, hidden_size)&lt;/code&gt; ：张量，包含批处理中每个元素的初始隐藏状态。</target>
        </trans-unit>
        <trans-unit id="cfde5becd622ec62656a4cff95b1913fb5911358" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_0&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.</source>
          <target state="translated">&lt;strong&gt;h_0&lt;/strong&gt;形状 &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt; ：张量，包含批次中每个元素的初始隐藏状态。如果未提供，则默认为零。如果RNN是双向的，则num_directions应该为2，否则应为1。</target>
        </trans-unit>
        <trans-unit id="a088baa848abf407fdf324f68a7fc23226f3bfd9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_0&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2, else it should be 1.</source>
          <target state="translated">&lt;strong&gt;h_0&lt;/strong&gt;形状 &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt; ：张量，包含批次中每个元素的初始隐藏状态。如果LSTM是双向的，则num_directions应该为2，否则应为1。</target>
        </trans-unit>
        <trans-unit id="e0e30ccc3d1652af234e0543d06149d194f40bc0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_1&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the next hidden state for each element in the batch</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;h_1 &lt;/strong&gt; &lt;code&gt;(batch, hidden_size)&lt;/code&gt; ：张量，包含批处理中每个元素的下一个隐藏状态</target>
        </trans-unit>
        <trans-unit id="e1c9ba2b299c711fcc8d467de3dea8569b50a3fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_n&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the hidden state for &lt;code&gt;t = seq_len&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;h_n&lt;/strong&gt;的形状 &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt; ：包含 &lt;code&gt;t = seq_len&lt;/code&gt; 的隐藏状态的张量</target>
        </trans-unit>
        <trans-unit id="3525fd2429c6604b476c82ddd74f59209ab301ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;h_n&lt;/strong&gt; of shape &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;: tensor containing the hidden state for &lt;code&gt;t = seq_len&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;h_n&lt;/strong&gt;的形状 &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt; ：张量，包含 &lt;code&gt;t = seq_len&lt;/code&gt; 的隐藏状态。</target>
        </trans-unit>
        <trans-unit id="ba61e8234e80482584a34f381f7534bd9ba1d290" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hard&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the returned samples will be discretized as one-hot vectors, but will be differentiated as if it is the soft sample in autograd</source>
          <target state="translated">&lt;strong&gt;hard&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则返回的样本将被离散为一热向量，但将被区分为好像是autograd中的软样本</target>
        </trans-unit>
        <trans-unit id="aaa96a08f23e0f6a631877636b216cb602e637fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hash_prefix&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If not None, the SHA256 downloaded file should start with &lt;code&gt;hash_prefix&lt;/code&gt;. Default: None</source>
          <target state="translated">&lt;strong&gt;hash_prefix&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果不是None，则下载的SHA256文件应以 &lt;code&gt;hash_prefix&lt;/code&gt; 开头。默认值：无</target>
        </trans-unit>
        <trans-unit id="b66c30a2662d014769668efe291e7362c5d7d9db" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;head_bias&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, adds a bias term to the &amp;lsquo;head&amp;rsquo; of the adaptive softmax. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;head_bias&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则向自适应softmax的&amp;ldquo; head&amp;rdquo;添加一个偏差项。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d30e56690f484d3c8d7a2b255db4bcbd77445f68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hidden&lt;/strong&gt; of shape &lt;code&gt;(batch, hidden_size)&lt;/code&gt;: tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided.</source>
          <target state="translated">&lt;strong&gt;隐藏&lt;/strong&gt;形状 &lt;code&gt;(batch, hidden_size)&lt;/code&gt; ：张量，包含批次中每个元素的初始隐藏状态。如果未提供，则默认为零。</target>
        </trans-unit>
        <trans-unit id="e67734f0b9cf7c79bc74ff13156c666a023e5f41" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hidden_size&lt;/strong&gt; &amp;ndash; The number of features in the hidden state &lt;code&gt;h&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;hidden_​​size&lt;/strong&gt; &amp;ndash;处于隐藏状态 &lt;code&gt;h&lt;/code&gt; 的特征数</target>
        </trans-unit>
        <trans-unit id="6e1564d55f92aeff911d4cdf1ca4875875da67b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;high&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; upper range (exclusive).</source>
          <target state="translated">&lt;strong&gt;高&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮动&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;上限（不包括）。</target>
        </trans-unit>
        <trans-unit id="3705e6bc9a6ecd869a7951f814f9fed46d9ff630" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;high&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; One above the highest integer to be drawn from the distribution.</source>
          <target state="translated">&lt;strong&gt;high&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要从分布中得出的最高整数之上的1。</target>
        </trans-unit>
        <trans-unit id="dc6dd784a95236db99f041d334a725f2f9b1a9a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;history_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; update history size (default: 100).</source>
          <target state="translated">&lt;strong&gt;history_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;更新历史记录大小（默认值：100）。</target>
        </trans-unit>
        <trans-unit id="c19ea35377296f18df50a468ab31eff648558a09" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hop_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the distance between neighboring sliding window frames. Default: &lt;code&gt;None&lt;/code&gt; (treated as equal to &lt;code&gt;floor(n_fft / 4)&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;hop_length&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;相邻的滑动窗口框架之间的距离。默认值： &lt;code&gt;None&lt;/code&gt; （等同于 &lt;code&gt;floor(n_fft / 4)&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="d1396026b4c7368bc625f59b4932fadbbf084c72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hop_length&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The distance between neighboring sliding window frames. (Default: &lt;code&gt;n_fft // 4&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;hop_length&lt;/strong&gt;（&lt;em&gt;可选&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;相邻滑动窗口框架之间的距离。（默认值： &lt;code&gt;n_fft // 4&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="6876910fda4d6ecccd2051aba33481c94d9368b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;host_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The hostname or IP Address the server store should run on.</source>
          <target state="translated">&lt;strong&gt;host_name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;服务器存储应在其上运行的主机名或IP地址。</target>
        </trans-unit>
        <trans-unit id="94284103cfc33f19f8a61eebc94176be0db80646" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hparam_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Each key-value pair in the dictionary is the name of the hyper parameter and it&amp;rsquo;s corresponding value. The type of the value can be one of &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;hparam_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;字典中的每个键值对都是hyper参数的名称，也是其对应的值。值的类型可以是 &lt;code&gt;bool&lt;/code&gt; ， &lt;code&gt;string&lt;/code&gt; ， &lt;code&gt;float&lt;/code&gt; ， &lt;code&gt;int&lt;/code&gt; 或 &lt;code&gt;None&lt;/code&gt; 之一。</target>
        </trans-unit>
        <trans-unit id="a1b563f2476f046122b214d6a9600f12ff9315b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;hparam_domain_discrete&lt;/strong&gt; &amp;ndash; (Optional[Dict[str, List[Any]]]) A dictionary that contains names of the hyperparameters and all discrete values they can hold</source>
          <target state="translated">&lt;strong&gt;hparam_domain_discrete&lt;/strong&gt; &amp;ndash;（可选[Dict [str，List [Any]]]）一个字典，其中包含超参数的名称以及它们可以保存的所有离散值</target>
        </trans-unit>
        <trans-unit id="98aaeaa4225400ecd738ec2048d131fe08b1d564" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;iK&lt;/strong&gt; (&lt;em&gt;tensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the input tensor of size</source>
          <target state="translated">&lt;strong&gt;iK&lt;/strong&gt;（&lt;em&gt;张量&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输入张量的大小</target>
        </trans-unit>
        <trans-unit id="e423e9ecf3beffc0eedb4329822c8534728b01ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ignore_index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies a target value that is ignored and does not contribute to the input gradient. When &lt;code&gt;size_average&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the loss is averaged over non-ignored targets.</source>
          <target state="translated">&lt;strong&gt;ignore_index&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;指定一个目标值，该目标值将被忽略并且不会对输入梯度产生影响。当 &lt;code&gt;size_average&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; 时，损耗是在非忽略目标上平均的。</target>
        </trans-unit>
        <trans-unit id="607b11f999212773791595ce05953927928c08a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ignore_index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies a target value that is ignored and does not contribute to the input gradient. When &lt;code&gt;size_average&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the loss is averaged over non-ignored targets. Default: -100</source>
          <target state="translated">&lt;strong&gt;ignore_index&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;指定一个目标值，该目标值将被忽略并且不会对输入梯度产生影响。当 &lt;code&gt;size_average&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; 时，损耗是在非忽略目标上平均的。默认值：-100</target>
        </trans-unit>
        <trans-unit id="c096d38fe26de10e968164a6aecd6f913177ea6e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;imag&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The imaginary part of the complex tensor. Must be same dtype as &lt;a href=&quot;torch.real#torch.real&quot;&gt;&lt;code&gt;real&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;imag&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;复数张量的虚部。dtype必须与&lt;a href=&quot;torch.real#torch.real&quot;&gt; &lt;code&gt;real&lt;/code&gt; &lt;/a&gt;相同。</target>
        </trans-unit>
        <trans-unit id="c3a96d8bd554be6eb7797de17442ad6cb99464a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;img_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Image data</source>
          <target state="translated">&lt;strong&gt;img_tensor&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;字符串/ blobname&lt;/em&gt;）&amp;ndash;图像数据</target>
        </trans-unit>
        <trans-unit id="9e075b9a8dfd668778490588e84bb0c9bbb577a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in1_features&lt;/strong&gt; &amp;ndash; size of each first input sample</source>
          <target state="translated">&lt;strong&gt;in1_features&lt;/strong&gt; &amp;ndash;每个第一个输入样本的大小</target>
        </trans-unit>
        <trans-unit id="99c9afda0be0c905049d69c6c60279520769cef1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in2_features&lt;/strong&gt; &amp;ndash; size of each second input sample</source>
          <target state="translated">&lt;strong&gt;in2_features&lt;/strong&gt; &amp;ndash;每秒钟输入样本的大小</target>
        </trans-unit>
        <trans-unit id="054cbce99ed259e05737255fcff3ec1a33f17b30" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in_channels&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of channels in the input image</source>
          <target state="translated">&lt;strong&gt;in_channels&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;输入图像中的通道数</target>
        </trans-unit>
        <trans-unit id="031258926af2ce0c91f35de69ae4829af92fe5cc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in_features&lt;/strong&gt; &amp;ndash; size of each input sample</source>
          <target state="translated">&lt;strong&gt;in_features&lt;/strong&gt; &amp;ndash;每个输入样本的大小</target>
        </trans-unit>
        <trans-unit id="e1cd84155beb6cb4e4e554a0fb3f34f7def9bf3d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;in_features&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of features in the input tensor</source>
          <target state="translated">&lt;strong&gt;in_features&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;输入张量中的特征数量</target>
        </trans-unit>
        <trans-unit id="de92c22d2099710d576bc540cf0e439bfe62dc1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;include_last_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;include_last_offset&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;请参阅模块初始化文档。默认值： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6c77074d3fbe6ed19bba6e5a032d17feba927877" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;include_last_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;offsets&lt;/code&gt; has one additional element, where the last element is equivalent to the size of &lt;code&gt;indices&lt;/code&gt;. This matches the CSR format.</source>
          <target state="translated">&lt;strong&gt;include_last_offset&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;） -如果 &lt;code&gt;True&lt;/code&gt; ， &lt;code&gt;offsets&lt;/code&gt; 具有一个附加的元件，其中最后元素等价于的大小 &lt;code&gt;indices&lt;/code&gt; 。这与CSR格式匹配。</target>
        </trans-unit>
        <trans-unit id="adc8afe3a34cbeea7690cc1b8d46533e74feca80" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;include_last_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the size of offsets is equal to the number of bags + 1.</source>
          <target state="translated">&lt;strong&gt;include_last_offset&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则偏移量的大小等于包数+ 1。</target>
        </trans-unit>
        <trans-unit id="0058952dc92b6430936a12a9320099bae5295fc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;increasing&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Order of the powers of the columns. If True, the powers increase from left to right, if False (the default) they are reversed.</source>
          <target state="translated">&lt;strong&gt;增加&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;列的幂顺序。如果为True，则幂从左到右增加；如果为False（默认值），则将它们反转。</target>
        </trans-unit>
        <trans-unit id="d624060723fbf002e4598220b5812e19f26a17a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; index to insert.</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要插入的索引。</target>
        </trans-unit>
        <trans-unit id="5d2ab5af76f511772ee4673ede1ce34b868d76a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the index to select with</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;要选择的索引</target>
        </trans-unit>
        <trans-unit id="35fb618fa2c424e1e9473beb050f9175521a3241" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; indices of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; to select from</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt;索引可供选择</target>
        </trans-unit>
        <trans-unit id="67e5b1c26904309bcbc72d6a5206411049f25fa6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; indices of &lt;code&gt;self&lt;/code&gt; tensor to fill in</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;要填充的 &lt;code&gt;self&lt;/code&gt; 张量的索引</target>
        </trans-unit>
        <trans-unit id="c8699c1c42412268aa01357837b44ae957ac901c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the 1-D tensor containing the indices to index</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;包含要索引的索引的一维张量</target>
        </trans-unit>
        <trans-unit id="3b1088f3894e3a3aade31aa3da2f7cbaa1c7f3c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices of elements to gather</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;要收集的元素的索引</target>
        </trans-unit>
        <trans-unit id="7246e33903dd34811bb50beca86c9f179b0ea261" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices of elements to scatter and add, can be either empty or the same size of src. When empty, the operation returns identity.</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;要分散和添加的元素的索引，可以为空或src的大小相同。如果为空，则该操作将返回标识。</target>
        </trans-unit>
        <trans-unit id="7891bb82e5f646ecc5571231eb40487d6adaedf7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;index&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices of elements to scatter, can be either empty or the same size of src. When empty, the operation returns identity</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;要分散的元素的索引，可以为空或src的大小相同。为空时，该操作将返回标识</target>
        </trans-unit>
        <trans-unit id="4489c58da0a616c049ed6d93d7f17fd55991d97a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices into self</source>
          <target state="translated">&lt;strong&gt;索引&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;自我索引</target>
        </trans-unit>
        <trans-unit id="e5be31c40930fbda8ef6fadbd69d27440a0a29e3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; the indices into tensor</source>
          <target state="translated">&lt;strong&gt;指数&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;） -该指数为张量</target>
        </trans-unit>
        <trans-unit id="4f340c71c41bf4a8b6f0ee0a633f1e707d60c41e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; Initial data for the tensor. Can be a list, tuple, NumPy &lt;code&gt;ndarray&lt;/code&gt;, scalar, and other types. Will be cast to a &lt;code&gt;torch.LongTensor&lt;/code&gt; internally. The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;array_like&lt;/em&gt;）&amp;ndash;张量的初始数据。可以是列表，元组，NumPy &lt;code&gt;ndarray&lt;/code&gt; ，标量和其他类型。将在内部投射到 &lt;code&gt;torch.LongTensor&lt;/code&gt; 。索引是矩阵中非零值的坐标，因此应为二维，其中第一维为张量维数，第二维为非零值数。</target>
        </trans-unit>
        <trans-unit id="05aa3324e9dca8478c49624094146779c5320358" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;sequence&lt;/em&gt;) &amp;ndash; Indices in the whole set selected for subset</source>
          <target state="translated">&lt;strong&gt;索引&lt;/strong&gt;（&lt;em&gt;序列&lt;/em&gt;）&amp;ndash;为子集选择的整个集合中的索引</target>
        </trans-unit>
        <trans-unit id="c088f1e272dfc4a0b7cc5311d10b29ca4ae57c70" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;sequence&lt;/em&gt;) &amp;ndash; a sequence of indices</source>
          <target state="translated">&lt;strong&gt;索引&lt;/strong&gt;（&lt;em&gt;序列&lt;/em&gt;）&amp;ndash;索引序列</target>
        </trans-unit>
        <trans-unit id="bef6961ff826304ba68b7564bb99ad681fdaf697" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;indices&lt;/strong&gt; (&lt;em&gt;tuple of LongTensor&lt;/em&gt;) &amp;ndash; tensors used to index into &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;index&lt;/strong&gt;（&lt;em&gt;LongTensor的元组&lt;/em&gt;）&amp;ndash;用于索引 &lt;code&gt;self&lt;/code&gt; 的张量。</target>
        </trans-unit>
        <trans-unit id="d19cbf8a68fcf3b4f455172ecef9b16a565a113c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;infos&lt;/strong&gt; (&lt;em&gt;IntTensor&lt;/em&gt;, &lt;em&gt;optional&lt;/em&gt;): if &lt;code&gt;get_infos&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this is a tensor of size</source>
          <target state="translated">&lt;strong&gt;infos&lt;/strong&gt;（&lt;em&gt;IntTensor&lt;/em&gt;，&lt;em&gt;可选&lt;/em&gt;）：如果 &lt;code&gt;get_infos&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; ，则这是一个张量</target>
        </trans-unit>
        <trans-unit id="71c1dcc99d861730834f2921fb9ea642ee26387c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the initial value of</source>
          <target state="translated">&lt;strong&gt;init&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;的初始值</target>
        </trans-unit>
        <trans-unit id="3387ec2d138470faa0b9b1e76a459e501c664a81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init_method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The URL to initialize &lt;code&gt;ProcessGroupGloo&lt;/code&gt; (default: &lt;code&gt;env://&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;init_method&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;初始化 &lt;code&gt;ProcessGroupGloo&lt;/code&gt; 的URL （默认值： &lt;code&gt;env://&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="da9829504ae0afe64db4aa47b65791dfaa083f83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init_method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The URL to initialize the distributed store used for rendezvous. It takes any value accepted for the same argument of &lt;a href=&quot;distributed#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; (default: &lt;code&gt;env://&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;init_method&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;初始化用于集合的分布式存储的URL。它接受&lt;a href=&quot;distributed#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;init_process_group()&lt;/code&gt; &lt;/a&gt;的相同参数接受的任何值（默认值： &lt;code&gt;env://&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="f325478530b5cf14071a5c700f82577ec5ba84d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;init_method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; URL specifying how to initialize the process group. Default is &amp;ldquo;env://&amp;rdquo; if no &lt;code&gt;init_method&lt;/code&gt; or &lt;code&gt;store&lt;/code&gt; is specified. Mutually exclusive with &lt;code&gt;store&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;init_method&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;指定如何初始化进程组的URL。如果未指定 &lt;code&gt;init_method&lt;/code&gt; 或 &lt;code&gt;store&lt;/code&gt; ,则默认值为&amp;ldquo; env：//&amp;rdquo; 。与 &lt;code&gt;store&lt;/code&gt; 互斥。</target>
        </trans-unit>
        <trans-unit id="9fa891f80017cd81f628a35707cc9e6065a280f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; (Currently not supported) can optionally do the operation in-place.</source>
          <target state="translated">&lt;strong&gt;就地&lt;/strong&gt;&amp;ndash;（当前不支持）可以选择&lt;strong&gt;就地&lt;/strong&gt;进行操作。</target>
        </trans-unit>
        <trans-unit id="df1cc134d4a1280a08aae8069753847bc753ab08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; If set to &lt;code&gt;True&lt;/code&gt;, will do this operation in-place. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;就地&lt;/strong&gt;&amp;ndash;如果设置为 &lt;code&gt;True&lt;/code&gt; ，则将&lt;strong&gt;就地&lt;/strong&gt;执行此操作。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a55c724ebe06e5259fc6013fba20d7f4e805cc86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; bool specifying if fusion happens in place on the model, by default a new model is returned</source>
          <target state="translated">&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; bool指定是否在模型上发生融合，默认情况下会返回一个新模型</target>
        </trans-unit>
        <trans-unit id="8a0af1cd98e89baa21a0964493ae5197db8d39c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; can optionally do the operation in-place. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;就地&lt;/strong&gt;&amp;ndash;可以选择&lt;strong&gt;就地&lt;/strong&gt;进行操作。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4a338586cc1b9e6364bb31bdac03d5949ded0e36" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; carry out model transformations in-place, the original module is mutated</source>
          <target state="translated">&lt;strong&gt;就地&lt;/strong&gt;&amp;ndash;&lt;strong&gt;就地&lt;/strong&gt;进行模型转换，原始模块已更改</target>
        </trans-unit>
        <trans-unit id="75aed03563c53dd2d0764eb5453c6ca6e4140d83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; &amp;ndash; perform the computation inplace</source>
          <target state="translated">&lt;strong&gt;就地&lt;/strong&gt;&amp;ndash;&lt;strong&gt;就地&lt;/strong&gt;执行计算</target>
        </trans-unit>
        <trans-unit id="fdf58b63be55a4b22c46032d3fd1d61d0bd927a2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If set to &lt;code&gt;True&lt;/code&gt;, will do this operation in-place</source>
          <target state="translated">&lt;strong&gt;就地&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果设置为 &lt;code&gt;True&lt;/code&gt; ，将&lt;strong&gt;就地&lt;/strong&gt;执行此操作</target>
        </trans-unit>
        <trans-unit id="2baabf2051ecce4e59ed7868711be86074a1121b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inplace&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; can optionally do the operation in-place. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;就地&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;可以选择&lt;strong&gt;就地&lt;/strong&gt;执行操作。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2ca73aff43bbd335b880e2e8b6461721261c7efd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input matrix</source>
          <target state="translated">&lt;strong&gt;input2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;输入矩阵</target>
        </trans-unit>
        <trans-unit id="7cb4517ba198e148817291a746b67bb3359b3275" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the &lt;code&gt;tau&lt;/code&gt; from &lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;input2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;来自&lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt; &lt;code&gt;torch.geqrf()&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;tau&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="14436103f8610b62c5af0d3f52320c0e695e6561" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input3&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the matrix to be multiplied.</source>
          <target state="translated">&lt;strong&gt;input3&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要相乘的矩阵。</target>
        </trans-unit>
        <trans-unit id="189471ee9fd0ae26f96b12a2f14fabdfdb2a55c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="2d43b3b03e5e1cc0bc29a4d3ee11d035641542b7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; A Tensor that is input to &lt;code&gt;functions&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;输入 &lt;code&gt;functions&lt;/code&gt; 张量</target>
        </trans-unit>
        <trans-unit id="3478ec4abd0f0da74946e0059075f92ae16838f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; Tensor of arbitrary shape</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;任意形状的张量</target>
        </trans-unit>
        <trans-unit id="64075621f7b49ac8cf3466ffee84214ef27b7e0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; expectation of underlying Poisson distribution.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;基本泊松分布的期望。</target>
        </trans-unit>
        <trans-unit id="e5c45d37ad1ca2bfd9ba95fc0c1c9aba750297da" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;输入张量</target>
        </trans-unit>
        <trans-unit id="fefd9a33978ca250fb3687e571631fed568e2f69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; input tensor of any shape</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;任何形状的输入张量</target>
        </trans-unit>
        <trans-unit id="32aa8fde0d3b37a5fd0bf094d226ea96d65d5b3e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; input tensor of shape</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;输入张量的形状</target>
        </trans-unit>
        <trans-unit id="1e71ece563e570f0828230ce4079bf1d6a1f9bfd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; quantized input</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;量化输入</target>
        </trans-unit>
        <trans-unit id="324d485d4d64467111174a180760e99e40ae34f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; quantized input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;量化输入张量</target>
        </trans-unit>
        <trans-unit id="1052a12b95427668122c4a5782e7d1c6ced7fbb7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; quantized input tensor of shape</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;形状的量化输入张量</target>
        </trans-unit>
        <trans-unit id="280fc2140640a681bb0a76e2eacb285f4f40a9a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; &amp;ndash; the first input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;&amp;ndash;第一个输入张量</target>
        </trans-unit>
        <trans-unit id="7c5a3515f7ca1c5139e9f3360aa15d38e06b1c58" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; an input Tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入张量</target>
        </trans-unit>
        <trans-unit id="c0b781ff3e115b7562060e3796452984aec9e1bc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D input vector</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;一维输入向量</target>
        </trans-unit>
        <trans-unit id="7e381244bd054e5229323f3fd533dcf76ded11c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-d int tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash; 1-d int张量</target>
        </trans-unit>
        <trans-unit id="318151f5ec7778ddab17a5a32f68c531c8b678c8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1D vector.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;一维矢量。</target>
        </trans-unit>
        <trans-unit id="302e5c41a337c972f93ff08bf742872e6882489e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Must be at least 1-dimensional.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;必须至少为一维。</target>
        </trans-unit>
        <trans-unit id="9cff6b01a05d93e056d3e7d25e27d95e0d5b44d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Must be at least 2-dimensional.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;必须至少为二维。</target>
        </trans-unit>
        <trans-unit id="508cdbc779d4073e5eafa0ff8836504797cfe9a3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The input tensor of size</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入张量的大小</target>
        </trans-unit>
        <trans-unit id="11314dbf954d397fca1f11546d1c56bacc29ebd7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The input tensor. Expected to be output of &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;stft()&lt;/code&gt;&lt;/a&gt;, can either be complex (&lt;code&gt;channel&lt;/code&gt;, &lt;code&gt;fft_size&lt;/code&gt;, &lt;code&gt;n_frame&lt;/code&gt;), or real (&lt;code&gt;channel&lt;/code&gt;, &lt;code&gt;fft_size&lt;/code&gt;, &lt;code&gt;n_frame&lt;/code&gt;, 2) where the &lt;code&gt;channel&lt;/code&gt; dimension is optional.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;输入张量。预期输出为&lt;a href=&quot;torch.stft#torch.stft&quot;&gt; &lt;code&gt;stft()&lt;/code&gt; &lt;/a&gt;，可以是复杂的（ &lt;code&gt;channel&lt;/code&gt; ， &lt;code&gt;fft_size&lt;/code&gt; ， &lt;code&gt;n_frame&lt;/code&gt; ），也可以是实数（ &lt;code&gt;channel&lt;/code&gt; ， &lt;code&gt;fft_size&lt;/code&gt; ， &lt;code&gt;n_frame&lt;/code&gt; ，2），其中 &lt;code&gt;channel&lt;/code&gt; 尺寸是可选的。</target>
        </trans-unit>
        <trans-unit id="25819484e745b900dfb30d16e53f617750bd99ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a minibatch of examples</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;示例的小批量</target>
        </trans-unit>
        <trans-unit id="c8a8643fc96ff022524bbbbcc16e1f74f4d027fc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; first tensor in the dot product. Its conjugate is used if it&amp;rsquo;s complex.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;点积中的第一个张量。如果它很复杂，则使用它的共轭。</target>
        </trans-unit>
        <trans-unit id="3329ef02c74e5cee67f1ff96ed2733ed78e48c67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; first tensor to compare</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;比较的第一个张量</target>
        </trans-unit>
        <trans-unit id="b6c3db01982d7f9c54ac50853d8f1beed2cda65f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; float tensor to quantize</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;浮点张量量化</target>
        </trans-unit>
        <trans-unit id="0c7042dc3bf98959f56c246765073fdcc4437d8b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input matrix</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入矩阵</target>
        </trans-unit>
        <trans-unit id="2add4041984cdf88b12d1f1e2dd5b3c7ef0a1d8c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; matrix to be added</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要添加的矩阵</target>
        </trans-unit>
        <trans-unit id="b95c32681c57401ab545053403e32395835243a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要相乘的矩阵</target>
        </trans-unit>
        <trans-unit id="2b1dc1a962b67cc0e0f4fe6ec1e3b9ed6f855288" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; multiple right-hand sides of size</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;大小的多个右侧</target>
        </trans-unit>
        <trans-unit id="fd44d464e1aa57b95d0330a7218514f91318409c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; padded batch of variable length sequences.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;填充了可变长度序列的批处理。</target>
        </trans-unit>
        <trans-unit id="2df5064f26ed4ff300eeca02d8d23ff3989d592a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the &lt;code&gt;a&lt;/code&gt; from &lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;） -的 &lt;code&gt;a&lt;/code&gt; 从&lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt; &lt;code&gt;torch.geqrf()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="32b3debabd5244f6f757a0ecbfc2001f87d51061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the dividend</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;股息</target>
        </trans-unit>
        <trans-unit id="fc63e66b77eddc23d0480985c434968ab3a3c432" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first batch of matrices to be multiplied</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要相乘的第一批矩阵</target>
        </trans-unit>
        <trans-unit id="8048457126f71ad2252c07afbe21ab1ad62cc0e3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;第一个输入张量</target>
        </trans-unit>
        <trans-unit id="40066a22db2f549d0b2b91e1d0653edab74dded7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要相乘的第一个矩阵</target>
        </trans-unit>
        <trans-unit id="8d03903d53b2c5ac4f518cd45d6008241190088c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first multiplicand tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;第一个被乘张量</target>
        </trans-unit>
        <trans-unit id="7f51f99307491138059682bbbc27c557807591a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first tensor to be multiplied</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要相乘的第一个张量</target>
        </trans-unit>
        <trans-unit id="1accceea4c5085a1b9d5fd922dec4a71a7c24ead" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input 2-D tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入二维张量</target>
        </trans-unit>
        <trans-unit id="6146e5ea09927c514d32a11ed0ac42f33556893d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input matrix</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;输入矩阵</target>
        </trans-unit>
        <trans-unit id="708c21e573ae8975fd41f843d793ad7f90dc01c9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入张量</target>
        </trans-unit>
        <trans-unit id="ccd5042b98d78e05ed8accf585abbd7c7cd67f8c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor containing probabilities</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;包含概率的输入张量</target>
        </trans-unit>
        <trans-unit id="a8678adfcf46f049849a9950535e8987135ee8c9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor containing the rates of the Poisson distribution</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;包含泊松分布速率的输入张量</target>
        </trans-unit>
        <trans-unit id="19b4b70bbc0703888b4dd081987a664f12caeab6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of at least &lt;code&gt;signal_ndim&lt;/code&gt; dimensions</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;至少为 &lt;code&gt;signal_ndim&lt;/code&gt; 尺寸的输入张量</target>
        </trans-unit>
        <trans-unit id="a80664bf19108f6871d4d9cc67ea5ec9d65038f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of at least &lt;code&gt;signal_ndim&lt;/code&gt;&lt;code&gt;+ 1&lt;/code&gt; dimensions</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;至少 &lt;code&gt;signal_ndim&lt;/code&gt; &lt;code&gt;+ 1&lt;/code&gt; 维的输入张量</target>
        </trans-unit>
        <trans-unit id="80ea65a4aaf35f42f84d23c01465ca2ef54bdaad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of probability values for the Bernoulli distribution</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash; Bernoulli分布的概率值的输入张量</target>
        </trans-unit>
        <trans-unit id="b642c0b47336e267e577b35820c587126ea9f39a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of size</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;大小的输入张量</target>
        </trans-unit>
        <trans-unit id="9159ecc16b63f9802803f1f98dd7cfcc6322e401" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor of size &lt;code&gt;(*, n, n)&lt;/code&gt; where &lt;code&gt;*&lt;/code&gt; is zero or more batch dimensions.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;大小为 &lt;code&gt;(*, n, n)&lt;/code&gt; 的输入张量，其中 &lt;code&gt;*&lt;/code&gt; 为零或更大的批处理尺寸。</target>
        </trans-unit>
        <trans-unit id="7caaa20ec7806018b377988dd677601f3f83e4d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;输入张量。</target>
        </trans-unit>
        <trans-unit id="121b8ceabf101922601fe3bb8a675692baf2cd6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor. Must be at least 1-dimensional.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;输入张量。必须至少为一维。</target>
        </trans-unit>
        <trans-unit id="80a6967e7a1bc373747e4ceda61d8eca3bcbe71d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor. Must be at least 2-dimensional.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;输入张量。必须至少为二维。</target>
        </trans-unit>
        <trans-unit id="d5176c20efe2b991fb3ef27de42aad8bfff75426" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the matrix</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;矩阵</target>
        </trans-unit>
        <trans-unit id="a9ce71bbfa8c25d01c8c318346faac5f3f4407cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the size of &lt;code&gt;input&lt;/code&gt; will determine size of the output tensor.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash; &lt;code&gt;input&lt;/code&gt; 的大小将决定输出张量的大小。</target>
        </trans-unit>
        <trans-unit id="bfcd8ed79796b25e26a5e670250a73272dac91fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;源张量</target>
        </trans-unit>
        <trans-unit id="b3cad4fa9c4a49fae5b079d14a2bcba4e124c2ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the square matrix of shape</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;形状的方阵</target>
        </trans-unit>
        <trans-unit id="09c118f2812817644cc5b84fc5bc2cef3421e809" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be added</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要添加的张量</target>
        </trans-unit>
        <trans-unit id="648002a80ff2960290b93380fa5ebeba8bd25668" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be reshaped</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要重塑的张量</target>
        </trans-unit>
        <trans-unit id="20715c854d53757985d23efabade3db743a6a166" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compare</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要比较的张量</target>
        </trans-unit>
        <trans-unit id="0c1865166964450f22d83f1a28613f076a2e569b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute the digamma function on</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;用于计算digamma函数的张量</target>
        </trans-unit>
        <trans-unit id="c2bf2493846223fdc5fbfe54614e402279de1747" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute the multivariate log-gamma function</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;用于计算多元对数伽马函数的张量</target>
        </trans-unit>
        <trans-unit id="7fbfb129c11e7747b44805a7b05a9ebc40147948" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to narrow</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要缩小的张量</target>
        </trans-unit>
        <trans-unit id="55c3c22205a1b70d592dec6666248c82e3690335" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to split</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要分割的张量</target>
        </trans-unit>
        <trans-unit id="3219155900c01df3eed96409ef1ed4b22f2fc99a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to unbind</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要解除绑定的张量</target>
        </trans-unit>
        <trans-unit id="1a48e0ca5030fc4d6af5bdfb8605eaef2755a644" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor with the starting points</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;具有起点的张量</target>
        </trans-unit>
        <trans-unit id="6cc211cd1b8495af379d1d59ebf66ec1fb368257" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; vector to be added</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要添加的向量</target>
        </trans-unit>
        <trans-unit id="d0f2899dfd7408899e467222cd4d0bd1c8b163e8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the dividend</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;数字&lt;/em&gt;）&amp;ndash;股息</target>
        </trans-unit>
        <trans-unit id="3e495db7a10b097798f9ab905342091739c99080" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; N-D tensor or a Scalar containing the search value(s).</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;标量&lt;/em&gt;）&amp;ndash; ND张量或包含搜索值的标量。</target>
        </trans-unit>
        <trans-unit id="54b5b721c1619fe54cfff53778c25cbdce11a2a0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;list of Tensors&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;张量&lt;em&gt;列表&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="e15a78cbbc8bd023145c6c784e4996207ef9b8e4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="5b1084c8300aad27ad1784e01fa04c5108343982" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; N-dimensional tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash; N维张量</target>
        </trans-unit>
        <trans-unit id="a4ba99c5e33ab9d93f9eeb31063659728503213f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Quantized input of type &lt;code&gt;torch.quint8&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;类型为 &lt;code&gt;torch.quint8&lt;/code&gt; 的量化输入</target>
        </trans-unit>
        <trans-unit id="e32b4df67a1c6fa976c98f26ed880fe2843dd472" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The input tensor. If dim is None, x must be 1-D or 2-D, unless &lt;code&gt;ord&lt;/code&gt; is None. If both &lt;code&gt;dim&lt;/code&gt; and &lt;code&gt;ord&lt;/code&gt; are None, the 2-norm of the input flattened to 1-D will be returned.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;输入张量。如果dim为None，则x必须为1-D或2-D，除非 &lt;code&gt;ord&lt;/code&gt; 为None。如果 &lt;code&gt;dim&lt;/code&gt; 和 &lt;code&gt;ord&lt;/code&gt; 均为None，则将返回展平为1-D的输入的2-norm。</target>
        </trans-unit>
        <trans-unit id="750efbed074a69bad5c30928c16477fc2a8db885" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入</target>
        </trans-unit>
        <trans-unit id="fbba8e02a600f5a44e37f994cfdcf15acf5f5674" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input of shape</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;形状输入</target>
        </trans-unit>
        <trans-unit id="71024ef201be154545b2752c7794987629860a82" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入张量</target>
        </trans-unit>
        <trans-unit id="cc13ec8f5ecb355720aad713d541718fbcff8ff1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; quantized input</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;量化输入</target>
        </trans-unit>
        <trans-unit id="ca4fccfc307fc839f56fcd2935b753c3a675a514" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; quantized input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;量化输入张量</target>
        </trans-unit>
        <trans-unit id="16adc05235f86a0bdba3f8d133f8ad24c146c434" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input SparseTensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入SparseTensor</target>
        </trans-unit>
        <trans-unit id="f15e5e30b2c90290ac32a42b9dde72a1f212a74f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;输入张量</target>
        </trans-unit>
        <trans-unit id="50bc5249b9927187f00659fce46d0556e5580c69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the input tensor representing a half-Hermitian signal</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;表示半赫密特信号的输入张量</target>
        </trans-unit>
        <trans-unit id="01ff6678d557f24c8e79e022f907950c5a82aff9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the real input tensor</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;实际输入张量</target>
        </trans-unit>
        <trans-unit id="912fbe0aeceffe41c39ef4b4f7a3bd4836fd3f31" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; Tensor containing bags of indices into the embedding matrix</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）-将张量的索引袋包含到嵌入矩阵中</target>
        </trans-unit>
        <trans-unit id="062fdb3d419326f615da299be36d7f8d3afff88a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; Tensor containing indices into the embedding matrix</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;em&gt;LongTensor&lt;/em&gt;）&amp;ndash;包含嵌入矩阵的索引的张量</target>
        </trans-unit>
        <trans-unit id="584da06db551e34afe167aa9b87c9a9f268850eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(batch, input_size)&lt;/code&gt;: tensor containing input features</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;输入&lt;/strong&gt; &lt;code&gt;(batch, input_size)&lt;/code&gt; ：包含输入要素的张量</target>
        </trans-unit>
        <trans-unit id="4a3704197e0eca68967963d49706554f7e113eb5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt;: tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;输入&lt;/strong&gt; &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt; ：包含输入序列特征的张量。输入也可以是打包的可变长度序列。有关详细信息，请参见&lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9ae74c54ba996ad29eb2561904532cd22f9106ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt;: tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.nn.utils.rnn.pack_sequence#torch.nn.utils.rnn.pack_sequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.pack_sequence()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状的&lt;strong&gt;输入&lt;/strong&gt; &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt; ：包含输入序列特征的张量。输入也可以是打包的可变长度序列。有关详细信息，请参见&lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;torch.nn.utils.rnn.pack_sequence#torch.nn.utils.rnn.pack_sequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.pack_sequence()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d073db700f14add42abc2cdb78180dfcfcd6265b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_lengths&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;input_lengths&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="5aab54f56e166a12d78bbb3bb93f9dd9e315d0e5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to reduce and scatter.</source>
          <target state="translated">&lt;strong&gt;input_list&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;要减少和分散的张量列表。</target>
        </trans-unit>
        <trans-unit id="717931cd002baccf50d9c1a13fdb425f6fc9f174" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_names&lt;/strong&gt; (&lt;em&gt;list of strings&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty list&lt;/em&gt;) &amp;ndash; names to assign to the input nodes of the graph, in order</source>
          <target state="translated">&lt;strong&gt;input_names&lt;/strong&gt;（&lt;em&gt;字符串列表&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为空列表&lt;/em&gt;）&amp;ndash;按顺序分配给图的输入节点的名称</target>
        </trans-unit>
        <trans-unit id="9f6472508915540bb1432835a90442a80c1103a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_size&lt;/strong&gt; &amp;ndash; The number of expected features in the input &lt;code&gt;x&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;input_size&lt;/strong&gt; &amp;ndash;输入 &lt;code&gt;x&lt;/code&gt; 中预期&lt;strong&gt;要素&lt;/strong&gt;的数量</target>
        </trans-unit>
        <trans-unit id="c79f2d549859c0d70790524045ea3d4bb1424ec0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_tensor_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to scatter one per rank.</source>
          <target state="translated">&lt;strong&gt;input_tensor_list&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;每个等级分散一个张量的张量列表。</target>
        </trans-unit>
        <trans-unit id="a9e6c1bd49660ef92968bbc7c3dbb9f033fb2e46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors(on different GPUs) to be broadcast from current process. Note that &lt;code&gt;len(input_tensor_list)&lt;/code&gt; needs to be the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;input_tensor_list&lt;/strong&gt;（&lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;要从当前进程广播的张量列表（在不同的GPU上）。请注意，对于调用此函数的所有分布式进程， &lt;code&gt;len(input_tensor_list)&lt;/code&gt; 必须相同。</target>
        </trans-unit>
        <trans-unit id="22e3bf528f143b22c44616b9a8dc2f788e501ebd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_tensor_lists&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;input_tensor_lists&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="e3999ded48b1c7630b579dd8899eda50d65501cf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_to_model&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;list of torch.Tensor&lt;/em&gt;) &amp;ndash; A variable or a tuple of variables to be fed.</source>
          <target state="translated">&lt;strong&gt;input_to_model&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;torch.Tensor&lt;em&gt;列表&lt;/em&gt;）&amp;ndash;要馈送的变量或变量元组。</target>
        </trans-unit>
        <trans-unit id="f2029d7d088f0d74beff905706cfd5a1a9481029" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; A dict containing sample inputs indexed by method names in &lt;code&gt;mod&lt;/code&gt;. The inputs will be passed to methods whose names correspond to inputs&amp;rsquo; keys while tracing. &lt;code&gt;{ 'forward' : example_forward_input, 'method2': example_method2_input}&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;包含样本输入的字典，该样本输入由 &lt;code&gt;mod&lt;/code&gt; 中的方法名称索引。输入将在跟踪时传递给名称对应于输入键的方法。 &lt;code&gt;{ 'forward' : example_forward_input, 'method2': example_method2_input}&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="259474d5c791b17db10ad248774065b0e9b78321" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; inputs to the module</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;模块的输入</target>
        </trans-unit>
        <trans-unit id="f165a76f213ab42e9ce783f6d2d213f4d07554b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; an iterable of tensors to add.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;张量的可迭代量。</target>
        </trans-unit>
        <trans-unit id="65e47b54be8e7f8c4dc3ba2fe581dac20a10b471" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;em&gt;sequence of Tensor&lt;/em&gt;) &amp;ndash; Inputs w.r.t. which the gradient will be returned (and not accumulated into &lt;code&gt;.grad&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;em&gt;张量序列&lt;/em&gt;）&amp;ndash;输入wrt，梯度将返回（不累积到 &lt;code&gt;.grad&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="964b6fac878c1326f1958f5fa8f64bdcbae7b497" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;em&gt;tuple of Tensor&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; inputs to the function</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;em&gt;张量&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量的&lt;/a&gt;&lt;em&gt;元组&lt;/em&gt;）&amp;ndash;函数的输入</target>
        </trans-unit>
        <trans-unit id="a4f77e9ef68c7a234c10cc1f3e81d35349c96a59" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;em&gt;tuple of Tensors&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; inputs to the function &lt;code&gt;func&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;输入&lt;/strong&gt;（&lt;em&gt;张量&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量的&lt;/a&gt;&lt;em&gt;元组&lt;/em&gt;）&amp;ndash;函数 &lt;code&gt;func&lt;/code&gt; 的输入。</target>
        </trans-unit>
        <trans-unit id="66391e4dbaee5f27163769a515f3f8c3c1f8efb1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;interprocess&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, the event can be shared between processes (default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;进程间&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，则事件可以在进程之间共享（默认值： &lt;code&gt;False&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="f465a3e8d61ca508a03930e50b813d53ad7144f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inverse_indices&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): (optional) if &lt;code&gt;return_inverse&lt;/code&gt; is True, there will be an additional returned tensor (same shape as input) representing the indices for where elements in the original input map to in the output; otherwise, this function will only return a single tensor.</source>
          <target state="translated">&lt;strong&gt;inverse_indices&lt;/strong&gt;（&lt;em&gt;Tensor&lt;/em&gt;）：（可选）如果 &lt;code&gt;return_inverse&lt;/code&gt; 为True，将有一个额外的返回张量（与输入形状相同），表示原始输入映射到输出中元素的位置的索引；否则，此函数将仅返回单个张量。</target>
        </trans-unit>
        <trans-unit id="1c290b4c2aff5a326fd2f54283da4670def4dca3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;is useful to see which input shapes contribute to the runtime&lt;/strong&gt; (&lt;em&gt;This&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;了解哪些输入形状有助于运行时很有用&lt;/strong&gt;（&lt;em&gt;This&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="d10b06bfdce2639f080a4d99b489d84dd548cc49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;is_master&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; True when initializing the server store, False for client stores.</source>
          <target state="translated">&lt;strong&gt;is_master&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;初始化服务器存储时为True，对于客户端存储为False。</target>
        </trans-unit>
        <trans-unit id="862ecdae56fdc1758ca8dd0945b92aba6b666d54" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;is_python_module&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt; (default), imports the produced shared library as a Python module. If &lt;code&gt;False&lt;/code&gt;, loads it into the process as a plain dynamic library.</source>
          <target state="translated">&lt;strong&gt;is_python_module&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; （默认），则将生成的共享库作为Python模块导入。如果为 &lt;code&gt;False&lt;/code&gt; ，则将其作为纯动态库加载到流程中。</target>
        </trans-unit>
        <trans-unit id="5e21dc46b7713d2938778d4c4d6aae5e230920ee" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;join&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Perform a blocking join on all processes.</source>
          <target state="translated">&lt;strong&gt;join&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;在所有进程上执行阻塞联接。</target>
        </trans-unit>
        <trans-unit id="c36211dc611d5f7962125dc176c17631f0fc9ec6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; &amp;ndash; additive factor. Default: 1</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt; &amp;ndash;加法因子。默认值：1</target>
        </trans-unit>
        <trans-unit id="e95587d3412a9d195f0a6e77a6567373e57381f7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; k for the k-th smallest element</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;第k个最小元素的k</target>
        </trans-unit>
        <trans-unit id="010b00e48fedcebcad1d2f9692050c44dd1f26ea" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of times to rotate</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;旋转次数</target>
        </trans-unit>
        <trans-unit id="f1a820c8c605e02de337a9983694a9f1d90c85ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the k in &amp;ldquo;top-k&amp;rdquo;</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;&amp;ldquo;前k个&amp;rdquo;中的k</target>
        </trans-unit>
        <trans-unit id="e84cdd778b11f55c6727a09ff5312f00f77186ba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;em&gt;integer&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of requested eigenpairs. Default is the number of</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt;（&lt;em&gt;整数&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;请求的特征对数。默认为</target>
        </trans-unit>
        <trans-unit id="46176694182befc26b76cf4ee9533bb916707744" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kdim&lt;/strong&gt; &amp;ndash; total number of features in key. Default: None.</source>
          <target state="translated">&lt;strong&gt;kdim&lt;/strong&gt; &amp;ndash;关键特征的总数。默认值：无。</target>
        </trans-unit>
        <trans-unit id="057988e71b8851f3d3a181e82f00cb24d94ed154" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keep_initializers_as_inputs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default None&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;keep_initializers_as_inputs&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;默认为None&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="16ca1136f6f7d7eedc320cddba2ed4a25d910b78" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;输出张量是否保持 &lt;code&gt;dim&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="18f7933e87f35c73c988304272aacb2824e2088e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not.</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;输出张量是否保持 &lt;code&gt;dim&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b8941cf07c98d813d55809e96bc7f701eb5365e5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;输出张量是否保持 &lt;code&gt;dim&lt;/code&gt; 。默认值： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5cc82008e4660ec6acca882ad0953eda363fe762" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not. Ignored if &lt;code&gt;dim=None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;输出张量是否保持 &lt;code&gt;dim&lt;/code&gt; 。如果 &lt;code&gt;dim=None&lt;/code&gt; ,则忽略。</target>
        </trans-unit>
        <trans-unit id="e56a9eeb53ccea32a9904a25d931267678cd1dec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Determines whether or not to keep the vector dimension. Default: False</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;确定是否保留矢量尺寸。默认值：False</target>
        </trans-unit>
        <trans-unit id="ad4ef3b64308f3d8dc47146285eef285afa65b13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If set to True, the reduced dimensions are retained in the result as dimensions with size one. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果设置为True，则缩小的尺寸将保留为尺寸为1的尺寸。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="49656d1fc9d8e7326c0f9cd0a4a399d7d00a8efc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether the output tensors have &lt;code&gt;dim&lt;/code&gt; retained or not. Ignored if &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输出张量是否保持 &lt;code&gt;dim&lt;/code&gt; 。如果 &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; 且 &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; 则忽略。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e926f558ead95bc431753d8cae0a5a04ab0c981c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; The size of the sliding window, must be &amp;gt; 0.</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;滑动窗口的大小，必须大于0。</target>
        </trans-unit>
        <trans-unit id="f384943e590807dc76a3468582f227aedc4a238c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; a single int, the size of the window</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;单个整数，窗口的大小</target>
        </trans-unit>
        <trans-unit id="572a73e28152cca7b78a46ac5637d93451f8a981" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; size of the pooling region. Can be a single number or a tuple &lt;code&gt;(kH, kW)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;池区域的大小。可以是单个数字或元组 &lt;code&gt;(kH, kW)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="014e7d7bdeac3998dbeeee898f78081432eebec9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; size of the pooling region. Can be a single number or a tuple &lt;code&gt;(kT, kH, kW)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;池区域的大小。可以是单个数字或元组 &lt;code&gt;(kT, kH, kW)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a26c47fa3182db8a890cdda0e99882bc0c208430" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;窗口的大小</target>
        </trans-unit>
        <trans-unit id="6caea6991ef207d1f8220f4b3d0bf3cc83fa3f4e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window to take a max over</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;取最大值的窗口的大小</target>
        </trans-unit>
        <trans-unit id="771b7c3eece18f47a1bfb3f3eecd292084766b6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window to take a max over. Can be a single number k (for a square kernel of k x k) or a tuple &lt;code&gt;(kh, kw)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;取最大值的窗口的大小。可以是单个数字k（对于kxk的平方核）或元组 &lt;code&gt;(kh, kw)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="86dbe9a6fa4b3ebfff876256dbee957af7b6f899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window. Can be a single number or a tuple &lt;code&gt;(kW,)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash;窗口的大小。可以是单个数字或元组 &lt;code&gt;(kW,)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6983b15f4f38a9ac825f42d5eb9c0f2f04b3cf67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Size of the convolving kernel</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;卷积内核的大小</target>
        </trans-unit>
        <trans-unit id="be2e08d3d82748f43712995275bcdf4a3dd15ad5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Size of the max pooling window.</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;最大池窗口的大小。</target>
        </trans-unit>
        <trans-unit id="cd3efc67efa8a3a8afc9e450066251f14074f4dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the sliding blocks</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;元组&lt;/a&gt;）&amp;ndash;滑块的大小</target>
        </trans-unit>
        <trans-unit id="0114fc6c0cd33e2cd2e18270605b3182ff85045a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key, and value have the same number of features.&lt;/strong&gt; (&lt;em&gt;query&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;键和值具有相同数量的功能。&lt;/strong&gt;（&lt;em&gt;查询&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="84a1ee94b9552fbe98a263714fe34401d07c1736" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key, value&lt;/strong&gt; (&lt;em&gt;query&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash; map a query and a set of key-value pairs to an output. See &amp;ldquo;Attention Is All You Need&amp;rdquo; for more details.</source>
          <target state="translated">&lt;strong&gt;键，值&lt;/strong&gt;（&lt;em&gt;query &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;）&amp;ndash;将查询和一组键-值对映射到输出。有关更多详细信息，请参见&amp;ldquo;注意就是全部&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="f0822e8093f74e590339677b718f3d7e76f763f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The function will return the value associated with this key.</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;该函数将返回与此键关联的值。</target>
        </trans-unit>
        <trans-unit id="b269c0df40f6a8dea8192305fc8edbdb790e8a51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The key in the store whose counter will be incremented.</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;商店中将递增其计数器的键。</target>
        </trans-unit>
        <trans-unit id="a79165af1a31b78c12a0c79537ce451875db8c0a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The key to be added to the store.</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;要添加到商店的密钥。</target>
        </trans-unit>
        <trans-unit id="a420b4a7c78ffaa362bae22a02d609b5238dbdad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The key to be deleted from the store</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;要从存储中删除的密钥</target>
        </trans-unit>
        <trans-unit id="dbc5adefc4e865a7f69b4455755c908e2aa6cbdc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; key to pop from the ModuleDict</source>
          <target state="translated">&lt;strong&gt;键&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;从ModuleDict弹出的键</target>
        </trans-unit>
        <trans-unit id="4f26ac6300ccaa9e27a066b28715d3964edce7d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; key to pop from the ParameterDict</source>
          <target state="translated">&lt;strong&gt;键&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;从ParameterDict弹出的键</target>
        </trans-unit>
        <trans-unit id="78144a9a3d220664056838664be8661e6c3c9060" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key_padding_mask&lt;/strong&gt; &amp;ndash; if provided, specified padding elements in the key will be ignored by the attention. When given a binary mask and a value is True, the corresponding value on the attention layer will be ignored. When given a byte mask and a value is non-zero, the corresponding value on the attention layer will be ignored</source>
          <target state="translated">&lt;strong&gt;key_padding_mask&lt;/strong&gt; &amp;ndash;如果提供的话，键中指定的填充元素将被忽略。给定二进制掩码且值为True时，关注层上的相应值将被忽略。给定字节掩码且值不为零时，关注层上的相应值将被忽略</target>
        </trans-unit>
        <trans-unit id="64d040096feaaa3ad1d281fdbf7b1e7688897fff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keys&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; List of keys on which to wait until they are set in the store.</source>
          <target state="translated">&lt;strong&gt;keys&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;在商店中等待设置之前要等待的键的列表。</target>
        </trans-unit>
        <trans-unit id="044d19f693d2f3d8a173c57835f733ffa0c81a94" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; Any keyword arguments.</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash;任何关键字参数。</target>
        </trans-unit>
        <trans-unit id="f1a566ba7fd0d874e168c17e63abfc5faaeda0fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; any keyword argument (unused)</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash;任何关键字参数（未使用）</target>
        </trans-unit>
        <trans-unit id="266f88e78551cdfc4dd3b12f3bdb84242fe5cbc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; arguments to pass to the optimizer constructor on each worker.</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash;传递给每个工作程序上的优化器构造函数的参数。</target>
        </trans-unit>
        <trans-unit id="792aa49fbbca0bb348cbf77a79dc714af59b3ad2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; keyword arguments passed on to a subclass of a &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash;传递给&lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod&quot;&gt; &lt;code&gt;BasePruningMethod&lt;/code&gt; &lt;/a&gt;的子类的关键字参数</target>
        </trans-unit>
        <trans-unit id="fedd0f20c005d43f5156a1e433f31ab84c26bd81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; keyword arguments passed on to a subclass of a &lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash;传递给&lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt; &lt;code&gt;BasePruningMethod&lt;/code&gt; &lt;/a&gt;的子类的关键字参数</target>
        </trans-unit>
        <trans-unit id="1c0b946c6e8e6d58a96c5dc6767edc5a0986bd04" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; other keyword arguments such as: amount (int or float): quantity of parameters to prune across the specified parameters. If &lt;code&gt;float&lt;/code&gt;, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If &lt;code&gt;int&lt;/code&gt;, it represents the absolute number of parameters to prune.</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash;其他关键字参数，例如：amount（整数或浮点数）：跨指定参数修剪的参数数量。如果 &lt;code&gt;float&lt;/code&gt; ，则应在0.0到1.0之间，并且代表要修剪的参数的分数。如果为 &lt;code&gt;int&lt;/code&gt; ，则表示要修剪的参数的绝对数量。</target>
        </trans-unit>
        <trans-unit id="d0fd99fc795f5d48a5e60df282d78e00104ba241" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; is a dictionary of keyword arguments for the &lt;code&gt;func&lt;/code&gt; invocation.</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;是用于 &lt;code&gt;func&lt;/code&gt; 调用的关键字参数的字典。</target>
        </trans-unit>
        <trans-unit id="13138447f871c2af389a4fca56a99836f8077860" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;label_img&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Images correspond to each data point</source>
          <target state="translated">&lt;strong&gt;label_img&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;图像对应于每个数据点</target>
        </trans-unit>
        <trans-unit id="c49724fe69a85b49c33c508646fb23cf737c434f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;labels&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Ground truth data. Binary label for each element.</source>
          <target state="translated">&lt;strong&gt;标签&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;string / blobname&lt;/em&gt;）&amp;ndash;地面真相数据。每个元素的二进制标签。</target>
        </trans-unit>
        <trans-unit id="264535b79c947ac6ae0426c447265ae41129aa0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lambd&lt;/strong&gt; &amp;ndash; the</source>
          <target state="translated">&lt;strong&gt;lambd&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="eb1bfc3c10cee85b47368e280d5fa5b8b99d7871" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lambd&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; decay term (default: 1e-4)</source>
          <target state="translated">&lt;strong&gt;lambd&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;衰减项（默认值：1e-4）</target>
        </trans-unit>
        <trans-unit id="1661e6401aad1339abbf5bd62f0c278ec8d6d90e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;largest&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return largest or smallest elements</source>
          <target state="translated">&lt;strong&gt;最大&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;布尔值&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;控制是否返回最大或最小元素</target>
        </trans-unit>
        <trans-unit id="fdf7fc35f25f5906a12f37c633b280b391c3c3d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;largest&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; when True, solve the eigenproblem for the largest eigenvalues. Otherwise, solve the eigenproblem for smallest eigenvalues. Default is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;最大&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;为True时，求解最大特征值的特征问题。否则，求解特征值最小的问题。默认值为 &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3c816953802bf0955cc5760c186166581884c57d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;last element is the size of the input, or the ending index position of the last bag&lt;/strong&gt; (&lt;em&gt;The&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;last元素是输入的大小，或最后一个包的结束索引位置&lt;/strong&gt;（&lt;em&gt;The&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="8b2a08a3d9a86f04fd85848e910356b2127aa22d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;last_epoch&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The index of last epoch. Default: -1.</source>
          <target state="translated">&lt;strong&gt;last_epoch&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;最后一个纪元的索引。默认值：-1。</target>
        </trans-unit>
        <trans-unit id="ee8be3a2ca398755a3635c9afaf9cf0d39b726e3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;last_epoch&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The index of the last batch. This parameter is used when resuming a training job. Since &lt;code&gt;step()&lt;/code&gt; should be invoked after each batch instead of after each epoch, this number represents the total number of &lt;em&gt;batches&lt;/em&gt; computed, not the total number of epochs computed. When last_epoch=-1, the schedule is started from the beginning. Default: -1</source>
          <target state="translated">&lt;strong&gt;last_epoch&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;最后一批的索引。恢复训练作业时使用此参数。由于应该在每个批处理之后而不是每个纪元之后调用 &lt;code&gt;step()&lt;/code&gt; ，因此该数字表示所计算的&lt;em&gt;批处理&lt;/em&gt;总数，而不是所计算的纪元总数。当last_epoch = -1时，调度将从头开始。默认值：-1</target>
        </trans-unit>
        <trans-unit id="ac7e5e95f90923fa77510427955802f84f53c2d7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;last_epoch&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The index of last epoch. Default: -1.</source>
          <target state="translated">&lt;strong&gt;last_epoch&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;最后一个纪元的索引。默认值：-1。</target>
        </trans-unit>
        <trans-unit id="88e9ebec7af1894b1a89ea6a01d54fd47775eace" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; currently only support &lt;code&gt;torch.strided&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;布局&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;当前仅支持 &lt;code&gt;torch.strided&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7bf3f4fbf68fed19ae95979f8c8178ebe6d46e40" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired layout of returned Tensor. Default: &lt;code&gt;torch.strided&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;layout&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的Tensor所需的布局。默认值： &lt;code&gt;torch.strided&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="94414c640396bd9bbbf2ad80f1e3206b610ac0ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired layout of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, defaults to the layout of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;layout&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的张量的所需布局。默认值：如果为 &lt;code&gt;None&lt;/code&gt; ，则默认为 &lt;code&gt;input&lt;/code&gt; 的布局。</target>
        </trans-unit>
        <trans-unit id="0db1c24c17c8fb5d6f179479b0b643184229505b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired layout of returned window tensor. Only &lt;code&gt;torch.strided&lt;/code&gt; (dense layout) is supported.</source>
          <target state="translated">&lt;strong&gt;layout&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的窗口张量的所需布局。仅支持 &lt;code&gt;torch.strided&lt;/code&gt; （密集布局）。</target>
        </trans-unit>
        <trans-unit id="46d7f78e6035019338c7eef0206b97309c29f933" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; {categoryName: &lt;em&gt;charts&lt;/em&gt;}, where &lt;em&gt;charts&lt;/em&gt; is also a dictionary {chartName: &lt;em&gt;ListOfProperties&lt;/em&gt;}. The first element in &lt;em&gt;ListOfProperties&lt;/em&gt; is the chart&amp;rsquo;s type (one of &lt;strong&gt;Multiline&lt;/strong&gt; or &lt;strong&gt;Margin&lt;/strong&gt;) and the second element should be a list containing the tags you have used in add_scalar function, which will be collected into the new chart.</source>
          <target state="translated">&lt;strong&gt;布局&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash; {类别名称：&lt;em&gt;图表&lt;/em&gt;}，其中&lt;em&gt;图表&lt;/em&gt;也是字典{chartName：&lt;em&gt;ListOfProperties&lt;/em&gt; }。&lt;em&gt;ListOfProperties中&lt;/em&gt;的第一个元素是图表的类型（&lt;strong&gt;Multiline&lt;/strong&gt;或&lt;strong&gt;Margin之一&lt;/strong&gt;），第二个元素应该是包含您在add_scalar函数中使用的标签的列表，这些标签将被收集到新图表中。</target>
        </trans-unit>
        <trans-unit id="e94626f3232ee79b88ea32ac6e17800f0711856b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the distance to the ending dimension</source>
          <target state="translated">&lt;strong&gt;length&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;到最终尺寸的距离</target>
        </trans-unit>
        <trans-unit id="8f03be3c5e51ff8247aa0a57df0a1b4f93ee5396" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;length&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The amount to trim the signal by (i.e. the original signal length). (Default: whole signal)</source>
          <target state="translated">&lt;strong&gt;长度&lt;/strong&gt;（&lt;em&gt;可选&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;修剪信号的量（即原始信号长度）。（默认：整个信号）</target>
        </trans-unit>
        <trans-unit id="b4ad30add260bff538fca1a6ab975e7e36e60203" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lengths&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; list of sequences lengths of each batch element.</source>
          <target state="translated">&lt;strong&gt;lengths&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;每个批处理元素的序列长度列表。</target>
        </trans-unit>
        <trans-unit id="46d7256e9acb60210f2e5001a7a7ab48fd8622b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lengths&lt;/strong&gt; (&lt;em&gt;sequence&lt;/em&gt;) &amp;ndash; lengths of splits to be produced</source>
          <target state="translated">&lt;strong&gt;长度&lt;/strong&gt;（&lt;em&gt;序列&lt;/em&gt;）&amp;ndash;要产生的分割长度</target>
        </trans-unit>
        <trans-unit id="0d4ae06157920c0edc4da18c286dd2281a28071e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;line_search_fn&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; either &amp;lsquo;strong_wolfe&amp;rsquo; or None (default: None).</source>
          <target state="translated">&lt;strong&gt;line_search_fn&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;&amp;ldquo; strong_wolfe&amp;rdquo;或&amp;ldquo;无&amp;rdquo;（默认值：无）。</target>
        </trans-unit>
        <trans-unit id="e2ddc7f0cb0f7aa1279d7434e7a52c24cdfc3d5a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;linewidth&lt;/strong&gt; &amp;ndash; The number of characters per line for the purpose of inserting line breaks (default = 80). Thresholded matrices will ignore this parameter.</source>
          <target state="translated">&lt;strong&gt;线宽&lt;/strong&gt;&amp;ndash;用于插入换行符的每行字符数（默认= 80）。阈值矩阵将忽略此参数。</target>
        </trans-unit>
        <trans-unit id="9a0b73f33b90888a42c750b6b973c0a4519c14cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;list&lt;/strong&gt; (&lt;em&gt;tensor&lt;/em&gt;) &amp;ndash; List of input and output tensors of the collective. The function operates in-place and requires that each tensor to be a GPU tensor on different GPUs. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;list&lt;/strong&gt;（&lt;em&gt;tensor&lt;/em&gt;）&amp;ndash;集合的输入和输出张量的列表。该函数在原位运行，并且要求每个张量都是不同GPU上的GPU张量。您还需要确保所有调用此函数的分布式进程的 &lt;code&gt;len(tensor_list)&lt;/code&gt; 都相同。</target>
        </trans-unit>
        <trans-unit id="932d285cb5500eeb2ef857a2e17a707d7fc096b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Location parameter of the distribution</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布的位置参数</target>
        </trans-unit>
        <trans-unit id="b6cbcefb888e1ab9711f04b51a668b64bf12e4ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; mean of log of distribution</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布对数的平均值</target>
        </trans-unit>
        <trans-unit id="bc194cc545cdcccb14c930cfbe31012644c22453" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; mean of the distribution</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布的均值</target>
        </trans-unit>
        <trans-unit id="205933e969912634f51b550fa1e983040295221b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; mean of the distribution (often referred to as mu)</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布的平均值（通常称为mu）</target>
        </trans-unit>
        <trans-unit id="e1b86547692726edeab7f94112d4af9d07100389" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; mode or median of the distribution.</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布的众数或中位数。</target>
        </trans-unit>
        <trans-unit id="8f219815927153fd66f4cdab28f993a70a68b018" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; mean of the distribution</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布的均值</target>
        </trans-unit>
        <trans-unit id="e9da880570a6da88adfb3bad6c9b9e0a223dc682" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; mean of the distribution with shape &lt;code&gt;batch_shape + event_shape&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状为 &lt;code&gt;batch_shape + event_shape&lt;/code&gt; 的分布平均值</target>
        </trans-unit>
        <trans-unit id="77f321ea22ac7ecd844fd4c85d32d738eb4a9fcd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Location parameter.</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点数&lt;/a&gt;）&amp;ndash;位置参数。</target>
        </trans-unit>
        <trans-unit id="1453ad4abaa60f2ac5cb1c6b5b077012128a2a7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loc&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; an angle in radians.</source>
          <target state="translated">&lt;strong&gt;loc&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;以弧度为单位的角度。</target>
        </trans-unit>
        <trans-unit id="a6af9ed1c4f286897f05981280cbd8b1f3ff4ebb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_dir&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Save directory location. Default is runs/&lt;strong&gt;CURRENT_DATETIME_HOSTNAME&lt;/strong&gt;, which changes after each run. Use hierarchical folder structure to compare between runs easily. e.g. pass in &amp;lsquo;runs/exp1&amp;rsquo;, &amp;lsquo;runs/exp2&amp;rsquo;, etc. for each new experiment to compare across them.</source>
          <target state="translated">&lt;strong&gt;log_dir&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;保存目录位置。默认值为运行次数/ &lt;strong&gt;CURRENT_DATETIME_HOSTNAME&lt;/strong&gt;，每次运行后都会更改。使用分层文件夹结构可以轻松地在运行之间进行比较。例如，为每个新实验传递&amp;ldquo; runs / exp1&amp;rdquo;，&amp;ldquo; runs / exp2&amp;rdquo;等，以便在它们之间进行比较。</target>
        </trans-unit>
        <trans-unit id="e21a2b0779d46aa79f400ad4cdf3c0dba396033e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_input&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; the loss is computed as</source>
          <target state="translated">&lt;strong&gt;log_input&lt;/strong&gt; &amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ,则损失计算为</target>
        </trans-unit>
        <trans-unit id="c6e337713f719f7f73fae5c0a44576d8936beac7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_input&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt; the loss is computed as</source>
          <target state="translated">&lt;strong&gt;log_input&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ,则损失计算为</target>
        </trans-unit>
        <trans-unit id="0f3912ec8124045880111aeedd237bc31f76c3a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_probs&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;log_probs&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="a96e8db96ae8039870ee95945a0d311143381324" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_target&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; A flag indicating whether &lt;code&gt;target&lt;/code&gt; is passed in the log space. It is recommended to pass certain distributions (like &lt;code&gt;softmax&lt;/code&gt;) in the log space to avoid numerical issues caused by explicit &lt;code&gt;log&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;log_target&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;一个标志，指示是否在日志空间中传递了 &lt;code&gt;target&lt;/code&gt; 。建议在日志空间中传递某些分布（如 &lt;code&gt;softmax&lt;/code&gt; ），以避免显式 &lt;code&gt;log&lt;/code&gt; 引起的数值问题。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7071da2a7b3f7ca5a3045161a47ac564d02ec18a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_target&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies whether &lt;code&gt;target&lt;/code&gt; is passed in the log space. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;log_target&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;指定是否在日志空间中传递 &lt;code&gt;target&lt;/code&gt; 。默认值： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b5bfe7f9ad9a8759384f7463a9f5c13f4bcc1cdb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; &amp;ndash; &lt;code&gt;[&amp;hellip;, num_features]&lt;/code&gt; unnormalized log probabilities</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt; &amp;ndash; &lt;code&gt;[&amp;hellip;, num_features]&lt;/code&gt; 归一化的日志概率</target>
        </trans-unit>
        <trans-unit id="c7b0e513e660e6ae0aecd8ce0340f25835570b8b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Event log-odds</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;事件对数</target>
        </trans-unit>
        <trans-unit id="9cd67273d6115306dfd71269c8f730293cecfea1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Event log-odds for probabilities of success</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;成功概率的事件对数</target>
        </trans-unit>
        <trans-unit id="d0dd62d6b118866e10be092ef3745e38b09d4ce9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; event log probabilities</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;事件日志概率</target>
        </trans-unit>
        <trans-unit id="c2c4916a23bcf24ab00242649727ed2f95b91453" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; event log-odds</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;事件对数</target>
        </trans-unit>
        <trans-unit id="b7efd530f6262255b871809674d067ec842a82da" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the log probability of each event.</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;每个事件的对数概率。</target>
        </trans-unit>
        <trans-unit id="f04b583a1f4e8907bdd1dcfa0e69ececfe642707" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; real valued parameters whose sigmoid matches &amp;lsquo;probs&amp;rsquo;</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;em&gt;Number &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash; S形与&amp;ldquo;概率&amp;rdquo;匹配的实数值参数</target>
        </trans-unit>
        <trans-unit id="3642c00caa6566edf3d584465c065796bfd40e70" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the log-odds of sampling &lt;code&gt;1&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;em&gt;Number &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;采样的对数奇数 &lt;code&gt;1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4b2712af2da3a7a55410ea9fc1006d769c2d438d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the log-odds of sampling &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;logits&lt;/strong&gt;（&lt;em&gt;数字&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;采样的对数奇数 &lt;code&gt;1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8bef4bf0c6f4823e7e112fc81eda3d3be435f702" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loss&lt;/strong&gt; is a Scalar representing the computed negative log likelihood loss</source>
          <target state="translated">&lt;strong&gt;loss&lt;/strong&gt;是一个标量，代表计算出的负对数似然损失</target>
        </trans-unit>
        <trans-unit id="9cf1dfa5f62dbefc053a252f2503eebdfb537995" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;low&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; lower range (inclusive).</source>
          <target state="translated">&lt;strong&gt;低&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;较低范围（含）。</target>
        </trans-unit>
        <trans-unit id="70e041ec68422ba2e379d712b1ccecdb156099a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;low&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Lowest integer to be drawn from the distribution. Default: 0.</source>
          <target state="translated">&lt;strong&gt;low&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;从分布中得出的最低整数。默认值：0</target>
        </trans-unit>
        <trans-unit id="7c5a7d8df51ea63239d3ca2a365d80e7b7f44e08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lower&lt;/strong&gt; &amp;ndash; lower bound of the uniform distribution. Default:</source>
          <target state="translated">&lt;strong&gt;下&lt;/strong&gt;&amp;ndash;均匀分布的下限。默认：</target>
        </trans-unit>
        <trans-unit id="d7b36d6b2207205361968b5b3da4740b41a65c67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; learning rate</source>
          <target state="translated">&lt;strong&gt;lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;学习率</target>
        </trans-unit>
        <trans-unit id="d0b7b5f75303acbfe6aeda36499b4e6455a92b41" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; learning rate (default: 1)</source>
          <target state="translated">&lt;strong&gt;lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;学习率（默认值：1）</target>
        </trans-unit>
        <trans-unit id="ad462d2123563bca49e628fcb70d455948a9eba3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; coefficient that scale delta before it is applied to the parameters (default: 1.0)</source>
          <target state="translated">&lt;strong&gt;lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;在将增量应用到参数之前缩放增量的系数（默认值：1.0）</target>
        </trans-unit>
        <trans-unit id="eca11e2fa06744018267d874d481642b6a99b183" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; learning rate (default: 1e-2)</source>
          <target state="translated">&lt;strong&gt;lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;学习率（默认值：1e-2）</target>
        </trans-unit>
        <trans-unit id="a6cad43fae486eff51402dafbfac4db7b6b965ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; learning rate (default: 1e-3)</source>
          <target state="translated">&lt;strong&gt;lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;学习率（默认值：1e-3）</target>
        </trans-unit>
        <trans-unit id="167483491609d9a0143c824fa5f5fb5841848e5f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; learning rate (default: 2e-3)</source>
          <target state="translated">&lt;strong&gt;lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;学习率（默认值：2e-3）</target>
        </trans-unit>
        <trans-unit id="d35030ab8c415ed71a5635972835c914552863c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr_decay&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; learning rate decay (default: 0)</source>
          <target state="translated">&lt;strong&gt;lr_decay&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;学习速率衰减（默认值：0）</target>
        </trans-unit>
        <trans-unit id="4ad1654b3c81c933afbb5f8a4c37726032cd7262" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lr_lambda&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; A function which computes a multiplicative factor given an integer parameter epoch, or a list of such functions, one for each group in optimizer.param_groups.</source>
          <target state="translated">&lt;strong&gt;lr_lambda&lt;/strong&gt;（&lt;em&gt;函数&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;列表&lt;/a&gt;）&amp;ndash;在给定整数参数纪元或此类函数列表的情况下计算乘法因子的函数，对于optimizer.param_groups中的每个组均使用一个。</target>
        </trans-unit>
        <trans-unit id="4f0a9fa0370655d11d3532fe9815ce442456bb8a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;m&lt;/strong&gt; &amp;ndash; A &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; to save.</source>
          <target state="translated">&lt;strong&gt;m&lt;/strong&gt; &amp;ndash;要保存的&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="fd123d273fbb02028d3c0300d6ad3c2fce942d1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;m&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of columns with default being &lt;code&gt;n&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;m&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;默认为 &lt;code&gt;n&lt;/code&gt; 的列数</target>
        </trans-unit>
        <trans-unit id="70f0c622ba7f16dab21096968ca88594ae3eb5fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;main_tag&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; The parent name for the tags</source>
          <target state="translated">&lt;strong&gt;main_tag&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;标签的父名称</target>
        </trans-unit>
        <trans-unit id="44bef03b746085c112465e22dd0b732f7855866e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;map_location&lt;/strong&gt; &amp;ndash; a function, &lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, string or a dict specifying how to remap storage locations</source>
          <target state="translated">&lt;strong&gt;map_location&lt;/strong&gt; &amp;ndash;函数，&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;，字符串或指定如何重新映射存储位置的字典</target>
        </trans-unit>
        <trans-unit id="ef33fe86d546f14a70960dd930eacfcbfad6910b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;map_location&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a function or a dict specifying how to remap storage locations (see torch.load)</source>
          <target state="translated">&lt;strong&gt;map_location&lt;/strong&gt;（&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;指定如何重新映射存储位置的函数或dict（请参阅torch.load）</target>
        </trans-unit>
        <trans-unit id="914b80d642dfeaba6272f2de3bf65d1022719a77" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;map_location&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; A simplified version of &lt;code&gt;map_location&lt;/code&gt; in &lt;code&gt;torch.jit.save&lt;/code&gt; used to dynamically remap storages to an alternative set of devices.</source>
          <target state="translated">&lt;strong&gt;map_location&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;）&amp;ndash; &lt;code&gt;map_location&lt;/code&gt; 中 &lt;code&gt;torch.jit.save&lt;/code&gt; 简化版本，用于动态地将存储重新映射到另一组设备。</target>
        </trans-unit>
        <trans-unit id="38f1d58703037b5452e6debc51817125c3e4159a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mapping&lt;/strong&gt; &amp;ndash; a dictionary that maps from nn module to nnq module</source>
          <target state="translated">&lt;strong&gt;映射&lt;/strong&gt;&amp;ndash;从nn模块映射到nnq模块的字典</target>
        </trans-unit>
        <trans-unit id="dcff61dc1a63e697b62ab44d808a367653b8b401" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mapping&lt;/strong&gt; &amp;ndash; a dictionary that maps from source module type to target module type, can be overwritten to allow swapping user defined Modules</source>
          <target state="translated">&lt;strong&gt;映射&lt;/strong&gt;&amp;ndash;从源模块类型映射到目标模块类型的字典，可以覆盖以允许交换用户定义的模块</target>
        </trans-unit>
        <trans-unit id="aba51605b877792de1fe61b3ad8c44e8616a52a0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mapping&lt;/strong&gt; &amp;ndash; correspondence between original module types and quantized counterparts</source>
          <target state="translated">&lt;strong&gt;映射&lt;/strong&gt;&amp;ndash;原始模块类型和量化的对应模块之间的对应关系</target>
        </trans-unit>
        <trans-unit id="cd0f4742cec293420674fc04d6567be19166a206" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mapping&lt;/strong&gt; &amp;ndash; dictionary that maps float modules to quantized modules to be replaced.</source>
          <target state="translated">&lt;strong&gt;映射&lt;/strong&gt;&amp;ndash;将浮点模块映射到要替换的量化模块的字典。</target>
        </trans-unit>
        <trans-unit id="0ee71f6909a96c9a3f4f2b409a0beb65f931f258" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mapping&lt;/strong&gt; &amp;ndash; maps type of a submodule to a type of corresponding dynamically quantized version with which the submodule needs to be replaced</source>
          <target state="translated">&lt;strong&gt;映射&lt;/strong&gt;&amp;ndash;将子模块的类型&lt;strong&gt;映射&lt;/strong&gt;到需要替换子模块的相应动态量化版本的类型</target>
        </trans-unit>
        <trans-unit id="a76d819de26b9a69327b4e9ff4618411dff8d317" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A non-negative margin representing the minimum difference between the positive and negative distances required for the loss to be 0. Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives. Default:</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;一个非负的余量，表示损失为0所需的正负距离之间的最小差。较大的余量惩罚负例相对于正数距离锚点距离不够的情况。默认：</target>
        </trans-unit>
        <trans-unit id="d33d454f6271f798670e376263ffba9cbf000630" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Default:</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;默认值：</target>
        </trans-unit>
        <trans-unit id="56ee260326698f65dd6b6c40f6a508083eb54156" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;默认值为</target>
        </trans-unit>
        <trans-unit id="024e1f6072ab1c5c9f6954c815378eb35255dec0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;默认值为 &lt;code&gt;1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0a1c2406f918b1a2ebe9a9c579789d15e7910666" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Should be a number from</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;应该是一个数字</target>
        </trans-unit>
        <trans-unit id="dc236878c72bde16cfeffe2cac289d6375b4d7f4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; &amp;ndash; the mask for the src sequence (optional).</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt; &amp;ndash; src序列的掩码（可选）。</target>
        </trans-unit>
        <trans-unit id="e18ffc51ffd4959b08fbd0a3bfc5fa56421b9e3e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; the boolean mask</source>
          <target state="translated">&lt;strong&gt;面具&lt;/strong&gt;（&lt;a href=&quot;#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;）&amp;ndash;布尔面具</target>
        </trans-unit>
        <trans-unit id="6415d8f4fc74353778af124a9edd9fa991dc2d49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; the tensor containing the binary mask to index with</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;）&amp;ndash;包含二进制掩码的张量，使用该索引进行索引</target>
        </trans-unit>
        <trans-unit id="09b9037dad942fd7a7535f675e34e4544c3bd0e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; binary mask to be applied to the parameter.</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;应用于参数的二进制掩码。</target>
        </trans-unit>
        <trans-unit id="e34cd5d03db7bc2e1ff2fedd665486796048ea46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; a SparseTensor which we filter &lt;code&gt;input&lt;/code&gt; based on its indices</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt;（&lt;em&gt;SparseTensor&lt;/em&gt;）&amp;ndash;一个SparseTensor，我们根据其索引过滤 &lt;code&gt;input&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e019f9c4c52d2f155730f344ebf436e60e0683e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat1&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要相乘的第一个矩阵</target>
        </trans-unit>
        <trans-unit id="3b6257ac15daec460e7856dfaf4bb8570f4c2d6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat1&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; a sparse matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat1&lt;/strong&gt;（&lt;em&gt;SparseTensor&lt;/em&gt;）&amp;ndash;要相乘的稀疏矩阵</target>
        </trans-unit>
        <trans-unit id="0d5be763c9e61f15bd0bc4d527929a6c1dd8cf14" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat1&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; the first sparse matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat1&lt;/strong&gt;（&lt;em&gt;SparseTensor&lt;/em&gt;）&amp;ndash;要相乘的第一个稀疏矩阵</target>
        </trans-unit>
        <trans-unit id="98880e96bbe3ad0fcc2eae35bc3ea2b501838cf1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second batch of matrices to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;要相乘的第二批矩阵</target>
        </trans-unit>
        <trans-unit id="0dc66f375564c02c1c9b573824bb73a7b00eaf7d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要相乘的第二个矩阵</target>
        </trans-unit>
        <trans-unit id="f696dccd1ae44ddee20d75e7dbc3ff06722bc099" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a dense matrix be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;将一个密矩阵相乘</target>
        </trans-unit>
        <trans-unit id="b94541c2bb36a977f8a383b6790acb61c7f9672c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second dense matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要相乘的第二个密矩阵</target>
        </trans-unit>
        <trans-unit id="1b163b780efadeab4d13fd7393ace98318c94610" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要相乘的矩阵</target>
        </trans-unit>
        <trans-unit id="02d4e6fa23ead0a267a7e63391cb2505b4395991" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a dense matrix to be added</source>
          <target state="translated">&lt;strong&gt;mat&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;要添加的密集矩阵</target>
        </trans-unit>
        <trans-unit id="a658df425748dff8f4417d65ab2c445b2fdf38ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;) &amp;ndash; A matrix which each row is the feature vector of the data point</source>
          <target state="translated">&lt;strong&gt;mat&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;）&amp;ndash;一个矩阵，每一行都是数据点的特征向量</target>
        </trans-unit>
        <trans-unit id="d80f81e280edcd37fa8ee208223d3ff8f1c41090" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;matrices&lt;/strong&gt; (&lt;em&gt;Tensors...&lt;/em&gt;) &amp;ndash; a sequence of 2 or more 2-D tensors whose product is to be determined.</source>
          <target state="translated">&lt;strong&gt;矩阵&lt;/strong&gt;（&lt;em&gt;张量...&lt;/em&gt;）&amp;ndash;由2个或多个2D张量决定的乘积序列。</target>
        </trans-unit>
        <trans-unit id="85dfbb6d8965fcf255941fecf0a3f9636ed92d49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; upper end of the range (inclusive)</source>
          <target state="translated">&lt;strong&gt;max&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;范围的上限（包括）</target>
        </trans-unit>
        <trans-unit id="ebd724e75db34df9a1697eb48e3e36ab4d0a6944" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; maximal value of each element in the output</source>
          <target state="translated">&lt;strong&gt;max&lt;/strong&gt;（&lt;em&gt;Number&lt;/em&gt;）&amp;ndash;输出中每个元素的最大值</target>
        </trans-unit>
        <trans-unit id="408cb0787a19c61a9e10d267b40c421e0d8c65b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; upper-bound of the range to be clamped to</source>
          <target state="translated">&lt;strong&gt;max&lt;/strong&gt;（&lt;em&gt;Number&lt;/em&gt;）&amp;ndash;要限制到的范围的上限</target>
        </trans-unit>
        <trans-unit id="fc3151b648e0f145cb6c4ddd3eb3ccbd16d8b4fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_eval&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; maximal number of function evaluations per optimization step (default: max_iter * 1.25).</source>
          <target state="translated">&lt;strong&gt;max_eval&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;每个优化步骤的最大函数评估数（默认值：max_iter * 1.25）。</target>
        </trans-unit>
        <trans-unit id="5b027542905604e3b228f1858a3f524982a5efab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_iter&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; maximal number of iterations per optimization step (default: 20)</source>
          <target state="translated">&lt;strong&gt;max_iter&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;每个优化步骤的最大迭代次数（默认值：20）</target>
        </trans-unit>
        <trans-unit id="1468666ae5d01433e87114e46f75596cf1556e35" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Upper learning rate boundaries in the cycle for each parameter group.</source>
          <target state="translated">&lt;strong&gt;max_lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;每个参数组在循环中的较高学习率边界。</target>
        </trans-unit>
        <trans-unit id="8ce86a6965b6720f122017897d60ca85346a4401" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Upper learning rate boundaries in the cycle for each parameter group. Functionally, it defines the cycle amplitude (max_lr - base_lr). The lr at any cycle is the sum of base_lr and some scaling of the amplitude; therefore max_lr may not actually be reached depending on scaling function.</source>
          <target state="translated">&lt;strong&gt;max_lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;每个参数组在循环中的较高学习率边界。从功能上讲，它定义了循环幅度（max_lr-base_lr）。任何周期的lr是base_lr与振幅的一定比例之和；因此，取决于缩放函数，可能实际上无法达到max_lr。</target>
        </trans-unit>
        <trans-unit id="377664c86626ff0059b1069c6f729fe1a4b4aa9e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_momentum&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Upper momentum boundaries in the cycle for each parameter group. Functionally, it defines the cycle amplitude (max_momentum - base_momentum). Note that momentum is cycled inversely to learning rate; at the start of a cycle, momentum is &amp;lsquo;max_momentum&amp;rsquo; and learning rate is &amp;lsquo;base_lr&amp;rsquo; Default: 0.95</source>
          <target state="translated">&lt;strong&gt;max_momentum&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;每个参数组在循环中的上动量边界。从功能上讲，它定义了循环幅度（max_momentum-base_momentum）。注意，动量与学习率成反比。在周期开始时，动量为&amp;ldquo; max_momentum&amp;rdquo;，学习率为&amp;ldquo; base_lr&amp;rdquo;默认值：0.95</target>
        </trans-unit>
        <trans-unit id="48deb872ed492bbcf29d1420a060c32f2d6bafb8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_momentum&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Upper momentum boundaries in the cycle for each parameter group. Functionally, it defines the cycle amplitude (max_momentum - base_momentum). The momentum at any cycle is the difference of max_momentum and some scaling of the amplitude; therefore base_momentum may not actually be reached depending on scaling function. Note that momentum is cycled inversely to learning rate; at the start of a cycle, momentum is &amp;lsquo;max_momentum&amp;rsquo; and learning rate is &amp;lsquo;base_lr&amp;rsquo; Default: 0.9</source>
          <target state="translated">&lt;strong&gt;max_momentum&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;每个参数组在循环中的上动量边界。从功能上讲，它定义了循环幅度（max_momentum-base_momentum）。任何周期的动量都是max_momentum与振幅的一定比例之差；因此，取决于缩放功能，实际上可能无法达到base_momentum。注意，动量与学习率成反比。在周期开始时，动量为&amp;ldquo; max_momentum&amp;rdquo;，学习速率为&amp;ldquo; base_lr&amp;rdquo;默认值：0.9</target>
        </trans-unit>
        <trans-unit id="18d2c9f69eba48f7e795f2b2a4286820cf804061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; max norm of the gradients</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;渐变的最大范数</target>
        </trans-unit>
        <trans-unit id="d4b953b25b1cba200ce3cd937a97f9f2c77d5eca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, each embedding vector with norm larger than &lt;code&gt;max_norm&lt;/code&gt; is renormalized to have norm &lt;code&gt;max_norm&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果给定， &lt;code&gt;max_norm&lt;/code&gt; 范数大于max_norm的每个嵌入向量重新规范化为norm &lt;code&gt;max_norm&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d7395b83c4b6884514e3400766844db4079e5559" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, each embedding vector with norm larger than &lt;code&gt;max_norm&lt;/code&gt; is renormalized to have norm &lt;code&gt;max_norm&lt;/code&gt;. Note: this will modify &lt;code&gt;weight&lt;/code&gt; in-place.</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;如果给定， &lt;code&gt;max_norm&lt;/code&gt; 范数大于max_norm的每个嵌入向量重新规范化为norm &lt;code&gt;max_norm&lt;/code&gt; 。注意：这将修改就地 &lt;code&gt;weight&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ccc83f5976a7da4c6cce23bdc0f1b550bc1baf18" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;请参阅模块初始化文档。</target>
        </trans-unit>
        <trans-unit id="616f5bd5271f84469f902e32daf9266f05355e51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;请参阅模块初始化文档。默认值： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f11300b5f0eb3648d7a253d285d8f366217f4085" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_queue&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Size of the queue for pending events and summaries before one of the &amp;lsquo;add&amp;rsquo; calls forces a flush to disk. Default is ten items.</source>
          <target state="translated">&lt;strong&gt;max_queue&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;在&amp;ldquo;添加&amp;rdquo;调用之一强制刷新到磁盘之前，未决事件和摘要的队列大小。默认值为十个项目。</target>
        </trans-unit>
        <trans-unit id="ac66a7d2aa72c2c8115cd465665fc5e11e447283" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_val&lt;/strong&gt; &amp;ndash; maximum value of the linear region range. Default: 1</source>
          <target state="translated">&lt;strong&gt;max_val&lt;/strong&gt; &amp;ndash;线性区域范围的最大值。默认值：1</target>
        </trans-unit>
        <trans-unit id="6600d2ace21bcb0602e70b0bbacf60b6d9d7c70c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;maxnorm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the maximum norm to keep each sub-tensor under</source>
          <target state="translated">&lt;strong&gt;maxnorm&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;保持每个子张量低于的最大范数</target>
        </trans-unit>
        <trans-unit id="5a295daf527fa3a8e842c0df2995c65b39e71553" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; &amp;ndash; the mean of the normal distribution</source>
          <target state="translated">&lt;strong&gt;均值&lt;/strong&gt;&amp;ndash;正态分布的均值</target>
        </trans-unit>
        <trans-unit id="a707f91e951faba9097d24d07d405e7ec311e6c6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor of per-element means</source>
          <target state="translated">&lt;strong&gt;均值&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;张量&lt;/a&gt;）&amp;ndash;每个元素均值的张量</target>
        </trans-unit>
        <trans-unit id="08c50d1f521b5ba09f6ffb7ce6539bb06a4a3f5b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the mean for all distributions</source>
          <target state="translated">&lt;strong&gt;平均值&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮点数&lt;/a&gt;）&amp;ndash;所有分布的平均值</target>
        </trans-unit>
        <trans-unit id="2955cca12dc9b4a6d69879869214d1c6770dfaaf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the mean for all distributions</source>
          <target state="translated">&lt;strong&gt;均值&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;所有分布的均值</target>
        </trans-unit>
        <trans-unit id="29ba1a569247c06dc81809a7bf872a0c7a96859b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory&lt;/strong&gt; &amp;ndash; the sequence from the last layer of the encoder (required).</source>
          <target state="translated">&lt;strong&gt;内存&lt;/strong&gt;&amp;ndash;从编码器的最后一层开始的顺序（必填）。</target>
        </trans-unit>
        <trans-unit id="588fc531f83b03eab1da4a2dc038d37bcca7f732" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_efficient&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;记忆效率&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="a683ca0a51a8aaad293fb3004568d17d8503ae0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_efficient&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; but slower. Default: &lt;em&gt;False&lt;/em&gt;. See &lt;a href=&quot;https://arxiv.org/pdf/1707.06990.pdf&quot;&gt;&amp;ldquo;paper&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;memory_efficient&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;但速度较慢。默认值：&lt;em&gt;False&lt;/em&gt;。见&lt;a href=&quot;https://arxiv.org/pdf/1707.06990.pdf&quot;&gt;&amp;ldquo;纸&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="847323568a90086efa211de3ba9bf7786ee86423" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的Tensor所需的内存格式。默认值： &lt;code&gt;torch.contiguous_format&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="60c76323a555a35cf5636b2f519a421ab878338e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的Tensor所需的内存格式。默认值： &lt;code&gt;torch.preserve_format&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c42c5648937cafb3804b61b720f4bb1140320b64" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的张量所需的内存格式。默认值： &lt;code&gt;torch.preserve_format&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="cb50e6c46386db61725174c03fb49b8c28339fd5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; Specifies memory allocation order. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;指定内存分配顺序。默认值： &lt;code&gt;torch.contiguous_format&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5d82e413d97971822435897c587b2c7a54d9ab8b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;. Note that memory format of &lt;code&gt;self&lt;/code&gt; is going to be unaffected if &lt;code&gt;self.size()&lt;/code&gt; matches &lt;code&gt;sizes&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash; Tensor所需的内存格式。默认值： &lt;code&gt;torch.contiguous_format&lt;/code&gt; 。需要注意的是内存格式 &lt;code&gt;self&lt;/code&gt; 会不会受到影响，如果 &lt;code&gt;self.size()&lt;/code&gt; 相匹配 &lt;code&gt;sizes&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bce750b8912dc23c58101b3c62c2faebe272c06d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;. Note that memory format of &lt;code&gt;self&lt;/code&gt; is going to be unaffected if &lt;code&gt;self.size()&lt;/code&gt; matches &lt;code&gt;tensor.size()&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash; Tensor所需的内存格式。默认值： &lt;code&gt;torch.contiguous_format&lt;/code&gt; 。请注意，如果 &lt;code&gt;self.size()&lt;/code&gt; 与 &lt;code&gt;tensor.size()&lt;/code&gt; 匹配，则 &lt;code&gt;self&lt;/code&gt; 的内存格式将不受影响。</target>
        </trans-unit>
        <trans-unit id="c209a0208ea88f4d30020b7c6ec0aa20f55f05ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的Tensor所需的内存格式。默认值： &lt;code&gt;torch.contiguous_format&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e31755556d7e8f828a7fc59bf5245af37dfc95a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;，可选）&amp;ndash;返回的Tensor所需的内存格式。默认值： &lt;code&gt;torch.preserve_format&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="287794474bd0369fafef4c83cd018633d29d34b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;code&gt;torch.memory_format&lt;/code&gt;) &amp;ndash; the desired memory format for 4D parameters and buffers in this module (keyword only argument)</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt;（ &lt;code&gt;torch.memory_format&lt;/code&gt; ）&amp;ndash;此模块中4D参数和缓冲区的所需内存格式（仅关键字参数）</target>
        </trans-unit>
        <trans-unit id="a5a2da6780e7a50206f83afa209cf1daa2cf9b20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for memory keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash;每批存储密钥的ByteTensor掩码（可选）。</target>
        </trans-unit>
        <trans-unit id="ad4fdd31c064f05525f133141ae55c8a9f9fb730" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the memory keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash;每批内存密钥的掩码（可选）。</target>
        </trans-unit>
        <trans-unit id="915d393bbda00e2dfc80c100ff44fe1a257646ed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash; the additive mask for the encoder output (optional).</source>
          <target state="translated">&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash;编码器输出的附加掩码（可选）。</target>
        </trans-unit>
        <trans-unit id="edbbc733c4baf5f4bca52c77bb7dfb7d5e94c518" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash; the mask for the memory sequence (optional).</source>
          <target state="translated">&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash;内存序列的掩码（可选）。</target>
        </trans-unit>
        <trans-unit id="420038f9d23e71250d8fc76d6db641779f55d944" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;metadata&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; A list of labels, each element will be convert to string</source>
          <target state="translated">&lt;strong&gt;元数据&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;列表&lt;/a&gt;）&amp;ndash;标签列表，每个元素都将转换为字符串</target>
        </trans-unit>
        <trans-unit id="fbe6c83a85e6ac8b011f0e187353dedf1dd97a86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; select LOBPCG method. See the description of the function above. Default is &amp;ldquo;ortho&amp;rdquo;.</source>
          <target state="translated">&lt;strong&gt;method&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;选择LOBPCG方法。请参阅上面的功能说明。默认为&amp;ldquo;正交&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="d982ed54ceb117939247c462414b383f4294a298" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;method&lt;/strong&gt; (&lt;em&gt;subclass of BasePruningMethod&lt;/em&gt;) &amp;ndash; child pruning method to be added to the container.</source>
          <target state="translated">&lt;strong&gt;method&lt;/strong&gt;（&lt;em&gt;BasePruningMethod的子类&lt;/em&gt;）&amp;ndash;要添加到容器的子修剪方法。</target>
        </trans-unit>
        <trans-unit id="ffaae191023c8ad384bc60a006a096527ebb2fe7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;metric_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Each key-value pair in the dictionary is the name of the metric and it&amp;rsquo;s corresponding value. Note that the key used here should be unique in the tensorboard record. Otherwise the value you added by &lt;code&gt;add_scalar&lt;/code&gt; will be displayed in hparam plugin. In most cases, this is unwanted.</source>
          <target state="translated">&lt;strong&gt;metric_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;字典中的每个键值对都是指标的名称及其对应的值。请注意，此处使用的密钥在张量板记录中应该是唯一的。否则，由 &lt;code&gt;add_scalar&lt;/code&gt; 添加的值将显示在hparam插件中。在大多数情况下，这是不需要的。</target>
        </trans-unit>
        <trans-unit id="cde916a1fef1faecfaf91715c84b2290e3f3776e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;milestones&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; List of epoch indices. Must be increasing.</source>
          <target state="translated">&lt;strong&gt;里程碑&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;列表&lt;/a&gt;）&amp;ndash;时期索引列表。必须增加。</target>
        </trans-unit>
        <trans-unit id="6dd8004576bc7350c9204a1c0262ab2ddb2d227d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; lower end of the range (inclusive)</source>
          <target state="translated">&lt;strong&gt;min&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;范围的下限（包括）</target>
        </trans-unit>
        <trans-unit id="cef73dc49333eeeba5dd9f4d0c270dee0f730953" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; lower-bound of the range to be clamped to</source>
          <target state="translated">&lt;strong&gt;min&lt;/strong&gt;（&lt;em&gt;Number&lt;/em&gt;）&amp;ndash;要限制的范围的下限</target>
        </trans-unit>
        <trans-unit id="55821f56c0bcd501a5ab8f1798c3910d8b63ffff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; minimal value of each element in the output</source>
          <target state="translated">&lt;strong&gt;min&lt;/strong&gt;（&lt;em&gt;Number&lt;/em&gt;）&amp;ndash;输出中每个元素的最小值</target>
        </trans-unit>
        <trans-unit id="b55691eca82df0da0cd97dd8e15fa3fb8bfbaf8a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min_lr&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; A scalar or a list of scalars. A lower bound on the learning rate of all param groups or each group respectively. Default: 0.</source>
          <target state="translated">&lt;strong&gt;min_lr&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;或&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;标量或标量列表。所有参数组或每个组的学习率的下限。默认值：0</target>
        </trans-unit>
        <trans-unit id="894532a159ed88aec99c8849664d2c1374ab2e44" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min_val&lt;/strong&gt; &amp;ndash; minimum value of the linear region range. Default: -1</source>
          <target state="translated">&lt;strong&gt;min_val&lt;/strong&gt; &amp;ndash;线性区域范围的最小值。默认值：-1</target>
        </trans-unit>
        <trans-unit id="a625bfe7a46218038f5b0ece187b38a8f18c7b30" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;minlength&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; optional, minimum number of bins. Should be non-negative.</source>
          <target state="translated">&lt;strong&gt;minlength&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;可选，最小箱数。应该是非负的。</target>
        </trans-unit>
        <trans-unit id="d62614dd84cb7f7218048107638c24812180feed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;missing_keys&lt;/strong&gt; is a list of str containing the missing keys</source>
          <target state="translated">&lt;strong&gt;missing_keys&lt;/strong&gt;是包含缺失键的str列表</target>
        </trans-unit>
        <trans-unit id="3a1dfa06520b080421ea46aff220b9d8cba6e0f5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mixture_distribution&lt;/strong&gt; &amp;ndash; &lt;code&gt;torch.distributions.Categorical&lt;/code&gt;-like instance. Manages the probability of selecting component. The number of categories must match the rightmost batch dimension of the &lt;code&gt;component_distribution&lt;/code&gt;. Must have either scalar &lt;code&gt;batch_shape&lt;/code&gt; or &lt;code&gt;batch_shape&lt;/code&gt; matching &lt;code&gt;component_distribution.batch_shape[:-1]&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;blend_distribution&lt;/strong&gt; &amp;ndash; &lt;code&gt;torch.distributions.Categorical&lt;/code&gt; 的实例。管理选择组件的可能性。类别数必须匹配 &lt;code&gt;component_distribution&lt;/code&gt; 的最右边的批次维。必须具有标量 &lt;code&gt;batch_shape&lt;/code&gt; 或 &lt;code&gt;batch_shape&lt;/code&gt; 匹配 &lt;code&gt;component_distribution.batch_shape[:-1]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f2dfaac7466031cf7ac17e86ad10d9de9e7ba1a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mod&lt;/strong&gt; &amp;ndash; input module</source>
          <target state="translated">&lt;strong&gt;mod&lt;/strong&gt; &amp;ndash;输入模块</target>
        </trans-unit>
        <trans-unit id="311fd585d83045aa88cc3eccbed4762dcd351324" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mod&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; a float module, either produced by torch.quantization utilities or provided by the user</source>
          <target state="translated">&lt;strong&gt;mod&lt;/strong&gt;（&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;）&amp;ndash;浮点模块，由Torch.quantization实用程序生成或由用户提供</target>
        </trans-unit>
        <trans-unit id="84a7cd86ad210aba9a85651fe50b04b508106e2f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mod&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; A &lt;code&gt;torch.nn.Module&lt;/code&gt; containing methods whose names are specified in &lt;code&gt;inputs&lt;/code&gt;. The given methods will be compiled as a part of a single &lt;code&gt;ScriptModule&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;mod&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;）&amp;ndash;一个 &lt;code&gt;torch.nn.Module&lt;/code&gt; 其中包含名称在 &lt;code&gt;inputs&lt;/code&gt; 中指定的方法。给定的方法将被编译为单个 &lt;code&gt;ScriptModule&lt;/code&gt; 的一部分。</target>
        </trans-unit>
        <trans-unit id="f3ad16e3543c64bbf2963c9325a83ed0fc537280" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; &amp;ndash; &lt;code&gt;'constant'&lt;/code&gt;, &lt;code&gt;'reflect'&lt;/code&gt;, &lt;code&gt;'replicate'&lt;/code&gt; or &lt;code&gt;'circular'&lt;/code&gt;. Default: &lt;code&gt;'constant'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;- &lt;code&gt;'constant'&lt;/code&gt; ， &lt;code&gt;'reflect'&lt;/code&gt; ， &lt;code&gt;'replicate'&lt;/code&gt; 或 &lt;code&gt;'circular'&lt;/code&gt; 。默认值： &lt;code&gt;'constant'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3ead1532b9e3bb8d41618811a33c97bd27a1a40b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; &amp;ndash; either &lt;code&gt;'fan_in'&lt;/code&gt; (default) or &lt;code&gt;'fan_out'&lt;/code&gt;. Choosing &lt;code&gt;'fan_in'&lt;/code&gt; preserves the magnitude of the variance of the weights in the forward pass. Choosing &lt;code&gt;'fan_out'&lt;/code&gt; preserves the magnitudes in the backwards pass.</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;&amp;ndash; &lt;code&gt;'fan_in'&lt;/code&gt; （默认）或 &lt;code&gt;'fan_out'&lt;/code&gt; 。选择 &lt;code&gt;'fan_in'&lt;/code&gt; 保留前向通过中权重方差的大小。选择 &lt;code&gt;'fan_out'&lt;/code&gt; 保留反向传递的幅度。</target>
        </trans-unit>
        <trans-unit id="de67441ea808eb9718fb3c1203b927e8646bf7b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Controls whether to enable flush denormal mode or not</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;控制是否启用冲洗非正常模式</target>
        </trans-unit>
        <trans-unit id="5954b2cd8044ad215ccb68f0b03903d436f396bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag whether to enable anomaly detection (&lt;code&gt;True&lt;/code&gt;), or disable (&lt;code&gt;False&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;标记是启用异常检测（ &lt;code&gt;True&lt;/code&gt; ），还是禁用（ &lt;code&gt;False&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="5f0ebb80a4f6d234b3bdc8d88adb240b1631fa72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag whether to enable grad (&lt;code&gt;True&lt;/code&gt;), or disable (&lt;code&gt;False&lt;/code&gt;). This can be used to conditionally enable gradients.</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;标记是启用grad（ &lt;code&gt;True&lt;/code&gt; ）还是禁用（ &lt;code&gt;False&lt;/code&gt; ）。这可用于有条件地启用渐变。</target>
        </trans-unit>
        <trans-unit id="c77c2993453675a1ae62a895e8af92b271ac8912" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to set training mode (&lt;code&gt;True&lt;/code&gt;) or evaluation mode (&lt;code&gt;False&lt;/code&gt;). Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;设置训练模式（ &lt;code&gt;True&lt;/code&gt; ）还是评估模式（ &lt;code&gt;False&lt;/code&gt; ）。默认值： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1c363213dc9407a65b9c8b56a57a7e4b83827d58" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; One of &lt;code&gt;min&lt;/code&gt;, &lt;code&gt;max&lt;/code&gt;. In &lt;code&gt;min&lt;/code&gt; mode, lr will be reduced when the quantity monitored has stopped decreasing; in &lt;code&gt;max&lt;/code&gt; mode it will be reduced when the quantity monitored has stopped increasing. Default: &amp;lsquo;min&amp;rsquo;.</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash; &lt;code&gt;min&lt;/code&gt; ， &lt;code&gt;max&lt;/code&gt; 。在 &lt;code&gt;min&lt;/code&gt; 模式下，当监视的数量停止减少时，lr将减小；在 &lt;code&gt;max&lt;/code&gt; 模式下，当监视的数量停止增加时，它将减少。默认值：&amp;ldquo; min&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="5e56f1e33b487200e30b2336e22da3a0101453c5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; One of {triangular, triangular2, exp_range}. Values correspond to policies detailed above. If scale_fn is not None, this argument is ignored. Default: &amp;lsquo;triangular&amp;rsquo;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash; {triangle，trialang2，exp_range}中的一种。值与上面详述的策略相对应。如果scale_fn不为None，则忽略此参数。默认值：&amp;ldquo;三角形&amp;rdquo;</target>
        </trans-unit>
        <trans-unit id="d7c74d3b555f009043988d195fb2bcd2f8149f0e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;用于上采样的算法： &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f9c27d3e94ffaa56b5363537c49d87d1a211071d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt; | &lt;code&gt;'area'&lt;/code&gt;. Default: &lt;code&gt;'nearest'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;用于上采样的算法： &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt; | &lt;code&gt;'area'&lt;/code&gt; 。默认值： &lt;code&gt;'nearest'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="385c5b4f0ae5e9736769d454130ca5949542ab90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; interpolation mode to calculate output values &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'nearest'&lt;/code&gt;. Default: &lt;code&gt;'bilinear'&lt;/code&gt; Note: When &lt;code&gt;mode='bilinear'&lt;/code&gt; and the input is 5-D, the interpolation mode used internally will actually be trilinear. However, when the input is 4-D, the interpolation mode will legitimately be bilinear.</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;插值模式，用于计算 &lt;code&gt;'bilinear'&lt;/code&gt; 输出值| | | | | | | | | | | | | | | | | | | &lt;code&gt;'nearest'&lt;/code&gt; 。默认值： &lt;code&gt;'bilinear'&lt;/code&gt; 注：当 &lt;code&gt;mode='bilinear'&lt;/code&gt; 且输入为5-D时，内部使用的插值模式实际上将是三线性的。但是，当输入为4-D时，插值模式将合法地是双线性的。</target>
        </trans-unit>
        <trans-unit id="4471a06de253ea298b84fb5695bcc2a35de32568" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the upsampling algorithm: one of &lt;code&gt;'nearest'&lt;/code&gt;, &lt;code&gt;'linear'&lt;/code&gt;, &lt;code&gt;'bilinear'&lt;/code&gt;, &lt;code&gt;'bicubic'&lt;/code&gt; and &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;'nearest'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;上采样算法： &lt;code&gt;'nearest'&lt;/code&gt; ， &lt;code&gt;'linear'&lt;/code&gt; ， &lt;code&gt;'bilinear'&lt;/code&gt; ， &lt;code&gt;'bicubic'&lt;/code&gt; 和 &lt;code&gt;'trilinear'&lt;/code&gt; 。默认值： &lt;code&gt;'nearest'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e579f4ae9e49fbfc6b51a7253cb4e53b5007b03e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;用于上采样的算法： &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0454ac8b9a020a3d1a98ccef37fc6aef70ca1aae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;'nearest'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;用于上采样的算法： &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt; 。默认值： &lt;code&gt;'nearest'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ac9a2bfc1170980964589f394256a29c3c8507f9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt;, &lt;code&gt;&quot;mean&quot;&lt;/code&gt; or &lt;code&gt;&quot;max&quot;&lt;/code&gt;. Specifies the way to reduce the bag. &lt;code&gt;&quot;sum&quot;&lt;/code&gt; computes the weighted sum, taking &lt;code&gt;per_sample_weights&lt;/code&gt; into consideration. &lt;code&gt;&quot;mean&quot;&lt;/code&gt; computes the average of the values in the bag, &lt;code&gt;&quot;max&quot;&lt;/code&gt; computes the max value over each bag. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt; ， &lt;code&gt;&quot;mean&quot;&lt;/code&gt; 或 &lt;code&gt;&quot;max&quot;&lt;/code&gt; 。指定减少袋子的方式。 &lt;code&gt;&quot;sum&quot;&lt;/code&gt; 计算加权总和，同时考虑到 &lt;code&gt;per_sample_weights&lt;/code&gt; 。 &lt;code&gt;&quot;mean&quot;&lt;/code&gt; 计算出袋子中值的平均值， &lt;code&gt;&quot;max&quot;&lt;/code&gt; 计算出每个袋子中的最大值。默认值： &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c098c83728e1a75267ad9d800f600477ae405fc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt;, &lt;code&gt;&quot;mean&quot;&lt;/code&gt; or &lt;code&gt;&quot;max&quot;&lt;/code&gt;. Specifies the way to reduce the bag. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt; ， &lt;code&gt;&quot;mean&quot;&lt;/code&gt; 或 &lt;code&gt;&quot;max&quot;&lt;/code&gt; 。指定减少袋子的方式。默认值： &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="83cf0f99fac2d6532263c56e5750c95e9d23633d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;模式&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;请参阅模块初始化文档。默认值： &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9774346c37a84f31aa240cbbfdfce4fadf6d9d11" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; &amp;ndash; Model containing the modules to be fused</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;&amp;ndash;包含要融合的模块的模型</target>
        </trans-unit>
        <trans-unit id="29b2c437e7636535db29713e4220f5fd433d8cb9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; &amp;ndash; input float model</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;&amp;ndash;输入浮点模型</target>
        </trans-unit>
        <trans-unit id="db0e889d7e53c74b060a05b4d68552e00a301946" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; &amp;ndash; input model</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;&amp;ndash;输入模型</target>
        </trans-unit>
        <trans-unit id="c7201a6681f7e3b18a60413f391b0568bbce7574" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; &amp;ndash; input model to be modified in-place</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;&amp;ndash;输入模型要就地修改</target>
        </trans-unit>
        <trans-unit id="cce56abc7cd237dbad132a5abb856634ed2030b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; Model to draw.</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;（&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;）&amp;ndash;绘制模型。</target>
        </trans-unit>
        <trans-unit id="c7f141d3875fe7470c5eeb6311e3f52659403c7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; the model to be exported.</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;（&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;）&amp;ndash;要导出的模型。</target>
        </trans-unit>
        <trans-unit id="5f38a617ca9f3ce30bb1aa507b57c0f8b9bb5233" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; a string of entrypoint name defined in repo&amp;rsquo;s hubconf.py</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;在仓库中的hubconf.py中定义的入口点名称字符串</target>
        </trans-unit>
        <trans-unit id="522ae153c9de2225d354ad39a76bc7201f1315a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; the name of a callable (entrypoint) defined in the repo/dir&amp;rsquo;s &lt;code&gt;hubconf.py&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;模型&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;在存储库/目录的 &lt;code&gt;hubconf.py&lt;/code&gt; 中定义的可调用（入口点）的名称。</target>
        </trans-unit>
        <trans-unit id="047b6c0ef907781caf5f3b90b83833193ffbb540" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model_dir&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; directory in which to save the object</source>
          <target state="translated">&lt;strong&gt;model_dir&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;保存对象的目录</target>
        </trans-unit>
        <trans-unit id="26db7d624e519d251822dbc050f229070d6875cc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; &amp;ndash; input module</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;&amp;ndash;输入模块</target>
        </trans-unit>
        <trans-unit id="69051b940b13590bcf82fdf23556640963ae7ded" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; &amp;ndash; input module with qconfig attributes for all the leaf modules</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;&amp;ndash;具有所有叶模块的qconfig属性的输入模块</target>
        </trans-unit>
        <trans-unit id="337535b0d4923600e1e36494036f6ec5fbd41fed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; &amp;ndash; input module with qconfig attributes for all the leaf modules that we want to quantize</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; &amp;ndash;具有qconfig属性的输入模块，用于我们要量化的所有叶子模块</target>
        </trans-unit>
        <trans-unit id="ff92bd1f8822db4dee990724fb95f189b28d6861" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; child module to be added to the module.</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt;（&lt;a href=&quot;#torch.nn.Module&quot;&gt;Module&lt;/a&gt;）&amp;ndash;要添加到该模块的子模块。</target>
        </trans-unit>
        <trans-unit id="4911eeef12d8491f308531700e789704028a53b0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; the module to evaluate in parallel</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;）&amp;ndash;并行评估的模块</target>
        </trans-unit>
        <trans-unit id="c599015a8c55f21c464f35319477082682454deb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; child module to be added to the module.</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;）&amp;ndash;要添加到该模块的子模块。</target>
        </trans-unit>
        <trans-unit id="13729f6038be326761df6ac3ec24b201e785b71f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; containing module</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;）&amp;ndash;包含模块</target>
        </trans-unit>
        <trans-unit id="f81af303cce1d2b13d56b554d4c54084215c693d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; module to be parallelized</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;）&amp;ndash;要并行化的模块</target>
        </trans-unit>
        <trans-unit id="af97e1697d5f0c0f0186596bfc816ba5d1b7233e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; containing module</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;）&amp;ndash;包含模块</target>
        </trans-unit>
        <trans-unit id="ca220270bc403ee33276152d6bc7a361e3f02584" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module containing one or more attr:&lt;code&gt;BatchNorm*D&lt;/code&gt; layers</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;）&amp;ndash;包含一个或多个attr的模块： &lt;code&gt;BatchNorm*D&lt;/code&gt; 层</target>
        </trans-unit>
        <trans-unit id="4aa37d25cda1e46d9840e5ce1e3bb87b97cabc4c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module containing the tensor to prune</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;）&amp;ndash;包含要修剪的张量的模块</target>
        </trans-unit>
        <trans-unit id="c58562dc7c80d28ea1d3eb37836c8dd81358feb4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module to append</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;）&amp;ndash;要附加的模块</target>
        </trans-unit>
        <trans-unit id="49d181f6c9a5ed2484bd66e1605a7cd8ed49448c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module to insert</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;）&amp;ndash;要插入的模块</target>
        </trans-unit>
        <trans-unit id="60a1ae701ce0942d303d74786dea8b40965fbefe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; object that is either pruned or unpruned</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;）&amp;ndash;已修剪或未修剪的对象</target>
        </trans-unit>
        <trans-unit id="b1cf5810a0ac4510111b7830d78e712ab1696f2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; a mapping (dictionary) from string to &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt;, or an iterable of key-value pairs of type (string, &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt;)</source>
          <target state="translated">&lt;strong&gt;modules&lt;/strong&gt;（&lt;em&gt;iterable&lt;/em&gt;）&amp;ndash;字符串到&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;的映射（字典），或者类型（string，&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;）的键值对的可迭代</target>
        </trans-unit>
        <trans-unit id="36d886b50a323b839fe922cbffadfc70109408b5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; iterable of modules to append</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;em&gt;可迭代&lt;/em&gt;）&amp;ndash;可添加模块的可迭代</target>
        </trans-unit>
        <trans-unit id="f8c11c9ebc42a4e244f2c526e48d9476468d0936" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a mapping (dictionary) of (string: module) or an iterable of key-value pairs of type (string, module)</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;em&gt;iterable &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;（字符串：模块）的映射（字典）或类型（字符串，模块）的键值对的可迭代</target>
        </trans-unit>
        <trans-unit id="82d83ba7e9a63e6fb88f202a85d0e2b54d0d5137" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; an iterable of modules to add</source>
          <target state="translated">&lt;strong&gt;模块&lt;/strong&gt;（&lt;em&gt;可迭代&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;可迭代的模块</target>
        </trans-unit>
        <trans-unit id="04bab62073b3560de718947a04af8b4f3a39a01e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules_to_fuse&lt;/strong&gt; &amp;ndash; list of list of module names to fuse. Can also be a list of strings if there is only a single list of modules to fuse.</source>
          <target state="translated">&lt;strong&gt;modules_to_fuse&lt;/strong&gt; &amp;ndash;要融合的模块名称列表。如果只有一个要融合的模块列表，则也可以是字符串列表。</target>
        </trans-unit>
        <trans-unit id="338d2bdd3427c2acd5798eb121524c531792b37a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;momentum&lt;/strong&gt; &amp;ndash; the value used for the running_mean and running_var computation. Can be set to &lt;code&gt;None&lt;/code&gt; for cumulative moving average (i.e. simple average). Default: 0.1</source>
          <target state="translated">&lt;strong&gt;动量&lt;/strong&gt;&amp;ndash;用于running_mean和running_var计算的值。对于累积移动平均线（即简单平均线），可以设置为&amp;ldquo; &lt;code&gt;None&lt;/code&gt; &amp;rdquo;。默认值：0.1</target>
        </trans-unit>
        <trans-unit id="2f0648d0e331c6484261bc1cae891f8cb0fe0f77" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;momentum&lt;/strong&gt; &amp;ndash; the value used for the running_mean and running_var computation. Default: 0.1</source>
          <target state="translated">&lt;strong&gt;动量&lt;/strong&gt;&amp;ndash;用于running_mean和running_var计算的值。默认值：0.1</target>
        </trans-unit>
        <trans-unit id="c19c4601cb6ff68b31939379514e144918decc6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;momentum&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; momentum factor (default: 0)</source>
          <target state="translated">&lt;strong&gt;动量&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;动量因子（默认值：0）</target>
        </trans-unit>
        <trans-unit id="f8ec4544b5e2bda9b818610177f75772c12c28c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;most and may help with size-specific optimizations or&lt;/strong&gt; (&lt;em&gt;the&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;大多数并可以与专用于特定尺寸的优化，或者帮助&lt;/strong&gt;（&lt;em&gt;中&lt;/em&gt;） -</target>
        </trans-unit>
        <trans-unit id="70b75af3861208c958c212d2f7e306b0528d2927" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;msg&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; ASCII message to associate with range</source>
          <target state="translated">&lt;strong&gt;msg&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;与范围关联的ASCII消息</target>
        </trans-unit>
        <trans-unit id="477e9d05b66b55fc3c54bb2c97211fbf7a30ec4d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;msg&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; ASCII message to associate with the event.</source>
          <target state="translated">&lt;strong&gt;msg&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;与事件关联的ASCII消息。</target>
        </trans-unit>
        <trans-unit id="2ffcdc1e2419287f46a2eda06597a5711ebd39cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of rows</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;行数</target>
        </trans-unit>
        <trans-unit id="a3afc73d777f69bfccc910de139a6b9b0a792a61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the order of the polygamma function</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;多重伽玛函数的阶数</target>
        </trans-unit>
        <trans-unit id="8d0ffe3929c3dd260792f2cfcd25cf94c93f071d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the power to raise the matrix to</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;将矩阵提高到的幂</target>
        </trans-unit>
        <trans-unit id="bb3a47c4c5e60d1d87f9833a363f367729f6f4f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the upper bound (exclusive)</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;上限（不包括）</target>
        </trans-unit>
        <trans-unit id="62cd9cb1469a9c478de28e4b1f09e1a6c903f1e0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt;) &amp;ndash; See documentation of valid entries for argument &lt;code&gt;p&lt;/code&gt; in &lt;a href=&quot;torch.norm#torch.norm&quot;&gt;&lt;code&gt;torch.norm()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;&amp;Ntilde;&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;浮子&lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;INF &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;-INF &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;'回回' &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;'NUC' &lt;/em&gt;）-对参数的有效条目的文档见 &lt;code&gt;p&lt;/code&gt; 在&lt;a href=&quot;torch.norm#torch.norm&quot;&gt; &lt;code&gt;torch.norm()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="360665e64fcf6fd508a3beb2effb1f77d9cc3d75" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Output signal length. This determines the length of the output signal. If given, the input will either be zero-padded or trimmed to this length before computing the real IFFT. Defaults to even output: &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输出信号长度。这决定了输出信号的长度。如果给定，则在计算实际IFFT之前，将对输入进行零填充或修整至该长度。默认为偶数输出： &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3f3dcf24d971f3f927b31f57cb8d0f3aa39957de" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Output signal length. This determines the length of the real output. If given, the input will either be zero-padded or trimmed to this length before computing the Hermitian FFT. Defaults to even output: &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;输出信号长度。这确定了实际输出的长度。如果给定，则在计算Hermitian FFT之前，将对输入进行零填充或修整至此长度。默认为偶数输出： &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="765bbbc030c273dcfddf61dec277dea877826f3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the FFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;信号长度。如果给定，则在计算FFT之前，将对输入进行零填充或修整到该长度。</target>
        </trans-unit>
        <trans-unit id="280814a17cd4d7c5c87be0ac03bb06c0096d600b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the Hermitian IFFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;信号长度。如果给定，则在计算Hermitian IFFT之前，将对输入进行零填充或修整至此长度。</target>
        </trans-unit>
        <trans-unit id="19a143bdd240b89803874ef31fae83cbc10ad3d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the IFFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;信号长度。如果给定，则在计算IFFT之前，将对输入进行零填充或修整至该长度。</target>
        </trans-unit>
        <trans-unit id="437d2ca26e7ac533d4bd5f39effee7652ff0b3a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the real FFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;信号长度。如果提供给定值，则在计算实际FFT之前，将对输入进行零填充或修整至该长度。</target>
        </trans-unit>
        <trans-unit id="8742179ec0bc2a9eaec8d9e4144c1b9a9f8cd29e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;) &amp;ndash; The number of steps to fast-forward by.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;em&gt;Int&lt;/em&gt;）&amp;ndash;快进的步数。</target>
        </trans-unit>
        <trans-unit id="0a8c721a95c8d2c05e104145a151d6fead527c01" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The length of sequence of points to draw. Default: 1</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;em&gt;Int &lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;要绘制的点序列的长度。默认值：1</target>
        </trans-unit>
        <trans-unit id="86e79b2a07cba2a326622f21aedf96b60e044c1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;em&gt;integer&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt;（&lt;em&gt;整数&lt;/em&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;如果</target>
        </trans-unit>
        <trans-unit id="9509b9869a54b18b43d0ef80248e150060481aa5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of classes in the dataset</source>
          <target state="translated">&lt;strong&gt;n_classes&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;数据集中的类数</target>
        </trans-unit>
        <trans-unit id="664468f137b786aae9b4053649115d89d17971a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_fft&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Size of Fourier transform</source>
          <target state="translated">&lt;strong&gt;n_fft&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;傅立叶变换的大小</target>
        </trans-unit>
        <trans-unit id="64c539b9a2fc08964cebb89aafe82cd323a6d67b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_fft&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; size of Fourier transform</source>
          <target state="translated">&lt;strong&gt;n_fft&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;傅立叶变换的大小</target>
        </trans-unit>
        <trans-unit id="73f1e40726186373d5acaec57f94cdeb84386c79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_power_iterations&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; number of power iterations to calculate spectral norm</source>
          <target state="translated">&lt;strong&gt;n_power_iterations&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;计算频谱范数的功率迭代次数</target>
        </trans-unit>
        <trans-unit id="c72673dc830afffed194953be854bb3754726c42" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name, input shapes) rather than just event name.&lt;/strong&gt; (&lt;em&gt;(&lt;/em&gt;&lt;em&gt;event&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;名称，输入形状），而不仅仅是事件名称。&lt;/strong&gt;（&lt;em&gt;（&lt;/em&gt;&lt;em&gt;事件&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="be6a1d5fe41bddbb64767aa43f1844148b7a2d5d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; &amp;ndash; The name of the extension to build. This MUST be the same as the name of the pybind11 module!</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; &amp;ndash;要构建的扩展名。该名称必须与pybind11模块的名称相同！</target>
        </trans-unit>
        <trans-unit id="8c69de6701f67b2c147cd64b9cd2a3b47551823b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; a globally unique name of this node. (e.g., &lt;code&gt;Trainer3&lt;/code&gt;, &lt;code&gt;ParameterServer2&lt;/code&gt;, &lt;code&gt;Master&lt;/code&gt;, &lt;code&gt;Worker1&lt;/code&gt;) Name can only contain number, alphabet, underscore, colon, and/or dash, and must be shorter than 128 characters.</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;此节点的全局唯一名称。（例如 &lt;code&gt;Trainer3&lt;/code&gt; ， &lt;code&gt;ParameterServer2&lt;/code&gt; ， &lt;code&gt;Master&lt;/code&gt; ， &lt;code&gt;Worker1&lt;/code&gt; ）名称只能包含数字，字母，下划线，冒号和/或破折号，并且必须少于128个字符。</target>
        </trans-unit>
        <trans-unit id="5183afed8cf3601b43896332cb5eec33dea53c97" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; parameter name within &lt;code&gt;module&lt;/code&gt; on which pruning will act.</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;将在其上执行修剪的 &lt;code&gt;module&lt;/code&gt; 内的参数名称。</target>
        </trans-unit>
        <trans-unit id="cd742c4f6eedba1b2162f8cb069fd19852c81f0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; name of weight parameter</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;重量参数的名称</target>
        </trans-unit>
        <trans-unit id="34a6862e100f7bbd8be83c2e2456ade36746f257" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; name of the buffer. The buffer can be accessed from this module using the given name</source>
          <target state="translated">&lt;strong&gt;名称&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;缓冲区的名称。可以使用给定名称从此模块访问缓冲区</target>
        </trans-unit>
        <trans-unit id="0a86d2efe3016120aa2e1ea06fc78fd6bcd8369d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; name of the child module. The child module can be accessed from this module using the given name</source>
          <target state="translated">&lt;strong&gt;名称&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;子模块的名称。可以使用给定名称从该模块访问子模块</target>
        </trans-unit>
        <trans-unit id="369152d10b48dccc5d7997cedd438126e9bd2abc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; name of the parameter. The parameter can be accessed from this module using the given name</source>
          <target state="translated">&lt;strong&gt;名称&lt;/strong&gt;（&lt;em&gt;字符串&lt;/em&gt;）&amp;ndash;参数的名称。可以使用给定名称从此模块访问参数</target>
        </trans-unit>
        <trans-unit id="c67b5abf72fae7d381fa3b1d37bcbc664d754902" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;names&lt;/strong&gt; (&lt;em&gt;iterable of str&lt;/em&gt;) &amp;ndash; The desired dimension ordering of the output tensor. May contain up to one Ellipsis that is expanded to all unmentioned dim names of &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;名称&lt;/strong&gt;（&lt;em&gt;str的可迭代&lt;/em&gt;）&amp;ndash;输出张量的所需尺寸顺序。最多可以包含一个省略号，该省略号扩展为所有未提及的 &lt;code&gt;self&lt;/code&gt; 暗淡名称。</target>
        </trans-unit>
        <trans-unit id="18ba741fd674f07602eeb307e77e22ffd8697dcb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;names&lt;/strong&gt; (&lt;em&gt;iterable of str&lt;/em&gt;) &amp;ndash; The desired names of the output tensor. May contain up to one Ellipsis.</source>
          <target state="translated">&lt;strong&gt;名称&lt;/strong&gt;（&lt;em&gt;str的可迭代&lt;/em&gt;）&amp;ndash;输出张量的所需名称。最多可以包含一个省略号。</target>
        </trans-unit>
        <trans-unit id="3dcce6a007ca6ff3a948d0e46c57a9b25d051833" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;need_weights&lt;/strong&gt; &amp;ndash; output attn_output_weights.</source>
          <target state="translated">&lt;strong&gt;need_weights&lt;/strong&gt; &amp;ndash;输出attn_output_weights。</target>
        </trans-unit>
        <trans-unit id="343ed070ed3d41cc4c3ee63a9a133db9d809bff0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;negative_slope&lt;/strong&gt; &amp;ndash; Controls the angle of the negative slope. Default: 1e-2</source>
          <target state="translated">&lt;strong&gt;negative_slope&lt;/strong&gt; &amp;ndash;控制负斜率的角度。默认值：1e-2</target>
        </trans-unit>
        <trans-unit id="f8e8bb0627658c20cc0c4866f6e07da9cc54f0c6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nesterov&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; enables Nesterov momentum (default: False)</source>
          <target state="translated">&lt;strong&gt;nesterov&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;可选&lt;/em&gt;）&amp;ndash;启用Nesterov动量（默认值：False）</target>
        </trans-unit>
        <trans-unit id="d2da9e071126ba50e59d5abd1403683c0e2d00d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_interval&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Value to use as the new growth interval.</source>
          <target state="translated">&lt;strong&gt;new_interval&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;用作新的增长间隔的值。</target>
        </trans-unit>
        <trans-unit id="4bec839b86f5243846ab899511cc5d003c1c78ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Value to use as the new scale backoff factor.</source>
          <target state="translated">&lt;strong&gt;new_scale&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;用作新比例尺补偿因子的值。</target>
        </trans-unit>
        <trans-unit id="022de68da67d2ead164e455f77fd162fdd34ca79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Value to use as the new scale growth factor.</source>
          <target state="translated">&lt;strong&gt;new_scale&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;用作新比例尺增长因子的值。</target>
        </trans-unit>
        <trans-unit id="e7ed1221b27b3bb5a36954c20d1c72571bd4d1d1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_scale&lt;/strong&gt; (float or &lt;code&gt;torch.cuda.FloatTensor&lt;/code&gt;, optional, default=None) &amp;ndash; New scale factor.</source>
          <target state="translated">&lt;strong&gt;new_scale&lt;/strong&gt;（float或 &lt;code&gt;torch.cuda.FloatTensor&lt;/code&gt; ，可选，默认为None）&amp;ndash;新的比例因子。</target>
        </trans-unit>
        <trans-unit id="c70cf625cede657dde5d0c120d5a1f74a918a253" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_state&lt;/strong&gt; (&lt;em&gt;torch.ByteTensor&lt;/em&gt;) &amp;ndash; The desired state</source>
          <target state="translated">&lt;strong&gt;new_state&lt;/strong&gt;（&lt;em&gt;torch.ByteTensor&lt;/em&gt;）&amp;ndash;所需状态</target>
        </trans-unit>
        <trans-unit id="7fd74008cc5669b78289c4a9b06d25331220701d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_state&lt;/strong&gt; (&lt;em&gt;torch.ByteTensor&lt;/em&gt;) &amp;ndash; The desired state.</source>
          <target state="translated">&lt;strong&gt;new_state&lt;/strong&gt;（&lt;em&gt;torch.ByteTensor&lt;/em&gt;）&amp;ndash;所需的状态。</target>
        </trans-unit>
        <trans-unit id="0cd655a13d52cfc3e39cde6648a63b09b5ee820b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_states&lt;/strong&gt; (&lt;em&gt;Iterable of torch.ByteTensor&lt;/em&gt;) &amp;ndash; The desired state for each device</source>
          <target state="translated">&lt;strong&gt;new_states&lt;/strong&gt;（&lt;em&gt;torch.ByteTensor的Iterable&lt;/em&gt;）&amp;ndash;每个设备的期望状态</target>
        </trans-unit>
        <trans-unit id="e8c5015026d05f7c2175e0d687fea36008f02797" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_strategy&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; Name of the selected strategy. Should be one of the values returned by &lt;a href=&quot;#torch.multiprocessing.get_all_sharing_strategies&quot;&gt;&lt;code&gt;get_all_sharing_strategies()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;new_strategy&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;所选策略的名称。应该是&lt;a href=&quot;#torch.multiprocessing.get_all_sharing_strategies&quot;&gt; &lt;code&gt;get_all_sharing_strategies()&lt;/code&gt; &lt;/a&gt;返回的值之一。</target>
        </trans-unit>
        <trans-unit id="3684197908f63147ef8bf8af4038b1e7eef5b679" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash; the number of heads in the multiheadattention models (default=8).</source>
          <target state="translated">&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash;多头&lt;strong&gt;注意力&lt;/strong&gt;模型中的头数（默认为8）。</target>
        </trans-unit>
        <trans-unit id="8c047d9990ce17c7638516b2eb9cd4d4eefd9f13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash; the number of heads in the multiheadattention models (required).</source>
          <target state="translated">&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash;多头&lt;strong&gt;注意力&lt;/strong&gt;模型中的头数（必填）。</target>
        </trans-unit>
        <trans-unit id="bf9b1d87107478239f509cdbfbfba2359192e4ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;niter&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; maximum number of iterations. When reached, the iteration process is hard-stopped and the current approximation of eigenpairs is returned. For infinite iteration but until convergence criteria is met, use &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;niter&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;最大迭代次数。当到达时，迭代过程将被严格停止，并返回本征对的当前近似值。对于无限迭代，但要满足收敛标准之前，请使用 &lt;code&gt;-1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="474b45a07e5133e74b4680b4ebef67231879479c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;niter&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of subspace iterations to conduct; niter must be a nonnegative integer, and defaults to 2.</source>
          <target state="translated">&lt;strong&gt;niter&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;，&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;进行子空间迭代的次数；niter必须为非负整数，默认为2。</target>
        </trans-unit>
        <trans-unit id="179187db6714db7b86343992867677ff4ff75191" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt; and the source is in pinned memory, the copy will be asynchronous with respect to the host. Otherwise, the argument has no effect.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，并且源位于固定内存中，则副本将相对于主机是异步的。否则，该参数无效。</target>
        </trans-unit>
        <trans-unit id="fda458f2f7dc476cf65c2462d3a8061f49814e9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt; and the source is in pinned memory, the copy will be asynchronous with respect to the host. Otherwise, the argument has no effect. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，并且源位于固定内存中，则副本将相对于主机是异步的。否则，该参数无效。默认值： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f5e9c95303e9f5242b9e3eeef2ca091abb7d7587" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;如果为 &lt;code&gt;True&lt;/code&gt; ，并且源位于固定内存中，而目标位于GPU上，反之亦然，则复制是相对于主机异步执行的。否则，该参数无效。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
