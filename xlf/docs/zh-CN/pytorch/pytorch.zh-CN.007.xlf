<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="ac5d2b1d677d49a0bd86ef0862a7927fd9191c9e" translate="yes" xml:space="preserve">
          <source>Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision. PyTorch supports both per tensor and per channel asymmetric linear quantization. To learn more how to use quantized functions in PyTorch, please refer to the &lt;a href=&quot;quantization#quantization-doc&quot;&gt;Quantization&lt;/a&gt; documentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18a85a5632065b99cfe45a2efad2f1ae99da1046" translate="yes" xml:space="preserve">
          <source>Quantize</source>
          <target state="translated">Quantize</target>
        </trans-unit>
        <trans-unit id="5dc78d5962844144dbb78dcd34c444f89d2360d5" translate="yes" xml:space="preserve">
          <source>Quantized Functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22040c5f1ace6596f37ed53e5feee71111db31d0" translate="yes" xml:space="preserve">
          <source>Quantizes an incoming tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ad43145efa235468f5902d61cd285ed9b73e61e" translate="yes" xml:space="preserve">
          <source>Quasi-random sampling</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06576556d1ad802f247cad11ae748be47b70cd9c" translate="yes" xml:space="preserve">
          <source>R</source>
          <target state="translated">R</target>
        </trans-unit>
        <trans-unit id="a4a12b6d13143948a19488e0d1cd0864bcfcd487" translate="yes" xml:space="preserve">
          <source>R(2+1)D-18 network</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d51f7562aadcec1a3d0cd7c60d6435cbf2ea1a0" translate="yes" xml:space="preserve">
          <source>R3D-18 network</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5db7969dcd30635e5d7867040b6cc76158dd175" translate="yes" xml:space="preserve">
          <source>RAW</source>
          <target state="translated">RAW</target>
        </trans-unit>
        <trans-unit id="2fe8814f679602ef8677e9b846ae9cc63646e90c" translate="yes" xml:space="preserve">
          <source>RNN</source>
          <target state="translated">RNN</target>
        </trans-unit>
        <trans-unit id="419fa7ef1354a7471cfefa40385138f81850a613" translate="yes" xml:space="preserve">
          <source>RNNBase</source>
          <target state="translated">RNNBase</target>
        </trans-unit>
        <trans-unit id="22c95097b5426fe43997d6eb11be7ab8c5097b78" translate="yes" xml:space="preserve">
          <source>RNNCell</source>
          <target state="translated">RNNCell</target>
        </trans-unit>
        <trans-unit id="c3282cbbcba660116d62c007822229220838a1c6" translate="yes" xml:space="preserve">
          <source>RPC</source>
          <target state="translated">RPC</target>
        </trans-unit>
        <trans-unit id="b75c8242fd289be2b08bd6f1908eeb3affe74a47" translate="yes" xml:space="preserve">
          <source>RReLU</source>
          <target state="translated">RReLU</target>
        </trans-unit>
        <trans-unit id="e908d326bea7dd110e9821c1f738fe31ee60caf9" translate="yes" xml:space="preserve">
          <source>RRef</source>
          <target state="translated">RRef</target>
        </trans-unit>
        <trans-unit id="e98cb22d66aa1860c5d982443eb2d7e84c9630f1" translate="yes" xml:space="preserve">
          <source>RRef Lifetime</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c36d9458e0d1baae7403b5ce642a78b09e4acc7f" translate="yes" xml:space="preserve">
          <source>Raises</source>
          <target state="translated">Raises</target>
        </trans-unit>
        <trans-unit id="d92af57a28c421f8d8438229f0b21202604e4ae3" translate="yes" xml:space="preserve">
          <source>Raises &lt;code&gt;RuntimeError&lt;/code&gt; if &lt;a href=&quot;https://ninja-build.org/&quot;&gt;ninja&lt;/a&gt; build system is not available on the system, does nothing otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe6245a65da1996031b65e42c6ba6186170ca87f" translate="yes" xml:space="preserve">
          <source>Raises ValueError if the value is not present.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aedcea91bbd64d179e04e09799d9cf9271d320c0" translate="yes" xml:space="preserve">
          <source>Random sampling</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a94ba04a9499be153f8aa33a992c875d347dc19" translate="yes" xml:space="preserve">
          <source>Random sampling creation ops are listed under &lt;a href=&quot;#random-sampling&quot;&gt;Random sampling&lt;/a&gt; and include: &lt;a href=&quot;generated/torch.rand#torch.rand&quot;&gt;&lt;code&gt;torch.rand()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.rand_like#torch.rand_like&quot;&gt;&lt;code&gt;torch.rand_like()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randn#torch.randn&quot;&gt;&lt;code&gt;torch.randn()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randn_like#torch.randn_like&quot;&gt;&lt;code&gt;torch.randn_like()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randint#torch.randint&quot;&gt;&lt;code&gt;torch.randint()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randint_like#torch.randint_like&quot;&gt;&lt;code&gt;torch.randint_like()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;generated/torch.randperm#torch.randperm&quot;&gt;&lt;code&gt;torch.randperm()&lt;/code&gt;&lt;/a&gt; You may also use &lt;a href=&quot;generated/torch.empty#torch.empty&quot;&gt;&lt;code&gt;torch.empty()&lt;/code&gt;&lt;/a&gt; with the &lt;a href=&quot;#inplace-random-sampling&quot;&gt;In-place random sampling&lt;/a&gt; methods to create &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; s with values sampled from a broader range of distributions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1033bbebd194535f79c8257b5bf0911dcfc67f5b" translate="yes" xml:space="preserve">
          <source>RandomStructured</source>
          <target state="translated">RandomStructured</target>
        </trans-unit>
        <trans-unit id="1bc526966e9f4a0fc0dc8703f5e03b9b477135e9" translate="yes" xml:space="preserve">
          <source>RandomUnstructured</source>
          <target state="translated">RandomUnstructured</target>
        </trans-unit>
        <trans-unit id="464ae7dc9e362bdfac200fc767cbef5d1f028f9c" translate="yes" xml:space="preserve">
          <source>Randomized leaky ReLU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e67c8ff6a6fe1b402c9707f9ca4025ad7e992ff" translate="yes" xml:space="preserve">
          <source>Randomly masks out entire channels (a channel is a feature map, e.g. the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5ee3860ad6da586f04541bda24f379685849499" translate="yes" xml:space="preserve">
          <source>Randomly zero out entire channels (a channel is a 2D feature map, e.g., the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d25942032b09a691f7d96817937bb37b8fc61cbd" translate="yes" xml:space="preserve">
          <source>Randomly zero out entire channels (a channel is a 3D feature map, e.g., the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e887e4a3161eab98177808f95ed573db9bd91832" translate="yes" xml:space="preserve">
          <source>Rank is a unique identifier assigned to each process within a distributed process group. They are always consecutive integers ranging from 0 to &lt;code&gt;world_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db193220cd72bbc96216458a492d5965637b4287" translate="yes" xml:space="preserve">
          <source>Rather, this directly calls the underlying LAPACK function &lt;code&gt;?geqrf&lt;/code&gt; which produces a sequence of &amp;lsquo;elementary reflectors&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a864fcb6762d236bc276a85137cd0fcd44b3001" translate="yes" xml:space="preserve">
          <source>ReLU</source>
          <target state="translated">ReLU</target>
        </trans-unit>
        <trans-unit id="5290128df38d58d4be3bdda2dec90bacff114b1c" translate="yes" xml:space="preserve">
          <source>ReLU6</source>
          <target state="translated">ReLU6</target>
        </trans-unit>
        <trans-unit id="3294ad6b1eda298355d27264864a84bb153e4e5b" translate="yes" xml:space="preserve">
          <source>Real values are finite when they are not NaN, negative infinity, or infinity. Complex values are finite when both their real and imaginary parts are finite.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bf7f7c605a0ed647c478d22e23c8b7c103aaf78" translate="yes" xml:space="preserve">
          <source>Real-to-complex Discrete Fourier Transform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cb84ee223d1d7f38f89544406d3d898f06cdafb" translate="yes" xml:space="preserve">
          <source>Rearranges elements in a tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4d632c1063de7870f16352716202b1f2a8c81c1" translate="yes" xml:space="preserve">
          <source>Receives a tensor asynchronously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f89320a075e26566ba50731edf2f47338c4432f" translate="yes" xml:space="preserve">
          <source>Receives a tensor synchronously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d3b40b37dfe8fdad50303f26863dfa5944ffb83" translate="yes" xml:space="preserve">
          <source>Recurrent Layers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="437a7c4fe39d00898697f5eea2075a348d8b6eda" translate="yes" xml:space="preserve">
          <source>Reduce and scatter a list of tensors to the whole group. Only nccl backend is currently supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e154454ad02bd98ccb4e04b626318e2ca6ecea3" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data across all machines in such a way that all get the final result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0845d8a3b333d7e6bdeae11a45e93d821e227572" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data across all machines in such a way that all get the final result. This function reduces a number of tensors on every node, while each tensor resides on different GPUs. Therefore, the input tensor in the tensor list needs to be GPU tensors. Also, each tensor in the tensor list needs to reside on a different GPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68d09fcde5e8e7a3c4ca4ab69d90b3bd77b87c7d" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data across all machines.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6916d4b854bb48bab1b470966a0bd89b2429552" translate="yes" xml:space="preserve">
          <source>Reduces the tensor data on multiple GPUs across all machines. Each tensor in &lt;code&gt;tensor_list&lt;/code&gt; should reside on a separate GPU</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72826c34e0b98307364b7bcd04a0655be2f7559a" translate="yes" xml:space="preserve">
          <source>Reduces, then scatters a list of tensors to all processes in a group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44eef8c0a66c5ce295026ad03e889f17e08ed29c" translate="yes" xml:space="preserve">
          <source>Reducing with the addition operation is the same as using &lt;a href=&quot;#torch.Tensor.scatter_add_&quot;&gt;&lt;code&gt;scatter_add_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b6d087fa2831e91be3ac6de64b3da6a95b4c118" translate="yes" xml:space="preserve">
          <source>Reduction Ops</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da9dd3248fef822f41edb238f214a556d8fa5e69" translate="yes" xml:space="preserve">
          <source>Reduction is not yet implemented for the CUDA backend.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45c3dc1c7731c6185824876ed514e54f71bacb64" translate="yes" xml:space="preserve">
          <source>Reference:</source>
          <target state="translated">Reference:</target>
        </trans-unit>
        <trans-unit id="5d20d0fee3b91643dd8d272ac33d01ca95179d82" translate="yes" xml:space="preserve">
          <source>References</source>
          <target state="translated">References</target>
        </trans-unit>
        <trans-unit id="9d1e4e7d27b519b1da3d7266c9c87d7861741080" translate="yes" xml:space="preserve">
          <source>References:</source>
          <target state="translated">References:</target>
        </trans-unit>
        <trans-unit id="9368e2ec97261508237a4befedcf1e3dc15edd5f" translate="yes" xml:space="preserve">
          <source>References::</source>
          <target state="translated">References::</target>
        </trans-unit>
        <trans-unit id="ba0ffdee70f599751e1059c2737dfaa0253ed5bb" translate="yes" xml:space="preserve">
          <source>Refines the dimension names of &lt;code&gt;self&lt;/code&gt; according to &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd83bfc89e8951867aebce2ddbcf9aebb755b1db" translate="yes" xml:space="preserve">
          <source>Refining is a special case of renaming that &amp;ldquo;lifts&amp;rdquo; unnamed dimensions. A &lt;code&gt;None&lt;/code&gt; dim can be refined to have any name; a named dim can only be refined to have the same name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5acc200962ac427c960517361870d2ca95708a0c" translate="yes" xml:space="preserve">
          <source>ReflectionPad1d</source>
          <target state="translated">ReflectionPad1d</target>
        </trans-unit>
        <trans-unit id="1970d048b8b11bdbb537bc4467b97dde9cbcbcf6" translate="yes" xml:space="preserve">
          <source>ReflectionPad2d</source>
          <target state="translated">ReflectionPad2d</target>
        </trans-unit>
        <trans-unit id="44e5f9796886b9f39a08e9c3d313df29a4afdc69" translate="yes" xml:space="preserve">
          <source>Registers a backward hook on the module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="780fedc50fbec8a5ee2093bca221ccb17c71d8a2" translate="yes" xml:space="preserve">
          <source>Registers a backward hook.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="859ad11a7a9b00f2dc1648434120e2c30f756c3a" translate="yes" xml:space="preserve">
          <source>Registers a forward hook on the module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1cc6d46047e39e672054a7b43c380ab89aa516c" translate="yes" xml:space="preserve">
          <source>Registers a forward pre-hook on the module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6aabe5246532aa5e226dacac93b7040def81f191" translate="yes" xml:space="preserve">
          <source>Remote Reference Protocol</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2611051acb1fb592d77daa5cae8fbc141634b65" translate="yes" xml:space="preserve">
          <source>Remove all items from the ModuleDict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19890e3b8941dee97b6730d3bdd4b5d7d4da71b3" translate="yes" xml:space="preserve">
          <source>Remove all items from the ParameterDict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42e212ea49cffd4d66b50c00fb3332336dc13f4d" translate="yes" xml:space="preserve">
          <source>Remove key from the ModuleDict and return its module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1225726758ca9313c0c5ad3ef2ebcc4ac3f41d5b" translate="yes" xml:space="preserve">
          <source>Remove key from the ParameterDict and return its parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9168342afe82b61ecfcba245e5a3e85066d9cae2" translate="yes" xml:space="preserve">
          <source>Removes a tensor dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10551f8140eae7eec1c2f790aa2c398a8a2c225b" translate="yes" xml:space="preserve">
          <source>Removes the pruning reparameterization from a module and the pruning method from the forward hook.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d39954d7304877c790bae592a897de9b12d0614" translate="yes" xml:space="preserve">
          <source>Removes the pruning reparameterization from a module and the pruning method from the forward hook. The pruned parameter named &lt;code&gt;name&lt;/code&gt; remains permanently pruned, and the parameter named &lt;code&gt;name+'_orig'&lt;/code&gt; is removed from the parameter list. Similarly, the buffer named &lt;code&gt;name+'_mask'&lt;/code&gt; is removed from the buffers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c59a012a002ebcdeb37a7a4b34651f264175236e" translate="yes" xml:space="preserve">
          <source>Removes the pruning reparameterization from a module. The pruned parameter named &lt;code&gt;name&lt;/code&gt; remains permanently pruned, and the parameter named &lt;code&gt;name+'_orig'&lt;/code&gt; is removed from the parameter list. Similarly, the buffer named &lt;code&gt;name+'_mask'&lt;/code&gt; is removed from the buffers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc2f6b46c8953513899753dc6f37ab21a947d81f" translate="yes" xml:space="preserve">
          <source>Removes the spectral normalization reparameterization from a module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6f3f85d165e444aba5b7212e4c107777c615fa6" translate="yes" xml:space="preserve">
          <source>Removes the weight normalization reparameterization from a module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52a78431ddbd753c3acf927411e5dc4eadd51b45" translate="yes" xml:space="preserve">
          <source>Renames dimension names of &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e15bfbedf002065481094064ab67496cead9c00" translate="yes" xml:space="preserve">
          <source>Render matplotlib figure into an image and add it to summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4424e2e484e1d0e2228176a1b9d133567150454" translate="yes" xml:space="preserve">
          <source>Repeat elements of a tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c71c8380a78ab9cf6beaa41ffbcea1de55f181da" translate="yes" xml:space="preserve">
          <source>Repeated tensor which has the same shape as input, except along the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb8854cff80d6a6dd0521042f630c62a94943f9c" translate="yes" xml:space="preserve">
          <source>Repeats this tensor along the specified dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d717a0451eef9c7694fd101a42a92bb95d3c0a0f" translate="yes" xml:space="preserve">
          <source>ReplicationPad1d</source>
          <target state="translated">ReplicationPad1d</target>
        </trans-unit>
        <trans-unit id="7134ff298e79c741cf90df7d64ae3929d67c6005" translate="yes" xml:space="preserve">
          <source>ReplicationPad2d</source>
          <target state="translated">ReplicationPad2d</target>
        </trans-unit>
        <trans-unit id="b3ace69bd0bb68cc7d2ded9c8edec593b271b884" translate="yes" xml:space="preserve">
          <source>ReplicationPad3d</source>
          <target state="translated">ReplicationPad3d</target>
        </trans-unit>
        <trans-unit id="e41aa1fbbb423bb33022752fd330ea4ede8e16b6" translate="yes" xml:space="preserve">
          <source>Reproducibility</source>
          <target state="translated">Reproducibility</target>
        </trans-unit>
        <trans-unit id="f2e21cfb2562445f4e03149dcac964dc2b3217e6" translate="yes" xml:space="preserve">
          <source>ResNeXt</source>
          <target state="translated">ResNeXt</target>
        </trans-unit>
        <trans-unit id="135c48b06dbed678d0d867cebf0cf2de161d70cb" translate="yes" xml:space="preserve">
          <source>ResNeXt-101 32x8d model from &lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;&amp;ldquo;Aggregated Residual Transformation for Deep Neural Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd1a95f8f26475fcde5af625d8ad155d8daa61e2" translate="yes" xml:space="preserve">
          <source>ResNeXt-101-32x8d</source>
          <target state="translated">ResNeXt-101-32x8d</target>
        </trans-unit>
        <trans-unit id="6345fcacef60a6153337313629690096bdc6aa78" translate="yes" xml:space="preserve">
          <source>ResNeXt-50 32x4d model from &lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;&amp;ldquo;Aggregated Residual Transformation for Deep Neural Networks&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6816178c1f62a28d2e7d31075a846209cc1ee81" translate="yes" xml:space="preserve">
          <source>ResNeXt-50-32x4d</source>
          <target state="translated">ResNeXt-50-32x4d</target>
        </trans-unit>
        <trans-unit id="78fa6ef9716ebb9b06e34fb7e8ef3e1ee1ff74a3" translate="yes" xml:space="preserve">
          <source>ResNet</source>
          <target state="translated">ResNet</target>
        </trans-unit>
        <trans-unit id="5e9c332cfed41849a28e63e75aa34789f743a723" translate="yes" xml:space="preserve">
          <source>ResNet (2+1)D</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="870e5dde5df25034d3630c3aac9cb2c4bf4e76fc" translate="yes" xml:space="preserve">
          <source>ResNet 3D</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da256605d586d089e9e7223940cb0055eadbd1ee" translate="yes" xml:space="preserve">
          <source>ResNet 3D 18</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8475b358157d99679b66bf1c03461ee4befbc51" translate="yes" xml:space="preserve">
          <source>ResNet MC 18</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f7d19436196d570e8d470413429de7c74b3c3f2" translate="yes" xml:space="preserve">
          <source>ResNet Mixed Convolution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65817ac0c28cdf514ee310ccdae57eb30ff37866" translate="yes" xml:space="preserve">
          <source>ResNet-101</source>
          <target state="translated">ResNet-101</target>
        </trans-unit>
        <trans-unit id="6cdb79fa3540b98aee4fbbedd859f85dfa5878e1" translate="yes" xml:space="preserve">
          <source>ResNet-101 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad50fc165163aca8aff90e2401f355f0d73cb36d" translate="yes" xml:space="preserve">
          <source>ResNet-152</source>
          <target state="translated">ResNet-152</target>
        </trans-unit>
        <trans-unit id="ce82bef112318844175b33dd6318fe126f6f7716" translate="yes" xml:space="preserve">
          <source>ResNet-152 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a95e0d1f4879bbdecde67b2d824acd91e0a2a593" translate="yes" xml:space="preserve">
          <source>ResNet-18</source>
          <target state="translated">ResNet-18</target>
        </trans-unit>
        <trans-unit id="0c0f62f5b13f506e60ccc5621518d2252a8fa85e" translate="yes" xml:space="preserve">
          <source>ResNet-18 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7751035efc6144aca1732aa23112dd3aecb6bc5" translate="yes" xml:space="preserve">
          <source>ResNet-34</source>
          <target state="translated">ResNet-34</target>
        </trans-unit>
        <trans-unit id="e8def5ecc7cddff157e2b586142f5fdf856d05a5" translate="yes" xml:space="preserve">
          <source>ResNet-34 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27444a897bb1c912cdd3b04f0a83fd62a5d2c590" translate="yes" xml:space="preserve">
          <source>ResNet-50</source>
          <target state="translated">ResNet-50</target>
        </trans-unit>
        <trans-unit id="238ac2833cd54b6df3e18e9c24a824061fd3a21c" translate="yes" xml:space="preserve">
          <source>ResNet-50 model from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;&amp;ldquo;Deep Residual Learning for Image Recognition&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f2d9cd833caae8dbee1966d8ab0943fddb27fd0" translate="yes" xml:space="preserve">
          <source>ResNext</source>
          <target state="translated">ResNext</target>
        </trans-unit>
        <trans-unit id="d6989ed48031dfd0f342adca72920ca82d14ffc5" translate="yes" xml:space="preserve">
          <source>Resets parameter data pointer so that they can use faster code paths.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5146907f6db4f1b0f9869f7b411013406ae86ae8" translate="yes" xml:space="preserve">
          <source>Resizes &lt;code&gt;self&lt;/code&gt; tensor to the specified size. If the number of elements is larger than the current storage size, then the underlying storage is resized to fit the new number of elements. If the number of elements is smaller, the underlying storage is not changed. Existing elements are preserved but any new memory is uninitialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70492132da5a47c3477a96c6627fc5933e85e1e1" translate="yes" xml:space="preserve">
          <source>Resizes the &lt;code&gt;self&lt;/code&gt; tensor to be the same size as the specified &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt;. This is equivalent to &lt;code&gt;self.resize_(tensor.size())&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc2cdc93dc037b80e1ebd8434da768aef6d0fcaf" translate="yes" xml:space="preserve">
          <source>Result is &lt;code&gt;-inf&lt;/code&gt; if &lt;code&gt;input&lt;/code&gt; has zero log determinant, and is &lt;code&gt;nan&lt;/code&gt; if &lt;code&gt;input&lt;/code&gt; has negative determinant.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ae09aed030eb1a83f83c301c7fc275b3c8a0647" translate="yes" xml:space="preserve">
          <source>RetinaNet</source>
          <target state="translated">RetinaNet</target>
        </trans-unit>
        <trans-unit id="a1e229ed770b9619ca67b1b0aef6ec1a40fa1776" translate="yes" xml:space="preserve">
          <source>RetinaNet ResNet-50 FPN</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f7a9d4a0bc6f5ce0cbca61c540daaa5837025ee" translate="yes" xml:space="preserve">
          <source>Retrieves a map from Tensor to the appropriate gradient for that Tensor accumulated in the provided context corresponding to the given &lt;code&gt;context_id&lt;/code&gt; as part of the distributed autograd backward pass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ece76093eabcbca0a40b151ec0259b426ce567d" translate="yes" xml:space="preserve">
          <source>Retrieves the value associated with the given &lt;code&gt;key&lt;/code&gt; in the store. If &lt;code&gt;key&lt;/code&gt; is not present in the store, the function will wait for &lt;code&gt;timeout&lt;/code&gt;, which is defined when initializing the store, before throwing an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24f096b221f9534bcad007f2b5a32b490950b5b5" translate="yes" xml:space="preserve">
          <source>Return</source>
          <target state="translated">Return</target>
        </trans-unit>
        <trans-unit id="9cae8b09f0118269a649c5008d17c8253bec9782" translate="yes" xml:space="preserve">
          <source>Return &lt;code&gt;True&lt;/code&gt; if this &lt;code&gt;Future&lt;/code&gt; is done. A &lt;code&gt;Future&lt;/code&gt; is done if it has a result or an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="402831e8533c0acc0b144ded8789c976ea34ab74" translate="yes" xml:space="preserve">
          <source>Return a tensor of elements selected from either &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt;, depending on &lt;code&gt;condition&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f0e9dea6ad89a9cf4c50eeccd2244407a0e3b6" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ModuleDict key/value pairs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53758c5a8d9838ee15c5a1139ddc298268e3f550" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ModuleDict keys.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75b2716bbd52d76a593565ce26e635f35a65eba3" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ModuleDict values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39aa7eccaf084effaa1d95b2523664d87adadc63" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ParameterDict key/value pairs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36d08ddba7858cda4d75cdfaa632b92a0d271817" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ParameterDict keys.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0eb7abc74094e832f39c777a2b9fdb3353665e0c" translate="yes" xml:space="preserve">
          <source>Return an iterable of the ParameterDict values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fb5e3008c47afba229895a4aa4b8cfa03845a94" translate="yes" xml:space="preserve">
          <source>Return the next floating-point value after &lt;code&gt;input&lt;/code&gt; towards &lt;code&gt;other&lt;/code&gt;, elementwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c457486fbf0726f2b8521c0379e30203a9c59a56" translate="yes" xml:space="preserve">
          <source>Return the recommended gain value for the given nonlinearity function. The values are as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="689416efbdc5cadbcaa00d5d52249a2a0b1ad5c6" translate="yes" xml:space="preserve">
          <source>Return the singular value decomposition &lt;code&gt;(U, S, V)&lt;/code&gt; of a matrix, batches of matrices, or a sparse matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41b1fb407b7fa442b77381701968fb175362cf78" translate="yes" xml:space="preserve">
          <source>Return type</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1254906d712ed370ba1cdf6cdc5b06fa43eea6c3" translate="yes" xml:space="preserve">
          <source>Returned Tensor shares the same storage with the original one. In-place modifications on either of them will be seen, and may trigger errors in correctness checks. IMPORTANT NOTE: Previously, in-place size / stride / storage changes (such as &lt;code&gt;resize_&lt;/code&gt; / &lt;code&gt;resize_as_&lt;/code&gt; / &lt;code&gt;set_&lt;/code&gt; / &lt;code&gt;transpose_&lt;/code&gt;) to the returned tensor also update the original tensor. Now, these in-place changes will not update the original tensor anymore, and will instead trigger an error. For sparse tensors: In-place indices / values changes (such as &lt;code&gt;zero_&lt;/code&gt; / &lt;code&gt;copy_&lt;/code&gt; / &lt;code&gt;add_&lt;/code&gt;) to the returned tensor will not update the original tensor anymore, and will instead trigger an error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="996cd4205ef23a24fd77a57ded3d3ea1bc26418b" translate="yes" xml:space="preserve">
          <source>Returned tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9582a02f141fc4b345b2936eba691cd0654efebc" translate="yes" xml:space="preserve">
          <source>Returns</source>
          <target state="translated">Returns</target>
        </trans-unit>
        <trans-unit id="11cfd066b647ca21ea710fa73097f97cb102e1f7" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;True&lt;/code&gt; if the &lt;a href=&quot;https://ninja-build.org/&quot;&gt;ninja&lt;/a&gt; build system is available on the system, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="196db82d442085adba66ce72a40bf4c6b883e9c5" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;True&lt;/code&gt; if the distributed package is available. Otherwise, &lt;code&gt;torch.distributed&lt;/code&gt; does not expose any other APIs. Currently, &lt;code&gt;torch.distributed&lt;/code&gt; is available on Linux, MacOS and Windows. Set &lt;code&gt;USE_DISTRIBUTED=1&lt;/code&gt; to enable it when building PyTorch from source. Currently, the default value is &lt;code&gt;USE_DISTRIBUTED=1&lt;/code&gt; for Linux and Windows, &lt;code&gt;USE_DISTRIBUTED=0&lt;/code&gt; for MacOS.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="616465fba98082b69d414e38f74b13cab726f4ca" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;True&lt;/code&gt; if your system supports flushing denormal numbers and it successfully configures flush denormal mode. &lt;a href=&quot;#torch.set_flush_denormal&quot;&gt;&lt;code&gt;set_flush_denormal()&lt;/code&gt;&lt;/a&gt; is only supported on x86 architectures supporting SSE3.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65ca52a0d52509836247baf62510fc9195f808a9" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;self&lt;/code&gt; tensor as a NumPy &lt;code&gt;ndarray&lt;/code&gt;. This tensor and the returned &lt;code&gt;ndarray&lt;/code&gt; share the same underlying storage. Changes to &lt;code&gt;self&lt;/code&gt; tensor will be reflected in the &lt;code&gt;ndarray&lt;/code&gt; and vice versa.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="606042b612f01e1413a4be37fdcf4bc9fb55a2fd" translate="yes" xml:space="preserve">
          <source>Returns &lt;code&gt;self&lt;/code&gt; tensor&amp;rsquo;s offset in the underlying storage in terms of number of storage elements (not bytes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcee86aa4247be4fa57afaf338977b171a646e64" translate="yes" xml:space="preserve">
          <source>Returns True if &lt;code&gt;obj&lt;/code&gt; is a PyTorch storage object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c0fb790a1f7d7b5df52c8eb6b44b136b1ef5094" translate="yes" xml:space="preserve">
          <source>Returns True if &lt;code&gt;obj&lt;/code&gt; is a PyTorch tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="598b755e55cee356b7f7a395b6039f5d177fd41e" translate="yes" xml:space="preserve">
          <source>Returns True if &lt;code&gt;self&lt;/code&gt; tensor is contiguous in memory in the order specified by memory format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f80a083f5b5de080482f9bd320c35bee376edd5c" translate="yes" xml:space="preserve">
          <source>Returns True if all elements in each row of the tensor in the given dimension &lt;code&gt;dim&lt;/code&gt; are True, False otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10febb846509f6f2bc8c4b9a8a6d5f7a4d94b02e" translate="yes" xml:space="preserve">
          <source>Returns True if all elements in the tensor are True, False otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec249a00c3df799b548b2828fcdbdce219624299" translate="yes" xml:space="preserve">
          <source>Returns True if any elements in each row of the tensor in the given dimension &lt;code&gt;dim&lt;/code&gt; are True, False otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19164100a9af1a366aaf5bd12a4e88efb4270d73" translate="yes" xml:space="preserve">
          <source>Returns True if any elements in the tensor are True, False otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93fef2bb2e23cd032c2bc66acb9ba2af786fd6c1" translate="yes" xml:space="preserve">
          <source>Returns True if both tensors are pointing to the exact same memory (same storage, offset, size and stride).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfeaffdf583441339db6cd69904330215eafe368" translate="yes" xml:space="preserve">
          <source>Returns True if the &lt;code&gt;input&lt;/code&gt; is a single element tensor which is not equal to zero after type conversions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c533fa6ff5203fb73d711ade459c89e619986758" translate="yes" xml:space="preserve">
          <source>Returns True if the &lt;code&gt;input&lt;/code&gt; is a single element tensor which is not equal to zero after type conversions. i.e. not equal to &lt;code&gt;torch.tensor([0.])&lt;/code&gt; or &lt;code&gt;torch.tensor([0])&lt;/code&gt; or &lt;code&gt;torch.tensor([False])&lt;/code&gt;. Throws a &lt;code&gt;RuntimeError&lt;/code&gt; if &lt;code&gt;torch.numel() != 1&lt;/code&gt; (even in case of sparse tensors).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4546d55dc55434836d7155a943fded11ace1b513" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;input&lt;/code&gt; is a complex data type i.e., one of &lt;code&gt;torch.complex64&lt;/code&gt;, and &lt;code&gt;torch.complex128&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ed711035f4f45a68bdc409be57f591a1203d447" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;input&lt;/code&gt; is a floating point data type i.e., one of &lt;code&gt;torch.float64&lt;/code&gt;, &lt;code&gt;torch.float32&lt;/code&gt; and &lt;code&gt;torch.float16&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ad196c93762cde87d752d5a63b5607aaf9d27a9" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;self&lt;/code&gt; is a complex data type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47b01dfd12ff21d88fce8263233ddd92fb4ed8af" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;self&lt;/code&gt; is a floating point data type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81de301f63a48cfa0447acb0616f4e3a8050d38a" translate="yes" xml:space="preserve">
          <source>Returns True if the data type of &lt;code&gt;self&lt;/code&gt; is a signed data type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b3d22229996fcea50652425a0ceef76726b9f91" translate="yes" xml:space="preserve">
          <source>Returns True if the global deterministic flag is turned on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5073df54cb09fc1a6407537c2e76e0147566896" translate="yes" xml:space="preserve">
          <source>Returns True if the global deterministic flag is turned on. Refer to &lt;a href=&quot;torch.set_deterministic#torch.set_deterministic&quot;&gt;&lt;code&gt;torch.set_deterministic()&lt;/code&gt;&lt;/a&gt; documentation for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4032dc2622bbc19b42824ae9a76253643ed72f9" translate="yes" xml:space="preserve">
          <source>Returns a 1-D tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2604008505b663501ba7ccd9df67158c244b1f4" translate="yes" xml:space="preserve">
          <source>Returns a 1-dimensional view of each input tensor with zero dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e25d75bccca92cff61915e5211fa5ae4cd4e83b9" translate="yes" xml:space="preserve">
          <source>Returns a 1-dimensional view of each input tensor with zero dimensions. Input tensors with one or more dimensions are returned as-is.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9b98594557024de39affd4c070595a178dad181" translate="yes" xml:space="preserve">
          <source>Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a93e2128169bc51774f54bd53d2eaec67c329a8" translate="yes" xml:space="preserve">
          <source>Returns a 2-dimensional view of each each input tensor with zero dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d4b7116a250c6d886720ec99aa88d8cbeb63c35" translate="yes" xml:space="preserve">
          <source>Returns a 2-dimensional view of each each input tensor with zero dimensions. Input tensors with two or more dimensions are returned as-is. :param input: :type input: Tensor or list of Tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b208e9701580107f4e0baee12e48579cf84134e" translate="yes" xml:space="preserve">
          <source>Returns a 3-dimensional view of each each input tensor with zero dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9be625c9292e0cee5fd9c2f9e9f3ae65376309fe" translate="yes" xml:space="preserve">
          <source>Returns a 3-dimensional view of each each input tensor with zero dimensions. Input tensors with three or more dimensions are returned as-is. :param input: :type input: Tensor or list of Tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab61e9a8b5883304b4c24f113af9c2e2c089bc01" translate="yes" xml:space="preserve">
          <source>Returns a &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object to a list of the passed in Futures.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cff2424065898889ca4c8ceba9391c00be8f3c4e" translate="yes" xml:space="preserve">
          <source>Returns a &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object that can be waited on. When completed, the return value of &lt;code&gt;func&lt;/code&gt; on &lt;code&gt;args&lt;/code&gt; and &lt;code&gt;kwargs&lt;/code&gt; can be retrieved from the &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3012b7f55211365d28ddf4ab3e32e9d56916febf" translate="yes" xml:space="preserve">
          <source>Returns a CPU copy of this storage if it&amp;rsquo;s not already on the CPU</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="310ef068d2b0176ea9cd4ecb440e8d929300b581" translate="yes" xml:space="preserve">
          <source>Returns a DLPack representing the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d50286946851edf8b261b9ee4ffcf514e96ce11" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with &lt;code&gt;0&lt;/code&gt;. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ab36bf75992b3e189a293c78e7fdb358c585560" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with &lt;code&gt;1&lt;/code&gt;. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aff928dda115238bd0307d57f02acbba9a324cfb" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="545a5b97b3133069c0e8dcc8e1ce77397a1e785a" translate="yes" xml:space="preserve">
          <source>Returns a Tensor of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; filled with uninitialized data. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1bd30076d669876272e68e1e793c79f23bddd95" translate="yes" xml:space="preserve">
          <source>Returns a Tensor with same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as the Tensor &lt;code&gt;other&lt;/code&gt;. When &lt;code&gt;non_blocking&lt;/code&gt;, tries to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor. When &lt;code&gt;copy&lt;/code&gt; is set, a new Tensor is created even when the Tensor already matches the desired conversion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ff74c2d1bff3e0ce5952d69b71bd9a1e607f1aa" translate="yes" xml:space="preserve">
          <source>Returns a Tensor with the specified &lt;a href=&quot;#torch.Tensor.device&quot;&gt;&lt;code&gt;device&lt;/code&gt;&lt;/a&gt; and (optional) &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;dtype&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; it is inferred to be &lt;code&gt;self.dtype&lt;/code&gt;. When &lt;code&gt;non_blocking&lt;/code&gt;, tries to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor. When &lt;code&gt;copy&lt;/code&gt; is set, a new Tensor is created even when the Tensor already matches the desired conversion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da569f76cd483df9524efcb31fcf2ea99e390904" translate="yes" xml:space="preserve">
          <source>Returns a Tensor with the specified &lt;code&gt;dtype&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6724b6006e294e6e49650c83c7e2700124a4da5f" translate="yes" xml:space="preserve">
          <source>Returns a bool indicating if CUDNN is currently available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e15fd6f4de5dc5fea9ffd2c5465a552199dc217b" translate="yes" xml:space="preserve">
          <source>Returns a contiguous in memory tensor containing the same data as &lt;code&gt;self&lt;/code&gt; tensor. If &lt;code&gt;self&lt;/code&gt; tensor is already in the specified memory format, this function returns the &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27f4f3450faf371eb6306a54c86ee05877b30941" translate="yes" xml:space="preserve">
          <source>Returns a contraction of a and b over multiple dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28370d731f31276aa7e934060964f2e577e96a76" translate="yes" xml:space="preserve">
          <source>Returns a copy of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3318b58b5db87c6ad9827c719c9a9b9dbdc40b78" translate="yes" xml:space="preserve">
          <source>Returns a copy of the tensor in &lt;code&gt;torch.mkldnn&lt;/code&gt; layout.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6881bd2839553790195cb237970005b22687467" translate="yes" xml:space="preserve">
          <source>Returns a copy of this object in CPU memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd445c8d669710f667e23d46ff8038e303167c04" translate="yes" xml:space="preserve">
          <source>Returns a copy of this object in CUDA memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d7501c9a5a1714d3c3684f56c90bd8b61fff5d3" translate="yes" xml:space="preserve">
          <source>Returns a copy of this storage</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d518eb5a72df432375d8394da8f628d15fd3b22" translate="yes" xml:space="preserve">
          <source>Returns a dictionary containing a whole state of the module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbff7cc734b7142fc6847934bd6e1e33f653b796" translate="yes" xml:space="preserve">
          <source>Returns a list containing the elements of this storage</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd4681a72abe05d09c99ad2246c5c6f58da6423c" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the &lt;code&gt;k&lt;/code&gt; th smallest element of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee8ea74a50bcff655454904543731546a0784b94" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the &lt;code&gt;k&lt;/code&gt; th smallest element of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each element found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e386080072251f678a51090a4553c8d16a045fa" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative maximum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="126e4b96929c50182f17c4bb4a58b7d0fe049898" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative maximum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each maximum value found in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0588c1c3069407fd276a9514a421bf82e6313f49" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative minimum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c882e37440105ee95efe87d7c7a08229fc1a4c09" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the cumulative minimum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each maximum value found in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="967b821b8f0b7a1f96a4f7d0f792de5f0185c446" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the maximum value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each maximum value found (argmax).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="340d25e61485b289574a04d557988b6aad2f299c" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the median value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each median value found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b24dd1ba3e9b5a8840a923ed9f1831a7b9b04bb" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the minimum value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. And &lt;code&gt;indices&lt;/code&gt; is the index location of each minimum value found (argmin).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc8471de2c101d3651a6d7a76fd12e82843e6661" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the mode value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;, i.e.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4cc2f3a360a06df266083c92ef6ae91e2b318f1" translate="yes" xml:space="preserve">
          <source>Returns a namedtuple &lt;code&gt;(values, indices)&lt;/code&gt; where &lt;code&gt;values&lt;/code&gt; is the mode value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;, i.e. a value which appears most often in that row, and &lt;code&gt;indices&lt;/code&gt; is the index location of each mode value found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55daf74ff9a749b34582eb6dc5a7e9467d0b17d0" translate="yes" xml:space="preserve">
          <source>Returns a new 1-D tensor which indexes the &lt;code&gt;input&lt;/code&gt; tensor according to the boolean mask &lt;code&gt;mask&lt;/code&gt; which is a &lt;code&gt;BoolTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc996281b6d8b730ea490f35416e253843087c8c" translate="yes" xml:space="preserve">
          <source>Returns a new SparseTensor with values from Tensor &lt;code&gt;input&lt;/code&gt; filtered by indices of &lt;code&gt;mask&lt;/code&gt; and values are ignored. &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;mask&lt;/code&gt; must have the same shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="650add904aa71e494da203b253a7e5daaa3f4c87" translate="yes" xml:space="preserve">
          <source>Returns a new Tensor with &lt;code&gt;data&lt;/code&gt; as the tensor data. By default, the returned Tensor has the same &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; as this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f5b88777af1b3fb2f4856550ea09e3d3ade90f2" translate="yes" xml:space="preserve">
          <source>Returns a new Tensor, detached from the current graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6cad31d8dba22f0073db8447536a302dee9ee8b" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing imaginary values of the &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a474356ccaab506872384349a8c7d3cc842edfca" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing imaginary values of the &lt;code&gt;self&lt;/code&gt; tensor. The returned tensor and &lt;code&gt;self&lt;/code&gt; share the same underlying storage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0417e03c0fc21d8aa9cfd0ad69033f35d283ab8f" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing real values of the &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecd577300f229280c9c5bc1fe369db0f8475652e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor containing real values of the &lt;code&gt;self&lt;/code&gt; tensor. The returned tensor and &lt;code&gt;self&lt;/code&gt; share the same underlying storage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c3a649630732036f386759b3c1fe0f4082f284" translate="yes" xml:space="preserve">
          <source>Returns a new tensor that is a narrowed version of &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="446ae7f4205e67fe0ead00f78a291ab93a7e711a" translate="yes" xml:space="preserve">
          <source>Returns a new tensor that is a narrowed version of &lt;code&gt;input&lt;/code&gt; tensor. The dimension &lt;code&gt;dim&lt;/code&gt; is input from &lt;code&gt;start&lt;/code&gt; to &lt;code&gt;start + length&lt;/code&gt;. The returned tensor and &lt;code&gt;input&lt;/code&gt; tensor share the same underlying storage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6897347512206bded239af0259e282422aa1908" translate="yes" xml:space="preserve">
          <source>Returns a new tensor which indexes the &lt;code&gt;input&lt;/code&gt; tensor along dimension &lt;code&gt;dim&lt;/code&gt; using the entries in &lt;code&gt;index&lt;/code&gt; which is a &lt;code&gt;LongTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9c1e11a5f9f21aaf09f7c09b28d3efe9b79c1c9" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with a dimension of size one inserted at the specified position.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3224c262166ef14a2d46031572904d6b7dc8f710" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element is &lt;code&gt;finite&lt;/code&gt; or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95e1f8a1ccb8a8da884d7e84169520f79117ec5e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is &amp;ldquo;close&amp;rdquo; to the corresponding element of &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4be234d2b824b3afbb8b6e3c023a9678a2fef898" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is &amp;ldquo;close&amp;rdquo; to the corresponding element of &lt;code&gt;other&lt;/code&gt;. Closeness is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9a96751e78a2d8505653806cfbbeebe8f0da987" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is NaN or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f12a3acfcbbec29775876cc40c95d5a00ba9dd4a" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is NaN or not. Complex values are considered NaN when either their real and/or imaginary part is NaN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c183c7e7c59ca8cd11a1eb4078b588d714403acc" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is real-valued or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d49a6f7124bd5cd437a7a8fee3ecaa6dd817cb5" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with boolean elements representing if each element of &lt;code&gt;input&lt;/code&gt; is real-valued or not. All real-valued types are considered real. Complex values are considered real when their imaginary part is 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc57cc29526229bfe21bab4f3ac0fa280da67107" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with each of the elements of &lt;code&gt;input&lt;/code&gt; converted from angles in degrees to radians.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e88584aef7be0fb19dcf3caab156e7c17acae22e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with each of the elements of &lt;code&gt;input&lt;/code&gt; converted from angles in radians to degrees.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fd6a07571fec21877bbfab5cd7f129520d284d3" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with each of the elements of &lt;code&gt;input&lt;/code&gt; rounded to the closest integer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe9fedb3aa9a3f8d1c80fddb5c3023ad4eb0562" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the arcsine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7301245f47a696980faac9e988f16c20bfda8b7" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the arctangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48ba42f2193edb51a142cab5570b31530effd843" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the ceil of the elements of &lt;code&gt;input&lt;/code&gt;, the smallest integer greater than or equal to each element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec380dfec0f03433bc5e3eb0dc32821c6d58c884" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the cosine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0f7755628d00f3662eb39d02532aaee3f952862" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the elements of &lt;code&gt;input&lt;/code&gt; at the given indices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c910712ac5b779edd94af13b8675d26b2ec9292" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the elements of &lt;code&gt;input&lt;/code&gt; at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="303a77ef9e4e8ebea411b724b70cc880893ce1e5" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the exponential of the elements minus 1 of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc8c5f6e874a9d0acbadee7550724c3fd5e88f46" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the exponential of the elements of the input tensor &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66422619029217fb49c5540ea658003ab25d0251" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the floor of the elements of &lt;code&gt;input&lt;/code&gt;, the largest integer less than or equal to each element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54289275fc2999c18e519269b9c836fadd53ce09" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the hyperbolic cosine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60d4e278d41229d94159bb88a5a80098f0f17944" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the hyperbolic sine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="529a1d5ed854492ced22f20ca045b03cdb98828a" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the hyperbolic tangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9966d85e500f92c101949dbcee56d3622b0b7c74" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the inverse hyperbolic cosine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="016516e7b6362bc2420ae10e09ad46e7409d58cb" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the inverse hyperbolic sine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8624b8361034217c02a1c5e88fca1edddd5ce5dd" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the inverse hyperbolic tangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfd8b16427d7265384f4ab1669de0b012956b1e0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logarithm to the base 10 of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca59edbe372ab054262e278a40d31de7be114996" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logarithm to the base 2 of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="768981f99c3160fc5f2a6b954d047547f7f51a33" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logit of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83c02ed817fb8ffcff4e801d08d12130cb9f1cab" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the logit of the elements of &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; is clamped to [eps, 1 - eps] when eps is not None. When eps is None and &lt;code&gt;input&lt;/code&gt; &amp;lt; 0 or &lt;code&gt;input&lt;/code&gt; &amp;gt; 1, the function will yields NaN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="743fb44188d39b917a57a969a7a2bdfa54f07c5c" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the natural logarithm of (1 + &lt;code&gt;input&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7802c5deb620e1b95914f599e220dfe558ee03c0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the natural logarithm of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9bebfac39f90f81173963e0ca1f126dea57da57" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the negative of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0595e3a74577061b95243faf09a3387b6e217a7" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the reciprocal of the elements of &lt;code&gt;input&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40e790541f395ea8a715d66e7db7815ecda1464f" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the reciprocal of the square-root of each of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82f5d4bb888952c73ce51e1bac717329cb2869c0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the same data as the &lt;code&gt;self&lt;/code&gt; tensor but of a different &lt;code&gt;shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="736d1d1a205da1b8f4c4709de8f6235951658a7e" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the sigmoid of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e2b36eb81199cdbe569cc67684536ac9defc3a0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the signs of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47f02b09b0f6a0ab4b9c1f34438e6706d93ade59" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the sine of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75f7c6fa74ae5240454bfc9ef7f507262ffe9ed2" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the square of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2f28004537b23138d7c295a5914cf3e65ab6fd0" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the square-root of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baf6cf4928d6ab113308458333184cd46b1dbec9" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the tangent of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c51c660d43995f5399bc591984337fa3aa3dd1db" translate="yes" xml:space="preserve">
          <source>Returns a new tensor with the truncated integer values of the elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71a9122ea30596ae8f8e0cfb84c73297b46f8b8e" translate="yes" xml:space="preserve">
          <source>Returns a new view of the &lt;code&gt;self&lt;/code&gt; tensor with singleton dimensions expanded to a larger size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04f242c1b997d817d7997eb7a445d6e3823e9344" translate="yes" xml:space="preserve">
          <source>Returns a partial view of &lt;code&gt;input&lt;/code&gt; with the its diagonal elements with respect to &lt;code&gt;dim1&lt;/code&gt; and &lt;code&gt;dim2&lt;/code&gt; appended as a dimension at the end of the shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3032b88cf4f390e50cfecedba4f33edc6cf5043" translate="yes" xml:space="preserve">
          <source>Returns a pretty-printed representation (as valid Python syntax) of the internal graph for the &lt;code&gt;forward&lt;/code&gt; method. See &lt;a href=&quot;../jit#inspecting-code&quot;&gt;Inspecting Code&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21aab95a18e188886df073751e7d106cd6f9db59" translate="yes" xml:space="preserve">
          <source>Returns a random permutation of integers from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;n - 1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af613cf5c56817cafaa6ac101470a6f4a4596731" translate="yes" xml:space="preserve">
          <source>Returns a result tensor where each</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a13c7d88cad174382717397efbd3cfcb039a6695" translate="yes" xml:space="preserve">
          <source>Returns a sparse copy of the tensor. PyTorch supports sparse tensors in &lt;a href=&quot;sparse#sparse-docs&quot;&gt;coordinate format&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0a96d92340e65cc2a84c22d4d7b7ff9aa5fc4fe" translate="yes" xml:space="preserve">
          <source>Returns a string representation of the internal graph for the &lt;code&gt;forward&lt;/code&gt; method. See &lt;a href=&quot;../jit#interpreting-graphs&quot;&gt;Interpreting Graphs&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="597e1ef5a6ebc351d6f9d2b405bdd9101ff81520" translate="yes" xml:space="preserve">
          <source>Returns a string representation of the internal graph for the &lt;code&gt;forward&lt;/code&gt; method. This graph will be preprocessed to inline all function and method calls. See &lt;a href=&quot;../jit#interpreting-graphs&quot;&gt;Interpreting Graphs&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbb10017036639ab22d4a14313f02dc34ac957a3" translate="yes" xml:space="preserve">
          <source>Returns a tensor containing the indices of all non-zero elements of &lt;code&gt;input&lt;/code&gt;. Each row in the result contains the indices of a non-zero element in &lt;code&gt;input&lt;/code&gt;. The result is sorted lexicographically, with the last index changing the fastest (C-style).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92387ca99fbc648117949c0806c35a077690e5b2" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with random integers generated uniformly between &lt;code&gt;low&lt;/code&gt; (inclusive) and &lt;code&gt;high&lt;/code&gt; (exclusive).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3052366ee17d89fee66f156e0077cbbe80ebcf2" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with random numbers from a normal distribution with mean &lt;code&gt;0&lt;/code&gt; and variance &lt;code&gt;1&lt;/code&gt; (also called the standard normal distribution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="071f27bb3cbfbdac0a3664bb5e1e9b570135a766" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with random numbers from a uniform distribution on the interval</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6ccb0d318d2aea6d35f4cd94e4134bbdd4f3636" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;0&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5053ad71aa6f4e2e9cdde0c5980a9be98d8e91ca" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;0&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;torch.zeros_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.zeros(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53e8d496bf6d2306beb97ee488fa23a9b84ced51" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;0&lt;/code&gt;, with the shape defined by the variable argument &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19bc36fafde43e2e6ce27a396db27c69f93641b5" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;1&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45f89a095c06d9b0650d201a4622d88088b3f6da" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;1&lt;/code&gt;, with the same size as &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;torch.ones_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="380e4f75952135cee58ac0cb34dec6379c82103a" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with the scalar value &lt;code&gt;1&lt;/code&gt;, with the shape defined by the variable argument &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2619f65f9f0c07b8f2554ca2a356bbee1fb49067" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with uninitialized data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c9d253aa1bcbf44289c2a22a9efa2be86cdae22" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with uninitialized data. The shape and strides of the tensor is defined by the variable argument &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;stride&lt;/code&gt; respectively. &lt;code&gt;torch.empty_strided(size, stride)&lt;/code&gt; is equivalent to &lt;code&gt;torch.empty(size).as_strided(size, stride)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="480a441694f9fb4e384f61d0c285c3346aba2867" translate="yes" xml:space="preserve">
          <source>Returns a tensor filled with uninitialized data. The shape of the tensor is defined by the variable argument &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a9df9f8590e35dc409160c4e4da50e8473fc470" translate="yes" xml:space="preserve">
          <source>Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef9879439829f78c493eca54baa6bd3b9da4b6a9" translate="yes" xml:space="preserve">
          <source>Returns a tensor of the same size as &lt;code&gt;input&lt;/code&gt; with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in &lt;code&gt;input&lt;/code&gt; i.e.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dee1e5e90adcef58cad4a12a8016b3c535cc3f0d" translate="yes" xml:space="preserve">
          <source>Returns a tensor that is a transposed version of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c3720e104640e1187905d7635a3f6f3703b6e8e" translate="yes" xml:space="preserve">
          <source>Returns a tensor that is a transposed version of &lt;code&gt;input&lt;/code&gt;. The given dimensions &lt;code&gt;dim0&lt;/code&gt; and &lt;code&gt;dim1&lt;/code&gt; are swapped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc2a3afc167973637c7f4b6c69bc81e1a7b7c261" translate="yes" xml:space="preserve">
          <source>Returns a tensor where each row contains &lt;code&gt;num_samples&lt;/code&gt; indices sampled from the multinomial probability distribution located in the corresponding row of tensor &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfd4b9d9504c67da6e3c81783a008d55415316b9" translate="yes" xml:space="preserve">
          <source>Returns a tensor where each sub-tensor of &lt;code&gt;input&lt;/code&gt; along dimension &lt;code&gt;dim&lt;/code&gt; is normalized such that the &lt;code&gt;p&lt;/code&gt;-norm of the sub-tensor is lower than the value &lt;code&gt;maxnorm&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3a6b5909320cbc074af2544b9626c6f4bda5986" translate="yes" xml:space="preserve">
          <source>Returns a tensor with all the dimensions of &lt;code&gt;input&lt;/code&gt; of size &lt;code&gt;1&lt;/code&gt; removed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4dca01252775c3a510432e13b2a50bd68aaad47" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same data and number of elements as &lt;code&gt;input&lt;/code&gt;, but with the specified shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10ea5ae4aa9d17fa5857d769438a3aa3d3b7e12d" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same data and number of elements as &lt;code&gt;input&lt;/code&gt;, but with the specified shape. When possible, the returned tensor will be a view of &lt;code&gt;input&lt;/code&gt;. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs. viewing behavior.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="859366eeae9c89a2d4641ddcda6c14627157bccd" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same data and number of elements as &lt;code&gt;self&lt;/code&gt; but with the specified shape. This method returns a view if &lt;code&gt;shape&lt;/code&gt; is compatible with the current shape. See &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;torch.Tensor.view()&lt;/code&gt;&lt;/a&gt; on when it is possible to return a view.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ddaf7cc67581deb40ac49cd798acd828948f3ec" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same shape as Tensor &lt;code&gt;input&lt;/code&gt; filled with random integers generated uniformly between &lt;code&gt;low&lt;/code&gt; (inclusive) and &lt;code&gt;high&lt;/code&gt; (exclusive).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4d7f431450f08dca6e6bf02ccea73d644849cfb" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03ce7caeebb968b62c8d34b90b828d1ce8423f2f" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; filled with &lt;code&gt;fill_value&lt;/code&gt;. &lt;code&gt;torch.full_like(input, fill_value)&lt;/code&gt; is equivalent to &lt;code&gt;torch.full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4b1fea8767410865166f5ee9867a018bc11da8d" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; that is filled with random numbers from a normal distribution with mean 0 and variance 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea94290136057228a379eae661032b4dbc67bcaf" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; that is filled with random numbers from a normal distribution with mean 0 and variance 1. &lt;code&gt;torch.randn_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.randn(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0152430be2c09d5c5103cb904fde37d1ace3b55a" translate="yes" xml:space="preserve">
          <source>Returns a tensor with the same size as &lt;code&gt;input&lt;/code&gt; that is filled with random numbers from a uniform distribution on the interval</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="823c3c765d13781fa9b963395a22444e3b621c72" translate="yes" xml:space="preserve">
          <source>Returns a tuple of 1-D tensors, one for each dimension in &lt;code&gt;input&lt;/code&gt;, each containing the indices (in that dimension) of all non-zero elements of &lt;code&gt;input&lt;/code&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcd5e2fc8161aab0c115280174b5bb6b68911439" translate="yes" xml:space="preserve">
          <source>Returns a tuple of all slices along a given dimension, already without it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9c24c4caad4a1ea9a709ef4d25a5add23c5abc6" translate="yes" xml:space="preserve">
          <source>Returns a tuple of tensors as &lt;code&gt;(the pivots, the L tensor, the U tensor)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cad07505f53debb40a34d79ccc9f58807d93a22d" translate="yes" xml:space="preserve">
          <source>Returns a tuple of:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48ec84de6060a777e4b133c0cc4cbb5c195b63f4" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a complex tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbd534c7cdca6e762bf6f1efb8dbc311c8d5604b" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a complex tensor. For an input complex tensor of &lt;code&gt;size&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5219316aa3ad16a6268bf6cb076669b071e63b0" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a real tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feec717f015dd3a3543847bb4922909ce0df9768" translate="yes" xml:space="preserve">
          <source>Returns a view of &lt;code&gt;input&lt;/code&gt; as a real tensor. For an input complex tensor of &lt;code&gt;size&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b19c812d92695d71cc123c4309dfdfb970e00990" translate="yes" xml:space="preserve">
          <source>Returns a view of the original tensor which contains all slices of size &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; from &lt;code&gt;self&lt;/code&gt; tensor in the dimension &lt;code&gt;dimension&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af681be32c7d06253ca1c1b67c18e2b4ecd6f876" translate="yes" xml:space="preserve">
          <source>Returns a view of the original tensor with its dimensions permuted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c55cff2ceacf5489627870098b732610149ca753" translate="yes" xml:space="preserve">
          <source>Returns an fp32 Tensor by dequantizing a quantized Tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a760468481f662aec69f0d66a0af21b8d01fcc9" translate="yes" xml:space="preserve">
          <source>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac68eb8bdb577f36ea46f58e6159bc7bdc815476" translate="yes" xml:space="preserve">
          <source>Returns an iterator over all modules in the network.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94fc7e2a384a791953b1e205101832ccf08471ae" translate="yes" xml:space="preserve">
          <source>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06d88a90e624553bccb897dec896158a9e8cbe10" translate="yes" xml:space="preserve">
          <source>Returns an iterator over immediate children modules.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="710ada787bca81e41a3d40e51f40a7c77bf13dde" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eff830e357832045671934c63ceb5cb2fcb5978" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module buffers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1b975207d4ac5172ef30d4d877fa0c9ee98199a" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa5e4dda23bfdd55410c837a325f1f9ec0f370cb" translate="yes" xml:space="preserve">
          <source>Returns an iterator over module parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48fce4dac8987007e7e689346df86ef5aaaf8d0c" translate="yes" xml:space="preserve">
          <source>Returns an uninitialized tensor with the same size as &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25a01c60e025b196abbdae1e228f044292cc80b3" translate="yes" xml:space="preserve">
          <source>Returns an uninitialized tensor with the same size as &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;torch.empty_like(input)&lt;/code&gt; is equivalent to &lt;code&gt;torch.empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab487b617ce0598b5cf2a7578485a234f9dec28c" translate="yes" xml:space="preserve">
          <source>Returns cosine similarity between</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e36c4e3a7a9f1d367dee6c46085960ff3fa5e136" translate="yes" xml:space="preserve">
          <source>Returns cosine similarity between x1 and x2, computed along dim.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="415079d9dd9bf0c3a5f12e73dab28b75c28128b7" translate="yes" xml:space="preserve">
          <source>Returns either a complex tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d89b2ba3d69dbf0c5536d8dba9d4a8221b96833a" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; that would result from performing an arithmetic operation on the provided input tensors. See type promotion &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;documentation&lt;/a&gt; for more information on the type promotion logic.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a64cb8b4d560048c2d03eaad56133c0e7564a88" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; with the smallest size and scalar kind that is not smaller nor of lower kind than either &lt;code&gt;type1&lt;/code&gt; or &lt;code&gt;type2&lt;/code&gt;. See type promotion &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;documentation&lt;/a&gt; for more information on the type promotion logic.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="615a0842a40834e6013343600f3be5a6a5475da4" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; that would result from performing an arithmetic operation on the provided input tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d1fdb76adea0e220c4916182503a08888092e2a" translate="yes" xml:space="preserve">
          <source>Returns the &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; with the smallest size and scalar kind that is not smaller nor of lower kind than either &lt;code&gt;type1&lt;/code&gt; or &lt;code&gt;type2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf82a1ecc16fe682cb2b7f0a986e6561051951df" translate="yes" xml:space="preserve">
          <source>Returns the &lt;code&gt;k&lt;/code&gt; largest elements of the given &lt;code&gt;input&lt;/code&gt; tensor along a given dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bed4d210c184a7836660a5c8e790f223aef9984" translate="yes" xml:space="preserve">
          <source>Returns the Generator state as a &lt;code&gt;torch.ByteTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b326f89b0009d9a68d7ef03ea15be0ad2d1ff47f" translate="yes" xml:space="preserve">
          <source>Returns the LU solve of the linear system</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7e41a542d6bed1cb096c1ed65295fbd9d0b0caa" translate="yes" xml:space="preserve">
          <source>Returns the address of the first element of &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dcc3de7b8c8581e1cdbe092b04332f6662ee7fa" translate="yes" xml:space="preserve">
          <source>Returns the backend of the given process group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ff2118aeefe8e264108f6bd90694f18e03d42e7" translate="yes" xml:space="preserve">
          <source>Returns the cross product of vectors in dimension &lt;code&gt;dim&lt;/code&gt; of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ea80ae8957ba72ac8ddc6e085e6f544e8ae8c05" translate="yes" xml:space="preserve">
          <source>Returns the cumulative product of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="672aa95c90df23603089d78e5a986ac0c7ee6f37" translate="yes" xml:space="preserve">
          <source>Returns the cumulative sum of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="711b80d2744d16d4fcb6dea10d90a382b486d415" translate="yes" xml:space="preserve">
          <source>Returns the indices of the buckets to which each value in the &lt;code&gt;input&lt;/code&gt; belongs, where the boundaries of the buckets are set by &lt;code&gt;boundaries&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f4a40b7b47151439ff4a946635582981d1e9915" translate="yes" xml:space="preserve">
          <source>Returns the indices of the buckets to which each value in the &lt;code&gt;input&lt;/code&gt; belongs, where the boundaries of the buckets are set by &lt;code&gt;boundaries&lt;/code&gt;. Return a new tensor with the same size as &lt;code&gt;input&lt;/code&gt;. If &lt;code&gt;right&lt;/code&gt; is False (default), then the left boundary is closed. More formally, the returned index satisfies the following rules:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e89c9544d1eb7458a38f74393c854c8ecda06cb" translate="yes" xml:space="preserve">
          <source>Returns the indices of the lower triangular part of a &lt;code&gt;row&lt;/code&gt;-by- &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a481df57e472778d81eb9d047f3b776a831dacb" translate="yes" xml:space="preserve">
          <source>Returns the indices of the lower triangular part of a &lt;code&gt;row&lt;/code&gt;-by- &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates. Indices are ordered based on rows and then columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36d1fcc471f42fd072f6a49d3437bd2fb723f49b" translate="yes" xml:space="preserve">
          <source>Returns the indices of the maximum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27e8f13c991f81ab6eaf5ea019cec0319d74f97f" translate="yes" xml:space="preserve">
          <source>Returns the indices of the maximum values of a tensor across a dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02a6d25f17c18c20395b7dbfe38496f775ac3649" translate="yes" xml:space="preserve">
          <source>Returns the indices of the minimum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7c9c6f3bffff8c19d01d21b7330abaf2fed0de4" translate="yes" xml:space="preserve">
          <source>Returns the indices of the minimum values of a tensor across a dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6112a2a2de721ce77e0fbceb09a5d99e7c8b1b09" translate="yes" xml:space="preserve">
          <source>Returns the indices of the upper triangular part of a &lt;code&gt;row&lt;/code&gt; by &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c610a94f21c0e29b9389ef4636aaf00f7bcfcca" translate="yes" xml:space="preserve">
          <source>Returns the indices of the upper triangular part of a &lt;code&gt;row&lt;/code&gt; by &lt;code&gt;col&lt;/code&gt; matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates. Indices are ordered based on rows and then columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c38cd5cab4c0cbb6855ee937ca43e344a716d2eb" translate="yes" xml:space="preserve">
          <source>Returns the indices that sort a tensor along a given dimension in ascending order by value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="528f25a31d271ea8c283f1c3f903d83097bb316f" translate="yes" xml:space="preserve">
          <source>Returns the initial seed for generating random numbers as a Python &lt;code&gt;long&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3583d38607467b25587c688245c573295c38448" translate="yes" xml:space="preserve">
          <source>Returns the initial seed for generating random numbers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f756dfcdc4b88f47cc8afe02c13bb828b05c63e7" translate="yes" xml:space="preserve">
          <source>Returns the log of summed exponentials of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6389ff7f37373c9ca57e71fc477f0c668bda055" translate="yes" xml:space="preserve">
          <source>Returns the log of summed exponentials of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. The computation is numerically stabilized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7b57cf20e91ac970ff715302367553ab5d606f0" translate="yes" xml:space="preserve">
          <source>Returns the logarithm of the cumulative summation of the exponentiation of elements of &lt;code&gt;input&lt;/code&gt; in the dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ece733a42c60a3b1bb785f7b96e5ca90ed6c9354" translate="yes" xml:space="preserve">
          <source>Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices &lt;code&gt;input&lt;/code&gt;, the other elements of the result tensor &lt;code&gt;out&lt;/code&gt; are set to 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="903bb5ad470677dd96718bed7dd424b4eea58c19" translate="yes" xml:space="preserve">
          <source>Returns the matrix exponential. Supports batched input. For a matrix &lt;code&gt;A&lt;/code&gt;, the matrix exponential is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57632c5d6ea2c48ab4c7ad8c0de751aa58bc8ad6" translate="yes" xml:space="preserve">
          <source>Returns the matrix norm or vector norm of a given tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa8212443e4c775af178e39c5b9d95062b7f280a" translate="yes" xml:space="preserve">
          <source>Returns the matrix product of the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2056ceddf487b6aeac66141f77f1593dd5d51a33" translate="yes" xml:space="preserve">
          <source>Returns the matrix raised to the power &lt;code&gt;n&lt;/code&gt; for square matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a715df6cd530cefa49cad9ca42363f5dcc48be7" translate="yes" xml:space="preserve">
          <source>Returns the matrix raised to the power &lt;code&gt;n&lt;/code&gt; for square matrices. For batch of matrices, each individual matrix is raised to the power &lt;code&gt;n&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2592d5f82bbbc822a97e96b68b786a9c78bb926c" translate="yes" xml:space="preserve">
          <source>Returns the maximum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa13bd7559d027b3477eb7ddbb196e1171a0bca9" translate="yes" xml:space="preserve">
          <source>Returns the maximum value of each slice of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension(s) &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="809ee94cff5a85854481052825bc00d99efb4eb6" translate="yes" xml:space="preserve">
          <source>Returns the mean value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b95b8ed42b947df36f019475ad19d862230385ee" translate="yes" xml:space="preserve">
          <source>Returns the mean value of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2abf9fb9cf56489f6a00a784d4d458d7895d090" translate="yes" xml:space="preserve">
          <source>Returns the median value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8878f4d09befec1d421d046a625ff001883087d7" translate="yes" xml:space="preserve">
          <source>Returns the minimum value of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a0cee886c48025d366605a4d62185c2c9000596" translate="yes" xml:space="preserve">
          <source>Returns the minimum value of each slice of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension(s) &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd09e78e1b1393b57b6e81bd22e6b7089ac87df8" translate="yes" xml:space="preserve">
          <source>Returns the number of dimensions of &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="074c1198678efc321484286e167225dc00032bc7" translate="yes" xml:space="preserve">
          <source>Returns the number of keys set in the store. Note that this number will typically be one greater than the number of keys added by &lt;code&gt;set()&lt;/code&gt; and &lt;code&gt;add()&lt;/code&gt; since one key is used to coordinate all the workers using the store.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77a1f23eab350f2cc1dff14c648c4ff6203e6c58" translate="yes" xml:space="preserve">
          <source>Returns the number of processes in the current process group</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6ca89b8a3b13965452fa2d1cea6ac87f72d7a23" translate="yes" xml:space="preserve">
          <source>Returns the number of threads used for inter-op parallelism on CPU (e.g.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8b5e8f68adc8148c1f9e13acbeae8fd51bfefc0" translate="yes" xml:space="preserve">
          <source>Returns the number of threads used for inter-op parallelism on CPU (e.g. in JIT interpreter)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c423a746fa97a8c78c6c6a0bea67a7ee6cacc04" translate="yes" xml:space="preserve">
          <source>Returns the number of threads used for parallelizing CPU operations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76a9d76393683122be08a7059b22ee9487de8af7" translate="yes" xml:space="preserve">
          <source>Returns the numerical rank of a 2-D tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="915a8c083943d2bf3a4491860c8c37370cb6d81a" translate="yes" xml:space="preserve">
          <source>Returns the numerical rank of a 2-D tensor. The method to compute the matrix rank is done using SVD by default. If &lt;code&gt;symmetric&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then &lt;code&gt;input&lt;/code&gt; is assumed to be symmetric, and the computation of the rank is done by obtaining the eigenvalues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9021b2a01727f502181983387c837330544dbe0" translate="yes" xml:space="preserve">
          <source>Returns the p-norm of (&lt;code&gt;input&lt;/code&gt; - &lt;code&gt;other&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0db967e67efe6e63a87c0ce474cb74d7038305af" translate="yes" xml:space="preserve">
          <source>Returns the product of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7140a19943936f9d48bbfc1f4b6d873ec50ed19" translate="yes" xml:space="preserve">
          <source>Returns the product of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="971be3e3aa0bf4f890c81c3791eba6b84f38ff83" translate="yes" xml:space="preserve">
          <source>Returns the q-th quantiles of all elements in the &lt;code&gt;input&lt;/code&gt; tensor, doing a linear interpolation when the q-th quantile lies between two data points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1aa60514b18ba933ebc0d3b97778472f133a31e9" translate="yes" xml:space="preserve">
          <source>Returns the q-th quantiles of each row of the &lt;code&gt;input&lt;/code&gt; tensor along the dimension &lt;code&gt;dim&lt;/code&gt;, doing a linear interpolation when the q-th quantile lies between two data points. By default, &lt;code&gt;dim&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; resulting in the &lt;code&gt;input&lt;/code&gt; tensor being flattened before computation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="855eae4c3b5ff9439f790aa02a1e5edcb2f9666b" translate="yes" xml:space="preserve">
          <source>Returns the quantization scheme of a given QTensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d9c1cd994cab4ee1d9aadcaf26ce62a26fd9235" translate="yes" xml:space="preserve">
          <source>Returns the random number generator state as a &lt;code&gt;torch.ByteTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="627a3c7f5879a8778db877ff3b00bbcfbf03056f" translate="yes" xml:space="preserve">
          <source>Returns the rank of current process group</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4525ac2f89a3ac5d0c306f28833d2a44e3540a50" translate="yes" xml:space="preserve">
          <source>Returns the real and the imaginary parts together as one tensor of the same shape of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e3148edb8aa985705a099b8ae7ab9879b62393f" translate="yes" xml:space="preserve">
          <source>Returns the result of running &lt;code&gt;func&lt;/code&gt; with &lt;code&gt;args&lt;/code&gt; and &lt;code&gt;kwargs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d3d453cc3ee6cad8567bb601546cc4fa1aa1364" translate="yes" xml:space="preserve">
          <source>Returns the size in bytes of an individual element.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38820622e4a658519544ad686f76dee59368c29c" translate="yes" xml:space="preserve">
          <source>Returns the size of the &lt;code&gt;self&lt;/code&gt; tensor. The returned value is a subclass of &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;&lt;code&gt;tuple&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="159dfd0ce2a90b4d47c871e593a62731a632dc99" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation and mean of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b541928a3e9600b386da860747f66bb8139c4d0a" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation and mean of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bbd91280991e2a9737689547bbddca952d63287" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e297a06301ae289868c8331b63443bb83703e3b8" translate="yes" xml:space="preserve">
          <source>Returns the standard-deviation of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ebb6fa0d71baf28bcf461777f1c5e425a2744c2" translate="yes" xml:space="preserve">
          <source>Returns the stride of &lt;code&gt;self&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5f0fbc903ffee7b0004fd1f9bcd5996f44017b1" translate="yes" xml:space="preserve">
          <source>Returns the sum of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1863758d4c0f9cfda8c72c22853117ba70ebdee5" translate="yes" xml:space="preserve">
          <source>Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14e6166614886b7770d3ecf48dce1bfb59192744" translate="yes" xml:space="preserve">
          <source>Returns the sum of each row of SparseTensor &lt;code&gt;input&lt;/code&gt; in the given dimensions &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them. When sum over all &lt;code&gt;sparse_dim&lt;/code&gt;, this method returns a Tensor instead of SparseTensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf49e8cc86ca6a6600ce29a25884a785a376abc6" translate="yes" xml:space="preserve">
          <source>Returns the sum of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;, treating Not a Numbers (NaNs) as zero. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d434d5c1c4d2f8c246ee3548fb97e54d9889e29" translate="yes" xml:space="preserve">
          <source>Returns the sum of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;. If &lt;code&gt;dim&lt;/code&gt; is a list of dimensions, reduce over all of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28abb051bc478158b8e05bc1054f16151a20a7cb" translate="yes" xml:space="preserve">
          <source>Returns the sum of the elements of the diagonal of the input 2-D matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="628247234e04df2fd2dd0c458a3e5e95270ff4e1" translate="yes" xml:space="preserve">
          <source>Returns the tensor as a (nested) list. For scalars, a standard Python number is returned, just like with &lt;a href=&quot;#torch.Tensor.item&quot;&gt;&lt;code&gt;item()&lt;/code&gt;&lt;/a&gt;. Tensors are automatically moved to the CPU first if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94ea64072a9591f059633c957623237cd647f97a" translate="yes" xml:space="preserve">
          <source>Returns the total number of elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d3970a743c03ce9d28802ddc4f6588b09bb7c8b" translate="yes" xml:space="preserve">
          <source>Returns the type if &lt;code&gt;dtype&lt;/code&gt; is not provided, else casts this object to the specified type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fea27b4bcbff9f0edb11c8bfcd39329450a9b92" translate="yes" xml:space="preserve">
          <source>Returns the type of the underlying storage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ac509092325d5bcdffb0cc3612c7cf497735d46" translate="yes" xml:space="preserve">
          <source>Returns the underlying storage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32fcdf754b9cb5a228ef02efc503187163097afb" translate="yes" xml:space="preserve">
          <source>Returns the unique elements of the input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26e4d829967fdd7e5612995ff5e9602634c0689a" translate="yes" xml:space="preserve">
          <source>Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices &lt;code&gt;input&lt;/code&gt;, the other elements of the result tensor &lt;code&gt;out&lt;/code&gt; are set to 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f17ab21227456440a4bca3f2fb221dbfad6b68d3" translate="yes" xml:space="preserve">
          <source>Returns the value of this tensor as a standard Python number. This only works for tensors with one element. For other cases, see &lt;a href=&quot;#torch.Tensor.tolist&quot;&gt;&lt;code&gt;tolist()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1cc620c9c632e9d45f1d98e6550b6c3781efad4" translate="yes" xml:space="preserve">
          <source>Returns the variance and mean of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ff1d1aa2591afcd14de03b53682da2b82cb9cc7" translate="yes" xml:space="preserve">
          <source>Returns the variance and mean of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af4e03a6f47c5a06e9dc95d8b7b0827b12d10bac" translate="yes" xml:space="preserve">
          <source>Returns the variance of all elements in the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0298d938b904aa1e59745be5e3318e09914487aa" translate="yes" xml:space="preserve">
          <source>Returns the variance of each row of the &lt;code&gt;input&lt;/code&gt; tensor in the given dimension &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88e4f4506a554a4b89da7d55d5cfa7515f220fb9" translate="yes" xml:space="preserve">
          <source>Returns the version of cuDNN</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c3ac5c69999b0a023804bb506ededc917b6c131" translate="yes" xml:space="preserve">
          <source>Returns this tensor as the same shape as &lt;code&gt;other&lt;/code&gt;. &lt;code&gt;self.reshape_as(other)&lt;/code&gt; is equivalent to &lt;code&gt;self.reshape(other.sizes())&lt;/code&gt;. This method returns a view if &lt;code&gt;other.sizes()&lt;/code&gt; is compatible with the current shape. See &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;torch.Tensor.view()&lt;/code&gt;&lt;/a&gt; on when it is possible to return a view.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="586000b57d8c3b25d201cf41023bcdd3dcb6f713" translate="yes" xml:space="preserve">
          <source>Returns this tensor cast to the type of the given tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88c329059251d00815688b5e671bb43e44ab8c23" translate="yes" xml:space="preserve">
          <source>Returns true if &lt;code&gt;self.data&lt;/code&gt; stored on a gpu</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69352252bee0873e3fb0a65734cef7e6482fff70" translate="yes" xml:space="preserve">
          <source>Returns true if &lt;code&gt;self.data&lt;/code&gt; stored on in pinned memory</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="373aeaf23062f8c5ecaff73e9be00cb54c4e37f3" translate="yes" xml:space="preserve">
          <source>Returns true if this tensor resides in pinned memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8e3480d7d70ecfc7b3c25ecaed7108c83b90b62" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with CUDA support. Note that this doesn&amp;rsquo;t necessarily mean CUDA is available; just that if this PyTorch binary were run a machine with working CUDA drivers and devices, we would be able to use it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98fd0f653522d8480237ac570476e6435a37e06f" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with MKL support.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="620b15262eed97044ef3e21b5235ee100fef8185" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with MKL-DNN support.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="957ab7585c4317f19aa9cfbd05dcb5165584e9c9" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch is built with OpenMP support.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57fa332c1c053f80c3eff6f20003e44a174f7e50" translate="yes" xml:space="preserve">
          <source>Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="770f265f08ee812cf8c52d62b5ca51586f3291bd" translate="yes" xml:space="preserve">
          <source>Returns whether or not the current node is the owner of this &lt;code&gt;RRef&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65ba60da18a01009c75c582854b7076b39cbf39e" translate="yes" xml:space="preserve">
          <source>Returns whether this &lt;code&gt;RRef&lt;/code&gt; has been confirmed by the owner. &lt;code&gt;OwnerRRef&lt;/code&gt; always returns true, while &lt;code&gt;UserRRef&lt;/code&gt; only returns true when the owner knowns about this &lt;code&gt;UserRRef&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0f5e59205b44dcceb0ac6759e21e032f1501bc8" translate="yes" xml:space="preserve">
          <source>Returns worker information of the node that owns this &lt;code&gt;RRef&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4edad2b2ca35229024c67f3f0d3bff7d93093b61" translate="yes" xml:space="preserve">
          <source>Returns worker name of the node that owns this &lt;code&gt;RRef&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7749fcf802c472b6c2f5bd0556805e456ffd5674" translate="yes" xml:space="preserve">
          <source>Returns:</source>
          <target state="translated">Returns:</target>
        </trans-unit>
        <trans-unit id="614439f097ad878a8635d81ef81858113ba66ffa" translate="yes" xml:space="preserve">
          <source>Returns: self</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63fbd9687bea5bf2237b15e3392da627d72bce65" translate="yes" xml:space="preserve">
          <source>Reverse the order of a n-D tensor along given axis in dims.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c79c0386989b48b4178b173f296df3e3c68180f2" translate="yes" xml:space="preserve">
          <source>Right now, this works only if the module is on the GPU and cuDNN is enabled. Otherwise, it&amp;rsquo;s a no-op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf85deb85c247cf504b5145a433d00570a94475a" translate="yes" xml:space="preserve">
          <source>Roll the tensor along the given dimension(s).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61764ff63ec4f189d73879d14b23769ece78814a" translate="yes" xml:space="preserve">
          <source>Roll the tensor along the given dimension(s). Elements that are shifted beyond the last position are re-introduced at the first position. If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f164f4fea8febd9cad272e82ab328161a3c6dcb" translate="yes" xml:space="preserve">
          <source>Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dfaeb09d713bebac16f06e9df8c867ae92ec360" translate="yes" xml:space="preserve">
          <source>Rotate a n-D tensor by 90 degrees in the plane specified by dims axis. Rotation direction is from the first towards the second axis if k &amp;gt; 0, and from the second towards the first for k &amp;lt; 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f997250f8d2d3174e19a84c2938437affe12ee1" translate="yes" xml:space="preserve">
          <source>Rule of thumb</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f35ba84a98c82f892526356da88061a3501723bb" translate="yes" xml:space="preserve">
          <source>Run it on the command line with</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="312956888e10f6c9efa0be100898714e9d49a550" translate="yes" xml:space="preserve">
          <source>Running a loaded model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5359eea6ab0e87db9479836bb9761e7ad6a157fe" translate="yes" xml:space="preserve">
          <source>Runtime characteristics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02aa629c8b16cd17a44f3a0efec2feed43937642" translate="yes" xml:space="preserve">
          <source>S</source>
          <target state="translated">S</target>
        </trans-unit>
        <trans-unit id="d7c8ea15b98297abf6f0c48aa6d1cd297394d77c" translate="yes" xml:space="preserve">
          <source>S ** 2 / (m - 1)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc71df7ac9f3ac27b7d12ac3903965de330de133" translate="yes" xml:space="preserve">
          <source>S = \text{max target length, if shape is } (N, S)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1678c8d5a5e1b27b84ba49edaa49f332453af05c" translate="yes" xml:space="preserve">
          <source>S=\text{num\_layers} * \text{num\_directions}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4cd3df709d03592b7820bf91be2a174166e078a" translate="yes" xml:space="preserve">
          <source>SELU</source>
          <target state="translated">SELU</target>
        </trans-unit>
        <trans-unit id="bad45f89fe2643171a9f0af482912ef53c58c8d3" translate="yes" xml:space="preserve">
          <source>SMART mode algorithm</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c798885ebfbe383227dbd5c2205277f8af9d524" translate="yes" xml:space="preserve">
          <source>SUM</source>
          <target state="translated">SUM</target>
        </trans-unit>
        <trans-unit id="2e4fbb0a9e252120bad1b2cf3ddef7f9a08b3c65" translate="yes" xml:space="preserve">
          <source>Same as &lt;a href=&quot;#torch.Tensor.narrow&quot;&gt;&lt;code&gt;Tensor.narrow()&lt;/code&gt;&lt;/a&gt; except returning a copy rather than shared storage. This is primarily for sparse tensors, which do not have a shared-storage narrow method. Calling &lt;code&gt;`narrow_copy&lt;/code&gt; with &lt;code&gt;`dimemsion &amp;gt; self.sparse_dim()`&lt;/code&gt; will return a copy with the relevant dense dimension narrowed, and &lt;code&gt;`self.shape`&lt;/code&gt; updated accordingly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f6402d6b42f6b20df7c7e5514d35048980475e" translate="yes" xml:space="preserve">
          <source>Sampled tensor of same shape as &lt;code&gt;logits&lt;/code&gt; from the Gumbel-Softmax distribution. If &lt;code&gt;hard=True&lt;/code&gt;, the returned samples will be one-hot, otherwise they will be probability distributions that sum to 1 across &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="870cb0523222c3bafa82fc03370a9998186a6c8a" translate="yes" xml:space="preserve">
          <source>Samples from the Gumbel-Softmax distribution (&lt;a href=&quot;https://arxiv.org/abs/1611.00712&quot;&gt;Link 1&lt;/a&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;Link 2&lt;/a&gt;) and optionally discretizes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb9c2993371e955a4cc850805ced703ca0a14469" translate="yes" xml:space="preserve">
          <source>Save an offline version of this module for use in a separate process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c01b4e6f82d950b9eb933dee7fd7ccb2a95a9e86" translate="yes" xml:space="preserve">
          <source>Save an offline version of this module for use in a separate process. The saved module serializes all of the methods, submodules, parameters, and attributes of this module. It can be loaded into the C++ API using &lt;code&gt;torch::jit::load(filename)&lt;/code&gt; or into the Python API with &lt;a href=&quot;torch.jit.load#torch.jit.load&quot;&gt;&lt;code&gt;torch.jit.load&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae2ed5816db3fac279ce9e6772770274eeecffb6" translate="yes" xml:space="preserve">
          <source>Saves an object to a disk file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="122590ee88a0a7371836192fc7f0f566864870ca" translate="yes" xml:space="preserve">
          <source>Say we have a model like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66da7860d1535f34a78cf5749db3d68876d558e1" translate="yes" xml:space="preserve">
          <source>Scatters a list of tensors to all processes in a group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8003f43b6ada6148476432121a9ade7662e59807" translate="yes" xml:space="preserve">
          <source>ScriptFunction</source>
          <target state="translated">ScriptFunction</target>
        </trans-unit>
        <trans-unit id="45d3892e0529a64b6123a79e03cc7e0f2432a98c" translate="yes" xml:space="preserve">
          <source>ScriptModule</source>
          <target state="translated">ScriptModule</target>
        </trans-unit>
        <trans-unit id="3fb95588d29ea3da9d0dc7585a2020bf65e56741" translate="yes" xml:space="preserve">
          <source>Scripted functions can call traced functions. This is particularly useful when you need to use control-flow around a simple feed-forward model. For instance the beam search of a sequence to sequence model will typically be written in script but can call an encoder module generated using tracing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="898752673b10b861d8ace49b60919a48cd4eac78" translate="yes" xml:space="preserve">
          <source>Scripting a function or &lt;code&gt;nn.Module&lt;/code&gt; will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af454137fb34eaadd60d3d10157722e0668fe3b2" translate="yes" xml:space="preserve">
          <source>Scripting a function or &lt;code&gt;nn.Module&lt;/code&gt; will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt;. TorchScript itself is a subset of the Python language, so not all features in Python work, but we provide enough functionality to compute on tensors and do control-dependent operations. For a complete guide, see the &lt;a href=&quot;../jit_language_reference#language-reference&quot;&gt;TorchScript Language Reference&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="033419356306d2d296e24d272874b31ebedcd66e" translate="yes" xml:space="preserve">
          <source>Scripting an &lt;code&gt;nn.Module&lt;/code&gt; by default will compile the &lt;code&gt;forward&lt;/code&gt; method and recursively compile any methods, submodules, and functions called by &lt;code&gt;forward&lt;/code&gt;. If a &lt;code&gt;nn.Module&lt;/code&gt; only uses features supported in TorchScript, no changes to the original module code should be necessary. &lt;code&gt;script&lt;/code&gt; will construct &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; that has copies of the attributes, parameters, and methods of the original module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b7757dc0bce246d1f7d37c65a1b7323d32d2496" translate="yes" xml:space="preserve">
          <source>Second, some operators will produce different values depending on whether or not they are coalesced or not (e.g., &lt;a href=&quot;#torch.sparse.FloatTensor._values&quot;&gt;&lt;code&gt;torch.sparse.FloatTensor._values()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.sparse.FloatTensor._indices&quot;&gt;&lt;code&gt;torch.sparse.FloatTensor._indices()&lt;/code&gt;&lt;/a&gt;, as well as &lt;a href=&quot;tensors#torch.Tensor.sparse_mask&quot;&gt;&lt;code&gt;torch.Tensor.sparse_mask()&lt;/code&gt;&lt;/a&gt;). These operators are prefixed by an underscore to indicate that they reveal internal implementation details and should be used with care, since code that works with coalesced sparse tensors may not work with uncoalesced sparse tensors; generally speaking, it is safest to explicitly coalesce before working with these operators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b6dced15fa8a0213a82f02ae1effe79ccf48d16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; for restrictions on tensor names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d23b93420a80f6bb1829feef82f05084851c1675" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.nn.quantized.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b27704ec42ef1503a1d419e6619ba79f9a13ebfb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.nn.quantized.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56a1d3982f38299aa1d9205f01ea00cd34354fef" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.nn.quantized.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4ccb661511817b74aa1b611837a5a3335536f1d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.utils.checkpoint.checkpoint&quot;&gt;&lt;code&gt;checkpoint()&lt;/code&gt;&lt;/a&gt; on how checkpointing works.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="592148f1f545aa4c74a139446df1dc46e1b6f5ca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#torch.utils.cpp_extension.load&quot;&gt;&lt;code&gt;load()&lt;/code&gt;&lt;/a&gt; for a description of arguments omitted below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd3e6f221b9ffca56a618c8ce4986b9d9a3b9a59" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#variable-resolution&quot;&gt;Variable Resolution&lt;/a&gt; for how variables are resolved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6663536c00122040c87a44bdc2b745caee1f1423" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../jit#inspecting-code&quot;&gt;Inspecting Code&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb8c27e43e09f15fd524c6c5a38cd014825e6c23" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../tensors#torch.Tensor.view&quot;&gt;&lt;code&gt;torch.Tensor.view()&lt;/code&gt;&lt;/a&gt; on when it is possible to return a view.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0410d55962a7fc08aaf5d7b12288cb6edf33cd4b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.abs#torch.abs&quot;&gt;&lt;code&gt;torch.abs()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ced4292c46e2d0f9084a0d4bbafd060bcaf8de87" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.acos#torch.acos&quot;&gt;&lt;code&gt;torch.acos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d557ccd80fb3258ddffbbb8174134a02d6cf179c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.acosh#torch.acosh&quot;&gt;&lt;code&gt;torch.acosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="789fcdc7d8a9ef51de9ddf2ef8954e307a7dd712" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.add#torch.add&quot;&gt;&lt;code&gt;torch.add()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37a8639e7cd42640a040dc7726bd5f806eb0bd35" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addbmm#torch.addbmm&quot;&gt;&lt;code&gt;torch.addbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d031d4e4498ba97f52d6d80a33dad228fb9f2cbe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addcdiv#torch.addcdiv&quot;&gt;&lt;code&gt;torch.addcdiv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="565ec468f6c035b17c0ac0bb82ee2cbcd8edaca7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addcmul#torch.addcmul&quot;&gt;&lt;code&gt;torch.addcmul()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2d04f2a20233d7e081134dcc2710d272865025a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addmm#torch.addmm&quot;&gt;&lt;code&gt;torch.addmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbb6e45db46d337e88fb01997ddfd0d38b1e36e5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addmv#torch.addmv&quot;&gt;&lt;code&gt;torch.addmv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0415452e192f39adc1dfb989387d7c4f3dd04593" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.addr#torch.addr&quot;&gt;&lt;code&gt;torch.addr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7040368b881cece8154506daeab47e7b26bc4465" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.allclose#torch.allclose&quot;&gt;&lt;code&gt;torch.allclose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5b8be1187577d5e5a0b32510f1f32129626cca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.amax#torch.amax&quot;&gt;&lt;code&gt;torch.amax()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bac9b8922811f35c234bf464a4494dbef74933b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.amin#torch.amin&quot;&gt;&lt;code&gt;torch.amin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5518b7da2603866919ecc93573fb7693cbe1d28" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.angle#torch.angle&quot;&gt;&lt;code&gt;torch.angle()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d6f36d28f663492799df5b5fcb97f2c82893849" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arccos#torch.arccos&quot;&gt;&lt;code&gt;torch.arccos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95b1cd872f49253eed8e157b208ed8426d2a08f0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arccosh#torch.arccosh&quot;&gt;&lt;code&gt;torch.arccosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20d7592e91b8ac1020ec98e06fb5bdf07f1891bc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arcsin#torch.arcsin&quot;&gt;&lt;code&gt;torch.arcsin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92063535c0e36748fc07d3768b27df3f9db98d33" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arcsinh#torch.arcsinh&quot;&gt;&lt;code&gt;torch.arcsinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f471a52f4701848a5c13052260382f54ba5f2bf2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arctan#torch.arctan&quot;&gt;&lt;code&gt;torch.arctan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6352e358921d4176f31796abd8e2e1d94c2c4807" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.arctanh#torch.arctanh&quot;&gt;&lt;code&gt;torch.arctanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a3005660e169df440b195c1013e466fc0dc0f85" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.argmax#torch.argmax&quot;&gt;&lt;code&gt;torch.argmax()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9336c76dce7b82519130c38591a8f4bc511802b3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.argmin#torch.argmin&quot;&gt;&lt;code&gt;torch.argmin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8db3f6696a6f968e7692af8c5ef5b20e20027f77" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.argsort#torch.argsort&quot;&gt;&lt;code&gt;torch.argsort()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a2ff963efa23ea4ed3e29949ad7d7c3a624603f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.as_strided#torch.as_strided&quot;&gt;&lt;code&gt;torch.as_strided()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="885b7e053cac4178633ab2cdae8c61527522af3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.asin#torch.asin&quot;&gt;&lt;code&gt;torch.asin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b825056a4e3742071a4388ba1c9dd880e2f684d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.asinh#torch.asinh&quot;&gt;&lt;code&gt;torch.asinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85ed8161a1e7cf3d498c0e025910cad264dbb99e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.atan#torch.atan&quot;&gt;&lt;code&gt;torch.atan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c4e94754d2f650204d6da4aafe2bedeb278399d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.atan2#torch.atan2&quot;&gt;&lt;code&gt;torch.atan2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed04a790c582bea4569ce9ba2a1f5fb49e96591b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.atanh#torch.atanh&quot;&gt;&lt;code&gt;torch.atanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f172a9267504e77b4582e306093325cd390dbe6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.baddbmm#torch.baddbmm&quot;&gt;&lt;code&gt;torch.baddbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ee51350ddf5c14b20523cca547052313b6da137" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bernoulli#torch.bernoulli&quot;&gt;&lt;code&gt;torch.bernoulli()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa6bd5fd2fc0d4cbf209b32b685dcd15549e17a1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bincount#torch.bincount&quot;&gt;&lt;code&gt;torch.bincount()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1330e38a3bff864a896452adaef91e316142ee7a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_and#torch.bitwise_and&quot;&gt;&lt;code&gt;torch.bitwise_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b232e0fb96bd322c2458574164c04bbfc68e696b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_not#torch.bitwise_not&quot;&gt;&lt;code&gt;torch.bitwise_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49bd1ecf94a298ed7136ddaa7b129d79af6f4f58" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_or#torch.bitwise_or&quot;&gt;&lt;code&gt;torch.bitwise_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74f2dbe9a2909c1557b61d4ca27fc1dfa0ee2a38" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bitwise_xor#torch.bitwise_xor&quot;&gt;&lt;code&gt;torch.bitwise_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50e2d514fed6ae782003300fa73df0e3bb831323" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.bmm#torch.bmm&quot;&gt;&lt;code&gt;torch.bmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c1407ae846f94e16c4554a9aed2a962bd7d5b41" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ceil#torch.ceil&quot;&gt;&lt;code&gt;torch.ceil()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ee9005d9f7612dda3673351dab212c7597eacf9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cholesky#torch.cholesky&quot;&gt;&lt;code&gt;torch.cholesky()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9234f12a7920c48c92b0b92789cbf7f520e6cce2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cholesky_inverse#torch.cholesky_inverse&quot;&gt;&lt;code&gt;torch.cholesky_inverse()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95412d4a68f7be2f448d2f6abdef3ba1039693ce" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cholesky_solve#torch.cholesky_solve&quot;&gt;&lt;code&gt;torch.cholesky_solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70d52135d5fe5109fdf4b68140efc30ed3ff15ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.chunk#torch.chunk&quot;&gt;&lt;code&gt;torch.chunk()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d2a8fa141c274f1ecc888c9dee97f508028c310" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.clamp#torch.clamp&quot;&gt;&lt;code&gt;torch.clamp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db643765ea3bdabe789a609a784f6f21e8b15ff6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.clone#torch.clone&quot;&gt;&lt;code&gt;torch.clone()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c5dee157b17c3fc64e10f3c111962a223627009" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.conj#torch.conj&quot;&gt;&lt;code&gt;torch.conj()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00b6992059c4a2ecf9c5ba83b4b4d6367e100b3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cos#torch.cos&quot;&gt;&lt;code&gt;torch.cos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f760d7b54a866c270d1f4f0fee69afc86260ce1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cosh#torch.cosh&quot;&gt;&lt;code&gt;torch.cosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e6ca2ba899e5a5ed0308b11c6dec0f921c1c386" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.count_nonzero#torch.count_nonzero&quot;&gt;&lt;code&gt;torch.count_nonzero()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3154a66df758bedd23c1ca8d445818980c877056" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cross#torch.cross&quot;&gt;&lt;code&gt;torch.cross()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c33b1f8ea95f5374185b2beef8bdc0333006ca40" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cummax#torch.cummax&quot;&gt;&lt;code&gt;torch.cummax()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7a6c4b7502006ffffe7f61bc361df0a8f5c3485" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cummin#torch.cummin&quot;&gt;&lt;code&gt;torch.cummin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="175fd7991a76a77d1e7947c94b32c3900db2a22a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cumprod#torch.cumprod&quot;&gt;&lt;code&gt;torch.cumprod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecda9d651f57ce0a80f553759df7118f9fc98f17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.cumsum#torch.cumsum&quot;&gt;&lt;code&gt;torch.cumsum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4c2bb557dabd8b8d6424a1086a8f0e49082dcc1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.deg2rad#torch.deg2rad&quot;&gt;&lt;code&gt;torch.deg2rad()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74fe8f78b0f15bbe31849b729e7353cfc88dda04" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.det#torch.det&quot;&gt;&lt;code&gt;torch.det()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87d829bc645704d604ad02215c0bb4c96717d9da" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diag#torch.diag&quot;&gt;&lt;code&gt;torch.diag()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d17eea2fe4310acb0e6689f3868245d146ae748a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diag_embed#torch.diag_embed&quot;&gt;&lt;code&gt;torch.diag_embed()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07ddff47af47155cb8195d49fd74ab5f110f0de6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diagflat#torch.diagflat&quot;&gt;&lt;code&gt;torch.diagflat()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9871639ca6ca069867ff9833f0d0bad21e81d3f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;torch.diagonal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd7c0b43d807db12fbff5fc78c8898e1347cf1a1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.digamma#torch.digamma&quot;&gt;&lt;code&gt;torch.digamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec5b576fe8744daae4dc7030555211156b888d46" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.dist#torch.dist&quot;&gt;&lt;code&gt;torch.dist()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ab62666946a8333d7379a60a2d1d9d3ae225fa2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.div#torch.div&quot;&gt;&lt;code&gt;torch.div()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cfd78ad9784ac679c7a2b9b5bca896325ba89a4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.divide#torch.divide&quot;&gt;&lt;code&gt;torch.divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="593f13a108fe5ed0675dcd7c508f6c35b99b0b10" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.dot#torch.dot&quot;&gt;&lt;code&gt;torch.dot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59a8ed7a18a443621255817cd4ad0bf4a0e632ca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.eig#torch.eig&quot;&gt;&lt;code&gt;torch.eig()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ab6c51079e17cb89630c1e4a91f1d3454d90b6f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.eq#torch.eq&quot;&gt;&lt;code&gt;torch.eq()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4813e89ec9293f99dfa5025547b461fb432f69d3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.equal#torch.equal&quot;&gt;&lt;code&gt;torch.equal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f7360444c9397fc1d5c5b1bc067d9af3c6e9edd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.erf#torch.erf&quot;&gt;&lt;code&gt;torch.erf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08fb634ad4f6c40b3935c0b3378501a7339f8fbe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.erfc#torch.erfc&quot;&gt;&lt;code&gt;torch.erfc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bd6c425dc9b646c2b2bed4edf1c5a988917c21f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.erfinv#torch.erfinv&quot;&gt;&lt;code&gt;torch.erfinv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad29dad56d468c778a3c249cc44c87db316a44e6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.exp#torch.exp&quot;&gt;&lt;code&gt;torch.exp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b6fbfd00b7b75b48f9ccfcacaa40ee11ef98750" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.expm1#torch.expm1&quot;&gt;&lt;code&gt;torch.expm1()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bbb47f4968cd75aa8ca7739f121cb837ee30c39" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fft#torch.fft&quot;&gt;&lt;code&gt;torch.fft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9a77b8be814999a1e18a3bcfe6fdc2b3f1b3bf0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fix#torch.fix&quot;&gt;&lt;code&gt;torch.fix()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aad979493ad2ea8c7660622a96be7811d0a81b87" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.flip#torch.flip&quot;&gt;&lt;code&gt;torch.flip()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bad831a531ebee9d67a2612a1d0e6978cc7ed27b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fliplr#torch.fliplr&quot;&gt;&lt;code&gt;torch.fliplr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87f6a8078b8a3f6f5a4247460381f4e94549ef39" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.flipud#torch.flipud&quot;&gt;&lt;code&gt;torch.flipud()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="399317938ad3be99c06e85c37e27d75701458b99" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.floor#torch.floor&quot;&gt;&lt;code&gt;torch.floor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcdf651ea00fbe14dab01c29ec405b9ced982377" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.floor_divide#torch.floor_divide&quot;&gt;&lt;code&gt;torch.floor_divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2efd0d46fdaf4a4f7fc46d9063330efa363c69ce" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.fmod#torch.fmod&quot;&gt;&lt;code&gt;torch.fmod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb5589e94e3540a14e8e7b3fac4f8fdf408c5f2f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.frac#torch.frac&quot;&gt;&lt;code&gt;torch.frac()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe3455e99f31e058dbdc692b113c1359d89488d7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.gather#torch.gather&quot;&gt;&lt;code&gt;torch.gather()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5d4ce8f33e2308a786a65897ca2b53b361ed230" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.gcd#torch.gcd&quot;&gt;&lt;code&gt;torch.gcd()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47e2863133f746b04949765203596816d2a569fd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ge#torch.ge&quot;&gt;&lt;code&gt;torch.ge()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc3905a5552f33afb11f303bb93b1f92da393e87" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0f396c7008d561476ffb59f26b17018bc84fa73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ger#torch.ger&quot;&gt;&lt;code&gt;torch.ger()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29a71ad0e5b1620b27e713b79b570ee4a9882fbd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.greater#torch.greater&quot;&gt;&lt;code&gt;torch.greater()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aa63e3e1cb9df927bb8622309466c088861e7c1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.greater_equal#torch.greater_equal&quot;&gt;&lt;code&gt;torch.greater_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22d16c3e505067a772ddee47e68d0c5e9efdf1ea" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.gt#torch.gt&quot;&gt;&lt;code&gt;torch.gt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f797b96d9a976433ee5e82f85c212bf9cc6c07aa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.heaviside#torch.heaviside&quot;&gt;&lt;code&gt;torch.heaviside()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4c88cbc91c3b48e1204ec2fc29b766aaa6e3c59" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.histc#torch.histc&quot;&gt;&lt;code&gt;torch.histc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f24053f673f97bf0cebaec0ddd1ab96fa9d420f2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.hypot#torch.hypot&quot;&gt;&lt;code&gt;torch.hypot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a27de95d9ce95538faa35bfb5a5044535b471e7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.i0#torch.i0&quot;&gt;&lt;code&gt;torch.i0()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55baf0c2297883aeca1f8032e140f1dce62c7f54" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ifft#torch.ifft&quot;&gt;&lt;code&gt;torch.ifft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbd53ee94265f26254d53b09c2158dbdc7c06b75" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.index_select#torch.index_select&quot;&gt;&lt;code&gt;torch.index_select()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91cb515b356d2c52d4004829619ffcf0284a140c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.inverse#torch.inverse&quot;&gt;&lt;code&gt;torch.inverse()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1921c02b416a3c35ca9a7616e742bedc37f85261" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.irfft#torch.irfft&quot;&gt;&lt;code&gt;torch.irfft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a61d72d732d7b3d2bfcfab031758abf3bd3f2bf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isclose#torch.isclose&quot;&gt;&lt;code&gt;torch.isclose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d43646aed73f0e63bb4282297ddeb0953661084" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isfinite#torch.isfinite&quot;&gt;&lt;code&gt;torch.isfinite()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f01c4969936eb94939bfba08517f9dc5d3c9b65" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isinf#torch.isinf&quot;&gt;&lt;code&gt;torch.isinf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c15049f87e6457b76bc4c833aad4e86fc330a9a4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isnan#torch.isnan&quot;&gt;&lt;code&gt;torch.isnan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0c99b8516b26410ede0975c9d5e8303e6a56d72" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isneginf#torch.isneginf&quot;&gt;&lt;code&gt;torch.isneginf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c45c9bc98276b87a137a720f4ab4cbfc8bccf9d9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isposinf#torch.isposinf&quot;&gt;&lt;code&gt;torch.isposinf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bff4ba1100e12cf9a28654669a565681a03dd913" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.isreal#torch.isreal&quot;&gt;&lt;code&gt;torch.isreal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcf71e098da4b8c28d983651980d01f5b1a6049b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.istft#torch.istft&quot;&gt;&lt;code&gt;torch.istft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f606579981b49ec0a8206d550a759168fd92964" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.kthvalue#torch.kthvalue&quot;&gt;&lt;code&gt;torch.kthvalue()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d8ba07cef0e3cd2ee953932e7401cfd0248e444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lcm#torch.lcm&quot;&gt;&lt;code&gt;torch.lcm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6699a864923ddee28ba56b38069aaab083349df" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.le#torch.le&quot;&gt;&lt;code&gt;torch.le()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32c678d238915a61f701966540f011fe2fc9cbc1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lerp#torch.lerp&quot;&gt;&lt;code&gt;torch.lerp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1d6db8a3f3362c5bfd61e84e72244e0ee6bf8e9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.less#torch.less&quot;&gt;&lt;code&gt;torch.less()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8eea9085bfaff6760dd93361241db5a26d61c2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.less_equal#torch.less_equal&quot;&gt;&lt;code&gt;torch.less_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cd2d05d4cdb6e340422b7b49a0f18ef4af47558" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lgamma#torch.lgamma&quot;&gt;&lt;code&gt;torch.lgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7caa6f91635bb60ab80ed9ca2541683e873e5da4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log#torch.log&quot;&gt;&lt;code&gt;torch.log()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73a23f7411ea79d1413155727db906f0562b2082" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log10#torch.log10&quot;&gt;&lt;code&gt;torch.log10()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8dc5bc392cc9737d55c7a288ffae377a0f80b8e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log1p#torch.log1p&quot;&gt;&lt;code&gt;torch.log1p()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b442c9296b5b51dc12a6d62a9e946bae4e4cace4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.log2#torch.log2&quot;&gt;&lt;code&gt;torch.log2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82580a23e0c28a78662f5e93ee563089d4043db8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logaddexp#torch.logaddexp&quot;&gt;&lt;code&gt;torch.logaddexp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7856ea9cc5c5b34b3fad25b3ceb90619e2bcf1a1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logaddexp2#torch.logaddexp2&quot;&gt;&lt;code&gt;torch.logaddexp2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d244fcdaec339fa07bf0c8b02d8e5206a3756511" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logcumsumexp#torch.logcumsumexp&quot;&gt;&lt;code&gt;torch.logcumsumexp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e64767e412c54452d0e93a4095d3fb5a34e4a87d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logdet#torch.logdet&quot;&gt;&lt;code&gt;torch.logdet()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dae45426090891d1953ee3ad38c045f8a0fceedc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_and#torch.logical_and&quot;&gt;&lt;code&gt;torch.logical_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d20544f0f1149d37dc67d5b4c2ec2fcf87602aaf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_not#torch.logical_not&quot;&gt;&lt;code&gt;torch.logical_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f1dd2cde87434261bce6932056bcd2beea83bc0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_or#torch.logical_or&quot;&gt;&lt;code&gt;torch.logical_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64c77ca5d503f49a2495909f4b01e01b4e55a15f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logical_xor#torch.logical_xor&quot;&gt;&lt;code&gt;torch.logical_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9fec990c19512cd7cbc5c7730d590537da8787a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logit#torch.logit&quot;&gt;&lt;code&gt;torch.logit()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7682310645eb1b3d8a10df47deccb4b498fc4809" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.logsumexp#torch.logsumexp&quot;&gt;&lt;code&gt;torch.logsumexp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f577c3338ec6045533458e8c6be36ac9572aed9e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lstsq#torch.lstsq&quot;&gt;&lt;code&gt;torch.lstsq()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e411f1ff349b11bfd836c08df5971026b855e59a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lt#torch.lt&quot;&gt;&lt;code&gt;torch.lt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="578639cb9fc16b15aa6b7e1967466fe9b09ff42d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lu#torch.lu&quot;&gt;&lt;code&gt;torch.lu()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c96a4514c11416811fe9f9b86d4dd2e1d0e4e1cd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.lu_solve#torch.lu_solve&quot;&gt;&lt;code&gt;torch.lu_solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c6b2883c1c8d2d0de37ea2c95e5b1fa94069b4d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.masked_select#torch.masked_select&quot;&gt;&lt;code&gt;torch.masked_select()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4dc4224536b289cdb91dd6eb3b784c8632062f7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.matmul#torch.matmul&quot;&gt;&lt;code&gt;torch.matmul()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18b30626e1ae4fc77dd2baf1eea08d60901e4a44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.matrix_exp#torch.matrix_exp&quot;&gt;&lt;code&gt;torch.matrix_exp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ceb6fc4ba32f1c6513652ba41e7ed5365209b9d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.matrix_power#torch.matrix_power&quot;&gt;&lt;code&gt;torch.matrix_power()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3d3a41458bccec6e7e87d98e4ad75ec5c4237fb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.max#torch.max&quot;&gt;&lt;code&gt;torch.max()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="689831f5600395b5cce9e382345788eac42fd2b3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.maximum#torch.maximum&quot;&gt;&lt;code&gt;torch.maximum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75cde60dd542a6062dc76781c6f95cef4726b299" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mean#torch.mean&quot;&gt;&lt;code&gt;torch.mean()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="106c7cf7d53f462e1efa14592e3a206e193353ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.median#torch.median&quot;&gt;&lt;code&gt;torch.median()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45e4b29591dc1fd5fe60cf3f1a2528339eb79d7a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.min#torch.min&quot;&gt;&lt;code&gt;torch.min()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71ff8dd28d5ec4bba7fa90d123381bf318d57316" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.minimum#torch.minimum&quot;&gt;&lt;code&gt;torch.minimum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f88fe431125507817f53eadcab5b7cf0486d3c3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mm#torch.mm&quot;&gt;&lt;code&gt;torch.mm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89a5d4426d8c3c83f76b02d2a04a8fa74cd9c984" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mode#torch.mode&quot;&gt;&lt;code&gt;torch.mode()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="480d2c05ebbc86790a491b5029a1882724ab97f9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.movedim#torch.movedim&quot;&gt;&lt;code&gt;torch.movedim()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e47d65e128408a5146c2909f05667f8df18f4de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mul#torch.mul&quot;&gt;&lt;code&gt;torch.mul()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="346834db1e953738900b156dccde72730c321179" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.multinomial#torch.multinomial&quot;&gt;&lt;code&gt;torch.multinomial()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2abc253dc35a3f16344ec6f7c0d4b4f3f6f389c0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.multiply#torch.multiply&quot;&gt;&lt;code&gt;torch.multiply()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd83a3f33cb0434d70d1281178c10f4d4186288c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mv#torch.mv&quot;&gt;&lt;code&gt;torch.mv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7ada1c677f5eab787ec7f543df6913243851e42" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.mvlgamma#torch.mvlgamma&quot;&gt;&lt;code&gt;torch.mvlgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96ec4016de71e2ca1618c82409f4cbcb9c612e86" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nanquantile#torch.nanquantile&quot;&gt;&lt;code&gt;torch.nanquantile()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eda1f1134fb78245db2a5b46d9c8dcff19e60476" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nansum#torch.nansum&quot;&gt;&lt;code&gt;torch.nansum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aaeb0cd2a053ef536d53c256571aadbdbf969ca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.narrow#torch.narrow&quot;&gt;&lt;code&gt;torch.narrow()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32b6bd21755f0280c169e12a964b6d0d8f9f944d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ne#torch.ne&quot;&gt;&lt;code&gt;torch.ne()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef00c00cfc229955de1af61e47329e20da955299" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.neg#torch.neg&quot;&gt;&lt;code&gt;torch.neg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c59bed38407778d4b3b65157e276bcba44fa481e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.negative#torch.negative&quot;&gt;&lt;code&gt;torch.negative()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab18f54431cb99ac38d5579314003713c8aef19f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nextafter#torch.nextafter&quot;&gt;&lt;code&gt;torch.nextafter()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="211dc318b0ac18e597f00d3389f89e2fa69af8fd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptiveavgpool1d#torch.nn.AdaptiveAvgPool1d&quot;&gt;&lt;code&gt;AdaptiveAvgPool1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c297648804959d7e566eb6462302a062556e0a26" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptiveavgpool2d#torch.nn.AdaptiveAvgPool2d&quot;&gt;&lt;code&gt;AdaptiveAvgPool2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e3e0fe3b85f801c746e8e3435b99b12af2758cb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptiveavgpool3d#torch.nn.AdaptiveAvgPool3d&quot;&gt;&lt;code&gt;AdaptiveAvgPool3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcb4c522bcd653244a2b0e212d2a6c1dec943575" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptivemaxpool1d#torch.nn.AdaptiveMaxPool1d&quot;&gt;&lt;code&gt;AdaptiveMaxPool1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9197dd28b388a9ad018e4140bcb03f05bef22fce" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptivemaxpool2d#torch.nn.AdaptiveMaxPool2d&quot;&gt;&lt;code&gt;AdaptiveMaxPool2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="671fa746ed1d96f6e5c409933c093bf281ece232" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.adaptivemaxpool3d#torch.nn.AdaptiveMaxPool3d&quot;&gt;&lt;code&gt;AdaptiveMaxPool3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06fcc12676bdce703006b9934a46a5d88c4ea69e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.alphadropout#torch.nn.AlphaDropout&quot;&gt;&lt;code&gt;AlphaDropout&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="299a82bba9fc9f3c48bfd00d90ea771941bb3509" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.avgpool1d#torch.nn.AvgPool1d&quot;&gt;&lt;code&gt;AvgPool1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e431c47012b760f030d5cd2cfeebdfaaa73e3a4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.avgpool2d#torch.nn.AvgPool2d&quot;&gt;&lt;code&gt;AvgPool2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d5e8ddb26e145fc6c6ccd8ea827c9249bd3e2c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.avgpool3d#torch.nn.AvgPool3d&quot;&gt;&lt;code&gt;AvgPool3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2f2febc074ac5ab0c26eb12dab1477a725d346c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.batchnorm1d#torch.nn.BatchNorm1d&quot;&gt;&lt;code&gt;BatchNorm1d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;BatchNorm2d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.batchnorm3d#torch.nn.BatchNorm3d&quot;&gt;&lt;code&gt;BatchNorm3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49181f1a5d0f855f350c509add5501b487b8de9a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.bceloss#torch.nn.BCELoss&quot;&gt;&lt;code&gt;BCELoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9b2acc69b3141658463c5b48ed119f653d953fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.bcewithlogitsloss#torch.nn.BCEWithLogitsLoss&quot;&gt;&lt;code&gt;BCEWithLogitsLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e05c2119de76670ff15f68392d6126a185752ff" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.celu#torch.nn.CELU&quot;&gt;&lt;code&gt;CELU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46a2836ec87b23dd081f1f557c9d269b806abf39" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.constantpad2d#torch.nn.ConstantPad2d&quot;&gt;&lt;code&gt;torch.nn.ConstantPad2d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.reflectionpad2d#torch.nn.ReflectionPad2d&quot;&gt;&lt;code&gt;torch.nn.ReflectionPad2d&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/torch.nn.replicationpad2d#torch.nn.ReplicationPad2d&quot;&gt;&lt;code&gt;torch.nn.ReplicationPad2d&lt;/code&gt;&lt;/a&gt; for concrete examples on how each of the padding modes works. Constant padding is implemented for arbitrary dimensions. Replicate padding is implemented for padding the last 3 dimensions of 5D input tensor, or the last 2 dimensions of 4D input tensor, or the last dimension of 3D input tensor. Reflect padding is only implemented for padding the last 2 dimensions of 4D input tensor, or the last dimension of 3D input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92e4bf1e1580e8ab1c867f9318919922f5d69097" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb3d45384af0f65dcc256fd4e526a226237028c3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; for other attributes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d1d57fe3bdff062ac6991806c22d029393fd38a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d165cb34672d664f9dd17ceb8fa4d5cf8092ba2a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; for other attributes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62b640305a360b502c1c6f7e2a7cc59219562d5b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="827a3d0d159d0163f089c1b8b07697a3b4d204b1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; for other attributes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c6215c6031dbc3057e738f03ebc6ccb657c175c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.convtranspose1d#torch.nn.ConvTranspose1d&quot;&gt;&lt;code&gt;ConvTranspose1d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92a07f307c29825975eb91630c55dc6f1ef73449" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.convtranspose2d#torch.nn.ConvTranspose2d&quot;&gt;&lt;code&gt;ConvTranspose2d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26d37ceb58b322f40fdbdfcf86ed7b27d34f3ea4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.convtranspose3d#torch.nn.ConvTranspose3d&quot;&gt;&lt;code&gt;ConvTranspose3d&lt;/code&gt;&lt;/a&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ecbef13440cb7e3c72978fb3f953d0ea4a05dec" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.cosineembeddingloss#torch.nn.CosineEmbeddingLoss&quot;&gt;&lt;code&gt;CosineEmbeddingLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07cebd07469d5659a87059395414105b3f0a54c1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.crossentropyloss#torch.nn.CrossEntropyLoss&quot;&gt;&lt;code&gt;CrossEntropyLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed9307322caa5510dafcec4ab6a6439e46cca0ac" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.ctcloss#torch.nn.CTCLoss&quot;&gt;&lt;code&gt;CTCLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90c67074e8fb1e5903e2b6ceed293a19589c2504" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.dropout#torch.nn.Dropout&quot;&gt;&lt;code&gt;Dropout&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b5e6bf0d87dc5eedbd14a70bf17165953b58726" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.dropout2d#torch.nn.Dropout2d&quot;&gt;&lt;code&gt;Dropout2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9181ef4cdcda4e21d4c1d578bf817479c3e73473" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.dropout3d#torch.nn.Dropout3d&quot;&gt;&lt;code&gt;Dropout3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9638040580d53d7a62b5948dfef978c66524b9c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.elu#torch.nn.ELU&quot;&gt;&lt;code&gt;ELU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9516b3d99ccc49e5403a54c4cd4186fa2ebff368" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt;&lt;code&gt;torch.nn.Embedding&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0ef85f5e373bd3344bdb431e1a684be4a2c111f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.embeddingbag#torch.nn.EmbeddingBag&quot;&gt;&lt;code&gt;torch.nn.EmbeddingBag&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87b8eae451b415ea1f7e39fa3cca366d80225aa8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.fold#torch.nn.Fold&quot;&gt;&lt;code&gt;torch.nn.Fold&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3f647c2cb1152f6be057eaec2f333adc27b7848" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hardshrink#torch.nn.Hardshrink&quot;&gt;&lt;code&gt;Hardshrink&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e54bc653f24897904f35291d48d7a4d3e1b15dd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hardsigmoid#torch.nn.Hardsigmoid&quot;&gt;&lt;code&gt;Hardsigmoid&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d8089dc9fcfe5932254ec4b47d12c1cbe02d107" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hardswish#torch.nn.Hardswish&quot;&gt;&lt;code&gt;Hardswish&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79e7f193eb69518b7c2bc43975107d6c9f8a543d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.hingeembeddingloss#torch.nn.HingeEmbeddingLoss&quot;&gt;&lt;code&gt;HingeEmbeddingLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a07f37d494d50f907a7a0be59a0004e665fc42f6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.instancenorm1d#torch.nn.InstanceNorm1d&quot;&gt;&lt;code&gt;InstanceNorm1d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.instancenorm2d#torch.nn.InstanceNorm2d&quot;&gt;&lt;code&gt;InstanceNorm2d&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.nn.instancenorm3d#torch.nn.InstanceNorm3d&quot;&gt;&lt;code&gt;InstanceNorm3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc584ec8326a5572f69ad2a713d36f3294777bbf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.kldivloss#torch.nn.KLDivLoss&quot;&gt;&lt;code&gt;KLDivLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82170e2aa45b79e0abc6968e9d7a135946023f5a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.l1loss#torch.nn.L1Loss&quot;&gt;&lt;code&gt;L1Loss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d19657b2b5b68544134330ee366c7bfea1457eb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bef43e82a39e507cbf89ef28c4b26fd78760fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.leakyrelu#torch.nn.LeakyReLU&quot;&gt;&lt;code&gt;LeakyReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2764126c51f5530622c4b4e091ebc79776ade07c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.localresponsenorm#torch.nn.LocalResponseNorm&quot;&gt;&lt;code&gt;LocalResponseNorm&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e31635636f40648e7e735d06a4392b7cebd2b258" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.logsigmoid#torch.nn.LogSigmoid&quot;&gt;&lt;code&gt;LogSigmoid&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="412a8150cd54d51d6530e2d245b63346bf33130a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.logsoftmax#torch.nn.LogSoftmax&quot;&gt;&lt;code&gt;LogSoftmax&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f565430e626357bd4afefcb8e556e2cb25e9480" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.lppool1d#torch.nn.LPPool1d&quot;&gt;&lt;code&gt;LPPool1d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35b0452fd507c2aa91e1da43aa355009dc166d13" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.lppool2d#torch.nn.LPPool2d&quot;&gt;&lt;code&gt;LPPool2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cbda61d0da4455a2876aa2b87f22199f2f1cdb3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.marginrankingloss#torch.nn.MarginRankingLoss&quot;&gt;&lt;code&gt;MarginRankingLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="898e6a57e299ae9b57ccd5993abb1ef8bd55140b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxpool1d#torch.nn.MaxPool1d&quot;&gt;&lt;code&gt;MaxPool1d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0dc529ce91ee71820fbf1ed9bed0661ddc036f6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxpool2d#torch.nn.MaxPool2d&quot;&gt;&lt;code&gt;MaxPool2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6be4f2f66ae6f0a242da37cad7e7f70f4a8e328" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt;&lt;code&gt;MaxPool3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5de0ae10e2d087fd9d49043502233c22cd7d1ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxunpool1d#torch.nn.MaxUnpool1d&quot;&gt;&lt;code&gt;MaxUnpool1d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06bc4bd975e3b0441df74b337a9e03841cdc0854" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxunpool2d#torch.nn.MaxUnpool2d&quot;&gt;&lt;code&gt;MaxUnpool2d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be3c23907ec483dcbebdd45f57208e45ff569446" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.maxunpool3d#torch.nn.MaxUnpool3d&quot;&gt;&lt;code&gt;MaxUnpool3d&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="787cf804e853557c82df78674a398c819b20b9c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.mseloss#torch.nn.MSELoss&quot;&gt;&lt;code&gt;MSELoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01976be184fbec1b413106ad9e281456840b581b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.multilabelmarginloss#torch.nn.MultiLabelMarginLoss&quot;&gt;&lt;code&gt;MultiLabelMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7aa5a41923f45ec7053a3fcb00c51f4757953233" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.multilabelsoftmarginloss#torch.nn.MultiLabelSoftMarginLoss&quot;&gt;&lt;code&gt;MultiLabelSoftMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1b726bdc0737f6680b51d100e20056a744ff1e6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.multimarginloss#torch.nn.MultiMarginLoss&quot;&gt;&lt;code&gt;MultiMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="729c99354cfb624e609e3f72dffceaad9cd0847c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.nllloss#torch.nn.NLLLoss&quot;&gt;&lt;code&gt;NLLLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ee9817c275d3255a1242d0c82f69825ae4ec439" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.pairwisedistance#torch.nn.PairwiseDistance&quot;&gt;&lt;code&gt;torch.nn.PairwiseDistance&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="100c5c298a4adf254a044824d7e8f1c566ed72d4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.pixelshuffle#torch.nn.PixelShuffle&quot;&gt;&lt;code&gt;PixelShuffle&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62b7addc0514a1405a79ca49e242813d820bc663" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.poissonnllloss#torch.nn.PoissonNLLLoss&quot;&gt;&lt;code&gt;PoissonNLLLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50b2df5a36c2945c6e24d5c71f419748722a3887" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.prelu#torch.nn.PReLU&quot;&gt;&lt;code&gt;PReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5978d8e05fcfe3f5b05baa41628058a1104f3a4e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.relu6#torch.nn.ReLU6&quot;&gt;&lt;code&gt;ReLU6&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f52859f67be89a0431749df85025dfa79a6a4c5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.rrelu#torch.nn.RReLU&quot;&gt;&lt;code&gt;RReLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="852d4ca82259db7394eed56f5e5c7736dab64bcf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.selu#torch.nn.SELU&quot;&gt;&lt;code&gt;SELU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13f47034bf13462a634f77a02e2bd8afda50269b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.sigmoid#torch.nn.Sigmoid&quot;&gt;&lt;code&gt;Sigmoid&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="568ac6254f20261c85c9d016122513b35b9c681e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.silu#torch.nn.SiLU&quot;&gt;&lt;code&gt;SiLU&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd919bcb7cd8684a3301f3776235810cef864477" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.smoothl1loss#torch.nn.SmoothL1Loss&quot;&gt;&lt;code&gt;SmoothL1Loss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aec2f6e607f94f542eec97b84c6a6b548899b489" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softmarginloss#torch.nn.SoftMarginLoss&quot;&gt;&lt;code&gt;SoftMarginLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c76fd9ca241b6dc4f7f601122680872738372dd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softmax#torch.nn.Softmax&quot;&gt;&lt;code&gt;Softmax&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6858b7405b4fb52e94900af334a9f8d7d36cdcef" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softmin#torch.nn.Softmin&quot;&gt;&lt;code&gt;Softmin&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3078ba39159561c5fdab61a5073beb5e6d358df8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softplus#torch.nn.Softplus&quot;&gt;&lt;code&gt;Softplus&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="169ff197b89985d58ad2ce1e9b54fb8b6c45231c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softshrink#torch.nn.Softshrink&quot;&gt;&lt;code&gt;Softshrink&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdc172b1efd10ce5727c58366e9d3635597d6ae5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.softsign#torch.nn.Softsign&quot;&gt;&lt;code&gt;Softsign&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29958016ecc903cab7fa7360e164fabacfbf9cca" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tanh#torch.nn.Tanh&quot;&gt;&lt;code&gt;Tanh&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a254e517f98f621d085febfde8c38a66e6d36e75" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tanhshrink#torch.nn.Tanhshrink&quot;&gt;&lt;code&gt;Tanhshrink&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35902a0c2cfa9e585fec0c3e3666693fec9dd4a9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.threshold#torch.nn.Threshold&quot;&gt;&lt;code&gt;Threshold&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ce6b129bc423f40aba54b0c2ce12c00beddaaaf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tripletmarginloss#torch.nn.TripletMarginLoss&quot;&gt;&lt;code&gt;TripletMarginLoss&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3fff4676883a1b11b9e2b38b57ad823ba8354c4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.tripletmarginwithdistanceloss#torch.nn.TripletMarginWithDistanceLoss&quot;&gt;&lt;code&gt;TripletMarginWithDistanceLoss&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6ce3d99c47d2a3129d44cea56b1d906e3f87b1a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nn.unfold#torch.nn.Unfold&quot;&gt;&lt;code&gt;torch.nn.Unfold&lt;/code&gt;&lt;/a&gt; for details</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9788bdbd224f6b9c0bd977e955f549886daf1bcf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.nonzero#torch.nonzero&quot;&gt;&lt;code&gt;torch.nonzero()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2369f591ef4e6e16ec27b6f775edd376eeeaebaa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.norm#torch.norm&quot;&gt;&lt;code&gt;torch.norm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56e7e5c8709e5c8e2f93b31866c6deb6c856253e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.not_equal#torch.not_equal&quot;&gt;&lt;code&gt;torch.not_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b9ce8340dc0317b49aade691cfc70799f4e8a00" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.numel#torch.numel&quot;&gt;&lt;code&gt;torch.numel()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4622b4f7c7ee0a0d13c8074a55141e4ff3229c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.orgqr#torch.orgqr&quot;&gt;&lt;code&gt;torch.orgqr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1edcc9509ea3d17ee6a647709ab6bf5071894e7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.ormqr#torch.ormqr&quot;&gt;&lt;code&gt;torch.ormqr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ec140159032ba8d0085d266f44eb6db3c1a6341" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.outer#torch.outer&quot;&gt;&lt;code&gt;torch.outer()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87e19d2ae8154d45a564a41febb06c16a86567e9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.pinverse#torch.pinverse&quot;&gt;&lt;code&gt;torch.pinverse()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7324cc21e0ad12841d92431a5e1818fae17672c9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.polygamma#torch.polygamma&quot;&gt;&lt;code&gt;torch.polygamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60b1f75853d0d1cd9cd5f0d2d089d7ee6125b0df" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.pow#torch.pow&quot;&gt;&lt;code&gt;torch.pow()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b8e7716730933beddce93ceeb9531967a7b8f33" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.prod#torch.prod&quot;&gt;&lt;code&gt;torch.prod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b444d47f2174704778737bc705448fc08b1ec182" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.qr#torch.qr&quot;&gt;&lt;code&gt;torch.qr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c72437f61c64c17a7e0b66bf3ffe01e9afc41be" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.quantile#torch.quantile&quot;&gt;&lt;code&gt;torch.quantile()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32fb1a354f8c66ea4a0848048572ffcf87e84e6f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rad2deg#torch.rad2deg&quot;&gt;&lt;code&gt;torch.rad2deg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc4ab991cb3b46b0132c1ba3ff2b91cc0500fdf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.reciprocal#torch.reciprocal&quot;&gt;&lt;code&gt;torch.reciprocal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfe7f00978e3613a7a554678c8956f4cb13251a3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.remainder#torch.remainder&quot;&gt;&lt;code&gt;torch.remainder()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47bdb2571c3f363d76dceb91442f7ba7bc5f47c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.renorm#torch.renorm&quot;&gt;&lt;code&gt;torch.renorm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="392bb5e2b00d5ad1124b111f4a08963b839d220b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.repeat_interleave#torch.repeat_interleave&quot;&gt;&lt;code&gt;torch.repeat_interleave()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d77b448fa6a312c6a3af7702ed4407f9a96ffff" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt;&lt;code&gt;torch.reshape()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64c78ad14ae1246bf4029f36289f782990d17cc2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;torch.rfft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="edc899a0ae7fde4858b6a50cce775b0372b7653c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.roll#torch.roll&quot;&gt;&lt;code&gt;torch.roll()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7815d433685f994781f0429772db78da8710e65c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rot90#torch.rot90&quot;&gt;&lt;code&gt;torch.rot90()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0947a333f5346f54b736a4223ca159d84235f8b5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.round#torch.round&quot;&gt;&lt;code&gt;torch.round()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3f439c8c8008d964e1bcaba78d49e70b3cb5ee0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.rsqrt#torch.rsqrt&quot;&gt;&lt;code&gt;torch.rsqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f1a0ad46bcdd4a06fd3e3e914c5990d45babeaf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sigmoid#torch.sigmoid&quot;&gt;&lt;code&gt;torch.sigmoid()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d03b7125b49df42263bd14ed0db4426d77994382" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sign#torch.sign&quot;&gt;&lt;code&gt;torch.sign()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0966c7edc653b2d2d7858c36c7f0e9e1d3aea910" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.signbit#torch.signbit&quot;&gt;&lt;code&gt;torch.signbit()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="241d2b853c66fa249e8726729a4ac39a10b2e697" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sin#torch.sin&quot;&gt;&lt;code&gt;torch.sin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89a061ad1e618c20982077437a8a87568c9307c4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sinh#torch.sinh&quot;&gt;&lt;code&gt;torch.sinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a499f1efa1ffa37cdc83e453614c6da1a94917dc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.slogdet#torch.slogdet&quot;&gt;&lt;code&gt;torch.slogdet()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b94d091f48db8b1ed862846a551122f839916ce3" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.solve#torch.solve&quot;&gt;&lt;code&gt;torch.solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7969c92902441e24ef604b1fb7e01e1633b60a0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sort#torch.sort&quot;&gt;&lt;code&gt;torch.sort()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec7801816e74ec7a3d900fbf20c476c205206e5a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.split#torch.split&quot;&gt;&lt;code&gt;torch.split()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39e5cf9eb721bd472b296db97e93a6ca162d7a75" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sqrt#torch.sqrt&quot;&gt;&lt;code&gt;torch.sqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e20283dbffe987cb9aa4c639a5d348b483031bd" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.square#torch.square&quot;&gt;&lt;code&gt;torch.square()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4537022c26f4e739fc2002bc8948554d909b1ec0" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b79329d6e4ba347ba65f0ebd150eb9025549e650" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.std#torch.std&quot;&gt;&lt;code&gt;torch.std()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8072306c8cd74c97cd95675a2ff3d6b6cdfaa602" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.stft#torch.stft&quot;&gt;&lt;code&gt;torch.stft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18ce7dc42c983592bcaecd4a3fc5855fdfc8d9ab" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sub#torch.sub&quot;&gt;&lt;code&gt;torch.sub()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af5eb1862625e7193f970d356cf7c80cbe6b8474" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.subtract#torch.subtract&quot;&gt;&lt;code&gt;torch.subtract()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66057444812a0310739be9c55bf3b8e63f04f931" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.sum#torch.sum&quot;&gt;&lt;code&gt;torch.sum()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcf75355dab89c53d2da96f041aaf2f0acf7b6d2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.svd#torch.svd&quot;&gt;&lt;code&gt;torch.svd()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfa85538b9855279675cb6cbe04a9c51aa801f91" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.symeig#torch.symeig&quot;&gt;&lt;code&gt;torch.symeig()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c1d54d9efffe6c88816f66acc03d8d8dfbcb987" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.t#torch.t&quot;&gt;&lt;code&gt;torch.t()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed0de6f96e833610021fd49c3f7874b4e1addb21" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.take#torch.take&quot;&gt;&lt;code&gt;torch.take()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99e605d53360cc080a69f4f5d980d95d7aa826ad" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.tan#torch.tan&quot;&gt;&lt;code&gt;torch.tan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e96f7967fc1e38f0303eea058aa618aef4fac2ef" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.tanh#torch.tanh&quot;&gt;&lt;code&gt;torch.tanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="777022f41fcab6d3a8b8bc1104eab2f51f7b9171" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.topk#torch.topk&quot;&gt;&lt;code&gt;torch.topk()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c49ff88894110989a51d17dc1b799b6a1d234266" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.trace#torch.trace&quot;&gt;&lt;code&gt;torch.trace()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dd4e10bc975adcbd79cbfba2536b23c1ca9fe5d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.transpose#torch.transpose&quot;&gt;&lt;code&gt;torch.transpose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bade69272d3a8a621109ac0c3cebe47f8592ccf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.triangular_solve#torch.triangular_solve&quot;&gt;&lt;code&gt;torch.triangular_solve()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f87e190394989d10b94b8ed6f12d07725726bba2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.tril#torch.tril&quot;&gt;&lt;code&gt;torch.tril()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d172b311d0d769ff2c0ed9dd6ac700f12b7519eb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.triu#torch.triu&quot;&gt;&lt;code&gt;torch.triu()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7d12fec787dfa2633076e0c7bc951ad201eab36" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.true_divide#torch.true_divide&quot;&gt;&lt;code&gt;torch.true_divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e33491c2346b21653dcb58517e74623e00bc1cf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.trunc#torch.trunc&quot;&gt;&lt;code&gt;torch.trunc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b23641ab143374e2f32432ecf86e4e46888de3d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unbind#torch.unbind&quot;&gt;&lt;code&gt;torch.unbind()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19b180c6110b55208ea1c8b65bc50f246a5ff942" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unique#torch.unique&quot;&gt;&lt;code&gt;torch.unique()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54a43b1289dd07e0a5b73c772257b5c512989147" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unique_consecutive#torch.unique_consecutive&quot;&gt;&lt;code&gt;torch.unique_consecutive()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd1faf4696524ab565ebe96977ff8f6d3996368c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.unsqueeze#torch.unsqueeze&quot;&gt;&lt;code&gt;torch.unsqueeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4056678fae5769fa6b3f1cdb6156ce7a2397a43" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.var#torch.var&quot;&gt;&lt;code&gt;torch.var()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="916b508c9cb38c716d16bc8c991ff57f921295f9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;generated/torch.vdot#torch.vdot&quot;&gt;&lt;code&gt;torch.vdot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b5ecc20fdf55d0eb2ca422795c8c3780a985baa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1602.07868&quot;&gt;https://arxiv.org/abs/1602.07868&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b9412e01247af2b574511c1ccac61f158442f0f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1606.08415&quot;&gt;Gaussian Error Linear Units (GELUs)&lt;/a&gt; where the SiLU (Sigmoid Linear Unit) was originally coined, and see &lt;a href=&quot;https://arxiv.org/abs/1702.03118&quot;&gt;Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1710.05941v1&quot;&gt;Swish: a Self-Gated Activation Function&lt;/a&gt; where the SiLU was experimented with later.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14f3ddc89b63e2e7ace4c43afa51eb155bb8b073" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1606.08415&quot;&gt;Gaussian Error Linear Units (GELUs)&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd1bf1046086c393add977bf1d0da3c9f0372ead" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1612.08083&quot;&gt;Language Modeling with Gated Convolutional Networks&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db07a2a989e739b25605b6e4d0716eb84e5dae0a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://arxiv.org/abs/1802.05957&quot;&gt;Spectral Normalization for Generative Adversarial Networks&lt;/a&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a6dff82856c75a203e206e75be968948b922059" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/master/test/test_cpp_extensions.py&quot;&gt;the tests&lt;/a&gt; for good examples of using this function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17c133c8d2a0e8bbfe7a62feb9aac8d574c244ed" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://software.intel.com/en-us/node/521004&quot;&gt;LAPACK documentation for geqrf&lt;/a&gt; for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21fd55c2238e14aca1f89595f1ab24153a2317e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;jit_unsupported#jit-unsupported&quot;&gt;TorchScript Unsupported Pytorch Constructs&lt;/a&gt; for a list of unsupported PyTorch functions and modules.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="867beb050ab38870ddc832eb3ecef0bd481ecc8d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;Named Tensors operator coverage&lt;/a&gt; for a full list of the supported torch and tensor operations. We do not yet support the following that is not covered by the link:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1babcf3a21d12db47391affdb4c96e1dd62be4d6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;nn.functional#torch.nn.functional.hardshrink&quot;&gt;&lt;code&gt;torch.nn.functional.hardshrink()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1db234df13e3a4d61ca75e6b5a3105bfac530a9e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;nn.functional#torch.nn.functional.interpolate&quot;&gt;&lt;code&gt;torch.nn.functional.interpolate()&lt;/code&gt;&lt;/a&gt; for implementation details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b45b38436f82adea06622961c718c298fe2b5459" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.jit.save#torch.jit.save&quot;&gt;&lt;code&gt;torch.jit.save&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="906e8a62d5d0063bfb8aed76d72645065a77e807" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.jit.trace#torch.jit.trace&quot;&gt;&lt;code&gt;torch.jit.trace&lt;/code&gt;&lt;/a&gt; for more information on tracing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="777f4ad759227cc1de547b64fab825a56ffc273e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.maximum#torch.maximum&quot;&gt;&lt;code&gt;torch.maximum()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee5434d3ddff1ae2016c291b61569fbc56d53430" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.minimum#torch.minimum&quot;&gt;&lt;code&gt;torch.minimum()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0be965581dce920964b073625fcdd3abb3431e9c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt; for details on conjugate symmetry.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72e0d158f46758840a4164068e9e82210cb8c350" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;AdaptiveAvgPool2d&lt;/code&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9940c6d70818d17787385090e557dd2c785cc737" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;AvgPool2d&lt;/code&gt; for details and output shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f13aa780c2216fa1121984d0068e8f5c43a24fb7" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;FeatureAlphaDropout&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d51e9069af161e98bae58fb7454beeacc6c7dd49" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;MaxPool2d&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8c535644744dd427c75006813886670b5ecbefc" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;torch.sgn()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf84761b907cce8756615b37c03c0de477c6797c" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.bernoulli&quot;&gt;&lt;code&gt;bernoulli()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.bernoulli#torch.bernoulli&quot;&gt;&lt;code&gt;torch.bernoulli()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f81c151298858c7ededc5c4b44ed15fc0e739e1" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.dense_dim&quot;&gt;&lt;code&gt;Tensor.dense_dim()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a95f7e982847b8fe1f244ef9a89f823deb4ea379" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.indices&quot;&gt;&lt;code&gt;Tensor.indices()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5404c54976e3ca510ce12e37b5127349f618c641" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.sparse_dim&quot;&gt;&lt;code&gt;Tensor.sparse_dim()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54ff5675a07df4058683c73c3542b2001d40f9cf" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;#torch.Tensor.values&quot;&gt;&lt;code&gt;Tensor.values()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7cb8cf286ca9cd05efe1662c9601fe839849b83" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;https://en.wikipedia.org/wiki/One-hot&quot;&gt;One-hot on Wikipedia&lt;/a&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b57d4272104e4b0612e05446cf15e6f3bd6c435" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;torch.nn.tripletmarginloss#torch.nn.TripletMarginLoss&quot;&gt;&lt;code&gt;TripletMarginLoss&lt;/code&gt;&lt;/a&gt;, which computes the triplet loss for input tensors using the</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="338b9a67a86b6e51ea1d6e3591262fbb1f90e795" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;torch.nn.tripletmarginwithdistanceloss#torch.nn.TripletMarginWithDistanceLoss&quot;&gt;&lt;code&gt;TripletMarginWithDistanceLoss&lt;/code&gt;&lt;/a&gt;, which computes the triplet margin loss for input tensors using a custom distance function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be5e1942829e9e077f50ab2375a2b7c88388f6d1" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;torch.nonzero#torch.nonzero&quot;&gt;&lt;code&gt;torch.nonzero()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3944875c16171bc90184fc5b9486bebdfeaab438" translate="yes" xml:space="preserve">
          <source>See also: &lt;a href=&quot;../distributed#distributed-basics&quot;&gt;Basics&lt;/a&gt; and &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-nn-ddp-instead&quot;&gt;Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel&lt;/a&gt;. The same constraints on input as in &lt;a href=&quot;torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel&lt;/code&gt;&lt;/a&gt; apply.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eb108ecfdf49da8d98dacb8dde1315fef208724" translate="yes" xml:space="preserve">
          <source>See also: &lt;code&gt;saving-loading-tensors&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eaee759e08dae96ac3e7296ea90bee9503c008c" translate="yes" xml:space="preserve">
          <source>See below for examples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f51e613b80a9cad0a8955652d10c4dc58a70617" translate="yes" xml:space="preserve">
          <source>See below for more details on the two behaviors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ddb6a37aae13cb0b24c2efb3a4dab06796b836f" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_8.html&quot;&gt;cuDNN 8 Release Notes&lt;/a&gt; for more information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81019ba57a197ef19b2f977fef5caa9379d67190" translate="yes" xml:space="preserve">
          <source>See: &lt;a href=&quot;https://arxiv.org/pdf/1505.00853.pdf&quot;&gt;https://arxiv.org/pdf/1505.00853.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0155b122fd91b7c13b804a1099ae2d088140dfb" translate="yes" xml:space="preserve">
          <source>Semantic Segmentation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c75579406c3ae78822e3ffcc9e4cc60ff251dd2d" translate="yes" xml:space="preserve">
          <source>Sender rank -1, if not part of the group</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17a32bd6e1dfb35f3140b1db64642f975712c5d9" translate="yes" xml:space="preserve">
          <source>Sends a tensor asynchronously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c841aadee573fffcf4298f38f9bffb444801dab" translate="yes" xml:space="preserve">
          <source>Sends a tensor synchronously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0edc0112db95758e96c3f9613104687a95e00afc" translate="yes" xml:space="preserve">
          <source>Sequential</source>
          <target state="translated">Sequential</target>
        </trans-unit>
        <trans-unit id="e7d74cd050fb66a4fa3c59e667aee9ae0ee10227" translate="yes" xml:space="preserve">
          <source>Sequential models execute a list of modules/functions in order (sequentially). Therefore, we can divide such a model in various segments and checkpoint each segment. All segments except the last will run in &lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt;&lt;code&gt;torch.no_grad()&lt;/code&gt;&lt;/a&gt; manner, i.e., not storing the intermediate activations. The inputs of each checkpointed segment will be saved for re-running the segment in the backward pass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89282363da677473acdbf45f0831bde9f4d3b6c4" translate="yes" xml:space="preserve">
          <source>Serialization</source>
          <target state="translated">Serialization</target>
        </trans-unit>
        <trans-unit id="086bcd13e430cfb2d3607712e21df8c908da9204" translate="yes" xml:space="preserve">
          <source>Serialization semantics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49d31523ecd7343c1a446e5158bebd854caf4035" translate="yes" xml:space="preserve">
          <source>Set options for printing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da649b091863ea75252b37be60743b57866836c1" translate="yes" xml:space="preserve">
          <source>Set options for printing. Items shamelessly taken from NumPy</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f8fce6ab85b47c6992c9a753d4c65a4df880bed" translate="yes" xml:space="preserve">
          <source>Set the extra representation of the module</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb1d30c28b5d6e9bf862978770dcfc4108953994" translate="yes" xml:space="preserve">
          <source>Set the result for this &lt;code&gt;Future&lt;/code&gt;, which will mark this &lt;code&gt;Future&lt;/code&gt; as completed and trigger all attached callbacks. Note that a &lt;code&gt;Future&lt;/code&gt; cannot be marked completed twice.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d01a2557701031cde3d1b8c62a166dbe983b48e" translate="yes" xml:space="preserve">
          <source>Set your device to local rank using either</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f9ed8e87d1736694183486ee8b4775a705262ed" translate="yes" xml:space="preserve">
          <source>Sets gradients of all model parameters to zero. See similar function under &lt;a href=&quot;../optim#torch.optim.Optimizer&quot;&gt;&lt;code&gt;torch.optim.Optimizer&lt;/code&gt;&lt;/a&gt; for more context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d404cad224614646e396f2671954c99061ff4ca5" translate="yes" xml:space="preserve">
          <source>Sets the Generator state.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="599ca5f4725e8b4ae5c8a8c258bedbaa0ae4f7ca" translate="yes" xml:space="preserve">
          <source>Sets the default &lt;code&gt;torch.Tensor&lt;/code&gt; type to floating point tensor type &lt;code&gt;t&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="017579c4ce17f464667bcc54bc1a6e8591f854a8" translate="yes" xml:space="preserve">
          <source>Sets the default &lt;code&gt;torch.Tensor&lt;/code&gt; type to floating point tensor type &lt;code&gt;t&lt;/code&gt;. This type will also be used as default floating point type for type inference in &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0194ba9213175f7befa0a141d39b82b09c76ae20" translate="yes" xml:space="preserve">
          <source>Sets the default floating point dtype to &lt;code&gt;d&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="552e257ff3a4ad554910ae569da22027db68a506" translate="yes" xml:space="preserve">
          <source>Sets the default floating point dtype to &lt;code&gt;d&lt;/code&gt;. This dtype is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03f12972542800069e5267c12cb43edb6f65202d" translate="yes" xml:space="preserve">
          <source>Sets the module in evaluation mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf6241075b09cc953edd0e9568c4cd5f5c88fe95" translate="yes" xml:space="preserve">
          <source>Sets the module in training mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="850e5cb239a66b02ec6c1c59e0300349c7abf33d" translate="yes" xml:space="preserve">
          <source>Sets the number of threads used for interop parallelism (e.g.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8644f2249be95fe3ec1aaa39ce51051699b0f6" translate="yes" xml:space="preserve">
          <source>Sets the number of threads used for interop parallelism (e.g. in JIT interpreter) on CPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf85722cd322795a8d83eb653874b27e33c5355c" translate="yes" xml:space="preserve">
          <source>Sets the number of threads used for intraop parallelism on CPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97ab6a55939177c2033f769ee905c9c0419e2d5d" translate="yes" xml:space="preserve">
          <source>Sets the random number generator state.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45382a699be8898ec2b2618f2defa7c97e636940" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers to a non-deterministic random number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7abac63ee55826e63cd8690359844f301cb36545" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers to a non-deterministic random number. Returns a 64 bit number used to seed the RNG.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82d234e8fcede91a904aeab469b5635a53af28cb" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90135ab68f94754348a83b2e9a672e458fc27687" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers. Returns a &lt;code&gt;torch.Generator&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec7c3df03637450d6927de0719c85e704fa2352b" translate="yes" xml:space="preserve">
          <source>Sets the seed for generating random numbers. Returns a &lt;code&gt;torch.Generator&lt;/code&gt; object. It is recommended to set a large seed, i.e. a number that has a good balance of 0 and 1 bits. Avoid having many 0 bits in the seed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f7618c30e9d279fa17b2c4bdef606d408ddac63" translate="yes" xml:space="preserve">
          <source>Sets the store&amp;rsquo;s default timeout. This timeout is used during initialization and in &lt;code&gt;wait()&lt;/code&gt; and &lt;code&gt;get()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fdbbd0a94629feee695b40b70eaf4cd936d83f2" translate="yes" xml:space="preserve">
          <source>Sets the underlying storage, size, and strides. If &lt;code&gt;source&lt;/code&gt; is a tensor, &lt;code&gt;self&lt;/code&gt; tensor will share the same storage and have the same size and strides as &lt;code&gt;source&lt;/code&gt;. Changes to elements in one tensor will be reflected in the other.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bcd71b693d5fcc4b6051caa2db49bd3be5ace5c" translate="yes" xml:space="preserve">
          <source>Sets whether PyTorch operations must use &amp;ldquo;deterministic&amp;rdquo; algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e8c135ec7a3af0dd0ffe1fe388882479c98805f" translate="yes" xml:space="preserve">
          <source>Sets whether PyTorch operations must use &amp;ldquo;deterministic&amp;rdquo; algorithms. That is, algorithms which, given the same input, and when run on the same software and hardware, always produce the same output. When True, operations will use deterministic algorithms when available, and if only nondeterministic algorithms are available they will throw a :class:RuntimeError when called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f66b4449eb38b9763427d77c0a12d7806005f6b" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;return_complex&lt;/code&gt; explicitly will be required in a future PyTorch release. Set it to False to preserve the current behavior or True to return a complex output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cee805f166fb37a702f66bc6ef5dafcc4636a19c" translate="yes" xml:space="preserve">
          <source>Setting the environment variable &lt;code&gt;PYTORCH_JIT=0&lt;/code&gt; will disable all script and tracing annotations. If there is hard-to-debug error in one of your TorchScript models, you can use this flag to force everything to run using native Python. Since TorchScript (scripting and tracing) is disabled with this flag, you can use tools like &lt;code&gt;pdb&lt;/code&gt; to debug the model code. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14edb2c4ec235464bf2c2b8b3e2ce45c04e83a80" translate="yes" xml:space="preserve">
          <source>Shape:</source>
          <target state="translated">Shape:</target>
        </trans-unit>
        <trans-unit id="f03987f78c9ae43379f61461ae0064f0d5607ece" translate="yes" xml:space="preserve">
          <source>Shared file system, &lt;code&gt;init_method=&quot;file://////{machine_name}/{share_folder_name}/some_file&quot;&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="931e6a72bc22b9c481f30ac82befe23983a1c7aa" translate="yes" xml:space="preserve">
          <source>Shared file-system initialization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe846e8cff1382c632019e0d7be670d40fca4949" translate="yes" xml:space="preserve">
          <source>Short-time Fourier transform (STFT).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba0ad92a63c363484c20c75c1280fe0b91b17b2c" translate="yes" xml:space="preserve">
          <source>Should be overridden by all subclasses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a37ae8778cd1020f5c30499fa7ea9a6181211f61" translate="yes" xml:space="preserve">
          <source>Show the docstring of entrypoint &lt;code&gt;model&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7504f2364dcd93257f97f33b05a38d51614bd7fa" translate="yes" xml:space="preserve">
          <source>ShuffleNet V2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f25ac460d78b88009ddd1aa94f79739535ca8b5" translate="yes" xml:space="preserve">
          <source>ShuffleNet v2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2cac7f225122d558eb3c0591bdc2ae980f1b0b1" translate="yes" xml:space="preserve">
          <source>SiLU</source>
          <target state="translated">SiLU</target>
        </trans-unit>
        <trans-unit id="40cbe2acb9d6a109dfc4fb28692090f839183dea" translate="yes" xml:space="preserve">
          <source>Sigmoid</source>
          <target state="translated">Sigmoid</target>
        </trans-unit>
        <trans-unit id="5b7359698c3ea62e0fe6f50fc802ad6bb7e51d4a" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;torch.nn.Conv2d&lt;/code&gt;&lt;/a&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d16e4a78bd1e379e62b250638417164ecf26a8e" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;generated/torch.nn.linear#torch.nn.Linear&quot;&gt;&lt;code&gt;Linear&lt;/code&gt;&lt;/a&gt;, attributes will be randomly initialized at module creation time and will be overwritten later</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c8d9b9716eb5e6f4a29b36c1d72924a394fd995" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;torch.nn.Conv2d&lt;/code&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7172942fcac61201e57b0f8f8151549517ac9d8" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;torch.nn.Linear&lt;/code&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb262cc11e95ba6ae1040b6fdf77b3aabdee1e50" translate="yes" xml:space="preserve">
          <source>Similar to &lt;code&gt;torch.nn.intrinsic.LinearReLU&lt;/code&gt;, with FakeQuantize modules initialized to default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="088b19f4865d3ae00ef9ed3545c87c4c39a038f5" translate="yes" xml:space="preserve">
          <source>Similar to the function above, but the means and standard deviations are shared among all drawn elements. The resulting tensor has size given by &lt;code&gt;size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="144ca09471d4e86a370dcd5e499624c907232699" translate="yes" xml:space="preserve">
          <source>Similar to the function above, but the means are shared among all drawn elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7b2ad151fdc2daf79483df18949d1a193fac72e" translate="yes" xml:space="preserve">
          <source>Similar to the function above, but the standard-deviations are shared among all drawn elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35e4478885a3d3de0a23fd41d27cf9e8b3fd2526" translate="yes" xml:space="preserve">
          <source>Similarly, a variable is not allowed to be used if it is only &lt;em&gt;defined&lt;/em&gt; along some paths through the function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ffdace347411406995002bee149d93b4c8d5097" translate="yes" xml:space="preserve">
          <source>Similarly, if you directly pass in a &lt;code&gt;store&lt;/code&gt; argument, it must be a &lt;code&gt;FileStore&lt;/code&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9be5c47bd8d9e298dbec515a79abc57fb63bd041" translate="yes" xml:space="preserve">
          <source>Similarly, the directions can be separated in the packed case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02a822df6b8073596762077fbb97fadeba9b1cf8" translate="yes" xml:space="preserve">
          <source>Simple Assignments</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5faf41d66cbc35e2d464a122a6e9520effb835d" translate="yes" xml:space="preserve">
          <source>Simple end to end example</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f6256b1a68c342ed7c517637989544d7f9e875b" translate="yes" xml:space="preserve">
          <source>Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d60674760461d218ee6d7f02184c2ead492c87d0" translate="yes" xml:space="preserve">
          <source>Since &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;stft()&lt;/code&gt;&lt;/a&gt; discards elements at the end of the signal if they do not fit in a frame, &lt;code&gt;istft&lt;/code&gt; may return a shorter signal than the original signal (can occur if &lt;code&gt;center&lt;/code&gt; is False since the signal isn&amp;rsquo;t padded).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b57ff46579e1243d4e5f8600a0a9241de5ac5737" translate="yes" xml:space="preserve">
          <source>Since SparseTensor._indices() is always a 2D tensor, the smallest sparse_dim = 1. Therefore, representation of a SparseTensor of sparse_dim = 0 is simply a dense tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e55bc14205c3b61b63018bcb70eae3ef124b8ad" translate="yes" xml:space="preserve">
          <source>Since eigenvalues and eigenvectors might be complex, backward pass is supported only for &lt;a href=&quot;torch.symeig#torch.symeig&quot;&gt;&lt;code&gt;torch.symeig()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cc899b4bce705836850ca654589c887f5fd6278" translate="yes" xml:space="preserve">
          <source>Since global structured pruning doesn&amp;rsquo;t make much sense unless the norm is normalized by the size of the parameter, we now limit the scope of global pruning to unstructured methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67bd75f4f8766a48c7b96bda1b055c053f15aefe" translate="yes" xml:space="preserve">
          <source>Since the input matrix &lt;code&gt;input&lt;/code&gt; is supposed to be symmetric, only the upper triangular portion is used by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21a1b9cf02c75eb1f1e22759af089802524d644f" translate="yes" xml:space="preserve">
          <source>Single-Node multi-process distributed training</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8df21c36569ccf0ecf10173294bd3bcb1ac958d" translate="yes" xml:space="preserve">
          <source>Slices the &lt;code&gt;self&lt;/code&gt; tensor along the selected dimension at the given index. This function returns a view of the original tensor with the given dimension removed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1388fcaebbfe7bba9af50141f343d91cd5010970" translate="yes" xml:space="preserve">
          <source>SmoothL1Loss</source>
          <target state="translated">SmoothL1Loss</target>
        </trans-unit>
        <trans-unit id="cf592edcfbdc177c81b474cbd6b83f6e29d0f7cc" translate="yes" xml:space="preserve">
          <source>So, it is recommended to always pass the signal length &lt;code&gt;n&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec836ce94eae96d1e5118d150d4218a7f447e2e4" translate="yes" xml:space="preserve">
          <source>So, it is recommended to always pass the signal shape &lt;code&gt;s&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fdb4ccd6a62db91e946fc4d593f43a0eb0c2b97" translate="yes" xml:space="preserve">
          <source>SobolEngine</source>
          <target state="translated">SobolEngine</target>
        </trans-unit>
        <trans-unit id="5780e85860e3ef851155673787aae34395fdcb14" translate="yes" xml:space="preserve">
          <source>SoftMarginLoss</source>
          <target state="translated">SoftMarginLoss</target>
        </trans-unit>
        <trans-unit id="bace6f3ab809aca48a2c72d1f9a972334f596086" translate="yes" xml:space="preserve">
          <source>SoftPlus is a smooth approximation to the ReLU function and can be used to constrain the output of a machine to always be positive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4db38f97f455fc816850ffbe57a25de4b9b124c8" translate="yes" xml:space="preserve">
          <source>SoftShrinkage</source>
          <target state="translated">SoftShrinkage</target>
        </trans-unit>
        <trans-unit id="a2852636b9c2b8ea655bec2aa6ef18c0c81bce34" translate="yes" xml:space="preserve">
          <source>SoftSign</source>
          <target state="translated">SoftSign</target>
        </trans-unit>
        <trans-unit id="06a2c3db74f0f43566dbc7efd5bedd81dfa46888" translate="yes" xml:space="preserve">
          <source>Softmax</source>
          <target state="translated">Softmax</target>
        </trans-unit>
        <trans-unit id="38b81da3b6ab3b9be6104d3e4c422885eca96901" translate="yes" xml:space="preserve">
          <source>Softmax is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0444b47cdcbeed809978f61fc222d1069a142d9c" translate="yes" xml:space="preserve">
          <source>Softmax2d</source>
          <target state="translated">Softmax2d</target>
        </trans-unit>
        <trans-unit id="29b7eb80efd3b1d65f2835df414e4222cab21ee1" translate="yes" xml:space="preserve">
          <source>Softmin</source>
          <target state="translated">Softmin</target>
        </trans-unit>
        <trans-unit id="af86abb7b472b1e8a9af01b4180064b037b78bf8" translate="yes" xml:space="preserve">
          <source>Softmin is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90ba42633b716cf810a9a32d70553b14c097c177" translate="yes" xml:space="preserve">
          <source>Softplus</source>
          <target state="translated">Softplus</target>
        </trans-unit>
        <trans-unit id="7bb40d05bf436ff810963d7ee11a5bc95644a2f9" translate="yes" xml:space="preserve">
          <source>Softshrink</source>
          <target state="translated">Softshrink</target>
        </trans-unit>
        <trans-unit id="2b10804bb8f17cdf24b14774ca1d70aa3ba213d6" translate="yes" xml:space="preserve">
          <source>Softsign</source>
          <target state="translated">Softsign</target>
        </trans-unit>
        <trans-unit id="73a65eb2cc67f9395fdddf23ed853dd71a26bf17" translate="yes" xml:space="preserve">
          <source>Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab02cfb3b2fcd0c1b4621d3c7cc39a469375c3ec" translate="yes" xml:space="preserve">
          <source>Solves a system of equations with a triangular coefficient matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5773ea0d4a0b0567ea2d9a3b38579ffd7e09e6ff" translate="yes" xml:space="preserve">
          <source>Some functions (for example, &lt;a href=&quot;https://docs.python.org/3/library/functions.html#zip&quot;&gt;&lt;code&gt;zip&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://docs.python.org/3/library/functions.html#enumerate&quot;&gt;&lt;code&gt;enumerate&lt;/code&gt;&lt;/a&gt;) can only operate on iterable types. Iterable types in TorchScript include &lt;code&gt;Tensor&lt;/code&gt;s, lists, tuples, dictionaries, strings, &lt;a href=&quot;generated/torch.nn.modulelist#torch.nn.ModuleList&quot;&gt;&lt;code&gt;torch.nn.ModuleList&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.moduledict#torch.nn.ModuleDict&quot;&gt;&lt;code&gt;torch.nn.ModuleDict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbbdc83ebf4a1410688a2167e77428899715f68d" translate="yes" xml:space="preserve">
          <source>Some input frequencies must be real-valued to satisfy the Hermitian property. In these cases the imaginary component will be ignored. For example, any imaginary component in the zero-frequency term cannot be represented in a real output and so will always be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5a5860f652baaa71e759f95e6546fb5a30df1fa" translate="yes" xml:space="preserve">
          <source>Some models use modules which have different training and evaluation behavior, such as batch normalization. To switch between these modes, use &lt;code&gt;model.train()&lt;/code&gt; or &lt;code&gt;model.eval()&lt;/code&gt; as appropriate. See &lt;a href=&quot;../generated/torch.nn.module#torch.nn.Module.train&quot;&gt;&lt;code&gt;train()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../generated/torch.nn.module#torch.nn.Module.eval&quot;&gt;&lt;code&gt;eval()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae4df2df1ef3b4db7bd9154e0c9f55f5890f0c7a" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as Brain Floating Point: use 1 sign, 8 exponent and 7 significand bits. Useful when range is important, since it has the same number of exponent bits as &lt;code&gt;float32&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78039ee874a9a5bb0eb3d37a1f02f096ee61bda5" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as Brain Floating Point: uses 1 sign, 8 exponent, and 7 significand bits. Useful when range is important, since it has the same number of exponent bits as &lt;code&gt;float32&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba80efc106bf3fdda88df0da58461971d3468eca" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand bits. Useful when precision is important at the expense of range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4633684bcdc43c53e1cfb801845c2325140c26e1" translate="yes" xml:space="preserve">
          <source>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand bits. Useful when precision is important.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3900f0b870b5719788e2d6646aafed691f38941e" translate="yes" xml:space="preserve">
          <source>Sorts the elements of the &lt;code&gt;input&lt;/code&gt; tensor along a given dimension in ascending order by value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a085f98a6ae4bb57c97870bfd419ca83f17e143" translate="yes" xml:space="preserve">
          <source>Sources may omit two required parts of a typical non-inline C++ extension: the necessary header includes, as well as the (pybind11) binding code. More precisely, strings passed to &lt;code&gt;cpp_sources&lt;/code&gt; are first concatenated into a single &lt;code&gt;.cpp&lt;/code&gt; file. This file is then prepended with &lt;code&gt;#include
&amp;lt;torch/extension.h&amp;gt;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38317d08ad25b33e290bef6bc76c581c87c8620f" translate="yes" xml:space="preserve">
          <source>Sparse Layers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e3084d96416ea178eaf45c018b3d6a666f048ab" translate="yes" xml:space="preserve">
          <source>Sparse functions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca9492470122675a4d013eba5c404de6d984fba7" translate="yes" xml:space="preserve">
          <source>SparseTensor has the following invariants:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad7f19daae9a456b6857c9e6506b86f3b2ab9c8d" translate="yes" xml:space="preserve">
          <source>SparseTensor._indices().shape = (sparse_dim, nnz)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="018f02659b563c79f98ce5dc06e6c8ead57c92f3" translate="yes" xml:space="preserve">
          <source>SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ca5e4706f1046fd29382939145a442a4ce0eeb1" translate="yes" xml:space="preserve">
          <source>Spawn utility</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2019fa476b609b73dfcc70b82b7767a098a7dbd" translate="yes" xml:space="preserve">
          <source>Specifically, in the forward pass, &lt;code&gt;function&lt;/code&gt; will run in &lt;a href=&quot;generated/torch.no_grad#torch.no_grad&quot;&gt;&lt;code&gt;torch.no_grad()&lt;/code&gt;&lt;/a&gt; manner, i.e., not storing the intermediate activations. Instead, the forward pass saves the inputs tuple and the &lt;code&gt;function&lt;/code&gt; parameter. In the backwards pass, the saved inputs and &lt;code&gt;function&lt;/code&gt; is retrieved, and the forward pass is computed on &lt;code&gt;function&lt;/code&gt; again, now tracking the intermediate activations, and then the gradients are calculated using these activation values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fb7ff759e9a0b4f8cf21fa63ff4032c4ca275d1" translate="yes" xml:space="preserve">
          <source>Specify &lt;code&gt;init_method&lt;/code&gt; (a URL string) which indicates where/how to discover peers. Optionally specify &lt;code&gt;rank&lt;/code&gt; and &lt;code&gt;world_size&lt;/code&gt;, or encode all required parameters in the URL and omit them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaa6b0a968f0861818a7c60f3b1e30636bcfe285" translate="yes" xml:space="preserve">
          <source>Specify &lt;code&gt;store&lt;/code&gt;, &lt;code&gt;rank&lt;/code&gt;, and &lt;code&gt;world_size&lt;/code&gt; explicitly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="729466c776095dc7f1dabe6031157b446a5540f2" translate="yes" xml:space="preserve">
          <source>Spectral Ops</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2edd2d0e89ea6a8fb45d2a4b97947c90f7836312" translate="yes" xml:space="preserve">
          <source>Spectral normalization stabilizes the training of discriminators (critics) in Generative Adversarial Networks (GANs) by rescaling the weight tensor with spectral norm</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7da9517b7a5b4892d14a9dd4e7bfc3bd2215ddfe" translate="yes" xml:space="preserve">
          <source>Splits a tensor into a specific number of chunks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15060a11c482f2d0d29c0ea280b19cfd35770c5a" translate="yes" xml:space="preserve">
          <source>Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2be38fc2259b1dc48a946fa30b9de28430d8f6" translate="yes" xml:space="preserve">
          <source>Splits the tensor into chunks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a4c888de6c076a07c14ac6f6526916b6b64d375" translate="yes" xml:space="preserve">
          <source>Splits the tensor into chunks. Each chunk is a view of the original tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bb9feffd05f6ed4721f33c4d4bcd3050fc0acce" translate="yes" xml:space="preserve">
          <source>SqueezeNet</source>
          <target state="translated">SqueezeNet</target>
        </trans-unit>
        <trans-unit id="8e3b43524d2794940e994fbdb21d126a6c23a892" translate="yes" xml:space="preserve">
          <source>SqueezeNet 1.0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83d7283f405d03fc00d84f279e5aa4a9ad100122" translate="yes" xml:space="preserve">
          <source>SqueezeNet 1.1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8ffcf5b4a1dac24c72399125fdd5187787b0df5" translate="yes" xml:space="preserve">
          <source>SqueezeNet 1.1 model from the &lt;a href=&quot;https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1&quot;&gt;official SqueezeNet repo&lt;/a&gt;. SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fe53423313b926c6b9706c2a81b42a519942948" translate="yes" xml:space="preserve">
          <source>SqueezeNet model architecture from the &lt;a href=&quot;https://arxiv.org/abs/1602.07360&quot;&gt;&amp;ldquo;SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &amp;lt;0.5MB model size&amp;rdquo;&lt;/a&gt; paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d061769f4cfb05ab146ba458ef5636f865a72a82" translate="yes" xml:space="preserve">
          <source>Stack tensors in sequence depthwise (along third axis).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46e9e1e8c6989a91e6a1a0548e571225be43cbbf" translate="yes" xml:space="preserve">
          <source>Stack tensors in sequence horizontally (column wise).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd5277dc6eddb37c391be9a3629b9809479f61ec" translate="yes" xml:space="preserve">
          <source>Stack tensors in sequence vertically (row wise).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7911bbae7aa66ed740b8a6ebf74df4fbffeb0338" translate="yes" xml:space="preserve">
          <source>State collector class for float operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5653cebc057d4791ce07031ad9286e729de6d691" translate="yes" xml:space="preserve">
          <source>Statements</source>
          <target state="translated">Statements</target>
        </trans-unit>
        <trans-unit id="19abb71cdc8040d0d69069e805acbb331fb10491" translate="yes" xml:space="preserve">
          <source>Step between two slices is given by &lt;code&gt;step&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a93d86688c50b7db5df06afe98e12c7eb843b764" translate="yes" xml:space="preserve">
          <source>Stores names for each of this tensor&amp;rsquo;s dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c7ec55740528fa4d2910cfad7b5e1cae6e7da08" translate="yes" xml:space="preserve">
          <source>Stride is the jump necessary to go from one element to the next one in the specified dimension &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt;. A tuple of all strides is returned when no argument is passed in. Otherwise, an integer value is returned as the stride in the particular dimension &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8234b01c9735ef16f8e122a86ac6b13bee795314" translate="yes" xml:space="preserve">
          <source>Submodules assigned in this way will be registered, and will have their parameters converted too when you call &lt;a href=&quot;#torch.nn.Module.to&quot;&gt;&lt;code&gt;to()&lt;/code&gt;&lt;/a&gt;, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82a36013ba03c5404268ec4092f5e0e3210ace06" translate="yes" xml:space="preserve">
          <source>Subscripts and Slicing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae017f86a36a573c987d535dde17fe71055f3774" translate="yes" xml:space="preserve">
          <source>Subsystems</source>
          <target state="translated">Subsystems</target>
        </trans-unit>
        <trans-unit id="fb5f075e6679b4e2fffcc3ea921e3be776764746" translate="yes" xml:space="preserve">
          <source>Subtracts &lt;code&gt;other&lt;/code&gt;, scaled by &lt;code&gt;alpha&lt;/code&gt;, from &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61228272a4a7f9d4dd0cc2a12ad63a807870bdc6" translate="yes" xml:space="preserve">
          <source>Sum &lt;code&gt;this&lt;/code&gt; tensor to &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;#torch.Tensor.size&quot;&gt;&lt;code&gt;size&lt;/code&gt;&lt;/a&gt; must be broadcastable to &lt;code&gt;this&lt;/code&gt; tensor size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2a1c18ad4d1dc4a9dbab6435947b2aca87f5bcb" translate="yes" xml:space="preserve">
          <source>SuperResolution</source>
          <target state="translated">SuperResolution</target>
        </trans-unit>
        <trans-unit id="fe6c7185d6335e53d7798880272887b9e595250b" translate="yes" xml:space="preserve">
          <source>Supported constant Python types are</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c9970da0829cd2d77d97494b716ecac47fb4272" translate="yes" xml:space="preserve">
          <source>Supported inputs are dense, sparse, and batches of dense matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a72acca9638828e6fcd59dd9d5146b8ffaac77cb" translate="yes" xml:space="preserve">
          <source>Supported operators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d88be7203e6e438cd32536d295a5ed587dd4a76" translate="yes" xml:space="preserve">
          <source>Supports &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcasting to a common shape&lt;/a&gt;, &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;type promotion&lt;/a&gt;, and integer, float, and complex inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12a17f409a6267d331bbba640e585b7dceceb728" translate="yes" xml:space="preserve">
          <source>Supports &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcasting to a common shape&lt;/a&gt;, &lt;a href=&quot;../tensor_attributes#type-promotion-doc&quot;&gt;type promotion&lt;/a&gt;, and integer, float, and complex inputs. Always promotes integer types to the default scalar type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c515e39b10e558f93fb5480918ab7b6f80dd1a7c" translate="yes" xml:space="preserve">
          <source>Supports broadcasting to a common shape, type promotion, and integer and float inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b5fa2f5e7f20411e614b5e4239c9394a99b2a3f" translate="yes" xml:space="preserve">
          <source>Symbolic functions should be implemented in Python. All of these functions interact with Python methods which are implemented via C++-Python bindings, but intuitively the interface they provide looks like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd8b7a9758c34d0bf6248878c673e14fd8037607" translate="yes" xml:space="preserve">
          <source>SyncBatchNorm</source>
          <target state="translated">SyncBatchNorm</target>
        </trans-unit>
        <trans-unit id="1dc553edb93ee2799123f5bdebb8f2d61aa9771e" translate="yes" xml:space="preserve">
          <source>Synchronizes all processes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68f18accfbfac81fef2a2bc99a682b9a686206f1" translate="yes" xml:space="preserve">
          <source>Synchronous and asynchronous collective operations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2c53d66948214258a26ca9ca845d7ac0c17f8e7" translate="yes" xml:space="preserve">
          <source>T</source>
          <target state="translated">T</target>
        </trans-unit>
        <trans-unit id="a55d4194696253efb0ce8eaeea351140c88a65da" translate="yes" xml:space="preserve">
          <source>T = \text{input length}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26aecc925a999c69c46a16510ab79a1145705de8" translate="yes" xml:space="preserve">
          <source>T+X</source>
          <target state="translated">T+X</target>
        </trans-unit>
        <trans-unit id="a614078b58d53b0cc0d0d780950744eb6f8ae5a6" translate="yes" xml:space="preserve">
          <source>TCP initialization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e80c75f58bfc00b9ae732035ef70cb00333f4a1c" translate="yes" xml:space="preserve">
          <source>Take in and process masked source/target sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="945a1e1f48dcf43605fff2c03f1828ea5952eb79" translate="yes" xml:space="preserve">
          <source>Take the instruction &lt;code&gt;%rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10&lt;/code&gt; for example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e94daa7e8a28b957c758019bcfa728a98c04545f" translate="yes" xml:space="preserve">
          <source>Takes LongTensor with index values of shape &lt;code&gt;(*)&lt;/code&gt; and returns a tensor of shape &lt;code&gt;(*, num_classes)&lt;/code&gt; that have zeros everywhere except where the index of last dimension matches the corresponding value of the input tensor, in which case it will be 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d3331f3bb652437bd8045860b4a682532d6d90a" translate="yes" xml:space="preserve">
          <source>Takes the inverse of the square matrix &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="537dfa1e7ebc0ec78b53314930b233f489d3f1c5" translate="yes" xml:space="preserve">
          <source>Takes the inverse of the square matrix &lt;code&gt;input&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; can be batches of 2D square tensors, in which case this function would return a tensor composed of individual inverses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0ad657474446cfbcb32a233330ba630a430b967" translate="yes" xml:space="preserve">
          <source>Takes the power of each element in &lt;code&gt;input&lt;/code&gt; with &lt;code&gt;exponent&lt;/code&gt; and returns a tensor with the result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9d3154243fedb184083b9dcec0135d9da418872" translate="yes" xml:space="preserve">
          <source>Taking a real-valued frequency signal and bringing it into the time domain gives Hermitian symmetric output:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19bff9fbbbadd7b339e0ee0ae1715d62fea9cae0" translate="yes" xml:space="preserve">
          <source>Tanh</source>
          <target state="translated">Tanh</target>
        </trans-unit>
        <trans-unit id="fa7acfd0630e85ee187c290a39277eaf9f5359da" translate="yes" xml:space="preserve">
          <source>Tanhshrink</source>
          <target state="translated">Tanhshrink</target>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="3032d3d269195493b60b2b5232d8a35ccf1cf179" translate="yes" xml:space="preserve">
          <source>Target_lengths: Tuple or tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cce3202a79fe1345bd15442aee9a15d0666fb25f" translate="yes" xml:space="preserve">
          <source>Targets: Tensor of size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="680cb2d3fe397d144ed6bcd0531961c3a05ca6c0" translate="yes" xml:space="preserve">
          <source>Tensor</source>
          <target state="translated">Tensor</target>
        </trans-unit>
        <trans-unit id="7d374fa02b51c2a0bd017c85ffdbaad8aa59c748" translate="yes" xml:space="preserve">
          <source>Tensor Attributes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47b8aa0b5113cdb5b15d1487280d5b3f9b245998" translate="yes" xml:space="preserve">
          <source>Tensor Views</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d5ce15cb1a252917b40c643e7a2eb6d5463df19" translate="yes" xml:space="preserve">
          <source>Tensor can be also expanded to a larger number of dimensions, and the new ones will be appended at the front. For the new dimensions, the size cannot be set to -1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f4edfd7fe26e893eda2475a21249dda3127731b" translate="yes" xml:space="preserve">
          <source>Tensor of size &lt;code&gt;T x B x *&lt;/code&gt; if &lt;code&gt;batch_first&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;. Tensor of size &lt;code&gt;B x T x *&lt;/code&gt; otherwise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f64e01f2c0bfc00c617fa5cfe062d17dd7881fa" translate="yes" xml:space="preserve">
          <source>TensorPipe Backend</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fa30b4e43ae7ab6c13e5a62747d73bd4f6a50ff" translate="yes" xml:space="preserve">
          <source>Tensors</source>
          <target state="translated">Tensors</target>
        </trans-unit>
        <trans-unit id="3f3793b3bb16961a91ba80319c433489d751557f" translate="yes" xml:space="preserve">
          <source>Tensors may not have two named dimensions with the same name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a4ff50c90d4ae49393e7ddb58e4182969af3c75" translate="yes" xml:space="preserve">
          <source>Ternary Expressions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3aa34ed971590db58293e74b01ccf27489043c07" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; has its sign bit set (is less than zero) or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5de15b26e6a795a7480af2f5882e1811d35f284" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; is infinite (positive or negative infinity) or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0285b21693b5a12974f50c902b26299554e6465" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; is negative infinity or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69536d45bf03029aac4041aa441f6044c68432e4" translate="yes" xml:space="preserve">
          <source>Tests if each element of &lt;code&gt;input&lt;/code&gt; is positive infinity or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93ef0dd827103681fcee453b78be2ff14e1a261d" translate="yes" xml:space="preserve">
          <source>The</source>
          <target state="translated">The</target>
        </trans-unit>
        <trans-unit id="2312d5bb8d4ccdb5a8d40c96ff98fa570d836574" translate="yes" xml:space="preserve">
          <source>The 1-dimensional dot product version of this function does not support an &lt;code&gt;out&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0763c643a0c9e64fc2e1987a16313347a5b7157" translate="yes" xml:space="preserve">
          <source>The 1.6 release of PyTorch switched &lt;code&gt;torch.save&lt;/code&gt; to use a new zipfile-based file format. &lt;code&gt;torch.load&lt;/code&gt; still retains the ability to load files in the old format. If for any reason you want &lt;code&gt;torch.save&lt;/code&gt; to use the old format, pass the kwarg &lt;code&gt;_use_new_zipfile_serialization=False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a532bc29eaf3d25b0af52da2857f32bdfeed457d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt;th dimension of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; must have the same size as the length of &lt;code&gt;index&lt;/code&gt; (which must be a vector), and all other dimensions must match &lt;code&gt;self&lt;/code&gt;, or an error will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbb84ae310dddae342bffdaeaa243633f2a53249" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.quasirandom.SobolEngine&quot;&gt;&lt;code&gt;torch.quasirandom.SobolEngine&lt;/code&gt;&lt;/a&gt; is an engine for generating (scrambled) Sobol sequences. Sobol sequences are an example of low discrepancy quasi-random sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2e5c436ae6a7b841286261fcf013451bf51db2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; argument in functions can generally be substituted with a string. This allows for fast prototyping of code.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f98c90dfa427c3d98ac8ee0cbb86e967d2daadab" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; contains a device type (&lt;code&gt;'cpu'&lt;/code&gt; or &lt;code&gt;'cuda'&lt;/code&gt;) and optional device ordinal for the device type. If the device ordinal is not present, this object will always represent the current device for the device type, even after &lt;a href=&quot;cuda#torch.cuda.set_device&quot;&gt;&lt;code&gt;torch.cuda.set_device()&lt;/code&gt;&lt;/a&gt; is called; e.g., a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; constructed with device &lt;code&gt;'cuda'&lt;/code&gt; is equivalent to &lt;code&gt;'cuda:X'&lt;/code&gt; where X is the result of &lt;a href=&quot;cuda#torch.cuda.current_device&quot;&gt;&lt;code&gt;torch.cuda.current_device()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36716fd31e682e7596ade3d0fc033b9418b25151" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; annotation&amp;rsquo;s behavior changes in PyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function or method callable from code that is exported. To get this functionality back, use &lt;code&gt;@torch.jit.unused()&lt;/code&gt;. &lt;code&gt;@torch.jit.ignore&lt;/code&gt; is now equivalent to &lt;code&gt;@torch.jit.ignore(drop=False)&lt;/code&gt;. See &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;@torch.jit.unused&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="629d16d00f1d4af587a0e984e39f346b9c762a9d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/torch.quasirandom.sobolengine#torch.quasirandom.SobolEngine&quot;&gt;&lt;code&gt;torch.quasirandom.SobolEngine&lt;/code&gt;&lt;/a&gt; is an engine for generating (scrambled) Sobol sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b29b06dcd5a85e7f1ec30bf4cac512a58a2b2613" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback-Leibler_divergence&quot;&gt;Kullback-Leibler divergence Loss&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f5b85ebb4e0453454d4b99cfd4ca555eb171ffc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;multiprocessing#multiprocessing-doc&quot;&gt;Multiprocessing package - torch.multiprocessing&lt;/a&gt; package also provides a &lt;code&gt;spawn&lt;/code&gt; function in &lt;a href=&quot;multiprocessing#torch.multiprocessing.spawn&quot;&gt;&lt;code&gt;torch.multiprocessing.spawn()&lt;/code&gt;&lt;/a&gt;. This helper function can be used to spawn multiple processes. It works by passing in the function that you want to run and spawns N processes to run it. This can be used for multiprocess distributed training as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e1098da0df12b2fcc4a3fa80eabfd00f062a3e8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;torch.mean#torch.mean&quot;&gt;&lt;code&gt;mean&lt;/code&gt;&lt;/a&gt; is a tensor with the mean of each output element&amp;rsquo;s normal distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235814295d4fe94a904ed9a1a782c8eebf3b58c5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;torch.std#torch.std&quot;&gt;&lt;code&gt;std&lt;/code&gt;&lt;/a&gt; is a tensor with the standard deviation of each output element&amp;rsquo;s normal distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fc3044dc4c4ace9a26403a7a793e46904198525" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;@torch.jit.script&lt;/code&gt; decorator will construct a &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; by compiling the body of the function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8a401f5a86feecc05362977ef403b66b5efedab" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;@torch.jit.script_method&lt;/code&gt; decorator</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9011f0cf08e406be11c8a00cbbbc2003dbdb187f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Final&lt;/code&gt; type constructor can be used to mark members as &lt;code&gt;constant&lt;/code&gt;. If members are not marked constant, they will be copied to the resulting &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; as an attribute. Using &lt;code&gt;Final&lt;/code&gt; opens opportunities for optimization if the value is known to be fixed and gives additional type safety.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="681a06025ef48d63b48a8f0ade5d434c9ed8e4d8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;None&lt;/code&gt; check must be within the if-statement&amp;rsquo;s condition; assigning a &lt;code&gt;None&lt;/code&gt; check to a variable and using it in the if-statement&amp;rsquo;s condition will not refine the types of variables in the check. Only local variables will be refined, an attribute like &lt;code&gt;self.x&lt;/code&gt; will not and must assigned to a local variable to be refined.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c57db6f6aeb13e4c4808482871b866cd32a08ce8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SummaryWriter&lt;/code&gt; class provides a high-level API to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="965753cbd79a45739bc9ad1bc6ad8aab3c55f336" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;__constants__&lt;/code&gt; array</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44a5102b3b32f58d5c9c3eb95af7ab62d791ac38" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;callable&lt;/code&gt; should have the signature:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4cd295b30506f6711ba85f58a42cc9115e197d2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;delete_key&lt;/code&gt; API is only supported by the &lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt;&lt;code&gt;TCPStore&lt;/code&gt;&lt;/a&gt;. Using this API with the &lt;a href=&quot;#torch.distributed.FileStore&quot;&gt;&lt;code&gt;FileStore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributed.HashStore&quot;&gt;&lt;code&gt;HashStore&lt;/code&gt;&lt;/a&gt; will result in an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e75f8845977efa943a8e24244efa0158e93fd55" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;grad_input&lt;/code&gt; and &lt;code&gt;grad_output&lt;/code&gt; may be tuples if the module has multiple inputs or outputs. The hook should not modify its arguments, but it can optionally return a new gradient with respect to input that will be used in place of &lt;code&gt;grad_input&lt;/code&gt; in subsequent computations. &lt;code&gt;grad_input&lt;/code&gt; will only correspond to the inputs given as positional arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c418e4ba558348daf084f57cfc5ba8f635661eb0" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;gradient_as_bucket_view&lt;/code&gt; mode does not yet work with Automatic Mixed Precision (AMP). AMP maintains stashed gradients that are used for unscaling gradients. With &lt;code&gt;gradient_as_bucket_view=True&lt;/code&gt;, these stashed gradients will point to communication buckets in the first iteration. In the next iteration, the communication buckets are mutated and thus these stashed gradients will be unexpectedly mutated as well, which might lead to wrong results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fd870aae016b2c00935c2fbc6c52d9270bae088" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; given through a forward call is expected to contain log-probabilities of each class. &lt;code&gt;input&lt;/code&gt; has to be a Tensor of size either</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60f14a9d856acc735af342914f0ff8281b2528f6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; is expected to contain raw, unnormalized scores for each class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6624e1abebb827c38014a043499dfb4fc7c338b8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;input&lt;/code&gt; tensor should be a tensor containing probabilities to be used for drawing the binary random number. Hence, all values in &lt;code&gt;input&lt;/code&gt; have to be in the range:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb4a0ff705e3f1a46ebc8daed33e4bce289527c8" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mask&lt;/code&gt; operates on the &lt;code&gt;self&lt;/code&gt; tensor, not on the given &lt;code&gt;source&lt;/code&gt; tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad5a92992bc736ff5322b797aa0cf7673e44901d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;n_fft&lt;/code&gt;, &lt;code&gt;hop_length&lt;/code&gt;, &lt;code&gt;win_length&lt;/code&gt; are all the same which prevents the calculation of right padding. These additional values could be zeros or a reflection of the signal so providing &lt;code&gt;length&lt;/code&gt; could be useful. If &lt;code&gt;length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; then padding will be aggressively removed (some loss of signal).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0ace9222bb0e305cbf096e49fb16c8bd736635b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;num_keys&lt;/code&gt; API is only supported by the &lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt;&lt;code&gt;TCPStore&lt;/code&gt;&lt;/a&gt;. Using this API with the &lt;a href=&quot;#torch.distributed.FileStore&quot;&gt;&lt;code&gt;FileStore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;#torch.distributed.HashStore&quot;&gt;&lt;code&gt;HashStore&lt;/code&gt;&lt;/a&gt; will result in an exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bd6f3dbf9c9f10c4e3b624b6d33b29b1f55e1ac" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument effectively adds &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; amount of zero padding to both sizes of the input. This is set so that when a &lt;a href=&quot;torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;#torch.nn.ConvTranspose1d&quot;&gt;&lt;code&gt;ConvTranspose1d&lt;/code&gt;&lt;/a&gt; are initialized with same parameters, they are inverses of each other in regard to the input and output shapes. However, when &lt;code&gt;stride &amp;gt; 1&lt;/code&gt;, &lt;a href=&quot;torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt; maps multiple input shapes to the same output shape. &lt;code&gt;output_padding&lt;/code&gt; is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. Note that &lt;code&gt;output_padding&lt;/code&gt; is only used to find output shape, but does not actually add zero-padding to output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5440e08e1ef68605bef85def7ab3c93778452300" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument effectively adds &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; amount of zero padding to both sizes of the input. This is set so that when a &lt;a href=&quot;torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;#torch.nn.ConvTranspose2d&quot;&gt;&lt;code&gt;ConvTranspose2d&lt;/code&gt;&lt;/a&gt; are initialized with same parameters, they are inverses of each other in regard to the input and output shapes. However, when &lt;code&gt;stride &amp;gt; 1&lt;/code&gt;, &lt;a href=&quot;torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt; maps multiple input shapes to the same output shape. &lt;code&gt;output_padding&lt;/code&gt; is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. Note that &lt;code&gt;output_padding&lt;/code&gt; is only used to find output shape, but does not actually add zero-padding to output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="624a36cdb030302abd92f10a870506676fb58830" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt; argument effectively adds &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; amount of zero padding to both sizes of the input. This is set so that when a &lt;a href=&quot;torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;#torch.nn.ConvTranspose3d&quot;&gt;&lt;code&gt;ConvTranspose3d&lt;/code&gt;&lt;/a&gt; are initialized with same parameters, they are inverses of each other in regard to the input and output shapes. However, when &lt;code&gt;stride &amp;gt; 1&lt;/code&gt;, &lt;a href=&quot;torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt; maps multiple input shapes to the same output shape. &lt;code&gt;output_padding&lt;/code&gt; is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. Note that &lt;code&gt;output_padding&lt;/code&gt; is only used to find output shape, but does not actually add zero-padding to output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac2a8aee0768d2dee229b10ae182a5bbe1013563" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;padding&lt;/code&gt;, &lt;code&gt;stride&lt;/code&gt; and &lt;code&gt;dilation&lt;/code&gt; arguments specify how the sliding blocks are retrieved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a86ce4705a9d8461e1968c13331ef942f95a281" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;remote&lt;/code&gt; API does not copy storages of argument tensors until sending them over the wire, which could be done by a different thread depending on the RPC backend type. The caller should make sure that the contents of those tensors stay intact until the returned RRef is confirmed by the owner, which can be checked using the &lt;a href=&quot;#torch.distributed.rpc.RRef.confirmed_by_owner&quot;&gt;&lt;code&gt;torch.distributed.rpc.RRef.confirmed_by_owner()&lt;/code&gt;&lt;/a&gt; API.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d9f2b4532f5542083c83b1d9834f5f944e782fe" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;rpc_async&lt;/code&gt; API does not copy storages of argument tensors until sending them over the wire, which could be done by a different thread depending on the RPC backend type. The caller should make sure that the contents of those tensors stay intact until the returned &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; completes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a7cdd56e507990bc132c8770c06d1f57641cbc2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;src&lt;/code&gt; tensor must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with the &lt;code&gt;self&lt;/code&gt; tensor. It may be of a different data type or reside on a different device.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17a168b9f78b1ca48e7a2120cd057ee2f894411e" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;target&lt;/code&gt; that this loss expects should be a class index in the range</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1785ac75c5e40c0724177cfc6462e25d84d9b18" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.distributed&lt;/code&gt; package also provides a launch utility in &lt;code&gt;torch.distributed.launch&lt;/code&gt;. This helper utility can be used to launch multiple processes per node for distributed training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72f50afcb54f84e9f4aac792b1e96785232d670d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.distributed&lt;/code&gt; package provides PyTorch support and communication primitives for multiprocess parallelism across several computation nodes running on one or more machines. The class &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt;&lt;/a&gt; builds on this functionality to provide synchronous distributed training as a wrapper around any PyTorch model. This differs from the kinds of parallelism provided by &lt;a href=&quot;multiprocessing&quot;&gt;Multiprocessing package - torch.multiprocessing&lt;/a&gt; and &lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel()&lt;/code&gt;&lt;/a&gt; in that it supports multiple network-connected machines and in that the user must explicitly launch a separate copy of the main training script for each process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1ce33b04ab70eff6a70899c7f72e87b970b8ffd" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.futures&lt;/code&gt; package is a &lt;strong&gt;Prototype&lt;/strong&gt; feature and subject to change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ae3c23dcd7aaa1724a7bbfd85a5d075a7d8913b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.jit.Attribute&lt;/code&gt; wrapper class</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd6ab112f221ddabf781ca4bc22d2c58fdee3a44" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.jit.annotate&lt;/code&gt; function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="addf386bae846dc433dd4589519a4e51ea1626e9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.layout&lt;/code&gt; class is in beta and subject to change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69af7e2fc3132014bb438bfe3f8c1bbddaee2ce2" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;torch.nn.Parameter&lt;/code&gt; wrapper and &lt;code&gt;register_buffer&lt;/code&gt; can be used to assign tensors to a module. Other values assigned to a module that is compiled will be added to the compiled module if their types can be inferred. All &lt;a href=&quot;#types&quot;&gt;types&lt;/a&gt; available in TorchScript can be used as module attributes. Tensor attributes are semantically the same as buffers. The type of empty lists and dictionaries and &lt;code&gt;None&lt;/code&gt; values cannot be inferred and must be specified via &lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;PEP 526-style&lt;/a&gt; class annotations. If a type cannot be inferred and is not explicilty annotated, it will not be added as an attribute to the resulting &lt;code&gt;ScriptModule&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc46cba00894331ffa02531912b869b31d53f5a1" translate="yes" xml:space="preserve">
          <source>The Connectionist Temporal Classification loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68d2c2ff975df64fa09115de4df3b92bf60905da" translate="yes" xml:space="preserve">
          <source>The FFT of a real signal is Hermitian-symmetric, &lt;code&gt;X[i] = conj(X[-i])&lt;/code&gt; so the output contains only the positive frequencies below the Nyquist frequency. To compute the full output, use &lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="554abbeeb98f672613a7ec23a19dc9e48ad28309" translate="yes" xml:space="preserve">
          <source>The FFT of a real signal is Hermitian-symmetric, &lt;code&gt;X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])&lt;/code&gt; so the full &lt;a href=&quot;#torch.fft.fftn&quot;&gt;&lt;code&gt;fftn()&lt;/code&gt;&lt;/a&gt; output contains redundant information. &lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt; instead omits the negative frequencies in the last dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e13169ea1b51d49a8b92e863c0bf3126ef56123" translate="yes" xml:space="preserve">
          <source>The Fourier domain representation of any real signal satisfies the Hermitian property: &lt;code&gt;X[i] = conj(X[-i])&lt;/code&gt;. This function always returns both the positive and negative frequency terms even though, for real inputs, the negative frequencies are redundant. &lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt; returns the more compact one-sided representation where only the positive frequencies are returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9fe021ce10d1cbbed575b9284c6f59da576001a" translate="yes" xml:space="preserve">
          <source>The Fourier domain representation of any real signal satisfies the Hermitian property: &lt;code&gt;X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])&lt;/code&gt;. This function always returns all positive and negative frequency terms even though, for real inputs, half of these values are redundant. &lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt; returns the more compact one-sided representation where only the positive frequencies of the last dimension are returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ad0a191a9fee1e60e241897ad6f1ce3ecbb965d" translate="yes" xml:space="preserve">
          <source>The Kullback-Leibler divergence loss measure</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79342dbd5370ca7ac1b96027ceb5844371ecbc95" translate="yes" xml:space="preserve">
          <source>The ONNX exporter can be both &lt;em&gt;trace-based&lt;/em&gt; and &lt;em&gt;script-based&lt;/em&gt; exporter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c11a05ce23a6c40119d293ee087abf34796175d7" translate="yes" xml:space="preserve">
          <source>The ONNX graph C++ definition is in &lt;code&gt;torch/csrc/jit/ir/ir.h&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a8c3a370e79a6afd160a058933e30e88f62a863" translate="yes" xml:space="preserve">
          <source>The Process Group Backend will be deprecated soon, we recommend using the TensorPipe Backend instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c611b23c7d2afdcd9cdf21ee774e5b2b21bffaa1" translate="yes" xml:space="preserve">
          <source>The Process Group agent instantiates a process group from the &lt;a href=&quot;distributed#module-torch.distributed&quot;&gt;&lt;code&gt;distributed&lt;/code&gt;&lt;/a&gt; module and utilizes its point-to-point communication capabilities to send RPC messages. Internally, the process group uses &lt;a href=&quot;https://github.com/facebookincubator/gloo/&quot;&gt;the Gloo library&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a48f9bb3889d63ba5122c625f2532d0293bf1e9f" translate="yes" xml:space="preserve">
          <source>The RPC module can leverage different backends to perform the communication between the nodes. The backend to be used can be specified in the &lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt;&lt;code&gt;init_rpc()&lt;/code&gt;&lt;/a&gt; function, by passing a certain value of the &lt;a href=&quot;#torch.distributed.rpc.BackendType&quot;&gt;&lt;code&gt;BackendType&lt;/code&gt;&lt;/a&gt; enum. Regardless of what backend is used, the rest of the RPC API won&amp;rsquo;t change. Each backend also defines its own subclass of the &lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;&lt;code&gt;RpcBackendOptions&lt;/code&gt;&lt;/a&gt; class, an instance of which can also be passed to &lt;a href=&quot;#torch.distributed.rpc.init_rpc&quot;&gt;&lt;code&gt;init_rpc()&lt;/code&gt;&lt;/a&gt; to configure the backend&amp;rsquo;s behavior.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
