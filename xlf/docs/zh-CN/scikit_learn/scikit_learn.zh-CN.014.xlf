<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="bb1fbbd8149208e44d7920553c652b0349a2e4cb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#lsa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#lsa&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4a0ae8aa40ea2e0cf2d9461f2ba205b77de375f1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#nmf&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#nmf&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="523c25ac611714a2884232ed4a3b8ea48f8aba43" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#pca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#pca&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="aa9dad4897d2af823fe726cce306b7009091c965" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#sparsecoder&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#sparsecoder&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="424d7bf0d29f09028621f6a77016037f8976dc79" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#sparsepca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#sparsepca&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="bb31f4d810b593c0d4100826896784b7db423e30" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../density#kernel-density&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../density#kernel-density&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="b8cfdd3f6a5935daac5c5163b44a190d819cf3f1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#adaboost&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../ensemble#adaboost&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="86400bc4bac71705c9aa6540ee3b030698a90e10" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#bagging&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../ensemble#bagging&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4a1ed19879f0785835e56a79d9b743e0ec4944b9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#forest&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../ensemble#forest&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="2427849a6d85ac2900e5917cd85e9a8f1e0026db" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#gradient-boosting&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../ensemble#gradient-boosting&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="74e27ba8cdd2eee9b3d79708f28f6531b62f6a85" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#partial-dependence&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../ensemble#partial-dependence&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="02f069134a44c53391b037c7fc439f82145f4541" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#random-trees-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../ensemble#random-trees-embedding&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3d0298d7a564e2bdb060a82b98586397ab1093aa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../ensemble#voting-classifier&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../ensemble#voting-classifier&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3b3089ffdf7c0064cb924ed3113eedce86da89f9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#dict-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../feature_extraction#dict-feature-extraction&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="2cae87659a2fb17a22e879d82f229f7150133e8d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#feature-hashing&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../feature_extraction#feature-hashing&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="227f83f3f45691e4e6ac89bd5c4292e7089c18d1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#image-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../feature_extraction#image-feature-extraction&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="10137dbd282e2c34d67ce96d138b644d7e83ce3c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_extraction#text-feature-extraction&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../feature_extraction#text-feature-extraction&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="eeafc617d896a18852b196d65714fb0cdfa671cc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#rfe&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../feature_selection#rfe&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="be00e3925bdea52e2671ec8561d266406b87e844" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="9563123917184cb45ca9461f7b3f9e5c290f2dbc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../feature_selection#variance-threshold&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../feature_selection#variance-threshold&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="ff9cf599736fe4fe2ebfa784747df392a4200f1f" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../gaussian_process#gaussian-process&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../gaussian_process#gaussian-process&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="d75a8b7d85fa84978a0ec8f30777c3a42aed10a4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../grid_search#grid-search&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../grid_search#grid-search&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="eb887baa2789fddc23d6beef61fca265307ecd58" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../grid_search#randomized-parameter-search&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../grid_search#randomized-parameter-search&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="75601fb7b797d9984583dbb0f5078075298f18d5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../impute#impute&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../impute#impute&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4a9d395f2980e33b7a924a6a12c64f75a808110b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../isotonic#isotonic&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../isotonic#isotonic&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="325f5783b35c73d1ac50a27b5fcba72938048669" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#additive-chi-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../kernel_approximation#additive-chi-kernel-approx&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="17d51749641f3da3ac030955c9fa8c847e6b067d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#nystroem-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../kernel_approximation#nystroem-kernel-approx&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="bd440824c891d3899b71ba7cdd6737fff87f7287" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#rbf-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../kernel_approximation#rbf-kernel-approx&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="332847419e8d0030ef93f1eacfc36a11e92afc2b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_approximation#skewed-chi-kernel-approx&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../kernel_approximation#skewed-chi-kernel-approx&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="7d3e13b8d25243ee549b8ac75191bed212dd0367" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../kernel_ridge#kernel-ridge&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../kernel_ridge#kernel-ridge&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="79136184797821e9320982ebefd4fdc6aee8fcc9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../label_propagation#label-propagation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../label_propagation#label-propagation&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="9d6cabb3bcc48c8b13d8efcb84b593c5e97fafde" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../lda_qda#lda-qda&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../lda_qda#lda-qda&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="1997cdd51434d666882d1c5e72dafd16763400c2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../learning_curve#learning-curve&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../learning_curve#learning-curve&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="edab24ce901236778794fa27e9de61a91dd86bcf" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#bayesian-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#bayesian-regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="9b98097e17c0cf7837b308d192730df9e81533c5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#elastic-net&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#elastic-net&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="fdea74fa206e7300a798fcdf4878b5477656890b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#huber-regression&quot;&gt;User Guide&lt;/a&gt;</source>
          <target state="translated">在&lt;a href=&quot;../linear_model#huber-regression&quot;&gt;用户指南中&lt;/a&gt;阅读更多内容</target>
        </trans-unit>
        <trans-unit id="605a6c65b202841b9fab85c42ab592224c31439e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#lasso&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#lasso&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="77dd7df8535c610e7e5f303489e92cf5eb573ae0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#least-angle-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#least-angle-regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="62d4fc4abd6308999d4ddf6145d511c1a64a45f8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#logistic-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#logistic-regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="62892a88a6229192a52c43f399daae6da1dfa9e7" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#multi-task-elastic-net&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#multi-task-elastic-net&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="cce4abc31be44b512209a87a8a1310dccdd746ed" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#multi-task-lasso&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#multi-task-lasso&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="63d9107930cb198a43c0da98652a54726063c1ca" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#omp&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#omp&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3170770312488b56140f8dbfe00f0d6184e99380" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#passive-aggressive&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#passive-aggressive&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="62985a29f77d63fea260e6068599d0e367d6df05" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#perceptron&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#perceptron&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="893a899efdba3adbe214f9ea4d308ce1b21b9673" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#ransac-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#ransac-regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="a05b7db13932de9fce1579dc368f7c3a0c753b2b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#ridge-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#ridge-regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="423509ee6c18b0afa9860664aaed5d7b2465f60c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../linear_model#theil-sen-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../linear_model#theil-sen-regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="0e298c4f51c9646d039f38079ecf13eeb9f51c35" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#isomap&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../manifold#isomap&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="b6567f6525c87d7835f328b71c58f3e36609854e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#locally-linear-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../manifold#locally-linear-embedding&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="8786aa07e28fcc1b246cbad7ac302288a26cdbb9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#multidimensional-scaling&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../manifold#multidimensional-scaling&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5db81b2394b8868895e638c7228ad4393e95e473" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#spectral-embedding&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../manifold#spectral-embedding&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="8dc4370c51c018661016d7dc40103661eb969866" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../manifold#t-sne&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../manifold#t-sne&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="12f1f31ea9aa0bf152f42f6e525501d833fa544e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#chi2-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../metrics#chi2-kernel&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="7ca1a0753b9133cba95108bd5cee6b65a7aca9e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#cosine-similarity&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../metrics#cosine-similarity&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="925b0027fe482eafac1c97466fcd8e514af11635" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#linear-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../metrics#linear-kernel&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="648de98a69589997eca7c7636b725bd10a74bddc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../metrics#metrics&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3f7fedfde3b7aa468849d2ea9db9146385c44b72" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#polynomial-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../metrics#polynomial-kernel&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="35dbd58928fec0c458fe20a80908cd4ec12d274d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#rbf-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../metrics#rbf-kernel&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="17512b696dbad66e286c04ad624c1265663ac384" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../metrics#sigmoid-kernel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../metrics#sigmoid-kernel&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5de34567070ba5628c050367f9e925100b0fc96a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../mixture#bgmm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../mixture#bgmm&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="533014884244f3ba887c95cc1354b3af546d07e6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../mixture#gmm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../mixture#gmm&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4f10a79354f2de579c599d2d8732a298b909fdeb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#accuracy-score&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="170be2eccb759dd0330485448ffb52236f29617f" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="1c1624381291de658aadcb0f8bba71ec760477bc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#classification-report&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#classification-report&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="02442b6427f4449db107842efe6df9bee26b4549" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#cohen-kappa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#cohen-kappa&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="60633d1944d25d8e42233b17be1ba5b89c87e50d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#confusion-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#confusion-matrix&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="d8c53077e3f840542fa4d81c9f7eb854a5a66b5d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#coverage-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#coverage-error&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="6db1944ec420ba7d264cc277fb06d2041e89b7b3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#dummy-estimators&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#dummy-estimators&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="d0061f5a7019cedca60fbe5efee87b2b70aafdf2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#explained-variance-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#explained-variance-score&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="caaad1578fa75a9e67d6c9a942aa5b385b1eddeb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#hamming-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#hamming-loss&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="d9f1528ff05d947bd2459205b85f7511b2d1d6e3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#hinge-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#hinge-loss&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="79adced881725d09911672ffa6b1fa3c11470877" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#jaccard-similarity-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#jaccard-similarity-score&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="9c76d43281b705daf6060bc769428acb99df2e1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#label-ranking-average-precision&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#label-ranking-average-precision&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="bc1444f7fb419d74ca2fc94b203e3cdd81418e90" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#label-ranking-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#label-ranking-loss&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="179dd1e5ea8f10c789dddd6c308f1168860f6139" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#log-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#log-loss&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3f5d5754f2137e3a906eef5875232e8fdfc76081" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#matthews-corrcoef&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#matthews-corrcoef&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="8f73fb1cae9461ab9f6400985b32548b8964a1b8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-absolute-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#mean-absolute-error&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5d1e1b9b31d605369dff3a437a68762e4751f2e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-squared-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#mean-squared-error&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="0b1b8bb5d6347e658149088fa461b3192cff9640" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#mean-squared-log-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#mean-squared-log-error&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="ecf4c4a829a08bf6e6519a0e6067e81b86c62fb2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#median-absolute-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#median-absolute-error&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="b5386b0a93afcac4bca9a0d368219ae5d6677670" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#precision-recall-f-measure-metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#precision-recall-f-measure-metrics&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="ca28351a846df3237d411aafad114a8333d94fec" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#r2-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#r2-score&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="0238aa0a0f95118ffe5b4c380749a69f2c36044d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#roc-metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#roc-metrics&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="a760b80ba54e4f80ac167d73dc67b67466c42dd6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#scoring&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="a9c28c0d6b12664d980e4a3fb42f49c518447592" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../model_evaluation#zero-one-loss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../model_evaluation#zero-one-loss&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="ce24690cf9d469b3f01a2115acdf5e26e2879d50" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#classifierchain&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../multiclass#classifierchain&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="f67013119ba3c3f06184866c4e55f5b0fe15d7b0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ecoc&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../multiclass#ecoc&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="2b596c84eeef681ee59e6eaa23e2ab0178795fb2" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ovo-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../multiclass#ovo-classification&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="0b84d654de937d7ea19c79ae871825d13809d0ae" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#ovr-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../multiclass#ovr-classification&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4cadbfd6d3a03561ef5fac73ce993b30f95820e4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../multiclass#regressorchain&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../multiclass#regressorchain&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="20c527e1422efd8cd521fd11a837b8771d68c0ed" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#bernoulli-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../naive_bayes#bernoulli-naive-bayes&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="435ca2dc0d648838a00a3b7bef24dac1a7adaa23" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#complement-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../naive_bayes#complement-naive-bayes&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3628821e07ebeec87b4e23e6366df9a20b612431" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#gaussian-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../naive_bayes#gaussian-naive-bayes&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="90e0d6fc128f0746c91ba73859829910362f4188" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../naive_bayes#multinomial-naive-bayes&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../naive_bayes#multinomial-naive-bayes&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="bbbfd3536fc48b983c24396bb250b8301c1a1818" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../neighbors#classification&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="d16dc8c3088a2f09d05b0c673b36bbb65842f4aa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#nearest-centroid-classifier&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../neighbors#nearest-centroid-classifier&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="efd88426b64fbe0e99a3366c9d29085372e0f20c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../neighbors#regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="b18180fa58bff344612505155e526d65757d6879" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neighbors#unsupervised-neighbors&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../neighbors#unsupervised-neighbors&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="f5ca7e934fae58a25ccd73b564917de49755ed2d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../neural_networks_unsupervised#rbm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../neural_networks_unsupervised#rbm&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="016cc2045fa59f9f6c76ed8dedce6c6a99a77250" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../outlier_detection#isolation-forest&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../outlier_detection#isolation-forest&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="23f7b3cec9a4c9afe4a28977379e61c0109412ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../outlier_detection#outlier-detection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../outlier_detection#outlier-detection&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="c340b4e9171351d4ac97e019f6a473179de82216" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#function-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#function-transformer&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="76c036a3098b42296deac8a1c5d7290cf1ae1229" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#imputation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#imputation&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="f405e1ec5f4ad33765a94962e9b33f15dadc4ec0" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#kernel-centering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#kernel-centering&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="6d6fa8fc54987f399b4367c5904e7df2b83b6932" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-binarization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#preprocessing-binarization&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="eb8d6e8ece3c81b8a542f9df331060a314e025fd" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-categorical-features&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#preprocessing-categorical-features&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="0f208a23c8504226892516180b238a9e74077793" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-discretization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#preprocessing-discretization&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="1f62a25e532bfe0603cc7a0c1c845cc880fe024e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-normalization&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#preprocessing-normalization&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5dc989f129ad1b4e3e5f3fdd6faa0e98cad51f1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-scaler&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#preprocessing-scaler&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="82f3e5bb34c91b65a524bb20b361c49cfb0fb233" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing#preprocessing-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing#preprocessing-transformer&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3cb28cc10f44afc34f1d4c1193f109ecbe0f6a68" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../preprocessing_targets#preprocessing-targets&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../preprocessing_targets#preprocessing-targets&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="8f8077a63c7a4dbd5d157802c4b7038867dc8b02" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#gaussian-random-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../random_projection#gaussian-random-matrix&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="e575964327dd84831f3a16b64ea31b230d51ed1a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#johnson-lindenstrauss&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../random_projection#johnson-lindenstrauss&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="10155b4478c3cc070907f4a54184b40aecf0a4e1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../random_projection#sparse-random-matrix&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../random_projection#sparse-random-matrix&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5272664804ace173fb4cbcbc5ddcfa3fe0afb9ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../sgd#sgd&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../sgd#sgd&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="55b58a72c59a271efec6d011a6007ff1a061e751" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../svm#svm-classification&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../svm#svm-classification&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="68050db6d2a4d61c2fe3bdaccce618cf42039304" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../svm#svm-regression&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../svm#svm-regression&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="fa2ff8d70f29d7b5c10c2ce65368640c95153f3a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../tree#tree&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../tree#tree&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="bc79a8f7da525c429ee0e5b183036b202a8b9f40" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;http://scikit-learn.org/stable/search.html&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;http://scikit-learn.org/stable/search.html&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="ea9af338459b2450a415084c5bfba27a1289f204" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;https://docs.python.org/3/c-api/memory.html#memory&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;https://docs.python.org/3/c-api/memory.html#memory&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="950c04b3c436731f3c44f5d5621d93d1c15ac31e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#parallel&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#parallel&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="fbb9f9ef042590ecbd5eb064b421494a6aa64ba3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;linear_model#perceptron&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;linear_model#perceptron&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="b3950e2b914b89c31fec890fc3bac839ddc83abb" translate="yes" xml:space="preserve">
          <source>Read-only attribute to access any step parameter by user given name. Keys are step names and values are steps parameters.</source>
          <target state="translated">只读属性,通过用户给定的名称访问任何步骤参数。键是步骤名称,值是步骤参数。</target>
        </trans-unit>
        <trans-unit id="e3cc541a2927d490b1b449fbfcf30124e2ea9571" translate="yes" xml:space="preserve">
          <source>Read-only attribute to access any transformer by given name. Keys are transformer names and values are the fitted transformer objects.</source>
          <target state="translated">只读属性,用于通过给定的名称访问任何变压器。键是变压器名称,值是已安装的变压器对象。</target>
        </trans-unit>
        <trans-unit id="83267413a88047148e04736326566653aabdff91" translate="yes" xml:space="preserve">
          <source>Real data sets are often subject to measurement or recording errors. Regular but uncommon observations may also appear for a variety of reasons. Observations which are very uncommon are called outliers. The empirical covariance estimator and the shrunk covariance estimators presented above are very sensitive to the presence of outliers in the data. Therefore, one should use robust covariance estimators to estimate the covariance of its real data sets. Alternatively, robust covariance estimators can be used to perform outlier detection and discard/downweight some observations according to further processing of the data.</source>
          <target state="translated">真实的数据集往往会出现测量或记录错误。由于各种原因,也可能出现有规律但不常见的观测值。非常不常见的观测值称为离群值。上面介绍的经验协方差估计器和缩小协方差估计器对数据中存在的异常值非常敏感。因此,人们应该使用稳健协方差估计器来估计其真实数据集的协方差。另外,稳健协方差估计器也可以用来进行离群值检测,并根据数据的进一步处理,剔除/降低一些观测值的权重。</target>
        </trans-unit>
        <trans-unit id="03d8b77e6b614dc7777dda68e24972906c1421c7" translate="yes" xml:space="preserve">
          <source>Real text may come from a variety of sources that may have used different encodings, or even be sloppily decoded in a different encoding than the one it was encoded with. This is common in text retrieved from the Web. The Python package &lt;a href=&quot;https://github.com/LuminosoInsight/python-ftfy&quot;&gt;ftfy&lt;/a&gt; can automatically sort out some classes of decoding errors, so you could try decoding the unknown text as &lt;code&gt;latin-1&lt;/code&gt; and then using &lt;code&gt;ftfy&lt;/code&gt; to fix errors.</source>
          <target state="translated">真实文本可能来自各种来源，这些来源可能使用了不同的编码，或者甚至以与编码时所用的编码不同的方式被粗略地解码。这在从Web检索的文本中很常见。Python软件包&lt;a href=&quot;https://github.com/LuminosoInsight/python-ftfy&quot;&gt;ftfy&lt;/a&gt;可以自动分类出一些解码错误，因此您可以尝试将未知文本解码为 &lt;code&gt;latin-1&lt;/code&gt; ，然后使用 &lt;code&gt;ftfy&lt;/code&gt; 修复错误。</target>
        </trans-unit>
        <trans-unit id="f1cc9e37cbdee25ad27a9a2fdb64bc7fff098c7f" translate="yes" xml:space="preserve">
          <source>Real-world data set</source>
          <target state="translated">真实世界的数据集</target>
        </trans-unit>
        <trans-unit id="3f7e1fd9149cf557b13e1453c928ae10ffbc6fe9" translate="yes" xml:space="preserve">
          <source>Recall</source>
          <target state="translated">Recall</target>
        </trans-unit>
        <trans-unit id="259d26fcd1552acd4759cfc21f7fa3b52a38a9cd" translate="yes" xml:space="preserve">
          <source>Recall (\(R\)) is defined as the number of true positives (\(T_p\)) over the number of true positives plus the number of false negatives (\(F_n\)).</source>
          <target state="translated">回忆(R\(R\))定义为真阳性数(\(T_p\))与真阳性数加假阴性数(\(F_n\))之和。</target>
        </trans-unit>
        <trans-unit id="2810a64dc1f258f67d5c7c98ab6b2f2d2b737db6" translate="yes" xml:space="preserve">
          <source>Recall is defined as \(\frac{T_p}{T_p+F_n}\), where \(T_p+F_n\) does not depend on the classifier threshold. This means that lowering the classifier threshold may increase recall, by increasing the number of true positive results. It is also possible that lowering the threshold may leave recall unchanged, while the precision fluctuates.</source>
          <target state="translated">回收率的定义是:(\frac{T_p}{T_p+F_n}),其中(T_p+F_n)不取决于分类器阈值。这意味着降低分类器阈值可能会通过增加真阳性结果的数量来提高召回率。降低阈值也有可能使召回率保持不变,而精度却在波动。</target>
        </trans-unit>
        <trans-unit id="12c28c24975811d7eeb74c51dd4566faa827303c" translate="yes" xml:space="preserve">
          <source>Recall of the positive class in binary classification or weighted average of the recall of each class for the multiclass task.</source>
          <target state="translated">二元分类中正类的召回率或多类任务中各类召回率的加权平均值。</target>
        </trans-unit>
        <trans-unit id="9b0d874ad6f60c8a5546b2d91aee9774c21ade6e" translate="yes" xml:space="preserve">
          <source>Recall that the chi-square test measures dependence between stochastic variables, so using this function &amp;ldquo;weeds out&amp;rdquo; the features that are the most likely to be independent of class and therefore irrelevant for classification.</source>
          <target state="translated">回想一下，卡方检验可测量随机变量之间的相关性，因此使用此功能可以&amp;ldquo;淘汰&amp;rdquo;最有可能与类别无关，因此与分类无关的特征。</target>
        </trans-unit>
        <trans-unit id="478b7b045cf681a86e016d3a84881b0be5302b03" translate="yes" xml:space="preserve">
          <source>Receiver Operating Characteristic (ROC)</source>
          <target state="translated">接收器工作特性(ROC)</target>
        </trans-unit>
        <trans-unit id="4e47188effac531b8036f078b2d1c56b3dc650b8" translate="yes" xml:space="preserve">
          <source>Receiver Operating Characteristic (ROC) with cross validation</source>
          <target state="translated">接收器操作特征(ROC)与交叉验证。</target>
        </trans-unit>
        <trans-unit id="b7f0928f87fcbb2ba15fc48d2fbbcee612b6e0c2" translate="yes" xml:space="preserve">
          <source>Recent theoretical results, however, show that the runtime to get some desired optimization accuracy does not increase as the training set size increases.</source>
          <target state="translated">然而,最近的理论结果表明,获得一些理想的优化精度的运行时间并不随着训练集大小的增加而增加。</target>
        </trans-unit>
        <trans-unit id="5906f3535fa47c9d81e0c2a781b29c5e0d43c1fa" translate="yes" xml:space="preserve">
          <source>Recently deprecated</source>
          <target state="translated">最近废弃的</target>
        </trans-unit>
        <trans-unit id="9801ca3e1180905873a07a61b9fbf4250f6ef67b" translate="yes" xml:space="preserve">
          <source>Recognizing hand-written digits</source>
          <target state="translated">识别手写数字</target>
        </trans-unit>
        <trans-unit id="6422fcc967f452634a501ffeeec039bbb50d3cbc" translate="yes" xml:space="preserve">
          <source>Recommendation</source>
          <target state="translated">Recommendation</target>
        </trans-unit>
        <trans-unit id="7ae114b4940981c3f59a807902e797cfb8b9ed0c" translate="yes" xml:space="preserve">
          <source>Reconstruct the image from all of its patches.</source>
          <target state="translated">从所有的补丁中重建图像。</target>
        </trans-unit>
        <trans-unit id="a69bf0379a492c240c469c84a534a2a64338d098" translate="yes" xml:space="preserve">
          <source>Reconstruction error associated with &lt;code&gt;embedding_&lt;/code&gt;</source>
          <target state="translated">与 &lt;code&gt;embedding_&lt;/code&gt; _相关的重建错误</target>
        </trans-unit>
        <trans-unit id="1947f1902face65ec435d917879598dbc8ce6456" translate="yes" xml:space="preserve">
          <source>Reconstruction error for the embedding vectors. Equivalent to &lt;code&gt;norm(Y - W Y, 'fro')**2&lt;/code&gt;, where W are the reconstruction weights.</source>
          <target state="translated">嵌入向量的重建错误。等效于 &lt;code&gt;norm(Y - W Y, 'fro')**2&lt;/code&gt; ，其中W是重构权重。</target>
        </trans-unit>
        <trans-unit id="ca4afd84f128c746490dc4294009897f387b924c" translate="yes" xml:space="preserve">
          <source>Recover the sources from X (apply the unmixing matrix).</source>
          <target state="translated">从X中恢复源(应用未混合矩阵)。</target>
        </trans-unit>
        <trans-unit id="5189873de2645d7e9d6e984c2e4dcb87fbddd6b3" translate="yes" xml:space="preserve">
          <source>Recovering a graphical structure from correlations in the data is a challenging thing. If you are interested in such recovery keep in mind that:</source>
          <target state="translated">从数据的相关性中恢复图形结构是一件具有挑战性的事情。如果你对这种恢复感兴趣,请记住:</target>
        </trans-unit>
        <trans-unit id="5137c9a2f6442417e8b7aba1873576c030b1a869" translate="yes" xml:space="preserve">
          <source>Recovery is easier from a correlation matrix than a covariance matrix: standardize your observations before running &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt;&lt;code&gt;GraphicalLasso&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">从相关矩阵进行的恢复要比协方差矩阵容易：在运行&lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt; &lt;code&gt;GraphicalLasso&lt;/code&gt; &lt;/a&gt;之前标准化观察结果</target>
        </trans-unit>
        <trans-unit id="c8fe62f88fb932af5ce49e0891e6c0663bd4c78a" translate="yes" xml:space="preserve">
          <source>Recurse for subsets \(Q_{left}(\theta^*)\) and \(Q_{right}(\theta^*)\) until the maximum allowable depth is reached, \(N_m &amp;lt; \min_{samples}\) or \(N_m = 1\).</source>
          <target state="translated">递归子集\（Q_ {left}（\ theta ^ *）\）和\（Q_ {right}（\ theta ^ *）\）直到达到最大允许深度\（N_m &amp;lt;\ min_ {samples} \ ）或\（N_m = 1 \）。</target>
        </trans-unit>
        <trans-unit id="458090dfd850799fafd4039868e137b6110733d3" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination</source>
          <target state="translated">递归特征消除</target>
        </trans-unit>
        <trans-unit id="876936c1a03ad35aaee4d7c0a210a8b4cbc79636" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination with built-in cross-validated selection of the best number of features</source>
          <target state="translated">递归特征消除,内置交叉验证选择最佳特征数量。</target>
        </trans-unit>
        <trans-unit id="b841c9268f6d1867d5de64daddaf5154745ad526" translate="yes" xml:space="preserve">
          <source>Recursive feature elimination with cross-validation</source>
          <target state="translated">交叉验证的递归特征消除法</target>
        </trans-unit>
        <trans-unit id="f4a79ff0d559c91d907224b612195b949c0dcbb9" translate="yes" xml:space="preserve">
          <source>Recursively merges the pair of clusters that minimally increases a given linkage distance.</source>
          <target state="translated">递归合并给定链接距离最小化的一对簇。</target>
        </trans-unit>
        <trans-unit id="ddfcf381f764140d92c6bcaa7d2f36dd958b0974" translate="yes" xml:space="preserve">
          <source>Recursively merges the pair of clusters that minimally increases within-cluster variance.</source>
          <target state="translated">递归合并最小化增加簇内方差的一对簇。</target>
        </trans-unit>
        <trans-unit id="cc9db3a795571c7e71f45670a1da7ff49b5f1557" translate="yes" xml:space="preserve">
          <source>Red</source>
          <target state="translated">Red</target>
        </trans-unit>
        <trans-unit id="bc205f81be4a216353df393b38e6e448e3d6f659" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then predict using the</source>
          <target state="translated">将X缩减到选定的特征,然后使用以下方法进行预测</target>
        </trans-unit>
        <trans-unit id="bf9e72d4c986bce41fdc36284d8c696fc7cd1045" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then predict using the underlying estimator.</source>
          <target state="translated">将X还原为选定的特征,然后使用基础估计器进行预测。</target>
        </trans-unit>
        <trans-unit id="8d212e578de2f7d8cae3e10b6613c11b25d96417" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then return the score of the</source>
          <target state="translated">对选定的特征进行减X,然后返回该特征的得分。</target>
        </trans-unit>
        <trans-unit id="b2ba56d17af6254814e9e8837c28ebdbfdf3e81f" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features and then return the score of the underlying estimator.</source>
          <target state="translated">将X减少到选定的特征,然后返回底层估计器的得分。</target>
        </trans-unit>
        <trans-unit id="5ac8754204592a64bbc9d9c861c2255ccc176581" translate="yes" xml:space="preserve">
          <source>Reduce X to the selected features.</source>
          <target state="translated">将X减少到选定的特征。</target>
        </trans-unit>
        <trans-unit id="bd16969298621fa8c1f346760a523bd0b16f816f" translate="yes" xml:space="preserve">
          <source>Reduce dimensionality through Gaussian random projection</source>
          <target state="translated">通过高斯随机投影降低维度</target>
        </trans-unit>
        <trans-unit id="be0672c3157469863e0dbc2c594e8a7dbae8ea2b" translate="yes" xml:space="preserve">
          <source>Reduce dimensionality through sparse random projection</source>
          <target state="translated">通过稀疏随机投影降低维度</target>
        </trans-unit>
        <trans-unit id="44394b963df355b53266b400bd5efd0a3d98a2e3" translate="yes" xml:space="preserve">
          <source>Reduced version of X. This will always be a dense array.</source>
          <target state="translated">X的缩小版,这将永远是一个密集的阵列。</target>
        </trans-unit>
        <trans-unit id="ee5b3fc2a4bbfe1e0e4647a94f46549e1aa8f492" translate="yes" xml:space="preserve">
          <source>Reducing the tendency to crowd points together at the center</source>
          <target state="translated">减少中心点挤在一起的倾向。</target>
        </trans-unit>
        <trans-unit id="4e5aa8a684683e1c180d9009332ba7545707f6be" translate="yes" xml:space="preserve">
          <source>Refer &lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;User Guide&lt;/a&gt; for the various cross-validation strategies that can be used here.</source>
          <target state="translated">有关可在此处使用的各种交叉验证策略，请参阅&lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;用户指南&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="292c4a00ad1e679d3207ae797de45ae0ac017706" translate="yes" xml:space="preserve">
          <source>Refer the &lt;a href=&quot;../../modules/metrics#metrics&quot;&gt;metrics module&lt;/a&gt; to learn more on the available scoring methods.</source>
          <target state="translated">请参阅&lt;a href=&quot;../../modules/metrics#metrics&quot;&gt;指标模块&lt;/a&gt;以了解有关可用评分方法的更多信息。</target>
        </trans-unit>
        <trans-unit id="0434a1e9c22e391418e05e3fd58acc0ff48a17cd" translate="yes" xml:space="preserve">
          <source>Refer to the &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class documentation for more information on the options available for nearest neighbors searches, including specification of query strategies, distance metrics, etc. For a list of available metrics, see the documentation of the &lt;a href=&quot;generated/sklearn.neighbors.distancemetric#sklearn.neighbors.DistanceMetric&quot;&gt;&lt;code&gt;DistanceMetric&lt;/code&gt;&lt;/a&gt; class.</source>
          <target state="translated">有关可用于最近邻居搜索的选项的更多信息，请参见&lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt;类文档，包括查询策略的规范，距离度量等。有关可用度量的列表，请参见&lt;a href=&quot;generated/sklearn.neighbors.distancemetric#sklearn.neighbors.DistanceMetric&quot;&gt; &lt;code&gt;DistanceMetric&lt;/code&gt; &lt;/a&gt;类的文档。</target>
        </trans-unit>
        <trans-unit id="45c3dc1c7731c6185824876ed514e54f71bacb64" translate="yes" xml:space="preserve">
          <source>Reference:</source>
          <target state="translated">Reference:</target>
        </trans-unit>
        <trans-unit id="0807ecc3a87cd348151a8742654a4d11738eee42" translate="yes" xml:space="preserve">
          <source>Reference: Brendan J. Frey and Delbert Dueck, &amp;ldquo;Clustering by Passing Messages Between Data Points&amp;rdquo;, Science Feb. 2007</source>
          <target state="translated">参考：Brendan J. Frey和Delbert Dueck，&amp;ldquo;通过在数据点之间传递消息进行聚类&amp;rdquo;，《科学》，2007年2月</target>
        </trans-unit>
        <trans-unit id="5d20d0fee3b91643dd8d272ac33d01ca95179d82" translate="yes" xml:space="preserve">
          <source>References</source>
          <target state="translated">References</target>
        </trans-unit>
        <trans-unit id="70202c45dcdc26b5b6c5b6ae6186520b5dbf9a54" translate="yes" xml:space="preserve">
          <source>References &lt;a href=&quot;#manning2008&quot; id=&quot;id16&quot;&gt;[Manning2008]&lt;/a&gt; and &lt;a href=&quot;#everingham2010&quot; id=&quot;id17&quot;&gt;[Everingham2010]&lt;/a&gt; present alternative variants of AP that interpolate the precision-recall curve. Currently, &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; does not implement any interpolated variant. References &lt;a href=&quot;#davis2006&quot; id=&quot;id18&quot;&gt;[Davis2006]&lt;/a&gt; and &lt;a href=&quot;#flach2015&quot; id=&quot;id19&quot;&gt;[Flach2015]&lt;/a&gt; describe why a linear interpolation of points on the precision-recall curve provides an overly-optimistic measure of classifier performance. This linear interpolation is used when computing area under the curve with the trapezoidal rule in &lt;a href=&quot;generated/sklearn.metrics.auc#sklearn.metrics.auc&quot;&gt;&lt;code&gt;auc&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参考文献&lt;a href=&quot;#manning2008&quot; id=&quot;id16&quot;&gt;[Manning2008]&lt;/a&gt;和&lt;a href=&quot;#everingham2010&quot; id=&quot;id17&quot;&gt;[Everingham2010]&lt;/a&gt;提出了插值精确召回曲线的AP的其他变体。当前，&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;不实现任何内插变量。参考文献&lt;a href=&quot;#davis2006&quot; id=&quot;id18&quot;&gt;[Davis2006]&lt;/a&gt;和&lt;a href=&quot;#flach2015&quot; id=&quot;id19&quot;&gt;[Flach2015]&lt;/a&gt;描述了为什么精确召回曲线上的点进行线性插值会过分乐观地评估分类器性能。当使用&lt;a href=&quot;generated/sklearn.metrics.auc#sklearn.metrics.auc&quot;&gt; &lt;code&gt;auc&lt;/code&gt; 中&lt;/a&gt;的梯形规则计算曲线下方的面积时，将使用此线性插值。</target>
        </trans-unit>
        <trans-unit id="9d1e4e7d27b519b1da3d7266c9c87d7861741080" translate="yes" xml:space="preserve">
          <source>References:</source>
          <target state="translated">References:</target>
        </trans-unit>
        <trans-unit id="070e67caa8030cdce21f1126698befb8bcb7259d" translate="yes" xml:space="preserve">
          <source>Refine the implementation and iterate until the exercise is solved.</source>
          <target state="translated">细化落实,反复推敲,直至解决练习问题。</target>
        </trans-unit>
        <trans-unit id="30293f3d46bf342b7b87609e1d9e2d226b609141" translate="yes" xml:space="preserve">
          <source>Refit an estimator using the best found parameters on the whole dataset.</source>
          <target state="translated">使用在整个数据集上找到的最佳参数重新安装一个估计器。</target>
        </trans-unit>
        <trans-unit id="11dc7769b39c7e2fbfa28c7d6e99d31fbe0999cf" translate="yes" xml:space="preserve">
          <source>Refitting and updating parameters</source>
          <target state="translated">重新装配和更新参数</target>
        </trans-unit>
        <trans-unit id="2641cb481062942bba2486cbdfe6e29aaa79719f" translate="yes" xml:space="preserve">
          <source>Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor &lt;code&gt;k+1&lt;/code&gt; and &lt;code&gt;k&lt;/code&gt;, have identical distances but different labels, the results will depend on the ordering of the training data.</source>
          <target state="translated">关于最近邻居算法，如果发现两个邻居（邻居 &lt;code&gt;k+1&lt;/code&gt; 和 &lt;code&gt;k&lt;/code&gt; ）具有相同的距离但标签不同，则结果将取决于训练数据的顺序。</target>
        </trans-unit>
        <trans-unit id="3a4e04e41225aa8ff5e407d1e9442425d3914882" translate="yes" xml:space="preserve">
          <source>Regarding the Nearest Neighbors algorithms, if two neighbors \(k+1\) and \(k\) have identical distances but different labels, the result will depend on the ordering of the training data.</source>
          <target state="translated">关于最近邻居算法,如果两个邻居/(k+1/)和/(k/)的距离相同但标签不同,结果将取决于训练数据的排序。</target>
        </trans-unit>
        <trans-unit id="1eb1498dac3539eb922647f7dc4e358f9465b670" translate="yes" xml:space="preserve">
          <source>Regression</source>
          <target state="translated">Regression</target>
        </trans-unit>
        <trans-unit id="6f098a92c565caa36624cdec85935988f88416e5" translate="yes" xml:space="preserve">
          <source>Regression based on k-nearest neighbors.</source>
          <target state="translated">基于k近邻的回归。</target>
        </trans-unit>
        <trans-unit id="e52baabe91c57b86ba9b6be948c44c1505083889" translate="yes" xml:space="preserve">
          <source>Regression based on neighbors within a fixed radius.</source>
          <target state="translated">基于固定半径内邻居的回归。</target>
        </trans-unit>
        <trans-unit id="86da186323db03ac887bf6826a44853992a16e47" translate="yes" xml:space="preserve">
          <source>Regression error for each estimator in the boosted ensemble.</source>
          <target state="translated">在提升的集合中,每个估计器的回归误差。</target>
        </trans-unit>
        <trans-unit id="681b64b08476ebf3542e41565130a2865d2ad32a" translate="yes" xml:space="preserve">
          <source>Regression metrics</source>
          <target state="translated">回归指标</target>
        </trans-unit>
        <trans-unit id="b13f44be1a8f68647be5c088688a38c172f2da40" translate="yes" xml:space="preserve">
          <source>Regression targets are cast to &lt;code&gt;float64&lt;/code&gt; and classification targets are maintained:</source>
          <target state="translated">回归目标 &lt;code&gt;float64&lt;/code&gt; 为float64，并维护分类目标：</target>
        </trans-unit>
        <trans-unit id="f3b24a4806e909790a107209c611ee2bc64eea03" translate="yes" xml:space="preserve">
          <source>Regressor chains (see &lt;code&gt;RegressorChain&lt;/code&gt;) is analogous to ClassifierChain as a way of combining a number of regressions into a single multi-target model that is capable of exploiting correlations among targets.</source>
          <target state="translated">回归链（请参阅 &lt;code&gt;RegressorChain&lt;/code&gt; ）类似于ClassifierChain，是一种将多个回归组合到单个多目标模型中的方法，该模型能够利用目标之间的相关性。</target>
        </trans-unit>
        <trans-unit id="71deff46eadb998974bb5b523046459c4126171b" translate="yes" xml:space="preserve">
          <source>Regressor object such as derived from &lt;code&gt;RegressorMixin&lt;/code&gt;. This regressor will automatically be cloned each time prior to fitting.</source>
          <target state="translated">诸如 &lt;code&gt;RegressorMixin&lt;/code&gt; 派生的Regressor对象。每次拟合之前，都会自动克隆此回归变量。</target>
        </trans-unit>
        <trans-unit id="8ee5e8c1b06e8eb22a8ed00eac909d93542fb00f" translate="yes" xml:space="preserve">
          <source>Regular expression denoting what constitutes a &amp;ldquo;token&amp;rdquo;, only used if &lt;code&gt;analyzer == 'word'&lt;/code&gt;. The default regexp select tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).</source>
          <target state="translated">表示什么构成&amp;ldquo;令牌&amp;rdquo;的正则表达式，仅在 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 。默认的regexp select标记包含2个或更多字母数字字符（标点符号被完全忽略，始终被视为标记分隔符）。</target>
        </trans-unit>
        <trans-unit id="59f33d089250e1e5437cf1a6ee8788463004eb35" translate="yes" xml:space="preserve">
          <source>Regular expression denoting what constitutes a &amp;ldquo;token&amp;rdquo;, only used if &lt;code&gt;analyzer == 'word'&lt;/code&gt;. The default regexp selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).</source>
          <target state="translated">表示什么构成&amp;ldquo;令牌&amp;rdquo;的正则表达式，仅在 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 。默认的regexp选择2个或更多字母数字字符的标记（标点符号被完全忽略，并始终视为标记分隔符）。</target>
        </trans-unit>
        <trans-unit id="be77bc307e84a0aac10925d8f1fc2021108dec7a" translate="yes" xml:space="preserve">
          <source>Regularization parameter.</source>
          <target state="translated">正则化参数。</target>
        </trans-unit>
        <trans-unit id="9b62127743cd97ba6ad4b32187def42a9377f6f5" translate="yes" xml:space="preserve">
          <source>Regularization path of L1- Logistic Regression</source>
          <target state="translated">L1-Logistic回归的正则化路径</target>
        </trans-unit>
        <trans-unit id="1d2806ac87cdfa838914ff36046d85dada345fed" translate="yes" xml:space="preserve">
          <source>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;C^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC.</source>
          <target state="translated">正则强度；必须为正浮点数。正则化改善了问题的条件，并减少了估计的方差。较大的值表示更强的正则化。Alpha对应于其他线性模型（例如LogisticRegression或LinearSVC）中的 &lt;code&gt;C^-1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="be6006907290ebd855d441d8740e427b29c7dba1" translate="yes" xml:space="preserve">
          <source>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;C^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="translated">正则强度；必须为正浮点数。正则化改善了问题的条件，并减少了估计的方差。较大的值表示更强的正则化。Alpha对应于其他线性模型（例如LogisticRegression或LinearSVC）中的 &lt;code&gt;C^-1&lt;/code&gt; 。如果传递数组，则认为惩罚是特定于目标的。因此，它们必须在数量上对应。</target>
        </trans-unit>
        <trans-unit id="b376a08d614180566b427fdacf91c0818ef5efed" translate="yes" xml:space="preserve">
          <source>Regularization:</source>
          <target state="translated">Regularization:</target>
        </trans-unit>
        <trans-unit id="1d68b45d1c0799ca4bfb1c8452cff406beffaec4" translate="yes" xml:space="preserve">
          <source>Regularizes the covariance estimate as &lt;code&gt;(1-reg_param)*Sigma + reg_param*np.eye(n_features)&lt;/code&gt;</source>
          <target state="translated">将协方差估计值正则化为 &lt;code&gt;(1-reg_param)*Sigma + reg_param*np.eye(n_features)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0dc3de67f15c489785125c5ff202f5bb5c1de138" translate="yes" xml:space="preserve">
          <source>Related links:</source>
          <target state="translated">相关链接:</target>
        </trans-unit>
        <trans-unit id="874f63e18691b726b5a14962b962788a3924c9f2" translate="yes" xml:space="preserve">
          <source>Related packages</source>
          <target state="translated">相关套餐</target>
        </trans-unit>
        <trans-unit id="752b35a2a37229a8c218e759b56115e98ae4923e" translate="yes" xml:space="preserve">
          <source>Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set (that is determined by the selected validation method), i.e. it has to be within (0, 1]. Otherwise it is interpreted as absolute sizes of the training sets. Note that for classification the number of samples usually have to be big enough to contain at least one sample from each class. (default: np.linspace(0.1, 1.0, 5))</source>
          <target state="translated">将用于生成学习曲线的训练实例的相对或绝对数量。如果dtype是float,它被视为训练集最大尺寸的一个分数(由所选的验证方法决定),即它必须在(0,1]范围内。否则它被解释为训练集的绝对大小。请注意,对于分类来说,样本的数量通常必须足够大,以包含每个类的至少一个样本。(默认:np.linspace(0.1,1.0,5))</target>
        </trans-unit>
        <trans-unit id="e736750a2d9c467a89ca7f6403004177eb48ae4d" translate="yes" xml:space="preserve">
          <source>Relative tolerance with regards to inertia to declare convergence</source>
          <target state="translated">对宣布收敛的惯性的相对容忍度</target>
        </trans-unit>
        <trans-unit id="d655bc00f28882b8955bcd0dba64423f1a2a174f" translate="yes" xml:space="preserve">
          <source>Relative tolerance with respect to stress at which to declare convergence.</source>
          <target state="translated">对宣布收敛的压力的相对容忍度。</target>
        </trans-unit>
        <trans-unit id="d7020f448aaf8aacc8b4d63537e375e865fff9d8" translate="yes" xml:space="preserve">
          <source>Remarks</source>
          <target state="translated">Remarks</target>
        </trans-unit>
        <trans-unit id="781186a9e71c63b13e8ecce5db03573a72d6ea8a" translate="yes" xml:space="preserve">
          <source>Remember that the number of samples required to populate the tree doubles for each additional level the tree grows to. Use &lt;code&gt;max_depth&lt;/code&gt; to control the size of the tree to prevent overfitting.</source>
          <target state="translated">请记住，填充树所需的样本数量会随着树增长到的每个其他级别而增加一倍。使用 &lt;code&gt;max_depth&lt;/code&gt; 来控制树的大小以防止过度拟合。</target>
        </trans-unit>
        <trans-unit id="4bf4b976e49f074d117b87d559bb1d8cc83e7f07" translate="yes" xml:space="preserve">
          <source>Remove accents and perform other character normalization during the preprocessing step. &amp;lsquo;ascii&amp;rsquo; is a fast method that only works on characters that have an direct ASCII mapping. &amp;lsquo;unicode&amp;rsquo; is a slightly slower method that works on any characters. None (default) does nothing.</source>
          <target state="translated">在预处理步骤中删除重音并执行其他字符归一化。&amp;ldquo; ascii&amp;rdquo;是一种快速方法，仅适用于具有直接ASCII映射的字符。&amp;ldquo; unicode&amp;rdquo;是一种适用于任何字符的稍慢的方法。无（默认）不执行任何操作。</target>
        </trans-unit>
        <trans-unit id="88db5eb33c691862cae13f32b896f34ad0aa3e75" translate="yes" xml:space="preserve">
          <source>Remove cache elements to make cache size fit in &lt;code&gt;bytes_limit&lt;/code&gt;.</source>
          <target state="translated">删除缓存元素以使缓存大小适合 &lt;code&gt;bytes_limit&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c30c90c09b566737e3cadee249c1dbd9a5837ec5" translate="yes" xml:space="preserve">
          <source>Rennie, J. D., Shih, L., Teevan, J., &amp;amp; Karger, D. R. (2003). &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;Tackling the poor assumptions of naive bayes text classifiers.&lt;/a&gt; In ICML (Vol. 3, pp. 616-623).</source>
          <target state="translated">Rennie，JD，Shih，L.，Teevan，J.，＆Karger，DR（2003）。&lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;解决朴素贝叶斯文本分类器的错误假设。&lt;/a&gt;在ICML（第3卷，第616-623页）中。</target>
        </trans-unit>
        <trans-unit id="22cb94c7b65fb89badcb1a01a1bdc2520f86d691" translate="yes" xml:space="preserve">
          <source>Rennie, J. D., Shih, L., Teevan, J., &amp;amp; Karger, D. R. (2003). Tackling the poor assumptions of naive bayes text classifiers. In ICML (Vol. 3, pp. 616-623). &lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&lt;/a&gt;</source>
          <target state="translated">Rennie，JD，Shih，L.，Teevan，J.，＆Karger，DR（2003）。解决朴素贝叶斯文本分类器的错误假设。在ICML（第3卷，第616-623页）中。&lt;a href=&quot;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&quot;&gt;http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7b2b956f64f931ba5071d16804050c6a770b0f6c" translate="yes" xml:space="preserve">
          <source>Repeated K-Fold cross validator.</source>
          <target state="translated">重复的K-Fold交叉验证器。</target>
        </trans-unit>
        <trans-unit id="09e61edee3c3dd07d459f8a0d674aecb9abdd36c" translate="yes" xml:space="preserve">
          <source>Repeated Stratified K-Fold cross validator.</source>
          <target state="translated">重复分层K-Fold交叉验证器。</target>
        </trans-unit>
        <trans-unit id="31147e137d241747c95bb952e4b6d40c9dd15695" translate="yes" xml:space="preserve">
          <source>Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled.</source>
          <target state="translated">当warm_start为True时,重复调用fit或partial_fit会导致与单次调用fit时不同的解,因为数据被洗牌的方式。</target>
        </trans-unit>
        <trans-unit id="98c452fea3cbd269dd6ec70d0b5da29305d91d54" translate="yes" xml:space="preserve">
          <source>Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling &lt;code&gt;fit&lt;/code&gt; resets this counter, while &lt;code&gt;partial_fit&lt;/code&gt; will result in increasing the existing counter.</source>
          <target state="translated">当warm_start为True时，重复调用fit或partial_fit可能会导致与单独调用fit时产生不同的解决方案，这是因为数据的混合方式。如果使用动态学习率，则根据已经看到的样本数量调整学习率。调用 &lt;code&gt;fit&lt;/code&gt; 将重置此计数器，而 &lt;code&gt;partial_fit&lt;/code&gt; 将导致增加现有计数器。</target>
        </trans-unit>
        <trans-unit id="c18fbe130422cbff11ad7c343bcdf981b3d72016" translate="yes" xml:space="preserve">
          <source>Repeats K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">重复K-Fold n次,每次重复的随机性不同。</target>
        </trans-unit>
        <trans-unit id="0f002866f53e9f1a3ed61e5e1fba772693ba8260" translate="yes" xml:space="preserve">
          <source>Repeats K-Fold n times.</source>
          <target state="translated">重复K-Fold n次。</target>
        </trans-unit>
        <trans-unit id="93875d4dd14cbae6916c80c9b56a2c66c78d91d4" translate="yes" xml:space="preserve">
          <source>Repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">重复分层K-Fold n次,每次重复的随机化程度不同。</target>
        </trans-unit>
        <trans-unit id="bc3191276b0777bd1786ea11e208ca1193541dc8" translate="yes" xml:space="preserve">
          <source>Repeats Stratified K-Fold n times.</source>
          <target state="translated">重复分层K-Fold n次。</target>
        </trans-unit>
        <trans-unit id="42a28d56095848fa739cd4170b90db72e0e3fba6" translate="yes" xml:space="preserve">
          <source>Representation of a Gaussian mixture model probability distribution. This class allows to estimate the parameters of a Gaussian mixture distribution.</source>
          <target state="translated">高斯混合物模型概率分布的表示方法。这一类可以估计高斯混合物分布的参数。</target>
        </trans-unit>
        <trans-unit id="7d32f20eabeb1b1b733ce2ae647c966b645ae539" translate="yes" xml:space="preserve">
          <source>Representation of weight vector(s) in kernel space</source>
          <target state="translated">核空间中权重向量的表示方法</target>
        </trans-unit>
        <trans-unit id="685e526ebada5eb1618a4fc73ea62f4b94674dc7" translate="yes" xml:space="preserve">
          <source>Representing ICA in the feature space gives the view of &amp;lsquo;geometric ICA&amp;rsquo;: ICA is an algorithm that finds directions in the feature space corresponding to projections with high non-Gaussianity. These directions need not be orthogonal in the original feature space, but they are orthogonal in the whitened feature space, in which all directions correspond to the same variance.</source>
          <target state="translated">在特征空间中表示ICA可获得&amp;ldquo;几何ICA&amp;rdquo;的视图：ICA是一种算法，可在特征空间中找到与具有高非高斯性的投影相对应的方向。这些方向不必在原始特征空间中是正交的，但是在白化特征空间中它们是正交的，其中所有方向都对应于相同的方差。</target>
        </trans-unit>
        <trans-unit id="c1838eb2b67d8c8494f46e5efb4e3cfa915b4c40" translate="yes" xml:space="preserve">
          <source>Representing data as sparse combinations of atoms from an overcomplete dictionary is suggested to be the way the mammalian primary visual cortex works. Consequently, dictionary learning applied on image patches has been shown to give good results in image processing tasks such as image completion, inpainting and denoising, as well as for supervised recognition tasks.</source>
          <target state="translated">哺乳动物初级视觉皮层的工作方式是将数据表示为来自超完整字典的原子的稀疏组合。因此,应用于图像补丁的字典学习已被证明在图像处理任务中,如图像完成、画中画和去噪,以及监督识别任务中都有良好的效果。</target>
        </trans-unit>
        <trans-unit id="ae4349c55f1ba2f99a753bd1f91ea54bfb7944a6" translate="yes" xml:space="preserve">
          <source>Represents the type of the target data as evaluated by utils.multiclass.type_of_target. Possible type are &amp;lsquo;continuous&amp;rsquo;, &amp;lsquo;continuous-multioutput&amp;rsquo;, &amp;lsquo;binary&amp;rsquo;, &amp;lsquo;multiclass&amp;rsquo;, &amp;lsquo;multiclass-multioutput&amp;rsquo;, &amp;lsquo;multilabel-indicator&amp;rsquo;, and &amp;lsquo;unknown&amp;rsquo;.</source>
          <target state="translated">表示由utils.multiclass.type_of_target评估的目标数据的类型。可能的类型是&amp;ldquo;连续&amp;rdquo;，&amp;ldquo;连续多输出&amp;rdquo;，&amp;ldquo;二进制&amp;rdquo;，&amp;ldquo;多类&amp;rdquo;，&amp;ldquo;多类多输出&amp;rdquo;，&amp;ldquo;多标签指示符&amp;rdquo;和&amp;ldquo;未知&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="20fa62ad1345bc75375b53f86b5eb2c26d718a95" translate="yes" xml:space="preserve">
          <source>Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.</source>
          <target state="translated">几乎不需要数据准备。其他技术通常需要数据标准化,需要创建虚拟变量,并删除空白值。但请注意,该模块不支持缺失值。</target>
        </trans-unit>
        <trans-unit id="fb71177a5a5b56c5ebee3cf20f44c503add01c10" translate="yes" xml:space="preserve">
          <source>Resample arrays or sparse matrices in a consistent way</source>
          <target state="translated">以一致的方式对数组或稀疏矩阵进行重新采样。</target>
        </trans-unit>
        <trans-unit id="2e8f725f5911194d74f9dab654d27796744b8361" translate="yes" xml:space="preserve">
          <source>Reshape a 2D image into a collection of patches</source>
          <target state="translated">将二维图像重塑为一组补丁。</target>
        </trans-unit>
        <trans-unit id="8fa86d755254fa7609fa763e5412d46d718d125d" translate="yes" xml:space="preserve">
          <source>Reshaping the output when the function has several return values:</source>
          <target state="translated">当函数有多个返回值时,对输出进行重塑。</target>
        </trans-unit>
        <trans-unit id="29b6020807e8bc7f4d853b727bb5a844490062e9" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default.</source>
          <target state="translated">将系数限制为&amp;gt; =0。请注意，您可能希望删除默认设置为True的fit_intercept。</target>
        </trans-unit>
        <trans-unit id="29979c4d4208dffcb3ff52bc6862f5032a097531" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsCV only makes sense for problems where a sparse solution is expected and/or reached.</source>
          <target state="translated">将系数限制为&amp;gt; =0。请注意，您可能希望删除默认设置为True的fit_intercept。在正约束下，对于较小的alpha值，模型系数不会收敛到普通最小二乘解。通常，逐步Lars-Lasso算法所达到的系数只有最小的alpha值（ &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 通常与坐标下降Lasso估计的解一致。因此，使用LassoLarsCV仅对预期和/或达到稀疏解决方案的问题有意义。</target>
        </trans-unit>
        <trans-unit id="39ff48ef2c581a13fca510ce558fecfc50f8d1b9" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsIC only makes sense for problems where a sparse solution is expected and/or reached.</source>
          <target state="translated">将系数限制为&amp;gt; =0。请注意，您可能希望删除默认设置为True的fit_intercept。在正约束下，对于较小的alpha值，模型系数不会收敛到普通最小二乘解。通常，逐步Lars-Lasso算法所达到的系数只有最小的alpha值（ &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 通常与坐标下降Lasso估计的解一致。因此，使用LassoLarsIC仅对预期和/或达到稀疏解决方案的问题有意义。</target>
        </trans-unit>
        <trans-unit id="82cf2cea5bace9dd3550046c8448d1e4ee78cc0a" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt;
0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator.</source>
          <target state="translated">将系数限制为&amp;gt; =0。请注意，您可能希望删除默认设置为True的fit_intercept。在正约束下，对于较小的alpha值，模型系数将不会收敛到普通最小二乘解。通常，逐步Lars-Lasso算法所达到的系数只有最小的alpha值（ &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 通常与坐标下降Lasso估计的解一致。</target>
        </trans-unit>
        <trans-unit id="cc4c23115ff5f9103869f3c0fe7331685f096b59" translate="yes" xml:space="preserve">
          <source>Restrict coefficients to be &amp;gt;= 0. This option is only allowed with method &amp;lsquo;lasso&amp;rsquo;. Note that the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (&lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent lasso_path function.</source>
          <target state="translated">将系数限制为&amp;gt; =0。仅在方法&amp;ldquo;套索&amp;rdquo;中允许使用此选项。请注意，对于较小的alpha值，模型系数不会收敛到普通最小二乘解。通常，逐步的Lars-Lasso算法所达到的系数只有最小的alpha值（ &lt;code&gt;alphas_[alphas_ &amp;gt; 0.].min()&lt;/code&gt; 通常与坐标下降lasso_path函数的解一致。</target>
        </trans-unit>
        <trans-unit id="4e0abdd8dd5609a60428b9608c1cb689b8074f2a" translate="yes" xml:space="preserve">
          <source>Restrict the features to those in support using feature selection.</source>
          <target state="translated">使用特征选择将特征限制在支持的范围内。</target>
        </trans-unit>
        <trans-unit id="241925f53a3e23af00cffc7d748ec3aff26588ad" translate="yes" xml:space="preserve">
          <source>Restricted Boltzmann Machine features for digit classification</source>
          <target state="translated">用于数字分类的限制性Boltzmann机器特征。</target>
        </trans-unit>
        <trans-unit id="7f3abfa37f2cf55ceba7590326cacc826953b894" translate="yes" xml:space="preserve">
          <source>Restricted Boltzmann machines (RBM) are unsupervised nonlinear feature learners based on a probabilistic model. The features extracted by an RBM or a hierarchy of RBMs often give good results when fed into a linear classifier such as a linear SVM or a perceptron.</source>
          <target state="translated">限制性玻尔兹曼机(RBM)是基于概率模型的无监督非线性特征学习器。RBM或RBM的层次结构所提取的特征,在输入线性分类器(如线性SVM或感知器)时,往往能得到良好的结果。</target>
        </trans-unit>
        <trans-unit id="3f490bbf3bdf7bf63209c86a4bdc9ab5af3ad16a" translate="yes" xml:space="preserve">
          <source>Results obtained with LassoLarsIC are based on AIC/BIC criteria.</source>
          <target state="translated">使用LassoLarsIC获得的结果是基于AIC/BIC标准的。</target>
        </trans-unit>
        <trans-unit id="520127a681e9beff0545f08ff1691745aa6a2355" translate="yes" xml:space="preserve">
          <source>Results of the clustering, like &lt;code&gt;rows&lt;/code&gt;.</source>
          <target state="translated">聚类的结果，如 &lt;code&gt;rows&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f81af77a87bd6c53dcd13a31f0c98b93dfbb1730" translate="yes" xml:space="preserve">
          <source>Results of the clustering. &lt;code&gt;rows[i, r]&lt;/code&gt; is True if cluster &lt;code&gt;i&lt;/code&gt; contains row &lt;code&gt;r&lt;/code&gt;. Available only after calling &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">聚类的结果。如果群集 &lt;code&gt;i&lt;/code&gt; 包含行 &lt;code&gt;r&lt;/code&gt; &lt;code&gt;rows[i, r]&lt;/code&gt; 为True 。仅在调用 &lt;code&gt;fit&lt;/code&gt; 后可用。</target>
        </trans-unit>
        <trans-unit id="09c5e8d3474ffc187ec47434a9de70365f40524a" translate="yes" xml:space="preserve">
          <source>Retrieve all neighbors and average distance within radius r:</source>
          <target state="translated">检索半径r内的所有邻居和平均距离。</target>
        </trans-unit>
        <trans-unit id="a21770a0dd9781336c9b39afe4d33a0b9399f538" translate="yes" xml:space="preserve">
          <source>Retrieve current values for configuration set by &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">检索由&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;set_config&lt;/code&gt; &lt;/a&gt;设置的配置的当前值</target>
        </trans-unit>
        <trans-unit id="795a8c10607f69a8d708655e1dfd2bda87866a63" translate="yes" xml:space="preserve">
          <source>Retrieve current values for configuration set by &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">检索由&lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;set_config&lt;/code&gt; &lt;/a&gt;设置的配置的当前值</target>
        </trans-unit>
        <trans-unit id="7d0b50936a7e8c687a75689a3dad17b7991a85ff" translate="yes" xml:space="preserve">
          <source>Return &lt;code&gt;True&lt;/code&gt;, if &lt;code&gt;y&lt;/code&gt; is in a multilabel format, else &lt;code&gt;`False&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;y&lt;/code&gt; 为多标签格式，则返回 &lt;code&gt;True&lt;/code&gt; ，否则返回 &lt;code&gt;`False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2cbe175cc2b51d30944704c3deb552cd5596a704" translate="yes" xml:space="preserve">
          <source>Return a callable that handles preprocessing and tokenization</source>
          <target state="translated">返回一个处理预处理和标记化的callable。</target>
        </trans-unit>
        <trans-unit id="35ce21f46958d2a4d6fb1e298eab74d1576eefb9" translate="yes" xml:space="preserve">
          <source>Return a function that splits a string into a sequence of tokens</source>
          <target state="translated">返回一个将字符串分割成一系列标记的函数。</target>
        </trans-unit>
        <trans-unit id="11d41c098e075f003f9bd2724f42d19606a938aa" translate="yes" xml:space="preserve">
          <source>Return a function to preprocess the text before tokenization</source>
          <target state="translated">返回一个在标记化之前对文本进行预处理的函数。</target>
        </trans-unit>
        <trans-unit id="6bd61b6b672e63d28fbd6bae4611675d07beef25" translate="yes" xml:space="preserve">
          <source>Return a mask which is safe to use on X.</source>
          <target state="translated">返回一个可以安全使用在X上的面具。</target>
        </trans-unit>
        <trans-unit id="2117f2c8a135db1ec3d7cfe90977838437ebd303" translate="yes" xml:space="preserve">
          <source>Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes.</source>
          <target state="translated">返回一个节点指示矩阵,其中非零元素表示样本通过节点。</target>
        </trans-unit>
        <trans-unit id="00bb62ba59798790184b007f565618b4467e20e2" translate="yes" xml:space="preserve">
          <source>Return class labels or probabilities for X for each estimator.</source>
          <target state="translated">返回每个估计器的类标签或X的概率。</target>
        </trans-unit>
        <trans-unit id="cd3438647a868f06b1d86d54754f891a6d1b48d4" translate="yes" xml:space="preserve">
          <source>Return feature names for output features</source>
          <target state="translated">返回输出特征的特征名称</target>
        </trans-unit>
        <trans-unit id="5493711c1bb2ce4e5d9065fe8f6089dfdca5aee9" translate="yes" xml:space="preserve">
          <source>Return feature names for output features.</source>
          <target state="translated">返回输出特征的特征名称。</target>
        </trans-unit>
        <trans-unit id="f1402e1d8dc357778164e5a8d0f1414de1f7666d" translate="yes" xml:space="preserve">
          <source>Return items or rows from X using indices.</source>
          <target state="translated">使用索引返回X中的项目或行。</target>
        </trans-unit>
        <trans-unit id="0576952c961c16373284e51db9969a6042ae18da" translate="yes" xml:space="preserve">
          <source>Return log probability estimates for the test vectors X.</source>
          <target state="translated">返回测试向量X的对数概率估计。</target>
        </trans-unit>
        <trans-unit id="72809cd1af29120a326f0c3f682d953d3b6c6e96" translate="yes" xml:space="preserve">
          <source>Return log-probability estimates for the test vector X.</source>
          <target state="translated">返回测试向量X的对数概率估计值。</target>
        </trans-unit>
        <trans-unit id="a7f22acdaa22f15d766147d74260994078d30e7e" translate="yes" xml:space="preserve">
          <source>Return posterior probabilities of classification.</source>
          <target state="translated">返回分类的后置概率。</target>
        </trans-unit>
        <trans-unit id="5e90634978b3f0ad930c9250eb92f9e0314026f1" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test data X.</source>
          <target state="translated">返回测试数据X的概率估计。</target>
        </trans-unit>
        <trans-unit id="3cc65811d5c67b9339e5de3fe46c1d36fda147a2" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test vector X.</source>
          <target state="translated">返回测试向量X的概率估计。</target>
        </trans-unit>
        <trans-unit id="eda641cffe9cac67f3fb260fe22ffd308b7dc69c" translate="yes" xml:space="preserve">
          <source>Return probability estimates for the test vectors X.</source>
          <target state="translated">返回测试向量X的概率估计。</target>
        </trans-unit>
        <trans-unit id="3c1542898f8a4979431ead39d5c15b799d51545e" translate="yes" xml:space="preserve">
          <source>Return squared Euclidean distances.</source>
          <target state="translated">返回欧几里得距离的平方。</target>
        </trans-unit>
        <trans-unit id="b6fe225e3cb643cedd5bc48ac43be276d960cd4f" translate="yes" xml:space="preserve">
          <source>Return staged predictions for X.</source>
          <target state="translated">返回X的阶段性预测。</target>
        </trans-unit>
        <trans-unit id="673aa7cb9999000b961a62897148f368c83b55e3" translate="yes" xml:space="preserve">
          <source>Return staged scores for X, y.</source>
          <target state="translated">返回X、y的阶段性成绩。</target>
        </trans-unit>
        <trans-unit id="8cf4d1ff3f261b4818ca6a890ea14f5502b4b54a" translate="yes" xml:space="preserve">
          <source>Return terms per document with nonzero entries in X.</source>
          <target state="translated">返回X中非零条目的每个文档的术语。</target>
        </trans-unit>
        <trans-unit id="5cdf5c1eeea61e59e70be57a77213eebbb153cfb" translate="yes" xml:space="preserve">
          <source>Return the anomaly score of each sample using the IsolationForest algorithm</source>
          <target state="translated">使用IsolationForest算法返回每个样本的异常得分。</target>
        </trans-unit>
        <trans-unit id="fe499de3a6f88d7210192161e1c6b2449ab1500c" translate="yes" xml:space="preserve">
          <source>Return the average Hamming loss between element of &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt;.</source>
          <target state="translated">返回 &lt;code&gt;y_true&lt;/code&gt; 和 &lt;code&gt;y_pred&lt;/code&gt; 元素之间的平均汉明损失。</target>
        </trans-unit>
        <trans-unit id="3b6f97194ee8e54eea84870d31851fd35f16981f" translate="yes" xml:space="preserve">
          <source>Return the average log-likelihood of all samples.</source>
          <target state="translated">返回所有样本的平均对数似然。</target>
        </trans-unit>
        <trans-unit id="c76a887a33fc9d47303cbdd34a0e4499db790aff" translate="yes" xml:space="preserve">
          <source>Return the bin identifier encoded as an integer value.</source>
          <target state="translated">返回编码为整数的bin标识符。</target>
        </trans-unit>
        <trans-unit id="2c7fad3d600f9c171ec8dd39485353f247ab50a0" translate="yes" xml:space="preserve">
          <source>Return the decision path in the forest</source>
          <target state="translated">返回森林中的决策路径</target>
        </trans-unit>
        <trans-unit id="d3a34834571e54a4248033c9eaba5b8e9bb1789f" translate="yes" xml:space="preserve">
          <source>Return the decision path in the tree</source>
          <target state="translated">返回树中的决策路径</target>
        </trans-unit>
        <trans-unit id="4e96d8947123569170f97aefff01f74cf9b0a6ca" translate="yes" xml:space="preserve">
          <source>Return the feature importances (the higher, the more important the</source>
          <target state="translated">返回特征导入度(越高,越重要)</target>
        </trans-unit>
        <trans-unit id="a6dd0a8039005a5293ba64e678b28da7b07a204e" translate="yes" xml:space="preserve">
          <source>Return the feature importances (the higher, the more important the feature).</source>
          <target state="translated">返回特征导入度(越高,特征越重要)。</target>
        </trans-unit>
        <trans-unit id="94661d32c77cb41c2127232860de2197f7083f9f" translate="yes" xml:space="preserve">
          <source>Return the feature importances.</source>
          <target state="translated">返回功能导入。</target>
        </trans-unit>
        <trans-unit id="0e8537aa46b4ea8a7cd6323f7580a004a7b06500" translate="yes" xml:space="preserve">
          <source>Return the formatted representation of the object.</source>
          <target state="translated">返回对象的格式化表示。</target>
        </trans-unit>
        <trans-unit id="6327801e23aebebbd4be478323001917b9194e97" translate="yes" xml:space="preserve">
          <source>Return the indices and distances of each point from the dataset lying in a ball with size &lt;code&gt;radius&lt;/code&gt; around the points of the query array. Points lying on the boundary are included in the results.</source>
          <target state="translated">返回数据集中每个点的索引和距离，该数据集位于球中，球的大小 &lt;code&gt;radius&lt;/code&gt; 围绕查询数组的点。边界上的点包括在结果中。</target>
        </trans-unit>
        <trans-unit id="0abc14c002459b9e0ac66d2f83f45cbf2ac07ca6" translate="yes" xml:space="preserve">
          <source>Return the indices and distances of some points from the dataset lying in a ball with size &lt;code&gt;radius&lt;/code&gt; around the points of the query array. Points lying on the boundary are included in the results.</source>
          <target state="translated">返回位于数据集中的数据集中某些点的索引和距离，球的大小 &lt;code&gt;radius&lt;/code&gt; 围绕查询数组的点。边界上的点包括在结果中。</target>
        </trans-unit>
        <trans-unit id="59896f479363f206b5f17c3575cb26dc74dc0030" translate="yes" xml:space="preserve">
          <source>Return the inner statistics A (dictionary covariance) and B (data approximation). Useful to restart the algorithm in an online setting. If return_inner_stats is True, return_code is ignored</source>
          <target state="translated">返回内部统计量A(字典协方差)和B(数据近似)。对在线环境下重新启动算法很有用。如果return_inner_stats为True,return_code将被忽略。</target>
        </trans-unit>
        <trans-unit id="71a76752665369a60f6ab1ee2da126886f72e89c" translate="yes" xml:space="preserve">
          <source>Return the kernel k(X, Y) and optionally its gradient.</source>
          <target state="translated">返回k(X,Y)核和可选的梯度。</target>
        </trans-unit>
        <trans-unit id="c76fd50f1e2f18eb3de394ebc844504c0bd95a4d" translate="yes" xml:space="preserve">
          <source>Return the log of probability estimates.</source>
          <target state="translated">返回概率估计的对数。</target>
        </trans-unit>
        <trans-unit id="ffd6e743e192ad562c49919b7b3f381f35e7b8ab" translate="yes" xml:space="preserve">
          <source>Return the log-likelihood of each sample.</source>
          <target state="translated">返回每个样本的对数似然。</target>
        </trans-unit>
        <trans-unit id="3b5cedcac6a255d68b2e31008e50600532cc0eda" translate="yes" xml:space="preserve">
          <source>Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty.</source>
          <target state="translated">返回C的最低边界,使C在(l1_min_C,无穷大)的模型保证不为空。</target>
        </trans-unit>
        <trans-unit id="a912065a7d66fe8acf25546053bf0686946ff49b" translate="yes" xml:space="preserve">
          <source>Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty. This applies to l1 penalized classifiers, such as LinearSVC with penalty=&amp;rsquo;l1&amp;rsquo; and linear_model.LogisticRegression with penalty=&amp;rsquo;l1&amp;rsquo;.</source>
          <target state="translated">返回C的最低界限，以确保对于（l1_min_C，infinity）中的C，模型不会为空。这适用于l1惩罚分类器，例如：惩罚为'l1'的LinearSVC和惩罚为'l1'的linear_model.LogisticRegression。</target>
        </trans-unit>
        <trans-unit id="78a008335b51a1c18596b7219334c44cdd4577a2" translate="yes" xml:space="preserve">
          <source>Return the number of CPUs.</source>
          <target state="translated">返回CPU的数量。</target>
        </trans-unit>
        <trans-unit id="a83e61f9ab288a41ba43637db7406ca5b7c5e918" translate="yes" xml:space="preserve">
          <source>Return the path of the scikit-learn data dir.</source>
          <target state="translated">返回 scikit-learn data dir 的路径。</target>
        </trans-unit>
        <trans-unit id="e508a8be5b82335ceafdbaf1e6ec3bbbf998c2f8" translate="yes" xml:space="preserve">
          <source>Return the shortest path length from source to all reachable nodes.</source>
          <target state="translated">返回从源点到所有可到达节点的最短路径长度。</target>
        </trans-unit>
        <trans-unit id="f99cff8804146f956c46d41c82ff30a32fcfa0ff" translate="yes" xml:space="preserve">
          <source>Returns -1 for anomalies/outliers and +1 for inliers.</source>
          <target state="translated">异常值/离群值为-1,离群值为+1。</target>
        </trans-unit>
        <trans-unit id="7411aff2f211ce9f855fdd4f002eb6a53a8bb626" translate="yes" xml:space="preserve">
          <source>Returns -1 for anomalies/outliers and 1 for inliers.</source>
          <target state="translated">异常值/离群值为-1,离群值为1。</target>
        </trans-unit>
        <trans-unit id="414e03f46831714a940e3ebbea4ecf95a3ebf408" translate="yes" xml:space="preserve">
          <source>Returns -1 for outliers and 1 for inliers.</source>
          <target state="translated">离群值为-1,离群值为1。</target>
        </trans-unit>
        <trans-unit id="505b1feca885daf978e29c8dabb245621a145944" translate="yes" xml:space="preserve">
          <source>Returns True if the given estimator is (probably) a classifier.</source>
          <target state="translated">如果给定的估计器是(可能)一个分类器,则返回True。</target>
        </trans-unit>
        <trans-unit id="a673678f28284206e4f771d2c532b3a9bf68458b" translate="yes" xml:space="preserve">
          <source>Returns True if the given estimator is (probably) a regressor.</source>
          <target state="translated">如果给定的估计器是(可能)一个回归器,则返回True。</target>
        </trans-unit>
        <trans-unit id="6877982ee547361eeeaa47d8ae2bb2ebf61437c5" translate="yes" xml:space="preserve">
          <source>Returns a clone of self with given hyperparameters theta.</source>
          <target state="translated">Returns a clone of self with given hyperparameters theta.</target>
        </trans-unit>
        <trans-unit id="8748a6c3e3b86a33a87860e1f928708591c21db6" translate="yes" xml:space="preserve">
          <source>Returns a dictionary of shortest path lengths keyed by target.</source>
          <target state="translated">返回由目标键入的最短路径长度字典。</target>
        </trans-unit>
        <trans-unit id="01c8da86ba8963c8f5e129fe43566909448c21a8" translate="yes" xml:space="preserve">
          <source>Returns a dynamically generated list of indices identifying the samples used for fitting each member of the ensemble, i.e., the in-bag samples.</source>
          <target state="translated">Returns a dynamically generated list of indices identifying samples used for fitting each member of the ensemble,namely,the in-bag samples.</target>
        </trans-unit>
        <trans-unit id="da4e687b702358c2c6b9e13a18e3175368903c06" translate="yes" xml:space="preserve">
          <source>Returns a full set of errors in case of multioutput input.</source>
          <target state="translated">在多输出输入的情况下,返回完整的错误集。</target>
        </trans-unit>
        <trans-unit id="36c74e5d06437c1c84b60b753285776e0a5a1083" translate="yes" xml:space="preserve">
          <source>Returns a full set of errors when the input is of multioutput format.</source>
          <target state="translated">当输入为多输出格式时,返回完整的错误集。</target>
        </trans-unit>
        <trans-unit id="70a672002707e9c7e153c69bb8b9bb04e4527348" translate="yes" xml:space="preserve">
          <source>Returns a full set of scores in case of multioutput input.</source>
          <target state="translated">在多输出输入的情况下,返回一组完整的分数。</target>
        </trans-unit>
        <trans-unit id="71c211cc8f7f96892c718bc1f6426bd958810763" translate="yes" xml:space="preserve">
          <source>Returns a huge value if none of the values are positive</source>
          <target state="translated">如果没有一个值是正值,则返回一个巨大的值。</target>
        </trans-unit>
        <trans-unit id="c704a97342e188146c3d1b7928d3c17a32957021" translate="yes" xml:space="preserve">
          <source>Returns a list of all hyperparameter specifications.</source>
          <target state="translated">返回所有超参数规格的列表。</target>
        </trans-unit>
        <trans-unit id="f0d7bca3b8b9fe8627158f5f4641022fd8b2f454" translate="yes" xml:space="preserve">
          <source>Returns a list of all hyperparameter.</source>
          <target state="translated">返回所有超参数的列表。</target>
        </trans-unit>
        <trans-unit id="bb51cbfb04bccafd184fd622b215d0ec11a12190" translate="yes" xml:space="preserve">
          <source>Returns a list of feature names, ordered by their indices.</source>
          <target state="translated">返回特征名称的列表,按其指数排序。</target>
        </trans-unit>
        <trans-unit id="34ea8d8a85c45dcfc562bcba86a58c905c99f874" translate="yes" xml:space="preserve">
          <source>Returns a matrix Y = DX, such as D is (n_features, n_components), X is (n_components, n_samples) and each column of X has exactly n_nonzero_coefs non-zero elements.</source>
          <target state="translated">返回一个矩阵Y=DX,如D是(n_features,n_components),X是(n_components,n_samples),X的每一列正好有n_nonzero_coefs非零元素。</target>
        </trans-unit>
        <trans-unit id="cbd0ed4e4005716c4bb4e960f578be5923f377b9" translate="yes" xml:space="preserve">
          <source>Returns an array X_original whose transform would be X.</source>
          <target state="translated">返回一个数组X_original,其变换为X。</target>
        </trans-unit>
        <trans-unit id="84c9e08b5d96fb6a7f3433674a11022fa61c7b88" translate="yes" xml:space="preserve">
          <source>Returns an array of the weighted modal (most common) value in a</source>
          <target state="translated">Returns an array of the weighted modal (most common)value in a...返回一个加权模态(最常见)值的数组。</target>
        </trans-unit>
        <trans-unit id="cafe057316f9911839a97b088931d3f0c5ac396b" translate="yes" xml:space="preserve">
          <source>Returns an instance of self.</source>
          <target state="translated">返回一个self的实例。</target>
        </trans-unit>
        <trans-unit id="2d37a031c71fcea2fed996bf43e20f28042d6cc2" translate="yes" xml:space="preserve">
          <source>Returns log-marginal likelihood of theta for training data.</source>
          <target state="translated">Returns log-marginal likelihood of theta for training data.</target>
        </trans-unit>
        <trans-unit id="c002970075885e58132251c6f46e809263939e08" translate="yes" xml:space="preserve">
          <source>Returns n_neighbors of approximate nearest neighbors.</source>
          <target state="translated">返回近似近邻的n_neighbors。</target>
        </trans-unit>
        <trans-unit id="fb2b7fa44b969b1b6614fbbe40b707fac7d6b54e" translate="yes" xml:space="preserve">
          <source>Returns predicted values.</source>
          <target state="translated">返回预测值。</target>
        </trans-unit>
        <trans-unit id="f4e6d32f29d1d2d6a2a4394141451d982c2d35a7" translate="yes" xml:space="preserve">
          <source>Returns self.</source>
          <target state="translated">返回自我。</target>
        </trans-unit>
        <trans-unit id="f6e9e9452782912bdbe94ae5d3a76dedbe086889" translate="yes" xml:space="preserve">
          <source>Returns the (flattened, log-transformed) non-fixed hyperparameters.</source>
          <target state="translated">返回(扁平化的、对数变换的)非固定超参数。</target>
        </trans-unit>
        <trans-unit id="19320b32e9aad6f858ca5ff0ef70b9bfebd867d9" translate="yes" xml:space="preserve">
          <source>Returns the (unshifted) scoring function of the samples.</source>
          <target state="translated">Returns the (unshifted)scoring function of the samples.</target>
        </trans-unit>
        <trans-unit id="657787f70ef4c51706bb87e28d19c4b31968ad05" translate="yes" xml:space="preserve">
          <source>Returns the &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; members.</source>
          <target state="translated">返回 &lt;code&gt;rows_&lt;/code&gt; 和 &lt;code&gt;columns_&lt;/code&gt; 成员。</target>
        </trans-unit>
        <trans-unit id="9a7a0a83f8ee3f88fa0c20189c0d4ac30a4fefe0" translate="yes" xml:space="preserve">
          <source>Returns the average of the array elements. The average is taken over the flattened array by default, otherwise over the specified axis. &lt;code&gt;float64&lt;/code&gt; intermediate and return values are used for integer inputs.</source>
          <target state="translated">返回数组元素的平均值。默认情况下，平均值取自展平的数组，否则取自指定的轴。 &lt;code&gt;float64&lt;/code&gt; 中间值和返回值用于整数输入。</target>
        </trans-unit>
        <trans-unit id="eb649861f38c5cc5c11712f4796a00d44a843890" translate="yes" xml:space="preserve">
          <source>Returns the coefficient of determination R^2 of the prediction.</source>
          <target state="translated">Returns the coefficient of determination R^2 of the prediction.</target>
        </trans-unit>
        <trans-unit id="b876cb187b297f2f67823973e339ef65d6c6d93d" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the sample for each class in the model. If decision_function_shape=&amp;rsquo;ovr&amp;rsquo;, the shape is (n_samples, n_classes)</source>
          <target state="translated">返回模型中每个类的样本决策函数。如果Decision_function_shape ='ovr'，则形状为（n_samples，n_classes）</target>
        </trans-unit>
        <trans-unit id="600321ecf92967e7d8dd43e86b0331fbf58144c8" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the sample for each model in the chain.</source>
          <target state="translated">返回链中每个模型的样本决策函数。</target>
        </trans-unit>
        <trans-unit id="f91d241e5e86a06081e46089c96ee552294a8b33" translate="yes" xml:space="preserve">
          <source>Returns the decision function of the samples.</source>
          <target state="translated">返回样本的决策函数。</target>
        </trans-unit>
        <trans-unit id="e78ab037aacacbbe51c5cf862f1aafc8648493d5" translate="yes" xml:space="preserve">
          <source>Returns the diagonal of the kernel k(X, X).</source>
          <target state="translated">返回k(X,X)核的对角线。</target>
        </trans-unit>
        <trans-unit id="574020c30b95a24e61673be93c56847aa7847d5e" translate="yes" xml:space="preserve">
          <source>Returns the distance of each sample from the decision boundary for each class.</source>
          <target state="translated">返回每个类的每个样本与决策边界的距离。</target>
        </trans-unit>
        <trans-unit id="be77bb9a28472ddd253b8a1ae1c648a1964afb4c" translate="yes" xml:space="preserve">
          <source>Returns the distance of each sample from the decision boundary for each class. This can only be used with estimators which implement the decision_function method.</source>
          <target state="translated">返回每个类的每个样本与决策边界的距离。这只能用于实现 decision_function 方法的估计器。</target>
        </trans-unit>
        <trans-unit id="b7fd90b44e187b56f57ca6954d88dd8f4e918ac9" translate="yes" xml:space="preserve">
          <source>Returns the distances of neighbors if set to True.</source>
          <target state="translated">如果设置为True,则返回邻居的距离。</target>
        </trans-unit>
        <trans-unit id="0736b2ffe9fa12ffc65d7dbeeef31b8086537469" translate="yes" xml:space="preserve">
          <source>Returns the index of the leaf that each sample is predicted as.</source>
          <target state="translated">返回每个样本被预测的叶子的索引。</target>
        </trans-unit>
        <trans-unit id="57ddd1698c4b02ed38d78d51bae715493abba55a" translate="yes" xml:space="preserve">
          <source>Returns the instance itself.</source>
          <target state="translated">返回实例本身。</target>
        </trans-unit>
        <trans-unit id="5121a7f65d8a5a923df4edf2decfc8ea51b437d5" translate="yes" xml:space="preserve">
          <source>Returns the log probability of the sample for each class in the model, where classes are ordered arithmetically for each output.</source>
          <target state="translated">返回模型中每个类的样本的对数概率,其中类对每个输出进行算术排序。</target>
        </trans-unit>
        <trans-unit id="be2a6279ffe3800dbed75602bf2c1d5d359b2ac2" translate="yes" xml:space="preserve">
          <source>Returns the log-probabilities of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">返回模型中每个类的样本的对数概率。列按类别顺序对应于类，因为它们出现在属性 &lt;code&gt;classes_&lt;/code&gt; 中。</target>
        </trans-unit>
        <trans-unit id="a5f0cb89d1ff1d82c8d766a8c85156fc08daf322" translate="yes" xml:space="preserve">
          <source>Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;.</source>
          <target state="translated">返回模型中每个类的样本的对数概率，其中类按照它们在 &lt;code&gt;self.classes_&lt;/code&gt; 中的顺序进行排序。</target>
        </trans-unit>
        <trans-unit id="fbd0270f78921c5ba9ddfa30e030482e2f54f42a" translate="yes" xml:space="preserve">
          <source>Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">返回模型中每个类的样本的对数概率。列按类别顺序对应于类，因为它们出现在属性 &lt;code&gt;classes_&lt;/code&gt; 中。</target>
        </trans-unit>
        <trans-unit id="a88bc22b9f72540c221027a9d39ebb7e5fc56ef0" translate="yes" xml:space="preserve">
          <source>Returns the log-transformed bounds on the theta.</source>
          <target state="translated">返回Theta的对数变换边界。</target>
        </trans-unit>
        <trans-unit id="97643d048879fe1d9046d0bda61e3506826edf2e" translate="yes" xml:space="preserve">
          <source>Returns the mean accuracy on the given test data and labels.</source>
          <target state="translated">返回给定测试数据和标签的平均精度。</target>
        </trans-unit>
        <trans-unit id="16bf89209ad0d6f3c40effbaf06ac2b2bd9f54f6" translate="yes" xml:space="preserve">
          <source>Returns the number of non-fixed hyperparameters of the kernel.</source>
          <target state="translated">返回内核的非固定超参数的数量。</target>
        </trans-unit>
        <trans-unit id="242d74929fe683a12c5d1964cc2e68959bffb690" translate="yes" xml:space="preserve">
          <source>Returns the number of splitting iterations in the cross-validator</source>
          <target state="translated">返回交叉验证器的分割迭代次数。</target>
        </trans-unit>
        <trans-unit id="7cfde4bf50ea94882908403c6cfbc382caa0a24b" translate="yes" xml:space="preserve">
          <source>Returns the number of splitting iterations in the cross-validator.</source>
          <target state="translated">返回交叉验证器中分割迭代的次数。</target>
        </trans-unit>
        <trans-unit id="062b49944b8da81fbcccbc3d275c30eb3575a9c8" translate="yes" xml:space="preserve">
          <source>Returns the object itself</source>
          <target state="translated">返回对象本身</target>
        </trans-unit>
        <trans-unit id="a733465cae828526edae8695b9480711c0093299" translate="yes" xml:space="preserve">
          <source>Returns the probability each Gaussian (state) in the model given each sample.</source>
          <target state="translated">Returns the probability each Gaussian (state)in the model given each sample.</target>
        </trans-unit>
        <trans-unit id="55dd4118273bb853d106f8d3ce6ecf4f148e2ce6" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model, where classes are ordered arithmetically, for each output.</source>
          <target state="translated">Returns the probability of the sample for each class in the model,where classes are ordered by arithmetically,for each output.</target>
        </trans-unit>
        <trans-unit id="169e349ed5581ba23a1b3967826f1082ad70f358" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;.</source>
          <target state="translated">返回模型中每个类的样本概率，其中类按照它们在 &lt;code&gt;self.classes_&lt;/code&gt; 中的顺序排序。</target>
        </trans-unit>
        <trans-unit id="3d7831ef98ef99639d4e7e4296f84556b7eba4a8" translate="yes" xml:space="preserve">
          <source>Returns the probability of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">返回模型中每个类的样本概率。列按类别顺序对应于类，因为它们出现在属性 &lt;code&gt;classes_&lt;/code&gt; 中。</target>
        </trans-unit>
        <trans-unit id="992c84bb142fb4e9f8a180866eff97d2128f0434" translate="yes" xml:space="preserve">
          <source>Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute &lt;code&gt;classes_&lt;/code&gt;.</source>
          <target state="translated">返回模型中每个类的样本概率。列按类别顺序对应于类，因为它们出现在属性 &lt;code&gt;classes_&lt;/code&gt; 中。</target>
        </trans-unit>
        <trans-unit id="91d445ad5de7a1e173775e4a8269cced0a330589" translate="yes" xml:space="preserve">
          <source>Returns the score of the model on the data X</source>
          <target state="translated">返回模型在数据X上的得分。</target>
        </trans-unit>
        <trans-unit id="f46bd5d1c2974b7fae37f8d3dfead452c6f632de" translate="yes" xml:space="preserve">
          <source>Returns the score of the prediction.</source>
          <target state="translated">返回预测的得分。</target>
        </trans-unit>
        <trans-unit id="860029a1d62d045e78979ea6dcc0cc94815fbc22" translate="yes" xml:space="preserve">
          <source>Returns the score on the given data, if the estimator has been refit.</source>
          <target state="translated">如果估计器被重新安装,返回给定数据的得分。</target>
        </trans-unit>
        <trans-unit id="ec85c2a1a827e7e3cec445aa44a3ba7f1fb3772b" translate="yes" xml:space="preserve">
          <source>Returns the score using the &lt;code&gt;scoring&lt;/code&gt; option on the given test data and labels.</source>
          <target state="translated">使用给定测试数据和标签上的 &lt;code&gt;scoring&lt;/code&gt; 选项返回分数。</target>
        </trans-unit>
        <trans-unit id="4f35f765fc0b19f20a03c16dab251d424926e332" translate="yes" xml:space="preserve">
          <source>Returns the submatrix corresponding to bicluster &lt;code&gt;i&lt;/code&gt;.</source>
          <target state="translated">返回与bicluster &lt;code&gt;i&lt;/code&gt; 对应的子矩阵。</target>
        </trans-unit>
        <trans-unit id="054a9a6e8f30544993a8a15fc5be2d4e55b3432a" translate="yes" xml:space="preserve">
          <source>Returns the transformer object.</source>
          <target state="translated">返回变压器对象。</target>
        </trans-unit>
        <trans-unit id="99d4a1b8b2f5f3c702de280e61afe0632ca64c65" translate="yes" xml:space="preserve">
          <source>Returns the transformer.</source>
          <target state="translated">返回变压器。</target>
        </trans-unit>
        <trans-unit id="1cf9d50da5b8378604942b3c0df2a2210aa8a416" translate="yes" xml:space="preserve">
          <source>Returns whether the kernel is stationary.</source>
          <target state="translated">Returns whether the kernel is stationary.</target>
        </trans-unit>
        <trans-unit id="7749fcf802c472b6c2f5bd0556805e456ffd5674" translate="yes" xml:space="preserve">
          <source>Returns:</source>
          <target state="translated">Returns:</target>
        </trans-unit>
        <trans-unit id="4cddff2f4be571d7beaa9444607024440a9fab7c" translate="yes" xml:space="preserve">
          <source>Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories made available by Reuters, Ltd. for research purposes. The dataset is extensively described in &lt;a href=&quot;#id9&quot; id=&quot;id7&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">路透社语料库第一卷（RCV1）是由Reuters，Ltd.出于研究目的而提供的800,000多个手动分类新闻专线报道的档案。数据集在&lt;a href=&quot;#id9&quot; id=&quot;id7&quot;&gt;[1]中进行了&lt;/a&gt;广泛描述。</target>
        </trans-unit>
        <trans-unit id="99e73709f3009df888327fcabb8674ce816a184a" translate="yes" xml:space="preserve">
          <source>Reuters Dataset related routines</source>
          <target state="translated">路透社数据集相关例程</target>
        </trans-unit>
        <trans-unit id="6601972f4e7c617814e4aa25931a1506c8822de1" translate="yes" xml:space="preserve">
          <source>Revealing data that lie in multiple, different, manifolds or clusters</source>
          <target state="translated">揭示位于多个、不同的表层或簇中的数据。</target>
        </trans-unit>
        <trans-unit id="f8d44f2683a18a11847619bb1e3f869a99808298" translate="yes" xml:space="preserve">
          <source>Revealing the structure at many scales on a single map</source>
          <target state="translated">在一张地图上揭示多种尺度的结构。</target>
        </trans-unit>
        <trans-unit id="e69284bfe1901a9177c5faf2810c62e97f3c9a53" translate="yes" xml:space="preserve">
          <source>Reverse the transformation operation</source>
          <target state="translated">反转转换操作</target>
        </trans-unit>
        <trans-unit id="c73f8d477c79109041865780eba0a7fa3d48301f" translate="yes" xml:space="preserve">
          <source>Ridge classifier</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ad4f2cdfdad42fbcf62f66b6cf545d851e2fc3f" translate="yes" xml:space="preserve">
          <source>Ridge classifier with built-in cross validation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74be3b618f2a083f8a9b4da6cc819c2a6587f706" translate="yes" xml:space="preserve">
          <source>Ridge classifier with built-in cross-validation.</source>
          <target state="translated">脊分类器,内置交叉验证。</target>
        </trans-unit>
        <trans-unit id="ed75d75f775d982f734209b7c7a763a7209d7d4d" translate="yes" xml:space="preserve">
          <source>Ridge regression</source>
          <target state="translated">脊线回归</target>
        </trans-unit>
        <trans-unit id="ab3890b5c3a5eec9daaf653c629ead9cfec0f465" translate="yes" xml:space="preserve">
          <source>Ridge regression is basically minimizing a penalised version of the least-squared function. The penalising &lt;code&gt;shrinks&lt;/code&gt; the value of the regression coefficients. Despite the few data points in each dimension, the slope of the prediction is much more stable and the variance in the line itself is greatly reduced, in comparison to that of the standard linear regression</source>
          <target state="translated">Ridge回归基本上是最小化最小二乘函数的惩罚形式。惩罚 &lt;code&gt;shrinks&lt;/code&gt; 了回归系数的值。尽管每个维度上的数据点都很少，但与标准线性回归相比，预测的斜率要稳定得多，并且直线本身的方差大大减少</target>
        </trans-unit>
        <trans-unit id="6f1409ad2637ad7ea4da4ca38bcc785d5bfc9e7b" translate="yes" xml:space="preserve">
          <source>Ridge regression with built-in cross validation</source>
          <target state="translated">内置交叉验证的岭回归</target>
        </trans-unit>
        <trans-unit id="fd3c67b92ef64e74b0815493290cb7a3bf85e6f3" translate="yes" xml:space="preserve">
          <source>Ridge regression with built-in cross-validation.</source>
          <target state="translated">脊回归,内置交叉验证。</target>
        </trans-unit>
        <trans-unit id="ee45b6f0ae2d4ed0129b8acfc2869825bd85e481" translate="yes" xml:space="preserve">
          <source>Ridgeway, &amp;ldquo;Generalized Boosted Models: A guide to the gbm package&amp;rdquo;, 2007</source>
          <target state="translated">Ridgeway，&amp;ldquo;广义增强模型：gbm软件包指南&amp;rdquo;，2007年</target>
        </trans-unit>
        <trans-unit id="8352081cfa5d8a99ae7d273942336fb93f08e6d3" translate="yes" xml:space="preserve">
          <source>Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.</source>
          <target state="translated">返回的内核k(X,Y)的右参数。如果没有,则用k(X,X)代替。</target>
        </trans-unit>
        <trans-unit id="2645e9d1a378ec5a701c32478a48af53bc8241e0" translate="yes" xml:space="preserve">
          <source>Roberto Perdisci JBirch - Java implementation of BIRCH clustering algorithm &lt;a href=&quot;https://code.google.com/archive/p/jbirch&quot;&gt;https://code.google.com/archive/p/jbirch&lt;/a&gt;</source>
          <target state="translated">Roberto Perdisci JBirch-BIRCH群集算法的Java实现&lt;a href=&quot;https://code.google.com/archive/p/jbirch&quot;&gt;https://code.google.com/archive/p/jbirch&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6cf9f332d60931812bd314aa88e28fabc6bcb34e" translate="yes" xml:space="preserve">
          <source>Robust covariance estimation and Mahalanobis distances relevance</source>
          <target state="translated">稳健的协方差估计和Mahalanobis距离的相关性</target>
        </trans-unit>
        <trans-unit id="328dcbba68a9846c5e7033a860bdea23249dfaea" translate="yes" xml:space="preserve">
          <source>Robust fitting is demoed in different situations:</source>
          <target state="translated">稳健拟合在不同情况下进行演示。</target>
        </trans-unit>
        <trans-unit id="165bec40e6cdbbb5b900c937da314f589c12c4da" translate="yes" xml:space="preserve">
          <source>Robust linear estimator fitting</source>
          <target state="translated">稳健的线性估计器拟合</target>
        </trans-unit>
        <trans-unit id="6d0888c61d68e6fb252eed4a871cfde78643505b" translate="yes" xml:space="preserve">
          <source>Robust linear model estimation using RANSAC</source>
          <target state="translated">使用RANSAC进行稳健的线性模型估计。</target>
        </trans-unit>
        <trans-unit id="23aa26f47001b43f39b1c12966fa2eb9a36e10dc" translate="yes" xml:space="preserve">
          <source>Robust regression is interested in fitting a regression model in the presence of corrupt data: either outliers, or error in the model.</source>
          <target state="translated">稳健回归对在存在腐败数据的情况下拟合回归模型感兴趣:要么是离群值,要么是模型中的误差。</target>
        </trans-unit>
        <trans-unit id="e1c857b593e499d6b23d149cc792aa8d43d0a1b9" translate="yes" xml:space="preserve">
          <source>Robust vs Empirical covariance estimate</source>
          <target state="translated">稳健与经验方差估计的比较</target>
        </trans-unit>
        <trans-unit id="6a7d1b999eca5ec26d95619619667b3c0bc96c39" translate="yes" xml:space="preserve">
          <source>RobustScaler</source>
          <target state="translated">RobustScaler</target>
        </trans-unit>
        <trans-unit id="cf1505b8a53e6cbb8dc8ba2f11bca53f9b323bb5" translate="yes" xml:space="preserve">
          <source>Robustness to outliers in output space (via robust loss functions)</source>
          <target state="translated">对输出空间异常值的稳健性(通过稳健损失函数)</target>
        </trans-unit>
        <trans-unit id="4e83213080c2899f47c79669335c5a49e2d9bcc2" translate="yes" xml:space="preserve">
          <source>RogersTanimotoDistance</source>
          <target state="translated">RogersTanimotoDistance</target>
        </trans-unit>
        <trans-unit id="fc05bb810ef4352b5a9e6b3b3412f9c1914cad7e" translate="yes" xml:space="preserve">
          <source>Root of the CFTree.</source>
          <target state="translated">CFTree的根。</target>
        </trans-unit>
        <trans-unit id="b104e71c68c3dfb7b73342e69442ee327c52c9d1" translate="yes" xml:space="preserve">
          <source>Rosenberg and Hirschberg further define &lt;strong&gt;V-measure&lt;/strong&gt; as the &lt;strong&gt;harmonic mean of homogeneity and completeness&lt;/strong&gt;:</source>
          <target state="translated">Rosenberg和Hirschberg进一步将&lt;strong&gt;V-measure&lt;/strong&gt;定义&lt;strong&gt;为均匀性和完整性&lt;/strong&gt;的&lt;strong&gt;调和平均值&lt;/strong&gt;：</target>
        </trans-unit>
        <trans-unit id="e15211ffc09c4f35527c5b1ce8949f07dae5bb18" translate="yes" xml:space="preserve">
          <source>Ross, J. Lim, R. Lin, M. Yang. Incremental Learning for Robust Visual</source>
          <target state="translated">Ross,J.Lim,R.Lin,M.Yang.稳健视觉的增量学习</target>
        </trans-unit>
        <trans-unit id="3f65ad777cccbda986726bad67a79a0d4e6952a1" translate="yes" xml:space="preserve">
          <source>Rousseeuw and Van Driessen &lt;a href=&quot;#id12&quot; id=&quot;id10&quot;&gt;[4]&lt;/a&gt; developed the FastMCD algorithm in order to compute the Minimum Covariance Determinant. This algorithm is used in scikit-learn when fitting an MCD object to data. The FastMCD algorithm also computes a robust estimate of the data set location at the same time.</source>
          <target state="translated">Rousseeuw和Van Driessen &lt;a href=&quot;#id12&quot; id=&quot;id10&quot;&gt;[4]&lt;/a&gt;开发了FastMCD算法，以计算最小协方差行列式。将MCD对象拟合到数据时，此算法在scikit-learn中使用。FastMCD算法还可以同时计算数据集位置的可靠估计。</target>
        </trans-unit>
        <trans-unit id="ae08282270da387413c613e92da23758e2b46e3a" translate="yes" xml:space="preserve">
          <source>Rousseeuw, P.J., Van Driessen, K. &amp;ldquo;A fast algorithm for the minimum covariance determinant estimator&amp;rdquo; Technometrics 41(3), 212 (1999)</source>
          <target state="translated">Rousseeuw，PJ，Van Driessen，K.&amp;ldquo;最小协方差行列式估计器的快速算法&amp;rdquo; Technometrics 41（3），212（1999）</target>
        </trans-unit>
        <trans-unit id="a147028da41451d64de65dc97e27ab58134df945" translate="yes" xml:space="preserve">
          <source>Row and column indices of the i&amp;rsquo;th bicluster.</source>
          <target state="translated">第i个bicluster的行和列索引。</target>
        </trans-unit>
        <trans-unit id="dff2cf4a000d72bb07a097b831cbf5d2768a6505" translate="yes" xml:space="preserve">
          <source>Row partition labels.</source>
          <target state="translated">行分区标签。</target>
        </trans-unit>
        <trans-unit id="173c6825d2552deeb977ce21a1b427b130c7161e" translate="yes" xml:space="preserve">
          <source>Run check_array on X.</source>
          <target state="translated">在X上运行check_array。</target>
        </trans-unit>
        <trans-unit id="6650ce15c2e2f568588d9785e121ddc90d1aad0a" translate="yes" xml:space="preserve">
          <source>Run cross-validation for single metric evaluation.</source>
          <target state="translated">运行交叉验证进行单指标评价。</target>
        </trans-unit>
        <trans-unit id="76efb9e1238b374a0b90938642b1634441ade412" translate="yes" xml:space="preserve">
          <source>Run fit on one set of parameters.</source>
          <target state="translated">在一组参数上运行拟合。</target>
        </trans-unit>
        <trans-unit id="b3fa8caf4882a1b3e630b18ced7d9eb65515b91e" translate="yes" xml:space="preserve">
          <source>Run fit with all sets of parameters.</source>
          <target state="translated">用所有参数集运行拟合。</target>
        </trans-unit>
        <trans-unit id="383d7fee23c4f0d9aff2e3402febc2f06b463f07" translate="yes" xml:space="preserve">
          <source>Run score function on (X, y) and get the appropriate features.</source>
          <target state="translated">在(X,y)上运行得分函数,得到相应的特征。</target>
        </trans-unit>
        <trans-unit id="75c05d3e2177d247ba4a31fbd998a4fb5a5db366" translate="yes" xml:space="preserve">
          <source>Run the clustering and plot</source>
          <target state="translated">运行聚类并绘制</target>
        </trans-unit>
        <trans-unit id="5095c28abb8c39013ff6dacae123b7ebc126a8c4" translate="yes" xml:space="preserve">
          <source>Running &lt;code&gt;GridSearchCV&lt;/code&gt; using multiple evaluation metrics</source>
          <target state="translated">使用多个评估指标运行 &lt;code&gt;GridSearchCV&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0fcbd6be054955e185bc7730125f0a6053dc76b6" translate="yes" xml:space="preserve">
          <source>RussellRaoDistance</source>
          <target state="translated">RussellRaoDistance</target>
        </trans-unit>
        <trans-unit id="3d35c7a842c5951e6e7d27253c473500693538e4" translate="yes" xml:space="preserve">
          <source>S. Marsland, &amp;ldquo;Machine Learning: An Algorithmic Perspective&amp;rdquo;, Chapter 10, 2009. &lt;a href=&quot;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&quot;&gt;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&lt;/a&gt;</source>
          <target state="translated">S. Marsland，&amp;ldquo;机器学习：算法视角&amp;rdquo;，2009年，第10章&lt;a href=&quot;http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py&quot;&gt;。http://seat.massey.ac.nz/personal/srmarsland/Code/10/lle.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1c12fa511d52194a5681ee8be41a1e398d85f290" translate="yes" xml:space="preserve">
          <source>S1</source>
          <target state="translated">S1</target>
        </trans-unit>
        <trans-unit id="474c9bc027ee3ef22851a5f8bfd976f08b197386" translate="yes" xml:space="preserve">
          <source>S2</source>
          <target state="translated">S2</target>
        </trans-unit>
        <trans-unit id="37a81d7cd2e4b8f7f2a8a35b26aa90c58c80afd8" translate="yes" xml:space="preserve">
          <source>S3</source>
          <target state="translated">S3</target>
        </trans-unit>
        <trans-unit id="69c195a662b9112a35f65e12d131a5b27ca87f2b" translate="yes" xml:space="preserve">
          <source>S4</source>
          <target state="translated">S4</target>
        </trans-unit>
        <trans-unit id="c3371c7d85f3802028519c691cc2d442bd72de40" translate="yes" xml:space="preserve">
          <source>S5</source>
          <target state="translated">S5</target>
        </trans-unit>
        <trans-unit id="69ba3f2fc09a1e00fed9f31e478c0eff5dced9e9" translate="yes" xml:space="preserve">
          <source>S6</source>
          <target state="translated">S6</target>
        </trans-unit>
        <trans-unit id="4c804f5a0904acd450fcddddab0dc632cd582e71" translate="yes" xml:space="preserve">
          <source>SA structure :</source>
          <target state="translated">SA结构:</target>
        </trans-unit>
        <trans-unit id="c0d8a0ca44b0696f5feb9dd5b2e501345c937c3c" translate="yes" xml:space="preserve">
          <source>SAG &amp;ndash; Mark Schmidt, Nicolas Le Roux, and Francis Bach</source>
          <target state="translated">凹陷-马克&amp;middot;施密特（Mark Schmidt），尼古拉斯&amp;middot;勒&amp;middot;鲁（Nicolas Le Roux）和弗朗西斯&amp;middot;巴赫（Francis Bach）</target>
        </trans-unit>
        <trans-unit id="b5f439b003a3f7bf1ca666e889005dbe06e41518" translate="yes" xml:space="preserve">
          <source>SAGA &amp;ndash; Defazio, A., Bach F. &amp;amp; Lacoste-Julien S. (2014).</source>
          <target state="translated">SAGA &amp;ndash; Defazio，A.，Bach F.＆Lacoste-Julien S.（2014）。</target>
        </trans-unit>
        <trans-unit id="5d555084f4d87558b3e1f1e41594c4567a72ffe9" translate="yes" xml:space="preserve">
          <source>SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives &lt;a href=&quot;https://arxiv.org/abs/1407.0202&quot;&gt;https://arxiv.org/abs/1407.0202&lt;/a&gt;</source>
          <target state="translated">SAGA：一种快速增量梯度方法，支持非强凸复合物镜&lt;a href=&quot;https://arxiv.org/abs/1407.0202&quot;&gt;https://arxiv.org/abs/1407.0202&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="47b0a2b31abf5ad7f508685c420934a3c9ceb224" translate="yes" xml:space="preserve">
          <source>SEuclideanDistance</source>
          <target state="translated">SEuclideanDistance</target>
        </trans-unit>
        <trans-unit id="25a0a10d5e57106efcf106b18fe758dffe61fd61" translate="yes" xml:space="preserve">
          <source>SF structure :</source>
          <target state="translated">SF结构:</target>
        </trans-unit>
        <trans-unit id="feee827f58feab6583e46c495c391eeebda8d75f" translate="yes" xml:space="preserve">
          <source>SGD fits a linear model to the training data. The member &lt;code&gt;coef_&lt;/code&gt; holds the model parameters:</source>
          <target state="translated">SGD将线性模型拟合到训练数据。成员 &lt;code&gt;coef_&lt;/code&gt; 保存模型参数：</target>
        </trans-unit>
        <trans-unit id="35603e0805a9ac47c224548952c5bc406f24681d" translate="yes" xml:space="preserve">
          <source>SGD has been successfully applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. Given that the data is sparse, the classifiers in this module easily scale to problems with more than 10^5 training examples and more than 10^5 features.</source>
          <target state="translated">SGD已经成功应用于文本分类和自然语言处理中经常遇到的大规模和稀疏的机器学习问题。考虑到数据是稀疏的,该模块中的分类器很容易扩展到超过10^5个训练实例和超过10^5个特征的问题。</target>
        </trans-unit>
        <trans-unit id="56826c4ca309b6e5b6fa33e22889222819ef98da" translate="yes" xml:space="preserve">
          <source>SGD is sensitive to feature scaling.</source>
          <target state="translated">SGD对特征缩放很敏感。</target>
        </trans-unit>
        <trans-unit id="aaaef0a56ff89a9fec86986b723dbc52782459a2" translate="yes" xml:space="preserve">
          <source>SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.</source>
          <target state="translated">SGD需要一些超参数,如正则化参数和迭代次数。</target>
        </trans-unit>
        <trans-unit id="2040a5158079ffce24f8b06ceaf317e6a14bde86" translate="yes" xml:space="preserve">
          <source>SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).</source>
          <target state="translated">SGD是Stochastic Gradient Descent(随机梯度下降)的缩写:每次估计损失的梯度,并以递减的强度计划(也就是学习率)沿途更新模型。</target>
        </trans-unit>
        <trans-unit id="a5409a86e2f59aff11c69a7f4ca4772e4d726f18" translate="yes" xml:space="preserve">
          <source>SGD: Maximum margin separating hyperplane</source>
          <target state="translated">SGD:超平面的最大分隔余量</target>
        </trans-unit>
        <trans-unit id="18e5f1878526787df86a80bc190ed115937ff46a" translate="yes" xml:space="preserve">
          <source>SGD: Penalties</source>
          <target state="translated">新元:处罚</target>
        </trans-unit>
        <trans-unit id="ba517f5cdbbcd13a216515c00be2b80ddd3cbbe7" translate="yes" xml:space="preserve">
          <source>SGD: Weighted samples</source>
          <target state="translated">新元:加权样本</target>
        </trans-unit>
        <trans-unit id="641c7150d49f1de3baa1799ce8aa92905ea998a5" translate="yes" xml:space="preserve">
          <source>SGD: convex loss functions</source>
          <target state="translated">SGD:凸性损失函数</target>
        </trans-unit>
        <trans-unit id="cf02fe82611c518b4850cfb8c1c714a0440b4d08" translate="yes" xml:space="preserve">
          <source>SGDClassifier can optimize the same cost function as LinearSVC by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.</source>
          <target state="translated">SGDClassifier可以通过调整惩罚和损失参数来优化与LinearSVC相同的成本函数。此外,它需要较少的内存,允许增量(在线)学习,并实现了各种损失函数和正则化制度。</target>
        </trans-unit>
        <trans-unit id="bf24393981aae53fe434537eb506bff7add3be48" translate="yes" xml:space="preserve">
          <source>SGDRegressor can optimize the same cost function as LinearSVR by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.</source>
          <target state="translated">SGDRegressor可以通过调整惩罚和损失参数来优化与LinearSVR相同的成本函数。此外,它需要较少的内存,允许增量(在线)学习,并实现各种损失函数和正则化制度。</target>
        </trans-unit>
        <trans-unit id="176392773f6f864a2cd9bd404f4a47c5c644890a" translate="yes" xml:space="preserve">
          <source>SKLEARN_ASSUME_FINITE:</source>
          <target state="translated">SKLEARN_ASSUME_FINITE:</target>
        </trans-unit>
        <trans-unit id="489eb75f9c6e942df30f531fa00564449214dacd" translate="yes" xml:space="preserve">
          <source>SKLEARN_SEED:</source>
          <target state="translated">SKLEARN_SEED:</target>
        </trans-unit>
        <trans-unit id="fb52c7cf741e16036b16d4758134cf0347d8fc36" translate="yes" xml:space="preserve">
          <source>SKLEARN_SITE_JOBLIB:</source>
          <target state="translated">SKLEARN_SITE_JOBLIB:</target>
        </trans-unit>
        <trans-unit id="182f8430558645ae44ec3e02ca4f97fb187183b5" translate="yes" xml:space="preserve">
          <source>SKLEARN_SKIP_NETWORK_TESTS:</source>
          <target state="translated">SKLEARN_SKIP_NETWORK_TESTS:</target>
        </trans-unit>
        <trans-unit id="ce18ea047ea4320bf80e4467a9a4d6882d0a0c5c" translate="yes" xml:space="preserve">
          <source>SKLEARN_WORKING_MEMORY:</source>
          <target state="translated">SKLEARN_WORKING_MEMORY:</target>
        </trans-unit>
        <trans-unit id="85baaac41fa88b4fe00f7bdceca42996f772a2b4" translate="yes" xml:space="preserve">
          <source>SVD solver to use. Either &amp;ldquo;arpack&amp;rdquo; for the ARPACK wrapper in SciPy (scipy.sparse.linalg.svds), or &amp;ldquo;randomized&amp;rdquo; for the randomized algorithm due to Halko (2009).</source>
          <target state="translated">使用SVD求解器。由于Halko（2009），对于SciPy（scipy.sparse.linalg.svds）中的ARPACK包装器，要么是&amp;ldquo; arpack&amp;rdquo;，要么是随机算法的&amp;ldquo; randomized&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="6af7199e8ddc63c7a75cd98d1b65821ed0efc2bf" translate="yes" xml:space="preserve">
          <source>SVD suffers from a problem called &amp;ldquo;sign indeterminacy&amp;rdquo;, which means the sign of the &lt;code&gt;components_&lt;/code&gt; and the output from transform depend on the algorithm and random state. To work around this, fit instances of this class to data once, then keep the instance around to do transformations.</source>
          <target state="translated">SVD存在一个称为&amp;ldquo;符号不确定性&amp;rdquo;的问题，这意味着 &lt;code&gt;components_&lt;/code&gt; 的符号以及变换的输出取决于算法和随机状态。要解决此问题，请将此类的实例一次放入数据，然后保留该实例进行转换。</target>
        </trans-unit>
        <trans-unit id="cbdd2a97d41c59ff884c822b77e5bbe85f9ba90e" translate="yes" xml:space="preserve">
          <source>SVM Exercise</source>
          <target state="translated">SVM练习</target>
        </trans-unit>
        <trans-unit id="b34d9f0295b39d40cbe5096a7d120f8070675e5a" translate="yes" xml:space="preserve">
          <source>SVM Margins Example</source>
          <target state="translated">SVM边际示例</target>
        </trans-unit>
        <trans-unit id="9a8ae56c5c075834fc4807237ba47d91cf12057b" translate="yes" xml:space="preserve">
          <source>SVM with custom kernel</source>
          <target state="translated">自定义内核的SVM</target>
        </trans-unit>
        <trans-unit id="9789cc13908fc9d7be883f1548c74adba099c7a4" translate="yes" xml:space="preserve">
          <source>SVM-Anova: SVM with univariate feature selection</source>
          <target state="translated">SVM-Annova:单变量特征选择的SVM。</target>
        </trans-unit>
        <trans-unit id="1d60b833a10753cb7a1e8445b24053366a62c2ba" translate="yes" xml:space="preserve">
          <source>SVM-Kernels</source>
          <target state="translated">SVM-Kernels</target>
        </trans-unit>
        <trans-unit id="83aa3a7ffedeffc55020607871a4abaa66f7a1c9" translate="yes" xml:space="preserve">
          <source>SVM: Maximum margin separating hyperplane</source>
          <target state="translated">SVM。最大限度地分离超平面</target>
        </trans-unit>
        <trans-unit id="6eea5ef53cf13552f771a06f957229c9212aa8d7" translate="yes" xml:space="preserve">
          <source>SVM: Separating hyperplane for unbalanced classes</source>
          <target state="translated">SVM。不平衡类的分离超平面</target>
        </trans-unit>
        <trans-unit id="cf6b9fd9e8253b8b76eff229f07c0360f2de682d" translate="yes" xml:space="preserve">
          <source>SVM: Weighted samples</source>
          <target state="translated">SVM。加权样本</target>
        </trans-unit>
        <trans-unit id="85f0e3e6752e2995f480bc673dc3817c45715958" translate="yes" xml:space="preserve">
          <source>SVMs can be used in regression &amp;ndash;&lt;a href=&quot;../../modules/generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; (Support Vector Regression)&amp;ndash;, or in classification &amp;ndash;&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; (Support Vector Classification).</source>
          <target state="translated">SVM可用于回归&amp;ndash; &lt;a href=&quot;../../modules/generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt;（支持向量回归）&amp;ndash;或分类&amp;ndash; &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;（支持向量分类）。</target>
        </trans-unit>
        <trans-unit id="7b1be869f06df9c591de1bdf323bb61b2e38d27a" translate="yes" xml:space="preserve">
          <source>SVMs decision function depends on some subset of the training data, called the support vectors. Some properties of these support vectors can be found in members &lt;code&gt;support_vectors_&lt;/code&gt;, &lt;code&gt;support_&lt;/code&gt; and &lt;code&gt;n_support&lt;/code&gt;:</source>
          <target state="translated">SVM的决策功能取决于训练数据的某些子集，称为支持向量。这些支持向量的某些属性可以在成员 &lt;code&gt;support_vectors_&lt;/code&gt; ， &lt;code&gt;support_&lt;/code&gt; 和 &lt;code&gt;n_support&lt;/code&gt; 中找到：</target>
        </trans-unit>
        <trans-unit id="798a54068fd4b730861d7008bf329c0c0c2c0e43" translate="yes" xml:space="preserve">
          <source>SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see &lt;a href=&quot;#scores-probabilities&quot;&gt;Scores and probabilities&lt;/a&gt;, below).</source>
          <target state="translated">SVM不直接提供概率估计，而是使用昂贵的五倍交叉验证来计算的（请参阅下面的&lt;a href=&quot;#scores-probabilities&quot;&gt;得分和概率&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="db6e7e410412f58574f766c3911f49badd42beca" translate="yes" xml:space="preserve">
          <source>Safety</source>
          <target state="translated">Safety</target>
        </trans-unit>
        <trans-unit id="fda84c44a4e30d5cb2a98cb6be80221a0339a2c0" translate="yes" xml:space="preserve">
          <source>Same as K-Fold but preserves the class distribution within each fold.</source>
          <target state="translated">与K-Fold相同,但保留了每个褶皱内的类分布。</target>
        </trans-unit>
        <trans-unit id="3ee571b5564a06c8cd876b67cbf6301868feea05" translate="yes" xml:space="preserve">
          <source>Same as shuffle split but preserves the class distribution within each iteration.</source>
          <target state="translated">与shuffle split相同,但保留了每个迭代内的类分布。</target>
        </trans-unit>
        <trans-unit id="b7e9bc6c5c66894cda1e66e0aa803e5c89c613cb" translate="yes" xml:space="preserve">
          <source>Same data with dummy feature added as first column.</source>
          <target state="translated">同样的数据,在第一列添加了虚拟特征。</target>
        </trans-unit>
        <trans-unit id="8528afb44e724dea86ccba97d23f6755cfc862fa" translate="yes" xml:space="preserve">
          <source>Sample data, in the form of a numpy array or a precomputed &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">样本数据，以numpy数组或预先计算的&lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; 的形式&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="58a55d6f93d14931521825c7a646b62d82a23f61" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array or a NearestNeighbors object.</source>
          <target state="translated">样本数据,形状=(n_samples,n_features),形式为numpy数组或NearestNeighbors对象。</target>
        </trans-unit>
        <trans-unit id="10ce65324acefea0898135b900280dadfb96fe1c" translate="yes" xml:space="preserve">
          <source>Sample data, shape = (n_samples, n_features), in the form of a numpy array, precomputed tree, or NearestNeighbors object.</source>
          <target state="translated">样本数据,形状=(n_samples,n_features),形式为numpy数组、预计算树或NearestNeighbors对象。</target>
        </trans-unit>
        <trans-unit id="ea442856bb6f3247c403f5eacbad9d49d9f34166" translate="yes" xml:space="preserve">
          <source>Sample integers without replacement.</source>
          <target state="translated">整数样本,不需要替换。</target>
        </trans-unit>
        <trans-unit id="4057b3cb6bd141b135fafdb32fce3f5d0c92b8db" translate="yes" xml:space="preserve">
          <source>Sample matrix.</source>
          <target state="translated">样本矩阵:</target>
        </trans-unit>
        <trans-unit id="cc8d82180e352f6e4eb38618a9b77ce032b1c63f" translate="yes" xml:space="preserve">
          <source>Sample pipeline for text feature extraction and evaluation</source>
          <target state="translated">文本特征提取和评估的样本流水线</target>
        </trans-unit>
        <trans-unit id="0982f69f498171fb424746f3b46f588b79249d60" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">最近中心点分类的使用示例。它将绘制每个等级的决策边界。</target>
        </trans-unit>
        <trans-unit id="f22b9a32693422a5abcec4767410509915bc2f8f" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">最近邻分类的使用示例。它将绘制每个类的决策边界。</target>
        </trans-unit>
        <trans-unit id="b6f1c43a568cbfebecbc9c4a468d534512e56696" translate="yes" xml:space="preserve">
          <source>Sample vectors from which to compute variances.</source>
          <target state="translated">用于计算方差的样本向量。</target>
        </trans-unit>
        <trans-unit id="4701e0099b8ff3338dac13ba80a9fd03a1b4e3e5" translate="yes" xml:space="preserve">
          <source>Sample vectors.</source>
          <target state="translated">样本矢量。</target>
        </trans-unit>
        <trans-unit id="e2a418c622901df3ef07f5cc98282eefd0e90959" translate="yes" xml:space="preserve">
          <source>Sample weight</source>
          <target state="translated">样品重量</target>
        </trans-unit>
        <trans-unit id="e69657285f6aad82f9a81418454c1c4adb873fb2" translate="yes" xml:space="preserve">
          <source>Sample weight.</source>
          <target state="translated">样品重量。</target>
        </trans-unit>
        <trans-unit id="03782597aeab2816675e9752810fe748c242aeef" translate="yes" xml:space="preserve">
          <source>Sample weights.</source>
          <target state="translated">样本权重:</target>
        </trans-unit>
        <trans-unit id="516c4850672ccbdd1765de8db9d3606a458e566e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to 1 / n_samples.</source>
          <target state="translated">取样权重,如果无,则初始化为1/n_samples。如果无,则样本权重初始化为1/n_samples。</target>
        </trans-unit>
        <trans-unit id="06e56dd5257a783cd783e2275240a5cef38438c1" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to &lt;code&gt;1 / n_samples&lt;/code&gt;.</source>
          <target state="translated">样品重量。如果为None，则将样本权重初始化为 &lt;code&gt;1 / n_samples&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b28026c224fc212b3c8db8d7abcf83fe154d5aba" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted.</source>
          <target state="translated">样本权重。如果无,则样本权重相同。</target>
        </trans-unit>
        <trans-unit id="dd4e4922a0bf331287b6e7fdee69023638c0a9c2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.</source>
          <target state="translated">样本权重。如果无,则样本权重相等。请注意,只有在所有基础估计器都支持样本权重的情况下,才会支持这个功能。</target>
        </trans-unit>
        <trans-unit id="72b5ffbf428e4946121de0a0ea4fb4fa9205e66d" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</source>
          <target state="translated">样本权重。如果无,则样本权重相等。请注意,只有在基础估计器支持样本加权的情况下,才会支持这个功能。</target>
        </trans-unit>
        <trans-unit id="e07f10e1efb6d03970a11a668db91780f97be9f4" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.</source>
          <target state="translated">样本权重。如果无,则样本权重相等。只有当基础回归器支持样本权重时才支持。</target>
        </trans-unit>
        <trans-unit id="d4811960b5c60cf1d2e21f4adf57777acf8cf860" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.</source>
          <target state="translated">样本权重。如果无,则样本权重相等。在每个节点中搜索分割时,会创建净零或负权重的子节点的分割会被忽略。</target>
        </trans-unit>
        <trans-unit id="76ebb3a0858ee52c5cebb457753ce9dfb9f1fd6e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">样本权重。如果无,则样本权重相等。在搜索每个节点中的分割时,会创建净零或负权重的子节点的分割会被忽略。在分类的情况下,如果分割会导致任何一个子节点中的任何一个类的权重为负,那么分割也会被忽略。</target>
        </trans-unit>
        <trans-unit id="317d3738fe42cf9aeb8c2e6052e8dee6f03e55e0" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">样本权重。如果无,则样本权重相等。当搜索每个节点中的分割时,会创建净零或负权重的子节点的分割会被忽略。如果分割会导致任何一个子节点中的任何一个类的权重为负,那么分割也会被忽略。</target>
        </trans-unit>
        <trans-unit id="a90c0865394b45b5f31d5c73cc5fa995827fa090" translate="yes" xml:space="preserve">
          <source>Samples a subset of training points, computes kernel on these and computes normalization matrix.</source>
          <target state="translated">对训练点的子集进行采样,对这些子集进行核计算,并计算归一化矩阵。</target>
        </trans-unit>
        <trans-unit id="489527d2412e4e73b577f6c6fbbfa5b2fc34f813" translate="yes" xml:space="preserve">
          <source>Samples generator</source>
          <target state="translated">样品生成器</target>
        </trans-unit>
        <trans-unit id="984aa7241ddfaa0a1125ba76d49684d954091644" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="translated">样本可能每个都有几个标签（请参阅&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="a729b3c883140152c8be9c9b913932e3054a28dd" translate="yes" xml:space="preserve">
          <source>Samples per class</source>
          <target state="translated">每班样本数</target>
        </trans-unit>
        <trans-unit id="72ff32775331fbcdecdd7b50f2f019ca6fd41d2c" translate="yes" xml:space="preserve">
          <source>Samples random projection according to n_features.</source>
          <target state="translated">根据n_features进行随机投影取样。</target>
        </trans-unit>
        <trans-unit id="251d1d7b5c7f8793378b7d465a809b22ff0293ea" translate="yes" xml:space="preserve">
          <source>Samples to cluster.</source>
          <target state="translated">要聚类的样本。</target>
        </trans-unit>
        <trans-unit id="1b35c86a656c810d2ffde5bec3bbb5716273c85d" translate="yes" xml:space="preserve">
          <source>Samples total</source>
          <target state="translated">样品总数</target>
        </trans-unit>
        <trans-unit id="d94a358c32f7a1a8aa072b320513050f66fbf3bb" translate="yes" xml:space="preserve">
          <source>Samples.</source>
          <target state="translated">Samples.</target>
        </trans-unit>
        <trans-unit id="79b4194bd3e79bf7f3c58fb9c6afe5574c4f3465" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be a text document (either bytes or unicode strings, file name or file object depending on the constructor argument) which will be tokenized and hashed.</source>
          <target state="translated">样本。每个样本必须是一个文本文档(可以是字节或unicode字符串,文件名或文件对象,取决于构造函数参数),它将被标记化和哈希。</target>
        </trans-unit>
        <trans-unit id="4ecf733dec873b2818a96fff2c4d7137b5e9cce2" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be iterable an (e.g., a list or tuple) containing/generating feature names (and optionally values, see the input_type constructor argument) which will be hashed. raw_X need not support the len function, so it can be the result of a generator; n_samples is determined on the fly.</source>
          <target state="translated">样本。每个样本必须是一个可迭代的(例如,一个列表或元组),其中包含/生成特征名称(以及可选的值,参见 input_type 构造函数参数),这些名称将被哈希。raw_X 不需要支持 len 函数,因此它可以是生成器的结果;n_samples 是在飞行中确定的。</target>
        </trans-unit>
        <trans-unit id="475a3c12e7131d5c7c597d45cbde5d7c042c5697" translate="yes" xml:space="preserve">
          <source>Samples. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.</source>
          <target state="translated">样品。如果kernel ==&amp;ldquo;预先计算&amp;rdquo;，则它是预先计算的内核矩阵，形状= [n_samples，n_samples_fitted]，其中n_samples_fitted是用于该估计量的拟合样本数。</target>
        </trans-unit>
        <trans-unit id="786961f4d535734fe86dc46d23d2c4ae6643e27e" translate="yes" xml:space="preserve">
          <source>Sampling interval. Must be specified when sample_steps not in {1,2,3}.</source>
          <target state="translated">取样时间间隔,当sample_steps不在{1,2,3}时必须指定。当sample_steps不在{1,2,3}时必须指定。</target>
        </trans-unit>
        <trans-unit id="2b1ee52c21297b409f91752fd0536580b7df89b8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="translated">对更多维度进行采样显然会带来更好的分类结果，但代价更高。这意味着在运行时间和精度之间需要权衡，这由参数n_components给出。注意，通过&lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt;使用随机梯度下降可以大大加快求解线性SVM以及近似内核SVM的速度。对于带内核的SVM，这是不容易实现的。</target>
        </trans-unit>
        <trans-unit id="3e5ac0adafac21480f1a521f8334d2085c97ee0a" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999, &amp;ldquo;An elementary proof of the Johnson-Lindenstrauss Lemma.&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</source>
          <target state="translated">Sanjoy Dasgupta和Anupam Gupta，1999年，&amp;ldquo; Johnson-Lindenstrauss Lemma的基本证明。&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="72e45a031f2d9ef687b450c7dbe04851bc78b888" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;An elementary proof of the Johnson-Lindenstrauss Lemma.&lt;/a&gt;</source>
          <target state="translated">Sanjoy Dasgupta和Anupam Gupta，1999年&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;。Johnson-Lindenstrauss Lemma的基本证明。&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="916673b66f20fa78c64c3896647266270d456625" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;lsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="translated">Sanjoy Dasgupta。2000年。&lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;随机投影实验。&lt;/a&gt;在第十六届人工智能不确定性会议论文集（UAI'00）中，Craig Boutilier和Mois&amp;eacute;sGoldszmidt（编辑）。美国加利福尼亚州旧金山的摩根考夫曼出版社（Morgan Kaufmann Publishers Inc.），编号143-151。</target>
        </trans-unit>
        <trans-unit id="3dc12a8bd942b1cd9b3ab450a012927de384bfa6" translate="yes" xml:space="preserve">
          <source>Save fitted model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has better score.</source>
          <target state="translated">如果离群者样本数最大,则将拟合模型保存为最佳模型。如果当前估计模型有相同的离群数,只有当它有更好的分数时,它才会被认为是最佳模型。</target>
        </trans-unit>
        <trans-unit id="94b03c70b196c58604c0a7faf7218bf6901b8e0c" translate="yes" xml:space="preserve">
          <source>Scalability</source>
          <target state="translated">Scalability</target>
        </trans-unit>
        <trans-unit id="199d842d852910d77fdbfb1dc59f0d2885e1b21f" translate="yes" xml:space="preserve">
          <source>Scalability can be boosted by using fewer seeds, for example by using a higher value of min_bin_freq in the get_bin_seeds function.</source>
          <target state="translated">可以通过使用较少的种子来提高可扩展性,例如,在get_bin_seeds函数中使用较高的min_bin_freq值。</target>
        </trans-unit>
        <trans-unit id="29f2c344812c53bdbb5e427694d6be2d492aaf47" translate="yes" xml:space="preserve">
          <source>Scalability, due to the sequential nature of boosting it can hardly be parallelized.</source>
          <target state="translated">可扩展性,由于提升的顺序性,它很难被并行化。</target>
        </trans-unit>
        <trans-unit id="f6484bee2609587949da674a2bdf0fe83ede7b2a" translate="yes" xml:space="preserve">
          <source>Scalability:</source>
          <target state="translated">Scalability:</target>
        </trans-unit>
        <trans-unit id="61dc05feb549eab6c07b7a94be612c538f71b094" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See also section of LinearSVC for more comparison element.</source>
          <target state="translated">使用liblinear实现的用于分类的可扩展线性支持向量机。查看LinearSVC的See also部分,了解更多的比较元素。</target>
        </trans-unit>
        <trans-unit id="eecb89d050bc91f7d55354e38239145e4acf15ef" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for regression implemented using liblinear.</source>
          <target state="translated">使用liblinear实现的用于回归的可扩展线性支持向量机。</target>
        </trans-unit>
        <trans-unit id="22b700f6b9ee53c2fb9ac81cf84c12516aa516e1" translate="yes" xml:space="preserve">
          <source>Scalable linear Support Vector Machine for classification using liblinear.</source>
          <target state="translated">利用liblinear进行分类的可扩展线性支持向量机。</target>
        </trans-unit>
        <trans-unit id="bdabc7bc958d2928d9827e9b54f6956c7bb824f2" translate="yes" xml:space="preserve">
          <source>Scale back the data to the original representation</source>
          <target state="translated">将数据缩减到原始表现形式</target>
        </trans-unit>
        <trans-unit id="561dee1ec35178a67790d71472d188769f1e1bd6" translate="yes" xml:space="preserve">
          <source>Scale each feature by its maximum absolute value.</source>
          <target state="translated">按其最大绝对值对每个特征进行缩放。</target>
        </trans-unit>
        <trans-unit id="2d3a1b9b18053dd9fb9c5426f583cf0f7d587a14" translate="yes" xml:space="preserve">
          <source>Scale each feature of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">通过与调用者提供的特定比例相乘,对数据矩阵的每个特征进行缩放,并假设一个(n_samples,n_features)形状。</target>
        </trans-unit>
        <trans-unit id="c6c81268e0182a1a807ca4c628dc76b97a0fa5dc" translate="yes" xml:space="preserve">
          <source>Scale each feature to the [-1, 1] range without breaking the sparsity.</source>
          <target state="translated">在不破坏稀疏性的前提下,将每个特征的规模扩大到[-1,1]范围。</target>
        </trans-unit>
        <trans-unit id="5deb9ce023c33b22d107e28507be5494ec70764b" translate="yes" xml:space="preserve">
          <source>Scale each non zero row of X to unit norm</source>
          <target state="translated">将X的每一行非零扩展到单位常数。</target>
        </trans-unit>
        <trans-unit id="617d6ad46bfccaf27b4ba0f374d21f46a99d594e" translate="yes" xml:space="preserve">
          <source>Scale each row of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">通过与调用者提供的特定比例相乘,对数据矩阵的每一行进行缩放,并假设一个(n_samples,n_features)形状。</target>
        </trans-unit>
        <trans-unit id="2febfe8f8ec8796f6ba7a4455156e82486b6b9ad" translate="yes" xml:space="preserve">
          <source>Scale factor between inner and outer circle.</source>
          <target state="translated">内圈和外圈之间的比例系数。</target>
        </trans-unit>
        <trans-unit id="651dfd0de4ed652c75c33e720387c590f106c0bd" translate="yes" xml:space="preserve">
          <source>Scale features using statistics that are robust to outliers.</source>
          <target state="translated">使用对离群值稳健的统计学来扩展特征。</target>
        </trans-unit>
        <trans-unit id="ea253b52225bff13ccf219a7ede865331cee2a5e" translate="yes" xml:space="preserve">
          <source>Scale input vectors individually to unit norm (vector length).</source>
          <target state="translated">将输入向量单独放大到单位规范(向量长度)。</target>
        </trans-unit>
        <trans-unit id="3db146d5ef4350db484651a2947cc4449aa1c920" translate="yes" xml:space="preserve">
          <source>Scale mixture parameter</source>
          <target state="translated">比例混合参数</target>
        </trans-unit>
        <trans-unit id="214cf07e698e140c0ab386ee80be892f7e60d56f" translate="yes" xml:space="preserve">
          <source>Scale the data</source>
          <target state="translated">缩放数据</target>
        </trans-unit>
        <trans-unit id="a00231cc0fa6cda008f7de726dc3328122b68e67" translate="yes" xml:space="preserve">
          <source>Scaled data has zero mean and unit variance:</source>
          <target state="translated">缩放数据的均值为零,单位方差。</target>
        </trans-unit>
        <trans-unit id="28f5624ffdfd0dbb670e710c5400ff826061c8e3" translate="yes" xml:space="preserve">
          <source>Scalers are linear (or more precisely affine) transformers and differ from each other in the way to estimate the parameters used to shift and scale each feature.</source>
          <target state="translated">缩放器是线性(或更准确地说是仿射)变换器,在估计用于移动和缩放每个特征的参数的方式上彼此不同。</target>
        </trans-unit>
        <trans-unit id="42fb0a5f800741efdeeef6c8d3f6efbb496929e6" translate="yes" xml:space="preserve">
          <source>Scaling a 1D array</source>
          <target state="translated">缩放一维阵列</target>
        </trans-unit>
        <trans-unit id="5e180a611580dedaac6cdcb57565a42487e31efa" translate="yes" xml:space="preserve">
          <source>Scaling features of X according to feature_range.</source>
          <target state="translated">根据 feature_range 缩放 X 的特征。</target>
        </trans-unit>
        <trans-unit id="faa375cb6d0913845d11a421f85f4fc1917244d4" translate="yes" xml:space="preserve">
          <source>Scaling inputs to unit norms is a common operation for text classification or clustering for instance. For instance the dot product of two l2-normalized TF-IDF vectors is the cosine similarity of the vectors and is the base similarity metric for the Vector Space Model commonly used by the Information Retrieval community.</source>
          <target state="translated">将输入缩放为单位规范是文本分类或聚类等常用的操作。例如两个l2归一化TF-IDF向量的点乘就是向量的余弦相似度,是信息检索界常用的向量空间模型的基本相似度量。</target>
        </trans-unit>
        <trans-unit id="c9df043572b1169b126da4f0a95f811ab4322363" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids.</source>
          <target state="translated">在类中心点所跨越的空间中对特征进行缩放。</target>
        </trans-unit>
        <trans-unit id="f91f363e9d78c82d08c38c5a1dbde0b091a85898" translate="yes" xml:space="preserve">
          <source>Scaling parameter of the chi2 kernel.</source>
          <target state="translated">chi2核的缩放参数。</target>
        </trans-unit>
        <trans-unit id="611f59db789837a47c8391146e294e88684d2aac" translate="yes" xml:space="preserve">
          <source>Scaling the regularization parameter for SVCs</source>
          <target state="translated">缩放SVC的正则化参数</target>
        </trans-unit>
        <trans-unit id="8ca361aee1b505e96263673a562173e09064f7c8" translate="yes" xml:space="preserve">
          <source>Scaling vs Whitening</source>
          <target state="translated">洗牙VS美白</target>
        </trans-unit>
        <trans-unit id="0b38453e586dafca0c0308eafbfda226dcf7f7c2" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those image can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="translated">Scikit-learn还嵌入了几张由作者以Creative Commons授权发布的JPEG图像样本。这些图像可以用来测试2D数据的算法和流水线。</target>
        </trans-unit>
        <trans-unit id="4f09669bc19a45a6af1925c5dd7e5320d97b9858" translate="yes" xml:space="preserve">
          <source>Scikit-learn also permits evaluation of multiple metrics in &lt;code&gt;GridSearchCV&lt;/code&gt;, &lt;code&gt;RandomizedSearchCV&lt;/code&gt; and &lt;code&gt;cross_validate&lt;/code&gt;.</source>
          <target state="translated">Scikit-learn还允许评估 &lt;code&gt;GridSearchCV&lt;/code&gt; ， &lt;code&gt;RandomizedSearchCV&lt;/code&gt; 和 &lt;code&gt;cross_validate&lt;/code&gt; 中的多个指标。</target>
        </trans-unit>
        <trans-unit id="5427512908da9e885639e4f06d90d3fbb899fa1a" translate="yes" xml:space="preserve">
          <source>Scikit-learn deals with learning information from one or more datasets that are represented as 2D arrays. They can be understood as a list of multi-dimensional observations. We say that the first axis of these arrays is the &lt;strong&gt;samples&lt;/strong&gt; axis, while the second is the &lt;strong&gt;features&lt;/strong&gt; axis.</source>
          <target state="translated">Scikit-learn处理来自一个或多个以2D数组表示的数据集的学习信息。它们可以理解为多维观测的列表。我们说这些数组的第一个轴是&lt;strong&gt;样本&lt;/strong&gt;轴，而第二个是&lt;strong&gt;特征&lt;/strong&gt;轴。</target>
        </trans-unit>
        <trans-unit id="68787e98ea90825b478bf4a016c311205a6818e9" translate="yes" xml:space="preserve">
          <source>Scikit-learn does some validation on data that increases the overhead per call to &lt;code&gt;predict&lt;/code&gt; and similar functions. In particular, checking that features are finite (not NaN or infinite) involves a full pass over the data. If you ensure that your data is acceptable, you may suppress checking for finiteness by setting the environment variable &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; to a non-empty string before importing scikit-learn, or configure it in Python with &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;. For more control than these global settings, a &lt;code&gt;config_context&lt;/code&gt; allows you to set this configuration within a specified context:</source>
          <target state="translated">Scikit-learn对数据进行一些验证，从而增加了每次调用 &lt;code&gt;predict&lt;/code&gt; 功能和类似功能的开销。特别是，检查特征是否有限（不是NaN或无限）涉及数据的完整传递。如果确保数据可接受，则可以通过在导入scikit-learn之前将环境变量 &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; 设置为非空字符串来抑制对有限性的检查，或者在Python中使用&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt;对其进行配置。为了获得比这些全局设置更多的控制权， &lt;code&gt;config_context&lt;/code&gt; 允许您在指定的上下文中设置此配置：</target>
        </trans-unit>
        <trans-unit id="562455165c34b7c83008b571c9bd46eceb879b92" translate="yes" xml:space="preserve">
          <source>Scikit-learn has a collection of classes which can be used to generate lists of train/test indices for popular cross-validation strategies.</source>
          <target state="translated">Scikit-learn有一个类的集合,可以用来为流行的交叉验证策略生成训练/测试指数列表。</target>
        </trans-unit>
        <trans-unit id="b670925eafc995f1763e66f682772271e15a05e5" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements different classes to estimate Gaussian mixture models, that correspond to different estimation strategies, detailed below.</source>
          <target state="translated">Scikit-learn实现了不同的类来估计高斯混合模型,这些类对应不同的估计策略,详见下文。</target>
        </trans-unit>
        <trans-unit id="e9a530527422759264cd84546f6a0bd4a26252b3" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements efficient kernel density estimation using either a Ball Tree or KD Tree structure, through the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator. The available kernels are shown in the second figure of this example.</source>
          <target state="translated">Scikit-learn通过&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt;估计器，使用Ball Tree或KD Tree结构实现了有效的内核密度估计。可用内核在本示例的第二张图中显示。</target>
        </trans-unit>
        <trans-unit id="b29477e8796624fa3eb37a4b942da5b84d872c57" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="translated">Scikit-learn是一个Python模块，在紧密结合的科学Python程序包世界（&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;，&lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;和&lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;）中集成了经典的机器学习算法。</target>
        </trans-unit>
        <trans-unit id="5244e6b9c3228eb8fcf423888d9d9a31c68e2222" translate="yes" xml:space="preserve">
          <source>Scikit-learn offers a more efficient implementation for the construction of decision trees. A naive implementation (as above) would recompute the class label histograms (for classification) or the means (for regression) at for each new split point along a given feature. Presorting the feature over all relevant samples, and retaining a running label count, will reduce the complexity at each node to \(O(n_{features}\log(n_{samples}))\), which results in a total cost of \(O(n_{features}n_{samples}\log(n_{samples}))\). This is an option for all tree based algorithms. By default it is turned on for gradient boosting, where in general it makes training faster, but turned off for all other algorithms as it tends to slow down training when training deep trees.</source>
          <target state="translated">Scikit-learn为决策树的构建提供了更高效的实现。一个天真的实现(如上所述)将沿着给定的特征重新计算每个新的分割点的类标签直方图(用于分类)或平均值(用于回归)。在所有相关样本上对特征进行预排序,并保留一个运行的标签数,将把每个节点的复杂度降低到/(O(n_{features}/log(n_{samples}))/),从而导致总成本为/(O(n_{features}n_{samples}/log(n_{samples}))/)。这是所有基于树的算法的一个选项。默认情况下,对于梯度提升来说,它是开启的,一般来说,它可以使训练速度更快,但对于所有其他算法来说,它是关闭的,因为在训练深度树时,它往往会减慢训练速度。</target>
        </trans-unit>
        <trans-unit id="4affb29f4cf970be26e1f3befb3e52980b3745a3" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</source>
          <target state="translated">Scikit-learn提供3种强大的回归估计量：&lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;，&lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt;和&lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="760c9dce2728b87b0e773a2a2023bd5ef6b1ebc6" translate="yes" xml:space="preserve">
          <source>Scikit-learn uses the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; library to enable parallel computing inside its estimators. See the joblib documentation for the switches to control parallel computing.</source>
          <target state="translated">Scikit-learn使用&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt;库在其估计器中启用并行计算。有关控制并行计算的开关，请参见joblib文档。</target>
        </trans-unit>
        <trans-unit id="dbdfa5cbcc37d085da70cbad1d49bb4154a25ae3" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="translated">Scipy提供了为存储稀疏数据而优化的稀疏矩阵数据结构。稀疏格式的主要特征是您不会存储零，因此，如果数据稀疏，则将使用更少的内存。稀疏（&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR或CSC&lt;/a&gt;）表示形式中的非零值将平均仅占用一个32位整数位置+ 64位浮点值+矩阵中每行或每列额外的32位。在密集（或稀疏）线性模型上使用稀疏输入可以大大加快预测速度，因为只有非零值特征会影响点积，从而影响模型预测。因此，如果在1e6维空间中有100个非零，则只需要100个乘法和加法运算即可，而不是1e6。</target>
        </trans-unit>
        <trans-unit id="73ff9df76cca7434e9bdc94c5c539e98a711a167" translate="yes" xml:space="preserve">
          <source>Scipy sparse matrix formats documentation</source>
          <target state="translated">Scipy稀疏矩阵格式文档</target>
        </trans-unit>
        <trans-unit id="ec44ac6f635d9837f888fea19337ecd3bc1dc78d" translate="yes" xml:space="preserve">
          <source>Score function (or loss function) with signature &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">具有签名 &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt; 得分函数（或损失函数）。</target>
        </trans-unit>
        <trans-unit id="4106362aa56af5a012e22c8aae43583defb47511" translate="yes" xml:space="preserve">
          <source>Score of self.predict(X) wrt. y.</source>
          <target state="translated">self.predict(X)wrt.y的得分。</target>
        </trans-unit>
        <trans-unit id="269ca6f46a2303fa294fd49cbab7d3d725c81bb2" translate="yes" xml:space="preserve">
          <source>Score of the prediction.</source>
          <target state="translated">预测的得分。</target>
        </trans-unit>
        <trans-unit id="fee68e2ae75f4d785b563d7d07175bca2df697af" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate.</source>
          <target state="translated">使用袋外估计得到的训练数据集的得分。</target>
        </trans-unit>
        <trans-unit id="fdd43514c35f028b5dfc878c7661a274717e7633" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given training / test split.</source>
          <target state="translated">该参数设置在给定的训练/测试分割上的得分。</target>
        </trans-unit>
        <trans-unit id="e14703c8615f59873dec25794c9dae3e6fdaa2e4" translate="yes" xml:space="preserve">
          <source>Score, and cross-validated scores</source>
          <target state="translated">得分,以及交叉验证的得分</target>
        </trans-unit>
        <trans-unit id="5ac699be69d4f6f03061e9fdf043eeb8d0ba0ed6" translate="yes" xml:space="preserve">
          <source>Scorer function used on the held out data to choose the best parameters for the model.</source>
          <target state="translated">在憋出的数据上使用的评分器函数来选择模型的最佳参数。</target>
        </trans-unit>
        <trans-unit id="dafe5cdb100f4bad5185f8a89151e9de127407db" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged with uniform weight.</source>
          <target state="translated">所有产出的分数取平均值,权重统一。</target>
        </trans-unit>
        <trans-unit id="a879b57711ff565bb3c57b9cbdbf3f09144796d5" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged, weighted by the variances of each individual output.</source>
          <target state="translated">所有产出的得分均为平均数,并按每项产出的差异加权。</target>
        </trans-unit>
        <trans-unit id="bad96478d4d42d160afd8f51da6516a096f00968" translate="yes" xml:space="preserve">
          <source>Scores of features.</source>
          <target state="translated">几十种功能。</target>
        </trans-unit>
        <trans-unit id="004421c31cff3e85919b0da3d9213b70c070211e" translate="yes" xml:space="preserve">
          <source>Scores on test set.</source>
          <target state="translated">试题集上的分数。</target>
        </trans-unit>
        <trans-unit id="9cb2f72d484e4d0e25f5504cf3cb781f6831387a" translate="yes" xml:space="preserve">
          <source>Scores on training sets.</source>
          <target state="translated">训练集的分数。</target>
        </trans-unit>
        <trans-unit id="a6e081bd4fc687e97f2a3c1767e01a47d8d0d090" translate="yes" xml:space="preserve">
          <source>Scoring</source>
          <target state="translated">Scoring</target>
        </trans-unit>
        <trans-unit id="88173ba266bcaafd44bc526091a11bf84a691634" translate="yes" xml:space="preserve">
          <source>Second example</source>
          <target state="translated">第二个例子</target>
        </trans-unit>
        <trans-unit id="e4e2db45443f0fd4ae50799405ca1ddce61eefb7" translate="yes" xml:space="preserve">
          <source>Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability.</source>
          <target state="translated">其次,在使用连通矩阵时,单一、平均和完全连接都是不稳定的,往往会产生一些快速增长的簇。事实上,平均和完全连接通过在合并两个簇时考虑两个簇之间的所有距离来对抗这种渗透行为(而单一连接通过只考虑簇之间最短的距离来夸大这种行为)。连通图打破了平均连通和完全连通的这种机制,使它们类似于更脆弱的单连通。对于非常稀疏的图(尝试减少 kneighbors_graph 中的邻居数量)和完全连接图,这种效果更加明显。特别是,在图中拥有非常少的邻域数量,就会施加一个接近于单联接的几何形状,而单联接的这种渗透不稳定性是众所周知的。</target>
        </trans-unit>
        <trans-unit id="53553e63fb4cb7ed1ae88d54b317154b9777e613" translate="yes" xml:space="preserve">
          <source>Seconds used for refitting the best model on the whole dataset.</source>
          <target state="translated">用于在整个数据集上重新装配最佳模型的秒数。</target>
        </trans-unit>
        <trans-unit id="fa04a576bd56d584afacdf30a223dc3f1fde4eb3" translate="yes" xml:space="preserve">
          <source>Section 5.4.4, pp. 252-253.</source>
          <target state="translated">第5.4.4节,第252-253页。</target>
        </trans-unit>
        <trans-unit id="d4628726ca2b8e9b183e1257c782a69297176123" translate="yes" xml:space="preserve">
          <source>Section contents</source>
          <target state="translated">科目内容</target>
        </trans-unit>
        <trans-unit id="978feab4a35a4b897d5316b48dac562d3091d0c5" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Features for Large-Scale Kernel Machines&amp;rdquo; by A. Rahimi and Benjamin Recht.</source>
          <target state="translated">请参阅A. Rahimi和Benjamin Recht撰写的&amp;ldquo;大型内核计算机的随机功能&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="b31673babc80845a872201a18703583634f75350" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Fourier Approximations for Skewed Multiplicative Histogram Kernels&amp;rdquo; by Fuxin Li, Catalin Ionescu and Cristian Sminchisescu.</source>
          <target state="translated">参见&amp;ldquo; Fusin Li&amp;rdquo;，Catalin Ionescu和Cristian Sminchisescu撰写的&amp;ldquo;偏斜的直方图直方图核的随机傅立叶近似&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="0df8f05c9ec568b4cc1c4d54a3085f0ebf794bd9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="translated">有关Mat&amp;eacute;rn内核的不同变体的更多详细信息，请参见&lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;，pp84。</target>
        </trans-unit>
        <trans-unit id="dd13548eb92de90d6303ee640236c96cda68888f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Mathematical formulation&lt;/a&gt; for a complete description of the decision function.</source>
          <target state="translated">有关决策函数的完整说明，请参见&lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;数学公式&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="90eaaa0456af60c46de8c81dc16ee15dad424d81" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples/compose/plot_transformed_target.py&lt;/a&gt;.</source>
          <target state="translated">参见&lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples / compose / plot_transformed_target.py&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0d70be16f79f29cfb466970ca83989e73f6c00bb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples/linear_model/plot_polynomial_interpolation.py&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;示例/linear_model/plot_polynomial_interpolation.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="66218b0f5237d32e41f01914713a47022cf20bb9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples/model_selection/plot_learning_curve.py&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;示例/model_selection/plot_learning_curve.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="41261fbeb952dd5951bf36801866ce019db00dde" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Plotting Validation Curves&lt;/a&gt;</source>
          <target state="translated">请参见&lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;绘制验证曲线&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6a3b0e6c0d79b7c03e9dbb288652a52d5e7d7fd5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Bayesian Ridge Regression&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">有关&lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;回归&lt;/a&gt;器的更多信息，请参见贝叶斯岭回归。</target>
        </trans-unit>
        <trans-unit id="824c64b490bd5bd779a22eec474ba042707228d1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-Sen estimator: generalized-median-based estimator&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">有关回归变量的更多信息，请参见&lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-Sen估计器：基于广义中值的估计器&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="36bf338f19ee54a0199babdefd0eaf5b203f80f4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Gaussian mixture models&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">有关估计器的更多信息，请参见&lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;高斯混合模型&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bda58af52a4d947e4c6e336facf5860c69c8478b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision tree&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">有关估算器的更多信息，请参见&lt;a href=&quot;../../modules/tree#tree&quot;&gt;决策树&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1876d72641fc6bba23917c9ce1b023a0c5308e82" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of using ROC to model species distribution.</source>
          <target state="translated">有关使用ROC对&lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;物种分布进行建模&lt;/a&gt;的示例，请参阅物种分布建模。</target>
        </trans-unit>
        <trans-unit id="3ca47154d5f58b185be5af00ff9392b2598d6abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Probability calibration of classifiers&lt;/a&gt; for an example of Brier score loss usage to perform probability calibration of classifiers.</source>
          <target state="translated">有关使用Brier分数损失来执行分类器概率校准的示例，请参阅&lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;分类&lt;/a&gt;器的概率校准。</target>
        </trans-unit>
        <trans-unit id="282928c19fbfe87fe4167148ff3b6058bc018479" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of classification report usage for hand-written digits.</source>
          <target state="translated">有关&lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;手写数字&lt;/a&gt;分类报告用法的示例，请参阅识别手写数字。</target>
        </trans-unit>
        <trans-unit id="72d62eaa2236b9a2dd2c8a6bb04573291c57c36e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of using a confusion matrix to classify hand-written digits.</source>
          <target state="translated">有关使用混淆矩阵对手写数字进行分类的示例，请参阅&lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;识别&lt;/a&gt;手写数字。</target>
        </trans-unit>
        <trans-unit id="87880060115f16d38cb34f093520114ae1691683" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; object to data and for visualizing the performances of the Ledoit-Wolf estimator in terms of likelihood.</source>
          <target state="translated">有关如何将&lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt;对象拟合到数据以及如何&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;用可能性&lt;/a&gt;可视化Ledoit-Wolf估计量的性能的示例，请参见收缩协方差估计：LodoitWolf与OAS和最大似然性。</target>
        </trans-unit>
        <trans-unit id="2209166f8c957bd217f6d5f461ba4322d29b02c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">有关如何将&lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt;对象拟合到数据的示例，请参见&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;收缩协方差估计：LedoitWolf与OAS和最大似然性&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="88a19b944edc191f5f7b057963b65a4e9112c1b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">有关如何将&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;对象拟合到数据的示例，请参见&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;收缩协方差估计：LedoitWolf与OAS和最大似然性&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8a3f5dc7dd1289a56afbdf19c9d4415f754d0c74" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">有关如何将&lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt;对象拟合到数据的示例，请参见&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;收缩协方差估计：LedoitWolf与OAS和最大似然性&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a2ce4b68a58fc4d4775fc307d3337bfc6ba95951" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf vs OAS estimation&lt;/a&gt; to visualize the Mean Squared Error difference between a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; and an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; estimator of the covariance.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf与OAS估计，&lt;/a&gt;以可视化&lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt;与协方差的&lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt;估计器之间的均方误差差。</target>
        </trans-unit>
        <trans-unit id="8878b5f91edc950d3f968af54f37c8ec353c6370" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; for an illustration of the difference between using a standard (&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;) or a robust estimate (&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;covariance.MinCovDet&lt;/code&gt;&lt;/a&gt;) of location and covariance to assess the degree of outlyingness of an observation.</source>
          <target state="translated">有关使用位置和协方差的标准（&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;）或鲁棒估计（&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;covariance.MinCovDet&lt;/code&gt; &lt;/a&gt;）之间的差异的&lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;评估，&lt;/a&gt;请参见稳健协方差估计和Mahalanobis距离相关性，以评估观察值的离边度。</target>
        </trans-unit>
        <trans-unit id="030742fc8b624a6be4238fb99cd9f5a0e364d687" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; to visualize the difference between &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; covariance estimators in terms of Mahalanobis distance (so we get a better estimate of the precision matrix too).</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;鲁棒协方差估计和Mahalanobis距离相关性，&lt;/a&gt;以可视化Mahalanobis距离可视化&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt;协方差估计器之间的差异（因此，我们也可以更好地估算精度矩阵）。</target>
        </trans-unit>
        <trans-unit id="f9a056a85b47a4a6c1a6d704788263d39761f07a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Robust vs Empirical covariance estimate&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; object to data and see how the estimate remains accurate despite the presence of outliers.</source>
          <target state="translated">有关如何将&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt;对象拟合到数据的示例，请参见&lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;稳健与经验协方差估计&lt;/a&gt;，并了解尽管存在异常值，该估计如何保持准确。</target>
        </trans-unit>
        <trans-unit id="995b452653e2a34828a53fff1225e032a84a1ed7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Gradient Boosting regression&lt;/a&gt; for an example of mean squared error usage to evaluate gradient boosting regression.</source>
          <target state="translated">有关评估梯度增强回归的均方误差用法的示例，请参见&lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;梯度增强&lt;/a&gt;回归。</target>
        </trans-unit>
        <trans-unit id="c70bb54b9f9c6d372a94de7482636d40519b333f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest example&lt;/a&gt; for an illustration of the use of IsolationForest.</source>
          <target state="translated">有关使用&lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest&lt;/a&gt;的说明，请参见IsolationForest示例。</target>
        </trans-unit>
        <trans-unit id="462e8cdc93001fb7a3648b1195482e1f8b22fe44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Test with permutations the significance of a classification score&lt;/a&gt; for an example of accuracy score usage using permutations of the dataset.</source>
          <target state="translated">有关使用数据集置换的准确性分数用法的示例，请参阅&lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;对置换进行检验以获取分类分数的重要性&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="39b73a8956b97e37d2a1a56a5487c771ec6755e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt; for an example of zero one loss usage to perform recursive feature elimination with cross-validation.</source>
          <target state="translated">有关&lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;使用交叉验证的递归特征消除&lt;/a&gt;的示例，请参见使用交叉验证的递归特征消除。</target>
        </trans-unit>
        <trans-unit id="92f30204fbfed37d4520688e6847c0f1dec6d444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Lasso and Elastic Net for Sparse Signals&lt;/a&gt; for an example of R&amp;sup2; score usage to evaluate Lasso and Elastic Net on sparse signals.</source>
          <target state="translated">有关&lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;稀疏信号&lt;/a&gt;的L&amp;sup2;得分用法示例，请参阅Lasso和Elastic Net的稀疏信号。</target>
        </trans-unit>
        <trans-unit id="01a78f9ef24e4fc8896bfa27a1c142f94096fbf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Polynomial interpolation&lt;/a&gt; for Ridge regression using created polynomial features.</source>
          <target state="translated">有关使用创建的多项式特征的Ridge回归的信息，请参见&lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;多项式插值&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6cc1903f7fccc8472139b491e9c35281e331be73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt; for an example of dimensionality reduction on a toy &amp;ldquo;S-curve&amp;rdquo; dataset.</source>
          <target state="translated">有关玩具&amp;ldquo; S曲线&amp;rdquo;数据集降维的示例，请参见&lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;流形学习方法的比较&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c13f7bab27de634fe8533a5ffc3f4d5d442fb940" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;&lt;/a&gt; for an example of dimensionality reduction on handwritten digits.</source>
          <target state="translated">有关减少手写数字尺寸的示例，请参见&lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;有关手写数字的流形学习：局部线性嵌入，Isomap&amp;hellip;&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ba387b296d0109ccfdd27d435e72e0bda0b98a94" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture&lt;/a&gt; for an example plotting the confidence ellipsoids for the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; with different &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; for different values of the parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt;.</source>
          <target state="translated">有关为参数 &lt;code&gt;weight_concentration_prior&lt;/code&gt; 的不同值绘制具有不同 &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; 的&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt;的置信椭圆体的示例，请参阅&lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;变化贝叶斯高斯混合物的浓度先验类型分析&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="17317cd9be65f918f2c9598fbac39ad346f5db56" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt; for an example on plotting the confidence ellipsoids for both &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">见&lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;高斯混合模型椭球&lt;/a&gt;上绘制两者的信心椭球的例子&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a5877cbb374e3dc33496a562d7ff812fdb5db635" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM covariances&lt;/a&gt; for an example of using the Gaussian mixture as clustering on the iris dataset.</source>
          <target state="translated">有关使用高斯混合作为虹膜数据集聚类的示例，请参见&lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM协方差&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="235746c777e5faff74a54e9f92e2aa47946dcca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Density Estimation for a Gaussian mixture&lt;/a&gt; for an example on plotting the density estimation.</source>
          <target state="translated">有关绘制密度估算值的示例，请参见&lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;高斯混合&lt;/a&gt;的密度估算值。</target>
        </trans-unit>
        <trans-unit id="1f45342ed85fb843511e05db7aa53da9e05cd4c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Gaussian Mixture Model Selection&lt;/a&gt; for an example of model selection performed with classical Gaussian mixture.</source>
          <target state="translated">有关使用经典高斯混合执行&lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;模型选择&lt;/a&gt;的示例，请参见高斯混合模型选择。</target>
        </trans-unit>
        <trans-unit id="2675c64adf13cc79a9b07f8da3e0d3af0522fc69" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a &lt;code&gt;pipeline.Pipeline&lt;/code&gt; instance.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;样本管道中的文本特征提取和评估&lt;/a&gt;示例，以获取带有分类器（此处为线性SVM的SGD训练并带有弹性网）的文本文档特征提取器（n-gram计数矢量化器和TF-IDF转换器）的网格搜索耦合参数示例。或L2惩罚）使用 &lt;code&gt;pipeline.Pipeline&lt;/code&gt; 实例。</target>
        </trans-unit>
        <trans-unit id="da92f3b35d742326e0c71721384ca2aaccbfcbb6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; for an example of using a confusion matrix to evaluate classifier output quality.</source>
          <target state="translated">有关使用混淆矩阵评估分类器输出质量的示例，请参见&lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;混淆矩阵&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="de7b9e4f40b1dbfe2688a95ace15280b606fa175" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; usage to estimate parameters using grid search with nested cross-validation.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;使用带有交叉验证的网格搜索进行参数估计，以&lt;/a&gt;获取&lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt;用法的示例，以使用带有嵌套交叉验证的网格搜索来估计参数。</target>
        </trans-unit>
        <trans-unit id="907fb39fc7f1b14d7a7b9cc2b05542f6688793e4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of Grid Search computation on the digits dataset.</source>
          <target state="translated">有关在数字数据集上进行网格搜索计算的示例，请参阅&lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;使用带有交叉验证的网格搜索进行参数估计&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="400cd83fcd5e25dceebfea56b549d5be061f5ba4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of classification report usage for grid search with nested cross-validation.</source>
          <target state="translated">有关&lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;使用&lt;/a&gt;嵌套交叉验证的网格搜索的分类报告用法的示例，请参阅使用带有交叉验证的网格搜索进行参数估计。</target>
        </trans-unit>
        <trans-unit id="2735aad85c6c7c554984533b716de0827c908e17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; being used to evaluate multiple metrics simultaneously.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;关于cross_val_score和GridSearchCV的多指标评估的演示，以获取&lt;/a&gt;用于同时评估多个指标的&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;的示例。</target>
        </trans-unit>
        <trans-unit id="c2ffbe0f12938b51592ad9e927a7d22caaeca8af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example usage.</source>
          <target state="translated">有关示例用法，请参见&lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;在cross_val_score和GridSearchCV上&lt;/a&gt;进行多指标评估的演示。</target>
        </trans-unit>
        <trans-unit id="8476e4237a00d9dd8e2ca35734caeb2c23a0697e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Nested versus non-nested cross-validation&lt;/a&gt; for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.</source>
          <target state="translated">有关虹膜数据集上交叉验证循环内网格搜索的示例，请参阅&lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;嵌套交叉验证与非嵌套交叉验证&lt;/a&gt;。这是通过网格搜索评估模型性能的最佳实践。</target>
        </trans-unit>
        <trans-unit id="e8dfb2ba828b857661aeb6d59ff74f5c4db05d22" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; usage to evaluate classifier output quality.</source>
          <target state="translated">有关用于评估分类器输出质量的&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt;用法的示例，请参见&lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7914d54070b906eba7716c438acf436730af131e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;Receiver Operating Characteristic (ROC)&lt;/a&gt; for an example of using ROC to evaluate the quality of the output of a classifier.</source>
          <target state="translated">有关使用ROC评估分类器输出质量的示例，请参阅&lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;接收器工作特性（ROC）&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="61240d29f349f145d4e8cf44909bfb9cc2f016b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Receiver Operating Characteristic (ROC) with cross validation&lt;/a&gt; for an example of using ROC to evaluate classifier output quality, using cross-validation.</source>
          <target state="translated">有关使用ROC使用交叉验证来评估分类器输出质量的示例，请参阅&lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;具有交叉验证的接收器操作特性（ROC）&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2194fe880eec73b4ed37b8700c0f77c050a462fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Outlier detection with Local Outlier Factor (LOF)&lt;/a&gt; for an illustration of the use of &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">有关使用&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;的说明，请参见&lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;使用局部离群值因子（LOF）的离群值检测&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bb13fcb17f205551a70f65831a46478e0af0f276" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;比较玩具数据集上的异常检测算法以进行离群值检测&lt;/a&gt;，以比较&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;与&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;（调整后的行为类似于离群值检测方法）以及基于协方差的离群值检测与&lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="64196936345ba93c97149a5b0ef386464e9766b9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">有关&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt;的比较，请参见&lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;比较玩具数据集上的异常检测算法以进行离群值检测&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="34db9fa5546a4563c9e371d735571ffbe05f0c7c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;比较异常检测算法以对玩具数据集&lt;/a&gt;进行异常检测，以与其他异常检测方法进行比较。</target>
        </trans-unit>
        <trans-unit id="624945e6b02bb2ff2c43f28f85ed4813c5cbe96d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="translated">有关Johnson-Lindenstrauss引理的理论解释和使用稀疏随机矩阵的经验验证，请参阅&lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;Johnson-Lindenstrauss绑定随机投影&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9ca7b8e34286a27914e5e700a286fbed9102f4af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;One-class SVM with non-linear kernel (RBF)&lt;/a&gt; for visualizing the frontier learned around some data by a &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;具有非线性内核（RBF）的一类SVM，&lt;/a&gt;以可视化&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;对象围绕某些数据学习的前沿。</target>
        </trans-unit>
        <trans-unit id="76c663b6a0471e4c53ba854f9c09becf8ef59fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt; usage to classify text documents.</source>
          <target state="translated">请参阅&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;使用稀疏功能&lt;/a&gt;对文本文档进行分类，以获取&lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt;用法对文本文档进行分类的示例。</target>
        </trans-unit>
        <trans-unit id="188cc26ffe635b802535768a1802c77d30908617" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of classification report usage for text documents.</source>
          <target state="translated">有关&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;文本文档&lt;/a&gt;分类报告用法的示例，请参阅使用稀疏特征分类文本文档。</target>
        </trans-unit>
        <trans-unit id="19118774a723324b6225f3d83bcf9761f94d3619" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of using a confusion matrix to classify text documents.</source>
          <target state="translated">有关使用混淆矩阵对文本文档进行分类的示例，请参见&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;使用稀疏特征&lt;/a&gt;对文本文档进行分类。</target>
        </trans-unit>
        <trans-unit id="81a2b2d1fb5035ca6b501c666e8a41c6286b60de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Specifying multiple metrics for evaluation&lt;/a&gt; for an example.</source>
          <target state="translated">有关示例，请参阅&lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;指定多个度量进行评估&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="479250f0ad90f3ce8d5fd16594b9c17af606dc2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; in the online documentation for a discussion of the choice of &lt;code&gt;algorithm&lt;/code&gt; and &lt;code&gt;leaf_size&lt;/code&gt;.</source>
          <target state="translated">有关 &lt;code&gt;algorithm&lt;/code&gt; 和 &lt;code&gt;leaf_size&lt;/code&gt; 的选择的讨论，请参见在线文档中的&lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="91032a83e07b0024745974d4bc72e492c7c9e85a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines and composite estimators&lt;/a&gt;.</source>
          <target state="translated">请参阅&lt;a href=&quot;compose#combining-estimators&quot;&gt;管道和复合估计量&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="516b0abd274bf0e8eb7951cfd8d017257e70560d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Loading features from dicts&lt;/a&gt; for categorical features that are represented as a dict, not as scalars.</source>
          <target state="translated">请参阅&lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;从字典中加载&lt;/a&gt;要素以获取表示为字典而不是标量的分类要素。</target>
        </trans-unit>
        <trans-unit id="5f5bdda151c122a6b0f331c022a3fe3419eba6e8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="translated">有关此数据集的更多信息，请参见&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;此处&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="59cc7550d6ebef4a36dc7cbd048f831a5c0d0f3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="translated">参见&lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="58869cd4ecac8051c9d79dfaa9dbb2a543b85dfe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;ldquo;Efficient additive kernels via explicit feature maps&amp;rdquo;&lt;/a&gt; A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence, 2011</source>
          <target state="translated">参见&lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;ldquo;通过显式特征图的高效加性内核&amp;rdquo;，&lt;/a&gt; A。Vedaldi和A. Zisserman，模式分析和机器智能，2011年</target>
        </trans-unit>
        <trans-unit id="4bdca7573215dd8d9f679d272cb9da9a534f1291" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;here&lt;/a&gt; for more information on this dataset.</source>
          <target state="translated">有关此数据集的更多信息，请参见&lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;此处&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7191cbc48e1c8b07d612d6ecdb398fe05677ce16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.</source>
          <target state="translated">有关详细信息，请参见&lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;评分参数：定义模型评估规则&lt;/a&gt;。在Iris数据集的情况下，样本在目标类别之间是平衡的，因此准确性和F1分数几乎相等。</target>
        </trans-unit>
        <trans-unit id="e083d29e5fc318a8e4c7186d224d71159333e317" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Novelty and Outlier Detection&lt;/a&gt; for the description and usage of OneClassSVM.</source>
          <target state="translated">有关OneClassSVM的描述和用法，请参阅&lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;新颖性和异常值检测&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2bf27f073ae6fdc435309a3de7aa195bb3e33f73" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;predict_proba&lt;/code&gt; for details.</source>
          <target state="translated">有关详细信息，请参见 &lt;code&gt;predict_proba&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9a6c19ee072204bfa0caf7b0899caf92ad1a79e0" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;refit&lt;/code&gt; parameter for more information on allowed values.</source>
          <target state="translated">有关允许值的更多信息，请参见 &lt;code&gt;refit&lt;/code&gt; 参数。</target>
        </trans-unit>
        <trans-unit id="fcd84460747232330056c00c1a39fd6ed47410b5" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;scoring&lt;/code&gt; parameter to know more about multiple metric evaluation.</source>
          <target state="translated">请参阅 &lt;code&gt;scoring&lt;/code&gt; 参数以了解有关多指标评估的更多信息。</target>
        </trans-unit>
        <trans-unit id="61a08f389a25b863d0fca5015a2885ff6fd5c8cd" translate="yes" xml:space="preserve">
          <source>See Also:</source>
          <target state="translated">另见:</target>
        </trans-unit>
        <trans-unit id="dd75486b56d3a12e77b37b7ce59de88eb8618b01" translate="yes" xml:space="preserve">
          <source>See Rasmussen and Williams 2006, pp84 for details regarding the different variants of the Matern kernel.</source>
          <target state="translated">参见Rasmussen和Williams 2006,pp84关于Matern内核的不同变体的细节。</target>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="translated">另见</target>
        </trans-unit>
        <trans-unit id="00556fb4b47eda5d6ddfa3723da8312c58733ada" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt;</source>
          <target state="translated">另请参阅&lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;通过交叉验证消除递归特征&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="371a87eafb4de078ff674d69a5a89c186532eb49" translate="yes" xml:space="preserve">
          <source>See also:</source>
          <target state="translated">另见:</target>
        </trans-unit>
        <trans-unit id="bbbf1c8bb1bb44153dbb121ba5ff682161041559" translate="yes" xml:space="preserve">
          <source>See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&amp;rdquo;s AUTOCLASS II conceptual clustering system finds 3 classes in the data.</source>
          <target state="translated">参见：1988 MLC会议录，第54-64页。Cheeseman等人的AUTOCLASS II概念聚类系统在数据中找到3个类别。</target>
        </trans-unit>
        <trans-unit id="6b55a2c7dcbc914b3c4abb672c6103792d08facf" translate="yes" xml:space="preserve">
          <source>See sklearn.svm.predict for a complete list of parameters.</source>
          <target state="translated">参见sklearn.svm.predict获取完整的参数列表。</target>
        </trans-unit>
        <trans-unit id="8c30624bfa9869c6a4a63a1b052f17576abbc1b5" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt; to download &lt;code&gt;svm_gui.py&lt;/code&gt;; add data points of both classes with right and left button, fit the model and change parameters and data.</source>
          <target state="translated">参见&lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt;下载 &lt;code&gt;svm_gui.py&lt;/code&gt; ; 使用左右按钮添加两个类别的数据点，拟合模型并更改参数和数据。</target>
        </trans-unit>
        <trans-unit id="3a7904b44fb635dd1b8e25248a204eaa4fae3a1b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息，请参见用户指南的&lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;分类评估&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="68bd165827c5ef6d955b9032ff7e059af8a91538" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息，请参见用户指南的&amp;ldquo; &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;群集性能评估&amp;rdquo;&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="8dd9c0a0a464abab54cd5ae3d828ecf303587e8d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息&lt;a href=&quot;metrics#metrics&quot;&gt;，&lt;/a&gt;请参见用户指南的成对度量，亲和力和内核部分。</target>
        </trans-unit>
        <trans-unit id="a5b49cc34cb79ec02e159e95ecb887eb0b2cb87b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;Classification metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息，请参见用户指南的&amp;ldquo; &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;分类指标&amp;rdquo;&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="9391e01adcbcd6eab5489ba5c5bbde2b34c1c767" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息，请参阅用户指南的&amp;ldquo; &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;模型评估：量化预测的质量&amp;rdquo;&lt;/a&gt;部分和&amp;ldquo; &lt;a href=&quot;metrics#metrics&quot;&gt;成对度量，亲和力和内核&amp;rdquo;&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="794b0f5d5def59a318bd787a4fccdd542a21003c" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;Multilabel ranking metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息，请参见用户指南的&amp;ldquo; &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;多标签排名指标&amp;rdquo;&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="2e87795fde7a0f4562bca5bb85f3c7f5918727b2" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;Regression metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息，请参见用户指南的&lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;回归指标&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="e8449bc2e3e9fd1500a092c7a467f1094a642fdf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">有关更多详细信息，请参见用户指南的&lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;&amp;ldquo;评分参数：定义模型评估规则&amp;rdquo;&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="bc10a00d51f81094bb499f5ba451c68f15309214" translate="yes" xml:space="preserve">
          <source>See the console&amp;rsquo;s output for further details about each model.</source>
          <target state="translated">有关每种型号的更多详细信息，请参见控制台的输出。</target>
        </trans-unit>
        <trans-unit id="cd81e4d9092f6289f9eb153c5b671f6c9ec59b00" translate="yes" xml:space="preserve">
          <source>See the docstring of DistanceMetric for a list of available metrics.</source>
          <target state="translated">请参阅DistanceMetric的docstring以获取可用的度量列表。</target>
        </trans-unit>
        <trans-unit id="bf132d2b0dc3be6b88274385f87b0ee3f849742c" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics.</source>
          <target state="translated">关于这些指标的细节,请参见 scipy.spatial.distance 的文档。</target>
        </trans-unit>
        <trans-unit id="7af63b893a630b06c001dfe05c36e8144bafc593" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="translated">有关这些指标的详细信息，请参见scipy.spatial.distance文档：&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http&lt;/a&gt; ://docs.scipy.org/doc/scipy/reference/spatial.distance.html</target>
        </trans-unit>
        <trans-unit id="c235949c8aa0b531ecb9dfa56db515940237097e" translate="yes" xml:space="preserve">
          <source>See the examples below and the doc string of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="translated">有关更多信息，请参见下面的示例和&lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt; &lt;code&gt;MLPClassifier.fit&lt;/code&gt; &lt;/a&gt;的文档字符串。</target>
        </trans-unit>
        <trans-unit id="0f593defdf84cd9d54340a0b9eb8bdbba2164c5f" translate="yes" xml:space="preserve">
          <source>See the examples below for further information.</source>
          <target state="translated">更多信息请参见下面的例子。</target>
        </trans-unit>
        <trans-unit id="43e09506578d0fedfc6592860be1e23c1f8ef43b" translate="yes" xml:space="preserve">
          <source>See the examples for such an application.</source>
          <target state="translated">请看这样的应用实例。</target>
        </trans-unit>
        <trans-unit id="e8c17521507d95b1954b9918e527f968af48b835" translate="yes" xml:space="preserve">
          <source>See. &amp;ldquo;Pattern Recognition and Machine Learning&amp;rdquo; by C. Bishop, 12.2.1 p. 574 or &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">看到。C. Bishop撰写的&amp;ldquo;模式识别和机器学习&amp;rdquo;，第12.2.1页。574或&lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e4871111c8505b7690af20e518e753ae1b90a5ad" translate="yes" xml:space="preserve">
          <source>Seed for the random number generator used for probability estimates. 0 by default.</source>
          <target state="translated">用于概率估计的随机数发生器的种子。默认为0。</target>
        </trans-unit>
        <trans-unit id="72c84d205a7667dfdb05c6ebaaf98f08a838df92" translate="yes" xml:space="preserve">
          <source>Seeding is performed using a binning technique for scalability.</source>
          <target state="translated">播种采用分片技术进行扩展。</target>
        </trans-unit>
        <trans-unit id="f1f3844996349c701e3db8be5a62a8ace310a543" translate="yes" xml:space="preserve">
          <source>Seeds used to initialize kernels. If not set, the seeds are calculated by clustering.get_bin_seeds with bandwidth as the grid size and default values for other parameters.</source>
          <target state="translated">用于初始化内核的种子。如果没有设置,种子由clustering.get_bin_seeds计算,网格大小为带宽,其他参数为默认值。</target>
        </trans-unit>
        <trans-unit id="1a053c7e782c53a91d6d509bf6a99224f4b893d2" translate="yes" xml:space="preserve">
          <source>Segmenting the picture of greek coins in regions</source>
          <target state="translated">按地区划分希腊钱币的画面</target>
        </trans-unit>
        <trans-unit id="05c2c519388dfeab1d2da32ad0c3a55d08148aed" translate="yes" xml:space="preserve">
          <source>Select &lt;code&gt;min_samples&lt;/code&gt; random samples from the original data and check whether the set of data is valid (see &lt;code&gt;is_data_valid&lt;/code&gt;).</source>
          <target state="translated">从原始数据中选择 &lt;code&gt;min_samples&lt;/code&gt; 个随机样本，并检查数据集是否有效（请参见 &lt;code&gt;is_data_valid&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="4c8220c40092a5223a7519a4053e419620df4d58" translate="yes" xml:space="preserve">
          <source>Select eigensolver to use. If n_components is much less than the number of training samples, arpack may be more efficient than the dense eigensolver.</source>
          <target state="translated">选择要使用的 eigensolver。如果n_components远小于训练样本的数量,那么arpack可能会比密集的eigensolver更有效。</target>
        </trans-unit>
        <trans-unit id="a8b26e8dd8c57424e2a0ff5f2b02e8bbc7be69eb" translate="yes" xml:space="preserve">
          <source>Select features according to a percentile of the highest scores.</source>
          <target state="translated">根据最高分的百分位数选择特征。</target>
        </trans-unit>
        <trans-unit id="d20a85a468318484f73da066702f203468ec7eb5" translate="yes" xml:space="preserve">
          <source>Select features according to the k highest scores.</source>
          <target state="translated">根据k个最高分选择特征。</target>
        </trans-unit>
        <trans-unit id="c3952e3b9f6e5571ab9a9f69665172397cc254d2" translate="yes" xml:space="preserve">
          <source>Select features based on a false positive rate test.</source>
          <target state="translated">根据假阳性率测试选择特征。</target>
        </trans-unit>
        <trans-unit id="32515d7cef117ccce44afc2f4f0b98f43d0db807" translate="yes" xml:space="preserve">
          <source>Select features based on an estimated false discovery rate.</source>
          <target state="translated">根据估计的错误发现率选择特征。</target>
        </trans-unit>
        <trans-unit id="6d7a0df88fc316c1f019dac960b65ab544487a37" translate="yes" xml:space="preserve">
          <source>Select features based on family-wise error rate.</source>
          <target state="translated">根据家族的错误率选择特征。</target>
        </trans-unit>
        <trans-unit id="ba417981f6009fc06cd3596ff9c6cb4c2bd25319" translate="yes" xml:space="preserve">
          <source>Select features based on percentile of the highest scores.</source>
          <target state="translated">根据最高分的百分位数选择特征。</target>
        </trans-unit>
        <trans-unit id="3532493330a0445601f2381a89fe492b8458f964" translate="yes" xml:space="preserve">
          <source>Select features based on the k highest scores.</source>
          <target state="translated">根据k个最高分选择特征。</target>
        </trans-unit>
        <trans-unit id="fc6cce4211d0c67d4111ac2f86243aa83948ed07" translate="yes" xml:space="preserve">
          <source>Select n_samples integers from the set [0, n_population) without replacement.</source>
          <target state="translated">从集合[0,n_population)中选择n_samples整数,不进行替换。</target>
        </trans-unit>
        <trans-unit id="e693da3619bc133d154aaf34e091d4f9f76e8468" translate="yes" xml:space="preserve">
          <source>Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples &amp;gt; n_features.</source>
          <target state="translated">选择算法来解决对偶或原始优化问题。当n_samples&amp;gt; n_features时，首选dual = False。</target>
        </trans-unit>
        <trans-unit id="e09f39accd13c28376a1ebc78d546869197bec0f" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the development training set, &amp;lsquo;test&amp;rsquo; for the development test set, and &amp;lsquo;10_folds&amp;rsquo; for the official evaluation set that is meant to be used with a 10-folds cross validation.</source>
          <target state="translated">选择要加载的数据集：&amp;ldquo;培训&amp;rdquo;用于开发训练集，&amp;ldquo;测试&amp;rdquo;用于开发测试集，&amp;ldquo; 10_folds&amp;rdquo;用于正式评估集，该评估集将与10倍交叉验证一起使用。</target>
        </trans-unit>
        <trans-unit id="da5a2fc4086f03333558c16d8aba6a6ba8f98164" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set (23149 samples), &amp;lsquo;test&amp;rsquo; for the test set (781265 samples), &amp;lsquo;all&amp;rsquo; for both, with the training samples first if shuffle is False. This follows the official LYRL2004 chronological split.</source>
          <target state="translated">选择要加载的数据集：训练集（23149个样本）的&amp;ldquo; train&amp;rdquo;，测试集（781265个样本）的&amp;ldquo; test&amp;rdquo;，两个测试集&amp;ldquo; all&amp;rdquo;，如果混洗为False，则首先使用训练样本。这是按照LYRL2004官方时间顺序进行的。</target>
        </trans-unit>
        <trans-unit id="a373737a4d85a4134f237dcaa76f506d35776152" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set, &amp;lsquo;test&amp;rsquo; for the test set, &amp;lsquo;all&amp;rsquo; for both, with shuffled ordering.</source>
          <target state="translated">选择要加载的数据集：训练集为&amp;ldquo; train&amp;rdquo;，测试集为&amp;ldquo; test&amp;rdquo;，两者均为&amp;ldquo; all&amp;rdquo;，并按随机顺序排序。</target>
        </trans-unit>
        <trans-unit id="c5f861c6085a651c0ed9619f5012b02bb9a2d195" translate="yes" xml:space="preserve">
          <source>Select the parameters that minimises the impurity</source>
          <target state="translated">选择最小化杂质的参数</target>
        </trans-unit>
        <trans-unit id="776d7f86c8363c5c583ee4e086a4256b8464f6f6" translate="yes" xml:space="preserve">
          <source>Select the portion to load: &amp;lsquo;train&amp;rsquo;, &amp;lsquo;test&amp;rsquo; or &amp;lsquo;raw&amp;rsquo;</source>
          <target state="translated">选择要加载的部分：&amp;ldquo;训练&amp;rdquo;，&amp;ldquo;测试&amp;rdquo;或&amp;ldquo;原始&amp;rdquo;</target>
        </trans-unit>
        <trans-unit id="09caeaab6645f9fa60776419a39bd350760c6b9f" translate="yes" xml:space="preserve">
          <source>Selecting &lt;code&gt;average=None&lt;/code&gt; will return an array with the score for each class.</source>
          <target state="translated">选择 &lt;code&gt;average=None&lt;/code&gt; 将返回一个数组，其中包含每个课程的分数。</target>
        </trans-unit>
        <trans-unit id="09987abb5cb6e00639cc8ad149fcfc0ee4e216e7" translate="yes" xml:space="preserve">
          <source>Selecting dimensionality reduction with Pipeline and GridSearchCV</source>
          <target state="translated">用Pipeline和GridSearchCV来选择减维方法</target>
        </trans-unit>
        <trans-unit id="b619a7e9444390b8df9ed15ee53211d47286dc3c" translate="yes" xml:space="preserve">
          <source>Selecting the number of clusters with silhouette analysis on KMeans clustering</source>
          <target state="translated">在KMeans聚类上用剪影分析选择聚类数量</target>
        </trans-unit>
        <trans-unit id="1e3a867140ee60f287b6c8b807e610aee224839f" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, use &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, use &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt;&lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;&lt;/a&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">选择用于查找奇异矢量的算法。可能是&amp;ldquo;随机&amp;rdquo;或&amp;ldquo; arpack&amp;rdquo;。如果是&amp;ldquo;随机化&amp;rdquo;的，则使用&lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; &lt;/a&gt;，对于大型矩阵来说可能更快。如果是'arpack'，请使用&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt; &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; &lt;/a&gt;，它虽然更准确，但在某些情况下可能更慢。</target>
        </trans-unit>
        <trans-unit id="ba0796ade5894bc55073846864af8524b40634d7" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">选择用于查找奇异矢量的算法。可能是&amp;ldquo;随机&amp;rdquo;或&amp;ldquo; arpack&amp;rdquo;。如果&amp;ldquo;随机化&amp;rdquo;，则使用 &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; ，对于大型矩阵来说可能更快。如果为'arpack'，则使用 &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; ，它虽然更准确，但在某些情况下可能更慢。</target>
        </trans-unit>
        <trans-unit id="0c634aac4fba33953abfb672747b23d137a6eb94" translate="yes" xml:space="preserve">
          <source>Sepal length</source>
          <target state="translated">萼片长度</target>
        </trans-unit>
        <trans-unit id="fb329e5a4491aa43414f15d76bffc8963ea0de09" translate="yes" xml:space="preserve">
          <source>Sepal width</source>
          <target state="translated">萼片宽度</target>
        </trans-unit>
        <trans-unit id="e5dddf892a3efc8978d095e912cc4306a1e49804" translate="yes" xml:space="preserve">
          <source>Separating inliers from outliers using a Mahalanobis distance</source>
          <target state="translated">使用Mahalanobis距离分离离群值和异常值</target>
        </trans-unit>
        <trans-unit id="aece656a00e1c7a3f193615a59fc1f63e6e58693" translate="yes" xml:space="preserve">
          <source>Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;ldquo;Decision Tree Construction Via Linear Programming.&amp;rdquo; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.</source>
          <target state="translated">上述分离平面是使用多表面方法树（MSM-T）[KP Bennett，&amp;ldquo;通过线性编程构造决策树&amp;rdquo;获得的。第四届中西部人工智能与认知科学学会会议论文集，第97-101页，1992年]，一种使用线性规划来构建决策树的分类方法。在1-4个特征和1-3个分离平面的空间中使用详尽搜索选择了相关特征。</target>
        </trans-unit>
        <trans-unit id="749810666e6448d7103b8c1ba2bbfef3e451d983" translate="yes" xml:space="preserve">
          <source>Separator string used when constructing new features for one-hot coding.</source>
          <target state="translated">构建新功能时使用的分隔符字符串,用于一热编码。</target>
        </trans-unit>
        <trans-unit id="70aafd2a89678b32332fcfe0ff93efd39c5a3c06" translate="yes" xml:space="preserve">
          <source>Sequence of integer labels or multilabel data to encode.</source>
          <target state="translated">要编码的整数标签或多标签数据的序列。</target>
        </trans-unit>
        <trans-unit id="63145e1c892f5c29b2a500cdc3f15222c0784b14" translate="yes" xml:space="preserve">
          <source>Sequence of resampled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">采集的重新采样副本的序列。原始阵列不受影响。</target>
        </trans-unit>
        <trans-unit id="22f488ee4fca141470b8e2b188abe2e7275b3dc0" translate="yes" xml:space="preserve">
          <source>Sequence of shuffled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">藏品的洗牌副本序列。原始阵列不受影响。</target>
        </trans-unit>
        <trans-unit id="05f31ec9564cc0e3d1b047a8eba0a9e234d2f0b3" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted class labels (&lt;code&gt;hard&lt;/code&gt; voting) or class probabilities before averaging (&lt;code&gt;soft&lt;/code&gt; voting). Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">加权序列（ &lt;code&gt;float&lt;/code&gt; 或 &lt;code&gt;int&lt;/code&gt; ），用于在平均（ &lt;code&gt;soft&lt;/code&gt; 投票）之前对预测的类别标签（ &lt;code&gt;hard&lt;/code&gt; 投票）或类别概率的出现进行加权。如果为 &lt;code&gt;None&lt;/code&gt; ,则使用统一的权重。</target>
        </trans-unit>
        <trans-unit id="0ea6d0fbbfa7ff1125b3f0dc0d1f0f204d3b725f" translate="yes" xml:space="preserve">
          <source>Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be &amp;lsquo;transforms&amp;rsquo;, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using &lt;code&gt;memory&lt;/code&gt; argument.</source>
          <target state="translated">依次应用变换列表和最终估算器。流水线的中间步骤必须是&amp;ldquo;转换&amp;rdquo;，也就是说，它们必须实现拟合和转换方法。最终估算器只需实现拟合。可以使用 &lt;code&gt;memory&lt;/code&gt; 参数来缓存管道中的转换器。</target>
        </trans-unit>
        <trans-unit id="5d912fff074ca31c7c82b5fde02f4d9656aba0e0" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;kernel='precomputed'&lt;/code&gt; and pass the Gram matrix instead of X in the fit method. At the moment, the kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided.</source>
          <target state="translated">设置 &lt;code&gt;kernel='precomputed'&lt;/code&gt; 并在fit方法中传递Gram矩阵而不是X。目前，必须提供&lt;em&gt;所有&lt;/em&gt;训练向量和测试向量之间的内核值。</target>
        </trans-unit>
        <trans-unit id="82c89924e3ff5aee8a7d762157ebec36e4bfb77e" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;n_clusters&lt;/code&gt; to a required value using &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt;.</source>
          <target state="translated">使用 &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt; 将 &lt;code&gt;n_clusters&lt;/code&gt; 设置为所需值。</target>
        </trans-unit>
        <trans-unit id="baf739c6d3f3081a673c9a62345f43337d9146af" translate="yes" xml:space="preserve">
          <source>Set an initial start configuration, randomly or not.</source>
          <target state="translated">设置初始启动配置,随机或不随机。</target>
        </trans-unit>
        <trans-unit id="7115214e952526d911c94e2c07be9533a4c1bc42" translate="yes" xml:space="preserve">
          <source>Set global scikit-learn configuration</source>
          <target state="translated">设置全局scikit-learn配置</target>
        </trans-unit>
        <trans-unit id="d973ce66011b9fa67c29ae92b31d59e39ce28a97" translate="yes" xml:space="preserve">
          <source>Set of samples, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">样本集,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="859e800d4c0c95faf85e59d644290b4f9223483a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">对于SVC ，将类i的参数C设置为 &lt;code&gt;class_weight[i]*C&lt;/code&gt; 如果未给出，则所有类都应具有权重一。&amp;ldquo;平衡&amp;rdquo;模式使用y的值自动将权重与输入数据中的类频率成反比地调整为 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="68197d507e5463b3337bc09b3b9761d9525e528a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">对于SVC，将类i的参数C设置为class_weight [i] * C。如果未给出，则所有类都应具有权重一。&amp;ldquo;平衡&amp;rdquo;模式使用y的值自动将权重与类频率成反比地调整为 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7ee0e3c771d52a3f4b21637b50de4b2fa144cadb" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">对于SVC，将类i的参数C设置为class_weight [i] * C。如果未给出，则所有类都应具有权重一。&amp;ldquo;平衡&amp;rdquo;模式使用y的值自动将权重与输入数据中的类频率成反比地调整为 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="02c4dadc552ae2f0292cf77b2c6f20b9175838e2" translate="yes" xml:space="preserve">
          <source>Set the parameters</source>
          <target state="translated">设置参数</target>
        </trans-unit>
        <trans-unit id="72f87d2d27b1f0c322a530ad0dc9b59597d7be5b" translate="yes" xml:space="preserve">
          <source>Set the parameters of this estimator.</source>
          <target state="translated">设置该估计器的参数。</target>
        </trans-unit>
        <trans-unit id="57d60e82b45349e99163b5cb25f5c26dc09997fb" translate="yes" xml:space="preserve">
          <source>Set the parameters of this kernel.</source>
          <target state="translated">设置该内核的参数。</target>
        </trans-unit>
        <trans-unit id="e51dac5748f92b9a4d95a295db13667c4d900b8f" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation during transformation.</source>
          <target state="translated">设置为False,在转换过程中执行原位计算。</target>
        </trans-unit>
        <trans-unit id="c9e442dcb8465293c9e9b1ca26f1df573cbc8a5b" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation.</source>
          <target state="translated">设置为 &quot;False&quot;,则执行原地计算。</target>
        </trans-unit>
        <trans-unit id="66ebe619c3b8004252e57f6a28ff4945f1da8024" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace row normalization and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">设置为 &quot;False&quot;,以执行嵌位行归一化并避免复制(如果输入已经是一个numpy数组)。</target>
        </trans-unit>
        <trans-unit id="00972eb158db00f5dae23773f938b4091d65b472" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace scaling and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">设置为False,以执行原地缩放并避免复制(如果输入已经是一个numpy数组)。</target>
        </trans-unit>
        <trans-unit id="08f65c010729649e9d6102eb99a0ed3b76fe0859" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">设置为False,以执行原位转换并避免复制(如果输入已经是一个numpy数组)。</target>
        </trans-unit>
        <trans-unit id="70773d7b4f76452047259ed8e2e9af7169f13fc0" translate="yes" xml:space="preserve">
          <source>Set to True to apply zero-mean, unit-variance normalization to the transformed output.</source>
          <target state="translated">设置为True,将零均值、单位方差归一化应用于变换后的输出。</target>
        </trans-unit>
        <trans-unit id="a7d505eb35ec97e19208554a83f21f5336e3915d" translate="yes" xml:space="preserve">
          <source>Set to true if output binary array is desired in CSR sparse format</source>
          <target state="translated">如果需要以CSR稀疏格式输出二进制数组,则设置为真。</target>
        </trans-unit>
        <trans-unit id="e9779b7ab3cf4b478b4bfa7669bfc4f6492ae2ea" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;assume_finite&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">设置 &lt;code&gt;assume_finite&lt;/code&gt; 的&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt;的默认值。</target>
        </trans-unit>
        <trans-unit id="2047224d21bf76be06bd841e22b2f6efe81f5987" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;working_memory&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">设置&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;working_memory&lt;/code&gt; 参数的默认值。</target>
        </trans-unit>
        <trans-unit id="8fc661c1feefb08f484398590a9cfaa0d200700d" translate="yes" xml:space="preserve">
          <source>Sets the seed of the global random generator when running the tests, for reproducibility.</source>
          <target state="translated">设置运行测试时全局随机发生器的种子,以保证重复性。</target>
        </trans-unit>
        <trans-unit id="ceca261ca4bfaf0dac2e7a5f6879bae3049e05bd" translate="yes" xml:space="preserve">
          <source>Sets the verbosity amount</source>
          <target state="translated">设置啰嗦的数量</target>
        </trans-unit>
        <trans-unit id="41f97bb142955ba403db62394a8510aa45205b7b" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well</source>
          <target state="translated">将其设置为True,可以得到各种分类器以及分类器的参数。</target>
        </trans-unit>
        <trans-unit id="2623b7b1ad6f2c3b5492832d70831c56aba6aac8" translate="yes" xml:space="preserve">
          <source>Setting the parameter by cross-validating the likelihood on three folds according to a grid of potential shrinkage parameters.</source>
          <target state="translated">根据潜在的收缩参数网格,通过在三个褶皱上交叉验证似然来设置参数。</target>
        </trans-unit>
        <trans-unit id="edca67601d1a75cccde1deb24fddb7bb63088fcb" translate="yes" xml:space="preserve">
          <source>Setting the parameters for the voting classifier</source>
          <target state="translated">设置投票分类器的参数</target>
        </trans-unit>
        <trans-unit id="cb6261b9db86d6920a006098fc7538ed80a40df3" translate="yes" xml:space="preserve">
          <source>Several estimators in the scikit-learn can use connectivity information between features or samples. For instance Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;) can cluster together only neighboring pixels of an image, thus forming contiguous patches:</source>
          <target state="translated">scikit学习中的多个估计器可以使用要素或样本之间的连接信息。例如，Ward聚类（&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;）只能将图像的相邻像素聚类在一起，从而形成连续的补丁：</target>
        </trans-unit>
        <trans-unit id="b2ad224369c25dffec31e32504aa18be16f8d837" translate="yes" xml:space="preserve">
          <source>Several functions allow you to analyze the precision, recall and F-measures score:</source>
          <target state="translated">有几个功能可以让您分析精确度、召回率和F-measures分数。</target>
        </trans-unit>
        <trans-unit id="beccb29e29ebc99080f8c36d4203650a9f29b872" translate="yes" xml:space="preserve">
          <source>Several methods have been developed to compare two sets of biclusters. For now, only &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt;&lt;code&gt;consensus_score&lt;/code&gt;&lt;/a&gt; (Hochreiter et. al., 2010) is available:</source>
          <target state="translated">已经开发了几种方法来比较两组双锥。目前，仅&lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt; &lt;code&gt;consensus_score&lt;/code&gt; &lt;/a&gt;得分（Hochreiter等，2010）可用：</target>
        </trans-unit>
        <trans-unit id="bf696ed0c48f638295bdb050d71aac6a4287ef6f" translate="yes" xml:space="preserve">
          <source>Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.</source>
          <target state="translated">scikit-learn中提供了几种回归和二元分类算法。将这些算法扩展到多类分类情况的一个简单方法是使用所谓的onevs-all方案。</target>
        </trans-unit>
        <trans-unit id="e301dd6062f7e9a79975fe8e2d0ba91694c4dbc3" translate="yes" xml:space="preserve">
          <source>Sex</source>
          <target state="translated">Sex</target>
        </trans-unit>
        <trans-unit id="94351e57e5ad4d9a685a9e5e4a3a8ed2b422ed01" translate="yes" xml:space="preserve">
          <source>Shape of the data arrays</source>
          <target state="translated">数据阵列的形状</target>
        </trans-unit>
        <trans-unit id="6ce851a20ced87e3a45210428f1caa987910f68a" translate="yes" xml:space="preserve">
          <source>Shape of the i&amp;rsquo;th bicluster.</source>
          <target state="translated">第i个双锥的形状。</target>
        </trans-unit>
        <trans-unit id="e14b35d505512b3adb2f8997ae35ca2be24040d8" translate="yes" xml:space="preserve">
          <source>Shape will be [n_samples, 1] for binary problems.</source>
          <target state="translated">二进制问题的形状将是[n_samples,1]。</target>
        </trans-unit>
        <trans-unit id="f4aa10e40109dde70a9d57a4c3969b16b2895540" translate="yes" xml:space="preserve">
          <source>Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].</source>
          <target state="translated">用指定的值移动特征。如果None,则用[-class_sep,class_sep]中的随机值移动特征。</target>
        </trans-unit>
        <trans-unit id="89ec1dbbc8f85faf0ad282b8a6481e07a4785260" translate="yes" xml:space="preserve">
          <source>Shifted opposite of the Local Outlier Factor of X.</source>
          <target state="translated">与X的局部离群因素相反的转变。</target>
        </trans-unit>
        <trans-unit id="5433cd73ac014316d0b32695693eab5029601309" translate="yes" xml:space="preserve">
          <source>Shorthand</source>
          <target state="translated">Shorthand</target>
        </trans-unit>
        <trans-unit id="a8178c51c2cc3204c708328447fd16ef389ce9b6" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.</source>
          <target state="translated">应该在内存不足以训练所有数据时使用。数据块可以通过多次迭代,其中第一次调用应该有一个所有目标变量的数组。</target>
        </trans-unit>
        <trans-unit id="12700416ee0fef7fdd5157d1c27acbb9da13d5c9" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration.</source>
          <target state="translated">应该在内存无法有效训练所有数据时使用。数据块可以在多次迭代中传递。</target>
        </trans-unit>
        <trans-unit id="ec934ba88e117c3577f933302800f3ab4b85705a" translate="yes" xml:space="preserve">
          <source>Show below is a logistic-regression classifiers decision boundaries on the first two dimensions (sepal length and width) of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; dataset. The datapoints are colored according to their labels.</source>
          <target state="translated">下面显示的是&lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;虹膜&lt;/a&gt;数据集的前两个维度（空间长度和宽度）上的逻辑回归分类器决策边界。数据点根据其标签着色。</target>
        </trans-unit>
        <trans-unit id="c74e263b32d3703a876a54ba7cc367e3fb1c6bbb" translate="yes" xml:space="preserve">
          <source>Shown in the plot is how the logistic regression would, in this synthetic dataset, classify values as either 0 or 1, i.e. class one or two, using the logistic curve.</source>
          <target state="translated">图中显示的是在这个合成数据集中,逻辑回归如何利用逻辑曲线将数值划分为0或1,即一类或二类。</target>
        </trans-unit>
        <trans-unit id="ca5bc8cbcc9592e82a2ca132c00133d4ad37408e" translate="yes" xml:space="preserve">
          <source>Shows how shrinkage improves classification.</source>
          <target state="translated">显示了收缩如何改善分类。</target>
        </trans-unit>
        <trans-unit id="5dc7ad8809a977f328219d536276f520094e2981" translate="yes" xml:space="preserve">
          <source>Shows how to use a function transformer in a pipeline. If you know your dataset&amp;rsquo;s first principle component is irrelevant for a classification task, you can use the FunctionTransformer to select all but the first column of the PCA transformed data.</source>
          <target state="translated">显示如何在管道中使用功能转换器。如果您知道数据集的第一主成分与分类任务无关，则可以使用FunctionTransformer选择PCA转换数据之外的所有第一列。</target>
        </trans-unit>
        <trans-unit id="f535d0d4250bfadc5c1c6932476e7cb22e7db70e" translate="yes" xml:space="preserve">
          <source>Shows the effect of collinearity in the coefficients of an estimator.</source>
          <target state="translated">显示估计器的系数中的一致性的影响。</target>
        </trans-unit>
        <trans-unit id="1a78e7f7618436a20d69e64d9d5ffb3bc060c908" translate="yes" xml:space="preserve">
          <source>Shrinkage</source>
          <target state="translated">Shrinkage</target>
        </trans-unit>
        <trans-unit id="29ad8c0361eee52379ab28eb86f7303c232b073b" translate="yes" xml:space="preserve">
          <source>Shrinkage and sparsity with logistic regression</source>
          <target state="translated">用逻辑回归法进行收缩和稀疏处理</target>
        </trans-unit>
        <trans-unit id="92e7e7782831a32d85f1f4adb6e6848b9931e9f2" translate="yes" xml:space="preserve">
          <source>Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</source>
          <target state="translated">收缩协方差估计。LedoitWolf与OAS和最大似然的比较。</target>
        </trans-unit>
        <trans-unit id="bc56f7d6f334df6e1bf7e25fb6694a2b96d3283e" translate="yes" xml:space="preserve">
          <source>Shrinkage is a tool to improve estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="translated">在训练样本数量比特征数量少的情况下，收缩是一种改进协方差矩阵估计的工具。在这种情况下，经验样本协方差是一个不好的估计。可以通过将&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;类的 &lt;code&gt;shrinkage&lt;/code&gt; 参数设置为'auto' 来使用收缩LDA 。这将按照Ledoit和Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;引入的引理，以解析的方式自动确定最佳的收缩参数。请注意，当前收缩仅在将 &lt;code&gt;solver&lt;/code&gt; 参数设置为&amp;ldquo; lsqr&amp;rdquo;或&amp;ldquo;本征&amp;rdquo;时有效。</target>
        </trans-unit>
        <trans-unit id="7e8136e1a5918ee41b1666fa514179c5cb22402c" translate="yes" xml:space="preserve">
          <source>Shrinkage parameter, possible values:</source>
          <target state="translated">收缩参数,可能值:</target>
        </trans-unit>
        <trans-unit id="b2a27e6ba825492dec9776790877b64e516e75e0" translate="yes" xml:space="preserve">
          <source>Shrunk covariance.</source>
          <target state="translated">缩小协方差。</target>
        </trans-unit>
        <trans-unit id="4dcdf0ff13bd4f7b65e07eadf0216796b5d56197" translate="yes" xml:space="preserve">
          <source>Shuffle arrays or sparse matrices in a consistent way</source>
          <target state="translated">以一致的方式对数组或稀疏矩阵进行洗牌。</target>
        </trans-unit>
        <trans-unit id="c0ccd0261920fa2fccaab512e3420b322d650304" translate="yes" xml:space="preserve">
          <source>Shuffle the samples and the features.</source>
          <target state="translated">对样本和功能进行洗牌。</target>
        </trans-unit>
        <trans-unit id="372aba820bed6f2900292d1b119c1b7c02346b33" translate="yes" xml:space="preserve">
          <source>Shuffle the samples.</source>
          <target state="translated">洗牌样品。</target>
        </trans-unit>
        <trans-unit id="bb741d2d7cb4e292767bcf7b4c4d2a7dcedf441d" translate="yes" xml:space="preserve">
          <source>Shuffle-Group(s)-Out cross-validation iterator</source>
          <target state="translated">Shuffle-Group(s)-Out交叉验证迭代器。</target>
        </trans-unit>
        <trans-unit id="04a76dd0a6286b28de9940305c73988458741a00" translate="yes" xml:space="preserve">
          <source>Signed distance is positive for an inlier and negative for an outlier.</source>
          <target state="translated">有符号的距离,对内者为正,对外者为负。</target>
        </trans-unit>
        <trans-unit id="175a8f49ca538859a1536806ea283ecf7546e18e" translate="yes" xml:space="preserve">
          <source>Signed distance to the separating hyperplane.</source>
          <target state="translated">到分离超平面的符号距离。</target>
        </trans-unit>
        <trans-unit id="bdea7e4b3b56af1c4dc44f101507e6d5fde4c3c5" translate="yes" xml:space="preserve">
          <source>Silhouette Coefficient for each samples.</source>
          <target state="translated">每个样品的轮廓系数。</target>
        </trans-unit>
        <trans-unit id="cef2e4d37f21e366fe4348cb5c8e3de442e95913" translate="yes" xml:space="preserve">
          <source>Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].</source>
          <target state="translated">轮廓分析可用于研究所得聚类之间的分离距离。轮廓图显示了一个聚类中的每个点与相邻聚类中的点的接近程度,从而提供了一种直观评估聚类数量等参数的方法。这个度量的范围是[-1,1]。</target>
        </trans-unit>
        <trans-unit id="f28647d65c56d46a3ca67f993f108ac366d59691" translate="yes" xml:space="preserve">
          <source>Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.</source>
          <target state="translated">轮廓系数(这些数值被称为)接近+1时,表示样本远离相邻聚类。值为0表示样本在两个相邻聚类之间的决策边界上或非常接近,负值表示这些样本可能被分配到了错误的聚类。</target>
        </trans-unit>
        <trans-unit id="88d328be635604c256d2743bcb180fd1daab0b36" translate="yes" xml:space="preserve">
          <source>Similar feature extractors should be built for other kind of unstructured data input such as images, audio, video, &amp;hellip;</source>
          <target state="translated">应该为其他类型的非结构化数据输入（例如图像，音频，视频等）构建类似的特征提取器。</target>
        </trans-unit>
        <trans-unit id="319655ff7753a6199642b7bf6692dc2bf99bfe55" translate="yes" xml:space="preserve">
          <source>Similar to AgglomerativeClustering, but recursively merges features instead of samples.</source>
          <target state="translated">类似于AgglomerativeClustering,但递归合并特征而不是样本。</target>
        </trans-unit>
        <trans-unit id="133d603767b5dc043e4bab49b5255c4ddd0f05fe" translate="yes" xml:space="preserve">
          <source>Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.</source>
          <target state="translated">与NuSVC类似,对于回归,使用参数nu来控制支持向量的数量。但与NuSVC不同的是,nu代替了C,这里nu代替了epsilon-SVR的参数epsilon。</target>
        </trans-unit>
        <trans-unit id="d1a2b055f0753742d67fc90d1d4811e0a5d9ab30" translate="yes" xml:space="preserve">
          <source>Similar to SVC but uses a parameter to control the number of support vectors.</source>
          <target state="translated">类似于SVC,但使用一个参数来控制支持向量的数量。</target>
        </trans-unit>
        <trans-unit id="367343dd50d61c27ddbb7a06df2fb9885bdf8a5f" translate="yes" xml:space="preserve">
          <source>Similar to SVC with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">类似于带有参数kernel ='linear'的SVC，但是是根据liblinear而不是libsvm来实现的，因此它在选择罚分和损失函数时具有更大的灵活性，并且应更好地扩展到大量样本。</target>
        </trans-unit>
        <trans-unit id="3ec63304462f4cbac1c3a261d38d9188bcded830" translate="yes" xml:space="preserve">
          <source>Similar to SVR with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">类似于带有参数kernel ='linear'的SVR，但它是根据liblinear而不是libsvm来实现的，因此它在选择罚分和损失函数时具有更大的灵活性，应更好地扩展到大量样本。</target>
        </trans-unit>
        <trans-unit id="997a429b680aeb0ca7576cadadd68b1d30fd4132" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms GBRT builds the additive model in a forward stagewise fashion:</source>
          <target state="translated">与其他升压算法类似,GBRT以正向滞后的方式建立加法模型。</target>
        </trans-unit>
        <trans-unit id="9dba587c665016505432ed3d83545171f96e0b75" translate="yes" xml:space="preserve">
          <source>Similarity between individual biclusters is computed. Then the best matching between sets is found using the Hungarian algorithm. The final score is the sum of similarities divided by the size of the larger set.</source>
          <target state="translated">计算各个双簇之间的相似度。然后使用匈牙利算法找到集之间的最佳匹配。最后的得分是相似度之和除以大集合的大小。</target>
        </trans-unit>
        <trans-unit id="a365c849553e02aafca0dfedfc5010bc90d3ae71" translate="yes" xml:space="preserve">
          <source>Similarity score between -1.0 and 1.0. Random labelings have an ARI close to 0.0. 1.0 stands for perfect match.</source>
          <target state="translated">相似性得分在-1.0和1.0之间。随机标签的ARI接近0.0。1.0代表完全匹配。</target>
        </trans-unit>
        <trans-unit id="186186d91781f080c251077ac03fc20cf1639d0c" translate="yes" xml:space="preserve">
          <source>Similarly, &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt;&lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt;&lt;/a&gt; repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">同样，&lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt; &lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt; &lt;/a&gt; -Fold重复执行Stratified K-Fold n次，每次重复具有不同的随机性。</target>
        </trans-unit>
        <trans-unit id="01f578d801e5d1ea722f26bf3985038251d17ab9" translate="yes" xml:space="preserve">
          <source>Similarly, L1 regularized logistic regression solves the following optimization problem</source>
          <target state="translated">类似地,L1正则化逻辑回归解决了以下优化问题。</target>
        </trans-unit>
        <trans-unit id="33d5515f485c474434afb456d44ce55ecb3a831d" translate="yes" xml:space="preserve">
          <source>Similarly, labels not present in the data sample may be accounted for in macro-averaging.</source>
          <target state="translated">同样,数据样本中不存在的标签也可以在宏观平均中加以考虑。</target>
        </trans-unit>
        <trans-unit id="0c868e091c0bbbbc855227dfcc9797f545ef094e" translate="yes" xml:space="preserve">
          <source>Simple 1D Kernel Density Estimation</source>
          <target state="translated">简单的一维核密度估计</target>
        </trans-unit>
        <trans-unit id="f5468d7aca1a86ccbbf784d0772796020bb33f7b" translate="yes" xml:space="preserve">
          <source>Simple to understand and to interpret. Trees can be visualised.</source>
          <target state="translated">简单的理解和解释。树木可以可视化。</target>
        </trans-unit>
        <trans-unit id="954c17f332cbfd66dfa98282859837f21d64fd6a" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a C-SVM of the selected features.</source>
          <target state="translated">简单使用Pipeline,连续运行单变量特征选择与anova,然后对所选特征进行C-SVM。</target>
        </trans-unit>
        <trans-unit id="50f8d26df97413619de7bb6966a9aa041cc32e16" translate="yes" xml:space="preserve">
          <source>Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors.</source>
          <target state="translated">简单使用支持向量机对样本进行分类。它将绘制决策面和支持向量。</target>
        </trans-unit>
        <trans-unit id="5b50d9c69163fc1e922706c7d40ea5de7c4c3507" translate="yes" xml:space="preserve">
          <source>Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with multivariate response, a.k.a. PLS2 - PLSRegression, with univariate response, a.k.a. PLS1 - CCA</source>
          <target state="translated">各种交叉分解算法的简单使用:-PLSCanonical-PLSRegression,with multivariate response,a.k.a.PLS2-PLSRegression,with univariate response,a.k.a.PLS1-CCA。</target>
        </trans-unit>
        <trans-unit id="0cd5c8d669edd41f72cf141b1f653ffc3a8f7d8a" translate="yes" xml:space="preserve">
          <source>Simply perform a svd on the crosscovariance matrix: X&amp;rsquo;Y There are no iterative deflation here.</source>
          <target state="translated">只需对交叉协方差矩阵执行svd：X'Y这里没有迭代放气。</target>
        </trans-unit>
        <trans-unit id="f72f0eda605215d24ff9d1908550395272883fb4" translate="yes" xml:space="preserve">
          <source>Simulations</source>
          <target state="translated">Simulations</target>
        </trans-unit>
        <trans-unit id="2e04b6f26b355099b78d114e001527cec11f01b3" translate="yes" xml:space="preserve">
          <source>Since \(P(x_1, \dots, x_n)\) is constant given the input, we can use the following classification rule:</source>
          <target state="translated">由于在给定输入的情况下,\(P(x_1,\dots,x_n)\)是常数,所以我们可以使用以下分类规则。</target>
        </trans-unit>
        <trans-unit id="4ed5170dfb2a4a5fe27dc284ef1f79230346d84b" translate="yes" xml:space="preserve">
          <source>Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.</source>
          <target state="translated">由于模型的内部表示在两个不同的架构上可能是不同的,所以不支持在一个架构上转储模型并在另一个架构上加载它。</target>
        </trans-unit>
        <trans-unit id="2e7dca0922f252e8bcb5dd7de62f190d029edf35" translate="yes" xml:space="preserve">
          <source>Since a simple modulo is used to transform the hash function to a column index, it is advisable to use a power of two as the &lt;code&gt;n_features&lt;/code&gt; parameter; otherwise the features will not be mapped evenly to the columns.</source>
          <target state="translated">由于使用简单的模将哈希函数转换为列索引，因此建议使用2的幂作为 &lt;code&gt;n_features&lt;/code&gt; 参数。否则，要素将不会均匀地映射到列。</target>
        </trans-unit>
        <trans-unit id="e94526c23963e4af6db5a385aa61965ac4ba9d0e" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">由于该方法需要适合 &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; 分类器，因此，由于其O（n_classes ^ 2）复杂性，因此该方法通常比其余方法慢一倍。但是，此方法对于无法很好地与 &lt;code&gt;n_samples&lt;/code&gt; 进行缩放的算法（例如内核算法）可能是有利的。这是因为每个单独的学习问题仅涉及数据的一小部分，而相对于其余部分，完整数据集的使用时间为 &lt;code&gt;n_classes&lt;/code&gt; 次。</target>
        </trans-unit>
        <trans-unit id="885cdc36b68d6b1fe527d22b8af012efa7ee88fc" translate="yes" xml:space="preserve">
          <source>Since our loss function is dependent on the amount of samples, the latter will influence the selected value of &lt;code&gt;C&lt;/code&gt;. The question that arises is &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</source>
          <target state="translated">由于损失函数取决于样本量，因此样本量将影响 &lt;code&gt;C&lt;/code&gt; 的选定值。出现的问题是 &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8414cbee67356c2ab2c8ba5220ad5c2247b09cc6" translate="yes" xml:space="preserve">
          <source>Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.</source>
          <target state="translated">由于递归分割可以用树形结构来表示,所以分离一个样本所需的分割次数相当于从根节点到终止节点的路径长度。</target>
        </trans-unit>
        <trans-unit id="41606a5be005625c4678c2fc6968d98c5bcdacbb" translate="yes" xml:space="preserve">
          <source>Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature&amp;rsquo;s value is zero. This mechanism is enabled by default with &lt;code&gt;alternate_sign=True&lt;/code&gt; and is particularly useful for small hash table sizes (&lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt;). For large hash table sizes, it can be disabled, to allow the output to be passed to estimators like &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt;&lt;/a&gt; feature selectors that expect non-negative inputs.</source>
          <target state="translated">由于散列函数可能会导致（不相关的）要素之间发生冲突，因此使用带符号的散列函数，并且散列值的符号确定存储在特征输出矩阵中的值的符号。这样，冲突可能会抵消而不是累积误差，并且任何输出要素的值的预期均值为零。默认情况下，使用 &lt;code&gt;alternate_sign=True&lt;/code&gt; 启用此机制，并且对于较小的哈希表大小（ &lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt; ）特别有用。对于较大的哈希表，可以将其禁用，以允许将输出传递给期望非负输入的估计器，例如&lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt; &lt;/a&gt;功能选择器。</target>
        </trans-unit>
        <trans-unit id="91020f655b0d3976000fc58a456fa0d94621c5a6" translate="yes" xml:space="preserve">
          <source>Since the kernel that is to be approximated is additive, the components of the input vectors can be treated separately. Each entry in the original space is transformed into 2*sample_steps+1 features, where sample_steps is a parameter of the method. Typical values of sample_steps include 1, 2 and 3.</source>
          <target state="translated">由于要近似的核是加法的,所以输入向量的分量可以分开处理。原始空间中的每个条目都被转化为2*sample_steps+1个特征,其中sample_steps是方法的一个参数。sample_steps的典型值包括1、2和3。</target>
        </trans-unit>
        <trans-unit id="dac98c213a89fd4774cf1c1f95b63e10c23ed6ab" translate="yes" xml:space="preserve">
          <source>Since the posterior is intractable, variational Bayesian method uses a simpler distribution \(q(z,\theta,\beta | \lambda, \phi, \gamma)\) to approximate it, and those variational parameters \(\lambda\), \(\phi\), \(\gamma\) are optimized to maximize the Evidence Lower Bound (ELBO):</source>
          <target state="translated">由于后验是难以解决的,变异贝叶斯方法使用更简单的分布/(q(z,\theta,\beta | \lambda,\phi,\gamma))来逼近它,那些变异参数/(\lambda/),\(\phi/),\(\gamma/)被优化为最大化证据下限(ELBO)。</target>
        </trans-unit>
        <trans-unit id="ce93b96a689b29304c626bbff15b3c9ae5662f8f" translate="yes" xml:space="preserve">
          <source>Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both &lt;code&gt;fpr&lt;/code&gt; and &lt;code&gt;tpr&lt;/code&gt;, which are sorted in reversed order during their calculation.</source>
          <target state="translated">由于阈值是从低值到高值排序的，因此在返回阈值时会将它们反转以确保它们对应于 &lt;code&gt;fpr&lt;/code&gt; 和 &lt;code&gt;tpr&lt;/code&gt; ，它们在计算过程中按相反的顺序排序。</target>
        </trans-unit>
        <trans-unit id="7f69d32984c3b4f143cfa37bb4e60432050ed0eb" translate="yes" xml:space="preserve">
          <source>Since there has not been much empirical work using approximate embeddings, it is advisable to compare results against exact kernel methods when possible.</source>
          <target state="translated">由于使用近似嵌入的经验性工作不多,所以在可能的情况下,最好将结果与精确内核方法进行比较。</target>
        </trans-unit>
        <trans-unit id="fa984969d0a90a5820c4fc022c64bfc47ca5a084" translate="yes" xml:space="preserve">
          <source>Single estimator versus bagging: bias-variance decomposition</source>
          <target state="translated">单一估计器与袋装估计器的比较:偏差-方差分解</target>
        </trans-unit>
        <trans-unit id="c2fe1a00c3aef2fdadf0dd5e7ea7933f55e2ab1b" translate="yes" xml:space="preserve">
          <source>Single metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt;</source>
          <target state="translated">使用 &lt;code&gt;cross_validate&lt;/code&gt; 进行单指标评估</target>
        </trans-unit>
        <trans-unit id="78a22764fe4a9b48a649589e690300655f65c80d" translate="yes" xml:space="preserve">
          <source>Single, average and complete linkage can be used with a variety of distances (or affinities), in particular Euclidean distance (&lt;em&gt;l2&lt;/em&gt;), Manhattan distance (or Cityblock, or &lt;em&gt;l1&lt;/em&gt;), cosine distance, or any precomputed affinity matrix.</source>
          <target state="translated">单个，平均和完整链接可以用于各种距离（或亲和力），尤其是欧几里得距离（&lt;em&gt;l2&lt;/em&gt;），曼哈顿距离（或Cityblock或&lt;em&gt;l1&lt;/em&gt;），余弦距离或任何预先计算的亲和度矩阵。</target>
        </trans-unit>
        <trans-unit id="857a843ae0f540aecaddebae91ddc74b518d5cf4" translate="yes" xml:space="preserve">
          <source>Singularities:</source>
          <target state="translated">Singularities:</target>
        </trans-unit>
        <trans-unit id="2df59d349ec07bd33a82cdc2b0c4c3d4152244c6" translate="yes" xml:space="preserve">
          <source>Size of minibatches for stochastic optimizers. If the solver is &amp;lsquo;lbfgs&amp;rsquo;, the classifier will not use minibatch. When set to &amp;ldquo;auto&amp;rdquo;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</source>
          <target state="translated">随机优化器的迷你批次的大小。如果求解器为&amp;ldquo; lbfgs&amp;rdquo;，则分类器将不使用迷你批处理。设置为&amp;ldquo;自动&amp;rdquo;时， &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="fa65aa30a853af1cf81f53119b6649c5aa5e2817" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split during its Ledoit-Wolf estimation. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">在Ledoit-Wolf估计过程中,协方差矩阵将被分割成的块的大小。这纯粹是内存优化,不影响结果。</target>
        </trans-unit>
        <trans-unit id="3bdf2049b3b05b0720764317c09e88bc19700eec" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">将协方差矩阵分割成的块的大小。这纯粹是内存优化,不影响结果。</target>
        </trans-unit>
        <trans-unit id="612eb8e8a229547855d2a4c02d66bbe2afb0395a" translate="yes" xml:space="preserve">
          <source>Size of the mini batches.</source>
          <target state="translated">迷你批的大小。</target>
        </trans-unit>
        <trans-unit id="aa636a80a54912b13ca3fa6029e0a40e02f80415" translate="yes" xml:space="preserve">
          <source>Size of the return array</source>
          <target state="translated">返回数组的大小</target>
        </trans-unit>
        <trans-unit id="08f603d3fe1f30df7982a9a08f592731c9eab73e" translate="yes" xml:space="preserve">
          <source>Size of the test sets.</source>
          <target state="translated">测试组的大小。</target>
        </trans-unit>
        <trans-unit id="1d7d650781fdf69336502b899ccd5c9f80ba4848" translate="yes" xml:space="preserve">
          <source>Skip input validation checks, including the Gram matrix when provided assuming there are handled by the caller when check_input=False.</source>
          <target state="translated">跳过输入验证检查,包括提供的格拉姆矩阵,假设当check_input=False时有调用者处理。</target>
        </trans-unit>
        <trans-unit id="119077d89fb1cbe89db9591404feee43530ef290" translate="yes" xml:space="preserve">
          <source>Slides explaining PLS</source>
          <target state="translated">解释PLS的幻灯片</target>
        </trans-unit>
        <trans-unit id="c3d721c0cfe644c7ca720484ae796856345cb087" translate="yes" xml:space="preserve">
          <source>Small outliers</source>
          <target state="translated">小的离群值</target>
        </trans-unit>
        <trans-unit id="6cf8c0d1548c80d5c7b8e80adf89b56b8a30e60f" translate="yes" xml:space="preserve">
          <source>Small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. Alpha corresponds to &lt;code&gt;(2*C)^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="translated">&amp;alpha;的较小正值会改善问题的状况，并减少估计的方差。在其他线性模型（例如LogisticRegression或LinearSVC &lt;code&gt;(2*C)^-1&lt;/code&gt; Alpha对应于（2 * C）^-1。如果传递数组，则认为惩罚是特定于目标的。因此，它们必须在数量上对应。</target>
        </trans-unit>
        <trans-unit id="8e135bd52bd2eb3356a694f0d8575402c5375bb6" translate="yes" xml:space="preserve">
          <source>Smaller values lead to better embedding and higher number of dimensions (n_components) in the target projection space.</source>
          <target state="translated">数值越小,目标投影空间的嵌入效果越好,维数(n_components)越高。</target>
        </trans-unit>
        <trans-unit id="178a5fd9e6a787566f82c9ecbd118e48b0edcccd" translate="yes" xml:space="preserve">
          <source>Smallest value of alpha / alpha_max considered</source>
          <target state="translated">考虑α/α_max的最小值。</target>
        </trans-unit>
        <trans-unit id="9ec75e4c898141f811f9d6fe4e66f6da7a97bb9c" translate="yes" xml:space="preserve">
          <source>Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.</source>
          <target state="translated">通过在文档频率上加1来平滑idf权重,就像在集合中看到一个额外的文档完全包含每一个术语一次一样。防止零分。</target>
        </trans-unit>
        <trans-unit id="8ec8b1649217676578a05802f05dc4dfdec72ebc" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class.</source>
          <target state="translated">各类的平滑经验对数概率。</target>
        </trans-unit>
        <trans-unit id="d5d952f65cbc310a8284a0aa676904d4b84a635c" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class. Only used in edge case with a single class in the training set.</source>
          <target state="translated">每个类的平滑经验对数概率。仅用于训练集中只有一个类的边缘情况。</target>
        </trans-unit>
        <trans-unit id="fb1739757cbc4d2da964b132a46ededacd98a2aa" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier for unfitted estimators.</source>
          <target state="translated">软投票/多数规则分类器用于非拟合估计器。</target>
        </trans-unit>
        <trans-unit id="a33a62c21ea4043dbf31a4f6ee598307b73aa466" translate="yes" xml:space="preserve">
          <source>Soft hint to choose the default backend if no specific backend was selected with the parallel_backend context manager. The default process-based backend is &amp;lsquo;loky&amp;rsquo; and the default thread-based backend is &amp;lsquo;threading&amp;rsquo;.</source>
          <target state="translated">如果没有使用parallel_backend上下文管理器选择特定的后端，则软提示选择默认的后端。默认的基于进程的后端是&amp;ldquo; loky&amp;rdquo;，默认的基于线程的后端是&amp;ldquo; threading&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="9653b7a05f5df3e5d87561ce96e265c541ad8c31" translate="yes" xml:space="preserve">
          <source>SokalMichenerDistance</source>
          <target state="translated">SokalMichenerDistance</target>
        </trans-unit>
        <trans-unit id="01ed2fbc860294634b46d80d008798b47284ef75" translate="yes" xml:space="preserve">
          <source>SokalSneathDistance</source>
          <target state="translated">SokalSneathDistance</target>
        </trans-unit>
        <trans-unit id="0b76645291a4941abead277af175738d7e9485f1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">解决方案：&lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97a1e21d1798b81e7cea434e741d7087aa2f4a99" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">解决方案：&lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d31ac38ecaa97cd7ca9cf4223578d60df63f89a9" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model:</source>
          <target state="translated">求解等差回归模型。</target>
        </trans-unit>
        <trans-unit id="48c6334f59edac84435c4184f66b59babd6924b9" translate="yes" xml:space="preserve">
          <source>Solve the ridge equation by the method of normal equations.</source>
          <target state="translated">用法线方程的方法求解山脊方程。</target>
        </trans-unit>
        <trans-unit id="b5fa00edfa7fc06c7e99359e114af78ec006b205" translate="yes" xml:space="preserve">
          <source>Solver to use in the computational routines:</source>
          <target state="translated">在计算例程中使用的求解器。</target>
        </trans-unit>
        <trans-unit id="5c136e6e68fedeebc5e62ea492bdc13f5c51a357" translate="yes" xml:space="preserve">
          <source>Solver to use, possible values:</source>
          <target state="translated">要使用的求解器,可能的值。</target>
        </trans-unit>
        <trans-unit id="577db6a48ff5a1db9c02bebc0320d90f752c60ef" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem online.</source>
          <target state="translated">在线解决一个字典学习矩阵分解问题。</target>
        </trans-unit>
        <trans-unit id="8820b686f5bac3c2f3bf8f93441f10523c0fe031" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem.</source>
          <target state="translated">解决了一个字典学习矩阵分解问题。</target>
        </trans-unit>
        <trans-unit id="b22d518aabf32cc9c9347bf653295056dc359f7f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.</source>
          <target state="translated">只使用Gram矩阵X.T*X和乘积X.T*y来解决n_targets正交匹配追求问题。</target>
        </trans-unit>
        <trans-unit id="80547cf29da9d4cc131f68d1680f3500976f9f6f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems. An instance of the problem has the form:</source>
          <target state="translated">解决n_targets正交匹配追寻问题。一个问题的实例具有以下形式。</target>
        </trans-unit>
        <trans-unit id="8d4fd8866d93aa1260a7a3d03ef9a9a9f9a2fc7d" translate="yes" xml:space="preserve">
          <source>Solves the optimization problem:</source>
          <target state="translated">解决优化问题。</target>
        </trans-unit>
        <trans-unit id="e29fb180670f8bd6283a93ce616785d39e9b899f" translate="yes" xml:space="preserve">
          <source>Some advantages of decision trees are:</source>
          <target state="translated">决策树的一些优点是:</target>
        </trans-unit>
        <trans-unit id="2b6f2b5ee645a40c14b49c77184129b10ec1567a" translate="yes" xml:space="preserve">
          <source>Some also work in the multilabel case:</source>
          <target state="translated">有的在多标签情况下也可以使用。</target>
        </trans-unit>
        <trans-unit id="8762622dcc16bf1560cb81f69bbd48256b77f9a4" translate="yes" xml:space="preserve">
          <source>Some calculations when implemented using standard numpy vectorized operations involve using a large amount of temporary memory. This may potentially exhaust system memory. Where computations can be performed in fixed-memory chunks, we attempt to do so, and allow the user to hint at the maximum size of this working memory (defaulting to 1GB) using &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;config_context&lt;/code&gt;. The following suggests to limit temporary working memory to 128 MiB:</source>
          <target state="translated">使用标准的numpy向量化操作实现的某些计算涉及使用大量的临时内存。这可能会耗尽系统内存。在可以以固定内存块执行计算的地方，我们尝试这样做，并允许用户使用&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt;或 &lt;code&gt;config_context&lt;/code&gt; 提示此工作内存的最大大小（默认为1GB）。以下建议将临时工作内存限制为128 MiB：</target>
        </trans-unit>
        <trans-unit id="f425af2b7289a6eb3b0699842a415a72e1141c04" translate="yes" xml:space="preserve">
          <source>Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt;&lt;code&gt;StratifiedShuffleSplit&lt;/code&gt;&lt;/a&gt; to ensure that relative class frequencies is approximately preserved in each train and validation fold.</source>
          <target state="translated">一些分类问题可能会在目标类别的分布上显示出很大的不平衡：例如，负样本可能比正样本多几倍。在这种情况下，建议使用在&lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt; &lt;code&gt;StratifiedShuffleSplit&lt;/code&gt; 中&lt;/a&gt;实现的分层抽样，以确保在每个序列和验证折中近似保留相对的班级频率。</target>
        </trans-unit>
        <trans-unit id="2ea2f829ceb432ffa0e3b3d420b4273e01e30d41" translate="yes" xml:space="preserve">
          <source>Some cross validation iterators, such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;, have an inbuilt option to shuffle the data indices before splitting them. Note that:</source>
          <target state="translated">一些交叉验证迭代器（例如&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;）具有一个内置选项，可以在拆分数据索引之前对数据索引进行混洗。注意：</target>
        </trans-unit>
        <trans-unit id="1b7524a4e391762865d52d4ee865a5a389b3ed4f" translate="yes" xml:space="preserve">
          <source>Some estimators expose a &lt;code&gt;transform&lt;/code&gt; method, for instance to reduce the dimensionality of the dataset.</source>
          <target state="translated">一些估计器会公开一种 &lt;code&gt;transform&lt;/code&gt; 方法，例如以减少数据集的维数。</target>
        </trans-unit>
        <trans-unit id="abe93a33221be53771cefc563a6b553fa747a230" translate="yes" xml:space="preserve">
          <source>Some literature promotes alternative definitions of balanced accuracy. Our definition is equivalent to &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; with class-balanced sample weights, and shares desirable properties with the binary case. See the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">一些文献提出了平衡精度的替代定义。我们的定义等同于&lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt;与类均衡样本的权重，并且与二进制的情况股期望的性质。请参阅《&lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;用户指南》&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="65e1dc1251c858f270c665ff61463afe65f478d7" translate="yes" xml:space="preserve">
          <source>Some metrics are essentially defined for binary classification tasks (e.g. &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled &lt;code&gt;1&lt;/code&gt; (though this may be configurable through the &lt;code&gt;pos_label&lt;/code&gt; parameter).</source>
          <target state="translated">本质上为二进制分类任务定义了一些度量标准（例如&lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt;）。在这些情况下，默认情况下仅假设肯定类标记为 &lt;code&gt;1&lt;/code&gt; （尽管可以通过 &lt;code&gt;pos_label&lt;/code&gt; 参数进行配置），仅评估肯定标签。</target>
        </trans-unit>
        <trans-unit id="d5ba6b95ba600216ff9982f7a3dbaf94b6802f73" translate="yes" xml:space="preserve">
          <source>Some models allow for specialized, efficient parameter search strategies, &lt;a href=&quot;#alternative-cv&quot;&gt;outlined below&lt;/a&gt;. Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; exhaustively considers all parameter combinations, while &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; can sample a given number of candidates from a parameter space with a specified distribution. After describing these tools we detail &lt;a href=&quot;#grid-search-tips&quot;&gt;best practice&lt;/a&gt; applicable to both approaches.</source>
          <target state="translated">某些模型允许使用专门的有效参数搜索策略，&lt;a href=&quot;#alternative-cv&quot;&gt;如下所示&lt;/a&gt;。scikit-learn中提供了两种对搜索候选进行采样的通用方法：对于给定值，&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;详尽地考虑所有参数组合，而&lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt;可以从具有指定分布的参数空间中采样给定数量的候选。在描述了这些工具之后，我们将详细介绍适用于这两种方法的&lt;a href=&quot;#grid-search-tips&quot;&gt;最佳实践&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="95196f8314df139319d7b42ff6d7520f5ecc9f1d" translate="yes" xml:space="preserve">
          <source>Some models also have &lt;code&gt;row_labels_&lt;/code&gt; and &lt;code&gt;column_labels_&lt;/code&gt; attributes. These models partition the rows and columns, such as in the block diagonal and checkerboard bicluster structures.</source>
          <target state="translated">一些模型还具有 &lt;code&gt;row_labels_&lt;/code&gt; 和 &lt;code&gt;column_labels_&lt;/code&gt; 属性。这些模型对行和列进行分区，例如在块对角线和棋盘格状两面体结构中。</target>
        </trans-unit>
        <trans-unit id="89f290ef487f7e4f63f1b82009e209966dcbe74f" translate="yes" xml:space="preserve">
          <source>Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter. This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.</source>
          <target state="translated">一些模型可以对某些参数的一系列值进行数据拟合,其效率几乎与对单一参数值的估计器进行拟合一样。可以利用这一特点进行更有效的交叉验证,用于该参数的模型选择。</target>
        </trans-unit>
        <trans-unit id="d786744290bacd9a4dfc207be555be0e40c3853e" translate="yes" xml:space="preserve">
          <source>Some models can offer an information-theoretic closed-form formula of the optimal estimate of the regularization parameter by computing a single regularization path (instead of several when using cross-validation).</source>
          <target state="translated">有些模型可以通过计算一个单一的正则化路径(而不是使用交叉验证时的多个路径),提供正则化参数最优估计的信息理论闭式公式。</target>
        </trans-unit>
        <trans-unit id="ad14a182695bef0a4c2fe22edd0961e8db73147c" translate="yes" xml:space="preserve">
          <source>Some of the clusters learned without connectivity constraints do not respect the structure of the swiss roll and extend across different folds of the manifolds. On the opposite, when opposing connectivity constraints, the clusters form a nice parcellation of the swiss roll.</source>
          <target state="translated">在没有连通性约束的情况下,所学到的一些簇并不尊重瑞士卷的结构,而是延伸到了歧管的不同褶皱中。相反,当反对连通性约束时,簇形成了一个漂亮的瑞士卷的解析。</target>
        </trans-unit>
        <trans-unit id="877cbb42097301f5a68339d0d9f55e4ca85ad3c3" translate="yes" xml:space="preserve">
          <source>Some of these are restricted to the binary classification case:</source>
          <target state="translated">其中一些仅限于二进制分类情况。</target>
        </trans-unit>
        <trans-unit id="bc828cde0b0d5dbd5e8ad77797297d4f6416ab76" translate="yes" xml:space="preserve">
          <source>Some other classifiers cope better with this harder version of the task. Try running &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; with and without the &lt;code&gt;--filter&lt;/code&gt; option to compare the results.</source>
          <target state="translated">其他一些分类器可以更好地应对此较难的任务。尝试运行带有或不 &lt;code&gt;--filter&lt;/code&gt; 选项的&lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;文本特征提取和评估的示例管道，&lt;/a&gt;以比较结果。</target>
        </trans-unit>
        <trans-unit id="1d754add1306692cb962c5467414be940979d0ab" translate="yes" xml:space="preserve">
          <source>Some parameter settings may result in a failure to &lt;code&gt;fit&lt;/code&gt; one or more folds of the data. By default, this will cause the entire search to fail, even if some parameter settings could be fully evaluated. Setting &lt;code&gt;error_score=0&lt;/code&gt; (or &lt;code&gt;=np.NaN&lt;/code&gt;) will make the procedure robust to such failure, issuing a warning and setting the score for that fold to 0 (or &lt;code&gt;NaN&lt;/code&gt;), but completing the search.</source>
          <target state="translated">某些参数设置可能会导致无法 &lt;code&gt;fit&lt;/code&gt; 一个或多个折叠。默认情况下，即使可以完全评估某些参数设置，这也会导致整个搜索失败。设置 &lt;code&gt;error_score=0&lt;/code&gt; （或 &lt;code&gt;=np.NaN&lt;/code&gt; ）将使该过程对这种失败具有鲁棒性，发出警告并将该折痕的得分设置为0（或 &lt;code&gt;NaN&lt;/code&gt; ），但完成搜索。</target>
        </trans-unit>
        <trans-unit id="f29c3cd2b5860fb787d236e9a466d0e36eb10659" translate="yes" xml:space="preserve">
          <source>Some tips and tricks:</source>
          <target state="translated">一些提示和技巧。</target>
        </trans-unit>
        <trans-unit id="63fe20eae64c7864fd32162af52c1f81421bc7d2" translate="yes" xml:space="preserve">
          <source>Sometimes it may be useful to convert the data back into the original feature space. The &lt;code&gt;inverse_transform&lt;/code&gt; function converts the binned data into the original feature space. Each value will be equal to the mean of the two bin edges.</source>
          <target state="translated">有时将数据转换回原始特征空间可能很有用。该 &lt;code&gt;inverse_transform&lt;/code&gt; 功能离散化的数据转换成原始特征空间。每个值将等于两个面元边缘的平均值。</target>
        </trans-unit>
        <trans-unit id="315bc72af841ed152a9aae1c3ac0990cdcb834ed" translate="yes" xml:space="preserve">
          <source>Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high.</source>
          <target state="translated">有时候,观察神经网络的学习系数可以深入了解学习行为。例如如果权重看起来没有结构化,可能有些权重根本没有使用,或者如果存在非常大的系数,可能正则化太低或者学习率太高。</target>
        </trans-unit>
        <trans-unit id="fbff2a8532eac744fd3e459bcddf3fd34f40adee" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="translated">源URL：&lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http&lt;/a&gt; : //www4.stat.ncsu.edu/~boos/var.select/diabetes.html</target>
        </trans-unit>
        <trans-unit id="bdef929636b0e2d76c9bcc79abe376f450451dd0" translate="yes" xml:space="preserve">
          <source>Sources, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">源,其中n_samples为样本数,n_components为元件数。</target>
        </trans-unit>
        <trans-unit id="dcbe3516134bdf9c59a33ffb1c2e3120ebfb3eac" translate="yes" xml:space="preserve">
          <source>Sparse Principal Components Analysis (SparsePCA)</source>
          <target state="translated">稀疏主成分分析(SparsePCA)</target>
        </trans-unit>
        <trans-unit id="e06472c25d26cda25191de9da3a114b1e469b208" translate="yes" xml:space="preserve">
          <source>Sparse coding</source>
          <target state="translated">稀疏编码</target>
        </trans-unit>
        <trans-unit id="32c8d921f9e1520199d1db9fe64aa6fb0f91121f" translate="yes" xml:space="preserve">
          <source>Sparse coding with a precomputed dictionary</source>
          <target state="translated">稀疏编码的预计算字典</target>
        </trans-unit>
        <trans-unit id="83cd17de4011d58af20829baa72e8c3c15415081" translate="yes" xml:space="preserve">
          <source>Sparse components extracted from the data.</source>
          <target state="translated">从数据中提取的稀疏成分。</target>
        </trans-unit>
        <trans-unit id="4aefb6aa7d814b8be3e6d2cb6f2931a1dadb31bc" translate="yes" xml:space="preserve">
          <source>Sparse input</source>
          <target state="translated">稀疏输入</target>
        </trans-unit>
        <trans-unit id="935bf4a32a6f741a33bb9ac8e725575de63e795c" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation</source>
          <target state="translated">稀疏的反协方差估计法</target>
        </trans-unit>
        <trans-unit id="409d5a415f20eafd9b9f09c6ba22d21458394422" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation with an l1-penalized estimator.</source>
          <target state="translated">稀疏的反协方差估计与l1-penalized估计器。</target>
        </trans-unit>
        <trans-unit id="2ee089f1e56c91604e7cab7d40e8b9f34677bb75" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty</source>
          <target state="translated">稀疏的反协方差/交叉验证选择的L1罚则</target>
        </trans-unit>
        <trans-unit id="92e371bb810dfdf353c195f32e5335e997df721c" translate="yes" xml:space="preserve">
          <source>Sparse principal components yields a more parsimonious, interpretable representation, clearly emphasizing which of the original features contribute to the differences between samples.</source>
          <target state="translated">稀疏的主成分产生了一个更简明、可解释的表示方式,清楚地强调了哪些原始特征对样本之间的差异有贡献。</target>
        </trans-unit>
        <trans-unit id="19dbec98d9db7f8dccbc05e595e6dcc554502b17" translate="yes" xml:space="preserve">
          <source>Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">稀疏随机矩阵是密集高斯随机投影矩阵的替代方案,可以保证类似的嵌入质量,同时内存效率更高,可以更快地计算投影数据。</target>
        </trans-unit>
        <trans-unit id="5ad88cbdaa9d7d5c176762a66b957d3aa9661770" translate="yes" xml:space="preserve">
          <source>Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">稀疏随机矩阵是密集随机投影矩阵的替代方案,它可以保证类似的嵌入质量,同时内存效率更高,可以更快地计算投影数据。</target>
        </trans-unit>
        <trans-unit id="a7a844fc75c56ce03e1afce70cb2355152140d0b" translate="yes" xml:space="preserve">
          <source>Sparsity</source>
          <target state="translated">Sparsity</target>
        </trans-unit>
        <trans-unit id="814e5a7e79ded720eafc96bc0232cca516d50079" translate="yes" xml:space="preserve">
          <source>Sparsity Example: Fitting only features 1 and 2</source>
          <target state="translated">稀疏性示例。只拟合特征1和2</target>
        </trans-unit>
        <trans-unit id="43cddceab3d136418b0e03e98d360e468cf1b8e5" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter.</source>
          <target state="translated">稀疏度控制参数。</target>
        </trans-unit>
        <trans-unit id="647e2a8c2a361b51e5b69ed284ca76c83752d0f6" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter. Higher values lead to sparser components.</source>
          <target state="translated">稀疏度控制参数。值越高,元件越稀疏。</target>
        </trans-unit>
        <trans-unit id="1a82be20d822213cd6b317bb5903a0613a76bafa" translate="yes" xml:space="preserve">
          <source>Species distribution modeling</source>
          <target state="translated">物种分布建模</target>
        </trans-unit>
        <trans-unit id="37195f9a92f1ed14e524a0ed92aab116b735c4ea" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. set_params(parameter_name=new_value) In addition, to setting the parameters of the &lt;code&gt;VotingClassifier&lt;/code&gt;, the individual classifiers of the &lt;code&gt;VotingClassifier&lt;/code&gt; can also be set or replaced by setting them to None.</source>
          <target state="translated">使用例如set_params（PARAMETER_NAME = NEW_VALUE）另外，为设置的参数的特定参数 &lt;code&gt;VotingClassifier&lt;/code&gt; ，所述的各个分类 &lt;code&gt;VotingClassifier&lt;/code&gt; 也可以设置或将它们设置为无取代。</target>
        </trans-unit>
        <trans-unit id="94e374689a4595b916bcf5e66713548e054c55c6" translate="yes" xml:space="preserve">
          <source>Specific weights can be assigned to each classifier via the &lt;code&gt;weights&lt;/code&gt; parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability.</source>
          <target state="translated">可以通过 &lt;code&gt;weights&lt;/code&gt; 参数将特定权重分配给每个分类器。当提供权重时，将收集每个分类器的预测类概率，乘以分类器权重，然后取平均值。然后从具有最高平均概率的类别标签中得出最终的类别标签。</target>
        </trans-unit>
        <trans-unit id="8fbbf3fe05797ad1e4c717c36a5a204246056853" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;ldquo;one_vs_rest&amp;rdquo; and &amp;ldquo;one_vs_one&amp;rdquo;. In &amp;ldquo;one_vs_rest&amp;rdquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;ldquo;one_vs_one&amp;rdquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates.</source>
          <target state="translated">指定如何处理多类分类问题。支持&amp;ldquo; one_vs_rest&amp;rdquo;和&amp;ldquo; one_vs_one&amp;rdquo;。在&amp;ldquo; one_vs_rest&amp;rdquo;中，为每个类别安装一个二进制高斯过程分类器，训练该分类器以将该类别与其余类别分开。在&amp;ldquo; one_vs_one&amp;rdquo;中，为每对类装配一个二进制高斯过程分类器，训练该分类器以将这两个类分开。这些二进制预测变量的预测被组合为多类预测。注意，&amp;ldquo; one_vs_one&amp;rdquo;不支持预测概率估计。</target>
        </trans-unit>
        <trans-unit id="9bddb5670bf596fd4f95945fb300823355f1c46f" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.</source>
          <target state="translated">指定是否应该在决策函数中加入一个常数(也就是偏置或截距)。</target>
        </trans-unit>
        <trans-unit id="032e8ae2185962af612ef54804c68499bb10a9e0" translate="yes" xml:space="preserve">
          <source>Specifies if the estimated precision is stored.</source>
          <target state="translated">指定是否存储估计精度。</target>
        </trans-unit>
        <trans-unit id="d38faf7dee61c2f434029c24d24417f5a7a63648" translate="yes" xml:space="preserve">
          <source>Specifies if the intercept should be fitted by the model. It must match the fit() method parameter.</source>
          <target state="translated">指定截距是否应该被模型拟合。它必须与fit()方法的参数相匹配。</target>
        </trans-unit>
        <trans-unit id="21164bb750beb75acb9ae9d1f3fb116169b84f4e" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape &lt;code&gt;(n_samples, n_samples)&lt;/code&gt;.</source>
          <target state="translated">指定算法中要使用的内核类型。它必须是&amp;ldquo;线性&amp;rdquo;，&amp;ldquo;多边形&amp;rdquo;，&amp;ldquo; rbf&amp;rdquo;，&amp;ldquo; Sigmoid&amp;rdquo;，&amp;ldquo;预先计算&amp;rdquo;或可调用的一个。如果没有给出，将使用&amp;ldquo; rbf&amp;rdquo;。如果给出了可调用对象，则将其用于根据数据矩阵预先计算内核矩阵；该矩阵应为形状数组 &lt;code&gt;(n_samples, n_samples)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7717364640e0a660ec81dfa33f675030f243fdf0" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to precompute the kernel matrix.</source>
          <target state="translated">指定算法中要使用的内核类型。它必须是&amp;ldquo;线性&amp;rdquo;，&amp;ldquo;多边形&amp;rdquo;，&amp;ldquo; rbf&amp;rdquo;，&amp;ldquo; Sigmoid&amp;rdquo;，&amp;ldquo;预先计算&amp;rdquo;或可调用的一个。如果没有给出，将使用&amp;ldquo; rbf&amp;rdquo;。如果给出了可调用对象，则将其用于预先计算内核矩阵。</target>
        </trans-unit>
        <trans-unit id="b9435d1c3c2633287cc32557661450b6f00ca78e" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. &amp;lsquo;hinge&amp;rsquo; is the standard SVM loss (used e.g. by the SVC class) while &amp;lsquo;squared_hinge&amp;rsquo; is the square of the hinge loss.</source>
          <target state="translated">指定损失函数。&amp;ldquo;铰链&amp;rdquo;是标准SVM损耗（例如由SVC类使用），而&amp;ldquo; squared_hinge&amp;rdquo;是铰链损耗的平方。</target>
        </trans-unit>
        <trans-unit id="68150facd38948e362a68f70eea508701955b6e7" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. The epsilon-insensitive loss (standard SVR) is the L1 loss, while the squared epsilon-insensitive loss (&amp;lsquo;squared_epsilon_insensitive&amp;rsquo;) is the L2 loss.</source>
          <target state="translated">指定损失函数。&amp;epsilon;不敏感损失（标准SVR）为L1损失，&amp;epsilon;不敏感平方损失（&amp;ldquo; squared_epsilon_insensitive&amp;rdquo;）为L2损失。</target>
        </trans-unit>
        <trans-unit id="1b5fabde85275fd0a5eb3f705ddd6c262b6e1ace" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. With &amp;lsquo;squared_hinge&amp;rsquo; it is the squared hinge loss (a.k.a. L2 loss). With &amp;lsquo;log&amp;rsquo; it is the loss of logistic regression models.</source>
          <target state="translated">指定损失函数。&amp;ldquo; squared_hinge&amp;rdquo;是铰链损耗的平方（也称为L2损耗）。对于&amp;ldquo; log&amp;rdquo;，这是逻辑回归模型的损失。</target>
        </trans-unit>
        <trans-unit id="82fe667ff963f19359a5dba7024bcea48fa12322" translate="yes" xml:space="preserve">
          <source>Specifies the norm used in the penalization. The &amp;lsquo;l2&amp;rsquo; penalty is the standard used in SVC. The &amp;lsquo;l1&amp;rsquo; leads to &lt;code&gt;coef_&lt;/code&gt; vectors that are sparse.</source>
          <target state="translated">指定惩罚中使用的规范。&amp;ldquo; 12&amp;rdquo;罚分是SVC中使用的标准。'l1'导致稀疏的 &lt;code&gt;coef_&lt;/code&gt; 向量。</target>
        </trans-unit>
        <trans-unit id="5a337b6de37f25f0ac3016f29ff1f6486795a255" translate="yes" xml:space="preserve">
          <source>Specifies the returned model. Select &lt;code&gt;'lar'&lt;/code&gt; for Least Angle Regression, &lt;code&gt;'lasso'&lt;/code&gt; for the Lasso.</source>
          <target state="translated">指定返回的模型。选择 &lt;code&gt;'lar'&lt;/code&gt; 作为最小角度回归，选择 &lt;code&gt;'lasso'&lt;/code&gt; 作为套索。</target>
        </trans-unit>
        <trans-unit id="32ab0cdbec2fd77050a55d02bdf5982ebc80779f" translate="yes" xml:space="preserve">
          <source>Specify a download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">指定数据集的下载和缓存文件夹。如果为None，则所有scikit学习数据都存储在&amp;ldquo;〜/ scikit_learn_data&amp;rdquo;子文件夹中。</target>
        </trans-unit>
        <trans-unit id="5a7f883c69415d4b4614ca7ec1c25ea069f17592" translate="yes" xml:space="preserve">
          <source>Specify an download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">指定数据集的下载和缓存文件夹。如果为None，则所有scikit学习数据都存储在&amp;ldquo;〜/ scikit_learn_data&amp;rdquo;子文件夹中。</target>
        </trans-unit>
        <trans-unit id="bef377c44b3d810cadc5cf65c208d01924bfa02c" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the data sets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">为数据集指定另一个下载和缓存文件夹。默认情况下，所有scikit学习数据都存储在&amp;ldquo;〜/ scikit_learn_data&amp;rdquo;子文件夹中。</target>
        </trans-unit>
        <trans-unit id="db707a2b2d7445205a990e044438fdad3fa08a72" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">为数据集指定另一个下载和缓存文件夹。默认情况下，所有scikit学习数据都存储在&amp;ldquo;〜/ scikit_learn_data&amp;rdquo;子文件夹中。</target>
        </trans-unit>
        <trans-unit id="e0a4c5302feb0239f945ee7ba84757ae55a6d243" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders. .. versionadded:: 0.19</source>
          <target state="translated">为数据集指定另一个下载和缓存文件夹。默认情况下，所有scikit学习数据都存储在&amp;ldquo;〜/ scikit_learn_data&amp;rdquo;子文件夹中。..版本添加：： 0.19</target>
        </trans-unit>
        <trans-unit id="3a104a4391c92d3464c7b1efaf07c449c778bcc9" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored</source>
          <target state="translated">指定是否存储估计精度</target>
        </trans-unit>
        <trans-unit id="68d4702fc734cffadd8a1ccf005f0aff7fa648f2" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored.</source>
          <target state="translated">指定是否存储估计精度。</target>
        </trans-unit>
        <trans-unit id="4984f447cb8f4f521871d2431cae9f4220dfb519" translate="yes" xml:space="preserve">
          <source>Specify the column name in the data to use as target. If &amp;lsquo;default-target&amp;rsquo;, the standard target column a stored on the server is used. If &lt;code&gt;None&lt;/code&gt;, all columns are returned as data and the target is &lt;code&gt;None&lt;/code&gt;. If list (of strings), all columns with these names are returned as multi-target (Note: not all scikit-learn classifiers can handle all types of multi-output combinations)</source>
          <target state="translated">在数据中指定要用作目标的列名。如果为&amp;ldquo;默认目标&amp;rdquo;，则使用服务器上存储的标准目标列a。如果为 &lt;code&gt;None&lt;/code&gt; ，则将所有列作为数据返回，并且目标为 &lt;code&gt;None&lt;/code&gt; 。如果是列表（包含字符串），则将所有具有这些名称的列作为多目标返回（注意：并非所有scikit-learn分类器都可以处理所有类型的多输出组合）</target>
        </trans-unit>
        <trans-unit id="86eb3ad2a989c13695b9d85dcb05b7c45343a61d" translate="yes" xml:space="preserve">
          <source>Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; The default is zero (i.e. machine precision) for both.</source>
          <target state="translated">指定结果的所需相对和绝对公差。如果真实结果为K_true，则返回的结果K_ret满足 &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; 的默认值为零（即机器精度）。</target>
        </trans-unit>
        <trans-unit id="0742682745f85d107eacd49ea30a7e49015c565b" translate="yes" xml:space="preserve">
          <source>Specify the leaf size of the underlying tree. See &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; for details. Default is 40.</source>
          <target state="translated">指定基础树的叶大小。有关详细信息，请参见&lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt;。默认值为40。</target>
        </trans-unit>
        <trans-unit id="a3eb34c47a1823aab704036791431543ed289a4a" translate="yes" xml:space="preserve">
          <source>Specify the parallelization backend implementation. Supported backends are:</source>
          <target state="translated">指定并行化后端实现。支持的后端有:</target>
        </trans-unit>
        <trans-unit id="9ef7e5427d37487b864821803fe9613488fa8ce1" translate="yes" xml:space="preserve">
          <source>Specify the size of the kernel cache (in MB).</source>
          <target state="translated">指定内核缓存的大小(单位:MB)。</target>
        </trans-unit>
        <trans-unit id="4329e4ac0b424da2818ac12cc4d13ce3581c4d3d" translate="yes" xml:space="preserve">
          <source>Specify what features are treated as categorical.</source>
          <target state="translated">指定哪些特征被作为分类处理。</target>
        </trans-unit>
        <trans-unit id="7d724db10f986282e8a5446f219cdacdbcddece6" translate="yes" xml:space="preserve">
          <source>Specify whether all or any of the given attributes must exist.</source>
          <target state="translated">指定所有或任何给定属性是否必须存在。</target>
        </trans-unit>
        <trans-unit id="d079850de1341ae0792b165a2e4c64406a6bf6cd" translate="yes" xml:space="preserve">
          <source>Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the &lt;code&gt;n_iter&lt;/code&gt; parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:</source>
          <target state="translated">使用字典指定应如何采样参数，这与为&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;指定参数非常相似。另外，使用 &lt;code&gt;n_iter&lt;/code&gt; 参数指定计算预算，即采样候选数或采样迭代数。对于每个参数，可以指定可能值的分布或离散选项的列表（将统一采样）：</target>
        </trans-unit>
        <trans-unit id="848f2bc6fd9feea5a4bd159161ff60b7b7f1ad05" translate="yes" xml:space="preserve">
          <source>Specifying the dataset by the name &amp;ldquo;iris&amp;rdquo; yields the lowest version, version 1, with the &lt;code&gt;data_id&lt;/code&gt; 61. To make sure you always get this exact dataset, it is safest to specify it by the dataset &lt;code&gt;data_id&lt;/code&gt;. The other dataset, with &lt;code&gt;data_id&lt;/code&gt; 969, is version 3 (version 2 has become inactive), and contains a binarized version of the data:</source>
          <target state="translated">用名称&amp;ldquo; iris&amp;rdquo;指定数据集将产生最低版本，即版本1，其 &lt;code&gt;data_id&lt;/code&gt; 为 61。为确保始终获得确切的数据集，最安全的方法是使用数据集 &lt;code&gt;data_id&lt;/code&gt; 进行指定。另一个具有 &lt;code&gt;data_id&lt;/code&gt; 969的数据集是版本3（版本2已停用），并且包含数据的二进制版本：</target>
        </trans-unit>
        <trans-unit id="3df7d54bd992cb63f5a75a6f7de49938e89cdde2" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to cluster graphs by their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt;:</source>
          <target state="translated">光谱聚类还可以用于通过图形的光谱嵌入对图进行聚类。在这种情况下，亲和度矩阵是图的邻接矩阵，并且SpectralClustering是用 &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt; 初始化的：</target>
        </trans-unit>
        <trans-unit id="943c880ba7aef37194c447e5760436985518b340" translate="yes" xml:space="preserve">
          <source>Spectral Co-Clustering algorithm (Dhillon, 2001).</source>
          <target state="translated">Spectral Co-Clustering算法(Dhillon,2001)。</target>
        </trans-unit>
        <trans-unit id="5c8a907562e6db42ff15e9df5a0d9b0b21be7b5f" translate="yes" xml:space="preserve">
          <source>Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph has one connected component. If there graph has many components, the first few eigenvectors will simply uncover the connected components of the graph.</source>
          <target state="translated">Spectral Embedding(Laplacian Eigenmaps)在图形只有一个连接成分时最有用。如果图形有许多成分,前几个特征向量将简单地揭示图形的连接成分。</target>
        </trans-unit>
        <trans-unit id="7ff62a97384e4faf388cb99bbcc076cbdae4a5ec" translate="yes" xml:space="preserve">
          <source>Spectral Embedding is an approach to calculating a non-linear embedding. Scikit-learn implements Laplacian Eigenmaps, which finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. The graph generated can be considered as a discrete approximation of the low dimensional manifold in the high dimensional space. Minimization of a cost function based on the graph ensures that points close to each other on the manifold are mapped close to each other in the low dimensional space, preserving local distances. Spectral embedding can be performed with the function &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt;&lt;code&gt;spectral_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt;&lt;code&gt;SpectralEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">频谱嵌入是一种用于计算非线性嵌入的方法。 Scikit-learn实现了Laplacian特征图，该特征图使用图Laplacian图的光谱分解来发现数据的低维表示。可以将生成的图视为高维空间中低维流形的离散近似。基于该图的成本函数的最小化可确保在流形上彼此靠近的点在低维空间中相互映射，从而保留局部距离。频谱嵌入可以通过函数&lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt; &lt;code&gt;spectral_embedding&lt;/code&gt; &lt;/a&gt;或它的面向对象的&lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt; &lt;code&gt;SpectralEmbedding&lt;/code&gt; 来执行&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3266962963ccf3ff289e43e7853a5feea31fa6fe" translate="yes" xml:space="preserve">
          <source>Spectral biclustering (Kluger, 2003).</source>
          <target state="translated">频谱双聚(Kluger,2003)。</target>
        </trans-unit>
        <trans-unit id="83334448105603952db5b041593dddc0f02ac19b" translate="yes" xml:space="preserve">
          <source>Spectral biclustering algorithms.</source>
          <target state="translated">光谱双聚类算法。</target>
        </trans-unit>
        <trans-unit id="3fddf3521d69d12bc13710d54a4adc12aa85f512" translate="yes" xml:space="preserve">
          <source>Spectral clustering</source>
          <target state="translated">光谱聚类</target>
        </trans-unit>
        <trans-unit id="453e3a7c69660270eecfb13dabf16149c8b4512b" translate="yes" xml:space="preserve">
          <source>Spectral clustering for image segmentation</source>
          <target state="translated">用于图像分割的光谱聚类</target>
        </trans-unit>
        <trans-unit id="f9409615dd1103c73760717b8600df9e2157d615" translate="yes" xml:space="preserve">
          <source>Spectral embedding for non-linear dimensionality reduction.</source>
          <target state="translated">用于非线性降维的光谱嵌入。</target>
        </trans-unit>
        <trans-unit id="8a0801a4fb2ecc40bcf6f04aa745ad2e1056e690" translate="yes" xml:space="preserve">
          <source>Spectral embedding of the training matrix.</source>
          <target state="translated">训练矩阵的光谱嵌入。</target>
        </trans-unit>
        <trans-unit id="063a83567f47ad5f5679accf564d96c923566ee9" translate="yes" xml:space="preserve">
          <source>Speed:</source>
          <target state="translated">Speed:</target>
        </trans-unit>
        <trans-unit id="7d07f6cca3dbed6cdb804f0e2864e093c6647564" translate="yes" xml:space="preserve">
          <source>Split arrays or matrices into random train and test subsets</source>
          <target state="translated">将数组或矩阵分割成随机的训练和测试子集。</target>
        </trans-unit>
        <trans-unit id="5e854ececac820d9fb56cdde854f788365393cf5" translate="yes" xml:space="preserve">
          <source>Splits it into K folds, trains on K-1 and then tests on the left-out.</source>
          <target state="translated">将其拆成K折,在K-1上训练,然后在左出上测试。</target>
        </trans-unit>
        <trans-unit id="c2518ac986a45f6943dccb55ec28e7fc9787e8f9" translate="yes" xml:space="preserve">
          <source>Splitter Classes</source>
          <target state="translated">分离器类</target>
        </trans-unit>
        <trans-unit id="474933f1a999ce205b180d93539f6dbb5b05050e" translate="yes" xml:space="preserve">
          <source>Splitter Functions</source>
          <target state="translated">分配器功能</target>
        </trans-unit>
        <trans-unit id="01474e72e0404f40fd189e5ac7233925222e580d" translate="yes" xml:space="preserve">
          <source>Squared L2 norms of the lines of y. Required if tol is not None.</source>
          <target state="translated">如果 tol 不是 None,则需要。</target>
        </trans-unit>
        <trans-unit id="89cdcd77a950e009dab4164bc976d2f6ebb6b9e7" translate="yes" xml:space="preserve">
          <source>Squared Mahalanobis distances of the observations.</source>
          <target state="translated">观测值的马哈兰诺比斯距离的平方。</target>
        </trans-unit>
        <trans-unit id="a0b13f625123904866bd60e38bc7611ba95c992c" translate="yes" xml:space="preserve">
          <source>Squared Sum - Sum of the squared L2 norm of all samples.</source>
          <target state="translated">平方和--所有样本的L2正态的平方和。</target>
        </trans-unit>
        <trans-unit id="1c1f19010d2ef30728a1e3cec08abc7bd4b0d974" translate="yes" xml:space="preserve">
          <source>Squared norm of the centroids.</source>
          <target state="translated">中心点的平方律。</target>
        </trans-unit>
        <trans-unit id="ff4530f7332d92145f70c600e76bef65d08e2445" translate="yes" xml:space="preserve">
          <source>Stability path based on randomized Lasso estimates</source>
          <target state="translated">基于随机化Lasso估计的稳定性路径。</target>
        </trans-unit>
        <trans-unit id="9a5fecba5d8d30ecb602724233c6166d767b3036" translate="yes" xml:space="preserve">
          <source>Stability selection Nicolai Meinshausen, Peter Buhlmann Journal of the Royal Statistical Society: Series B Volume 72, Issue 4, pages 417-473, September 2010 DOI: 10.1111/j.1467-9868.2010.00740.x</source>
          <target state="translated">稳定性选择 Nicolai Meinshausen,Peter Buhlmann 英国皇家统计学会杂志:B系列第72卷第4期,第417-473页,2010年9月DOI:10.1111/j.1467-9868.2010.00740.x。</target>
        </trans-unit>
        <trans-unit id="891f1b1c9f204fa14cf72f5b45193c02a0d262be" translate="yes" xml:space="preserve">
          <source>Standard deviation of Gaussian noise added to the data.</source>
          <target state="translated">添加到数据中的高斯噪声的标准差。</target>
        </trans-unit>
        <trans-unit id="f806d5207c92015615b11e0738f918dc0548c864" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when return_std is True.</source>
          <target state="translated">查询点的预测分布的标准差。仅当return_std为真时返回。</target>
        </trans-unit>
        <trans-unit id="6edd185d8d7cdfc859bd82ca69e1fcc7af90edcd" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution of query points.</source>
          <target state="translated">查询点的预测分布的标准差。</target>
        </trans-unit>
        <trans-unit id="ea11cb9dbd7c4fc006fb08938b76124b12688d69" translate="yes" xml:space="preserve">
          <source>StandardScaler</source>
          <target state="translated">StandardScaler</target>
        </trans-unit>
        <trans-unit id="9f96721b99a0217af973cbedbcbf7d1fa7440aeb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean / variance in a negative way. In such cases, the median and the interquartile range often give better results.</source>
          <target state="translated">数据集的标准化是许多机器学习估计器的共同要求。通常情况下,这是通过去除均值和缩放为单位方差来实现的。然而,离群值往往会以负面的方式影响样本的均值/方差。在这种情况下,中位数和四分位数范围通常会给出更好的结果。</target>
        </trans-unit>
        <trans-unit id="3845481860a037ebc5c39c64e8de0e95fe45e3fb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).</source>
          <target state="translated">数据集的标准化是许多机器学习估计器的共同要求:如果各个特征或多或少看起来不像是标准的正态分布数据(如均值为0和单位方差的高斯),它们可能会表现得很糟糕。</target>
        </trans-unit>
        <trans-unit id="781aef30981524e4bc3b3ab4682d7e1b6f686dcb" translate="yes" xml:space="preserve">
          <source>Standardize a dataset along any axis</source>
          <target state="translated">沿任何轴线对数据集进行标准化</target>
        </trans-unit>
        <trans-unit id="8089cb9b9abb90199844c7f8d2ad6ef5ad6b9827" translate="yes" xml:space="preserve">
          <source>Standardize features by removing the mean and scaling to unit variance</source>
          <target state="translated">通过去除平均数并按单位方差缩放来实现特征标准化</target>
        </trans-unit>
        <trans-unit id="070fc0ca4dc6d3cb17aee36f0432a76e85e66a77" translate="yes" xml:space="preserve">
          <source>Start pointer to all the leaves.</source>
          <target state="translated">开始指针指向所有的叶子。</target>
        </trans-unit>
        <trans-unit id="08a6668f9a564bddd6d8fa9fd4934eeea4b017c7" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">嵌入的起始配置,以初始化SMACOF算法。默认情况下,算法是用一个随机选择的数组来初始化的。</target>
        </trans-unit>
        <trans-unit id="7252947fdd6406b9475a3bf1b686e53848838289" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">嵌入的起始配置,用于初始化算法。默认情况下,算法是用一个随机选择的数组来初始化的。</target>
        </trans-unit>
        <trans-unit id="91cd41feb47c4fc7679dfd69c834b11820027a8b" translate="yes" xml:space="preserve">
          <source>Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss.</source>
          <target state="translated">从初始随机权重开始,多层感知器(MLP)通过反复更新这些权重来最小化损失函数。在计算完损失后,后向传递将其从输出层传播到前几层,为每个权重参数提供一个旨在降低损失的更新值。</target>
        </trans-unit>
        <trans-unit id="fcf350fa97b4ef940922ec2e36ae5accc928bb98" translate="yes" xml:space="preserve">
          <source>Starting node for path</source>
          <target state="translated">路径的起始节点</target>
        </trans-unit>
        <trans-unit id="bed5865b6136905da0496b8ae96a4873f78bef72" translate="yes" xml:space="preserve">
          <source>Stat Ass, 79:871, 1984.</source>
          <target state="translated">Stat Ass,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="6493ce2cca639b99501821839727266114fab06b" translate="yes" xml:space="preserve">
          <source>Statistical learning</source>
          <target state="translated">统计学习</target>
        </trans-unit>
        <trans-unit id="ff430697ec62291221833385a34a445a9ee9ecdf" translate="yes" xml:space="preserve">
          <source>Statistical learning: the setting and the estimator object in scikit-learn</source>
          <target state="translated">统计学习:scikit-learn中的设置和估计器对象。</target>
        </trans-unit>
        <trans-unit id="a673f9d4e8314126b08e8f81bb3a33f3d78b1e09" translate="yes" xml:space="preserve">
          <source>Still effective in cases where number of dimensions is greater than the number of samples.</source>
          <target state="translated">在维数大于样本数的情况下仍然有效。</target>
        </trans-unit>
        <trans-unit id="2473d40abe8e9fb2e7f524b8bad4d74240273fa9" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent</source>
          <target state="translated">随机梯度下降</target>
        </trans-unit>
        <trans-unit id="195b32448a080f6c15b39de98057b7fe1bc4693b" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is an optimization technique which minimizes a loss function in a stochastic fashion, performing a gradient descent step sample by sample. In particular, it is a very efficient method to fit linear models.</source>
          <target state="translated">随机梯度下降法是一种优化技术,它以随机的方式最小化损失函数,逐个样本执行梯度下降步骤。特别是,它是一种非常有效的拟合线性模型的方法。</target>
        </trans-unit>
        <trans-unit id="e3aa3ce34d4d1d755f86485089b5a4b4f435a8e2" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be easily done using &lt;code&gt;StandardScaler&lt;/code&gt;:</source>
          <target state="translated">随机梯度下降对要素缩放非常敏感，因此强烈建议对数据进行缩放。例如，将输入向量X上的每个属性缩放为[0,1]或[-1，+ 1]，或将其标准化为均值0和方差1。请注意，必须对测试向量应用&lt;em&gt;相同的&lt;/em&gt;缩放比例，以达到获得有意义的结果。这可以使用 &lt;code&gt;StandardScaler&lt;/code&gt; 轻松完成：</target>
        </trans-unit>
        <trans-unit id="ee01e77469d8f50feb7b1b4735d433d85aa0d812" translate="yes" xml:space="preserve">
          <source>Stochastic gradient boosting allows to compute out-of-bag estimates of the test deviance by computing the improvement in deviance on the examples that are not included in the bootstrap sample (i.e. the out-of-bag examples). The improvements are stored in the attribute &lt;code&gt;oob_improvement_&lt;/code&gt;. &lt;code&gt;oob_improvement_[i]&lt;/code&gt; holds the improvement in terms of the loss on the OOB samples if you add the i-th stage to the current predictions. Out-of-bag estimates can be used for model selection, for example to determine the optimal number of iterations. OOB estimates are usually very pessimistic thus we recommend to use cross-validation instead and only use OOB if cross-validation is too time consuming.</source>
          <target state="translated">随机梯度增强可以通过计算自举样本中未包含的示例（即，袋装示例）的偏差改善来计算袋装测试偏差的估计值。改进存储在属性 &lt;code&gt;oob_improvement_&lt;/code&gt; 中。 &lt;code&gt;oob_improvement_[i]&lt;/code&gt; 如果将第i阶段添加到当前预测中，则可以改善OOB样本的损失。袋外估计可以用于模型选择，例如，确定最佳迭代次数。 OOB估计通常非常悲观，因此我们建议改用交叉验证，并且仅在交叉验证太耗时时才使用OOB。</target>
        </trans-unit>
        <trans-unit id="5823a3f0a9a6ed167c583e77307156305a3e83ac" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large. The &lt;code&gt;partial_fit&lt;/code&gt; method allows online/out-of-core learning.</source>
          <target state="translated">随机梯度下降是拟合线性模型的简单但非常有效的方法。当样本数量（和特征数量）非常多时，此功能特别有用。该 &lt;code&gt;partial_fit&lt;/code&gt; 方法Online允许/外的核心学习。</target>
        </trans-unit>
        <trans-unit id="88c2b7432b4c70aedd301d6441f9f686fac99afd" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of \(E(w,b)\) by considering a single training example at a time.</source>
          <target state="translated">随机梯度下降是一种针对无约束优化问题的优化方法。与(批处理)梯度下降法不同,SGD通过每次考虑一个训练实例来逼近\(E(w,b)\)的真实梯度。</target>
        </trans-unit>
        <trans-unit id="3bc9b5e942f6c3298a3799e63fea9d4e51700363" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">在n_clusters时提前停止树的构建。如果簇的数量与特征的数量相比并不多,这个选项对于减少计算时间很有用。这个选项只有在指定连接矩阵时才有用。还需要注意的是,当改变聚类数量和使用缓存时,计算完整的树可能会更有优势。</target>
        </trans-unit>
        <trans-unit id="3dc26590d142d1e5e73aaec1d67524322b86dfd8" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. In this case, the complete tree is not computed, thus the &amp;lsquo;children&amp;rsquo; output is of limited use, and the &amp;lsquo;parents&amp;rsquo; output should rather be used. This option is valid only when specifying a connectivity matrix.</source>
          <target state="translated">尽早在n_clusters处停止树的构建。如果簇数与样本数相比不小的话，这对于减少计算时间很有用。在这种情况下，不会计算完整的树，因此&amp;ldquo;子级&amp;rdquo;输出用途有限，而应使用&amp;ldquo;父级&amp;rdquo;输出。仅当指定连接矩阵时，此选项才有效。</target>
        </trans-unit>
        <trans-unit id="44e9e4435e20e453549059a3ee4002b032ad438a" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">在n_clusters时提前停止树的构建。如果簇的数量与样本的数量相比并不多,那么这个选项对于减少计算时间是很有用的。这个选项只有在指定连通性矩阵时才有用。还需要注意的是,当改变聚类数量和使用缓存时,计算完整的树可能会更有优势。</target>
        </trans-unit>
        <trans-unit id="84a6e50b1119dc5648f3c425a6b5dee68899e309" translate="yes" xml:space="preserve">
          <source>Stop iteration if at least this number of inliers are found.</source>
          <target state="translated">如果至少找到这个数量的离群值,则停止迭代。</target>
        </trans-unit>
        <trans-unit id="538193aed5fb2f898d909880cd3e81469e15df67" translate="yes" xml:space="preserve">
          <source>Stop iteration if score is greater equal than this threshold.</source>
          <target state="translated">如果得分大于等于该阈值,则停止迭代。</target>
        </trans-unit>
        <trans-unit id="12517d0c8ade549d252ae4e535d57433e9861479" translate="yes" xml:space="preserve">
          <source>Stop solver after this many iterations regardless of accuracy (XXX Currently there is no API to know whether this kicked in.) -1 by default.</source>
          <target state="translated">迭代次数多了就停止求解,不管精度如何(XXX 目前没有API知道是否启动。)默认为-1。</target>
        </trans-unit>
        <trans-unit id="df6a1587df9722b5b493e30cfc313089ab29220d" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged. Default is 1.e-3.</source>
          <target state="translated">如果w已经收敛,则停止算法。默认为1.e-3。</target>
        </trans-unit>
        <trans-unit id="7cf46a1e9b2d853c73253eb4c96cbe1ea1bb5aa6" translate="yes" xml:space="preserve">
          <source>Stop words are words like &amp;ldquo;and&amp;rdquo;, &amp;ldquo;the&amp;rdquo;, &amp;ldquo;him&amp;rdquo;, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as signal for prediction. Sometimes, however, similar words are useful for prediction, such as in classifying writing style or personality.</source>
          <target state="translated">停用词是指诸如&amp;ldquo;和&amp;rdquo;，&amp;ldquo;该&amp;rdquo;，&amp;ldquo;他&amp;rdquo;之类的词，它们被认为在表示文本内容方面没有任何信息，可以将其删除以避免将其理解为预测的信号。但是，有时候，类似的单词对于预测很有用，例如在对写作风格或性格进行分类时。</target>
        </trans-unit>
        <trans-unit id="7eb24af52d1aa9e6b8d6715fd2fd646422f9b535" translate="yes" xml:space="preserve">
          <source>Stopping criteria.</source>
          <target state="translated">停止标准。</target>
        </trans-unit>
        <trans-unit id="51b3a0bb0b4d84ebe8a65cc9b8c0c2b3279fba93" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when using arpack eigen_solver.</source>
          <target state="translated">当使用 arpack eigen_solver 时,Laplacian 矩阵 eigendecomposition 的停止标准。</target>
        </trans-unit>
        <trans-unit id="68414daf9a6e27622678aff82460baea3a51326c" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the newton-cg and lbfgs solvers, the iteration will stop when &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_i&lt;/code&gt; is the i-th component of the gradient.</source>
          <target state="translated">停止标准。对于newton-cg和lbfgs求解器，当 &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; 其中 &lt;code&gt;g_i&lt;/code&gt; 是梯度的第i个分量。</target>
        </trans-unit>
        <trans-unit id="fe10af6492740b92517388e940d4c53ee7e65f2c" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for EM algorithm.</source>
          <target state="translated">EM算法的停止公差。</target>
        </trans-unit>
        <trans-unit id="3afb8412732c53a6b3ed5f0cf3d5d66e9526d993" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for updating document topic distribution in E-step.</source>
          <target state="translated">对电子步骤中更新文档主题分布停止容忍。</target>
        </trans-unit>
        <trans-unit id="5745be1c1a529a40ad5578990283b7d9ed5dfe16" translate="yes" xml:space="preserve">
          <source>Store n output values in leaves, instead of 1;</source>
          <target state="translated">在叶子中存储n个输出值,而不是1个。</target>
        </trans-unit>
        <trans-unit id="8a6ab3415c7252ce3e941fe62193814f0365a625" translate="yes" xml:space="preserve">
          <source>Stores nearest neighbors instance, including BallTree or KDtree if applicable.</source>
          <target state="translated">存储最近的邻居实例,包括BallTree或KDtree(如果适用)。</target>
        </trans-unit>
        <trans-unit id="f9d028499b97399f71598e9bb920fa52d5ec8313" translate="yes" xml:space="preserve">
          <source>Stores the affinity matrix used in &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">存储用于 &lt;code&gt;fit&lt;/code&gt; 的亲和矩阵。</target>
        </trans-unit>
        <trans-unit id="781b70a9f7d2aabdccb43059620f25863827cacd" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors</source>
          <target state="translated">存储嵌入向量</target>
        </trans-unit>
        <trans-unit id="9fe548f57e57cace725aa47be0bac94930f35de7" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors.</source>
          <target state="translated">存储嵌入向量。</target>
        </trans-unit>
        <trans-unit id="e7019b0e2126237169f8ccc84f1dacd8599b7b63" translate="yes" xml:space="preserve">
          <source>Stores the geodesic distance matrix of training data.</source>
          <target state="translated">存储训练数据的测地距离矩阵。</target>
        </trans-unit>
        <trans-unit id="7bfa0d6921b4ff07d4718354c3a4168af9b3a946" translate="yes" xml:space="preserve">
          <source>Stores the position of the dataset in the embedding space.</source>
          <target state="translated">存储数据集在嵌入空间中的位置。</target>
        </trans-unit>
        <trans-unit id="8197f80c6163117652499db82ad63b22aa5b87b2" translate="yes" xml:space="preserve">
          <source>Stores the training data.</source>
          <target state="translated">存储训练数据。</target>
        </trans-unit>
        <trans-unit id="6485fe8179de6b50a8b0db7cf302477ffee4cf50" translate="yes" xml:space="preserve">
          <source>Strategy to use to generate predictions.</source>
          <target state="translated">用来生成预测的策略。</target>
        </trans-unit>
        <trans-unit id="9ba291b4721c49cd83c83d224ae746db45b32e1d" translate="yes" xml:space="preserve">
          <source>Strategy used to define the widths of the bins.</source>
          <target state="translated">用于定义料仓宽度的策略。</target>
        </trans-unit>
        <trans-unit id="890ad0feded21dbb4c68bfca3e2d7cdbb498d411" translate="yes" xml:space="preserve">
          <source>Stratified K-Folds cross-validator</source>
          <target state="translated">分层K-Folds交叉验证器</target>
        </trans-unit>
        <trans-unit id="078f2e04c72cf2c2cef672d9cd530d809895796a" translate="yes" xml:space="preserve">
          <source>Stratified ShuffleSplit cross-validator</source>
          <target state="translated">分层ShuffleSplit交叉验证器。</target>
        </trans-unit>
        <trans-unit id="10ef227c2ccc54bd522a7229f1c708e11ce5e295" translate="yes" xml:space="preserve">
          <source>Strehl, Alexander, and Joydeep Ghosh (2002). &amp;ldquo;Cluster ensembles &amp;ndash; a knowledge reuse framework for combining multiple partitions&amp;rdquo;. Journal of Machine Learning Research 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi:10.1162/153244303321897735&lt;/a&gt;.</source>
          <target state="translated">Strehl，Alexander和Joydeep Ghosh（2002）。&amp;ldquo;集群集成&amp;ndash;用于组合多个分区的知识重用框架&amp;rdquo;。机器学习研究杂志3：583&amp;ndash;617。&lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi：10.1162 / 153244303321897735&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8f823045d1b6e6e3e2566fad8b86b9a7f7274035" translate="yes" xml:space="preserve">
          <source>String describing the type of covariance parameters to use. Must be one of:</source>
          <target state="translated">描述要使用的协方差参数类型的字符串。必须是以下类型之一:</target>
        </trans-unit>
        <trans-unit id="24715b349c9d19241a871e75b2e65bf44d424eee" translate="yes" xml:space="preserve">
          <source>String describing the type of the weight concentration prior. Must be one of:</source>
          <target state="translated">描述之前重量浓度类型的字符串。必须是以下类型之一:</target>
        </trans-unit>
        <trans-unit id="428566ee279a0d9edb0dac9070b52a231b258cad" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix</source>
          <target state="translated">要使用的内核函数或内核函数本身的字符串标识符。只有'rbf'和'knn'字符串是有效输入。传递的函数应采用两个输入，每个输入的形状为[n_samples，n_features]，并返回一个[n_samples，n_samples]形状的权重矩阵</target>
        </trans-unit>
        <trans-unit id="af724a0a2167e8652dc92f95eace643e40894f38" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix.</source>
          <target state="translated">要使用的内核函数或内核函数本身的字符串标识符。只有'rbf'和'knn'字符串是有效输入。传递的函数应采用两个输入，每个输入的形状为[n_samples，n_features]，并返回一个[n_samples，n_samples]形状的权重矩阵。</target>
        </trans-unit>
        <trans-unit id="62948e7b4671e9ca0f3cde3750c969c3432c4224" translate="yes" xml:space="preserve">
          <source>String identifier of the dataset. Note that OpenML can have multiple datasets with the same name.</source>
          <target state="translated">数据集的字符串标识符。注意,OpenML可以有多个同名的数据集。</target>
        </trans-unit>
        <trans-unit id="df0679bd93bc3d3699b427e726c60dd8e54a8049" translate="yes" xml:space="preserve">
          <source>String inputs, &amp;ldquo;absolute_loss&amp;rdquo; and &amp;ldquo;squared_loss&amp;rdquo; are supported which find the absolute loss and squared loss per sample respectively.</source>
          <target state="translated">支持字符串输入&amp;ldquo; absolute_loss&amp;rdquo;和&amp;ldquo; squared_loss&amp;rdquo;，分别输入每个样本的绝对损耗和平方损耗。</target>
        </trans-unit>
        <trans-unit id="0e35f8f4354526879dda20784b410a6fffd10219" translate="yes" xml:space="preserve">
          <source>String must be in {&amp;lsquo;frobenius&amp;rsquo;, &amp;lsquo;kullback-leibler&amp;rsquo;, &amp;lsquo;itakura-saito&amp;rsquo;}. Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from &amp;lsquo;frobenius&amp;rsquo; (or 2) and &amp;lsquo;kullback-leibler&amp;rsquo; (or 1) lead to significantly slower fits. Note that for beta_loss &amp;lt;= 0 (or &amp;lsquo;itakura-saito&amp;rsquo;), the input matrix X cannot contain zeros. Used only in &amp;lsquo;mu&amp;rsquo; solver.</source>
          <target state="translated">字符串必须位于{'frobenius'，'kullback-leibler'，'itakura-saito'}中。Beta散度应最小化，以测量X与点积WH之间的距离。请注意，不同于&amp;ldquo; frobenius&amp;rdquo;（或2）和&amp;ldquo; kullback-leibler&amp;rdquo;（或1）的值会导致拟合速度明显变慢。注意，对于beta_loss &amp;lt;= 0（或'itakura-saito'），输入矩阵X不能包含零。仅在&amp;ldquo; mu&amp;rdquo;求解器中使用。</target>
        </trans-unit>
        <trans-unit id="9f2d9e288ea5ff4eb7ea1abaab0c518bb3979797" translate="yes" xml:space="preserve">
          <source>String names for input features if available. By default, &amp;ldquo;x0&amp;rdquo;, &amp;ldquo;x1&amp;rdquo;, &amp;hellip; &amp;ldquo;xn_features&amp;rdquo; is used.</source>
          <target state="translated">输入功能的字符串名称（如果有）。默认情况下，使用&amp;ldquo; x0&amp;rdquo;，&amp;ldquo; x1&amp;rdquo;，&amp;hellip;&amp;hellip;&amp;ldquo; xn_features&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="6eb302a1a8353d21c585781076747cec5064ac6a" translate="yes" xml:space="preserve">
          <source>String representation of the input tree in GraphViz dot format. Only returned if &lt;code&gt;out_file&lt;/code&gt; is None.</source>
          <target state="translated">GraphViz点格式的输入树的字符串表示形式。仅在 &lt;code&gt;out_file&lt;/code&gt; 为None时返回。</target>
        </trans-unit>
        <trans-unit id="a25a8a192fb86c92debb43e92001c859f89e3fcf" translate="yes" xml:space="preserve">
          <source>String[s] representing allowed sparse matrix formats, such as &amp;lsquo;csc&amp;rsquo;, &amp;lsquo;csr&amp;rsquo;, etc. If the input is sparse but not in the allowed format, it will be converted to the first listed format. True allows the input to be any format. False means that a sparse matrix input will raise an error.</source>
          <target state="translated">表示允许的稀疏矩阵格式的字符串，例如'csc'，'csr'等。如果输入是稀疏的但不是允许的格式，它将被转换为第一个列出的格式。 True允许输入为任何格式。 False表示稀疏矩阵输入将引发错误。</target>
        </trans-unit>
        <trans-unit id="b91b90e5e49a63cce92ec827bcf2ae012d9565f3" translate="yes" xml:space="preserve">
          <source>Subsequently, the object is created as:</source>
          <target state="translated">随后,该对象被创建为:</target>
        </trans-unit>
        <trans-unit id="d8cf7e7f541f13164e6f0420a446eeb6e92a09d1" translate="yes" xml:space="preserve">
          <source>Subset of X on first axis</source>
          <target state="translated">第一轴X的子集</target>
        </trans-unit>
        <trans-unit id="6ae596021e773a90882ea646d69c3ae9bc66f60f" translate="yes" xml:space="preserve">
          <source>Subset of target values</source>
          <target state="translated">目标值子集</target>
        </trans-unit>
        <trans-unit id="71578b0f6daa48f798b6ba24f599e04480076227" translate="yes" xml:space="preserve">
          <source>Subset of the target values</source>
          <target state="translated">目标值的子集</target>
        </trans-unit>
        <trans-unit id="223f88ba981735506f55650c24adc2c0be541ac7" translate="yes" xml:space="preserve">
          <source>Subset of the training data</source>
          <target state="translated">训练数据的子集</target>
        </trans-unit>
        <trans-unit id="6bc315a85db741490d46c866dcdf3685f245d4e2" translate="yes" xml:space="preserve">
          <source>Subset of training data</source>
          <target state="translated">训练数据的子集</target>
        </trans-unit>
        <trans-unit id="19abeb39c58b2714170ce5a2488e41705eacf825" translate="yes" xml:space="preserve">
          <source>Subset of training points used to construct the feature map.</source>
          <target state="translated">用于构建特征图的训练点子集。</target>
        </trans-unit>
        <trans-unit id="af82dc274666b6dae18b2b0a4a918322786e1ec9" translate="yes" xml:space="preserve">
          <source>Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier.</source>
          <target state="translated">这样的数据分组是特定领域的。一个例子是,当有从多个病人那里收集到的医疗数据,从每个病人身上抽取多个样本。而这样的数据很可能是依赖于各个组的。在我们的例子中,每个样本的患者id将是它的组标识符。</target>
        </trans-unit>
        <trans-unit id="116040368f9a04b617abdb5e80205920c1827d88" translate="yes" xml:space="preserve">
          <source>Such integer representation can, however, not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).</source>
          <target state="translated">然而,这样的整数表示不能直接用于所有的scikit-learn估计器,因为这些估计器期望的是连续的输入,并且会将类别解释为有序的,而这往往不是人们所希望的(即浏览器的集合被任意排序)。</target>
        </trans-unit>
        <trans-unit id="db90c3a55b9a44b531c3ac8e926f4bff46ae5000" translate="yes" xml:space="preserve">
          <source>Sum of squared distances of samples to their closest cluster center.</source>
          <target state="translated">样本到其最近的聚类中心的平方距离之和。</target>
        </trans-unit>
        <trans-unit id="51853ebee0d0437a819288d394e52f2825e89e10" translate="yes" xml:space="preserve">
          <source>Sum-kernel k1 + k2 of two kernels k1 and k2.</source>
          <target state="translated">两个核k1和k2的和核k1+k2。</target>
        </trans-unit>
        <trans-unit id="70ee3e3bff0af30ecffa237a657d140e21c08452" translate="yes" xml:space="preserve">
          <source>Summary Statistics:</source>
          <target state="translated">统计摘要:</target>
        </trans-unit>
        <trans-unit id="fd64088007de4ee1ec90faddb61b9fabe7591dbe" translate="yes" xml:space="preserve">
          <source>Supervised learning algorithms will require a category label for each document in the training set. In this case the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents.</source>
          <target state="translated">监督学习算法需要为训练集中的每个文档提供类别标签。在这种情况下,类别是新闻组的名称,而新闻组的名称也恰好是存放单个文档的文件夹的名称。</target>
        </trans-unit>
        <trans-unit id="a76d63a44e8696360e974f3be74fa9ede463ccb8" translate="yes" xml:space="preserve">
          <source>Supervised learning: predicting an output variable from high-dimensional observations</source>
          <target state="translated">监督学习:从高维观测值预测输出变量。</target>
        </trans-unit>
        <trans-unit id="6eafe7087c2917502cf9a105460eb618a5158ac5" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">支持向量分类（SVC）与RandomForestClassifier相比，显示出甚至更多的S型曲线，这是典型的最大利润率方法（比较Niculescu-Mizil和Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;），这些方法侧重于接近决策边界的硬样本（支持向量）。</target>
        </trans-unit>
        <trans-unit id="ed5eaa4e09c1fde40caa79c99d658b1a804b4ecf" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="translated">支持向量机算法不是缩放不变的，因此&lt;strong&gt;强烈建议您缩放数据&lt;/strong&gt;。例如，将输入向量X上的每个属性缩放为[0,1]或[-1，+ 1]，或将其标准化为均值0和方差1。请注意，必须对测试向量应用&lt;em&gt;相同的&lt;/em&gt;缩放比例获得有意义的结果。有关缩放和规范化的更多详细信息，请参见&lt;a href=&quot;preprocessing#preprocessing&quot;&gt;预处理数据&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="7db4fe2bb2b495808d702cc828d549eda5ecd6dd" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for Regression implemented using libsvm.</source>
          <target state="translated">使用libsvm实现回归的支持向量机。</target>
        </trans-unit>
        <trans-unit id="f893d85d40edb954e6730df0c490772b3e2a0229" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.</source>
          <target state="translated">用libsvm实现的用于分类的支持向量机,有一个参数可以控制支持向量的数量。</target>
        </trans-unit>
        <trans-unit id="5051cb5a7ebb600b6c87a0405fb53ae2a929b69a" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification using libsvm.</source>
          <target state="translated">使用libsvm进行分类的支持向量机。</target>
        </trans-unit>
        <trans-unit id="c9c0030d3280fdd6faa0de4e8ec40fd895c7cc05" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for regression implemented using libsvm using a parameter to control the number of support vectors.</source>
          <target state="translated">使用libsvm实现回归的支持向量机,使用一个参数来控制支持向量的数量。</target>
        </trans-unit>
        <trans-unit id="56158ab7bc33e3424017c0101c6f6a1afb88a3a9" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by this &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="translated">支持向量机是功能强大的工具，但随着训练向量数量的增加，其计算和存储需求也迅速增加。SVM的核心是二次规划问题（QP），它将支持向量与其余训练数据分开。此基于&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;的实现所使用的QP解算器的缩放比例为\（O（n_ {features} \ times n_ {samples} ^ 2）\）和\（O（n_ {features} \ times n_ {samples} ^ 3）\ ），具体取决于实践中使用&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;缓存的效率（取决于数据集）。如果数据非常稀疏，则应将\（n_ {features} \）替换为样本矢量中非零特征的平均数量。</target>
        </trans-unit>
        <trans-unit id="5aeba1d5d3764ce4f342c9f3c5c4d98c95831ef3" translate="yes" xml:space="preserve">
          <source>Support Vector Regression (SVR) using linear and non-linear kernels</source>
          <target state="translated">使用线性和非线性核的支持向量回归(SVR)</target>
        </trans-unit>
        <trans-unit id="c38caf86bc0ea77939ed0d559b2d4f17cae05de8" translate="yes" xml:space="preserve">
          <source>Support Vector Regression implemented using libsvm.</source>
          <target state="translated">使用libsvm实现支持向量回归。</target>
        </trans-unit>
        <trans-unit id="9f57f9c660b4dd2f0deaa4ba97e0c878c516d5af" translate="yes" xml:space="preserve">
          <source>Support vector machines (SVMs)</source>
          <target state="translated">支持向量机(SVMs)</target>
        </trans-unit>
        <trans-unit id="bbbf41eb38c0c6ebc14c9776b74f3b7c7223e260" translate="yes" xml:space="preserve">
          <source>Support vectors.</source>
          <target state="translated">支持向量。</target>
        </trans-unit>
        <trans-unit id="a54e8408d47bb6e31202d1c04b19dcb2a41dd085" translate="yes" xml:space="preserve">
          <source>Supports sparse matrices, as long as they are nonnegative.</source>
          <target state="translated">支持稀疏矩阵,只要它们是非负的。</target>
        </trans-unit>
        <trans-unit id="3d69897cfb127444947f0af512011088c32f7842" translate="yes" xml:space="preserve">
          <source>Suppose there are \(n\) training samples, \(m\) features, \(k\) hidden layers, each containing \(h\) neurons - for simplicity, and \(o\) output neurons. The time complexity of backpropagation is \(O(n\cdot m \cdot h^k \cdot o \cdot i)\), where \(i\) is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training.</source>
          <target state="translated">假设有训练样本、特征、隐藏层,每个隐藏层都包含有简单的神经元和输出神经元。反向传播的时间复杂度是 \(O(ncdot m \cdot h^k \cdot o \cdot i)\),其中 \(i\)是迭代次数。由于反向传播的时间复杂度较高,因此建议从较少的隐藏神经元数量和较少的隐藏层开始进行训练。</target>
        </trans-unit>
        <trans-unit id="717b26aef2df5c03a35ae859cfcbb420ec45f953" translate="yes" xml:space="preserve">
          <source>Swaps two columns of a CSC/CSR matrix in-place.</source>
          <target state="translated">原地交换CSC/CSR矩阵的两列。</target>
        </trans-unit>
        <trans-unit id="1069fce64f91499526a54ca2a920222a7a6a7b20" translate="yes" xml:space="preserve">
          <source>Swaps two rows of a CSC/CSR matrix in-place.</source>
          <target state="translated">原地交换CSC/CSR矩阵的两行。</target>
        </trans-unit>
        <trans-unit id="fe072010fa51f4d65d4b1c57510d1adce13a6e7b" translate="yes" xml:space="preserve">
          <source>Swiss Roll reduction with LLE</source>
          <target state="translated">用LLE减少瑞士卷</target>
        </trans-unit>
        <trans-unit id="2230299d58c6b8fd7778e9806246c78a89ba5d37" translate="yes" xml:space="preserve">
          <source>Symmetrized version of the input array, i.e. the average of array and array.transpose(). If sparse, then duplicate entries are first summed and zeros are eliminated.</source>
          <target state="translated">输入数组的对称版本,即数组和array.transpose()的平均值。如果是稀疏的,则先将重复的条目相加,然后去掉零。</target>
        </trans-unit>
        <trans-unit id="5617e20da29f8f9d1be80cd4e8da4f2cca7d87a9" translate="yes" xml:space="preserve">
          <source>Symmetry: d(x, y) = d(y, x)</source>
          <target state="translated">对称性:d(x,y)=d(y,x)</target>
        </trans-unit>
        <trans-unit id="5c4b58b32e84506455d7badad68c3391e5ed62f8" translate="yes" xml:space="preserve">
          <source>Synthetic example</source>
          <target state="translated">综合实例</target>
        </trans-unit>
        <trans-unit id="a2f05b63d3eed62a3d034f7470902282f6f3879f" translate="yes" xml:space="preserve">
          <source>T. Calinski and J. Harabasz, 1974. &amp;ldquo;A dendrite method for cluster analysis&amp;rdquo;. Communications in Statistics</source>
          <target state="translated">T. Calinski和J. Harabasz，1974年。&amp;ldquo;一种用于聚类分析的枝晶方法&amp;rdquo;。统计通讯</target>
        </trans-unit>
        <trans-unit id="cfd0a0e6ed4317c498cad6dff52fb64a880cf1fc" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie，R。Tibshirani和J. Friedman，&amp;ldquo;统计学习的要素&amp;rdquo; 2&amp;rdquo;，施普林格，2009年。</target>
        </trans-unit>
        <trans-unit id="7f7943ebfea41ffafd05b1021989488d98e43338" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, p592-593, Springer, 2009.</source>
          <target state="translated">T. Hastie，R。Tibshirani和J. Friedman，&amp;ldquo;统计学习的要素&amp;rdquo; 2英寸，p592-593，施普林格，2009年。</target>
        </trans-unit>
        <trans-unit id="70c29954ab4c3cb7794dae94a173c1937d4eb172" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie，R。Tibshirani和J. Friedman，&amp;ldquo;统计学习的要素&amp;rdquo;，施普林格，2009年。</target>
        </trans-unit>
        <trans-unit id="83fcdb4c642340f440ec3c76643b0ff4a3e4d907" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T. Hastie，R。Tibshirani和J. Friedman。&amp;ldquo;统计学习的要素&amp;rdquo;，施普林格，2009年。</target>
        </trans-unit>
        <trans-unit id="cb7835aaacc19565f84e186774c00699f37d4811" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.</source>
          <target state="translated">T.Hastie,R.Tibshirani and J.Friedman.Elements of Statistical Learning Ed.2,Springer,2009.</target>
        </trans-unit>
        <trans-unit id="d4c99bc2ba4c28ec35fea9e0c8535d7da602917b" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.</source>
          <target state="translated">T.Hastie,R.Tibshirani and J.Friedman.Elements of Statistical Learning,Springer,2009.</target>
        </trans-unit>
        <trans-unit id="080b47cb3536b08b8d64a0132c354c0e69235639" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Springer 2009</source>
          <target state="translated">T. Hastie，R。Tibshirani，J。Friedman，&lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;《统计学习的要素》&lt;/a&gt;，Springer，2009年</target>
        </trans-unit>
        <trans-unit id="caa676716fee5a5c020ff878a7d0616f2b82e015" translate="yes" xml:space="preserve">
          <source>T. Ho, &amp;ldquo;The random subspace method for constructing decision forests&amp;rdquo;, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</source>
          <target state="translated">T. Ho，&amp;ldquo;用于构建决策森林的随机子空间方法&amp;rdquo;，《模式分析与机器智能》，第20（8）期，第832-844页，1998年。</target>
        </trans-unit>
        <trans-unit id="12a252b4085c50c08e5600b6a2ace31faa3ef960" translate="yes" xml:space="preserve">
          <source>T. Yang, Y. Li, M. Mahdavi, R. Jin and Z. Zhou &amp;ldquo;Nystroem Method vs Random Fourier Features: A Theoretical and Empirical Comparison&amp;rdquo;, Advances in Neural Information Processing Systems 2012</source>
          <target state="translated">杨T.，Y。李，M。Mahdavi，R。Jin和Z.Zhou，&amp;ldquo; Nystroem方法与随机傅立叶特征：理论和经验比较&amp;rdquo;，神经信息处理系统进展2012</target>
        </trans-unit>
        <trans-unit id="01f0642e8e9ab9a87342728e5ceb8bbd9d2f4ab3" translate="yes" xml:space="preserve">
          <source>TAX full-value property-tax rate per $10,000</source>
          <target state="translated">TAX 全值财产税率每10,000美元。</target>
        </trans-unit>
        <trans-unit id="dd1b5c68340d106d37b309522fe8b393cb21ad39" translate="yes" xml:space="preserve">
          <source>TF-IDF vectors of text documents crawled from the web</source>
          <target state="translated">从网上抓取的文本文件的TF-IDF向量。</target>
        </trans-unit>
        <trans-unit id="45e8bc91482fcb8372ecf82971819bb3adf7f455" translate="yes" xml:space="preserve">
          <source>TODO: implement zip dataset loading too</source>
          <target state="translated">待办事项:实现zip数据集的加载。</target>
        </trans-unit>
        <trans-unit id="8ab0e32d1d047cd892b558c9b2f078b6857615c4" translate="yes" xml:space="preserve">
          <source>Takes a group array to group observations.</source>
          <target state="translated">以组数组观察。</target>
        </trans-unit>
        <trans-unit id="3fd5fa24212eb9a6093f6fb3922373c2e928c57e" translate="yes" xml:space="preserve">
          <source>Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks).</source>
          <target state="translated">将组信息考虑在内,以避免建立具有不平衡类分布的褶皱(用于二元或多类分类任务)。</target>
        </trans-unit>
        <trans-unit id="d9f2745c15759b2e07e7b8ac9dcbd8d3eb7f1df5" translate="yes" xml:space="preserve">
          <source>Talks given, slide-sets and other information relevant to scikit-learn.</source>
          <target state="translated">与scikit-learn相关的讲座、幻灯片和其他信息。</target>
        </trans-unit>
        <trans-unit id="61ad50a9b9189cc3cf1874568e35e7901ff4c982" translate="yes" xml:space="preserve">
          <source>Target</source>
          <target state="translated">Target</target>
        </trans-unit>
        <trans-unit id="3566560919d090e98a5bc58e40d68ba478487e60" translate="yes" xml:space="preserve">
          <source>Target number of non-zero coefficients. Use &lt;code&gt;np.inf&lt;/code&gt; for no limit.</source>
          <target state="translated">非零系数的目标数量。 &lt;code&gt;np.inf&lt;/code&gt; 使用np.inf。</target>
        </trans-unit>
        <trans-unit id="de81f661c0a5f66b2eb62d654cf5ee97c42a462f" translate="yes" xml:space="preserve">
          <source>Target relative to X for classification or regression; None for unsupervised learning.</source>
          <target state="translated">对于分类或回归,目标相对于X;对于无监督学习,无。</target>
        </trans-unit>
        <trans-unit id="d9d3de45f60123470c229b29def5cf613978229f" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="translated">目标分数可以是肯定类别的概率估计，置信度值或决策的非阈值度量（如某些分类器上的&amp;ldquo; decision_function&amp;rdquo;所返回）。</target>
        </trans-unit>
        <trans-unit id="2da36130db1b72e7220423e41225d3cfbecbf96b" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers). For binary y_true, y_score is supposed to be the score of the class with greater label.</source>
          <target state="translated">目标分数可以是肯定类别的概率估计，置信度值或决策的非阈值度量（如某些分类器上的&amp;ldquo; decision_function&amp;rdquo;所返回）。对于二进制y_true，应该将y_score作为具有更大标签的类的分数。</target>
        </trans-unit>
        <trans-unit id="1c1467eb9fce38ab3f431a143b7b4099a3d2d978" translate="yes" xml:space="preserve">
          <source>Target values</source>
          <target state="translated">目标值</target>
        </trans-unit>
        <trans-unit id="1eb29851ae3516c30efee3683f12f4c58d29d5ce" translate="yes" xml:space="preserve">
          <source>Target values (class labels in classification, real numbers in regression)</source>
          <target state="translated">目标值(分类中的类标签,回归中的实数)</target>
        </trans-unit>
        <trans-unit id="9236c7bb185e41917cc98485dd0c1b72938dc4f1" translate="yes" xml:space="preserve">
          <source>Target values (integers for classification, real numbers for regression).</source>
          <target state="translated">目标值(分类用整数,回归用实数)。</target>
        </trans-unit>
        <trans-unit id="abfa5417a6d6ee53dab20f6c0ef952512e0950c9" translate="yes" xml:space="preserve">
          <source>Target values (integers)</source>
          <target state="translated">目标值(整数)</target>
        </trans-unit>
        <trans-unit id="030d74b88e6ada2cc611aa05819c6875ad926cb6" translate="yes" xml:space="preserve">
          <source>Target values (integers). Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">目标值（整数）。如有必要，将强制转换为X的dtype</target>
        </trans-unit>
        <trans-unit id="489913dd1ba6e89f6fe19c6ab73a6d0ba1572bbc" translate="yes" xml:space="preserve">
          <source>Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.</source>
          <target state="translated">目标值(分类中的字符串或整数,回归中的实数)对于分类来说,标签必须对应于类。</target>
        </trans-unit>
        <trans-unit id="20f1907edd6deff55545e2c6878457953ca23f05" translate="yes" xml:space="preserve">
          <source>Target values in training data (also required for prediction)</source>
          <target state="translated">训练数据中的目标值(也是预测所需)</target>
        </trans-unit>
        <trans-unit id="5698f85443295556a3231f89aa327fa20aab0ad9" translate="yes" xml:space="preserve">
          <source>Target values of shape = [n_samples] or [n_samples, n_outputs]</source>
          <target state="translated">shape的目标值=[n_samples]或[n_samples,n_outputs]。</target>
        </trans-unit>
        <trans-unit id="da9e802f308bd36e270eb5bda433836f08ce2390" translate="yes" xml:space="preserve">
          <source>Target values, array of float values, shape = [n_samples]</source>
          <target state="translated">目标值,浮动值的数组,形状=[n_samples]。</target>
        </trans-unit>
        <trans-unit id="9d4acf064ddb5b23ed0c4bdf7cb1ed1c86e0cce4" translate="yes" xml:space="preserve">
          <source>Target values, must be binary</source>
          <target state="translated">目标值,必须是二进制</target>
        </trans-unit>
        <trans-unit id="3784ae1e62853f0d4899c1eb47f9d650c50e4292" translate="yes" xml:space="preserve">
          <source>Target values.</source>
          <target state="translated">目标值:</target>
        </trans-unit>
        <trans-unit id="7a264b43381dcd3fa803548587f56b48ebe73a21" translate="yes" xml:space="preserve">
          <source>Target values. All sparse matrices are converted to CSR before inverse transformation.</source>
          <target state="translated">目标值。所有稀疏矩阵在逆向转换前都会转换为CSR。</target>
        </trans-unit>
        <trans-unit id="338b0342f37ab2a3243f471f75fbb6b8060759e1" translate="yes" xml:space="preserve">
          <source>Target values. Class labels must be an integer or float, or array-like objects of integer or float for multilabel classifications.</source>
          <target state="translated">目标值。类标签必须是一个整数或浮点数,或者对于多标签分类,必须是整数或浮点数的数组类对象。</target>
        </trans-unit>
        <trans-unit id="d95ddd0372c185ada4f873880d8cf72b3e972b79" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification.</source>
          <target state="translated">目标值。二维矩阵只应包含0和1,代表多标签分类。</target>
        </trans-unit>
        <trans-unit id="7d68da7045b7713975074def112516b22e3d548e" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.</source>
          <target state="translated">目标值。2-d矩阵只应包含0和1,代表多标签分类。稀疏矩阵可以是CSR、CSC、COO、DOK或LIL。</target>
        </trans-unit>
        <trans-unit id="5ca333a3206ea1ae310cc995419dd5b579b0311c" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">目标值。如有必要，将强制转换为X的dtype</target>
        </trans-unit>
        <trans-unit id="a73f8fffa45e4edde85ae5cfe9a7df8f5b0ddf64" translate="yes" xml:space="preserve">
          <source>Target vector (class labels).</source>
          <target state="translated">目标向量(类标签)。</target>
        </trans-unit>
        <trans-unit id="fbbf7212be6c75614582f7683105e9b145317ffe" translate="yes" xml:space="preserve">
          <source>Target vector relative to X</source>
          <target state="translated">目标向量相对于X</target>
        </trans-unit>
        <trans-unit id="9b9ad2408038efc60fe0697bee9336f5ceee389a" translate="yes" xml:space="preserve">
          <source>Target vector relative to X.</source>
          <target state="translated">目标向量相对于X。</target>
        </trans-unit>
        <trans-unit id="cb81b6b3ab32530c4b31b59fded732e0bc1457db" translate="yes" xml:space="preserve">
          <source>Target vector.</source>
          <target state="translated">目标矢量:</target>
        </trans-unit>
        <trans-unit id="86747748812222a9af434d10160edcea63797259" translate="yes" xml:space="preserve">
          <source>Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.</source>
          <target state="translated">目标向量,其中n_samples为样本数,n_targets为响应变量数。</target>
        </trans-unit>
        <trans-unit id="bb444a37f78059e3557a89e3cec7d30ee2a0e255" translate="yes" xml:space="preserve">
          <source>Target. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">目标。如有必要，将强制转换为X的dtype</target>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="d35260a00f655f27edcc35a7eb16da44a4f671a6" translate="yes" xml:space="preserve">
          <source>Targets</source>
          <target state="translated">Targets</target>
        </trans-unit>
        <trans-unit id="bae347ef05fa5719d83860ee11ad8e50b4550a95" translate="yes" xml:space="preserve">
          <source>Targets for input data.</source>
          <target state="translated">输入数据的目标。</target>
        </trans-unit>
        <trans-unit id="25e14b664fd8a2e3008eacd528868e3512f875a8" translate="yes" xml:space="preserve">
          <source>Targets for supervised learning.</source>
          <target state="translated">监督学习的目标。</target>
        </trans-unit>
        <trans-unit id="e907b7e300146da06f6bd372dfec64398cc10d60" translate="yes" xml:space="preserve">
          <source>Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">用于评分的目标。必须满足流水线所有步骤的标签要求。</target>
        </trans-unit>
        <trans-unit id="12f7c88d38da9108a78eb595ada57372e18cdd00" translate="yes" xml:space="preserve">
          <source>Technically the Lasso model is optimizing the same objective function as the Elastic Net with &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (no L2 penalty).</source>
          <target state="translated">从技术上讲，套索模型正在优化与弹性网相同的目标函数，其中 &lt;code&gt;l1_ratio=1.0&lt;/code&gt; （无L2损失）。</target>
        </trans-unit>
        <trans-unit id="7c21757d6dba7765c9b420762d607df44985a57d" translate="yes" xml:space="preserve">
          <source>Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.</source>
          <target state="translated">获得了n=442名糖尿病患者的10个基线变量、年龄、性别、体重指数、平均血压和6个血清测量值,以及感兴趣的反应,这是基线一年后疾病进展的定量测量。</target>
        </trans-unit>
        <trans-unit id="faacbc438202f94eb51c4c27efecd77f5a804a90" translate="yes" xml:space="preserve">
          <source>Tenenbaum, J.B.; De Silva, V.; &amp;amp; Langford, J.C. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500)</source>
          <target state="translated">Tenenbaum，JB；De Silva，V .; ＆J. Langford，JC一种用于减少非线性维数的全局几何框架。科学290（5500）</target>
        </trans-unit>
        <trans-unit id="2a1358959d0f2f819085e4aa4680265c467cbf33" translate="yes" xml:space="preserve">
          <source>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">Tenenhaus,M.(1998年)。PLS回归:理论与实践。巴黎:Editions Technic.</target>
        </trans-unit>
        <trans-unit id="0a268d2f62458299ec67330e170374c2cecaa669" translate="yes" xml:space="preserve">
          <source>Terms that were ignored because they either:</source>
          <target state="translated">被忽略的条款,因为它们要么。</target>
        </trans-unit>
        <trans-unit id="9f2d4d3a12b50c0b296af732b3fa3674c7292a32" translate="yes" xml:space="preserve">
          <source>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</source>
          <target state="translated">测试数据,我们计算其似然性,其中n_samples是样本数,n_features是特征数。X_test被假定为来自于与拟合中使用的数据相同的分布(包括中心化)。</target>
        </trans-unit>
        <trans-unit id="ed7e95a0302971bec5a032415d69927921186679" translate="yes" xml:space="preserve">
          <source>Test data to be transformed, must have the same number of features as the data used to train the model.</source>
          <target state="translated">要转换的测试数据,必须与用于训练模型的数据具有相同数量的特征。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
