<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="840b342f8bab010ed9a33830388b79c022d751bb" translate="yes" xml:space="preserve">
          <source>There are three different implementations of Support Vector Regression: &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt;&lt;code&gt;LinearSVR&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt;&lt;code&gt;LinearSVR&lt;/code&gt;&lt;/a&gt; provides a faster implementation than &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; but only considers linear kernels, while &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; implements a slightly different formulation than &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt;&lt;code&gt;LinearSVR&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&quot;#svm-implementation-details&quot;&gt;Implementation details&lt;/a&gt; for further details.</source>
          <target state="translated">支持向量回归有三种不同的实现方式：&lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt; &lt;code&gt;LinearSVR&lt;/code&gt; &lt;/a&gt;。&lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt; &lt;code&gt;LinearSVR&lt;/code&gt; &lt;/a&gt;提供了比&lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt;更快的实现，但是仅考虑了线性内核，而&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; &lt;/a&gt;实现了与&lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt; &lt;code&gt;LinearSVR&lt;/code&gt; &lt;/a&gt;略有不同的表达方式。有关更多详细&lt;a href=&quot;#svm-implementation-details&quot;&gt;信息&lt;/a&gt;，请参见实现细节。</target>
        </trans-unit>
        <trans-unit id="7c46376033bb18a7479bbb076a0191da5ac66026" translate="yes" xml:space="preserve">
          <source>There are three different implementations of Support Vector Regression: &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt;&lt;code&gt;LinearSVR&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt;&lt;code&gt;LinearSVR&lt;/code&gt;&lt;/a&gt; provides a faster implementation than &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; but only considers the linear kernel, while &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; implements a slightly different formulation than &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt;&lt;code&gt;LinearSVR&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&quot;#svm-implementation-details&quot;&gt;Implementation details&lt;/a&gt; for further details.</source>
          <target state="translated">支持向量回归有三种不同的实现方式：&lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt; &lt;code&gt;LinearSVR&lt;/code&gt; &lt;/a&gt;。&lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt; &lt;code&gt;LinearSVR&lt;/code&gt; &lt;/a&gt;提供了比&lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt;更快的实现，但是仅考虑了线性内核，而&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; &lt;/a&gt;实现的配方与&lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt; &lt;code&gt;SVR&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt; &lt;code&gt;LinearSVR&lt;/code&gt; &lt;/a&gt;略有不同。有关更多详细&lt;a href=&quot;#svm-implementation-details&quot;&gt;信息&lt;/a&gt;，请参见实现细节。</target>
        </trans-unit>
        <trans-unit id="6325cb8ad2d750db2de1f50457999e3ed60c95ad" translate="yes" xml:space="preserve">
          <source>There are three main kinds of dataset interfaces that can be used to get datasets depending on the desired type of dataset.</source>
          <target state="translated">根据所需的数据集类型,主要有三种数据集接口可以用来获取数据集。</target>
        </trans-unit>
        <trans-unit id="f738d3558005f6c63ce087749d6fa9a898307784" translate="yes" xml:space="preserve">
          <source>There are two main methods to approximate the integral above, namely the &amp;lsquo;brute&amp;rsquo; and &amp;lsquo;recursion&amp;rsquo; methods. The &lt;code&gt;method&lt;/code&gt; parameter controls which method to use.</source>
          <target state="translated">有两种近似上述积分的主要方法，即&amp;ldquo;粗略&amp;rdquo;和&amp;ldquo;递归&amp;rdquo;方法。该 &lt;code&gt;method&lt;/code&gt; 使用参数控制该方法。</target>
        </trans-unit>
        <trans-unit id="8d867308d6cfc04930e6d66867b250110233d07e" translate="yes" xml:space="preserve">
          <source>There are two options to assign labels:</source>
          <target state="translated">有两个选项来分配标签。</target>
        </trans-unit>
        <trans-unit id="60a8f9c96bc7f93958ce08005db84d1ac5e8a2b4" translate="yes" xml:space="preserve">
          <source>There are two ways of evaluating a biclustering result: internal and external. Internal measures, such as cluster stability, rely only on the data and the result themselves. Currently there are no internal bicluster measures in scikit-learn. External measures refer to an external source of information, such as the true solution. When working with real data the true solution is usually unknown, but biclustering artificial data may be useful for evaluating algorithms precisely because the true solution is known.</source>
          <target state="translated">评价双聚类结果有两种方法:内部和外部。内部测量,比如聚类稳定性,只依赖于数据和结果本身。目前scikit-learn中没有内部的双聚类测量方法。外部测量指的是外部信息源,比如真解。在处理真实数据时,真实解通常是未知的,但双聚类人工数据可能对评估算法有用,正是因为真实解是已知的。</target>
        </trans-unit>
        <trans-unit id="21ade7db23177cbafdee1241d820ab218814e247" translate="yes" xml:space="preserve">
          <source>There are two ways to specify multiple scoring metrics for the &lt;code&gt;scoring&lt;/code&gt; parameter:</source>
          <target state="translated">有两种方法可以为 &lt;code&gt;scoring&lt;/code&gt; 参数指定多个评分指标：</target>
        </trans-unit>
        <trans-unit id="c9e248c64205afb9beabc74d09eccb0781bdceea" translate="yes" xml:space="preserve">
          <source>There exist several strategies to perform Bayesian ridge regression. This implementation is based on the algorithm described in Appendix A of (Tipping, 2001) where updates of the regularization parameters are done as suggested in (MacKay, 1992). Note that according to A New View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these update rules do not guarantee that the marginal likelihood is increasing between two consecutive iterations of the optimization.</source>
          <target state="translated">有几种策略可以进行贝叶斯岭回归。本实施例基于(Tipping,2001)附录A中描述的算法,其中正则化参数的更新是按照(MacKay,1992)中的建议进行的。需要注意的是,根据A New View of Automatic Relevance Determination(Wipf and Nagarajan,2008),这些更新规则并不能保证边际似然在连续两次优化迭代之间不断增加。</target>
        </trans-unit>
        <trans-unit id="cdf4947857438b0c51097ba679415b8309e576f2" translate="yes" xml:space="preserve">
          <source>There exists two types of MDS algorithm: metric and non metric. In the scikit-learn, the class &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; implements both. In Metric MDS, the input similarity matrix arises from a metric (and thus respects the triangular inequality), the distances between output two points are then set to be as close as possible to the similarity or dissimilarity data. In the non-metric version, the algorithms will try to preserve the order of the distances, and hence seek for a monotonic relationship between the distances in the embedded space and the similarities/dissimilarities.</source>
          <target state="translated">MDS算法有两种：公制和非公制。在scikit-learn中，&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;类同时实现了这两种方法。在度量MDS中，输入相似性矩阵来自度量（因此考虑了三角形不等式），然后将输出两点之间的距离设置为尽可能接近相似性或不相似性数据。在非度量版本中，算法将尝试保留距离的顺序，并因此在嵌入式空间中的距离与相似度/相异度之间寻求单调关系。</target>
        </trans-unit>
        <trans-unit id="9e945ec56932f8495741411aac1ef0391f41ea70" translate="yes" xml:space="preserve">
          <source>There is absolutely no guarantee of recovering a ground truth. First, choosing the right number of clusters is hard. Second, the algorithm is sensitive to initialization, and can fall into local minima, although scikit-learn employs several tricks to mitigate this issue.</source>
          <target state="translated">绝对不能保证恢复地道。首先,选择合适的集群数量是很难的。其次,算法对初始化很敏感,可能会陷入局部最小值,尽管scikit-learn采用了几个技巧来缓解这个问题。</target>
        </trans-unit>
        <trans-unit id="a5fa0b690cccf03ea1d32deadc1c15c3039ee96d" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="translated">内置支持以&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;支持的格式在任何矩阵中提供的稀疏数据。但是，为了获得最大效率，请使用&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix中&lt;/a&gt;定义的CSR矩阵格式。</target>
        </trans-unit>
        <trans-unit id="46a0af0f073c85f45d179011b96dd0c21ed6963a" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="translated">内置支持以&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;支持的格式在任何矩阵中提供的稀疏数据。但是，为了获得最大效率，请使用&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix中&lt;/a&gt;定义的CSR矩阵格式。</target>
        </trans-unit>
        <trans-unit id="7bf90eed7a42877d9e674dd4cae64f5ef3af07a9" translate="yes" xml:space="preserve">
          <source>There is no general rule to select an alpha parameter for recovery of non-zero coefficients. It can by set by cross-validation (&lt;code&gt;LassoCV&lt;/code&gt; or &lt;code&gt;LassoLarsCV&lt;/code&gt;), though this may lead to under-penalized models: including a small number of non-relevant variables is not detrimental to prediction score. BIC (&lt;code&gt;LassoLarsIC&lt;/code&gt;) tends, on the opposite, to set high values of alpha.</source>
          <target state="translated">没有一般规则来选择用于恢复非零系数的alpha参数。可以通过交叉验证（ &lt;code&gt;LassoCV&lt;/code&gt; 或 &lt;code&gt;LassoLarsCV&lt;/code&gt; ）进行设置，尽管这可能会导致模型欠缺惩罚：包括少量无关变量不会损害预测得分。相反，BIC（ &lt;code&gt;LassoLarsIC&lt;/code&gt; ）倾向于设置较高的alpha值。</target>
        </trans-unit>
        <trans-unit id="ff0ab54a4c7a8a1cf35484dbae4d9dce95d5c026" translate="yes" xml:space="preserve">
          <source>There might be a difference in the scores obtained between &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;solver=liblinear&lt;/code&gt; or &lt;code&gt;LinearSVC&lt;/code&gt; and the external liblinear library directly, when &lt;code&gt;fit_intercept=False&lt;/code&gt; and the fit &lt;code&gt;coef_&lt;/code&gt; (or) the data to be predicted are zeroes. This is because for the sample(s) with &lt;code&gt;decision_function&lt;/code&gt; zero, &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;LinearSVC&lt;/code&gt; predict the negative class, while liblinear predicts the positive class. Note that a model with &lt;code&gt;fit_intercept=False&lt;/code&gt; and having many samples with &lt;code&gt;decision_function&lt;/code&gt; zero, is likely to be a underfit, bad model and you are advised to set &lt;code&gt;fit_intercept=True&lt;/code&gt; and increase the intercept_scaling.</source>
          <target state="translated">当 &lt;code&gt;fit_intercept=False&lt;/code&gt; 和fit &lt;code&gt;coef_&lt;/code&gt; （或）要预测的数据为零时，使用 &lt;code&gt;solver=liblinear&lt;/code&gt; 或 &lt;code&gt;LinearSVC&lt;/code&gt; 的&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;与外部liblinear库之间获得的分数可能会有所不同。这是因为对于 &lt;code&gt;decision_function&lt;/code&gt; &lt;code&gt;LinearSVC&lt;/code&gt; 为零的样本，&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;和LinearSVC预测负类，而liblinear预测正类。请注意，与模型 &lt;code&gt;fit_intercept=False&lt;/code&gt; ，并具有许多样品 &lt;code&gt;decision_function&lt;/code&gt; 为零，很可能是一个underfit，坏的模式，建议您设置 &lt;code&gt;fit_intercept=True&lt;/code&gt; 并增加intercept_scaling。</target>
        </trans-unit>
        <trans-unit id="4a4216d2986ca1c413a45927f7f8dc07ca811204" translate="yes" xml:space="preserve">
          <source>Therefore, a logarithmic (&lt;code&gt;np.log1p&lt;/code&gt;) and an exponential function (&lt;code&gt;np.expm1&lt;/code&gt;) will be used to transform the targets before training a linear regression model and using it for prediction.</source>
          <target state="translated">因此，在训练线性回归模型并将其用于预测之前，将使用对数（ &lt;code&gt;np.log1p&lt;/code&gt; ）和指数函数（ &lt;code&gt;np.expm1&lt;/code&gt; ）转换目标。</target>
        </trans-unit>
        <trans-unit id="6912f2dbecf0d873a7ad1021b00fc015a0232427" translate="yes" xml:space="preserve">
          <source>These are transformers that are not intended to be used on features, only on supervised learning targets. See also &lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;Transforming target in regression&lt;/a&gt; if you want to transform the prediction target for learning, but evaluate the model in the original (untransformed) space.</source>
          <target state="translated">这些是不打算在功能上使用的变压器，仅在有监督的学习目标上使用。如果要转换预测目标以进行学习，但请在原始（未转换）空间中评估模型，另请参见&lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;在回归中转换目标&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9c615abfdf912d61f49e70314e0bacb6d3789d48" translate="yes" xml:space="preserve">
          <source>These classifiers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no hyperparameters to tune.</source>
          <target state="translated">这些分类器之所以吸引人,是因为它们具有易于计算的闭式解,本质上是多类的,在实践中已经被证明是行之有效的,而且没有超参数可以调整。</target>
        </trans-unit>
        <trans-unit id="fde55c65b8197fd0cbaa58300d107768af9ed389" translate="yes" xml:space="preserve">
          <source>These constraint are useful to impose a certain local structure, but they also make the algorithm faster, especially when the number of the samples is high.</source>
          <target state="translated">这些约束对于强加一定的局部结构是很有用的,但也会使算法的速度更快,特别是当样本数量较多时。</target>
        </trans-unit>
        <trans-unit id="ebd210a6b7ae21f6cafc3c41203edaaa46e25728" translate="yes" xml:space="preserve">
          <source>These datasets are useful to quickly illustrate the behavior of the various algorithms implemented in scikit-learn. They are however often too small to be representative of real world machine learning tasks.</source>
          <target state="translated">这些数据集对于快速说明scikit-learn中实现的各种算法的行为非常有用。然而,它们往往太小,不能代表真实世界的机器学习任务。</target>
        </trans-unit>
        <trans-unit id="8d2ab26191aa60fb366e6a03a6fce9c7d01208ba" translate="yes" xml:space="preserve">
          <source>These environment variables should be set before importing scikit-learn.</source>
          <target state="translated">这些环境变量应该在导入 scikit-learn 之前进行设置。</target>
        </trans-unit>
        <trans-unit id="b821932825baa77bb11f8b1f95c8cc38b1d75bf5" translate="yes" xml:space="preserve">
          <source>These estimators are called similarly to their counterparts, with &amp;lsquo;CV&amp;rsquo; appended to their name.</source>
          <target state="translated">这些估算器的名称与对应估算器的名称类似，后缀&amp;ldquo; CV&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="4895efc31f112ba17d5e8de5c88b9b84cbaac29a" translate="yes" xml:space="preserve">
          <source>These estimators are described in more detail below in &lt;a href=&quot;#histogram-based-gradient-boosting&quot;&gt;Histogram-Based Gradient Boosting&lt;/a&gt;.</source>
          <target state="translated">这些估算器将在下面&lt;a href=&quot;#histogram-based-gradient-boosting&quot;&gt;的基于直方图的梯度提升&lt;/a&gt;中更详细地描述。</target>
        </trans-unit>
        <trans-unit id="31d7d129bfc794bb111166051ddf1fbfd1e21090" translate="yes" xml:space="preserve">
          <source>These estimators are still &lt;strong&gt;experimental&lt;/strong&gt;: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="translated">这些估算器仍处于&lt;strong&gt;试验阶段&lt;/strong&gt;：其预测和API可能会发生变化，而不会发生任何弃用周期。要使用它们，您需要显式导入 &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="bd57beb09d61462992a46fc07ecdff56e4d9c660" translate="yes" xml:space="preserve">
          <source>These estimators fit multiple regression problems (or tasks) jointly, while inducing sparse coefficients. While the inferred coefficients may differ between the tasks, they are constrained to agree on the features that are selected (non-zero coefficients).</source>
          <target state="translated">这些估计器共同拟合多个回归问题(或任务),同时诱导稀疏系数。虽然各任务之间的推断系数可能不同,但它们被限制在所选特征上达成一致(非零系数)。</target>
        </trans-unit>
        <trans-unit id="fac22fa1718df2cc93fd78246f559caa4e598cf3" translate="yes" xml:space="preserve">
          <source>These examples illustrate the main features of the releases of scikit-learn.</source>
          <target state="translated">这些例子说明了scikit-learn版本的主要特点。</target>
        </trans-unit>
        <trans-unit id="8bef6d4f1ba3e716c219b98d63998eb428a7438d" translate="yes" xml:space="preserve">
          <source>These families of algorithms are useful to find linear relations between two multivariate datasets: the &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; arguments of the &lt;code&gt;fit&lt;/code&gt; method are 2D arrays.</source>
          <target state="translated">这些算法系列可用于查找两个多元数据集之间的线性关系： &lt;code&gt;fit&lt;/code&gt; 方法的 &lt;code&gt;X&lt;/code&gt; 和 &lt;code&gt;Y&lt;/code&gt; 参数是2D数组。</target>
        </trans-unit>
        <trans-unit id="1f2f0c6c7df23095dba3fa00aa5227521de2ff47" translate="yes" xml:space="preserve">
          <source>These fast estimators first bin the input samples &lt;code&gt;X&lt;/code&gt; into integer-valued bins (typically 256 bins) which tremendously reduces the number of splitting points to consider, and allows the algorithm to leverage integer-based data structures (histograms) instead of relying on sorted continuous values when building the trees. The API of these estimators is slightly different, and some of the features from &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; are not yet supported, for instance some loss functions.</source>
          <target state="translated">这些快速估计器首先将输入样本 &lt;code&gt;X&lt;/code&gt; 装箱成整数值的装箱（通常为256个装箱），这大大减少了要考虑的分割点数量，并使算法可以利用基于整数的数据结构（直方图），而不是依赖于已排序的连续数据建造树木时的价值。这些估算器的API略有不同，并且&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; 的&lt;/a&gt;某些功能尚不支持，例如某些损失函数。</target>
        </trans-unit>
        <trans-unit id="e90c7c20b495d718d6ee1761b52661a07d31f2ac" translate="yes" xml:space="preserve">
          <source>These figures aid in illustrating how a point cloud can be very flat in one direction&amp;ndash;which is where PCA comes in to choose a direction that is not flat.</source>
          <target state="translated">这些图有助于说明点云如何在一个方向上非常平坦，这就是PCA选择不平坦方向的原因。</target>
        </trans-unit>
        <trans-unit id="5b3c06102d71e9aa21ce3635f214fb7544bfe93e" translate="yes" xml:space="preserve">
          <source>These functions have an &lt;code&gt;multioutput&lt;/code&gt; keyword argument which specifies the way the scores or losses for each individual target should be averaged. The default is &lt;code&gt;'uniform_average'&lt;/code&gt;, which specifies a uniformly weighted mean over outputs. If an &lt;code&gt;ndarray&lt;/code&gt; of shape &lt;code&gt;(n_outputs,)&lt;/code&gt; is passed, then its entries are interpreted as weights and an according weighted average is returned. If &lt;code&gt;multioutput&lt;/code&gt; is &lt;code&gt;'raw_values'&lt;/code&gt; is specified, then all unaltered individual scores or losses will be returned in an array of shape &lt;code&gt;(n_outputs,)&lt;/code&gt;.</source>
          <target state="translated">这些函数具有一个 &lt;code&gt;multioutput&lt;/code&gt; 关键字参数，该参数指定应平均每个单个目标的得分或损失的方式。默认值为 &lt;code&gt;'uniform_average'&lt;/code&gt; ，它指定输出的均匀加权平均值。如果 &lt;code&gt;ndarray&lt;/code&gt; 形状为 &lt;code&gt;(n_outputs,)&lt;/code&gt; 的ndarray,则将其条目解释为权重，并返回相应的加权平均值。如果指定了 &lt;code&gt;multioutput&lt;/code&gt; 为 &lt;code&gt;'raw_values'&lt;/code&gt; ，则所有未更改的单个得分或损失将以形状数组 &lt;code&gt;(n_outputs,)&lt;/code&gt; 返回。</target>
        </trans-unit>
        <trans-unit id="8f744234c4fef479ca52103694dddbbb39569d67" translate="yes" xml:space="preserve">
          <source>These functions return a tuple &lt;code&gt;(X, y)&lt;/code&gt; consisting of a &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; numpy array &lt;code&gt;X&lt;/code&gt; and an array of length &lt;code&gt;n_samples&lt;/code&gt; containing the targets &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">这些函数返回一个元组 &lt;code&gt;(X, y)&lt;/code&gt; 该元组由 &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; 个 numpy数组 &lt;code&gt;X&lt;/code&gt; 和一个长度为 &lt;code&gt;n_samples&lt;/code&gt; 的包含目标 &lt;code&gt;y&lt;/code&gt; 的数组组成。</target>
        </trans-unit>
        <trans-unit id="7ea4b087a47ece8eb67eda1c13d069b3e5f40d70" translate="yes" xml:space="preserve">
          <source>These generators produce a matrix of features and corresponding discrete targets.</source>
          <target state="translated">这些生成器会产生一个特征矩阵和相应的离散目标。</target>
        </trans-unit>
        <trans-unit id="ff830f502c3a30a0f4f3f842eff62f7849f20cad" translate="yes" xml:space="preserve">
          <source>These histogram-based estimators can be &lt;strong&gt;orders of magnitude faster&lt;/strong&gt; than &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; when the number of samples is larger than tens of thousands of samples.</source>
          <target state="translated">当样本数量大于成千上万个样本时，这些基于直方图的估计器可能比&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;&lt;strong&gt;快&lt;/strong&gt;几个数量级。</target>
        </trans-unit>
        <trans-unit id="7870342f67a34d74383fe781d3e91593569275ef" translate="yes" xml:space="preserve">
          <source>These images how similar features are merged together using feature agglomeration.</source>
          <target state="translated">这些图像如何使用特征集聚将相似的特征合并在一起。</target>
        </trans-unit>
        <trans-unit id="2f6550a6d877a222d311c7f7d2e4efbab68b15f3" translate="yes" xml:space="preserve">
          <source>These matrices can be used to impose connectivity in estimators that use connectivity information, such as Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;), but also to build precomputed kernels, or similarity matrices.</source>
          <target state="translated">这些矩阵可用于在使用连通性信息的估计器中强加连通性，例如Ward聚类（&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;），也可用于构建预先计算的内核或相似性矩阵。</target>
        </trans-unit>
        <trans-unit id="f1476efa19922a5a7b34be362fc1e06a3ae81118" translate="yes" xml:space="preserve">
          <source>These metrics &lt;strong&gt;require the knowledge of the ground truth classes&lt;/strong&gt; while almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).</source>
          <target state="translated">这些度量标准&lt;strong&gt;需要了解基本事实类别，&lt;/strong&gt;而&lt;strong&gt;实际上&lt;/strong&gt;却几乎不可用，或者需要人工注释者手动分配（如在有监督的学习环境中）。</target>
        </trans-unit>
        <trans-unit id="102278a50cfd01c3d7a2cbdc18b76a5ce6b39772" translate="yes" xml:space="preserve">
          <source>These models allow for response variables to have error distributions other than a normal distribution:</source>
          <target state="translated">这些模型允许响应变量具有正态分布以外的误差分布。</target>
        </trans-unit>
        <trans-unit id="1b78634dcd7b938ef7f64bb3d2756751845f06a1" translate="yes" xml:space="preserve">
          <source>These objects take as input a scoring function that returns univariate scores and p-values (or only scores for &lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt;&lt;code&gt;SelectKBest&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt;&lt;code&gt;SelectPercentile&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">这些对象将一个得分函数作为输入，该函数返回单变量得分和p值（或仅返回&lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt; &lt;code&gt;SelectKBest&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt; &lt;code&gt;SelectPercentile&lt;/code&gt; 的&lt;/a&gt;得分）：</target>
        </trans-unit>
        <trans-unit id="7d570e698357345b9d25fb0f909251adbc540e40" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="translated">可以通过属性 &lt;code&gt;dual_coef_&lt;/code&gt; 其中包含差异\（\ alpha_i- \ alpha_i ^ * \）， &lt;code&gt;support_vectors_&lt;/code&gt; （包含支持向量）和 &lt;code&gt;intercept_&lt;/code&gt; (其具有独立项\（b \））来访问这些参数。</target>
        </trans-unit>
        <trans-unit id="fc9887aaf0c2ed20eb0f603451b50a8d7e26af7c" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="translated">可以通过以下属性来访问这些参数：属性 &lt;code&gt;dual_coef_&lt;/code&gt; 保存乘积\（y_i \ alpha_i \）， &lt;code&gt;support_vectors_&lt;/code&gt; 保存支撑向量， &lt;code&gt;intercept_&lt;/code&gt; 属性保存独立项\（b \）</target>
        </trans-unit>
        <trans-unit id="3403571e1d1dd77b054e08b8e749a4d9b5c4d316" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\)</source>
          <target state="translated">这些参数可以通过成员 &lt;code&gt;dual_coef_&lt;/code&gt; （具有差异\（\ alpha_i- \ alpha_i ^ * \），具有支持向量的 &lt;code&gt;support_vectors_&lt;/code&gt; 和具有独立项\（\ rho \）的 &lt;code&gt;intercept_&lt;/code&gt; 来访问。</target>
        </trans-unit>
        <trans-unit id="9254aef96f1c8727db185406da2727e74822dda9" translate="yes" xml:space="preserve">
          <source>These quantities are also related to the (\(F_1\)) score, which is defined as the harmonic mean of precision and recall.</source>
          <target state="translated">这些数量也与((F_1/1))分值有关,它被定义为精度和召回的谐波平均值。</target>
        </trans-unit>
        <trans-unit id="8ec6209edcb97e57d934d74900289c4f7467ca16" translate="yes" xml:space="preserve">
          <source>These represent the 14 features measured at each point of the map grid. The latitude/longitude values for the grid are discussed below. Missing data is represented by the value -9999.</source>
          <target state="translated">这些代表了在地图网格的每一点上测量的14个特征。网格的经纬度值在下面讨论。缺少的数据用数值-9999表示。</target>
        </trans-unit>
        <trans-unit id="e11ef00d62661e429b4b798a345a9c8d62a348e6" translate="yes" xml:space="preserve">
          <source>These steps are performed either a maximum number of times (&lt;code&gt;max_trials&lt;/code&gt;) or until one of the special stop criteria are met (see &lt;code&gt;stop_n_inliers&lt;/code&gt; and &lt;code&gt;stop_score&lt;/code&gt;). The final model is estimated using all inlier samples (consensus set) of the previously determined best model.</source>
          <target state="translated">这些步骤将执行最大次数（ &lt;code&gt;max_trials&lt;/code&gt; ），或者直到满足特殊停止条件之一为止（请参见 &lt;code&gt;stop_n_inliers&lt;/code&gt; 和 &lt;code&gt;stop_score&lt;/code&gt; ）。使用先前确定的最佳模型的所有内部样本（共识集）估计最终模型。</target>
        </trans-unit>
        <trans-unit id="ffccb4ceb37928160a8178b1e93c390573c106cb" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;6&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="translated">这三个距离是beta散度族的特例，分别具有\（\ beta = 2，1，0 \）&lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;6&lt;/a&gt;。&amp;beta;散度定义为：</target>
        </trans-unit>
        <trans-unit id="eff89650d9905b662c6df80228e926f2f144c91b" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="translated">这三个距离是&amp;beta;-散度族的特例，分别具有\（\ beta = 2，1，0 \）&lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt;。&amp;beta;散度定义为：</target>
        </trans-unit>
        <trans-unit id="100dafc268c3e9d0b628da1715aed2440b14ba32" translate="yes" xml:space="preserve">
          <source>These throughputs are achieved on a single process. An obvious way to increase the throughput of your application is to spawn additional instances (usually processes in Python because of the &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GIL&lt;/a&gt;) that share the same model. One might also add machines to spread the load. A detailed explanation on how to achieve this is beyond the scope of this documentation though.</source>
          <target state="translated">这些吞吐量是在单个过程中实现的。增加应用程序吞吐量的一个显而易见的方法是生成共享同一模型的其他实例（通常是由于&lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GIL而&lt;/a&gt;在Python中进行处理）。可能还会增加一台机器来分散负载。但是，有关如何实现此目的的详细说明超出了本文档的范围。</target>
        </trans-unit>
        <trans-unit id="b826ad64b72daa0458c9fdfb2862fce60b4db70b" translate="yes" xml:space="preserve">
          <source>They also have built-in support for missing values, which avoids the need for an imputer.</source>
          <target state="translated">它们还内置了对缺失值的支持,这就避免了对微机的需求。</target>
        </trans-unit>
        <trans-unit id="e63971597c4df5f2dc150f90b566e1219b6a632a" translate="yes" xml:space="preserve">
          <source>They are not sparse, i.e., they use the whole samples/features information to perform the prediction.</source>
          <target state="translated">它们不是稀疏的,即使用整个样本/特征信息来进行预测。</target>
        </trans-unit>
        <trans-unit id="26f84bd6fe103542912ebb1fb588d29515a2fd6d" translate="yes" xml:space="preserve">
          <source>They can be loaded using the following functions:</source>
          <target state="translated">可以使用以下函数加载它们:</target>
        </trans-unit>
        <trans-unit id="f7ddbd9f45ee3f137b5eb656135dce7584351da0" translate="yes" xml:space="preserve">
          <source>They expose a &lt;code&gt;split&lt;/code&gt; method which accepts the input dataset to be split and yields the train/test set indices for each iteration of the chosen cross-validation strategy.</source>
          <target state="translated">他们公开了一个 &lt;code&gt;split&lt;/code&gt; 方法，该方法接受要拆分的输入数据集，并为所选交叉验证策略的每次迭代生成训练/测试集索引。</target>
        </trans-unit>
        <trans-unit id="03bbcc98e1d567dd0afc112fe378a99851c98226" translate="yes" xml:space="preserve">
          <source>They lose efficiency in high dimensional spaces &amp;ndash; namely when the number of features exceeds a few dozens.</source>
          <target state="translated">它们会在高维空间中失去效率，也就是说，当特征数量超过几十个时。</target>
        </trans-unit>
        <trans-unit id="a673690dbc33eee17ee6f3995f817097918876ff" translate="yes" xml:space="preserve">
          <source>This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).</source>
          <target state="translated">此缩放器移除中位数,并根据分位数范围对数据进行缩放(默认为IQR:四分位数范围)。IQR是第1个四分位数(25分位数)和第3个四分位数(75分位数)之间的范围。</target>
        </trans-unit>
        <trans-unit id="d9994b645c162ae9e80a2c6bc1c81390f2e92325" translate="yes" xml:space="preserve">
          <source>This Warning is used in meta estimators GridSearchCV and RandomizedSearchCV and the cross-validation helper function cross_val_score to warn when there is an error while fitting the estimator.</source>
          <target state="translated">这个Warning用于元估计器GridSearchCV和RandomizedSearchCV以及交叉验证辅助函数cross_val_score中,当拟合估计器时出现错误时,会发出警告。</target>
        </trans-unit>
        <trans-unit id="7f5e3d23312509826c13f1663d34b7e7912ac4af" translate="yes" xml:space="preserve">
          <source>This algorithm can be viewed as an instance or data reduction method, since it reduces the input data to a set of subclusters which are obtained directly from the leaves of the CFT. This reduced data can be further processed by feeding it into a global clusterer. This global clusterer can be set by &lt;code&gt;n_clusters&lt;/code&gt;. If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the subclusters from the leaves are directly read off, otherwise a global clustering step labels these subclusters into global clusters (labels) and the samples are mapped to the global label of the nearest subcluster.</source>
          <target state="translated">该算法可以视为一种实例或数据约简方法，因为它将输入数据缩减为一组直接从CFT的叶获得的子簇。减少的数据可以通过将其馈送到全局群集器中进行进一步处理。可以由 &lt;code&gt;n_clusters&lt;/code&gt; 设置此全局群集器。如果 &lt;code&gt;n_clusters&lt;/code&gt; 设置为None，则直接读取叶子中的子集群，否则全局聚类步骤将这些子集群标记为全局集群（标签），并将样本映射到最近的子集群的全局标签。</target>
        </trans-unit>
        <trans-unit id="895ec6bb1e64f58ea59b9ae781fa620e703125a9" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">该算法涵盖了文献中的几篇著作。当将数据集的随机子集绘制为样本的随机子集时，该算法称为&amp;ldquo;粘贴&amp;rdquo; &lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。如果抽取样本进行替换，则该方法称为Bagging &lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;。当将数据集的随机子集绘制为要素的随机子集时，该方法称为随机子空间&lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;。最后，当基于样本和特征的子集建立基础估计量时，该方法称为随机补丁&lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="870122c945d57891e89c2ba931542331f1b4afdb" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">该算法涵盖了文献中的几篇著作。当将数据集的随机子集绘制为样本的随机子集时，该算法称为&amp;ldquo;粘贴&amp;rdquo; &lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。如果抽取样本进行替换，则该方法称为Bagging &lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;。当将数据集的随机子集绘制为要素的随机子集时，该方法称为随机子空间&lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;。最后，当基于样本和特征的子集建立基础估计量时，该方法称为随机补丁&lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="866e774dfaaba96a720c3090067c49c13cac935f" translate="yes" xml:space="preserve">
          <source>This algorithm finds a (usually very good) approximate truncated singular value decomposition using randomization to speed up the computations. It is particularly fast on large matrices on which you wish to extract only a small number of components. In order to obtain further speed up, &lt;code&gt;n_iter&lt;/code&gt; can be set &amp;lt;=2 (at the cost of loss of precision).</source>
          <target state="translated">该算法使用随机化找到（通常非常好）近似的截断奇异值分解，以加快计算速度。对于只希望提取少量成分的大型矩阵，该方法特别快。为了获得进一步的加速，可以将 &lt;code&gt;n_iter&lt;/code&gt; 设置为&amp;lt;= 2（以牺牲精度为代价）。</target>
        </trans-unit>
        <trans-unit id="c5eff13aab5e02ba6e328f932a803b28ba41ee60" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size * n_features&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.</source>
          <target state="translated">该算法具有恒定的内存复杂性，其数量约为 &lt;code&gt;batch_size * n_features&lt;/code&gt; ，从而可以使用np.memmap文件，而无需将整个文件加载到内存中。对于稀疏矩阵，将输入分批转换为密集矩阵（以便能够减去均值），这避免了在任何时候存储整个密集矩阵。</target>
        </trans-unit>
        <trans-unit id="77977d31f5357c834112cbb27bbc98b5c64c10d7" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory.</source>
          <target state="translated">该算法具有恒定的内存复杂性，大约为 &lt;code&gt;batch_size&lt;/code&gt; ，从而可以使用np.memmap文件，而无需将整个文件加载到内存中。</target>
        </trans-unit>
        <trans-unit id="f443979a9a019e4d6947465617b7828e98c7b59f" translate="yes" xml:space="preserve">
          <source>This algorithm is illustrated below.</source>
          <target state="translated">这种算法如下图所示。</target>
        </trans-unit>
        <trans-unit id="9586aed3b1a5b6a2c44b32af5cc0558b6ad496a6" translate="yes" xml:space="preserve">
          <source>This algorithm solves the normalized cut for k=2: it is a normalized spectral clustering.</source>
          <target state="translated">该算法解决了k=2的归一化切割:是一种归一化谱聚类。</target>
        </trans-unit>
        <trans-unit id="01c65a021c885e4e00baaaa5c6652a314a97daa3" translate="yes" xml:space="preserve">
          <source>This algorithm will always use all the components it has access to, needing held-out data or information theoretical criteria to decide how many components to use in the absence of external cues.</source>
          <target state="translated">这种算法总是会使用它能获得的所有组件,在没有外部线索的情况下,需要持出数据或信息理论标准来决定使用多少组件。</target>
        </trans-unit>
        <trans-unit id="ddf04fe856314e7dd4ddddf49f4086029e04d842" translate="yes" xml:space="preserve">
          <source>This allows better model selection than probabilistic PCA in the presence of heteroscedastic noise:</source>
          <target state="translated">这使得在存在异质噪声的情况下,模型选择比概率PCA更好。</target>
        </trans-unit>
        <trans-unit id="3307a2458ebbefda8ea7fe8b898077ec4cadcf2c" translate="yes" xml:space="preserve">
          <source>This also works where final estimator is &lt;code&gt;None&lt;/code&gt;: all prior transformations are applied.</source>
          <target state="translated">这在最终估计器为 &lt;code&gt;None&lt;/code&gt; 的情况下也适用：所有先前的转换都将应用。</target>
        </trans-unit>
        <trans-unit id="c63b80512d8853cd76b24210ee07543da5c60fc4" translate="yes" xml:space="preserve">
          <source>This assumption is the base of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;Vector Space Model&lt;/a&gt; often used in text classification and clustering contexts.</source>
          <target state="translated">这个假设是&lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;向量空间模型&lt;/a&gt;的基础，向量模型通常用于文本分类和聚类上下文中。</target>
        </trans-unit>
        <trans-unit id="a8d2386009078ecaad8deb62662ebfbef6798072" translate="yes" xml:space="preserve">
          <source>This attribute is not available if &lt;code&gt;refit&lt;/code&gt; is a function.</source>
          <target state="translated">如果 &lt;code&gt;refit&lt;/code&gt; 是函数，则此属性不可用。</target>
        </trans-unit>
        <trans-unit id="8142b653ecd3322ad782e8a8807635d6c4c0325e" translate="yes" xml:space="preserve">
          <source>This calibration results in a lower log-loss. Note that an alternative would have been to increase the number of base estimators which would have resulted in a similar decrease in log-loss.</source>
          <target state="translated">这种校准的结果是降低对数损失。请注意,一个替代办法是增加基础估计器的数量,这将导致对数损失的类似减少。</target>
        </trans-unit>
        <trans-unit id="3ba422e075fa10216e381bf46530abda4e719fab" translate="yes" xml:space="preserve">
          <source>This call requires the estimation of a p x q matrix, which may be an issue in high dimensional space.</source>
          <target state="translated">此调用需要估计一个p x q矩阵,这在高维空间中可能是一个问题。</target>
        </trans-unit>
        <trans-unit id="345a3bd30c8553d3251f728b344d1bd100958670" translate="yes" xml:space="preserve">
          <source>This can be confirmed on a independent testing set with similar remarks:</source>
          <target state="translated">这一点可以在独立的测试集上用类似的说法来证实。</target>
        </trans-unit>
        <trans-unit id="e60927eda9d0f07135f56fa39eaa1a8f1f9c2813" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#id2&quot;&gt;Ridge Regression&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the parameters \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="translated">这可以通过在模型的超参数上引入无信息的&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;先验&lt;/a&gt;来完成。&lt;a href=&quot;#id2&quot;&gt;Ridge回归中&lt;/a&gt;使用的\（\ ell_ {2} \）正则化等效于在精度为\（\ lambda ^ {-1} \）的参数\（w \）下，在高斯条件下找到最大后验估计。代替手动设置 &lt;code&gt;lambda&lt;/code&gt; ，可以将其视为要从数据中估计的随机变量。</target>
        </trans-unit>
        <trans-unit id="bdd26b00d9d2e1f23dcd81c9f002391507919ff9" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the coefficients \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="translated">这可以通过在模型的超参数上引入无信息的&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;先验&lt;/a&gt;来完成。&lt;a href=&quot;#ridge-regression&quot;&gt;Ridge回归和分类中&lt;/a&gt;使用的\（\ ell_ {2} \）正则化等效于在精度为\（\ lambda ^ {-1} \ ）。代替手动设置 &lt;code&gt;lambda&lt;/code&gt; ，可以将其视为要从数据中估计的随机变量。</target>
        </trans-unit>
        <trans-unit id="aa181018cfeb3219e1e67073f9c58ca90a0c4faa" translate="yes" xml:space="preserve">
          <source>This can be done by using the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; utility function.</source>
          <target state="translated">这可以通过使用&lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt;实用程序函数来完成。</target>
        </trans-unit>
        <trans-unit id="821e5435b62e56a883478da64d6731f6479103d5" translate="yes" xml:space="preserve">
          <source>This can be set to a higher value than the actual number of features in any of the input files, but setting it to a lower value will cause an exception to be raised.</source>
          <target state="translated">这个值可以设置为比任何一个输入文件中的实际特征数更高的值,但设置为较低的值会导致异常发生。</target>
        </trans-unit>
        <trans-unit id="4a0bd36c1ccd6d51b38a900236d58695657d5aff" translate="yes" xml:space="preserve">
          <source>This class allows to infer an approximate posterior distribution over the parameters of a Gaussian mixture distribution. The effective number of components can be inferred from the data.</source>
          <target state="translated">这类方法可以推断出高斯混合分布参数的近似后验分布。可以从数据中推断出有效的成分数。</target>
        </trans-unit>
        <trans-unit id="6130cf2c7564234b715447525f16ff596ebe842e" translate="yes" xml:space="preserve">
          <source>This class can be used to cross-validate time series data samples that are observed at fixed time intervals.</source>
          <target state="translated">该类可用于交叉验证以固定时间间隔观测的时间序列数据样本。</target>
        </trans-unit>
        <trans-unit id="88afb4091eb2a25b2e2017ee8508b1ff5c5ae125" translate="yes" xml:space="preserve">
          <source>This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.</source>
          <target state="translated">该类实现了一个元估计器,它可以在数据集的不同子样本上拟合一些随机化决策树(也就是额外树),并使用平均法来提高预测精度和控制过度拟合。</target>
        </trans-unit>
        <trans-unit id="dd60f6580be8e1908408c4fbfd8d3915f46e55b1" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.</source>
          <target state="translated">该类使用liblinear、newton-cg、sag和lbfgs优化器实现逻辑回归。newton-cg、sag和lbfgs求解器只支持L2正则化,采用原始公式。liblinear解算器同时支持L1和L2正则化,仅对L2罚则采用双公式。</target>
        </trans-unit>
        <trans-unit id="44487ffdb33876a6a42d281dea9cfa59f8e7af24" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. Elastic-Net penalty is only supported by the saga solver.</source>
          <target state="translated">该类使用liblinear、newton-cg、sag和lbfgs优化器实现逻辑回归。newton-cg、sag和lbfgs求解器只支持L2正则化,采用原始公式。liblinear求解器同时支持L1和L2正则化,只支持L2罚则的双重公式。Elastic-Net罚则只有saga求解器支持。</target>
        </trans-unit>
        <trans-unit id="350693d0493245dcbd676a8f10e001d5020f745e" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="translated">此类使用'liblinear'库，'newton-cg'，'sag'和'lbfgs'求解器实现正则逻辑回归。它可以处理密集和稀疏输入。使用C排序数组或包含64位浮点数的CSR矩阵可获得最佳性能；其他任何输入格式将被转换（并复制）。</target>
        </trans-unit>
        <trans-unit id="7a8a7622df62d8a1b619a206bf179dc5e9e851ab" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. &lt;strong&gt;Note that regularization is applied by default&lt;/strong&gt;. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="translated">此类使用'liblinear'库，'newton-cg'，'sag'，'saga'和'lbfgs'求解器实现正则逻辑回归。&lt;strong&gt;请注意，默认情况下将应用正则化&lt;/strong&gt;。它可以处理密集和稀疏输入。使用C排序的数组或包含64位浮点数的CSR矩阵可获得最佳性能。其他任何输入格式将被转换（并复制）。</target>
        </trans-unit>
        <trans-unit id="2c107aea4a3526193efe1f31d97ccab92891d87f" translate="yes" xml:space="preserve">
          <source>This class implements the Graphical Lasso algorithm.</source>
          <target state="translated">该类实现了图形化的Lasso算法。</target>
        </trans-unit>
        <trans-unit id="456e7e6f7be68de425401d6f66fe28d8a1090538" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost-SAMME [2].</source>
          <target state="translated">这个类实现了被称为AdaBoost-SAMME的算法[2]。</target>
        </trans-unit>
        <trans-unit id="003b6bf538c58eeda3c6fd28b21967bfd8b6c40e" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost.R2 [2].</source>
          <target state="translated">这个类实现了被称为AdaBoost.R2的算法[2]。</target>
        </trans-unit>
        <trans-unit id="63c4b52b10df12140782204ea7cf58fe0edab9de" translate="yes" xml:space="preserve">
          <source>This class implements two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data.</source>
          <target state="translated">该类实现了两种类型的权重分布的先验:一种是Dirichlet分布的有限混合模型,另一种是Dirichlet过程的无限混合模型。在实践中Dirichlet Process推理算法是近似的,并使用一个固定的最大分量数的截断分布(称为棒破表示)。实际使用的分量数几乎总是取决于数据。</target>
        </trans-unit>
        <trans-unit id="e15e7e7d8d04d41fdd2a4f34183baa0366e86dea" translate="yes" xml:space="preserve">
          <source>This class inherits from PLS with mode=&amp;rdquo;A&amp;rdquo; and deflation_mode=&amp;rdquo;canonical&amp;rdquo;, norm_y_weights=True and algorithm=&amp;rdquo;nipals&amp;rdquo;, but svd should provide similar results up to numerical errors.</source>
          <target state="translated">此类从PLS继承，其模式为&amp;ldquo; A&amp;rdquo;且deflation_mode =&amp;ldquo; canonical&amp;rdquo;，norm_y_weights = True，algorithm =&amp;ldquo; nipals&amp;rdquo;，但svd应该提供类似的结果，直至出现数值错误。</target>
        </trans-unit>
        <trans-unit id="a0a1d1daa83e6ad727cb13fd589f28f37b44df20" translate="yes" xml:space="preserve">
          <source>This class inherits from both ValueError and AttributeError to help with exception handling and backward compatibility.</source>
          <target state="translated">该类继承自ValueError和AttributeError,以帮助异常处理和向后兼容。</target>
        </trans-unit>
        <trans-unit id="d34b4e0a14d3a494edeba399329a47fb49b3ee6c" translate="yes" xml:space="preserve">
          <source>This class is a low-memory alternative to DictVectorizer and CountVectorizer, intended for large-scale (online) learning and situations where memory is tight, e.g. when running prediction code on embedded devices.</source>
          <target state="translated">该类是DictVectorizer和CountVectorizer的低内存替代品,适用于大规模(在线)学习和内存紧张的情况,例如在嵌入式设备上运行预测代码时。</target>
        </trans-unit>
        <trans-unit id="8e34d865883b535f68990f01a240eaab9f87f080" translate="yes" xml:space="preserve">
          <source>This class is hence suitable for use in the early steps of a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">因此，此类适合在&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;的早期步骤中使用：</target>
        </trans-unit>
        <trans-unit id="eef0760dd6d25fd731b9abce61656453bb690cee" translate="yes" xml:space="preserve">
          <source>This class is useful when the behavior of &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt; is desired, but the number of groups is large enough that generating all possible partitions with \(P\) groups withheld would be prohibitively expensive. In such a scenario, &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt;&lt;code&gt;GroupShuffleSplit&lt;/code&gt;&lt;/a&gt; provides a random sample (with replacement) of the train / test splits generated by &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">当需要使用&lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt;的行为时，此类非常有用，但是组的数量足够大，以至于生成所有可能的分区并保留\（P \）组将非常昂贵。在这种情况下，&lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt; &lt;code&gt;GroupShuffleSplit&lt;/code&gt; &lt;/a&gt;提供了由&lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt;生成的训练/测试拆分的随机样本（带有替换）。</target>
        </trans-unit>
        <trans-unit id="9d924f7a026f05763f1c88ce464db057fdea146c" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;a href=&quot;#sklearn.neighbors.DistanceMetric.get_metric&quot;&gt;&lt;code&gt;get_metric&lt;/code&gt;&lt;/a&gt; class method and the metric string identifier (see below).</source>
          <target state="translated">此类为快速距离度量功能提供了统一的接口。可以通过&lt;a href=&quot;#sklearn.neighbors.DistanceMetric.get_metric&quot;&gt; &lt;code&gt;get_metric&lt;/code&gt; &lt;/a&gt;类方法和度量标准字符串标识符（请参见下文）访问各种度量标准。</target>
        </trans-unit>
        <trans-unit id="edf4c29bfa2afe43016dc0b6660ad50132bd51ec" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;code&gt;get_metric&lt;/code&gt; class method and the metric string identifier (see below). For example, to use the Euclidean distance:</source>
          <target state="translated">此类为快速距离度量功能提供统一的接口。可以通过 &lt;code&gt;get_metric&lt;/code&gt; 类方法和度量标准字符串标识符（请参见下文）访问各种度量标准。例如，使用欧几里得距离：</target>
        </trans-unit>
        <trans-unit id="336f533fd7cf96bc18f597ff7211d31f0cd62386" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.</source>
          <target state="translated">该类支持密集和稀疏输入,多类支持按照onevstherest方案处理。</target>
        </trans-unit>
        <trans-unit id="aebcf6792861578bf4b4a69a0be71898d4023b6a" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input.</source>
          <target state="translated">该类支持密集和稀疏输入。</target>
        </trans-unit>
        <trans-unit id="4042c6697e9df3310aa51f4f2bbe289c3d222c6e" translate="yes" xml:space="preserve">
          <source>This class turns sequences of symbolic feature names (strings) into scipy.sparse matrices, using a hash function to compute the matrix column corresponding to a name. The hash function employed is the signed 32-bit version of Murmurhash3.</source>
          <target state="translated">该类将符号特征名称(字符串)序列转化为scipy.sparse矩阵,使用哈希函数计算名称对应的矩阵列。采用的哈希函数是Murmurhash3的签名32位版本。</target>
        </trans-unit>
        <trans-unit id="afb2ca6e635ea8a6abf9d5cec38428c8ecdc147c" translate="yes" xml:space="preserve">
          <source>This classification dataset is constructed by taking a multi-dimensional standard normal distribution and defining classes separated by nested concentric multi-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">这个分类数据集的构建方法是采用一个多维标准正态分布,并通过嵌套的多维同心球来定义类,使每个类中的样本数量大致相等(量子数的分布)。</target>
        </trans-unit>
        <trans-unit id="db081d4f3b8473550c6831dd235016867584f8ea" translate="yes" xml:space="preserve">
          <source>This classifier first converts the target values into &lt;code&gt;{-1, 1}&lt;/code&gt; and then treats the problem as a regression task (multi-output regression in the multiclass case).</source>
          <target state="translated">该分类器首先将目标值转换为 &lt;code&gt;{-1, 1}&lt;/code&gt; ，然后将问题视为回归任务（在多类情况下为多输出回归）。</target>
        </trans-unit>
        <trans-unit id="9c043eb0cb49ef78462962da4adb4099e130c09c" translate="yes" xml:space="preserve">
          <source>This classifier is sometimes referred to as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Least-squares_support-vector_machine&quot;&gt;Least Squares Support Vector Machines&lt;/a&gt; with a linear kernel.</source>
          <target state="translated">该分类器有时被称为带有线性核的&lt;a href=&quot;https://en.wikipedia.org/wiki/Least-squares_support-vector_machine&quot;&gt;最小二乘支持向量机&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a35e593acabc67ebdf8fae8d0484d5f85056d4a7" translate="yes" xml:space="preserve">
          <source>This classifier is useful as a simple baseline to compare with other (real) classifiers. Do not use it for real problems.</source>
          <target state="translated">这个分类器可以作为一个简单的基线与其他(真实)分类器进行比较。不要用它来解决实际问题。</target>
        </trans-unit>
        <trans-unit id="4ceac36d1efc9bb429dd84350330a84101bb5c8c" translate="yes" xml:space="preserve">
          <source>This classifier lost over a lot of its F-score, just because we removed metadata that has little to do with topic classification. It loses even more if we also strip this metadata from the training data:</source>
          <target state="translated">这个分类器损失了很多F-score,只是因为我们去掉了与主题分类关系不大的元数据。如果我们把这些元数据也从训练数据中剥离出来,它的损失就更大了。</target>
        </trans-unit>
        <trans-unit id="064e5da463cfecd3ca166c4023a79d0a6500160d" translate="yes" xml:space="preserve">
          <source>This combination is implementing in &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt;, a transformer class that is mostly API compatible with &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; is stateless, meaning that you don&amp;rsquo;t have to call &lt;code&gt;fit&lt;/code&gt; on it:</source>
          <target state="translated">这种结合是在&lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; 中&lt;/a&gt;实现的，HashingVectorizer是一种转换器类，主要与&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; API兼容。&lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt;是无状态的，这意味着你不必调用 &lt;code&gt;fit&lt;/code&gt; 就可以了：</target>
        </trans-unit>
        <trans-unit id="1d56591f4aa7f0ebb864c2d8835af7dfb7f8f26b" translate="yes" xml:space="preserve">
          <source>This combines the values of agglomerated features into a single value, and should accept an array of shape [M, N] and the keyword argument &lt;code&gt;axis=1&lt;/code&gt;, and reduce it to an array of size [M].</source>
          <target state="translated">它将聚集的要素的值合并为一个值，并应接受形状为[M，N]且关键字参数 &lt;code&gt;axis=1&lt;/code&gt; 的数组，并将其减小为大小[M]的数组。</target>
        </trans-unit>
        <trans-unit id="26c788fe31e79bd1bbf24fbba8a1b8342ff15ce1" translate="yes" xml:space="preserve">
          <source>This consumes less memory than shuffling the data directly.</source>
          <target state="translated">这比直接洗牌数据消耗的内存更少。</target>
        </trans-unit>
        <trans-unit id="9c8cf431c4f1299ae41612f84a50a597aa4a1059" translate="yes" xml:space="preserve">
          <source>This creates binary hashes of input data points by getting the dot product of input points and hash_function then transforming the projection into a binary string array based on the sign (positive/negative) of the projection. A sorted array of binary hashes is created.</source>
          <target state="translated">该函数通过获取输入点的点积和hash_function,然后根据投影的符号(正/负)将投影转化为二进制字符串数组,从而创建输入数据点的二进制哈希。一个经过排序的二进制哈希数组就创建完成了。</target>
        </trans-unit>
        <trans-unit id="75f340063df2a6996986c297d7d4423dc4417e05" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">这个交叉验证对象是StratifiedKFold和ShuffleSplit的合并,它返回的是分层随机化的褶皱。褶皱是通过保留每类样本的百分比来进行的。</target>
        </trans-unit>
        <trans-unit id="ab90d891a9b7f61040a0bd2fc78eae2488d53a3a" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;. In the kth split, it returns first k folds as train set and the (k+1)th fold as test set.</source>
          <target state="translated">此交叉验证对象是&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;的变体。在第k次拆分中，它返回前k个折叠作为训练集，第（k + 1）个折叠作为测试集。</target>
        </trans-unit>
        <trans-unit id="c3d6a6171342c06e134b7087a7e83e3f80ba8a79" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">这个交叉验证对象是KFold的一个变体,它可以返回分层褶皱。褶皱是通过保留每类样本的百分比来制作的。</target>
        </trans-unit>
        <trans-unit id="2c34ca372157ddad0d3d18ffb66a8717775276f6" translate="yes" xml:space="preserve">
          <source>This data sets consists of 3 different types of irises&amp;rsquo; (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray</source>
          <target state="translated">此数据集由3种不同类型的虹膜（Setosa，Versicolour和Virginica）的花瓣和萼片长度组成，存储在150x4 numpy中。</target>
        </trans-unit>
        <trans-unit id="158d23b76a72fb850a277110200a4b319b51d7f5" translate="yes" xml:space="preserve">
          <source>This database is also available through the UW CS ftp server:</source>
          <target state="translated">这个数据库也可以通过UW CS ftp服务器获得。</target>
        </trans-unit>
        <trans-unit id="8f0ed5f875aa21e65ca9d6116dc0e918ff34c0ff" translate="yes" xml:space="preserve">
          <source>This dataset consists of 20,640 samples and 9 features.</source>
          <target state="translated">该数据集由20,640个样本和9个特征组成。</target>
        </trans-unit>
        <trans-unit id="2e15d3adbea56bdf31e76cb4ee55fcf6dfb7c05f" translate="yes" xml:space="preserve">
          <source>This dataset is a collection of JPEG pictures of famous people collected over the internet, all details are available on the official website:</source>
          <target state="translated">这个数据集是通过网络收集的名人JPEG图片,所有细节都可以在官方网站上找到。</target>
        </trans-unit>
        <trans-unit id="1c0b9129c637e05601004735cb7bfdbdba431796" translate="yes" xml:space="preserve">
          <source>This dataset is described in Celeux et al [1]. as:</source>
          <target state="translated">这个数据集在Celeux等人[1]中描述为。</target>
        </trans-unit>
        <trans-unit id="e92704f97c6e77c413a0405e7cf7dd2e32191660" translate="yes" xml:space="preserve">
          <source>This dataset is described in Friedman [1] and Breiman [2].</source>
          <target state="translated">这个数据集在Friedman[1]和Breiman[2]中描述。</target>
        </trans-unit>
        <trans-unit id="473d3b557a1c23b381f633c2c2acf0c38c2a328f" translate="yes" xml:space="preserve">
          <source>This dataset is made up of 1797 8x8 images. Each image, like the one shown below, is of a hand-written digit. In order to utilize an 8x8 figure like this, we&amp;rsquo;d have to first transform it into a feature vector with length 64.</source>
          <target state="translated">该数据集由1797张8x8图像组成。每个图像（如下图所示）都是手写数字。为了利用这样的8x8图形，我们必须首先将其转换为长度为64的特征向量。</target>
        </trans-unit>
        <trans-unit id="39a3f4ca0d0c444ed57d3ff159dafbaf0cf5d2c9" translate="yes" xml:space="preserve">
          <source>This dataset is suitable for multi-ouput regression tasks.</source>
          <target state="translated">该数据集适用于多输出回归任务。</target>
        </trans-unit>
        <trans-unit id="73cdbbbbdb25af126933f658f4b065e86b9c1a55" translate="yes" xml:space="preserve">
          <source>This dataset represents the geographic distribution of species. The dataset is provided by Phillips et. al. (2006).</source>
          <target state="translated">该数据集代表了物种的地理分布。该数据集由Phillips等人(2006)提供。(2006).</target>
        </trans-unit>
        <trans-unit id="e72397d5f7691c5c60df49442bb007cee4717786" translate="yes" xml:space="preserve">
          <source>This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).</source>
          <target state="translated">这个数据集来自1990年美国人口普查,每个人口普查区组使用一行。街区组是美国人口普查局公布样本数据的最小地理单位(一个街区组的人口通常为600至3 000人)。</target>
        </trans-unit>
        <trans-unit id="47bf559cf1abc9fb33a96a120f583ad0bcd0f9f8" translate="yes" xml:space="preserve">
          <source>This dataset was obtained from the StatLib repository. &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</source>
          <target state="translated">该数据集是从StatLib存储库获得的。&lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4668c093fae272aec3196fc6d39e4e5a4eede980" translate="yes" xml:space="preserve">
          <source>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</source>
          <target state="translated">这个数据集来自卡内基梅隆大学维护的StatLib库。</target>
        </trans-unit>
        <trans-unit id="9b1b90be23e0adb200134bcc2570822a79ae6e88" translate="yes" xml:space="preserve">
          <source>This demonstrates Label Propagation learning a good boundary even with a small amount of labeled data.</source>
          <target state="translated">这证明了Label Propagation即使在少量标签数据的情况下也能学习到良好的边界。</target>
        </trans-unit>
        <trans-unit id="33d36bf521beb70b7b2f4b7e5d24d58f96f46c86" translate="yes" xml:space="preserve">
          <source>This description can be vectorized into a sparse two-dimensional matrix suitable for feeding into a classifier (maybe after being piped into a &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; for normalization):</source>
          <target state="translated">可以将该描述矢量化为适合输入分类器的稀疏二维矩阵（也许在将其通过管道&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;text.TfidfTransformer&lt;/code&gt; &lt;/a&gt;到text.TfidfTransformer中进行归一化之后）：</target>
        </trans-unit>
        <trans-unit id="12f7e332bc936dbb460a17349dda07780cab7782" translate="yes" xml:space="preserve">
          <source>This determines which warnings will be made in the case that this function is being used to return only one of its metrics.</source>
          <target state="translated">这决定了在这个函数被用来只返回其中一个指标的情况下,会发出哪些警告。</target>
        </trans-unit>
        <trans-unit id="a1a66d0ad9255f63c11b93170b95da4e6eeaea4f" translate="yes" xml:space="preserve">
          <source>This downscaling is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf&amp;ndash;idf&lt;/a&gt; for &amp;ldquo;Term Frequency times Inverse Document Frequency&amp;rdquo;.</source>
          <target state="translated">这种缩减称为&amp;ldquo;术语频率乘以文档的倒数频率&amp;rdquo;的&lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf&amp;ndash;idf&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="edeebc499fdf886cf2b1fe82f9cc25a148384f70" translate="yes" xml:space="preserve">
          <source>This early stopping strategy is activated if &lt;code&gt;early_stopping=True&lt;/code&gt;; otherwise the stopping criterion only uses the training loss on the entire input data. To better control the early stopping strategy, we can specify a parameter &lt;code&gt;validation_fraction&lt;/code&gt; which set the fraction of the input dataset that we keep aside to compute the validation score. The optimization will continue until the validation score did not improve by at least &lt;code&gt;tol&lt;/code&gt; during the last &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations. The actual number of iterations is available at the attribute &lt;code&gt;n_iter_&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;early_stopping=True&lt;/code&gt; ，则激活此提前停止策略；否则，停止标准仅对整个输入数据使用训练损失。为了更好地控制提前停止策略，我们可以指定一个参数 &lt;code&gt;validation_fraction&lt;/code&gt; ，该参数设置输入数据集的一部分，我们将其保留来计算验证分数。优化将继续进行，直到在最后的 &lt;code&gt;n_iter_no_change&lt;/code&gt; 迭代期间验证得分至少提高了 &lt;code&gt;tol&lt;/code&gt; 为止。实际的迭代次数在属性 &lt;code&gt;n_iter_&lt;/code&gt; 处可用。</target>
        </trans-unit>
        <trans-unit id="6528dcf2523991bd357ca56474b42d537ada09b8" translate="yes" xml:space="preserve">
          <source>This embedding can also &amp;lsquo;work&amp;rsquo; even if the &lt;code&gt;adjacency&lt;/code&gt; variable is not strictly the adjacency matrix of a graph but more generally an affinity or similarity matrix between samples (for instance the heat kernel of a euclidean distance matrix or a k-NN matrix).</source>
          <target state="translated">即使该 &lt;code&gt;adjacency&lt;/code&gt; 变量并非严格地是图的邻接矩阵，而更通常是样本之间的亲和度或相似度矩阵（例如，欧几里得距离矩阵或k-NN矩阵的热核），该嵌入也可以&amp;ldquo;起作用&amp;rdquo; 。</target>
        </trans-unit>
        <trans-unit id="ac8e43e8e0acd749c6d9f51af67c9e65cc70e9b4" translate="yes" xml:space="preserve">
          <source>This enables ducktyping by hasattr returning True according to the sub-estimator.</source>
          <target state="translated">这可以通过hasattr根据子估计器返回True来实现ducktyping。</target>
        </trans-unit>
        <trans-unit id="662188aeeffeee289aab2f0d97150266d90c022d" translate="yes" xml:space="preserve">
          <source>This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.</source>
          <target state="translated">这种编码是许多scikit-learn估计器,特别是线性模型和标准核的SVM所需要的。</target>
        </trans-unit>
        <trans-unit id="752036d9bd5ae374e975c046f504e0b38de39538" translate="yes" xml:space="preserve">
          <source>This estimator</source>
          <target state="translated">该估算器</target>
        </trans-unit>
        <trans-unit id="f8a8301fe86e970315ab1f664d0852d178958868" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="translated">该估计器允许对输入的不同列或列子集分别进行变换,每个变换器产生的特征将被连接起来形成一个单一的特征空间。这对于异构数据或列式数据非常有用,可以将多个特征提取机制或变换组合成一个变换器。</target>
        </trans-unit>
        <trans-unit id="36ceeb9f387752a577aeb048b3f21cd319ecfb48" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the results combined into a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="translated">该估计器允许对输入的不同列或列子集分别进行变换,并将结果组合成一个单一的特征空间。这对于异构数据或列式数据很有用,可以将几种特征提取机制或变换组合成一个变换器。</target>
        </trans-unit>
        <trans-unit id="02199e2b9b2bd941c7464261eedf68a6fd2d82e2" translate="yes" xml:space="preserve">
          <source>This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer.</source>
          <target state="translated">该估计器将一个变压器对象列表并行应用到输入数据中,然后将结果连在一起。这对于将几种特征提取机制结合到一个变换器中非常有用。</target>
        </trans-unit>
        <trans-unit id="a93ab3d6ae360c030a56bd4fabca46c42abdaf54" translate="yes" xml:space="preserve">
          <source>This estimator approximates a slightly different version of the additive chi squared kernel then &lt;code&gt;metric.additive_chi2&lt;/code&gt; computes.</source>
          <target state="translated">此估算器近似近似加和卡方内核的版本，然后由 &lt;code&gt;metric.additive_chi2&lt;/code&gt; 计算。</target>
        </trans-unit>
        <trans-unit id="53ea424698dba4ed1ec741d2d0ce2fbd09225a41" translate="yes" xml:space="preserve">
          <source>This estimator can be used to model different GLMs depending on the &lt;code&gt;power&lt;/code&gt; parameter, which determines the underlying distribution.</source>
          <target state="translated">该估计器可用于根据 &lt;code&gt;power&lt;/code&gt; 参数对不同的GLM建模，而功率参数决定了基础分布。</target>
        </trans-unit>
        <trans-unit id="57f1dab8dd3e838e06f9128461ff865667eb2891" translate="yes" xml:space="preserve">
          <source>This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">该估计器内置了对多变量回归的支持(即当y是一个形状为[n_samples,n_targets]的二维数组时)。</target>
        </trans-unit>
        <trans-unit id="534f21211e3056d3896d05b949c661c4f992dd5f" translate="yes" xml:space="preserve">
          <source>This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.</source>
          <target state="translated">这个估计器对缺失值(NaNs)有原生支持。在训练过程中,树生长器根据潜在的收益,在每个分割点学习具有缺失值的样本是否应该被分配到左子或右子。在预测时,有缺失值的样本会因此被分配到左子或右子。如果在训练过程中没有遇到给定特征的缺失值,那么缺失值的样本就会被映射到样本最多的哪个子代。</target>
        </trans-unit>
        <trans-unit id="7130a824407818977c24f15960ee70da6f59d9ca" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the &lt;code&gt;partial_fit&lt;/code&gt; method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="translated">该估计器通过随机梯度下降（SGD）学习实现正则化线性模型：一次估计每个样本的损耗梯度，并随着强度进度表（即学习率）的降低而更新模型。SGD允许通过 &lt;code&gt;partial_fit&lt;/code&gt; 方法进行小批量（在线/核心外）学习。为了使用默认学习率计划获得最佳结果，数据应具有零均值和单位方差。</target>
        </trans-unit>
        <trans-unit id="ab45bcef3fd31ebffe9c4724334c2d64921dae44" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="translated">这个估计器用随机梯度下降(SGD)学习实现了正则化线性模型:每次每个样本都会估计损失的梯度,并在途中以递减的强度计划(也就是学习率)更新模型。SGD允许minibatch(在线/核心外)学习,参见partial_fit方法。为了使用默认的学习率时间表获得最佳效果,数据的均值和单位方差应该为零。</target>
        </trans-unit>
        <trans-unit id="7005478518d9bca348fcae966cb157ede91131ca" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="translated">对于大型数据集（n_samples&amp;gt; = 10000），此估计器比&lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;快得多。</target>
        </trans-unit>
        <trans-unit id="505ce7903463cb2537c439b476cf7830c59f9934" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="translated">对于大型数据集（n_samples&amp;gt; = 10000），此估计器比&lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;快得多。</target>
        </trans-unit>
        <trans-unit id="5fdb17bfdb14f498d9377f8ca9b7cc2199a41d7f" translate="yes" xml:space="preserve">
          <source>This estimator is stateless (besides constructor parameters), the fit method does nothing but is useful when used in a pipeline.</source>
          <target state="translated">这个估计器是无状态的(除了构造函数参数),拟合方法什么都不做,但在管道中使用时很有用。</target>
        </trans-unit>
        <trans-unit id="b10e025b81eb3a8b5b21ad615292ad7338f1e2a3" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: default parameters or details of behaviour might change without any deprecation cycle. Resolving the following issues would help stabilize &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt;: convergence criteria (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14338&quot;&gt;#14338&lt;/a&gt;), default estimators (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/13286&quot;&gt;#13286&lt;/a&gt;), and use of random state (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/15611&quot;&gt;#15611&lt;/a&gt;). To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;.</source>
          <target state="translated">此估算器目前仍处于&lt;strong&gt;试验阶段&lt;/strong&gt;：默认参数或行为细节可能会更改，而不会发生任何弃用周期。解决以下问题将有助于稳定&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; &lt;/a&gt;：收敛标准（&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14338&quot;&gt;＃14338&lt;/a&gt;），默认估计量（&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/13286&quot;&gt;＃13286&lt;/a&gt;）和随机状态的使用（&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/15611&quot;&gt;＃15611&lt;/a&gt;）。要使用它，您需要显式导入 &lt;code&gt;enable_iterative_imputer&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3ba8a49b5a7145a75b81ed477df1577dc2f0d079" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="translated">此估算器目前仍处于&lt;strong&gt;试验阶段&lt;/strong&gt;：预测和API可能会发生变化，而不会发生任何弃用周期。要使用它，您需要显式导入 &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="7c7878b26bf7f32e88e4f83c2d2d772f7f3023cd" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;:</source>
          <target state="translated">此估算器目前仍处于&lt;strong&gt;试验阶段&lt;/strong&gt;：预测和API可能会发生变化，而不会发生任何弃用周期。要使用它，您需要显式导入 &lt;code&gt;enable_iterative_imputer&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="d8c9fb1adc7eae2561c12b442ef315ae822391e8" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.</source>
          <target state="translated">这个估计器对每个特征进行单独的缩放和转换,使其在训练集上处于给定的范围内,例如在零和一之间。</target>
        </trans-unit>
        <trans-unit id="42d08f109b32ce107e9f058e7449521b0b6eab28" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one.</source>
          <target state="translated">这个估计器对每个特征进行单独的缩放和翻译,使其在训练集上处于给定的范围内,即在零和一之间。</target>
        </trans-unit>
        <trans-unit id="ce7850baf5a7a3e7ef75716db2d2e4af71c92137" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.</source>
          <target state="translated">这个估计器对每个特征进行单独的缩放和翻译,使训练集中每个特征的最大绝对值为1.0。它不会移动/中心数据,因此不会破坏任何稀疏性。</target>
        </trans-unit>
        <trans-unit id="0ff92b3f8e56701f386ccbc5279ec5fdb2974bc0" translate="yes" xml:space="preserve">
          <source>This estimator scales each feature individually such that the maximal absolute value of each feature in the training set will be 1.0.</source>
          <target state="translated">该估计器对每个特征进行单独缩放,使训练集中每个特征的最大绝对值将为1.0。</target>
        </trans-unit>
        <trans-unit id="354214ed410106228bbb593cd82a49f32a2508f8" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on (X * X.T) or (X.T * X), whichever is more efficient.</source>
          <target state="translated">该估计器支持两种算法：快速随机SVD求解器和&amp;ldquo;天真&amp;rdquo;算法，该算法使用ARPACK作为（X * XT）或（XT * X）上的本征求解器，以效率较高的一种为准。</target>
        </trans-unit>
        <trans-unit id="0a991e8d6eff0a5b7f5a276b54be6da66c4dae45" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on &lt;code&gt;X * X.T&lt;/code&gt; or &lt;code&gt;X.T * X&lt;/code&gt;, whichever is more efficient.</source>
          <target state="translated">此估算器支持两种算法：快速随机SVD求解器和&amp;ldquo;天真&amp;rdquo;算法，该算法使用ARPACK作为 &lt;code&gt;X * X.T&lt;/code&gt; 或 &lt;code&gt;X.T * X&lt;/code&gt; 的特征求解器，以效率更高的一种为准。</target>
        </trans-unit>
        <trans-unit id="438c738ad18e280c91d7884cd24490873bfed375" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc, making sure that the estimator complies with &lt;code&gt;scikit-learn&lt;/code&gt; conventions as detailed in &lt;a href=&quot;https://scikit-learn.org/0.23/developers/develop.html#rolling-your-own-estimator&quot;&gt;Rolling your own estimator&lt;/a&gt;. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="translated">该估计器将运行广泛的测试套件以进行输入验证，形状等，确保该估计器符合 &lt;code&gt;scikit-learn&lt;/code&gt; 约定，如&lt;a href=&quot;https://scikit-learn.org/0.23/developers/develop.html#rolling-your-own-estimator&quot;&gt;滚动您自己的估计器中所述&lt;/a&gt;。如果Estimator类从sklearn.base的相应mixin继承，则将运行针对分类器，回归器，聚类或转换器的附加测试。</target>
        </trans-unit>
        <trans-unit id="3ed5861f671a7b7a1c102cd9c37c8bf2e273de13" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="translated">该估计器将运行一个广泛的测试套件,用于输入验证、形状等。如果Estimator类继承了sklearn.base的相应mixin,则将运行分类器、回归器、聚类或变换器的额外测试。</target>
        </trans-unit>
        <trans-unit id="7011f5e2b484f266188acd0aba4f3d3175f11ed0" translate="yes" xml:space="preserve">
          <source>This example also shows the usefulness of applying Ridge regression to highly ill-conditioned matrices. For such matrices, a slight change in the target variable can cause huge variances in the calculated weights. In such cases, it is useful to set a certain regularization (alpha) to reduce this variation (noise).</source>
          <target state="translated">这个例子还显示了将Ridge回归应用于高度不符合条件的矩阵的有用性。对于这样的矩阵,目标变量的轻微变化都会导致计算出的权重出现巨大的变异。在这种情况下,设置一定的正则化(alpha)来减少这种变异(噪声)是很有用的。</target>
        </trans-unit>
        <trans-unit id="66087b50dbc537ea3a892d00ee467bc12eeadd33" translate="yes" xml:space="preserve">
          <source>This example applies to &lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;The Olivetti faces dataset&lt;/a&gt; different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="translated">此示例适用于&lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;Olivetti面数据集&lt;/a&gt;，该数据集来自模块&lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; 的&lt;/a&gt;不同无监督矩阵分解（降维）方法（请参阅文档一章&amp;ldquo;&lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;分解组件中的信号（矩阵分解问题）&amp;rdquo;&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="7f82721c4674480adff4241dbcac8e543f16c868" translate="yes" xml:space="preserve">
          <source>This example applies to olivetti_faces different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="translated">此示例适用于olivetti_faces从模块不同的无监督矩阵分解（降维）方法&lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; &lt;/a&gt;（参见文档章节&lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;中部件分解的信号（矩阵因式分解问题）&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="209229078f7e258d4985eec4947d8dca83616df9" translate="yes" xml:space="preserve">
          <source>This example balances model complexity and cross-validated score by finding a decent accuracy within 1 standard deviation of the best accuracy score while minimising the number of PCA components [1].</source>
          <target state="translated">本例通过在最佳精度分数的1个标准差内找到一个像样的精度,同时尽量减少PCA组件的数量,来平衡模型复杂度和交叉验证分数[1]。</target>
        </trans-unit>
        <trans-unit id="33924f5409489cd3edd1b22f28ee011b17a585da" translate="yes" xml:space="preserve">
          <source>This example compares 2 dimensionality reduction strategies:</source>
          <target state="translated">这个例子比较了2个维度的减少策略。</target>
        </trans-unit>
        <trans-unit id="d2a9de2244899372ce613f7320d0c8868284b849" translate="yes" xml:space="preserve">
          <source>This example compares different (linear) dimensionality reduction methods applied on the Digits data set. The data set contains images of digits from 0 to 9 with approximately 180 samples of each class. Each image is of dimension 8x8 = 64, and is reduced to a two-dimensional data point.</source>
          <target state="translated">这个例子比较了应用在Digits数据集上的不同(线性)维度降低方法。该数据集包含从0到9的数字图像,每个类别大约有180个样本。每个图像的维度为8x8=64,并被还原为一个二维数据点。</target>
        </trans-unit>
        <trans-unit id="1ba8c26b14d0dc5555ed6b18d75cbed15c385668" translate="yes" xml:space="preserve">
          <source>This example compares non-nested and nested cross-validation strategies on a classifier of the iris data set. Nested cross-validation (CV) is often used to train a model in which hyperparameters also need to be optimized. Nested CV estimates the generalization error of the underlying model and its (hyper)parameter search. Choosing the parameters that maximize non-nested CV biases the model to the dataset, yielding an overly-optimistic score.</source>
          <target state="translated">这个例子比较了虹膜数据集分类器上的非嵌套和嵌套交叉验证策略。嵌套交叉验证(CV)通常用于训练一个模型,其中超参数也需要优化。嵌套CV估计基础模型及其(超)参数搜索的泛化误差。选择最大化非嵌套CV的参数会使模型对数据集产生偏差,产生过度优化的分数。</target>
        </trans-unit>
        <trans-unit id="7ef1cb506f6769f9ea8f57cc850c6090d62898eb" translate="yes" xml:space="preserve">
          <source>This example compares the timing of Birch (with and without the global clustering step) and MiniBatchKMeans on a synthetic dataset having 100,000 samples and 2 features generated using make_blobs.</source>
          <target state="translated">这个例子比较了Birch(有和没有全局聚类步骤)和MiniBatchKMeans在一个有100,000个样本和2个特征的合成数据集上使用make_blobs生成的时间。</target>
        </trans-unit>
        <trans-unit id="8901e1f5225dc1b7e06d2fabb8f06f19a3753c45" translate="yes" xml:space="preserve">
          <source>This example constructs a pipeline that does dimensionality reduction followed by prediction with a support vector classifier. It demonstrates the use of &lt;code&gt;GridSearchCV&lt;/code&gt; and &lt;code&gt;Pipeline&lt;/code&gt; to optimize over different classes of estimators in a single CV run &amp;ndash; unsupervised &lt;code&gt;PCA&lt;/code&gt; and &lt;code&gt;NMF&lt;/code&gt; dimensionality reductions are compared to univariate feature selection during the grid search.</source>
          <target state="translated">本示例构建了一个进行降维处理，然后使用支持向量分类器进行预测的管道。它演示了如何使用 &lt;code&gt;GridSearchCV&lt;/code&gt; 和 &lt;code&gt;Pipeline&lt;/code&gt; 在单个CV运行中针对不同类别的估计量进行优化-将无监督的 &lt;code&gt;PCA&lt;/code&gt; 和 &lt;code&gt;NMF&lt;/code&gt; 降维与在网格搜索过程中的单变量特征进行比较。</target>
        </trans-unit>
        <trans-unit id="ebd831df4448cf766c6eb0e33a12d358fbfa3057" translate="yes" xml:space="preserve">
          <source>This example demonstrates Gradient Boosting to produce a predictive model from an ensemble of weak predictive models. Gradient boosting can be used for regression and classification problems. Here, we will train a model to tackle a diabetes regression task. We will obtain the results from &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; with least squares loss and 500 regression trees of depth 4.</source>
          <target state="translated">此示例演示了梯度增强从一组弱预测模型中生成预测模型的过程。梯度提升可用于回归和分类问题。在这里，我们将训练一个模型来解决糖尿病的消退任务。我们将从&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; 中&lt;/a&gt;获得最小平方损失和500个深度为4的回归树的结果。</target>
        </trans-unit>
        <trans-unit id="b084d11db0bc218128b35a7afe55ac9fa7c4daf1" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to approximate a function with a polynomial of degree n_degree by using ridge regression. Concretely, from n_samples 1d points, it suffices to build the Vandermonde matrix, which is n_samples x n_degree+1 and has the following form:</source>
          <target state="translated">本例演示了如何利用岭回归来逼近一个度数为n_degree的多项式函数。具体来说,从n_samples 1d点出发,建立Vandermonde矩阵就可以了,该矩阵为n_samples x n_degree+1,其形式如下。</target>
        </trans-unit>
        <trans-unit id="8509d7895b98e9b3d2d07ed03eae90baa68f1c72" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a checkerboard dataset and bicluster it using the Spectral Biclustering algorithm.</source>
          <target state="translated">这个例子演示了如何使用Spectral Biclustering算法生成一个棋盘数据集并进行双聚类。</target>
        </trans-unit>
        <trans-unit id="fb9a20a0b6ffdb624c38c357324f211d180af27f" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a dataset and bicluster it using the Spectral Co-Clustering algorithm.</source>
          <target state="translated">这个例子演示了如何使用Spectral Co-Clustering算法生成一个数据集并进行双聚类。</target>
        </trans-unit>
        <trans-unit id="9b609f5368296ac180488994b6106bba8395b9b3" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. The choice of features is not particularly helpful, but serves to illustrate the technique.</source>
          <target state="translated">本示例演示如何在包含不同类型&lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt;的数据集上使用ColumnTransformer。功能的选择并不是特别有帮助，但是可以用来说明该技术。</target>
        </trans-unit>
        <trans-unit id="4e024e96a6e8109f327c2d890a3a85ee374e03bd" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. We use the 20-newsgroups dataset and compute standard bag-of-words features for the subject line and body in separate pipelines as well as ad hoc features on the body. We combine them (with weights) using a ColumnTransformer and finally train a classifier on the combined set of features.</source>
          <target state="translated">本示例演示如何在包含不同类型&lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt;的数据集上使用sklearn.compose.ColumnTransformer。我们使用20个新闻组数据集，并在单独的管道中为主题行和正文计算标准的词袋功能，以及正文上的临时功能。我们使用ColumnTransformer组合它们（与权重），最后在组合的特征集上训练分类器。</target>
        </trans-unit>
        <trans-unit id="76d491fec0fed042e6d7927f2dc124b698f9bded" translate="yes" xml:space="preserve">
          <source>This example demonstrates the Spectral Co-clustering algorithm on the twenty newsgroups dataset. The &amp;lsquo;comp.os.ms-windows.misc&amp;rsquo; category is excluded because it contains many posts containing nothing but data.</source>
          <target state="translated">本示例演示了二十个新闻组数据集上的频谱共聚算法。&amp;ldquo; comp.os.ms-windows.misc&amp;rdquo;类别被排除在外，因为它包含许多帖子，其中仅包含数据。</target>
        </trans-unit>
        <trans-unit id="6186f51b55d8cba756254a15fe651e5e8504791a" translate="yes" xml:space="preserve">
          <source>This example demonstrates the behavior of Gaussian mixture models fit on data that was not sampled from a mixture of Gaussian random variables. The dataset is formed by 100 points loosely spaced following a noisy sine curve. There is therefore no ground truth value for the number of Gaussian components.</source>
          <target state="translated">这个例子展示了高斯混合模型在数据上拟合的行为,这些数据不是从高斯随机变量的混合物中采样的。数据集是由100个点沿着一条有噪声的正弦曲线松散地排列而成。因此,高斯分量的数量没有基本真值。</target>
        </trans-unit>
        <trans-unit id="a1949f51dde2d60d7d4d1e707d145c1301537434" translate="yes" xml:space="preserve">
          <source>This example demonstrates the power of semisupervised learning by training a Label Spreading model to classify handwritten digits with sets of very few labels.</source>
          <target state="translated">这个例子展示了半监督学习的力量,通过训练一个Label Spreading模型来对具有极少标签集的手写数字进行分类。</target>
        </trans-unit>
        <trans-unit id="c6020c6a7334e89ced3b2c5f4b02f4ed9989e37f" translate="yes" xml:space="preserve">
          <source>This example demonstrates the problems of underfitting and overfitting and how we can use linear regression with polynomial features to approximate nonlinear functions. The plot shows the function that we want to approximate, which is a part of the cosine function. In addition, the samples from the real function and the approximations of different models are displayed. The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called &lt;strong&gt;underfitting&lt;/strong&gt;. A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will &lt;strong&gt;overfit&lt;/strong&gt; the training data, i.e. it learns the noise of the training data. We evaluate quantitatively &lt;strong&gt;overfitting&lt;/strong&gt; / &lt;strong&gt;underfitting&lt;/strong&gt; by using cross-validation. We calculate the mean squared error (MSE) on the validation set, the higher, the less likely the model generalizes correctly from the training data.</source>
          <target state="translated">此示例演示了拟合不足和拟合过度的问题，以及如何使用具有多项式特征的线性回归来近似非线性函数。该图显示了我们要近似的函数，它是余弦函数的一部分。此外，还将显示来自实函数的样本以及不同模型的近似值。这些模型具有不同程度的多项式特征。我们可以看到线性函数（阶数为1的多项式）不足以拟合训练样本。这称为&lt;strong&gt;欠拟合&lt;/strong&gt;。 4次多项式几乎完美地逼近了真函数。但是，对于更高的程度，模型将&lt;strong&gt;过度拟合&lt;/strong&gt;训练数据，即模型会学习训练数据的噪声。我们定量评估&lt;strong&gt;&lt;/strong&gt;通过使用交叉验证来&lt;strong&gt;过度拟合&lt;/strong&gt; / &lt;strong&gt;不足&lt;/strong&gt;&lt;strong&gt;拟合&lt;/strong&gt;。我们在验证集上计算均方误差（MSE），数值越高，模型从训练数据中正确推广的可能性就越小。</target>
        </trans-unit>
        <trans-unit id="a2d558b6f5e9fa98f7c27a3a7352d216289c9012" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; to map data from various distributions to a normal distribution.</source>
          <target state="translated">此示例演示了如何通过&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt; &lt;code&gt;PowerTransformer&lt;/code&gt; &lt;/a&gt;使用Box-Cox和Yeo-Johnson变换将数据从各种分布映射到正态分布。</target>
        </trans-unit>
        <trans-unit id="ab8d51c9ac9762c2930c84a5a03c1c12345a6627" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; to map data from various distributions to a normal distribution.</source>
          <target state="translated">本示例演示了通过 &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; 使用Box-Cox和Yeo-Johnson变换将数据从各种分布映射到正态分布。</target>
        </trans-unit>
        <trans-unit id="9b62ef0be0bf7ce49acab00a23e04164c0becf9d" translate="yes" xml:space="preserve">
          <source>This example does not perform any learning over the data (see &lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of classification based on the attributes in this dataset). It simply shows the kernel density estimate of observed data points in geospatial coordinates.</source>
          <target state="translated">本示例不对数据进行任何学习（有关基于此数据集中属性的分类示例，请参阅&lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;物种分布建模&lt;/a&gt;）。它仅显示了地理空间坐标中观察到的数据点的核密度估计。</target>
        </trans-unit>
        <trans-unit id="03eea75ae69c05ca0f9dc1a13d89bbd210d48145" translate="yes" xml:space="preserve">
          <source>This example doesn&amp;rsquo;t show it, as we&amp;rsquo;re in a low-dimensional space, but another advantage of the Dirichlet process model is that it can fit full covariance matrices effectively even when there are less examples per cluster than there are dimensions in the data, due to regularization properties of the inference algorithm.</source>
          <target state="translated">这个示例没有显示出来，因为我们处于低维空间，但是Dirichlet过程模型的另一个优点是，即使每个聚类中的示例少于维中的维，它也可以有效地拟合完整的协方差矩阵。数据，归因于推理算法的正则化属性。</target>
        </trans-unit>
        <trans-unit id="7b398c0b1dbb0f3edb9cc17097a9c9f8696a24cc" translate="yes" xml:space="preserve">
          <source>This example employs several unsupervised learning techniques to extract the stock market structure from variations in historical quotes.</source>
          <target state="translated">本例采用了几种无监督学习技术,从历史行情的变化中提取股票市场结构。</target>
        </trans-unit>
        <trans-unit id="41937f256baaea1198c4d043d4bb81b61df0d50b" translate="yes" xml:space="preserve">
          <source>This example fits a Gradient Boosting model with least squares loss and 500 regression trees of depth 4.</source>
          <target state="translated">本例拟合了一个最小二乘损失的梯度提升模型和500棵深度为4的回归树。</target>
        </trans-unit>
        <trans-unit id="e8121408498cf6fb8c886d50eef2580465ff3307" translate="yes" xml:space="preserve">
          <source>This example fits an AdaBoosted decision stump on a non-linearly separable classification dataset composed of two &amp;ldquo;Gaussian quantiles&amp;rdquo; clusters (see &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt;&lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt;&lt;/a&gt;) and plots the decision boundary and decision scores. The distributions of decision scores are shown separately for samples of class A and B. The predicted class label for each sample is determined by the sign of the decision score. Samples with decision scores greater than zero are classified as B, and are otherwise classified as A. The magnitude of a decision score determines the degree of likeness with the predicted class label. Additionally, a new dataset could be constructed containing a desired purity of class B, for example, by only selecting samples with a decision score above some value.</source>
          <target state="translated">本示例将AdaBoosted决策树桩拟合到由两个&amp;ldquo;高斯分位数&amp;rdquo;集群组成的非线性可分离分类数据集中（请参阅&lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt; &lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt; &lt;/a&gt;），并绘制决策边界和决策得分。分别显示了A类和B类样本的决策分数分布。每个样本的预测类别标签由决策分数的符号确定。决策得分大于零的样本归为B，否则归为A。决策得分的大小决定了与预测类别标签的相似度。另外，例如，仅通过选择决策得分高于某个值的样本，就可以构建一个包含所需纯度B类的新数据集。</target>
        </trans-unit>
        <trans-unit id="02c230a18f98a72777c5f2652062014b16511fe8" translate="yes" xml:space="preserve">
          <source>This example has a fair amount of visualization-related code, as visualization is crucial here to display the graph. One of the challenge is to position the labels minimizing overlap. For this we use an heuristic based on the direction of the nearest neighbor along each axis.</source>
          <target state="translated">这个例子有相当多的可视化相关的代码,因为在这里可视化是显示图形的关键。其中一个挑战是如何将标签的位置最小化重叠。为此,我们使用了一个基于沿每个轴的最近邻方向的启发式方法。</target>
        </trans-unit>
        <trans-unit id="6aeec4c0fd48150be3eb10918e11b6fbb03261c5" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="translated">本示例说明了XPC数据上的GPC。比较的是静止的各向同性内核（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt;）和非平稳的内核（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;）。在此特定数据集上，由于类边界是线性的并且与坐标轴重合，因此&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;内核获得了更好的结果。但是，实际上，诸如&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; 之类的&lt;/a&gt;固定内核通常会获得更好的结果。</target>
        </trans-unit>
        <trans-unit id="259139974bd9ca7304e763dff02af979bb7908e6" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;code&gt;DotProduct&lt;/code&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="translated">此示例说明了XPC数据上的GPC。比较的是固定的各向同性内核（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt;）和非固定的内核（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;）。在此特定数据集上，由于类边界是线性的并且与坐标轴重合，因此 &lt;code&gt;DotProduct&lt;/code&gt; 内核获得了更好的结果。但是，实际上，诸如&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; 之类的&lt;/a&gt;固定内核通常会获得更好的结果。</target>
        </trans-unit>
        <trans-unit id="a467b781e30c272f4f5e4645f1261bd726b14e8d" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (RBF) and a non-stationary kernel (DotProduct). On this particular dataset, the DotProduct kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In general, stationary kernels often obtain better results.</source>
          <target state="translated">这个例子说明了XOR数据的GPC。比较的是一个固定的、各向同性的内核(RBF)和一个非固定的内核(DotProduct)。在这个特定的数据集上,DotProduct内核获得了更好的结果,因为类边界是线性的,并且与坐标轴重合。一般来说,静止核往往能得到更好的结果。</target>
        </trans-unit>
        <trans-unit id="722f803000769d905ffb0b191f686c49464dc23e" translate="yes" xml:space="preserve">
          <source>This example illustrates a generic implementation of a meta-estimator which extends clustering by inducing a classifier from the cluster labels.</source>
          <target state="translated">这个例子说明了一个元估计器的通用实现,它通过从簇标签中诱导出一个分类器来扩展聚类。</target>
        </trans-unit>
        <trans-unit id="397c051adb668f2e353216b8af31fde49c4b91b4" translate="yes" xml:space="preserve">
          <source>This example illustrates a learned distance metric that maximizes the nearest neighbors classification accuracy. It provides a visual representation of this metric compared to the original point space. Please refer to the &lt;a href=&quot;../../modules/neighbors#nca&quot;&gt;User Guide&lt;/a&gt; for more information.</source>
          <target state="translated">此示例说明了一个学习的距离度量，该距离度量使最近的邻居分类精度最大化。与原始点空间相比，它提供了该指标的直观表示。请参阅《&lt;a href=&quot;../../modules/neighbors#nca&quot;&gt;用户指南》&lt;/a&gt;以获取更多信息。</target>
        </trans-unit>
        <trans-unit id="b43f5231cb55a1a95a64bd8afe5472e7955fc98b" translate="yes" xml:space="preserve">
          <source>This example illustrates and compares the bias-variance decomposition of the expected mean squared error of a single estimator against a bagging ensemble.</source>
          <target state="translated">这个例子说明并比较了单个估计器与袋装集合的预期均方误差的偏方差分解。</target>
        </trans-unit>
        <trans-unit id="0a3450a632d656139c95a4f138b569cec22ba6ef" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise added to every fifth datapoint. The first figure compares the learned model of KRR and SVR when both complexity/regularization and bandwidth of the RBF kernel are optimized using grid-search. The learned functions are very similar; however, fitting KRR is approx. seven times faster than fitting SVR (both with grid-search). However, prediction of 100000 target values is more than tree times faster with SVR since it has learned a sparse model using only approx. 1/3 of the 100 training datapoints as support vectors.</source>
          <target state="translated">这个例子说明了在人工数据集上的两种方法,该数据集由一个正弦目标函数和强噪声组成,每五个数据点都会添加强噪声。第一个图比较了使用网格搜索优化RBF内核的复杂性/正则化和带宽时KRR和SVR的学习模型。学习到的函数非常相似;然而,拟合KRR比拟合SVR快约7倍(均采用网格搜索)。然而,由于SVR只使用了100个训练数据点中的约1/3作为支持向量来学习稀疏模型,因此预测100000个目标值的速度比SVR快一树倍以上。</target>
        </trans-unit>
        <trans-unit id="bdbaaa805869c3c13d157f267aeffaf332ff1284" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise. The figure compares the learned model of KRR and GPR based on a ExpSineSquared kernel, which is suited for learning periodic functions. The kernel&amp;rsquo;s hyperparameters control the smoothness (l) and periodicity of the kernel (p). Moreover, the noise level of the data is learned explicitly by GPR by an additional WhiteKernel component in the kernel and by the regularization parameter alpha of KRR.</source>
          <target state="translated">此示例说明了人工数据集上的两种方法，该方法由正弦目标函数和强噪声组成。该图比较了基于ExpSineSquared内核的KRR和GPR的学习模型，该模型适合于学习周期性函数。内核的超参数控制内核的平滑度（l）和周期性（p）。此外，数据的噪声级别由GPR通过内核中的其他WhiteKernel组件以及KRR的正则化参数alpha明确学习。</target>
        </trans-unit>
        <trans-unit id="745a420beb7d4cfe3dcb516bc28a36f2576e5395" translate="yes" xml:space="preserve">
          <source>This example illustrates how sigmoid calibration changes predicted probabilities for a 3-class classification problem. Illustrated is the standard 2-simplex, where the three corners correspond to the three classes. Arrows point from the probability vectors predicted by an uncalibrated classifier to the probability vectors predicted by the same classifier after sigmoid calibration on a hold-out validation set. Colors indicate the true class of an instance (red: class 1, green: class 2, blue: class 3).</source>
          <target state="translated">这个例子说明了sigmoid校准如何改变3类分类问题的预测概率。图中是标准的2-Simplex,其中三个角对应三个类。箭头从未校准的分类器预测的概率向量指向同一分类器在保留验证集上进行sigmoid校准后预测的概率向量。颜色表示一个实例的真实等级(红色:等级1,绿色:等级2,蓝色:等级3)。</target>
        </trans-unit>
        <trans-unit id="12c733d8527ccd2c1862324a52d9d453fa3717b9" translate="yes" xml:space="preserve">
          <source>This example illustrates how the Mahalanobis distances are affected by outlying data: observations drawn from a contaminating distribution are not distinguishable from the observations coming from the real, Gaussian distribution that one may want to work with. Using MCD-based Mahalanobis distances, the two populations become distinguishable. Associated applications are outliers detection, observations ranking, clustering, &amp;hellip; For visualization purpose, the cubic root of the Mahalanobis distances are represented in the boxplot, as Wilson and Hilferty suggest [2]</source>
          <target state="translated">此示例说明了边远数据如何影响马氏距离：从污染性分布中得出的观测值与可能要使用的真实高斯分布中的观测值没有区别。使用基于MCD的Mahalanobis距离，这两个种群变得可区分。关联的应用是离群值检测，观察值排名，聚类...&amp;hellip;为了可视化目的，马氏距离的立方根在方框图中表示，如Wilson和Hilferty所建议的[2]。</target>
        </trans-unit>
        <trans-unit id="e6c2656adbcd3c5e59b375bc18300061f72c931d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping using many fewer estimators. This can significantly reduce training time, memory usage and prediction latency.</source>
          <target state="translated">此示例说明了如何在&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;模型中使用提早停止，以实现与不使用更少估计量而无需提早停止构建的模型几乎相同的精度。这可以显着减少训练时间，内存使用量和预测延迟。</target>
        </trans-unit>
        <trans-unit id="c9534999032b13d85edbba90f8420279af14435d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping. This can significantly reduce training time. Note that scores differ between the stopping criteria even from early iterations because some of the training data is held out with the validation stopping criterion.</source>
          <target state="translated">此示例说明了如何在&lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt;模型中使用提前停止，与未提前停止构建的模型相比，该方法几乎可以达到相同的精度。这样可以大大减少培训时间。请注意，即使是早期迭代，停止准则之间的分数也会有所不同，因为某些训练数据会与验证停止准则保持一致。</target>
        </trans-unit>
        <trans-unit id="c861b8fa50d5165e1e9cdc8044114c0ba76be7f1" translate="yes" xml:space="preserve">
          <source>This example illustrates how to apply different preprocessing and feature extraction pipelines to different subsets of features, using &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt;. This is particularly handy for the case of datasets that contain heterogeneous data types, since we may want to scale the numeric features and one-hot encode the categorical ones.</source>
          <target state="translated">本示例说明了如何使用&lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt;将不同的预处理和特征提取管道应用于不同的特征子集。对于包含异构数据类型的数据集，这尤其方便，因为我们可能要缩放数字特征并对分类特征进行一次热编码。</target>
        </trans-unit>
        <trans-unit id="7688b615fac5133028d275260a50b4a9e7d6a213" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML.</source>
          <target state="translated">这个例子说明了GPR与包括WhiteKernel在内的和核可以估计数据的噪声水平。对数边际似然(LML)景观的说明表明,LML存在两个局部最大值。</target>
        </trans-unit>
        <trans-unit id="aab3b4258aabcd6bfe55c7c5adf04622c59229dc" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML. The first corresponds to a model with a high noise level and a large length scale, which explains all variations in the data by noise. The second one has a smaller noise level and shorter length scale, which explains most of the variation by the noise-free functional relationship. The second model has a higher likelihood; however, depending on the initial value for the hyperparameters, the gradient-based optimization might also converge to the high-noise solution. It is thus important to repeat the optimization several times for different initializations.</source>
          <target state="translated">这个例子说明了GPR与包括WhiteKernel在内的和核可以估计数据的噪声水平。对数边际似然(LML)景观的说明表明,LML存在两个局部最大值。第一个对应的是一个具有高噪声水平和大长度尺度的模型,它可以通过噪声解释数据的所有变化。第二个具有较小的噪声水平和较短的长度尺度,它能通过无噪声的函数关系解释大部分的变化。第二种模型具有较高的似然性;然而,根据超参数的初始值,基于梯度的优化也可能收敛到高噪声解。因此,对于不同的初始化,多次重复优化是很重要的。</target>
        </trans-unit>
        <trans-unit id="d19a1528c92e37a37fb4fd9cad2cad1ac3d91123" translate="yes" xml:space="preserve">
          <source>This example illustrates the differences between univariate F-test statistics and mutual information.</source>
          <target state="translated">这个例子说明了单变量F检验统计和相互信息的区别。</target>
        </trans-unit>
        <trans-unit id="7867032d06fe0e647e7865e3d58419806006e425" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of monotonic constraints on a gradient boosting estimator.</source>
          <target state="translated">这个例子说明了单调约束对梯度提升估计器的影响。</target>
        </trans-unit>
        <trans-unit id="b411e019157b9b0953b37eb36e27bc6a8ffb3f5f" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of the parameters &lt;code&gt;gamma&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt; of the Radial Basis Function (RBF) kernel SVM.</source>
          <target state="translated">此示例说明了径向基函数（RBF）内核SVM 的参数 &lt;code&gt;gamma&lt;/code&gt; 和 &lt;code&gt;C&lt;/code&gt; 的影响。</target>
        </trans-unit>
        <trans-unit id="0f49634dcf1598fde3c403bd7ddd702e3816c634" translate="yes" xml:space="preserve">
          <source>This example illustrates the need for robust covariance estimation on a real data set. It is useful both for outlier detection and for a better understanding of the data structure.</source>
          <target state="translated">这个例子说明了对真实数据集进行稳健的协方差估计的必要性。它对于检测异常值和更好地理解数据结构都很有用。</target>
        </trans-unit>
        <trans-unit id="dc09ff23a3cae32be328d47d0a0a7e64185cd75a" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an RBF kernel with different choices of the hyperparameters. The first figure shows the predicted probability of GPC with arbitrarily chosen hyperparameters and with the hyperparameters corresponding to the maximum log-marginal-likelihood (LML).</source>
          <target state="translated">这个例子说明了不同超参数选择下RBF内核的GPC预测概率。第一张图显示了任意选择的超参数和与最大对数边际似然(LML)对应的超参数下的GPC预测概率。</target>
        </trans-unit>
        <trans-unit id="d49b62c58d1a1ad4b52cfdb4df97043fcb25dfc7" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">这个例子说明了在虹膜数据集的二维版本上,各向同性和各向异性RBF内核的GPC预测概率。各向异性的RBF内核通过给两个特征维度分配不同的长度尺度来获得略高的对数边际似然。</target>
        </trans-unit>
        <trans-unit id="f8e8b4dfa6bc8bbc237c34d26328609c3561c0d3" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. This illustrates the applicability of GPC to non-binary classification. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">这个例子说明了在虹膜数据集的二维版本上,同向性和异向性RBF内核的GPC预测概率。这说明了GPC对非二元分类的适用性。各向异性RBF核通过对两个特征维度分配不同的长度尺度,获得了略高的对边似然。</target>
        </trans-unit>
        <trans-unit id="d60d503f722a9b87495f756d071794c2e2c52164" translate="yes" xml:space="preserve">
          <source>This example illustrates the prior and posterior of a GPR with different kernels. Mean, standard deviation, and 10 samples are shown for both prior and posterior.</source>
          <target state="translated">这个例子说明了不同内核的GPR的前值和后值。平均值、标准差和10个样本都显示了前值和后值。</target>
        </trans-unit>
        <trans-unit id="404891c56bd0f5f01fae61c2e12336745bf204d5" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Gaussian processes for regression and classification tasks on data that are not in fixed-length feature vector form. This is achieved through the use of kernel functions that operates directly on discrete structures such as variable-length sequences, trees, and graphs.</source>
          <target state="translated">这个例子说明了在非固定长度特征向量形式的数据上使用高斯过程进行回归和分类任务。这是通过使用核函数来实现的,核函数直接操作于离散结构,如可变长度的序列、树和图。</target>
        </trans-unit>
        <trans-unit id="b759d3b33b67e0716b08ee9d527244bce9326eed" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Poisson, Gamma and Tweedie regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt;, and is inspired by an R tutorial &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">该示例说明了在&lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;法国汽车第三方责任索赔数据集&lt;/a&gt;上使用Poisson，Gamma和Tweedie回归的方法，并受到R教程&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1的&lt;/a&gt;启发。</target>
        </trans-unit>
        <trans-unit id="d658c6dcc61e946966ad0e8390aa06974df82a41" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of log-linear Poisson regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt; from &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and compares it with a linear model fitted with the usual least squared error and a non-linear GBRT model fitted with the Poisson loss (and a log-link).</source>
          <target state="translated">本示例说明了从&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;开始的&lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;法国汽车第三方责任索赔数据集&lt;/a&gt;上的对数线性Poisson回归，并将其与符合通常最小二乘误差的线性模型和符合Poisson损失的非线性GBRT模型进行了比较（和一个日志链接）。</target>
        </trans-unit>
        <trans-unit id="7e4f09a45ae58596e6f6f82a5f372f88442c0679" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt; meta-estimator to perform multi-output regression. A random forest regressor is used, which supports multi-output regression natively, so the results can be compared.</source>
          <target state="translated">此示例说明了使用&lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt;元估计器执行多输出回归。使用了随机森林回归器，该回归器本身支持多输出回归，因此可以比较结果。</target>
        </trans-unit>
        <trans-unit id="b7cdc524f76e4e3da39b555dc7fb49145ad1abf9" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the print_changed_only global parameter.</source>
          <target state="translated">这个例子说明了print_changed_only全局参数的使用。</target>
        </trans-unit>
        <trans-unit id="8a4413b8994df2fb3a9be31d12e5c3eff453a657" translate="yes" xml:space="preserve">
          <source>This example illustrates visually in the feature space a comparison by results using two different component analysis techniques.</source>
          <target state="translated">这个例子直观地说明了在特征空间中使用两种不同的成分分析技术的结果比较。</target>
        </trans-unit>
        <trans-unit id="a61e83a5c393fe6eb13b5e3a4d37f5a941d5abef" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="translated">此示例基于Hastie等人2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1的&lt;/a&gt;图10.2 ，说明了离散SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;增强算法和实际SAMME.R增强算法之间的性能差异。两种算法都在二进制分类任务上进行评估，其中目标Y是10个输入要素的非线性函数。</target>
        </trans-unit>
        <trans-unit id="2cd2616385e5968100e838cea35843639b5d4649" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="translated">此示例基于Hastie等人2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]的&lt;/a&gt;图10.2 ，说明了离散SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;增强算法和实际SAMME.R增强算法之间的性能差异。两种算法都在二进制分类任务上进行评估，其中目标Y是10个输入要素的非线性函数。</target>
        </trans-unit>
        <trans-unit id="f74f72b73b7f5fc12f50525ee3a073668f796ed6" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &amp;ldquo;Gaussian Processes for Machine Learning&amp;rdquo; [RW2006]. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 2001. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">本示例基于第5.4.3节&amp;ldquo;用于机器学习的高斯过程&amp;rdquo; [RW2006]。它说明了使用对数边际似然法上的梯度上升的复杂内核工程和超参数优化的示例。数据由1958年至2001年在夏威夷的莫纳罗阿天文台收集的每月平均大气CO2浓度（百万分之一体积（ppmv））组成。目标是对随时间t变化的CO2浓度进行建模。 。</target>
        </trans-unit>
        <trans-unit id="b3b5741f90375b259727a574f2a0488e7637e5bc" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]&lt;/a&gt;. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 1997. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">该示例基于&lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]的&lt;/a&gt; 5.4.3节。它说明了使用对数边际似然法上的梯度上升的复杂内核工程和超参数优化的示例。数据由1958年至1997年之间在夏威夷的莫纳罗阿天文台收集的每月平均大气CO2浓度（以体积百万分之一（ppmv）为单位）组成。目标是对随时间t变化的CO2浓度进行建模。 。</target>
        </trans-unit>
        <trans-unit id="9ecc1c02a68f38d70271669af08df8c1497b1d98" translate="yes" xml:space="preserve">
          <source>This example is commented in the &lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;tutorial section of the user manual&lt;/a&gt;.</source>
          <target state="translated">该示例&lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;在用户手册&lt;/a&gt;的教程部分中进行了注释。</target>
        </trans-unit>
        <trans-unit id="9143eb314f05280f157b4081755ef4be5d0d1857" translate="yes" xml:space="preserve">
          <source>This example is meant to illustrate situations where k-means will produce unintuitive and possibly unexpected clusters. In the first three plots, the input data does not conform to some implicit assumption that k-means makes and undesirable clusters are produced as a result. In the last plot, k-means returns intuitive clusters despite unevenly sized blobs.</source>
          <target state="translated">这个例子是为了说明k-means会产生不直观和可能意外的聚类的情况。在前三张图中,输入数据不符合k-means做出的一些隐含假设,因此产生了不理想的聚类。在最后一张图中,尽管blubs大小不均,k-means还是会返回直观的聚类。</target>
        </trans-unit>
        <trans-unit id="0549792fdb7404b1799803948805283b1004db4d" translate="yes" xml:space="preserve">
          <source>This example plots several randomly generated classification datasets. For easy visualization, all datasets have 2 features, plotted on the x and y axis. The color of each point represents its class label.</source>
          <target state="translated">这个例子绘制了几个随机生成的分类数据集。为了便于可视化,所有数据集都有2个特征,分别绘制在x轴和y轴上。每个点的颜色代表其类标签。</target>
        </trans-unit>
        <trans-unit id="301c1da5ab62941da3ba93fb4d30f8869ad9b8b5" translate="yes" xml:space="preserve">
          <source>This example plots the corresponding dendrogram of a hierarchical clustering using AgglomerativeClustering and the dendrogram method available in scipy.</source>
          <target state="translated">这个例子使用AgglomerativeClustering和scipy中可用的dendrogram方法绘制了一个分层聚类的相应dendrogram。</target>
        </trans-unit>
        <trans-unit id="fb84e7488212d58818869cb1a848aafb46dc6573" translate="yes" xml:space="preserve">
          <source>This example plots the covariance ellipsoids of each class and decision boundary learned by LDA and QDA. The ellipsoids display the double standard deviation for each class. With LDA, the standard deviation is the same for all the classes, while each class has its own standard deviation with QDA.</source>
          <target state="translated">这个例子绘制了由LDA和QDA学习的每个类和决策边界的协方差椭圆。椭圆显示的是每个类的双标准差。在LDA中,所有类的标准差都是一样的,而QDA中每个类都有自己的标准差。</target>
        </trans-unit>
        <trans-unit id="61cf8846c08926de131cab630666b0d7a1ff4033" translate="yes" xml:space="preserve">
          <source>This example plots the ellipsoids obtained from a toy dataset (mixture of three Gaussians) fitted by the &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class models with a Dirichlet distribution prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt;) and a Dirichlet process prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt;). On each figure, we plot the results for three different values of the weight concentration prior.</source>
          <target state="translated">此示例绘制从 &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; GaussianMixture 类模型拟合的玩具数据集（三个高斯的混合物）获得的椭圆体，该模型具有Dirichlet分布先验（ &lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt; ）和Dirichlet加工先验（ &lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt; ）。在每个图上，我们绘制了三个不同重量浓度值的结果。</target>
        </trans-unit>
        <trans-unit id="e769643d14b1851635097bc926523b99ade21d56" translate="yes" xml:space="preserve">
          <source>This example presents how to chain KNeighborsTransformer and TSNE in a pipeline. It also shows how to wrap the packages &lt;code&gt;annoy&lt;/code&gt; and &lt;code&gt;nmslib&lt;/code&gt; to replace KNeighborsTransformer and perform approximate nearest neighbors. These packages can be installed with &lt;code&gt;pip install annoy nmslib&lt;/code&gt;.</source>
          <target state="translated">本示例说明如何在管道中链接KNeighborsTransformer和TSNE。这也说明了如何包装包 &lt;code&gt;annoy&lt;/code&gt; 和 &lt;code&gt;nmslib&lt;/code&gt; 更换KNeighborsTransformer和执行近似最近的邻居。这些软件包可以通过 &lt;code&gt;pip install annoy nmslib&lt;/code&gt; 安装。</target>
        </trans-unit>
        <trans-unit id="b0d46d4faf4d4d45c7ba844c05b8ff931d890d6c" translate="yes" xml:space="preserve">
          <source>This example presents the different strategies implemented in KBinsDiscretizer:</source>
          <target state="translated">这个例子介绍了KBinsDiscretizer中实现的不同策略。</target>
        </trans-unit>
        <trans-unit id="83f4e337d08dbc1524d014ed0118fe74e8fd5454" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">该示例复制了Zhu等人&lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1的&lt;/a&gt;图1，并显示了增强如何改善多类问题的预测准确性。分类数据集是通过采用十维标准正态分布并定义三个由嵌套同心十维球面分隔的类来构造的，从而每个类中的样本数量大致相等（\（\ chi ^ 2 \）分布的分位数）。</target>
        </trans-unit>
        <trans-unit id="aff95617011fc0f39a1d4573107679df90fa3c83" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">该示例复制了Zhu等人的图1 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]，&lt;/a&gt;并显示了增强如何改善多类问题的预测准确性。分类数据集是通过采用十维标准正态分布并定义三个由嵌套同心十维球体分隔的类来构造的，从而每个类中的样本数量大致相等（\（\ chi ^ 2 \）分布的分位数）。</target>
        </trans-unit>
        <trans-unit id="f0193d5eae04ea4c45d1272eb8f24ceb76514e1e" translate="yes" xml:space="preserve">
          <source>This example serves as a visual check that IPCA is able to find a similar projection of the data to PCA (to a sign flip), while only processing a few samples at a time. This can be considered a &amp;ldquo;toy example&amp;rdquo;, as IPCA is intended for large datasets which do not fit in main memory, requiring incremental approaches.</source>
          <target state="translated">此示例用作视觉检查，以确保IPCA能够找到与PCA相似的数据投影（至符号翻转），而一次仅处理几个样本。这可以被视为&amp;ldquo;玩具示例&amp;rdquo;，因为IPCA适用于不适合主存储器的大型数据集，需要增量方法。</target>
        </trans-unit>
        <trans-unit id="3dfa9a56451c107730b94ff094ad060fe6660b05" translate="yes" xml:space="preserve">
          <source>This example should be taken with a grain of salt, as the intuition conveyed does not necessarily carry over to real datasets. Particularly in high-dimensional spaces, data can more easily be separated linearly. Moreover, using feature discretization and one-hot encoding increases the number of features, which easily lead to overfitting when the number of samples is small.</source>
          <target state="translated">这个例子应该带着盐分,因为所传达的直觉不一定适用于真实的数据集。特别是在高维空间中,数据更容易被线性分离。此外,使用特征离散化和一热编码会增加特征数量,当样本数量较少时,容易导致过拟合。</target>
        </trans-unit>
        <trans-unit id="ad21e470ff2bffe875ca12e50c6f8a883eaa0515" translate="yes" xml:space="preserve">
          <source>This example shows an example usage of the &lt;code&gt;split&lt;/code&gt; method.</source>
          <target state="translated">本示例显示了 &lt;code&gt;split&lt;/code&gt; 方法的示例用法。</target>
        </trans-unit>
        <trans-unit id="05321a1b8964aa5eaada463be8f8b6ab44686817" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different anomaly detection algorithms on 2D datasets. Datasets contain one or two modes (regions of high density) to illustrate the ability of algorithms to cope with multimodal data.</source>
          <target state="translated">这个例子展示了不同的异常检测算法在二维数据集上的特点。数据集包含一个或两个模式(高密度区域),以说明算法处理多模态数据的能力。</target>
        </trans-unit>
        <trans-unit id="9671740bdc9e0f010272719df08d61d30b070724" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different clustering algorithms on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D. With the exception of the last dataset, the parameters of each of these dataset-algorithm pairs has been tuned to produce good clustering results. Some algorithms are more sensitive to parameter values than others.</source>
          <target state="translated">此示例显示了&amp;ldquo;有趣&amp;rdquo;但仍在2D模式下的数据集上不同聚类算法的特征。除最后一个数据集外，每个数据集算法对的参数都已调整以产生良好的聚类结果。一些算法比其他算法对参数值更敏感。</target>
        </trans-unit>
        <trans-unit id="408c25df8162bc85c75adf89aefb6c4283aab313" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different linkage methods for hierarchical clustering on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D.</source>
          <target state="translated">此示例显示了&amp;ldquo;有趣&amp;rdquo;但仍在2D模式下用于数据集上层次聚类的不同链接方法的特征。</target>
        </trans-unit>
        <trans-unit id="ee904b77cbf769dbe7d1093eb852f864329f4bb5" translate="yes" xml:space="preserve">
          <source>This example shows how kernel density estimation (KDE), a powerful non-parametric density estimation technique, can be used to learn a generative model for a dataset. With this generative model in place, new samples can be drawn. These new samples reflect the underlying model of the data.</source>
          <target state="translated">这个例子展示了内核密度估计(KDE)--一种强大的非参数密度估计技术--如何被用来学习一个数据集的生成模型。有了这个生成模型,就可以抽取新的样本。这些新样本反映了数据的基本模型。</target>
        </trans-unit>
        <trans-unit id="54102d8f78c42d496181e5bcdf5a40bdaee3e42d" translate="yes" xml:space="preserve">
          <source>This example shows how quantile regression can be used to create prediction intervals.</source>
          <target state="translated">这个例子展示了如何使用量化回归来创建预测区间。</target>
        </trans-unit>
        <trans-unit id="682ea376dc5fd413204f119c7903367cc1b71149" translate="yes" xml:space="preserve">
          <source>This example shows how to build a classification pipeline with a BernoulliRBM feature extractor and a &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; classifier. The hyperparameters of the entire model (learning rate, hidden layer size, regularization) were optimized by grid search, but the search is not reproduced here because of runtime constraints.</source>
          <target state="translated">本示例说明如何使用BernoulliRBM特征提取器和&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;分类器构建分类管道。整个模型的超参数（学习率，隐藏层大小，正则化）已通过网格搜索进行了优化，但由于运行时的限制，此处未复制搜索。</target>
        </trans-unit>
        <trans-unit id="e6287a37f5ab2f7e58b3aa65bfc9b371f8d2e434" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">本示例说明如何从在加利福尼亚住房数据集中训练的&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; 中&lt;/a&gt;获得部分依赖图。该示例取自&lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="acf93c17a79b2f475e2915043f3e806cbddc60a2" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">本示例说明如何从在加利福尼亚住房数据集中训练的&lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt; &lt;code&gt;MLPRegressor&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;获得部分依赖图。该示例取自&lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="dd4b844c3488b502b915a6b11d22b13911beaa74" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores.</source>
          <target state="translated">这个例子展示了如何在运行SVC(支持向量分类器)之前进行单变量特征选择,以提高分类得分。</target>
        </trans-unit>
        <trans-unit id="f7865c444403c29f04e970d66c2c5367cc834a8b" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores. We use the iris dataset (4 features) and add 36 non-informative features. We can find that our model achieves best performance when we select around 10% of features.</source>
          <target state="translated">这个例子展示了如何在运行SVC(支持向量分类器)之前执行单变量特征选择,以提高分类得分。我们使用虹膜数据集(4个特征)并添加36个非信息特征。我们可以发现,当我们选择10%左右的特征时,我们的模型达到了最佳性能。</target>
        </trans-unit>
        <trans-unit id="47a26e628df959c3e5ed3ffe4f4f3490e8927a8d" translate="yes" xml:space="preserve">
          <source>This example shows how to plot some of the first layer weights in a MLPClassifier trained on the MNIST dataset.</source>
          <target state="translated">这个例子展示了如何绘制在MNIST数据集上训练的MLPClassifier中的一些第一层权重。</target>
        </trans-unit>
        <trans-unit id="dd07bd7e7afed03f3c2a3c74458c42dc14028dfe" translate="yes" xml:space="preserve">
          <source>This example shows how to plot the decision surface for four SVM classifiers with different kernels.</source>
          <target state="translated">这个例子展示了如何绘制四个具有不同内核的SVM分类器的决策面。</target>
        </trans-unit>
        <trans-unit id="981971245cdda71fb264be7304dc1e201a08b23b" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt;&lt;code&gt;cross_val_predict&lt;/code&gt;&lt;/a&gt; to visualize prediction errors.</source>
          <target state="translated">本示例说明如何使用&lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt; &lt;code&gt;cross_val_predict&lt;/code&gt; &lt;/a&gt;可视化预测错误。</target>
        </trans-unit>
        <trans-unit id="52dcf2b8bf47a153b3ba3beca30c9af85b850fad" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;code&gt;cross_val_predict&lt;/code&gt; to visualize prediction errors.</source>
          <target state="translated">本示例说明如何使用 &lt;code&gt;cross_val_predict&lt;/code&gt; 可视化预测错误。</target>
        </trans-unit>
        <trans-unit id="42d1610b65eff631d96069dbbdf35236afd1d573" translate="yes" xml:space="preserve">
          <source>This example shows how to use Permutation Importances as an alternative that can mitigate those limitations.</source>
          <target state="translated">这个例子展示了如何使用Permutation Importances作为一种可以减轻这些限制的替代方法。</target>
        </trans-unit>
        <trans-unit id="351c02b1031f149a08df70cbeed39cd2a6bb9ec7" translate="yes" xml:space="preserve">
          <source>This example shows that Kernel PCA is able to find a projection of the data that makes data linearly separable.</source>
          <target state="translated">这个例子表明,Kernel PCA能够找到数据的投影,使数据可以线性分离。</target>
        </trans-unit>
        <trans-unit id="607fdb6fda0285694fd1dd982f83082f2f9a6687" translate="yes" xml:space="preserve">
          <source>This example shows that imputing the missing values can give better results than discarding the samples containing any missing value. Imputing does not always improve the predictions, so please check via cross-validation. Sometimes dropping rows or using marker values is more effective.</source>
          <target state="translated">这个例子表明,推算缺失值比丢弃包含任何缺失值的样本可以得到更好的结果。归入并不总是能改善预测结果,所以请通过交叉验证进行检查。有时放弃行或使用标记值更有效。</target>
        </trans-unit>
        <trans-unit id="b6045a3110197ccfd64402c3c879acac73bdaadb" translate="yes" xml:space="preserve">
          <source>This example shows that model selection can be performed with Gaussian Mixture Models using information-theoretic criteria (BIC). Model selection concerns both the covariance type and the number of components in the model. In that case, AIC also provides the right result (not shown to save time), but BIC is better suited if the problem is to identify the right model. Unlike Bayesian procedures, such inferences are prior-free.</source>
          <target state="translated">这个例子表明,可以使用信息理论标准(BIC)对高斯混合模型进行模型选择。模型选择既涉及到协方差类型,也涉及到模型中成分的数量。在这种情况下,AIC也能提供正确的结果(未显示节省时间),但如果问题是确定正确的模型,BIC更适合。与贝叶斯程序不同,这种推论是无先验的。</target>
        </trans-unit>
        <trans-unit id="7ed4db944a196b1cb5ab23d8834c95cd5421c757" translate="yes" xml:space="preserve">
          <source>This example shows that you can do non-linear regression with a linear model, using a pipeline to add non-linear features. Kernel methods extend this idea and can induce very high (even infinite) dimensional feature spaces.</source>
          <target state="translated">这个例子表明,你可以用线性模型做非线性回归,使用管道来添加非线性特征。内核方法扩展了这个想法,可以诱导出非常高(甚至是无限)维度的特征空间。</target>
        </trans-unit>
        <trans-unit id="48dcc848c2d6e1561f6c336d60b0fb518f9ab59a" translate="yes" xml:space="preserve">
          <source>This example shows the ROC response of different datasets, created from K-fold cross-validation. Taking all of these curves, it is possible to calculate the mean area under curve, and see the variance of the curve when the training set is split into different subsets. This roughly shows how the classifier output is affected by changes in the training data, and how different the splits generated by K-fold cross-validation are from one another.</source>
          <target state="translated">这个例子显示了不同数据集的ROC响应,由K倍交叉验证创建。将所有这些曲线,可以计算出曲线下的平均面积,并看到训练集被分割成不同子集时的曲线方差。这大致可以看出分类器的输出是如何受到训练数据变化的影响,以及K-fold交叉验证所产生的分裂数据之间的差异。</target>
        </trans-unit>
        <trans-unit id="7b92e840bf44fca60c7edc394c5ccf3da0546857" translate="yes" xml:space="preserve">
          <source>This example shows the effect of imposing a connectivity graph to capture local structure in the data. The graph is simply the graph of 20 nearest neighbors.</source>
          <target state="translated">这个例子显示了强加一个连接图来捕捉数据中局部结构的效果。该图只是20个最近的邻居的图。</target>
        </trans-unit>
        <trans-unit id="a122bd5b47879a72d10715b2e2741901d74ebd5f" translate="yes" xml:space="preserve">
          <source>This example shows the reconstruction of an image from a set of parallel projections, acquired along different angles. Such a dataset is acquired in &lt;strong&gt;computed tomography&lt;/strong&gt; (CT).</source>
          <target state="translated">此示例显示了从一组沿不同角度获取的平行投影重建图像的方法。此类数据集是在&lt;strong&gt;计算机断层扫描&lt;/strong&gt;（CT）中获取的。</target>
        </trans-unit>
        <trans-unit id="277c7e399c7f521a9367c3279ba6605ffa32bb5b" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="translated">这个例子显示了使用树之林来评估图像分类任务(人脸)中像素的重要性。像素越热,越重要。</target>
        </trans-unit>
        <trans-unit id="1fc99c46b3490d43b644ebffe104cba9573e1195" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the impurity-based importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="translated">这个例子显示了使用树之林来评估图像分类任务(人脸)中像素的基于杂质的重要性。像素越热,越重要。</target>
        </trans-unit>
        <trans-unit id="181df9c721e88b620fbcd3038af372d2bc17958d" translate="yes" xml:space="preserve">
          <source>This example shows the use of multi-output estimator to complete images. The goal is to predict the lower half of a face given its upper half.</source>
          <target state="translated">这个例子展示了使用多输出估计器来完成图像。目标是预测一个人脸的下半部分,给定其上半部分。</target>
        </trans-unit>
        <trans-unit id="c194d9ad3fd820ff97a5b60a54a77ad5e096ac46" translate="yes" xml:space="preserve">
          <source>This example simulates a multi-label document classification problem. The dataset is generated randomly based on the following process:</source>
          <target state="translated">本例模拟了一个多标签文档分类问题。数据集是根据以下过程随机生成的。</target>
        </trans-unit>
        <trans-unit id="beca62f6aeebe1ac71c16bdf04b277689fc51da6" translate="yes" xml:space="preserve">
          <source>This example uses &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; on a graph created from voxel-to-voxel difference on an image to break this image into multiple partly-homogeneous regions.</source>
          <target state="translated">本示例在根据图像上体素之间的差异创建的图上使用&amp;ldquo; &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;光谱&amp;rdquo;聚类&lt;/a&gt;，以将该图像分为多个部分均匀的区域。</target>
        </trans-unit>
        <trans-unit id="b1b3f16a0bb367262a72b24da0008ca16f86a096" translate="yes" xml:space="preserve">
          <source>This example uses a large dataset of faces to learn a set of 20 x 20 images patches that constitute faces.</source>
          <target state="translated">这个例子使用一个大型的人脸数据集来学习构成人脸的一组20×20的图像补丁。</target>
        </trans-unit>
        <trans-unit id="0ad2a4281006cf2ce3833b3619a37abf58d678e0" translate="yes" xml:space="preserve">
          <source>This example uses different scalers, transformers, and normalizers to bring the data within a pre-defined range.</source>
          <target state="translated">这个例子使用不同的标量器、变换器和归一化器,使数据在预定义的范围内。</target>
        </trans-unit>
        <trans-unit id="e1bfbae38c6acd2b8b362eacb6ca0227cf12cdc6" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; class to demonstrate the principles of Kernel Density Estimation in one dimension.</source>
          <target state="translated">本示例使用&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt;类在一个维度上演示内核密度估计的原理。</target>
        </trans-unit>
        <trans-unit id="a99077db11e6455dfdf5d225265c8630cb316352" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;.</source>
          <target state="translated">此示例使用 &lt;code&gt;scipy.stats&lt;/code&gt; 模块，该模块包含许多用于采样参数的有用分布，例如 &lt;code&gt;expon&lt;/code&gt; ， &lt;code&gt;gamma&lt;/code&gt; ， &lt;code&gt;uniform&lt;/code&gt; 或 &lt;code&gt;randint&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1c91a9c343e9d52fecff06520d2432c55d78e2a0" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;. In principle, any function can be passed that provides a &lt;code&gt;rvs&lt;/code&gt; (random variate sample) method to sample a value. A call to the &lt;code&gt;rvs&lt;/code&gt; function should provide independent random samples from possible parameter values on consecutive calls.</source>
          <target state="translated">此示例使用 &lt;code&gt;scipy.stats&lt;/code&gt; 模块，该模块包含许多有用的采样参数分布，例如 &lt;code&gt;expon&lt;/code&gt; ， &lt;code&gt;gamma&lt;/code&gt; ， &lt;code&gt;uniform&lt;/code&gt; 或 &lt;code&gt;randint&lt;/code&gt; 。原则上，可以传递提供 &lt;code&gt;rvs&lt;/code&gt; （随机变量样本）方法以采样值的任何函数。调用 &lt;code&gt;rvs&lt;/code&gt; 函数应从连续调用的可能参数值中提供独立的随机样本。</target>
        </trans-unit>
        <trans-unit id="d9381762b80079a0275cf5384c50652951b2c3b8" translate="yes" xml:space="preserve">
          <source>This example uses the only the first feature of the &lt;code&gt;diabetes&lt;/code&gt; dataset, in order to illustrate a two-dimensional plot of this regression technique. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation.</source>
          <target state="translated">本示例仅使用 &lt;code&gt;diabetes&lt;/code&gt; 数据集的第一个特征，以说明此回归技术的二维图。可以在图中看到直线，显示了线性回归如何尝试绘制一条直线，该直线将最大程度地减少数据集中观察到的响应与通过线性近似预测的响应之间的残差平方和。</target>
        </trans-unit>
        <trans-unit id="c6bb5d76743a81844f0fc5afc16345d399cae103" translate="yes" xml:space="preserve">
          <source>This example visualizes some training loss curves for different stochastic learning strategies, including SGD and Adam. Because of time-constraints, we use several small datasets, for which L-BFGS might be more suitable. The general trend shown in these examples seems to carry over to larger datasets, however.</source>
          <target state="translated">这个例子可视化了不同随机学习策略的一些训练损失曲线,包括 SGD 和 Adam。由于时间限制,我们使用了几个小数据集,对于这些数据集,L-BFGS可能更适合。然而,这些例子中显示的一般趋势似乎可以延续到更大的数据集。</target>
        </trans-unit>
        <trans-unit id="65646a35859e04e16667e59a0e282463725f9c9e" translate="yes" xml:space="preserve">
          <source>This example visualizes the behavior of several common scikit-learn objects for comparison.</source>
          <target state="translated">这个例子将几个常见的scikit-learn对象的行为可视化,以便比较。</target>
        </trans-unit>
        <trans-unit id="49dcb9492cd2c3de6ca468ca869fddbd4adf1109" translate="yes" xml:space="preserve">
          <source>This example visualizes the partitions given by several trees and shows how the transformation can also be used for non-linear dimensionality reduction or non-linear classification.</source>
          <target state="translated">这个例子将几个树给出的分区可视化,并展示了如何将变换也用于非线性维度减少或非线性分类。</target>
        </trans-unit>
        <trans-unit id="6942c7999112e031e7e9f390f17a63a6ea65b8dd" translate="yes" xml:space="preserve">
          <source>This example was inspired by the &lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html&quot;&gt;XGBoost documentation&lt;/a&gt;.</source>
          <target state="translated">此示例的灵感来自&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html&quot;&gt;XGBoost文档&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6888e16176d5ba984d30e5b2aecac9e36e3202eb" translate="yes" xml:space="preserve">
          <source>This example will also work by replacing &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; with &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt;. Setting the &lt;code&gt;loss&lt;/code&gt; parameter of the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; equal to &lt;code&gt;hinge&lt;/code&gt; will yield behaviour such as that of a SVC with a linear kernel.</source>
          <target state="translated">通过将 &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; 替换为 &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt; 此示例也可以工作。设置 &lt;code&gt;loss&lt;/code&gt; 的参数&lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt;等于 &lt;code&gt;hinge&lt;/code&gt; 将产生的行为，例如，与线性核一个SVC的。</target>
        </trans-unit>
        <trans-unit id="b7e7228e1bc6d35fed471b6c3015699404cca0fb" translate="yes" xml:space="preserve">
          <source>This example will generate three figures.</source>
          <target state="translated">这个例子将产生三个数字。</target>
        </trans-unit>
        <trans-unit id="5d6705d9213c8c7167b6f8a12276b073092deeca" translate="yes" xml:space="preserve">
          <source>This example will provide some hints in interpreting coefficient in linear models, pointing at problems that arise when either the linear model is not appropriate to describe the dataset, or when features are correlated.</source>
          <target state="translated">这个例子将为解释线性模型中的系数提供一些提示,指出当线性模型不适合描述数据集,或者特征相关时出现的问题。</target>
        </trans-unit>
        <trans-unit id="08633b59361c5b4332dffd09b9ac681bbe920080" translate="yes" xml:space="preserve">
          <source>This example, inspired from Chen&amp;rsquo;s publication [1], shows a comparison of the estimated MSE of the LW and OAS methods, using Gaussian distributed data.</source>
          <target state="translated">这个例子的灵感来自Chen的出版物[1]，显示了使用高斯分布数据对LW和OAS方法的估计MSE的比较。</target>
        </trans-unit>
        <trans-unit id="8aeed7fa163e961c6e7fadbb3ef8c5a658c9cc15" translate="yes" xml:space="preserve">
          <source>This examples demonstrates how to precompute the k nearest neighbors before using them in KNeighborsClassifier. KNeighborsClassifier can compute the nearest neighbors internally, but precomputing them can have several benefits, such as finer parameter control, caching for multiple use, or custom implementations.</source>
          <target state="translated">这个例子演示了如何在KNeighborsClassifier中使用k个最近的邻居之前预先计算它们。KNeighborsClassifier可以在内部计算最近的邻居,但预先计算它们可以有几个好处,比如更精细的参数控制、多次使用的缓存或自定义实现。</target>
        </trans-unit>
        <trans-unit id="f9260a90e6c35e520398765702d07497fe04f1a8" translate="yes" xml:space="preserve">
          <source>This examples shows how a classifier is optimized by cross-validation, which is done using the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; object on a development set that comprises only half of the available labeled data.</source>
          <target state="translated">此示例显示了如何通过交叉验证来优化分类器，交叉验证是通过在仅包含可用标记数据的一半的开发集上使用&lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt;对象完成的。</target>
        </trans-unit>
        <trans-unit id="e16048c7f7cf75798d53fe7e675cc81cd1d6af8b" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the feature importances of the forest, along with their inter-trees variability.</source>
          <target state="translated">这个例子展示了使用树木森林来评估特征对人工分类任务的重要性。红条是森林的特征重要性,以及它们的树间变化。</target>
        </trans-unit>
        <trans-unit id="cdab1575e5f24de85ab913b14f241e0bd17fea2d" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the impurity-based feature importances of the forest, along with their inter-trees variability.</source>
          <target state="translated">这个例子显示了使用树木森林来评估特征在人工分类任务上的重要性。红条是森林中基于杂质的特征重要性,以及它们的树间变化。</target>
        </trans-unit>
        <trans-unit id="4fb4f14900902539137295018be0a0c7a07b1094" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;Cross-validated estimators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">在&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;模型选择&lt;/a&gt;的&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;交叉验证估计器&lt;/a&gt;部分中使用此练习：&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;科学数据统计学习指南的&lt;/a&gt;选择估计器及其参数部分。</target>
        </trans-unit>
        <trans-unit id="621b0c8349abb129c7bc150bd9745f46f49af3ab" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;Cross-validation generators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">本练习在&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;模型选择&lt;/a&gt;的&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;交叉验证生成器&lt;/a&gt;部分中使用：&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;《科学数据处理统计学习指南》的&amp;ldquo; &lt;/a&gt;选择估计量及其参数&amp;rdquo;部分。</target>
        </trans-unit>
        <trans-unit id="6915ba6643fea2f9e387885428a6e6189c7df3bf" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;Classification&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">此练习在&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;监督学习&lt;/a&gt;的&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;分类&lt;/a&gt;部分中使用：从&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;用于科学数据处理的统计学习指南的&lt;/a&gt;高维观测部分预测输出变量。</target>
        </trans-unit>
        <trans-unit id="421684adc1a996556d28fe46ff4c101c2f3063ef" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;Using kernels&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">本练习在&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;监督学习&lt;/a&gt;的&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;使用内核&lt;/a&gt;部分中使用：从&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;用于科学数据处理的统计学习指南的&lt;/a&gt;高维观测部分预测输出变量。</target>
        </trans-unit>
        <trans-unit id="dadb46eeaf7a2bf2f8f61dc107ba2d3f5d55d33a" translate="yes" xml:space="preserve">
          <source>This extends to the multiclass case as follows. Let the true labels for a set of samples be encoded as a 1-of-K binary indicator matrix \(Y\), i.e., \(y_{i,k} = 1\) if sample \(i\) has label \(k\) taken from a set of \(K\) labels. Let \(P\) be a matrix of probability estimates, with \(p_{i,k} = \operatorname{Pr}(t_{i,k} = 1)\). Then the log loss of the whole set is</source>
          <target state="translated">这扩展到多类情况如下。让一组样本的真实标签被编码为一个1-of-K的二进制指标矩阵 \(Y\),即,如果样本 \(i)\具有从一组 \(K\)标签中抽取的标签 \(k)\,则 \(y_{i,k}=1\)。让\(P\)是一个概率估计的矩阵,其中\(p_{i,k}=\operatorname{Pr}(t_{i,k}=1)\)。那么整个集合的对数损失为</target>
        </trans-unit>
        <trans-unit id="826a67cf49f96f56e23921af61e52712fab61d33" translate="yes" xml:space="preserve">
          <source>This factory function wraps scoring functions for use in GridSearchCV and cross_val_score. It takes a score function, such as &lt;code&gt;accuracy_score&lt;/code&gt;, &lt;code&gt;mean_squared_error&lt;/code&gt;, &lt;code&gt;adjusted_rand_index&lt;/code&gt; or &lt;code&gt;average_precision&lt;/code&gt; and returns a callable that scores an estimator&amp;rsquo;s output.</source>
          <target state="translated">此工厂函数包装评分函数，以用于GridSearchCV和cross_val_score。它需要一个得分的功能，如 &lt;code&gt;accuracy_score&lt;/code&gt; ， &lt;code&gt;mean_squared_error&lt;/code&gt; ， &lt;code&gt;adjusted_rand_index&lt;/code&gt; 或 &lt;code&gt;average_precision&lt;/code&gt; 并返回一个可调用的是分数的估计的输出。</target>
        </trans-unit>
        <trans-unit id="5eb7a4eb6e2161d3d9f2a7b4c7010506ccf35ad1" translate="yes" xml:space="preserve">
          <source>This feature corresponds to the sepal length in cm. Once the quantile transformation applied, those landmarks approach closely the percentiles previously defined:</source>
          <target state="translated">这个特征对应于以厘米为单位的萼片长度。一旦应用分位数变换,这些地标就会接近之前定义的百分数。</target>
        </trans-unit>
        <trans-unit id="18a1d2c5a41fd4d57af7a6bb802060cade230322" translate="yes" xml:space="preserve">
          <source>This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.</source>
          <target state="translated">这种特征选择算法只看特征(X),而不是所需的输出(y),因此可以用于无监督学习。</target>
        </trans-unit>
        <trans-unit id="677c582ff4a458e9dc8e636909bbbb985fe5cce6" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; preprocessor. This preprocessor transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="translated">该图是使用&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt;预处理器创建的。该预处理器将输入数据矩阵转换为给定程度的新数据矩阵。可以如下使用：</target>
        </trans-unit>
        <trans-unit id="6faa801ac2c09333248247cbfc3515a179a790a8" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; transformer, which transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="translated">该图是使用&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt;转换器创建的，该转换器将输入数据矩阵转换为给定度数的新数据矩阵。它可以按如下方式使用：</target>
        </trans-unit>
        <trans-unit id="adbd1df9acbf84e51fe5dc83e34aca6a9423eabf" translate="yes" xml:space="preserve">
          <source>This figure shows an example of such an ROC curve:</source>
          <target state="translated">该图显示了这样一条ROC曲线的例子。</target>
        </trans-unit>
        <trans-unit id="e1207da0df5038f5f29891db83b7d5022ead8471" translate="yes" xml:space="preserve">
          <source>This folder is used by some large dataset loaders to avoid downloading the data several times.</source>
          <target state="translated">这个文件夹被一些大型数据集加载器使用,以避免多次下载数据。</target>
        </trans-unit>
        <trans-unit id="697a12fdadac01e298b3e16a8634659c2b054014" translate="yes" xml:space="preserve">
          <source>This format is a text-based format, with one sample per line. It does not store zero valued features hence is suitable for sparse dataset.</source>
          <target state="translated">这种格式是一种基于文本的格式,每行有一个样本,它不存储零值特征,因此适合于稀疏数据集。它不存储零值特征,因此适用于稀疏数据集。</target>
        </trans-unit>
        <trans-unit id="a2fe6f0ee6734c2a60bcbb1d0d95dc9dfd886002" translate="yes" xml:space="preserve">
          <source>This format is used as the default format for both svmlight and the libsvm command line programs.</source>
          <target state="translated">这种格式被用作 svmlight 和 libsvm 命令行程序的默认格式。</target>
        </trans-unit>
        <trans-unit id="a2e505f490185afab8e1242d5832b6872eb9a667" translate="yes" xml:space="preserve">
          <source>This formulation has two advantages over other ways of computing distances. First, it is computationally efficient when dealing with sparse data. Second, if one argument varies but the other remains unchanged, then &lt;code&gt;dot(x, x)&lt;/code&gt; and/or &lt;code&gt;dot(y, y)&lt;/code&gt; can be pre-computed.</source>
          <target state="translated">与其他计算距离的方式相比，此公式具有两个优点。首先，在处理稀疏数据时它在计算上是有效的。其次，如果一个参数变化而另一个参数保持不变，则可以预先计算 &lt;code&gt;dot(x, x)&lt;/code&gt; 和/或 &lt;code&gt;dot(y, y)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fd76e45c139161a6c2340aa524dcf0429afb583e" translate="yes" xml:space="preserve">
          <source>This function computes Cohen&amp;rsquo;s kappa &lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;, a score that expresses the level of agreement between two annotators on a classification problem. It is defined as</source>
          <target state="translated">此函数计算Cohen的kappa &lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;，该分数表示两个注释者在分类问题上的一致程度。定义为</target>
        </trans-unit>
        <trans-unit id="1a26f30c64bc915159ba37349551edb033f8db68" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance).</source>
          <target state="translated">这个函数为X中的每一行计算最接近Y行的索引(根据指定的距离)。</target>
        </trans-unit>
        <trans-unit id="40ca8ec3788866f2480b1619115207e644d05cac" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance). The minimal distances are also returned.</source>
          <target state="translated">这个函数为X中的每一行计算最接近Y行的索引(根据指定的距离)。同时返回最小距离。</target>
        </trans-unit>
        <trans-unit id="6e14f241e1c03d6b67a6c0f22515d375ae432487" translate="yes" xml:space="preserve">
          <source>This function crawls the module and gets all classes that inherit from BaseEstimator. Classes that are defined in test-modules are not included. By default meta_estimators such as GridSearchCV are also not included.</source>
          <target state="translated">这个函数抓取模块并获取所有继承自BaseEstimator的类。不包括在测试模块中定义的类。默认情况下,元估计器(如GridSearchCV)也不包括在内。</target>
        </trans-unit>
        <trans-unit id="311d27372cf5315019acfac7480657777c623446" translate="yes" xml:space="preserve">
          <source>This function does not try to extract features into a numpy array or scipy sparse matrix. In addition, if load_content is false it does not try to load the files in memory.</source>
          <target state="translated">这个函数不会尝试将特征提取到numpy数组或scipy稀疏矩阵中。此外,如果 load_content 为 false,它不会尝试加载内存中的文件。</target>
        </trans-unit>
        <trans-unit id="28042729acf4bf75d343c82f013b112dad91f4c8" translate="yes" xml:space="preserve">
          <source>This function generates a GraphViz representation of the decision tree, which is then written into &lt;code&gt;out_file&lt;/code&gt;. Once exported, graphical renderings can be generated using, for example:</source>
          <target state="translated">此函数生成决策树的GraphViz表示形式，然后将其写入 &lt;code&gt;out_file&lt;/code&gt; 。导出后，可以使用以下方式生成图形渲染：</target>
        </trans-unit>
        <trans-unit id="90af5dc07a0d6b1b987fbe6284966c35b8f7dbed" translate="yes" xml:space="preserve">
          <source>This function implements Test 1 in:</source>
          <target state="translated">该函数实现了测试1中。</target>
        </trans-unit>
        <trans-unit id="51510777ab8c25d02b45243629e172250d646e40" translate="yes" xml:space="preserve">
          <source>This function is called with the estimated model and the randomly selected data: &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped. Rejecting samples with this function is computationally costlier than with &lt;code&gt;is_data_valid&lt;/code&gt;. &lt;code&gt;is_model_valid&lt;/code&gt; should therefore only be used if the estimated model is needed for making the rejection decision.</source>
          <target state="translated">使用估计的模型和随机选择的数据调用此函数： &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt; 。如果其返回值为False，则跳过当前随机选择的子样本。与 &lt;code&gt;is_data_valid&lt;/code&gt; 相比，使用此函数拒绝样本的计算开销更大。因此，仅在需要估计模型来做出拒绝决策时才应使用 &lt;code&gt;is_model_valid&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a4283f593950d3e9c84617d07a78fd011e78bfa4" translate="yes" xml:space="preserve">
          <source>This function is called with the randomly selected data before the model is fitted to it: &lt;code&gt;is_data_valid(X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped.</source>
          <target state="translated">在对模型进行拟合之前，将使用随机选择的数据调用此函数： &lt;code&gt;is_data_valid(X, y)&lt;/code&gt; 。如果其返回值为False，则跳过当前随机选择的子样本。</target>
        </trans-unit>
        <trans-unit id="7289fd594a0de96a89a572bf0a7bd6e9501fda52" translate="yes" xml:space="preserve">
          <source>This function is equivalent to mapping load_svmlight_file over a list of files, except that the results are concatenated into a single, flat list and the samples vectors are constrained to all have the same number of features.</source>
          <target state="translated">这个函数相当于将 load_svmlight_file 映射到一个文件列表上,只是结果会被连接成一个单一的、平坦的列表,而且样本向量被限制为都具有相同数量的特征。</target>
        </trans-unit>
        <trans-unit id="828fa7414b6e6676bd49f6624bf5ec1232d13777" translate="yes" xml:space="preserve">
          <source>This function makes it possible to compute this transformation for a fixed set of class labels known ahead of time.</source>
          <target state="translated">这个函数可以对事先已知的一组固定的类标签计算这种变换。</target>
        </trans-unit>
        <trans-unit id="910452d7cd5e91358a13a185cadee882cea17632" translate="yes" xml:space="preserve">
          <source>This function modifies the estimator in-place.</source>
          <target state="translated">该函数对估计器进行就地修改。</target>
        </trans-unit>
        <trans-unit id="3e0bd9f3948e27380d0112f277598d80d17269d2" translate="yes" xml:space="preserve">
          <source>This function requires the true binary value and the target scores, which can either be probability estimates of the positive class, confidence values, or binary decisions. Here is a small example of how to use the &lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt;&lt;code&gt;roc_curve&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">此函数需要真实的二进制值和目标分数，它们可以是正类的概率估计值，置信度值或二进制决策。这是一个如何使用&lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt; &lt;code&gt;roc_curve&lt;/code&gt; &lt;/a&gt;函数的小例子：</target>
        </trans-unit>
        <trans-unit id="2ddc8c678c75b432a0f0fafa6490a9a69a784bf8" translate="yes" xml:space="preserve">
          <source>This function returns a score of the mean square difference between the actual outcome and the predicted probability of the possible outcome. The actual outcome has to be 1 or 0 (true or false), while the predicted probability of the actual outcome can be a value between 0 and 1.</source>
          <target state="translated">这个函数返回实际结果和可能结果的预测概率之间的均值平方差的分数,实际结果必须是1或0(真或假),而实际结果的预测概率可以是0和1之间的值。实际结果必须是1或0(真或假),而实际结果的预测概率可以是0和1之间的数值。</target>
        </trans-unit>
        <trans-unit id="fbdeef434a34fee928d2d9974f81cfc54768558d" translate="yes" xml:space="preserve">
          <source>This function returns posterior probabilities of classification according to each class on an array of test vectors X.</source>
          <target state="translated">这个函数根据测试向量数组X上的每个类返回分类的后验概率。</target>
        </trans-unit>
        <trans-unit id="f7adc46ef6325367984cfe5d6cabca879706d70d" translate="yes" xml:space="preserve">
          <source>This function returns the Silhouette Coefficient for each sample.</source>
          <target state="translated">该函数返回每个样本的轮廓系数。</target>
        </trans-unit>
        <trans-unit id="30221178098fdd3682a8c91454092d6226b25e4f" translate="yes" xml:space="preserve">
          <source>This function returns the mean Silhouette Coefficient over all samples. To obtain the values for each sample, use &lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt;&lt;code&gt;silhouette_samples&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">此函数返回所有样本的平均轮廓系数。要获取每个样本的值，请使用&lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt; &lt;code&gt;silhouette_samples&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="bd812dc35d867d7152375e5009e2698c8db08fc0" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists to allow for a description of the mapping for each of the valid strings.</source>
          <target state="translated">这个函数只是返回有效的对偶距离度量。它的存在是为了允许对每个有效字符串的映射进行描述。</target>
        </trans-unit>
        <trans-unit id="fa4705a70e55596dcf2ace89a6d2a8d09a9fcccf" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists, however, to allow for a verbose description of the mapping for each of the valid strings.</source>
          <target state="translated">这个函数只是返回有效的对偶距离度量。然而,它的存在是为了允许对每个有效字符串的映射进行详细描述。</target>
        </trans-unit>
        <trans-unit id="d1a7a45215b31f0644d6e686c87b329e59419299" translate="yes" xml:space="preserve">
          <source>This function won&amp;rsquo;t compute the intercept.</source>
          <target state="translated">此函数不会计算截距。</target>
        </trans-unit>
        <trans-unit id="a808622a520f852134a2d8734b9e29ce0a669efe" translate="yes" xml:space="preserve">
          <source>This function works with dense 2D arrays only.</source>
          <target state="translated">这个函数只适用于密集的二维数组。</target>
        </trans-unit>
        <trans-unit id="19a23bf41918ee91955f633ce4d818d45490ef26" translate="yes" xml:space="preserve">
          <source>This function&amp;rsquo;s formula is as follows:</source>
          <target state="translated">该函数的公式如下：</target>
        </trans-unit>
        <trans-unit id="7541ac358f5bb3bc5dcdfc1193ff72d6ac233a66" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble predicted class probabilities after each iteration of boosting and therefore allows monitoring, such as to determine the predicted class probabilities on a test set after each boost.</source>
          <target state="translated">这种生成器方法在每次迭代提升后都能得到集合预测的类概率,因此可以进行监控,比如在每次提升后确定测试集上的预测类概率。</target>
        </trans-unit>
        <trans-unit id="7c1ad29f5d19940cf714626cd821b0934b5bc400" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.</source>
          <target state="translated">这种生成器方法在每次迭代升压后都会产生合集预测,因此可以进行监控,比如在每次升压后确定对测试集的预测。</target>
        </trans-unit>
        <trans-unit id="acc74c06c673308a3e484c230b5ff2c8348cfe79" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.</source>
          <target state="translated">这种生成器方法在每次迭代升压后都能得到合集得分,因此可以进行监控,比如在每次升压后确定测试集的得分。</target>
        </trans-unit>
        <trans-unit id="1fe14f98435d58bb1786320c156e4b531f66e48b" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_multilabel_classification#sklearn.datasets.make_multilabel_classification&quot;&gt;&lt;code&gt;make_multilabel_classification&lt;/code&gt;&lt;/a&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="translated">这说明了&lt;a href=&quot;../../modules/generated/sklearn.datasets.make_multilabel_classification#sklearn.datasets.make_multilabel_classification&quot;&gt; &lt;code&gt;make_multilabel_classification&lt;/code&gt; &lt;/a&gt;数据集生成器。每个样本都包含两个特征的计数（总共最多50个），这两个特征在两个类别的每个类别中的分布不同。</target>
        </trans-unit>
        <trans-unit id="cb7462acd1f1e763247c87d170997bea5c436272" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="translated">这说明了 &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; 数据集生成器。每个样本都包含两个特征的计数（总共最多50个），这两个特征在两个类别的每个类别中的分布不同。</target>
        </trans-unit>
        <trans-unit id="b80113eed9b4b9668cc4e8b638bede5d1f2cf638" translate="yes" xml:space="preserve">
          <source>This implementation bulk-computes all neighborhood queries, which increases the memory complexity to O(n.d) where d is the average number of neighbors, while original DBSCAN had memory complexity O(n). It may attract a higher memory complexity when querying these nearest neighborhoods, depending on the &lt;code&gt;algorithm&lt;/code&gt;.</source>
          <target state="translated">此实现批量计算所有邻居查询，这将内存复杂度提高到O（nd），其中d是邻居的平均数量，而原始DBSCAN的内存复杂度为O（n）。在查询这些最近邻域时，它可能会吸引更高的内存复杂性，具体取决于 &lt;code&gt;algorithm&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="48627963240be2350bc0acdc732c6b5348961a90" translate="yes" xml:space="preserve">
          <source>This implementation deviates from the original OPTICS by first performing k-nearest-neighborhood searches on all points to identify core sizes, then computing only the distances to unprocessed points when constructing the cluster order. Note that we do not employ a heap to manage the expansion candidates, so the time complexity will be O(n^2).</source>
          <target state="translated">这个实现偏离了原来的OPTICS,首先对所有的点进行k-最近邻搜索来识别核心大小,然后在构造簇序时只计算与未处理点的距离。需要注意的是,我们没有采用堆来管理扩展候选点,所以时间复杂度将为O(n^2)。</target>
        </trans-unit>
        <trans-unit id="aed3668d0e58719270c1129ddb01322705c078e7" translate="yes" xml:space="preserve">
          <source>This implementation follows what is explained in the original paper &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;1&lt;/a&gt;. For the optimisation method, it currently uses scipy&amp;rsquo;s L-BFGS-B with a full gradient computation at each iteration, to avoid to tune the learning rate and provide stable learning.</source>
          <target state="translated">该实现遵循原始论文&lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;1&lt;/a&gt;中的解释。对于优化方法，它当前使用scipy的L-BFGS-B在每次迭代时进行全梯度计算，以避免调整学习速率并提供稳定的学习。</target>
        </trans-unit>
        <trans-unit id="92eb61902d4dfd6571a464d87feff72fe7b32901" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="translated">此实现基于R. Rubinstein，M. Zibulevsky，M.和Elad，M.，《使用批量正交匹配追踪技术报告有效实现K-SVD算法》，CS Technion，2008年4月&lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;。http：//www.cs。 technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="12813af32368fc3d74f568cdec1c9e38f408115a" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="translated">此实现基于R.Rubinstein，Z.bulevsky，M.和Elad，M.，使用批量正交匹配追踪技术报告的K-SVD算法的有效实现-CS Technion，2008年4月&lt;a href=&quot;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;.https：//www.cs。 technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6fb112845601277f8931b295b857e73c1428c8fb" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g. with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="translated">这个实现默认情况下是不节省内存的,因为它在不能使用kd-树或球树的情况下(如稀疏矩阵),构建了一个完整的配对相似度矩阵。这个矩阵将消耗n^2个浮点数。绕过这个问题的机制有以下几种。</target>
        </trans-unit>
        <trans-unit id="34d2660e23d61d989853bcf418296ddcc27d9606" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g., with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="translated">这个实现默认情况下是不节省内存的,因为在不能使用kd-树或球树的情况下(例如,使用稀疏矩阵),它构建了一个完整的配对相似度矩阵。这个矩阵会消耗n^2个浮点数。绕过这个问题的机制有以下几种。</target>
        </trans-unit>
        <trans-unit id="5e691dc0883398091a16d8a17daee0ec7cd95f29" translate="yes" xml:space="preserve">
          <source>This implementation is inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt;.</source>
          <target state="translated">此实现受到&lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM的&lt;/a&gt;启发。</target>
        </trans-unit>
        <trans-unit id="cc51c30dcd01f51cada4be15777f17eb95eb7cbd" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="translated">此实现不适用于大规模应用。特别是，scikit-learn不提供GPU支持。有关更快的基于GPU的实现以及提供更多灵活性来构建深度学习架构的框架，请参见&lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="228da043cb5452c21accbc429ac2d994bed0f4a9" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;https://scikit-learn.org/0.23/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="translated">此实现不适用于大规模应用。特别是，scikit-learn不提供GPU支持。有关更快的基于GPU的实现以及提供更多灵活性来构建深度学习体系结构的框架，请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0e30a130e6449e6025aca5fcf59ecb737e97cb91" translate="yes" xml:space="preserve">
          <source>This implementation is written in Cython and is reasonably fast. However, a faster API-compatible loader is also available at:</source>
          <target state="translated">这个实现是用Cython编写的,速度相当快。然而,一个更快的API兼容的加载器也可以在以下网站获得。</target>
        </trans-unit>
        <trans-unit id="b488dd9d3cb1238d47d93805595214963db6dd0c" translate="yes" xml:space="preserve">
          <source>This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.</source>
          <target state="translated">这个实现使用scipy.sparse.csr_matrix产生了一个稀疏的计数表示。</target>
        </trans-unit>
        <trans-unit id="42bc7bbc3f5bd0df8efbfbad62976f6ec6db583b" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that 3 PLS packages provided in the R language (R-project):</source>
          <target state="translated">本实施例提供的结果与R语言中提供的3个PLS包(R-项目)相同。</target>
        </trans-unit>
        <trans-unit id="09c013dbb84b7e3d406ea0732bc3a8236ed37cbd" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that the &amp;ldquo;plspm&amp;rdquo; package provided in the R language (R-project), using the function plsca(X, Y). Results are equal or collinear with the function &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; of the &amp;ldquo;mixOmics&amp;rdquo; package. The difference relies in the fact that mixOmics implementation does not exactly implement the Wold algorithm since it does not normalize y_weights to one.</source>
          <target state="translated">使用函数plsca（X，Y），此实现提供与R语言（R-project）中提供的&amp;ldquo; plspm&amp;rdquo;包相同的结果。结果与&amp;ldquo; mixOmics&amp;rdquo;包的函数 &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; 相等或共线。区别在于，由于mixOmics实现未将y_weights归一化，因此它并未完全实现Wold算法。</target>
        </trans-unit>
        <trans-unit id="36e4a374c505873717456a086d5c9ed44e5157f6" translate="yes" xml:space="preserve">
          <source>This implementation will refuse to center scipy.sparse matrices since it would make them non-sparse and would potentially crash the program with memory exhaustion problems.</source>
          <target state="translated">这个实现将拒绝将scipy.sparse矩阵居中,因为这会使它们变成非稀疏的,并有可能因内存耗尽问题而使程序崩溃。</target>
        </trans-unit>
        <trans-unit id="6684c1532df5f751b6b61c242ea952621dc3f4e8" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense and sparse numpy arrays of floating point values.</source>
          <target state="translated">这个实现可以处理以密集和稀疏的浮点值numpy数组表示的数据。</target>
        </trans-unit>
        <trans-unit id="b0df3cb22108e4cd0ed0fcd534ed03e427412c64" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays of floating point values for the features.</source>
          <target state="translated">这个实现是用密集的numpy数组浮点值来表示特征的数据。</target>
        </trans-unit>
        <trans-unit id="4abb3ee00da8e0ef45c7b10f884f8d272712ca81" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values.</source>
          <target state="translated">这个实现可以处理以密集numpy数组或稀疏scipy数组浮点值表示的数据。</target>
        </trans-unit>
        <trans-unit id="c3c22c958df17cff584f8c572beeb762a9a0290e" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM).</source>
          <target state="translated">这个实现可以处理以密集或稀疏的浮点值数组表示的特征数据。它所拟合的模型可以用损失参数来控制;默认情况下,它拟合的是线性支持向量机(SVM)。</target>
        </trans-unit>
        <trans-unit id="c43a7d8bb7931a79100804db2f074a29d45e4b6b" translate="yes" xml:space="preserve">
          <source>This improvement is not visible in the Silhouette Coefficient which is small for both as this measure seem to suffer from the phenomenon called &amp;ldquo;Concentration of Measure&amp;rdquo; or &amp;ldquo;Curse of Dimensionality&amp;rdquo; for high dimensional datasets such as text data. Other measures such as V-measure and Adjusted Rand Index are information theoretic based evaluation scores: as they are only based on cluster assignments rather than distances, hence not affected by the curse of dimensionality.</source>
          <target state="translated">这种改善在轮廓系数中不明显，这对于两者来说都是很小的，因为对于像文本数据这样的高维数据集，此度量似乎遭受称为&amp;ldquo;度量集中&amp;rdquo;或&amp;ldquo;维数诅咒&amp;rdquo;的现象。其他度量（例如V度量和调整后的兰德指数）都是基于信息理论的评估得分：因为它们仅基于聚类分配而不是距离，因此不受维度诅咒的影响。</target>
        </trans-unit>
        <trans-unit id="18d0a71ee91c72fbdd2b834782dff2f0f441f1d5" translate="yes" xml:space="preserve">
          <source>This index signifies the average &amp;lsquo;similarity&amp;rsquo; between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves.</source>
          <target state="translated">该指数表示聚类之间的平均&amp;ldquo;相似度&amp;rdquo;，其中相似度是一种将聚类之间的距离与聚类本身的大小进行比较的度量。</target>
        </trans-unit>
        <trans-unit id="a0d4ffe805942e66e32866a4eb458e728074d78e" translate="yes" xml:space="preserve">
          <source>This initially creates clusters of points normally distributed (std=1) about vertices of an &lt;code&gt;n_informative&lt;/code&gt;-dimensional hypercube with sides of length &lt;code&gt;2*class_sep&lt;/code&gt; and assigns an equal number of clusters to each class. It introduces interdependence between these features and adds various types of further noise to the data.</source>
          <target state="translated">最初，这将创建一个长度为 &lt;code&gt;2*class_sep&lt;/code&gt; 且边长为2 * class_sep的正态分布于（n = &lt;code&gt;n_informative&lt;/code&gt; 维超立方体的顶点周围的点簇（std = 1），并为每个类分配相等数量的簇。它引入了这些功能之间的相互依赖性，并为数据增加了各种类型的进一步噪声。</target>
        </trans-unit>
        <trans-unit id="57108bb9f4ef70d6ebe6d73913a67e52e844d200" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="translated">此接口是&lt;strong&gt;试验性的&lt;/strong&gt;，后续发行版可能会更改属性，恕不另行通知（尽管应该仅对 &lt;code&gt;data&lt;/code&gt; 和 &lt;code&gt;target&lt;/code&gt; 进行较小的更改）。</target>
        </trans-unit>
        <trans-unit id="5b14c6be212126cf2e3bdc1fe1c6fe8f3c7dc46d" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; as at version 0.20 and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="translated">此接口从0.20版开始处于&lt;strong&gt;试验状态&lt;/strong&gt;，后续版本可能会更改属性，恕不另行通知（尽管对 &lt;code&gt;data&lt;/code&gt; 和 &lt;code&gt;target&lt;/code&gt; 的更改应该很小）。</target>
        </trans-unit>
        <trans-unit id="7f6be37b4617684744b3ccc169d2c583b6e3ddc1" translate="yes" xml:space="preserve">
          <source>This is a convenience alias to &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; to do random permutations of the collections.</source>
          <target state="translated">这是 &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; 以便对集合进行随机排列的便利别名。</target>
        </trans-unit>
        <trans-unit id="4632bc2ee98a17257db1d248b06f38b79a53d4ef" translate="yes" xml:space="preserve">
          <source>This is a convenience function; the transformation is done using the default settings for &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;. For more advanced usage (stopword filtering, n-gram extraction, etc.), combine fetch_20newsgroups with a custom &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这是一种便利功能；转换使用&lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt;的默认设置完成。要进行更高级的使用（停用词过滤，n-gram提取等），请将fetch_20newsgroups与自定义&lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2b3dbf5e1c5e08d66c77786f2bcbc632afc0312a" translate="yes" xml:space="preserve">
          <source>This is a convenience routine for the sake of testing. For many metrics, the utilities in scipy.spatial.distance.cdist and scipy.spatial.distance.pdist will be faster.</source>
          <target state="translated">这是一个方便的例程,用于测试。对于许多指标,scipy.spatial.distance.cdist 和 scipy.spatial.distance.pdist 中的实用程序会更快。</target>
        </trans-unit>
        <trans-unit id="7a67e0a846a2ab3c88cb06fc2b7950cd30914abe" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. &lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</source>
          <target state="translated">这是UCI ML乳腺癌威斯康星州（诊断）数据集的副本。&lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22bae61d9be3213577df5087cb01b12cfdf8dff4" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Wine recognition datasets. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</source>
          <target state="translated">这是UCI ML Wine识别数据集的副本。&lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c52f45448ee0e84b694b7c38bdbed7fd0e586461" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML housing dataset. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</source>
          <target state="translated">这是UCI ML住房数据集的副本。&lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a6d742ac48191eb71d1c4aabf6003187f0d21a9d" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets</source>
          <target state="translated">这是一个UCI ML手写数字数据集的测试集的副本</target>
        </trans-unit>
        <trans-unit id="3dee2146876159a5a0b048cd24a612fae4a810ca" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="translated">这是UCI ML手写数字数据集测试集的副本，网址为&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handheld+Digits&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="60177910f782c7923853f8284b0287f57e3bf220" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="translated">这是UCI ML手写数字数据集测试集的副本&lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handheld+Digits&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fd4a60c08b29c6d6af237f8cfa14740252c7d04a" translate="yes" xml:space="preserve">
          <source>This is a general function, given points on a curve. For computing the area under the ROC-curve, see &lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;. For an alternative way to summarize a precision-recall curve, see &lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">给定曲线上的点，这是一项常规功能。要计算ROC曲线下的面积，请参阅&lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt;。有关汇总精确调用曲线的另一种方法，请参见&lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3944e3eb8c8ea1f918637d2548f35fa74cd97d2a" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting with &lt;code&gt;transformer_weights&lt;/code&gt;.</source>
          <target state="translated">这是ColumnTransformer构造函数的简写；它不需要也不允许命名变压器。取而代之的是，将根据其类型自动为它们指定名称。它还不允许使用 &lt;code&gt;transformer_weights&lt;/code&gt; 进行加权。</target>
        </trans-unit>
        <trans-unit id="37510c6c60985c0ea76b5bcc4364db965e5a12fd" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">这是ColumnTransformer构造函数的简写;它不需要也不允许为变换器命名。取而代之的是,将根据它们的类型自动给它们命名。它也不允许加权。</target>
        </trans-unit>
        <trans-unit id="022d95ed0540e35ea0bdce867e9a502603bc5f51" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the FeatureUnion constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">这是 FeatureUnion 构造函数的简写;它不需要也不允许为变换器命名。取而代之的是,将根据它们的类型自动给它们命名。它也不允许加权。</target>
        </trans-unit>
        <trans-unit id="52a890ca0cc5d284d366294db21e8c380349733e" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the Pipeline constructor; it does not require, and does not permit, naming the estimators. Instead, their names will be set to the lowercase of their types automatically.</source>
          <target state="translated">这是管道构造函数的简写;它不需要也不允许对估计器进行命名。取而代之的是,它们的名称将被自动设置为其类型的小写。</target>
        </trans-unit>
        <trans-unit id="bcbf4cb6d3eb7ea12d02241a9a60f7a4e6044f4d" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.predict(X)&lt;/code&gt;.</source>
          <target state="translated">这是 &lt;code&gt;estimator_.predict(X)&lt;/code&gt; 的包装。</target>
        </trans-unit>
        <trans-unit id="17ebe8027dbbfba976bb150f0e9172e06d0c02ec" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.score(X, y)&lt;/code&gt;.</source>
          <target state="translated">这是 &lt;code&gt;estimator_.score(X, y)&lt;/code&gt; 的包装。</target>
        </trans-unit>
        <trans-unit id="602675ab661ad893c615b29b13c1d56146fcfa0b" translate="yes" xml:space="preserve">
          <source>This is an alternative to passing a &lt;code&gt;backend='backend_name'&lt;/code&gt; argument to the &lt;code&gt;Parallel&lt;/code&gt; class constructor. It is particularly useful when calling into library code that uses joblib internally but does not expose the backend argument in its own API.</source>
          <target state="translated">这是将 &lt;code&gt;backend='backend_name'&lt;/code&gt; 参数传递给 &lt;code&gt;Parallel&lt;/code&gt; 类构造函数的替代方法。当调用在内部使用joblib但未在其自己的API中公开后端参数的库代码时，此功能特别有用。</target>
        </trans-unit>
        <trans-unit id="47f9c3947e84bb8a914aa6f2f19cb2c5e42e970f" translate="yes" xml:space="preserve">
          <source>This is an example of &lt;strong&gt;bias/variance tradeoff&lt;/strong&gt;: the larger the ridge &lt;code&gt;alpha&lt;/code&gt; parameter, the higher the bias and the lower the variance.</source>
          <target state="translated">这是&lt;strong&gt;偏差/方差折衷的&lt;/strong&gt;一个示例：脊 &lt;code&gt;alpha&lt;/code&gt; 参数越大，偏差越大，方差越小。</target>
        </trans-unit>
        <trans-unit id="d75c7c933c17fefbabe7c2e292b885d0ecac3a21" translate="yes" xml:space="preserve">
          <source>This is an example of applying &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; on a corpus of documents and extract additive models of the topic structure of the corpus. The output is a list of topics, each represented as a list of terms (weights are not shown).</source>
          <target state="translated">这是在文档语料库上应用&lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt;并提取该语料库主题结构的附加模型的示例。输出是主题列表，每个主题都表示为术语列表（未显示权重）。</target>
        </trans-unit>
        <trans-unit id="53176f2993974522405fa17c9a80a84e38a4969c" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used for classification using an out-of-core approach: learning from data that doesn&amp;rsquo;t fit into main memory. We make use of an online classifier, i.e., one that supports the partial_fit method, that will be fed with batches of examples. To guarantee that the features space remains the same over time we leverage a HashingVectorizer that will project each example into the same feature space. This is especially useful in the case of text classification where new features (words) may appear in each batch.</source>
          <target state="translated">这是一个示例，显示了如何使用核心方法将scikit-learn用于分类：从不适合主内存的数据中学习。我们利用一种在线分类器，即一种支持partial_fit方法的分类器，该分类器将提供大量示例。为了确保要素空间随着时间的推移保持不变，我们利用了HashingVectorizer，它将每个示例投影到相同的要素空间中。这在文本分类的情况下特别有用，在文本分类中，每批中都可能出现新功能（单词）。</target>
        </trans-unit>
        <trans-unit id="1620bf9fc1f7795235eabc8e2a67657eca16390d" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.</source>
          <target state="translated">这是一个展示如何使用 scikit-learn 使用单词袋方法按主题对文档进行分类的例子。这个例子使用scipy.sparse矩阵来存储特征,并展示了各种可以有效处理稀疏矩阵的分类器。</target>
        </trans-unit>
        <trans-unit id="687fdb042e4ef171de769c4722977550577ec678" translate="yes" xml:space="preserve">
          <source>This is an example showing how the scikit-learn can be used to cluster documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features instead of standard numpy arrays.</source>
          <target state="translated">这个例子展示了如何使用 scikit-learn 通过使用词袋方法按主题进行文档聚类。这个例子使用 scipy.sparse 矩阵来存储特征,而不是标准的 numpy 数组。</target>
        </trans-unit>
        <trans-unit id="c505c2f7b70a5aa0d5582bdc56a7d9627b32a4d8" translate="yes" xml:space="preserve">
          <source>This is an example showing the prediction latency of various scikit-learn estimators.</source>
          <target state="translated">这是一个显示各种scikit-learn估计器的预测延迟的例子。</target>
        </trans-unit>
        <trans-unit id="9e4f7a05490ee1267f03d9980bace7147baa0b76" translate="yes" xml:space="preserve">
          <source>This is an extension of the algorithm in scipy.stats.mode.</source>
          <target state="translated">这是scipy.stats.mode中算法的扩展。</target>
        </trans-unit>
        <trans-unit id="375819c22c211b4c7fc97205acd724c3a575f620" translate="yes" xml:space="preserve">
          <source>This is an implementation that uses the result of the previous model to speed up computations along the set of solutions, making it faster than sequentially calling LogisticRegression for the different parameters. Note that there will be no speedup with liblinear solver, since it does not handle warm-starting.</source>
          <target state="translated">这是一个使用前一个模型的结果沿着解集加速计算的实现,使得它比连续调用LogisticRegression来处理不同的参数要快。需要注意的是,使用liblinear求解器不会有任何加速,因为它不处理暖启动。</target>
        </trans-unit>
        <trans-unit id="89098058da4c55a1db96b87aadaa162a0a15baba" translate="yes" xml:space="preserve">
          <source>This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a &lt;code&gt;score&lt;/code&gt; function, or &lt;code&gt;scoring&lt;/code&gt; must be passed.</source>
          <target state="translated">假定这样做是为了实现scikit-learn估计器接口。估算者需要提供 &lt;code&gt;score&lt;/code&gt; 函数，或者必须通过 &lt;code&gt;scoring&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a9f1a5b0fa7d00ad69170d1ab81bf1031dee11a2" translate="yes" xml:space="preserve">
          <source>This is called a &lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; cross-validation.</source>
          <target state="translated">这称为&lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;交叉验证。</target>
        </trans-unit>
        <trans-unit id="2e974743bc0fdffbf7238debaf0ee76bb5a5d9b2" translate="yes" xml:space="preserve">
          <source>This is called cosine similarity, because Euclidean (L2) normalization projects the vectors onto the unit sphere, and their dot product is then the cosine of the angle between the points denoted by the vectors.</source>
          <target state="translated">这就是所谓的余弦相似性,因为欧几里得(L2)归一化将向量投射到单位球面上,它们的点积就是向量所表示的点之间角度的余弦。</target>
        </trans-unit>
        <trans-unit id="9b01365512b47448f649e450ddd111360a73cfc3" translate="yes" xml:space="preserve">
          <source>This is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;curse of dimensionality&lt;/a&gt; and is a core problem that machine learning addresses.</source>
          <target state="translated">这称为&lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;维数诅咒，&lt;/a&gt;是机器学习解决的核心问题。</target>
        </trans-unit>
        <trans-unit id="25e5e11d6a0e13a60841f1cb72db59989d03472f" translate="yes" xml:space="preserve">
          <source>This is currently implemented in the following classes:</source>
          <target state="translated">目前在以下类中实现。</target>
        </trans-unit>
        <trans-unit id="a774a1be5070f83615f896d6d2ec16ebfbe92e4e" translate="yes" xml:space="preserve">
          <source>This is done in 2 steps:</source>
          <target state="translated">这是通过2个步骤完成的。</target>
        </trans-unit>
        <trans-unit id="0c564a0d4cfad247ff47792f5a12558130a84f0c" translate="yes" xml:space="preserve">
          <source>This is equivalent to fit followed by transform, but more efficiently implemented.</source>
          <target state="translated">这相当于先拟合后变换,但实现效率更高。</target>
        </trans-unit>
        <trans-unit id="831022bba18e9ed70a7a762cd8243e7523afeddb" translate="yes" xml:space="preserve">
          <source>This is especially useful when the whole dataset is too big to fit in memory at once.</source>
          <target state="translated">当整个数据集太大而无法一次放入内存时,这一点特别有用。</target>
        </trans-unit>
        <trans-unit id="75c0bef753e28aecf63e47221c52fe362a027981" translate="yes" xml:space="preserve">
          <source>This is implemented as &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; which will return the label of the class with most votes by estimators predicting the outcome of a decision for each possible class pair.</source>
          <target state="translated">这以 &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; 形式实现，该函数将通过估计器为每个可能的类对预测决策结果的方法，返回投票最多的类的标签。</target>
        </trans-unit>
        <trans-unit id="9b2a6723fed7b2d139e18e341020f963dc7f8450" translate="yes" xml:space="preserve">
          <source>This is implemented by linking the points X into the graph of geodesic distances of the training data. First the &lt;code&gt;n_neighbors&lt;/code&gt; nearest neighbors of X are found in the training data, and from these the shortest geodesic distances from each point in X to each point in the training data are computed in order to construct the kernel. The embedding of X is the projection of this kernel onto the embedding vectors of the training set.</source>
          <target state="translated">这是通过将点X链接到训练数据的测地线距离图中来实现的。首先，在训练数据中找到X 的 &lt;code&gt;n_neighbors&lt;/code&gt; 个最近邻居，然后从中计算出X中每个点到训练数据中每个点的最短测地距离，以构造核。X的嵌入是此内核在训练集的嵌入向量上的投影。</target>
        </trans-unit>
        <trans-unit id="51ae8a82b3eff6fb295f70aa28171d41c73ac3db" translate="yes" xml:space="preserve">
          <source>This is implemented in &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt;. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; constructor parameter. This parameter has no influence on &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这在&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; 中&lt;/a&gt;实现。可以使用 &lt;code&gt;n_components&lt;/code&gt; 构造函数参数设置所需的尺寸。此参数对&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt; &lt;/a&gt;没有影响。</target>
        </trans-unit>
        <trans-unit id="8989f9efb82b77a4f24da08f40263dc49964cf0b" translate="yes" xml:space="preserve">
          <source>This is implemented in the &lt;code&gt;transform&lt;/code&gt; method. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; parameter. This parameter has no influence on the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods.</source>
          <target state="translated">这是在 &lt;code&gt;transform&lt;/code&gt; 方法中实现的。可以使用 &lt;code&gt;n_components&lt;/code&gt; 参数设置所需的尺寸。该参数对 &lt;code&gt;fit&lt;/code&gt; 和 &lt;code&gt;predict&lt;/code&gt; 方法没有影响。</target>
        </trans-unit>
        <trans-unit id="de8220f3c95931fc4241bdd5334e66fca04da2f0" translate="yes" xml:space="preserve">
          <source>This is known as &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">这称为&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1c0b6d6227299e9452904f2af6316a83adba923a" translate="yes" xml:space="preserve">
          <source>This is minimized if \(h(x_i)\) is fitted to predict a value that is proportional to the negative gradient \(-g_i\). Therefore, at each iteration, &lt;strong&gt;the estimator&lt;/strong&gt;\(h_m\)&lt;strong&gt;is fitted to predict the negative gradients of the samples&lt;/strong&gt;. The gradients are updated at each iteration. This can be considered as some kind of gradient descent in a functional space.</source>
          <target state="translated">如果拟合\（h（x_i）\）以预测与负梯度\（-g_i \）成正比的值，则这将最小化。因此，在每次迭代中，都&lt;strong&gt;使用估计量&lt;/strong&gt;\（h_m \）&lt;strong&gt;来预测样本的负梯度&lt;/strong&gt;。在每次迭代时更新梯度。这可以认为是功能空间中的某种梯度下降。</target>
        </trans-unit>
        <trans-unit id="1d1ef16c8ffe6df8c7a1a81b132f67cdda1b92ea" translate="yes" xml:space="preserve">
          <source>This is more efficient than calling fit followed by transform.</source>
          <target state="translated">这比调用fit后再进行transform更有效率。</target>
        </trans-unit>
        <trans-unit id="1dfb3afc660617ced3002fefa24847b5bb1a14dd" translate="yes" xml:space="preserve">
          <source>This is mostly equivalent to calling:</source>
          <target state="translated">这主要相当于打电话。</target>
        </trans-unit>
        <trans-unit id="bbd51f304b678a157464ff7ab03c52123d04218d" translate="yes" xml:space="preserve">
          <source>This is not a symmetric function.</source>
          <target state="translated">这不是一个对称函数。</target>
        </trans-unit>
        <trans-unit id="0b5c42967b0e34c52656dd80a4e659c6f0fa2181" translate="yes" xml:space="preserve">
          <source>This is not exactly the same as &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt;. The authors of &lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt; prefer the version above as it is always positive definite. Since the kernel is additive, it is possible to treat all components \(x_i\) separately for embedding. This makes it possible to sample the Fourier transform in regular intervals, instead of approximating using Monte Carlo sampling.</source>
          <target state="translated">这与 &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt; 并不完全相同。&lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt;的作者更喜欢上面的版本，因为它始终是肯定的。由于内核是可加性的，因此可以单独处理所有组件\（x_i \）进行嵌入。这样就可以以规则的间隔对傅立叶变换进行采样，而不是使用蒙特卡洛采样进行近似。</target>
        </trans-unit>
        <trans-unit id="f7f802fcac19c1c8ed1c55f673312d761a2c94a7" translate="yes" xml:space="preserve">
          <source>This is not the case for &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt;: both are bound by the relationship:</source>
          <target state="translated">对于&lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt;并非如此：两者都受以下关系约束：</target>
        </trans-unit>
        <trans-unit id="5d73f5b087f2ecb2dadb8778d3d18cfc19507034" translate="yes" xml:space="preserve">
          <source>This is not true for &lt;code&gt;mutual_info_score&lt;/code&gt;, which is therefore harder to judge:</source>
          <target state="translated">对于 &lt;code&gt;mutual_info_score&lt;/code&gt; 并非如此，因此很难判断：</target>
        </trans-unit>
        <trans-unit id="982101a3d677907e48e034c807cde26531a0468b" translate="yes" xml:space="preserve">
          <source>This is only available if no vocabulary was given.</source>
          <target state="translated">只有在没有给定词汇的情况下才能使用。</target>
        </trans-unit>
        <trans-unit id="0ca1a333516e3b52907835d092958662636ea528" translate="yes" xml:space="preserve">
          <source>This is particularly important for doing grid searches:</source>
          <target state="translated">这对于做网格搜索尤为重要。</target>
        </trans-unit>
        <trans-unit id="2413be66af5e312ff97e484aff33c56868971fbe" translate="yes" xml:space="preserve">
          <source>This is perhaps the best known database to be found in the pattern recognition literature. Fisher&amp;rsquo;s paper is a classic in the field and is referenced frequently to this day. (See Duda &amp;amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.</source>
          <target state="translated">这也许是模式识别文献中最著名的数据库。费舍尔的论文是该领域的经典之作，至今一直被引用。（例如，请参见Duda＆Hart。）数据集包含3个类，每个类有50个实例，其中每个类都涉及一种虹膜植物。一类与另一类可线性分离；另一类可线性分离。后者不能线性分离。</target>
        </trans-unit>
        <trans-unit id="32ef6d8e689e0cbccf726fb7a94339c2864c487f" translate="yes" xml:space="preserve">
          <source>This is present only if &lt;code&gt;refit&lt;/code&gt; is not False.</source>
          <target state="translated">仅当 &lt;code&gt;refit&lt;/code&gt; 不为False 时才存在。</target>
        </trans-unit>
        <trans-unit id="717414c2af196799a3d1dc1aec1269a995318377" translate="yes" xml:space="preserve">
          <source>This is similar to the error set size, but weighted by the number of relevant and irrelevant labels. The best performance is achieved with a ranking loss of zero.</source>
          <target state="translated">这与错误集大小类似,但由相关和不相关标签的数量加权。排名损失为零时,性能最佳。</target>
        </trans-unit>
        <trans-unit id="00034266cafd87d919959c8134650d981f2c4466" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="translated">这是scikit-learn的类和函数参考。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;完整的用户指南&lt;/a&gt;以获取更多详细信息，因为类和函数的原始规范可能不足以提供有关其用法的完整指南。有关在API上重复的概念的参考，请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;&amp;ldquo;通用术语表和API元素&amp;rdquo;&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0706513e1a92902a9b1d8477404304aebd12678b" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="translated">这是scikit-learn的类和函数参考。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/user_guide.html#user-guide&quot;&gt;完整的用户指南&lt;/a&gt;以获取更多详细信息，因为类和函数的原始规范可能不足以提供有关其用法的完整指南。有关在API上重复的概念的参考，请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;&amp;ldquo;通用术语表和API元素&amp;rdquo;&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="486cb190a77f54ef106791f7b4834d94d87b42d4" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns &lt;code&gt;y_pred&lt;/code&gt; probabilities for its training data &lt;code&gt;y_true&lt;/code&gt;. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="translated">这是在（多项式）逻辑回归及其扩展（例如神经网络）中使用的损失函数，定义为返回其训练数据 &lt;code&gt;y_true&lt;/code&gt; 的 &lt;code&gt;y_pred&lt;/code&gt; 概率的逻辑模型的负对数似然率。仅为两个或多个标签定义对数丢失。对于在{0,1}中具有真实标签yt且yt = 1的估计概率yp的单个样本，对数损失为</target>
        </trans-unit>
        <trans-unit id="9c0b38fb17b983574b86706f2172c4c4bac1c6a5" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier&amp;rsquo;s predictions. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="translated">这是在（多项式）逻辑回归及其扩展（例如神经网络）中使用的损失函数，定义为给定概率分类器预测的真实标签的负对数似然性。仅为两个或多个标签定义对数丢失。对于在{0,1}中具有真实标签yt且估计概率yp为yt = 1的单个样本，对数损失为</target>
        </trans-unit>
        <trans-unit id="a9111de5c7f4d9db0e2dc4faf926c5c47ae0eb12" translate="yes" xml:space="preserve">
          <source>This is the result of calling &lt;code&gt;method&lt;/code&gt;</source>
          <target state="translated">这是调用 &lt;code&gt;method&lt;/code&gt; 的结果</target>
        </trans-unit>
        <trans-unit id="611492c50f944d397ce592f12eabee4801e28de1" translate="yes" xml:space="preserve">
          <source>This is the structured version, that takes into account some topological structure between samples.</source>
          <target state="translated">这是结构化的版本,它考虑到了样本之间的一些拓扑结构。</target>
        </trans-unit>
        <trans-unit id="eb0a6c68cdbb70ef7265210b8b8760243faa6912" translate="yes" xml:space="preserve">
          <source>This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.</source>
          <target state="translated">这对于拟合截距项的实现很有用,否则无法直接拟合它。</target>
        </trans-unit>
        <trans-unit id="1c420e62ce6697ac415dbca5798c0153080b025c" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">如果必须重用先前使用的模型的存储属性，这将很有用。如果设置为False，则每次调用时系数都会被改写。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="036c7996302f5b904a8b61c47c147a7a9733676a" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">如果必须重新使用先前使用的模型的存储属性，这将很有用。如果设置为False，则每次适合调用时都将重写系数。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2abc93ddea964d3eb32a39867456d5dfe5ef9180" translate="yes" xml:space="preserve">
          <source>This is visible if we compare the standard deviations of different features.</source>
          <target state="translated">如果我们比较不同特征的标准差,就可以看出这一点。</target>
        </trans-unit>
        <trans-unit id="42f2c0052d88e51f5df6c26752c192f81040ec01" translate="yes" xml:space="preserve">
          <source>This kernel is a popular choice for computing the similarity of documents represented as tf-idf vectors. &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; accepts &lt;code&gt;scipy.sparse&lt;/code&gt; matrices. (Note that the tf-idf functionality in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; can produce normalized vectors, in which case &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; is equivalent to &lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt;&lt;code&gt;linear_kernel&lt;/code&gt;&lt;/a&gt;, only slower.)</source>
          <target state="translated">该内核是用于计算以tf-idf向量表示的文档的相似度的流行选择。&lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt;接受 &lt;code&gt;scipy.sparse&lt;/code&gt; 矩阵。（请注意， &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; 中的tf-idf功能可以生成规范化的矢量，在这种情况下，&lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt;等效于&lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt; &lt;code&gt;linear_kernel&lt;/code&gt; &lt;/a&gt;，只是速度较慢。）</target>
        </trans-unit>
        <trans-unit id="f1fbcea40cf4aba903be6eddf36c859a1718e3b8" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth.</source>
          <target state="translated">这个核是无限可微分的,这意味着以这个核作为协方函数的GP具有所有阶数的均方导数,因此是非常平稳的。</target>
        </trans-unit>
        <trans-unit id="ffa176d62610a7e6d304ab9efadadddacf7fa00e" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. See &lt;a href=&quot;#redc669bcbe98-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;, Chapter 4, Section 4.2, for further details of the RBF kernel.</source>
          <target state="translated">该内核是无限可微的，这意味着具有该内核作为协方差函数的GP具有所有阶的均方导数，因此非常平滑。有关RBF内核的更多详细信息，请参见&lt;a href=&quot;#redc669bcbe98-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;，第4章，第4.2节。</target>
        </trans-unit>
        <trans-unit id="6ad60f9f3ef06c9a3898414b0afc593eaff20c1d" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. The prior and posterior of a GP resulting from an RBF kernel are shown in the following figure:</source>
          <target state="translated">这个核是无限可微分的,这意味着以这个核作为协方函数的GP具有所有阶数的均方导数,因此是非常平稳的。由RBF核产生的GP的前、后值如下图所示。</target>
        </trans-unit>
        <trans-unit id="6cbded70a18b870dfff7fda8d59e204ebd77900f" translate="yes" xml:space="preserve">
          <source>This kind of singular profiles is often seen in practice, for instance:</source>
          <target state="translated">这种单一的型材在实践中经常见到,比如。</target>
        </trans-unit>
        <trans-unit id="30529b10016c80d5c9ab1e213672fabc65487573" translate="yes" xml:space="preserve">
          <source>This last point is expected due to the nature of the problem: the occurrence of accidents is mostly dominated by circumstantial causes that are not captured in the columns of the dataset and can indeed be considered as purely random.</source>
          <target state="translated">最后一点是预料之中的,因为问题的性质:事故的发生大多以间接原因为主,而这些原因并没有被数据集的列子所捕获,确实可以认为是纯随机的。</target>
        </trans-unit>
        <trans-unit id="1df4414d1e47e9ea41e98b8c6e13b5eeb49e06ac" translate="yes" xml:space="preserve">
          <source>This left out portion can be used to estimate the generalization error without having to rely on a separate validation set. This estimate comes &amp;ldquo;for free&amp;rdquo; as no additional data is needed and can be used for model selection.</source>
          <target state="translated">这个遗漏的部分可以用来估计泛化误差，而不必依赖单独的验证集。该估计是&amp;ldquo;免费&amp;rdquo;的，因为不需要其他数据，可以用于模型选择。</target>
        </trans-unit>
        <trans-unit id="4f52c7809ab985057ba93af9b88459b0d10b33a2" translate="yes" xml:space="preserve">
          <source>This makes sure that the loss function is not heavily influenced by the outliers while not completely ignoring their effect.</source>
          <target state="translated">这就保证了损失函数不会受到离群值的严重影响,同时也不会完全忽略其影响。</target>
        </trans-unit>
        <trans-unit id="2fb338a66a8f54901bcaa2314035cd86710a7d6d" translate="yes" xml:space="preserve">
          <source>This means each coefficient \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="translated">这意味着每一个系数(w_{i}\)都是从高斯分布中抽取出来的,以零为中心,精度为(lambda_{i}\)。</target>
        </trans-unit>
        <trans-unit id="4826ff4b754b03a246d73c38aa2c971ffdf335e1" translate="yes" xml:space="preserve">
          <source>This means each weight \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="translated">这意味着每个权重(w_{i})都是从高斯分布中抽取的,以零为中心,精度为(lambda_{i})。</target>
        </trans-unit>
        <trans-unit id="de2308f740624c092eea038ac13deb5af2b1fa80" translate="yes" xml:space="preserve">
          <source>This means that any classifiers handling multi-output multiclass or multi-task classification tasks, support the multi-label classification task as a special case. Multi-task classification is similar to the multi-output classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="translated">这意味着,任何处理多输出多类或多任务分类任务的分类器,都会支持多标签分类任务这一特殊情况。多任务分类与多输出分类任务类似,但模型公式不同。更多信息,请参见相关估计器文档。</target>
        </trans-unit>
        <trans-unit id="6157bc0b8c2f67c8a593bf2d12852c000be43e72" translate="yes" xml:space="preserve">
          <source>This measure is not adjusted for chance. Therefore &lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt;&lt;code&gt;adjusted_mutual_info_score&lt;/code&gt;&lt;/a&gt; might be preferred.</source>
          <target state="translated">这项措施没有调整的机会。因此，&lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt; &lt;code&gt;adjusted_mutual_info_score&lt;/code&gt; &lt;/a&gt;可能是首选。</target>
        </trans-unit>
        <trans-unit id="cca48ea1404a91d2df7b18cac656df30067cb12b" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each boosting iteration.</source>
          <target state="translated">这种方法可以在每次升压迭代后进行监控(即确定测试集的误差)。</target>
        </trans-unit>
        <trans-unit id="778da8cdceb825f45e49260c13130972c415ba18" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each stage.</source>
          <target state="translated">这种方法可以在每个阶段后进行监测(即确定测试集的误差)。</target>
        </trans-unit>
        <trans-unit id="893e20b8eaafff147aad0ee519c22b2be0783798" translate="yes" xml:space="preserve">
          <source>This method allows to generalize prediction to &lt;em&gt;new observations&lt;/em&gt; (not in the training set). Only available for novelty detection (when novelty is set to True).</source>
          <target state="translated">这种方法可以将预测推广到&lt;em&gt;新的观测值&lt;/em&gt;（不在训练集中）。仅可用于新颖性检测（新颖性设置为True时）。</target>
        </trans-unit>
        <trans-unit id="e13bbab31202d773dbd5b155d7e0b7799ca54f84" translate="yes" xml:space="preserve">
          <source>This method computes the least squares solution using a singular value decomposition of X. If X is a matrix of size (n, p) this method has a cost of \(O(n p^2)\), assuming that \(n \geq p\).</source>
          <target state="translated">如果X是一个大小为(n,p)的矩阵,这种方法的成本为(O(n p^2)\),假设(n geq p\)。</target>
        </trans-unit>
        <trans-unit id="dc0919b0c811a79ed295c00492df459fa5ab93e8" translate="yes" xml:space="preserve">
          <source>This method doesn&amp;rsquo;t do anything. It exists purely for compatibility with the scikit-learn transformer API.</source>
          <target state="translated">此方法没有任何作用。纯粹为了与scikit-learn转换器API兼容而存在。</target>
        </trans-unit>
        <trans-unit id="89035c0aee87e0125ffcf7bf5f0dbe56fcfb74a9" translate="yes" xml:space="preserve">
          <source>This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">这种方法有一定的性能和数值稳定性开销,因此最好在尽可能大的数据块上调用partial_fit(只要在内存预算中拟合),以隐藏开销。</target>
        </trans-unit>
        <trans-unit id="a344504140059db6f88458066c961354f795c6a7" translate="yes" xml:space="preserve">
          <source>This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">这个方法有一定的性能开销,因此最好在尽可能大的数据块上调用partial_fit(只要在内存预算内拟合)来隐藏开销。</target>
        </trans-unit>
        <trans-unit id="03d61ee68976e414aa4354d3a63287b0819f990d" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity as &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="translated">此方法的复杂度与&lt;a href=&quot;#ordinary-least-squares&quot;&gt;普通最小二乘相同&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ceeeb1e178fb9959d4ffe786c9917a8fc68013bb" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity than an &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="translated">此方法的复杂度与&lt;a href=&quot;#ordinary-least-squares&quot;&gt;普通最小二乘法相同&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8149d43c4db3023940e20ddee18dfd4caaeb24b1" translate="yes" xml:space="preserve">
          <source>This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.</source>
          <target state="translated">这个方法有望在一个数据集的不同块上连续调用几次,从而实现核心外学习或在线学习。</target>
        </trans-unit>
        <trans-unit id="7914e16bc2009e2d4fc76b2006a65a031a42eb76" translate="yes" xml:space="preserve">
          <source>This method is just there to implement the usual API and hence work in pipelines.</source>
          <target state="translated">这个方法只是为了实现通常的API,从而在管道中工作。</target>
        </trans-unit>
        <trans-unit id="53a4e9f6af590018ff1a37b6f68db2405dd79282" translate="yes" xml:space="preserve">
          <source>This method is just there to mark the fact that this transformer can work in a streaming setup.</source>
          <target state="translated">这个方法只是为了标志这个变压器可以在流媒体设置中工作。</target>
        </trans-unit>
        <trans-unit id="1ad1f3e2c791502dcf55d0ea0c930c86843ade76" translate="yes" xml:space="preserve">
          <source>This method is meant to be called concurrently by the multiprocessing callback. We rely on the thread-safety of dispatch_one_batch to protect against concurrent consumption of the unprotected iterator.</source>
          <target state="translated">这个方法是要被多进程回调并发调用的。我们依靠dispatch_one_batch的线程安全保护来防止未受保护的迭代器的并发消耗。</target>
        </trans-unit>
        <trans-unit id="4e81340dab29281a8d6b3bd99833383bb408f46c" translate="yes" xml:space="preserve">
          <source>This method is not deterministic: it computes a quantity called the free energy on X, then on a randomly corrupted version of X, and returns the log of the logistic function of the difference.</source>
          <target state="translated">这种方法不是确定性的:它在X上计算一个叫做自由能的量,然后在X的随机损坏版本上计算,并返回差值的对数函数的对数。</target>
        </trans-unit>
        <trans-unit id="483c17ab697933f17e74386d9739e36cf3fc93e7" translate="yes" xml:space="preserve">
          <source>This method is only available for log loss and modified Huber loss.</source>
          <target state="translated">这种方法只适用于对数损失和修正的Huber损失。</target>
        </trans-unit>
        <trans-unit id="d7475ebc10f647671bee9a4be7afee1b81279276" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">这种方法提供了一种安全的方法,将距离矩阵作为输入,同时保留了与许多其他采用向量数组的算法的兼容性。</target>
        </trans-unit>
        <trans-unit id="b5d8e2fef5ebecb0c66f96f2926a64438412f355" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a kernel matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">这种方法提供了一种安全的方式来接收一个内核矩阵作为输入,同时保留了与其他许多接收向量数组的算法的兼容性。</target>
        </trans-unit>
        <trans-unit id="c662dd229414f848149c194436efac32b71db4c2" translate="yes" xml:space="preserve">
          <source>This method returns a Fortran-ordered array. To convert it to a C-ordered array, use &amp;lsquo;np.ascontiguousarray&amp;rsquo;.</source>
          <target state="translated">此方法返回一个按Fortran排序的数组。要将其转换为C顺序的数组，请使用'np.ascontiguousarray'。</target>
        </trans-unit>
        <trans-unit id="0fc2db598aaa9c1a0947d8f73a1238d30285a532" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a distance matrix, and returns a distance matrix. If the input is a vector array, the distances are computed. If the input is a distances matrix, it is returned instead.</source>
          <target state="translated">本方法接受一个向量数组或距离矩阵,并返回一个距离矩阵。如果输入的是一个向量数组,则计算距离。如果输入的是距离矩阵,则返回距离矩阵。</target>
        </trans-unit>
        <trans-unit id="924736c0bae89c3f4376281e6a105fa549739eb4" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a kernel matrix, and returns a kernel matrix. If the input is a vector array, the kernels are computed. If the input is a kernel matrix, it is returned instead.</source>
          <target state="translated">本方法接受一个向量数组或内核矩阵,并返回一个内核矩阵。如果输入的是一个向量数组,则计算核数。如果输入是一个向量数组,则计算核数,如果输入是一个核矩阵,则返回核数。</target>
        </trans-unit>
        <trans-unit id="b80df7fbbffdde8aff9c30af4a5bee17e602075b" translate="yes" xml:space="preserve">
          <source>This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.</source>
          <target state="translated">这种方法将特征转换为遵循均匀或正态分布。因此,对于一个给定的特征,这种转换倾向于分散最常见的值。它还可以减少(边际)离群值的影响:因此,这是一种稳健的预处理方案。</target>
        </trans-unit>
        <trans-unit id="88cc56a80a6739c5287afd3119dab66fa95d86a9" translate="yes" xml:space="preserve">
          <source>This method will raise a &lt;code&gt;ValueError&lt;/code&gt; if any of the estimators do not have &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">如果任何估计量都不具有 &lt;code&gt;predict_proba&lt;/code&gt; ,则此方法将引发 &lt;code&gt;ValueError&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4a6448f2646e45809baed97b35289a513191212b" translate="yes" xml:space="preserve">
          <source>This method works similarly to the builtin &lt;code&gt;apply&lt;/code&gt;, except that the function is called only if the cache is not up to date.</source>
          <target state="translated">此方法的工作方式与内置 &lt;code&gt;apply&lt;/code&gt; 相似，只是仅在缓存不是最新的时才调用该函数。</target>
        </trans-unit>
        <trans-unit id="3b270b097c02b54b15c6706faba2a05992e48391" translate="yes" xml:space="preserve">
          <source>This metric is furthermore symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.</source>
          <target state="translated">该指标是进一步对称：开关 &lt;code&gt;label_true&lt;/code&gt; 与 &lt;code&gt;label_pred&lt;/code&gt; 将返回相同的分数值。当不知道真实的地面事实时，这对于测量两个独立标签分配策略在同一数据集上的一致性很有用。</target>
        </trans-unit>
        <trans-unit id="b8da4b4fabd4786b82c03e2c15a17659173e15c8" translate="yes" xml:space="preserve">
          <source>This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score value in any way.</source>
          <target state="translated">此度量标准与标签的绝对值无关：类或群集标签值的排列不会以任何方式更改得分值。</target>
        </trans-unit>
        <trans-unit id="bfbb6fef2be45da43d1153172735208301268ab3" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">该指标是不对称的：开关 &lt;code&gt;label_true&lt;/code&gt; 与 &lt;code&gt;label_pred&lt;/code&gt; 将返回&lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt;这将是不同一般。</target>
        </trans-unit>
        <trans-unit id="d6ecae2ce63387462768b5daf2f548b32eba4de4" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">该指标是不对称的：开关 &lt;code&gt;label_true&lt;/code&gt; 与 &lt;code&gt;label_pred&lt;/code&gt; 将返回&lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt;这将是不同一般。</target>
        </trans-unit>
        <trans-unit id="b4ddf27eda44a85481c7034e578198a043591cb2" translate="yes" xml:space="preserve">
          <source>This metric is not well-defined for single samples and will return a NaN value if n_samples is less than two.</source>
          <target state="translated">这个度量标准对于单个样本没有很好的定义,如果n_samples小于两个,将返回一个NaN值。</target>
        </trans-unit>
        <trans-unit id="e3d29b108d9b9b14881da7a1115d336ab614cf19" translate="yes" xml:space="preserve">
          <source>This metric is used in multilabel ranking problem, where the goal is to give better rank to the labels associated to each sample.</source>
          <target state="translated">这个度量用于多标签排名问题,目标是给每个样本相关的标签更好的排名。</target>
        </trans-unit>
        <trans-unit id="aca1523dd1402afa978fd168a95010ba6eea69bb" translate="yes" xml:space="preserve">
          <source>This might be clearer with an example: consider a three class problem with class 0 having three support vectors \(v^{0}_0, v^{1}_0, v^{2}_0\) and class 1 and 2 having two support vectors \(v^{0}_1, v^{1}_1\) and \(v^{0}_2, v^{1}_2\) respectively. For each support vector \(v^{j}_i\), there are two dual coefficients. Let&amp;rsquo;s call the coefficient of support vector \(v^{j}_i\) in the classifier between classes \(i\) and \(k\)\(\alpha^{j}_{i,k}\). Then &lt;code&gt;dual_coef_&lt;/code&gt; looks like this:</source>
          <target state="translated">用一个示例可能会更清楚：考虑一个三类问题，其中类别0具有三个支持向量\（v ^ {0} _0，v ^ {1} _0，v ^ {2} _0 \）且类别1和2具有三个支持向量两个支持向量\（v ^ {0} _1，v ^ {1} _1 \）和\（v ^ {0} _2，v ^ {1} _2 \）。对于每个支持向量\（v ^ {j} _i \），有两个对偶系数。我们将分类器\（i \）和\（k \）\（\ alpha ^ {j} _ {i，k} \）之间的分类器中的支持向量\（v ^ {j} _i \）称为系数。然后， &lt;code&gt;dual_coef_&lt;/code&gt; 看起来像这样：</target>
        </trans-unit>
        <trans-unit id="70091de439c388c847d5db9bb63c11ef6af9aff3" translate="yes" xml:space="preserve">
          <source>This might be made more clear by an example:</source>
          <target state="translated">举个例子也许能更清楚地说明这一点。</target>
        </trans-unit>
        <trans-unit id="a18c0c170fadd6145ebf30e97149394844cb89ac" translate="yes" xml:space="preserve">
          <source>This mixin provides a feature selector implementation with &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;inverse_transform&lt;/code&gt; functionality given an implementation of &lt;code&gt;_get_support_mask&lt;/code&gt;.</source>
          <target state="translated">给定 &lt;code&gt;_get_support_mask&lt;/code&gt; 的实现，此mixin提供了具有 &lt;code&gt;transform&lt;/code&gt; 和 &lt;code&gt;inverse_transform&lt;/code&gt; 功能的功能选择器实现。</target>
        </trans-unit>
        <trans-unit id="87c35466b9ea86a2466ad7ff0fff224c499553d9" translate="yes" xml:space="preserve">
          <source>This model has many parameters, however the default values are quite reasonable (please see the &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;reference documentation&lt;/a&gt; for the details):</source>
          <target state="translated">该模型具有许多参数，但是默认值是相当合理的（有关详细信息，请参见&lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;参考文档&lt;/a&gt;）：</target>
        </trans-unit>
        <trans-unit id="a96824cdb923fbde7424d806cedfbff3d185c97a" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="translated">该模型是以下顺序Karhunen-Loeve变换的扩展： &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; 请参见&lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22862405516241c579b3ee92c4c4e899025ea8d7" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;em&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/em&gt; See &lt;a href=&quot;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="translated">该模型是以下顺序Karhunen-Loeve变换的扩展：&lt;em&gt;A. Levy和M. Lindenbaum，&amp;ldquo;顺序Karhunen-Loeve基础提取及其在图像中的应用&amp;rdquo;，IEEE Transactions on Image Processing，第9卷，第8期，第1371- 1374，2000年8月。&lt;/em&gt;请参阅&lt;a href=&quot;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5eaf31e8c5d94894f814f950dadb507546a62c7a" translate="yes" xml:space="preserve">
          <source>This model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.</source>
          <target state="translated">该模型类似于基本的标签传播算法,但使用基于归一化图Laplacian的亲和矩阵和跨标签的软箝制。</target>
        </trans-unit>
        <trans-unit id="31cfc2556e1a899818d23b9328ee0744c892d322" translate="yes" xml:space="preserve">
          <source>This model optimizes the log-loss function using LBFGS or stochastic gradient descent.</source>
          <target state="translated">该模型采用LBFGS或随机梯度下降法优化对数损失函数。</target>
        </trans-unit>
        <trans-unit id="a4064d8d27531f23ac21cbcbd5928e344df2525d" translate="yes" xml:space="preserve">
          <source>This model optimizes the squared-loss using LBFGS or stochastic gradient descent.</source>
          <target state="translated">该模型采用LBFGS或随机梯度下降法优化平方亏损。</target>
        </trans-unit>
        <trans-unit id="5bcd7dedd8759fb896822dc89b59d5206ebfcc53" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape (n_samples, n_targets)).</source>
          <target state="translated">该模型求解回归模型,损失函数为线性最小二乘函数,正则化由l2-norm给出。也称为岭回归或Tikhonov正则化。该估计器内置了对多变量回归的支持(即当y是一个形状为(n_samples,n_targets)的二维数组时)。</target>
        </trans-unit>
        <trans-unit id="5745ffae87fdf8e03232a3372f515cd928402ef0" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">该模型求解回归模型,损失函数为线性最小二乘函数,正则化由l2-norm给出。也称为岭回归或Tikhonov正则化。该估计器内置了对多变量回归的支持(即当y是形状为[n_samples,n_targets]的二维数组时)。</target>
        </trans-unit>
        <trans-unit id="f19c01936c0bc27e43d782c2c60b0838b0f4894d" translate="yes" xml:space="preserve">
          <source>This module contains both distance metrics and kernels. A brief summary is given on the two here.</source>
          <target state="translated">这个模块包含了距离度量和内核两个方面。在这里对两者做一个简单的总结。</target>
        </trans-unit>
        <trans-unit id="ea7156035377b3d98062532f66578932992ce326" translate="yes" xml:space="preserve">
          <source>This module contains two loaders. The first one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt;, returns a list of the raw texts that can be fed to text feature extractors such as &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; with custom parameters so as to extract feature vectors. The second one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt;&lt;/a&gt;, returns ready-to-use features, i.e., it is not necessary to use a feature extractor.</source>
          <target state="translated">该模块包含两个装载程序。第一个是&lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt;，返回原始文本的列表，这些原始文本可以通过自定义参数馈送到文本特征提取器（例如&lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; )&lt;/a&gt;，以提取特征向量。第二个是&lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt; &lt;/a&gt;，返回即用型功能，即，不必使用功能提取器。</target>
        </trans-unit>
        <trans-unit id="e5dbda685e3f3b6ebc21c265d6368ea8386c5f03" translate="yes" xml:space="preserve">
          <source>This module implements multiclass learning algorithms:</source>
          <target state="translated">本模块实现了多类学习算法。</target>
        </trans-unit>
        <trans-unit id="40fee252ae7de928b5fc80e9416986beafe64ef4" translate="yes" xml:space="preserve">
          <source>This module implements multioutput regression and classification.</source>
          <target state="translated">该模块实现了多输出回归和分类。</target>
        </trans-unit>
        <trans-unit id="f4b5a1fcc345642615c5317116147407ee22511b" translate="yes" xml:space="preserve">
          <source>This module offers support for multi-output problems by implementing this strategy in both &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt;&lt;code&gt;DecisionTreeRegressor&lt;/code&gt;&lt;/a&gt;. If a decision tree is fit on an output array Y of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; then the resulting estimator will:</source>
          <target state="translated">该模块通过在&lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt; &lt;code&gt;DecisionTreeRegressor&lt;/code&gt; 中&lt;/a&gt;实施此策略，为多输出问题提供支持。如果决策树适合大小为 &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; 的输出数组Y，则结果估计器将：</target>
        </trans-unit>
        <trans-unit id="69b4d83c7d3d58178d932db005c229bef475361e" translate="yes" xml:space="preserve">
          <source>This normalization is implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; class:</source>
          <target state="translated">该规范化由&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt;类实现：</target>
        </trans-unit>
        <trans-unit id="36bde3d3011eb8df53f7587f509f261b5588364f" translate="yes" xml:space="preserve">
          <source>This object uses workers to compute in parallel the application of a function to many different arguments. The main functionality it brings in addition to using the raw multiprocessing or concurrent.futures API are (see examples for details):</source>
          <target state="translated">这个对象使用worker来并行计算一个函数对许多不同参数的应用。除了使用原始的多处理或concurrent.futures API外,它带来的主要功能有(详见示例)。</target>
        </trans-unit>
        <trans-unit id="43f85d31a1122b5ce913b6ac1587dc97b9fac8c9" translate="yes" xml:space="preserve">
          <source>This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the &amp;lsquo;real world&amp;rsquo;.</source>
          <target state="translated">该软件包还具有帮助者获取大型数据集的功能，这些数据集通常被机器学习社区用来对来自&amp;ldquo;现实世界&amp;rdquo;的数据的算法进行基准测试。</target>
        </trans-unit>
        <trans-unit id="8291d2ecf0ae6621cc55dbf9132ec6413177dbb1" translate="yes" xml:space="preserve">
          <source>This parameter does not have any effect. The components are always normalized.</source>
          <target state="translated">此参数没有任何影响。分量总是标准化的。</target>
        </trans-unit>
        <trans-unit id="f678792533c8ea573ae326139ccc463721df5e43" translate="yes" xml:space="preserve">
          <source>This parameter has been renamed to n_components and will be removed in version 0.21. .. deprecated:: 0.19</source>
          <target state="translated">这个参数已经改名为n_components,并将在0.21版本中被移除。 ...废弃的:。0.19</target>
        </trans-unit>
        <trans-unit id="b9bd887348c693f73ff73c188c30554ec63931d0" translate="yes" xml:space="preserve">
          <source>This parameter has no effect on the matplotlib tree visualisation and it is kept here for backward compatibility.</source>
          <target state="translated">这个参数对matplotlib树的可视化没有影响,为了向后兼容而保留在这里。</target>
        </trans-unit>
        <trans-unit id="95ab9404db52634d7b16f5cf223dc53c5df9617b" translate="yes" xml:space="preserve">
          <source>This parameter has no effect, is deprecated, and will be removed.</source>
          <target state="translated">这个参数没有效果,已经废弃,将被删除。</target>
        </trans-unit>
        <trans-unit id="c3803345bcca4c293ec436fd5df6e0af3703aedc" translate="yes" xml:space="preserve">
          <source>This parameter is deprecated and will be removed in v0.24.</source>
          <target state="translated">这个参数已经废弃,并将在v0.24中被删除。</target>
        </trans-unit>
        <trans-unit id="2008376a104f1f0d722babab4554d9900556a331" translate="yes" xml:space="preserve">
          <source>This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">如果词汇不是None,这个参数会被忽略。</target>
        </trans-unit>
        <trans-unit id="4896edc233b2b945e9bfe76cd7c644f9b147f395" translate="yes" xml:space="preserve">
          <source>This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">当 &lt;code&gt;fit_intercept&lt;/code&gt; 设置为False 时，将忽略此参数。如果为True，则将在回归之前通过减去均值并除以l2-范数来对回归变量X进行归一化。如果你想规范，请使用&lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt;之前调用 &lt;code&gt;fit&lt;/code&gt; 于与估计 &lt;code&gt;normalize=False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a954f8a244020c9f424e9822cfad5459a2f5fec4" translate="yes" xml:space="preserve">
          <source>This parameter is ignored.</source>
          <target state="translated">该参数被忽略。</target>
        </trans-unit>
        <trans-unit id="74de1b86fb436972ff8b47352593daa33d35779f" translate="yes" xml:space="preserve">
          <source>This parameter is not needed to compute tfidf.</source>
          <target state="translated">计算tfidf时不需要这个参数。</target>
        </trans-unit>
        <trans-unit id="18c6fb9267c5496a0a4415bd237b294d4f877c13" translate="yes" xml:space="preserve">
          <source>This parameter is required for multiclass/multilabel targets. If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">对于多类/多标签目标，此参数是必需的。如果为 &lt;code&gt;None&lt;/code&gt; ，则返回每个班级的分数。否则，这将确定对数据执行的平均类型：</target>
        </trans-unit>
        <trans-unit id="4b54c5323e385131687ecd8fe6362000ef5ec12b" translate="yes" xml:space="preserve">
          <source>This parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\) :</source>
          <target state="translated">可以通过成员 &lt;code&gt;dual_coef_&lt;/code&gt; 其包含乘积\（y_i \ alpha_i \））， &lt;code&gt;support_vectors_&lt;/code&gt; (其支持支撑向量）和 &lt;code&gt;intercept_&lt;/code&gt; (其具有独立项\（\ rho \））来访问此参数：</target>
        </trans-unit>
        <trans-unit id="f0e92a41ff311d2df395e780ee2f06d2a63e9cbc" translate="yes" xml:space="preserve">
          <source>This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.</source>
          <target state="translated">这个路径长度,是这种随机树的森林的平均值,是规范性的测量,也是我们的决策函数。</target>
        </trans-unit>
        <trans-unit id="80dec09fc285dd6f9c561fc2931162bad1982cdb" translate="yes" xml:space="preserve">
          <source>This plot compares the decision surfaces learned by a decision tree classifier (first column), by a random forest classifier (second column), by an extra- trees classifier (third column) and by an AdaBoost classifier (fourth column).</source>
          <target state="translated">该图比较了决策树分类器(第一列)、随机森林分类器(第二列)、树外分类器(第三列)和AdaBoost分类器(第四列)学习的决策面。</target>
        </trans-unit>
        <trans-unit id="3b15144cc63de75145bd9b8c8333a27bef49a738" translate="yes" xml:space="preserve">
          <source>This plot is called a Lorenz curve and can be summarized by the Gini index:</source>
          <target state="translated">这张图称为洛伦兹曲线,可以用基尼指数来概括。</target>
        </trans-unit>
        <trans-unit id="8e05dc7c1a0ec44a96abb884d1ce621cca93db4e" translate="yes" xml:space="preserve">
          <source>This problem can safely be ignored when the number of samples is more than a thousand and the number of clusters is less than 10. &lt;strong&gt;For smaller sample sizes or larger number of clusters it is safer to use an adjusted index such as the Adjusted Rand Index (ARI)&lt;/strong&gt;.</source>
          <target state="translated">当样本数大于一千且聚类数小于10时，可以安全地忽略此问题。&lt;strong&gt;对于较小的样本量或较大的聚类数，使用调整后的索引（如调整后的兰德指数（ ARI）&lt;/strong&gt;。</target>
        </trans-unit>
        <trans-unit id="432c2ac32bcc01f0466fb33da0cfef7067b741ad" translate="yes" xml:space="preserve">
          <source>This problem stems from two limitations of impurity-based feature importances:</source>
          <target state="translated">这个问题源于基于杂质特征导入的两个限制。</target>
        </trans-unit>
        <trans-unit id="fcd7e110cbbcbd004685bcd45cf928dd3da1b5b1" translate="yes" xml:space="preserve">
          <source>This procedure (spectral clustering on an image) is an efficient approximate solution for finding normalized graph cuts.</source>
          <target state="translated">这个过程(图像上的光谱聚类)是寻找归一化图形切割的有效近似解。</target>
        </trans-unit>
        <trans-unit id="f7d25c0cd20cd8cb8daa937c60ac3edd0b2b2f75" translate="yes" xml:space="preserve">
          <source>This ranking metric yields a high value if true labels are ranked high by &lt;code&gt;y_score&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;y_score&lt;/code&gt; 将真实标签排名较高，则此排名指标将产生较高的价值。</target>
        </trans-unit>
        <trans-unit id="7a8651d966c336f363771d222433438f229cb5c2" translate="yes" xml:space="preserve">
          <source>This regressor is useful as a simple baseline to compare with other (real) regressors. Do not use it for real problems.</source>
          <target state="translated">这个回归器作为一个简单的基线是有用的,可以与其他(真实的)回归器进行比较。不要将其用于实际问题。</target>
        </trans-unit>
        <trans-unit id="566769fe300350777b617d7ceed39620171814da" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices by passing &lt;code&gt;with_mean=False&lt;/code&gt; to avoid breaking the sparsity structure of the data.</source>
          <target state="translated">还可以通过传递 &lt;code&gt;with_mean=False&lt;/code&gt; 来将此缩放器应用于稀疏CSR或CSC矩阵，以避免破坏数据的稀疏性结构。</target>
        </trans-unit>
        <trans-unit id="bf350412f5695ebe05a62d114269ff308d8edf9f" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices.</source>
          <target state="translated">该缩放器也可以应用于稀疏的CSR或CSC矩阵。</target>
        </trans-unit>
        <trans-unit id="096cae15373bbc176ca80052b34794345347f334" translate="yes" xml:space="preserve">
          <source>This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.</source>
          <target state="translated">这个分数可以用来从X中选择测试chi-squared统计值最高的n_features特征,相对于类而言,它必须只包含布尔值或频率等非负值特征(例如,文档分类中的术语计数)。</target>
        </trans-unit>
        <trans-unit id="bc67f7a4c884a57cb8d65e3051862bc296a2adb5" translate="yes" xml:space="preserve">
          <source>This score is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the &lt;code&gt;'arithmetic'&lt;/code&gt; option for averaging.</source>
          <target state="translated">该分数与带有 &lt;code&gt;'arithmetic'&lt;/code&gt; 选项进行平均的&lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt;相同。</target>
        </trans-unit>
        <trans-unit id="81b377dd4306b3470c7efb10edcaa8d55b57210b" translate="yes" xml:space="preserve">
          <source>This section illustrates the use of a &lt;code&gt;Pipeline&lt;/code&gt; with &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">本节说明了将 &lt;code&gt;Pipeline&lt;/code&gt; 与 &lt;code&gt;GridSearchCV&lt;/code&gt; 一起使用</target>
        </trans-unit>
        <trans-unit id="929a45e65dc1a0cd0b685d6194be9ae4708eb857" translate="yes" xml:space="preserve">
          <source>This should make it possible to check that the cross-validation score is in the same range as before.</source>
          <target state="translated">这样一来,应该可以检查出交叉验证的分数是否和以前一样在同一个范围内。</target>
        </trans-unit>
        <trans-unit id="08af461e03baea2ad13f22a738ff3dde29c2a50f" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">这显示了一个示例，该示例使用基于Haversine距离度量（即，经度/纬度上的点的距离）构建的球树，对地理空间数据进行基于邻居的查询（尤其是内核密度估计）。数据集由Phillips等提供。等 （2006）。如果可用，该示例将使用&lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;底图&lt;/a&gt;来绘制南美的海岸线和国家边界。</target>
        </trans-unit>
        <trans-unit id="d9d5278cf29981ffe0af23942c116e835acd3587" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;https://matplotlib.org/basemap/&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">这显示了一个示例，该示例使用基于Haversine距离度量（即，经度/纬度上的点的距离）构建的球树，对地理空间数据进行基于邻居的查询（尤其是内核密度估计）。该数据集由Phillips等提供。al。（2006）。如果可用，该示例将使用&lt;a href=&quot;https://matplotlib.org/basemap/&quot;&gt;底图&lt;/a&gt;绘制南美的海岸线和国家边界。</target>
        </trans-unit>
        <trans-unit id="38716491ad409e2f991bc1db8f7b1d944921bf99" translate="yes" xml:space="preserve">
          <source>This sort of preprocessing can be streamlined with the &lt;a href=&quot;compose#pipeline&quot;&gt;Pipeline&lt;/a&gt; tools. A single object representing a simple polynomial regression can be created and used as follows:</source>
          <target state="translated">可以使用&lt;a href=&quot;compose#pipeline&quot;&gt;管道&lt;/a&gt;工具简化此类预处理。可以创建并使用一个代表简单多项式回归的对象，如下所示：</target>
        </trans-unit>
        <trans-unit id="4e6050ab2083fb67a848ffe7f83ae292a8f60f62" translate="yes" xml:space="preserve">
          <source>This strategy can also be used for multilabel learning, where a classifier is used to predict multiple labels for instance, by fitting on a 2-d matrix in which cell [i, j] is 1 if sample i has label j and 0 otherwise.</source>
          <target state="translated">这种策略也可以用于多标签学习,比如一个分类器用于预测多个标签,在一个2-d矩阵上进行拟合,其中如果样本i有标签j,则单元[i,j]为1,否则为0。</target>
        </trans-unit>
        <trans-unit id="8cd6a64f79d725ef1cdd342315685305aab51887" translate="yes" xml:space="preserve">
          <source>This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">该策略包括为每个类别对配备一个分类器。在预测时，选择获得最多选票的班级。由于该方法需要适合 &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; 分类器，因此，由于其O（n_classes ^ 2）复杂性，因此该方法通常比其余方法慢一倍。但是，此方法对于无法很好地与 &lt;code&gt;n_samples&lt;/code&gt; 进行缩放的算法（例如内核算法）可能是有利的。这是因为每个单独的学习问题仅涉及数据的一小部分，而相对于其余部分，完整数据集的使用次数为 &lt;code&gt;n_classes&lt;/code&gt; 次。</target>
        </trans-unit>
        <trans-unit id="de640b51f281cc0046c1a9e652c58d4e96ebef0b" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification</source>
          <target state="translated">这种策略包括为每个目标拟合一个分类器。这是对不支持多目标分类的分类器进行扩展的简单策略。</target>
        </trans-unit>
        <trans-unit id="7d6fb6c6a7f2b79b31f4627b09bbb93dcc2f3bc4" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one regressor per target. This is a simple strategy for extending regressors that do not natively support multi-target regression.</source>
          <target state="translated">这个策略包括对每个目标拟合一个回归器。这是一个简单的策略,用于扩展不支持多目标回归的回归器。</target>
        </trans-unit>
        <trans-unit id="27cbaceed22a6f90d5ae07c700825d27bfca1f78" translate="yes" xml:space="preserve">
          <source>This strategy has several advantages:</source>
          <target state="translated">这种策略有几个优点。</target>
        </trans-unit>
        <trans-unit id="91d49a77db9793bc904e6dbf1c0dda029b6c110b" translate="yes" xml:space="preserve">
          <source>This strategy is illustrated below.</source>
          <target state="translated">这种策略如下图所示。</target>
        </trans-unit>
        <trans-unit id="02849272fb07ed52ea9b00f7ccc02a748c971372" translate="yes" xml:space="preserve">
          <source>This strategy, also known as &lt;strong&gt;one-vs-all&lt;/strong&gt;, is implemented in &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;OneVsRestClassifier&lt;/code&gt;&lt;/a&gt;. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only &lt;code&gt;n_classes&lt;/code&gt; classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice.</source>
          <target state="translated">这一策略，也被称为&lt;strong&gt;一个-VS-所有&lt;/strong&gt;，在实施&lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;OneVsRestClassifier&lt;/code&gt; &lt;/a&gt;。该策略包括为每个类别配备一个分类器。对于每个分类器，该分类将与所有其他分类进行拟合。除了其计算效率（仅需要 &lt;code&gt;n_classes&lt;/code&gt; 个分类器）之外，此方法的一个优点是其可解释性。由于每个类别仅由一个分类器表示，因此可以通过检查其对应的分类器来获取有关该类别的知识。这是最常用的策略，并且是合理的默认选择。</target>
        </trans-unit>
        <trans-unit id="27ac94ab878e8b852843daf6fdc6644656d86a0e" translate="yes" xml:space="preserve">
          <source>This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see &lt;a href=&quot;svm#svm&quot;&gt;Support Vector Machines&lt;/a&gt;). The following feature functions perform non-linear transformations of the input, which can serve as a basis for linear classification or other algorithms.</source>
          <target state="translated">该子模块包含近似于与某些内核对应的特征映射的函数，例如在支持向量机中使用的功能（请参阅&lt;a href=&quot;svm#svm&quot;&gt;支持向量机&lt;/a&gt;）。以下功能函数执行输入的非线性转换，可以用作线性分类或其他算法的基础。</target>
        </trans-unit>
        <trans-unit id="fcbae9cfcf0bd03c252edbce0ec54b00175fa149" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options.</source>
          <target state="translated">这个测试可以应用于类或实例。目前,类有一些与构造有关的附加测试,而通过实例可以测试多个选项。</target>
        </trans-unit>
        <trans-unit id="1df76b4b8062cdd31b59f7b7a96f694c7a4a84f4" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options. However, support for classes is deprecated since version 0.23 and will be removed in version 0.24 (class checks will still be run on the instances).</source>
          <target state="translated">这个测试可以应用于类或实例。类目前有一些与构造有关的附加测试,而通过实例可以测试多个选项。然而,从0.23版本开始,对类的支持就被废弃了,并将在0.24版本中被移除(类检查仍将在实例上运行)。</target>
        </trans-unit>
        <trans-unit id="fe4512e0330ee3f9d4d908b10acadfb35dcb4b46" translate="yes" xml:space="preserve">
          <source>This text vectorizer implementation uses the hashing trick to find the token string name to feature integer index mapping.</source>
          <target state="translated">这个文本向量器的实现使用哈希技巧来寻找标记字符串名称到特征整数索引的映射。</target>
        </trans-unit>
        <trans-unit id="90704510327932a48fb3c52155398163f97475e2" translate="yes" xml:space="preserve">
          <source>This transformation is often used as an alternative to zero mean, unit variance scaling.</source>
          <target state="translated">这种变换经常被用作零均值、单位方差缩放的替代方法。</target>
        </trans-unit>
        <trans-unit id="6539f7aec79b7dc39bdc0281525ed4d20f3ca8db" translate="yes" xml:space="preserve">
          <source>This transformation will only be exact if n_components=n_features</source>
          <target state="translated">只有在n_components=n_features的情况下,这个转换才会精确。</target>
        </trans-unit>
        <trans-unit id="2f720ce11fea82f150f2e1314efc3b6e74d2aa65" translate="yes" xml:space="preserve">
          <source>This transformer is able to work both with dense numpy arrays and scipy.sparse matrix (use CSR format if you want to avoid the burden of a copy / conversion).</source>
          <target state="translated">这个变换器既能处理密集的numpy数组,也能处理scipy.sparse矩阵(如果你想避免复制/转换的负担,请使用CSR格式)。</target>
        </trans-unit>
        <trans-unit id="22f51ce5936d304512713b7c2d6420a9339ed07c" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently.</source>
          <target state="translated">本变换器通过截断奇异值分解(SVD)进行线性维度降低。与PCA不同的是,这个估计器在计算奇异值分解之前并不对数据进行居中处理,这意味着它可以有效地处理scipy.sparse矩阵。这意味着它可以高效地处理scipy.sparse矩阵。</target>
        </trans-unit>
        <trans-unit id="548ea059334e4b91f9c90aef5db25d9def754336" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.</source>
          <target state="translated">本变换器通过截断奇异值分解(SVD)进行线性维度降低。与PCA不同的是,该估计器在计算奇异值分解之前不对数据进行居中处理。这意味着它可以有效地处理稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="cbf82199a6ba754f7c0185042f3f4e595a8e8525" translate="yes" xml:space="preserve">
          <source>This transformer should be used to encode target values, &lt;em&gt;i.e.&lt;/em&gt;&lt;code&gt;y&lt;/code&gt;, and not the input &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">该变压器应该用于编码的目标值，&lt;em&gt;即&lt;/em&gt; &lt;code&gt;y&lt;/code&gt; ，而不是输入 &lt;code&gt;X&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c058bdf39166834e7b3e02bee2a3dc32df1bea5c" translate="yes" xml:space="preserve">
          <source>This transformer turns lists of mappings (dict-like objects) of feature names to feature values into Numpy arrays or scipy.sparse matrices for use with scikit-learn estimators.</source>
          <target state="translated">这个变换器将特征名与特征值的映射列表(类似dict的对象)变成Numpy数组或scipy.sparse矩阵,用于scikit-learn估计器。</target>
        </trans-unit>
        <trans-unit id="6fa17f9065133747f6dee2c04fd6c387874c04ab" translate="yes" xml:space="preserve">
          <source>This tutorial will explore &lt;em&gt;statistical learning&lt;/em&gt;, the use of machine learning techniques with the goal of &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;statistical inference&lt;/a&gt;: drawing conclusions on the data at hand.</source>
          <target state="translated">本教程将探讨&lt;em&gt;统计学习&lt;/em&gt;，以及将机器学习技术用于&lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;统计推断&lt;/a&gt;的目的：根据手头的数据得出结论。</target>
        </trans-unit>
        <trans-unit id="d770164eec068c2686e18d9f67f7678a7fe3d2ab" translate="yes" xml:space="preserve">
          <source>This uses the Benjamini-Hochberg procedure. &lt;code&gt;alpha&lt;/code&gt; is an upper bound on the expected false discovery rate.</source>
          <target state="translated">这使用了Benjamini-Hochberg过程。 &lt;code&gt;alpha&lt;/code&gt; 是预期的错误发现率的上限。</target>
        </trans-unit>
        <trans-unit id="25630de50e6415b67bb72ea47abf6e457ed32d31" translate="yes" xml:space="preserve">
          <source>This uses the score defined by &lt;code&gt;scoring&lt;/code&gt; where provided, and the &lt;code&gt;best_estimator_.score&lt;/code&gt; method otherwise.</source>
          <target state="translated">这将使用通过 &lt;code&gt;scoring&lt;/code&gt; 在提供的地方）定义的评分，否则使用 &lt;code&gt;best_estimator_.score&lt;/code&gt; 方法。</target>
        </trans-unit>
        <trans-unit id="28c90b747be44784ef68312c004db0e8049cba2c" translate="yes" xml:space="preserve">
          <source>This utility is documented, but &lt;strong&gt;private&lt;/strong&gt;. This means that backward compatibility might be broken without any deprecation cycle.</source>
          <target state="translated">该实用程序已记录，但为&lt;strong&gt;private&lt;/strong&gt;。这意味着在没有任何弃用周期的情况下可能会破坏向后兼容性。</target>
        </trans-unit>
        <trans-unit id="f6f06f080d161d82167224fa4f5455a90c3bc7e3" translate="yes" xml:space="preserve">
          <source>This utility is meant to be used internally by estimators themselves, typically in their own predict / transform methods.</source>
          <target state="translated">这个工具是为了让估计者自己在内部使用,通常在他们自己的预测/转换方法中使用。</target>
        </trans-unit>
        <trans-unit id="57e78bad29e459afb6f7e8e9a46e0b5e6e5f4fa9" translate="yes" xml:space="preserve">
          <source>This value is valid if class_weight parameter in fit() is not set.</source>
          <target state="translated">如果fit()中的class_weight参数没有设置,这个值是有效的。</target>
        </trans-unit>
        <trans-unit id="0973d55bbbd406d7d050b325e278935eae6a368e" translate="yes" xml:space="preserve">
          <source>This value of the mutual information and also the normalized variant is not adjusted for chance and will tend to increase as the number of different labels (clusters) increases, regardless of the actual amount of &amp;ldquo;mutual information&amp;rdquo; between the label assignments.</source>
          <target state="translated">互信息的值以及归一化的变体都不会偶然调整，并且会随着不同标签（集群）数量的增加而增加，而与标签分配之间的&amp;ldquo;互信息&amp;rdquo;的实际数量无关。</target>
        </trans-unit>
        <trans-unit id="ec27c204380d1bf1bec671104c4e5cc563667983" translate="yes" xml:space="preserve">
          <source>This visualization is an example of a &lt;em&gt;kernel density estimation&lt;/em&gt;, in this case with a top-hat kernel (i.e. a square block at each point). We can recover a smoother distribution by using a smoother kernel. The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total. The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points.</source>
          <target state="translated">该可视化是&lt;em&gt;内核密度估计&lt;/em&gt;的示例，在这种情况下，使用高礼帽内核（即每个点处的正方形块）。我们可以使用更平滑的内核来恢复更平滑的分布。右下角的图显示了高斯核密度估计，其中每个点对总和贡献了高斯曲线。结果是一个平滑的密度估计值，该估计值是从数据得出的，并且可以用作功能强大的点分布的非参数模型。</target>
        </trans-unit>
        <trans-unit id="1cad85e71e9b226b43b5778c8058de4fe70516a7" translate="yes" xml:space="preserve">
          <source>This warning is used to notify the user that BLAS was not used for dot operation and hence the efficiency may be affected.</source>
          <target state="translated">该警告用于通知用户,BLAS没有用于点操作,因此效率可能会受到影响。</target>
        </trans-unit>
        <trans-unit id="7b4c8162b5298ba9d922a2200274b38ddddf44e8" translate="yes" xml:space="preserve">
          <source>This warning notifies the user that the efficiency may not be optimal due to some reason which may be included as a part of the warning message. This may be subclassed into a more specific Warning class.</source>
          <target state="translated">这个警告通知用户,由于某些原因,效率可能不是最佳的,这些原因可能会作为警告信息的一部分。这可能会被子类化为一个更具体的警告类。</target>
        </trans-unit>
        <trans-unit id="ec79da6e5e29f4afd0662e82ec298c39ed6dbabd" translate="yes" xml:space="preserve">
          <source>This warning occurs when some input data needs to be converted or interpreted in a way that may not match the user&amp;rsquo;s expectations.</source>
          <target state="translated">当某些输入数据需要以不符合用户期望的方式进行转换或解释时，会发生此警告。</target>
        </trans-unit>
        <trans-unit id="14994b75958434504d6803fa4be46a86d6219fc9" translate="yes" xml:space="preserve">
          <source>This was originally a term weighting scheme developed for information retrieval (as a ranking function for search engines results) that has also found good use in document classification and clustering.</source>
          <target state="translated">这原本是一种为信息检索而开发的术语加权方案(作为搜索引擎结果的排名功能),在文档分类和聚类中也有很好的应用。</target>
        </trans-unit>
        <trans-unit id="90d00e9f85af52e63288d2fca3d9f513dce9de12" translate="yes" xml:space="preserve">
          <source>This, however, is not the case in the Ledoit-Wolf procedure when the population covariance happens to be a multiple of the identity matrix. In this case, the Ledoit-Wolf shrinkage estimate approaches 1 as the number of samples increases. This indicates that the optimal estimate of the covariance matrix in the Ledoit-Wolf sense is multiple of the identity. Since the population covariance is already a multiple of the identity matrix, the Ledoit-Wolf solution is indeed a reasonable estimate.</source>
          <target state="translated">然而,在Ledoit-Wolf程序中,当人口协方差恰好是身份矩阵的倍数时,情况并非如此。在这种情况下,随着样本数量的增加,Ledoit-Wolf的收缩估计值接近1。这说明Ledoit-Wolf意义上的协方差矩阵的最优估计是身份的倍数。由于种群协方差已经是身份矩阵的倍数,所以Ledoit-Wolf解确实是一个合理的估计。</target>
        </trans-unit>
        <trans-unit id="e911226999d28ae4c4eb95cef049955b008548cf" translate="yes" xml:space="preserve">
          <source>Those 3 metrics are independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score values in any way.</source>
          <target state="translated">这3个指标与标签的绝对值无关：类或群集标签值的排列不会以任何方式更改得分值。</target>
        </trans-unit>
        <trans-unit id="a17151aff3f6e79d6bfb3bc3e7c5d30ff3b77b7d" translate="yes" xml:space="preserve">
          <source>Those metrics are based on normalized conditional entropy measures of the clustering labeling to evaluate given the knowledge of a Ground Truth class labels of the same samples.</source>
          <target state="translated">这些度量是基于聚类标签的归一化条件熵度量,来评估给定相同样本的Ground Truth类标签的知识。</target>
        </trans-unit>
        <trans-unit id="831e093286e91d34e1415d38600e7c8277f14a07" translate="yes" xml:space="preserve">
          <source>Though not technically a variant of LLE, Local tangent space alignment (LTSA) is algorithmically similar enough to LLE that it can be put in this category. Rather than focusing on preserving neighborhood distances as in LLE, LTSA seeks to characterize the local geometry at each neighborhood via its tangent space, and performs a global optimization to align these local tangent spaces to learn the embedding. LTSA can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'ltsa'&lt;/code&gt;.</source>
          <target state="translated">尽管从技术上讲不是LLE的变体，但局部切线空间对齐（LTSA）在算法上与LLE足够相似，因此可以将其归入此类。 LTSA并没有像LLE中那样关注保留邻域距离，而是寻求通过其切线空间表征每个邻域的局部几何形状，并执行全局优化以对齐这些局部切线空间以学习嵌入。 LTSA可以使用&lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt;函数或其面向对象的对&lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt;通过关键字 &lt;code&gt;method = 'ltsa'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3dcfc8b5bdf930c1b66451c5dc30f486901100ee" translate="yes" xml:space="preserve">
          <source>Three different types of SVM-Kernels are displayed below. The polynomial and RBF are especially useful when the data-points are not linearly separable.</source>
          <target state="translated">下面显示了三种不同类型的SVM-Kernels。当数据点不可线性分离时,多项式和RBF特别有用。</target>
        </trans-unit>
        <trans-unit id="2eb0d5d5e8d716a06a5bc42a652c1781cf721343" translate="yes" xml:space="preserve">
          <source>Threshold for binarizing (mapping to booleans) of sample features. If None, input is presumed to already consist of binary vectors.</source>
          <target state="translated">采样特征二值化(映射到布尔运算)的阈值。如果无,则假定输入已经由二进制向量组成。</target>
        </trans-unit>
        <trans-unit id="ac359cd376aaf3163dffdc564a92f8f55ebdbfe9" translate="yes" xml:space="preserve">
          <source>Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.</source>
          <target state="translated">树木生长中早期停止的阈值。如果一个节点的不纯度高于阈值,则该节点将分裂,否则就是叶子。</target>
        </trans-unit>
        <trans-unit id="d2dde1e4fd07fa9e4ff99bf50a843f5c394281b4" translate="yes" xml:space="preserve">
          <source>Threshold for shrinking centroids to remove features.</source>
          <target state="translated">缩小中心点以去除特征的阈值。</target>
        </trans-unit>
        <trans-unit id="5b50eca69565a6240c9cb586697767c09ac4525e" translate="yes" xml:space="preserve">
          <source>Threshold on the size of arrays passed to the workers that triggers automated memory mapping in temp_folder. Can be an int in Bytes, or a human-readable string, e.g., &amp;lsquo;1M&amp;rsquo; for 1 megabyte. Use None to disable memmapping of large arrays. Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">传递给工作线程的数组大小的阈值，该阈值触发temp_folder中的自动内存映射。可以是Byte形式的int值，也可以是人类可读的字符串，例如1 MB的'1M'。使用None禁用大型阵列的映射。仅在backend =&amp;ldquo; loky&amp;rdquo;或&amp;ldquo; multiprocessing&amp;rdquo;时激活。</target>
        </trans-unit>
        <trans-unit id="3bf722c4ec04176f091be4d50fbd629d5b754a20" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation in SVD solver.</source>
          <target state="translated">在SVD求解器中用于等级估计的阈值。</target>
        </trans-unit>
        <trans-unit id="0168a115989469a76c56e8c46c0d56b1a01f88c6" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation.</source>
          <target state="translated">用于等级估计的阈值。</target>
        </trans-unit>
        <trans-unit id="558232b0add0e7cf1e4001c15b7a509781ecfb59" translate="yes" xml:space="preserve">
          <source>Threshold used in the binary and multi-label cases.</source>
          <target state="translated">二元和多标签情况下使用的阈值。</target>
        </trans-unit>
        <trans-unit id="d260a173cc06214ee3d2352996ea165371c17c29" translate="yes" xml:space="preserve">
          <source>Thresholding</source>
          <target state="translated">Thresholding</target>
        </trans-unit>
        <trans-unit id="8265a18b28c2cb3c5a28ceb45384d9a49c2f7715" translate="yes" xml:space="preserve">
          <source>Thresholding is clearly not useful for denoising, but it is here to show that it can produce a suggestive output with very high speed, and thus be useful for other tasks such as object classification, where performance is not necessarily related to visualisation.</source>
          <target state="translated">阈值对于去噪显然是没有用的,但在这里要说明的是,它可以以非常高的速度产生提示性的输出,因此对于其他任务,如对象分类是有用的,而这些任务的性能与可视化没有必然联系。</target>
        </trans-unit>
        <trans-unit id="c4d29a75003891e7d5c5dbb3dea7166bf19f4ab9" translate="yes" xml:space="preserve">
          <source>Thresholding is very fast but it does not yield accurate reconstructions. They have been shown useful in literature for classification tasks. For image reconstruction tasks, orthogonal matching pursuit yields the most accurate, unbiased reconstruction.</source>
          <target state="translated">阈值化的速度非常快,但它不能产生准确的重建。在文献中,它们已被证明对分类任务是有用的。对于图像重建任务,正交匹配追求产生最准确、无偏的重建。</target>
        </trans-unit>
        <trans-unit id="3904c870d9e800cc53a98ecb8acef59d010fad3d" translate="yes" xml:space="preserve">
          <source>Throw a ValueError if X contains NaN or infinity.</source>
          <target state="translated">如果X包含NaN或无穷大,则抛出一个ValueError。</target>
        </trans-unit>
        <trans-unit id="8b8612c016401dc529cb09be5ddd6996fe872d9c" translate="yes" xml:space="preserve">
          <source>Thus in binary classification, the count of true negatives is \(C_{0,0}\), false negatives is \(C_{1,0}\), true positives is \(C_{1,1}\) and false positives is \(C_{0,1}\).</source>
          <target state="translated">因此,在二元分类中,真否定的计数是/(C_{0,0}/),假否定的计数是/(C_{1,0}/),真阳性的计数是/(C_{1,1}/),假阳性的计数是/(C_{0,1}/)。</target>
        </trans-unit>
        <trans-unit id="877864e25b035038afd6bbe5a72ca90fb8e0741e" translate="yes" xml:space="preserve">
          <source>Thus the median of the input becomes the mean of the output, centered at 0. The normal output is clipped so that the input&amp;rsquo;s minimum and maximum &amp;mdash; corresponding to the 1e-7 and 1 - 1e-7 quantiles respectively &amp;mdash; do not become infinite under the transformation.</source>
          <target state="translated">因此，输入的中位数变为以0为中心的输出的平均值。正常输出被裁剪，以便输入的最小和最大值（分别对应于1e-7和1-1e-7分位数）在以下条件下不会变为无限大转变。</target>
        </trans-unit>
        <trans-unit id="911ea2c24698b41ad1167139365e2f911ee7efcc" translate="yes" xml:space="preserve">
          <source>Thus, among the considered estimators, &lt;code&gt;PoissonRegressor&lt;/code&gt; and &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; are a-priori better suited for modeling the long tail distribution of the non-negative data as compared to the &lt;code&gt;Ridge&lt;/code&gt; model which makes a wrong assumption on the distribution of the target variable.</source>
          <target state="translated">因此，在考虑的估计量中，与对目标变量的分布做出错误假设的 &lt;code&gt;Ridge&lt;/code&gt; 模型相比， &lt;code&gt;PoissonRegressor&lt;/code&gt; 和 &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; 更适合于建模非负数据的长尾分布。</target>
        </trans-unit>
        <trans-unit id="0808b4cdf67452766c8c5389635c6458f9990f5b" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015</source>
          <target state="translated">因此,大部分目标信号(34.4ppm)由长期上升趋势(长度尺度41.8年)解释。周期性成分的振幅为3.27ppm,衰减时间为180年,长度尺度为1.44年。衰减时间长,说明我们有一个局部非常接近周期性的季节成分。相关噪声的振幅为0.197ppm,长度尺度为0.138年,白噪声贡献为0.197ppm。因此,整体的噪声水平非常小,说明数据可以被模型很好地解释。该图还显示,该模型在2015年左右之前都能做出非常有把握的预测。</target>
        </trans-unit>
        <trans-unit id="4ab3c0245825ab663f7197647adadf073e4b3e64" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015.</source>
          <target state="translated">因此,大部分目标信号(34.4ppm)由长期上升趋势(长度尺度41.8年)解释。周期性成分的振幅为3.27ppm,衰减时间为180年,长度尺度为1.44年。衰减时间长,说明我们有一个局部非常接近周期性的季节成分。相关噪声的振幅为0.197ppm,长度尺度为0.138年,白噪声贡献为0.197ppm。因此,整体的噪声水平非常小,说明数据可以被模型很好地解释。该图还显示,该模型在2015年左右之前都能做出非常有把握的预测。</target>
        </trans-unit>
        <trans-unit id="af16f18f91308907d1dd8226e54112fa0bd29044" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="translated">张天，Raghu Ramakrishnan，Maron Livny BIRCH：一种用于大型数据库的有效数据聚类方法。&lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d89b88657fcb13ceb20c877ea478d701717a393" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="translated">张天，Raghu Ramakrishnan，Maron Livny BIRCH：一种用于大型数据库的有效数据聚类方法。&lt;a href=&quot;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="867d68dbf4c080ab9e706507919b510dbb556be3" translate="yes" xml:space="preserve">
          <source>Tianqi Chen, Carlos Guestrin, &lt;a href=&quot;https://arxiv.org/abs/1603.02754&quot;&gt;&amp;ldquo;XGBoost: A Scalable Tree Boosting System&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">陈天琪，Carlos Guestrin，&lt;a href=&quot;https://arxiv.org/abs/1603.02754&quot;&gt;&amp;ldquo; XGBoost：可扩展的树增强系统&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d53cad37906f55db18b858cf86bfeef9ad9688eb" translate="yes" xml:space="preserve">
          <source>Tibshirani, R., Hastie, T., Narasimhan, B., &amp;amp; Chu, G. (2002). Diagnosis of multiple cancer types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences of the United States of America, 99(10), 6567-6572. The National Academy of Sciences.</source>
          <target state="translated">Tibshirani，R.，Hastie，T.，Narasimhan，B.，＆Chu，G.（2002）。通过基因表达的收缩质心诊断多种癌症。美国国家科学院院刊，99（10），6567-6572。美国国家科学院。</target>
        </trans-unit>
        <trans-unit id="54643cfd9d395af8d03ef9fab4df1a2cdb437e0c" translate="yes" xml:space="preserve">
          <source>Tie breaking is costly if &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;, and therefore it is not enabled by default. This example illustrates the effect of the &lt;code&gt;break_ties&lt;/code&gt; parameter for a multiclass classification problem and &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; ，则平局打破是昂贵的，因此默认情况下不启用。此示例说明了 &lt;code&gt;break_ties&lt;/code&gt; 参数对多类分类问题和Decision_function_shape &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a297f524f28779281bb4e53d7b6af672dcac3672" translate="yes" xml:space="preserve">
          <source>Ties are broken using the secondary method from Leeuw, 1977.</source>
          <target state="translated">用Leeuw,1977年的次要方法破除纽带。</target>
        </trans-unit>
        <trans-unit id="59976e05663a4d82c80a3273030c2c2f87094f4d" translate="yes" xml:space="preserve">
          <source>Ties between features with equal scores will be broken in an unspecified way.</source>
          <target state="translated">得分相同的特征之间的平局将以一种不特定的方式被打破。</target>
        </trans-unit>
        <trans-unit id="c41dd9e78b42392c90f4c6ddfb54f7863f5482f1" translate="yes" xml:space="preserve">
          <source>Ties in &lt;code&gt;y_scores&lt;/code&gt; are broken by giving maximal rank that would have been assigned to all tied values.</source>
          <target state="translated">&lt;code&gt;y_scores&lt;/code&gt; 中的关系通过给出将分配给所有绑定值的最大等级来中断。</target>
        </trans-unit>
        <trans-unit id="ba73dffe02601a1abd345b6200b276334877401b" translate="yes" xml:space="preserve">
          <source>Time Series cross-validator</source>
          <target state="translated">时间序列交叉验证器</target>
        </trans-unit>
        <trans-unit id="bbad16d201e3f82cae87bba42e6286ebcef9d190" translate="yes" xml:space="preserve">
          <source>Time series data is characterised by the correlation between observations that are near in time (&lt;em&gt;autocorrelation&lt;/em&gt;). However, classical cross-validation techniques such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; assume the samples are independent and identically distributed, and would result in unreasonable correlation between training and testing instances (yielding poor estimates of generalisation error) on time series data. Therefore, it is very important to evaluate our model for time series data on the &amp;ldquo;future&amp;rdquo; observations least like those that are used to train the model. To achieve this, one solution is provided by &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt;&lt;code&gt;TimeSeriesSplit&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">时间序列数据的特征在于接近时间的观测值之间的相关性（&lt;em&gt;自相关&lt;/em&gt;）。但是，经典的交叉验证技术（例如&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; )&lt;/a&gt;假设样本是独立且均匀分布的，并且会导致时间序列数据的训练实例与测试实例之间出现不合理的相关性（产生泛化误差的不良估计）。因此，对我们的模型进行评估以获取关于&amp;ldquo;未来&amp;rdquo;观测的时间序列数据非常重要，这至少要像用于训练模型的观测那样。为此，&lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt; &lt;code&gt;TimeSeriesSplit&lt;/code&gt; &lt;/a&gt;提供了一种解决方案。</target>
        </trans-unit>
        <trans-unit id="a6268d75d578276d37dec9fce6dea804677e6b49" translate="yes" xml:space="preserve">
          <source>Timeout limit for each task to complete. If any task takes longer a TimeOutError will be raised. Only applied when n_jobs != 1</source>
          <target state="translated">每个任务完成的超时限制。如果任何任务需要更长的时间,将引发TimeOutError。只适用于n_jobs !=1时。</target>
        </trans-unit>
        <trans-unit id="f98ee87f52adb2c6f3aaf1f01bab51d0b9ae3622" translate="yes" xml:space="preserve">
          <source>Times spent for fitting in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="translated">花费的时间以秒为单位。仅在 &lt;code&gt;return_times&lt;/code&gt; 为True时存在。</target>
        </trans-unit>
        <trans-unit id="3c46532137bb2ae8358c0137ca60928cd3434340" translate="yes" xml:space="preserve">
          <source>Times spent for scoring in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="translated">在几秒钟内花费的得分时间。仅在 &lt;code&gt;return_times&lt;/code&gt; 为True时存在。</target>
        </trans-unit>
        <trans-unit id="22c6faf6f7a1dbffed43da8c3c0a736a2f22b862" translate="yes" xml:space="preserve">
          <source>Timing and accuracy plots</source>
          <target state="translated">时间和精度图</target>
        </trans-unit>
        <trans-unit id="834cbd0fedba36c3380f74ce91ef668820820b53" translate="yes" xml:space="preserve">
          <source>To achieve better accuracy, &lt;code&gt;X_norm_squared&lt;/code&gt; and &lt;code&gt;Y_norm_squared&lt;/code&gt; may be unused if they are passed as &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">为了获得更好的精度，如果 &lt;code&gt;X_norm_squared&lt;/code&gt; 和 &lt;code&gt;Y_norm_squared&lt;/code&gt; 作为 &lt;code&gt;float32&lt;/code&gt; 传递，则可以不使用它们。</target>
        </trans-unit>
        <trans-unit id="8879146d32620a1e603bf26a188c9426e79a5ed0" translate="yes" xml:space="preserve">
          <source>To address the computational inefficiencies of the brute-force approach, a variety of tree-based data structures have been invented. In general, these structures attempt to reduce the required number of distance calculations by efficiently encoding aggregate distance information for the sample. The basic idea is that if point \(A\) is very distant from point \(B\), and point \(B\) is very close to point \(C\), then we know that points \(A\) and \(C\) are very distant, &lt;em&gt;without having to explicitly calculate their distance&lt;/em&gt;. In this way, the computational cost of a nearest neighbors search can be reduced to \(O[D N \log(N)]\) or better. This is a significant improvement over brute-force for large \(N\).</source>
          <target state="translated">为了解决暴力破解方法的计算效率低下的问题，发明了多种基于树的数据结构。通常，这些结构试图通过有效地编码样本的集合距离信息来减少所需的距离计算数量。基本思想是，如果点\（A \）与点\（B \）距离很远，并且点\（B \）非常接近点\（C \），那么我们知道点\（A \ ）和\（C \）距离很远，&lt;em&gt;而不必显式计算它们的距离&lt;/em&gt;。这样，可以将最近邻居搜索的计算成本降低到\（O [DN \ log（N）] \）或更好。对于大\（N \），这是对蛮力的重大改进。</target>
        </trans-unit>
        <trans-unit id="81ec528524d941df99755c9bb7fceaf80c6a8752" translate="yes" xml:space="preserve">
          <source>To address the inefficiencies of KD Trees in higher dimensions, the &lt;em&gt;ball tree&lt;/em&gt; data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.</source>
          <target state="translated">为了解决高维KD树的低效率问题，开发了&lt;em&gt;球树&lt;/em&gt;数据结构。在KD树沿笛卡尔轴划分数据的地方，球树在一系列嵌套的超球体中划分数据。与KD树相比，这使树的构建成本更高，但导致的数据结构即使在非常高的维度上也可以非常高效地处理高度结构化的数据。</target>
        </trans-unit>
        <trans-unit id="a11d5f0b5df4ea3ced24dc7521fb6d9f97740ba3" translate="yes" xml:space="preserve">
          <source>To address this concern, a number of supervised and unsupervised linear dimensionality reduction frameworks have been designed, such as Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, and others. These algorithms define specific rubrics to choose an &amp;ldquo;interesting&amp;rdquo; linear projection of the data. These methods can be powerful, but often miss important non-linear structure in the data.</source>
          <target state="translated">为了解决此问题，已设计了许多有监督和无监督的线性降维框架，例如主成分分析（PCA），独立成分分析，线性判别分析等。这些算法定义了特定的原则，以选择数据的&amp;ldquo;有趣&amp;rdquo;线性投影。这些方法功能强大，但通常会丢失数据中重要的非线性结构。</target>
        </trans-unit>
        <trans-unit id="c134b5f4c4fa3b034f915a1c4077d9f58401c669" translate="yes" xml:space="preserve">
          <source>To address this issue you can use &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;whiten=True&lt;/code&gt; to further remove the linear correlation across features.</source>
          <target state="translated">要解决此问题，您可以将&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt; &lt;/a&gt;与 &lt;code&gt;whiten=True&lt;/code&gt; 一起使用，以进一步消除跨要素的线性相关性。</target>
        </trans-unit>
        <trans-unit id="5dfb268e42cc748904256c70f6b80b2da01edce9" translate="yes" xml:space="preserve">
          <source>To also transform a test set \(X\), we multiply it with \(V_k\):</source>
          <target state="translated">要转换一个测试集(X),我们将它与(V_k)相乘。</target>
        </trans-unit>
        <trans-unit id="6e914d8189fa250ac9b4b7ea3cf2e62431cbcccd" translate="yes" xml:space="preserve">
          <source>To apply an classifier on this data, we need to flatten the image, to turn the data in a (samples, feature) matrix:</source>
          <target state="translated">为了对这些数据应用分类器,我们需要对图像进行扁平化处理,将数据变成一个(样本、特征)矩阵。</target>
        </trans-unit>
        <trans-unit id="8ef7600ab8e39fc13b7dc9585804325c8072844d" translate="yes" xml:space="preserve">
          <source>To avoid instability issues in case the system is under-determined, regularization can be applied (Ridge regression) via the &lt;code&gt;ridge_alpha&lt;/code&gt; parameter.</source>
          <target state="translated">为了避免在系统不确定的情况下出现不稳定问题，可以通过 &lt;code&gt;ridge_alpha&lt;/code&gt; 参数应用正则化（Ridge回归）。</target>
        </trans-unit>
        <trans-unit id="622754a0a375aafa66f9d8336ffd00fcfc0a1948" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSC matrix.</source>
          <target state="translated">为了避免内存拷贝,调用者应该传递一个CSC矩阵。</target>
        </trans-unit>
        <trans-unit id="21a05d95ccb73f51d245c302b02e9a8f32df0276" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSR matrix.</source>
          <target state="translated">为了避免内存拷贝,呼叫者应该传递一个CSR矩阵。</target>
        </trans-unit>
        <trans-unit id="e5ab0a4f687079cc593610e8d8c0f15b79824d4d" translate="yes" xml:space="preserve">
          <source>To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.</source>
          <target state="translated">为了避免内存重新分配,建议直接使用该格式在内存中分配初始数据。</target>
        </trans-unit>
        <trans-unit id="ee93c7e2ac06e08c1567b0ca209ad480ea5f1b80" translate="yes" xml:space="preserve">
          <source>To avoid the computation of global clustering, for every call of &lt;code&gt;partial_fit&lt;/code&gt; the user is advised</source>
          <target state="translated">为了避免计算全局聚类，建议每次调用 &lt;code&gt;partial_fit&lt;/code&gt; 时都建议用户</target>
        </trans-unit>
        <trans-unit id="e81cbf7353acbc69eeae43ca8cf143e58e658d10" translate="yes" xml:space="preserve">
          <source>To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called &lt;code&gt;tf&lt;/code&gt; for Term Frequencies.</source>
          <target state="translated">为了避免这些潜在的差异，只需将文档中每个单词的出现次数除以文档中单词的总数即可：这些新功能称为术语频率 &lt;code&gt;tf&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="39f01dfdcdf5847fd1935ba52ba9be2bfc80430b" translate="yes" xml:space="preserve">
          <source>To avoid this problem, nested CV effectively uses a series of train/validation/test set splits. In the inner loop (here executed by &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;), the score is approximately maximized by fitting a model to each training set, and then directly maximized in selecting (hyper)parameters over the validation set. In the outer loop (here in &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt;), generalization error is estimated by averaging test set scores over several dataset splits.</source>
          <target state="translated">为避免此问题，嵌套CV有效地使用了一系列训练/验证/测试集拆分。在内部循环（在此由&lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;执行）中，通过将模型拟合到每个训练集来近似最大化分数，然后在验证集上选择（超级）参数时直接将其最大化。在外部循环中（此处为&lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt;），通过对几个数据集拆分中的测试集得分求平均值来估计泛化误差。</target>
        </trans-unit>
        <trans-unit id="5ed52a0ba64199519b793ee9dad54a31d6d3eaed" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.</source>
          <target state="translated">为了避免不必要的内存重复,fit方法的X和y参数应该直接以Fortran-contiguous numpy数组的形式传递。</target>
        </trans-unit>
        <trans-unit id="a37b39aad5fcf98e98548e781cdec5193cfe7b97" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.</source>
          <target state="translated">为了避免不必要的内存重复,fit方法的X参数应该直接以Fortran-contiguous numpy数组的形式传递。</target>
        </trans-unit>
        <trans-unit id="d9c2f7485084c926a2f68d8587d615406cc01649" translate="yes" xml:space="preserve">
          <source>To be in favorable recovery conditions, we sample the data from a model with a sparse inverse covariance matrix. In addition, we ensure that the data is not too much correlated (limiting the largest coefficient of the precision matrix) and that there a no small coefficients in the precision matrix that cannot be recovered. In addition, with a small number of observations, it is easier to recover a correlation matrix rather than a covariance, thus we scale the time series.</source>
          <target state="translated">为了在有利的恢复条件下,我们从一个具有稀疏反协方差矩阵的模型中抽取数据。此外,我们还要保证数据的相关性不大(限制精密矩阵的最大系数),并且精密矩阵中没有不能恢复的小系数。此外,在观测值较少的情况下,恢复相关矩阵比恢复协方差更容易,因此我们对时间序列进行了缩放。</target>
        </trans-unit>
        <trans-unit id="f7fd313aae703eaa110952d34fbc2e74f81a873c" translate="yes" xml:space="preserve">
          <source>To be removed in 0.21</source>
          <target state="translated">将在0.21中删除</target>
        </trans-unit>
        <trans-unit id="b656a9f4366f6cbcc5b1e6914e7bc1a8d099ee57" translate="yes" xml:space="preserve">
          <source>To be removed in 0.22</source>
          <target state="translated">将在0.22中删除</target>
        </trans-unit>
        <trans-unit id="b622879f90e0f79392a411b5be4ae9945d5e85aa" translate="yes" xml:space="preserve">
          <source>To be removed in 0.24</source>
          <target state="translated">将在0.24内删除</target>
        </trans-unit>
        <trans-unit id="bc387423485c5a73576ae6f9089ec34a8b143ae6" translate="yes" xml:space="preserve">
          <source>To begin with, all values for \(r\) and \(a\) are set to zero, and the calculation of each iterates until convergence. As discussed above, in order to avoid numerical oscillations when updating the messages, the damping factor \(\lambda\) is introduced to iteration process:</source>
          <target state="translated">首先,将所有的r/(r/)和a/(a/)的值设置为零,然后对每个值进行迭代计算,直到收敛。如上所述,为了避免更新信息时的数值振荡,在迭代过程中引入了阻尼因子\(\lambda\)。</target>
        </trans-unit>
        <trans-unit id="ebc5cb56aa5d3da850d595b902c1384fa4142906" translate="yes" xml:space="preserve">
          <source>To begin, we&amp;rsquo;ll visualize our data.</source>
          <target state="translated">首先，我们将可视化数据。</target>
        </trans-unit>
        <trans-unit id="57e47e513e200b11a216f9768279c1f81e7b3157" translate="yes" xml:space="preserve">
          <source>To benchmark different estimators for your case you can simply change the &lt;code&gt;n_features&lt;/code&gt; parameter in this example: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt;. This should give you an estimate of the order of magnitude of the prediction latency.</source>
          <target state="translated">要针对您的案例对不同的估计量进行基准测试，您可以在此示例中简单地更改 &lt;code&gt;n_features&lt;/code&gt; 参数：&lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt;。这应该给您估计预测延迟的数量级。</target>
        </trans-unit>
        <trans-unit id="892d831a9e807296347eacb2e8474830ca349663" translate="yes" xml:space="preserve">
          <source>To compare a set of found biclusters to the set of true biclusters, two similarity measures are needed: a similarity measure for individual biclusters, and a way to combine these individual similarities into an overall score.</source>
          <target state="translated">为了将一组发现的双簇与一组真正的双簇进行比较,需要两个相似性测量:一个是单个双簇的相似性测量,另一个是将这些单个相似性合并成一个总分的方法。</target>
        </trans-unit>
        <trans-unit id="f0ff37a06cd777b22ebe208ab3110388f720b201" translate="yes" xml:space="preserve">
          <source>To compare individual biclusters, several measures have been used. For now, only the Jaccard index is implemented:</source>
          <target state="translated">为了比较各个双联体,已经使用了几种测量方法。目前,只采用了Jaccard指数。</target>
        </trans-unit>
        <trans-unit id="658de85a569a63b4d478720bcfaf7adeb72fbb36" translate="yes" xml:space="preserve">
          <source>To compare the 3 models from this perspective, one can plot the cumulative proportion of claims vs the cumulative proportion of exposure for the test samples order by the model predictions, from safest to riskiest according to each model.</source>
          <target state="translated">从这个角度来比较3个模型,可以按照模型预测的顺序,按照每个模型从最安全到最风险的顺序,绘制出测试样本的累计索赔比例与累计暴露比例。</target>
        </trans-unit>
        <trans-unit id="30a2aa60dabe3d1d8b8497c6228442c6c55454f4" translate="yes" xml:space="preserve">
          <source>To control display of warnings.</source>
          <target state="translated">控制警告的显示。</target>
        </trans-unit>
        <trans-unit id="6c3d05eecff544d238db6888c87daeb42794f44b" translate="yes" xml:space="preserve">
          <source>To control the verbosity of the procedure.</source>
          <target state="translated">要控制程序的啰嗦。</target>
        </trans-unit>
        <trans-unit id="d66f891ca7bde7537002ad52d27fc9dd62dd5881" translate="yes" xml:space="preserve">
          <source>To convert categorical features to such integer codes, we can use the &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt;. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):</source>
          <target state="translated">要将分类特征转换为此类整数代码，我们可以使用&lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt; &lt;code&gt;OrdinalEncoder&lt;/code&gt; &lt;/a&gt;。此估算器将每个分类特征转换为一个新的整数特征（0到n_categories-1）：</target>
        </trans-unit>
        <trans-unit id="c4d6b75ae9bd1ab8a2aa45db1ede3ed88ee6cb4c" translate="yes" xml:space="preserve">
          <source>To correct this, the list of labels should be passed in as:</source>
          <target state="translated">为了纠正这一点,应将标签列表传递为。</target>
        </trans-unit>
        <trans-unit id="693e8d8ca1982fe1e279b5869b2b710976d06558" translate="yes" xml:space="preserve">
          <source>To counter this effect we can discount the expected RI \(E[\text{RI}]\) of random labelings by defining the adjusted Rand index as follows:</source>
          <target state="translated">为了应对这种效应,我们可以通过定义调整后的兰德指数,对随机标签的预期RI/(E[\text{RI}]\)进行贴现,如下所示。</target>
        </trans-unit>
        <trans-unit id="2ccfac714af4138a2df70ede11b2ff4e1963a414" translate="yes" xml:space="preserve">
          <source>To create positive examples click the left mouse button; to create negative examples click the right button.</source>
          <target state="translated">要创建正面的例子,请点击鼠标左键;要创建负面的例子,请点击右键。</target>
        </trans-unit>
        <trans-unit id="3c7bf94a5fb077c325503613ed6e46ecc0fdb413" translate="yes" xml:space="preserve">
          <source>To decide on the importance of the features we are going to use LassoCV estimator. The features with the highest absolute &lt;code&gt;coef_&lt;/code&gt; value are considered the most important</source>
          <target state="translated">为了确定功能的重要性，我们将使用LassoCV估计器。绝对 &lt;code&gt;coef_&lt;/code&gt; 值最高的要素被认为是最重要的</target>
        </trans-unit>
        <trans-unit id="91f3b8c70c19596fa3422a68b56ef8a0e44f9e91" translate="yes" xml:space="preserve">
          <source>To describe the dataset as a linear model we use a ridge regressor with a very small regularization and to model the logarithm of the WAGE.</source>
          <target state="translated">为了将数据集描述为一个线性模型,我们使用一个正则化非常小的山脊回归器,并对WAGE的对数进行建模。</target>
        </trans-unit>
        <trans-unit id="a890a65f7673c36b72863dcfff2db0d979bb71bc" translate="yes" xml:space="preserve">
          <source>To design our machine-learning pipeline, we first manually check the type of data that we are dealing with:</source>
          <target state="translated">为了设计我们的机器学习管道,我们首先手动检查我们所处理的数据类型。</target>
        </trans-unit>
        <trans-unit id="d0bfc36f728f01d8f998e7e774b5cc731a5652d7" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on inertia, set max_no_improvement to None.</source>
          <target state="translated">要禁用基于惯性的收敛检测,请将max_no_improvement设置为None。</target>
        </trans-unit>
        <trans-unit id="644ea86209186f0b63818c18611416bf68aa348b" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on normalized center change, set tol to 0.0 (default).</source>
          <target state="translated">要禁用基于归一化中心变化的收敛检测,请将tol设置为0.0(默认)。</target>
        </trans-unit>
        <trans-unit id="8f49411326bd4f684fb56ae33f90d4fd9150ab8c" translate="yes" xml:space="preserve">
          <source>To do the exercises, copy the content of the &amp;lsquo;skeletons&amp;rsquo; folder as a new folder named &amp;lsquo;workspace&amp;rsquo;:</source>
          <target state="translated">要进行练习，请将&amp;ldquo; skeletons&amp;rdquo;文件夹的内容复制为名为&amp;ldquo; workspace&amp;rdquo;的新文件夹：</target>
        </trans-unit>
        <trans-unit id="79cf44a84fa8878b10f291a31335b47430451015" translate="yes" xml:space="preserve">
          <source>To each column, a different transformation can be applied, such as preprocessing or a specific feature extraction method:</source>
          <target state="translated">对每一列,可以应用不同的变换,如预处理或特定的特征提取方法。</target>
        </trans-unit>
        <trans-unit id="2e998c39435525bfb05b6223ee051590414cf95b" translate="yes" xml:space="preserve">
          <source>To ensure that estimators yield reasonable predictions for different policyholder types, we can bin test samples according to &lt;code&gt;y_pred&lt;/code&gt; returned by each model. Then for each bin, we compare the mean predicted &lt;code&gt;y_pred&lt;/code&gt;, with the mean observed target:</source>
          <target state="translated">为了确保估算器可以针对不同的保单持有人类型做出合理的预测，我们可以根据每个模型返回的 &lt;code&gt;y_pred&lt;/code&gt; 对测试样本进行分类。然后，对于每个bin，我们将平均预测的 &lt;code&gt;y_pred&lt;/code&gt; 与平均观测到的目标进行比较：</target>
        </trans-unit>
        <trans-unit id="a0a5ce85df1e1aafd2ebf61b7efd7098beb62d7b" translate="yes" xml:space="preserve">
          <source>To estimate a probabilistic model (e.g. a Gaussian model), estimating the precision matrix, that is the inverse covariance matrix, is as important as estimating the covariance matrix. Indeed a Gaussian model is parametrized by the precision matrix.</source>
          <target state="translated">要估计一个概率模型(如高斯模型),估计精密矩阵,即反协方差矩阵,与估计协方差矩阵同样重要。事实上,高斯模型是以精密矩阵为参数的。</target>
        </trans-unit>
        <trans-unit id="06985e50b51113b200d13cecad3eedd2a07fa798" translate="yes" xml:space="preserve">
          <source>To evaluate the impact of the scale of the dataset (&lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_features&lt;/code&gt;) while controlling the statistical properties of the data (typically the correlation and informativeness of the features), it is also possible to generate synthetic data.</source>
          <target state="translated">为了在控制数据的统计属性（通常是特征的相关性和信息性）的同时评估数据集规模（ &lt;code&gt;n_samples&lt;/code&gt; 和 &lt;code&gt;n_features&lt;/code&gt; ）的影响，也可以生成综合数据。</target>
        </trans-unit>
        <trans-unit id="fa6d485f0cac2ad780f34f2a0f500816dbb434b1" translate="yes" xml:space="preserve">
          <source>To evaluate the pertinence of the used metrics, we will consider as a baseline a &amp;ldquo;dummy&amp;rdquo; estimator that constantly predicts the mean frequency of the training sample.</source>
          <target state="translated">为了评估所使用指标的相关性，我们将以&amp;ldquo;虚拟&amp;rdquo;估算器作为基线，该估算器不断地预测训练样本的平均频率。</target>
        </trans-unit>
        <trans-unit id="8b81da86f6a51388bf88e8748866dfbc1da10ddb" translate="yes" xml:space="preserve">
          <source>To fully specify a dataset, you need to provide a name and a version, though the version is optional, see &lt;a href=&quot;#openml-versions&quot;&gt;Dataset Versions&lt;/a&gt; below. The dataset contains a total of 1080 examples belonging to 8 different classes:</source>
          <target state="translated">要完全指定数据集，您需要提供名称和版本，尽管版本是可选的，请参见下面的&amp;ldquo; &lt;a href=&quot;#openml-versions&quot;&gt;数据集版本&amp;rdquo;&lt;/a&gt;。数据集总共包含1080个示例，这些示例属于8个不同的类别：</target>
        </trans-unit>
        <trans-unit id="eddbe44ecc236b178d14592239180b4231c2f462" translate="yes" xml:space="preserve">
          <source>To get a better measure of prediction accuracy (which we can use as a proxy for goodness of fit of the model), we can successively split the data in &lt;em&gt;folds&lt;/em&gt; that we use for training and testing:</source>
          <target state="translated">为了更好地衡量预测准确性（我们可以将其用作模型拟合优度的代理），我们可以将数据依次&lt;em&gt;折叠&lt;/em&gt;以用于训练和测试：</target>
        </trans-unit>
        <trans-unit id="8f2c7c86e5d1b0f8592203b4a46517414e54ce05" translate="yes" xml:space="preserve">
          <source>To get identical results for each split, set &lt;code&gt;random_state&lt;/code&gt; to an integer.</source>
          <target state="translated">要获得每个拆分相同的结果，请将 &lt;code&gt;random_state&lt;/code&gt; 设置为整数。</target>
        </trans-unit>
        <trans-unit id="0228140936e0aced4eaa7c77d90637025c4d0909" translate="yes" xml:space="preserve">
          <source>To get started with this tutorial, you must first install &lt;em&gt;scikit-learn&lt;/em&gt; and all of its required dependencies.</source>
          <target state="translated">要开始本教程，您必须首先安装&lt;em&gt;scikit-learn&lt;/em&gt;及其所有必需的依赖项。</target>
        </trans-unit>
        <trans-unit id="8d91bad777aec839541c338ab9f11be081ee54c6" translate="yes" xml:space="preserve">
          <source>To get the signed distance to the hyperplane use &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt;&lt;code&gt;SGDClassifier.decision_function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">要获得到超平面的签名距离，请使用&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt; &lt;code&gt;SGDClassifier.decision_function&lt;/code&gt; &lt;/a&gt;：</target>
        </trans-unit>
        <trans-unit id="507e34b3976bcfaf958e1f0006102fdd2d8713ea" translate="yes" xml:space="preserve">
          <source>To go further we remove one of the 2 features and check what is the impact on the model stability.</source>
          <target state="translated">为了更进一步,我们去掉2个功能中的一个,检查对模型稳定性有什么影响。</target>
        </trans-unit>
        <trans-unit id="6ae2612052e54b7be6598947088a287fffd01403" translate="yes" xml:space="preserve">
          <source>To illustrate &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt;, first let&amp;rsquo;s create an imbalanced dataset:</source>
          <target state="translated">为了说明&lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt;，首先让我们创建一个不平衡的数据集：</target>
        </trans-unit>
        <trans-unit id="e7a02a8f3e922c68cd6ce64dca33ce54683ffb1b" translate="yes" xml:space="preserve">
          <source>To illustrate this with a simple example, let&amp;rsquo;s assume we have 3 classifiers and a 3-class classification problems where we assign equal weights to all classifiers: w1=1, w2=1, w3=1.</source>
          <target state="translated">为了用一个简单的例子说明这一点，我们假设我们有3个分类器和3类分类问题，其中我们为所有分类器分配相等的权重：w1 = 1，w2 = 1，w3 = 1。</target>
        </trans-unit>
        <trans-unit id="27fe4060cc8aa9166cda2609863b9fdd12999baf" translate="yes" xml:space="preserve">
          <source>To illustrate this, PCA is performed comparing the use of data with &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt; applied, to unscaled data. The results are visualized and a clear difference noted. The 1st principal component in the unscaled set can be seen. It can be seen that feature #13 dominates the direction, being a whole two orders of magnitude above the other features. This is contrasted when observing the principal component for the scaled version of the data. In the scaled version, the orders of magnitude are roughly the same across all the features.</source>
          <target state="translated">为了说明这一点，执行PCA，将应用了&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt;的数据的使用与未缩放的数据进行比较。结果可视化，并指出明显的差异。可以看到未缩放集合中的第一个主成分。可以看出，特征＃13主导了方向，比其他特征高两个数量级。当观察数据的缩放版本的主成分时，这是相反的。在缩放版本中，所有功能的数量级大致相同。</target>
        </trans-unit>
        <trans-unit id="952f60109f87198cc4767d483a08ad921abb5966" translate="yes" xml:space="preserve">
          <source>To improve the conditioning of the problem (i.e. mitigating the &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;The curse of dimensionality&lt;/a&gt;), it would be interesting to select only the informative features and set non-informative ones, like feature 2 to 0. Ridge regression will decrease their contribution, but not set them to zero. Another penalization approach, called &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; (least absolute shrinkage and selection operator), can set some coefficients to zero. Such methods are called &lt;strong&gt;sparse method&lt;/strong&gt; and sparsity can be seen as an application of Occam&amp;rsquo;s razor: &lt;em&gt;prefer simpler models&lt;/em&gt;.</source>
          <target state="translated">为了改善问题的状况（即减轻&lt;a href=&quot;#curse-of-dimensionality&quot;&gt;维数的诅咒&lt;/a&gt;），仅选择信息性特征并将非信息性特征（例如特征2设置为0）会很有趣。他们为零。另一种惩罚方法称为&lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt;（最小绝对收缩和选择算子），可以将一些系数设置为零。这种方法称为&lt;strong&gt;稀疏方法&lt;/strong&gt;，稀疏性可以看作是Occam剃刀的一种应用：&lt;em&gt;更喜欢简单的模型&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="172f2bacd24a45cfb82f466d14d1d58833b9ee69" translate="yes" xml:space="preserve">
          <source>To install the latest version (with pip):</source>
          <target state="translated">要安装最新版本(用pip)。</target>
        </trans-unit>
        <trans-unit id="f028c20036ea78694db90136b8cb3004f099e0bf" translate="yes" xml:space="preserve">
          <source>To limit the memory consumption, we queue examples up to a fixed amount before feeding them to the learner.</source>
          <target state="translated">为了限制内存消耗,我们将例子排到一个固定的数量,然后再将它们喂给学习者。</target>
        </trans-unit>
        <trans-unit id="61f860c325e06c4f97b9f4c7ced3d5279054856d" translate="yes" xml:space="preserve">
          <source>To load from an external dataset, please refer to &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;loading external datasets&lt;/a&gt;.</source>
          <target state="translated">要从外部数据集&lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;加载&lt;/a&gt;，请参阅加载外部数据集。</target>
        </trans-unit>
        <trans-unit id="d787fd22509da728f07846c2b5d3ecac1d6b4105" translate="yes" xml:space="preserve">
          <source>To load the data and visualize the images:</source>
          <target state="translated">加载数据并将图像可视化。</target>
        </trans-unit>
        <trans-unit id="b4be4dde535adc435619c6f0e295e0ce05bad72b" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance.</source>
          <target state="translated">为了让这个例子运行得更快,我们使用很少的隐藏单元,并且只在很短的时间内进行训练。训练时间越长,权重的空间外观就越平滑。</target>
        </trans-unit>
        <trans-unit id="c413b102ea3791278492eefc26d38700197d19c5" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance. The example will throw a warning because it doesn&amp;rsquo;t converge, in this case this is what we want because of CI&amp;rsquo;s time constraints.</source>
          <target state="translated">为了使示例运行更快，我们使用了很少的隐藏单元，并且只训练了很短的时间。训练时间越长，举重的空间外观就越平滑。该示例将发出警告，因为它没有收敛，在这种情况下，由于CI的时间限制，这就是我们想要的。</target>
        </trans-unit>
        <trans-unit id="96ba992a3c5af68caa74d107191c5a3c32806c93" translate="yes" xml:space="preserve">
          <source>To make the preprocessor, tokenizer and analyzers aware of the model parameters it is possible to derive from the class and override the &lt;code&gt;build_preprocessor&lt;/code&gt;, &lt;code&gt;build_tokenizer&lt;/code&gt; and &lt;code&gt;build_analyzer&lt;/code&gt; factory methods instead of passing custom functions.</source>
          <target state="translated">为了使预处理器，令牌生成器和分析器了解模型参数，可以从类派生并覆盖 &lt;code&gt;build_preprocessor&lt;/code&gt; ， &lt;code&gt;build_tokenizer&lt;/code&gt; 和 &lt;code&gt;build_analyzer&lt;/code&gt; 工厂方法，而不用传递自定义函数。</target>
        </trans-unit>
        <trans-unit id="c0f08b8475e4b67e5147698ce9ccb818f0394d27" translate="yes" xml:space="preserve">
          <source>To make this more explicit, consider the following notation:</source>
          <target state="translated">为了更明确地说明这一点,请考虑以下的记法。</target>
        </trans-unit>
        <trans-unit id="8ada09feb86f8f3751dffbeeaba0e1e4f69156a7" translate="yes" xml:space="preserve">
          <source>To obtain a fully probabilistic model, the output \(y\) is assumed to be Gaussian distributed around \(X w\):</source>
          <target state="translated">为了获得一个完全的概率模型,假设输出/(y)是围绕/(X w/)的高斯分布。</target>
        </trans-unit>
        <trans-unit id="65178eef58b048e690e1c210520e38da80789880" translate="yes" xml:space="preserve">
          <source>To perform classification with generalized linear models, see &lt;a href=&quot;#logistic-regression&quot;&gt;Logistic regression&lt;/a&gt;.</source>
          <target state="translated">要使用广义线性模型进行分类，请参阅&lt;a href=&quot;#logistic-regression&quot;&gt;Logistic回归&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="72dc32b7225454e8d7c0ec26f14d95b55df2c79a" translate="yes" xml:space="preserve">
          <source>To quantify estimation error, we plot the likelihood of unseen data for different values of the shrinkage parameter. We also show the choices by cross-validation, or with the LedoitWolf and OAS estimates.</source>
          <target state="translated">为了量化估计误差,我们绘制了不同收缩参数值的未见数据的可能性。我们还显示了通过交叉验证,或与LedoitWolf和OAS估计的选择。</target>
        </trans-unit>
        <trans-unit id="397393d3de29d9ed57b4f231bd553afc264bafab" translate="yes" xml:space="preserve">
          <source>To return the corresponding classical subsets of kddcup 99. If None, return the entire kddcup 99 dataset.</source>
          <target state="translated">要返回kddcup 99的相应经典子集。如果None,返回整个kddcup 99数据集。</target>
        </trans-unit>
        <trans-unit id="b0e502baa68f0434bb574994337b41db58fa07c4" translate="yes" xml:space="preserve">
          <source>To run cross-validation on multiple metrics and also to return train scores, fit times and score times.</source>
          <target state="translated">要在多个指标上运行交叉验证,也要返回训练得分、拟合时间和得分时间。</target>
        </trans-unit>
        <trans-unit id="2d79b95a40b4d1ea2f276f13509aebc984e2d932" translate="yes" xml:space="preserve">
          <source>To see how this generalizes the binary log loss given above, note that in the binary case, \(p_{i,0} = 1 - p_{i,1}\) and \(y_{i,0} = 1 - y_{i,1}\), so expanding the inner sum over \(y_{i,k} \in \{0,1\}\) gives the binary log loss.</source>
          <target state="translated">为了了解这如何概括上面给出的二元对数损失,请注意,在二元情况下,\(p_{i,0}=1-p_{i,1}\)和\(y_{i,0}=1-y_{i,1}\),因此在\(y_{i,k}\in \{0,1/}\)上扩展内和,得到二元对数损失。</target>
        </trans-unit>
        <trans-unit id="25684d8b1766d360b665e8498a44a626b2b5bd13" translate="yes" xml:space="preserve">
          <source>To set &lt;code&gt;n_clusters=None&lt;/code&gt; initially</source>
          <target state="translated">最初设置 &lt;code&gt;n_clusters=None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="78f293aec6a6c458449c6dc3bcd71b696525a449" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds.</source>
          <target state="translated">为了加快算法的速度,只接受那些至少有min_bin_freq点的bin作为种子。</target>
        </trans-unit>
        <trans-unit id="e1dfcbed698085a7ab462cf760bf24e65a9e8400" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds. If not defined, set to 1.</source>
          <target state="translated">为了加快算法的速度,只接受那些至少有min_bin_freq点的bin作为种子。如果没有定义,设置为1。</target>
        </trans-unit>
        <trans-unit id="d139a616dfe019ba73a251e6419e9ddac4a94c0f" translate="yes" xml:space="preserve">
          <source>To support imputation in inductive mode we store each feature&amp;rsquo;s estimator during the &lt;code&gt;fit&lt;/code&gt; phase, and predict without refitting (in order) during the &lt;code&gt;transform&lt;/code&gt; phase.</source>
          <target state="translated">为了支持归纳模式下的插补，我们在 &lt;code&gt;fit&lt;/code&gt; 阶段存储每个要素的估计量，并在 &lt;code&gt;transform&lt;/code&gt; 阶段进行预测而不进行重新拟合（按顺序）。</target>
        </trans-unit>
        <trans-unit id="d14a37b58107d5112ea5c1494d2809710215a276" translate="yes" xml:space="preserve">
          <source>To train the &lt;code&gt;estimators&lt;/code&gt; and &lt;code&gt;final_estimator&lt;/code&gt;, the &lt;code&gt;fit&lt;/code&gt; method needs to be called on the training data:</source>
          <target state="translated">要训​​练 &lt;code&gt;estimators&lt;/code&gt; 和 &lt;code&gt;final_estimator&lt;/code&gt; ，需要在训练数据上调用 &lt;code&gt;fit&lt;/code&gt; 方法：</target>
        </trans-unit>
        <trans-unit id="fd2f04d7c6e080a2cce0d2e7339e598ba17acac5" translate="yes" xml:space="preserve">
          <source>To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call &lt;code&gt;transform&lt;/code&gt; instead of &lt;code&gt;fit_transform&lt;/code&gt; on the transformers, since they have already been fit to the training set:</source>
          <target state="translated">为了尝试预测新文档的结果，我们需要使用与以前几乎相同的特征提取链来提取特征。区别在于我们在转换 &lt;code&gt;fit_transform&lt;/code&gt; 上调用 &lt;code&gt;transform&lt;/code&gt; 而不是fit_transform，因为它们已经适合训练集：</target>
        </trans-unit>
        <trans-unit id="5da67914dc5314b6125944bb748e1a3d6c08f736" translate="yes" xml:space="preserve">
          <source>To understand the use of LDA in dimensionality reduction, it is useful to start with a geometric reformulation of the LDA classification rule explained above. We write \(K\) for the total number of target classes. Since in LDA we assume that all classes have the same estimated covariance \(\Sigma\), we can rescale the data so that this covariance is the identity:</source>
          <target state="translated">为了理解LDA在降维中的应用,我们可以从上面解释的LDA分类规则的几何重述开始。我们将目标类的总数量写为 \(K\)。由于在LDA中,我们假设所有的类都有相同的估计协方差 \(\Sigma\),我们可以重新调整数据的尺度,使这个协方差是身份。</target>
        </trans-unit>
        <trans-unit id="6df5e0eab0e1e02def9ae99e68c6ddf1a841d6d1" translate="yes" xml:space="preserve">
          <source>To use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you need to instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator:</source>
          <target state="translated">要使用&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;进行新颖性检测，即预测标签或计算新的看不见数据的异常分数，您需要在将估算器拟合之前将 &lt;code&gt;novelty&lt;/code&gt; 参数设置为 &lt;code&gt;True&lt;/code&gt; 来实例化估算器：</target>
        </trans-unit>
        <trans-unit id="011ed6ad19bc2f123579a7e50ff8b4dad33bf360" translate="yes" xml:space="preserve">
          <source>To use joblib.Memory to cache the svmlight file:</source>
          <target state="translated">要使用joblib.Memory来缓存svmlight文件。</target>
        </trans-unit>
        <trans-unit id="e88dca9a24e84cd773e046a28a4daa4e8217f9da" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the :mod`~sklearn.feature_extraction.text` module to build a feature extraction transformer that suits your problem.</source>
          <target state="translated">要在scikit-learn分类或聚类算法中使用文本文件,你需要使用 :mod`~sklearn.feature_extraction.text`模块来构建适合你问题的特征提取变换器。</target>
        </trans-unit>
        <trans-unit id="e11936ea84de206f18d8b708b6f4eca9fb6c8b59" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; module to build a feature extraction transformer that suits your problem.</source>
          <target state="translated">要在scikit-learn分类或聚类算法中使用文本文件，您将需要使用 &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; 模块来构建适合您问题的特征提取转换器。</target>
        </trans-unit>
        <trans-unit id="c7aa2d2ef894f356c354736ecb4235681bee95b2" translate="yes" xml:space="preserve">
          <source>To use this dataset with scikit-learn, we transform each 8x8 image into a feature vector of length 64</source>
          <target state="translated">为了用scikit-learn来使用这个数据集,我们将每张8x8的图像转换为一个长度为64的特征向量</target>
        </trans-unit>
        <trans-unit id="f5d271c927cff9ea25de07089e51938b7e86a2a7" translate="yes" xml:space="preserve">
          <source>To use this model as a classifier, we just need to estimate from the training data the class priors \(P(y=k)\) (by the proportion of instances of class \(k\)), the class means \(\mu_k\) (by the empirical sample class means) and the covariance matrices (either by the empirical sample class covariance matrices, or by a regularized estimator: see the section on shrinkage below).</source>
          <target state="translated">为了使用这个模型作为分类器,我们只需要从训练数据中估计出类前值/(P(y=k)/)(通过类实例的比例/(k/)),类均值/(mu_k/)(通过经验样本类均值)和协方差矩阵(通过经验样本类协方差矩阵,或者通过正则化估计器:见下面关于收缩的部分)。</target>
        </trans-unit>
        <trans-unit id="54c39e1b5f1a8214dbbbffa4ce79accc0474a39a" translate="yes" xml:space="preserve">
          <source>To use this model for classification, one needs to combine a &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; instance that learns the optimal transformation with a &lt;a href=&quot;generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt; instance that performs the classification in the projected space. Here is an example using the two classes:</source>
          <target state="translated">要使用此模型进行分类，需要将学习最佳转换的&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; &lt;/a&gt;实例与在投影空间中执行分类的&lt;a href=&quot;generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt; &lt;code&gt;KNeighborsClassifier&lt;/code&gt; &lt;/a&gt;实例结合起来。这是使用两个类的示例：</target>
        </trans-unit>
        <trans-unit id="6e5117e9f756d52dfb6878a7715bd7c9bf590353" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="translated">为了验证模型，我们需要一个评分函数（请参阅&lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;指标和评分：量化预测质量&lt;/a&gt;），例如分类器的准确性。选择估算器的多个超参数的正确方法当然是网格搜索或类似的方法（请参阅&lt;a href=&quot;grid_search#grid-search&quot;&gt;调整估算器的超参数&lt;/a&gt;），该方法选择在一个或多个验证集上具有最高得分的超参数。请注意，如果我们基于验证分数优化超参数，则验证分数会产生偏差，不再是对泛化的良好估计。为了获得适当的泛化估计，我们必须在另一个测试集上计算分数。</target>
        </trans-unit>
        <trans-unit id="5d015bfb570917361c4b4abaaa59f5e623d8c463" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="translated">为了验证模型，我们需要一个评分函数（请参阅&lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;模型评估：量化预测的质量&lt;/a&gt;），例如分类器的准确性。选择估算器的多个超参数的正确方法当然是网格搜索或类似的方法（请参见&lt;a href=&quot;grid_search#grid-search&quot;&gt;调整估算器的超参数&lt;/a&gt;），该方法选择在一个或多个验证集上具有最高分数的超参数。请注意，如果我们基于验证分数优化超参数，则验证分数会产生偏差，不再是对泛化的良好估计。为了获得适当的泛化估计，我们必须在另一个测试集上计算分数。</target>
        </trans-unit>
        <trans-unit id="4f24d3986e58b34af3ea2c4b07af932b987ecc57" translate="yes" xml:space="preserve">
          <source>To verify this interpretation we plot the variability of the AGE and EXPERIENCE coefficient.</source>
          <target state="translated">为了验证这种解释,我们绘制了年龄和经验系数的变异性。</target>
        </trans-unit>
        <trans-unit id="baa10199f999bc30e58b0035ac2f6e51132399ed" translate="yes" xml:space="preserve">
          <source>To visualize the probability weighting, we fit each classifier on the training set and plot the predicted class probabilities for the first sample in this example dataset.</source>
          <target state="translated">为了可视化概率权重,我们在训练集上拟合每个分类器,并绘制该示例数据集中第一个样本的预测类概率。</target>
        </trans-unit>
        <trans-unit id="ba234a16bb1a2ae4619585ca04988c1afd574060" translate="yes" xml:space="preserve">
          <source>Tokenize the documents and count the occurrences of token and return them as a sparse matrix</source>
          <target state="translated">对文档进行token化,计算token的出现次数,并以稀疏矩阵的形式返回。</target>
        </trans-unit>
        <trans-unit id="e89caeb25fc24a274e225b242d49cc6fb7ddfa72" translate="yes" xml:space="preserve">
          <source>Tokenizing text with &lt;code&gt;scikit-learn&lt;/code&gt;</source>
          <target state="translated">使用 &lt;code&gt;scikit-learn&lt;/code&gt; 对文本进行标记</target>
        </trans-unit>
        <trans-unit id="45d4a0ebe499a5d042ac0f7bc4284501d3667758" translate="yes" xml:space="preserve">
          <source>Tolerance for &amp;lsquo;arpack&amp;rsquo; method Not used if eigen_solver==&amp;rsquo;dense&amp;rsquo;.</source>
          <target state="translated">'arpack'方法的公差如果eigen_solver =='dense'不使用。</target>
        </trans-unit>
        <trans-unit id="318dfc593e0123f93a8fe309f411532f48eea756" translate="yes" xml:space="preserve">
          <source>Tolerance for ARPACK. 0 means machine precision. Ignored by randomized SVD solver.</source>
          <target state="translated">ARPACK的公差。0表示机器精度。随机化SVD求解器忽略。</target>
        </trans-unit>
        <trans-unit id="13511570864a98fa2d61f43da929b11b4894937f" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if &lt;code&gt;method == 'hessian'&lt;/code&gt;</source>
          <target state="translated">黑森州特征映射方法的公差。仅在 &lt;code&gt;method == 'hessian'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e4c877ba267607a99e62c8b31f7891feda117cf7" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if method == &amp;lsquo;hessian&amp;rsquo;</source>
          <target state="translated">黑森州特征映射方法的公差。仅在方法=='hessian'时使用</target>
        </trans-unit>
        <trans-unit id="aeb25ea9c0101939a4336136b4e11db71f1bb1be" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if &lt;code&gt;method == 'modified'&lt;/code&gt;</source>
          <target state="translated">修正的LLE方法的公差。仅在 &lt;code&gt;method == 'modified'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b6502cfb6f414093cd5faf0376953824eae5e86f" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if method == &amp;lsquo;modified&amp;rsquo;</source>
          <target state="translated">修正的LLE方法的公差。仅在方法=='modified'时使用</target>
        </trans-unit>
        <trans-unit id="40eaf2d9a188116c07595886d4a67c9121557ecf" translate="yes" xml:space="preserve">
          <source>Tolerance for singular values computed by svd_solver == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">svd_solver =='arpack'计算的奇异值的公差。</target>
        </trans-unit>
        <trans-unit id="a495f50d68c5f0d21905244c442ac1ec46831c6d" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criteria.</source>
          <target state="translated">停止标准的容忍度。</target>
        </trans-unit>
        <trans-unit id="1f900b2be351c5e1d6397b25c9a2e6c5e5c36343" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criterion.</source>
          <target state="translated">停止标准的公差。</target>
        </trans-unit>
        <trans-unit id="4d73abe23fd3517118aa70ae58840719c14ae6a0" translate="yes" xml:space="preserve">
          <source>Tolerance for the early stopping. When the loss is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations (if set to a number), the training stops.</source>
          <target state="translated">允许提前停止。当 &lt;code&gt;n_iter_no_change&lt;/code&gt; 迭代的损失至少没有改善时（如果设置为数字），训练将停止。</target>
        </trans-unit>
        <trans-unit id="334a1d6597d473e85cc8725e20828e0c9824ea02" translate="yes" xml:space="preserve">
          <source>Tolerance for the optimization. When the loss or score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive iterations, unless &lt;code&gt;learning_rate&lt;/code&gt; is set to &amp;lsquo;adaptive&amp;rsquo;, convergence is considered to be reached and training stops.</source>
          <target state="translated">优化公差。当损失或成绩不被至少提高 &lt;code&gt;tol&lt;/code&gt; 为 &lt;code&gt;n_iter_no_change&lt;/code&gt; 连续迭代，除非 &lt;code&gt;learning_rate&lt;/code&gt; 设置为&amp;ldquo;自适应&amp;rdquo;，融合被认为是达到和培训停止。</target>
        </trans-unit>
        <trans-unit id="6938a4dcb29969d15aaa6cafefb8f09b830ed305" translate="yes" xml:space="preserve">
          <source>Tolerance for the stopping condition.</source>
          <target state="translated">停止条件的公差。</target>
        </trans-unit>
        <trans-unit id="3a49445cc3e76e8c0deab47f4b10c5bd7dc33960" translate="yes" xml:space="preserve">
          <source>Tolerance of the stopping condition.</source>
          <target state="translated">停止条件的容忍度。</target>
        </trans-unit>
        <trans-unit id="48a48ded1ae1ed29a7ddaed19c15db301472918d" translate="yes" xml:space="preserve">
          <source>Tolerance on update at each iteration.</source>
          <target state="translated">每次迭代更新时的公差。</target>
        </trans-unit>
        <trans-unit id="a2223ba588ac8a94dc6928512bbe1ae559b46f6b" translate="yes" xml:space="preserve">
          <source>Tolerance used in the iterative algorithm default 1e-06.</source>
          <target state="translated">迭代算法中使用的公差,默认为1e-06。</target>
        </trans-unit>
        <trans-unit id="20a2955c412dcae35aa2ef964ce8c2d4b1c07dcb" translate="yes" xml:space="preserve">
          <source>Tolerance when calculating spatial median.</source>
          <target state="translated">计算空间中位数时的公差。</target>
        </trans-unit>
        <trans-unit id="f3d0c54c4b7882f5280f0492c26f2bf33d35d2a2" translate="yes" xml:space="preserve">
          <source>Tony Blair</source>
          <target state="translated">托尼-布莱尔</target>
        </trans-unit>
        <trans-unit id="e1781cb6d03ccb2216639c1d54de7540b9fc2c2b" translate="yes" xml:space="preserve">
          <source>Tools for imputing missing values are discussed at &lt;a href=&quot;impute#impute&quot;&gt;Imputation of missing values&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;impute#impute&quot;&gt;插补缺失值的&lt;/a&gt;工具在插补缺失值中进行了讨论。</target>
        </trans-unit>
        <trans-unit id="0d184ce2992ee425b9d4cc3d528da94fb4da399d" translate="yes" xml:space="preserve">
          <source>Tophat kernel (&lt;code&gt;kernel = 'tophat'&lt;/code&gt;)</source>
          <target state="translated">Tophat内核（ &lt;code&gt;kernel = 'tophat'&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="0954aa60533f43dc3b2b9a9cbdee11a74f79eada" translate="yes" xml:space="preserve">
          <source>Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</source>
          <target state="translated">用非负矩阵因子化和Latent Dirichlet Allocation进行主题提取。</target>
        </trans-unit>
        <trans-unit id="97129616afbfcb01d33b44619c8bf267194395ac" translate="yes" xml:space="preserve">
          <source>Total Phenols:</source>
          <target state="translated">酚类总量:</target>
        </trans-unit>
        <trans-unit id="b9c3723a92a74173bb8adb739559660c0010b476" translate="yes" xml:space="preserve">
          <source>Total impurity of leaves vs effective alphas of pruned tree</source>
          <target state="translated">叶子的总杂质与修剪树的有效碱度对比</target>
        </trans-unit>
        <trans-unit id="24a9e81269d05c734577a89440230faee238f7b2" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X.</source>
          <target state="translated">X中数据的总对数似然。</target>
        </trans-unit>
        <trans-unit id="1861e0049c1f17066ecafccd7b29a27b43a45cf0" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X. This is normalized to be a probability density, so the value will be low for high-dimensional data.</source>
          <target state="translated">X中数据的总对数似然性,这个是归一化的概率密度,所以对于高维数据,这个值会很低。</target>
        </trans-unit>
        <trans-unit id="0acc1077bbd3872347f5d4223b32bfa85b2dc24b" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;a href=&quot;#sklearn.decomposition.LatentDirichletAllocation.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">文件总数。仅在&lt;a href=&quot;#sklearn.decomposition.LatentDirichletAllocation.partial_fit&quot;&gt; &lt;code&gt;partial_fit&lt;/code&gt; &lt;/a&gt;方法中使用。</target>
        </trans-unit>
        <trans-unit id="4055747cee4593e58e4a6dcbfa7d6ccc61845cf0" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">文件总数。仅在 &lt;code&gt;partial_fit&lt;/code&gt; 方法中使用。</target>
        </trans-unit>
        <trans-unit id="aed40ed5719d059f29eba1177189a60b01059871" translate="yes" xml:space="preserve">
          <source>Total phenols</source>
          <target state="translated">总酚类</target>
        </trans-unit>
        <trans-unit id="babba0bc0e9a3e36ce98f362a62519c8eacb94cb" translate="yes" xml:space="preserve">
          <source>Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method Andrew V. Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</source>
          <target state="translated">走向最佳预处理特征求解器：局部最佳块预处理共轭梯度法Andrew V. Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e3ae1e8d052cc2d0c25bbda7e5d0370ec624b1e8" translate="yes" xml:space="preserve">
          <source>Toy example of 1D regression using linear, polynomial and RBF kernels.</source>
          <target state="translated">使用线性、多项式和RBF核的一维回归的玩具例子。</target>
        </trans-unit>
        <trans-unit id="264fa08a131d6382d6715d8c951f2b5bea1c373c" translate="yes" xml:space="preserve">
          <source>Traceback example, note how the line of the error is indicated as well as the values of the parameter passed to the function that triggered the exception, even though the traceback happens in the child process:</source>
          <target state="translated">回溯的例子,请注意,尽管回溯发生在子进程中,但如何显示错误的行以及传递给触发异常的函数的参数值。</target>
        </trans-unit>
        <trans-unit id="8718fa41b5577d15733c0d074d4e6ea2d5f88486" translate="yes" xml:space="preserve">
          <source>Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.</source>
          <target state="translated">Tracking,International Journal of Computer Vision,Volume 77,Issue 1-3,pp.125-141,May 2008.</target>
        </trans-unit>
        <trans-unit id="20662c705376209f11480639e3ee11e7bf62f8df" translate="yes" xml:space="preserve">
          <source>Traditional regression metrics such as Mean Squared Error and Mean Absolute Error are hard to meaningfully interpret on count values with many zeros.</source>
          <target state="translated">传统的回归指标,如均值平方误差和均值绝对误差,在有许多零的计数值上很难有意义的解释。</target>
        </trans-unit>
        <trans-unit id="6e4826fce9da6f5f03d1b11115df13e0bc514c4a" translate="yes" xml:space="preserve">
          <source>Train all data by multiple calls to partial_fit.</source>
          <target state="translated">通过多次调用 partial_fit 来训练所有数据。</target>
        </trans-unit>
        <trans-unit id="bd98708380c7e60a9c0a687f254abca8478a36f8" translate="yes" xml:space="preserve">
          <source>Train and test sizes may be different in each fold, with a difference of at most &lt;code&gt;n_classes&lt;/code&gt;.</source>
          <target state="translated">每个折叠的训练和测试大小可能不同，最多 &lt;code&gt;n_classes&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1c08c1bee3835bcafdb50e8cdda68c68d71fa67e" translate="yes" xml:space="preserve">
          <source>Train error vs Test error</source>
          <target state="translated">训练误差与测试误差</target>
        </trans-unit>
        <trans-unit id="357c94d50b669e3c60f0758a6140ed17dc81af61" translate="yes" xml:space="preserve">
          <source>Train l1-penalized logistic regression models on a binary classification problem derived from the Iris dataset.</source>
          <target state="translated">在源于Iris数据集的二元分类问题上训练l1-penalized logistic回归模型。</target>
        </trans-unit>
        <trans-unit id="5099d1b071bb02f5306e84c9c0e29bbe834adc72" translate="yes" xml:space="preserve">
          <source>Train models on the diabetes dataset</source>
          <target state="translated">在糖尿病数据集上训练模型</target>
        </trans-unit>
        <trans-unit id="0cfcb0c276264df865da734aa7faab6c6b43fed6" translate="yes" xml:space="preserve">
          <source>Train the model using libsvm (low-level method)</source>
          <target state="translated">使用libsvm(低级方法)训练模型。</target>
        </trans-unit>
        <trans-unit id="b7dd566e0e9177f3a0300b3c2ac1d09a00aaeda2" translate="yes" xml:space="preserve">
          <source>Training a Random Forest and Plotting the ROC Curve</source>
          <target state="translated">训练随机森林和绘制ROC曲线。</target>
        </trans-unit>
        <trans-unit id="ff5331ad7dc89bf5a9dd23c31ab738af7815c499" translate="yes" xml:space="preserve">
          <source>Training a classifier</source>
          <target state="translated">训练一个分类器</target>
        </trans-unit>
        <trans-unit id="8dcfc4ff7c1f7cc06878c0cf93f4198eb475ff8d" translate="yes" xml:space="preserve">
          <source>Training classifiers</source>
          <target state="translated">训练分类器</target>
        </trans-unit>
        <trans-unit id="0f0630eb2ecfdd0ed6f7defc6642e6c0143bcbf3" translate="yes" xml:space="preserve">
          <source>Training data</source>
          <target state="translated">训练数据</target>
        </trans-unit>
        <trans-unit id="6c7c988c62ce8a65ab6394bf4f62bdef696bbe60" translate="yes" xml:space="preserve">
          <source>Training data, requires length = n_samples</source>
          <target state="translated">训练数据,需要长度=n_samples。</target>
        </trans-unit>
        <trans-unit id="c0c6cec2e93954e8c33880af1baef2b15439d9d5" translate="yes" xml:space="preserve">
          <source>Training data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">训练数据，其中 &lt;code&gt;n_samples&lt;/code&gt; 是样本数， &lt;code&gt;n_features&lt;/code&gt; 是要素数。</target>
        </trans-unit>
        <trans-unit id="70fa8e3174eef9a1ccfc0bda8b38c7cfbf09ffd6" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">训练数据,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="1d999bb02f6364cf15c69e5533af993a3fc0fdd8" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">训练数据,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="c4f931e6893a5565e07f4500ddfb86c154c8b1a3" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, of shape (n_samples, n_samples).</source>
          <target state="translated">训练数据，这也是预测所必需的。如果kernel ==&amp;ldquo; precomputed&amp;rdquo;，则它是形状为（n_samples，n_samples）的预先计算的训练矩阵。</target>
        </trans-unit>
        <trans-unit id="f12731d4ed32a02266da09997a2bf0e000555cf6" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">训练数据，这也是预测所必需的。如果kernel ==&amp;ldquo; precomputed&amp;rdquo;，则它是预先计算的训练矩阵，shape = [n_samples，n_samples]。</target>
        </trans-unit>
        <trans-unit id="c5441fed149296831061b9151bd71d563327dc0d" translate="yes" xml:space="preserve">
          <source>Training data.</source>
          <target state="translated">训练数据:</target>
        </trans-unit>
        <trans-unit id="4319dec91a5574f9382b1b679ba9c82bf44c0f15" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, shape [n_samples, n_features], or [n_samples, n_samples] if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">训练数据。如果是数组或矩阵，则将其形状设置为[n_samples，n_features]，或者，如果metric ='precomputed'，则设置为[n_samples，n_samples]。</target>
        </trans-unit>
        <trans-unit id="744e21c8d62df0575ccae05fe593cde4f20f55b7" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, the shape is (n_samples, n_features), or (n_samples, n_samples) if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">训练数据。如果是数组或矩阵，则形状为（n_samples，n_features），或者，如果metric ='precomputed'，则形状为（n_samples，n_samples）。</target>
        </trans-unit>
        <trans-unit id="f6ee318ff46063d0c81310a68af0a95508a0a339" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, of shape (n_samples, n_samples).</source>
          <target state="translated">训练数据。如果kernel ==&amp;ldquo; precomputed&amp;rdquo;，则它是形状为（n_samples，n_samples）的预计算内核矩阵。</target>
        </trans-unit>
        <trans-unit id="3cc715a75ede17772899f7cc9ab69882475a79bc" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">训练数据。如果kernel ==&amp;ldquo; precomputed&amp;rdquo;，则它是一个预先计算的内核矩阵，shape = [n_samples，n_samples]。</target>
        </trans-unit>
        <trans-unit id="6ea489741914be2912ee247eeaf800f3ba49e6d8" translate="yes" xml:space="preserve">
          <source>Training data. If using GCV, will be cast to float64 if necessary.</source>
          <target state="translated">训练数据。如果使用GCV,必要时将投向float64。</target>
        </trans-unit>
        <trans-unit id="b12ede4c226e6e2f235813d30bce55744269c03f" translate="yes" xml:space="preserve">
          <source>Training data. Must fulfill input requirements of first step of the pipeline.</source>
          <target state="translated">训练数据。必须满足流水线第一步的输入要求。</target>
        </trans-unit>
        <trans-unit id="d5044fd4a2ac02d5a0b137f2f3b7fd6b8f65a006" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If &lt;code&gt;y&lt;/code&gt; is mono-output then &lt;code&gt;X&lt;/code&gt; can be sparse.</source>
          <target state="translated">训练数据。直接作为Fortran连续数据传递，以避免不必要的内存重复。如果 &lt;code&gt;y&lt;/code&gt; 是单输出，则 &lt;code&gt;X&lt;/code&gt; 可以稀疏。</target>
        </trans-unit>
        <trans-unit id="8ed7855d8da328d2505a0bcd1c3302665b72cb3d" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse.</source>
          <target state="translated">训练数据。直接以Fortran连续数据的形式传递,避免不必要的内存重复。如果y是单输出,X可以是稀疏的。</target>
        </trans-unit>
        <trans-unit id="4c004afef287030c2dcb4a937f43adb06e1cdf0e" translate="yes" xml:space="preserve">
          <source>Training data. Shape [n_samples, n_features], or [n_samples, n_samples] if affinity==&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">训练数据。形状为[n_samples，n_features]或[n_samples，n_samples]（如果affinity ==&amp;ldquo;预计算&amp;rdquo;）。</target>
        </trans-unit>
        <trans-unit id="30765b444b768ceb7d6bccc7cc4dd80dd79e1fcb" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;.</source>
          <target state="translated">训练实例进行聚类，或者如果 &lt;code&gt;affinity='precomputed'&lt;/code&gt; ，则训练实例之间的距离。</target>
        </trans-unit>
        <trans-unit id="c7fd3fb257a793666a84757ce13a7e7b97d84277" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;metric='precomputed'&lt;/code&gt;. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">训练实例进行聚类，如果 &lt;code&gt;metric='precomputed'&lt;/code&gt; ，则训练实例之间的距离。如果提供了稀疏矩阵，它将被转换为稀疏 &lt;code&gt;csr_matrix&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="106fdf378e3c73e01e49b8eb92780c5d664680e0" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse feature matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;affinity='precomputed'&lt;/code&gt; ，则训练实例进行聚类，或训练实例之间的相似性/亲和性。如果提供了稀疏特征矩阵，它将被转换为稀疏 &lt;code&gt;csr_matrix&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e31b10426b1248f84a44c65b36e8acd0e5e7589c" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse matrix is provided in a format other than &lt;code&gt;csr_matrix&lt;/code&gt;, &lt;code&gt;csc_matrix&lt;/code&gt;, or &lt;code&gt;coo_matrix&lt;/code&gt;, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;affinity='precomputed'&lt;/code&gt; ，则训练实例进行聚类，或训练实例之间的相似性/亲和性。如果以 &lt;code&gt;csr_matrix&lt;/code&gt; ， &lt;code&gt;csc_matrix&lt;/code&gt; 或 &lt;code&gt;coo_matrix&lt;/code&gt; 以外的格式提供稀疏矩阵，它将被转换为稀疏 &lt;code&gt;csr_matrix&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="be8959fb1d08ac2482d5adecb9cc6d42cd3487ff" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.</source>
          <target state="translated">训练实例进行聚类。必须注意的是,数据将被转换为C排序,如果给定的数据不是C连续的,将导致内存拷贝。</target>
        </trans-unit>
        <trans-unit id="eed67f947767b8d48d69b1a746024e52c70765e3" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it&amp;rsquo;s not in CSR format.</source>
          <target state="translated">训练实例进行集群。必须注意的是，数据将转换为C顺序，如果给定的数据不是C连续的，则将导致内存复制。如果传递的是稀疏矩阵，则如果不是CSR格式，则会进行复制。</target>
        </trans-unit>
        <trans-unit id="1fb973e1446d09c43085a14e14217bfa82f35fac" translate="yes" xml:space="preserve">
          <source>Training set and testing set</source>
          <target state="translated">训练集和测试集</target>
        </trans-unit>
        <trans-unit id="ea59a824d416e7ea0dc63df33b1afa59cdb64566" translate="yes" xml:space="preserve">
          <source>Training set.</source>
          <target state="translated">训练集。</target>
        </trans-unit>
        <trans-unit id="3c518c488676e60e90ca53bcc0aa7271b669fe4d" translate="yes" xml:space="preserve">
          <source>Training set: only the shape is used to find optimal random matrix dimensions based on the theory referenced in the afore mentioned papers.</source>
          <target state="translated">训练集:根据上述论文中引用的理论,只用形状来寻找最优的随机矩阵维度。</target>
        </trans-unit>
        <trans-unit id="68d52cda6c0756d21c2527d22eda07d7e45f55d9" translate="yes" xml:space="preserve">
          <source>Training target.</source>
          <target state="translated">培训目标:</target>
        </trans-unit>
        <trans-unit id="32e48bd3169f82f98b7879700514da5daba97549" translate="yes" xml:space="preserve">
          <source>Training targets. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">培训目标。必须满足流水线各步骤的标签要求。</target>
        </trans-unit>
        <trans-unit id="bc89d708a926da60c1e855065f294a150e4844da" translate="yes" xml:space="preserve">
          <source>Training vector, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the total number of features.</source>
          <target state="translated">训练向量，其中 &lt;code&gt;n_samples&lt;/code&gt; 是样本数， &lt;code&gt;n_features&lt;/code&gt; 是特征总数。</target>
        </trans-unit>
        <trans-unit id="325dc392b957558d0accbc4c288eabf85d0d476c" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">训练向量,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="01000b19ae19a1d02ea4ceb374852ca509745c92" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="translated">训练向量,其中n_samples为样本数,n_features为特征数。注意,中心子收缩不能用于稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="6a8354ff2f178d04d8fd18ac8502cba6a9d2e53e" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">训练向量,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="d6cf7c60af251621aaa911db11caacf9c4de19a4" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="translated">训练向量,其中n_samples为样本数,n_features为特征数。注意,中心收缩不能用于稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="23811d7edf5d74f8278700a3182a9d6e499aa68e" translate="yes" xml:space="preserve">
          <source>Training vectors, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">训练向量，其中 &lt;code&gt;n_samples&lt;/code&gt; 是样本数， &lt;code&gt;n_features&lt;/code&gt; 是特征数。</target>
        </trans-unit>
        <trans-unit id="66e0bce9861c05444da85a9795d5edcc3de5cb5e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">训练向量,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="f64b8abd734d5648613b346b4bb3c97a56c66bbf" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples, n_samples).</source>
          <target state="translated">训练向量，其中n_samples是样本数，n_​​features是特征数。对于内核=&amp;ldquo;预先计算&amp;rdquo;，X的预期形状为（n_samples，n_samples）。</target>
        </trans-unit>
        <trans-unit id="f07e6c81521ffea6a563851833abed1de8063cb9" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, &amp;hellip;, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.</source>
          <target state="translated">训练向量，其中n_samples是样本数，n_​​features是特征数。在此，假设X的每个特征都来自不同的分类分布。进一步假定每个特征的所有类别均由数字0，&amp;hellip;，n-1表示，其中n表示给定特征的类别总数。例如，这可以在OrdinalEncoder的帮助下实现。</target>
        </trans-unit>
        <trans-unit id="d1d0a9d845fc3b099041b2d0f31be0d050a7001e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. When using GCV, will be cast to float64 if necessary.</source>
          <target state="translated">训练向量,其中n_samples为样本数,n_features为特征数。当使用GCV时,必要时将被转为float64。</target>
        </trans-unit>
        <trans-unit id="ee5e82a19ba6d9a5b4fc8f431028f4e0ae5cae2a" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of predictors.</source>
          <target state="translated">训练向量,其中n_samples为样本数,n_features为预测因子数。</target>
        </trans-unit>
        <trans-unit id="3dbb8cbc3c8d093280069e8e889d1e0c62e1afde" translate="yes" xml:space="preserve">
          <source>Transform X back to its original space.</source>
          <target state="translated">将X变换回原来的空间。</target>
        </trans-unit>
        <trans-unit id="dbfeebba6e53c937056143e8cf1258378ae1c26d" translate="yes" xml:space="preserve">
          <source>Transform X back to original space.</source>
          <target state="translated">将X变换回原来的空间。</target>
        </trans-unit>
        <trans-unit id="aad161b5ffd8fb6722cd74d5621a58697eead90e" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of k nearest neighbors</source>
          <target state="translated">将X转化为k个最近邻居的(加权)图。</target>
        </trans-unit>
        <trans-unit id="063b3e20cfa017691e75a65bb052691ed38fc79c" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of neighbors nearer than a radius</source>
          <target state="translated">将X转化为比半径更近的邻居图(加权)。</target>
        </trans-unit>
        <trans-unit id="2fcdcd20eec681f04cc400d1e7a3d3a35f46ced9" translate="yes" xml:space="preserve">
          <source>Transform X into subcluster centroids dimension.</source>
          <target state="translated">将X转化为子群中心点维度。</target>
        </trans-unit>
        <trans-unit id="da3379264043ea94358e5b4b01ce80967c41f1a5" translate="yes" xml:space="preserve">
          <source>Transform X separately by each transformer, concatenate results.</source>
          <target state="translated">由各变压器分别变换X,将结果连起来。</target>
        </trans-unit>
        <trans-unit id="054e9dc484301382a53ef7807c44414f413c3b43" translate="yes" xml:space="preserve">
          <source>Transform X to a cluster-distance space.</source>
          <target state="translated">将X转化为簇-距离空间。</target>
        </trans-unit>
        <trans-unit id="9340d4e978871cfc2faf3772609beb4370b76837" translate="yes" xml:space="preserve">
          <source>Transform X to ordinal codes.</source>
          <target state="translated">将X转化为序码。</target>
        </trans-unit>
        <trans-unit id="d750cda6e828d45a370fec4538601ee99b5443be" translate="yes" xml:space="preserve">
          <source>Transform X using one-hot encoding.</source>
          <target state="translated">使用一热编码变换X。</target>
        </trans-unit>
        <trans-unit id="f9e88a65d85f54852f98655b3f250fdbf7750c92" translate="yes" xml:space="preserve">
          <source>Transform X using the forward function.</source>
          <target state="translated">用正向函数变换X。</target>
        </trans-unit>
        <trans-unit id="fb06535ce9222390887b51d0862f28eec382f495" translate="yes" xml:space="preserve">
          <source>Transform X using the inverse function.</source>
          <target state="translated">利用反函数对X进行变换。</target>
        </trans-unit>
        <trans-unit id="55b2dc92fd17631d37a113cafae1257246c63b9f" translate="yes" xml:space="preserve">
          <source>Transform X.</source>
          <target state="translated">变换X。</target>
        </trans-unit>
        <trans-unit id="df5b966033d10ab5ffd4498c25f3563581fac3a4" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a normalized tf or tf-idf representation</source>
          <target state="translated">将计数矩阵转换为归一化的tf或tf-idf表示。</target>
        </trans-unit>
        <trans-unit id="c6579300b554475d257c93a2551d1e7ac8d00f29" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a tf or tf-idf representation</source>
          <target state="translated">将计数矩阵转换为tf或tf-idf表示法</target>
        </trans-unit>
        <trans-unit id="cfe77beec60d283a1ae2557849fffc568b20c2b6" translate="yes" xml:space="preserve">
          <source>Transform a new matrix using the built clustering</source>
          <target state="translated">使用建立的聚类转换一个新的矩阵。</target>
        </trans-unit>
        <trans-unit id="eb758f2f9f4d3b4a21a0f5aa711d86b7f433cb44" translate="yes" xml:space="preserve">
          <source>Transform a sequence of documents to a document-term matrix.</source>
          <target state="translated">将文档序列转换为文档项矩阵。</target>
        </trans-unit>
        <trans-unit id="90d7961623626a54873e65ae75f5e5aedaf80a7d" translate="yes" xml:space="preserve">
          <source>Transform a sequence of instances to a scipy.sparse matrix.</source>
          <target state="translated">将一个实例序列转换为scipy.sparse矩阵。</target>
        </trans-unit>
        <trans-unit id="482237f55f57c5ab1436ea9ad6e0ca3a5497f2c8" translate="yes" xml:space="preserve">
          <source>Transform a signal as a sparse combination of Ricker wavelets. This example visually compares different sparse coding methods using the &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt;&lt;/a&gt; estimator. The Ricker (also known as Mexican hat or the second derivative of a Gaussian) is not a particularly good kernel to represent piecewise constant signals like this one. It can therefore be seen how much adding different widths of atoms matters and it therefore motivates learning the dictionary to best fit your type of signals.</source>
          <target state="translated">将信号转换为Ricker小波的稀疏组合。本示例使用&lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt; &lt;/a&gt;估计器直观地比较了不同的稀疏编码方法。Ricker（也称为墨西哥帽或高斯的二阶导数）并不是一种特别好的内核，无法表示像这样的分段常数信号。因此，可以看出添加不同宽度的原子有多重要，因此可以激发学习字典以最适合您的信号类型的需求。</target>
        </trans-unit>
        <trans-unit id="3c3158f9e95a76dac9ab046600d246dc683b1322" translate="yes" xml:space="preserve">
          <source>Transform array or sparse matrix X back to feature mappings.</source>
          <target state="translated">将数组或稀疏矩阵X变换回特征映射。</target>
        </trans-unit>
        <trans-unit id="43aed443a30ff04a0a7d38cae0c2e3f2c765ad45" translate="yes" xml:space="preserve">
          <source>Transform between iterable of iterables and a multilabel format</source>
          <target state="translated">在iterable的iterable和多标签格式之间进行转换。</target>
        </trans-unit>
        <trans-unit id="8428b18b095eb02611727f6a1283e0146f4aea18" translate="yes" xml:space="preserve">
          <source>Transform binary labels back to multi-class labels</source>
          <target state="translated">将二进制标签转换回多类标签</target>
        </trans-unit>
        <trans-unit id="2d5fb2d774241a80b97c22822072a1cd5822cad7" translate="yes" xml:space="preserve">
          <source>Transform data X according to the fitted model.</source>
          <target state="translated">根据拟合模型变换数据X。</target>
        </trans-unit>
        <trans-unit id="e993947ab9336eb409d6a8eb55c55e2b5b858d46" translate="yes" xml:space="preserve">
          <source>Transform data back to its original space.</source>
          <target state="translated">将数据变换回原来的空间。</target>
        </trans-unit>
        <trans-unit id="b922af176e5b4295d0d766cd496f7523d4754428" translate="yes" xml:space="preserve">
          <source>Transform data to polynomial features</source>
          <target state="translated">将数据转化为多项式特征</target>
        </trans-unit>
        <trans-unit id="f1a4a6b05048c3643e26b0d505b52199b7895296" translate="yes" xml:space="preserve">
          <source>Transform dataset.</source>
          <target state="translated">转换数据集。</target>
        </trans-unit>
        <trans-unit id="00a7e9f2b3e643cac0fe08c5b1d0d59cfff5c504" translate="yes" xml:space="preserve">
          <source>Transform discretized data back to original feature space.</source>
          <target state="translated">将离散化数据转换回原始特征空间。</target>
        </trans-unit>
        <trans-unit id="0146265304f248a8c03f040ea5d584981839ec0b" translate="yes" xml:space="preserve">
          <source>Transform documents to document-term matrix.</source>
          <target state="translated">将文件转化为文档术语矩阵。</target>
        </trans-unit>
        <trans-unit id="778e7579ae52504e167839efee081ba3167de93f" translate="yes" xml:space="preserve">
          <source>Transform feature-&amp;gt;value dicts to array or sparse matrix.</source>
          <target state="translated">将feature-&amp;gt; value dict转换为数组或稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="8fde1456e50a374e1e8877ac2d0ea9941a580f00" translate="yes" xml:space="preserve">
          <source>Transform features by scaling each feature to a given range.</source>
          <target state="translated">通过将每个特征缩放到给定范围来变换特征。</target>
        </trans-unit>
        <trans-unit id="c8f4f5c3bee4bfd8c782321e0d4eb227c2d3191b" translate="yes" xml:space="preserve">
          <source>Transform features using quantiles information.</source>
          <target state="translated">利用量子信息变换特征。</target>
        </trans-unit>
        <trans-unit id="ace4ae2489dd9688eddb3a58e732664d39d28a92" translate="yes" xml:space="preserve">
          <source>Transform labels back to original encoding.</source>
          <target state="translated">将标签转换回原始编码。</target>
        </trans-unit>
        <trans-unit id="76c682df30bb4975f2641f2e89f16cc0b5f2d625" translate="yes" xml:space="preserve">
          <source>Transform labels to normalized encoding.</source>
          <target state="translated">将标签转换为归一化编码。</target>
        </trans-unit>
        <trans-unit id="e6d8f7568400d53b2f444fa6cbf018c08b09552e" translate="yes" xml:space="preserve">
          <source>Transform multi-class labels to binary labels</source>
          <target state="translated">将多类标签转换为二进制标签</target>
        </trans-unit>
        <trans-unit id="ec1f3a72d306387b537de1b3b116fbdf51b17550" translate="yes" xml:space="preserve">
          <source>Transform new data by linear interpolation</source>
          <target state="translated">通过线性插值转换新数据</target>
        </trans-unit>
        <trans-unit id="7e25dbc81754715628745ec728c6c249ac9d1737" translate="yes" xml:space="preserve">
          <source>Transform new points into embedding space.</source>
          <target state="translated">将新点转化为嵌入空间。</target>
        </trans-unit>
        <trans-unit id="17e15b65d999776fc7cb047cfc38d87f9b340eec" translate="yes" xml:space="preserve">
          <source>Transform the data X according to the fitted NMF model</source>
          <target state="translated">根据拟合的NMF模型对数据X进行变换。</target>
        </trans-unit>
        <trans-unit id="28a4737ac1d13b4e451237dc699b89c49f7fb862" translate="yes" xml:space="preserve">
          <source>Transform the given indicator matrix into label sets</source>
          <target state="translated">将给定的指标矩阵转化为标签集</target>
        </trans-unit>
        <trans-unit id="38739bda11e07f48ac023acb8323ed328f115bd5" translate="yes" xml:space="preserve">
          <source>Transform the given label sets</source>
          <target state="translated">转换给定的标签集</target>
        </trans-unit>
        <trans-unit id="92a052e88a019f5aca9bb96a9137d202560617b4" translate="yes" xml:space="preserve">
          <source>Transform the sources back to the mixed data (apply mixing matrix).</source>
          <target state="translated">将源转换回混合数据(应用混合矩阵)。</target>
        </trans-unit>
        <trans-unit id="6414c408546f181e607c3ec28647dd72e64872ea" translate="yes" xml:space="preserve">
          <source>Transform your features into a higher dimensional, sparse space. Then train a linear model on these features.</source>
          <target state="translated">将你的特征转化为更高维度的稀疏空间。然后在这些特征上训练一个线性模型。</target>
        </trans-unit>
        <trans-unit id="d3709f378c935401f6b259df9cce5a50135da098" translate="yes" xml:space="preserve">
          <source>Transformed array.</source>
          <target state="translated">转化的数组。</target>
        </trans-unit>
        <trans-unit id="4a8a97e010ec7ac27b50257ef7ee542c13ba8846" translate="yes" xml:space="preserve">
          <source>Transformed data</source>
          <target state="translated">转换后的数据</target>
        </trans-unit>
        <trans-unit id="d460e113769e190612a2b959c1c729d7e8676439" translate="yes" xml:space="preserve">
          <source>Transformed data in the binned space.</source>
          <target state="translated">在二进制空间中变换数据。</target>
        </trans-unit>
        <trans-unit id="14642329121567cf9f5775d8a6512d3b978fccd2" translate="yes" xml:space="preserve">
          <source>Transformed data matrix</source>
          <target state="translated">变换后的数据矩阵</target>
        </trans-unit>
        <trans-unit id="0d3a338b719647431757293955a1513d13c572f4" translate="yes" xml:space="preserve">
          <source>Transformed data.</source>
          <target state="translated">转化的数据。</target>
        </trans-unit>
        <trans-unit id="08b12f8aaa8632b66a6a22bc4de550a469c3cc9c" translate="yes" xml:space="preserve">
          <source>Transformed dataset.</source>
          <target state="translated">转换后的数据集。</target>
        </trans-unit>
        <trans-unit id="eeb85e59603c1cea29acb31c92a29204737376ea" translate="yes" xml:space="preserve">
          <source>Transformed input.</source>
          <target state="translated">转化输入。</target>
        </trans-unit>
        <trans-unit id="0a6145f06a4913811002ff339bc5284d2892e790" translate="yes" xml:space="preserve">
          <source>Transformed samples</source>
          <target state="translated">改造后的样品</target>
        </trans-unit>
        <trans-unit id="a40fe3e47da3940e6c654b4aca4fd3b4db53b382" translate="yes" xml:space="preserve">
          <source>Transformed values.</source>
          <target state="translated">转变的价值。</target>
        </trans-unit>
        <trans-unit id="0b6f242e80f2185c5234be3f41a48f40589d58f3" translate="yes" xml:space="preserve">
          <source>Transformer instance.</source>
          <target state="translated">变压器实例。</target>
        </trans-unit>
        <trans-unit id="dd414e8652819a2c899c58cada9c3dd8cc66e071" translate="yes" xml:space="preserve">
          <source>Transformer mixin that performs feature selection given a support mask</source>
          <target state="translated">在给定支持掩码的情况下,执行特征选择的变压器混音器。</target>
        </trans-unit>
        <trans-unit id="6d517e36599e67ec967c7be2afac6d7777579d1a" translate="yes" xml:space="preserve">
          <source>Transformer used in &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">用于 &lt;code&gt;predict&lt;/code&gt; 和 &lt;code&gt;fit&lt;/code&gt; 变压器。</target>
        </trans-unit>
        <trans-unit id="43471a7ace97310a9577002aa9803e00d83e6192" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="translated">变压器通常与分类器，回归器或其他估计器组合在一起，以构建复合估计器。最常用的工具是&lt;a href=&quot;#pipeline&quot;&gt;管道&lt;/a&gt;。流水线通常与&lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt;结合使用，FeatureUnion将变压器的输出连接到复合特征空间中。&lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt;处理转换&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;目标&lt;/a&gt;（即log-transform &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt;）。相反，管道仅转换观察到的数据（&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="021fd2002f82b7c8da7b92d01fe659fdcbdaeb82" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-177&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="translated">变压器通常与分类器，回归器或其他估算器组合在一起，以构建复合估算器。最常用的工具是&lt;a href=&quot;#pipeline&quot;&gt;管道&lt;/a&gt;。流水线通常与&lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt;结合使用，FeatureUnion将变压器的输出连接到一个复合特征空间中。&lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt;处理转换&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-target&quot;&gt;目标&lt;/a&gt;（即log-transform &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-177&quot;&gt;y&lt;/a&gt;）。相反，管道仅转换观察到的数据（&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-x&quot;&gt;X&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="b69fe15775501662a569d2ed632ddbe970e558ef" translate="yes" xml:space="preserve">
          <source>Transformers for missing value imputation</source>
          <target state="translated">缺失值推算的变压器</target>
        </trans-unit>
        <trans-unit id="4804df5ca1652cab2567ab10e41eae2d30b7e99a" translate="yes" xml:space="preserve">
          <source>Transforming Classifier Scores into Accurate Multiclass Probability Estimates, B. Zadrozny &amp;amp; C. Elkan, (KDD 2002)</source>
          <target state="translated">B. Zadrozny＆C. Elkan，将分类器得分转换为准确的多类概率估计，（KDD 2002）</target>
        </trans-unit>
        <trans-unit id="74f517360774a680819178109aa2b52b87d4fd99" translate="yes" xml:space="preserve">
          <source>Transforming distance to well-behaved similarities</source>
          <target state="translated">将距离转化为行为良好的相似性</target>
        </trans-unit>
        <trans-unit id="87156c340b6aec33fafb3545fc791ff4187014aa" translate="yes" xml:space="preserve">
          <source>Transforms between iterable of iterables and a multilabel format, e.g. a (samples x classes) binary matrix indicating the presence of a class label.</source>
          <target state="translated">在iterable的iterable和multilabel格式之间进行转换,例如,一个(样本x类)二进制矩阵表示类标签的存在。</target>
        </trans-unit>
        <trans-unit id="dfe17b4b683a10ef2eafef30897d9c629bf96dd6" translate="yes" xml:space="preserve">
          <source>Transforms discretized data back to original feature space.</source>
          <target state="translated">将离散化数据转换回原始特征空间。</target>
        </trans-unit>
        <trans-unit id="5bd7a9a7032f01002afe1d21dc1635e87bd5dbc6" translate="yes" xml:space="preserve">
          <source>Transforms features by scaling each feature to a given range.</source>
          <target state="translated">通过将每个特征缩放到给定范围来转换特征。</target>
        </trans-unit>
        <trans-unit id="45675a7235910659531092f94ca2cac1226cb6a9" translate="yes" xml:space="preserve">
          <source>Transforms lists of feature-value mappings to vectors.</source>
          <target state="translated">将特征值映射列表转换为向量。</target>
        </trans-unit>
        <trans-unit id="18a051a7877c1a9e6b194ac68c49193ac689d698" translate="yes" xml:space="preserve">
          <source>Transforms text into a sparse matrix of n-gram counts.</source>
          <target state="translated">将文本转换为一个n-gram计数的稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="ff596a653686d4986dda1851c66682d846f4bf4d" translate="yes" xml:space="preserve">
          <source>Transforms the image samples in X into a matrix of patch data.</source>
          <target state="translated">将X中的图像样本转换为补丁数据的矩阵。</target>
        </trans-unit>
        <trans-unit id="aff42f13a1dfe3735469a5dd26ab12a5bac4a9ad" translate="yes" xml:space="preserve">
          <source>Tree pruning</source>
          <target state="translated">树木修剪</target>
        </trans-unit>
        <trans-unit id="dda8f4221caceb0e1b9d09350500616b39f0c3c5" translate="yes" xml:space="preserve">
          <source>Tree&amp;rsquo;s Feature Importance from Mean Decrease in Impurity (MDI)</source>
          <target state="translated">从杂质平均减少量（MDI）看树的特征重要性</target>
        </trans-unit>
        <trans-unit id="d6a25d0e3691aa7e7e60fcc1d61ee6046c7d09b3" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="translated">基于树的估计量（请参阅&lt;a href=&quot;classes#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt;模块和sklearn.ensemble模块中的&lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt;）可用于计算特征重要性，而特征重要性又可用于丢弃不相关的特征（与&lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt;结合使用时）元变压器）：</target>
        </trans-unit>
        <trans-unit id="ccdf4aec1fccb56109a1e3945469e98a8d62aca9" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute impurity-based feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="translated">基于树的估计（参见&lt;a href=&quot;classes#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt;的树木模块和森林&lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt;模块）可用于计算基于杂质特征重要度，这反过来又可以用于丢弃不相关特征（当与耦合&lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt;元转换器）：</target>
        </trans-unit>
        <trans-unit id="3629b84a13698bd03a810f8a682027a82e4a7e42" translate="yes" xml:space="preserve">
          <source>Tree-based models provide an alternative measure of &lt;a href=&quot;ensemble#random-forest-feature-importance&quot;&gt;feature importances based on the mean decrease in impurity&lt;/a&gt; (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data.</source>
          <target state="translated">基于树的模型&lt;a href=&quot;ensemble#random-forest-feature-importance&quot;&gt;基于杂质的平均减少量&lt;/a&gt;（MDI）提供了一种重要的特征度量方法。通过决策树的分裂准则（吉尼，熵或均方误差）来量化杂质。但是，此方法可以高度重视当模型过拟合时可能无法对看不见的数据进行预测的特征。另一方面，基于置换的功能重要性可以避免此问题，因为可以对看不见的数据进行计算。</target>
        </trans-unit>
        <trans-unit id="81d8ac0c0739336d0bbd6f8053b2fde8039cdb1c" translate="yes" xml:space="preserve">
          <source>Triangle Inequality: d(x, y) + d(y, z) &amp;gt;= d(x, z)</source>
          <target state="translated">三角不等式：d（x，y）+ d（y，z）&amp;gt; = d（x，z）</target>
        </trans-unit>
        <trans-unit id="331d2c199452ae22aa8941c5bcbe6a7fe41c68b5" translate="yes" xml:space="preserve">
          <source>Tristan Fletcher: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Relevance Vector Machines explained&lt;/a&gt;</source>
          <target state="translated">Tristan Fletcher：&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;相关向量机介绍&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3b19d80cd81c13647ace615b9d73da08b4d8c61b" translate="yes" xml:space="preserve">
          <source>True : always precompute distances</source>
          <target state="translated">真:总是预先计算距离</target>
        </trans-unit>
        <trans-unit id="27f22be4c5a651c1c27cbdc4b85cf77c839d3ddd" translate="yes" xml:space="preserve">
          <source>True : always precompute distances.</source>
          <target state="translated">True:总是预先计算距离。</target>
        </trans-unit>
        <trans-unit id="ebac1d7d68472a848a069828ba36b6b2dd6227bb" translate="yes" xml:space="preserve">
          <source>True binary labels in binary indicator format.</source>
          <target state="translated">二进制指标格式的真实二进制标签。</target>
        </trans-unit>
        <trans-unit id="94ad072572f1b0d8a6896ff3fd5d5269c3006cce" translate="yes" xml:space="preserve">
          <source>True binary labels or binary label indicators.</source>
          <target state="translated">真正的二元标签或二元标签指标。</target>
        </trans-unit>
        <trans-unit id="173029937373f6d16ed7438491b1a8131b2bc4cb" translate="yes" xml:space="preserve">
          <source>True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given.</source>
          <target state="translated">真正的二进制标签。如果标签不是{-1,1}或者{0,1},那么应该明确给出pos_label。</target>
        </trans-unit>
        <trans-unit id="394534b1dcaf25753dd90ddcd321d6ef1b441d87" translate="yes" xml:space="preserve">
          <source>True if a fixed vocabulary of term to indices mapping is provided by the user</source>
          <target state="translated">如果用户提供了一个固定的词汇到索引的映射,则为真。</target>
        </trans-unit>
        <trans-unit id="cba1cd7ae39f91f6d0e2908d3956200bdf94de07" translate="yes" xml:space="preserve">
          <source>True if estimator is a classifier and False otherwise.</source>
          <target state="translated">如果估计器是一个分类器,则为真,否则为假。</target>
        </trans-unit>
        <trans-unit id="7e34070b9f977933411df9b814860396cade02bb" translate="yes" xml:space="preserve">
          <source>True if estimator is a regressor and False otherwise.</source>
          <target state="translated">如果估计器是回归者,则为真,否则为假。</target>
        </trans-unit>
        <trans-unit id="d039a95b006860b5b92d23f84015c0458d6fdb1a" translate="yes" xml:space="preserve">
          <source>True if the array returned from predict is to be in sparse CSC format. Is automatically set to True if the input y is passed in sparse format.</source>
          <target state="translated">如果predict返回的数组是稀疏的CSC格式,则为True。如果输入的y是稀疏格式,则自动设置为True。</target>
        </trans-unit>
        <trans-unit id="018f28ffd2c7241c63be51b46bba3e8aa528d907" translate="yes" xml:space="preserve">
          <source>True if the input data to transform is given as a sparse matrix, False otherwise.</source>
          <target state="translated">如果要转换的输入数据为稀疏矩阵,则为真,否则为假。</target>
        </trans-unit>
        <trans-unit id="06236e43536e8bd62b7d950e36ddd9dca022a999" translate="yes" xml:space="preserve">
          <source>True if the output at fit is 2d, else false.</source>
          <target state="translated">如果拟合时的输出为2d,则为真,否则为假。</target>
        </trans-unit>
        <trans-unit id="abda54d00232aa3c71419926e38966e372a6e200" translate="yes" xml:space="preserve">
          <source>True if the returned array from transform is desired to be in sparse CSR format.</source>
          <target state="translated">如果希望变换后返回的数组是稀疏的CSR格式,则为真。</target>
        </trans-unit>
        <trans-unit id="b3f5d1c4b9aeea8d97315ada02d3f0f3b6e0dbc5" translate="yes" xml:space="preserve">
          <source>True labels for X.</source>
          <target state="translated">X的真实标签。</target>
        </trans-unit>
        <trans-unit id="d40646e12c6271d621333c3801ded96344098308" translate="yes" xml:space="preserve">
          <source>True labels or binary label indicators. The binary and multiclass cases expect labels with shape (n_samples,) while the multilabel case expects binary label indicators with shape (n_samples, n_classes).</source>
          <target state="translated">真标签或二进制标签指示器。二进制和多类情况下,期望标签的形状是(n_samples,),而多标签情况下,期望二进制标签指示器的形状是(n_samples,n_classes)。</target>
        </trans-unit>
        <trans-unit id="24a7816a0ae25d0715f83e367246b56738200fc8" translate="yes" xml:space="preserve">
          <source>True mutual information can&amp;rsquo;t be negative. If its estimate turns out to be negative, it is replaced by zero.</source>
          <target state="translated">真正的相互信息不能是负面的。如果其估计结果为负，则将其替换为零。</target>
        </trans-unit>
        <trans-unit id="1086f49a3e748a59792d8342e65dffdfa18d8ff5" translate="yes" xml:space="preserve">
          <source>True positive rate.</source>
          <target state="translated">真正的阳性率。</target>
        </trans-unit>
        <trans-unit id="e857c90bead41164c28f265fe201e3c7a69f5d75" translate="yes" xml:space="preserve">
          <source>True target, consisting of integers of two values. The positive label must be greater than the negative label.</source>
          <target state="translated">真目标,由两个值的整数组成。正标必须大于负标。</target>
        </trans-unit>
        <trans-unit id="5f6f5563a268706baa91536cfcd1565c453cd8e7" translate="yes" xml:space="preserve">
          <source>True targets of binary classification in range {-1, 1} or {0, 1}.</source>
          <target state="translated">二元分类的真目标在{-1,1}或{0,1}范围内。</target>
        </trans-unit>
        <trans-unit id="308caeb8e2723647ce2ad06a73f50c7b1bd2b781" translate="yes" xml:space="preserve">
          <source>True targets of multilabel classification, or true scores of entities to be ranked.</source>
          <target state="translated">多标签分类的真实目标,或待排序实体的真实分数。</target>
        </trans-unit>
        <trans-unit id="6e2bbfc40bf0e63b31fb5b0351be961b49cc74be" translate="yes" xml:space="preserve">
          <source>True targets.</source>
          <target state="translated">真正的目标。</target>
        </trans-unit>
        <trans-unit id="18dd5ee40d70767a2f6629e8ff8969a87290115e" translate="yes" xml:space="preserve">
          <source>True values for X</source>
          <target state="translated">X的真实值</target>
        </trans-unit>
        <trans-unit id="81e3774c236b4c61a22388a1a822b3e69fb3e5a6" translate="yes" xml:space="preserve">
          <source>True values for X.</source>
          <target state="translated">X的真值。</target>
        </trans-unit>
        <trans-unit id="7e4dee4cabccdb0d80fb65794484e70b177b35d1" translate="yes" xml:space="preserve">
          <source>True values of target.</source>
          <target state="translated">目标的真值。</target>
        </trans-unit>
        <trans-unit id="0d7ce48badf2f0a91a36bec7511768633417749f" translate="yes" xml:space="preserve">
          <source>True when convergence was reached in fit(), False otherwise.</source>
          <target state="translated">当fit()中达到收敛时为true,否则为False。</target>
        </trans-unit>
        <trans-unit id="d333cd18e174fe06286d776d55b1b9eaf760ce1b" translate="yes" xml:space="preserve">
          <source>True: Force all values of X to be finite.</source>
          <target state="translated">真:强迫X的所有值都是有限的。</target>
        </trans-unit>
        <trans-unit id="42eef53fc6823568b56bf4bf254799ea2d7766d8" translate="yes" xml:space="preserve">
          <source>True: Force all values of array to be finite.</source>
          <target state="translated">True:强制数组的所有值都是有限的。</target>
        </trans-unit>
        <trans-unit id="260b9ffda14105c1fd2ffa31d36eae7c83268ddd" translate="yes" xml:space="preserve">
          <source>True: the results is casted to an unsigned int</source>
          <target state="translated">True:结果被转换为一个无符号的int。</target>
        </trans-unit>
        <trans-unit id="e67782a583f6700ced58a8f740875b4358d4fb58" translate="yes" xml:space="preserve">
          <source>Trustworthiness of the low-dimensional embedding.</source>
          <target state="translated">低维嵌入的可信度。</target>
        </trans-unit>
        <trans-unit id="00b6f6ebc7b7070cf35772b16b427811573346a1" translate="yes" xml:space="preserve">
          <source>Try classifying classes 1 and 2 from the iris dataset with SVMs, with the 2 first features. Leave out 10% of each class and test prediction performance on these observations.</source>
          <target state="translated">试着用SVMs对虹膜数据集中的类1和类2进行分类,先用2个特征。留出每个类的10%,并在这些观测值上测试预测性能。</target>
        </trans-unit>
        <trans-unit id="5449ae93c54cf3f8e79ab0ee95bb4ee118bd4f84" translate="yes" xml:space="preserve">
          <source>Try classifying the digits dataset with nearest neighbors and a linear model. Leave out the last 10% and test prediction performance on these observations.</source>
          <target state="translated">尝试用最近的邻居和线性模型对数字数据集进行分类。留出最后10%,并对这些观测值的预测性能进行测试。</target>
        </trans-unit>
        <trans-unit id="7a783eca4388b1c7b8c830f476caa080328ba3c3" translate="yes" xml:space="preserve">
          <source>Try playing around with the &lt;code&gt;analyzer&lt;/code&gt; and &lt;code&gt;token normalisation&lt;/code&gt; under &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">尝试在&lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;下使用 &lt;code&gt;analyzer&lt;/code&gt; 和 &lt;code&gt;token normalisation&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b7e468fa3f6cfdfb33fa6bf28dcdf3165bf89507" translate="yes" xml:space="preserve">
          <source>Try to differentiate the two first classes of the iris data</source>
          <target state="translated">试着区分虹膜数据的两个第一类。</target>
        </trans-unit>
        <trans-unit id="1bc09af6523c25787ea3631aac8c3f52f8bc29dc" translate="yes" xml:space="preserve">
          <source>Try using &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;Truncated SVD&lt;/a&gt; for &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;latent semantic analysis&lt;/a&gt;.</source>
          <target state="translated">尝试使用&lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;截断的SVD&lt;/a&gt;进行&lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;潜在语义分析&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="126c548fa4d4a4c65c7759b8f0eb82ce5677dab5" translate="yes" xml:space="preserve">
          <source>Tsoumakas, G., Katakis, I., &amp;amp; Vlahavas, I. (2010). Mining multi-label data. In Data mining and knowledge discovery handbook (pp. 667-685). Springer US.</source>
          <target state="translated">Tsoumakas，G.，Katakis，I.和Vlahavas，I.（2010）。挖掘多标签数据。在《数据挖掘和知识发现手册》（第667-685页）中。施普林格美国。</target>
        </trans-unit>
        <trans-unit id="0d016a3ee3141a6ebd01b9c31169fb6ec8d37fd6" translate="yes" xml:space="preserve">
          <source>Tuning the hyper-parameters of an estimator</source>
          <target state="translated">调整估计器的超参数。</target>
        </trans-unit>
        <trans-unit id="2e926727653886b165b872a4b6b2a62bf90f0bd1" translate="yes" xml:space="preserve">
          <source>Tuple of row and column indicators for a set of biclusters.</source>
          <target state="translated">一组双簇的行和列指标元组。</target>
        </trans-unit>
        <trans-unit id="a813118f879d8793b6336ef94325f8c8d09426be" translate="yes" xml:space="preserve">
          <source>Tuples of the form (transformer, columns) specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="translated">形式为(transformer,columns)的图元组,指定要应用于数据子集的transformer对象。</target>
        </trans-unit>
        <trans-unit id="c054700312acf34cbacbc98d115120c76da3a6d5" translate="yes" xml:space="preserve">
          <source>Turn seed into a np.random.RandomState instance</source>
          <target state="translated">将种子变成一个np.random.RandomState实例。</target>
        </trans-unit>
        <trans-unit id="4b18a115e0842d6d0ba3a4ec2ed7b07c665b5f56" translate="yes" xml:space="preserve">
          <source>Tutorial exercises</source>
          <target state="translated">辅导练习</target>
        </trans-unit>
        <trans-unit id="007a671747688cedb01751baca6545483f05de7a" translate="yes" xml:space="preserve">
          <source>Tutorial setup</source>
          <target state="translated">教程设置</target>
        </trans-unit>
        <trans-unit id="025f75efad84ed2b985f2818a53e81aa77abca7c" translate="yes" xml:space="preserve">
          <source>Tutorial: A tutorial on statistical-learning for scientific data processing</source>
          <target state="translated">教程。关于科学数据处理的统计学习教程</target>
        </trans-unit>
        <trans-unit id="e7df3b5ebbaf2fd3b4b4579edbd7ce42f46db699" translate="yes" xml:space="preserve">
          <source>Tutorial: An introduction to machine learning with scikit-learn</source>
          <target state="translated">教程。使用scikit-learn进行机器学习的介绍。</target>
        </trans-unit>
        <trans-unit id="8682fb6c27e32858369b74e47f829fad6c8d3a68" translate="yes" xml:space="preserve">
          <source>Tutorial: Choosing the right estimator</source>
          <target state="translated">教程。选择正确的估算器</target>
        </trans-unit>
        <trans-unit id="2865c0d93493065de0c34da92792e35a845226d3" translate="yes" xml:space="preserve">
          <source>Tutorial: Model selection</source>
          <target state="translated">教程:模型选择</target>
        </trans-unit>
        <trans-unit id="b7709b919b68974b71489ceb95a00ef31c4eda72" translate="yes" xml:space="preserve">
          <source>Tutorial: Putting it all together</source>
          <target state="translated">教程。把所有的东西放在一起</target>
        </trans-unit>
        <trans-unit id="b0b3bc4bbf4e62230750bf24baeb122d7a994298" translate="yes" xml:space="preserve">
          <source>Tutorial: Statistical learning</source>
          <target state="translated">教程。统计学习</target>
        </trans-unit>
        <trans-unit id="a149365421f01d98250256737c350c42a4cd4b82" translate="yes" xml:space="preserve">
          <source>Tutorial: Supervised learning</source>
          <target state="translated">教程。监督学习</target>
        </trans-unit>
        <trans-unit id="4353f067a68843e09ae0691ab9f9c44ef2e6db23" translate="yes" xml:space="preserve">
          <source>Tutorial: Unsupervised learning</source>
          <target state="translated">教程。无监督学习</target>
        </trans-unit>
        <trans-unit id="206fac7baeed5ee14f8990630b6607a7c33e8644" translate="yes" xml:space="preserve">
          <source>Tutorial: Working With Text Data</source>
          <target state="translated">教程。使用文本数据</target>
        </trans-unit>
        <trans-unit id="b919de3c63710fd07133db7062fb5a1fbffa0bfe" translate="yes" xml:space="preserve">
          <source>Tutorial: scikit-learn Tutorials</source>
          <target state="translated">教程:scikit-learn 教程</target>
        </trans-unit>
        <trans-unit id="654171647baa6be8557a5d627cf35c7075ebb257" translate="yes" xml:space="preserve">
          <source>Tutorials</source>
          <target state="translated">Tutorials</target>
        </trans-unit>
        <trans-unit id="b9f0efb9bc5f86b33edfdb893732e46d86a776bd" translate="yes" xml:space="preserve">
          <source>Tweedie deviance is a homogeneous function of degree &lt;code&gt;2-power&lt;/code&gt;. Thus, Gamma distribution with &lt;code&gt;power=2&lt;/code&gt; means that simultaneously scaling &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has no effect on the deviance. For Poisson distribution &lt;code&gt;power=1&lt;/code&gt; the deviance scales linearly, and for Normal distribution (&lt;code&gt;power=0&lt;/code&gt;), quadratically. In general, the higher &lt;code&gt;power&lt;/code&gt; the less weight is given to extreme deviations between true and predicted targets.</source>
          <target state="translated">Tweedie偏差是 &lt;code&gt;2-power&lt;/code&gt; 的同构函数。因此， &lt;code&gt;power=2&lt;/code&gt; 伽马分布意味着同时缩放 &lt;code&gt;y_true&lt;/code&gt; 和 &lt;code&gt;y_pred&lt;/code&gt; 对偏差没有影响。对于Poisson分布功效 &lt;code&gt;power=1&lt;/code&gt; ，偏差线性地缩放，而对于正态分布（ &lt;code&gt;power=0&lt;/code&gt; ），方形地缩放。通常， &lt;code&gt;power&lt;/code&gt; 越高，真实目标与预测目标之间的极端偏差所占的权重就越小。</target>
        </trans-unit>
        <trans-unit id="b534d41a45e4c1bc7da48b9a62fdc9565da97cac" translate="yes" xml:space="preserve">
          <source>Tweedie power parameter. Either power &amp;lt;= 0 or power &amp;gt;= 1.</source>
          <target state="translated">Tweedie功率参数。功率&amp;lt;= 0或功率&amp;gt; = 1。</target>
        </trans-unit>
        <trans-unit id="25d7747a25958e3f10fc9c93bbab44d13248adbd" translate="yes" xml:space="preserve">
          <source>Tweedie regression on insurance claims</source>
          <target state="translated">Tweedie对保险索赔的回归</target>
        </trans-unit>
        <trans-unit id="995550b74403db560a3a2ea8d3906cd56b901336" translate="yes" xml:space="preserve">
          <source>Two algorithms are demoed: ordinary k-means and its more scalable cousin minibatch k-means.</source>
          <target state="translated">演示了两种算法:普通k-means和它的更可扩展的表兄minibatch k-means。</target>
        </trans-unit>
        <trans-unit id="3b934d458351995534fed7d234de7b14c38f4cd4" translate="yes" xml:space="preserve">
          <source>Two approaches for performing calibration of probabilistic predictions are provided: a parametric approach based on Platt&amp;rsquo;s sigmoid model and a non-parametric approach based on isotonic regression (&lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt;&lt;code&gt;sklearn.isotonic&lt;/code&gt;&lt;/a&gt;). Probability calibration should be done on new data not used for model fitting. The class &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; uses a cross-validation generator and estimates for each split the model parameter on the train samples and the calibration of the test samples. The probabilities predicted for the folds are then averaged. Already fitted classifiers can be calibrated by &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; via the parameter cv=&amp;rdquo;prefit&amp;rdquo;. In this case, the user has to take care manually that data for model fitting and calibration are disjoint.</source>
          <target state="translated">提供了两种执行概率预测标定的方法：基于Platt的S型模型的参数方法和基于等张回归的非参数方法（&lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt; &lt;code&gt;sklearn.isotonic&lt;/code&gt; &lt;/a&gt;）。概率校准应针对未用于模型拟合的新数据进行。&lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt;类使用交叉验证生成器，并针对每个拆分估计样本上的模型参数和测试样本的校准。然后将对折的预测概率进行平均。&lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; 可以&lt;/a&gt;通过参数cv =&amp;ldquo; prefit&amp;rdquo; 来校准已经拟合的分类器。在这种情况下，用户必须手动注意用于模型拟合和校准的数据是不相交的。</target>
        </trans-unit>
        <trans-unit id="de7e8d6ad699213a292d0c528c5ddad33bca14ae" translate="yes" xml:space="preserve">
          <source>Two consequences of imposing a connectivity can be seen. First clustering with a connectivity matrix is much faster.</source>
          <target state="translated">可以看出施加连通性的两个后果。首先用连通性矩阵进行聚类要快得多。</target>
        </trans-unit>
        <trans-unit id="73ece4ca1e1779fbf5110031e848f2313deac958" translate="yes" xml:space="preserve">
          <source>Two cross-validation loops are performed in parallel: one by the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; estimator to set &lt;code&gt;gamma&lt;/code&gt; and the other one by &lt;code&gt;cross_val_score&lt;/code&gt; to measure the prediction performance of the estimator. The resulting scores are unbiased estimates of the prediction score on new data.</source>
          <target state="translated">并行执行两个交叉验证循环：一个由&lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;估计器设置 &lt;code&gt;gamma&lt;/code&gt; ，另一个由 &lt;code&gt;cross_val_score&lt;/code&gt; 来测量估计器的预测性能。所得分数是对新数据的预测分数的无偏估计。</target>
        </trans-unit>
        <trans-unit id="d467efdd44bf60415fc895b8589d9d81d46d02ec" translate="yes" xml:space="preserve">
          <source>Two families of ensemble methods are usually distinguished:</source>
          <target state="translated">通常有两类合集方法的区别。</target>
        </trans-unit>
        <trans-unit id="e8ac95de27d48015555c5b981483208d51b8f268" translate="yes" xml:space="preserve">
          <source>Two feature extraction methods can be used in this example:</source>
          <target state="translated">本例中可以使用两种特征提取方法。</target>
        </trans-unit>
        <trans-unit id="ebb2ce8305b879c94bfe5ff4f307e7a35d679e99" translate="yes" xml:space="preserve">
          <source>Two plots will be shown for each scaler/normalizer/transformer. The left figure will show a scatter plot of the full data set while the right figure will exclude the extreme values considering only 99 % of the data set, excluding marginal outliers. In addition, the marginal distributions for each feature will be shown on the side of the scatter plot.</source>
          <target state="translated">每个缩放器/归一化器/变换器将显示两张图。左图将显示全部数据集的散点图,而右图将排除极端值,只考虑数据集的99%,排除边缘异常值。此外,每个特征的边际分布将显示在散点图的侧面。</target>
        </trans-unit>
        <trans-unit id="d08300d20f1b41587441de06b29a0ea2e0345c8c" translate="yes" xml:space="preserve">
          <source>Two regions are populated: when the EXPERIENCE coefficient is positive the AGE one is negative and viceversa.</source>
          <target state="translated">填充了两个区域:当经验系数为正时,年龄系数为负,反之亦然。</target>
        </trans-unit>
        <trans-unit id="348f286c4d7d6b276984cd38d102dc527023a237" translate="yes" xml:space="preserve">
          <source>Two separate datasets are used for the two different plots. The reason behind this is the &lt;code&gt;l1&lt;/code&gt; case works better on sparse data, while &lt;code&gt;l2&lt;/code&gt; is better suited to the non-sparse case.</source>
          <target state="translated">两个不同的数据集使用两个单独的数据集。这背后的原因是 &lt;code&gt;l1&lt;/code&gt; 情况在稀疏数据上效果更好，而 &lt;code&gt;l2&lt;/code&gt; 情况更适合于非稀疏情况。</target>
        </trans-unit>
        <trans-unit id="77c4595f573f3df24ff0cb3827f75f6aed496412" translate="yes" xml:space="preserve">
          <source>Two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations of the features and thus preserve the rank of the values along each feature.</source>
          <target state="translated">有两种类型的变换:分位数变换和功率变换。量子化和幂级变换都是基于特征的单调变换,因此保留了每个特征值的等级。</target>
        </trans-unit>
        <trans-unit id="32895c2e5eacd1283051e2d5a4f1fd3f826fb6ed" translate="yes" xml:space="preserve">
          <source>Two-class AdaBoost</source>
          <target state="translated">两级AdaBoost</target>
        </trans-unit>
        <trans-unit id="b8fde32df7d701e50fc79883cdf21005c9469e51" translate="yes" xml:space="preserve">
          <source>Type casting</source>
          <target state="translated">铸件类型</target>
        </trans-unit>
        <trans-unit id="7b90464c9a3a0593a486a1facdfd06e25cac2162" translate="yes" xml:space="preserve">
          <source>Type of SVM: C SVC, nu SVC, one class, epsilon SVR, nu SVR</source>
          <target state="translated">SVM的类型。C SVC,nu SVC,一类,epsilon SVR,nu SVR。</target>
        </trans-unit>
        <trans-unit id="fb24034e0a15fdb11753c4c561fec377a847eca1" translate="yes" xml:space="preserve">
          <source>Type of SVM: C_SVC, NuSVC, OneClassSVM, EpsilonSVR or NuSVR respectively. 0 by default.</source>
          <target state="translated">SVM的类型。C_SVC,NuSVC,OneClassSVM,EpsilonSVR 或 NuSVR.默认为0。</target>
        </trans-unit>
        <trans-unit id="05734831eef4f60aabd73eed1535149e1780b49e" translate="yes" xml:space="preserve">
          <source>Type of kernel.</source>
          <target state="translated">内核的类型。</target>
        </trans-unit>
        <trans-unit id="7784bde958a1d323776ea14d0478698cc397c040" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, and &amp;lsquo;distance&amp;rsquo; will return the distances between neighbors according to the given metric.</source>
          <target state="translated">返回矩阵的类型：'connectivity'将返回具有1和0的连通性矩阵，而'distance'将根据给定的度量返回邻居之间的距离。</target>
        </trans-unit>
        <trans-unit id="029a83801426f186d4049ef92d5f3d3590b1d125" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, in &amp;lsquo;distance&amp;rsquo; the edges are Euclidean distance between points.</source>
          <target state="translated">返回矩阵的类型：'connectivity'将返回具有1和0的连通性矩阵，在'distance'中，边为点之间的欧几里得距离。</target>
        </trans-unit>
        <trans-unit id="e2af4c36790c9137ba49cdb815accc60f6f75311" translate="yes" xml:space="preserve">
          <source>Type of store backend for reading/writing cache files. Default: &amp;lsquo;local&amp;rsquo;. The &amp;lsquo;local&amp;rsquo; backend is using regular filesystem operations to manipulate data (open, mv, etc) in the backend.</source>
          <target state="translated">用于读取/写入缓存文件的存储后端的类型。默认值：&amp;ldquo;本地&amp;rdquo;。&amp;ldquo;本地&amp;rdquo;后端正在使用常规文件系统操作来操纵后端中的数据（打开，MV等）。</target>
        </trans-unit>
        <trans-unit id="858cba7a97e85950fd69a9661ce88f3dff1bf729" translate="yes" xml:space="preserve">
          <source>Type of the matrix returned by fit_transform() or transform().</source>
          <target state="translated">fit_transform()或transform()返回的矩阵类型。</target>
        </trans-unit>
        <trans-unit id="b6e792a3d08a7bd144dac10e42edb461fd3dd2e3" translate="yes" xml:space="preserve">
          <source>Type to use in computing the mean. For integer inputs, the default is &lt;code&gt;float64&lt;/code&gt;; for floating point inputs, it is the same as the input dtype.</source>
          <target state="translated">用于计算平均值的类型。对于整数输入，默认值为 &lt;code&gt;float64&lt;/code&gt; ；对于浮点输入，它与输入dtype相同。</target>
        </trans-unit>
        <trans-unit id="9af8f14bd15271db0f113f7c146e7fa9294b1caa" translate="yes" xml:space="preserve">
          <source>TypeError</source>
          <target state="translated">TypeError</target>
        </trans-unit>
        <trans-unit id="363cb5cb9b015bf8fe75ee8f6f3ad675ca5618cc" translate="yes" xml:space="preserve">
          <source>UNION</source>
          <target state="translated">UNION</target>
        </trans-unit>
        <trans-unit id="d609f86a64dc993cf97b5c1696e70d121d69089c" translate="yes" xml:space="preserve">
          <source>UNION_not_member</source>
          <target state="translated">UNION_not_member</target>
        </trans-unit>
        <trans-unit id="5c8cdf8bfe08e7fa632507cd27d7c4593fc32d5d" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;2&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="translated">在假设数据是高斯分布的前提下，Chen等人。&lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;2&lt;/a&gt;得出了一个旨在选择收缩系数的公式，该公式产生的均方误差比Ledoit和Wolf公式给出的均方误差小。所得的估计量称为协方差的Oracle收缩率近似估计量。</target>
        </trans-unit>
        <trans-unit id="f77afa338a167babd59a76b7f498d6550ba586ff" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="translated">在假设数据是高斯分布的前提下，Chen等人。&lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;得出了一个旨在选择收缩系数的公式，该公式产生的均方误差比Ledoit和Wolf公式给出的均方误差小。所得的估计量称为协方差的Oracle收缩率近似估计量。</target>
        </trans-unit>
        <trans-unit id="b57ce0246b95ca0ff3d95c499722ea513c24180d" translate="yes" xml:space="preserve">
          <source>Underfitting vs. Overfitting</source>
          <target state="translated">低配与过配</target>
        </trans-unit>
        <trans-unit id="10dab5fb240281c20bb10ad043cbba82ec3b0bd6" translate="yes" xml:space="preserve">
          <source>Understanding the decision tree structure</source>
          <target state="translated">了解决策树结构</target>
        </trans-unit>
        <trans-unit id="a381b476a1bdd0042346ffd8d02655a7131aa344" translate="yes" xml:space="preserve">
          <source>Undo the scaling of X according to feature_range.</source>
          <target state="translated">根据feature_range撤销X的缩放。</target>
        </trans-unit>
        <trans-unit id="11b4a2e4a2b6531b9e75ad23f03f25fd4f8ecde0" translate="yes" xml:space="preserve">
          <source>Uniform weights are used by default.</source>
          <target state="translated">默认使用统一的权重。</target>
        </trans-unit>
        <trans-unit id="9421754583ed6d327fe582bef2d0e2d0f17ba0c4" translate="yes" xml:space="preserve">
          <source>Unique class labels.</source>
          <target state="translated">独特的类标签。</target>
        </trans-unit>
        <trans-unit id="6efd4cf40567c19c24a13e3421a6d1109a47da44" translate="yes" xml:space="preserve">
          <source>Uniquely holds the label for each class.</source>
          <target state="translated">唯一地保存每个类的标签。</target>
        </trans-unit>
        <trans-unit id="78bd370935302db3cfb593c9af76aeb130eb71c4" translate="yes" xml:space="preserve">
          <source>Unit Deviance \(d(y, \hat{y})\)</source>
          <target state="translated">单位偏差(d(y,hat{y})/)</target>
        </trans-unit>
        <trans-unit id="15f758514c6db2ef9033ee5636e4d09d40ce9747" translate="yes" xml:space="preserve">
          <source>Univariate Feature Selection</source>
          <target state="translated">单变量特征选择</target>
        </trans-unit>
        <trans-unit id="820dda4dd874419c514343cc2737763cc18b33d1" translate="yes" xml:space="preserve">
          <source>Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="translated">单变量特征选择通过基于单变量统计检验选择最佳特征来工作。可以将其视为估算器的预处理步骤。Scikit-learn将要素选择例程公开为实现了 &lt;code&gt;transform&lt;/code&gt; 方法的对象：</target>
        </trans-unit>
        <trans-unit id="b943e7c2ae0f248f889b02c7d797d243c0d56e6a" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable mode.</source>
          <target state="translated">单变量特征选择器,可配置模式。</target>
        </trans-unit>
        <trans-unit id="05b44ce5dcc153b8702db1e0eab0c9af1fb62f9c" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable strategy.</source>
          <target state="translated">具有可配置策略的单变量特征选择器。</target>
        </trans-unit>
        <trans-unit id="049ea86cb7534beee7ca7abb3073edcde3e3d399" translate="yes" xml:space="preserve">
          <source>Univariate imputation of missing values.</source>
          <target state="translated">缺失值的单变量推算。</target>
        </trans-unit>
        <trans-unit id="d9b7ebeeb7d99a7c69a9087085473be1721215ee" translate="yes" xml:space="preserve">
          <source>Univariate linear regression tests.</source>
          <target state="translated">单变量线性回归检验。</target>
        </trans-unit>
        <trans-unit id="833fdc74927caa030c0f5f51bade98d55541b93d" translate="yes" xml:space="preserve">
          <source>Unlabeled entries in &lt;code&gt;y&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; 中未标记的条目</target>
        </trans-unit>
        <trans-unit id="d5f2b47c1710490958929f8f01f5858025c133e1" translate="yes" xml:space="preserve">
          <source>Unless otherwise specified, input will be cast to &lt;code&gt;float64&lt;/code&gt;:</source>
          <target state="translated">除非另有说明，否则输入将 &lt;code&gt;float64&lt;/code&gt; 为float64：</target>
        </trans-unit>
        <trans-unit id="6027b38892a9b0df12f36988c98a41a4655ff464" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;, the representation of a vector is obtained in an additive fashion, by superimposing the components, without subtracting. Such additive models are efficient for representing images and text.</source>
          <target state="translated">与&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;不同，矢量的表示形式是通过加法而不叠加地以加法方式获得的。这样的加性模型对于表示图像和文本是有效的。</target>
        </trans-unit>
        <trans-unit id="5817d589292c98298ab95a877d7595e724495088" translate="yes" xml:space="preserve">
          <source>Unlike SVC (based on LIBSVM), LinearSVC (based on LIBLINEAR) does not provide the support vectors. This example demonstrates how to obtain the support vectors in LinearSVC.</source>
          <target state="translated">与SVC(基于LIBSVM)不同,LinearSVC(基于LIBLINEAR)不提供支持向量。这个例子演示了如何在LinearSVC中获取支持向量。</target>
        </trans-unit>
        <trans-unit id="f73d55c7488edaa74f7dc85966062a8a5be2b94b" translate="yes" xml:space="preserve">
          <source>Unlike most other scores, R^2 score may be negative (it need not actually be the square of a quantity R).</source>
          <target state="translated">与其他大多数分数不同的是,R^2分数可能是负数(它实际上不需要是一个量R的平方)。</target>
        </trans-unit>
        <trans-unit id="fb0dd07f15380472f302743b85f6d7c3f60efb9d" translate="yes" xml:space="preserve">
          <source>Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range as seen in the zoomed-in figure. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below).</source>
          <target state="translated">与之前的标度器不同,该标度器的居中和标度统计是基于百分数的,因此不会受到少数非常大的边际离群值的影响。因此,转换后的特征值范围比之前的标度器大,更重要的是,它们大致相似:对于这两个特征,大多数转换后的值位于[-2,3]范围内,如放大图所示。请注意,离群值本身仍然存在于变换后的数据中。如果希望单独剪除离群值,则需要进行非线性变换(见下文)。</target>
        </trans-unit>
        <trans-unit id="be4091e1f0941887f57bdebf1b1a9b607356f1f1" translate="yes" xml:space="preserve">
          <source>Unlike the previous transformations, normalization refers to a per sample transformation instead of a per feature transformation.</source>
          <target state="translated">与之前的变换不同,归一化指的是每个样本的变换,而不是每个特征的变换。</target>
        </trans-unit>
        <trans-unit id="1e78af54fb2d86af104fdf7cb3b33ae0e42d69f8" translate="yes" xml:space="preserve">
          <source>Unmarried</source>
          <target state="translated">Unmarried</target>
        </trans-unit>
        <trans-unit id="d6efdeaf0fd8663d7b74628a841a2a21988919e0" translate="yes" xml:space="preserve">
          <source>Unregularized graph based semi-supervised learning</source>
          <target state="translated">基于无规则化图的半监督学习方式</target>
        </trans-unit>
        <trans-unit id="27bee227769f6c4dd6bbb550e3dab104adba94bb" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF)</source>
          <target state="translated">使用局部离群因子(LOF)进行无监督离群检测。</target>
        </trans-unit>
        <trans-unit id="3cf71ccf2a88f28c3a0cfcb75adfc8979981d7f4" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF).</source>
          <target state="translated">使用局部外差因子(LOF)进行无监督外差检测。</target>
        </trans-unit>
        <trans-unit id="7b5353048e77b9864be0e146d8fe78c3034a09d3" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection.</source>
          <target state="translated">无监督外差检测。</target>
        </trans-unit>
        <trans-unit id="a2eb50b9e0078078696dd41ce50d788a5cac282f" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection. Estimate the support of a high-dimensional distribution. The implementation is based on libsvm.</source>
          <target state="translated">无监督外差检测。估计高维分布的支持度。基于libsvm实现。</target>
        </trans-unit>
        <trans-unit id="091dbb252c60dafbec16ee540eb9588c7d736a5b" translate="yes" xml:space="preserve">
          <source>Unsupervised learner for implementing neighbor searches.</source>
          <target state="translated">用于实现邻域搜索的无监督学习器。</target>
        </trans-unit>
        <trans-unit id="336bcbb510eed89e13ba021c352635cdc0677016" translate="yes" xml:space="preserve">
          <source>Unsupervised learning: seeking representations of the data</source>
          <target state="translated">无监督学习:寻求数据的表示方法</target>
        </trans-unit>
        <trans-unit id="568c5820f9e5362ca266c9125e695403019435a8" translate="yes" xml:space="preserve">
          <source>Unused parameter.</source>
          <target state="translated">未使用的参数。</target>
        </trans-unit>
        <trans-unit id="207a5be036cc811b3313bce86d86c7d5b4302176" translate="yes" xml:space="preserve">
          <source>Update k means estimate on a single mini-batch X.</source>
          <target state="translated">更新k是指对单个小批量X的估计。</target>
        </trans-unit>
        <trans-unit id="08230ffcab1953eb1050f05815a03e0d48694ae9" translate="yes" xml:space="preserve">
          <source>Update the model with a single iteration over the given data.</source>
          <target state="translated">对给定数据进行单次迭代更新模型。</target>
        </trans-unit>
        <trans-unit id="718430f889e80a3494a47ee7bec5ca3329673e5e" translate="yes" xml:space="preserve">
          <source>Updated feature-wise means.</source>
          <target state="translated">更新功能上的手段。</target>
        </trans-unit>
        <trans-unit id="4f10d24907ba29eca99bd941c7ead98539a4f5b4" translate="yes" xml:space="preserve">
          <source>Updated feature-wise variances.</source>
          <target state="translated">更新了功能方面的差异。</target>
        </trans-unit>
        <trans-unit id="693a7de21c7466734e7ffa03c5ae997209e7997d" translate="yes" xml:space="preserve">
          <source>Updated number of seen samples.</source>
          <target state="translated">更新了看到的样本数量。</target>
        </trans-unit>
        <trans-unit id="410e0e09369f3d862bca36022b47e478be0933f7" translate="yes" xml:space="preserve">
          <source>Updates the model using the data in X as a mini-batch.</source>
          <target state="translated">使用X中的数据作为小批量更新模型。</target>
        </trans-unit>
        <trans-unit id="93ec1aa11f1be18275b029134004fd1ab02c997f" translate="yes" xml:space="preserve">
          <source>Upper bound on a uniform noise parameter to be added to the &lt;code&gt;y&lt;/code&gt; values, to satisfy the model&amp;rsquo;s assumption of one-at-a-time computations. Might help with stability.</source>
          <target state="translated">要添加到 &lt;code&gt;y&lt;/code&gt; 值的均匀噪声参数的上限，以满足模型一次计算的假设。可能会对稳定性有所帮助。</target>
        </trans-unit>
        <trans-unit id="07333ba49211f5c72e60dfd1b7f4f04d69ceed93" translate="yes" xml:space="preserve">
          <source>Upper bound on the highest predicted value (the maximum may still be lower). If not set, defaults to +inf.</source>
          <target state="translated">最高预测值的上界(最大值可能仍然较低)。如果没有设置,默认为+inf。</target>
        </trans-unit>
        <trans-unit id="48b5dd5eaa54e931a34dd1d6396ec1c9d66da80b" translate="yes" xml:space="preserve">
          <source>Urbanowicz R.J., Moore, J.H. &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: description and evaluation of a scalable learning classifier system&lt;/a&gt;, Evol. Intel. (2015) 8: 89.</source>
          <target state="translated">Urbanowicz RJ，Moore，JH &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0：可扩展学习分类系统&lt;/a&gt; Evol的描述和评估。英特尔。（2015）8：89。</target>
        </trans-unit>
        <trans-unit id="fec43ce445f974147bd0eb223a50147e7fb7202d" translate="yes" xml:space="preserve">
          <source>Usage example:</source>
          <target state="translated">用例。</target>
        </trans-unit>
        <trans-unit id="173610cb31251b28e80fadc258036215d99d7128" translate="yes" xml:space="preserve">
          <source>Usage examples:</source>
          <target state="translated">用例。</target>
        </trans-unit>
        <trans-unit id="272998fc40498f57127bf4e7cf71805cd53c9500" translate="yes" xml:space="preserve">
          <source>Use 0 when &lt;code&gt;Y&lt;/code&gt; contains the output of decision_function (classifier). Use 0.5 when &lt;code&gt;Y&lt;/code&gt; contains the output of predict_proba.</source>
          <target state="translated">当 &lt;code&gt;Y&lt;/code&gt; 包含Decision_function（分类器）的输出时，请使用0 。当 &lt;code&gt;Y&lt;/code&gt; 包含predict_proba的输出时，请使用0.5 。</target>
        </trans-unit>
        <trans-unit id="cf1718d68df5d7e88cb5c515bd9f0d9c1cb19546" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#optics&quot;&gt;OPTICS&lt;/a&gt; clustering in conjunction with the &lt;code&gt;extract_dbscan&lt;/code&gt; method. OPTICS clustering also calculates the full pairwise matrix, but only keeps one row in memory at a time (memory complexity n).</source>
          <target state="translated">将&lt;a href=&quot;#optics&quot;&gt;OPTICS&lt;/a&gt;集群与 &lt;code&gt;extract_dbscan&lt;/code&gt; 方法结合使用。OPTICS集群还可以计算完整的成对矩阵，但是一次只能在内存中保留一行（内存复杂度n）。</target>
        </trans-unit>
        <trans-unit id="f7e4377e83d25be8830adecce4de8c2384ca00b7" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by data types</source>
          <target state="translated">通过按数据类型选择列来使用 &lt;code&gt;ColumnTransformer&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e21d1ee32a85ffa963b44a044a8fb65d4d276f52" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by names</source>
          <target state="translated">通过按名称选择列来使用 &lt;code&gt;ColumnTransformer&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e620712d1a8872ff21d8a3d8ca61cf7867c4f8c8" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;min_samples_split&lt;/code&gt; or &lt;code&gt;min_samples_leaf&lt;/code&gt; to ensure that multiple samples inform every decision in the tree, by controlling which splits will be considered. A very small number will usually mean the tree will overfit, whereas a large number will prevent the tree from learning the data. Try &lt;code&gt;min_samples_leaf=5&lt;/code&gt; as an initial value. If the sample size varies greatly, a float number can be used as percentage in these two parameters. While &lt;code&gt;min_samples_split&lt;/code&gt; can create arbitrarily small leaves, &lt;code&gt;min_samples_leaf&lt;/code&gt; guarantees that each leaf has a minimum size, avoiding low-variance, over-fit leaf nodes in regression problems. For classification with few classes, &lt;code&gt;min_samples_leaf=1&lt;/code&gt; is often the best choice.</source>
          <target state="translated">使用 &lt;code&gt;min_samples_split&lt;/code&gt; 或 &lt;code&gt;min_samples_leaf&lt;/code&gt; 可通过控制要考虑的分割来确保多个样本通知树中的每个决策。数量很少通常意味着树会过拟合，而数量很大将阻止树学习数据。尝试将 &lt;code&gt;min_samples_leaf=5&lt;/code&gt; 用作初始值。如果样本大小变化很大，则可以将浮点数用作这两个参数中的百分比。尽管 &lt;code&gt;min_samples_split&lt;/code&gt; 可以创建任意小的叶子，但 &lt;code&gt;min_samples_leaf&lt;/code&gt; 保证每个叶子都具有最小的大小，从而避免了回归问题中的低方差，过度拟合叶子节点。对于很少分类的分类， &lt;code&gt;min_samples_leaf=1&lt;/code&gt; 通常是最佳选择。</target>
        </trans-unit>
        <trans-unit id="3429b333ce93c8bae91a85fe794f080132090825" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</source>
          <target state="translated">使用 &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7760fd58346bed0a2b559e055012bd8a21868552" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the Boston dataset.</source>
          <target state="translated">使用SelectFromModel元变换器与Lasso一起从波士顿数据集中选择最佳的几个特征。</target>
        </trans-unit>
        <trans-unit id="054f12ffb2d5e13349a9508049b7a257d7468dbe" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the diabetes dataset.</source>
          <target state="translated">使用SelectFromModel元变换器与Lasso一起从糖尿病数据集中选择最佳的几个特征。</target>
        </trans-unit>
        <trans-unit id="71685d673fcc400f8aa4ec7ef3e4a61bf3bbf5f7" translate="yes" xml:space="preserve">
          <source>Use approximate bound as score.</source>
          <target state="translated">用近似界限作为分数。</target>
        </trans-unit>
        <trans-unit id="400d526bc775314ded26ebb1519045ccc0979588" translate="yes" xml:space="preserve">
          <source>Use density = 1 / 3.0 if you want to reproduce the results from Achlioptas, 2001.</source>
          <target state="translated">如果你想重现Achlioptas,2001年的结果,使用密度=1/3.0。</target>
        </trans-unit>
        <trans-unit id="38fb3c866f165060e0d95ec1a873c702ff2c91dc" translate="yes" xml:space="preserve">
          <source>Use only on new data</source>
          <target state="translated">仅用于新数据</target>
        </trans-unit>
        <trans-unit id="0eb6d7f6360fc3b257840e6d0ece909142d961e3" translate="yes" xml:space="preserve">
          <source>Use splitting criteria that compute the average reduction across all n outputs.</source>
          <target state="translated">使用分割标准,计算所有n个输出的平均减少量。</target>
        </trans-unit>
        <trans-unit id="d4a5711bd46bd2a4542a66497bb7f3342ea23a7f" translate="yes" xml:space="preserve">
          <source>Use the Akaike information criterion (AIC), the Bayes Information criterion (BIC) and cross-validation to select an optimal value of the regularization parameter alpha of the &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; estimator.</source>
          <target state="translated">使用Akaike信息标准（AIC），贝叶斯信息标准（BIC）和交叉验证来选择&lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;套索&lt;/a&gt;估计器的正则化参数alpha的最佳值。</target>
        </trans-unit>
        <trans-unit id="35f6c244b8fd2da4794beb17214246bc1c30610f" translate="yes" xml:space="preserve">
          <source>Usecase</source>
          <target state="translated">Usecase</target>
        </trans-unit>
        <trans-unit id="4ea5661d3bd8912bbf2723a42ab4c0cf1ece7994" translate="yes" xml:space="preserve">
          <source>Used during dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">在字典学习期间使用。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1bc010bd367bf6cb9590a9c8e8bd3ff37b7e270c" translate="yes" xml:space="preserve">
          <source>Used during randomized svd. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">在随机svd期间使用。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="85ae15952ef1b8cedfa1ed0f0a5091e5742f9b4a" translate="yes" xml:space="preserve">
          <source>Used for NMF initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">用于NMF初始化（当 &lt;code&gt;init&lt;/code&gt; =='nndsvdar'或'random'时），并用于协调下降。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="15383d0945f438ddc1d77fc1ae0921de1e717777" translate="yes" xml:space="preserve">
          <source>Used for VotingClassifier</source>
          <target state="translated">用于投票分类器</target>
        </trans-unit>
        <trans-unit id="06c1133b6cf5dee9bc1f27b86d9cca1c046fd5c1" translate="yes" xml:space="preserve">
          <source>Used for initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">用于初始化（ &lt;code&gt;init&lt;/code&gt; =='nndsvdar'或'random'时）和协调下降。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a4845a789add1f32681ae6a68b7dba0e6bdbe2af" translate="yes" xml:space="preserve">
          <source>Used for initializing the dictionary when &lt;code&gt;dict_init&lt;/code&gt; is not specified, randomly shuffling the data when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">当未指定 &lt;code&gt;dict_init&lt;/code&gt; 时，用于初始化字典；在 &lt;code&gt;shuffle&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 时，用于随机改组数据，并更新字典。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2d6d1bb4bf090f9031a078f80f81b5cfa346c5fb" translate="yes" xml:space="preserve">
          <source>Used for internal caching. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">用于内部缓存。默认情况下,不进行缓存。如果给定一个字符串,则是缓存目录的路径。</target>
        </trans-unit>
        <trans-unit id="78a755bf17a9d084d2f5bc3468af8892921b3298" translate="yes" xml:space="preserve">
          <source>Used for random shuffling when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, during online dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">在线词典学习期间，当将 &lt;code&gt;shuffle&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 时，用于随机改组。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a659f5ae4cfedf0686976ca2f311fa3c53dbc2ce" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">用于随机化奇异值分解和k-means初始化。使用int可以确定随机性。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b3bb1fd38ab7b6b511c90e9e3f961817f7b29fe6" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">用于随机化奇异值分解和k-means初始化。使用int可以确定随机性。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ad6bfb2aef10b93bd4ad8fd792d19a69ba0f50a9" translate="yes" xml:space="preserve">
          <source>Used for randomly initializing the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">用于随机初始化字典。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e0ee2dc12a427741bfbfa29dc3b32d1b1d854da3" translate="yes" xml:space="preserve">
          <source>Used for shuffling the data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">将 &lt;code&gt;shuffle&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 时，用于对数据进行混洗。为多个函数调用传递可重复输出的int值。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="04206996c9eca941c8da97d474cf5a147f4b8713" translate="yes" xml:space="preserve">
          <source>Used to cache the fitted transformers of the pipeline. By default, no caching is performed. If a string is given, it is the path to the caching directory. Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. Use the attribute &lt;code&gt;named_steps&lt;/code&gt; or &lt;code&gt;steps&lt;/code&gt; to inspect estimators within the pipeline. Caching the transformers is advantageous when fitting is time consuming.</source>
          <target state="translated">用于缓存管道的已装配变压器。默认情况下，不执行缓存。如果给出了字符串，则它是缓存目录的路径。启用缓存会在安装之前触发变压器的克隆。因此，不能直接检查提供给管道的变压器实例。使用 &lt;code&gt;named_steps&lt;/code&gt; 或 &lt;code&gt;steps&lt;/code&gt; 属性检查管道中的估计量。当安装耗时时，缓存变压器是有利的。</target>
        </trans-unit>
        <trans-unit id="b831b0ccc618367ad6990c063d4f6b68c21b54a0" translate="yes" xml:space="preserve">
          <source>Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">用于缓存树的计算输出。默认情况下,不进行缓存。如果给出一个字符串,则是缓存目录的路径。</target>
        </trans-unit>
        <trans-unit id="5b58434a86ea5888954537c341361956c0e8c395" translate="yes" xml:space="preserve">
          <source>Used to determine when to &amp;ldquo;early stop&amp;rdquo;. The fitting process is stopped when none of the last &lt;code&gt;n_iter_no_change&lt;/code&gt; scores are better than the &lt;code&gt;n_iter_no_change - 1&lt;/code&gt; -th-to-last one, up to some tolerance. Only used if early stopping is performed.</source>
          <target state="translated">用于确定何时&amp;ldquo;早停&amp;rdquo;。当最后的 &lt;code&gt;n_iter_no_change&lt;/code&gt; 得分都不比 &lt;code&gt;n_iter_no_change - 1&lt;/code&gt; 倒数最后一个得分好，并且达到一定的公差时，停止拟合过程。仅在执行提前停止时使用。</target>
        </trans-unit>
        <trans-unit id="9462556717c7577fff4ef47d9f5dcd20523f1516" translate="yes" xml:space="preserve">
          <source>Used to initialize &lt;code&gt;w_init&lt;/code&gt; when not specified, with a normal distribution. Pass an int, for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">未指定时用于初始化 &lt;code&gt;w_init&lt;/code&gt; ，具有正态分布。传递一个int，以在多个函数调用之间获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f19cda342b4acf0d93861aea53bc9a6ea559de82" translate="yes" xml:space="preserve">
          <source>Used to pick randomly the &lt;code&gt;max_features&lt;/code&gt; used at each split. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">用于随机选择每个拆分中使用的 &lt;code&gt;max_features&lt;/code&gt; 。有关详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="605a4bcc1f5d9a0fe3ef69215d05c4963e05e516" translate="yes" xml:space="preserve">
          <source>Used to shuffle the training data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">随机 &lt;code&gt;shuffle&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 时，用于随机播放训练数据。为多个函数调用传递可重复输出的int值。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ec2d1021c796c8396406488bdd5b004de6014166" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties.</source>
          <target state="translated">用于指定惩罚中使用的规范。'newton-cg'，'sag'和'lbfgs'求解器仅支持l2罚分。</target>
        </trans-unit>
        <trans-unit id="5860deefa3fd6b4c16483df037c0ad7cd840b1dc" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver.</source>
          <target state="translated">用于指定惩罚中使用的规范。'newton-cg'，'sag'和'lbfgs'求解器仅支持l2罚分。仅&amp;ldquo; saga&amp;rdquo;求解器支持&amp;ldquo; elasticnet&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="f2cadba66c38ca766b85abc4b1e03568d1fa6dab" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver. If &amp;lsquo;none&amp;rsquo; (not supported by the liblinear solver), no regularization is applied.</source>
          <target state="translated">用于指定惩罚中使用的规范。'newton-cg'，'sag'和'lbfgs'求解器仅支持l2罚分。仅&amp;ldquo; saga&amp;rdquo;求解器支持&amp;ldquo; elasticnet&amp;rdquo;。如果为&amp;ldquo; none&amp;rdquo;（liblinear求解器不支持），则不应用任何正则化。</target>
        </trans-unit>
        <trans-unit id="90efd63a8d51063de92a896b88cf64deaa03a244" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">在 &lt;code&gt;eigen_solver&lt;/code&gt; =='arpack'时使用。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="27dcb202bde84d98eaa9b02f62b647ecce32aaba" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;shuffle&lt;/code&gt; is True. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">在 &lt;code&gt;shuffle&lt;/code&gt; 为True时使用。为多个函数调用传递可重复输出的int值。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8694b55c04737ba18ec4ec98388e9997e16f39ac" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo; or &amp;lsquo;saga&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">在 &lt;code&gt;solver&lt;/code&gt; =='sag'或'saga'随机播放数据时使用。有关详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="59bf45c1d50e7570f6107bdd3616f32c93f002ed" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">当 &lt;code&gt;solver&lt;/code&gt; =='sag'，'saga'或'liblinear'来重排数据时使用。有关详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e6070822f60356161845953fee6c5bfe74cf5d59" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver='sag'&lt;/code&gt;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. Note that this only applies to the solver and not the cross-validation generator. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">在 &lt;code&gt;solver='sag'&lt;/code&gt; ，'saga'或'liblinear'混合数据时使用。请注意，这仅适用于求解器，不适用于交叉验证生成器。有关详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f152cc191601223884f2e892b0e88e2ae399e550" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">在 &lt;code&gt;svd_solver&lt;/code&gt; =='arpack'或'randomized'时使用。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5a789f5832dbb34972e6ab11f85f2125e32dddce" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="translated">对于在回归问题中应用非线性变换很有用。可以将其转换为Transformer（例如QuantileTransformer）或函数及其逆函数（例如 &lt;code&gt;log&lt;/code&gt; 和 &lt;code&gt;exp&lt;/code&gt; )。</target>
        </trans-unit>
        <trans-unit id="74349d111804f80e1a38097923f8879dfbcca7b0" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation to the target &lt;code&gt;y&lt;/code&gt; in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="translated">在回归问题中将非线性变换应用于目标 &lt;code&gt;y&lt;/code&gt; 很有用。可以将其作为Transformer（例如QuantileTransformer）或函数及其逆函数（例如 &lt;code&gt;log&lt;/code&gt; 和 &lt;code&gt;exp&lt;/code&gt; )来给出。</target>
        </trans-unit>
        <trans-unit id="665be16622d5dce4c265443eced33f5309efed0f" translate="yes" xml:space="preserve">
          <source>Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.</source>
          <target state="translated">仅对牛顿-CG、下垂和lbfgs求解器有用。求解器收敛的最大迭代次数。</target>
        </trans-unit>
        <trans-unit id="1f7081fc6e8837c157dbcac4dfe150624d77daa3" translate="yes" xml:space="preserve">
          <source>Useful only when the solver &amp;lsquo;liblinear&amp;rsquo; is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt;.</source>
          <target state="translated">仅在使用求解器'liblinear'并将self.fit_intercept设置为True时有用。在这种情况下，x变为[x，self.intercept_scaling]，即，将常量值等于intercept_scaling的&amp;ldquo;合成&amp;rdquo;特征附加到实例矢量。截距将变为 &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="cb4f9242d2c5bef801309a7b11564e9f2917779f" translate="yes" xml:space="preserve">
          <source>Useful tutorials for developing a feel for some of scikit-learn's applications in the machine learning field.</source>
          <target state="translated">有用的教程,用于培养对scikit-learn在机器学习领域的一些应用的感觉。</target>
        </trans-unit>
        <trans-unit id="bec249e659662f7d5947bf09a1ea1d4a552885b0" translate="yes" xml:space="preserve">
          <source>User Guide</source>
          <target state="translated">用户指南</target>
        </trans-unit>
        <trans-unit id="221a6dc59fa62390ffe53703a42fa985bbe3d0ea" translate="yes" xml:space="preserve">
          <source>Uses &lt;a href=&quot;#sklearn.model_selection.ParameterGrid&quot;&gt;&lt;code&gt;ParameterGrid&lt;/code&gt;&lt;/a&gt; to perform a full parallelized parameter search.</source>
          <target state="translated">使用&lt;a href=&quot;#sklearn.model_selection.ParameterGrid&quot;&gt; &lt;code&gt;ParameterGrid&lt;/code&gt; &lt;/a&gt;执行完整的并行化参数搜索。</target>
        </trans-unit>
        <trans-unit id="32b4edc9350cb6d93cc0316d635ce26e35fa63d2" translate="yes" xml:space="preserve">
          <source>Uses BLAS GEMM as replacement for numpy.dot where possible to avoid unnecessary copies.</source>
          <target state="translated">尽可能使用BLAS GEMM来替代numpy.dot,以避免不必要的拷贝。</target>
        </trans-unit>
        <trans-unit id="ac4bd4f4f631e790604905794abbd6ed09d66803" translate="yes" xml:space="preserve">
          <source>Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.</source>
          <target state="translated">在决策函数中使用训练点的子集(称为支持向量),所以它也是内存高效的。</target>
        </trans-unit>
        <trans-unit id="4a4b56e0bea50fff706430a1a94289a4e5e03040" translate="yes" xml:space="preserve">
          <source>Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.</source>
          <target state="translated">使用白盒模型。如果给定的情况在模型中是可以观察到的,那么条件的解释很容易用布尔逻辑来解释。相反,在黑箱模型中(例如,在人工神经网络中),结果可能更难解释。</target>
        </trans-unit>
        <trans-unit id="ced5d25baa7aaf39837296d764096d52eb67f5ca" translate="yes" xml:space="preserve">
          <source>Uses sampling the fourier transform of the kernel characteristic at regular intervals.</source>
          <target state="translated">采用定时采样的方式对内核特征进行傅里叶变换。</target>
        </trans-unit>
        <trans-unit id="2c633fc259072170ae02b4cf8b2266258b09ddc5" translate="yes" xml:space="preserve">
          <source>Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform).</source>
          <target state="translated">使用由fit(或fit_transform)学习的词汇和文档频率(df)。</target>
        </trans-unit>
        <trans-unit id="cdea6e25f0fe24b03bf907dbf26253d4f40a11df" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; or &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; enables the &lt;code&gt;predict_proba&lt;/code&gt; method, which gives a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">使用 &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; 或 &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; 启用 &lt;code&gt;predict_proba&lt;/code&gt; 方法，该方法为每个样本\（x \）提供了概率估计向量\（P（y | x）\）：</target>
        </trans-unit>
        <trans-unit id="4072d118d17ebbe341d060ec8f347bb287543668" translate="yes" xml:space="preserve">
          <source>Using FunctionTransformer to select columns</source>
          <target state="translated">使用FunctionTransformer选择列</target>
        </trans-unit>
        <trans-unit id="af570039f4e6335c176e5a0ced20f61ade37ec58" translate="yes" xml:space="preserve">
          <source>Using KBinsDiscretizer to discretize continuous features</source>
          <target state="translated">使用KBinsDiscretizer对连续特征进行离散化处理。</target>
        </trans-unit>
        <trans-unit id="58dd6560cd1dd1ff16a956c31444ffff4530a294" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more feature are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">使用由 &lt;code&gt;LinearSVC(loss='l2', penalty='l1', dual=False)&lt;/code&gt; 提供的L1惩罚（损失=&amp;ldquo; l2&amp;rdquo;，惩罚=&amp;ldquo; l1&amp;rdquo;，对偶=假）会产生稀疏解，即，只有特征权重的子集不同于零并且有助于决策函数。 &lt;code&gt;C&lt;/code&gt; 的增加将产生更复杂的模型（选择了更多功能）。可以使用&lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;l1_min_c&lt;/code&gt; &lt;/a&gt;计算得出&amp;ldquo;空&amp;rdquo;模型（所有权重等于零）的 &lt;code&gt;C&lt;/code&gt; 值。</target>
        </trans-unit>
        <trans-unit id="927a462bb89282ccdc19c70530472008783e5ed5" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more features are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">使用由 &lt;code&gt;LinearSVC(loss='l2', penalty='l1', dual=False)&lt;/code&gt; 提供的L1惩罚（损失=&amp;ldquo; l2&amp;rdquo;，惩罚=&amp;ldquo; l1&amp;rdquo;，对偶=假）会产生稀疏解，即，只有特征权重的子集不同于零并且有助于决策函数。 &lt;code&gt;C&lt;/code&gt; 的增加将产生更复杂的模型（选择了更多功能）。可以使用&lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;l1_min_c&lt;/code&gt; &lt;/a&gt;计算得出&amp;ldquo;空&amp;rdquo;模型（所有权重等于零）的 &lt;code&gt;C&lt;/code&gt; 值。</target>
        </trans-unit>
        <trans-unit id="757f15a3dfafa1d1e98a6f1f457c43151b4efe0d" translate="yes" xml:space="preserve">
          <source>Using LDA and QDA requires computing the log-posterior which depends on the class priors \(P(y=k)\), the class means \(\mu_k\), and the covariance matrices.</source>
          <target state="translated">使用LDA和QDA需要计算对数后验,它取决于类前导(P(y=k)\)、类均值(\mu_k\)和协方差矩阵。</target>
        </trans-unit>
        <trans-unit id="0033ecf2999fee9c8f71baf5ea186698e26a6aa1" translate="yes" xml:space="preserve">
          <source>Using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; without cache enabled, it is possible to inspect the original instance such as:</source>
          <target state="translated">使用未启用缓存的&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;，可以检查原始实例，例如：</target>
        </trans-unit>
        <trans-unit id="8841876aa584e88fcc31f689448303a79af806c4" translate="yes" xml:space="preserve">
          <source>Using a first-order Taylor approximation, the value of \(l\) can be approximated as follows:</source>
          <target state="translated">利用一阶泰勒近似法,可将/(l/)的值近似为:</target>
        </trans-unit>
        <trans-unit id="4b38a6f3576ed137cc4e9a9f59798fb707d4dde4" translate="yes" xml:space="preserve">
          <source>Using a single underlying feature the model learns both the x and y coordinate as output.</source>
          <target state="translated">使用单一的底层特征,模型学习x和y坐标作为输出。</target>
        </trans-unit>
        <trans-unit id="6d5ea28ea8efb863c08e76177dc50acce9324f64" translate="yes" xml:space="preserve">
          <source>Using a small &lt;code&gt;max_features&lt;/code&gt; value can significantly decrease the runtime.</source>
          <target state="translated">使用较小的 &lt;code&gt;max_features&lt;/code&gt; 值可以大大减少运行时间。</target>
        </trans-unit>
        <trans-unit id="07d5b2f6d48114d6bc5306f53b2bbecb12f93559" translate="yes" xml:space="preserve">
          <source>Using a sub-pipeline, the fitted coefficients can be mapped back into the original feature space.</source>
          <target state="translated">使用子管道,可以将拟合系数映射回原始特征空间。</target>
        </trans-unit>
        <trans-unit id="03c1a9468c05dba06aec630e70cb3912379c2cb0" translate="yes" xml:space="preserve">
          <source>Using its &lt;code&gt;partial_fit&lt;/code&gt; method on chunks of data fetched sequentially from the local hard drive or a network database.</source>
          <target state="translated">在从本地硬盘驱动器或网络数据库顺序获取的数据块上使用其 &lt;code&gt;partial_fit&lt;/code&gt; 方法。</target>
        </trans-unit>
        <trans-unit id="ee5e8e298a940fdf98e8e52d2f16edd9327907f7" translate="yes" xml:space="preserve">
          <source>Using kernels</source>
          <target state="translated">使用内核</target>
        </trans-unit>
        <trans-unit id="9cfba89ca182507cccdcf4094af12bc5a4c62801" translate="yes" xml:space="preserve">
          <source>Using orthogonal matching pursuit for recovering a sparse signal from a noisy measurement encoded with a dictionary</source>
          <target state="translated">使用正交匹配追求从用字典编码的噪声测量中恢复稀疏信号。</target>
        </trans-unit>
        <trans-unit id="24a0ae926e510d4f01c040899e37f954b1d9b717" translate="yes" xml:space="preserve">
          <source>Using pre_dispatch in a producer/consumer situation, where the data is generated on the fly. Note how the producer is first called 3 times before the parallel loop is initiated, and then called to generate new data on the fly:</source>
          <target state="translated">在生产者/消费者的情况下使用pre_dispatch,数据是在飞行中生成的。请注意,在并行循环启动之前,生产者先被调用3次,然后再被调用以在飞行中生成新数据。</target>
        </trans-unit>
        <trans-unit id="efd1182f39233190c4734b5ce34b9cfcf1bbe0bb" translate="yes" xml:space="preserve">
          <source>Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.</source>
          <target state="translated">Using t-SNE.Journal of Machine Learning Research 9:2579-2605,2008.</target>
        </trans-unit>
        <trans-unit id="52758be5ab8f6ab028b2bf9ad6db5d2b69896663" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TfidfTransformer&lt;/code&gt;&amp;rsquo;s default settings, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; the term frequency, the number of times a term occurs in a given document, is multiplied with idf component, which is computed as</source>
          <target state="translated">使用 &lt;code&gt;TfidfTransformer&lt;/code&gt; 的默认设置， &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; ，术语频率，即术语在给定文档中出现的次数，乘以idf分量，计算为</target>
        </trans-unit>
        <trans-unit id="95d62a973e97428e1fb3d7b86f3a392143b00b8c" translate="yes" xml:space="preserve">
          <source>Using the GraphicalLasso estimator to learn a covariance and sparse precision from a small number of samples.</source>
          <target state="translated">使用GraphicalLasso估计器从少量样本中学习一个协方差和稀疏精度。</target>
        </trans-unit>
        <trans-unit id="f9e94a3c6c72e38b7c72fe500879db6b6bb31872" translate="yes" xml:space="preserve">
          <source>Using the Iris dataset, we can construct a tree as follows:</source>
          <target state="translated">使用Iris数据集,我们可以构建一棵树,如下所示。</target>
        </trans-unit>
        <trans-unit id="99fdc1f5bc1cbf237a61e42fe43157752d29d604" translate="yes" xml:space="preserve">
          <source>Using the Poisson loss with a log-link can correct these problems and lead to a well-calibrated linear model.</source>
          <target state="translated">使用Poisson损失与对数连线可以纠正这些问题,并得到一个校准良好的线性模型。</target>
        </trans-unit>
        <trans-unit id="f990799abb31a15673ef02f50b5506399075290a" translate="yes" xml:space="preserve">
          <source>Using the expected value, the adjusted mutual information can then be calculated using a similar form to that of the adjusted Rand index:</source>
          <target state="translated">利用预期值,然后可以用类似于调整后的兰德指数的形式计算调整后的相互信息。</target>
        </trans-unit>
        <trans-unit id="525fdffa79943fda791ea83f2bc571cbb29e45c1" translate="yes" xml:space="preserve">
          <source>Using the naive conditional independence assumption that</source>
          <target state="translated">利用天真的条件独立性假设,即</target>
        </trans-unit>
        <trans-unit id="ded2353583b49d229cc248063161251fcd75da59" translate="yes" xml:space="preserve">
          <source>Using the prediction pipeline in a grid search</source>
          <target state="translated">在网格搜索中使用预测管道。</target>
        </trans-unit>
        <trans-unit id="4b65de55e2dd198ac6e2aecd67614d2f3e1d68d9" translate="yes" xml:space="preserve">
          <source>Using the results of the previous exercises and the &lt;code&gt;cPickle&lt;/code&gt; module of the standard library, write a command line utility that detects the language of some text provided on &lt;code&gt;stdin&lt;/code&gt; and estimate the polarity (positive or negative) if the text is written in English.</source>
          <target state="translated">使用先前练习的结果和标准库的 &lt;code&gt;cPickle&lt;/code&gt; 模块，编写一个命令行实用程序，该程序可检测 &lt;code&gt;stdin&lt;/code&gt; 上提供的某些文本的语言，并估计文本（如果是英语）的极性（正或负）。</target>
        </trans-unit>
        <trans-unit id="271df6087c1c40487d3dd610dcce2afcb5a005f8" translate="yes" xml:space="preserve">
          <source>Using this modification, the tf-idf of the third term in document 1 changes to 1.8473:</source>
          <target state="translated">通过这一修改,文件1中第三个术语的tf-idf变为1.8473。</target>
        </trans-unit>
        <trans-unit id="a81923715d05cfae1b7290021e8d9f8915c03011" translate="yes" xml:space="preserve">
          <source>Usually the Normalized Discounted Cumulative Gain (NDCG, computed by ndcg_score) is preferred.</source>
          <target state="translated">通常,归一化折现累计收益(NDCG,由ndcg_score计算)是首选。</target>
        </trans-unit>
        <trans-unit id="35033b7b1c0300bd76803da2e755fdbe07a7c28b" translate="yes" xml:space="preserve">
          <source>Utilities from joblib:</source>
          <target state="translated">来自joblib的实用工具。</target>
        </trans-unit>
        <trans-unit id="c9ee5681d3c59f7541c27a38b67edf46259e187b" translate="yes" xml:space="preserve">
          <source>V</source>
          <target state="translated">V</target>
        </trans-unit>
        <trans-unit id="8d1950c14bc870de437b37f806aaa51c635a9ec3" translate="yes" xml:space="preserve">
          <source>V measure</source>
          <target state="translated">V措施</target>
        </trans-unit>
        <trans-unit id="a6ed7787c295565530f8c589d9ab12370f5f5b3d" translate="yes" xml:space="preserve">
          <source>V or VI</source>
          <target state="translated">五或六</target>
        </trans-unit>
        <trans-unit id="e659ac0cd03fda8c2776727471548e055d6ecaa7" translate="yes" xml:space="preserve">
          <source>V-Measure (NMI with arithmetic mean option.)</source>
          <target state="translated">V-Measure(带有算术平均值选项的NMI)。</target>
        </trans-unit>
        <trans-unit id="893c35d89ea6a5c89935fd8eeed462af4410524f" translate="yes" xml:space="preserve">
          <source>V-Measure is furthermore symmetric: swapping &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;label_pred&lt;/code&gt; will give the same score. This does not hold for homogeneity and completeness. V-Measure is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the arithmetic averaging method.</source>
          <target state="translated">V-测量是对称此外：交换 &lt;code&gt;labels_true&lt;/code&gt; 和 &lt;code&gt;label_pred&lt;/code&gt; 将给出相同的分数。这不适用于同质性和完整性。使用算术平均方法，V度量与&lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt;相同。</target>
        </trans-unit>
        <trans-unit id="47faeee4990a814efec079e593cccd036ad6778a" translate="yes" xml:space="preserve">
          <source>V-measure cluster labeling given a ground truth.</source>
          <target state="translated">在给定地真值的情况下,进行V度量簇标签。</target>
        </trans-unit>
        <trans-unit id="a4fd517acce42be80ab9791260ae88f5cbdf1a52" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Spam filtering with Naive Bayes &amp;ndash; Which Naive Bayes?&lt;/a&gt; 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">V. Metsis，I。Androutsopoulos和G. Paliouras（2006）。&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;使用朴素贝叶斯过滤垃圾邮件&amp;ndash;哪些朴素贝叶斯？&lt;/a&gt;第三届会议 在电子邮件和反垃圾邮件（CEAS）上。</target>
        </trans-unit>
        <trans-unit id="942786415758a60976a047b84669d53dbc12ecc2" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with naive Bayes &amp;ndash; Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">V. Metsis，I。Androutsopoulos和G. Paliouras（2006）。使用朴素贝叶斯过滤垃圾邮件&amp;ndash;哪些朴素贝叶斯？第三届会议 在电子邮件和反垃圾邮件（CEAS）上。</target>
        </trans-unit>
        <trans-unit id="a4d9f3d16f166bfe390c3f0be94b7a7169e9ff69" translate="yes" xml:space="preserve">
          <source>Valid &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;multiclass&lt;/a&gt; representations for &lt;code&gt;type_of_target&lt;/code&gt; (&lt;code&gt;y&lt;/code&gt;) are:</source>
          <target state="translated">&lt;code&gt;type_of_target&lt;/code&gt; （ &lt;code&gt;y&lt;/code&gt; ）的有效&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;多类&lt;/a&gt;表示形式是：</target>
        </trans-unit>
        <trans-unit id="c9c007aafb4123183734854c6075f37be2b0eaac" translate="yes" xml:space="preserve">
          <source>Valid &lt;code&gt;type_of_target&lt;/code&gt;</source>
          <target state="translated">有效的 &lt;code&gt;type_of_target&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ca4c1a38268237e7698432accf1a9a5a48b6fb08" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_distances.</source>
          <target state="translated">pairwise_distances的有效指标。</target>
        </trans-unit>
        <trans-unit id="26700c8a25eea6fd902a0bb4963f14783c982650" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_kernels</source>
          <target state="translated">pairwise_kernels的有效指标</target>
        </trans-unit>
        <trans-unit id="850c962c3f063b586578621ee12bbb84d6f38bb7" translate="yes" xml:space="preserve">
          <source>Valid options:</source>
          <target state="translated">有效选项:</target>
        </trans-unit>
        <trans-unit id="493108de26f61e3b76acfe363b14fa409e1fdc9a" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with &lt;code&gt;get_params()&lt;/code&gt;.</source>
          <target state="translated">有效的参数键可以使用 &lt;code&gt;get_params()&lt;/code&gt; 列出。</target>
        </trans-unit>
        <trans-unit id="1a791ec45bdf21e7b9592679ed5472b3c5ab8093" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with get_params().</source>
          <target state="translated">有效的参数键可以用get_params()列出。</target>
        </trans-unit>
        <trans-unit id="90d9fefcb561047bbbd742b13c3608c6fcf1e657" translate="yes" xml:space="preserve">
          <source>Valid values for metric are:</source>
          <target state="translated">度量的有效值是:</target>
        </trans-unit>
        <trans-unit id="47edea5ff3c24dcb16dc15647447ec5c4a9d77c2" translate="yes" xml:space="preserve">
          <source>Valid values for metric are::</source>
          <target state="translated">度量的有效值为:。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
