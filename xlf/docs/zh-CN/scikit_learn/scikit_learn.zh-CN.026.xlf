<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="d12e9e0a147a9568f0ed25818d59a0a5266f2c85" translate="yes" xml:space="preserve">
          <source>where the summations are over all documents \(j\) not in class \(c\), \(d_{ij}\) is either the count or tf-idf value of term \(i\) in document \(j\), \(\alpha_i\) is a smoothing hyperparameter like that found in MNB, and \(\alpha = \sum_{i} \alpha_i\). The second normalization addresses the tendency for longer documents to dominate parameter estimates in MNB. The classification rule is:</source>
          <target state="translated">其中,总和是指所有不在类/(c/)/的文档/(j/)的总和,/(d_{ij}/)是文档/(j/)/中术语/(i/)的计数或tf-idf值,/(alpha_i/)是一个平滑的超参数,就像在MMB中发现的那样,而/(alpha/=\sum_{i}alpha_i/)。第二个归一化解决了MMB中长文档主导参数估计的倾向。分类规则是:</target>
        </trans-unit>
        <trans-unit id="5f226a762f7088288a42a2470dfad535771c1b1c" translate="yes" xml:space="preserve">
          <source>where the weights \(w_i\) are strictly positive, and both &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are arbitrary real quantities.</source>
          <target state="translated">其中权重\（w_i \）严格为正，并且 &lt;code&gt;X&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 均为任意实数。</target>
        </trans-unit>
        <trans-unit id="a359df10ad1dd5e991d6402b5b0f2d6f8dc21dd4" translate="yes" xml:space="preserve">
          <source>where we make use of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;hinge loss&lt;/a&gt;. This is the form that is directly optimized by &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt;, but unlike the dual form, this one does not involve inner products between samples, so the famous kernel trick cannot be applied. This is why only the linear kernel is supported by &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; (\(\phi\) is the identity function).</source>
          <target state="translated">我们利用&lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;铰链损失&lt;/a&gt;。这是由&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;直接优化的形式，但是与双重形式不同，该形式不涉及样本之间的内部乘积，因此无法应用著名的内核技巧。这就是为什么&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;仅支持线性内核（\（\ phi \）是标识函数）的原因。</target>
        </trans-unit>
        <trans-unit id="e63ec3af2f71eb9f83e0e53e57d3e62ffb69a574" translate="yes" xml:space="preserve">
          <source>where we make use of the epsilon-insensitive loss, i.e. errors of less than \(\varepsilon\) are ignored. This is the form that is directly optimized by &lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt;&lt;code&gt;LinearSVR&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">在这里我们利用了对&amp;epsilon;不敏感的损失，即小于\（\ varepsilon \）的误差将被忽略。这是&lt;a href=&quot;generated/sklearn.svm.linearsvr#sklearn.svm.LinearSVR&quot;&gt; &lt;code&gt;LinearSVR&lt;/code&gt; &lt;/a&gt;直接优化的形式。</target>
        </trans-unit>
        <trans-unit id="365862a50c0682caa8baa6f30edca76e3e5f81ed" translate="yes" xml:space="preserve">
          <source>where:</source>
          <target state="translated">where:</target>
        </trans-unit>
        <trans-unit id="013382572d31db216a27ecdaa1fa33a09a5c7203" translate="yes" xml:space="preserve">
          <source>whereas &amp;lsquo;discrete&amp;rsquo; will iteratively search for the closest partition space to the embedding space.</source>
          <target state="translated">而&amp;ldquo;离散&amp;rdquo;将迭代搜索最接近嵌入空间的分区空间。</target>
        </trans-unit>
        <trans-unit id="82a236a881a2193c5e029a9fbe8e9321b45550dd" translate="yes" xml:space="preserve">
          <source>whether the python function returns a score (&lt;code&gt;greater_is_better=True&lt;/code&gt;, the default) or a loss (&lt;code&gt;greater_is_better=False&lt;/code&gt;). If a loss, the output of the python function is negated by the scorer object, conforming to the cross validation convention that scorers return higher values for better models.</source>
          <target state="translated">python函数是否返回得分（ &lt;code&gt;greater_is_better=True&lt;/code&gt; ，默认值）还是损失（ &lt;code&gt;greater_is_better=False&lt;/code&gt; ）。如果丢失，则计分器对象将否定python函数的输出，这符合交叉验证约定，即计分器返回较高的值以获得更好的模型。</target>
        </trans-unit>
        <trans-unit id="ca7f02b8487441fd3d262de7c1bf459e056f3988" translate="yes" xml:space="preserve">
          <source>whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为 &quot;假&quot;,则在计算中不使用截距(例如,预计数据已经居中)。</target>
        </trans-unit>
        <trans-unit id="eb2b99684f8643f549ce456fd0d4aceecadd9133" translate="yes" xml:space="preserve">
          <source>whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为false,在计算中不使用截距(例如,预计数据已经居中)。</target>
        </trans-unit>
        <trans-unit id="fff5e4feac16ea0f407c6e1aca2d1e7a882b2255" translate="yes" xml:space="preserve">
          <source>whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered). Default is True.</source>
          <target state="translated">是否计算该模型的截距。如果设置为false,则在计算中不使用截距(例如,预计数据已经居中)。默认为True。</target>
        </trans-unit>
        <trans-unit id="371afce2354db33569867dcbbdf380c6f977315f" translate="yes" xml:space="preserve">
          <source>whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为false,在计算中不使用截距(即数据预期是居中的)。</target>
        </trans-unit>
        <trans-unit id="14015886da14177f23934957dd8ca1e4ae719959" translate="yes" xml:space="preserve">
          <source>whether to return the computed norms</source>
          <target state="translated">是否返回计算后的规范</target>
        </trans-unit>
        <trans-unit id="44f327fe37ff17b81c59cf92446caaa8f42d2de1" translate="yes" xml:space="preserve">
          <source>whether to return the number of iterations or not.</source>
          <target state="translated">是否返回迭代次数。</target>
        </trans-unit>
        <trans-unit id="bd4bb02386dd67bc98e056fa3677c00d26605958" translate="yes" xml:space="preserve">
          <source>whether to scale the data</source>
          <target state="translated">是否缩放数据</target>
        </trans-unit>
        <trans-unit id="474d7e2a58426cda0e78fb1654defcdd45b748e8" translate="yes" xml:space="preserve">
          <source>whether to scale the data?</source>
          <target state="translated">是否要对数据进行缩放?</target>
        </trans-unit>
        <trans-unit id="83c65cd7ea9e6a10512756481dcc650bb3d5d25c" translate="yes" xml:space="preserve">
          <source>whether to shuffle the data before splitting it in batches</source>
          <target state="translated">是否对数据进行洗牌后再进行分批处理。</target>
        </trans-unit>
        <trans-unit id="70c18981ade9461cec2dc03101eb9167280394e0" translate="yes" xml:space="preserve">
          <source>whether to shuffle the samples before forming batches</source>
          <target state="translated">是否要在成批前对样品进行洗牌。</target>
        </trans-unit>
        <trans-unit id="4dcf582a0957b71b14ef075a77111f844268d57e" translate="yes" xml:space="preserve">
          <source>whether to use out-of-bag samples to estimate the R^2 on unseen data.</source>
          <target state="translated">是否使用袋外样本来估计未见数据的R^2。</target>
        </trans-unit>
        <trans-unit id="b6b61ff62fce45bda9955d907eb87a751852a087" translate="yes" xml:space="preserve">
          <source>which differs from multinomial NB&amp;rsquo;s rule in that it explicitly penalizes the non-occurrence of a feature \(i\) that is an indicator for class \(y\), where the multinomial variant would simply ignore a non-occurring feature.</source>
          <target state="translated">与多项式NB的规则不同之处在于，它显式地惩罚了不出现作为类\（y \）指示符的特征\（i \），其中多项式变体将简单地忽略不存在的特征。</target>
        </trans-unit>
        <trans-unit id="91652bad0d48a34b8d306782c12bb9277c69d928" translate="yes" xml:space="preserve">
          <source>which makes it infeasible to be applied exhaustively to problems with a large number of samples and features. Therefore, the magnitude of a subpopulation can be chosen to limit the time and space complexity by considering only a random subset of all possible combinations.</source>
          <target state="translated">这使得它不可能详尽地应用于具有大量样本和特征的问题。因此,可以选择子群的大小,通过只考虑所有可能组合的随机子集来限制时间和空间的复杂性。</target>
        </trans-unit>
        <trans-unit id="1f5675fd405b3870847044da3d8e0e53d145cc1c" translate="yes" xml:space="preserve">
          <source>while plotting the decision function of classifiers for toy 2D datasets can help get an intuitive understanding of their respective expressive power, be aware that those intuitions don&amp;rsquo;t always generalize to more realistic high-dimensional problems.</source>
          <target state="translated">虽然为玩具2D数据集绘制分类器的决策函数可以帮助直观了解其各自的表达能力，但请注意，这些直觉并不总能推广到更现实的高维问题。</target>
        </trans-unit>
        <trans-unit id="33bef6e44041e801264ee8de978f3c796e458754" translate="yes" xml:space="preserve">
          <source>while the Box-Cox transform is given by:</source>
          <target state="translated">而Box-Cox变换为:</target>
        </trans-unit>
        <trans-unit id="913ae494d2a230c80a8a3584f5a402f72ff80aca" translate="yes" xml:space="preserve">
          <source>will be represented by a &lt;code&gt;cv_results_&lt;/code&gt; dict of:</source>
          <target state="translated">将由以下内容的 &lt;code&gt;cv_results_&lt;/code&gt; dict表示：</target>
        </trans-unit>
        <trans-unit id="111b33b98689e8257afc969e3536218cbb35de24" translate="yes" xml:space="preserve">
          <source>with &amp;lsquo;kmeans&amp;rsquo; spectral clustering will cluster samples in the embedding space using a kmeans algorithm</source>
          <target state="translated">带有'kmeans'光谱聚类的对象将使用kmeans算法对嵌入空间中的样本进行聚类</target>
        </trans-unit>
        <trans-unit id="3f35f07260f987ed0b5b5bcda6d9cd2cbaa6a322" translate="yes" xml:space="preserve">
          <source>with \(C_q\) the set of points in cluster \(q\), \(c_q\) the center of cluster \(q\), \(c_E\) the center of \(E\), and \(n_q\) the number of points in cluster \(q\).</source>
          <target state="translated">与 \(C_q\)集群中的点的集合(q\),\(c_q\)集群的中心(q\),\(c_E\)集群的中心(E\),和 \(n_q\)集群的点的数量(q\)。</target>
        </trans-unit>
        <trans-unit id="e4c5fbecf11c7e278af9e6a9c8b7b01b6ee57f82" translate="yes" xml:space="preserve">
          <source>with \(N\) = &lt;code&gt;n_samples&lt;/code&gt; and \(p_i\) the probability of sample \(i\) being correctly classified according to a stochastic nearest neighbors rule in the learned embedded space:</source>
          <target state="translated">其中\（N \）= &lt;code&gt;n_samples&lt;/code&gt; 和\（p_i \）根据学习的嵌入空间中的随机最近邻居规则正确分类样本\（i \）的概率：</target>
        </trans-unit>
        <trans-unit id="345168b15468e95bee9648b3aa7cf5b6763a07fa" translate="yes" xml:space="preserve">
          <source>with \(N\) be the number of points in our data, \(C_q\) be the set of points in cluster \(q\), \(c_q\) be the center of cluster \(q\), \(c\) be the center of \(E\), \(n_q\) be the number of points in cluster \(q\).</source>
          <target state="translated">与 \(N\)是我们数据中的点的数量,\(C_q\)是集群中的点的集合 \(q\),\(c_q\)是集群的中心 \(q\),\(c\)是中心 \(E\),\(n_q\)是集群中的点的数量 \(q)。</target>
        </trans-unit>
        <trans-unit id="7dc1f6921c6cf15190336a1220b70f10a26c5382" translate="yes" xml:space="preserve">
          <source>with \(\text{diag}(A) = \lambda = \{\lambda_{1},...,\lambda_{p}\}\).</source>
          <target state="translated">用((\text{diag}(A)=\lambda=\{\lambda_{1},...,\lambda_{p}\})。</target>
        </trans-unit>
        <trans-unit id="68c6fbdbd0482d98522520dccdea0b4853738610" translate="yes" xml:space="preserve">
          <source>with \(\text{rank}_{ij} = \left|\left\{k: \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\right|\). Given the rank definition, ties in &lt;code&gt;y_scores&lt;/code&gt; are broken by giving the maximal rank that would have been assigned to all tied values.</source>
          <target state="translated">与\（\ text {rank} _ {ij} = \ left | \ left \ {k：\ hat {f} _ {ik} \ geq \ hat {f} _ {ij} \ right \} \ right | \ ）。在给定等级定义的情况下， &lt;code&gt;y_scores&lt;/code&gt; 中的关系通过给出将分配给所有绑定值的最大等级来打破。</target>
        </trans-unit>
        <trans-unit id="c0e2d65d8e8746bcfbd3b586946a135f79a8365c" translate="yes" xml:space="preserve">
          <source>with \(diag \; (A) = \lambda = \{\lambda_{1},...,\lambda_{p}\}\).</source>
          <target state="translated">伴随着</target>
        </trans-unit>
        <trans-unit id="1bc06e7e28c42475b7d707f9718736f4ddbd17d4" translate="yes" xml:space="preserve">
          <source>with \(n\) the total number of samples, \(n_c\) and \(n_k\) the number of samples respectively belonging to class \(c\) and cluster \(k\), and finally \(n_{c,k}\) the number of samples from class \(c\) assigned to cluster \(k\).</source>
          <target state="translated">样本总数,分别属于类(c)和群组(k)的样本数,最后(n_{c,k})来自类(c)的样本数分配给群组(k)。</target>
        </trans-unit>
        <trans-unit id="e6717602ffc042cfe94a4ada96c852fcfd94b89d" translate="yes" xml:space="preserve">
          <source>with shape (n_samples_X, n_features).</source>
          <target state="translated">形状为(n_samples_X,n_features)。</target>
        </trans-unit>
        <trans-unit id="130c3dea3bab17122d9187add718d2a52bab1ac7" translate="yes" xml:space="preserve">
          <source>with shape (n_samples_Y, n_features).</source>
          <target state="translated">形状为(n_samples_Y,n_features)。</target>
        </trans-unit>
        <trans-unit id="7176037722c482ec648c7a4d0ab383e3c26258d8" translate="yes" xml:space="preserve">
          <source>working_memory</source>
          <target state="translated">working_memory</target>
        </trans-unit>
        <trans-unit id="685167af31565295b9ec793fe638b00e03e4ee28" translate="yes" xml:space="preserve">
          <source>working_memory:</source>
          <target state="translated">working_memory:</target>
        </trans-unit>
        <trans-unit id="ec059058794ef04072e97c3c012f3c089f752571" translate="yes" xml:space="preserve">
          <source>x coordinates. These must be either monotonic increasing or monotonic decreasing.</source>
          <target state="translated">x坐标。这些坐标必须是单调递增或单调递减。</target>
        </trans-unit>
        <trans-unit id="93be3475e81cca8fe81bd348a8e8044feb14a34c" translate="yes" xml:space="preserve">
          <source>x_scores if Y is not given, (x_scores, y_scores) otherwise.</source>
          <target state="translated">如果没有给定Y,则为x_scores,否则为(x_scores,y_scores)。</target>
        </trans-unit>
        <trans-unit id="f763628073dc66c776b49f2ea59596f1fb161375" translate="yes" xml:space="preserve">
          <source>y = x_1 + sin(6 * pi * x_2) + 0.1 * N(0, 1), that is the third features is completely irrelevant.</source>
          <target state="translated">y=x_1+sin(6*pi*x_2)+0.1*N(0,1),也就是第三个特征完全无关。</target>
        </trans-unit>
        <trans-unit id="44bde91388dde42b39bc4802c838ef7dead9299e" translate="yes" xml:space="preserve">
          <source>y coordinates.</source>
          <target state="translated">y坐标。</target>
        </trans-unit>
        <trans-unit id="cd5af67d54e9ac16db529640dc05594a7c235d64" translate="yes" xml:space="preserve">
          <source>y is found increasing or decreasing with respect to x based on a Spearman correlation test.</source>
          <target state="translated">根据Spearman相关检验,发现y相对于x增加或减少。</target>
        </trans-unit>
        <trans-unit id="6b6468266858c892d35ef922b37cee3aad4bd1c0" translate="yes" xml:space="preserve">
          <source>y[i] are inputs (real numbers)</source>
          <target state="translated">y[i]是输入值(实数)。</target>
        </trans-unit>
        <trans-unit id="d8fe27e5bf382b7d1e10b706610f994e79c89043" translate="yes" xml:space="preserve">
          <source>y_[i] are fitted</source>
          <target state="translated">y_[i]是拟合的</target>
        </trans-unit>
        <trans-unit id="fb360f9c09ac8c5edb2f18be5de4e80ea4c430d0" translate="yes" xml:space="preserve">
          <source>yes</source>
          <target state="translated">yes</target>
        </trans-unit>
        <trans-unit id="9d7c3728f055d86479c32eaec15e4945cac533c2" translate="yes" xml:space="preserve">
          <source>your dataset consists of heterogeneous data types (e.g. raster images and text captions),</source>
          <target state="translated">你的数据集由不同的数据类型组成(如光栅图像和文本标题)。</target>
        </trans-unit>
        <trans-unit id="35265396b2d0983733aeab30828befa396ef18f3" translate="yes" xml:space="preserve">
          <source>your dataset is stored in a &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame&quot;&gt;&lt;code&gt;pandas.DataFrame&lt;/code&gt;&lt;/a&gt; and different columns require different processing pipelines.</source>
          <target state="translated">您的数据集存储在&lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame&quot;&gt; &lt;code&gt;pandas.DataFrame&lt;/code&gt; 中,&lt;/a&gt;并且不同的列需要不同的处理管道。</target>
        </trans-unit>
        <trans-unit id="3f55d25961d6274662aaca9be3663c0e2b0990a7" translate="yes" xml:space="preserve">
          <source>z = (x - u) / s</source>
          <target state="translated">z=(x-u)/s</target>
        </trans-unit>
        <trans-unit id="94e6c850e7d98bb73a8bc6656412d5077deca880" translate="yes" xml:space="preserve">
          <source>~180</source>
          <target state="translated">~180</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
