<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="2555b04ef28112b324874c1cc2f3bf2b5b5c384e" translate="yes" xml:space="preserve">
          <source>Mutual information, a non-negative value</source>
          <target state="translated">相互信息,一个非负值。</target>
        </trans-unit>
        <trans-unit id="b51a60734da64be0e618bacbea2865a8a7dcd669" translate="yes" xml:space="preserve">
          <source>N</source>
          <target state="translated">N</target>
        </trans-unit>
        <trans-unit id="4e1221dedd7ee34eb6931a44dc15d9a84ca69a81" translate="yes" xml:space="preserve">
          <source>N : number of dimensions</source>
          <target state="translated">N:尺寸数</target>
        </trans-unit>
        <trans-unit id="8daf5ce04352d841160e980446540ca50cce58e4" translate="yes" xml:space="preserve">
          <source>N-grams to the rescue! Instead of building a simple collection of unigrams (n=1), one might prefer a collection of bigrams (n=2), where occurrences of pairs of consecutive words are counted.</source>
          <target state="translated">N-grams来拯救你! 与其建立一个简单的单字格集合(n=1),不如建立一个大字格集合(n=2),在这个集合中,一对连续的单词的出现次数被计算在内。</target>
        </trans-unit>
        <trans-unit id="0d5c48bb908535393359e08969f6193dc43fff44" translate="yes" xml:space="preserve">
          <source>NCA can be seen as learning a (squared) Mahalanobis distance metric:</source>
          <target state="translated">NCA可以看作是学习一个(平方)马哈兰诺比斯距离度量。</target>
        </trans-unit>
        <trans-unit id="78bd06a1d3ff24b26b2d2d7bba48b35d89d447f8" translate="yes" xml:space="preserve">
          <source>NCA can be used to perform supervised dimensionality reduction. The input data are projected onto a linear subspace consisting of the directions which minimize the NCA objective. The desired dimensionality can be set using the parameter &lt;code&gt;n_components&lt;/code&gt;. For instance, the following figure shows a comparison of dimensionality reduction with Principal Component Analysis (&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt;), Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Neighborhood Component Analysis (&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) on the Digits dataset, a dataset with size \(n_{samples} = 1797\) and \(n_{features} = 64\). The data set is split into a training and a test set of equal size, then standardized. For evaluation the 3-nearest neighbor classification accuracy is computed on the 2-dimensional projected points found by each method. Each data sample belongs to one of 10 classes.</source>
          <target state="translated">NCA可用于执行监督的降维。输入数据被投影到线性子空间上，该线性子空间由最小化NCA目标的方向组成。可以使用参数 &lt;code&gt;n_components&lt;/code&gt; 设置所需的尺寸。例如，下图显示了&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt; &lt;/a&gt;维与主成分分析（sklearn.decomposition.PCA），线性判别分析（&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;）和邻域成分分析（&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; )的比较。&lt;/a&gt;）在Digits数据集上，大小为\（n_ {samples} = 1797 \）和\（n_ {features} = 64 \）的数据集。将数据集分为大小相等的训练集和测试集，然后进行标准化。为了评估，在每种方法找到的二维投影点上计算了3个最近邻分类精度。每个数据样本属于10个类别之一。</target>
        </trans-unit>
        <trans-unit id="178c8cecc0d6623e23a76bbb064f3967dc7aa43a" translate="yes" xml:space="preserve">
          <source>NCA classification has been shown to work well in practice for data sets of varying size and difficulty. In contrast to related methods such as Linear Discriminant Analysis, NCA does not make any assumptions about the class distributions. The nearest neighbor classification can naturally produce highly irregular decision boundaries.</source>
          <target state="translated">NCA分类已被证明在实践中对不同规模和难度的数据集效果良好。与线性判别分析(Linear Discriminant Analysis)等相关方法相比,NCA不对类分布做任何假设。最近邻分类自然会产生高度不规则的决策边界。</target>
        </trans-unit>
        <trans-unit id="a288a9444d289c6327b252974b74e26d9ed71a92" translate="yes" xml:space="preserve">
          <source>NCA stores a matrix of pairwise distances, taking &lt;code&gt;n_samples ** 2&lt;/code&gt; memory. Time complexity depends on the number of iterations done by the optimisation algorithm. However, one can set the maximum number of iterations with the argument &lt;code&gt;max_iter&lt;/code&gt;. For each iteration, time complexity is &lt;code&gt;O(n_components x n_samples x min(n_samples, n_features))&lt;/code&gt;.</source>
          <target state="translated">NCA存储成对距离的矩阵，占用 &lt;code&gt;n_samples ** 2&lt;/code&gt; 内存。时间复杂度取决于优化算法完成的迭代次数。但是，可以使用参数 &lt;code&gt;max_iter&lt;/code&gt; 设置最大迭代次数。对于每个迭代，时间复杂度为 &lt;code&gt;O(n_components x n_samples x min(n_samples, n_features))&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="235c4fdc295d941494351e73dad0edc432affd04" translate="yes" xml:space="preserve">
          <source>NFF : number of dims in which both values are False</source>
          <target state="translated">NFF:两个值都为假的dims数。</target>
        </trans-unit>
        <trans-unit id="f242d8e1cdbbc8cb628621d8d57f10327047707d" translate="yes" xml:space="preserve">
          <source>NFT : number of dims in which the first value is False, second is True</source>
          <target state="translated">NFT:第一个值为假,第二个值为真的dims数。</target>
        </trans-unit>
        <trans-unit id="ced12bb5137dbf26fd788e77cae54623cdb8b2e8" translate="yes" xml:space="preserve">
          <source>NMF is best used with the &lt;code&gt;fit_transform&lt;/code&gt; method, which returns the matrix W. The matrix H is stored into the fitted model in the &lt;code&gt;components_&lt;/code&gt; attribute; the method &lt;code&gt;transform&lt;/code&gt; will decompose a new matrix X_new based on these stored components:</source>
          <target state="translated">NMF最好与 &lt;code&gt;fit_transform&lt;/code&gt; 方法一起使用，该方法返回矩阵W。矩阵H存储在 &lt;code&gt;components_&lt;/code&gt; 属性中的拟合模型中。方法 &lt;code&gt;transform&lt;/code&gt; 将基于这些存储的分量分解新的矩阵X_new：</target>
        </trans-unit>
        <trans-unit id="9546ef450bf032f2a099e2b8894066e314108bcc" translate="yes" xml:space="preserve">
          <source>NMI and MI are not adjusted against chance.</source>
          <target state="translated">NMI和MI不作偶然调整。</target>
        </trans-unit>
        <trans-unit id="ec8506cc20e415f16975d43b2c6e163b63b7c223" translate="yes" xml:space="preserve">
          <source>NNEQ / (NNEQ + 0.5 * NTT)</source>
          <target state="translated">NNEQ/(NNEQ+0.5*NTT)</target>
        </trans-unit>
        <trans-unit id="64142d93685b184d0f4668dd2d38de67d364504a" translate="yes" xml:space="preserve">
          <source>NNEQ / (NTT + NNZ)</source>
          <target state="translated">NNEQ/(NTT+NNZ)</target>
        </trans-unit>
        <trans-unit id="9e2ca45598fef4852f298770d7c7037071a195c1" translate="yes" xml:space="preserve">
          <source>NNEQ / N</source>
          <target state="translated">NNEQ/N</target>
        </trans-unit>
        <trans-unit id="bd22d441438dd8339012b8925c55919834498020" translate="yes" xml:space="preserve">
          <source>NNEQ / NNZ</source>
          <target state="translated">NNEQ/NNZ</target>
        </trans-unit>
        <trans-unit id="a4e22ff89a7f8daef1da10b2c311e81f8eb57054" translate="yes" xml:space="preserve">
          <source>NNEQ : number of non-equal dimensions, NNEQ = NTF + NFT</source>
          <target state="translated">NNEQ:非等维数,NNEQ=NTF+NFT。</target>
        </trans-unit>
        <trans-unit id="80bfd3623c0e507836f83286688a2ee41b18b00e" translate="yes" xml:space="preserve">
          <source>NNZ / N</source>
          <target state="translated">NNZ/NN</target>
        </trans-unit>
        <trans-unit id="93209a2edd337e6dc4e7c870a3c72537cea28fdf" translate="yes" xml:space="preserve">
          <source>NNZ : number of nonzero dimensions, NNZ = NTF + NFT + NTT</source>
          <target state="translated">NNZ:非零维数,NNZ=NTF+NFT+NTT。</target>
        </trans-unit>
        <trans-unit id="a8ad860c15810cce0e7beac1c91da3ab2cb22c47" translate="yes" xml:space="preserve">
          <source>NOTE</source>
          <target state="translated">NOTE</target>
        </trans-unit>
        <trans-unit id="b81cbdff62e50c72d48e4feea8a9ed88bea18bef" translate="yes" xml:space="preserve">
          <source>NOTE that when using custom scorers, each scorer should return a single value. Metric functions returning a list/array of values can be wrapped into multiple scorers that return one value each.</source>
          <target state="translated">注意,当使用自定义评分器时,每个评分器应返回一个值。返回一个列表/数组值的度量函数可以被包装成多个评分器,每个评分器返回一个值。</target>
        </trans-unit>
        <trans-unit id="9764dfb854390dc404102ac64200b55e363e83df" translate="yes" xml:space="preserve">
          <source>NOX nitric oxides concentration (parts per 10 million)</source>
          <target state="translated">NOX 一氧化氮浓度(千万分之一)</target>
        </trans-unit>
        <trans-unit id="99542bc2231d38286b9a1dbe4685e8690203b845" translate="yes" xml:space="preserve">
          <source>NTF : number of dims in which the first value is True, second is False</source>
          <target state="translated">NTF:第一值为真,第二值为假的dims数。</target>
        </trans-unit>
        <trans-unit id="d7aff2fba38c5d47fc1d509779237efeccf9cd66" translate="yes" xml:space="preserve">
          <source>NTT : number of dims in which both values are True</source>
          <target state="translated">NTT:两个值都为真的dims数。</target>
        </trans-unit>
        <trans-unit id="f7fd9c68f804acda665d2ab082217bb1583318f2" translate="yes" xml:space="preserve">
          <source>NaN</source>
          <target state="translated">NaN</target>
        </trans-unit>
        <trans-unit id="6e2518fe965a665a40ec6f1bf71cbacd3d7014df" translate="yes" xml:space="preserve">
          <source>NaNs are ignored in the algorithm.</source>
          <target state="translated">算法中忽略了NaNs。</target>
        </trans-unit>
        <trans-unit id="bce02ea83698a345c8e67696ff8bdcc86ad6e774" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in &lt;code&gt;fit&lt;/code&gt;, and maintained in &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">NaN被视为缺失值：忽略 &lt;code&gt;fit&lt;/code&gt; ，并在 &lt;code&gt;transform&lt;/code&gt; 中保持。</target>
        </trans-unit>
        <trans-unit id="7b2cc2bc3bfa4ab2fba6e73cce899558220dd79a" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in fit, and maintained in transform.</source>
          <target state="translated">NaNs作为缺失值处理:在拟合中不考虑,在变换中保持。</target>
        </trans-unit>
        <trans-unit id="d13d7452647efb26ab0d2b1a3596526a7f4ca5d6" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded to compute the statistics, and maintained during the data transformation.</source>
          <target state="translated">NaNs被视为缺失值:在计算统计数据时不予考虑,并在数据转换过程中予以保留。</target>
        </trans-unit>
        <trans-unit id="d5c044a4b683787e1d22f3d89c2071d25a271b09" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for categorical features</source>
          <target state="translated">贝叶斯</target>
        </trans-unit>
        <trans-unit id="80d8f13b4e334c4342adf34b360ad118e5e25aa3" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multinomial models</source>
          <target state="translated">贝叶斯</target>
        </trans-unit>
        <trans-unit id="92990e6c1a566f0d055f974e25026ec604b9ccd9" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multivariate Bernoulli models.</source>
          <target state="translated">Naive Bayes classifier for multivariate Bernoulli models.</target>
        </trans-unit>
        <trans-unit id="c95f9acb4985f23ad6962fd01ae91dec549e7273" translate="yes" xml:space="preserve">
          <source>Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.</source>
          <target state="translated">与更复杂的方法相比,奈夫贝叶斯学习器和分类器的速度可以非常快。类条件特征分布的解耦意味着每个分布都可以作为一个一维分布进行独立估计。这反过来又有助于缓解来自维度诅咒的问题。</target>
        </trans-unit>
        <trans-unit id="bb7ceea48fd3728ed03cf0ba21b4839b323fc974" translate="yes" xml:space="preserve">
          <source>Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes&amp;rsquo; theorem with the &amp;ldquo;naive&amp;rdquo; assumption of conditional independence between every pair of features given the value of the class variable. Bayes&amp;rsquo; theorem states the following relationship, given class variable \(y\) and dependent feature vector \(x_1\) through \(x_n\), :</source>
          <target state="translated">朴素贝叶斯方法是一组监督学习算法，基于贝叶斯定理，在给定类变量值的情况下，每对特征之间具有条件独立性的&amp;ldquo;朴素&amp;rdquo;假设适用于贝叶斯定理。贝叶斯定理给出以下关系，给定类变量\（y \）和从属特征向量\（x_1 \）到\（x_n \），</target>
        </trans-unit>
        <trans-unit id="f65600325bc091b7b293639582ad70691e2ac960" translate="yes" xml:space="preserve">
          <source>Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;MultinomialNB&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt;&lt;code&gt;BernoulliNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt; expose a &lt;code&gt;partial_fit&lt;/code&gt; method that can be used incrementally as done with other classifiers as demonstrated in &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. All naive Bayes classifiers support sample weighting.</source>
          <target state="translated">朴素贝叶斯模型可用于解决大规模分类问题，而完整的训练集可能无法满足这些分类问题。为了处理这种情况，&lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;MultinomialNB&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt; &lt;code&gt;BernoulliNB&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;GaussianNB&lt;/code&gt; &lt;/a&gt;公开了 &lt;code&gt;partial_fit&lt;/code&gt; 方法，该方法可以像其他分类器一样逐步使用，如&lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;文本文档的核心分类中所示&lt;/a&gt;。所有朴素贝叶斯分类器均支持样本加权。</target>
        </trans-unit>
        <trans-unit id="f07ca99358e3e69c28471fb128e9c221473a78cf" translate="yes" xml:space="preserve">
          <source>Name for labeling curve. If &lt;code&gt;None&lt;/code&gt;, the name of the estimator is used.</source>
          <target state="translated">标记曲线的名称。如果为 &lt;code&gt;None&lt;/code&gt; ，则使用估计器的名称。</target>
        </trans-unit>
        <trans-unit id="44b4a8733a267298aba42ed906f0510d314435b0" translate="yes" xml:space="preserve">
          <source>Name of ROC Curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="translated">用于标记的ROC曲线的名称。如果为 &lt;code&gt;None&lt;/code&gt; ，则使用估计器的名称。</target>
        </trans-unit>
        <trans-unit id="048c56c2b44d92cd1c41343db29430d22afe211f" translate="yes" xml:space="preserve">
          <source>Name of columns containing this regex pattern will be included. If None, column selection will not be selected based on pattern.</source>
          <target state="translated">包含此regex模式的列名将被包含。如果为 &quot;无&quot;,则不会根据模式选择列。</target>
        </trans-unit>
        <trans-unit id="7f39a3bd9bee33098b86f18fcaf23fc1b1f211a0" translate="yes" xml:space="preserve">
          <source>Name of dataset</source>
          <target state="translated">数据集名称</target>
        </trans-unit>
        <trans-unit id="325b56c17b8389991fec124de840a19f36bc1993" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i.</source>
          <target state="translated">每个特征的名称;feature_names[i]持有索引为i的特征名称。</target>
        </trans-unit>
        <trans-unit id="f379c68cd7abf28a38376a7f9401ab9de0d511e5" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i. By default, the name of the feature corresponds to their numerical index for NumPy array and their column name for pandas dataframe.</source>
          <target state="translated">每个特征的名称;feature_names[i]保存了索引为i的特征的名称,默认情况下,特征的名称对应于NumPy数组的数字索引和pandas数据框架的列名。</target>
        </trans-unit>
        <trans-unit id="1ea3134d139c317d0bc4edf673307764ffe8b0cd" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, the estimator name is not shown.</source>
          <target state="translated">估计者的名称。如果无,则不显示估算器名称。</target>
        </trans-unit>
        <trans-unit id="b8c1daded10cddfabf9a6fd7ee9e2ee679e1adbf" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, then the estimator name is not shown.</source>
          <target state="translated">估计者的名称。如果无,则不显示估算器名称。</target>
        </trans-unit>
        <trans-unit id="ed7e838c9509fe0de6c00e0d7bd5bf221ec76bc1" translate="yes" xml:space="preserve">
          <source>Name of precision recall curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="translated">标记的精确召回曲线的名称。如果为 &lt;code&gt;None&lt;/code&gt; ，则使用估计器的名称。</target>
        </trans-unit>
        <trans-unit id="1d63bfd9357f039d867c5652a85ab61996c87f94" translate="yes" xml:space="preserve">
          <source>Name of the data set on mldata.org, e.g.: &amp;ldquo;leukemia&amp;rdquo;, &amp;ldquo;Whistler Daily Snowfall&amp;rdquo;, etc. The raw name is automatically converted to a mldata.org URL .</source>
          <target state="translated">mldata.org上的数据集名称，例如：&amp;ldquo;白血病&amp;rdquo;，&amp;ldquo;惠斯勒每日降雪量&amp;rdquo;等。原始名称会自动转换为mldata.org URL。</target>
        </trans-unit>
        <trans-unit id="866f4401ef93cfed3b044fff6753dc1e913659b2" translate="yes" xml:space="preserve">
          <source>Name of the output activation function.</source>
          <target state="translated">输出激活功能的名称。</target>
        </trans-unit>
        <trans-unit id="5a3a86d298c7e4314e724bb2623d8c6979ee2b6e" translate="yes" xml:space="preserve">
          <source>Name of the parameter that will be varied.</source>
          <target state="translated">要改变的参数名称。</target>
        </trans-unit>
        <trans-unit id="d08ba4e92bc82e0b0eddb2db204950ac5386e156" translate="yes" xml:space="preserve">
          <source>Name of the sub-estimator that can be accessed as an attribute of the base object. If a list or a tuple of names are provided, the first sub-estimator that is an attribute of the base object will be used.</source>
          <target state="translated">可作为基础对象属性访问的子估计器的名称。如果提供了一个列表或一个元组的名称,将使用作为基础对象属性的第一个子估计器。</target>
        </trans-unit>
        <trans-unit id="ce3ec81584fa2d87df12f144e2480deecc5a975a" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the data.</source>
          <target state="translated">包含数据的列名或索引。</target>
        </trans-unit>
        <trans-unit id="0ae5e537b1c061ee0b3ccea7c63ace2088ca02dd" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the target values.</source>
          <target state="translated">包含目标值的列名或索引。</target>
        </trans-unit>
        <trans-unit id="3170e49e906772d2e2d83c510613a736bad3f541" translate="yes" xml:space="preserve">
          <source>Named features not encountered during fit or fit_transform will be silently ignored.</source>
          <target state="translated">在fit或fit_transform过程中没有遇到的命名特征将被默默忽略。</target>
        </trans-unit>
        <trans-unit id="dd3283d9f71127c2e2cb8ea6f07a41ece4a049ce" translate="yes" xml:space="preserve">
          <source>Names of each of the features.</source>
          <target state="translated">每个特征的名称:</target>
        </trans-unit>
        <trans-unit id="99983f06243c41c70b7f7a98a21b26cf2a2ec6a9" translate="yes" xml:space="preserve">
          <source>Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If &lt;code&gt;True&lt;/code&gt;, shows a symbolic representation of the class name.</source>
          <target state="translated">每个目标类的名称按升序排列。仅与分类相关，不支持多输出。如果为 &lt;code&gt;True&lt;/code&gt; ，则显示类名的符号表示。</target>
        </trans-unit>
        <trans-unit id="e9e6ba24a1711383d87f42cc11bb29b29e568b73" translate="yes" xml:space="preserve">
          <source>Names of each target (RCV1 topics), as ordered in dataset.target.</source>
          <target state="translated">每个目标(RCV1专题)的名称,按dataset.target排序。</target>
        </trans-unit>
        <trans-unit id="5ee798b80fce1c26ac31847940e2cbb9594ee08b" translate="yes" xml:space="preserve">
          <source>Names of the features produced by transform.</source>
          <target state="translated">通过变换产生的特征名称。</target>
        </trans-unit>
        <trans-unit id="8769733c023d80ccc969e39d7e721f7eef2c8e42" translate="yes" xml:space="preserve">
          <source>Native support for missing values for gradient boosting</source>
          <target state="translated">原生支持梯度提升的缺失值。</target>
        </trans-unit>
        <trans-unit id="4aded465f8c4c45d7d7ec8d437901909b15f0b3f" translate="yes" xml:space="preserve">
          <source>Natural handling of data of mixed type (= heterogeneous features)</source>
          <target state="translated">混合类型数据的自然处理(=异质特征</target>
        </trans-unit>
        <trans-unit id="0a4d2a1303aed1ff654767155d9269907f0d020c" translate="yes" xml:space="preserve">
          <source>Nearest Centroid Classification</source>
          <target state="translated">最近的中心体分类</target>
        </trans-unit>
        <trans-unit id="bfa0969ff4ed25d459c6eac3badc5bf9f79ee3f4" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors</source>
          <target state="translated">最近的邻居</target>
        </trans-unit>
        <trans-unit id="fa1459036257eab60db8e1afe6d9886bbc5e8a42" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors Classification</source>
          <target state="translated">最近鄰居分類</target>
        </trans-unit>
        <trans-unit id="c7b70d3a90c9b413590f1c3fdfeae8dc16304398" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors regression</source>
          <target state="translated">最近邻域回归</target>
        </trans-unit>
        <trans-unit id="cc8575a20e3e28eef4bfc70e48146f9994bd7318" translate="yes" xml:space="preserve">
          <source>Nearest centroid classifier.</source>
          <target state="translated">近心器。</target>
        </trans-unit>
        <trans-unit id="8b02ae7bd0e5dc3ad9885f92e92e8dfc0759e655" translate="yes" xml:space="preserve">
          <source>Nearest neighbor and the curse of dimensionality</source>
          <target state="translated">最近的邻居和维度的诅咒</target>
        </trans-unit>
        <trans-unit id="5db95950f32dda99cc2cb722bb90ec8e1106f00f" translate="yes" xml:space="preserve">
          <source>Needless to say, the cross-validation involved in Platt scaling is an expensive operation for large datasets. In addition, the probability estimates may be inconsistent with the scores, in the sense that the &amp;ldquo;argmax&amp;rdquo; of the scores may not be the argmax of the probabilities. (E.g., in binary classification, a sample may be labeled by &lt;code&gt;predict&lt;/code&gt; as belonging to a class that has probability &amp;lt;&amp;frac12; according to &lt;code&gt;predict_proba&lt;/code&gt;.) Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">不用说，Platt缩放所涉及的交叉验证对于大型数据集而言是一项昂贵的操作。另外，在分数的&amp;ldquo; argmax&amp;rdquo;可能不是概率的argmax的意义上，概率估计可能与分数不一致。 （例如，在二进制分类中，根据 &lt;code&gt;predict_proba&lt;/code&gt; ，样本可能被 &lt;code&gt;predict&lt;/code&gt; 标记为属于概率&amp;lt;1/2的类别。）普氏方法也存在理论问题。如果需要的置信度，但是这些不必是概率，那么最好是集 &lt;code&gt;probability=False&lt;/code&gt; 和使用 &lt;code&gt;decision_function&lt;/code&gt; 代替 &lt;code&gt;predict_proba&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5040421db1ecb4c2ff96e24808174eee959aab93" translate="yes" xml:space="preserve">
          <source>Neighborhood Component Analysis (NCA) is a machine learning algorithm for metric learning. It learns a linear transformation in a supervised fashion to improve the classification accuracy of a stochastic nearest neighbors rule in the transformed space.</source>
          <target state="translated">邻域分量分析(NCA)是一种用于度量学习的机器学习算法。它以监督的方式学习线性变换,以提高变换空间中随机最近邻规则的分类精度。</target>
        </trans-unit>
        <trans-unit id="e58fc95c9278805803f18a9db5fe3ea3f42040b6" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis</source>
          <target state="translated">邻里成分分析</target>
        </trans-unit>
        <trans-unit id="ba8f206becb6fe0a43da0c0c40642a7520c206e1" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA) tries to find a feature space such that a stochastic nearest neighbor algorithm will give the best accuracy. Like LDA, it is a supervised method.</source>
          <target state="translated">邻域成分分析(NCA)试图找到一个特征空间,使随机最近邻算法能给出最佳精度。和LDA一样,它也是一种有监督的方法。</target>
        </trans-unit>
        <trans-unit id="aee814d8b405edd4d076224daf37938472d0e4bb" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA, &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) is a distance metric learning algorithm which aims to improve the accuracy of nearest neighbors classification compared to the standard Euclidean distance. The algorithm directly maximizes a stochastic variant of the leave-one-out k-nearest neighbors (KNN) score on the training set. It can also learn a low-dimensional linear projection of data that can be used for data visualization and fast classification.</source>
          <target state="translated">邻域成分分析（NCA，&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; &lt;/a&gt;）是一种距离度量学习算法，与标准的欧几里得距离相比，该算法旨在提高最近邻分类的准确性。该算法直接最大化训练集上遗忘的k近邻（KNN）分数的随机变量。它还可以学习可用于数据可视化和快速分类的数据的低维线性投影。</target>
        </trans-unit>
        <trans-unit id="e267b3659f7643549165a2fa213a97174cdd61c0" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis Illustration</source>
          <target state="translated">邻里成分分析图解</target>
        </trans-unit>
        <trans-unit id="5d2390b5dea0fabfaec001753e4e7ab98989a540" translate="yes" xml:space="preserve">
          <source>Neighborhoods are restricted the points at a distance lower than radius.</source>
          <target state="translated">邻域是限制在距离小于半径的点。</target>
        </trans-unit>
        <trans-unit id="71b4c3c0886885b3bdb78dd9feb31a745b98d96e" translate="yes" xml:space="preserve">
          <source>Neighbors-based classification is a type of &lt;em&gt;instance-based learning&lt;/em&gt; or &lt;em&gt;non-generalizing learning&lt;/em&gt;: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</source>
          <target state="translated">邻居为基础的分类是一类&lt;em&gt;基于实例的学习&lt;/em&gt;或&lt;em&gt;不学习概括&lt;/em&gt;：它并不试图构建一个通用的内部模型，只是训练数据的存储情况。分类是根据每个点的最近邻居的简单多数票来计算的：向查询点分配数据类，该数据类在该点的最近邻居中具有最多的代表。</target>
        </trans-unit>
        <trans-unit id="f556f4d2d6fabe3a4b78772a04d1d08bf693d3a1" translate="yes" xml:space="preserve">
          <source>Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</source>
          <target state="translated">基于邻域的回归可以用于数据标签是连续而非离散变量的情况。分配给一个查询点的标签是根据其最近邻居标签的平均值计算的。</target>
        </trans-unit>
        <trans-unit id="f17c48105fdd248ad2de1f1ac3f1cabb43429cec" translate="yes" xml:space="preserve">
          <source>Nested cross-validation</source>
          <target state="translated">嵌套交叉验证</target>
        </trans-unit>
        <trans-unit id="029453980f1f56140cec84a6516b88cf4da43353" translate="yes" xml:space="preserve">
          <source>Nested versus non-nested cross-validation</source>
          <target state="translated">嵌套式与非嵌套式交叉验证</target>
        </trans-unit>
        <trans-unit id="3991fd2dc72259103c5d9e42cbe59d2a7e448f31" translate="yes" xml:space="preserve">
          <source>Neural Networks</source>
          <target state="translated">神经网络</target>
        </trans-unit>
        <trans-unit id="8c7edd0d2fdd43b38d35974fe3274794c4023842" translate="yes" xml:space="preserve">
          <source>Never unpickle untrusted data as it could lead to malicious code being executed upon loading.</source>
          <target state="translated">千万不要解开不受信任的数据,因为这可能导致恶意代码在加载时被执行。</target>
        </trans-unit>
        <trans-unit id="5a7c69a057920dae02f0ceb2f6458cca465cc67b" translate="yes" xml:space="preserve">
          <source>New data point to be inserted into the LSH Forest.</source>
          <target state="translated">将插入LSH森林的新数据点。</target>
        </trans-unit>
        <trans-unit id="48ff6f532fccde3a69a322cc1151c107ad295ffd" translate="yes" xml:space="preserve">
          <source>New data to predict.</source>
          <target state="translated">新的数据来预测。</target>
        </trans-unit>
        <trans-unit id="b9599b4d9149cfd51951922f7155a3dc95944ff0" translate="yes" xml:space="preserve">
          <source>New data to predict. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">新数据可预测。如果提供了稀疏矩阵，它将被转换为稀疏 &lt;code&gt;csr_matrix&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e461db7b42b4e1d723a59598bcca510859163aef" translate="yes" xml:space="preserve">
          <source>New data to transform.</source>
          <target state="translated">新的数据要转化。</target>
        </trans-unit>
        <trans-unit id="329a026b697f0ae2b6fcf5ede884e3254ea37650" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">新数据,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="68d214f5c1780f5e1075a93cc2054064839f0ca3" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features. All values of X must be strictly greater than &amp;ldquo;-skewedness&amp;rdquo;.</source>
          <target state="translated">新数据，其中样本数量中的n_samples个，要素数量中的n_features个。X的所有值都必须严格大于&amp;ldquo;偏斜度&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="6e6bacb37aec6214dc7bc345656e9fc6be9d8645" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">新数据,其中n_samples为样本数,n_components为成分数。</target>
        </trans-unit>
        <trans-unit id="ed0f15ab3ccef84bd24b03af80dd2d8f760b3551" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of pls components.</source>
          <target state="translated">新的数据,其中n_samples为样本数,n_components为pps组件数。</target>
        </trans-unit>
        <trans-unit id="9774ac05294602db6164b128c08e5838d8dd2c30" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">新数据,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="2cec1d1d13a623e2cead9e687223c0b43410804e" translate="yes" xml:space="preserve">
          <source>New data.</source>
          <target state="translated">新数据:</target>
        </trans-unit>
        <trans-unit id="2dcde8ec0560b6129ac7ceb94e6b76437cebda2e" translate="yes" xml:space="preserve">
          <source>New in version 0.10.</source>
          <target state="translated">0.10版本的新内容。</target>
        </trans-unit>
        <trans-unit id="d68d01022d3e4f6b4abc88815d154b4b27565257" translate="yes" xml:space="preserve">
          <source>New in version 0.12.</source>
          <target state="translated">0.12版本的新内容。</target>
        </trans-unit>
        <trans-unit id="dc28b70929f839a69ed3e45ea011105ea33d52a9" translate="yes" xml:space="preserve">
          <source>New in version 0.13.</source>
          <target state="translated">0.13版本的新内容。</target>
        </trans-unit>
        <trans-unit id="52ebd0001be9ad2ddaeba3e98fe57c162ffbf813" translate="yes" xml:space="preserve">
          <source>New in version 0.14.</source>
          <target state="translated">0.14版本的新内容。</target>
        </trans-unit>
        <trans-unit id="73af4998c8d20c7743147253e8c7d8a51d34634f" translate="yes" xml:space="preserve">
          <source>New in version 0.15.</source>
          <target state="translated">0.15版本的新内容。</target>
        </trans-unit>
        <trans-unit id="81c56a91b55dc7fbe4322466c0b6b3d2def29380" translate="yes" xml:space="preserve">
          <source>New in version 0.16.</source>
          <target state="translated">0.16版本的新内容。</target>
        </trans-unit>
        <trans-unit id="b2a489d3a2d4dc51668c693a83253f531fff88d5" translate="yes" xml:space="preserve">
          <source>New in version 0.16: If the input is sparse, the output will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;. Else, output type is the same as the input type.</source>
          <target state="translated">版本0.16中的新增功能：如果输入稀疏，则输出将是 &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; 。否则，输出类型与输入类型相同。</target>
        </trans-unit>
        <trans-unit id="60b69c65bf1a3241e15d0d894ba32eab25d7cdd7" translate="yes" xml:space="preserve">
          <source>New in version 0.17.</source>
          <target state="translated">0.17版本的新内容。</target>
        </trans-unit>
        <trans-unit id="21cf2264569599d5dcc312306fa70dfc0eda22f5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;code&gt;random_state&lt;/code&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">0.17版中的新功能： &lt;code&gt;random_state&lt;/code&gt; 支持随机平均梯度。</target>
        </trans-unit>
        <trans-unit id="dc470080fe5f5c357c2ad73809b92faa7362d9a9" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="abf887094b036a443ef8f8f3b6efb216ee34cd24" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6b2ff85ecc2a1a01962dd33b1e34753285ca0790" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;alpha&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">版本0.17中的新功能：在坐标下降求解器中使用的&lt;em&gt;Alpha&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="6808fe2d57e6aeef92c976187ce0a06abf1ebec1" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;cd&lt;/em&gt;坐标下降法可提高速度。</target>
        </trans-unit>
        <trans-unit id="7b66bf990e4010a15f9d64925c054de502637170" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;class_weight=&amp;rsquo;balanced&amp;rsquo;&lt;/em&gt;</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;class_weight ='balanced'&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ea86dc59df4308dd8eeb6d9e2ae15359239ba528" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_max_&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;data_max_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="1f6c1c10d870e8e7d70fedf31cf3a9ee8c7d746d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_min_&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;data_min_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e853c35f6d282db32a11152441252fd53da7f57f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_range_&lt;/em&gt;</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;data_range_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="edb88b5a13c967ddfdc52fb30c87cf6cd8e55cef" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;decision_function_shape=&amp;rsquo;ovr&amp;rsquo;&lt;/em&gt; is recommended.</source>
          <target state="translated">0.17版中的新功能：建议&lt;em&gt;Decision_function_shape ='ovr'&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="18bd409dbab688800dc645ecf6dc2d319b6dc274" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;lasso_cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;lasso_cd&lt;/em&gt;坐标下降方法可提高速度。</target>
        </trans-unit>
        <trans-unit id="5c5696058be6bc7e1f1d8d04441e99d3b67a5a9d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;minmax_scale&lt;/em&gt; function interface to &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">在新版本0.17：&lt;em&gt;minmax_scale&lt;/em&gt;功能接口&lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="61491e91a5cc882c8d0472b81b77bf74b7ea4e3d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;presort&lt;/em&gt; parameter.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;预排序&lt;/em&gt;参数。</target>
        </trans-unit>
        <trans-unit id="b2b731bdc9bf8dfc47673f8abfcc6c2c7f1f838c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;random_state&lt;/em&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;random_state&lt;/em&gt;支持随机平均梯度。</target>
        </trans-unit>
        <trans-unit id="727acdfec60aa8d5fe01b0fab35aa36437da02bb" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to Classifier.</source>
          <target state="translated">0.17版中的新功能：对&lt;em&gt;classifier的sample_weight&lt;/em&gt;支持。</target>
        </trans-unit>
        <trans-unit id="6a9e702e6dde8c5e083d3061949d66f0c1cd0a95" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to LogisticRegression.</source>
          <target state="translated">0.17版中的新功能：对LogisticRegression的&lt;em&gt;sample_weight&lt;/em&gt;支持。</target>
        </trans-unit>
        <trans-unit id="8bf7c72c906a46e4bafab411161accafb9f3258f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt;</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;scale_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="26b994b5337cbc66d9e87cecbe064dc645c2d9c5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt; attribute.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;scale_&lt;/em&gt;属性。</target>
        </trans-unit>
        <trans-unit id="acaea6c314c50f12e63f6a31caa95dae9a93cb16" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;shuffle&lt;/em&gt; parameter used in the Coordinate Descent solver.</source>
          <target state="translated">版本0.17中的新增功能：在坐标下降求解器中使用的&lt;em&gt;洗牌&lt;/em&gt;参数。</target>
        </trans-unit>
        <trans-unit id="3c9ad8ece37a0ad66c0695ab197f051fc5c4f74b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; constructor parameter.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;warm_start&lt;/em&gt;构造函数参数。</target>
        </trans-unit>
        <trans-unit id="5d7ee9d78ae5139184086665f72ad9adc489e60f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; to support &lt;em&gt;lbfgs&lt;/em&gt;, &lt;em&gt;newton-cg&lt;/em&gt;, &lt;em&gt;sag&lt;/em&gt;, &lt;em&gt;saga&lt;/em&gt; solvers.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;warm_start&lt;/em&gt;支持&lt;em&gt;lbfgs&lt;/em&gt;，&lt;em&gt;newton-cg&lt;/em&gt;，&lt;em&gt;sag&lt;/em&gt;和&lt;em&gt;saga&lt;/em&gt;求解器。</target>
        </trans-unit>
        <trans-unit id="6005792b774eeae7e9401b712800c9c602a22ebe" translate="yes" xml:space="preserve">
          <source>New in version 0.17: A function &lt;em&gt;label_ranking_loss&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：函数&lt;em&gt;label_ranking_loss&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e93da6946e01b1e23cbc1e7009a23425c993a384" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Approximate optimization &lt;em&gt;method&lt;/em&gt; via the Barnes-Hut.</source>
          <target state="translated">版本0.17中的新功能：通过Barnes-Hut的近似优化&lt;em&gt;方法&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="9365f66e13f87cb3bbf8aaf0ec5863c643029aff" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Coordinate Descent solver.</source>
          <target state="translated">0.17版本新增:坐标下降求解器。</target>
        </trans-unit>
        <trans-unit id="c589f3a156d1562e5e258c1483b29eaa7a3bb671" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Dummy Classifier now supports prior fitting strategy using parameter &lt;em&gt;prior&lt;/em&gt;.</source>
          <target state="translated">在新版本0.17：虚拟分类现在支持使用参数之前安装的策略&lt;em&gt;之前&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="4c1ba1a9df4e3f1eda2057a3d8675352ba0c6105" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Gaussian Naive Bayes supports fitting with &lt;em&gt;sample_weight&lt;/em&gt;.</source>
          <target state="translated">版本0.17中的新功能：高斯朴素贝叶斯支持使用&lt;em&gt;sample_weight进行&lt;/em&gt;拟合。</target>
        </trans-unit>
        <trans-unit id="b94e1008bb6bd8880b48f9c93c89015eb39cf414" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Parallel Execution using &lt;em&gt;n_jobs&lt;/em&gt;.</source>
          <target state="translated">0.17版中的新功能：使用&lt;em&gt;n_jobs&lt;/em&gt;并行执行。</target>
        </trans-unit>
        <trans-unit id="56295350a01a04673ce10a1274f3f2850857660f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Regularization parameter &lt;em&gt;l1_ratio&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">版本0.17中的新增功能：在坐标下降求解器中使用的正则化参数&lt;em&gt;l1_ratio&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="bfb15daea388e7bc4652a64e3ee368ec3ef32e45" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Stochastic Average Gradient descent solver.</source>
          <target state="translated">0.17版本新增:随机平均梯度下降求解器。</target>
        </trans-unit>
        <trans-unit id="90ee93ad6b0e53eed26b86779c90b9633cb9848b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: class_weight == &amp;lsquo;balanced&amp;rsquo;</source>
          <target state="translated">0.17版中的新功能：class_weight =='balanced'</target>
        </trans-unit>
        <trans-unit id="db422a34a0885d2d1033db36affb13affc0d2065" translate="yes" xml:space="preserve">
          <source>New in version 0.17: metric &lt;em&gt;precomputed&lt;/em&gt; to accept precomputed sparse matrix.</source>
          <target state="translated">版本0.17中的新功能：度量已&lt;em&gt;预先计算&lt;/em&gt;为接受预先计算的稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="545f1d599ea32d73544f4951073f7ce5e1f64bf6" translate="yes" xml:space="preserve">
          <source>New in version 0.17: optional parameter &lt;em&gt;presort&lt;/em&gt;.</source>
          <target state="translated">版本0.17中的新功能：可选参数&lt;em&gt;presort&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="1c0b7964a491c4c8234983325c356450f442446c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;code&gt;dense_output&lt;/code&gt; for dense output.</source>
          <target state="translated">版本0.17中的新功能：用于密集输出的参数 &lt;code&gt;dense_output&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="46c6419997a8eb39c61c2c50456a363282489838" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;class_weight&lt;/em&gt; to automatically weight samples.</source>
          <target state="translated">0.17版中的新功能：参数&lt;em&gt;class_weight&lt;/em&gt;可自动对样本加权。</target>
        </trans-unit>
        <trans-unit id="e8cbf38ab0cedfa95f7fc33391f9602285bd6e17" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;drop_intermediate&lt;/em&gt;.</source>
          <target state="translated">0.17版中的新功能：参数&lt;em&gt;drop_intermediate&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="960c43bc8538ca35574a01cc68a5f2b510105d22" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;multilabel&lt;/em&gt; to support multilabel datasets.</source>
          <target state="translated">0.17版中的新功能：参数&lt;em&gt;multilabel&lt;/em&gt;支持多标签数据集。</target>
        </trans-unit>
        <trans-unit id="3788b38f2b10aab217952de3365bf7b88f170f8d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;n_iter_without_progress&lt;/em&gt; to control stopping criteria.</source>
          <target state="translated">版本0.17中的新功能：参数&lt;em&gt;n_iter_without_progress&lt;/em&gt;用于控制停止条件。</target>
        </trans-unit>
        <trans-unit id="8db0c53c524e84f302dbc1a0dbd534321460f08f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to LinearRegression.</source>
          <target state="translated">0.17版中的新功能：LinearRegression支持参数&lt;em&gt;sample_weight&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="2a05312b3a418ca739af1c2a1750981f3df80101" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter to allow &lt;em&gt;sparse&lt;/em&gt; output.</source>
          <target state="translated">0.17版中的新功能：允许&lt;em&gt;稀疏&lt;/em&gt;输出的参数。</target>
        </trans-unit>
        <trans-unit id="8550f8dcfdefc5ee2595ff5a932287ae10047927" translate="yes" xml:space="preserve">
          <source>New in version 0.18.</source>
          <target state="translated">0.18版本的新内容。</target>
        </trans-unit>
        <trans-unit id="bc1978fea309e92ee1923ea481a6fd1eab915379" translate="yes" xml:space="preserve">
          <source>New in version 0.18.0.</source>
          <target state="translated">0.18.0版本的新内容。</target>
        </trans-unit>
        <trans-unit id="f6899efa546ca366fb803a6a6fcb7b4b47706e4f" translate="yes" xml:space="preserve">
          <source>New in version 0.18: ..</source>
          <target state="translated">0.18版本的新内容:.</target>
        </trans-unit>
        <trans-unit id="11462cefb53316ba0a8e0880815bfa04af36466b" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Mean Absolute Error (MAE) criterion.</source>
          <target state="translated">0.18版本新增:平均绝对误差(MAE)标准。</target>
        </trans-unit>
        <trans-unit id="f3588d83291a2be20994392c7201429910c5a8e9" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Stochastic Average Gradient descent solver for &amp;lsquo;multinomial&amp;rsquo; case.</source>
          <target state="translated">版本0.18中的新功能：用于&amp;ldquo;多项式&amp;rdquo;情况的随机平均梯度下降求解器。</target>
        </trans-unit>
        <trans-unit id="0eb4d3b4907b28878c6666a16cc5abd9e36f4f00" translate="yes" xml:space="preserve">
          <source>New in version 0.19.</source>
          <target state="translated">0.19版本的新内容。</target>
        </trans-unit>
        <trans-unit id="e10489dae5e0fb6aa174b77a26bd312889388c1d" translate="yes" xml:space="preserve">
          <source>New in version 0.19: Multiplicative Update solver.</source>
          <target state="translated">0.19版本新增:乘法更新求解器。</target>
        </trans-unit>
        <trans-unit id="c260a9e7caaac82377fee1bfeace2cf2272b4b1a" translate="yes" xml:space="preserve">
          <source>New in version 0.19: SAGA solver.</source>
          <target state="translated">0.19版本新增:SAGA解算器。</target>
        </trans-unit>
        <trans-unit id="d56c2d84411d9a6c91bdf6681efc0b4e653d1de5" translate="yes" xml:space="preserve">
          <source>New in version 0.19: l1 penalty with SAGA solver (allowing &amp;lsquo;multinomial&amp;rsquo; + L1)</source>
          <target state="translated">0.19版中的新功能：SAGA求解器的惩罚为l1（允许&amp;ldquo;多项式&amp;rdquo; + L1）</target>
        </trans-unit>
        <trans-unit id="69d687c70a1657bfe591a19056b06b9f07dd4b5e" translate="yes" xml:space="preserve">
          <source>New in version 0.19: parameter &lt;em&gt;average&lt;/em&gt; to use weights averaging in SGD</source>
          <target state="translated">版本0.19中的新功能：参数&lt;em&gt;平均值&lt;/em&gt;使用SGD中的权重平均值</target>
        </trans-unit>
        <trans-unit id="e6570e8764c255a027de40e9e3eb2d1c722d495c" translate="yes" xml:space="preserve">
          <source>New in version 0.20.</source>
          <target state="translated">0.20版本的新内容。</target>
        </trans-unit>
        <trans-unit id="6c617d40b81d2b01909932fc5a27e561e533ba93" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;SimpleImputer&lt;/code&gt; replaces the previous &lt;code&gt;sklearn.preprocessing.Imputer&lt;/code&gt; estimator which is now removed.</source>
          <target state="translated">0.20版中的新功能： &lt;code&gt;SimpleImputer&lt;/code&gt; 替换了之前已删除的以前的 &lt;code&gt;sklearn.preprocessing.Imputer&lt;/code&gt; 估计器。</target>
        </trans-unit>
        <trans-unit id="92da9b59ee8f1aee40e76bd7e7f9a69e15158836" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;behaviour&lt;/code&gt; is added in 0.20 for back-compatibility purpose.</source>
          <target state="translated">0.20版中的新功能：在0.20中添加了 &lt;code&gt;behaviour&lt;/code&gt; ，以实现向后兼容。</target>
        </trans-unit>
        <trans-unit id="89ff3bd96af64e1a70d0744f65ccf966040b095d" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">0.20版中的新功能： &lt;code&gt;force_all_finite&lt;/code&gt; 接受字符串 &lt;code&gt;'allow-nan'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="fe256f44bbbbc2bd0c867a8e63ec681a6240ed59" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;adaptive&amp;rsquo; option</source>
          <target state="translated">0.20版中的新功能：添加了&amp;ldquo;自适应&amp;rdquo;选项</target>
        </trans-unit>
        <trans-unit id="c29982d75481689af02d31b620cd5f76c827f04a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;early_stopping&amp;rsquo; option</source>
          <target state="translated">0.20版中的新功能：添加了&amp;ldquo; early_stopping&amp;rdquo;选项</target>
        </trans-unit>
        <trans-unit id="383b2bc5e9967f26e0b4b20cd947fb1316e6616a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;n_iter_no_change&amp;rsquo; option</source>
          <target state="translated">0.20版中的新功能：添加了&amp;ldquo; n_iter_no_change&amp;rdquo;选项</target>
        </trans-unit>
        <trans-unit id="5896f9ff4dd021dab607afd66ed0a221195a00c5" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;validation_fraction&amp;rsquo; option</source>
          <target state="translated">0.20版中的新功能：添加了&amp;ldquo; validation_fraction&amp;rdquo;选项</target>
        </trans-unit>
        <trans-unit id="646e72bed85791f997c7991fa5af303d05883478" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added the &amp;lsquo;single&amp;rsquo; option</source>
          <target state="translated">0.20版中的新功能：添加了&amp;ldquo;单个&amp;rdquo;选项</target>
        </trans-unit>
        <trans-unit id="1468919e56b56c4ded7ab6dba66d158a1002d5be" translate="yes" xml:space="preserve">
          <source>New in version 0.20: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to BayesianRidge.</source>
          <target state="translated">0.20版中的新功能：BayesianRidge支持参数&lt;em&gt;sample_weight&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="7c256855a0d81868bca650e3f1d5676a1f0ae5da" translate="yes" xml:space="preserve">
          <source>New in version 0.20: strategy=&amp;rdquo;constant&amp;rdquo; for fixed value imputation.</source>
          <target state="translated">0.20版中的新功能：对于固定值插补，strategy =&amp;ldquo; constant&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="6371a324a0f9b28d52fcce7a713bd8acc7b321e0" translate="yes" xml:space="preserve">
          <source>New in version 0.21.</source>
          <target state="translated">0.21版本的新内容。</target>
        </trans-unit>
        <trans-unit id="28bbafe212871917c1ae23be319d534da486ed2c" translate="yes" xml:space="preserve">
          <source>New in version 0.21: &lt;code&gt;n_connected_components_&lt;/code&gt; was added to replace &lt;code&gt;n_components_&lt;/code&gt;.</source>
          <target state="translated">在新版本0.21： &lt;code&gt;n_connected_components_&lt;/code&gt; 加入取代 &lt;code&gt;n_components_&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="be8b989c4868c5bd7f2040240742c5509b13b840" translate="yes" xml:space="preserve">
          <source>New in version 0.22.</source>
          <target state="translated">0.22版本的新内容。</target>
        </trans-unit>
        <trans-unit id="69cdaee84ba92c12f0c1ee7d5ea78cec5fb3129d" translate="yes" xml:space="preserve">
          <source>New in version 0.22: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">0.22版中的新功能： &lt;code&gt;force_all_finite&lt;/code&gt; 接受字符串 &lt;code&gt;'allow-nan'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1fed47321851e7513d73e52b53e589471c95ed14" translate="yes" xml:space="preserve">
          <source>New in version 0.23.</source>
          <target state="translated">0.23版本的新内容。</target>
        </trans-unit>
        <trans-unit id="3131ca254bc6ccc53b97a121b7c7087eb729d9ad" translate="yes" xml:space="preserve">
          <source>New in version 0.23: this parameter was previously hardcoded as 0.</source>
          <target state="translated">0.23版本的新内容:这个参数以前是硬编码为0。</target>
        </trans-unit>
        <trans-unit id="1c41c95cafce09fc00bdb02d31fa4b185ade21eb" translate="yes" xml:space="preserve">
          <source>New in version 0.5.</source>
          <target state="translated">0.5版本的新内容。</target>
        </trans-unit>
        <trans-unit id="48e2833e629833b7582fc86a591171cccb4a2aa1" translate="yes" xml:space="preserve">
          <source>New in version 0.8.</source>
          <target state="translated">0.8版本的新内容。</target>
        </trans-unit>
        <trans-unit id="e0798e2f31cc8f6f05534a395874ff516c037ea2" translate="yes" xml:space="preserve">
          <source>New in version 0.9.</source>
          <target state="translated">0.9版本的新内容。</target>
        </trans-unit>
        <trans-unit id="3dcb523c8b35ef7bba188a1b72a37583d73585c0" translate="yes" xml:space="preserve">
          <source>New in version 1.7.0.</source>
          <target state="translated">1.7.0版本的新内容。</target>
        </trans-unit>
        <trans-unit id="382bf23b05f69ca7724427a219843811ca7f86bf" translate="yes" xml:space="preserve">
          <source>New plotting API</source>
          <target state="translated">新的绘图API</target>
        </trans-unit>
        <trans-unit id="58fbaea601eebe84b9d8f8508a33c9a4b3025541" translate="yes" xml:space="preserve">
          <source>New to Scientific Python?</source>
          <target state="translated">科学Python的新手?</target>
        </trans-unit>
        <trans-unit id="9f6a58e9ea6f2ce3d4a15836e22f7c6b8aed6e50" translate="yes" xml:space="preserve">
          <source>Next we create 10 classifier chains. Each classifier chain contains a logistic regression model for each of the 14 labels. The models in each chain are ordered randomly. In addition to the 103 features in the dataset, each model gets the predictions of the preceding models in the chain as features (note that by default at training time each model gets the true labels as features). These additional features allow each chain to exploit correlations among the classes. The Jaccard similarity score for each chain tends to be greater than that of the set independent logistic models.</source>
          <target state="translated">接下来我们创建10条分类器链。每条分类器链都包含了14个标签中每个标签的逻辑回归模型。每个链中的模型是随机排序的。除了数据集中的103个特征外,每个模型都会得到链中前几个模型的预测作为特征(注意在训练时默认情况下,每个模型都会得到真实标签作为特征)。这些额外的特征允许每个链利用类之间的相关性。每个链的Jaccard相似度得分往往大于集合独立逻辑模型的相似度得分。</target>
        </trans-unit>
        <trans-unit id="d753c88a8af3a7221324f1f115e965ef2e7003fc" translate="yes" xml:space="preserve">
          <source>Next we fit the Poisson regressor on the target variable. We set the regularization strength &lt;code&gt;alpha&lt;/code&gt; to approximately 1e-6 over number of samples (i.e. &lt;code&gt;1e-12&lt;/code&gt;) in order to mimic the Ridge regressor whose L2 penalty term scales differently with the number of samples.</source>
          <target state="translated">接下来，我们将Poisson回归变量拟合到目标变量上。我们将正则化强度 &lt;code&gt;alpha&lt;/code&gt; 设置为样本数量（即 &lt;code&gt;1e-12&lt;/code&gt; ）的大约1e-6 ，以便模拟其L2惩罚项随样本数量不同而变化的Ridge回归器。</target>
        </trans-unit>
        <trans-unit id="1ae340c010af24c68842322aa72c1a3f11d7dacf" translate="yes" xml:space="preserve">
          <source>Next, let&amp;rsquo;s compare the accuracy of &lt;code&gt;SVC&lt;/code&gt; and &lt;code&gt;most_frequent&lt;/code&gt;:</source>
          <target state="translated">接下来，让我们比较 &lt;code&gt;SVC&lt;/code&gt; 和 &lt;code&gt;most_frequent&lt;/code&gt; 的准确性：</target>
        </trans-unit>
        <trans-unit id="c6c64a04d2e12fed93b98d6c01ec2531f747d55c" translate="yes" xml:space="preserve">
          <source>Next, we manually pick a threshold by visual inspection of the dendrogram to group our features into clusters and choose a feature from each cluster to keep, select those features from our dataset, and train a new random forest. The test accuracy of the new random forest did not change much compared to the random forest trained on the complete dataset.</source>
          <target state="translated">接下来,我们通过对树枝图的视觉检查,手动选取一个阈值,将我们的特征分组为聚类,并从每个聚类中选择一个特征保留,从我们的数据集中选择这些特征,并训练一个新的随机森林。与在完整数据集上训练的随机森林相比,新的随机森林的测试精度并没有太大的变化。</target>
        </trans-unit>
        <trans-unit id="60abf98c19bebf728f6b765cf9ba6a0bbf19fa43" translate="yes" xml:space="preserve">
          <source>Next, we plot the ROC curve with a single call to &lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt;&lt;code&gt;sklearn.metrics.plot_roc_curve&lt;/code&gt;&lt;/a&gt;. The returned &lt;code&gt;svc_disp&lt;/code&gt; object allows us to continue using the already computed ROC curve for the SVC in future plots.</source>
          <target state="translated">接下来，我们通过一次调用&lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt; &lt;code&gt;sklearn.metrics.plot_roc_curve&lt;/code&gt; &lt;/a&gt;绘制ROC曲线。返回的 &lt;code&gt;svc_disp&lt;/code&gt; 对象使我们可以在以后的图中继续使用已经计算出的SVC ROC曲线。</target>
        </trans-unit>
        <trans-unit id="0e2a2edce50f17d924871b306d2618d9b3454954" translate="yes" xml:space="preserve">
          <source>Next, we plot the tree based feature importance and the permutation importance. The permutation importance plot shows that permuting a feature drops the accuracy by at most &lt;code&gt;0.012&lt;/code&gt;, which would suggest that none of the features are important. This is in contradiction with the high test accuracy computed above: some feature must be important. The permutation importance is calculated on the training set to show how much the model relies on each feature during training.</source>
          <target state="translated">接下来，我们绘制基于树的特征重要性和置换重要性。排列重要性图显示，对特征进行排列最多会使准确性降低 &lt;code&gt;0.012&lt;/code&gt; ，这表明所有特征都不重要。这与上面计算出的高测试精度相矛盾：某些功能必须很重要。在训练集上计算置换重要性，以显示模型在训练过程中对每个特征的依赖程度。</target>
        </trans-unit>
        <trans-unit id="4301caa6a55515044571ecdaaa2f60c152ef3c59" translate="yes" xml:space="preserve">
          <source>Next, we train a decision tree using the effective alphas. The last value in &lt;code&gt;ccp_alphas&lt;/code&gt; is the alpha value that prunes the whole tree, leaving the tree, &lt;code&gt;clfs[-1]&lt;/code&gt;, with one node.</source>
          <target state="translated">接下来，我们使用有效的alpha训练决策树。 &lt;code&gt;ccp_alphas&lt;/code&gt; 中的最后一个值是修剪整棵树的alpha值，剩下的树 &lt;code&gt;clfs[-1]&lt;/code&gt; 仅有一个节点。</target>
        </trans-unit>
        <trans-unit id="19146388ab896a5ab7b0d5fd5a0ecbdbda416e05" translate="yes" xml:space="preserve">
          <source>Next, we will split our dataset to use 90% for training and leave the rest for testing. We will also set the regression model parameters. You can play with these parameters to see how the results change.</source>
          <target state="translated">接下来,我们将对数据集进行拆分,将90%的数据用于训练,剩下的数据用于测试。我们还将设置回归模型参数。你可以玩玩这些参数,看看结果如何变化。</target>
        </trans-unit>
        <trans-unit id="cedfa60674e3afd543975ecc551b601711fc3043" translate="yes" xml:space="preserve">
          <source>Nick Street</source>
          <target state="translated">尼克街</target>
        </trans-unit>
        <trans-unit id="91b4478e43e149a2b1b071a76d13f7593530f726" translate="yes" xml:space="preserve">
          <source>No measurement errors, only modelling errors (fitting a sine with a polynomial)</source>
          <target state="translated">没有测量误差,只有建模误差(用多项式拟合正弦)。</target>
        </trans-unit>
        <trans-unit id="53e801c8ef7a5f95a28c0516586238c464a24031" translate="yes" xml:space="preserve">
          <source>No penalty (&amp;lsquo;none&amp;rsquo;)</source>
          <target state="translated">没有罚款（&amp;ldquo;无&amp;rdquo;）</target>
        </trans-unit>
        <trans-unit id="ea249cedbd757dbfa8a8d6da523734c90b706a5c" translate="yes" xml:space="preserve">
          <source>No-op.</source>
          <target state="translated">No-op.</target>
        </trans-unit>
        <trans-unit id="91eb5693ecb00a7deb087fb78e26bb4414167d8c" translate="yes" xml:space="preserve">
          <source>Noisy (non informative) features are added to the iris data and univariate feature selection is applied. For each feature, we plot the p-values for the univariate feature selection and the corresponding weights of an SVM. We can see that univariate feature selection selects the informative features and that these have larger SVM weights.</source>
          <target state="translated">在虹膜数据中添加有噪声(非信息)特征,并应用单变量特征选择。对于每个特征,我们绘制了单变量特征选择的p值和SVM的相应权重。我们可以看到,单变量特征选择选择了信息性特征,而且这些特征的SVM权重较大。</target>
        </trans-unit>
        <trans-unit id="7bfbed76958c0127f9523f9a22b3af54ca060586" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{jk}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">非度量&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;专注于数据的排序。如果\（S_ {ij} &amp;lt;S_ {jk} \），则嵌入应强制执行\（d_ {ij} &amp;lt;d_ {jk} \）。一个简单的强制算法是在\（S_ {ij} \）上使用\（d_ {ij} \）的单调回归，以相同顺序产生视差\（\ hat {d} _ {ij} \）为\（S_ {ij} \）。</target>
        </trans-unit>
        <trans-unit id="79474361fd46a8f4ede8053ea7e6b01fe3e41cb6" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{kl}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">非度量&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;专注于数据的排序。如果\（S_ {ij} &amp;lt;S_ {kl} \），则嵌入应强制执行\（d_ {ij} &amp;lt;d_ {jk} \）。一个简单的强制算法是在\（S_ {ij} \）上使用\（d_ {ij} \）的单调回归，以相同顺序产生视差\（\ hat {d} _ {ij} \）为\（S_ {ij} \）。</target>
        </trans-unit>
        <trans-unit id="cde06657a13db59e2826469e9066556199cf0756" translate="yes" xml:space="preserve">
          <source>Non-Negative Matrix Factorization (NMF)</source>
          <target state="translated">非负矩阵分解(NMF)</target>
        </trans-unit>
        <trans-unit id="68976e33a3c8d43b10cc9525f441a8468ba55fa6" translate="yes" xml:space="preserve">
          <source>Non-adjusted measures such as the V-Measure show a dependency between the number of clusters and the number of samples: the mean V-Measure of random labeling increases significantly as the number of clusters is closer to the total number of samples used to compute the measure.</source>
          <target state="translated">非调整措施,如V-Measure,显示出聚类数量和样本数量之间的依赖性:随机标签的平均V-Measure随着聚类数量接近用于计算措施的样本总数而显著增加。</target>
        </trans-unit>
        <trans-unit id="f88076515287321d1c6a383215ea60241a35e283" translate="yes" xml:space="preserve">
          <source>Non-categorical features are always stacked to the right of the matrix.</source>
          <target state="translated">非分类特征总是堆积在矩阵的右边。</target>
        </trans-unit>
        <trans-unit id="24a06b494b2c3f21a83a9f0f9fdd0eb49c7e8dca" translate="yes" xml:space="preserve">
          <source>Non-deterministic iterable over random candidate combinations for hyper- parameter search. If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">超参数搜索的非确定性可迭代过随机候选组合。如果所有的参数都是以列表的形式出现,则采用无替换的抽样方式。如果至少有一个参数是以分布形式给出的,则采用带替换的抽样。对于连续参数,强烈建议使用连续分布。</target>
        </trans-unit>
        <trans-unit id="aed22ef611faa3f82d0b12f8491e5be1b5315c9c" translate="yes" xml:space="preserve">
          <source>Non-flat geometry clustering is useful when the clusters have a specific shape, i.e. a non-flat manifold, and the standard euclidean distance is not the right metric. This case arises in the two top rows of the figure above.</source>
          <target state="translated">非平面几何聚类在聚类具有特定形状,即非平面歧面,而标准欧氏距离不是正确的度量时,是很有用的。这种情况出现在上图最上面的两行中。</target>
        </trans-unit>
        <trans-unit id="d81a98cb7a8247dec56f2cf029b08c2754ab68be" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes</source>
          <target state="translated">非平坦的几何形状,不均匀的群集大小。</target>
        </trans-unit>
        <trans-unit id="e75d67cb225b885154dd48c75a213bc3e9636016" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes, variable cluster density</source>
          <target state="translated">非平坦的几何形状,不均匀的集群大小,可变的集群密度。</target>
        </trans-unit>
        <trans-unit id="7b7727887cb8285fcb9cde529e76207a2b5daf47" translate="yes" xml:space="preserve">
          <source>Non-linear SVM</source>
          <target state="translated">非线性SVM</target>
        </trans-unit>
        <trans-unit id="71ce2ef9edaad67f892b761574c731b5860fa36a" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through Isometric Mapping</source>
          <target state="translated">通过等距映射减少非线性尺寸</target>
        </trans-unit>
        <trans-unit id="ca7d812e2ac6b7f89b19c50d5270fc422c0be019" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through the use of kernels (see &lt;a href=&quot;../metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt;).</source>
          <target state="translated">通过使用内核减少非线性维数（请参阅&lt;a href=&quot;../metrics#metrics&quot;&gt;成对度量，亲和力和内核&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="69451865a7cd1607229864b3445a0d944d36c962" translate="yes" xml:space="preserve">
          <source>Non-negative Matrix Factorization is applied with two different objective functions: the Frobenius norm, and the generalized Kullback-Leibler divergence. The latter is equivalent to Probabilistic Latent Semantic Indexing.</source>
          <target state="translated">非负矩阵因子化应用了两个不同的目标函数:Frobenius norm,和广义Kullback-Leibler分歧。后者相当于概率性潜在语义索引(Probabilistic Latent Semantic Indexing)。</target>
        </trans-unit>
        <trans-unit id="049d9a61285421f1af788bdccc4c4d917a5eaaf1" translate="yes" xml:space="preserve">
          <source>Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.</source>
          <target state="translated">在协方差的对角线上加上非负的正则化。可以保证协方差矩阵都是正值。</target>
        </trans-unit>
        <trans-unit id="e703a00863d9d81a02bf7dd7a3e8359867bf5db3" translate="yes" xml:space="preserve">
          <source>Non-negativity: d(x, y) &amp;gt;= 0</source>
          <target state="translated">非负性：d（x，y）&amp;gt; = 0</target>
        </trans-unit>
        <trans-unit id="8ae68d0948137da9bc3c21e9e27af7e4326ecb8c" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that assign all classes members to the same clusters are still complete:</source>
          <target state="translated">非完美的标签,将所有的类成员分配到同一个簇中,仍然是完整的。</target>
        </trans-unit>
        <trans-unit id="3eebc1d955c5491410d251396ee4489d9155e3cb" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that further split classes into more clusters can be perfectly homogeneous:</source>
          <target state="translated">非完美的标签,进一步将类分成更多的簇,可以是完全同质的。</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="cc144a8b86207cd903656d8b31d75d721fe9dfb7" translate="yes" xml:space="preserve">
          <source>None : retain all features (the default).</source>
          <target state="translated">无:保留所有功能(默认)。</target>
        </trans-unit>
        <trans-unit id="ff2ddb49167696f5a698e9f0e7cdd839b8eb8d6f" translate="yes" xml:space="preserve">
          <source>None : when any outlier is detected, ValueError will be raised.</source>
          <target state="translated">无:当检测到任何异常值时,将引发ValueError。</target>
        </trans-unit>
        <trans-unit id="a7d85d18152a49d1da74509ce25fde6fe11019f7" translate="yes" xml:space="preserve">
          <source>None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs</source>
          <target state="translated">无,在这种情况下,所有作业都会被立即创建和生成。对于轻量级和快速运行的作业,可使用此选项,以避免因按需生成作业而造成延迟。</target>
        </trans-unit>
        <trans-unit id="bbd7e8e517d8f43bda3aa20760641b5d7e8f9cfa" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross validation,</source>
          <target state="translated">无,使用默认的3倍交叉验证。</target>
        </trans-unit>
        <trans-unit id="888271bd46afcca7669b4e3985d515e3c7e7f9d8" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross-validation,</source>
          <target state="translated">无,使用默认的3倍交叉验证。</target>
        </trans-unit>
        <trans-unit id="13182ccf32b1d9cf4c4c76a99a35a2cf619a1e90" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross validation,</source>
          <target state="translated">无,使用默认的5次交叉验证。</target>
        </trans-unit>
        <trans-unit id="93be41b6686f4cc42a91be2da8610759134def66" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross-validation,</source>
          <target state="translated">无,使用默认的5倍交叉验证。</target>
        </trans-unit>
        <trans-unit id="701ee91f692f57554848e1c6f0edff54e4f7d839" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation</source>
          <target state="translated">无,使用高效的留一漏一交叉验证。</target>
        </trans-unit>
        <trans-unit id="d7a547edfb07309939d3c23d0b3c605eac4c310a" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation (also known as Generalized Cross-Validation).</source>
          <target state="translated">无,要使用高效的留一漏一交叉验证(又称广义交叉验证)。</target>
        </trans-unit>
        <trans-unit id="eb8094c10799533f02930dac24b80933c23d4beb" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt; n_features, otherwise &amp;lsquo;random&amp;rsquo;.</source>
          <target state="translated">无：如果n_components &amp;lt;n_features个，则为'nndsvd'，否则为'random'。</target>
        </trans-unit>
        <trans-unit id="ac08cb5e83064548a9a5dbf3f70202653e682537" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt;= min(n_samples, n_features),</source>
          <target state="translated">无：如果n_components &amp;lt;= min（n_samples，n_features），则为'nndsvd'，</target>
        </trans-unit>
        <trans-unit id="64b167835d86e0f7a116b1ea8c9009b09567d9bf" translate="yes" xml:space="preserve">
          <source>None: no shrinkage (default).</source>
          <target state="translated">无:无收缩(默认)。</target>
        </trans-unit>
        <trans-unit id="147e773e8ccd784cf7c8200779acc5978ecfc7ee" translate="yes" xml:space="preserve">
          <source>Nonflavanoid Phenols:</source>
          <target state="translated">非黄酮类酚类。</target>
        </trans-unit>
        <trans-unit id="906dd4b97159051d3691e718b04ffdc7a18ebb83" translate="yes" xml:space="preserve">
          <source>Nonflavanoid phenols</source>
          <target state="translated">非黄酮类酚类</target>
        </trans-unit>
        <trans-unit id="c5cf58c1ab6a436b96c0b6790ce2675b3d6917ee" translate="yes" xml:space="preserve">
          <source>Norm used to normalize term vectors. None for no normalization.</source>
          <target state="translated">用来归一化术语向量的规范。无表示不进行归一化。</target>
        </trans-unit>
        <trans-unit id="45e118d0563ea8581f830f46e85b60ae714faae4" translate="yes" xml:space="preserve">
          <source>Normal</source>
          <target state="translated">Normal</target>
        </trans-unit>
        <trans-unit id="baeabcda0198bd70ffaabb333ee49b38a8e0ee34" translate="yes" xml:space="preserve">
          <source>Normal and Shrinkage Linear Discriminant Analysis for classification</source>
          <target state="translated">用于分类的正态和收缩线性判别分析。</target>
        </trans-unit>
        <trans-unit id="1c651aee92e671db7fa9048c6cdacbd12ea197da" translate="yes" xml:space="preserve">
          <source>Normalization matrix needed for embedding. Square root of the kernel matrix on &lt;code&gt;components_&lt;/code&gt;.</source>
          <target state="translated">嵌入所需的规范化矩阵。 &lt;code&gt;components_&lt;/code&gt; _上内核矩阵的平方根。</target>
        </trans-unit>
        <trans-unit id="b2dd009a742549bee9ad100542b0f67ba3a05708" translate="yes" xml:space="preserve">
          <source>Normalize samples individually to unit norm.</source>
          <target state="translated">将样本单独归一化为单位正态。</target>
        </trans-unit>
        <trans-unit id="1cc78071dce653cdb1a895ced93da41b36798ab2" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information</source>
          <target state="translated">归一化相互信息</target>
        </trans-unit>
        <trans-unit id="6d15c4ae0d04e936f901929872b9ad476ca9800b" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information (NMI) is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by some generalized mean of &lt;code&gt;H(labels_true)&lt;/code&gt; and &lt;code&gt;H(labels_pred))&lt;/code&gt;, defined by the &lt;code&gt;average_method&lt;/code&gt;.</source>
          <target state="translated">标准化互信息（NMI）是互信息（MI）分数的归一化，可在0（无互信息）和1（完美相关）之间缩放结果。在此函数中，互信息通过 &lt;code&gt;H(labels_true)&lt;/code&gt; 和 &lt;code&gt;H(labels_pred))&lt;/code&gt; 的一些广义均值归一化，均值由 &lt;code&gt;average_method&lt;/code&gt; 定义。</target>
        </trans-unit>
        <trans-unit id="2009d38e6ab058cf38d5f44a4aa1fda0316b3372" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information between two clusterings.</source>
          <target state="translated">两个聚类之间的归一化互信息。</target>
        </trans-unit>
        <trans-unit id="4f7979e77b9a0db2d6d4f14823a6b0012cc9a130" translate="yes" xml:space="preserve">
          <source>Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</source>
          <target state="translated">归一化的剪切和图像分割，2000年Jianbo Shi，Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bcdc09e5b38e3433007fe04c41bf1718c142c846" translate="yes" xml:space="preserve">
          <source>Normalized input X.</source>
          <target state="translated">归一化输入X。</target>
        </trans-unit>
        <trans-unit id="cf0305ad6a5172727382b32897870cffde3ce433" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels</source>
          <target state="translated">各类标签的归一化概率分布</target>
        </trans-unit>
        <trans-unit id="53f158b7f3551b0f974a1547fdea15ef3000e7be" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels.</source>
          <target state="translated">各类标签的归一化概率分布。</target>
        </trans-unit>
        <trans-unit id="3dd51ff507e0ed7c736dd049baf65846cc243ec4" translate="yes" xml:space="preserve">
          <source>Normalized total reduction of criteria by feature (Gini importance).</source>
          <target state="translated">按特征归一化的标准总减量(基尼重要性)。</target>
        </trans-unit>
        <trans-unit id="f4b126cd68b1eba9b799b0ffccc1898e8bfe924f" translate="yes" xml:space="preserve">
          <source>Normalizer</source>
          <target state="translated">Normalizer</target>
        </trans-unit>
        <trans-unit id="2b3ec4d083535b907de33251ab28d9b72b55d74b" translate="yes" xml:space="preserve">
          <source>Normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. If None, confusion matrix will not be normalized.</source>
          <target state="translated">归一化真实(行)、预测(列)条件或所有人群的混淆矩阵。如果为 &quot;无&quot;,则不对混淆矩阵进行归一化处理。</target>
        </trans-unit>
        <trans-unit id="a19366221588f526c166820c530dd8f2268ea2b7" translate="yes" xml:space="preserve">
          <source>Not all models benefit from optimized BLAS and Lapack implementations. For instance models based on (randomized) decision trees typically do not rely on BLAS calls in their inner loops, nor do kernel SVMs (&lt;code&gt;SVC&lt;/code&gt;, &lt;code&gt;SVR&lt;/code&gt;, &lt;code&gt;NuSVC&lt;/code&gt;, &lt;code&gt;NuSVR&lt;/code&gt;). On the other hand a linear model implemented with a BLAS DGEMM call (via &lt;code&gt;numpy.dot&lt;/code&gt;) will typically benefit hugely from a tuned BLAS implementation and lead to orders of magnitude speedup over a non-optimized BLAS.</source>
          <target state="translated">并非所有模型都受益于优化的BLAS和Lapack实施。例如，基于（随机）决策树的模型通常不依赖于其内部循环中的BLAS调用，也不依赖于内核SVM（ &lt;code&gt;SVC&lt;/code&gt; ， &lt;code&gt;SVR&lt;/code&gt; ， &lt;code&gt;NuSVC&lt;/code&gt; ， &lt;code&gt;NuSVR&lt;/code&gt; ）。另一方面，通过BLAS DGEMM调用（通过 &lt;code&gt;numpy.dot&lt;/code&gt; ）实现的线性模型通常会从调整后的BLAS实现中受益匪浅，并会比未优化的BLAS提速几个数量级。</target>
        </trans-unit>
        <trans-unit id="d1a17af19f5388af9d6596cc0ea7dbb1d739e255" translate="yes" xml:space="preserve">
          <source>Not available</source>
          <target state="translated">未提供</target>
        </trans-unit>
        <trans-unit id="2f1306ffef95e5ddbb8f4b2f3a60c6ede1c9a1f3" translate="yes" xml:space="preserve">
          <source>Not scalable</source>
          <target state="translated">不可扩展</target>
        </trans-unit>
        <trans-unit id="6671bcf801635373715efa03216b0f9d13f34c22" translate="yes" xml:space="preserve">
          <source>Not scalable with &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; 使用n_samples进行扩展</target>
        </trans-unit>
        <trans-unit id="d70eb56b501fa2ef808df1c818502bbb5b800d19" translate="yes" xml:space="preserve">
          <source>Not scalable with n_samples</source>
          <target state="translated">不能扩展n_samples</target>
        </trans-unit>
        <trans-unit id="5f0f2378acb52b70e08107dc0bdd42ae2edf4fdf" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistence purpose.</source>
          <target state="translated">未使用,为API一致性目的而存在。</target>
        </trans-unit>
        <trans-unit id="3c8ec850c7c26d11c7ae99e5fae0ce11ac404b3f" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistency by convention.</source>
          <target state="translated">未使用,按惯例为API一致性而存在。</target>
        </trans-unit>
        <trans-unit id="abfeb2bc66d46ae118c694d4f663b42a0b277b39" translate="yes" xml:space="preserve">
          <source>Not used, present here for API consistency by convention.</source>
          <target state="translated">没有使用,这里是为了约定的API一致性。</target>
        </trans-unit>
        <trans-unit id="3f8740a7ea28a56477d25ad1aaaf52d864b49a7d" translate="yes" xml:space="preserve">
          <source>NotFittedError</source>
          <target state="translated">NotFittedError</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="14ba06ae5f3993adde2848620bcf508016c9c617" translate="yes" xml:space="preserve">
          <source>Note : Laplacian Eigenmaps is the actual algorithm implemented here.</source>
          <target state="translated">注:Laplacian Eigenmaps是这里实现的实际算法。</target>
        </trans-unit>
        <trans-unit id="21546711de316cf946ba53a498f41ae0550616cc" translate="yes" xml:space="preserve">
          <source>Note how some use the group/class information while others do not.</source>
          <target state="translated">请注意有些人如何使用组/类信息,而有些人则没有。</target>
        </trans-unit>
        <trans-unit id="c3c271844b997675d3bb1a8d39599227fbe7b490" translate="yes" xml:space="preserve">
          <source>Note how the optimal value of alpha varies for each fold. This illustrates why nested-cross validation is necessary when trying to evaluate the performance of a method for which a parameter is chosen by cross-validation: this choice of parameter may not be optimal for unseen data.</source>
          <target state="translated">请注意每个褶皱的α的最佳值是如何变化的。这说明了为什么在试图评估一个通过交叉验证选择参数的方法的性能时,嵌套交叉验证是必要的:这种参数的选择对于未见数据来说可能不是最优的。</target>
        </trans-unit>
        <trans-unit id="92e53ea7bdcc226c7bc1da5197dd56da468b26d1" translate="yes" xml:space="preserve">
          <source>Note on inappropriate usage of cross_val_predict</source>
          <target state="translated">关于不恰当使用cross_val_predict的说明。</target>
        </trans-unit>
        <trans-unit id="b437e168efe2a06e08f52a3ad3a931f217ecf431" translate="yes" xml:space="preserve">
          <source>Note on notations presented in the graphical model above, which can be found in Hoffman et al. (2013):</source>
          <target state="translated">关于上述图形模型中提出的注解,可参见Hoffman等(2013)。</target>
        </trans-unit>
        <trans-unit id="029f2db65bc50c936edb77149f903f8d03abd995" translate="yes" xml:space="preserve">
          <source>Note on the lookup process: depending on the type of name_or_id, will choose between integer id lookup or metadata name lookup by looking at the unzipped archives and metadata file.</source>
          <target state="translated">查找过程中的注意点:根据name_or_id的类型,将通过查看解压后的存档和元数据文件,选择整数id查找或元数据名称查找。</target>
        </trans-unit>
        <trans-unit id="637677b94f16fb377d9bcfbae4602956aad7da33" translate="yes" xml:space="preserve">
          <source>Note that &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</source>
          <target state="translated">请注意，只有在比例大致相同的要素上才能确保&amp;ldquo; sag&amp;rdquo;和&amp;ldquo; saga&amp;rdquo;快速收敛。您可以使用sklearn.preprocessing中的缩放器对数据进行预处理。</target>
        </trans-unit>
        <trans-unit id="92f3fcd7326295f6a74b7d0528bb22c0cf404ba4" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsregressor#sklearn.neighbors.KNeighborsRegressor&quot;&gt;&lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt;&lt;/a&gt; is different from KNN imputation, which learns from samples with missing values by using a distance metric that accounts for missing values, rather than imputing them.</source>
          <target state="translated">请注意，&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsregressor#sklearn.neighbors.KNeighborsRegressor&quot;&gt; &lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt; &lt;/a&gt;与KNN插补不同，后者通过使用考虑缺失值而不是插补值的距离度量从缺失值的样本中学习。</target>
        </trans-unit>
        <trans-unit id="bfc6f56d0d9af5825aa3c5bc1de0fcc87a2bde36" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; calculates unadjusted R&amp;sup2; without correcting for bias in sample variance of y.</source>
          <target state="translated">注意，&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt;计算未经调整的R&amp;sup2;，而无需校正y样本方差的偏差。</target>
        </trans-unit>
        <trans-unit id="fb2d865fbf24560bc423d4932883d3877000a02a" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; does not support &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods by default but only a &lt;code&gt;fit_predict&lt;/code&gt; method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">请注意，默认情况下，&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;不支持 &lt;code&gt;predict&lt;/code&gt; ， &lt;code&gt;decision_function&lt;/code&gt; 和 &lt;code&gt;score_samples&lt;/code&gt; 方法，而仅支持 &lt;code&gt;fit_predict&lt;/code&gt; 方法，因为该估算器最初是用于异常值检测的。可以通过 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性访问训练样本的异常分数。</target>
        </trans-unit>
        <trans-unit id="c2b0ede00caa9f24f249766b854d734ce8a77594" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;estimators_&lt;/code&gt; are fitted on the full &lt;code&gt;X&lt;/code&gt; while &lt;code&gt;final_estimator_&lt;/code&gt; is trained using cross-validated predictions of the base estimators using &lt;code&gt;cross_val_predict&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;estimators_&lt;/code&gt; 拟合在完整的 &lt;code&gt;X&lt;/code&gt; 上,而 &lt;code&gt;final_estimator_&lt;/code&gt; 是使用cross_val_predict使用基础估计量的交叉验证预测来 &lt;code&gt;cross_val_predict&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9cc23e915eab7d76b355d3d788a42c200a9cfa75" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;fit_predict&lt;/code&gt; is not available in this case.</source>
          <target state="translated">请注意，在这种情况下， &lt;code&gt;fit_predict&lt;/code&gt; 不可用。</target>
        </trans-unit>
        <trans-unit id="a64277fe0445c7a49bb63f1b3128c36db8f44687" translate="yes" xml:space="preserve">
          <source>Note that &lt;strong&gt;early-stopping is enabled by default if the number of samples is larger than 10,000&lt;/strong&gt;. The early-stopping behaviour is controlled via the &lt;code&gt;early-stopping&lt;/code&gt;, &lt;code&gt;scoring&lt;/code&gt;, &lt;code&gt;validation_fraction&lt;/code&gt;, &lt;code&gt;n_iter_no_change&lt;/code&gt;, and &lt;code&gt;tol&lt;/code&gt; parameters. It is possible to early-stop using an arbitrary &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scorer&quot;&gt;scorer&lt;/a&gt;, or just the training or validation loss. Note that for technical reasons, using a scorer is significantly slower than using the loss. By default, early-stopping is performed if there are at least 10,000 samples in the training set, using the validation loss.</source>
          <target state="translated">请注意，&lt;strong&gt;如果样本数大于10,000，则默认情况下会启用提前停止&lt;/strong&gt;。早期停止行为是通过 &lt;code&gt;early-stopping&lt;/code&gt; ， &lt;code&gt;scoring&lt;/code&gt; ， &lt;code&gt;validation_fraction&lt;/code&gt; ， &lt;code&gt;n_iter_no_change&lt;/code&gt; 和 &lt;code&gt;tol&lt;/code&gt; 参数进行控制的。有可能提前停止使用任意计&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scorer&quot;&gt;分器&lt;/a&gt;，或者只是停止训练或验证损失。请注意，出于技术原因，使用计分器比使用损失慢得多。默认情况下，如果训练集中至少有10,000个样本，则使用验证损失执行提前停止。</target>
        </trans-unit>
        <trans-unit id="05da1e73517821e307ab23620f26a2cb5cf58320" translate="yes" xml:space="preserve">
          <source>Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.</source>
          <target state="translated">需要注意的是,稀疏PCA成分的正交性并不像PCA那样被强制执行,因此不能使用简单的线性投影。</target>
        </trans-unit>
        <trans-unit id="6d11171b334a15c9f3a0ed71d47a8e76e15de782" translate="yes" xml:space="preserve">
          <source>Note that a call to the &lt;code&gt;transform&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; is not allowed to change the number of samples. Therefore multiple imputations cannot be achieved by a single call to &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">请注意，不允许调用&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;transform&lt;/code&gt; 方法来更改样本数。因此，不能通过单次调用 &lt;code&gt;transform&lt;/code&gt; 来实现多个插补。</target>
        </trans-unit>
        <trans-unit id="38919ec8aa75d45b22406b99670380fbc01ee90e" translate="yes" xml:space="preserve">
          <source>Note that all classifiers handling multioutput-multiclass (also known as multitask classification) tasks, support the multilabel classification task as a special case. Multitask classification is similar to the multioutput classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="translated">需要注意的是,所有处理多输出-多分类(也称为多任务分类)任务的分类器,都支持作为特例的多标签分类任务。多任务分类与多输出分类任务类似,但模型公式不同。更多信息,请参阅相关估计器文档。</target>
        </trans-unit>
        <trans-unit id="3a04205581b19a745020f7a71bf7734034b648ca" translate="yes" xml:space="preserve">
          <source>Note that backwards compatibility may not be supported.</source>
          <target state="translated">请注意,可能不支持向后兼容。</target>
        </trans-unit>
        <trans-unit id="8a36ac6808e625c8a29705bcc1d1fb6cf63760b8" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space.</source>
          <target state="translated">请注意，在SciPy 0.16之前， &lt;code&gt;scipy.stats.distributions&lt;/code&gt; 不接受自定义RNG实例，并且始终使用 &lt;code&gt;numpy.random&lt;/code&gt; 中的单例RNG 。因此，每当使用 &lt;code&gt;scipy.stats&lt;/code&gt; 分布来定义参数搜索空间时，设置 &lt;code&gt;random_state&lt;/code&gt; 将不能保证确定性迭代。</target>
        </trans-unit>
        <trans-unit id="9a716693e5778e1463e7644515aedc4c9b2a1b82" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space. Deterministic behavior is however guaranteed from SciPy 0.16 onwards.</source>
          <target state="translated">请注意，在SciPy 0.16之前， &lt;code&gt;scipy.stats.distributions&lt;/code&gt; 不接受自定义RNG实例，并且始终使用 &lt;code&gt;numpy.random&lt;/code&gt; 中的单例RNG 。因此，每当使用 &lt;code&gt;scipy.stats&lt;/code&gt; 分布来定义参数搜索空间时，设置 &lt;code&gt;random_state&lt;/code&gt; 将不能保证确定性迭代。但是，从SciPy 0.16起可以保证确定性行为。</target>
        </trans-unit>
        <trans-unit id="8803233984e598253564c68adac3c470cc868526" translate="yes" xml:space="preserve">
          <source>Note that even for a classification task, the \(h_m\) sub-estimator is still a regressor, not a classifier. This is because the sub-estimators are trained to predict (negative) &lt;em&gt;gradients&lt;/em&gt;, which are always continuous quantities.</source>
          <target state="translated">请注意，即使对于分类任务，\（h_m \）子估计量仍然是回归变量，而不是分类变量。这是因为训练了子估计量以预测（负）&lt;em&gt;梯度&lt;/em&gt;，该&lt;em&gt;梯度&lt;/em&gt;始终是连续量。</target>
        </trans-unit>
        <trans-unit id="45e5cb26ef2b019b9c0f33d27cd0fca50cc9bb8f" translate="yes" xml:space="preserve">
          <source>Note that for any single value of &lt;code&gt;eps&lt;/code&gt;, DBSCAN will tend to have a shorter run time than OPTICS; however, for repeated runs at varying &lt;code&gt;eps&lt;/code&gt; values, a single run of OPTICS may require less cumulative runtime than DBSCAN. It is also important to note that OPTICS&amp;rsquo; output is close to DBSCAN&amp;rsquo;s only if &lt;code&gt;eps&lt;/code&gt; and &lt;code&gt;max_eps&lt;/code&gt; are close.</source>
          <target state="translated">注意，对于任何单个 &lt;code&gt;eps&lt;/code&gt; 值，DBSCAN的运行时间往往比OPTICS短。但是，对于以不同 &lt;code&gt;eps&lt;/code&gt; 值重复运行，一次OPTICS可能需要的累积运行时间少于DBSCAN。同样重要的是要注意，只有在 &lt;code&gt;eps&lt;/code&gt; 和 &lt;code&gt;max_eps&lt;/code&gt; 接近时，OPTICS的输出才接近DBSCAN的输出。</target>
        </trans-unit>
        <trans-unit id="8c441ea193159e43e5ae4f2f43b7cd455bbc50a0" translate="yes" xml:space="preserve">
          <source>Note that for floating-point input, the mean is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for &lt;code&gt;float32&lt;/code&gt; (see example below). Specifying a higher-precision accumulator using the &lt;code&gt;dtype&lt;/code&gt; keyword can alleviate this issue.</source>
          <target state="translated">请注意，对于浮点输入，将使用与输入相同的精度来计算平均值。根据输入数据，这可能导致结果不准确，尤其是对于 &lt;code&gt;float32&lt;/code&gt; （请参见下面的示例）。使用 &lt;code&gt;dtype&lt;/code&gt; 关键字指定更高精度的累加器可以缓解此问题。</target>
        </trans-unit>
        <trans-unit id="1c1b3dcae0a3cdb049378b61a52e8a6e218b843e" translate="yes" xml:space="preserve">
          <source>Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].</source>
          <target state="translated">需要注意的是,对于多输出(包括多标签)的权重应该在自己的dict中为每一列的每个类定义。例如,对于四类多标签分类权重应该是[{0:1,1:1},{0:1,1:5},{0:1,1:1},{0:1,1:1}],而不是[{1:1},{2:5},{3:1},{4:1}]。</target>
        </trans-unit>
        <trans-unit id="7f057f4a3cfb222efbfc3fdf93e59924824aafce" translate="yes" xml:space="preserve">
          <source>Note that if features have very different scaling or statistical properties, &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; may not be able to capture the links between related features. Using a &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; can be useful in these settings.</source>
          <target state="translated">请注意，如果要素具有不同的缩放比例或统计属性，则&lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt; &lt;/a&gt;可能无法捕获相关要素之间的链接。在这些设置中，使用&lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="daa34c655040f11fbac2193226735416d5ff6724" translate="yes" xml:space="preserve">
          <source>Note that if the values of your similarity matrix are not well distributed, e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable. In which case it is advised to apply a transformation to the entries of the matrix. For instance, in the case of a signed distance matrix, is common to apply a heat kernel:</source>
          <target state="translated">请注意,如果你的相似度矩阵的值分布不均匀,例如负值或使用距离矩阵而不是相似度,那么光谱问题将是奇异的,问题无法解决。在这种情况下,建议对矩阵的条目进行变换。例如,在有符号距离矩阵的情况下,通常应用热核。</target>
        </trans-unit>
        <trans-unit id="82c5d12dd2770bc5d00d9e0fd296f522b36a2aec" translate="yes" xml:space="preserve">
          <source>Note that in binary classification, recall of the positive class is also known as &amp;ldquo;sensitivity&amp;rdquo;; recall of the negative class is &amp;ldquo;specificity&amp;rdquo;.</source>
          <target state="translated">请注意，在二元分类中，对阳性分类的记忆也称为&amp;ldquo;敏感性&amp;rdquo;。否定类别的回忆是&amp;ldquo;特异性&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="56700fbea0a4382f56515fac76889ee512c8d3cb" translate="yes" xml:space="preserve">
          <source>Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path</source>
          <target state="translated">请注意,在某些情况下,Lars求解器实现该功能的速度可能会快很多。特别是,线性插值可以用于检索lars_path输出值之间的模型系数</target>
        </trans-unit>
        <trans-unit id="c065b9ad388e273aa3b214ab1297a55e0496eb57" translate="yes" xml:space="preserve">
          <source>Note that in general, robust fitting in high-dimensional setting (large &lt;code&gt;n_features&lt;/code&gt;) is very hard. The robust models here will probably not work in these settings.</source>
          <target state="translated">请注意，通常，在高维设置（大 &lt;code&gt;n_features&lt;/code&gt; ）中进行鲁棒拟合非常困难。这里的健壮模型可能无法在这些设置下工作。</target>
        </trans-unit>
        <trans-unit id="64011c56ebca18074907020d8d3e99112269576a" translate="yes" xml:space="preserve">
          <source>Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important.</source>
          <target state="translated">需要注意的是,在实际操作中,人们不会同时使用网格搜索在这么多不同的参数上进行搜索,而是只选择那些认为最重要的参数。</target>
        </trans-unit>
        <trans-unit id="b7d16723edd6b0c8a445c16934e7dfaedb2752ae" translate="yes" xml:space="preserve">
          <source>Note that in the case of &amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo; and &amp;lsquo;euclidean&amp;rsquo; (which are valid scipy.spatial.distance metrics), the scikit-learn implementation will be used, which is faster and has support for sparse matrices (except for &amp;lsquo;cityblock&amp;rsquo;). For a verbose description of the metrics from scikit-learn, see the __doc__ of the sklearn.pairwise.distance_metrics function.</source>
          <target state="translated">请注意，对于&amp;ldquo; cityblock&amp;rdquo;，&amp;ldquo; cosine&amp;rdquo;和&amp;ldquo; euclidean&amp;rdquo;（它们是有效的scipy.spatial.distance指标），将使用scikit-learn实现，它实现得更快，并且支持稀疏矩阵（除了'城市街区'）。有关scikit-learn中指标的详细说明，请参见sklearn.pairwise.distance_metrics函数的__doc__。</target>
        </trans-unit>
        <trans-unit id="81154799705dfac8836df66f3a0269041db1173b" translate="yes" xml:space="preserve">
          <source>Note that in the multilabel case, each sample can have any number of labels. This returns the marginal probability that the given sample has the label in question. For example, it is entirely consistent that two labels both have a 90% probability of applying to a given sample.</source>
          <target state="translated">注意,在多标签的情况下,每个样本可以有任意数量的标签。这将返回给定样本拥有相关标签的边际概率。例如,两个标签都有90%的概率适用于给定样本,这是完全一致的。</target>
        </trans-unit>
        <trans-unit id="01d7bf1a38a1f2f757397967cae9b7d66ce2602c" translate="yes" xml:space="preserve">
          <source>Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):</source>
          <target state="translated">请注意,在前一个语料库中,第一个和最后一个文档有完全相同的词,因此被编码为相等的向量。尤其是我们失去了最后一个文档是问句形式的信息。为了保留一些局部的排序信息,我们可以在1-grams(单个单词)之外提取2-grams的单词。</target>
        </trans-unit>
        <trans-unit id="61d12fb0837cc546c2865fefff8f9a5fb5f27798" translate="yes" xml:space="preserve">
          <source>Note that it is also possible to get the output of the stacked &lt;code&gt;estimators&lt;/code&gt; using the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="translated">请注意，也可以使用 &lt;code&gt;transform&lt;/code&gt; 方法获取堆叠 &lt;code&gt;estimators&lt;/code&gt; 的输出：</target>
        </trans-unit>
        <trans-unit id="8dcb354ad6f05344d318f25389a442779bd42bda" translate="yes" xml:space="preserve">
          <source>Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.</source>
          <target state="translated">需要注意的是,通常情况下,这些参数中的一小部分会对模型的预测或计算性能产生很大影响,而其他参数可以保持默认值。建议阅读估计器类的docstring,可能通过阅读所附的文献参考资料,对它们的预期行为有更深入的了解。</target>
        </trans-unit>
        <trans-unit id="e39d258640f71b07567efcd3611fa0f4dfc35df8" translate="yes" xml:space="preserve">
          <source>Note that it is important to check that the model is accurate enough on a test set before plotting the partial dependence since there would be little use in explaining the impact of a given feature on the prediction function of a poor model.</source>
          <target state="translated">需要注意的是,在绘制部分依赖性之前,必须先检查模型在测试集上是否足够准确,因为在解释给定特征对差的模型的预测函数的影响时,没有什么用处。</target>
        </trans-unit>
        <trans-unit id="38e7c6473cb1417f0189c236d54733065555b837" translate="yes" xml:space="preserve">
          <source>Note that it maximizes both the correlations between the scores and the intra-block variances.</source>
          <target state="translated">请注意,它能使分数和块内方差之间的相关性最大化。</target>
        </trans-unit>
        <trans-unit id="7fe083a60697e58d27f138d9ea26d77a87096c53" translate="yes" xml:space="preserve">
          <source>Note that it maximizes only the correlations between the scores.</source>
          <target state="translated">请注意,它只最大化了分数之间的相关性。</target>
        </trans-unit>
        <trans-unit id="4ad685eaf7c64ded5f9210b1f3461deac7d47f1a" translate="yes" xml:space="preserve">
          <source>Note that monotonic constraints only constraint the output &amp;ldquo;all else being equal&amp;rdquo;. Indeed, the following relation &lt;strong&gt;is not enforced&lt;/strong&gt; by a positive constraint: \(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2')\).</source>
          <target state="translated">请注意，单调约束仅约束输出&amp;ldquo;其他所有条件均相等&amp;rdquo;。实际上，以下关系&lt;strong&gt;不是&lt;/strong&gt;由正约束来&lt;strong&gt;强制执行&lt;/strong&gt;的：\（x_1 \ leq x_1'\ imply F（x_1，x_2）\ leq F（x_1'，x_2'）\）。</target>
        </trans-unit>
        <trans-unit id="9b4460fdb66af9bc149af45e106adc5f1d493bbf" translate="yes" xml:space="preserve">
          <source>Note that noisy data can &amp;ldquo;short-circuit&amp;rdquo; the manifold, in essence acting as a bridge between parts of the manifold that would otherwise be well-separated. Manifold learning on noisy and/or incomplete data is an active area of research.</source>
          <target state="translated">请注意，嘈杂的数据可能会使歧管&amp;ldquo;短路&amp;rdquo;，本质上是充当歧管各部分之间的桥梁，否则这些部分将被很好地分离。在嘈杂和/或不完整的数据上进行流形学习是研究的活跃领域。</target>
        </trans-unit>
        <trans-unit id="cf4033d0f4ffad84f5c58c4e0d89634a33d57e14" translate="yes" xml:space="preserve">
          <source>Note that on this tabular dataset, Gradient Boosting Machines are both significantly faster to train and more accurate than neural networks. It is also significantly cheaper to tune their hyperparameters (the default tend to work well while this is not often the case for neural networks).</source>
          <target state="translated">请注意,在这个表格数据集上,梯度提升机的训练速度和准确度都明显高于神经网络。调整其超参数的成本也要低得多(默认值往往能很好地工作,而神经网络的情况往往不是这样)。</target>
        </trans-unit>
        <trans-unit id="67d5dd89ca82637aa1c574ab8cabbf8ba39e4cb8" translate="yes" xml:space="preserve">
          <source>Note that pickle has some security and maintainability issues. Please refer to section &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;Model persistence&lt;/a&gt; for more detailed information about model persistence with scikit-learn.</source>
          <target state="translated">请注意，泡菜存在一些安全性和可维护性问题。有关使用scikit-learn的模型持久&lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;性&lt;/a&gt;的更多详细信息，请参阅模型持久性部分。</target>
        </trans-unit>
        <trans-unit id="23cd95765d94c327b5282b4a1fe3e5dffe405a3a" translate="yes" xml:space="preserve">
          <source>Note that polynomial features are used implicitly in &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel methods&lt;/a&gt; (e.g., &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;sklearn.svm.SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt;&lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt;&lt;/a&gt;) when using polynomial &lt;a href=&quot;svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">注意，使用多项式&lt;a href=&quot;svm#svm-kernels&quot;&gt;内核函数&lt;/a&gt;时，多项式特征在&lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;内核方法&lt;/a&gt;（例如&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;sklearn.svm.SVC&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt; &lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt; &lt;/a&gt;）中隐式使用。</target>
        </trans-unit>
        <trans-unit id="675c6d53180ed2915c2b59bf4a0a0e8fbac69215" translate="yes" xml:space="preserve">
          <source>Note that providing &lt;code&gt;y&lt;/code&gt; is sufficient to generate the splits and hence &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; may be used as a placeholder for &lt;code&gt;X&lt;/code&gt; instead of actual training data.</source>
          <target state="translated">请注意，提供 &lt;code&gt;y&lt;/code&gt; 足以生成拆分，因此可以将 &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; 用作 &lt;code&gt;X&lt;/code&gt; 的占位符，而不是实际的训练数据。</target>
        </trans-unit>
        <trans-unit id="df4d1f63cde2c26d664594a284ce306040d06cfb" translate="yes" xml:space="preserve">
          <source>Note that shrinkage works only with &amp;lsquo;lsqr&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="translated">请注意，收缩仅适用于&amp;ldquo; lsqr&amp;rdquo;和&amp;ldquo;本征&amp;rdquo;求解器。</target>
        </trans-unit>
        <trans-unit id="dd7adf0d494ffc5bcd4e70266fd05b000aa00dcc" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format.</source>
          <target state="translated">请注意，&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt;函数仅限于二进制情况。该&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;功能只在二元分类和多标指标格式。</target>
        </trans-unit>
        <trans-unit id="8d400c4e81cd0336ee43fd779c1c25e212117f34" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format. The &lt;a href=&quot;generated/sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt;&lt;code&gt;plot_precision_recall_curve&lt;/code&gt;&lt;/a&gt; function plots the precision recall as follows.</source>
          <target state="translated">请注意，&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt;函数仅限于二进制情况。该&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;功能只在二元分类和多标指标格式。该&lt;a href=&quot;generated/sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt; &lt;code&gt;plot_precision_recall_curve&lt;/code&gt; &lt;/a&gt;函数图精度召回如下。</target>
        </trans-unit>
        <trans-unit id="651372cf76a2e0eca2cd0e2ced075f5cfd44a313" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt;&lt;code&gt;Binarizer&lt;/code&gt;&lt;/a&gt; is similar to the &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt;&lt;code&gt;KBinsDiscretizer&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;k = 2&lt;/code&gt;, and when the bin edge is at the value &lt;code&gt;threshold&lt;/code&gt;.</source>
          <target state="translated">注意，&lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt; &lt;code&gt;Binarizer&lt;/code&gt; &lt;/a&gt;是类似于&lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt; &lt;code&gt;KBinsDiscretizer&lt;/code&gt; &lt;/a&gt;当 &lt;code&gt;k = 2&lt;/code&gt; ，而当箱边缘处的值 &lt;code&gt;threshold&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="96049a1871e8f004cea40c870be340fc85046579" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer &lt;a href=&quot;#id18&quot; id=&quot;id1&quot;&gt;16&lt;/a&gt;, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">请注意，&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;还通过使用选项 &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; 实现了替代的多类策略，即由Crammer和Singer &lt;a href=&quot;#id18&quot; id=&quot;id1&quot;&gt;16&lt;/a&gt;制定的所谓多类SVM 。实际上，通常首选&amp;ldquo;一对多&amp;rdquo;分类，因为结果大多相似，但运行时间却少得多。</target>
        </trans-unit>
        <trans-unit id="b78ef718e6ed1cb354d8ff189ba4de9e4443cf71" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. This method is consistent, which is not true for one-vs-rest classification. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">请注意，&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;还通过使用选项 &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; 实现了替代的多类策略，即由Crammer和Singer制定的所谓多类SVM 。此方法是一致的，对于&amp;ldquo;一对休息&amp;rdquo;分类是不正确的。实际上，通常首选&amp;ldquo;一对多&amp;rdquo;分类，因为结果大多相似，但运行时间明显较少。</target>
        </trans-unit>
        <trans-unit id="6d0f75c58b62c96c540e90be5dd6446b78869fb4" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__add__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Sum(RBF(), RBF())&lt;/code&gt; is equivalent to using the + operator with &lt;code&gt;RBF() + RBF()&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;__add__&lt;/code&gt; 魔术方法已被覆盖，因此 &lt;code&gt;Sum(RBF(), RBF())&lt;/code&gt; 等效于将+运算符与 &lt;code&gt;RBF() + RBF()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="acd06ce9a0926c4eda997a94789bc82988610943" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__mul__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Product(RBF(), RBF())&lt;/code&gt; is equivalent to using the * operator with &lt;code&gt;RBF() * RBF()&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;__mul__&lt;/code&gt; magic方法被覆盖，因此 &lt;code&gt;Product(RBF(), RBF())&lt;/code&gt; 等效于将*运算符与 &lt;code&gt;RBF() * RBF()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d495fb41e55b7018b37ac27eeb250fbaf347d05a" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__pow__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Exponentiation(RBF(), 2)&lt;/code&gt; is equivalent to using the ** operator with &lt;code&gt;RBF() ** 2&lt;/code&gt;.</source>
          <target state="translated">请注意， &lt;code&gt;__pow__&lt;/code&gt; 魔术方法已被覆盖，因此 &lt;code&gt;Exponentiation(RBF(), 2)&lt;/code&gt; 等同于将**运算符与 &lt;code&gt;RBF() ** 2&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3a88b0087b5b199ea4beb800b3ce5a1f6c9022a8" translate="yes" xml:space="preserve">
          <source>Note that the Gini index only characterize the ranking performance of the model but not its calibration: any monotonic transformation of the predictions leaves the Gini index of the model unchanged.</source>
          <target state="translated">需要注意的是,基尼指数只能表征模型的排名性能,而不能表征模型的标定:任何预测的单调变换都会使模型的基尼指数不变。</target>
        </trans-unit>
        <trans-unit id="4b2885ce1a0d54c6be5b37dba1e7a9bea3c67ec1" translate="yes" xml:space="preserve">
          <source>Note that the Multiplicative Update (&amp;lsquo;mu&amp;rsquo;) solver cannot update zeros present in the initialization, so it leads to poorer results when used jointly with the basic NNDSVD algorithm which introduces a lot of zeros; in this case, NNDSVDa or NNDSVDar should be preferred.</source>
          <target state="translated">请注意，乘法更新（'mu'）求解器无法更新初始化中存在的零，因此与引入大量零的基本NNDSVD算法一起使用时，结果会更差。在这种情况下，应首选NNDSVDa或NNDSVDar。</target>
        </trans-unit>
        <trans-unit id="542b5d2a5a3926264004f7807400969fe48d422d" translate="yes" xml:space="preserve">
          <source>Note that the current implementation only supports regression estimators.</source>
          <target state="translated">请注意,目前的实现只支持回归估计器。</target>
        </trans-unit>
        <trans-unit id="7ac1e23398a8f2960b2ec6ee5eea4c00d3f041dd" translate="yes" xml:space="preserve">
          <source>Note that the dataset contains categorical and numerical variables. We will need to take this into account when preprocessing the dataset thereafter.</source>
          <target state="translated">请注意,数据集包含分类变量和数字变量。之后在对数据集进行预处理时,我们需要考虑到这一点。</target>
        </trans-unit>
        <trans-unit id="5878ce2fa9f81f5b0b2794d8ccb7e40e7db1917d" translate="yes" xml:space="preserve">
          <source>Note that the dict values can either be scorer functions or one of the predefined metric strings.</source>
          <target state="translated">请注意,dict值可以是scorer函数,也可以是预定义的度量字符串之一。</target>
        </trans-unit>
        <trans-unit id="a97f1f4d24f812e6f4b824a150b492f876f8dbe2" translate="yes" xml:space="preserve">
          <source>Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (&lt;code&gt;LinearSVC(dual=True)&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;PassiveAggressive&lt;/code&gt;) but it does for algorithms that work with CSC matrices (&lt;code&gt;LinearSVC(dual=False)&lt;/code&gt;, &lt;code&gt;Lasso()&lt;/code&gt;, etc).</source>
          <target state="translated">请注意，维度不会影响在CSR矩阵（ &lt;code&gt;LinearSVC(dual=True)&lt;/code&gt; ， &lt;code&gt;Perceptron&lt;/code&gt; ， &lt;code&gt;SGDClassifier&lt;/code&gt; ， &lt;code&gt;PassiveAggressive&lt;/code&gt; ）上运行的算法的CPU训练时间，但会影响与CSC矩阵一起使用的算法（ &lt;code&gt;LinearSVC(dual=False)&lt;/code&gt; ， &lt;code&gt;Lasso()&lt;/code&gt; 等）。</target>
        </trans-unit>
        <trans-unit id="435cce9f843df9a5bdcdf7f7022599966bcaee8d" translate="yes" xml:space="preserve">
          <source>Note that the estimate_bandwidth function is much less scalable than the mean shift algorithm and will be the bottleneck if it is used.</source>
          <target state="translated">需要注意的是,估计带宽函数的可扩展性远不如均值移动算法,如果使用该函数,将是瓶颈。</target>
        </trans-unit>
        <trans-unit id="bce829a8923d634c66b8b2d36d28916cd48e0ab9" translate="yes" xml:space="preserve">
          <source>Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels &lt;code&gt;fit&lt;/code&gt; upon. With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:</source>
          <target state="translated">需要注意的是第四和第五实例返回的所有零，这表明它们没有相匹配的三个标签 &lt;code&gt;fit&lt;/code&gt; 于。使用多标签输出，也可以为一个实例分配多个标签：</target>
        </trans-unit>
        <trans-unit id="21f39572b525862541f5e3b74bb03e06aac617ef" translate="yes" xml:space="preserve">
          <source>Note that the heat map plot has a special colorbar with a midpoint value close to the score values of the best performing models so as to make it easy to tell them apart in the blink of an eye.</source>
          <target state="translated">需要注意的是,热力图图中有一个特殊的色条,其中点值与表现最好的模型的得分值接近,以便于在眨眼间就能分辨出它们。</target>
        </trans-unit>
        <trans-unit id="8c847c9ef93d363951399eb5e5ddd91d785490b8" translate="yes" xml:space="preserve">
          <source>Note that the importance values for the top features represent a large fraction of the reference score of 0.356.</source>
          <target state="translated">请注意,顶级特征的重要性值占参考分数0.356的很大一部分。</target>
        </trans-unit>
        <trans-unit id="3f19bf1a17574ce6b7f5a8199cbb6b2ed04a3916" translate="yes" xml:space="preserve">
          <source>Note that the maximum likelihood estimate corresponds to no shrinkage, and thus performs poorly. The Ledoit-Wolf estimate performs really well, as it is close to the optimal and is computational not costly. In this example, the OAS estimate is a bit further away. Interestingly, both approaches outperform cross-validation, which is significantly most computationally costly.</source>
          <target state="translated">请注意,最大似然估计对应的是无收缩,因此表现很差。Ledoit-Wolf估计的表现非常好,因为它接近最优,而且计算成本不高。在这个例子中,OAS估计离得有点远。有趣的是,这两种方法的表现都优于交叉验证,而交叉验证的计算成本明显最高。</target>
        </trans-unit>
        <trans-unit id="be3cea96be539a6f36c7349851efbc1b4f539ceb" translate="yes" xml:space="preserve">
          <source>Note that the number of dimensions is independent of the original number of features but instead depends on the size of the dataset: the larger the dataset, the higher is the minimal dimensionality of an eps-embedding.</source>
          <target state="translated">请注意,维数与原始特征数无关,而是取决于数据集的大小:数据集越大,eps-embedding的最小维数越高。</target>
        </trans-unit>
        <trans-unit id="1426a0972df2ef3ae4847218faa4ab1a45e2a26b" translate="yes" xml:space="preserve">
          <source>Note that the parameter &lt;code&gt;alpha&lt;/code&gt; is applied as a Tikhonov regularization of the assumed covariance between the training points.</source>
          <target state="translated">请注意，参数 &lt;code&gt;alpha&lt;/code&gt; 用作训练点之间假定协方差的Tikhonov正则化。</target>
        </trans-unit>
        <trans-unit id="57bfd4549eb4e4a76c8eb0b9ddf20a2f4a52c8d2" translate="yes" xml:space="preserve">
          <source>Note that the precision may not decrease with recall. The definition of precision (\(\frac{T_p}{T_p + F_p}\)) shows that lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase precision. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing precision.</source>
          <target state="translated">请注意,精度可能不会随着召回率的提高而降低。精度的定义(\(frac{T_p}{T_p+F_p}\))表明,降低分类器的阈值可能会增加分母,通过增加返回的结果数量。如果之前的阈值设置得过高,新的结果可能都是真阳性,这将提高精度。如果之前的阈值差不多或太低,进一步降低阈值会引入假阳性,降低精度。</target>
        </trans-unit>
        <trans-unit id="07e181d114b5848fdd4cb0661edb49154d99e027" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the &lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space. Here the manifold problem matches fairly that of representing a flat map of the Earth, as with &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;map projection&lt;/a&gt;</source>
          <target state="translated">请注意，&lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt;的目的是找到数据的低维表示形式（此处为2D），其中距离很好地尊重了原始高维空间中的距离，这与其他流形学习算法不同，它不寻求低维空间中数据的各向同性表示。在这里，流形问题与表示地球平面图的问题相当匹配，就像&lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;地图投影一样&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="951ad93c2b6a49b38a3c4a8dabf905c9019bf128" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the MDS is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space.</source>
          <target state="translated">需要注意的是,MDS的目的是寻找数据的低维表示(这里是二维),其中的距离很好地尊重原高维空间中的距离,与其他显式学习算法不同的是,它并不寻求数据在低维空间中的同向表示。</target>
        </trans-unit>
        <trans-unit id="6c07e8b80629c5d24a4c78874f28fde4e1598ff3" translate="yes" xml:space="preserve">
          <source>Note that the resulting model is the average claim amount per claim. As such, it is conditional on having at least one claim, and cannot be used to predict the average claim amount per policy in general.</source>
          <target state="translated">请注意,得出的模型是每次索赔的平均索赔额。因此,它是以至少有一项索赔为条件的,不能用来预测每份保单的一般平均索赔额。</target>
        </trans-unit>
        <trans-unit id="faff2f13ccab498a5068027cb2f2891a11c4c2ca" translate="yes" xml:space="preserve">
          <source>Note that the scalers accept both Compressed Sparse Rows and Compressed Sparse Columns format (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; and &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt;). Any other sparse input will be &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt;. To avoid unnecessary memory copies, it is recommended to choose the CSR or CSC representation upstream.</source>
          <target state="translated">请注意，缩放器接受压缩的稀疏行和压缩的稀疏列格式（请参阅 &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; 和 &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt; ）。任何其他稀疏输入都将&lt;strong&gt;转换为&amp;ldquo;压缩稀疏行&amp;rdquo;表示形式&lt;/strong&gt;。为避免不必要的内存复制，建议选择上游的CSR或CSC表示形式。</target>
        </trans-unit>
        <trans-unit id="0ac4948c4f86990406e6391d28cab3438b2d6038" translate="yes" xml:space="preserve">
          <source>Note that the transformations successfully map the data to a normal distribution when applied to certain datasets, but are ineffective with others. This highlights the importance of visualizing the data before and after transformation.</source>
          <target state="translated">请注意,当应用于某些数据集时,转换成功地将数据映射到正态分布,但对其他数据集无效。这凸显了在转换前后对数据进行可视化的重要性。</target>
        </trans-unit>
        <trans-unit id="c025c974076c003b893079ae24539cfe87c45c45" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;code&gt;memory&lt;/code&gt; to enable caching becomes interesting when the fitting of a transformer is costly.</source>
          <target state="translated">请注意，当变压器的安装成本很高时，使用 &lt;code&gt;memory&lt;/code&gt; 来启用缓存就变得很有趣。</target>
        </trans-unit>
        <trans-unit id="e3bd8ce7db50d77dd828df23ba8a7913ea07b656" translate="yes" xml:space="preserve">
          <source>Note that there are many different formulations for the Sparse PCA problem. The one implemented here is based on &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]&lt;/a&gt; . The optimization problem solved is a PCA problem (dictionary learning) with an \(\ell_1\) penalty on the components:</source>
          <target state="translated">请注意，稀疏PCA问题有许多不同的表述。此处实现的是基于&lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]的&lt;/a&gt;。解决的优化问题是PCA问题（字典学习），对组件的惩罚为\（\ ell_1 \）：</target>
        </trans-unit>
        <trans-unit id="3533aed52b9c93cbfd7c732492e759ef81f9eff6" translate="yes" xml:space="preserve">
          <source>Note that there exist a lot of different clustering criteria and associated algorithms. The simplest clustering algorithm is &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;.</source>
          <target state="translated">请注意，存在许多不同的聚类标准和相关算法。最简单的聚类算法是&lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7a1a308b56337fe667b4a60765401b66807cafaf" translate="yes" xml:space="preserve">
          <source>Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.</source>
          <target state="translated">请注意,如果指定了 sample_weight,这些权重将与 sample_weight(通过拟合方法传递)相乘。</target>
        </trans-unit>
        <trans-unit id="523c4300803e2407441df32761d9ac234d32f175" translate="yes" xml:space="preserve">
          <source>Note that theta are typically the log-transformed values of the kernel&amp;rsquo;s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.</source>
          <target state="translated">请注意，&amp;theta;通常是内核超参数的对数转换值，因为搜索空间的这种表示形式更适合于超参数搜索，因为像长度标尺之类的超参数自然地生活在对数标尺上。</target>
        </trans-unit>
        <trans-unit id="18d756a791b41973e0843ab0a78a9e37c703da28" translate="yes" xml:space="preserve">
          <source>Note that this accuracy of this l1-penalized linear model is significantly below what can be reached by an l2-penalized linear model or a non-linear multi-layer perceptron model on this dataset.</source>
          <target state="translated">需要注意的是,这个l1-penalized线性模型的这个精度明显低于l2-penalized线性模型或非线性多层感知器模型在这个数据集上所能达到的精度。</target>
        </trans-unit>
        <trans-unit id="fe64330213465e1693b793ed059df249f5fb9ff2" translate="yes" xml:space="preserve">
          <source>Note that this component typically should not be used in a vanilla &lt;code&gt;Pipeline&lt;/code&gt; consisting of transformers and a classifier, but rather could be added using a &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt;.</source>
          <target state="translated">请注意，通常不应在由变压器和分类器组成的香草 &lt;code&gt;Pipeline&lt;/code&gt; 使用此组件，而应使用 &lt;code&gt;FeatureUnion&lt;/code&gt; 或 &lt;code&gt;ColumnTransformer&lt;/code&gt; 添加该组件。</target>
        </trans-unit>
        <trans-unit id="d1586f7c06fc3985d60451a7a19048e48e062430" translate="yes" xml:space="preserve">
          <source>Note that this compound kernel returns the results of all simple kernel stacked along an additional axis.</source>
          <target state="translated">需要注意的是,这个复合内核会返回所有简单内核沿一个附加轴堆叠的结果。</target>
        </trans-unit>
        <trans-unit id="31acdd30123a3b6dcbfca492a99f8cbc9dc2455a" translate="yes" xml:space="preserve">
          <source>Note that this computation of feature importance is based on entropy, and it is distinct from &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; which is based on permutation of the features.</source>
          <target state="translated">请注意，特征重要性的这种计算基于熵，并且与基于特征置换的&lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt; &lt;/a&gt;不同。</target>
        </trans-unit>
        <trans-unit id="70f8f8292a30b78b7e2885afabc408eef407b785" translate="yes" xml:space="preserve">
          <source>Note that this definition is not valid if \(\beta \in (0; 1)\), yet it can be continuously extended to the definitions of \(d_{KL}\) and \(d_{IS}\) respectively.</source>
          <target state="translated">请注意,如果(0;1)/)/)这个定义是不成立的,但它可以不断扩展到分别定义为(d_{KL}/)和(d_{IS}/)。</target>
        </trans-unit>
        <trans-unit id="7550e059eb4d092ae42a40cda726bb20131c9e24" translate="yes" xml:space="preserve">
          <source>Note that this estimator is different from the R implementation of Robust Regression (&lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt;) because the R implementation does a weighted least squares implementation with weights given to each sample on the basis of how much the residual is greater than a certain threshold.</source>
          <target state="translated">请注意，此估算器不同于R的鲁棒回归（&lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt;）实现，因为R实现了加权最小二乘实现，权重为每个样本都基于残差大于某个阈值的多少。</target>
        </trans-unit>
        <trans-unit id="5472d869ea9e0f8e4cfcc121937d62eb4599c58a" translate="yes" xml:space="preserve">
          <source>Note that this example is, however, only an illustration since for this specific case fitting PCA is not necessarily slower than loading the cache. Hence, use the &lt;code&gt;memory&lt;/code&gt; constructor parameter when the fitting of a transformer is costly.</source>
          <target state="translated">但是请注意，此示例仅是说明，因为在这种特定情况下，拟合PCA不一定比加载缓存慢。因此，当变压器的安装成本很高时，请使用 &lt;code&gt;memory&lt;/code&gt; 构造函数参数。</target>
        </trans-unit>
        <trans-unit id="1b5bac58d61d7142976dd586739448ed8787f73e" translate="yes" xml:space="preserve">
          <source>Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.</source>
          <target state="translated">请注意,这种格式不是用来隐式存储矩阵中的缺失值,因为它会在变换时使矩阵变稠。用0编码的缺失值必须与密集输入一起使用。</target>
        </trans-unit>
        <trans-unit id="ceed59ec0d8d185c9512413b150620f381e9c0c0" translate="yes" xml:space="preserve">
          <source>Note that this function does not regenerate the original data due to discretization rounding.</source>
          <target state="translated">请注意,由于离散化四舍五入,该函数不会再生原始数据。</target>
        </trans-unit>
        <trans-unit id="90f3882ef5e6cb2ec08d6d3659b834d53aaa84d9" translate="yes" xml:space="preserve">
          <source>Note that this gives us a different indication than the graph, as the graph reflects conditional relations between variables, while the clustering reflects marginal properties: variables clustered together can be considered as having a similar impact at the level of the full stock market.</source>
          <target state="translated">请注意,这给我们的指示与图表不同,因为图表反映的是变量之间的条件关系,而聚类反映的是边际属性:聚类在一起的变量可以被认为在完整的股票市场层面具有类似的影响。</target>
        </trans-unit>
        <trans-unit id="29fe04606c06b888c8ec9e6f0120963e08f606ce" translate="yes" xml:space="preserve">
          <source>Note that this is always a dense array.</source>
          <target state="translated">注意,这总是一个密集的数组。</target>
        </trans-unit>
        <trans-unit id="8400da57b096333e7a778582f2569282a236fe34" translate="yes" xml:space="preserve">
          <source>Note that this is stochastic, and that if random_state is not fixed, repeated calls, or permuted input, will yield different results.</source>
          <target state="translated">需要注意的是,这是随机的,如果random_state不固定,重复调用,或者permuted输入,会得到不同的结果。</target>
        </trans-unit>
        <trans-unit id="426217e7254990be151f425ed53a8b743a92e13d" translate="yes" xml:space="preserve">
          <source>Note that this two-dimensional example is very degenerate: generally the number of features would be much greater than the &amp;ldquo;document length&amp;rdquo;, while here we have much larger documents than vocabulary. Similarly, with &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt;, it is much less likely that a feature distinguishes a particular class.</source>
          <target state="translated">请注意，这个二维示例非常简陋：特征的数量通常会比&amp;ldquo;文档长度&amp;rdquo;大得多，而此处的文档比词汇量大得多。类似地，使用 &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt; ，特征区别特定类的可能性就小得多。</target>
        </trans-unit>
        <trans-unit id="dcf3e0855a66eb55e0eddd9daaf862dddfda1dac" translate="yes" xml:space="preserve">
          <source>Note that this type is the most specific type that can be inferred. For example:</source>
          <target state="translated">注意,这种类型是可以推断出的最具体的类型。例如:</target>
        </trans-unit>
        <trans-unit id="1fefb84f794ce8a86674757b08d8dabfe97347de" translate="yes" xml:space="preserve">
          <source>Note that this will affect all uses of &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt;&lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt;&lt;/a&gt; within the context.</source>
          <target state="translated">请注意，这将影响上下文中&lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt; &lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt; 的&lt;/a&gt;所有使用。</target>
        </trans-unit>
        <trans-unit id="ab32001c49d58b4f0c9d94bbfb77f7ddeaf05601" translate="yes" xml:space="preserve">
          <source>Note that those results can be highly dependent on the value of &lt;code&gt;learning_rate_init&lt;/code&gt;.</source>
          <target state="translated">请注意，这些结果可能高度依赖于 &lt;code&gt;learning_rate_init&lt;/code&gt; 的值。</target>
        </trans-unit>
        <trans-unit id="aa786acd948a782d7b514486d406120e9b9bf46a" translate="yes" xml:space="preserve">
          <source>Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.</source>
          <target state="translated">请注意,与标准的交叉验证方法不同,连续的训练集是前面的训练集的超集。</target>
        </trans-unit>
        <trans-unit id="be1d5d21cf434df3c562c8f7229d77ef9e790ff3" translate="yes" xml:space="preserve">
          <source>Note that we could have used the least squares loss for the &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; model. This would wrongly assume a normal distributed response variable as does the &lt;code&gt;Ridge&lt;/code&gt; model, and possibly also lead to slightly negative predictions. However the gradient boosted trees would still perform relatively well and in particular better than &lt;code&gt;PoissonRegressor&lt;/code&gt; thanks to the flexibility of the trees combined with the large number of training samples.</source>
          <target state="translated">注意，我们可以对 &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; 模型使用最小二乘损失。这将错误地假设一个正态分布的响应变量，就像 &lt;code&gt;Ridge&lt;/code&gt; 模型一样，并且可能还会导致略微负面的预测。但是，由于梯度树的灵活性以及大量的训练样本，因此梯度增强树的性能仍然相对较好，尤其是比 &lt;code&gt;PoissonRegressor&lt;/code&gt; 更好。</target>
        </trans-unit>
        <trans-unit id="b632488ec02d373b59188cfae81036b1d7135a34" translate="yes" xml:space="preserve">
          <source>Note that when using dictionary learning to extract a representation (e.g. for sparse coding) clustering can be a good proxy to learn the dictionary. For instance the &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; estimator is computationally efficient and implements on-line learning with a &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">请注意，当使用字典学习来提取表示形式（例如，用于稀疏编码）时，聚类可以是学习字典的良好代理。例如，&lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt;估计器的计算效率很高，并使用 &lt;code&gt;partial_fit&lt;/code&gt; 方法实现了在线学习。</target>
        </trans-unit>
        <trans-unit id="b38cc6be43472cae197ca98a60df5eafaa29d73f" translate="yes" xml:space="preserve">
          <source>Note that with all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data!</source>
          <target state="translated">注意，使用所有这些策略， &lt;code&gt;predict&lt;/code&gt; 方法将完全忽略输入数据！</target>
        </trans-unit>
        <trans-unit id="75c6be4694b9eabe59018390268fd820a052b7d5" translate="yes" xml:space="preserve">
          <source>Note that, by default, scikit-learn uses its embedded (vendored) version of joblib. A configuration switch (documented below) controls this behavior.</source>
          <target state="translated">请注意,默认情况下,scikit-learn 使用其嵌入式 (vendored)版本的 joblib。一个配置开关(如下文所述)可以控制这种行为。</target>
        </trans-unit>
        <trans-unit id="ae98ee9bcd2e5d0854b3eaebde47d02a011f815f" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the observation \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\).</source>
          <target state="translated">请注意，在这种表示法中，假设观察值\（y_i \）在试验\（i \）中采用集合\（{-1，1} \）中的值。</target>
        </trans-unit>
        <trans-unit id="e6bd4762fd372de20f9b98cd74d805456dc39e3e" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the target \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\). We can also see that Elastic-Net is equivalent to \(\ell_1\) when \(\rho = 1\) and equivalent to \(\ell_2\) when \(\rho=0\).</source>
          <target state="translated">请注意，在这种表示法中，假设目标\（y_i \）在试验\（i \）中采用集合\（{-1，1} \）中的值。我们还可以看到，当\（\ rho = 1 \）时，Elastic-Net等效于\（\ ell_1 \），而当\（\ rho = 0 \）时，Elastic-Net等效于\（\ ell_2 \）。</target>
        </trans-unit>
        <trans-unit id="79d7c15c2a930f99c60199078ea59a499e19fbc8" translate="yes" xml:space="preserve">
          <source>Note that, the color range of the precision matrices is tweaked to improve readability of the figure. The full range of values of the empirical precision is not displayed.</source>
          <target state="translated">需要注意的是,对精度矩阵的颜色范围进行了调整,以提高图的可读性。不显示经验精度的全部数值范围。</target>
        </trans-unit>
        <trans-unit id="285f98e8d01e4962eff6724b78a3c6724d0931e6" translate="yes" xml:space="preserve">
          <source>Note that:</source>
          <target state="translated">请注意:</target>
        </trans-unit>
        <trans-unit id="5bd74df6988f671f3aaedf9864231e7cb14cad2a" translate="yes" xml:space="preserve">
          <source>Note the use of a generator comprehension, which introduces laziness into the feature extraction: tokens are only processed on demand from the hasher.</source>
          <target state="translated">请注意使用生成器理解,它将懒惰引入到特征提取中:代币只在哈希的需求下进行处理。</target>
        </trans-unit>
        <trans-unit id="1984eb2d93c7fabc5820f74c1a6deb67cdefe2d3" translate="yes" xml:space="preserve">
          <source>Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">注意!合成特征权重和其他所有特征一样,要经过l1/l2的正则化。为了减少正则化对合成特征权重的影响(因此对截距的影响),必须增加截距_scaling。</target>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="translated">Note:</target>
        </trans-unit>
        <trans-unit id="b85cf8e5cd9762e5dd866d246742bbab950fd9b8" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeaveOneOut()&lt;/code&gt; is equivalent to &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; and &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of samples.</source>
          <target state="translated">注意： &lt;code&gt;LeaveOneOut()&lt;/code&gt; 等效于 &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; 和 &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; ，其中 &lt;code&gt;n&lt;/code&gt; 是样本数。</target>
        </trans-unit>
        <trans-unit id="31e8baf167adcc23a2adc9382a5f1918c617d9e9" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeavePOut(p)&lt;/code&gt; is NOT equivalent to &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; which creates non-overlapping test sets.</source>
          <target state="translated">注意： &lt;code&gt;LeavePOut(p)&lt;/code&gt; 与创建非重叠测试集的 &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; 不等效。</target>
        </trans-unit>
        <trans-unit id="bea1be387c131c6f224a4e72fba375bf5b015ed7" translate="yes" xml:space="preserve">
          <source>Note: Currently &lt;code&gt;TSNE(metric='precomputed')&lt;/code&gt; does not modify the precomputed distances, and thus assumes that precomputed euclidean distances are squared. In future versions, a parameter in TSNE will control the optional squaring of precomputed distances (see #12401).</source>
          <target state="translated">注意：目前， &lt;code&gt;TSNE(metric='precomputed')&lt;/code&gt; 不会修改预先计算的距离，因此假定预先计算的欧几里德距离为平方。在将来的版本中，TSNE中的参数将控制预计算距离的可选平方（请参阅＃12401）。</target>
        </trans-unit>
        <trans-unit id="432e1c4e6e288e7db18e2c42d6e410c6adeb71c8" translate="yes" xml:space="preserve">
          <source>Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times &lt;code&gt;n_samples&lt;/code&gt; (i.e. the sum of squares of each column totals 1).</source>
          <target state="translated">注意：这10个特征变量中的每一个均已用标准偏差乘以 &lt;code&gt;n_samples&lt;/code&gt; （即，每列的平方和总计1）进行平均居中和缩放。</target>
        </trans-unit>
        <trans-unit id="02b388a51976f4b3884d316ec9ed343cbbaf27f0" translate="yes" xml:space="preserve">
          <source>Note: Evaluation of eval_gradient is not analytic but numeric and all</source>
          <target state="translated">注:eval_gradient的评估不是分析式的,而是数值式的,所有的</target>
        </trans-unit>
        <trans-unit id="f97fa8efa81cc34898992868ec31edd01fe1abf9" translate="yes" xml:space="preserve">
          <source>Note: For larger datasets (n_samples &amp;gt;= 10000), please refer to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">注意：对于更大的数据集（n_samples&amp;gt; = 10000），请参考&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;sklearn.ensemble.HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a5290473efc5984775f303f01f61e6c7775623f5" translate="yes" xml:space="preserve">
          <source>Note: If a lambda is used as the function, then the resulting transformer will not be pickleable.</source>
          <target state="translated">注意:如果使用lambda作为函数,那么产生的变压器将不能被拾取。</target>
        </trans-unit>
        <trans-unit id="78c3e35dab7ccbe33bae1787c55dabbd050c5a91" translate="yes" xml:space="preserve">
          <source>Note: In KNeighborsTransformer we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;, and for compatibility reasons, one extra neighbor is computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. Please note that we do the same in the proposed wrappers.</source>
          <target state="translated">注意：在KNeighborsTransformer中，我们使用的定义包括每个训练点作为 &lt;code&gt;n_neighbors&lt;/code&gt; 计数中自己的邻居，并且出于兼容性的原因，当 &lt;code&gt;mode == 'distance'&lt;/code&gt; 时会计算一个额外的邻居。请注意，我们在建议的包装中也做同样的事情。</target>
        </trans-unit>
        <trans-unit id="ab7df665871a4d2a9feffe69dfea4e192c2cd75e" translate="yes" xml:space="preserve">
          <source>Note: L2 normalization is also known as spatial sign preprocessing.</source>
          <target state="translated">注:L2归一化又称空间符号预处理。</target>
        </trans-unit>
        <trans-unit id="09a1c78e2b9dafeb4ae2773774e2099dbe747a0e" translate="yes" xml:space="preserve">
          <source>Note: Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">注意：我们的实现得分比Tsoumakas等人（2010年）给出的得分高1。这将其扩展为处理实例具有0个真实标签的简并情况。</target>
        </trans-unit>
        <trans-unit id="956d1e2ca58f2ab0bdb4afea5546244c422bc323" translate="yes" xml:space="preserve">
          <source>Note: See the &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;Introduction to machine learning with scikit-learn Tutorial&lt;/a&gt; for a quick run-through on the basic machine learning vocabulary used within scikit-learn.</source>
          <target state="translated">注意：有关&lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;scikit-learn中&lt;/a&gt;使用的基本机器学习词汇的快速介绍，请参见scikit-learn机器学习简介教程。</target>
        </trans-unit>
        <trans-unit id="7a9381252d0555984c45c1d913a85b0a19a4797d" translate="yes" xml:space="preserve">
          <source>Note: The default solver &amp;lsquo;adam&amp;rsquo; works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, &amp;lsquo;lbfgs&amp;rsquo; can converge faster and perform better.</source>
          <target state="translated">注意：就训练时间和验证分数而言，默认求解器&amp;ldquo; adam&amp;rdquo;在相对较大的数据集（具有数千个训练样本或更多）上的效果很好。但是，对于小型数据集，&amp;ldquo; lbfgs&amp;rdquo;可以收敛得更快并且性能更好。</target>
        </trans-unit>
        <trans-unit id="271df9bc769d4f6f6224f70e1c75a6c3d0d4e15f" translate="yes" xml:space="preserve">
          <source>Note: The parameters &lt;code&gt;test_size&lt;/code&gt; and &lt;code&gt;train_size&lt;/code&gt; refer to groups, and not to samples, as in ShuffleSplit.</source>
          <target state="translated">注意：如在ShuffleSplit中一样，参数 &lt;code&gt;test_size&lt;/code&gt; 和 &lt;code&gt;train_size&lt;/code&gt; 是指组，而不是样本。</target>
        </trans-unit>
        <trans-unit id="d9b8539222215de6f9b7a2dc0d47dad55ab9503a" translate="yes" xml:space="preserve">
          <source>Note: a one-hot encoding of y labels should use a LabelBinarizer instead.</source>
          <target state="translated">注意:y标签的一键编码应该使用LabelBinarizer代替。</target>
        </trans-unit>
        <trans-unit id="1ed0914b13c92897638e72f9758df4b91ef77876" translate="yes" xml:space="preserve">
          <source>Note: although we will make new pipelines with the processors which we wrote in the previous section for the 3 learners, the final estimator RidgeCV() does not need preprocessing of the data as it will be fed with the already preprocessed output from the 3 learners.</source>
          <target state="translated">注意:虽然我们将用我们在上一节为3个学习者编写的处理器制作新的管道,但最终的估计器RidgeCV()不需要对数据进行预处理,因为它将用3个学习者已经预处理过的输出来输入。</target>
        </trans-unit>
        <trans-unit id="af48a21921f21ca5ba4feec03dc7cfdb83d643b6" translate="yes" xml:space="preserve">
          <source>Note: as k-means is optimizing a non-convex objective function, it will likely end up in a local optimum. Several runs with independent random init might be necessary to get a good convergence.</source>
          <target state="translated">注意:由于k-means优化的是一个非凸目标函数,它很可能最终会达到局部最优。为了获得良好的收敛性,可能需要进行多次独立的随机初始化运行。</target>
        </trans-unit>
        <trans-unit id="3bb7791854593a3b717f90311f25871cac16570c" translate="yes" xml:space="preserve">
          <source>Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:与其他交叉验证策略相反,随机拆分并不能保证所有的折线都是不同的,尽管这对于可观的数据集来说还是很有可能的。</target>
        </trans-unit>
        <trans-unit id="ec23f8c549cab8298e97ba96412d8acd5b97a819" translate="yes" xml:space="preserve">
          <source>Note: fitting on sparse input will override the setting of this parameter, using brute force.</source>
          <target state="translated">注意:在稀疏输入上的拟合将覆盖该参数的设置,使用蛮力。</target>
        </trans-unit>
        <trans-unit id="f2a5a8b06402f76d2a1b1f28ad2e90efb04ea841" translate="yes" xml:space="preserve">
          <source>Note: if you manage your own numerical data it is recommended to use an optimized file format such as HDF5 to reduce data load times. Various libraries such as H5Py, PyTables and pandas provides a Python interface for reading and writing data in that format.</source>
          <target state="translated">注意:如果你管理自己的数值数据,建议使用优化的文件格式,如HDF5,以减少数据加载时间。各种库如H5Py、PyTables和pandas提供了一个Python接口,用于读写该格式的数据。</target>
        </trans-unit>
        <trans-unit id="cb39d5746d1ab528272657961084b4241cfe3f85" translate="yes" xml:space="preserve">
          <source>Note: in the plot, &amp;ldquo;unlabeled samples&amp;rdquo; does not mean that we don&amp;rsquo;t know the labels (as in semi-supervised learning) but that the samples simply do &lt;em&gt;not&lt;/em&gt; have a label.</source>
          <target state="translated">注意：在图中，&amp;ldquo;未标记样本&amp;rdquo;并不意味着我们不知道标记（如在半监督学习中一样），而是样本根本&lt;em&gt;没有&lt;/em&gt;标记。</target>
        </trans-unit>
        <trans-unit id="403fd153dcfc1c72561472b5e34372d5de58734f" translate="yes" xml:space="preserve">
          <source>Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:和ShuffleSplit策略一样,分层随机拆分并不能保证所有的褶皱都是不同的,尽管这对于可观的数据集来说还是很有可能的。</target>
        </trans-unit>
        <trans-unit id="12964c4f090e67fee00edc80b29c8ee9b28b7b3b" translate="yes" xml:space="preserve">
          <source>Note: the implementation of &lt;code&gt;inverse_transform&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;svd_solver='randomized'&lt;/code&gt; is not the exact inverse transform of &lt;code&gt;transform&lt;/code&gt; even when &lt;code&gt;whiten=False&lt;/code&gt; (default).</source>
          <target state="translated">注：执行 &lt;code&gt;inverse_transform&lt;/code&gt; 在&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;与 &lt;code&gt;svd_solver='randomized'&lt;/code&gt; 是不准确的反变换的 &lt;code&gt;transform&lt;/code&gt; ，即使 &lt;code&gt;whiten=False&lt;/code&gt; （默认值）。</target>
        </trans-unit>
        <trans-unit id="f5990a880094bfe59d250a6cb72959923dee6858" translate="yes" xml:space="preserve">
          <source>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</source>
          <target state="translated">注意:每次调用该属性时都会重新创建列表,以便通过不存储采样数据来减少对象的内存占用。因此,获取属性的速度可能比预期的要慢。</target>
        </trans-unit>
        <trans-unit id="b4fa4a5f4c66fdf91fefb2f5d8a9d04622e730f8" translate="yes" xml:space="preserve">
          <source>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">注意：在找到至少一个有效的节点样本分区之前，分割的搜索不会停止，即使它需要有效检查多个 &lt;code&gt;max_features&lt;/code&gt; 功能也是如此。</target>
        </trans-unit>
        <trans-unit id="4064827fd69033d32661395cc63853ae193f7d3a" translate="yes" xml:space="preserve">
          <source>Note: this implementation can be used with binary, multiclass and multilabel classification, but some restrictions apply (see Parameters).</source>
          <target state="translated">注意:本实施例可用于二进制、多类和多标签分类,但有一些限制适用(参见参数)。</target>
        </trans-unit>
        <trans-unit id="5af1722805bd08a73be9d8b2f383c0eb417bbdd9" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.</source>
          <target state="translated">注:本实施例仅限于标签指示器格式的二元分类任务或多标签分类任务。</target>
        </trans-unit>
        <trans-unit id="2dab9af505b98147ed8303644f1fce8db17174c7" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task.</source>
          <target state="translated">注:本实施例仅限于二元分类任务或多标签分类任务。</target>
        </trans-unit>
        <trans-unit id="229c71e40bdbb475df5a5f3c46414bb1e9fb11cf" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task.</source>
          <target state="translated">注意:本实施例仅限于二进制分类任务。</target>
        </trans-unit>
        <trans-unit id="77503a53930a4c6773bcfd9900ee0500aa085f94" translate="yes" xml:space="preserve">
          <source>Note: with the optional parameter &lt;code&gt;svd_solver='randomized'&lt;/code&gt;, we also need to give &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; the size of the lower-dimensional space &lt;code&gt;n_components&lt;/code&gt; as a mandatory input parameter.</source>
          <target state="translated">注意：使用可选参数 &lt;code&gt;svd_solver='randomized'&lt;/code&gt; ，我们还需要给&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;较低维空间 &lt;code&gt;n_components&lt;/code&gt; 的大小作为强制输入参数。</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="8365e7c537a7bde197e775fc685e729bf7dcde79" translate="yes" xml:space="preserve">
          <source>Notice that this class does not support sparse input. See &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; for an alternative with sparse data.</source>
          <target state="translated">请注意，此类不支持稀疏输入。有关稀疏数据的替代方法，请参见&lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="24a6d73ad577eece3a7c4a8079ee0685b19c5eef" translate="yes" xml:space="preserve">
          <source>Novelty detection</source>
          <target state="translated">新颖性检测</target>
        </trans-unit>
        <trans-unit id="0c6ce6f3a8c7f0ac9123407bf644e00c93b8a85c" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor (LOF)</source>
          <target state="translated">使用局部离群值因子(LOF)进行新奇度检测</target>
        </trans-unit>
        <trans-unit id="d039fa812c1beff75961eedb7fd0d56d4bd6cef8" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor is illustrated below.</source>
          <target state="translated">新颖性检测与局部离群因素如下图所示。</target>
        </trans-unit>
        <trans-unit id="0baacee2d29c362912e19aeae2a56e9b5de18251" translate="yes" xml:space="preserve">
          <source>November, 1995</source>
          <target state="translated">1995年11月</target>
        </trans-unit>
        <trans-unit id="f56b60fb36ba6e7108f33fd204674d75974c9ca0" translate="yes" xml:space="preserve">
          <source>Now looking at the computation time of the different parts, we see that the vectorization is much more expensive than learning itself. From the different algorithms, &lt;code&gt;MultinomialNB&lt;/code&gt; is the most expensive, but its overhead can be mitigated by increasing the size of the mini-batches (exercise: change &lt;code&gt;minibatch_size&lt;/code&gt; to 100 and 10000 in the program and compare).</source>
          <target state="translated">现在查看不同部分的计算时间，我们发现矢量化比学习本身要昂贵得多。从不同的算法来看， &lt;code&gt;MultinomialNB&lt;/code&gt; 是最昂贵的，但是可以通过增加小批量的大小来减轻开销（练习：在程序 &lt;code&gt;minibatch_size&lt;/code&gt; 更改为100和10000并进行比较）。</target>
        </trans-unit>
        <trans-unit id="e921254526b0e2e9cacf92a70632a272e818cfb0" translate="yes" xml:space="preserve">
          <source>Now that the coefficients have been scaled, we can safely compare them.</source>
          <target state="translated">现在,系数已经被缩放,我们可以安全地比较它们。</target>
        </trans-unit>
        <trans-unit id="703648eec6ac2a9ecd5332ac2370f3cbb5d40c50" translate="yes" xml:space="preserve">
          <source>Now that we have our features, we can train a classifier to try to predict the category of a post. Let&amp;rsquo;s start with a &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;na&amp;iuml;ve Bayes&lt;/a&gt; classifier, which provides a nice baseline for this task. &lt;code&gt;scikit-learn&lt;/code&gt; includes several variants of this classifier; the one most suitable for word counts is the multinomial variant:</source>
          <target state="translated">现在我们有了功能，我们可以训练分类器来尝试预测帖子的类别。让我们从&lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;朴素的贝叶斯&lt;/a&gt;分类器开始，它为该任务提供了一个很好的基准。 &lt;code&gt;scikit-learn&lt;/code&gt; 包括该分类器的多种变体；多项式最适合单词计数：</target>
        </trans-unit>
        <trans-unit id="88e8cd01d787ca5c585c186900aea23cd932893c" translate="yes" xml:space="preserve">
          <source>Now we can use Ames Housing dataset to make the predictions. We check the performance of each individual predictor as well as of the stack of the regressors.</source>
          <target state="translated">现在我们可以使用Ames Housing数据集来进行预测。我们检查每个单独的预测器以及回归器堆栈的性能。</target>
        </trans-unit>
        <trans-unit id="c77da09ad9df95918caa9589e1cfa5804c7aace6" translate="yes" xml:space="preserve">
          <source>Now we create a &lt;code&gt;FeatureUnion&lt;/code&gt;. All features will be imputed using &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt;, in order to enable classifiers to work with this data. Additionally, it adds the the indicator variables from &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">现在我们创建一个 &lt;code&gt;FeatureUnion&lt;/code&gt; 。为了使分类器能够使用此数据，将使用&lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt;估算所有功能。此外，它还添加了&lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; 中&lt;/a&gt;的指标变量。</target>
        </trans-unit>
        <trans-unit id="0e66fc30e8519d1cd12806317bc82ad0b2345f16" translate="yes" xml:space="preserve">
          <source>Now we want to select the two features which are the most important. SelectFromModel() allows for setting the threshold. Only the features with the &lt;code&gt;coef_&lt;/code&gt; higher than the threshold will remain. Here, we want to set the threshold slightly above the third highest &lt;code&gt;coef_&lt;/code&gt; calculated by LassoCV() from our data.</source>
          <target state="translated">现在我们要选择最重要的两个功能。SelectFromModel（）允许设置阈值。仅保留 &lt;code&gt;coef_&lt;/code&gt; 高于阈值的要素。在这里，我们希望将阈值设置为略高于LassoCV（）从数据中计算出的第三高的 &lt;code&gt;coef_&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6c18c8137b5b9d8aae8dc57c26f7d6b41951afd4" translate="yes" xml:space="preserve">
          <source>Now we will estimate the score on the data where the missing values are replaced by 0:</source>
          <target state="translated">现在我们将对缺失值被0代替的数据进行估计得分。</target>
        </trans-unit>
        <trans-unit id="2b6f8334bd6af42d0add5e2131513b016d9f6e6d" translate="yes" xml:space="preserve">
          <source>Now we will initiate the gradient boosting regressors and fit it with our training data. Let&amp;rsquo;s also look and the mean squared error on the test data.</source>
          <target state="translated">现在，我们将启动梯度增强回归器，并将其与我们的训练数据拟合。我们还要看一下测试数据上的均方误差。</target>
        </trans-unit>
        <trans-unit id="2c5cf2d42930f189f93938b87f35b21f55ff5f6c" translate="yes" xml:space="preserve">
          <source>Now we will use each of the regressors to make the 20 first predictions.</source>
          <target state="translated">现在,我们将用每一个回归者来进行20个第一次的预测。</target>
        </trans-unit>
        <trans-unit id="936a8dbed55baf9b2e1ebda09b75843de98173ab" translate="yes" xml:space="preserve">
          <source>Now we will write a function which will score the results on the differently imputed data. Let&amp;rsquo;s look at each imputer separately:</source>
          <target state="translated">现在，我们将编写一个函数，该函数将对不同插补数据的结果进行评分。让我们分别看一下每个不良因素：</target>
        </trans-unit>
        <trans-unit id="39c382cf98b09c769e0ece49478f8e5a21269790" translate="yes" xml:space="preserve">
          <source>Now you can &lt;em&gt;predict&lt;/em&gt; new values. In this case, you&amp;rsquo;ll predict using the last image from &lt;code&gt;digits.data&lt;/code&gt;. By predicting, you&amp;rsquo;ll determine the image from the training set that best matches the last image.</source>
          <target state="translated">现在您可以&lt;em&gt;预测&lt;/em&gt;新值。在这种情况下，您将预测使用 &lt;code&gt;digits.data&lt;/code&gt; 中的最后一张图像。通过预测，您将从训练集中确定与最后一张图像最匹配的图像。</target>
        </trans-unit>
        <trans-unit id="4bde0a1195bac7469e935b78a194104a68da7a29" translate="yes" xml:space="preserve">
          <source>Now, if we repeat this computation for the remaining 2 terms in the document, we get</source>
          <target state="translated">现在,如果我们对文档中剩余的2个术语进行重复计算,我们得到的是</target>
        </trans-unit>
        <trans-unit id="ece88bcd9ec161c2a2872c2fb61e36a0d64c7a18" translate="yes" xml:space="preserve">
          <source>Now, without any further assumptions the idea of having a latent variable \(h\) would be superfluous &amp;ndash; \(x\) can be completely modelled with a mean and a covariance. We need to impose some more specific structure on one of these two parameters. A simple additional assumption regards the structure of the error covariance \(\Psi\):</source>
          <target state="translated">现在，无需任何进一步假设，具有潜在变量\（h \）的想法将是多余的&amp;ndash; \（x \）可以使用均值和协方差完全建模。我们需要对这两个参数之一施加一些更具体的结构。一个简单的附加假设涉及误差协方差\（\ Psi \）的结构：</target>
        </trans-unit>
        <trans-unit id="a31389fe4ff0ebc6e5c5d38e5dab56436f6bc483" translate="yes" xml:space="preserve">
          <source>Nu Support Vector Regression.</source>
          <target state="translated">Nu支持向量回归。</target>
        </trans-unit>
        <trans-unit id="a9b51312b4e809b61f7b24f233552372d8a4d343" translate="yes" xml:space="preserve">
          <source>Nu-Support Vector Classification.</source>
          <target state="translated">Nu-Support Vector分类。</target>
        </trans-unit>
        <trans-unit id="3fd1d9cda92e08af6fee8cba19fd970cf1f0632b" translate="yes" xml:space="preserve">
          <source>Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). &lt;code&gt;l1_ratio=1&lt;/code&gt; corresponds to the Lasso.</source>
          <target state="translated">0到1之间的数字传递给弹性网（在l1和l2罚分之间缩放）。 &lt;code&gt;l1_ratio=1&lt;/code&gt; 对应于套索。</target>
        </trans-unit>
        <trans-unit id="7957f8886c98fbf5a70e65a8ee06b411dfa2ec9d" translate="yes" xml:space="preserve">
          <source>Number of Attributes</source>
          <target state="translated">属性数量</target>
        </trans-unit>
        <trans-unit id="28831313b9efda1fb2d5e62ae541d82eeaf2e628" translate="yes" xml:space="preserve">
          <source>Number of Attributes:</source>
          <target state="translated">属性数:</target>
        </trans-unit>
        <trans-unit id="2bbc98640e09a456dee6d19b3fcc0a288b212310" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证循环中使用的CPU内核数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e0f96f6f23ce740144b8c92df340b8480f6b786d" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证循环中使用的CPU内核数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e056a5a70210c137f261290dad04190fbc9ce82b" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">如果multi_class ='ovr'&amp;rdquo;，则在对类进行并行化时使用的CPU内核数。当 &lt;code&gt;solver&lt;/code&gt; 设置为&amp;ldquo; liblinear&amp;rdquo;时，无论是否指定了&amp;ldquo; multi_class&amp;rdquo;，该参数都将被忽略。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ba00da4689fb46c7f1453ab4c4d840dda819bf30" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">如果multi_class ='ovr'&amp;rdquo;，则在对类进行并行化时使用的CPU内核数。当 &lt;code&gt;solver&lt;/code&gt; 设置为&amp;ldquo; liblinear&amp;rdquo;时，无论是否指定了&amp;ldquo; multi_class&amp;rdquo;，该参数都将被忽略。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="044a045266785f2237c066206c338baa3e1d5bb2" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证期间要使用的CPU数量。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="299b1e18443f4440c97e32fcbc5b33894e6807aa" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证期间要使用的CPU数量。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="aaf36da587212084529abec535211c954c2e7c01" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证期间要使用的CPU数量。请注意，仅当给定l1_ratio的多个值时，才使用此选项。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="abb87aba72afe118ccbcfcbd98130537908df821" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证期间要使用的CPU数量。请注意，仅当给定了l1_ratio的多个值时，才使用此选项。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="52783b9f963f3f1690dd5d40572b3875e2a7ade7" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the resampling. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">重采样期间要使用的CPU数量。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9b0888ca0284a2c854ae8715c4ccbdf2a4510807" translate="yes" xml:space="preserve">
          <source>Number of Instances</source>
          <target state="translated">实例数</target>
        </trans-unit>
        <trans-unit id="a2666336978a0f4e8c547b7534c07249ba6000fd" translate="yes" xml:space="preserve">
          <source>Number of Instances:</source>
          <target state="translated">实例数:</target>
        </trans-unit>
        <trans-unit id="0bc3461e8033920222bec6b216692137eee9c091" translate="yes" xml:space="preserve">
          <source>Number of Monte Carlo samples per original feature. Equals the dimensionality of the computed feature space.</source>
          <target state="translated">每个原始特征的蒙特卡洛样本数。等于计算出的特征空间的维度。</target>
        </trans-unit>
        <trans-unit id="3262f2b1a48253ff0690a8a75cfdd12aae481720" translate="yes" xml:space="preserve">
          <source>Number of active features across every target for the model refit with the best hyperparameters got by cross-validating across all folds.</source>
          <target state="translated">在所有褶皱交叉验证得到的最佳超参数下,每个目标的活跃特征数量。</target>
        </trans-unit>
        <trans-unit id="4cbf5cb47ecd9996ec380ef5f0f19c258c9e11e4" translate="yes" xml:space="preserve">
          <source>Number of active features across every target.</source>
          <target state="translated">每个目标的活动特征数量。</target>
        </trans-unit>
        <trans-unit id="4d39e5d8b3efa9d6f8372f94e39a5395c837b600" translate="yes" xml:space="preserve">
          <source>Number of active features across every target. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">每个目标上的活动功能数量。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="e0c8a9190fa0a6b6567e6260a08bbc16ad38e0e1" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path</source>
          <target state="translated">正则化路径上的阿尔法数</target>
        </trans-unit>
        <trans-unit id="21389bf92cd8e8648f186478c091bf8c596c9371" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path, used for each l1_ratio.</source>
          <target state="translated">沿着正则化路径的阿尔法数,用于每个l1_ratio。</target>
        </trans-unit>
        <trans-unit id="cbe7afb5599ad451cab3f599179a64fd19bd9311" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path.</source>
          <target state="translated">正则化路径上的阿尔法数。</target>
        </trans-unit>
        <trans-unit id="cb76f13b1ca274d0ac0509e0599ee9f88692f95e" translate="yes" xml:space="preserve">
          <source>Number of best singular vectors to which to project the data for clustering.</source>
          <target state="translated">投射数据进行聚类的最佳奇异向量的数量。</target>
        </trans-unit>
        <trans-unit id="669eddc43c369820a90c37333994758dabadb237" translate="yes" xml:space="preserve">
          <source>Number of binary hidden units.</source>
          <target state="translated">二进制隐藏单元的数量。</target>
        </trans-unit>
        <trans-unit id="df5056a6b08a72e6eb298ef5a65870b5ddc8c698" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. An ignored feature at index &lt;code&gt;i&lt;/code&gt; will have &lt;code&gt;n_bins_[i] == 0&lt;/code&gt;.</source>
          <target state="translated">每个功能箱的数量。索引 &lt;code&gt;i&lt;/code&gt; 处被忽略的特征将具有 &lt;code&gt;n_bins_[i] == 0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d7a7f2e004236d911cb66cf34176f3d71e43ecca" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. Bins whose width are too small (i.e., &amp;lt;= 1e-8) are removed with a warning.</source>
          <target state="translated">每个功能箱的数量。宽度过小的垃圾箱（即&amp;lt;= 1e-8）会被警告移除。</target>
        </trans-unit>
        <trans-unit id="a230a570a7b298a4731493b5111f06efb3bd3e1c" translate="yes" xml:space="preserve">
          <source>Number of bins to discretize the [0, 1] interval. A bigger number requires more data. Bins with no samples (i.e. without corresponding values in &lt;code&gt;y_prob&lt;/code&gt;) will not be returned, thus the returned arrays may have less than &lt;code&gt;n_bins&lt;/code&gt; values.</source>
          <target state="translated">离散化[0，1]间隔的仓数。更大的数量需要更多的数据。没有样本的 &lt;code&gt;y_prob&lt;/code&gt; （即y_prob中没有相应的值）将不会被返回，因此返回的数组可能具有小于 &lt;code&gt;n_bins&lt;/code&gt; 的值。</target>
        </trans-unit>
        <trans-unit id="9e19457800c5864e1fbdcc0291b0ef620abfd78c" translate="yes" xml:space="preserve">
          <source>Number of bins. A bigger number requires more data.</source>
          <target state="translated">仓的数量。数字越大,需要的数据越多。</target>
        </trans-unit>
        <trans-unit id="0c552ab63ca0f87bf2127208daa3692ef5597992" translate="yes" xml:space="preserve">
          <source>Number of classes</source>
          <target state="translated">班级数量</target>
        </trans-unit>
        <trans-unit id="fbe9989009b56729007d1b9895a9883c9be1c338" translate="yes" xml:space="preserve">
          <source>Number of classes.</source>
          <target state="translated">班级数量:</target>
        </trans-unit>
        <trans-unit id="f70f556044c9d189136c9439d7b869763e660892" translate="yes" xml:space="preserve">
          <source>Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples.</source>
          <target state="translated">在最后的聚类步骤后的聚类数量,将叶子中的子聚类视为新样本。</target>
        </trans-unit>
        <trans-unit id="d93f166299b2fe351648697f50539b771bbcab5f" translate="yes" xml:space="preserve">
          <source>Number of clusters to extract.</source>
          <target state="translated">要提取的集群数量。</target>
        </trans-unit>
        <trans-unit id="eb68d1899db83f395f515eac11a92a2f39369f2a" translate="yes" xml:space="preserve">
          <source>Number of combinations taken into account from &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples.</source>
          <target state="translated">从&amp;ldquo; n选择k&amp;rdquo;中考虑的组合数，其中n是样本数，k是子样本数。</target>
        </trans-unit>
        <trans-unit id="7fdc37b73d2c326edb84e2aac0aaad0a3921fc6b" translate="yes" xml:space="preserve">
          <source>Number of components</source>
          <target state="translated">组成部分的数量</target>
        </trans-unit>
        <trans-unit id="cd12f5ccc87c2314d1a7462c1838eb4fba879a35" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt; n_classes - 1) for dimensionality reduction.</source>
          <target state="translated">用于降维的组件数（&amp;lt;n_classes-1）。</target>
        </trans-unit>
        <trans-unit id="dfb009c80642e429ebd085f522e99f9888546747" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt;= min(n_classes - 1, n_features)) for dimensionality reduction. If None, will be set to min(n_classes - 1, n_features). This parameter only affects the &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="translated">用于降维的组件数（&amp;lt;= min（n_classes-1，n_features））。如果为None，则将设置为min（n_classes-1，n_features）。此参数仅影响 &lt;code&gt;transform&lt;/code&gt; 方法。</target>
        </trans-unit>
        <trans-unit id="678dcaccd382015a606461223e75a521f8c270e3" translate="yes" xml:space="preserve">
          <source>Number of components to keep</source>
          <target state="translated">需要保留的组件数量</target>
        </trans-unit>
        <trans-unit id="209051725a6de8e5e1e5fa7a1e74f7eb06a44fec" translate="yes" xml:space="preserve">
          <source>Number of components to keep.</source>
          <target state="translated">要保留的部件数量。</target>
        </trans-unit>
        <trans-unit id="d04623123bcfd2ce2b9c37b5c1e9535768de28a7" translate="yes" xml:space="preserve">
          <source>Number of components to keep. If &lt;code&gt;n_components `` is ``None&lt;/code&gt;, then &lt;code&gt;n_components&lt;/code&gt; is set to &lt;code&gt;min(n_samples, n_features)&lt;/code&gt;.</source>
          <target state="translated">要保留的组件数。如果 &lt;code&gt;n_components `` is ``None&lt;/code&gt; ，则 &lt;code&gt;n_components&lt;/code&gt; 设置为 &lt;code&gt;min(n_samples, n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="864a5ed4a409c99b07b3c02fc85e293c54d58811" translate="yes" xml:space="preserve">
          <source>Number of components to keep. if n_components is not set all components are kept:</source>
          <target state="translated">如果没有设置n_components,则保留所有组件。</target>
        </trans-unit>
        <trans-unit id="b681f0aabf7a4e88ff6e07d02e6d3053416c7e30" translate="yes" xml:space="preserve">
          <source>Number of components to use. If none is passed, all are used.</source>
          <target state="translated">要使用的组件数量。如果没有通过,则全部使用。</target>
        </trans-unit>
        <trans-unit id="a4c9442f9290e02b19f88b85f02bacea3cfec6f7" translate="yes" xml:space="preserve">
          <source>Number of components, if n_components is not set all features are kept.</source>
          <target state="translated">组件的数量,如果没有设置n_components,则会保留所有的特征。</target>
        </trans-unit>
        <trans-unit id="cd25fc9de4a04b081f0b9a2b60926bce89997152" translate="yes" xml:space="preserve">
          <source>Number of components. If None, all non-zero components are kept.</source>
          <target state="translated">组件的数量。如果为 &quot;无&quot;,则保留所有非零组件。</target>
        </trans-unit>
        <trans-unit id="45f800ea0c8bd716a5f59f6d34dd8fdf95b8f22e" translate="yes" xml:space="preserve">
          <source>Number of components:</source>
          <target state="translated">组成部分的数量。</target>
        </trans-unit>
        <trans-unit id="08ad46845beb5661bae33c15135ad1635029f790" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">跨折时要并行运行的芯数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="858edfcde96e4df6617cbdeba5e365378b873cbb" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">跨折时可并行运行的芯数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8c854de6ce1141c59e336a0d697b5a2d467a137a" translate="yes" xml:space="preserve">
          <source>Number of decimal digits to display.</source>
          <target state="translated">要显示的小数位数。</target>
        </trans-unit>
        <trans-unit id="0da9d602da12f13ca29bd75af12cc8c869e57a9f" translate="yes" xml:space="preserve">
          <source>Number of dictionary atoms to extract.</source>
          <target state="translated">要提取的字典原子的数量。</target>
        </trans-unit>
        <trans-unit id="5227337d1c8f00f0cc5985a46091828c912745d3" translate="yes" xml:space="preserve">
          <source>Number of digits for formatting output floating point values. When &lt;code&gt;output_dict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this will be ignored and the returned values will not be rounded.</source>
          <target state="translated">用于格式化输出浮点值的位数。当 &lt;code&gt;output_dict&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; 时，它将被忽略，并且返回的值将不会四舍五入。</target>
        </trans-unit>
        <trans-unit id="393e0ab0962f61be4ea05f66f75cf83a58c8acb8" translate="yes" xml:space="preserve">
          <source>Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.</source>
          <target state="translated">每个节点的杂质、阈值和值属性的值中浮点的精度位数。</target>
        </trans-unit>
        <trans-unit id="857511ca3ff53ac74c7a9a64491518f8a98aa57b" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities.</source>
          <target state="translated">浸透异样的维度数。</target>
        </trans-unit>
        <trans-unit id="60a7a9ccef477eb7d360b15d4ec93323fc3722cf" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities. If an &lt;code&gt;init&lt;/code&gt; array is provided, this option is overridden and the shape of &lt;code&gt;init&lt;/code&gt; is used to determine the dimensionality of the embedding space.</source>
          <target state="translated">沉浸差异的维数。如果提供了 &lt;code&gt;init&lt;/code&gt; 数组，则会覆盖此选项，并且 &lt;code&gt;init&lt;/code&gt; 的形状用于确定嵌入空间的维数。</target>
        </trans-unit>
        <trans-unit id="f601fdb82b970f8ccae9e3060c9f42a8faed55c3" translate="yes" xml:space="preserve">
          <source>Number of documents to use in each EM iteration. Only used in online learning.</source>
          <target state="translated">每次EM迭代中使用的文件数量。仅用于在线学习。</target>
        </trans-unit>
        <trans-unit id="25fead66533b3559387b2fcbff51a361b6ce623f" translate="yes" xml:space="preserve">
          <source>Number of eigen vectors to use for the spectral embedding</source>
          <target state="translated">用于光谱嵌入的特征向量的数量。</target>
        </trans-unit>
        <trans-unit id="70fb7e9ad9dffd747feff757e8b6b2c3b8c3ad21" translate="yes" xml:space="preserve">
          <source>Number of examples per minibatch.</source>
          <target state="translated">每个小批量的例子数量。</target>
        </trans-unit>
        <trans-unit id="f3a87cabcd8ae2a3f47b41980367db8a154ace86" translate="yes" xml:space="preserve">
          <source>Number of features</source>
          <target state="translated">特征数量</target>
        </trans-unit>
        <trans-unit id="c43d2150a87097029c4596d560aaf86e8bb6b759" translate="yes" xml:space="preserve">
          <source>Number of features in the training data.</source>
          <target state="translated">训练数据中的特征数量。</target>
        </trans-unit>
        <trans-unit id="577fe93a084a93466c74dd6388a400050adba06b" translate="yes" xml:space="preserve">
          <source>Number of features of each sample.</source>
          <target state="translated">每个样本的特征数量。</target>
        </trans-unit>
        <trans-unit id="48c9c477edb63770940bc1b8209cb208de55d13b" translate="yes" xml:space="preserve">
          <source>Number of features seen during &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;拟合&lt;/a&gt;期间看到的特征数量。</target>
        </trans-unit>
        <trans-unit id="f26773f39b3b679c0daff789f714ad69f2880ea0" translate="yes" xml:space="preserve">
          <source>Number of features to construct. How many data points will be used to construct the mapping.</source>
          <target state="translated">要构建的特征数量。用多少数据点来构建图谱。</target>
        </trans-unit>
        <trans-unit id="d56ef4ad6a94ab0bc79a9c8a295f26cabf4e9608" translate="yes" xml:space="preserve">
          <source>Number of features with missing values.</source>
          <target state="translated">缺失值的特征数量。</target>
        </trans-unit>
        <trans-unit id="8bfcb7d61331a9745e723fb4ee723054b5ce91e8" translate="yes" xml:space="preserve">
          <source>Number of folds. Must be at least 2.</source>
          <target state="translated">褶皱的数量。必须是至少2个。</target>
        </trans-unit>
        <trans-unit id="37148505c5ccd477f2cd9888510233bf49ab48d7" translate="yes" xml:space="preserve">
          <source>Number of grid points. The path is linearly reinterpolated on a grid between 0 and 1 before computing the scores.</source>
          <target state="translated">网格点的数量。在计算分数之前,路径在0和1之间的网格上线性重插。</target>
        </trans-unit>
        <trans-unit id="609fe53affef0db7e95afe01e9b3b2b42cfee225" translate="yes" xml:space="preserve">
          <source>Number of groups (&lt;code&gt;p&lt;/code&gt;) to leave out in the test split.</source>
          <target state="translated">要在测试分组中忽略的组数（ &lt;code&gt;p&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="7836a44e33451a2adc5e90b29cc50de43f4df6df" translate="yes" xml:space="preserve">
          <source>Number of iteration done before the next print.</source>
          <target state="translated">下一次打印前的迭代次数。</target>
        </trans-unit>
        <trans-unit id="58ef557aa3516e101a9370d2bf015690817ac32f" translate="yes" xml:space="preserve">
          <source>Number of iteration rounds that occurred. Will be less than &lt;code&gt;self.max_iter&lt;/code&gt; if early stopping criterion was reached.</source>
          <target state="translated">发生的迭代轮数。如果达到提前停止标准，则将小于 &lt;code&gt;self.max_iter&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c7ee7fcff30c38dbe60673fcfaba39d5dcac363e" translate="yes" xml:space="preserve">
          <source>Number of iterations corresponding to the best results. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">对应于最佳结果的迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="b6dedae4e35c925119d2eb7b698bd022b8304ae7" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;randomized_svd&lt;/code&gt;&lt;/a&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">随机SVD求解器的迭代次数。ARPACK不使用。默认值大于&lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;randomized_svd&lt;/code&gt; 中&lt;/a&gt;的默认值，以处理可能具有较大的缓慢衰减频谱的稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="b89cf5a40a3578805b3d3e22f18c4e3365baf655" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;code&gt;randomized_svd&lt;/code&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">随机SVD求解器的迭代次数。ARPACK不使用。默认值大于 &lt;code&gt;randomized_svd&lt;/code&gt; 中的默认值，以处理可能具有较大的缓慢衰减频谱的稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="b158b03d08af1b718d3d75c350a03244a2d1a76a" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method computed by svd_solver == &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">svd_solver =='随机化'计算出的幂方法的迭代次数。</target>
        </trans-unit>
        <trans-unit id="ea8482c683ec2d466d38eba89e78f2c408d93dba" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method. 3 by default. Only used if &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;</source>
          <target state="translated">幂方法的迭代次数。默认为3。仅在 &lt;code&gt;svd_method&lt;/code&gt; 等于&amp;ldquo;随机化&amp;rdquo;时使用</target>
        </trans-unit>
        <trans-unit id="e2a3f7897a04130ec9ab6e8a06f184c73a2db962" translate="yes" xml:space="preserve">
          <source>Number of iterations needed for the spatial median.</source>
          <target state="translated">空间中位数所需的迭代次数。</target>
        </trans-unit>
        <trans-unit id="0a6f367644c8353f5e90ff32f9e722b8b3c35762" translate="yes" xml:space="preserve">
          <source>Number of iterations of the EM step.</source>
          <target state="translated">EM步骤的迭代次数。</target>
        </trans-unit>
        <trans-unit id="ca85b057132e8737cc9bd5d9895d1c2f0a3952a0" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component.</source>
          <target state="translated">每个组件的NIPALS内循环的迭代次数。</target>
        </trans-unit>
        <trans-unit id="38592412005a60e12235ac166647e6d24941d551" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component. Not useful if the algorithm provided is &amp;ldquo;svd&amp;rdquo;.</source>
          <target state="translated">每个组件的NIPALS内部循环的迭代次数。如果提供的算法是&amp;ldquo; svd&amp;rdquo;，则无用。</target>
        </trans-unit>
        <trans-unit id="b3f0661f5b6a537d1cfcf27ec4e37f08f53a4a65" translate="yes" xml:space="preserve">
          <source>Number of iterations run for the optimal alpha.</source>
          <target state="translated">最佳α的迭代次数。</target>
        </trans-unit>
        <trans-unit id="c9d82135ee15642aa7ae8817dc570334ab80622b" translate="yes" xml:space="preserve">
          <source>Number of iterations run.</source>
          <target state="translated">运行的迭代次数。</target>
        </trans-unit>
        <trans-unit id="cc453132656fb5fe083f1f7f5f3c0a7066108d51" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">运行的迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 时才返回。</target>
        </trans-unit>
        <trans-unit id="346838eb1c236609499116f6804a1aeab6029a68" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">运行的迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="bae285cae0e2d21ef6dbbaa8dd54db30234b47e0" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if return_n_iter is set to True.</source>
          <target state="translated">运行的迭代次数。只有return_n_iter设置为True时才会返回。</target>
        </trans-unit>
        <trans-unit id="6e040a3af3a9255e0d8c4455bc3543184ccbc3ff" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to an invalid model defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">由于 &lt;code&gt;is_model_valid&lt;/code&gt; 定义的模型无效，因此跳过了迭代次数。</target>
        </trans-unit>
        <trans-unit id="51f697c488b6017321338ddb492864c9436800d7" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to finding zero inliers.</source>
          <target state="translated">由于发现零离群值而跳过的迭代次数。</target>
        </trans-unit>
        <trans-unit id="6eebd535eebcad36fc18ca23295141a0bc8384b3" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt;.</source>
          <target state="translated">由于 &lt;code&gt;is_data_valid&lt;/code&gt; 定义的数据无效，因此跳过了迭代次数。</target>
        </trans-unit>
        <trans-unit id="2b48b7f3d47c667152c7041a648c896ae52b12ff" translate="yes" xml:space="preserve">
          <source>Number of iterations taken to converge.</source>
          <target state="translated">收敛的迭代次数。</target>
        </trans-unit>
        <trans-unit id="63b22566940c8c05aad34ed364e32e6bea85ba5f" translate="yes" xml:space="preserve">
          <source>Number of iterations that &lt;code&gt;scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)&lt;/code&gt; has run for.</source>
          <target state="translated">进行了 &lt;code&gt;scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)&lt;/code&gt; 的迭代次数。</target>
        </trans-unit>
        <trans-unit id="e35e76f80d1bcb32a849fe5cd7421a6593683d9d" translate="yes" xml:space="preserve">
          <source>Number of iterations that fmin_l_bfgs_b has run for.</source>
          <target state="translated">fmin_l_bfgs_b运行的次数。</target>
        </trans-unit>
        <trans-unit id="e6fe9562687f3b9f37db26e9dd5d7295821884aa" translate="yes" xml:space="preserve">
          <source>Number of iterations to perform.</source>
          <target state="translated">要执行的迭代次数。</target>
        </trans-unit>
        <trans-unit id="744edb5cd8af9d3cbdec3cef824f76ed36468258" translate="yes" xml:space="preserve">
          <source>Number of iterations with no change in the number of estimated clusters that stops the convergence.</source>
          <target state="translated">停止收敛的估计聚类数量不变的迭代次数。</target>
        </trans-unit>
        <trans-unit id="1bb6572e9c67b7f2e1d3c0099c8130bc63fa4d36" translate="yes" xml:space="preserve">
          <source>Number of iterations with no improvement to wait before early stopping.</source>
          <target state="translated">在提前停止之前,等待没有改善的迭代次数。</target>
        </trans-unit>
        <trans-unit id="427bd42a1575036c8163feb881b5305713a1194a" translate="yes" xml:space="preserve">
          <source>Number of iterations. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="20dbe7868d12b42e72b8007b758b8aa006423eb6" translate="yes" xml:space="preserve">
          <source>Number of iterations/sweeps over the training dataset to perform during training.</source>
          <target state="translated">训练过程中对训练数据集进行的迭代/扫频次数。</target>
        </trans-unit>
        <trans-unit id="805e89de9bc259ba0d4faba86a9892d5aeb2c894" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">要并行运行的作业数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f64638965b4156e5561d4f1aeb7b5023899255aa" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">要并行运行的作业数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="68e07911a64110ae2d25f4573c1be042d5d1283e" translate="yes" xml:space="preserve">
          <source>Number of label for each output.</source>
          <target state="translated">每个输出的标签数量。</target>
        </trans-unit>
        <trans-unit id="bd419af7c37c78ed35cd8f556746c5d780f24447" translate="yes" xml:space="preserve">
          <source>Number of layers.</source>
          <target state="translated">层数:</target>
        </trans-unit>
        <trans-unit id="4192e6479d3e36a298ef5ede4c2274eeba61eb5b" translate="yes" xml:space="preserve">
          <source>Number of leaves in the hierarchical tree.</source>
          <target state="translated">层次树的叶子数量。</target>
        </trans-unit>
        <trans-unit id="ba1aa7966ff18979251514a0f2aad7e015769458" translate="yes" xml:space="preserve">
          <source>Number of leaves.</source>
          <target state="translated">叶子的数量。</target>
        </trans-unit>
        <trans-unit id="cfcbfd1023f8a82de0be1bdb45b84e4fb92fdade" translate="yes" xml:space="preserve">
          <source>Number of mini-batch iterations to perform.</source>
          <target state="translated">要执行的小批量迭代次数。</target>
        </trans-unit>
        <trans-unit id="4bc27955a0ba30e7799dd7d637ec50bb558a2a01" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors effectively used.</source>
          <target state="translated">有效利用的最近邻居的数量。</target>
        </trans-unit>
        <trans-unit id="eff81c828ce86aeb5087b71b68182742b417d4b0" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors for nearest_neighbors graph building.</source>
          <target state="translated">构建nearest_neighbors图的最近邻居数量。</target>
        </trans-unit>
        <trans-unit id="f4b6da30fa273de202c93a0a24f9b983a9a2a207" translate="yes" xml:space="preserve">
          <source>Number of neighboring samples to use for imputation.</source>
          <target state="translated">邻近样本的数量用来进行推算。</target>
        </trans-unit>
        <trans-unit id="216e3472c822df844cda9519c2636b73cd479f24" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample in the transformed sparse graph. For compatibility reasons, as each sample is considered as its own neighbor, one extra neighbor will be computed when mode == &amp;lsquo;distance&amp;rsquo;. In this case, the sparse graph contains (n_neighbors + 1) neighbors.</source>
          <target state="translated">变换后的稀疏图中每个样本的邻居数。出于兼容性原因，由于每个样本都被视为自己的邻居，因此当mode =='distance'时将计算一个额外的邻居。在这种情况下，稀疏图包含（n_neighbors + 1）个邻居。</target>
        </trans-unit>
        <trans-unit id="37fe95cfc748f25efeacf97021fc7a2313be0b5a" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample.</source>
          <target state="translated">每个样本的邻居数量。</target>
        </trans-unit>
        <trans-unit id="51b538d5b2a3f95b9485557e25d620a9a782f3b4" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample. (default is value passed to the constructor).</source>
          <target state="translated">每个样本的邻域数量(默认为传递给构造函数的值)。(默认是传递给构造函数的值)。</target>
        </trans-unit>
        <trans-unit id="efd458290903df55801a7ce6bf62f9ba73dd0009" translate="yes" xml:space="preserve">
          <source>Number of neighbors k that will be considered.</source>
          <target state="translated">将被考虑的邻居k的数量。</target>
        </trans-unit>
        <trans-unit id="d3cee20cf7566ae95a6af940493b4c430f93d3a6" translate="yes" xml:space="preserve">
          <source>Number of neighbors required. If not provided, this will return the number specified at the initialization.</source>
          <target state="translated">需要的邻居数量。如果没有提供,将返回初始化时指定的数量。</target>
        </trans-unit>
        <trans-unit id="1e55799760cfa2d3bdbd572fe607c1fc4b77b9d7" translate="yes" xml:space="preserve">
          <source>Number of neighbors to be returned from query function when it is not provided to the &lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">未提供给&lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;方法的查询函数返回的邻居数。</target>
        </trans-unit>
        <trans-unit id="3262363328a422de3ed07567136a319deb9ad271" translate="yes" xml:space="preserve">
          <source>Number of neighbors to get (default is the value passed to the constructor).</source>
          <target state="translated">要获取的邻居数量(默认是传递给构造函数的值)。</target>
        </trans-unit>
        <trans-unit id="02076e172db6b5e77d67d9ae83e2b88dc66a094e" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。</target>
        </trans-unit>
        <trans-unit id="e28eb76463a74cc573864c82f5c8b8d60708a92f" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。</target>
        </trans-unit>
        <trans-unit id="4a844d73b7e4afd6cea1487cf59defb5c0385114" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries. If n_neighbors is larger than the number of samples provided, all samples will be used.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。如果n_neighbors大于提供的样本数，则将使用所有样本。</target>
        </trans-unit>
        <trans-unit id="7e98c15b26d0846d8c1e878d641afc0e3d115b38" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。</target>
        </trans-unit>
        <trans-unit id="70cd89c4110a42556e2c733194f1c90f3d647ddb" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">用于连续变量的MI估计的邻居数，请参见&lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;和&lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;。较高的值会减少估计的方差，但可能会带来偏差。</target>
        </trans-unit>
        <trans-unit id="237e706a6f5317f1b4ad85e94d1e882cb7b24021" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">用于连续变量的MI估计的邻居数，请参见&lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;和&lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;。较高的值会减少估计的方差，但可能会带来偏差。</target>
        </trans-unit>
        <trans-unit id="9f8819cc7687f8afeb7c24c0200033a234d0c39c" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use when constructing the affinity matrix using the nearest neighbors method. Ignored for &lt;code&gt;affinity='rbf'&lt;/code&gt;.</source>
          <target state="translated">使用最近邻居方法构造亲和力矩阵时要使用的邻居数量。被忽略为 &lt;code&gt;affinity='rbf'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c37287ec818bb6dad17b995ed5729153d9a8118d" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; and &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">在解决方案的每一列中定位的非零系数的数量。仅由 &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; 和 &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; ，在 &lt;code&gt;omp&lt;/code&gt; 情况下被 &lt;code&gt;alpha&lt;/code&gt; 覆盖。</target>
        </trans-unit>
        <trans-unit id="3d8a9b81dd6bc7c054449c6745360802b0f076b9" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm='lars'&lt;/code&gt; and &lt;code&gt;algorithm='omp'&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">在解决方案的每一列中定位的非零系数的数量。仅由 &lt;code&gt;algorithm='lars'&lt;/code&gt; 和 &lt;code&gt;algorithm='omp'&lt;/code&gt; ，在 &lt;code&gt;omp&lt;/code&gt; 情况下被 &lt;code&gt;alpha&lt;/code&gt; 覆盖。</target>
        </trans-unit>
        <trans-unit id="0be2c79389c0a56a89ad2014f6366b3f95d2bca8" translate="yes" xml:space="preserve">
          <source>Number of other features to use to estimate the missing values of each feature column. Nearness between features is measured using the absolute correlation coefficient between each feature pair (after initial imputation). To ensure coverage of features throughout the imputation process, the neighbor features are not necessarily nearest, but are drawn with probability proportional to correlation for each imputed target feature. Can provide significant speed-up when the number of features is huge. If &lt;code&gt;None&lt;/code&gt;, all features will be used.</source>
          <target state="translated">用于估计每个要素列的缺失值的其他要素的数量。使用每个要素对之间的绝对相关系数（在初始插补之后）测量要素之间的邻近度。为了确保整个插补过程中的要素覆盖，相邻要素不一定是最接近的，而是以与每个插补目标要素的相关性成正比的概率绘制。当功能数量巨大时，可以大大提高速度。如果为 &lt;code&gt;None&lt;/code&gt; ，则将使用所有功能。</target>
        </trans-unit>
        <trans-unit id="27f9bf5a85bc89aa70ea3dbacba13e73a444a9f8" translate="yes" xml:space="preserve">
          <source>Number of outputs.</source>
          <target state="translated">产出数量:</target>
        </trans-unit>
        <trans-unit id="a01758eccae198371ad1fbda71e0227c6924ab24" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">要运行的并行作业数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="aec9eb1029d40469b12f590579b2421b0ac783c2" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">要运行的并行作业数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="89260d16706c6571daecae9b230dfb394e4f8e34" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are produced.</source>
          <target state="translated">产生的参数设置数量。</target>
        </trans-unit>
        <trans-unit id="26680dedc0c193794be077118d1d33ec7cee22de" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.</source>
          <target state="translated">n_iter对运行时间与解决方案的质量进行了权衡。</target>
        </trans-unit>
        <trans-unit id="9b3af5a87173ff58737497b2a7b2dff4ac22b716" translate="yes" xml:space="preserve">
          <source>Number of passes over the dataset.</source>
          <target state="translated">对数据集的访问次数。</target>
        </trans-unit>
        <trans-unit id="e919298382f2b30ec9254222b02df5121a7447b9" translate="yes" xml:space="preserve">
          <source>Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified &lt;code&gt;leaf_size&lt;/code&gt;, a leaf node is guaranteed to satisfy &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt;, except in the case that &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt;.</source>
          <target state="translated">切换为蛮力的点数。更改leaf_size不会影响查询的结果，但是会显着影响查询的速度以及存储构造的树所需的内存。存储树比例尺所需的内存量约为n_samples / leaf_size。对于指定的 &lt;code&gt;leaf_size&lt;/code&gt; ，保证叶子节点满足 &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt; ，除非 &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="74f0e4f1324b195e40b6b67840245cc6639acde5" translate="yes" xml:space="preserve">
          <source>Number of power iterations used to stabilize the result</source>
          <target state="translated">用于稳定结果的幂级迭代次数。</target>
        </trans-unit>
        <trans-unit id="3af0fded49ca0f3c99c5f4242edefb1980f1ee1e" translate="yes" xml:space="preserve">
          <source>Number of power iterations. It can be used to deal with very noisy problems. When &amp;lsquo;auto&amp;rsquo;, it is set to 4, unless &lt;code&gt;n_components&lt;/code&gt; is small (&amp;lt; .1 * min(X.shape)) &lt;code&gt;n_iter&lt;/code&gt; in which case is set to 7. This improves precision with few components.</source>
          <target state="translated">功率迭代次数。它可以用于处理非常嘈杂的问题。如果为'auto'，则将其设置为4，除非 &lt;code&gt;n_components&lt;/code&gt; 很小（&amp;lt;.1 * min（X.shape）），在这种情况下，将 &lt;code&gt;n_iter&lt;/code&gt; 设置为7。这将提高组件数量的精度。</target>
        </trans-unit>
        <trans-unit id="01905db27e1b09268197900ceb99a1346e890115" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The str can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">并行执行的预调度作业数（默认为全部）。该选项可以减少分配的内存。str可以是类似&amp;ldquo; 2 * n_jobs&amp;rdquo;的表达式。</target>
        </trans-unit>
        <trans-unit id="7c2b5ab18e2bf242894b9a2ecca14a388d432f49" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The string can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">并行执行的预调度作业数（默认为全部）。该选项可以减少分配的内存。该字符串可以是类似于&amp;ldquo; 2 * n_jobs&amp;rdquo;的表达式。</target>
        </trans-unit>
        <trans-unit id="344e1da2c8fa0e4b376ce3e457a99189b911e25a" translate="yes" xml:space="preserve">
          <source>Number of previous iterations completed on the dictionary used for initialization.</source>
          <target state="translated">用于初始化的字典上完成的前几次迭代次数。</target>
        </trans-unit>
        <trans-unit id="20853d9102158a366a61d28a6b2cb29c20c98681" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative density function.</source>
          <target state="translated">要计算的量子数。它与用于分解累积密度函数的地标数目相对应。</target>
        </trans-unit>
        <trans-unit id="548caec42d172e8575f71a33916af24287471704" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative distribution function. If n_quantiles is larger than the number of samples, n_quantiles is set to the number of samples as a larger number of quantiles does not give a better approximation of the cumulative distribution function estimator.</source>
          <target state="translated">要计算的量子数。它对应于用来分散累积分布函数的地标数量。如果n_quantiles大于样本数,则n_quantiles设置为样本数,因为较多的量子数并不能更好地逼近累积分布函数估计器。</target>
        </trans-unit>
        <trans-unit id="e4aaf1e86836dfafd99ac1220487fd647e794f84" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried with the k-means algorithm.</source>
          <target state="translated">用k-means算法尝试的随机初始化次数。</target>
        </trans-unit>
        <trans-unit id="b43bc8af90e8df6a17a3d2db5f152fc9e0f7509e" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the &lt;code&gt;n_init&lt;/code&gt; initializations as measured by inertia.</source>
          <target state="translated">尝试的随机初始化的数量。与KMeans相反，该算法仅使用一次惯性测量的 &lt;code&gt;n_init&lt;/code&gt; 最佳初始化，仅运行一次。</target>
        </trans-unit>
        <trans-unit id="2a775249dab61ada8ba714fbef3fe2a6cd5e7f9a" translate="yes" xml:space="preserve">
          <source>Number of random selection trials until one of the stop criteria is met. It is always &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt;.</source>
          <target state="translated">达到停止标准之一之前的随机选择试验次数。它总是 &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ddb00b53d153c760e3c244cb1587828c964053be" translate="yes" xml:space="preserve">
          <source>Number of randomized models.</source>
          <target state="translated">随机模型的数量。</target>
        </trans-unit>
        <trans-unit id="6e7920a40024bb45accfba5d3a9412bad8885ccd" translate="yes" xml:space="preserve">
          <source>Number of re-shuffling &amp;amp; splitting iterations.</source>
          <target state="translated">重新改组和拆分迭代的次数。</target>
        </trans-unit>
        <trans-unit id="8c1de77526ac5586c3170ef35d398449f2b6a01e" translate="yes" xml:space="preserve">
          <source>Number of rows and columns (resp.) in the bicluster.</source>
          <target state="translated">双簇中的行数和列数(简称)。</target>
        </trans-unit>
        <trans-unit id="ad1b9067ab876b7409a0c802cf769015719aca95" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">拟合过程中每个(类、特征)遇到的样本数。这个值是由提供的样本权重加权的。</target>
        </trans-unit>
        <trans-unit id="c92a24738a539e752aec89fe917078bdb81b48d8" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">在拟合过程中,每个类所遇到的样本数量。这个值是由提供的样本权重加权的。</target>
        </trans-unit>
        <trans-unit id="7d9434e4be81d003217d0ff99bec2958d6cf8f1c" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each feature during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">在拟合过程中,每个特征遇到的样本数量。这个值是由提供的样本权重加权的。</target>
        </trans-unit>
        <trans-unit id="4189046e920c071a46d31153d30f2c5546e5d75d" translate="yes" xml:space="preserve">
          <source>Number of samples in a subcluster.</source>
          <target state="translated">一个子群中的样本数量。</target>
        </trans-unit>
        <trans-unit id="d6a1b136f66f610a4896adec7fc65cb72260eca1" translate="yes" xml:space="preserve">
          <source>Number of samples in the training data.</source>
          <target state="translated">训练数据中的样本数。</target>
        </trans-unit>
        <trans-unit id="b1b8d68fdf55246f42bd4140ab8cdd3ea5232e3c" translate="yes" xml:space="preserve">
          <source>Number of samples seen so far, excluded X.</source>
          <target state="translated">迄今所见样本数,排除X。</target>
        </trans-unit>
        <trans-unit id="f3eb4ebcff443a5740a69d115e4c7d66ed2b7058" translate="yes" xml:space="preserve">
          <source>Number of samples to calculate the parameters. This is at least the number of features (plus 1 if fit_intercept=True) and the number of samples as a maximum. A lower number leads to a higher breakdown point and a low efficiency while a high number leads to a low breakdown point and a high efficiency. If None, take the minimum number of subsamples leading to maximal robustness. If n_subsamples is set to n_samples, Theil-Sen is identical to least squares.</source>
          <target state="translated">计算参数的样本数。这至少是特征数(如果fit_intercept=True,则加1)和最大样本数。较低的数字导致较高的击穿点和较低的效率,而较高的数字导致较低的击穿点和较高的效率。如果None,取导致最大鲁棒性的最小子样本数。如果n_subsamples设置为n_samples,则Theil-Sen与最小二乘法相同。</target>
        </trans-unit>
        <trans-unit id="fc350dda13f5c287c8548b6575ceb1d2c780f61c" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. Defaults to 1.</source>
          <target state="translated">要生成的样本数量。默认值为1。</target>
        </trans-unit>
        <trans-unit id="e94e897f1bb653d4e0feaefd5987d4a553f8af8b" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays.</source>
          <target state="translated">要生成的样本数量。如果将其设为 &quot;无&quot;,则会自动设置为数组的第一维。</target>
        </trans-unit>
        <trans-unit id="1a167b23f9bb21704b10da0ef2fc738d507dce40" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays. If replace is False it should not be larger than the length of arrays.</source>
          <target state="translated">要生成的样本数量。如果留为None,则自动设置为数组的第一维。如果替换为False,则不应大于数组的长度。</target>
        </trans-unit>
        <trans-unit id="37b65d0e64d2d03034e5f2f5fa109bac79447708" translate="yes" xml:space="preserve">
          <source>Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.</source>
          <target state="translated">为加快初始化速度而随机抽样的样本数(有时以牺牲精度为代价):唯一的算法是通过在数据的随机子集上运行批量KMeans来初始化的。这需要大于n_clusters。</target>
        </trans-unit>
        <trans-unit id="79fd133ee683290a8c4b438718235e4555547cff" translate="yes" xml:space="preserve">
          <source>Number of samples. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">样本数。如果给定一个数组,它将以数组的方式计算一个安全的成分数。</target>
        </trans-unit>
        <trans-unit id="ea4ca73ab41ec6033a853674e7fbc815a311d3cf" translate="yes" xml:space="preserve">
          <source>Number of samples. Pass n_samples when the slices are to be used for sparse matrix indexing; slicing off-the-end raises an exception, while it works for NumPy arrays.</source>
          <target state="translated">采样数,当切片用于稀疏矩阵索引时,传递n_samples。当切片要用于稀疏矩阵索引时,传递n_samples;在结束时切片会引发一个异常,而对于NumPy数组来说,它是可行的。</target>
        </trans-unit>
        <trans-unit id="a75d9ceb8c321c78e9909168b2356ee01f06d1c4" translate="yes" xml:space="preserve">
          <source>Number of singular values and vectors to extract.</source>
          <target state="translated">要提取的单值和向量的数量。</target>
        </trans-unit>
        <trans-unit id="9259a302604f8c3d052d9766a0665f74598f4a66" translate="yes" xml:space="preserve">
          <source>Number of singular vectors to check.</source>
          <target state="translated">要检查的奇异向量的数量。</target>
        </trans-unit>
        <trans-unit id="4e03fb606fcab969781bb42da4618d24e54a8291" translate="yes" xml:space="preserve">
          <source>Number of slices to generate.</source>
          <target state="translated">要生成的片数。</target>
        </trans-unit>
        <trans-unit id="2834c0f8a56b1dcfce6f6e78db200759bce6dd7b" translate="yes" xml:space="preserve">
          <source>Number of spaces between edges. The higher it is, the wider the result.</source>
          <target state="translated">边缘之间的空间数。它越高,结果越宽。</target>
        </trans-unit>
        <trans-unit id="c55cc369cb9552b44b4a575f3aae7b0b751a97c8" translate="yes" xml:space="preserve">
          <source>Number of sparse atoms to extract.</source>
          <target state="translated">要提取的稀疏原子的数量。</target>
        </trans-unit>
        <trans-unit id="133c33b7f976c18813a243c5632b24f2c8e81111" translate="yes" xml:space="preserve">
          <source>Number of splits. Must be at least 2.</source>
          <target state="translated">分割的数量。必须至少是2个。</target>
        </trans-unit>
        <trans-unit id="a6bce09538dcde7e7ff60020a73de4974cae38ac" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of EM to reach the convergence.</source>
          <target state="translated">EM的最佳拟合达到收敛所使用的步数。</target>
        </trans-unit>
        <trans-unit id="aec50834e9d4a500ee385c37d29d58bdc624bb7e" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of inference to reach the convergence.</source>
          <target state="translated">推理的最佳拟合达到收敛所使用的步数。</target>
        </trans-unit>
        <trans-unit id="ef96b42c053cf6cd51d23012a0a52b84b2a07604" translate="yes" xml:space="preserve">
          <source>Number of support vectors for each class.</source>
          <target state="translated">每个类的支持向量的数量。</target>
        </trans-unit>
        <trans-unit id="424ae2b2f85d63b5b83778ea64c14167e1acf984" translate="yes" xml:space="preserve">
          <source>Number of targets</source>
          <target state="translated">目标数量</target>
        </trans-unit>
        <trans-unit id="abc9da602c481111cdc9cad2b9a2ec618fddfb11" translate="yes" xml:space="preserve">
          <source>Number of test samples in this split.</source>
          <target state="translated">本次拆分的测试样本数量。</target>
        </trans-unit>
        <trans-unit id="35ccbd0ed91056f0b431a8e36f769a8655c75e9b" translate="yes" xml:space="preserve">
          <source>Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.</source>
          <target state="translated">k-means算法在不同中心点种子下运行的次数。最终结果将是n_init连续运行的惯性的最佳输出。</target>
        </trans-unit>
        <trans-unit id="f584f00fb96d0392221b2f107adcb2345328d3b9" translate="yes" xml:space="preserve">
          <source>Number of times cross-validator needs to be repeated.</source>
          <target state="translated">交叉验证器需要重复的次数。</target>
        </trans-unit>
        <trans-unit id="5d2e8dfe07ab898c902f4c479175b6b09037f98d" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress.</source>
          <target state="translated">SMACOF算法在不同初始化下运行的次数。最终结果将是所有运行中的最佳输出,由最终应力最小的运行确定。</target>
        </trans-unit>
        <trans-unit id="61d47a44584bfde40c1396e5d7fc8603c469e589" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress. If &lt;code&gt;init&lt;/code&gt; is provided, this option is overridden and a single run is performed.</source>
          <target state="translated">SMACOF算法将使用不同的初始化运行的次数。最终结果将是运行的最佳输出，取决于最终应力最小的运行。如果提供了 &lt;code&gt;init&lt;/code&gt; ，则将覆盖此选项并执行一次运行。</target>
        </trans-unit>
        <trans-unit id="279a7d188f8d456ddd160319a5480a2db5aa1c81" translate="yes" xml:space="preserve">
          <source>Number of times to permute &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; 的置换次数。</target>
        </trans-unit>
        <trans-unit id="463dac0c15a56b554ec940dbcedbd42982c379fb" translate="yes" xml:space="preserve">
          <source>Number of times to permute a feature.</source>
          <target state="translated">一个功能的permute次数。</target>
        </trans-unit>
        <trans-unit id="69631a318e07c7e122bb29c914f2e0417bbb3ea3" translate="yes" xml:space="preserve">
          <source>Number of top features to select. The &amp;ldquo;all&amp;rdquo; option bypasses selection, for use in a parameter search.</source>
          <target state="translated">要选择的主要功能数。&amp;ldquo; all&amp;rdquo;选项绕过选择，用于参数搜索。</target>
        </trans-unit>
        <trans-unit id="da4c15da76668749b2d08dac7e93fa89fa01cae3" translate="yes" xml:space="preserve">
          <source>Number of topics.</source>
          <target state="translated">专题数量:</target>
        </trans-unit>
        <trans-unit id="fbddcfb20eac49b636d0567ae2783e45f24d5db9" translate="yes" xml:space="preserve">
          <source>Number of trees in the LSH Forest.</source>
          <target state="translated">LSH森林中的树木数量。</target>
        </trans-unit>
        <trans-unit id="f59a66952049f5c09c592626a93864184fb52de6" translate="yes" xml:space="preserve">
          <source>Number of trees in the forest.</source>
          <target state="translated">森林中的树木数量;</target>
        </trans-unit>
        <trans-unit id="883143c355bb70d9c124548ac182b0a674cf4c90" translate="yes" xml:space="preserve">
          <source>Number of values per feature.</source>
          <target state="translated">每个特征值的数量。</target>
        </trans-unit>
        <trans-unit id="3d3c8a841ea2fec708f92a22e6cb69db77e1725b" translate="yes" xml:space="preserve">
          <source>Number of vectors to use in calculating the SVD. Corresponds to &lt;code&gt;ncv&lt;/code&gt; when &lt;code&gt;svd_method=arpack&lt;/code&gt; and &lt;code&gt;n_oversamples&lt;/code&gt; when &lt;code&gt;svd_method&lt;/code&gt; is &amp;lsquo;randomized`.</source>
          <target state="translated">用于计算SVD的向量数。对应于 &lt;code&gt;ncv&lt;/code&gt; 当 &lt;code&gt;svd_method=arpack&lt;/code&gt; 和 &lt;code&gt;n_oversamples&lt;/code&gt; 当 &lt;code&gt;svd_method&lt;/code&gt; 是&amp;ldquo;randomized`。</target>
        </trans-unit>
        <trans-unit id="16bf53dde5c63fb6777b19bf3ca8bb646d21ca57" translate="yes" xml:space="preserve">
          <source>Number of weight updates performed during training. Same as &lt;code&gt;(n_iter_ * n_samples)&lt;/code&gt;.</source>
          <target state="translated">训练期间进行的体重更新次数。与 &lt;code&gt;(n_iter_ * n_samples)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="cfc2be0c624984ee3eedecc63144bb2eb0e00cd3" translate="yes" xml:space="preserve">
          <source>Numbers of training examples that has been used to generate the learning curve. Note that the number of ticks might be less than n_ticks because duplicate entries will be removed.</source>
          <target state="translated">用来生成学习曲线的训练例子的数量。请注意,ticks的数量可能会小于n_ticks,因为重复的条目会被删除。</target>
        </trans-unit>
        <trans-unit id="a28c04c9b4b005997c9b362ad026f41b8cd86540" translate="yes" xml:space="preserve">
          <source>Numeric Features:</source>
          <target state="translated">数值特征。</target>
        </trans-unit>
        <trans-unit id="89c43bf4b62114e4d6b82aa7a39bcd64acde71ea" translate="yes" xml:space="preserve">
          <source>Numeric stopping criterion (WRITEME). 1e-3 by default.</source>
          <target state="translated">数值停止标准(WRITEME)。默认为1e-3。</target>
        </trans-unit>
        <trans-unit id="546b4b9a9bb1a271c23a369b5102c7b719bb257b" translate="yes" xml:space="preserve">
          <source>Numerical solver to use.</source>
          <target state="translated">数值求解器使用。</target>
        </trans-unit>
        <trans-unit id="e91bee1467e40de4d946ed662375c173925b59f5" translate="yes" xml:space="preserve">
          <source>Numerical solver to use:</source>
          <target state="translated">数值求解器使用。</target>
        </trans-unit>
        <trans-unit id="1bda3e35c6cc189118f551c9ef807d4c37dc07f6" translate="yes" xml:space="preserve">
          <source>Numerical solver to use: &amp;lsquo;cd&amp;rsquo; is a Coordinate Descent solver. &amp;lsquo;mu&amp;rsquo; is a Multiplicative Update solver.</source>
          <target state="translated">要使用的数值求解器：'cd'是坐标下降求解器。'mu'是一个乘法更新求解器。</target>
        </trans-unit>
        <trans-unit id="c42d401e991cba0a784aff1388e26ed9b57a65e8" translate="yes" xml:space="preserve">
          <source>O. Ledoit and M. Wolf, &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">O. Ledoit和M. Wolf，&amp;ldquo;大尺寸协方差矩阵的适当条件估计器&amp;rdquo;，《多元分析杂志》，第88卷，第2期，2004年2月，第365-411页。</target>
        </trans-unit>
        <trans-unit id="e39d7c7a6dfc71c75f7fd3b1688e4255ab0569b5" translate="yes" xml:space="preserve">
          <source>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.</source>
          <target state="translated">O.L.Mangasarian,W.N.Street and W.H.Wolberg.乳腺癌诊断和预后通过线性编程。运营研究,43(4),570-577页,1995年7月-8月。</target>
        </trans-unit>
        <trans-unit id="dea6ae2f186812bc2bf8114a674ec0e8c8de8039" translate="yes" xml:space="preserve">
          <source>OAS is a particular form of shrinkage described in &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">Chen等人在IEEE Trans的&amp;ldquo; MMSE协方差估计的收缩算法&amp;rdquo;中描述了OAS是一种特殊的收缩形式。在标志上。Proc。，第58卷，第10期，2010年10月。</target>
        </trans-unit>
        <trans-unit id="516f97783bd415e3a50d6dad8302febb07d2e198" translate="yes" xml:space="preserve">
          <source>OCCUPATION</source>
          <target state="translated">OCCUPATION</target>
        </trans-unit>
        <trans-unit id="d588c2d5cad6e344a9a328bc0dcc94f63bfe1c53" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Clerical</source>
          <target state="translated">OCCUPATION_Clerical</target>
        </trans-unit>
        <trans-unit id="b725bc8de0a483c5d88499d9e7c87c7ae4685ba8" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Management</source>
          <target state="translated">OCCUPATION_Management</target>
        </trans-unit>
        <trans-unit id="0e54eeff266f2a17bed8c69e66148a30421390e0" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Other</source>
          <target state="translated">OCCUPATION_Other</target>
        </trans-unit>
        <trans-unit id="d50ba20894189c3830106f0cfb4a70b0e6554b4e" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Professional</source>
          <target state="translated">OCCUPATION_Professional</target>
        </trans-unit>
        <trans-unit id="d9264bc2d4c97fd3584da75ee0731d202c6b28fe" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Sales</source>
          <target state="translated">OCCUPATION_Sales</target>
        </trans-unit>
        <trans-unit id="7c720959f75a9b22fee1afe843481ec6692d4aa6" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Service</source>
          <target state="translated">OCCUPATION_Service</target>
        </trans-unit>
        <trans-unit id="f3fd8009dd2433d1a63abbabb480a18d05e74108" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines</source>
          <target state="translated">稀释葡萄酒的OD280/OD315</target>
        </trans-unit>
        <trans-unit id="2f76e133c144664f6ceed4509b6ad3d9fe14a67d" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines:</source>
          <target state="translated">稀释葡萄酒的OD280/OD315。</target>
        </trans-unit>
        <trans-unit id="9ce3bd4224c8c1780db56b4125ecf3f24bf748b7" translate="yes" xml:space="preserve">
          <source>OK</source>
          <target state="translated">OK</target>
        </trans-unit>
        <trans-unit id="8e8565eb895a4e523ac266f2a6f2af45cda869f8" translate="yes" xml:space="preserve">
          <source>OMP is based on a greedy algorithm that includes at each step the atom most highly correlated with the current residual. It is similar to the simpler matching pursuit (MP) method, but better in that at each iteration, the residual is recomputed using an orthogonal projection on the space of the previously chosen dictionary elements.</source>
          <target state="translated">OMP是基于一种贪婪的算法,在每一步都包含与当前残差相关性最高的原子。它类似于更简单的匹配追寻(MP)方法,但更好的是,在每次迭代时,残差都会在先前选择的字典元素的空间上使用正交投影重新计算。</target>
        </trans-unit>
        <trans-unit id="702567365ae2f6da8d5fc9650aab7f68f2e2b4bd" translate="yes" xml:space="preserve">
          <source>OOB Errors for Random Forests</source>
          <target state="translated">随机森林的OOB错误</target>
        </trans-unit>
        <trans-unit id="7556880ffb905f4996fa16b161902fde13e5d1be" translate="yes" xml:space="preserve">
          <source>OPTICS</source>
          <target state="translated">OPTICS</target>
        </trans-unit>
        <trans-unit id="3921b01080f70880ca169ee2dd262001f08a9a03" translate="yes" xml:space="preserve">
          <source>OPTICS (Ordering Points To Identify the Clustering Structure), closely related to DBSCAN, finds core sample of high density and expands clusters from them &lt;a href=&quot;#r2c55e37003fe-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. Unlike DBSCAN, keeps cluster hierarchy for a variable neighborhood radius. Better suited for usage on large datasets than the current sklearn implementation of DBSCAN.</source>
          <target state="translated">与DBSCAN密切相关的OPTICS（识别聚类结构的订购点）发现了高密度的核心样本，并从中扩展了聚类&lt;a href=&quot;#r2c55e37003fe-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。与DBSCAN不同，保留集群层次结构用于可变的邻域半径。与当前的DBSCAN sklearn实现相比，它更适合用于大型数据集。</target>
        </trans-unit>
        <trans-unit id="3657cfede2d1ca1450e1e96704c7fe1e79174b7f" translate="yes" xml:space="preserve">
          <source>OPTICS ordered point indices (&lt;code&gt;ordering_&lt;/code&gt;)</source>
          <target state="translated">OPTICS有序点索引（ &lt;code&gt;ordering_&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="2b77a29777f0317be507e501f5c60c74e4daaff5" translate="yes" xml:space="preserve">
          <source>OR, if affinity==`precomputed`, a precomputed affinity matrix of shape (n_samples, n_samples)</source>
          <target state="translated">或者,如果affinity==`precomputed`,则预先计算一个形状为(n_samples,n_samples)的亲和力矩阵。</target>
        </trans-unit>
        <trans-unit id="c8f36dd22506f2db935605e7016ba4725ee8d954" translate="yes" xml:space="preserve">
          <source>OVR + L1 penalty</source>
          <target state="translated">普通车牌号码+L1罚款</target>
        </trans-unit>
        <trans-unit id="6fb4b4e4f3901ecb1795e224abe18919de690335" translate="yes" xml:space="preserve">
          <source>OVR + L2 penalty</source>
          <target state="translated">普通车牌号+二级罚款</target>
        </trans-unit>
        <trans-unit id="cb5d65d3f62b5d33c694bb026fc2cc2e2c9008af" translate="yes" xml:space="preserve">
          <source>Object that mocks the urlopen function to fake requests to mldata.</source>
          <target state="translated">模拟urlopen函数的对象,以伪造对mldata的请求。</target>
        </trans-unit>
        <trans-unit id="e59a9b80a8b5844a54b21160c3e6341a042b77f2" translate="yes" xml:space="preserve">
          <source>Object that stores computed values.</source>
          <target state="translated">存储计算值的对象。</target>
        </trans-unit>
        <trans-unit id="04c754a9ec758f22d2ae91b0fe2718c4051ca8ed" translate="yes" xml:space="preserve">
          <source>Object used to transform multiclass labels to binary labels and vice-versa.</source>
          <target state="translated">用于将多类标签转换为二进制标签,反之亦然。</target>
        </trans-unit>
        <trans-unit id="cdd1673e245cacca55f04fb3561b4eb5194072ad" translate="yes" xml:space="preserve">
          <source>Objects that will be checked for consistent length.</source>
          <target state="translated">要检查长度是否一致的对象。</target>
        </trans-unit>
        <trans-unit id="ca9385c00c56b402f0d7c8ffd3817a9453089565" translate="yes" xml:space="preserve">
          <source>Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</source>
          <target state="translated">从决策树和朴素的贝叶斯分类器中获得校准的概率估计，B。Zadrozny＆C. Elkan，ICML 2001</target>
        </trans-unit>
        <trans-unit id="e90a2c57a395bd5ca1744a90561d5ec67c512ffb" translate="yes" xml:space="preserve">
          <source>Obviously when the number of features increases so does the memory consumption of each example. Indeed, for a matrix of \(M\) instances with \(N\) features, the space complexity is in \(O(NM)\). From a computing perspective it also means that the number of basic operations (e.g., multiplications for vector-matrix products in linear models) increases too. Here is a graph of the evolution of the prediction latency with the number of features:</source>
          <target state="translated">显然,当特征数量增加时,每个实例的内存消耗也会增加。事实上,对于一个具有(N)特征的矩阵(M)实例,空间复杂度为(O(NM))。从计算的角度来看,这也意味着基本运算的数量(例如,线性模型中向量-矩阵乘积的乘法)也会增加。下面是预测延迟随特征数量的变化图。</target>
        </trans-unit>
        <trans-unit id="215c08c61e401481973fc6ab07ef3f7e0eb253cc" translate="yes" xml:space="preserve">
          <source>Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel with the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If we give this parameter a value of &lt;code&gt;-1&lt;/code&gt;, grid search will detect how many cores are installed and use them all:</source>
          <target state="translated">显然，这种详尽的搜索可能很昂贵。如果我们拥有多个CPU内核，我们可以告诉网格搜索器尝试将这8个参数组合与 &lt;code&gt;n_jobs&lt;/code&gt; 参数并行进行。如果我们将此参数的值设置为 &lt;code&gt;-1&lt;/code&gt; ，那么网格搜索将检测到已安装了多少个内核并全部使用了它们：</target>
        </trans-unit>
        <trans-unit id="b4b9ad57c64718cb6c7c5d4cbab51ee018de2ade" translate="yes" xml:space="preserve">
          <source>Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.</source>
          <target state="translated">出现次数是一个好的开始,但有一个问题:较长的文档会比较短的文档有更高的平均次数值,即使它们可能谈论相同的主题。</target>
        </trans-unit>
        <trans-unit id="ca59a1039148105183d8291ca83a4fbed4483e6f" translate="yes" xml:space="preserve">
          <source>Of course, we cannot use the transformer to make any predictions. We should wrap this in a &lt;code&gt;Pipeline&lt;/code&gt; with a classifier (e.g., a &lt;code&gt;DecisionTreeClassifier&lt;/code&gt;) to be able to make predictions.</source>
          <target state="translated">当然，我们不能使用变压器进行任何预测。我们应该使用分类器（例如 &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; ）将其包装在 &lt;code&gt;Pipeline&lt;/code&gt; 中，以便能够进行预测。</target>
        </trans-unit>
        <trans-unit id="d31e6b35c3a4fbda0c959d2368ee4f77d248cc70" translate="yes" xml:space="preserve">
          <source>Of particular interest is the ability of &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt; to mimic the behavior of missForest, a popular imputation package for R. In this example, we have chosen to use &lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; instead of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestRegressor&lt;/code&gt;&lt;/a&gt; (as in missForest) due to its increased speed.</source>
          <target state="translated">特别令人感兴趣的是&lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt; &lt;/a&gt;的功能，以模仿missForest（R的流行插补包）的行为。在此示例中，我们选择使用&lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt; &lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt; &lt;/a&gt;而不是&lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;sklearn.ensemble.RandomForestRegressor&lt;/code&gt; &lt;/a&gt;（如missForest），因为它提高了速度。</target>
        </trans-unit>
        <trans-unit id="d2bfdaca8f6fadc90e32a081ace94f3ad9884e84" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">偏移量用于根据原始分数定义决策函数。我们具有以下关系： &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。 &lt;code&gt;offset_&lt;/code&gt; 定义如下。当污染参数设置为&amp;ldquo;自动&amp;rdquo;时，偏移量等于-0.5，这是因为离群值接近0而离群值接近-1。如果提供的污染参数不同于&amp;ldquo;自动&amp;rdquo;，则以这样的方式定义偏移量，即在训练中获得期望的异常值数量（决策函数&amp;lt;0的样本）。</target>
        </trans-unit>
        <trans-unit id="64b2af0bc2328de785be4029344182e16e12fcc6" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. Assuming behaviour == &amp;lsquo;new&amp;rsquo;, &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training. Assuming the behaviour parameter is set to &amp;lsquo;old&amp;rsquo;, we always have &lt;code&gt;offset_ = -0.5&lt;/code&gt;, making the decision function independent from the contamination parameter.</source>
          <target state="translated">偏移量用于根据原始分数定义决策函数。我们具有以下关系： &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。假设行为=='new'，则 &lt;code&gt;offset_&lt;/code&gt; 定义如下。当污染参数设置为&amp;ldquo;自动&amp;rdquo;时，偏移量等于-0.5，这是因为离群值的分数接近0而离群值的分数接近-1。如果提供的污染参数不同于&amp;ldquo;自动&amp;rdquo;，则以这样的方式定义偏移量，即在训练中获得预期的异常值数量（决策函数&amp;lt;0的样本）。假设行为参数设置为&amp;ldquo;旧&amp;rdquo;，我们总是具有 &lt;code&gt;offset_ = -0.5&lt;/code&gt; ，从而使决策函数独立于污染参数。</target>
        </trans-unit>
        <trans-unit id="bbd227107da9d921e8bc12d3a3ca7fd4c0bd101f" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. The offset depends on the contamination parameter and is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">偏移量用于根据原始分数定义决策函数。我们具有以下关系： &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。偏移量取决于污染参数，其定义方式是在训练中获得预期的异常值数量（决策函数&amp;lt;0的样本）。</target>
        </trans-unit>
        <trans-unit id="4f4356395ebd6023fbdce24e12feab7e5ca80606" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt;. The offset is the opposite of &lt;code&gt;intercept_&lt;/code&gt; and is provided for consistency with other outlier detection algorithms.</source>
          <target state="translated">偏移量用于根据原始分数定义决策函数。我们具有以下关系：Decision_function = score_samples- &lt;code&gt;offset_&lt;/code&gt; 。偏移量与 &lt;code&gt;intercept_&lt;/code&gt; 相反，并且为与其他异常值检测算法保持一致而提供。</target>
        </trans-unit>
        <trans-unit id="9195b75fbc020bb9db88d8b131967914e6de2adf" translate="yes" xml:space="preserve">
          <source>Offset used to obtain binary labels from the raw scores. Observations having a negative_outlier_factor smaller than &lt;code&gt;offset_&lt;/code&gt; are detected as abnormal. The offset is set to -1.5 (inliers score around -1), except when a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided. In that case, the offset is defined in such a way we obtain the expected number of outliers in training.</source>
          <target state="translated">偏移量用于从原始分数获取二进制标签。 negative_outlier_factor小于 &lt;code&gt;offset_&lt;/code&gt; 的观测值被检测为异常。偏移设置为-1.5（内部分数约为-1），除非提供的污染参数不同于&amp;ldquo;自动&amp;rdquo;。在那种情况下，以这样的方式定义偏移量，即我们可以在训练中获得预期的异常值数量。</target>
        </trans-unit>
        <trans-unit id="36fd88d1882973048dccc0ac8ca74e6c4f6b2ec1" translate="yes" xml:space="preserve">
          <source>Often features are not given as continuous values but categorical. For example a person could have features &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt;. Such features can be efficiently coded as integers, for instance &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; could be expressed as &lt;code&gt;[0, 1, 3]&lt;/code&gt; while &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; would be &lt;code&gt;[1, 2, 1]&lt;/code&gt;.</source>
          <target state="translated">通常，功能不是连续值而是分类的。例如，某人可能具有以下特征： &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt; ， &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt; ， &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; 。此类功能可以有效地编码为整数，例如 &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; 可以表示为 &lt;code&gt;[0, 1, 3]&lt;/code&gt; 而 &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; 为 &lt;code&gt;[1, 2, 1]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3d1f21e77b74fb7449c1f9b0570088bab1bd6c20" translate="yes" xml:space="preserve">
          <source>Often features do not contribute equally to predict the target response; in many situations the majority of the features are in fact irrelevant. When interpreting a model, the first question usually is: what are those important features and how do they contributing in predicting the target response?</source>
          <target state="translated">通常情况下,特征对预测目标响应的贡献并不一样;在许多情况下,大多数特征实际上是不相关的。在解释一个模型时,第一个问题通常是:那些重要的特征是什么,它们对预测目标反应的贡献如何?</target>
        </trans-unit>
        <trans-unit id="cd4e41585434180ead957592fb3bbf7ed399aaf1" translate="yes" xml:space="preserve">
          <source>Often it&amp;rsquo;s useful to add complexity to the model by considering nonlinear features of the input data. A simple and common method to use is polynomial features, which can get features&amp;rsquo; high-order and interaction terms. It is implemented in &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">通常，考虑输入数据的非线性特征会增加模型的复杂性。多项式特征是一种简单而通用的方法，它可以获取特征的高阶和相互作用项。它在&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; 中&lt;/a&gt;实现：</target>
        </trans-unit>
        <trans-unit id="e408c9080a80cd5dee3de8b66c635dedc13aaef1" translate="yes" xml:space="preserve">
          <source>Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.</source>
          <target state="translated">通常情况下,解决机器学习问题最困难的部分可能是为工作找到合适的估计器。</target>
        </trans-unit>
        <trans-unit id="7b3890ce47285c29340d329412b63023825aa83a" translate="yes" xml:space="preserve">
          <source>Often, you will want to convert an existing Python function into a transformer to assist in data cleaning or processing. You can implement a transformer from an arbitrary function with &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt;. For example, to build a transformer that applies a log transformation in a pipeline, do:</source>
          <target state="translated">通常，您将需要将现有的Python函数转换为转换器，以帮助进行数据清理或处理。您可以使用&lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt;从任意函数实现转换器。例如，要构建在管道中应用对数转换的转换器，请执行以下操作：</target>
        </trans-unit>
        <trans-unit id="3a99e53e60f11cdf73347e45ac4d6a8ace6059f3" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11</source>
          <target state="translated">Ojala and Garriga.Permutation Tests for Studying Classifier Performance.机器学习研究杂志》(2010)第11卷。</target>
        </trans-unit>
        <trans-unit id="4a78f8007754f084c0abbe2f8fe08318ed671586" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11 &lt;a href=&quot;http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf&quot;&gt;[pdf]&lt;/a&gt;.</source>
          <target state="translated">奥哈拉（Ojala）和加里加（Garriga）。用于研究分类器性能的排列测试。机器学习研究杂志（2010）卷。11 &lt;a href=&quot;http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf&quot;&gt;[pdf]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d82f7d71018bfffc818f9af5a47b640ae31345cd" translate="yes" xml:space="preserve">
          <source>Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tibshirani, David Botstein and Russ B. Altman, Missing value estimation methods for DNA microarrays, BIOINFORMATICS Vol. 17 no. 6, 2001 Pages 520-525.</source>
          <target state="translated">Olga Troyanskaya,Michael Cantor,Gavin Sherlock,Pat Brown,Trevor Hastie,Robert Tibshirani,David Botstein and Russ B.Altman,Missing value estimation methods for DNA microarrays,BIOINFORMATICS Vol.17 no.6,2001 Pages 520-525.</target>
        </trans-unit>
        <trans-unit id="f9aa2dba7b6fd084ffccc78f5a1359dabe654fd3" translate="yes" xml:space="preserve">
          <source>On &amp;ldquo;small&amp;rdquo; datasets (less than a few hundred points), the quantile transformer is prone to overfitting. The use of the power transform is then recommended.</source>
          <target state="translated">在&amp;ldquo;小型&amp;rdquo;数据集（少于几百个点）上，分位数转换器容易过拟合。然后建议使用功率变换。</target>
        </trans-unit>
        <trans-unit id="d0f97ce49fc19f915019c9855a072a57bec1774a" translate="yes" xml:space="preserve">
          <source>On L2-normalized data, this function is equivalent to linear_kernel.</source>
          <target state="translated">在L2归一化数据上,这个函数相当于线性核。</target>
        </trans-unit>
        <trans-unit id="d978bf78cd4e4a7f593a82a72e7f97f769b529af" translate="yes" xml:space="preserve">
          <source>On Spectral Clustering: Analysis and an algorithm, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</source>
          <target state="translated">关于频谱聚类：分析和算法，2001年Andrew Y. Ng，Michael I. Jordan，Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c042431c0ae0ab161c8569f0669e312480d87b4b" translate="yes" xml:space="preserve">
          <source>On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640&amp;ndash;650., Wilks, D. S., 1990a</source>
          <target state="translated">关于连续降水期的预报概率的组合。威。Forecasting，5，640&amp;ndash;650。，Wilks，DS，1990a</target>
        </trans-unit>
        <trans-unit id="05fe02625303adf1ec7a757f80f079f0cfb615a5" translate="yes" xml:space="preserve">
          <source>On the contrary the classical finite mixture model with a Dirichlet distribution prior will favor more uniformly weighted components and therefore tends to divide natural clusters into unnecessary sub-components.</source>
          <target state="translated">相反,具有Dirichlet分布先验的经典有限混合模型会倾向于更均匀的加权成分,因此倾向于将自然簇划分为不必要的子成分。</target>
        </trans-unit>
        <trans-unit id="a881270be1f0c36e65b4d9407272c7539d9eb831" translate="yes" xml:space="preserve">
          <source>On the diabetes dataset, find the optimal regularization parameter alpha.</source>
          <target state="translated">在糖尿病数据集上,找到最佳正则化参数α。</target>
        </trans-unit>
        <trans-unit id="d20d94e86b214eba2d2a083bdeb7805cae8a5dbd" translate="yes" xml:space="preserve">
          <source>On the digits dataset, plot the cross-validation score of a &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; estimator with an linear kernel as a function of parameter &lt;code&gt;C&lt;/code&gt; (use a logarithmic grid of points, from 1 to 10).</source>
          <target state="translated">在数字数据集上，绘制具有线性核的&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;估计量的交叉验证得分作为参数 &lt;code&gt;C&lt;/code&gt; 的函数（使用点的对数网格，范围为1到10）。</target>
        </trans-unit>
        <trans-unit id="70934046ec7198c15e5255a457f5b5f8aad47e7d" translate="yes" xml:space="preserve">
          <source>On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from &lt;code&gt;predict_proba&lt;/code&gt; are not to be taken too seriously.</source>
          <target state="translated">另一方面，尽管朴素的贝叶斯被认为是一个体面的分类器，但是它被认为是一个不好的估计器，因此， &lt;code&gt;predict_proba&lt;/code&gt; 的概率输出不必太在意。</target>
        </trans-unit>
        <trans-unit id="11ff999f3cb9557f779d2d870e0da3265a08df2a" translate="yes" xml:space="preserve">
          <source>On the following figure we are fitting a dataset not well-depicted by a Gaussian mixture. Adjusting the &lt;code&gt;weight_concentration_prior&lt;/code&gt;, parameter of the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; controls the number of components used to fit this data. We also present on the last two plots a random sampling generated from the two resulting mixtures.</source>
          <target state="translated">在下图中，我们拟合的数据集没有被高斯混合很好地描述。调整&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;weight_concentration_prior&lt;/code&gt; 参数，可控制用于拟合此数据的组件数。我们还在最后两个图上显示了从这两种所得混合物生成的随机采样。</target>
        </trans-unit>
        <trans-unit id="e0986e74679be65bf8af00d65ae0c2feb9ddbaaf" translate="yes" xml:space="preserve">
          <source>On the graph of webpages and links those values are called the PageRank scores by Google.</source>
          <target state="translated">在网页和链接的图上,这些数值被Google称为PageRank分数。</target>
        </trans-unit>
        <trans-unit id="56dda47abffe67d113799c44a62fa9885afd300e" translate="yes" xml:space="preserve">
          <source>On the left side the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. On the right side we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples.</source>
          <target state="translated">左侧是一个奈夫贝叶斯分类器对数字数据集的学习曲线。注意,训练得分和交叉验证得分在最后都不是很好。然而,在更复杂的数据集中可以发现曲线的形状非常频繁:训练得分在开始时非常高,然后减少,交叉验证得分在开始时非常低,然后增加。在右侧我们看到了一个采用RBF内核的SVM的学习曲线。我们可以清楚地看到,训练得分仍然在最大值附近,验证得分可以通过更多的训练样本来提高。</target>
        </trans-unit>
        <trans-unit id="8734edc10a3853b319869c6d2b6c4a8a8cc0d2c2" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training &lt;code&gt;n_classes&lt;/code&gt; models.</source>
          <target state="translated">另一方面，&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;实施了&amp;ldquo;一对多&amp;rdquo;策略，从而训练了 &lt;code&gt;n_classes&lt;/code&gt; 个模型。</target>
        </trans-unit>
        <trans-unit id="f954522d1ed09b2ae8779aaabe3dfa6c3ae4de4e" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained:</source>
          <target state="translated">另一方面，&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;实施了&amp;ldquo; 一对多 &amp;rdquo;策略，从而训练了n_class模型。如果只有两节课，则只训练一种模型：</target>
        </trans-unit>
        <trans-unit id="b6899866fd2175cc1abac032537947b3dc26ecc5" translate="yes" xml:space="preserve">
          <source>On the other hand, the weights obtained with regularization are more stable (see the &lt;a href=&quot;../../modules/linear_model#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; User Guide section). This increased stability is visible from the plot, obtained from data perturbations, in a cross validation. This plot can be compared with the &lt;a href=&quot;#covariation&quot;&gt;previous one&lt;/a&gt;.</source>
          <target state="translated">另一方面，通过正则化获得的权重更稳定（请参阅《&lt;a href=&quot;../../modules/linear_model#ridge-regression&quot;&gt;Ridge回归和分类&lt;/a&gt;用户指南》部分）。在交叉验证中，从数据扰动获得的图上可以看到这种增加的稳定性。可以将此图与&lt;a href=&quot;#covariation&quot;&gt;上一个&lt;/a&gt;图进行比较。</target>
        </trans-unit>
        <trans-unit id="86b28d625cb14fb5485ff23b3eca337a06cecaf2" translate="yes" xml:space="preserve">
          <source>On the plots, train data is shown as dots, while test data is shown as crosses. The iris dataset is four-dimensional. Only the first two dimensions are shown here, and thus some points are separated in other dimensions.</source>
          <target state="translated">在图上,训练数据显示为点,而测试数据显示为十字。虹膜数据集是四维的。这里只显示了前两个维度,因此一些点在其他维度上是分开的。</target>
        </trans-unit>
        <trans-unit id="fc82fddedc10b52f931e2d57575d5196e2c6dd2d" translate="yes" xml:space="preserve">
          <source>On the twenty newsgroups on the other hand the dimensionality can be decreased from 56436 down to 10000 while reasonably preserving pairwise distances.</source>
          <target state="translated">另一方面,在20个新闻组上,维度可以从56436降到10000,同时合理地保留了配对距离。</target>
        </trans-unit>
        <trans-unit id="43f757b33d0dc72835f44fdaffe6492249fea14f" translate="yes" xml:space="preserve">
          <source>On this example, the first two rows represent linearly non-separable datasets (moons and concentric circles) while the third is approximately linearly separable. On the two linearly non-separable datasets, feature discretization largely increases the performance of linear classifiers. On the linearly separable dataset, feature discretization decreases the performance of linear classifiers. Two non-linear classifiers are also shown for comparison.</source>
          <target state="translated">在这个例子上,前两行代表线性不可分离的数据集(月亮和同心圆),而第三行是近似线性可分离的。在两个线性不可分离的数据集上,特征离散化很大程度上提高了线性分类器的性能。在线性可分离的数据集上,特征离散化降低了线性分类器的性能。还展示了两种非线性分类器进行比较。</target>
        </trans-unit>
        <trans-unit id="3162e7b183de96ba6bf8f8587d34db62edc4b217" translate="yes" xml:space="preserve">
          <source>Once the optimization problem is solved, the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; for a given sample \(x\) becomes:</source>
          <target state="translated">一旦求解优化问题以，输出&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;对于给定的样品\（X \）变为：</target>
        </trans-unit>
        <trans-unit id="07aa293f8032a091371331fd78ad762690098968" translate="yes" xml:space="preserve">
          <source>Once trained, we can export the tree in &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with</source>
          <target state="translated">经过培训后，我们可以使用&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt;导出器以&lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt;格式导出树。如果使用&lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt;软件包管理器，则可以使用以下命令安装graphviz二进制文件和python软件包：</target>
        </trans-unit>
        <trans-unit id="ed70a2ff6fe86d781de8936cfd7e74b27161e201" translate="yes" xml:space="preserve">
          <source>Once trained, you can plot the tree with the &lt;a href=&quot;generated/sklearn.tree.plot_tree#sklearn.tree.plot_tree&quot;&gt;&lt;code&gt;plot_tree&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">训练后，您可以使用&lt;a href=&quot;generated/sklearn.tree.plot_tree#sklearn.tree.plot_tree&quot;&gt; &lt;code&gt;plot_tree&lt;/code&gt; &lt;/a&gt;函数绘制树：</target>
        </trans-unit>
        <trans-unit id="28066560ad38f3f5dad45c5652f6a508803ee2c3" translate="yes" xml:space="preserve">
          <source>One can always drop the first column for each feature:</source>
          <target state="translated">可以随时放弃每个功能的第一列。</target>
        </trans-unit>
        <trans-unit id="0471206705323c6d53e55b1c35697675c16b2c95" translate="yes" xml:space="preserve">
          <source>One can discard categories not seen during &lt;code&gt;fit&lt;/code&gt;:</source>
          <target state="translated">一个人可以舍弃在 &lt;code&gt;fit&lt;/code&gt; 过程中看不到的类别：</target>
        </trans-unit>
        <trans-unit id="e1a30cbb2660486e3a34f97fc6f2ebc285138723" translate="yes" xml:space="preserve">
          <source>One can observe here that logistic regression is well calibrated as its curve is nearly diagonal. Linear SVC&amp;rsquo;s calibration curve or reliability diagram has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors). Both kinds of calibration can fix this issue and yield nearly identical results. The next figure shows the calibration curve of Gaussian naive Bayes on the same data, with both kinds of calibration and also without calibration.</source>
          <target state="translated">在这里可以看到，逻辑回归的曲线接近对角线，因此可以很好地进行校准。线性SVC的校准曲线或可靠性图具有S型曲线，这对于自信不足的分类器而言是典型的。在LinearSVC的情况下，这是由铰链损失的裕度属性引起的，该属性使铰链损失可以集中在靠近决策边界（支持向量）的硬样本上。两种校准均可解决此问题，并产生几乎相同的结果。下图显示了高斯朴素贝叶斯在相同数据上的校准曲线，包括两种校准以及未校准。</target>
        </trans-unit>
        <trans-unit id="cce2911ccedb3667eaee804d61905917155ff5c2" translate="yes" xml:space="preserve">
          <source>One can observe that with homoscedastic noise both FA and PCA succeed in recovering the size of the low rank subspace. The likelihood with PCA is higher than FA in this case. However PCA fails and overestimates the rank when heteroscedastic noise is present. Under appropriate circumstances the low rank models are more likely than shrinkage models.</source>
          <target state="translated">我们可以观察到,在同序噪声的情况下,FA和PCA都能成功恢复低秩子空间的大小。在这种情况下,PCA的似然比FA高。然而PCA失败了,当存在异序噪声时,高估了秩。在适当的情况下,低秩模型比收缩模型的可能性更大。</target>
        </trans-unit>
        <trans-unit id="5282642c4183bcd75159c8592f0d08e21bceb6b2" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:</source>
          <target state="translated">可以将预测标签中的0和1进行换算,将2改名为3,得到同样的分数。</target>
        </trans-unit>
        <trans-unit id="f2e197fb258bad312502ac44a4234fe5a6877692" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3, and get the same score:</source>
          <target state="translated">可以将预测标签中的0和1进行换算,将2改名为3,得到同样的分数。</target>
        </trans-unit>
        <trans-unit id="e33d3feeafd2b2e6157812f722f3e7fb8358ba7c" translate="yes" xml:space="preserve">
          <source>One can see that Gaussian naive Bayes performs very badly but does so in an other way than linear SVC: While linear SVC exhibited a sigmoid calibration curve, Gaussian naive Bayes&amp;rsquo; calibration curve has a transposed-sigmoid shape. This is typical for an over-confident classifier. In this case, the classifier&amp;rsquo;s overconfidence is caused by the redundant features which violate the naive Bayes assumption of feature-independence.</source>
          <target state="translated">可以看到，高斯朴素贝叶斯的性能很差，但它的性能不同于线性SVC：线性SVC表现出S形的校准曲线，而高斯朴素贝叶斯的校准曲线却具有转位的S形。这对于过分自信的分类器来说是典型的。在这种情况下，分类器的过分自信是由多余的特征引起的，这些冗余的特征违反了朴素的贝叶斯独立于特征的假设。</target>
        </trans-unit>
        <trans-unit id="15c1fc9ad0e4ecc150e99497720122e04673bd38" translate="yes" xml:space="preserve">
          <source>One can see that NCA enforces a clustering of the data that is visually meaningful despite the large reduction in dimension.</source>
          <target state="translated">可以看到,尽管维度大为降低,但NCA强制执行的数据聚类是有视觉意义的。</target>
        </trans-unit>
        <trans-unit id="82900035fe0f11887cd04ee23edd3ee0d6e6bf18" translate="yes" xml:space="preserve">
          <source>One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.</source>
          <target state="translated">机器学习内的一种常见模式是使用在数据的非线性函数上训练的线性模型。这种方法保持了线性方法一般快速的性能,同时允许它们适应更广泛的数据。</target>
        </trans-unit>
        <trans-unit id="fa0690f9f0e7bd840855247cda57999b3e6dd175" translate="yes" xml:space="preserve">
          <source>One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). From this assumption, we generally try to define the &amp;ldquo;shape&amp;rdquo; of the data, and can define outlying observations as observations which stand far enough from the fit shape.</source>
          <target state="translated">执行离群值检测的一种常用方法是假设常规数据来自已知分布（例如，数据是高斯分布的）。从这个假设出发，我们通常尝试定义数据的&amp;ldquo;形状&amp;rdquo;，并且可以将外围观察定义为距离拟合形状足够远的观察。</target>
        </trans-unit>
        <trans-unit id="9d03fc67e51edb11ba912aa95289c786040f1c20" translate="yes" xml:space="preserve">
          <source>One drawback of kernel methods is, that it might be necessary to store many kernel values \(k(x_i, x_j)\) during optimization. If a kernelized classifier is applied to new data \(y_j\), \(k(x_i, y_j)\) needs to be computed to make predictions, possibly for many different \(x_i\) in the training set.</source>
          <target state="translated">核方法的一个缺点是,在优化过程中可能需要存储许多核值(k(x_i,x_j)\)。如果一个内核化的分类器被应用到新的数据中,就需要计算出许多不同的训练集中的内核值来进行预测。</target>
        </trans-unit>
        <trans-unit id="cdf9b1d4485b82e7ed1999a3fb7fb5adb4dbca12" translate="yes" xml:space="preserve">
          <source>One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; &amp;lsquo;isolates&amp;rsquo; observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</source>
          <target state="translated">在高维数据集中执行异常检测的一种有效方法是使用随机森林。所述&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;通过随机选择一个功能，然后随机选择所选择的特征的最大值和最小值之间的分裂值&amp;ldquo;分离的观察。</target>
        </trans-unit>
        <trans-unit id="b5c13007d70aa1a0e4a2816404f0d61b9e0ac135" translate="yes" xml:space="preserve">
          <source>One important thing to note is that the algorithms implemented in this module can take different kinds of matrix as input. All the methods accept standard data matrices of shape &lt;code&gt;[n_samples, n_features]&lt;/code&gt;. These can be obtained from the classes in the &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module. For &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt;&lt;code&gt;AffinityPropagation&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; one can also input similarity matrices of shape &lt;code&gt;[n_samples, n_samples]&lt;/code&gt;. These can be obtained from the functions in the &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">需要注意的重要一点是，此模块中实现的算法可以采用不同种类的矩阵作为输入。所有方法都接受形状为 &lt;code&gt;[n_samples, n_features]&lt;/code&gt; 标准数据矩阵。这些可以从&lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt;模块中的类获得。对于&lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt; &lt;code&gt;AffinityPropagation&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt; &lt;code&gt;SpectralClustering&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; ,&lt;/a&gt;也可以输入形状为 &lt;code&gt;[n_samples, n_samples]&lt;/code&gt; 相似度矩阵。这些可以从&lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt;模块中的函数获得。</target>
        </trans-unit>
        <trans-unit id="deab058e87e7d8cac343ed7483a7cf721eca4119" translate="yes" xml:space="preserve">
          <source>One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of &lt;em&gt;modified locally linear embedding&lt;/em&gt; (MLLE). MLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'modified'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt;.</source>
          <target state="translated">解决正则化问题的一种方法是在每个邻域中使用多个权重向量。这是&lt;em&gt;修改的局部线性嵌入&lt;/em&gt;（MLLE）的本质。 MLLE可以通过函数&lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt;或其面向对象的对等&lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt;来执行， &lt;code&gt;method = 'modified'&lt;/code&gt; 为关键字method ='modified'。它要求 &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8b0abef56ded5ecf131b35733971a4004aa542f0" translate="yes" xml:space="preserve">
          <source>One might alternatively consider a collection of character n-grams, a representation resilient against misspellings and derivations.</source>
          <target state="translated">我们也可以考虑一个字符n-grams的集合,一个对错别字和派生有弹性的表示。</target>
        </trans-unit>
        <trans-unit id="9787d541696df0f6a8e4fd9ada866862db9e0d0c" translate="yes" xml:space="preserve">
          <source>One might want to drop one of the two columns only for features with 2 categories. In this case, you can set the parameter &lt;code&gt;drop='if_binary'&lt;/code&gt;.</source>
          <target state="translated">一个人可能只想删除具有2个类别的要素的两列之一。在这种情况下，您可以设置参数 &lt;code&gt;drop='if_binary'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="61c492958dc81c1a6d9f632bafd3909d2bb143b8" translate="yes" xml:space="preserve">
          <source>One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.</source>
          <target state="translated">这里面临的一个挑战是,求解器可能无法收敛到一个条件良好的估计值。相应的α值就会出现缺失值,但最优值可能接近这些缺失值。</target>
        </trans-unit>
        <trans-unit id="70a04d887115ca6d6700f00cd1afa9bf1cffed38" translate="yes" xml:space="preserve">
          <source>One of the earliest approaches to manifold learning is the Isomap algorithm, short for Isometric Mapping. Isomap can be viewed as an extension of Multi-dimensional Scaling (MDS) or Kernel PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points. Isomap can be performed with the object &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt;&lt;code&gt;Isomap&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Isomap算法是流形学习的最早方法之一，Isomap算法是Isometric Mapping（等距映射）的缩写。Isomap可以看作是多维缩放（MDS）或内核PCA的扩展。Isomap寻求维数较低的嵌入，以保持所有点之间的测地距离。可以使用对象&lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt; &lt;code&gt;Isomap&lt;/code&gt; &lt;/a&gt;执行Isomap。</target>
        </trans-unit>
        <trans-unit id="8d30b63915c687687af955c31a96ac094f06cb9f" translate="yes" xml:space="preserve">
          <source>One of the most straight-forward concerns one may have when using/choosing a machine learning toolkit is the latency at which predictions can be made in a production environment.</source>
          <target state="translated">在使用/选择机器学习工具包时,人们可能会有一个最直接的顾虑,那就是在生产环境中进行预测的延迟。</target>
        </trans-unit>
        <trans-unit id="e3967d3ba22f4ac7f4c1ab09bac9634bd847ca9c" translate="yes" xml:space="preserve">
          <source>One of:</source>
          <target state="translated">其中一个:</target>
        </trans-unit>
        <trans-unit id="d25b0126083dd51df31e94af07b51bd893fc80ee" translate="yes" xml:space="preserve">
          <source>One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:</source>
          <target state="translated">核密度估计的另一个有用的应用是学习一个数据集的非参数生成模型,以便有效地从这个生成模型中抽取新的样本。下面是一个使用这个过程来创建一组新的手写数字的例子,使用在数据的PCA投影上学习的高斯核。</target>
        </trans-unit>
        <trans-unit id="fee8a97f6bc38e5962a611f176ea8084294905c7" translate="yes" xml:space="preserve">
          <source>One possible difference with the &lt;code&gt;glasso&lt;/code&gt; R package is that the diagonal coefficients are not penalized.</source>
          <target state="translated">&lt;code&gt;glasso&lt;/code&gt; R包的一种可能差异是对角系数不会受到惩罚。</target>
        </trans-unit>
        <trans-unit id="a927f9db65135d8f0443d271707e3494a0dc3ae7" translate="yes" xml:space="preserve">
          <source>One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. &lt;code&gt;impute.SimpleImputer&lt;/code&gt;). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. &lt;code&gt;impute.IterativeImputer&lt;/code&gt;).</source>
          <target state="translated">一类插补算法是单变量的，它仅使用第i个要素维中的非缺失值（例如 &lt;code&gt;impute.SimpleImputer&lt;/code&gt; ）来插补第i个要素维中的值。相比之下，多元插补算法使用整个可用特征维集来估计缺失值（例如 &lt;code&gt;impute.IterativeImputer&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="ea6c78b875e9abbb9afb65361c14c4ab4fe517e5" translate="yes" xml:space="preserve">
          <source>One typical use case is to wrap an existing metric function from the library with non-default values for its parameters, such as the &lt;code&gt;beta&lt;/code&gt; parameter for the &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">一种典型的用例是使用非默认值为其参数包装库中的现有度量标准函数，例如&lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt;函数的 &lt;code&gt;beta&lt;/code&gt; 参数：</target>
        </trans-unit>
        <trans-unit id="d21d62671a1a16508e611633019b29f0b4ceb760" translate="yes" xml:space="preserve">
          <source>One way to avoid the query complexity is to pre-compute sparse neighborhoods in chunks using &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;mode='distance'&lt;/code&gt;, then using &lt;code&gt;metric='precomputed'&lt;/code&gt; here.</source>
          <target state="translated">避免查询复杂性的一种方法是使用&lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt; &lt;/a&gt;以 &lt;code&gt;mode='distance'&lt;/code&gt; 预先计算块中的稀疏邻域，然后在此处使用 &lt;code&gt;metric='precomputed'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="cfb9ef5c0f82cd02b0fe2a37197cc7c17a10edff" translate="yes" xml:space="preserve">
          <source>One way to handle this is to cluster features that are correlated and only keep one feature from each cluster. This strategy is explored in the following example: &lt;a href=&quot;../auto_examples/inspection/plot_permutation_importance_multicollinear#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py&quot;&gt;Permutation Importance with Multicollinear or Correlated Features&lt;/a&gt;.</source>
          <target state="translated">处理此问题的一种方法是将关联的要素聚类，并且每个聚类仅保留一个要素。在以下示例中探讨了该策略：&lt;a href=&quot;../auto_examples/inspection/plot_permutation_importance_multicollinear#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py&quot;&gt;具有多重共线性或相关特征的置换重要性&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b4307d41eb1bb94d21cc13cd8d41c0af8c2af52b" translate="yes" xml:space="preserve">
          <source>One way to plot the curves is to place them in the same figure, with the curves of each model on each row. First, we create a figure with two axes within two rows and one column. The two axes are passed to the &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; functions of &lt;code&gt;tree_disp&lt;/code&gt; and &lt;code&gt;mlp_disp&lt;/code&gt;. The given axes will be used by the plotting function to draw the partial dependence. The resulting plot places the decision tree partial dependence curves in the first row of the multi-layer perceptron in the second row.</source>
          <target state="translated">绘制曲线的一种方法是将它们放置在同一图形中，每个模型的曲线在每一行上。首先，我们创建一个图形，该图形在两行一列中具有两个轴。这两个轴传递给 &lt;code&gt;tree_disp&lt;/code&gt; 和 &lt;code&gt;mlp_disp&lt;/code&gt; 的&lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay.plot&quot;&gt; &lt;code&gt;plot&lt;/code&gt; &lt;/a&gt;函数。给定的轴将由绘图功能用于绘制部分相关性。结果图将决策树部分相关曲线放置在第二行的多层感知器的第一行中。</target>
        </trans-unit>
        <trans-unit id="7904a0df31dead1d3d1a1bdda9b6baa78b3e3ac4" translate="yes" xml:space="preserve">
          <source>One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter \(r\), which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as \(r \to 0\), the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for \(r &amp;gt; 0\). This problem manifests itself in embeddings which distort the underlying geometry of the manifold.</source>
          <target state="translated">LLE的一个众所周知的问题是正则化问题。当邻居数大于输入维数时，定义每个本地邻居的矩阵秩不足。为了解决这个问题，标准LLE应用了一个任意的正则化参数\（r \），该参数相对于局部权重矩阵的轨迹进行选择。尽管可以正式证明，当\（r \ to 0 \）时，解收敛于所需的嵌入，但不能保证将找到\（r&amp;gt; 0 \）的最优解。该问题以使歧管的基本几何形状变形的嵌入表现出来。</target>
        </trans-unit>
        <trans-unit id="4a89ac2f620199dd99f97fe1ad98300bc4f72269" translate="yes" xml:space="preserve">
          <source>One-class SVM with non-linear kernel (RBF)</source>
          <target state="translated">非线性内核(RBF)的一类SVM。</target>
        </trans-unit>
        <trans-unit id="a699b63cc6020c9e087bddfc75a6724c5b45ee5c" translate="yes" xml:space="preserve">
          <source>One-hot encoded discretized features can make a model more expressive, while maintaining interpretability. For instance, pre-processing with a discretizer can introduce nonlinearity to linear models.</source>
          <target state="translated">一热编码的离散化特征可以使模型更具表现力,同时保持可解释性。例如,用离散器进行预处理,可以给线性模型引入非线性。</target>
        </trans-unit>
        <trans-unit id="b4a3aede9df40da523f973c7487f254218f78511" translate="yes" xml:space="preserve">
          <source>One-vs-one multiclass strategy</source>
          <target state="translated">一对一多类策略</target>
        </trans-unit>
        <trans-unit id="ee528cbd4b4f2e2829af351b64b6eb8bfd42a4f6" translate="yes" xml:space="preserve">
          <source>One-vs-the-rest (OvR) multiclass/multilabel strategy</source>
          <target state="translated">一对一(OvR)多类/多标签策略</target>
        </trans-unit>
        <trans-unit id="64ecee535f4fdc8be570462551ed8105268af715" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above Figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them.</source>
          <target state="translated">单向PDP告诉我们目标响应和目标特征之间的交互作用(如线性、非线性)。上图中左上角的图显示了一个地区的收入中位数对房价中位数的影响,我们可以清楚地看到它们之间的线性关系。</target>
        </trans-unit>
        <trans-unit id="0d4f461fa5ad14a45b8d87efade862b196a923a9" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them. Note that PDPs assume that the target features are independent from the complement features, and this assumption is often violated in practice.</source>
          <target state="translated">单向PDP告诉我们目标反应和目标特征之间的相互作用(如线性、非线性)。上图中左上角的图是某区收入中位数对房价中位数的影响,我们可以清楚地看到它们之间的线性关系。需要注意的是,PDPs假设目标特征与补充特征是独立的,而这一假设在实践中往往被违反。</target>
        </trans-unit>
        <trans-unit id="624143e59cce6d91c0d6bbc328865a41ed589524" translate="yes" xml:space="preserve">
          <source>OneHotEncoder</source>
          <target state="translated">OneHotEncoder</target>
        </trans-unit>
        <trans-unit id="aae2ee6c9851c7a4ce4cd6cfb817bfde607325bf" translate="yes" xml:space="preserve">
          <source>Online Passive-Aggressive Algorithms &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt;&amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</source>
          <target state="translated">在线被动攻击算法&amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt; &amp;gt; K. Crammer，O.Dekel，J.Keshat，S.Shalev-Shwartz，Y.Singer- JMLR（2006）</target>
        </trans-unit>
        <trans-unit id="59363dcf6a532d4c72655a5346d2c500295612f8" translate="yes" xml:space="preserve">
          <source>Online VB with Mini-Batch update.</source>
          <target state="translated">在线VB与小批量更新。</target>
        </trans-unit>
        <trans-unit id="829e73254cb47c834763ade46578341830688d18" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling.</source>
          <target state="translated">在线计算X的最大绝对值,以便于以后的缩放。</target>
        </trans-unit>
        <trans-unit id="1dffcf7d5a055d764cfb2adb13901c054d8691b3" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">在线计算X的最大绝对值，以便以后缩放。所有X都作为一个批处理。这适用于由于 &lt;code&gt;n_samples&lt;/code&gt; 数量过多或从连续流中读取X 而无法进行 &lt;code&gt;fit&lt;/code&gt; 情况。</target>
        </trans-unit>
        <trans-unit id="5b59fd4b2594ce8e5c7bbe150a07e7588723c96b" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling.</source>
          <target state="translated">在线计算X上的均值和std,以便以后进行缩放。</target>
        </trans-unit>
        <trans-unit id="98a787216e7563ac11e03cf3274711f17911c2c2" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">在线计算X上的均值和标准差，以便以后缩放。所有X都作为一个批处理。这适用于由于 &lt;code&gt;n_samples&lt;/code&gt; 数量过多或从连续流中读取X 而无法进行 &lt;code&gt;fit&lt;/code&gt; 情况。</target>
        </trans-unit>
        <trans-unit id="3a0a40bed8a368eb74567adc0b902d5438bbb233" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling.</source>
          <target state="translated">在线计算X上的最小值和最大值,以便于以后的缩放。</target>
        </trans-unit>
        <trans-unit id="245a52e0e0da8fa60b8bd0ab73c4b352a71c8d4a" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">在线计算X上的最小值和最大值，以便以后缩放。所有X都作为一个批处理。这适用于由于 &lt;code&gt;n_samples&lt;/code&gt; 数量过多或从连续流中读取X 而无法进行 &lt;code&gt;fit&lt;/code&gt; 情况。</target>
        </trans-unit>
        <trans-unit id="3bdeb493aeece54b83eea920715d4b7167b710bb" translate="yes" xml:space="preserve">
          <source>Online learning of a dictionary of parts of faces</source>
          <target state="translated">在线学习人脸部位词典。</target>
        </trans-unit>
        <trans-unit id="afbac89ba6ac8bba06d8e8f00f8db1d633c505b3" translate="yes" xml:space="preserve">
          <source>Online learning.</source>
          <target state="translated">在线学习。</target>
        </trans-unit>
        <trans-unit id="e15bae968fe9434653919edecb56e181cf3bdca0" translate="yes" xml:space="preserve">
          <source>Online learning. Prevents rebuilding of CFTree from scratch.</source>
          <target state="translated">在线学习。防止从头开始重建CFTree。</target>
        </trans-unit>
        <trans-unit id="fba366205dda8a9f9c620fa8147677029ec02688" translate="yes" xml:space="preserve">
          <source>Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">仅在backend =&amp;ldquo; loky&amp;rdquo;或&amp;ldquo; multiprocessing&amp;rdquo;时激活。</target>
        </trans-unit>
        <trans-unit id="302203b3b2bd4b6979838ea661e3dedb562a6303" translate="yes" xml:space="preserve">
          <source>Only adjusted measures can hence safely be used as a consensus index to evaluate the average stability of clustering algorithms for a given value of k on various overlapping sub-samples of the dataset.</source>
          <target state="translated">因此,只有调整后的测量方法才能安全地作为一种共识指数来评价聚类算法在给定的k值下,在数据集的各种重叠子样本上的平均稳定性。</target>
        </trans-unit>
        <trans-unit id="b41ade38f91e30c61b5c1030ad80447ac59509af" translate="yes" xml:space="preserve">
          <source>Only applies to sparse matrices. If True, the sparse entries of the matrix are discarded to compute the quantile statistics. If False, these entries are treated as zeros.</source>
          <target state="translated">仅适用于稀疏矩阵。如果为真,矩阵的稀疏条目将被丢弃以计算量化统计。如果为假,则这些条目被视为零。</target>
        </trans-unit>
        <trans-unit id="6239790ca1ea503b946542f5fd11362f9a8d181e" translate="yes" xml:space="preserve">
          <source>Only available for novelty detection (when novelty is set to True). The argument X is supposed to contain &lt;em&gt;new data&lt;/em&gt;: if X contains a point from training, it considers the later in its own neighborhood. Also, the samples in X are not considered in the neighborhood of any point. The score_samples on training data is available by considering the the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">仅可用于新颖性检测（新颖性设置为True时）。参数X应该包含&lt;em&gt;新数据&lt;/em&gt;：如果X包含来自训练的点，则它将在其自己的邻域中考虑后者。同样，在任何点附近都不会考虑X中的样本。可以通过考虑 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性来获得训练数据的score_samples 。</target>
        </trans-unit>
        <trans-unit id="42065a31e81b2581624e9d29e5e9b175fb835b62" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;decision_function&lt;/code&gt;.</source>
          <target state="translated">仅当 &lt;code&gt;refit=True&lt;/code&gt; 和底层估计支持 &lt;code&gt;decision_function&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b5f87bbc5994209afe765ecb3d4b6e3e28348b8b" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;refit=True&lt;/code&gt; 并且基础估算器支持 &lt;code&gt;predict&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="d2e232f30b7c8c685e1c17116e7dcb136df3f8ad" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_log_proba&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;refit=True&lt;/code&gt; 且基础估算器支持 &lt;code&gt;predict_log_proba&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="590883a61b4915ecfb6720c62deaa2c81b9eda84" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;refit=True&lt;/code&gt; 且基础估算器支持 &lt;code&gt;predict_proba&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="3fd90433c474723d07589bf28196170034c8822e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator implements &lt;code&gt;inverse_transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">仅在基础估算器实现 &lt;code&gt;inverse_transform&lt;/code&gt; 和 &lt;code&gt;refit=True&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="5b6ee95bb2d64ff7d78caebfb3e0ee07b947d80e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator supports &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">仅在基础估算器支持 &lt;code&gt;transform&lt;/code&gt; 和 &lt;code&gt;refit=True&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="551c945d5055fc75c52f88f345bac01b44b1a207" translate="yes" xml:space="preserve">
          <source>Only consider the highest k scores in the ranking. If None, use all outputs.</source>
          <target state="translated">只考虑排名中最高的k分。如果无,则使用所有输出。</target>
        </trans-unit>
        <trans-unit id="91571ddad0f13d4b107795b8172bb8b9e0e57731" translate="yes" xml:space="preserve">
          <source>Only kernels that produce similarity scores (non-negative values that increase with similarity) should be used. This property is not checked by the clustering algorithm.</source>
          <target state="translated">只应使用产生相似度分数的内核(随着相似度增加而增加的非负值)。聚类算法不检查这一属性。</target>
        </trans-unit>
        <trans-unit id="78ed917f99bf2dac895a03ac7d7777a9a2c30e89" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;as_frame=True&lt;/code&gt;. DataFrame with &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;as_frame=True&lt;/code&gt; 时存在。具有 &lt;code&gt;data&lt;/code&gt; 和 &lt;code&gt;target&lt;/code&gt; DataFrame 。</target>
        </trans-unit>
        <trans-unit id="0fcc91c5ac8dfa2c9d74fba74f9744bbfabacd86" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;load_content=True&lt;/code&gt;. The raw text data to learn.</source>
          <target state="translated">仅在 &lt;code&gt;load_content=True&lt;/code&gt; 时存在。要学习的原始文本数据。</target>
        </trans-unit>
        <trans-unit id="91f57910319c7032022a687ad833db0e0811e172" translate="yes" xml:space="preserve">
          <source>Only report results for the class specified by &lt;code&gt;pos_label&lt;/code&gt;. This is applicable only if targets (&lt;code&gt;y_{true,pred}&lt;/code&gt;) are binary.</source>
          <target state="translated">仅报告 &lt;code&gt;pos_label&lt;/code&gt; 指定的类的结果。仅当目标（ &lt;code&gt;y_{true,pred}&lt;/code&gt; ）是二进制的时才适用。</target>
        </trans-unit>
        <trans-unit id="aa7683d2cc754187a7839c7481d51d4e421e244f" translate="yes" xml:space="preserve">
          <source>Only returned if return_distance is set to True (for compatibility). The distances between the centers of the nodes. &lt;code&gt;distances[i]&lt;/code&gt; corresponds to a weighted euclidean distance between the nodes &lt;code&gt;children[i, 1]&lt;/code&gt; and &lt;code&gt;children[i, 2]&lt;/code&gt;. If the nodes refer to leaves of the tree, then &lt;code&gt;distances[i]&lt;/code&gt; is their unweighted euclidean distance. Distances are updated in the following way (from scipy.hierarchy.linkage):</source>
          <target state="translated">仅在return_distance设置为True（出于兼容性）时返回。节点中心之间的距离。 &lt;code&gt;distances[i]&lt;/code&gt; 对应于节点child &lt;code&gt;children[i, 1]&lt;/code&gt; 和 &lt;code&gt;children[i, 2]&lt;/code&gt; 之间的加权欧几里得距离。如果节点引用树的叶子，则 &lt;code&gt;distances[i]&lt;/code&gt; 是其未加权的欧几里得距离。距离以以下方式更新（来自scipy.hierarchy.linkage）：</target>
        </trans-unit>
        <trans-unit id="76cbc59243676edd420339801c25adc86e4aefb2" translate="yes" xml:space="preserve">
          <source>Only set if whiten is &amp;lsquo;True&amp;rsquo;. This is the pre-whitening matrix that projects data onto the first &lt;code&gt;n_components&lt;/code&gt; principal components.</source>
          <target state="translated">仅在增白为&amp;ldquo;真&amp;rdquo;时设置。这是将数据投影到第一个 &lt;code&gt;n_components&lt;/code&gt; 主成分上的预白化矩阵。</target>
        </trans-unit>
        <trans-unit id="b2ff6162a14531590c3fe05f5c4da22c170a731e" translate="yes" xml:space="preserve">
          <source>Only the first 4 features are informative. The remaining features are useless.</source>
          <target state="translated">只有前4个功能是有参考价值的。其余的特征都是无用的。</target>
        </trans-unit>
        <trans-unit id="9ccbc07fdd81d8170c7e3632973044099dfe4b4c" translate="yes" xml:space="preserve">
          <source>Only the first max_depth levels of the tree are exported. Truncated branches will be marked with &amp;ldquo;&amp;hellip;&amp;rdquo;.</source>
          <target state="translated">仅导出树的第一个max_depth级别。截断的分支将标记为&amp;ldquo;&amp;hellip;&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="ccdb28c17d5d885e725cff4c70b04cf05f415c05" translate="yes" xml:space="preserve">
          <source>Only used if method=&amp;rsquo;barnes_hut&amp;rsquo; This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. &amp;lsquo;angle&amp;rsquo; is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below &amp;lsquo;angle&amp;rsquo; then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.</source>
          <target state="translated">仅在method ='barnes_hut'时使用。这是Barnes-Hut T-SNE在速度和精度之间的权衡。&amp;ldquo;角度&amp;rdquo;是从点开始测量的远距离节点的角度大小（在[3]中称为theta）。如果该大小小于&amp;ldquo;角度&amp;rdquo;，则将其用作其中包含的所有点的汇总节点。此方法对此参数在0.2-0.8范围内的变化不太敏感。小于0.2的角度会迅速增加计算时间，大于0.8的角度会迅速增加误差。</target>
        </trans-unit>
        <trans-unit id="feeded53201cd1098b357f2543d3cc3ddaf2bc59" translate="yes" xml:space="preserve">
          <source>Only used in edge case with a single class in the training set.</source>
          <target state="translated">只用于训练集中只有一个类的边缘情况。</target>
        </trans-unit>
        <trans-unit id="e51e92f95034c804fc0810fdbc5d315daca2beb0" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;solver='sgd'&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;solver='sgd'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="593a45b59b3c39f850f6d06cebef909401c1e524" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;svd_method&lt;/code&gt; 等于&amp;ldquo;随机化&amp;rdquo;时使用。在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="da0ee672f8455720f39dadc83f429b90e16b4655" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of function calls. Note that number of function calls will be greater than or equal to the number of iterations for the MLPRegressor.</source>
          <target state="translated">仅在Solver ='lbfgs'时使用。函数调用的最大数量。求解器进行迭代，直到收敛（由&amp;ldquo; tol&amp;rdquo;确定），迭代次数达到max_iter或此函数调用次数为止。请注意，函数调用的数量将大于或等于MLPRegressor的迭代数量。</target>
        </trans-unit>
        <trans-unit id="f33d0ac38f880719381151e0f77c153552e9c099" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of loss function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of loss function calls. Note that number of loss function calls will be greater than or equal to the number of iterations for the &lt;code&gt;MLPClassifier&lt;/code&gt;.</source>
          <target state="translated">仅在Solver ='lbfgs'时使用。丢失函数调用的最大次数。求解器迭代直到收敛（由&amp;ldquo; tol&amp;rdquo;确定），迭代次数达到max_iter或损失函数调用的次数为止。请注意，损失函数调用的次数将大于或等于 &lt;code&gt;MLPClassifier&lt;/code&gt; 的迭代次数。</target>
        </trans-unit>
        <trans-unit id="3466b805d384e470c3d1ee2beb1b9b317ac5cc22" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">仅在Solver ='sgd'时使用。</target>
        </trans-unit>
        <trans-unit id="04fb050fa307025a8b877f9d2c83069449f7ca94" translate="yes" xml:space="preserve">
          <source>Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">仅当存在 &lt;code&gt;rows_&lt;/code&gt; 和 &lt;code&gt;columns_&lt;/code&gt; 属性时有效。</target>
        </trans-unit>
        <trans-unit id="516478ad62f05e00111ddd57ddd26de9d50efa29" translate="yes" xml:space="preserve">
          <source>Open problem: Stock Market Structure</source>
          <target state="translated">开放性问题:股票市场结构</target>
        </trans-unit>
        <trans-unit id="988a0621a69f95c126d429edd6ad72b8b9753d30" translate="yes" xml:space="preserve">
          <source>OpenBLAS</source>
          <target state="translated">OpenBLAS</target>
        </trans-unit>
        <trans-unit id="01e06dfe8463084e545b7490a5b6cab212cacc1b" translate="yes" xml:space="preserve">
          <source>OpenML ID of the dataset. The most specific way of retrieving a dataset. If data_id is not given, name (and potential version) are used to obtain a dataset.</source>
          <target state="translated">数据集的OpenML ID。检索数据集的最具体方式。如果没有给出data_id,则使用名称(和潜在的版本)来获取数据集。</target>
        </trans-unit>
        <trans-unit id="b73a248fb134eb9cb2d0288db81a01291423c17b" translate="yes" xml:space="preserve">
          <source>OpenMP is used to parallelize code written in Cython or C, relying on multi-threading exclusively. By default (and unless joblib is trying to avoid oversubscription), the implementation will use as many threads as possible.</source>
          <target state="translated">OpenMP用于并行化Cython或C语言编写的代码,完全依赖多线程。默认情况下(除非joblib试图避免超量订阅),实现将使用尽可能多的线程。</target>
        </trans-unit>
        <trans-unit id="3c0cb6e8849966972823d3a411e3fa85cccc3662" translate="yes" xml:space="preserve">
          <source>Opposite of the Local Outlier Factor of X.</source>
          <target state="translated">X的局部离群因素的对立面。</target>
        </trans-unit>
        <trans-unit id="5e68f725eeef777e12b4d3a454a6208991fd24e6" translate="yes" xml:space="preserve">
          <source>Opposite of the Mahalanobis distances.</source>
          <target state="translated">对面的马哈兰博斯距离。</target>
        </trans-unit>
        <trans-unit id="b5fb56d4ea090bc2e90702500456ef35c8c80910" translate="yes" xml:space="preserve">
          <source>Opposite of the anomaly score defined in the original paper.</source>
          <target state="translated">与原论文中定义的异常得分相反。</target>
        </trans-unit>
        <trans-unit id="8d0235738e36c010f5cce0e1d51d26583f4fbd2f" translate="yes" xml:space="preserve">
          <source>Opposite of the value of X on the K-means objective.</source>
          <target state="translated">K-means目标上X值的相反。</target>
        </trans-unit>
        <trans-unit id="d4790d7d59a93c4896ec3d473b252d9c8e90d50a" translate="yes" xml:space="preserve">
          <source>Optimal choices for the sampling interval for certain data ranges can be computed (see the reference). The default values should be reasonable.</source>
          <target state="translated">可以计算出某些数据范围的采样间隔的最佳选择(见参考文献)。默认值应该是合理的。</target>
        </trans-unit>
        <trans-unit id="ce024d3ab746293c4c12993e7780e537aaab5bd3" translate="yes" xml:space="preserve">
          <source>Optimized BLAS / LAPACK implementations include:</source>
          <target state="translated">优化的BLAS/LAPACK实施包括:</target>
        </trans-unit>
        <trans-unit id="e7a4cb55708bbb7494e2613ab1d6bd3cf5f4ed80" translate="yes" xml:space="preserve">
          <source>Optimizing the KL divergence can be a little bit tricky sometimes. There are five parameters that control the optimization of t-SNE and therefore possibly the quality of the resulting embedding:</source>
          <target state="translated">优化KL分叉有时会有点棘手。有五个参数可以控制t-SNE的优化,从而可能控制结果嵌入的质量。</target>
        </trans-unit>
        <trans-unit id="59b7edea35dae0ba7f04b93972cd416b8729437e" translate="yes" xml:space="preserve">
          <source>Option to scale data</source>
          <target state="translated">缩放数据的选项</target>
        </trans-unit>
        <trans-unit id="b448cb50c967f57d438352622bd92cc83d5cd21c" translate="yes" xml:space="preserve">
          <source>Optional display names matching the labels (same order).</source>
          <target state="translated">可选择与标签相匹配的显示名称(顺序相同)。</target>
        </trans-unit>
        <trans-unit id="f7746b3179890337eeaaee24d3cefbf3e21f4716" translate="yes" xml:space="preserve">
          <source>Optional list of label indices to include in the report.</source>
          <target state="translated">报告中可选的标签索引列表。</target>
        </trans-unit>
        <trans-unit id="444d0152ba1b6a9d2f83b135dcad3591aef4140b" translate="yes" xml:space="preserve">
          <source>Optionally, weights can be provided for the individual classifiers:</source>
          <target state="translated">可选地,可以为各个分类器提供权重。</target>
        </trans-unit>
        <trans-unit id="53297f66af025e9af455b9620b74f88cfef40f7b" translate="yes" xml:space="preserve">
          <source>Or a confusion matrix can be constructed for each sample&amp;rsquo;s labels:</source>
          <target state="translated">或者可以为每个样本的标签构建一个混淆矩阵：</target>
        </trans-unit>
        <trans-unit id="bdffb8593fdda1fb06f464d41401bd543c75d539" translate="yes" xml:space="preserve">
          <source>Or as a dict mapping scorer name to a predefined or custom scoring function:</source>
          <target state="translated">或者作为一个将评分器名称映射到预定义或自定义评分功能的dict。</target>
        </trans-unit>
        <trans-unit id="568b3f93d3d74f4712d93109fe9bc1b3579dc2ff" translate="yes" xml:space="preserve">
          <source>Or drop a column for feature only having 2 categories:</source>
          <target state="translated">或者为只有2个类别的特征删除一栏。</target>
        </trans-unit>
        <trans-unit id="2919d9f2f1803bd27d88cb6979d8731b9671873d" translate="yes" xml:space="preserve">
          <source>Or, the Itakura-Saito (IS) divergence:</source>
          <target state="translated">或者说,板仓-斋藤(IS)的分歧。</target>
        </trans-unit>
        <trans-unit id="2eae1790c8b18065a4e4be5e643bf49617d7e481" translate="yes" xml:space="preserve">
          <source>Oracle Approximating Shrinkage Estimator</source>
          <target state="translated">Oracle近似收缩估算器</target>
        </trans-unit>
        <trans-unit id="09fb6aaba7940a7b7ffdbc9cbb9b3498303c1bad" translate="yes" xml:space="preserve">
          <source>Orange</source>
          <target state="translated">Orange</target>
        </trans-unit>
        <trans-unit id="1b5910554dc9c47445df182faeace08d47d3ef72" translate="yes" xml:space="preserve">
          <source>Order of output array in the dense case. &amp;lsquo;F&amp;rsquo; order is faster to compute, but may slow down subsequent estimators.</source>
          <target state="translated">在密集情况下输出数组的顺序。&amp;ldquo; F&amp;rdquo;阶的计算速度更快，但可能会减慢后续的估计量。</target>
        </trans-unit>
        <trans-unit id="61e854a8201b91e00e8fdcbd770fb61bc8a83663" translate="yes" xml:space="preserve">
          <source>Order of the norm used to filter the vectors of coefficients below &lt;code&gt;threshold&lt;/code&gt; in the case where the &lt;code&gt;coef_&lt;/code&gt; attribute of the estimator is of dimension 2.</source>
          <target state="translated">在估算器的 &lt;code&gt;coef_&lt;/code&gt; 属性的尺寸为2 的情况下，用于过滤低于 &lt;code&gt;threshold&lt;/code&gt; 的系数矢量的范数的顺序。</target>
        </trans-unit>
        <trans-unit id="04f01a5d4b5e2de7c5bc38f04fe789073a85e1a0" translate="yes" xml:space="preserve">
          <source>Ordinary Least Squares and Ridge Regression Variance</source>
          <target state="translated">普通最小二乘法和山脊回归方差。</target>
        </trans-unit>
        <trans-unit id="69dfb38c02d49acfa60317532da350814008c91b" translate="yes" xml:space="preserve">
          <source>Ordinary least squares Linear Regression.</source>
          <target state="translated">普通最小二乘线性回归。</target>
        </trans-unit>
        <trans-unit id="c6a26fb9333dc9c04fcf0b8a8d439bec3529ccb6" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the book &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; by Radford M. Neal</source>
          <target state="translated">Radford M.Neal 在《 &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; 的贝叶斯学习》一书中详细介绍了原始算法。</target>
        </trans-unit>
        <trans-unit id="285a92205b1ae0ee38089b09c3441dcd00669592" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">Hastie等人在论文的&lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;最小角回归中&lt;/a&gt;详细介绍了原始算法。</target>
        </trans-unit>
        <trans-unit id="b56fc3a445b7bdb3d075f8c4b435d8408f7cbd6d" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;https://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">Hastie等人在论文的&lt;a href=&quot;https://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;最小角回归中&lt;/a&gt;详细介绍了原始算法。</target>
        </trans-unit>
        <trans-unit id="40e1a40682f2197d130d7160c72b099cf6445896" translate="yes" xml:space="preserve">
          <source>Original Owners:</source>
          <target state="translated">原主人。</target>
        </trans-unit>
        <trans-unit id="7ad091e9d90ec0296b62c3e5e44ac8d89a063912" translate="yes" xml:space="preserve">
          <source>Original data</source>
          <target state="translated">原始数据</target>
        </trans-unit>
        <trans-unit id="e08c8e7e7ce9b41fa431a10c664db0046193d186" translate="yes" xml:space="preserve">
          <source>Original indices of sorted hashed values in the fitted index.</source>
          <target state="translated">拟合指数中排序哈希值的原始指数。</target>
        </trans-unit>
        <trans-unit id="7bcdd254a48ca093c51f99fbea960c8ba5abba3d" translate="yes" xml:space="preserve">
          <source>Original points</source>
          <target state="translated">原点</target>
        </trans-unit>
        <trans-unit id="d62335c307cfd6338409df5c3eb510c3da387b07" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit</source>
          <target state="translated">正交匹配追求</target>
        </trans-unit>
        <trans-unit id="4b43e1fc477a65c488f6b885c65608062bcdd067" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">正交匹配追求(OMP)</target>
        </trans-unit>
        <trans-unit id="6f8635fe08116f66d41828127f270123a3daf2dc" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit model (OMP)</source>
          <target state="translated">正交匹配追求模型(OMP)</target>
        </trans-unit>
        <trans-unit id="b4cea4b2e1d94206efdd2c81ac084782051e04a0" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit (&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt;)</source>
          <target state="translated">正交匹配追踪（&lt;a href=&quot;linear_model#omp&quot;&gt;正交匹配追踪（OMP）&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="2d35a4350f19547a1df08de9c97e28d5eb4c4c18" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">正交匹配追踪是在G. Mallat，Z. Zhang中引入的，《时频字典的匹配追踪》，IEEE Transactions on Signal Processing，Vol。41，No.12（1993年12月），第3397-3415页。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="5e7d9b3e4cebb5843b9125c6b797beb3832d1f95" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">正交匹配追踪是在S. Mallat，Z. Zhang中引入的，《时频字典的匹配追踪》，IEEE Transactions on Signal Processing，Vol。41，No.12（1993年12月），第3397-3415页。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="6e6a6f2086bb5fe5dbfd17d8d5f502d48759834b" translate="yes" xml:space="preserve">
          <source>Other</source>
          <target state="translated">Other</target>
        </trans-unit>
        <trans-unit id="708bf6f62e354ff314651598e7eebc62fd8d2bb2" translate="yes" xml:space="preserve">
          <source>Other Parameters</source>
          <target state="translated">其他参数</target>
        </trans-unit>
        <trans-unit id="0faa321ae463cf423d057b0fb19c09b0142f3c2a" translate="yes" xml:space="preserve">
          <source>Other Parameters:</source>
          <target state="translated">其他参数:</target>
        </trans-unit>
        <trans-unit id="f7488409b393eaa19a207155b56a3606cc42d9c5" translate="yes" xml:space="preserve">
          <source>Other Versions</source>
          <target state="translated">其他版本</target>
        </trans-unit>
        <trans-unit id="bf60b2f111b62bfaee7623785937d680b71fe343" translate="yes" xml:space="preserve">
          <source>Other distance functions can be used in NMF as, for example, the (generalized) Kullback-Leibler (KL) divergence, also referred as I-divergence:</source>
          <target state="translated">其他的距离函数也可以用在NMF中,例如,(广义的)Kullback-Leibler(KL)发散,也称为I发散。</target>
        </trans-unit>
        <trans-unit id="7ba50765d1cae4c4ed89d4ff332ed3b825d08abc" translate="yes" xml:space="preserve">
          <source>Other features match the names and e-mail addresses of particular people who were posting at the time.</source>
          <target state="translated">其他功能可匹配当时发帖的特定人员的姓名和电子邮件地址。</target>
        </trans-unit>
        <trans-unit id="51c966edfa7d64a0b7dcf68b92d77cfd5b366772" translate="yes" xml:space="preserve">
          <source>Other machine learning packages for Python and related projects. Also algorithms that are slightly out of scope or not well established enough for scikit-learn.</source>
          <target state="translated">其他Python和相关项目的机器学习包。也有稍微超出scikit-learn范围或不够成熟的算法。</target>
        </trans-unit>
        <trans-unit id="2ea8bcd548fe9ec11d17cc82aea4ab0fbdf7f8f3" translate="yes" xml:space="preserve">
          <source>Other regression generators generate functions deterministically from randomized features. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt;&lt;code&gt;make_sparse_uncorrelated&lt;/code&gt;&lt;/a&gt; produces a target as a linear combination of four features with fixed coefficients. Others encode explicitly non-linear relations: &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt;&lt;code&gt;make_friedman1&lt;/code&gt;&lt;/a&gt; is related by polynomial and sine transforms; &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt;&lt;code&gt;make_friedman2&lt;/code&gt;&lt;/a&gt; includes feature multiplication and reciprocation; and &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt;&lt;code&gt;make_friedman3&lt;/code&gt;&lt;/a&gt; is similar with an arctan transformation on the target.</source>
          <target state="translated">其他回归生成器根据随机特征确定性地生成函数。&lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt; &lt;code&gt;make_sparse_uncorrelated&lt;/code&gt; &lt;/a&gt;将目标生成为具有固定系数的四个特征的线性组合。其他的则编码明确的非线性关系：&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt; &lt;code&gt;make_friedman1&lt;/code&gt; &lt;/a&gt;通过多项式和正弦变换相关；&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt; &lt;code&gt;make_friedman2&lt;/code&gt; &lt;/a&gt;包含特征乘法和往复运算；和&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt; &lt;code&gt;make_friedman3&lt;/code&gt; &lt;/a&gt;与目标反正切变换相似。</target>
        </trans-unit>
        <trans-unit id="756226f83bdd3199110bcb639e6fbe93b81b2b14" translate="yes" xml:space="preserve">
          <source>Others also work in the multiclass case:</source>
          <target state="translated">其他的也是在多类情况下工作。</target>
        </trans-unit>
        <trans-unit id="31c4dae2edc1b6ad8f22c0a6f68a8f7ab2bd8316" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be a sequence of items that can be of type string or byte.</source>
          <target state="translated">否则,输入将是一个可以是字符串或字节类型的项目序列。</target>
        </trans-unit>
        <trans-unit id="bce48a0cb0a5e5960a4a35ec10cf25f56bf2f60b" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be the sequence strings or bytes items are expected to be analyzed directly.</source>
          <target state="translated">否则,预计将直接分析输入的序列字符串或字节项。</target>
        </trans-unit>
        <trans-unit id="1eb83bd09e16b910ee3986257ed6e80732bc066a" translate="yes" xml:space="preserve">
          <source>Our definition: &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;, &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; and &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;, where &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; adopt the adjusted version to ensure that random predictions have a score of \(0\) and perfect predictions have a score of \(1\)..</source>
          <target state="translated">我们的定义：&lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;，&lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt;和&lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;，其中&lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt;采用调整后的版本，以确保随机预测的得分为\（0 \）和完美预测的得分为\（1 \）。 。</target>
        </trans-unit>
        <trans-unit id="4dd148768e9c37b7c74e1f4e4e0bf60f2fa1ec4e" translate="yes" xml:space="preserve">
          <source>Our goal is to predict the expected frequency of claims following car accidents for a new policyholder given the historical data over a population of policyholders.</source>
          <target state="translated">我们的目标是根据保单持有人的历史数据,预测新保单持有人发生车祸后的预期索赔频率。</target>
        </trans-unit>
        <trans-unit id="51a30e97a793068228d5bb8b3efc1038cb1f9689" translate="yes" xml:space="preserve">
          <source>Our implementation of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; was inspired by the R MICE package (Multivariate Imputation by Chained Equations) &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;, but differs from it by returning a single imputation instead of multiple imputations. However, &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; can also be used for multiple imputations by applying it repeatedly to the same dataset with different random seeds when &lt;code&gt;sample_posterior=True&lt;/code&gt;. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;, chapter 4 for more discussion on multiple vs. single imputations.</source>
          <target state="translated">我们的&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; 的&lt;/a&gt;实现受到R MICE程序包（通过链式方程进行的多元插补）的启发&lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;，但与之不同之处在于，它返回的是单个插补而不是多个插补。但是，当 &lt;code&gt;sample_posterior=True&lt;/code&gt; 时，通过将&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; &lt;/a&gt;重复应用于具有不同随机种子的同一数据集，也可以将其用于多个插补。有关多重插补与单个插补的更多讨论，请参见第&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;章第4章。</target>
        </trans-unit>
        <trans-unit id="a60ce8fd0b60aee8ad7f5d9f917babe62e72b491" translate="yes" xml:space="preserve">
          <source>Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">我们的实现的得分比Tsoumakas等人（2010年）给出的得分高1。这将其扩展为可以处理实例具有0个真实标签的退化情况。</target>
        </trans-unit>
        <trans-unit id="fe0259b257120510b76da78ac976bdfb1e816c30" translate="yes" xml:space="preserve">
          <source>Our target for prediction: the wage. Wages are described as floating-point number in dollars per hour.</source>
          <target state="translated">我们预测的目标:工资。工资以每小时美元为单位的浮点数来描述。</target>
        </trans-unit>
        <trans-unit id="c3f0fa9ade6f943d608603fdef87384f7f12b49b" translate="yes" xml:space="preserve">
          <source>Out of the &lt;code&gt;n_features&lt;/code&gt; features, only 5 are actually used to compute &lt;code&gt;y&lt;/code&gt;. The remaining features are independent of &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">在 &lt;code&gt;n_features&lt;/code&gt; 个特征中，实际上只有5个用于计算 &lt;code&gt;y&lt;/code&gt; 。其余特征与 &lt;code&gt;y&lt;/code&gt; 无关。</target>
        </trans-unit>
        <trans-unit id="de345f1c1e8c124d63c9ee465bc413813ba2423e" translate="yes" xml:space="preserve">
          <source>Out-of-bag (OOB) estimates can be a useful heuristic to estimate the &amp;ldquo;optimal&amp;rdquo; number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt;), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.</source>
          <target state="translated">袋外（OOB）估计可能是一种有用的启发式方法，用于估计增强迭代的&amp;ldquo;最佳&amp;rdquo;次数。OOB估计值几乎与交叉验证估计值相同，但是可以即时进行计算，而无需重复进行模型拟合。OOB估计仅适用于随机梯度增强（即 &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt; ），该估计是基于自举样本中未包含的示例（所谓的&amp;ldquo;袋外示例&amp;rdquo;）从损失的改善中得出的。OOB估计器是真实测试损失的悲观估计器，但是对于少量的树仍然是一个相当不错的近似值。</target>
        </trans-unit>
        <trans-unit id="0edae687594f6a8a4aaab025d755be89c91cf6e0" translate="yes" xml:space="preserve">
          <source>Out-of-core (or &amp;ldquo;external memory&amp;rdquo;) learning is a technique used to learn from data that cannot fit in a computer&amp;rsquo;s main memory (RAM).</source>
          <target state="translated">核外（或&amp;ldquo;外部内存&amp;rdquo;）学习是一种用于从无法容纳在计算机主内存（RAM）中的数据中学习的技术。</target>
        </trans-unit>
        <trans-unit id="9961951956a78a655327742f08dd6b72dea1283f" translate="yes" xml:space="preserve">
          <source>Out-of-core classification of text documents</source>
          <target state="translated">文本文件的核心外分类</target>
        </trans-unit>
        <trans-unit id="1ee8fea1697e4d708569e4bb179873c92ff19379" translate="yes" xml:space="preserve">
          <source>Out:</source>
          <target state="translated">Out:</target>
        </trans-unit>
        <trans-unit id="5dd0aa388360b95626a38da9b18844d684c8d25b" translate="yes" xml:space="preserve">
          <source>Outlier detection</source>
          <target state="translated">异常值检测</target>
        </trans-unit>
        <trans-unit id="875f738eb0e68cda4066331e25fac5af4c71d682" translate="yes" xml:space="preserve">
          <source>Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.</source>
          <target state="translated">离群点检测和新奇点检测都是用于异常点检测,人们对检测异常或不寻常的观察结果感兴趣。那么,离群值检测也被称为无监督异常检测,新奇度检测被称为半监督异常检测。在异常点检测的情况下,异常点/异常值不能形成一个密集的聚类,因为现有的估计器假设异常点/异常值位于低密度区域。相反,在新奇点检测的情况下,新奇点/异常点只要位于训练数据的低密度区域,就可以形成一个密集簇,在这种情况下被认为是正常的。</target>
        </trans-unit>
        <trans-unit id="e16ebe52f017c4437fca8210daa352b7f7a34559" translate="yes" xml:space="preserve">
          <source>Outlier detection from covariance estimation may break or not perform well in high-dimensional settings. In particular, one will always take care to work with &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt;.</source>
          <target state="translated">在高维设置中，根据协方差估计进行的异常值检测可能会中断或效果不佳。特别要注意的是，要始终使用 &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="eb5776745abd0907a25a2d19ca27c92845132829" translate="yes" xml:space="preserve">
          <source>Outlier detection is similar to novelty detection in the sense that the goal is to separate a core of regular observations from some polluting ones, called &lt;em&gt;outliers&lt;/em&gt;. Yet, in the case of outlier detection, we don&amp;rsquo;t have a clean data set representing the population of regular observations that can be used to train any tool.</source>
          <target state="translated">离群值检测与新颖性检测类似，在某种意义上，目标是将常规观测的核心与某些受污染的观测&lt;em&gt;值（离群值）&lt;/em&gt;分开。但是，在离群值检测的情况下，我们没有干净的数据集来表示可用于训练任何工具的常规观测值。</target>
        </trans-unit>
        <trans-unit id="1d8881b6614c5c1d87283378baf1dfbd30d62aa2" translate="yes" xml:space="preserve">
          <source>Outlier detection on a real data set</source>
          <target state="translated">真实数据集的离群值检测</target>
        </trans-unit>
        <trans-unit id="4567caf33a07f033c1e56ef9d81272da195ec4e4" translate="yes" xml:space="preserve">
          <source>Outlier detection with Local Outlier Factor (LOF)</source>
          <target state="translated">使用局部离群值因子(LOF)进行离群值检测。</target>
        </trans-unit>
        <trans-unit id="fd5effe3fc538ea2a8eadf46c1fdeca372b53b13" translate="yes" xml:space="preserve">
          <source>Outlier-robust regressors</source>
          <target state="translated">离群索居的回归者</target>
        </trans-unit>
        <trans-unit id="1d4ae6e212657597b75c35cebf362553af1f6b83" translate="yes" xml:space="preserve">
          <source>Outliers in the X direction</source>
          <target state="translated">X方向的离群值</target>
        </trans-unit>
        <trans-unit id="1280eb8e6f7378d868cfa7fd24acb5cb10594078" translate="yes" xml:space="preserve">
          <source>Outliers in the y direction</source>
          <target state="translated">y方向的离群值</target>
        </trans-unit>
        <trans-unit id="fd162763a0f66a902211a2d40da7afdfc74ea634" translate="yes" xml:space="preserve">
          <source>Output a list of n_output arrays of class probabilities upon &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">在输出级的概率n_output阵列的列表 &lt;code&gt;predict_proba&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8298d7fc7f7d06e9b0287b5d9b7af6acdbad01e4" translate="yes" xml:space="preserve">
          <source>Output n_output values upon &lt;code&gt;predict&lt;/code&gt;;</source>
          <target state="translated">根据 &lt;code&gt;predict&lt;/code&gt; 输出n_output值;</target>
        </trans-unit>
        <trans-unit id="c9a682f0f812fa2f90e0a2d7878d2c9702a9c510" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;3&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">基于输出代码的策略与剩下的一对一和一对一完全不同。使用这些策略，每个类都在一个欧几里得空间中表示，每个维只能为0或1。另一种表达方式是，每个类都由一个二进制代码（0和1的数组）表示。跟踪每个类的位置/代码的矩阵称为代码簿。代码大小是上述空间的维数。直观地讲，每个类都应由一个尽可能唯一的代码表示，并且应设计一个好的代码书来优化分类的准确性。在此实现中，我们仅使用&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;3中&lt;/a&gt;所提倡的随机生成的代码簿，尽管将来可能会添加更复杂的方法。</target>
        </trans-unit>
        <trans-unit id="0c950fe98702d8e76b55b31a01ec26c58021324c" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">基于输出代码的策略与剩下的一对一和一对一完全不同。使用这些策略，每个类都在一个欧几里得空间中表示，每个维只能是0或1。另一种表达方式是，每个类都由一个二进制代码（0和1的数组）表示。跟踪每个类的位置/代码的矩阵称为代码簿。代码大小是上述空间的维数。直观地，每个类都应由一个尽可能唯一的代码表示，并且应设计一个好的代码书来优化分类的准确性。在此实现中，我们仅使用&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]中&lt;/a&gt;提倡的随机生成的代码簿，尽管将来可能会添加更多复杂的方法。</target>
        </trans-unit>
        <trans-unit id="ce947ff733c2ff6c4c204d57e36546e6961c8fdc" translate="yes" xml:space="preserve">
          <source>Output-code based strategies consist in representing each class with a binary code (an array of 0s and 1s). At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen. The main advantage of these strategies is that the number of classifiers used can be controlled by the user, either for compressing the model (0 &amp;lt; code_size &amp;lt; 1) or for making the model more robust to errors (code_size &amp;gt; 1). See the documentation for more details.</source>
          <target state="translated">基于输出代码的策略包括用二进制代码（0和1的数组）表示每个类。在拟合时，在代码簿中每位装配一个二进制分类器。在预测时，分类器用于在类空间中投影新点，并选择最接近这些点的类。这些策略的主要优点是用户可以控制使用的分类器数量，以压缩模型（0 &amp;lt;code_size &amp;lt;1）或使模型对错误更健壮（code_size&amp;gt; 1）。有关更多详细信息，请参见文档。</target>
        </trans-unit>
        <trans-unit id="a7e6bae7017e237617a86072aea77d9c980daf13" translate="yes" xml:space="preserve">
          <source>Overall mean.</source>
          <target state="translated">总的平均数。</target>
        </trans-unit>
        <trans-unit id="870624bf4593bb4fe243ffdc55690c0daf6811c5" translate="yes" xml:space="preserve">
          <source>Overall mean. Only present if solver is &amp;lsquo;svd&amp;rsquo;.</source>
          <target state="translated">总体均值。仅当求解器为&amp;ldquo; svd&amp;rdquo;时才存在。</target>
        </trans-unit>
        <trans-unit id="39400cd6ec0520b5a4505f75497b844c4371060d" translate="yes" xml:space="preserve">
          <source>Overall you can expect the prediction time to increase at least linearly with the number of features (non-linear cases can happen depending on the global memory footprint and estimator).</source>
          <target state="translated">总的来说,你可以预期预测时间至少会随着特征数量的增加而线性增加(非线性情况可能发生,这取决于全局内存占用和估计器)。</target>
        </trans-unit>
        <trans-unit id="3ee1d3fb4e75cd6c2d707958304caf7e92bfaa8b" translate="yes" xml:space="preserve">
          <source>Overall, the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;) has a weak impact on the claim severity, both in observed and predicted data.</source>
          <target state="translated">总体而言，无论是在观察数据还是预测数据中，驾驶员年龄（ &lt;code&gt;DrivAge&lt;/code&gt; ）对索赔严重性的影响均很小。</target>
        </trans-unit>
        <trans-unit id="91bd96083d98dc97930a239b87544217767aceaf" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps.</source>
          <target state="translated">在保留tokenizing和n-grams生成步骤的同时,覆盖预处理(字符串转换)阶段。</target>
        </trans-unit>
        <trans-unit id="acdc2f08598a5d995bb4a299bbeb6695fc569906" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps. Only applies if &lt;code&gt;analyzer is not callable&lt;/code&gt;.</source>
          <target state="translated">在保留标记化和n-gram生成步骤的同时，覆盖预处理（字符串转换）阶段。仅适用于 &lt;code&gt;analyzer is not callable&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="abd6316e00c26c25837bba2d69b86f216194acd8" translate="yes" xml:space="preserve">
          <source>Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">在保留预处理和n-gram生成步骤的同时，覆盖字符串标记化步骤。仅在 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="33411261f8481ce8d25af4edfb3eb882b6e66f99" translate="yes" xml:space="preserve">
          <source>Oversubscription can arise in the exact same fashion with parallelized routines from MKL, OpenBLAS or BLIS that are nested in joblib calls.</source>
          <target state="translated">来自MKL、OpenBLAS或BLIS的并行化例程,如果嵌套在joblib调用中,也会以完全相同的方式出现超配。</target>
        </trans-unit>
        <trans-unit id="9ed28a68908d4cdeb1448490b897df73855c6566" translate="yes" xml:space="preserve">
          <source>P. Geurts, D. Ernst., and L. Wehenkel, &amp;ldquo;Extremely randomized trees&amp;rdquo;, Machine Learning, 63(1), 3-42, 2006.</source>
          <target state="translated">P. Geurts，D。Ernst。和L. Wehenkel，&amp;ldquo;极端随机树&amp;rdquo;，Machine Learning，63（1），3-42，2006年。</target>
        </trans-unit>
        <trans-unit id="12d77ff2c2e2faf889fa68d60f9acbbdadb178db" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. J. Am Stat Ass, 79:871, 1984.</source>
          <target state="translated">P.J.Rousseeuw。二乘法回归的最小中位数。J.Am Stat Ass,79:871,1984。</target>
        </trans-unit>
        <trans-unit id="915eb2720a9af992fe72961a5e439fc3997b7b8e" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. Journal of American Statistical Ass., 79:871, 1984.</source>
          <target state="translated">P.J.Rousseeuw。二乘法回归的最小中值。Journal of American Statistical Ass.,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="b9c25cc16ba020ea92289241ec3d659cb7a5c1ce" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach，M.Kull，&lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;精确召回增益曲线：PR分析正确完成&lt;/a&gt;，NIPS 2015。</target>
        </trans-unit>
        <trans-unit id="6732b8c3c2862c9a25623cf97fcdcc10a13cb40d" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach，M.Kull，《&lt;a href=&quot;https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;精确召回增益曲线：正确的PR分析》&lt;/a&gt;，NIPS，2015年。</target>
        </trans-unit>
        <trans-unit id="df9f68f22da202cd6a48417661656eae814961f2" translate="yes" xml:space="preserve">
          <source>PCA centers but does not scale the input data for each feature before applying the SVD. The optional parameter &lt;code&gt;whiten=True&lt;/code&gt; makes it possible to project the data onto the singular space while scaling each component to unit variance. This is often useful if the models down-stream make strong assumptions on the isotropy of the signal: this is for example the case for Support Vector Machines with the RBF kernel and the K-Means clustering algorithm.</source>
          <target state="translated">在应用SVD之前，PCA会居中，但不会按比例缩放每个功能的输入数据。可选参数 &lt;code&gt;whiten=True&lt;/code&gt; 使得可以将数据投影到奇异空间上，同时将每个分量缩放到单位方差。如果下游模型对信号的各向同性有很强的假设，这通常会很有用：例如，带有RBF内核和K-Means聚类算法的支持向量机就是这种情况。</target>
        </trans-unit>
        <trans-unit id="492b92fdeb678aa5ea0a0b2e24c313120c5ad6a0" translate="yes" xml:space="preserve">
          <source>PCA example with Iris Data-set</source>
          <target state="translated">Iris数据集的PCA实例</target>
        </trans-unit>
        <trans-unit id="e783d8dc6810fed89a1dbeb972c615c5d6fa683c" translate="yes" xml:space="preserve">
          <source>PCA is used to decompose a multivariate dataset in a set of successive orthogonal components that explain a maximum amount of the variance. In scikit-learn, &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is implemented as a &lt;em&gt;transformer&lt;/em&gt; object that learns \(n\) components in its &lt;code&gt;fit&lt;/code&gt; method, and can be used on new data to project it on these components.</source>
          <target state="translated">PCA用于分解一组解释最大方差的连续正交分量中的多元数据集。在scikit-learn中，&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;被实现为一个&lt;em&gt;转换&lt;/em&gt;对象，该对象以其 &lt;code&gt;fit&lt;/code&gt; 方法学习\（n \）个组件，并可用于新数据以将其投影到这些组件上。</target>
        </trans-unit>
        <trans-unit id="a8428e4319c22658665567a92df72d0be42ed589" translate="yes" xml:space="preserve">
          <source>PCA, on the other hand, finds orthogonal directions in the raw feature space that correspond to directions accounting for maximum variance.</source>
          <target state="translated">PCA则是在原始特征空间中找到正交方向,对应占最大方差的方向。</target>
        </trans-unit>
        <trans-unit id="daf6b41a17ad64437397807edf4249f5c767d4f8" translate="yes" xml:space="preserve">
          <source>PDF documentation</source>
          <target state="translated">PDF文件</target>
        </trans-unit>
        <trans-unit id="39addbbc6b853c00475e9525bae3e13c16a88c57" translate="yes" xml:space="preserve">
          <source>PDF of a random variable Y following Poisson, Tweedie (power=1.5) and Gamma distributions with different mean values (\(\mu\)). Observe the point mass at \(Y=0\) for the Poisson distribution and the Tweedie (power=1.5) distribution, but not for the Gamma distribution which has a strictly positive target domain.</source>
          <target state="translated">一个随机变量Y在Poisson、Tweedie(power=1.5)和Gamma分布之后的PDF,其平均值不同(())。观察Poisson分布和Tweedie(power=1.5)分布的点质量,但Gamma分布的点质量并不是严格的正目标域。</target>
        </trans-unit>
        <trans-unit id="83a2c673c060675dd48fb711d1c30c7deadadba5" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above Figure shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">具有两个目标特征的PDP显示了两个特征之间的相互作用。例如,上图中的两个变量PDP显示了房价中位数对房龄和每户平均居住人数联合值的依赖性。我们可以清楚地看到这两个特征之间的互动关系。对于平均住户数大于2的情况,房价几乎与房龄无关,而对于小于2的值,则对房龄有很大的依赖性。</target>
        </trans-unit>
        <trans-unit id="eb9628323c2e00c334e5176712c96c9098e56078" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above figure shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than 2 there is a strong dependence on age.</source>
          <target state="translated">具有两个目标特征的PDP显示了两个特征之间的相互作用。例如,上图中的双变量PDP显示了房价中位数对房龄和每户平均居住人数联合值的依赖性。我们可以清楚地看到两个特征之间的相互作用:对于平均入住人数大于2的情况,房价几乎与房龄无关,而对于小于2的数值,则对房龄有很强的依赖性。</target>
        </trans-unit>
        <trans-unit id="818b23313a5fe3e3ead33eeac95b3f83aefbbeb6" translate="yes" xml:space="preserve">
          <source>PLS regression</source>
          <target state="translated">PLS回归</target>
        </trans-unit>
        <trans-unit id="256d47be93e9a1da4b73eeee064926026bfad0da" translate="yes" xml:space="preserve">
          <source>PLSCanonical implements the 2 blocks canonical PLS of the original Wold algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</source>
          <target state="translated">PLSCanonical实现了原始Wold算法[Tenenhaus 1998]p.204的2块规范PLS,在[Wegelin 2000]中称为PLS-C2A。</target>
        </trans-unit>
        <trans-unit id="cbfe13649cb0f1ff547f98c2537765f522c1604e" translate="yes" xml:space="preserve">
          <source>PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1 in case of one dimensional response. This class inherits from _PLS with mode=&amp;rdquo;A&amp;rdquo;, deflation_mode=&amp;rdquo;regression&amp;rdquo;, norm_y_weights=False and algorithm=&amp;rdquo;nipals&amp;rdquo;.</source>
          <target state="translated">PLSRegression实现一维响应时称为PLS2或PLS1的PLS 2块回归。此类从_PLS继承，其模式为&amp;ldquo; A&amp;rdquo;，deflation_mode =&amp;ldquo;回归&amp;rdquo;，norm_y_weights = False，算法=&amp;ldquo; nipals&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="5bd004de10b3be3d62af4c772e0a783e4c8d0cf7" translate="yes" xml:space="preserve">
          <source>PTRATIO pupil-teacher ratio by town</source>
          <target state="translated">PTRATIO 按城市分列的学生-教师比率</target>
        </trans-unit>
        <trans-unit id="41c1bb8d3d0929f28ded963b3c507fc9ad31e847" translate="yes" xml:space="preserve">
          <source>Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions, Statistics and Probability Letters, 33 (1997) 291-297</source>
          <target state="translated">Pace,R.Kelley和Ronald Barry,《稀疏空间自回归》,《统计与概率学报》,33(1997)291-297。</target>
        </trans-unit>
        <trans-unit id="839107cb8051c220f3fa3546dd66b100d0cfaf46" translate="yes" xml:space="preserve">
          <source>Pairwise Euclidean distances between points in the dataset.</source>
          <target state="translated">数据集中各点之间的欧几里得距离。</target>
        </trans-unit>
        <trans-unit id="91ced6bbdf313e062ca8a5307f468c6f86bd6aab" translate="yes" xml:space="preserve">
          <source>Pairwise dissimilarities between the points. Must be symmetric.</source>
          <target state="translated">点之间的对偶异同。必须是对称的。</target>
        </trans-unit>
        <trans-unit id="d8020c04569a536923cc79cf93520b90edece8e9" translate="yes" xml:space="preserve">
          <source>Pairwise metrics</source>
          <target state="translated">配对指标</target>
        </trans-unit>
        <trans-unit id="0f7f7966f9f80e85baa6445a47b9d7c8941de99f" translate="yes" xml:space="preserve">
          <source>Parameter &lt;code&gt;nu&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;OneClassSVM&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; approximates the fraction of training errors and support vectors.</source>
          <target state="translated">参数 &lt;code&gt;nu&lt;/code&gt; 在&lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;OneClassSVM&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; &lt;/a&gt;近似于训练误差和支持向量的分数。</target>
        </trans-unit>
        <trans-unit id="539d705b4d5ce5e51b178019bd7f151f362e066d" translate="yes" xml:space="preserve">
          <source>Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogenous.</source>
          <target state="translated">控制核的不均匀性的参数,如果sigma_0=0,则核是均匀的。如果sigma_0=0,则内核是同质的。</target>
        </trans-unit>
        <trans-unit id="2462327ecfe7c5d6548ffb2d6d2c9cd234dbc30c" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level</source>
          <target state="translated">控制噪音水平的参数</target>
        </trans-unit>
        <trans-unit id="c00b33b8475549fd87f899268c585bfb7eff3c97" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level (variance)</source>
          <target state="translated">控制噪声水平(方差)的参数。</target>
        </trans-unit>
        <trans-unit id="4958bb8c16cafb2697226165d2c132d7ac8dc77e" translate="yes" xml:space="preserve">
          <source>Parameter estimation using grid search with cross-validation</source>
          <target state="translated">利用交叉验证的网格搜索进行参数估计。</target>
        </trans-unit>
        <trans-unit id="c2428812e57708220766f99c6be2b35f70d17ffd" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel</source>
          <target state="translated">knn内核的参数</target>
        </trans-unit>
        <trans-unit id="3b0d1a590649f050970c31b6418be3790d6a82df" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which is a strictly positive integer.</source>
          <target state="translated">knn核的参数,是一个严格的正整数。</target>
        </trans-unit>
        <trans-unit id="849fb657e2772ba4166207f98cd952ea68adf842" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which need to be strictly positive.</source>
          <target state="translated">knn核的参数,需要严格为正。</target>
        </trans-unit>
        <trans-unit id="1fe064660ce73ee246b908fe6ec0781ebb1b98a2" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel</source>
          <target state="translated">rbf内核的参数</target>
        </trans-unit>
        <trans-unit id="deecb0cfdd93d212c57e43f85e54500d3ea12cc6" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel.</source>
          <target state="translated">rbf内核的参数。</target>
        </trans-unit>
        <trans-unit id="766ac73c1e3445a4aa75bd4ec364753f58d7ba1c" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt;&lt;/a&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">&lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt; 中&lt;/a&gt;的Minkowski度量参数。当p = 1时，这等效于对p = 2使用manhattan_distance（l1）和euclidean_distance（l2）。对于任意p，使用minkowski_distance（l_p）。</target>
        </trans-unit>
        <trans-unit id="79b884107bc3e783bfcd688080df4a673a9117bc" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">&lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt; 指标的参数来自sklearn.metrics.pairwise.pairwise_distances。当p = 1时，这等效于对p = 2使用manhattan_distance（l1）和euclidean_distance（l2）。对于任意p，使用minkowski_distance（l_p）。</target>
        </trans-unit>
        <trans-unit id="2987673c5e2227c54e84a4c36c70d874959de513" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">来自sklearn.metrics.pairwise.pairwise_distances的Minkowski度量参数。当p=1时,相当于使用曼哈顿距离(l1),当p=2时,使用欧几里得距离(l2)。对于任意的p,使用minkowski_distance (l_p)。</target>
        </trans-unit>
        <trans-unit id="76b1a424a6610c92a4ff7dfc12b9deaa7fadd9d4" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric</source>
          <target state="translated">对核的参数gamma由度量器指定</target>
        </trans-unit>
        <trans-unit id="1a54a92f7211f800d04136c5d7139c5f372c6e37" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric. It should be positive.</source>
          <target state="translated">对偶核的参数gamma,由度量衡指定。应该是正值。</target>
        </trans-unit>
        <trans-unit id="5f182d859d9049c92f489a6a5f8f861f198a0672" translate="yes" xml:space="preserve">
          <source>Parameter names mapped to their values.</source>
          <target state="translated">对应到其值的参数名称。</target>
        </trans-unit>
        <trans-unit id="6c7eaceb91dd3f01e9a6c5c6273381eb8837898b" translate="yes" xml:space="preserve">
          <source>Parameter of RBF kernel: exp(-gamma * x^2)</source>
          <target state="translated">参数或RBF核:exp(-gamma*x^2)</target>
        </trans-unit>
        <trans-unit id="0a55d1c3b23ce41ff45285111de0d234bf72191c" translate="yes" xml:space="preserve">
          <source>Parameter of the corresponding mode.</source>
          <target state="translated">对应模式的参数。</target>
        </trans-unit>
        <trans-unit id="bd306dfafa0f09eb6ebeeb4165e12648835ffbc7" translate="yes" xml:space="preserve">
          <source>Parameter setting that gave the best results on the hold out data.</source>
          <target state="translated">剔除数据后得到最佳结果的参数设置。</target>
        </trans-unit>
        <trans-unit id="feb33995ff27df7648c2862697f9ab2d916fc6ad" translate="yes" xml:space="preserve">
          <source>Parameter to control the quality of the embedding according to the Johnson-Lindenstrauss lemma when n_components is set to &amp;lsquo;auto&amp;rsquo;.</source>
          <target state="translated">当n_components设置为'auto'时，根据Johnson-Lindenstrauss引理控制嵌入质量的参数。</target>
        </trans-unit>
        <trans-unit id="9ebea54f905d700d979affa38d92638bb2ef6e53" translate="yes" xml:space="preserve">
          <source>Parameter tuning using grid search</source>
          <target state="translated">使用网格搜索进行参数调整</target>
        </trans-unit>
        <trans-unit id="025546b75e4d071d18ff381aef96422930bc33e9" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). If a 1D y is passed in at fit (non multi-task usage), &lt;code&gt;coef_&lt;/code&gt; is then a 1D array. Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">参数向量（成本函数公式中的W）。如果适当传递1D y（非多任务用法），则 &lt;code&gt;coef_&lt;/code&gt; 为一维数组。注意， &lt;code&gt;coef_&lt;/code&gt; 存储 &lt;code&gt;W&lt;/code&gt; ， &lt;code&gt;W.T&lt;/code&gt; 的转置。</target>
        </trans-unit>
        <trans-unit id="fe2cd82aa0b85722f1fb3f2651910fd5a1cb8bc3" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">参数向量（成本函数公式中的W）。注意， &lt;code&gt;coef_&lt;/code&gt; 存储 &lt;code&gt;W&lt;/code&gt; ， &lt;code&gt;W.T&lt;/code&gt; 的转置。</target>
        </trans-unit>
        <trans-unit id="40a18e293fedd48b8399b301e107b7d0fd89c55d" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the cost function formula),</source>
          <target state="translated">参数向量(成本函数公式中的w);</target>
        </trans-unit>
        <trans-unit id="f2cc602f72e28952a1109943af93a6b27340c9a5" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the formulation formula).</source>
          <target state="translated">参数向量(公式中的w);</target>
        </trans-unit>
        <trans-unit id="b98d4ebc4de7e076498469fbea1e480d774d01d2" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the problem formulation).</source>
          <target state="translated">参数向量(问题表述中的w);</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="561ad54783e422872a1f3fe4a9c36ebd61273494" translate="yes" xml:space="preserve">
          <source>Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.</source>
          <target state="translated">作为可调用对象传递的内核的参数(关键字参数)和值。被其他内核忽略。</target>
        </trans-unit>
        <trans-unit id="80f07c17ffcb9ce6c39eaf0025d7648367dfab02" translate="yes" xml:space="preserve">
          <source>Parameters for the metric used to compute distances to neighbors.</source>
          <target state="translated">用于计算与邻居距离的度量参数。</target>
        </trans-unit>
        <trans-unit id="89febd358321017f18d670418f2852c0de1ee9c6" translate="yes" xml:space="preserve">
          <source>Parameters of the estimators in the pipeline can be accessed using the &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; syntax:</source>
          <target state="translated">可以使用 &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; 语法访问管道中估计器的参数：</target>
        </trans-unit>
        <trans-unit id="da0d463840d0f1c86c777dbae23f9ad6731982e6" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo; or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">可以使用变压器名称和以&amp;ldquo; __&amp;rdquo;分隔的参数名称来设置变压器的参数。可以通过将参数的名称设置为另一个变压器来完全替换一个变压器，也可以通过将其设置为'drop'或 &lt;code&gt;None&lt;/code&gt; 来移除它。</target>
        </trans-unit>
        <trans-unit id="689a87c23200ec6fa5f83b0f33b09b3222cdab89" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo;.</source>
          <target state="translated">可以使用变压器名称和以&amp;ldquo; __&amp;rdquo;分隔的参数名称来设置变压器的参数。可以通过将参数的名称设置为另一个变压器来完全替换一个变压器，也可以通过将其设置为&amp;ldquo; drop&amp;rdquo;来将其移除。</target>
        </trans-unit>
        <trans-unit id="fc1660202c57ce270668effe7d8743477471db0d" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;estimator.fit&lt;/code&gt; method of each step.</source>
          <target state="translated">传递给每个步骤的 &lt;code&gt;estimator.fit&lt;/code&gt; 方法的参数。</target>
        </trans-unit>
        <trans-unit id="cdc9ca5309db0dd08f8314e5e5818e96afcd9144" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method at each step of the regressor chain.</source>
          <target state="translated">在回归链的每个步骤传递给 &lt;code&gt;fit&lt;/code&gt; 方法的参数。</target>
        </trans-unit>
        <trans-unit id="b076b9abb4a3e4211d375c7fba667486c4754cb9" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of each step, where each parameter name is prefixed such that parameter &lt;code&gt;p&lt;/code&gt; for step &lt;code&gt;s&lt;/code&gt; has key &lt;code&gt;s__p&lt;/code&gt;.</source>
          <target state="translated">传递给每个步骤的 &lt;code&gt;fit&lt;/code&gt; 方法的参数，其中每个参数名称都带有前缀，使得步骤 &lt;code&gt;s&lt;/code&gt; 的参数 &lt;code&gt;p&lt;/code&gt; 具有键 &lt;code&gt;s__p&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1ab85e076de8886205c489db8ed7843daa19517c" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the estimator</source>
          <target state="translated">传递给估算器的 &lt;code&gt;fit&lt;/code&gt; 方法的参数</target>
        </trans-unit>
        <trans-unit id="6dde0ba4e8565b39355c42aec6126c1947540a58" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the underlying regressor.</source>
          <target state="translated">传递给基础回归器的 &lt;code&gt;fit&lt;/code&gt; 方法的参数。</target>
        </trans-unit>
        <trans-unit id="0e8067debf1488481c61a1eaa4a0a76867521e4f" translate="yes" xml:space="preserve">
          <source>Parameters to be set on estimator for this grid point.</source>
          <target state="translated">该网格点的估计器上要设置的参数。</target>
        </trans-unit>
        <trans-unit id="191e3e986e6964fefdb746bdbd32d026ac54732c" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method of the estimator.</source>
          <target state="translated">传递给估计器拟合方法的参数。</target>
        </trans-unit>
        <trans-unit id="80e379dd51d34ce2dbedd57a975596631a95d883" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method.</source>
          <target state="translated">要传递给拟合方法的参数。</target>
        </trans-unit>
        <trans-unit id="36ccb38b123600d9fbc78ab0cd9b6b307a008e1c" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called at the end of all transformations in the pipeline. Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.</source>
          <target state="translated">在管道中所有转换结束时调用的 &lt;code&gt;predict&lt;/code&gt; 参数。请注意，虽然这可以用于从具有return_std或return_cov的某些模型返回不确定性，但是由管道中的转换生成的不确定性不会传播到最终估计器。</target>
        </trans-unit>
        <trans-unit id="b3a7c9dd881e64a7f41aafeb58e4f8bfcc6a5b4f" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called by the &lt;code&gt;final_estimator&lt;/code&gt;. Note that this may be used to return uncertainties from some estimators with &lt;code&gt;return_std&lt;/code&gt; or &lt;code&gt;return_cov&lt;/code&gt;. Be aware that it will only accounts for uncertainty in the final estimator.</source>
          <target state="translated">由 &lt;code&gt;final_estimator&lt;/code&gt; 调用的 &lt;code&gt;predict&lt;/code&gt; 参数。请注意，这可以用于返回带有 &lt;code&gt;return_std&lt;/code&gt; 或 &lt;code&gt;return_cov&lt;/code&gt; 的某些估计量的不确定性。请注意，这只会考虑最终估算器中的不确定性。</target>
        </trans-unit>
        <trans-unit id="381c775599d6e4185d4410725809e360928357cd" translate="yes" xml:space="preserve">
          <source>Parameters:</source>
          <target state="translated">Parameters:</target>
        </trans-unit>
        <trans-unit id="99be92c9a2dedb3674880d6acb8f2dcdcbd96ff3" translate="yes" xml:space="preserve">
          <source>Parsing a text based source can be expensive. When working on repeatedly on the same dataset, it is recommended to wrap this loader with joblib.Memory.cache to store a memmapped backup of the CSR results of the first call and benefit from the near instantaneous loading of memmapped structures for the subsequent calls.</source>
          <target state="translated">解析一个基于文本的源可能是昂贵的。当重复处理同一数据集时,建议用joblib.Memory.cache来封装这个加载器,以存储第一次调用的CSR结果的memmapped备份,并从后续调用的memmapped结构近乎瞬时的加载中获益。</target>
        </trans-unit>
        <trans-unit id="9dffe51138babd8f1ead215ce660a1e946197066" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plot (PDP) visualization.</source>
          <target state="translated">部分依赖图(PDP)可视化。</target>
        </trans-unit>
        <trans-unit id="f8d5f258416422c57466cd67cc8a02c6b05a80fd" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plots</source>
          <target state="translated">部分依赖性图</target>
        </trans-unit>
        <trans-unit id="07df4cbd5294e07465f804b7c9b36c5d5a43e82b" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for Gradient Boosting</source>
          <target state="translated">梯度提升的部分依赖性计算方法</target>
        </trans-unit>
        <trans-unit id="b282664cc1d0ff2c6d0b320162703f3341719289" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for multi-layer perceptron</source>
          <target state="translated">多层感知器的部分依赖性计算方法</target>
        </trans-unit>
        <trans-unit id="e9c89f964f1a01a36b42f3fe4848b74ccc63e0e6" translate="yes" xml:space="preserve">
          <source>Partial Least Square SVD</source>
          <target state="translated">部分最小平方SVD</target>
        </trans-unit>
        <trans-unit id="0af696b5fd6af6b13c25a86aed283f8f2b249126" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">部分依赖 &lt;code&gt;features&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="93cbd804a6e8e51bf70182f90134157ea23f1138" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;target_variables&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;target_variables&lt;/code&gt; 的部分依赖。</target>
        </trans-unit>
        <trans-unit id="abf44f40a8ead68e3c71b46bec075211dc75d783" translate="yes" xml:space="preserve">
          <source>Partial dependence of a feature (or a set of features) corresponds to the average response of an estimator for each possible value of the feature.</source>
          <target state="translated">一个特征(或一组特征)的部分依赖性对应于估计器对特征的每个可能值的平均响应。</target>
        </trans-unit>
        <trans-unit id="c99d4545385034142f3b81de241245acbbd2acd6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response as a function of the &amp;lsquo;target&amp;rsquo; features.</source>
          <target state="translated">部分依赖图（PDP）显示了目标响应&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;和一组&amp;ldquo;目标&amp;rdquo;特征之间的依赖关系，在所有其他特征（&amp;ldquo;互补&amp;rdquo;特征）的值上处于边际位置。直观地，我们可以将部分依赖关系解释为预期目标响应与&amp;ldquo;目标&amp;rdquo;特征的函数。</target>
        </trans-unit>
        <trans-unit id="8a65d01c56b56d7e6904a157392f75eb71dc3b44" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; as a function of the &amp;lsquo;target&amp;rsquo; features &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;.</source>
          <target state="translated">部分依赖图（PDP）显示了目标响应与一组&amp;ldquo;目标&amp;rdquo;特征之间的依赖关系，使所有其他特征（&amp;ldquo;互补&amp;rdquo;特征）的值处于边际位置。直观地，我们可以将部分依赖关系解释为预期目标响应&lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt;作为&amp;ldquo;目标&amp;rdquo;特征&lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;的函数。</target>
        </trans-unit>
        <trans-unit id="9fe71a24f95abe640c27c0bbf2214ad816fa5b2e" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">部分依赖地块的 &lt;code&gt;features&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="652e656223f58b0f5fc37309adb1b1ac47d155cf" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for tree ensembles.</source>
          <target state="translated">树形集合的部分依赖性图。</target>
        </trans-unit>
        <trans-unit id="c1a7be74107eb23fd9bfcd8698a88bc718aa4772" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the joint values of the &lt;code&gt;target_variables&lt;/code&gt; and the function represented by the &lt;code&gt;gbrt&lt;/code&gt;.</source>
          <target state="translated">部分依赖图显示了 &lt;code&gt;target_variables&lt;/code&gt; 的联合值与 &lt;code&gt;gbrt&lt;/code&gt; 表示的函数之间的依赖关系。</target>
        </trans-unit>
        <trans-unit id="fc1161112f98108492921350df0f600984c6b3b0" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;2&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception, the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features.</source>
          <target state="translated">部分依赖图显示了目标函数&lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;2&lt;/a&gt;与一组&amp;ldquo;目标&amp;rdquo;特征之间的依赖关系，使所有其他特征（补码特征）的值处于边际位置。由于人类感知的局限性，目标特征集的大小必须很小（通常是一两个），因此通常在最重要的特征中选择目标特征。</target>
        </trans-unit>
        <trans-unit id="04afc172d4359535322f4eeb08a601341437662b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features (see &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt;&lt;code&gt;feature_importances_&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">局部依赖性图显示了目标函数&lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;与一组&amp;ldquo;目标&amp;rdquo;特征之间的依赖性，从而边缘化了所有其他特征（互补特征）的值。由于人类感知的限制，目标特征集的大小必须很小（通常是一两个），因此通常在最重要的特征中选择目标特征（请参阅&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt; &lt;code&gt;feature_importances_&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="a4a9c59e85db7b4787e5c0d6935be7408b0e1749" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">具有两个目标特征的部分依赖图使我们能够直观地看到它们之间的相互作用。双向部分依赖图显示了房价中位数对房龄和每户平均居住人数联合值的依赖性。我们可以清楚地看到这两个特征之间的相互作用:对于平均入住率大于2的情况,房价几乎与房龄无关,而对于小于2的数值,则对房龄有很强的依赖性。</target>
        </trans-unit>
        <trans-unit id="27028d4e93727066aec3e2e83aa74954e7719a8b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">具有两个目标特征的部分依赖图使我们能够直观地看到它们之间的相互作用。双向部分依赖图显示了房价中位数对房龄和每户平均居住人数联合值的依赖性。我们可以清楚地看到这两个特征之间的相互作用。对于平均居住人数大于2人的家庭,房价几乎与房龄无关,而对于小于2人的家庭,则对房龄有很大的依赖性。</target>
        </trans-unit>
        <trans-unit id="b6af299fa9b94db48e98129e260b1eeb813719a6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots.</source>
          <target state="translated">部分依赖图。</target>
        </trans-unit>
        <trans-unit id="6e99bc5cb78022b1555bc70fa32795dba1ae5f4f" translate="yes" xml:space="preserve">
          <source>Partially fit underlying estimators</source>
          <target state="translated">部分拟合基本估算器</target>
        </trans-unit>
        <trans-unit id="0a5bfb5dfddbf187589aac0e6c6f726ea3a56e0f" translate="yes" xml:space="preserve">
          <source>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</source>
          <target state="translated">特别是在高维空间中,数据更容易被线性分离,而天真贝叶斯和线性SVM等分类器的简单性可能会带来比其他分类器更好的泛化效果。</target>
        </trans-unit>
        <trans-unit id="ee5c2f652fa0ba7331b6add7547b0b3f663aedd3" translate="yes" xml:space="preserve">
          <source>Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure.</source>
          <target state="translated">在假设数据具有基本棋盘结构的前提下,对行和列进行分区。例如,如果有两个行分区和三个列分区,那么每行将属于三个双簇,每列将属于两个双簇。对应的行、列标签向量的外积就可以得到这个棋盘结构。</target>
        </trans-unit>
        <trans-unit id="364b4c71a5c83a360f4fe86b4c60a48d2e33f726" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible output for permutation of &lt;code&gt;y&lt;/code&gt; values among samples. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">传递一个int以获得可重复的输出，以在样本之间对 &lt;code&gt;y&lt;/code&gt; 值进行排列。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="fa828ddb159ddfa77238aad6f870c00db1af477d" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">在多个函数调用之间传递int以获得可重现的结果。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d9f564dc265e98a01f24f70d1576b62ca3b43bd3" translate="yes" xml:space="preserve">
          <source>Passing a 2D matrix for multilabel classification</source>
          <target state="translated">为多标签分类传递二维矩阵。</target>
        </trans-unit>
        <trans-unit id="cd2bb1a7aa8efcc1bd63306134f3100f91fc6ef3" translate="yes" xml:space="preserve">
          <source>Passing these predictions into an evaluation metric may not be a valid way to measure generalization performance. Results can differ from &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; unless all tests sets have equal size and the metric decomposes over samples.</source>
          <target state="translated">将这些预测传递到评估指标中可能不是衡量泛化性能的有效方法。结果可能与&lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt; &lt;code&gt;cross_validate&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt;不同，除非所有测试集的大小均相等，并且度量对样本进行分解。</target>
        </trans-unit>
        <trans-unit id="144adab066cd5c92a6778f61a4778ef74c72b2a0" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Classifier</source>
          <target state="translated">被动攻击型分类器</target>
        </trans-unit>
        <trans-unit id="d61635eec17c853d9d6e1ff234afe50660f92701" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Regressor</source>
          <target state="translated">被动进攻型调节器</target>
        </trans-unit>
        <trans-unit id="291afa1da61effaacff4bf3e40a8045b9b8d343b" translate="yes" xml:space="preserve">
          <source>Patches are assumed to overlap and the image is constructed by filling in the patches from left to right, top to bottom, averaging the overlapping regions.</source>
          <target state="translated">假设斑点重叠,通过从左到右、从上到下填充斑点,对重叠区域进行平均,构建图像。</target>
        </trans-unit>
        <trans-unit id="18a1699e2836ba2addd008ee2015c4e0ca5931f6" translate="yes" xml:space="preserve">
          <source>Path to the main folder holding one subfolder per category</source>
          <target state="translated">通往主文件夹的路径,每个类别有一个子文件夹。</target>
        </trans-unit>
        <trans-unit id="98ee95181d901b366d1fe1c0df5a309cc7a3de65" translate="yes" xml:space="preserve">
          <source>Penalization parameter selected.</source>
          <target state="translated">选择处罚参数。</target>
        </trans-unit>
        <trans-unit id="269c93d9d03f37f0d0341535ce102e3bd06fa60f" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad)</source>
          <target state="translated">处罚拦截(不良)</target>
        </trans-unit>
        <trans-unit id="3bbf431b41c522bd1eb1b65ea50fc21584275d87" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad) yes no no no no Faster for large datasets no no no yes yes Robust to unscaled datasets yes yes yes no no ============================ =========== ======= =========== ===== ======</source>
          <target state="translated">惩罚拦截(坏)是 否 否 否 否 对大型数据集更快 否 否 否 是 是 是 对未缩放的数据集有鲁棒性 是 是 是 否 ====================================================================。</target>
        </trans-unit>
        <trans-unit id="64a00002571bc14aac9e57cf087ec95ea0663632" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term.</source>
          <target state="translated">误差项的惩罚参数C。</target>
        </trans-unit>
        <trans-unit id="78e16aaecb446c766536c888cb2ab681d45d227a" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term. The penalty is a squared l2 penalty. The bigger this parameter, the less regularization is used.</source>
          <target state="translated">误差项的惩罚参数C。该惩罚是l2个惩罚的平方。该参数越大,正则化的使用越少。</target>
        </trans-unit>
        <trans-unit id="92dc577567bc10903722a0cd6bc84fd8cb538ac8" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BFGS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">默认情况下，使用scipy.optimize.minimize中的&amp;ldquo; L-BFGS-B&amp;rdquo;算法。如果未传递任何参数，则内核的参数将保持不变。可用的内部优化器包括：</target>
        </trans-unit>
        <trans-unit id="36c27027dd1d6e2db082fc2d8518ad5ddec8cac4" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BGFS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">默认情况下，使用scipy.optimize.minimize中的&amp;ldquo; L-BGFS-B&amp;rdquo;算法。如果未传递任何参数，则内核的参数将保持不变。可用的内部优化器包括：</target>
        </trans-unit>
        <trans-unit id="f4b4203fc28ce6d3a674721e39c00d5f8047107a" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;fmin_l_bfgs_b&amp;rsquo; algorithm from scipy.optimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">默认情况下，使用scipy.optimize中的&amp;ldquo; fmin_l_bfgs_b&amp;rdquo;算法。如果未传递任何参数，则内核参数保持固定。可用的内部优化器包括：</target>
        </trans-unit>
        <trans-unit id="6244b7856d25c3c666d36fccf077f85fa1982ad7" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum.</source>
          <target state="translated">每功能调整为最小。</target>
        </trans-unit>
        <trans-unit id="3b00bbffe150e7b8c58881b0f3768ad4c9012a12" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum. Equivalent to &lt;code&gt;min - X.min(axis=0) * self.scale_&lt;/code&gt;</source>
          <target state="translated">每个功能调整的最小值。等效于 &lt;code&gt;min - X.min(axis=0) * self.scale_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d1fcc9536b36965b70f539451057ec6f4f433503" translate="yes" xml:space="preserve">
          <source>Per feature maximum absolute value.</source>
          <target state="translated">每个特征最大绝对值。</target>
        </trans-unit>
        <trans-unit id="c5e7199d590adbeaea5c7d5a6fd8bd4755090a1c" translate="yes" xml:space="preserve">
          <source>Per feature maximum seen in the data</source>
          <target state="translated">数据中看到的每个特征最大值</target>
        </trans-unit>
        <trans-unit id="102581d144872704eb291cec69ea6b75f7b2f4ae" translate="yes" xml:space="preserve">
          <source>Per feature minimum seen in the data</source>
          <target state="translated">在数据中看到的每个特征最小值</target>
        </trans-unit>
        <trans-unit id="9af0de5bb3d05f02ad6ecd6ef96e244722359bc9" translate="yes" xml:space="preserve">
          <source>Per feature range &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt; seen in the data</source>
          <target state="translated">数据中看到的每个要素范围 &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3041c95c2bc4cf499751cc15dcfa6079b79d0c01" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data.</source>
          <target state="translated">每个特征数据的相对比例。</target>
        </trans-unit>
        <trans-unit id="2aca96873ba30a1f44a2ea13c9cca023c862496e" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">每个要素的数据相对缩放。当 &lt;code&gt;with_std=False&lt;/code&gt; 时等于 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="add1f6f8b0508a85231ee2c9d67b3d85e4b4574a" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equivalent to &lt;code&gt;(max - min) / (X.max(axis=0) - X.min(axis=0))&lt;/code&gt;</source>
          <target state="translated">每个要素的数据相对缩放比例。等效于 &lt;code&gt;(max - min) / (X.max(axis=0) - X.min(axis=0))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1f0850ba910ca1120662899ac545a63448e94c53" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. This is calculated using &lt;code&gt;np.sqrt(var_)&lt;/code&gt;. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">每个要素的数据相对缩放比例。这是使用 &lt;code&gt;np.sqrt(var_)&lt;/code&gt; 计算的。当 &lt;code&gt;with_std=False&lt;/code&gt; 时等于 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="03c5a380bfcbdfa271df31ac8e5033140b3c462f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">按功能的经验均值汇总在对 &lt;code&gt;partial_fit&lt;/code&gt; 的调用上。</target>
        </trans-unit>
        <trans-unit id="9b69855eee3f3bb7b79cdf586195cf71da93449f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set.</source>
          <target state="translated">每个特征的经验平均值,由训练集估计。</target>
        </trans-unit>
        <trans-unit id="78b2f336c949583f3bdffdc9a030b0f9e6170c47" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set. Equal to &lt;code&gt;X.mean(axis=0)&lt;/code&gt;.</source>
          <target state="translated">根据训练集估算的每特征经验均值。等于 &lt;code&gt;X.mean(axis=0)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a8c85c36120ad4d7e0ffc8553bf9d9bb4f653d40" translate="yes" xml:space="preserve">
          <source>Per-feature empirical variance, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">每个功能的经验方差，通过对 &lt;code&gt;partial_fit&lt;/code&gt; 的调用进行汇总。</target>
        </trans-unit>
        <trans-unit id="bb6e9ff3187e622eed5823426c5d8cc8b9a5e66d" translate="yes" xml:space="preserve">
          <source>Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</source>
          <target state="translated">每个样本的权重。重新调整每个样本的C。较高的权重迫使分类器更加重视这些点。</target>
        </trans-unit>
        <trans-unit id="022818083764d59bc1c545a8df2dfc49cf87ec2a" translate="yes" xml:space="preserve">
          <source>Per-topic word distributions are independently drawn, where in reality all would be affected by a sparse base distribution, and would be correlated.</source>
          <target state="translated">每题词分布都是独立绘制的,在现实中都会受到稀疏基数分布的影响,会有相关性。</target>
        </trans-unit>
        <trans-unit id="508100893e29e053d40024965b139e71658b7b80" translate="yes" xml:space="preserve">
          <source>Percent of features to keep.</source>
          <target state="translated">保留功能的百分比。</target>
        </trans-unit>
        <trans-unit id="510c90c1028713db83438ed3b7d7b97622c046bb" translate="yes" xml:space="preserve">
          <source>Percentage of the number of classes to be used to create the code book. A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. A number greater than 1 will require more classifiers than one-vs-the-rest.</source>
          <target state="translated">用于创建代码簿的类数的百分比。在0和1之间的数字将需要比一个对其余的分类器更少的分类器。大于1的数字将需要更多的分类器,而不是一个对其余的分类器。</target>
        </trans-unit>
        <trans-unit id="ab474311418f716aa90a18ba4aac10d5e0126b01" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components.</source>
          <target state="translated">每个选定的组成部分所解释的方差百分比。</target>
        </trans-unit>
        <trans-unit id="6b606c4b3521608268acaf8a83daf1d705edec66" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.</source>
          <target state="translated">每个选定组件解释的方差百分比。如果未设置 &lt;code&gt;n_components&lt;/code&gt; ,则将存储所有分量，并且解释的方差之和等于1.0。仅在使用特征或svd解算器时可用。</target>
        </trans-unit>
        <trans-unit id="d93d3d6b53ae20e2e020e6bfd5f07bc4328ff552" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0.</source>
          <target state="translated">每个选定的成分所解释的方差百分比。如果所有成分都被储存,则解释的方差之和等于1.0。</target>
        </trans-unit>
        <trans-unit id="b76d05a7855a1137343582656ace6f381d34c7bd" translate="yes" xml:space="preserve">
          <source>Perceptron: \(L(y_i, f(x_i)) = \max(0, - y_i f(x_i))\).</source>
          <target state="translated">Perceptron:\(L(y_i,f(x_i))=max(0,-y_i f(x_i))/)。</target>
        </trans-unit>
        <trans-unit id="5ae537dc31ff6e276137ba1f3f08f14e2d75b135" translate="yes" xml:space="preserve">
          <source>Perfect labeling is scored 1.0:</source>
          <target state="translated">完美标注得1.0分。</target>
        </trans-unit>
        <trans-unit id="e0246cf8e59488c8ec6f2dd495c80e88ab5e2c38" translate="yes" xml:space="preserve">
          <source>Perfect labelings are both homogeneous and complete, hence have score 1.0:</source>
          <target state="translated">完美的标签既是同质的又是完整的,因此得分为1.0。</target>
        </trans-unit>
        <trans-unit id="0b6e6a15e84a2c0c2b67bd408293381d6bde8086" translate="yes" xml:space="preserve">
          <source>Perfect labelings are complete:</source>
          <target state="translated">完美的标签是完整的。</target>
        </trans-unit>
        <trans-unit id="c929d898b15ba46b39cbe3a578cc048974dbb0f3" translate="yes" xml:space="preserve">
          <source>Perfect labelings are homogeneous:</source>
          <target state="translated">完美的标签是同质的。</target>
        </trans-unit>
        <trans-unit id="158762f0fcedf70ff27743eef2b9fe2391aaecf5" translate="yes" xml:space="preserve">
          <source>Perfectly matching labelings have a score of 1 even</source>
          <target state="translated">完全匹配的标签得1分,甚至是1分</target>
        </trans-unit>
        <trans-unit id="689d4751e15d0ca03ac4490cb60697622e5a7435" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data</source>
          <target state="translated">对数据进行亲和传播聚类。</target>
        </trans-unit>
        <trans-unit id="dee861689c2a0a2296c4bb43119e58f854cfe756" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data.</source>
          <target state="translated">对数据进行亲和传播聚类。</target>
        </trans-unit>
        <trans-unit id="5a1975729819b04264272cf944b37eeff6c54bb5" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix, and return cluster labels.</source>
          <target state="translated">根据特征或距离矩阵进行DBSCAN聚类,并返回聚类标签。</target>
        </trans-unit>
        <trans-unit id="463c2804b4b2c3d108889b17acd479af4436cc72" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix.</source>
          <target state="translated">根据特征或距离矩阵进行DBSCAN聚类。</target>
        </trans-unit>
        <trans-unit id="b65b6612279cd3a62fed32683d01c69787a97da2" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features, or distance matrix.</source>
          <target state="translated">根据特征或距离矩阵进行DBSCAN聚类。</target>
        </trans-unit>
        <trans-unit id="458d7c0c2b90dff326f89ad767c75f6a1812b730" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from vector array or distance matrix.</source>
          <target state="translated">从向量数组或距离矩阵执行DBSCAN聚类。</target>
        </trans-unit>
        <trans-unit id="959d910f7763a2ffdb63e2da58508fc0266c6120" translate="yes" xml:space="preserve">
          <source>Perform Fast Independent Component Analysis.</source>
          <target state="translated">进行快速独立成分分析。</target>
        </trans-unit>
        <trans-unit id="c424661559fd4111ae395a81a440da23c2d8b00f" translate="yes" xml:space="preserve">
          <source>Perform OPTICS clustering.</source>
          <target state="translated">进行OPTICS聚类。</target>
        </trans-unit>
        <trans-unit id="b44047366aaa6bbf25bda0720c2b9955136f4c83" translate="yes" xml:space="preserve">
          <source>Perform a Locally Linear Embedding analysis on the data.</source>
          <target state="translated">对数据进行局部线性嵌入分析。</target>
        </trans-unit>
        <trans-unit id="ac1255795fd03e9f556426224dcbfbd70ca25e88" translate="yes" xml:space="preserve">
          <source>Perform a shortest-path graph search on a positive directed or undirected graph.</source>
          <target state="translated">在正向或无向图上进行最短路径图搜索。</target>
        </trans-unit>
        <trans-unit id="5913acb65bcb3cfc0407c274e6a0ae6c08f54988" translate="yes" xml:space="preserve">
          <source>Perform binary classification using non-linear SVC with RBF kernel. The target to predict is a XOR of the inputs.</source>
          <target state="translated">使用非线性SVC与RBF内核进行二元分类。要预测的目标是输入的XOR。</target>
        </trans-unit>
        <trans-unit id="a259ca5c38306ae844a312467fcf634f7a4c4cb8" translate="yes" xml:space="preserve">
          <source>Perform classification on an array of test vectors X.</source>
          <target state="translated">对测试向量数组X进行分类。</target>
        </trans-unit>
        <trans-unit id="1af0f015c949bd1c16d805fdf5523bbcd5119678" translate="yes" xml:space="preserve">
          <source>Perform classification on samples in X.</source>
          <target state="translated">对X中的样本进行分类。</target>
        </trans-unit>
        <trans-unit id="b3b3f491b55f8b579a228793b65f99ca8d0d1a92" translate="yes" xml:space="preserve">
          <source>Perform classification on test vectors X.</source>
          <target state="translated">对测试向量X进行分类。</target>
        </trans-unit>
        <trans-unit id="2cc5f65a2c2c90fbeebd06f8fc6c4b4510abcc97" translate="yes" xml:space="preserve">
          <source>Perform clustering on X and returns cluster labels.</source>
          <target state="translated">对X进行聚类,并返回聚类标签。</target>
        </trans-unit>
        <trans-unit id="db94ca6613eef6e933177aeabe20672ae9208bdf" translate="yes" xml:space="preserve">
          <source>Perform clustering.</source>
          <target state="translated">进行聚类。</target>
        </trans-unit>
        <trans-unit id="f9f7c30d76f5b933404ebf4eb86819fed33be90a" translate="yes" xml:space="preserve">
          <source>Perform dimensionality reduction on X.</source>
          <target state="translated">对X进行降维。</target>
        </trans-unit>
        <trans-unit id="ea3d4bd6b3c1842187bced8b218fbec04eb7bd42" translate="yes" xml:space="preserve">
          <source>Perform fit on X and returns labels for X.</source>
          <target state="translated">对X进行拟合,并返回X的标签。</target>
        </trans-unit>
        <trans-unit id="6d24d9dcbe2141c7b30ceff371628950cd7ca425" translate="yes" xml:space="preserve">
          <source>Perform is_fitted validation for estimator.</source>
          <target state="translated">对估计器进行is_fitted验证。</target>
        </trans-unit>
        <trans-unit id="28c6ac8c77fceae308f63cb91c2fe135b4f5904f" translate="yes" xml:space="preserve">
          <source>Perform mapping to a normal distribution using a power transform.</source>
          <target state="translated">使用功率变换执行映射到正态分布。</target>
        </trans-unit>
        <trans-unit id="f154e55e13cfe215c964ae2fb4c3f06da46b83fe" translate="yes" xml:space="preserve">
          <source>Perform mean shift clustering of data using a flat kernel.</source>
          <target state="translated">使用平核对数据进行均值移动聚类。</target>
        </trans-unit>
        <trans-unit id="5d74999037a10ebb61d14a38ac3c1f58c8d3eb1c" translate="yes" xml:space="preserve">
          <source>Perform one Gibbs sampling step.</source>
          <target state="translated">执行一个吉布斯采样步骤。</target>
        </trans-unit>
        <trans-unit id="a608c191f0cb8597865dd893c202fb7da2ab975c" translate="yes" xml:space="preserve">
          <source>Perform one epoch of stochastic gradient descent on given samples.</source>
          <target state="translated">对给定的样本进行一次随机梯度下降。</target>
        </trans-unit>
        <trans-unit id="b97c414705aa3f4f9199ddb08da830ac54e8fe97" translate="yes" xml:space="preserve">
          <source>Perform regression on samples in X.</source>
          <target state="translated">对X中的样本进行回归。</target>
        </trans-unit>
        <trans-unit id="dd51e0250263d470cb8a4effc410185e24e99d6f" translate="yes" xml:space="preserve">
          <source>Perform robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">进行稳健的标准化,消除离群值的影响,但不把离群值和离群值放在同一尺度上。</target>
        </trans-unit>
        <trans-unit id="1506956d6558b19c7df6e1dc69b0a99dea667d55" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix, and return cluster labels.</source>
          <target state="translated">根据特征或亲和矩阵进行光谱聚类,并返回聚类标签。</target>
        </trans-unit>
        <trans-unit id="557e6799397c88d4bc14664b365f9609412e8548" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix.</source>
          <target state="translated">根据特征或亲和矩阵进行光谱聚类。</target>
        </trans-unit>
        <trans-unit id="ebef79dfac2e65b8c25ad9bb7fdce83cd9513504" translate="yes" xml:space="preserve">
          <source>Perform standardization by centering and scaling</source>
          <target state="translated">通过居中和缩放进行标准化</target>
        </trans-unit>
        <trans-unit id="4bc7fa7479a101fbc87b729f92b16086a341ed9e" translate="yes" xml:space="preserve">
          <source>Perform standardization that is faster, but less robust to outliers.</source>
          <target state="translated">执行标准化,速度更快,但对异常值的鲁棒性较差。</target>
        </trans-unit>
        <trans-unit id="3c9e3951bcb75f5ea77167c7144b5b5a81bd6690" translate="yes" xml:space="preserve">
          <source>Performs DBSCAN extraction for an arbitrary epsilon.</source>
          <target state="translated">对一个任意的epsilon执行DBSCAN提取。</target>
        </trans-unit>
        <trans-unit id="b688f62a3ad12b1d7c84b19ede9050b44271064d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of categorical features.</source>
          <target state="translated">对分类特征进行一键编码。</target>
        </trans-unit>
        <trans-unit id="8d75208cdd518398a274b5c66a99a07cd1c4674d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of dictionary items (also handles string-valued features).</source>
          <target state="translated">对字典项进行一次性编码(也处理字符串值的特征)。</target>
        </trans-unit>
        <trans-unit id="c8a1451466ddb25587dffc5d4da05875ebb74725" translate="yes" xml:space="preserve">
          <source>Performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.</source>
          <target state="translated">对夏宫(中国)图像进行像素向量量化(VQ),在保持整体外观质量的前提下,将显示图像所需的颜色数量从96,615种独特颜色减少到64种。</target>
        </trans-unit>
        <trans-unit id="b9ac5dd9fc2e45481e3dd5c8a6199a86e1da0656" translate="yes" xml:space="preserve">
          <source>Performs an approximate one-hot encoding of dictionary items or strings.</source>
          <target state="translated">对字典项或字符串进行近似的一键编码。</target>
        </trans-unit>
        <trans-unit id="d01f1a997cf8a75714d83a10021fc81a3a7d1f94" translate="yes" xml:space="preserve">
          <source>Performs an ordinal (integer) encoding of the categorical features.</source>
          <target state="translated">执行分类特征的序数(整数)编码。</target>
        </trans-unit>
        <trans-unit id="7945877a79ee9606b9df91e80330316ac1099e28" translate="yes" xml:space="preserve">
          <source>Performs approximate nearest neighbor search using LSH forest.</source>
          <target state="translated">使用LSH森林进行近似近邻搜索。</target>
        </trans-unit>
        <trans-unit id="9bab7093aa44c52b527bcacee82e15ab827f7949" translate="yes" xml:space="preserve">
          <source>Performs binarization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行二进制化。</target>
        </trans-unit>
        <trans-unit id="9334db1899f0bba94453f1ee6fbd171b507e5ed1" translate="yes" xml:space="preserve">
          <source>Performs centering and scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行居中和缩放。</target>
        </trans-unit>
        <trans-unit id="506256c7ae18c8053ecaa6445590a98acf36aa0e" translate="yes" xml:space="preserve">
          <source>Performs clustering on X and returns cluster labels.</source>
          <target state="translated">对X进行聚类并返回聚类标签。</target>
        </trans-unit>
        <trans-unit id="38545772bd4529f41bf4bec322ebc7f80ab61f41" translate="yes" xml:space="preserve">
          <source>Performs inductive inference across the model.</source>
          <target state="translated">对整个模型进行归纳推理。</target>
        </trans-unit>
        <trans-unit id="de7dc9fb5a771d54ea7fadc4d86dd2f8269f14e4" translate="yes" xml:space="preserve">
          <source>Performs normalization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API 执行规范化（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）。</target>
        </trans-unit>
        <trans-unit id="72f57dd0021b24f09da3fde633d42235df9baa52" translate="yes" xml:space="preserve">
          <source>Performs outlier detection on X.</source>
          <target state="translated">对X进行异常值检测。</target>
        </trans-unit>
        <trans-unit id="c032681b9d32a5a7daa554f673be122edd3ede2b" translate="yes" xml:space="preserve">
          <source>Performs power transformation using the &lt;code&gt;Transformer&lt;/code&gt; API (as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API（作为&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;预处理的一部分）执行电源转换。</target>
        </trans-unit>
        <trans-unit id="9b0d235575d753630f72f479dd595fb051616b74" translate="yes" xml:space="preserve">
          <source>Performs quantile-based scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API 执行基于分位数的缩放（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）。</target>
        </trans-unit>
        <trans-unit id="b88ebf81bb1a4e07e575709aa3160fcbaf33439c" translate="yes" xml:space="preserve">
          <source>Performs robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">进行稳健的标准化,消除离群值的影响,但不把离群值和离群值放在同一尺度上。</target>
        </trans-unit>
        <trans-unit id="269796266e3e34d93d181d30bdc48e574f3c9af7" translate="yes" xml:space="preserve">
          <source>Performs scaling to a given range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用&amp;ldquo; Transformer&amp;rdquo; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行缩放到给定范围的缩放。</target>
        </trans-unit>
        <trans-unit id="bd68fa80cce73218da8c0d7af21a3e3a79fd9429" translate="yes" xml:space="preserve">
          <source>Performs scaling to the [-1, 1] range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用Transformer API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分），将比例缩放到[-1，1]范围。</target>
        </trans-unit>
        <trans-unit id="a6c272533c048656769d2922baf310f99127bfa0" translate="yes" xml:space="preserve">
          <source>Performs scaling to unit variance using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用&amp;ldquo; Transformer&amp;rdquo; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行缩放至单位方差。</target>
        </trans-unit>
        <trans-unit id="ac7c14a68907c3e1c4fe02a23cc6348fd68ae158" translate="yes" xml:space="preserve">
          <source>Performs standardization that is faster, but less robust to outliers.</source>
          <target state="translated">执行标准化,速度更快,但对异常值的鲁棒性较差。</target>
        </trans-unit>
        <trans-unit id="1607c75c65b63f50e007f7f133bc5dda8dc230b2" translate="yes" xml:space="preserve">
          <source>Performs the TF-IDF transformation from a provided matrix of counts.</source>
          <target state="translated">从提供的计数矩阵中执行TF-IDF转换。</target>
        </trans-unit>
        <trans-unit id="d1ac21bb0cdcd78e01860cf682da905f50be135c" translate="yes" xml:space="preserve">
          <source>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</source>
          <target state="translated">即使它的假设在一定程度上被生成数据的真实模型所违反,也表现良好。</target>
        </trans-unit>
        <trans-unit id="692363e79545ccc206eddd0f61af20f5fd6d3794" translate="yes" xml:space="preserve">
          <source>Permutation Importance vs Random Forest Feature Importance (MDI)</source>
          <target state="translated">模数重要性与随机森林特征重要性(MDI)的比较</target>
        </trans-unit>
        <trans-unit id="2dbaba5e5cc669da918a57d2be9cb7dc2cc9dadb" translate="yes" xml:space="preserve">
          <source>Permutation Importance with Multicollinear or Correlated Features</source>
          <target state="translated">多线性或相关特征的换位重要性</target>
        </trans-unit>
        <trans-unit id="9a4bc8d95c0343a8677dd56e966704c1868adf4a" translate="yes" xml:space="preserve">
          <source>Permutation feature importance is a model inspection technique that can be used for any &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fitted&quot;&gt;fitted&lt;/a&gt;&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;estimator&lt;/a&gt; when the data is tabular. This is especially useful for non-linear or opaque &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;estimators&lt;/a&gt;. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature.</source>
          <target state="translated">置换特征重要性是一种模型检查技术，当数据为表格形式时，可用于任何&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fitted&quot;&gt;拟合的&lt;/a&gt;&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;估计量&lt;/a&gt;。这对于非线性或不透明的&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;估计器&lt;/a&gt;特别有用。排列特征的重要性定义为当单个特征值随机混洗&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;时模型得分的降低。此过程破坏了特征与目标之间的关系，因此模型得分的下降表示模型对特征的依赖程度。该技术受益于模型不可知，并且可以使用特征的不同排列进行多次计算。</target>
        </trans-unit>
        <trans-unit id="3fc1a156ae6d2a8be8ad1b31632c3738303816a9" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;#rd9e56ef97513-bre&quot; id=&quot;id1&quot;&gt;[BRE]&lt;/a&gt;.</source>
          <target state="translated">置换对特征评估的重要性&lt;a href=&quot;#rd9e56ef97513-bre&quot; id=&quot;id1&quot;&gt;[BRE]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="dcae56d3241bbe2509401411f131fd455126611a" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#rd9e56ef97513-bre&quot; id=&quot;id2&quot;&gt;[Rd9e56ef97513-BRE]&lt;/a&gt;.</source>
          <target state="translated">置换对特征评估的重要性&lt;a href=&quot;generated/sklearn.inspection.permutation_importance#rd9e56ef97513-bre&quot; id=&quot;id2&quot;&gt;[Rd9e56ef97513-BRE]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0604878bcce5e380bc3c27303af860b5876e2620" translate="yes" xml:space="preserve">
          <source>Permutation importances can be computed either on the training set or on a held-out testing or validation set. Using a held-out set makes it possible to highlight which features contribute the most to the generalization power of the inspected model. Features that are important on the training set but not on the held-out set might cause the model to overfit.</source>
          <target state="translated">替换进口量可以在训练集上计算,也可以在保留下来的测试或验证集上计算。使用保留出来的集合可以突出哪些特征对检验模型的泛化能力贡献最大。在训练集上很重要的特征,但在暂缓测试集上不重要的特征可能会导致模型过拟合。</target>
        </trans-unit>
        <trans-unit id="ff7711423fb41bb0ca16132a11855fff8a63fa44" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importance</source>
          <target state="translated">基于排列组合的特征重要性</target>
        </trans-unit>
        <trans-unit id="2babb881bd9df0cbbe32387aebb8f1fc14de7576" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importances do not exhibit such a bias. Additionally, the permutation feature importance may be computed performance metric on the model predictions predictions and can be used to analyze any model class (not just tree-based models).</source>
          <target state="translated">基于换元的特征导入率不会表现出这样的偏差。此外,排列特征重要性可以计算模型预测预报的性能指标,可以用来分析任何模型类(不仅仅是树型模型)。</target>
        </trans-unit>
        <trans-unit id="1a9a31609b061b9c4c3ea5164d451f2cf664e34b" translate="yes" xml:space="preserve">
          <source>Perplexity is defined as exp(-1. * log-likelihood per word)</source>
          <target state="translated">迷惑性定义为exp(-1.*每个词的对数可能性)</target>
        </trans-unit>
        <trans-unit id="80863d8aea17a1c5fba5bee33e10fcfe3c3b5254" translate="yes" xml:space="preserve">
          <source>Perplexity score.</source>
          <target state="translated">困惑的分数。</target>
        </trans-unit>
        <trans-unit id="25e7450397b385690390d4cb490d54af7bb7f613" translate="yes" xml:space="preserve">
          <source>Perplexity tolerance in batch learning. Only used when &lt;code&gt;evaluate_every&lt;/code&gt; is greater than 0.</source>
          <target state="translated">批处理学习中的困惑容忍度。仅在 &lt;code&gt;evaluate_every&lt;/code&gt; 大于0时使用。</target>
        </trans-unit>
        <trans-unit id="bed69aed128c6d53c076bf23b1786ba34af67dfd" translate="yes" xml:space="preserve">
          <source>Persistent Contrastive Divergence addresses this. Instead of starting a new chain each time the gradient is needed, and performing only one Gibbs sampling step, in PCD we keep a number of chains (fantasy particles) that are updated \(k\) Gibbs steps after each weight update. This allows the particles to explore the space more thoroughly.</source>
          <target state="translated">持久性对比发散解决了这个问题。在PCD中,我们不需要每次需要梯度时都启动一个新的链,并且只执行一个Gibbs采样步,而是保留一些链(幻想粒子),在每次权重更新后,都会更新(k)个Gibbs步。这使得粒子可以更彻底地探索空间。</target>
        </trans-unit>
        <trans-unit id="d4d9d12e88278335e6c824e88af73f55a763004e" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti,Robust Statistics Concomitant scale estimates,pg 172.</target>
        </trans-unit>
        <trans-unit id="977cdb0f1102753846469a4e3ab78497c359fae5" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti:Robust Statistics,Concomitant scale estimates,第172页。</target>
        </trans-unit>
        <trans-unit id="f869e193262fa2d8e1a9ddde0485aa49aaa656aa" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi:10.1016/0377-0427(87)90125-7&lt;/a&gt;.</source>
          <target state="translated">Peter J.Rousseeuw（1987）。&amp;ldquo;剪影：对聚类分析的解释和验证的图形帮助&amp;rdquo;。计算和应用数学20：53&amp;ndash;65。&lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi：10.1016 / 0377-0427（87）90125-7&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="801ff1e5ba061302f2ef13b831a12ef30f616d52" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53-65.</source>
          <target state="translated">Peter J.Rousseeuw（1987）。&amp;ldquo;剪影：对聚类分析的解释和验证的图形帮助&amp;rdquo;。计算和应用数学20：53-65。</target>
        </trans-unit>
        <trans-unit id="6884db0930152b7581421b9e7df37cdc709bc0ae" translate="yes" xml:space="preserve">
          <source>Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.</source>
          <target state="translated">pickle和unpickle一棵树。请注意,树的状态在pickle操作中被保存:树在unpickling时不需要重建。</target>
        </trans-unit>
        <trans-unit id="4a6d28315bc21af0edd71a7862fc9db5f7a4917f" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">李平，T。哈斯提和KW教堂，2006年，&amp;ldquo;非常稀疏的随机投影&amp;rdquo;。&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fb3d4adf8ec429eb640cc1eefb0227abf08a6683" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">李平，T。哈斯提和KW教堂，2006年，&amp;ldquo;非常稀疏的随机投影&amp;rdquo;。&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3462e562173cab76115a1fabd23d03498a615dda" translate="yes" xml:space="preserve">
          <source>Ping Li, Trevor J. Hastie, and Kenneth W. Church. 2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;Very sparse random projections.&lt;/a&gt; In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD &amp;lsquo;06). ACM, New York, NY, USA, 287-296.</source>
          <target state="translated">李萍，Trevor J. Hastie和Kenneth W. Church。2006年。&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;非常稀疏的随机投影。&lt;/a&gt;在第12届ACM SIGKDD关于知识发现和数据挖掘的国际会议论文集（KDD '06）中。美国纽约州纽约市，ACM，287-296。</target>
        </trans-unit>
        <trans-unit id="32b1d5a78493496dd5152fd2d504f7e21009e3f2" translate="yes" xml:space="preserve">
          <source>Pipeline</source>
          <target state="translated">Pipeline</target>
        </trans-unit>
        <trans-unit id="5fcec2c4630ab50971732249756f691f50ae9f29" translate="yes" xml:space="preserve">
          <source>Pipeline Anova SVM</source>
          <target state="translated">管道 Anova SVM</target>
        </trans-unit>
        <trans-unit id="a041187d94eb589a1ba5ff98293ef896e00c97e7" translate="yes" xml:space="preserve">
          <source>Pipeline of transforms with a final estimator.</source>
          <target state="translated">带有最终估计器的变换流水线。</target>
        </trans-unit>
        <trans-unit id="b728ae3e883ea99a9d120fc06880b19e80fef86a" translate="yes" xml:space="preserve">
          <source>Pipeline&amp;rsquo;s &lt;code&gt;named_steps&lt;/code&gt; attribute allows accessing steps by name with tab completion in interactive environments:</source>
          <target state="translated">管道的 &lt;code&gt;named_steps&lt;/code&gt; 属性允许在交互式环境中按名称和带有制表符补全的方式访问步骤：</target>
        </trans-unit>
        <trans-unit id="73de4ddfaf9a511a59191faaa0679d43b9d9c3eb" translate="yes" xml:space="preserve">
          <source>Pipelines and composite estimators</source>
          <target state="translated">管道和综合估算器</target>
        </trans-unit>
        <trans-unit id="52761af283a0d9e614a4e2ba9d4a353d3fd70a7b" translate="yes" xml:space="preserve">
          <source>Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.</source>
          <target state="translated">管道通过确保使用相同的样本来训练变换器和预测器,有助于避免在交叉验证中把统计数据从测试数据泄露到训练的模型中。</target>
        </trans-unit>
        <trans-unit id="3d31223cfe1830200469a76812f595efba107474" translate="yes" xml:space="preserve">
          <source>Pipelining</source>
          <target state="translated">Pipelining</target>
        </trans-unit>
        <trans-unit id="04ae27026f61a0e2fe9396849cac7271f4f56e69" translate="yes" xml:space="preserve">
          <source>Pipelining: chaining a PCA and a logistic regression</source>
          <target state="translated">管线化:将PCA和逻辑回归进行链式连接</target>
        </trans-unit>
        <trans-unit id="4d2bb7a399ca2f416aedb250a1c02b6dbddd98f5" translate="yes" xml:space="preserve">
          <source>Pixel importances with a parallel forest of trees</source>
          <target state="translated">平行树林的像素进口量。</target>
        </trans-unit>
        <trans-unit id="2ca4493c014c6673344a97eb7b5e5aaa17897b68" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo; SVM的概率输出以及与正规化似然方法的比较&amp;rdquo;&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="94b48515f27c2ba66dc001876eed954b37962189" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">Platt &lt;a href=&quot;https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo; SVM的概率输出以及与正规化似然方法的比较&amp;rdquo;&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6cd3fc864a17260622e839224271f277841ca1af" translate="yes" xml:space="preserve">
          <source>Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">众所周知，普拉特的方法也有理论上的问题。如果需要的置信度，但是这些不必是概率，那么最好是集 &lt;code&gt;probability=False&lt;/code&gt; 和使用 &lt;code&gt;decision_function&lt;/code&gt; 代替 &lt;code&gt;predict_proba&lt;/code&gt; 。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
