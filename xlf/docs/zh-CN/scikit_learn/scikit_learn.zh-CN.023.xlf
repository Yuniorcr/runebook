<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="21601426cfbdf9a26553c2613d8f13b5c8a0699e" translate="yes" xml:space="preserve">
          <source>Validate scalar parameters type and value.</source>
          <target state="translated">验证标量参数类型和值。</target>
        </trans-unit>
        <trans-unit id="ec59a2a93f21b1aa3fbc16cd26b3b2dbab6fa78b" translate="yes" xml:space="preserve">
          <source>Validation curve.</source>
          <target state="translated">验证曲线。</target>
        </trans-unit>
        <trans-unit id="675b8482a7f9f38fa965a1efe10c6a6ee6ec5cdb" translate="yes" xml:space="preserve">
          <source>Value added to the diagonal of the kernel matrix during fitting. Larger values correspond to increased noise level in the observations. This can also prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Note that this is equivalent to adding a WhiteKernel with c=alpha. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge.</source>
          <target state="translated">拟合过程中添加到内核矩阵对角线上的值。数值越大,说明观测值的噪声越大。这也可以防止在拟合过程中出现潜在的数字问题,确保计算值形成一个正定矩阵。如果传递了一个数组,它的条目数必须与用于拟合的数据相同,并作为数据点相关的噪声水平。注意,这相当于添加了一个c=alpha的WhiteKernel。允许直接指定噪声水平作为参数,主要是为了方便和与Ridge保持一致。</target>
        </trans-unit>
        <trans-unit id="cdffc29f88adeffd4bcff100fb7aa53a66956d52" translate="yes" xml:space="preserve">
          <source>Value for numerical stability in adam. Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">亚当数值稳定性的值。仅在solver ='adam'时使用</target>
        </trans-unit>
        <trans-unit id="c6350d6ef6528ee88ef12a12465bebefd1891dd8" translate="yes" xml:space="preserve">
          <source>Value of the pseudo-likelihood (proxy for likelihood).</source>
          <target state="translated">伪可能性的值(可能性的代理)。</target>
        </trans-unit>
        <trans-unit id="7a1b051ea7b4e31aba2ba2519e8c31958f649214" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.</source>
          <target state="translated">如果估算器拟合中出现错误，则分配给分数的值。如果设置为&amp;ldquo; raise&amp;rdquo;，则会引发错误。如果给出数值，则引发FitFailedWarning。此参数不会影响重新安装步骤，这将始终引发错误。</target>
        </trans-unit>
        <trans-unit id="7c9f9f5dcfc8aebd4eea110198ededa32c4b1278" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">如果估算器拟合出现错误，则分配给分数的值。如果设置为&amp;ldquo; raise&amp;rdquo;，则会引发错误。如果给出数值，则引发FitFailedWarning。此参数不会影响重新安装步骤，这将始终引发错误。默认值为&amp;ldquo; raise&amp;rdquo;，但从0.22版开始，它将更改为np.nan。</target>
        </trans-unit>
        <trans-unit id="51fe27463b1bbffac6c175b98fff3a09a8ef007a" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If set to &amp;lsquo;raise-deprecating&amp;rsquo;, a FutureWarning is printed before the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise-deprecating&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">如果估算器拟合出现错误，则分配给分数的值。如果设置为&amp;ldquo; raise&amp;rdquo;，则会引发错误。如果设置为'raise-preprecating'，则会在出现错误之前打印出FutureWarning。如果给出数值，则引发FitFailedWarning。此参数不会影响重新安装步骤，这将始终引发错误。默认值为&amp;ldquo;不赞成使用&amp;rdquo;，但从0.22版开始，它将更改为np.nan。</target>
        </trans-unit>
        <trans-unit id="402a4cfb84a22d3670431b1576518e6587de93b8" translate="yes" xml:space="preserve">
          <source>Value to use for the dummy feature.</source>
          <target state="translated">假人功能使用的值。</target>
        </trans-unit>
        <trans-unit id="82321dd8f607145fb8d2875c3e367d82d45dfc71" translate="yes" xml:space="preserve">
          <source>Value with which negative labels must be encoded.</source>
          <target state="translated">必须对负标签进行编码的值。</target>
        </trans-unit>
        <trans-unit id="4e0758fceaa4f106e89501aa7c196eea7d1ad1c2" translate="yes" xml:space="preserve">
          <source>Value with which positive labels must be encoded.</source>
          <target state="translated">必须对正标签进行编码的值。</target>
        </trans-unit>
        <trans-unit id="ca5e1888f7ff9f4679a3377b455596a48d014681" translate="yes" xml:space="preserve">
          <source>ValueError</source>
          <target state="translated">ValueError</target>
        </trans-unit>
        <trans-unit id="6a7ed2e67e56dace630120ac5c7bd01e4d032523" translate="yes" xml:space="preserve">
          <source>Values greater than the threshold map to 1, while values less than or equal to the threshold map to 0. With the default threshold of 0, only positive values map to 1.</source>
          <target state="translated">大于阈值的值映射为1,而小于或等于阈值的值映射为0,默认阈值为0时,只有正值映射为1。</target>
        </trans-unit>
        <trans-unit id="0a659f48fb09b2c2dd949774cc3bd6b7ffd6fd87" translate="yes" xml:space="preserve">
          <source>Values in each bin have the same nearest center of a 1D k-means cluster.</source>
          <target state="translated">每个bin中的数值都有相同的1D k-means簇的最近中心。</target>
        </trans-unit>
        <trans-unit id="c67d763b94a97115ba7ee9d49115a272cb508cf6" translate="yes" xml:space="preserve">
          <source>Values of n_samples samples drawn from Gaussian process and evaluated at query points.</source>
          <target state="translated">从高斯过程中抽取的n_samples样本的值,并在查询点进行评估。</target>
        </trans-unit>
        <trans-unit id="1cd1b62dfd3b6a63572d1bf631789bd088451d1d" translate="yes" xml:space="preserve">
          <source>Values of the visible layer after one Gibbs step.</source>
          <target state="translated">一个吉布斯步骤后可见层的数值。</target>
        </trans-unit>
        <trans-unit id="c9500aef779ad4ab4355590ca05b9c0de0aa083a" translate="yes" xml:space="preserve">
          <source>Values of the visible layer to start from.</source>
          <target state="translated">可见层的值要从哪里开始。</target>
        </trans-unit>
        <trans-unit id="d9ca5115511a5b00d878e1de5b9daa8f530b632c" translate="yes" xml:space="preserve">
          <source>Values of the visible layer. Must be all-boolean (not checked).</source>
          <target state="translated">可见层的数值。必须是全布尔值(不勾选)。</target>
        </trans-unit>
        <trans-unit id="35e8d31773dfd80568909d00a3100d73e50de4e1" translate="yes" xml:space="preserve">
          <source>Values predicted by each regressor.</source>
          <target state="translated">每个回归者预测的数值。</target>
        </trans-unit>
        <trans-unit id="445d09e482944669dc8a6e893591f45bda28254b" translate="yes" xml:space="preserve">
          <source>Vanschoren, van Rijn, Bischl and Torgo &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;ldquo;OpenML: networked science in machine learning&amp;rdquo;&lt;/a&gt;, ACM SIGKDD Explorations Newsletter, 15(2), 49-60, 2014.</source>
          <target state="translated">Vanschoren，van Rijn，Bischl和Torgo，&lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;ldquo;&lt;/a&gt; OpenML ：机器学习中的网络科学&amp;rdquo;，ACM SIGKDD Explorations Newsletter，15（2），49-60，2014年。</target>
        </trans-unit>
        <trans-unit id="ba47c39bbafea14cc75438e6420272a547d1a3e3" translate="yes" xml:space="preserve">
          <source>Variance explained by each of the selected components.</source>
          <target state="translated">每个选定的组成部分所解释的差异。</target>
        </trans-unit>
        <trans-unit id="17b5cb397e6ad9830d59b5fc66bebb45024c7ef4" translate="yes" xml:space="preserve">
          <source>Variances of individual features.</source>
          <target state="translated">各个特征的差异。</target>
        </trans-unit>
        <trans-unit id="7933f72bf76c6cfbc1dde87498522f5e833878e6" translate="yes" xml:space="preserve">
          <source>Variational Bayesian estimation of a Gaussian mixture.</source>
          <target state="translated">高斯混合物的变异贝叶斯估计。</target>
        </trans-unit>
        <trans-unit id="e459652719d6e0edf38bb3c9f14dba040888c62f" translate="yes" xml:space="preserve">
          <source>Variational inference is an extension of expectation-maximization that maximizes a lower bound on model evidence (including priors) instead of data likelihood. The principle behind variational methods is the same as expectation-maximization (that is both are iterative algorithms that alternate between finding the probabilities for each point to be generated by each mixture and fitting the mixture to these assigned points), but variational methods add regularization by integrating information from prior distributions. This avoids the singularities often found in expectation-maximization solutions but introduces some subtle biases to the model. Inference is often notably slower, but not usually as much so as to render usage unpractical.</source>
          <target state="translated">变异推理是期望最大化的延伸,它最大化了模型证据(包括前值)的下限,而不是数据似然。变分方法的原理与期望最大化相同(即两者都是在寻找每个混合物产生的每个点的概率和将混合物拟合到这些分配点之间交替进行的迭代算法),但变分方法通过整合来自先验分布的信息来增加正则化。这避免了期望最大化解决方案中经常发现的奇异性,但会给模型引入一些微妙的偏差。推断通常会明显变慢,但通常不至于使使用不切实际。</target>
        </trans-unit>
        <trans-unit id="009e019794c4b5a288d65b8e0eabe9064e298c81" translate="yes" xml:space="preserve">
          <source>Variational inference techniques for the Dirichlet process still work with a finite approximation to this infinite mixture model, but instead of having to specify a priori how many components one wants to use, one just specifies the concentration parameter and an upper bound on the number of mixture components (this upper bound, assuming it is higher than the &amp;ldquo;true&amp;rdquo; number of components, affects only algorithmic complexity, not the actual number of components used).</source>
          <target state="translated">Dirichlet过程的变分推理技术仍可在此无限混合模型的有限近似下使用，但不必先验地指定一个人要使用多少组分，只需指定浓度参数和混合物数量的上限即可组件（假设该上限高于&amp;ldquo;真实&amp;rdquo;的组件数量，则仅影响算法复杂度，而不影响实际使用的组件数量）。</target>
        </trans-unit>
        <trans-unit id="bfc42eb1bb86ce5f62b086e9ffd3c67a080b0730" translate="yes" xml:space="preserve">
          <source>Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, &lt;code&gt;components_[i, j]&lt;/code&gt; can be viewed as pseudocount that represents the number of times word &lt;code&gt;j&lt;/code&gt; was assigned to topic &lt;code&gt;i&lt;/code&gt;. It can also be viewed as distribution over the words for each topic after normalization: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt;.</source>
          <target state="translated">主题词分布的变体参数。由于主题词分配的完整条件是Dirichlet， &lt;code&gt;components_[i, j]&lt;/code&gt; 可以看作是伪计数，它表示将词 &lt;code&gt;j&lt;/code&gt; 分配给主题 &lt;code&gt;i&lt;/code&gt; 的次数。归一化后，也可以将其视为每个主题的单词分布： &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="65cb8d21f19957f8f56d7ec3aeccadf0c1efbc6f" translate="yes" xml:space="preserve">
          <source>Various Agglomerative Clustering on a 2D embedding of digits</source>
          <target state="translated">在数字的二维嵌入上进行各种聚类分析</target>
        </trans-unit>
        <trans-unit id="ddbf21d472ec4b83f538c33f12eb263b69f44ca0" translate="yes" xml:space="preserve">
          <source>Various improvements were made to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. On top of the Poisson loss mentionned above, these estimators now support &lt;a href=&quot;../../modules/ensemble#sw-hgbdt&quot;&gt;sample weights&lt;/a&gt;. Also, an automatic early-stopping criterion was added: early-stopping is enabled by default when the number of samples exceeds 10k. Finally, users can now define &lt;a href=&quot;../../modules/ensemble#monotonic-cst-gbdt&quot;&gt;monotonic constraints&lt;/a&gt; to constrain the predictions based on the variations of specific features. In the following example, we construct a target that is generally positively correlated with the first feature, with some noise. Applying monotoinc constraints allows the prediction to capture the global effect of the first feature, instead of fitting the noise.</source>
          <target state="translated">对&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt; &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;进行了各种改进。除了上面提到的泊松损失之外，这些估计器现在支持&lt;a href=&quot;../../modules/ensemble#sw-hgbdt&quot;&gt;样本权重&lt;/a&gt;。此外，还添加了自动提前停止条件：默认情况下，当样本数超过10k时，将启用提前停止。最后，用户现在可以基于特定特征的变化定义&lt;a href=&quot;../../modules/ensemble#monotonic-cst-gbdt&quot;&gt;单调约束&lt;/a&gt;来约束预测。在以下示例中，我们构建了一个目标，该目标通常与第一个特征呈正相关，并带有一些噪声。应用单变约束可以使预测捕获第一个特征的整体效果，而不是拟合噪声。</target>
        </trans-unit>
        <trans-unit id="b1e276370580ceeca94d9a25d3b75abf89a69938" translate="yes" xml:space="preserve">
          <source>Varying regularization in Multi-layer Perceptron</source>
          <target state="translated">多层感知器的可变正则化</target>
        </trans-unit>
        <trans-unit id="1e178759402bc070ae202c1ae1b1666da0dd6a9c" translate="yes" xml:space="preserve">
          <source>Vector Quantization Example</source>
          <target state="translated">矢量量化实例</target>
        </trans-unit>
        <trans-unit id="ba8b3829eecac2c5ad85a64a161b0e7f2fae54cf" translate="yes" xml:space="preserve">
          <source>Vector of errors at each iteration.</source>
          <target state="translated">每次迭代的误差向量。</target>
        </trans-unit>
        <trans-unit id="4e8912fa819c195ed09c153115c88939fa1f2e3c" translate="yes" xml:space="preserve">
          <source>Vector to be scored, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">要计分的向量，其中 &lt;code&gt;n_samples&lt;/code&gt; 是样本数， &lt;code&gt;n_features&lt;/code&gt; 是特征数。</target>
        </trans-unit>
        <trans-unit id="cf31e021601b7cdd3aba8ca6f6502b2543cdeb94" translate="yes" xml:space="preserve">
          <source>VehAge</source>
          <target state="translated">VehAge</target>
        </trans-unit>
        <trans-unit id="ea3a474961d1b758addd0978141f5ebc1f6f2b70" translate="yes" xml:space="preserve">
          <source>VehBrand</source>
          <target state="translated">VehBrand</target>
        </trans-unit>
        <trans-unit id="fda6c72b6cabb64878498cd55268cca04e8d770b" translate="yes" xml:space="preserve">
          <source>VehGas</source>
          <target state="translated">VehGas</target>
        </trans-unit>
        <trans-unit id="9e0c38e996b000566fa359d3ed449ba796915a3e" translate="yes" xml:space="preserve">
          <source>VehPower</source>
          <target state="translated">VehPower</target>
        </trans-unit>
        <trans-unit id="93c6f0903309fd539ceb7d4710cf07f7db8cb1d8" translate="yes" xml:space="preserve">
          <source>Verbose mode when fitting the model.</source>
          <target state="translated">拟合模型时采用Verbose模式。</target>
        </trans-unit>
        <trans-unit id="ee5731f921bfe2d1197cd007f006306ad3328112" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations.</source>
          <target state="translated">在PD计算过程中,有详细的输出。</target>
        </trans-unit>
        <trans-unit id="eeb343db47ab9124ef417c41d9bdb92839772dc0" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations. Defaults to 0.</source>
          <target state="translated">在PD计算中的详细输出。默认值为0。</target>
        </trans-unit>
        <trans-unit id="65d3f9d357c8217e4b4161cc31c9983e755e9511" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated.</source>
          <target state="translated">Verbosity标志,控制函数执行时发出的调试信息。</target>
        </trans-unit>
        <trans-unit id="66d100e92da285b9102a10ebf1825a4d7ce2d91c" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated. The higher, the more verbose. Can be 0, 1, or 2.</source>
          <target state="translated">Verbosity标志,控制函数执行时发出的调试信息。越高,越啰嗦。可以是0、1或2。</target>
        </trans-unit>
        <trans-unit id="a606460a9db19f2456900341e545d542d386dcd0" translate="yes" xml:space="preserve">
          <source>Verbosity level.</source>
          <target state="translated">啰嗦程度。</target>
        </trans-unit>
        <trans-unit id="9cadb350a887ea26b759cec53fba259b94be0b70" translate="yes" xml:space="preserve">
          <source>Verbosity level. Setting verbose &amp;gt; 0 will display additional information depending on the solver used.</source>
          <target state="translated">详细程度。设置详细&amp;gt; 0将显示其他信息，具体取决于所使用的求解器。</target>
        </trans-unit>
        <trans-unit id="c09635f4883cd7798a06597eead68509e08bef52" translate="yes" xml:space="preserve">
          <source>Verbosity mode.</source>
          <target state="translated">啰嗦模式。</target>
        </trans-unit>
        <trans-unit id="4ee9c427e0cc678ca91bc7294708dc43db03512b" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#gp-kernels&quot;&gt;kernels&lt;/a&gt; can be specified. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">多功能：可以指定不同的&lt;a href=&quot;#gp-kernels&quot;&gt;内核&lt;/a&gt;。提供了通用内核，但是也可以指定自定义内核。</target>
        </trans-unit>
        <trans-unit id="4b16fac84e3102257e26d97dc6bcc2775a76c275" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">多功能：可以为决策功能指定不同的&lt;a href=&quot;#svm-kernels&quot;&gt;内核&lt;/a&gt;功能。提供了通用内核，但是也可以指定自定义内核。</target>
        </trans-unit>
        <trans-unit id="102caab3d934ebf62d9240e41edbdfb96ec830ff" translate="yes" xml:space="preserve">
          <source>Version of the dataset. Can only be provided if also &lt;code&gt;name&lt;/code&gt; is given. If &amp;lsquo;active&amp;rsquo; the oldest version that&amp;rsquo;s still active is used. Since there may be more than one active version of a dataset, and those versions may fundamentally be different from one another, setting an exact version is highly recommended.</source>
          <target state="translated">数据集的版本。仅当提供 &lt;code&gt;name&lt;/code&gt; 才能提供。如果&amp;ldquo;活动&amp;rdquo;，则使用仍在活动的最旧版本。由于一个数据集可能有多个活动版本，并且这些版本在根本上可能彼此不同，因此强烈建议设置一个确切的版本。</target>
        </trans-unit>
        <trans-unit id="2d0ab9e3d9a896817cdfc684c77fbf9f0c4f1aac" translate="yes" xml:space="preserve">
          <source>Version: RCV1-v2, vectors, full sets, topics multilabels.</source>
          <target state="translated">版本。RCV1-v2,向量,全集,主题多标签。</target>
        </trans-unit>
        <trans-unit id="dfb46f94f7d77a5ddeabfd408748577e450d338b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, large &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">非常大的 &lt;code&gt;n_samples&lt;/code&gt; ，大 &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3496b8ff284f2499d5b89bafe815a9579d5a779b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">非常大的 &lt;code&gt;n_samples&lt;/code&gt; ，中 &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="90edfe52a065a045edbdd25bf2f2316a234658ac" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt; with &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;MiniBatch code&lt;/a&gt;</source>
          <target state="translated">非常大的 &lt;code&gt;n_samples&lt;/code&gt; ，中 &lt;code&gt;n_clusters&lt;/code&gt; 与&lt;a href=&quot;#mini-batch-kmeans&quot;&gt;MiniBatch代码&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="56b71e89fb1079caaadefd0889e9a22e8b0560e3" translate="yes" xml:space="preserve">
          <source>Videos</source>
          <target state="translated">Videos</target>
        </trans-unit>
        <trans-unit id="644cc701dadc9ddd9912f1b11b35ead35737260b" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method &lt;a href=&quot;#veb2010&quot; id=&quot;id15&quot;&gt;[VEB2010]&lt;/a&gt;. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="translated">Vinh等。（2010年）通过平均方法命名NMI和AMI的变体&lt;a href=&quot;#veb2010&quot; id=&quot;id15&quot;&gt;[VEB2010]&lt;/a&gt;。他们的&amp;ldquo; sqrt&amp;rdquo;和&amp;ldquo; sum&amp;rdquo;平均值是几何和算术平均值。我们使用这些更广泛的通用名称。</target>
        </trans-unit>
        <trans-unit id="f74a22805e87ed187a5bf75da0c74d88f9fc4e05" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method [VEB2010]. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="translated">Vinh等。（2010年）通过平均方法命名了NMI和AMI的变体[VEB2010]。他们的&amp;ldquo; sqrt&amp;rdquo;和&amp;ldquo; sum&amp;rdquo;平均值是几何和算术平均值。我们使用这些更广泛的通用名称。</target>
        </trans-unit>
        <trans-unit id="3e1bb17ff94c0af1df416cfea07d80b830f06013" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="translated">Vinh，Epps和Bailey，（2009年）。&amp;ldquo;用于聚类比较的信息理论方法&amp;rdquo;。第26届年度机器学习国际会议论文集-ICML '09。&lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi：10.1145 / 1553374.1553511&lt;/a&gt;。ISBN 9781605585161。</target>
        </trans-unit>
        <trans-unit id="aa05fa0b125b1736672a1d80de8273f7659ae9f5" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="translated">Vinh，Epps和Bailey，（2010年）。&amp;ldquo;用于聚类比较的信息理论方法：变异，属性，归一化和机会校正&amp;rdquo;。JMLR &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt; &amp;gt;</target>
        </trans-unit>
        <trans-unit id="40fdfddfc4699e8e891d021e6ce4e4252243f9c7" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance, JMLR</source>
          <target state="translated">Vinh,Epps,and Bailey,(2010)。信息理论措施的聚类比较。Variants,Properties,Normalization and Correction for Chance,JMLR。</target>
        </trans-unit>
        <trans-unit id="64eeb8915eff8290b0627c8aa96dd46ee4bda6f1" translate="yes" xml:space="preserve">
          <source>Visualise your tree as you are training by using the &lt;code&gt;export&lt;/code&gt; function. Use &lt;code&gt;max_depth=3&lt;/code&gt; as an initial tree depth to get a feel for how the tree is fitting to your data, and then increase the depth.</source>
          <target state="translated">使用 &lt;code&gt;export&lt;/code&gt; 功能在训练时可视化您的树。使用 &lt;code&gt;max_depth=3&lt;/code&gt; 作为初始树的深度，以了解树如何适合您的数据，然后增加深度。</target>
        </trans-unit>
        <trans-unit id="d175985b87dd9f620aa960059c730b4a35e3bcb5" translate="yes" xml:space="preserve">
          <source>Visualization</source>
          <target state="translated">Visualization</target>
        </trans-unit>
        <trans-unit id="38623835e09f3cd243cdf966707dad9de4ecfeda" translate="yes" xml:space="preserve">
          <source>Visualization of MLP weights on MNIST</source>
          <target state="translated">MNIST上MLP权重的可视化。</target>
        </trans-unit>
        <trans-unit id="a291ff40a157c9afd67fb01fd3c6b6d368d78978" translate="yes" xml:space="preserve">
          <source>Visualization of predictions obtained from different models.</source>
          <target state="translated">从不同模型获得的预测的可视化。</target>
        </trans-unit>
        <trans-unit id="94a741e26bd8d9bfdacbab90c67da4753dcabca8" translate="yes" xml:space="preserve">
          <source>Visualizations with Display Objects</source>
          <target state="translated">使用显示对象进行可视化</target>
        </trans-unit>
        <trans-unit id="a6c65fa336dc53edc04e670583358fb288a99997" translate="yes" xml:space="preserve">
          <source>Visualize cross-validation indices for many CV objects</source>
          <target state="translated">可视化许多CV对象的交叉验证指数。</target>
        </trans-unit>
        <trans-unit id="4a2bddc914855cb9100c33fc5e346e89e1926136" translate="yes" xml:space="preserve">
          <source>Visualize our data</source>
          <target state="translated">将我们的数据可视化</target>
        </trans-unit>
        <trans-unit id="28ba2de8813583360eb0588f62cb6dc19a1f4072" translate="yes" xml:space="preserve">
          <source>Visualize the resulting regions</source>
          <target state="translated">视觉化的结果区域</target>
        </trans-unit>
        <trans-unit id="b77da1f257213eacf5971ec98d2f34c8fe910374" translate="yes" xml:space="preserve">
          <source>Visualizing cross-validation behavior in scikit-learn</source>
          <target state="translated">在scikit-learn中可视化交叉验证行为。</target>
        </trans-unit>
        <trans-unit id="e6614e53d3137ea4329f7b88a52f014060c402bb" translate="yes" xml:space="preserve">
          <source>Visualizing the stock market structure</source>
          <target state="translated">视觉化的股票市场结构</target>
        </trans-unit>
        <trans-unit id="3e1e0ef10e7a115946f530e934380438421c5b34" translate="yes" xml:space="preserve">
          <source>Vocabulary: classification and regression</source>
          <target state="translated">词汇:分类和回归</target>
        </trans-unit>
        <trans-unit id="9b3e588521f2631086f0d4ea61248bd80936e042" translate="yes" xml:space="preserve">
          <source>VotingRegressor</source>
          <target state="translated">VotingRegressor</target>
        </trans-unit>
        <trans-unit id="dd7b37acd93acaf11b82a9ebbc3eea819b85e0ef" translate="yes" xml:space="preserve">
          <source>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171.</source>
          <target state="translated">W.H.Wolberg,W.N.Street,and O.L.Mangasarian.从细针吸液中诊断乳腺癌的机器学习技术。Cancer Letters 77(1994)163-171.</target>
        </trans-unit>
        <trans-unit id="985d7c09beb3a8622b6c063b009de9296fdb89ed" translate="yes" xml:space="preserve">
          <source>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.</source>
          <target state="translated">WN街，WH Wolberg和OL Mangasarian。核特征提取用于乳腺肿瘤诊断。IS＆T / SPIE 1993年国际电子成像研讨会：科学和技术，第1905卷，第861-870页，加利福尼亚州圣何塞，1993年。</target>
        </trans-unit>
        <trans-unit id="0525374f4c7331dc5d256feba32a265d327160ed" translate="yes" xml:space="preserve">
          <source>WDBC-Benign</source>
          <target state="translated">WDBC-Benign</target>
        </trans-unit>
        <trans-unit id="fd630df285b07b6076d3b38d88445f6031d3902e" translate="yes" xml:space="preserve">
          <source>WDBC-Malignant</source>
          <target state="translated">WDBC-Malignant</target>
        </trans-unit>
        <trans-unit id="9b852a8108b3e892136da9e7da9f0a5bb56540ea" translate="yes" xml:space="preserve">
          <source>WMinkowskiDistance</source>
          <target state="translated">WMinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="c3600a53fe931326fad0ec5abc0f593830220f56" translate="yes" xml:space="preserve">
          <source>Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp;amp; Liu, T. Y. (2013, May). A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th Annual Conference on Learning Theory (COLT 2013)</source>
          <target state="translated">Wang，Y.，Wang L.，Li，Y.，He，D.，Chen，W.，＆Liu，TY（2013，May）。NDCG排名测度的理论分析。在第26届学习理论年会（COLT 2013）的会议记录中</target>
        </trans-unit>
        <trans-unit id="4e8ee595c7db5dd5f284f8fb603cc66c6c8287ae" translate="yes" xml:space="preserve">
          <source>Ward clustering based on a Feature matrix.</source>
          <target state="translated">基于特征矩阵的病房聚类。</target>
        </trans-unit>
        <trans-unit id="1af684513cf70467c9307765e01677f8970cff6e" translate="yes" xml:space="preserve">
          <source>Ward hierarchical clustering</source>
          <target state="translated">病房分层聚类</target>
        </trans-unit>
        <trans-unit id="d2173ac976f5809b703436c0de33dab1598b674c" translate="yes" xml:space="preserve">
          <source>Ward is the most effective method for noisy data.</source>
          <target state="translated">Ward是对噪声数据最有效的方法。</target>
        </trans-unit>
        <trans-unit id="e9c45563358e813f157ba81b33143542165ba84e" translate="yes" xml:space="preserve">
          <source>Warning</source>
          <target state="translated">Warning</target>
        </trans-unit>
        <trans-unit id="44d79cfceaac3d6c963709a9f443a7578dfdd3fa" translate="yes" xml:space="preserve">
          <source>Warning class used if there is an error while fitting the estimator.</source>
          <target state="translated">拟合估计器时有错误时使用的警告类。</target>
        </trans-unit>
        <trans-unit id="c56f46b7e83e71f0bcaf54dacd8cfc15c71ef274" translate="yes" xml:space="preserve">
          <source>Warning class used to notify the user of any change in the behavior.</source>
          <target state="translated">警告类用于通知用户行为的任何变化。</target>
        </trans-unit>
        <trans-unit id="43a2ad1c4144ef567b3006486da55db4df5bcce7" translate="yes" xml:space="preserve">
          <source>Warning used to notify implicit data conversions happening in the code.</source>
          <target state="translated">用于通知代码中发生的隐式数据转换的警告。</target>
        </trans-unit>
        <trans-unit id="69bb37448a64e3ca58327c210b042b57b19259a7" translate="yes" xml:space="preserve">
          <source>Warning used to notify the user of inefficient computation.</source>
          <target state="translated">用于通知用户计算效率低下的警告。</target>
        </trans-unit>
        <trans-unit id="95fde5bcc048210bdd2da0e9628c10dadee1ce1e" translate="yes" xml:space="preserve">
          <source>Warning used when the dot operation does not use BLAS.</source>
          <target state="translated">当点运算不使用BLAS时使用的警告。</target>
        </trans-unit>
        <trans-unit id="77d4a9d6a0a46436c153d66828a62d378a7e1f5d" translate="yes" xml:space="preserve">
          <source>Warning used when the metric is invalid</source>
          <target state="translated">当度量无效时使用的警告</target>
        </trans-unit>
        <trans-unit id="d0aaba5d13d0d7235d440530a46ccfa6343b56ff" translate="yes" xml:space="preserve">
          <source>Warning: Extra-trees should only be used within ensemble methods.</source>
          <target state="translated">警告:Extra-trees只能在集合方法中使用。额外树只能在集合方法中使用。</target>
        </trans-unit>
        <trans-unit id="c083bc8548c03dc08f53c7e8a611e5699830557a" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="translated">警告：基于杂质的特征重要性可能会误导高基数特征（许多唯一值）。另请参见&lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a70a0040ebdf5db3cf497e998d5844dc921e921b" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="translated">警告：基于杂质的特征重要性可能会误导高基数特征（许多唯一值）。另请参见&lt;a href=&quot;sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c2eb6fdf9d13ab34884681ef0c66f41e16b52aad" translate="yes" xml:space="preserve">
          <source>Warning: this function is experimental and subject to change in a future version of joblib.</source>
          <target state="translated">警告:这个功能是实验性的,在未来的joblib版本中可能会改变。</target>
        </trans-unit>
        <trans-unit id="b33d3bb4e4bfe5e80c2407f4ead429c7fa466ef0" translate="yes" xml:space="preserve">
          <source>We achieved 83.5% accuracy. Let&amp;rsquo;s see if we can do better with a linear &lt;a href=&quot;../../modules/svm#svm&quot;&gt;support vector machine (SVM)&lt;/a&gt;, which is widely regarded as one of the best text classification algorithms (although it&amp;rsquo;s also a bit slower than na&amp;iuml;ve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:</source>
          <target state="translated">我们达到了83.5％的准确性。让我们看看是否可以使用线性&lt;a href=&quot;../../modules/svm#svm&quot;&gt;支持向量机（SVM）&lt;/a&gt;来做得更好，线性支持向量机被广泛认为是最好的文本分类算法之一（尽管它比朴素的贝叶斯算法还慢一些）。我们可以通过简单地将另一个分类器对象插入管道来更改学习者：</target>
        </trans-unit>
        <trans-unit id="5e4234559a6f8eb7829d45ed1528d4d2b014e858" translate="yes" xml:space="preserve">
          <source>We achieved 91.3% accuracy using the SVM. &lt;code&gt;scikit-learn&lt;/code&gt; provides further utilities for more detailed performance analysis of the results:</source>
          <target state="translated">使用SVM，我们达到了91.3％的准确性。 &lt;code&gt;scikit-learn&lt;/code&gt; 提供了更多实用程序来对结果进行更详细的性能分析：</target>
        </trans-unit>
        <trans-unit id="4073bf855ec3741a8d17116f66549a3127ee1b52" translate="yes" xml:space="preserve">
          <source>We add observation noise to these waveforms. We generate very sparse noise: only 6% of the time points contain noise. As a result, the l1 norm of this noise (ie &amp;ldquo;cityblock&amp;rdquo; distance) is much smaller than it&amp;rsquo;s l2 norm (&amp;ldquo;euclidean&amp;rdquo; distance). This can be seen on the inter-class distance matrices: the values on the diagonal, that characterize the spread of the class, are much bigger for the Euclidean distance than for the cityblock distance.</source>
          <target state="translated">我们将观察噪声添加到这些波形中。我们会产生非常稀疏的噪声：只有6％的时间点包含噪声。结果，此噪声的l1范数（即&amp;ldquo;街区&amp;rdquo;距离）比其l2范数（&amp;ldquo;欧几里得&amp;rdquo;距离）小得多。这可以从类间距离矩阵中看出：代表欧几里得距离的对角线上的值（代表类的扩展），比城市街区距离要大得多。</target>
        </trans-unit>
        <trans-unit id="0408d5d268f82423b1624837fe33bcd8dd7f81b2" translate="yes" xml:space="preserve">
          <source>We also observe that &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; has much smoother predictions than &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. For the plots to be comparable, it is necessary to subtract the average value of the target &lt;code&gt;y&lt;/code&gt;: The &amp;lsquo;recursion&amp;rsquo; method, used by default for &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, does not account for the initial predictor (in our case the average target). Setting the target average to 0 avoids this bias.</source>
          <target state="translated">我们还观察到&lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt; &lt;code&gt;MLPRegressor&lt;/code&gt; 的&lt;/a&gt;预测比&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;平滑得多。为了使图具有可比性，必须减去目标 &lt;code&gt;y&lt;/code&gt; 的平均值：默认情况下，&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;使用的&amp;ldquo;递归&amp;rdquo;方法不考虑初始预测变量（在我们的情况下为平均目标）。将目标平均值设置为0可以避免这种偏差。</target>
        </trans-unit>
        <trans-unit id="5fc281c3e8b120a8bce90f392d5367731bdfa8e6" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for ARD for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">我们还绘制了使用多项式特征扩展的一维回归的ARD的预测和不确定性。注意不确定性在图的右侧开始上升。这是因为这些测试样本在训练样本的范围之外。</target>
        </trans-unit>
        <trans-unit id="bda5a1ba58eab4f9acd36ef763104051f247918e" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for Bayesian Ridge Regression for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">我们还绘制了使用多项式特征扩展的一维回归的贝叶斯岭回归的预测和不确定性。注意不确定性在图的右侧开始上升。这是因为这些测试样本在训练样本的范围之外。</target>
        </trans-unit>
        <trans-unit id="796db2c0bddee3a97c873bf6deae5d571e22b022" translate="yes" xml:space="preserve">
          <source>We also show the tree structure of a model built on all of the features.</source>
          <target state="translated">我们还展示了建立在所有特征上的模型的树结构。</target>
        </trans-unit>
        <trans-unit id="b29f4bff482ccd99c1af96e146d78b516ea318aa" translate="yes" xml:space="preserve">
          <source>We also use warm_start=True which means that the coefficients of the models are reused to initialize the next model fit to speed-up the computation of the full-path.</source>
          <target state="translated">我们还使用了warm_start=True,这意味着模型的系数会被重新用于初始化下一个模型的拟合,以加快全路径的计算速度。</target>
        </trans-unit>
        <trans-unit id="58db9129e28b6367a4c4b1cf6dbdf62e7e4b259e" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes and new features! We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.22.html#changes-0-22&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="translated">我们很高兴地宣布scikit-learn 0.22的发布，其中包含许多错误修复和新功能！我们在下面详细介绍此版本的一些主要功能。有关所有更改的详尽列表，请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.22.html#changes-0-22&quot;&gt;发行说明&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="85e7dd24e85e9c4275de753975b0d57e773f0b77" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.23! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. &lt;strong&gt;For an exhaustive list of all the changes&lt;/strong&gt;, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.23.html#changes-0-23&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="translated">我们很高兴宣布scikit-learn 0.23的发布！添加了许多错误修复和改进，以及一些新的关键功能。我们在下面详细介绍此版本的一些主要功能。&lt;strong&gt;有关所有更改的详尽列表&lt;/strong&gt;，请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.23.html#changes-0-23&quot;&gt;发行说明&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0f24896ee5efd7713cddd30b90821fa31665d4c0" translate="yes" xml:space="preserve">
          <source>We assume that the observations are independent and identically distributed (i.i.d.).</source>
          <target state="translated">我们假设观测值是独立和同分布的(i.i.d.)。</target>
        </trans-unit>
        <trans-unit id="1552999210b3502aaea38a27415ef28fc1fbf44a" translate="yes" xml:space="preserve">
          <source>We build an artificial dataset where the target value is in general positively correlated with the first feature (with some random and non-random variations), and in general negatively correlated with the second feature.</source>
          <target state="translated">我们建立了一个人工数据集,其中目标值一般与第一个特征正相关(有一些随机和非随机变化),一般与第二个特征负相关。</target>
        </trans-unit>
        <trans-unit id="b19a456f973e90e2b4e21cdba9f00b15173fd0ef" translate="yes" xml:space="preserve">
          <source>We call &lt;strong&gt;vectorization&lt;/strong&gt; the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the &lt;strong&gt;Bag of Words&lt;/strong&gt; or &amp;ldquo;Bag of n-grams&amp;rdquo; representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.</source>
          <target state="translated">我们&lt;strong&gt;将向量化&lt;/strong&gt;称为将文本文档集合转换为数字特征向量的一般过程。这种特定的策略（标记化，计数和归一化）称为&amp;ldquo; &lt;strong&gt;词袋&amp;rdquo;&lt;/strong&gt;或&amp;ldquo; n &lt;strong&gt;字词&lt;/strong&gt;袋&amp;rdquo;表示。通过单词出现来描述文档，而完全忽略文档中单词的相对位置信息。</target>
        </trans-unit>
        <trans-unit id="c42f4b562ec41f92f6f2792dcf47013aca7ffcc1" translate="yes" xml:space="preserve">
          <source>We can additionally validate these models by comparing observed and predicted total claim amount over the test and train subsets. We see that, on average, both model tend to underestimate the total claim (but this behavior depends on the amount of regularization).</source>
          <target state="translated">我们还可以通过比较测试和训练子集上观察到的和预测到的总索赔额来验证这些模型。我们看到,平均而言,这两个模型都倾向于低估总索赔额(但这种行为取决于正则化的数量)。</target>
        </trans-unit>
        <trans-unit id="63503e35b14a81c8aca7c86c612044cbc5b560d3" translate="yes" xml:space="preserve">
          <source>We can also export the tree in &lt;a href=&quot;https://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;https://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with &lt;code&gt;conda install python-graphviz&lt;/code&gt;.</source>
          <target state="translated">我们还可以使用&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt;导出器以&lt;a href=&quot;https://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt;格式导出树。如果使用&lt;a href=&quot;https://conda.io&quot;&gt;conda&lt;/a&gt;软件包管理器，则可以使用 &lt;code&gt;conda install python-graphviz&lt;/code&gt; 来安装graphviz二进制文件和python软件包。</target>
        </trans-unit>
        <trans-unit id="096029ae48dbb08bf7baa8066a510ed0e5cf55ab" translate="yes" xml:space="preserve">
          <source>We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, also its standard deviation (return_std=True) or covariance (return_cov=True). Note that at most one of the two can be requested.</source>
          <target state="translated">我们也可以通过使用GP先验来基于非拟合模型进行预测。除了预测分布的均值外,还可以得到它的标准差(return_std=True)或协方差(return_cov=True)。需要注意的是,最多可以要求两者中的一个。</target>
        </trans-unit>
        <trans-unit id="c4674ccfad638384c25bbb5d0cf26d42218171fa" translate="yes" xml:space="preserve">
          <source>We can check the coefficient variability through cross-validation: it is a form of data perturbation (related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Resampling_(statistics)&quot;&gt;resampling&lt;/a&gt;).</source>
          <target state="translated">我们可以通过交叉验证来检查系数的变异性：这是数据扰动的一种形式（与&lt;a href=&quot;https://en.wikipedia.org/wiki/Resampling_(statistics)&quot;&gt;重采样&lt;/a&gt;有关）。</target>
        </trans-unit>
        <trans-unit id="7f60df7f123136fa11f4ddf222fab31a6a72d17d" translate="yes" xml:space="preserve">
          <source>We can choose &lt;code&gt;alpha&lt;/code&gt; to minimize left out error, this time using the diabetes dataset rather than our synthetic data:</source>
          <target state="translated">我们可以选择 &lt;code&gt;alpha&lt;/code&gt; 以最大程度地减少遗漏的错误，这次使用糖尿病数据集而不是我们的综合数据：</target>
        </trans-unit>
        <trans-unit id="a7e4da902c37585f80154c204f27a006746ba8cb" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the average occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="translated">我们可以清楚地看到,房价中位数与收入中位数呈线性关系(左上角),当每户平均居住人数增加时,房价会下降(中上角)。右上图显示,一个地区的房龄对(中位数)房价影响不大;每户平均房间数也是如此。x轴上的勾号代表了训练数据中特征值的分位数。</target>
        </trans-unit>
        <trans-unit id="469d4e6eabf44c56eec1620cbb6087744c30d3f6" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the avg. occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="translated">我们可以清楚地看到,房价中位数与收入中位数呈线性关系(左上角),当每户平均居住人数增加时,房价会下降(中上角)。右上图显示,一个地区的房龄对(中位数)房价影响不大;每户平均房间数也是如此。x轴上的勾号代表了训练数据中特征值的分位数。</target>
        </trans-unit>
        <trans-unit id="c32b4a200d58f731852c3f4a8eefb32ef18f31ed" translate="yes" xml:space="preserve">
          <source>We can keep the remaining rating columns by setting &lt;code&gt;remainder='passthrough'&lt;/code&gt;. The values are appended to the end of the transformation:</source>
          <target state="translated">我们可以通过设置 &lt;code&gt;remainder='passthrough'&lt;/code&gt; 来保留剩余的评分栏。这些值将附加到转换的末尾：</target>
        </trans-unit>
        <trans-unit id="a59ff6e4288992e31a9513b51da5a036927e8ec8" translate="yes" xml:space="preserve">
          <source>We can now load the list of files matching those categories as follows:</source>
          <target state="translated">现在我们可以加载与这些类别相匹配的文件列表,如下所示。</target>
        </trans-unit>
        <trans-unit id="f1f864cfbdff004081b5667459fd9c49d8fcf703" translate="yes" xml:space="preserve">
          <source>We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier:</source>
          <target state="translated">现在,我们可以快速地对一个训练集进行采样,同时保留40%的数据来测试(评估)我们的分类器。</target>
        </trans-unit>
        <trans-unit id="6d11b97d462683ffa27a678189fc90fddb4a8ee5" translate="yes" xml:space="preserve">
          <source>We can observe that the &lt;code&gt;embarked&lt;/code&gt; and &lt;code&gt;sex&lt;/code&gt; columns were tagged as &lt;code&gt;category&lt;/code&gt; columns when loading the data with &lt;code&gt;fetch_openml&lt;/code&gt;. Therefore, we can use this information to dispatch the categorical columns to the &lt;code&gt;categorical_transformer&lt;/code&gt; and the remaining columns to the &lt;code&gt;numerical_transformer&lt;/code&gt;.</source>
          <target state="translated">我们可以观察到， &lt;code&gt;embarked&lt;/code&gt; 和 &lt;code&gt;sex&lt;/code&gt; 栏被标记为 &lt;code&gt;category&lt;/code&gt; 加载的数据时，列 &lt;code&gt;fetch_openml&lt;/code&gt; 。因此，我们可以使用此信息将分类列分派给 &lt;code&gt;categorical_transformer&lt;/code&gt; ，其余列分派给 &lt;code&gt;numerical_transformer&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="850dcea5aea59348ecbdc161cc86fe56ad9b64b5" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">通过投影到线性子空间\（H_L \）上，我们可以将尺寸进一步减小到选定的\（L \），这样可以最大化投影后\（\ mu ^ * _ k \）的方差（实际上，我们正在为转换后的类手段\（\ mu ^ * _ k \））做PCA形式。此\（L \）对应于&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; &lt;/a&gt;方法中使用的 &lt;code&gt;n_components&lt;/code&gt; 参数。有关更多详细信息，请参见&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="92db19023b735fef317e25e1a918af44df264854" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;1&lt;/a&gt; for more details.</source>
          <target state="translated">通过投影到线性子空间\（H_L \）上，我们可以进一步减小尺寸到选定的\（L \），这将最大化投影后\（\ mu ^ * _ k \）的方差（实际上，我们正在为转换后的类手段\（\ mu ^ * _ k \））做PCA形式。此\（L \）对应于&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;transform&lt;/code&gt; &lt;/a&gt;方法中使用的 &lt;code&gt;n_components&lt;/code&gt; 参数。有关更多详细信息，请参见&lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;1&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="32e64fece84cec61516540c9bc9ea581152251c6" translate="yes" xml:space="preserve">
          <source>We can see that &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; preserves the class ratios (approximately 1 / 10) in both train and test dataset.</source>
          <target state="translated">我们可以看到&lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;在训练数据集和测试数据集中都保留了类比率（大约1/10）。</target>
        </trans-unit>
        <trans-unit id="bee45302ee9842b9e6d2e72404b6369d8b7e97cc" translate="yes" xml:space="preserve">
          <source>We can see that for low values of &lt;code&gt;n_components&lt;/code&gt; the distribution is wide with many distorted pairs and a skewed distribution (due to the hard limit of zero ratio on the left as distances are always positives) while for larger values of n_components the distortion is controlled and the distances are well preserved by the random projection.</source>
          <target state="translated">我们可以看到，对于 &lt;code&gt;n_components&lt;/code&gt; 较低的值，分布较宽，具有许多扭曲对和偏斜的分布（由于左侧的零比率的硬性限制，因为距离始终为正值），而对于n_components较大的值，则可以控制失真，并且通过随机投影可以很好地保持距离。</target>
        </trans-unit>
        <trans-unit id="d51b2a4e76fb7eb99807202c5234812c15585e4c" translate="yes" xml:space="preserve">
          <source>We can see that if the maximum depth of the tree (controlled by the &lt;code&gt;max_depth&lt;/code&gt; parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit.</source>
          <target state="translated">我们可以看到，如果将树的最大深度（由 &lt;code&gt;max_depth&lt;/code&gt; 参数控制）设置得太高，则决策树将学习训练数据的细节，并从噪声中学习，即它们过度拟合。</target>
        </trans-unit>
        <trans-unit id="5bc27bfd8c709ab5505734b2124db3dbd09e7af4" translate="yes" xml:space="preserve">
          <source>We can see that, although feature 2 has a strong coefficient on the full model, it conveys little information on &lt;code&gt;y&lt;/code&gt; when considered with feature 1.</source>
          <target state="translated">我们可以看到，尽管特征2在整个模型中具有很强的系数，但是当与特征1一起考虑时，它几乎没有传达关于 &lt;code&gt;y&lt;/code&gt; 的信息。</target>
        </trans-unit>
        <trans-unit id="208e5f1f40787dd5dcd62a253128bd90d5a3414b" translate="yes" xml:space="preserve">
          <source>We can turn those concept as scores &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt;. Both are bounded below by 0.0 and above by 1.0 (higher is better):</source>
          <target state="translated">我们可以将这些概念转化为score &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt;。两者都在0.0之下限制在1.0范围之内（越高越好）：</target>
        </trans-unit>
        <trans-unit id="592289b1a6fdac7a6256bbd4a62b88701d16e505" translate="yes" xml:space="preserve">
          <source>We can use the function &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt;&lt;code&gt;learning_curve&lt;/code&gt;&lt;/a&gt; to generate the values that are required to plot such a learning curve (number of samples that have been used, the average scores on the training sets and the average scores on the validation sets):</source>
          <target state="translated">我们可以使用函数&lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt; &lt;code&gt;learning_curve&lt;/code&gt; &lt;/a&gt;生成绘制这样的学习曲线所需的值（已使用的样本数，训练集的平均分数和验证集的平均分数）：</target>
        </trans-unit>
        <trans-unit id="36de20f1638d2356805015f502415f93be57efc5" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated by the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;), vehicle age (&lt;code&gt;VehAge&lt;/code&gt;) and the insurance bonus/malus (&lt;code&gt;BonusMalus&lt;/code&gt;).</source>
          <target state="translated">我们可以在视觉上比较观察值和预测值，这些值由驾驶员年龄（ &lt;code&gt;DrivAge&lt;/code&gt; ），车辆年龄（ &lt;code&gt;VehAge&lt;/code&gt; ）和保险红利/奖金（ &lt;code&gt;BonusMalus&lt;/code&gt; ）汇总而成。</target>
        </trans-unit>
        <trans-unit id="b0507ecbdf9b58dd0986ef6194b95f4c79d58f52" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated for the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;).</source>
          <target state="translated">我们可以在视觉上比较观察值和预测值，这些值针对驾驶员年龄（ &lt;code&gt;DrivAge&lt;/code&gt; ）进行汇总。</target>
        </trans-unit>
        <trans-unit id="3c55a99ecafce9d11edefa5f7981438b525c546b" translate="yes" xml:space="preserve">
          <source>We classify 8x8 images of digits into two classes: 0-4 against 5-9. The visualization shows coefficients of the models for varying C.</source>
          <target state="translated">我们将8x8的数字图像分为两类。0-4与5-9。可视化显示了不同C的模型的系数。</target>
        </trans-unit>
        <trans-unit id="523600239bb64c3dc717f02d73255329247ddc08" translate="yes" xml:space="preserve">
          <source>We configured a pipeline to scale the numerical input features and tuned the neural network size and learning rate to get a reasonable compromise between training time and predictive performance on a test set.</source>
          <target state="translated">我们配置了一条流水线来扩展数值输入特征,并对神经网络的大小和学习率进行了调整,以在测试集上获得训练时间和预测性能之间的合理折中。</target>
        </trans-unit>
        <trans-unit id="4c2ceff57e3b51d317fe78664f4ea8312ed35966" translate="yes" xml:space="preserve">
          <source>We consider 3 features x_1, x_2, x_3 distributed uniformly over [0, 1], the target depends on them as follows:</source>
          <target state="translated">我们考虑3个特征x_1,x_2,x_3均匀分布在[0,1]上,目标取决于它们,如下。</target>
        </trans-unit>
        <trans-unit id="f5f452641b4c7cde04f8f2f3146b6f807ae80e50" translate="yes" xml:space="preserve">
          <source>We construct the freMTPL2 dataset by joining the freMTPL2freq table, containing the number of claims (&lt;code&gt;ClaimNb&lt;/code&gt;), with the freMTPL2sev table, containing the claim amount (&lt;code&gt;ClaimAmount&lt;/code&gt;) for the same policy ids (&lt;code&gt;IDpol&lt;/code&gt;).</source>
          <target state="translated">我们通过加入freMTPL2freq表，含有权利要求（数构建freMTPL2数据集 &lt;code&gt;ClaimNb&lt;/code&gt; ），与freMTPL2sev表，将含有权利要求量（ &lt;code&gt;ClaimAmount&lt;/code&gt; 针对相同策略ID（） &lt;code&gt;IDpol&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="8b738423194ebf355d81c34c5848e446f6f25c86" translate="yes" xml:space="preserve">
          <source>We create a multi-label dataset, to illustrate the precision-recall in multi-label settings</source>
          <target state="translated">我们创建了一个多标签数据集,以说明在多标签设置中的精确性-回归性</target>
        </trans-unit>
        <trans-unit id="2b472a5c2bccac31b45ff227b2c9930cbabaf64f" translate="yes" xml:space="preserve">
          <source>We create the preprocessing pipelines for both numeric and categorical data.</source>
          <target state="translated">我们创建了数字数据和分类数据的预处理流水线。</target>
        </trans-unit>
        <trans-unit id="6395abe83d6b6a4aa4bc2a531d4a8a4bd65d8620" translate="yes" xml:space="preserve">
          <source>We describe here the mathematical details of the SGD procedure. A good overview with convergence rates can be found in &lt;a href=&quot;#id16&quot; id=&quot;id4&quot;&gt;12&lt;/a&gt;.</source>
          <target state="translated">我们在这里描述SGD程序的数学细节。关于收敛速度的一个很好的概述可以在&lt;a href=&quot;#id16&quot; id=&quot;id4&quot;&gt;12中&lt;/a&gt;找到。</target>
        </trans-unit>
        <trans-unit id="5f9ff80fbe7d3d20607821a1978395dad8f7243a" translate="yes" xml:space="preserve">
          <source>We describe these 3 scenarios in the following subsections.</source>
          <target state="translated">我们在以下几小节中描述这3种情况。</target>
        </trans-unit>
        <trans-unit id="7df3a30efca0a13e3a362147c9be1fa02a3e02fd" translate="yes" xml:space="preserve">
          <source>We don&amp;rsquo;t allow:</source>
          <target state="translated">我们不允许：</target>
        </trans-unit>
        <trans-unit id="484dbca389e5beb12ba95d531ed59ac647119de0" translate="yes" xml:space="preserve">
          <source>We fetch the data from &lt;a href=&quot;http://openml.org/&quot;&gt;OpenML&lt;/a&gt;. Note that setting the parameter &lt;code&gt;as_frame&lt;/code&gt; to True will retrieve the data as a pandas dataframe.</source>
          <target state="translated">我们从&lt;a href=&quot;http://openml.org/&quot;&gt;OpenML&lt;/a&gt;获取数据。请注意，将参数 &lt;code&gt;as_frame&lt;/code&gt; 设置为True会将数据检索为pandas数据框。</target>
        </trans-unit>
        <trans-unit id="43167795aabd351e0317ac3702c4dd940441044a" translate="yes" xml:space="preserve">
          <source>We filter out &lt;code&gt;ClaimAmount == 0&lt;/code&gt; as the Gamma distribution has support on \((0, \infty)\), not \([0, \infty)\).</source>
          <target state="translated">我们过滤掉 &lt;code&gt;ClaimAmount == 0&lt;/code&gt; 因为Gamma分布支持\（（0，\ infty）\），而不是\（[0，\ infty）\）。</target>
        </trans-unit>
        <trans-unit id="c17cba12ad6e5c2f931d1de0fcadd712e7bb0a0a" translate="yes" xml:space="preserve">
          <source>We first find the separating plane with a plain SVC and then plot (dashed) the separating hyperplane with automatically correction for unbalanced classes.</source>
          <target state="translated">我们先用普通SVC找到分离平面,然后绘制(虚线)自动修正不平衡类的分离超平面。</target>
        </trans-unit>
        <trans-unit id="1b6887ebea04d51a67698037588b0795f4c76e3a" translate="yes" xml:space="preserve">
          <source>We first present GBRT for regression, and then detail the classification case.</source>
          <target state="translated">我们首先介绍回归的GBRT,然后详细介绍分类案例。</target>
        </trans-unit>
        <trans-unit id="916afde7457af1caed530318ff87e1a7a139918e" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="translated">我们发现 &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; 可以提供与 &lt;code&gt;max_depth=k-1&lt;/code&gt; 相当的结果，但是训练起来明显更快，但代价是稍高的训练误差。参数 &lt;code&gt;max_leaf_nodes&lt;/code&gt; 对应于&lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]中&lt;/a&gt;有关梯度增强一章中的变量 &lt;code&gt;J&lt;/code&gt; ，并且与R的gbm包中的参数 &lt;code&gt;interaction.depth&lt;/code&gt; 有关，其中 &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9a42cbe6e58382c593ff38ee7701bfc70bcd66e4" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="translated">我们发现 &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; 可以提供与 &lt;code&gt;max_depth=k-1&lt;/code&gt; 相当的结果，但是训练起来明显更快，但代价是训练误差略高。参数 &lt;code&gt;max_leaf_nodes&lt;/code&gt; 对应于&lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id15&quot;&gt;[F2001]中&lt;/a&gt;有关梯度增强一章中的变量 &lt;code&gt;J&lt;/code&gt; ，并且与R的gbm包中的参数 &lt;code&gt;interaction.depth&lt;/code&gt; 有关，其中 &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="72f7189dc223c470430f67b7332d9ced78363339" translate="yes" xml:space="preserve">
          <source>We found that Averaged SGD works best with a larger number of features and a higher eta0</source>
          <target state="translated">我们发现,在特征数量较多、eta0较高的情况下,Averaged SGD效果最好。</target>
        </trans-unit>
        <trans-unit id="2147828a070acc191399f3a8049f6a914fdacd22" translate="yes" xml:space="preserve">
          <source>We further include two random variables that are not correlated in any way with the target variable (&lt;code&gt;survived&lt;/code&gt;):</source>
          <target state="translated">我们进一步包括两个随机变量，它们与目标变量（ &lt;code&gt;survived&lt;/code&gt; ）没有任何关系：</target>
        </trans-unit>
        <trans-unit id="ecc641e4f0c3be544f8ba1b6978d12b64c778e22" translate="yes" xml:space="preserve">
          <source>We generate data from three groups of waveforms. Two of the waveforms (waveform 1 and waveform 2) are proportional one to the other. The cosine distance is invariant to a scaling of the data, as a result, it cannot distinguish these two waveforms. Thus even with no noise, clustering using this distance will not separate out waveform 1 and 2.</source>
          <target state="translated">我们从三组波形中生成数据。其中有两个波形(波形1和波形2)是相互成比例的。余弦距离对数据的缩放是不变的,因此,它不能区分这两个波形。因此,即使在没有噪声的情况下,用这个距离进行聚类也不能将波形1和波形2分离出来。</target>
        </trans-unit>
        <trans-unit id="03835cacd7901d07f747c14f209b80543758c4fd" translate="yes" xml:space="preserve">
          <source>We have seen that some estimators can transform data and that some estimators can predict variables. We can also create combined estimators:</source>
          <target state="translated">我们已经看到,有些估计器可以转换数据,有些估计器可以预测变量。我们还可以创建组合估计器。</target>
        </trans-unit>
        <trans-unit id="996013b3c282443801da622c65fee1deca3cef01" translate="yes" xml:space="preserve">
          <source>We have seen that sparsity could be used to mitigate the curse of dimensionality, &lt;em&gt;i.e&lt;/em&gt; an insufficient amount of observations compared to the number of features. Another approach is to merge together similar features: &lt;strong&gt;feature agglomeration&lt;/strong&gt;. This approach can be implemented by clustering in the feature direction, in other words clustering the transposed data.</source>
          <target state="translated">我们已经看到稀疏性可以用来减轻维数的诅咒，&lt;em&gt;即&lt;/em&gt;与特征数量相比，观测值不足。另一种方法是将相似的特征融合在一起：&lt;strong&gt;特征集聚&lt;/strong&gt;。可以通过在特征方向上进行聚类（换句话说，对转置后的数据进行聚类）来实现此方法。</target>
        </trans-unit>
        <trans-unit id="f70b46435230cf70b0b3d749ceef620b9bcdee9d" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="translated">我们特别放弃了两篇论文的作者所使用的优化，即在特定情况下使用QR分解来降低SVD的算法复杂性。该技术的来源是《 &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt; 。该技术已被省略，因为仅在分解 &lt;code&gt;n_samples&lt;/code&gt; （行）&amp;gt; = 5/3 * &lt;code&gt;n_features&lt;/code&gt; （列）的矩阵时才有优势，并且会损害所实现算法的可读性。如果认为必要的话，这将是未来优化的好机会。</target>
        </trans-unit>
        <trans-unit id="ac54e4e32d1eea16ad8753f857ea27f0962cb421" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;em&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/em&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="translated">我们特别放弃了两篇论文的作者所使用的优化，即在特定情况下使用QR分解来降低SVD的算法复杂性。该技术的来源是《&lt;em&gt;矩阵计算》，第三版，G。Holub和C. Van Loan，第5章，第5.4.4节，第252-253页。&lt;/em&gt;。该技术已被省略，因为仅当分解 &lt;code&gt;n_samples&lt;/code&gt; （行）&amp;gt; = 5/3 * &lt;code&gt;n_features&lt;/code&gt; （列）的矩阵时才有优势，并且会损害所实现算法的可读性。如果认为必要的话，这将是未来优化的好机会。</target>
        </trans-unit>
        <trans-unit id="db298eced453f06f8efed43be73a03415c98ca01" translate="yes" xml:space="preserve">
          <source>We have to reconstruct model and parameters to make sure we stay in sync with the python object.</source>
          <target state="translated">我们必须重建模型和参数,以确保我们与python对象保持同步。</target>
        </trans-unit>
        <trans-unit id="ca5f08fcacf0548e5e0c637b82c4414e44704050" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) (instead of \(C\)) which controls the number of support vectors and &lt;em&gt;margin errors&lt;/em&gt;: \(\nu \in (0, 1]\) is an upper bound on the fraction of margin errors and a lower bound of the fraction of support vectors. A margin error corresponds to a sample that lies on the wrong side of its margin boundary: it is either misclassified, or it is correctly classified but does not lie beyond the margin.</source>
          <target state="translated">我们引入了一个新参数\（\ nu \）（而不是\（C \）），该参数控制支持向量的数量和&lt;em&gt;边距误差&lt;/em&gt;：\（\ nu \ in（0，1] \）是边际误差的一部分和支持向量的下限的边界边际误差对应于位于其边际边界错误一侧的样本：它被错误分类，或者被正确分类，但没有超出边际。</target>
        </trans-unit>
        <trans-unit id="f2683785e1f3e3ccb40d3941fed7d5fa67a33cfc" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) which controls the number of support vectors and training errors. The parameter \(\nu \in (0, 1]\) is an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.</source>
          <target state="translated">我们引入一个新的参数\(\nu\)来控制支持向量和训练错误的数量。这个参数(nu(0,1))是训练错误分数的上限和支持向量分数的下限。</target>
        </trans-unit>
        <trans-unit id="60ccb05e0b7446f76670a424f0fabb01d1ca71b3" translate="yes" xml:space="preserve">
          <source>We need a vectorized version of the image. &lt;code&gt;'rescaled_coins'&lt;/code&gt; is a down-scaled version of the coins image to speed up the process:</source>
          <target state="translated">我们需要图像的矢量化版本。 &lt;code&gt;'rescaled_coins'&lt;/code&gt; 是硬币图像的缩小版本，以加快处理速度：</target>
        </trans-unit>
        <trans-unit id="284f00654c2880797bacd24e85e3bc2f5ec8be8d" translate="yes" xml:space="preserve">
          <source>We no longer get the collisions, but this comes at the expense of a much larger dimensionality of the output space. Of course, other terms than the 19 used here might still collide with each other.</source>
          <target state="translated">我们不再得到碰撞,但这是以输出空间的维度大大增加为代价的。当然,除了这里使用的19个术语外,其他术语仍可能相互碰撞。</target>
        </trans-unit>
        <trans-unit id="a19ee5584b95e367f6c768452e1c513e3bb433ea" translate="yes" xml:space="preserve">
          <source>We now inspect the coefficients across several cross-validation folds.</source>
          <target state="translated">我们现在检查几个交叉验证折线的系数。</target>
        </trans-unit>
        <trans-unit id="9d37726e46e38fa3806c6050ccef5f0b5ccde0ad" translate="yes" xml:space="preserve">
          <source>We now provide a &lt;code&gt;pytest&lt;/code&gt; specific decorator which allows &lt;code&gt;pytest&lt;/code&gt; to run all checks independently and report the checks that are failing.</source>
          <target state="translated">现在，我们提供了 &lt;code&gt;pytest&lt;/code&gt; 特定的装饰器，该装饰器允许 &lt;code&gt;pytest&lt;/code&gt; 独立运行所有检查并报告失败的检查。</target>
        </trans-unit>
        <trans-unit id="b22fff2428986dd4d9e25659e5099f6fa799f31a" translate="yes" xml:space="preserve">
          <source>We now support imputation for completing missing values using k-Nearest Neighbors.</source>
          <target state="translated">我们现在支持使用k-最近邻来完成缺失值的推算。</target>
        </trans-unit>
        <trans-unit id="3b146f434972f2182b845909391decf90277ad41" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the perplexity value increases.</source>
          <target state="translated">我们观察到,随着迷惑值的增加,形状有越来越清晰的趋势。</target>
        </trans-unit>
        <trans-unit id="0e7a6d4d2e128e719f76bf1799c4515162612bfb" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the preplexity value increases.</source>
          <target state="translated">我们观察到,随着复杂度值的增加,形状趋于清晰。</target>
        </trans-unit>
        <trans-unit id="3705c31d0fb66694929007b0cdad834fbbaf06c2" translate="yes" xml:space="preserve">
          <source>We plot partial dependence curves for features &amp;ldquo;age&amp;rdquo; and &amp;ldquo;bmi&amp;rdquo; (body mass index) for the decision tree. With two features, &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; expects to plot two curves. Here the plot function place a grid of two plots using the space defined by &lt;code&gt;ax&lt;/code&gt; .</source>
          <target state="translated">我们为决策树的&amp;ldquo;年龄&amp;rdquo;和&amp;ldquo; bmi&amp;rdquo;（体重指数）特征绘制了部分依赖曲线。具有两个功能，&lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt; &lt;code&gt;plot_partial_dependence&lt;/code&gt; &lt;/a&gt;期望绘制两条曲线。这里的plot函数使用 &lt;code&gt;ax&lt;/code&gt; 定义的空间放置两个图的网格。</target>
        </trans-unit>
        <trans-unit id="b4e7d2188aa62b346706f6bd2a1ae94095756883" translate="yes" xml:space="preserve">
          <source>We plot predicted labels on both training and held out test data using a variety of GMM covariance types on the iris dataset. We compare GMMs with spherical, diagonal, full, and tied covariance matrices in increasing order of performance. Although one would expect full covariance to perform best in general, it is prone to overfitting on small datasets and does not generalize well to held out test data.</source>
          <target state="translated">我们绘制了使用各种GMM协方差类型在虹膜数据集上对训练和持出测试数据的预测标签。我们比较了GMM与球形、对角线、全协方差和并列协方差矩阵的性能递增顺序。虽然人们期望全协方差在一般情况下表现最好,但它在小数据集上容易过度拟合,并且不能很好地推广到保持出来的测试数据上。</target>
        </trans-unit>
        <trans-unit id="7ead9de71a0f24e08ddaae8aaa6dd6470443d3a2" translate="yes" xml:space="preserve">
          <source>We recommend &lt;a href=&quot;#id15&quot; id=&quot;id6&quot;&gt;13&lt;/a&gt; and &lt;a href=&quot;#id16&quot; id=&quot;id7&quot;&gt;14&lt;/a&gt; as good references for the theory and practicalities of SVMs.</source>
          <target state="translated">我们建议&lt;a href=&quot;#id15&quot; id=&quot;id6&quot;&gt;13&lt;/a&gt;和&lt;a href=&quot;#id16&quot; id=&quot;id7&quot;&gt;14&lt;/a&gt;作为SVM的理论和实用性的良好参考。</target>
        </trans-unit>
        <trans-unit id="8a444360e57dc0870f14b3c959a7b626922e7571" translate="yes" xml:space="preserve">
          <source>We see that &lt;code&gt;SVC&lt;/code&gt; doesn&amp;rsquo;t do much better than a dummy classifier. Now, let&amp;rsquo;s change the kernel:</source>
          <target state="translated">我们看到 &lt;code&gt;SVC&lt;/code&gt; 并没有比虚拟分类器好得多。现在，让我们更改内核：</target>
        </trans-unit>
        <trans-unit id="9619f66671fbeb88bbee2c1b3d850c22bdb6ab25" translate="yes" xml:space="preserve">
          <source>We see that the accuracy was boosted to almost 100%. A cross validation strategy is recommended for a better estimate of the accuracy, if it is not too CPU costly. For more information see the &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; section. Moreover if you want to optimize over the parameter space, it is highly recommended to use an appropriate methodology; see the &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt; section for details.</source>
          <target state="translated">我们看到准确性提高到几乎100％。如果CPU的成本不太高，建议使用交叉验证策略以更好地估计准确性。有关更多信息，请参见&amp;ldquo; &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;交叉验证：评估估计器性能&amp;rdquo;&lt;/a&gt;部分。此外，如果要在参数空间上进行优化，强烈建议使用适当的方法。有关详细信息，请参见&lt;a href=&quot;grid_search#grid-search&quot;&gt;调整估计器的超参数&lt;/a&gt;部分。</target>
        </trans-unit>
        <trans-unit id="b05b900d7824680be8b5fe4195a1e87507494a4c" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="translated">我们看到，所得到的&lt;em&gt;多项式回归&lt;/em&gt;在我们上面考虑的同一类线性模型中（即该模型在\（w \）中是线性的），并且可以通过相同的技术来求解。通过考虑使用这些基本函数构建的高维空间中的线性拟合，该模型可以灵活地适应更大范围的数据。</target>
        </trans-unit>
        <trans-unit id="d680bb4e5101fe3a9df93911d26cfa982767e679" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we&amp;rsquo;d considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="translated">我们看到，所得的&lt;em&gt;多项式回归&lt;/em&gt;属于我们上面考虑的同一类线性模型（即，该模型在\（w \）中是线性的），并且可以通过相同的技术来求解。通过考虑使用这些基本函数构建的高维空间中的线性拟合，该模型可以灵活地适应更大范围的数据。</target>
        </trans-unit>
        <trans-unit id="1a0e7af8231b7a460dcfd9acf44c6323ad1ea844" translate="yes" xml:space="preserve">
          <source>We selected two sets of two variables from the Boston housing data set as an illustration of what kind of analysis can be done with several outlier detection tools. For the purpose of visualization, we are working with two-dimensional examples, but one should be aware that things are not so trivial in high-dimension, as it will be pointed out.</source>
          <target state="translated">我们从波士顿住房数据集中选取了两组两个变量,来说明用几种离群值检测工具可以做什么样的分析。为了可视化的目的,我们使用的是二维的例子,但我们应该意识到,在高维的情况下,事情并不那么琐碎,这一点将被指出。</target>
        </trans-unit>
        <trans-unit id="940e7a9289cb117779f9b0e089fc6f41ec456057" translate="yes" xml:space="preserve">
          <source>We should also note that small differences in scores results from the random splits of the cross-validation procedure. Those spurious variations can be smoothed out by increasing the number of CV iterations &lt;code&gt;n_splits&lt;/code&gt; at the expense of compute time. Increasing the value number of &lt;code&gt;C_range&lt;/code&gt; and &lt;code&gt;gamma_range&lt;/code&gt; steps will increase the resolution of the hyper-parameter heat map.</source>
          <target state="translated">我们还应该注意，分数的微小差异是由交叉验证过程的随机分裂造成的。可以通过增加CV迭代次数 &lt;code&gt;n_splits&lt;/code&gt; 来消除那些虚假的变化，但会浪费计算时间。增加 &lt;code&gt;C_range&lt;/code&gt; 和 &lt;code&gt;gamma_range&lt;/code&gt; 步骤的值数量将增加超参数热图的分辨率。</target>
        </trans-unit>
        <trans-unit id="1cbc5d306e08afa1d68b1045fc6a567611cf26d2" translate="yes" xml:space="preserve">
          <source>We show that linear_model.Lasso provides the same results for dense and sparse data and that in the case of sparse data the speed is improved.</source>
          <target state="translated">我们表明,linear_model.Lasso对密集数据和稀疏数据提供了同样的结果,而且在稀疏数据的情况下,速度得到了提高。</target>
        </trans-unit>
        <trans-unit id="971fe5258bb92dd314d2f061a23d12526523f329" translate="yes" xml:space="preserve">
          <source>We split the sample into a train and a test dataset. Only the train dataset will be used in the following exploratory analysis. This is a way to emulate a real situation where predictions are performed on an unknown target, and we don&amp;rsquo;t want our analysis and decisions to be biased by our knowledge of the test data.</source>
          <target state="translated">我们将样本分为训练和测试数据集。在下面的探索性分析中，将仅使用火车数据集。这是一种模拟在未知目标上执行预测的真实情况的方法，并且我们不希望我们的测试数据知识对我们的分析和决策产生偏见。</target>
        </trans-unit>
        <trans-unit id="9729e48da1dbe46bc3dec3ab22ad1f98a7a56bb9" translate="yes" xml:space="preserve">
          <source>We start by modeling the target variable with the (l2 penalized) least squares linear regression model, more comonly known as Ridge regression. We use a low penalization &lt;code&gt;alpha&lt;/code&gt;, as we expect such a linear model to under-fit on such a large dataset.</source>
          <target state="translated">我们首先使用（l2罚分）最小二乘线性回归模型对目标变量进行建模，此模型通常称为Ridge回归。我们使用低惩罚的 &lt;code&gt;alpha&lt;/code&gt; 值，因为我们期望这样的线性模型不能适合如此大的数据集。</target>
        </trans-unit>
        <trans-unit id="efbf964638e7ca0fbdc3e1bd2a5029a9cbed6b8c" translate="yes" xml:space="preserve">
          <source>We start by training a label propagation model with only 10 labeled points, then we select the top five most uncertain points to label. Next, we train with 15 labeled points (original 10 + 5 new ones). We repeat this process four times to have a model trained with 30 labeled examples. Note you can increase this to label more than 30 by changing &lt;code&gt;max_iterations&lt;/code&gt;. Labeling more than 30 can be useful to get a sense for the speed of convergence of this active learning technique.</source>
          <target state="translated">我们首先训练仅带有10个标记点的标签传播模型，然后选择前五个不确定性最高的点进行标记。接下来，我们训练15个带标记的点（原始10个+ 5个新点）。我们重复此过程四次，以训练带有30个带标签的示例的模型。请注意，您可以通过更改 &lt;code&gt;max_iterations&lt;/code&gt; 将其增加以标记30个以上。标记超过30个可能有助于了解这种主动学习技术的融合速度。</target>
        </trans-unit>
        <trans-unit id="b926aa4a7c89ca684b4dc714781356e70fac60ed" translate="yes" xml:space="preserve">
          <source>We thus transform the KDD Data set into two different data sets: SA and SF.</source>
          <target state="translated">因此,我们将KDD数据集转化为两个不同的数据集。SA和SF。</target>
        </trans-unit>
        <trans-unit id="c5856ddc1b1774be0ac4aef6a043703c4e71a274" translate="yes" xml:space="preserve">
          <source>We train a random forest classifier and create a plot comparing it to the SVC ROC curve. Notice how &lt;code&gt;svc_disp&lt;/code&gt; uses &lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; to plot the SVC ROC curve without recomputing the values of the roc curve itself. Furthermore, we pass &lt;code&gt;alpha=0.8&lt;/code&gt; to the plot functions to adjust the alpha values of the curves.</source>
          <target state="translated">我们训练一个随机森林分类器，并创建一个将其与SVC ROC曲线进行比较的图。注意 &lt;code&gt;svc_disp&lt;/code&gt; 如何使用&lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay.plot&quot;&gt; &lt;code&gt;plot&lt;/code&gt; &lt;/a&gt;来绘制SVC ROC曲线，而无需重新计算roc曲线本身的值。此外，我们将 &lt;code&gt;alpha=0.8&lt;/code&gt; 传递给绘图函数以调整曲线的alpha值。</target>
        </trans-unit>
        <trans-unit id="38d99d5f10e1040b13651031a8f4b3d74d91ef9a" translate="yes" xml:space="preserve">
          <source>We train and test the datasets with 15 different classification models and get performance results for each model.</source>
          <target state="translated">我们用15个不同的分类模型对数据集进行训练和测试,并得到每个模型的性能结果。</target>
        </trans-unit>
        <trans-unit id="f695efb4e75bb85159c9142762a64409b0330558" translate="yes" xml:space="preserve">
          <source>We use &lt;a href=&quot;../../modules/generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; to learn an embedding and plot the points after the transformation. We then take the embedding and find the nearest neighbors.</source>
          <target state="translated">我们使用&lt;a href=&quot;../../modules/generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; &lt;/a&gt;学习嵌入并在转换后绘制点。然后，我们进行嵌入并找到最近的邻居。</target>
        </trans-unit>
        <trans-unit id="0b8cd078987f149b454cdac8f89f7fb050617be5" translate="yes" xml:space="preserve">
          <source>We use &lt;code&gt;ClaimNb&lt;/code&gt; as &lt;code&gt;sample_weight&lt;/code&gt; to account for policies that contain more than one claim.</source>
          <target state="translated">我们使用 &lt;code&gt;ClaimNb&lt;/code&gt; 作为 &lt;code&gt;sample_weight&lt;/code&gt; 来说明包含多个索赔的保单。</target>
        </trans-unit>
        <trans-unit id="13122bf873819e99a4ec7d32c926bbee95474f9b" translate="yes" xml:space="preserve">
          <source>We use a GridSearchCV to set the dimensionality of the PCA</source>
          <target state="translated">我们使用GridSearchCV来设置PCA的维度。</target>
        </trans-unit>
        <trans-unit id="61efd119ac2fcb7bb96489a56e2c262d1e964f20" translate="yes" xml:space="preserve">
          <source>We use a biased estimator for the standard deviation, equivalent to &lt;code&gt;numpy.std(x, ddof=0)&lt;/code&gt;. Note that the choice of &lt;code&gt;ddof&lt;/code&gt; is unlikely to affect model performance.</source>
          <target state="translated">对于标准偏差，我们使用了一个偏差估算器，它等于 &lt;code&gt;numpy.std(x, ddof=0)&lt;/code&gt; 。请注意，选择 &lt;code&gt;ddof&lt;/code&gt; 不太可能影响模型性能。</target>
        </trans-unit>
        <trans-unit id="83c28baded6fcaa48849ef740f04075945b33344" translate="yes" xml:space="preserve">
          <source>We use clustering to group together quotes that behave similarly. Here, amongst the &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;various clustering techniques&lt;/a&gt; available in the scikit-learn, we use &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Affinity Propagation&lt;/a&gt; as it does not enforce equal-size clusters, and it can choose automatically the number of clusters from the data.</source>
          <target state="translated">我们使用聚类将表现相似的报价分组在一起。在这里，在scikit-learn中可用的&lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;各种聚类技术&lt;/a&gt;中，我们使用&amp;ldquo; &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;相似性传播&amp;rdquo;，&lt;/a&gt;因为它不强制执行大小相等的聚类，并且可以从数据中自动选择聚类数量。</target>
        </trans-unit>
        <trans-unit id="78d7bc0e66fad92fa188a5bbaa0a7aaa581101c6" translate="yes" xml:space="preserve">
          <source>We use sparse inverse covariance estimation to find which quotes are correlated conditionally on the others. Specifically, sparse inverse covariance gives us a graph, that is a list of connection. For each symbol, the symbols that it is connected too are those useful to explain its fluctuations.</source>
          <target state="translated">我们使用稀疏反协方差估计来寻找哪些行情对其他行情有条件的相关性。具体来说,稀疏反协方差给我们提供了一个图,也就是一个连接的列表。对于每个符号来说,它所连接的符号也是那些对解释其波动有用的符号。</target>
        </trans-unit>
        <trans-unit id="0bc034dd2aa1865c002d495e95115e5b8c709a84" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the 20 newsgroups text document (TF-IDF word frequencies) dataset or on the digits dataset:</source>
          <target state="translated">我们在20个新闻组文本文档(TF-IDF词频)数据集或数字数据集上验证了上述界限。</target>
        </trans-unit>
        <trans-unit id="4e3f49993eefd3c100d45584ffc552355d0d52e7" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the digits dataset or on the 20 newsgroups text document (TF-IDF word frequencies) dataset:</source>
          <target state="translated">我们在数字数据集或20个新闻组文本文档(TF-IDF词频)数据集上验证上述界限。</target>
        </trans-unit>
        <trans-unit id="63b1da5381eb76c29e4f139b0a4a0f6fa6f76bca" translate="yes" xml:space="preserve">
          <source>We want to calculate the distance between the Ezeiza Airport (Buenos Aires, Argentina) and the Charles de Gaulle Airport (Paris, France)</source>
          <target state="translated">我们想计算埃塞萨机场(阿根廷布宜诺斯艾利斯)和戴高乐机场(法国巴黎)之间的距离。</target>
        </trans-unit>
        <trans-unit id="4bd2e73735072e414ab7c853666f3b851cc359c1" translate="yes" xml:space="preserve">
          <source>We want to compare the performance of the MiniBatchKMeans and KMeans: the MiniBatchKMeans is faster, but gives slightly different results (see &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Mini Batch K-Means&lt;/a&gt;).</source>
          <target state="translated">我们想比较MiniBatchKMeans和KMeans的性能：MiniBatchKMeans更快，但给出的结果略有不同（请参阅&lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Mini Batch K-Means&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="76b3c7c02e156a1d558e413ab95dd6c124236bdc" translate="yes" xml:space="preserve">
          <source>We will also create a transformer that extracts the length of the text and the number of sentences.</source>
          <target state="translated">我们还将创建一个变压器,提取文本的长度和句子的数量。</target>
        </trans-unit>
        <trans-unit id="b8ae1ec8b6dd301757e7e59be0a9aeff645f7f18" translate="yes" xml:space="preserve">
          <source>We will cluster a set of data, first with KMeans and then with MiniBatchKMeans, and plot the results. We will also plot the points that are labelled differently between the two algorithms.</source>
          <target state="translated">我们将对一组数据进行聚类,先用KMeans,再用MiniBatchKMeans,并绘制结果。我们还将绘制两种算法之间标注不同的点。</target>
        </trans-unit>
        <trans-unit id="de730c276ad64150c605a83740871002db6683ff" translate="yes" xml:space="preserve">
          <source>We will compare the performance of both approaches. To quantify the performance of both models, one can compute the mean deviance of the train and test data assuming a Compound Poisson-Gamma distribution of the total claim amount. This is equivalent to a Tweedie distribution with a &lt;code&gt;power&lt;/code&gt; parameter between 1 and 2.</source>
          <target state="translated">我们将比较两种方法的性能。为了量化两个模型的性能，可以假设总索赔额的复合Poisson-Gamma分布来计算列车和测试数据的平均偏差。这等效于 &lt;code&gt;power&lt;/code&gt; 参数在1到2之间的Tweedie分布。</target>
        </trans-unit>
        <trans-unit id="b4cfcf9a2f9d6095c0707be11ca996fe9017bf9d" translate="yes" xml:space="preserve">
          <source>We will probably have to use an estimator or a parametrization of the current estimator that can learn more complex concepts (i.e. has a lower bias). If the training score is much greater than the validation score for the maximum number of training samples, adding more training samples will most likely increase generalization. In the following plot you can see that the SVM could benefit from more training examples.</source>
          <target state="translated">我们可能要使用一个估计器或当前估计器的参数化,它可以学习更复杂的概念(即具有较低的偏差)。如果最大训练样本数的训练得分远大于验证得分,那么增加更多的训练样本很可能会增加泛化。在下面的图中,你可以看到,SVM可以从更多的训练样本中受益。</target>
        </trans-unit>
        <trans-unit id="3f09acb611dde4d0822059b7dd910a6bf0d4be22" translate="yes" xml:space="preserve">
          <source>We will review here the orders of magnitude you can expect from a number of scikit-learn estimators in different contexts and provide some tips and tricks for overcoming performance bottlenecks.</source>
          <target state="translated">我们将在这里回顾一下在不同情况下你可以从一些scikit-learn估计器中得到的数量级,并提供一些克服性能瓶颈的技巧和窍门。</target>
        </trans-unit>
        <trans-unit id="7c06ec0897b21dbb460bd6d56256bf3c61c9d6ea" translate="yes" xml:space="preserve">
          <source>We will train our classifier with the following features:</source>
          <target state="translated">我们将用以下特征来训练我们的分类器。</target>
        </trans-unit>
        <trans-unit id="3be1dd4cfac1d63b4ce361f8740d86e98582c7b5" translate="yes" xml:space="preserve">
          <source>We will use &lt;a href=&quot;http://jse.amstat.org/v19n3/decock.pdf&quot;&gt;Ames Housing&lt;/a&gt; dataset which was first compiled by Dean De Cock and became better known after it was used in Kaggle challenge. It is a set of 1460 residential homes in Ames, Iowa, each described by 80 features. We will use it to predict the final logarithmic price of the houses. In this example we will use only 20 most interesting features chosen using GradientBoostingRegressor() and limit number of entries (here we won&amp;rsquo;t go into the details on how to select the most interesting features).</source>
          <target state="translated">我们将使用由Dean De Cock首次编译的&lt;a href=&quot;http://jse.amstat.org/v19n3/decock.pdf&quot;&gt;Ames Housing&lt;/a&gt;数据集，该数据集在Kaggle挑战赛中使用后就广为人知。它是爱荷华州埃姆斯市的一套1460套住宅，每套都有80个功能。我们将使用它来预测房屋的最终对数价格。在此示例中，我们将仅使用通过GradientBoostingRegressor（）选择的20个最有趣的功能，并限制条目数（此处我们将不介绍如何选择最有趣的功能的细节）。</target>
        </trans-unit>
        <trans-unit id="037b81bcdb33690797b74b53d8be309b975609a6" translate="yes" xml:space="preserve">
          <source>We will use data from the &lt;a href=&quot;https://www.openml.org/d/534&quot;&gt;&amp;ldquo;Current Population Survey&amp;rdquo;&lt;/a&gt; from 1985 to predict wage as a function of various features such as experience, age, or education.</source>
          <target state="translated">我们将使用1985年&lt;a href=&quot;https://www.openml.org/d/534&quot;&gt;&amp;ldquo;当前人口调查&amp;rdquo;中的&lt;/a&gt;数据来预测工资，这些工资是各种特征的函数，例如经验，年龄或教育程度。</target>
        </trans-unit>
        <trans-unit id="66b44f9dbf66aa535fbabfa2d804ce4636c53d36" translate="yes" xml:space="preserve">
          <source>We will use the &lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;20 newsgroups dataset&lt;/a&gt;, which comprises posts from newsgroups on 20 topics. This dataset is split into train and test subsets based on messages posted before and after a specific date. We will only use posts from 2 categories to speed up running time.</source>
          <target state="translated">我们将使用&lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;20个新闻组数据集&lt;/a&gt;，其中包含来自20个主题的新闻组中的帖子。该数据集根据在特定日期之前和之后发布的消息分为训练和测试子集。我们将只使用2个类别的帖子来加快运行时间。</target>
        </trans-unit>
        <trans-unit id="889d3befa932d46595e6941bb656f25678ccbe94" translate="yes" xml:space="preserve">
          <source>We will use two datasets: Diabetes dataset which consists of 10 feature variables collected from diabetes patients with an aim to predict disease progression and California Housing dataset for which the target is the median house value for California districts.</source>
          <target state="translated">我们将使用两个数据集。糖尿病数据集由从糖尿病患者收集的10个特征变量组成,目的是预测疾病的进展;加州住房数据集的目标是加州各区的房屋价值中位数。</target>
        </trans-unit>
        <trans-unit id="7968cd3ef765f8c808b9f8985bbceb6fcebbccfc" translate="yes" xml:space="preserve">
          <source>We will work with the diabetes dataset which consists of 10 features collected from a cohort of diabetes patients. The target is a quantitative measure of disease progression one year after baseline.</source>
          <target state="translated">我们将使用糖尿病数据集,其中包括从糖尿病患者队列中收集的10个特征。目标是对基线一年后疾病进展的定量测量。</target>
        </trans-unit>
        <trans-unit id="5ab95440492dec088ab7d086a3622b86acadc7e7" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ll define a function that lets us visualize the behavior of each cross-validation object. We&amp;rsquo;ll perform 4 splits of the data. On each split, we&amp;rsquo;ll visualize the indices chosen for the training set (in blue) and the test set (in red).</source>
          <target state="translated">我们将定义一个函数，使我们可以可视化每个交叉验证对象的行为。我们将对数据进行4次拆分。在每个分组上，我们将为训练集（蓝色）和测试集（红色）可视化选择的索引。</target>
        </trans-unit>
        <trans-unit id="70c023ae490fc71ae664cdd80527ab708a5db4b9" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ve already encountered some parameters such as &lt;code&gt;use_idf&lt;/code&gt; in the &lt;code&gt;TfidfTransformer&lt;/code&gt;. Classifiers tend to have many parameters as well; e.g., &lt;code&gt;MultinomialNB&lt;/code&gt; includes a smoothing parameter &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;SGDClassifier&lt;/code&gt; has a penalty parameter &lt;code&gt;alpha&lt;/code&gt; and configurable loss and penalty terms in the objective function (see the module documentation, or use the Python &lt;code&gt;help&lt;/code&gt; function to get a description of these).</source>
          <target state="translated">我们已经在 &lt;code&gt;use_idf&lt;/code&gt; 中遇到了一些参数，例如 &lt;code&gt;TfidfTransformer&lt;/code&gt; 。分类器也往往具有许多参数。例如， &lt;code&gt;MultinomialNB&lt;/code&gt; 包括平滑参数 &lt;code&gt;alpha&lt;/code&gt; 和 &lt;code&gt;SGDClassifier&lt;/code&gt; 具有惩罚参数 &lt;code&gt;alpha&lt;/code&gt; 的目标函数和可配置的损失和惩罚项（见模块文档，或使用Python &lt;code&gt;help&lt;/code&gt; 函数来获取这些的说明）。</target>
        </trans-unit>
        <trans-unit id="e255008aad692a93735d4b63680bd4a96fdd74f7" translate="yes" xml:space="preserve">
          <source>Weight function used in prediction. Possible values:</source>
          <target state="translated">预测中使用的权重函数。可能的值:</target>
        </trans-unit>
        <trans-unit id="96df76d7fa199e301349be570d5ef4d0bb6a7f3d" translate="yes" xml:space="preserve">
          <source>Weight given to each sample.</source>
          <target state="translated">给予每个样本的重量。</target>
        </trans-unit>
        <trans-unit id="a7a3ce3e7a16ef99378bfef64690454462da25e9" translate="yes" xml:space="preserve">
          <source>Weight matrix, where n_features in the number of visible units and n_components is the number of hidden units.</source>
          <target state="translated">权重矩阵,其中n_features为可见单元数,n_components为隐藏单元数。</target>
        </trans-unit>
        <trans-unit id="77c7b393c2f516d7fd42969c3e5ce51aceb4c82c" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with a negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="translated">每个样本的权重，使得重量至少为 &lt;code&gt;min_samples&lt;/code&gt; 的样本本身就是核心样本；负重量的样本可能会阻止其eps邻居成为核心。请注意，权重是绝对的，默认为1。</target>
        </trans-unit>
        <trans-unit id="d0664e46a183d0a2a2e3afcbc3b6c5ba30a9d4ef" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="translated">每个样品的重量，以使重量至少为 &lt;code&gt;min_samples&lt;/code&gt; 的样品本身就是核心样品；负重量的样本可能会阻止其eps邻居成为核心。请注意，权重是绝对的，默认为1。</target>
        </trans-unit>
        <trans-unit id="5cc536fd8cf249ec4c2e295665e0070f1b9cec67" translate="yes" xml:space="preserve">
          <source>Weight of precision in harmonic mean.</source>
          <target state="translated">精度在谐波平均值中的比重。</target>
        </trans-unit>
        <trans-unit id="6cd90e03c276712f974984f65620519bcea49500" translate="yes" xml:space="preserve">
          <source>Weight vector(s).</source>
          <target state="translated">权重向量。</target>
        </trans-unit>
        <trans-unit id="ac0d2c9a738f9c54a5d208ddac8f22019ff9c627" translate="yes" xml:space="preserve">
          <source>Weight, Waist and Pulse.</source>
          <target state="translated">体重、腰围和脉搏。</target>
        </trans-unit>
        <trans-unit id="c74e4e7c5caf95682fb65872b5814741f06c7fac" translate="yes" xml:space="preserve">
          <source>Weighted average</source>
          <target state="translated">加权平均数</target>
        </trans-unit>
        <trans-unit id="39392047d0260b6fc1e042825fdae9116d630e28" translate="yes" xml:space="preserve">
          <source>Weighted average probability for each class per sample.</source>
          <target state="translated">每个班级每个样本的加权平均概率。</target>
        </trans-unit>
        <trans-unit id="62deefeab258040887cdf6743a94e11a29168c6f" translate="yes" xml:space="preserve">
          <source>Weighted within-class covariance matrix. It corresponds to &lt;code&gt;sum_k prior_k * C_k&lt;/code&gt; where &lt;code&gt;C_k&lt;/code&gt; is the covariance matrix of the samples in class &lt;code&gt;k&lt;/code&gt;. The &lt;code&gt;C_k&lt;/code&gt; are estimated using the (potentially shrunk) biased estimator of covariance. If solver is &amp;lsquo;svd&amp;rsquo;, only exists when &lt;code&gt;store_covariance&lt;/code&gt; is True.</source>
          <target state="translated">加权类内协方差矩阵。它对应于 &lt;code&gt;sum_k prior_k * C_k&lt;/code&gt; ，其中 &lt;code&gt;C_k&lt;/code&gt; 是类别 &lt;code&gt;k&lt;/code&gt; 中样本的协方差矩阵。的 &lt;code&gt;C_k&lt;/code&gt; 使用协方差的（潜在收缩）偏置估算器估算。如果求解器为&amp;ldquo; svd&amp;rdquo;，则仅在 &lt;code&gt;store_covariance&lt;/code&gt; 为True时存在。</target>
        </trans-unit>
        <trans-unit id="ec852c96538aadaa4b0b959b23f492c546aedd45" translate="yes" xml:space="preserve">
          <source>Weighting type to calculate the score. None means no weighted; &amp;ldquo;linear&amp;rdquo; means linear weighted; &amp;ldquo;quadratic&amp;rdquo; means quadratic weighted.</source>
          <target state="translated">加权类型以计算分数。没有表示没有加权；&amp;ldquo;线性&amp;rdquo;是指线性加权；&amp;ldquo;二次方&amp;rdquo;是指二次加权。</target>
        </trans-unit>
        <trans-unit id="9a702ae7f12a23bf0cde9786ae821e6b340d4991" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples (1. for unweighted).</source>
          <target state="translated">应用于单个样本的权重(1.为未加权)。</target>
        </trans-unit>
        <trans-unit id="0c68217fe30f051f7b997da07ad569653cfdb104" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed.</source>
          <target state="translated">适用于单个样本的权重。如果没有提供,则假定为统一的权重。</target>
        </trans-unit>
        <trans-unit id="3070fe087be2b6fbe15f65d4db644297c1112686" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified</source>
          <target state="translated">适用于单个样本的权重。如果没有提供,则假定为统一权重。如果指定了class_weight,这些权重将与class_weight(通过构造函数传递)相乘。</target>
        </trans-unit>
        <trans-unit id="479d03c6533edea4de55367d8593a7974391f281" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified.</source>
          <target state="translated">适用于单个样本的权重。如果没有提供,则假定为统一权重。如果指定了class_weight,这些权重将与class_weight(通过构造函数传递)相乘。</target>
        </trans-unit>
        <trans-unit id="86b1d5826d4836f8e129b6346c9e9e60976aafee" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features (coefficients in the primal problem). This is only available in the case of a linear kernel.</source>
          <target state="translated">分配给特征的权重(原始问题中的系数)。这只有在线性核的情况下才有。</target>
        </trans-unit>
        <trans-unit id="4b149f5e057b5bff95048ebeff46bfac0e7a368d" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features.</source>
          <target state="translated">分配给特征的权重。</target>
        </trans-unit>
        <trans-unit id="4094f309127a892ba2564eecc3f5264343e18998" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="translated">与类相关的权重，形式为 &lt;code&gt;{class_label: weight}&lt;/code&gt; 。如果为None，则所有类的权重都应为1。对于多输出问题，可以按与y列相同的顺序提供字典列表。</target>
        </trans-unit>
        <trans-unit id="8064bf8d5d6b0c15f7ed813823cc0da43a8bc7e6" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">与类关联的权重，形式为 &lt;code&gt;{class_label: weight}&lt;/code&gt; 。如果未给出，则所有类都应具有权重一。</target>
        </trans-unit>
        <trans-unit id="96f3238c530c2df09403ab213fee9515feb36c99" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="translated">与类关联的权重，形式为 &lt;code&gt;{class_label: weight}&lt;/code&gt; 。如果未给出，则所有类都应具有权重一。对于多输出问题，可以按与y列相同的顺序提供字典列表。</target>
        </trans-unit>
        <trans-unit id="4a87f3dd4dfb432aa1a51752552e165c9cc23301" translate="yes" xml:space="preserve">
          <source>Weights associated with classes. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">与班级相关的权重。如果没有给定,所有班级的权重都是1。</target>
        </trans-unit>
        <trans-unit id="4837ab63e8195a91fca82bbd82590df1bbe7fcc4" translate="yes" xml:space="preserve">
          <source>Weights for each estimator in the boosted ensemble.</source>
          <target state="translated">在增强的集合中,每个估计器的权重。</target>
        </trans-unit>
        <trans-unit id="5f0089227653fec68913be1b7a199c273e750b44" translate="yes" xml:space="preserve">
          <source>Weights of training data.</source>
          <target state="translated">训练数据的权重。</target>
        </trans-unit>
        <trans-unit id="55ddc90a49d39d4b40d722b720afa82441019829" translate="yes" xml:space="preserve">
          <source>Weights on each point of the regression. If None, weight is set to 1 (equal weights).</source>
          <target state="translated">回归中每个点的权重。如果无,权重设为1(权重相等)。</target>
        </trans-unit>
        <trans-unit id="0946f675292deb36a2ff9f4a33806ccd9e9e1833" translate="yes" xml:space="preserve">
          <source>Weights. If set to None, all weights will be set to 1 (equal weights).</source>
          <target state="translated">权重。如果设置为 &quot;无&quot;,则所有权重都将设置为1(权重相等)。</target>
        </trans-unit>
        <trans-unit id="c1f521c553b00dab458900dd1fb3f949a6ba99ab" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class.</source>
          <target state="translated">校准良好的分类器是一种概率分类器,预测_proba方法的输出可以直接解释为置信度。例如,一个经过良好校准的(二进制)分类器应该对样本进行分类,在它给出的预测_proba值接近0.8的样本中,大约有80%的样本实际上属于正类。</target>
        </trans-unit>
        <trans-unit id="8b629519ceaa09dd1767dbc350008d2ef28e9249" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.</source>
          <target state="translated">校准良好的分类器是一种概率分类器,预测_proba方法的输出可以直接解释为置信度。例如,一个经过良好校准的(二进制)分类器应该对样本进行分类,在它给出的预测_proba值接近0.8的样本中,大约80%的样本实际上属于正类。</target>
        </trans-unit>
        <trans-unit id="6db2509535d857954c618d97c17994b5d42574ae" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class. The following plot compares how well the probabilistic predictions of different classifiers are calibrated:</source>
          <target state="translated">校准良好的分类器是一种概率分类器,预测_proba方法的输出可以直接解释为置信度。例如,一个校准良好的(二进制)分类器应该对样本进行分类,在它给出的预测_proba值接近0.8的样本中,大约80%的样本实际上属于正类。下图比较了不同分类器的概率预测的校准程度。</target>
        </trans-unit>
        <trans-unit id="830bc34728ca0799f710b4883d58631c6dfded76" translate="yes" xml:space="preserve">
          <source>Wether to include meta-estimators that are somehow special and can not be default-constructed sensibly. These are currently Pipeline, FeatureUnion and GridSearchCV</source>
          <target state="translated">是否包括一些特殊的元估计器,不能合理的默认构造。目前这些元估计器是Pipeline、FeatureUnion和GridSearchCV。</target>
        </trans-unit>
        <trans-unit id="d4f157bc9962e4b0dc2a197ed14e50902555d749" translate="yes" xml:space="preserve">
          <source>What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?</source>
          <target state="translated">各种决策树算法都有哪些,它们之间有什么不同?scikit-learn中实现的是哪一种?</target>
        </trans-unit>
        <trans-unit id="a1f5f9cd3d06157b8582b1ca4000a5bc395e765a" translate="yes" xml:space="preserve">
          <source>What this example shows us is the behavior &amp;ldquo;rich getting richer&amp;rdquo; of agglomerative clustering that tends to create uneven cluster sizes. This behavior is pronounced for the average linkage strategy, that ends up with a couple of singleton clusters, while in the case of single linkage we get a single central cluster with all other clusters being drawn from noise points around the fringes.</source>
          <target state="translated">该示例向我们展示的是聚集聚类的行为&amp;ldquo;越富越富&amp;rdquo;，这往往会导致大小不均的聚类。对于平均链接策略，此行为是明显的，它以几个单例群集结束，而在单链接的情况下，我们得到一个中央群集，所有其他群集都从边缘周围的噪声点得出。</target>
        </trans-unit>
        <trans-unit id="32580ac608fcdadc1c2050695a6c24cae1fcef1f" translate="yes" xml:space="preserve">
          <source>What we can see that:</source>
          <target state="translated">我们可以看到的是,。</target>
        </trans-unit>
        <trans-unit id="bd10ebd98b3e733be938ffeb72efbd3793589a2c" translate="yes" xml:space="preserve">
          <source>When &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; is applied on a &amp;ldquo;document-term&amp;rdquo; matrix, the matrix will be decomposed into a &amp;ldquo;topic-term&amp;rdquo; matrix and a &amp;ldquo;document-topic&amp;rdquo; matrix. While &amp;ldquo;topic-term&amp;rdquo; matrix is stored as &lt;code&gt;components_&lt;/code&gt; in the model, &amp;ldquo;document-topic&amp;rdquo; matrix can be calculated from &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="translated">当将&lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt;应用于&amp;ldquo;文档术语&amp;rdquo;矩阵时，该矩阵将分解为&amp;ldquo;主题术语&amp;rdquo;矩阵和&amp;ldquo;文档主题&amp;rdquo;矩阵。当&amp;ldquo;主题词&amp;rdquo;矩阵作为 &lt;code&gt;components_&lt;/code&gt; 存储在模型中时，&amp;ldquo;文档主题&amp;rdquo;矩阵可以通过 &lt;code&gt;transform&lt;/code&gt; 方法来计算。</target>
        </trans-unit>
        <trans-unit id="0c7daae89d35601e80a373ec7022d580692d615d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;False&lt;/code&gt;, checks are evaluated when &lt;code&gt;check_estimator&lt;/code&gt; is called. When &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;check_estimator&lt;/code&gt; returns a generator that yields (estimator, check) tuples. The check is run by calling &lt;code&gt;check(estimator)&lt;/code&gt;.</source>
          <target state="translated">如果为 &lt;code&gt;False&lt;/code&gt; ，则在 &lt;code&gt;check_estimator&lt;/code&gt; 时评估检查。如果为 &lt;code&gt;True&lt;/code&gt; ，则 &lt;code&gt;check_estimator&lt;/code&gt; 返回生成（估计器，检查）元组的生成器。通过调用 &lt;code&gt;check(estimator)&lt;/code&gt; 运行检查。</target>
        </trans-unit>
        <trans-unit id="d35c02f0322e905eb57e225a27ca83f7c5f6cc47" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=0&lt;/code&gt;, columns which only contained missing values at &lt;code&gt;fit&lt;/code&gt; are discarded upon &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">当 &lt;code&gt;axis=0&lt;/code&gt; 时，仅包含 &lt;code&gt;fit&lt;/code&gt; 缺失值的列在 &lt;code&gt;transform&lt;/code&gt; 被丢弃。</target>
        </trans-unit>
        <trans-unit id="7cf98e7188203ecb0d30e3564b161d5393433799" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=1&lt;/code&gt;, an exception is raised if there are rows for which it is not possible to fill in the missing values (e.g., because they only contain missing values).</source>
          <target state="translated">当 &lt;code&gt;axis=1&lt;/code&gt; 时，如果存在无法填充缺失值的行（例如，因为它们仅包含缺失值），则会引发异常。</target>
        </trans-unit>
        <trans-unit id="efffb9d033635c3e5b63e6f6f527201ab0e206e9" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;ccp_alpha&lt;/code&gt; is set to zero and keeping the other default parameters of &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, the tree overfits, leading to a 100% training accuracy and 88% testing accuracy. As alpha increases, more of the tree is pruned, thus creating a decision tree that generalizes better. In this example, setting &lt;code&gt;ccp_alpha=0.015&lt;/code&gt; maximizes the testing accuracy.</source>
          <target state="translated">如果将 &lt;code&gt;ccp_alpha&lt;/code&gt; 设置为零并保留&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt;的其他默认参数，则树会过拟合，从而导致100％的训练准确度和88％的测试准确度。随着alpha的增加，会修剪掉更多的树，从而创建更通用的决策树。在此示例中，设置 &lt;code&gt;ccp_alpha=0.015&lt;/code&gt; 可最大程度地提高测试准确性。</target>
        </trans-unit>
        <trans-unit id="4bce6b6fbd4b9fe79bfc7468f7df9f938d3ce841" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;fit&lt;/code&gt; does not converge, &lt;code&gt;cluster_centers_&lt;/code&gt; becomes an empty array and all training samples will be labelled as &lt;code&gt;-1&lt;/code&gt;. In addition, &lt;code&gt;predict&lt;/code&gt; will then label every sample as &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">当 &lt;code&gt;fit&lt;/code&gt; 不收敛时， &lt;code&gt;cluster_centers_&lt;/code&gt; 变为一个空数组，所有训练样本将被标记为 &lt;code&gt;-1&lt;/code&gt; 。此外， &lt;code&gt;predict&lt;/code&gt; 然后将每个样本标记为 &lt;code&gt;-1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f7c77c5939a6b7b3a7ed9ce47827d49725522a57" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;gamma&lt;/code&gt; is very small, the model is too constrained and cannot capture the complexity or &amp;ldquo;shape&amp;rdquo; of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.</source>
          <target state="translated">当 &lt;code&gt;gamma&lt;/code&gt; 非常小时，该模型太受约束，无法捕获数据的复杂性或&amp;ldquo;形状&amp;rdquo;。任何选择的支持向量的影响区域将包括整个训练集。所得模型的行为将类似于具有一组超平面的线性模型，该超平面将两个类别的任何一对的高密度中心分开。</target>
        </trans-unit>
        <trans-unit id="6579a89bba02e2aa5596acf0a356de3285b5831f" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;learning_method&lt;/code&gt; is &amp;lsquo;online&amp;rsquo;, use mini-batch update. Otherwise, use batch update.</source>
          <target state="translated">当 &lt;code&gt;learning_method&lt;/code&gt; 为&amp;ldquo;在线&amp;rdquo;时，请使用小批量更新。否则，请使用批量更新。</target>
        </trans-unit>
        <trans-unit id="1789662661fe322dc45828ec3c3eb62749643034" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;novelty&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; be aware that you must only use &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; on new unseen data and not on the training samples as this would lead to wrong results. The scores of abnormality of the training samples are always accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">当将 &lt;code&gt;novelty&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 时，请注意，您只能在新的看不见的数据上而不是训练样本上使用 &lt;code&gt;predict&lt;/code&gt; ， &lt;code&gt;decision_function&lt;/code&gt; 和 &lt;code&gt;score_samples&lt;/code&gt; ，因为这会导致错误的结果。始终可以通过 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性访问训练样本的异常分数。</target>
        </trans-unit>
        <trans-unit id="6539967754248da8802fa11e92b0d1b2532b93b8" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;predict_proba&lt;/code&gt; is used by each estimator (i.e. most of the time for &lt;code&gt;stack_method='auto'&lt;/code&gt; or specifically for &lt;code&gt;stack_method='predict_proba'&lt;/code&gt;), The first column predicted by each estimator will be dropped in the case of a binary classification problem. Indeed, both feature will be perfectly collinear.</source>
          <target state="translated">当每个估计器使用 &lt;code&gt;predict_proba&lt;/code&gt; 时（即，大多数情况下， &lt;code&gt;stack_method='auto'&lt;/code&gt; 或专门用于 &lt;code&gt;stack_method='predict_proba'&lt;/code&gt; ），在二进制分类问题的情况下，将删除每个估计器预测的第一列。确实，这两个功能将完全共线。</target>
        </trans-unit>
        <trans-unit id="380c86407d2b15e6e735d8a020999525510d4000" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold for each class. Otherwise, leave &lt;code&gt;random_state&lt;/code&gt; as &lt;code&gt;None&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">当 &lt;code&gt;shuffle&lt;/code&gt; 为True时， &lt;code&gt;random_state&lt;/code&gt; 会影响索引的顺序，从而控制每个类别的每个折叠的随机性。否则，将 &lt;code&gt;random_state&lt;/code&gt; 保留为 &lt;code&gt;None&lt;/code&gt; 。为多个函数调用传递可重复输出的int值。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="dba0ae97777bf9e3aca974d6ebb1591964b94b4e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">当 &lt;code&gt;shuffle&lt;/code&gt; 为True时， &lt;code&gt;random_state&lt;/code&gt; 会影响索引的顺序，从而控制每个折叠的随机性。否则，此参数无效。为多个函数调用传递可重复输出的int值。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2f36c5dece71799d4edbabcfff5ea8ed2f825b4d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;true positive + false negative == 0&lt;/code&gt; ，记得返回0，提高 &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; 。可以使用 &lt;code&gt;zero_division&lt;/code&gt; 修改此行为。</target>
        </trans-unit>
        <trans-unit id="43540f9f914266a4b6caeeeeef53fc90c0648c6e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt; or &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, f-score returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;true positive + false positive == 0&lt;/code&gt; 或 &lt;code&gt;true positive + false negative == 0&lt;/code&gt; ，F值返回0，提高 &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; 。可以使用 &lt;code&gt;zero_division&lt;/code&gt; 修改此行为。</target>
        </trans-unit>
        <trans-unit id="ba4ca3b8ef57a04587026d0caa7a41ba81b60463" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision is undefined; When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall is undefined. In such cases, by default the metric will be set to 0, as will f-score, and &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; will be raised. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">当 &lt;code&gt;true positive + false positive == 0&lt;/code&gt; ，精度是未定义; 如果 &lt;code&gt;true positive + false negative == 0&lt;/code&gt; ，召回不确定。在这种情况下，默认情况下，度量将设置为0，f分数也将设置为0，并且将引发 &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; 。可以使用 &lt;code&gt;zero_division&lt;/code&gt; 修改此行为。</target>
        </trans-unit>
        <trans-unit id="c54bb2862f6516891f7056fa35777ac8bd097188" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;true positive + false positive == 0&lt;/code&gt; ，精度返回0，提高 &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; 。可以使用 &lt;code&gt;zero_division&lt;/code&gt; 修改此行为。</target>
        </trans-unit>
        <trans-unit id="70168d4d772dfaf9b58be440f7660f3adf7f21be" translate="yes" xml:space="preserve">
          <source>When False, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; both being sparse will yield sparse output. When True, output will always be a dense array.</source>
          <target state="translated">如果为False，则 &lt;code&gt;a&lt;/code&gt; 和 &lt;code&gt;b&lt;/code&gt; 都将是稀疏的，将产生稀疏的输出。设置为True时，输出将始终是密集数组。</target>
        </trans-unit>
        <trans-unit id="f3329fe0cead2a208482794593628ff4dce53789" translate="yes" xml:space="preserve">
          <source>When False, either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; being sparse will yield sparse output. When True, output will always be an array.</source>
          <target state="translated">如果为False，则稀疏的 &lt;code&gt;a&lt;/code&gt; 或 &lt;code&gt;b&lt;/code&gt; 都会产生稀疏的输出。如果为True，则输出将始终是一个数组。</target>
        </trans-unit>
        <trans-unit id="1bb4bf21b8d21fdceb61000bf23d6624de5a3ca6" translate="yes" xml:space="preserve">
          <source>When False, only the predictions of estimators will be used as training data for &lt;code&gt;final_estimator&lt;/code&gt;. When True, the &lt;code&gt;final_estimator&lt;/code&gt; is trained on the predictions as well as the original training data.</source>
          <target state="translated">当为False时，仅估计器的预测将用作 &lt;code&gt;final_estimator&lt;/code&gt; 的训练数据。当为True时，将根据预测以及原始训练数据对 &lt;code&gt;final_estimator&lt;/code&gt; 进行训练。</target>
        </trans-unit>
        <trans-unit id="0baad85c0e4d647371baa109869739d44cb0f600" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are divided by &lt;code&gt;n_samples&lt;/code&gt; times &lt;code&gt;components_&lt;/code&gt; to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">为True（默认为False）时， &lt;code&gt;components_&lt;/code&gt; 向量除以 &lt;code&gt;n_samples&lt;/code&gt; 乘以 &lt;code&gt;components_&lt;/code&gt; ,以确保具有单位分量方差的不相关输出。</target>
        </trans-unit>
        <trans-unit id="3eaa2881688032030c765cb871d4c787aff03fe7" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are multiplied by the square root of n_samples and then divided by the singular values to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">为True（默认情况下为False）时， &lt;code&gt;components_&lt;/code&gt; 向量乘以n_samples的平方根，然后除以奇异值，以确保具有单位分量方差的不相关输出。</target>
        </trans-unit>
        <trans-unit id="afb8087ad0f4a499dd14f72be9807792c351ecd8" translate="yes" xml:space="preserve">
          <source>When True, an absolute value is applied to the features matrix prior to returning it. When used in conjunction with alternate_sign=True, this significantly reduces the inner product preservation property.</source>
          <target state="translated">当True时,在返回特征矩阵之前,会对其应用一个绝对值。当与alternate_sign=True一起使用时,会显著降低内积保存属性。</target>
        </trans-unit>
        <trans-unit id="204d5c48d22bd9cd74d36182840231c3ecac4f55" translate="yes" xml:space="preserve">
          <source>When True, an alternating sign is added to the features as to approximately conserve the inner product in the hashed space even for small n_features. This approach is similar to sparse random projection.</source>
          <target state="translated">当True时,一个交替符号被添加到特征上,即使对于小的n_特征,也能在哈希空间中近似地保存内积。这种方法类似于稀疏随机投影。</target>
        </trans-unit>
        <trans-unit id="e4283276989a341cb6ca6bb94564d0f53f92318b" translate="yes" xml:space="preserve">
          <source>When X and/or Y are CSR sparse matrices and they are not already in canonical format, this function modifies them in-place to make them canonical.</source>
          <target state="translated">当X和/或Y是CSR稀疏矩阵,并且它们还不是规范格式时,这个函数就地修改它们,使它们成为规范格式。</target>
        </trans-unit>
        <trans-unit id="e08ec276d8bba6d4be8a6e677715ca1a35d4dd15" translate="yes" xml:space="preserve">
          <source>When a grouped cross-validator is used, the group labels are also passed on to the &lt;code&gt;split&lt;/code&gt; method of the cross-validator. The cross-validator uses them for grouping the samples while splitting the dataset into train/test set.</source>
          <target state="translated">当使用分组的交叉验证器时，组标签也将传递到交叉验证器的 &lt;code&gt;split&lt;/code&gt; 方法。交叉验证器使用它们对样本进行分组，同时将数据集分为训练/测试集。</target>
        </trans-unit>
        <trans-unit id="96fd8c38f0f9978d89774efb70a7d42aee5d30ee" translate="yes" xml:space="preserve">
          <source>When a specific number of neighbors is queried (using &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt;), the definition of &lt;code&gt;n_neighbors&lt;/code&gt; is ambiguous since it can either include each training point as its own neighbor, or exclude them. Neither choice is perfect, since including them leads to a different number of non-self neighbors during training and testing, while excluding them leads to a difference between &lt;code&gt;fit(X).transform(X)&lt;/code&gt; and &lt;code&gt;fit_transform(X)&lt;/code&gt;, which is against scikit-learn API. In &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt; we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;. However, for compatibility reasons with other estimators which use the other definition, one extra neighbor will be computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. To maximise compatibility with all estimators, a safe choice is to always include one extra neighbor in a custom nearest neighbors estimator, since unnecessary neighbors will be filtered by following estimators.</source>
          <target state="translated">当询问邻居的特定号码（使用&lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt; &lt;code&gt;KNeighborsTransformer&lt;/code&gt; &lt;/a&gt;）的定义 &lt;code&gt;n_neighbors&lt;/code&gt; 是模糊的，因为它可以包括每个培训点作为自己的邻居，或者排除它们。这两种选择都不是完美的，因为在训练和测试期间包含它们会导致不同数量的非 &lt;code&gt;fit(X).transform(X)&lt;/code&gt; 邻居，而将它们排除在外则会导致fit（X）.transform（X）和 &lt;code&gt;fit_transform(X)&lt;/code&gt; 之间的差异，这与scikit背道而驰-学习API。在&lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt; &lt;code&gt;KNeighborsTransformer&lt;/code&gt; 中,&lt;/a&gt;我们使用的定义包括每个训练点作为 &lt;code&gt;n_neighbors&lt;/code&gt; 计数中自己的邻居。但是，出于与使用其他定义的其他估算器的兼容性原因，当 &lt;code&gt;mode == 'distance'&lt;/code&gt; 时，将计算一个额外的邻居。为了最大限度地提高与所有估算器的兼容性，一个安全的选择是始终在自定义的最近邻估算器中包括一个额外的邻居，因为不必要的邻居将被后续的估算器过滤掉。</target>
        </trans-unit>
        <trans-unit id="6c0f90cdc44694d62adb6ac9bccd5513d6bf148f" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, &lt;code&gt;fit&lt;/code&gt; will result in a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">当所有训练样本具有相同的相似性和相同的偏好时，聚类中心和标签的分配取决于偏好。如果首选项小于相似性，则 &lt;code&gt;fit&lt;/code&gt; 将导致单个聚类中心，并为每个样本标记 &lt;code&gt;0&lt;/code&gt; 。否则，每个训练样本将成为其自己的聚类中心，并被分配一个唯一的标签。</target>
        </trans-unit>
        <trans-unit id="c440a8e563c9cc7b9752f14072284d81697bdfcd" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample will be returned. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">当所有训练样本具有相同的相似性和相同的偏好时，聚类中心和标签的分配取决于偏好。如果首选项小于相似性，则将返回单个聚类中心和每个样本的标签 &lt;code&gt;0&lt;/code&gt; 。否则，每个训练样本将成为其自己的聚类中心，并被分配一个唯一的标签。</target>
        </trans-unit>
        <trans-unit id="2494d11b03713922afdad3fa1bc52bb7064577b4" translate="yes" xml:space="preserve">
          <source>When alpha is very large, the regularization effect dominates the squared loss function and the coefficients tend to zero. At the end of the path, as alpha tends toward zero and the solution tends towards the ordinary least squares, coefficients exhibit big oscillations. In practise it is necessary to tune alpha in such a way that a balance is maintained between both.</source>
          <target state="translated">当α非常大时,正则化效应主导平方损失函数,系数趋向于零。在路径的末端,由于α趋向于零,解趋向于普通最小二乘,系数表现出大的振荡。在实际工作中,有必要对α进行调整,使两者之间保持平衡。</target>
        </trans-unit>
        <trans-unit id="e93a4fdf68d407dc869190eca6cd7dfaf57ad986" translate="yes" xml:space="preserve">
          <source>When applying LOF for outlier detection, there are no &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods but only a &lt;code&gt;fit_predict&lt;/code&gt; method. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute. Note that &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; can be used on new unseen data when LOF is applied for novelty detection, i.e. when the &lt;code&gt;novelty&lt;/code&gt; parameter is set to &lt;code&gt;True&lt;/code&gt;. See &lt;a href=&quot;#novelty-with-lof&quot;&gt;Novelty detection with Local Outlier Factor&lt;/a&gt;.</source>
          <target state="translated">在将LOF应用于异常值检测时，没有 &lt;code&gt;predict&lt;/code&gt; ， &lt;code&gt;decision_function&lt;/code&gt; 和 &lt;code&gt;score_samples&lt;/code&gt; 方法，而只有 &lt;code&gt;fit_predict&lt;/code&gt; 方法。可以通过 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性访问训练样本的异常分数。请注意，当将LOF应用于新颖性检测时，即，当 &lt;code&gt;novelty&lt;/code&gt; 参数设置为 &lt;code&gt;True&lt;/code&gt; 时，可以对新的看不见的数据使用 &lt;code&gt;predict&lt;/code&gt; ， &lt;code&gt;decision_function&lt;/code&gt; 和 &lt;code&gt;score_samples&lt;/code&gt; 。请参阅&lt;a href=&quot;#novelty-with-lof&quot;&gt;具有局部异常值因素的新颖性检测&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2ec6d5a6d0d8178f2ec5cc1ea59ce167ddd0a98a" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">构建词汇时,忽略那些文档频率严格高于给定阈值的词汇(语料库特定的停止词)。如果是范围[0.0,1.0]的浮点数,该参数代表文档的比例,整数绝对数。如果词汇不为None,该参数将被忽略。</target>
        </trans-unit>
        <trans-unit id="869141a5ff3e1444543cdaec8c9968684d76b66e" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">在构建词汇时,忽略那些文档频率严格高于给定阈值的词汇(特定语料库的停止词)。如果是float,该参数代表文档的比例,整数绝对数。如果词汇不为None,则忽略该参数。</target>
        </trans-unit>
        <trans-unit id="d83f4236f3f25a9891417b446059c6cca3f6ec76" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">在构建词汇时,忽略那些文档频率严格低于给定阈值的词汇。这个值在文献中也叫截止值。如果是浮点数,范围为[0.0,1.0],该参数代表文档的比例,整数绝对数。如果词汇量不是None,则忽略该参数。</target>
        </trans-unit>
        <trans-unit id="1f13ad80586b74ad6fdc521fde036c051cf6e0e7" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">在构建词汇时,忽略那些文档频率严格低于给定阈值的词汇。这个值在文献中也称为cut-off。如果是float,该参数代表文档的比例,整数绝对数。如果词汇不为None,则忽略该参数。</target>
        </trans-unit>
        <trans-unit id="757013c910e6b4628ced11d689b0016d8c17e540" translate="yes" xml:space="preserve">
          <source>When calculating class-wise multilabel confusion matrix \(C\), the count of true negatives for class \(i\) is \(C_{i,0,0}\), false negatives is \(C_{i,1,0}\), true positives is \(C_{i,1,1}\) and false positives is \(C_{i,0,1}\).</source>
          <target state="translated">在计算类多标签混淆矩阵(C\)时,类(i\)的真否定数为(C_{i,0,0}\),假否定数为(C_{i,1,0}\),真肯定数为(C_{i,1,1}\),假肯定数为(C_{i,0,1}\)。</target>
        </trans-unit>
        <trans-unit id="8ed788b8f95069d89dcb15b1bea5b5e7da9a9648" translate="yes" xml:space="preserve">
          <source>When calling &lt;code&gt;fit&lt;/code&gt;, an affinity matrix is constructed using either kernel function such the Gaussian (aka RBF) kernel of the euclidean distanced &lt;code&gt;d(X, X)&lt;/code&gt;:</source>
          <target state="translated">调用 &lt;code&gt;fit&lt;/code&gt; 时，将使用任一个核函数（例如，距离为 &lt;code&gt;d(X, X)&lt;/code&gt; 的欧式）的高斯（aka RBF）核构造亲和矩阵：</target>
        </trans-unit>
        <trans-unit id="5c5941b79e3bd733fe2a806a66f459a87c19af32" translate="yes" xml:space="preserve">
          <source>When dealing with a cleaned dataset, the preprocessing can be automatic by using the data types of the column to decide whether to treat a column as a numerical or categorical feature. &lt;a href=&quot;../../modules/generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;sklearn.compose.make_column_selector&lt;/code&gt;&lt;/a&gt; gives this possibility. First, let&amp;rsquo;s only select a subset of columns to simplify our example.</source>
          <target state="translated">处理干净的数据集时，可以通过使用列的数据类型来决定是将列视为数字特征还是分类特征来自动进行预处理。&lt;a href=&quot;../../modules/generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt; &lt;code&gt;sklearn.compose.make_column_selector&lt;/code&gt; &lt;/a&gt;提供了这种可能性。首先，让我们仅选择列的子集来简化我们的示例。</target>
        </trans-unit>
        <trans-unit id="da9c4333516559f145c3dcae1d1fd9f5e0da891d" translate="yes" xml:space="preserve">
          <source>When doing classification in scikit-learn, &lt;code&gt;y&lt;/code&gt; is a vector of integers or strings.</source>
          <target state="translated">在scikit-learn中进行分类时， &lt;code&gt;y&lt;/code&gt; 是整数或字符串的向量。</target>
        </trans-unit>
        <trans-unit id="fb08dbb1ad477236e66b72b0cef9bccfd1ceec61" translate="yes" xml:space="preserve">
          <source>When doing supervised learning, a simple sanity check consists of comparing one&amp;rsquo;s estimator against simple rules of thumb. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt; implements several such simple strategies for classification:</source>
          <target state="translated">在进行监督学习时，简单的健全性检查包括将自己的估计量与简单的经验法则进行比较。&lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt;实现了几种这样的简单分类策略：</target>
        </trans-unit>
        <trans-unit id="3bf9748662d1dbe365a15ba24b002d016f11408b" translate="yes" xml:space="preserve">
          <source>When evaluating different settings (&amp;ldquo;hyperparameters&amp;rdquo;) for estimators, such as the &lt;code&gt;C&lt;/code&gt; setting that must be manually set for an SVM, there is still a risk of overfitting &lt;em&gt;on the test set&lt;/em&gt; because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can &amp;ldquo;leak&amp;rdquo; into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called &amp;ldquo;validation set&amp;rdquo;: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.</source>
          <target state="translated">当评估用于估计不同的设置（&amp;ldquo;超参数&amp;rdquo;），如 &lt;code&gt;C&lt;/code&gt; 必须为一个SVM手动设定的设定，仍然存在过度拟合的风险&lt;em&gt;在测试组&lt;/em&gt;，因为这些参数可以进行调整，直到估计器执行最优。这样，有关测试集的知识可以&amp;ldquo;渗入&amp;rdquo;模型，并且评估指标不再报告泛化性能。为了解决此问题，可以将数据集的另一部分保留为所谓的&amp;ldquo;验证集&amp;rdquo;：对训练集进行训练，然后对验证集进行评估，以及实验何时成功，可以对测试集进行最终评估。</target>
        </trans-unit>
        <trans-unit id="b6d52e3adfb55f9048c5ef57545d77d640ae7db4" translate="yes" xml:space="preserve">
          <source>When evaluating text classifiers on the 20 Newsgroups data, you should strip newsgroup-related metadata. In scikit-learn, you can do this by setting &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt;. The F-score will be lower because it is more realistic.</source>
          <target state="translated">当评估20个新闻组数据上的文本分类器时，应删除与新闻组相关的元数据。在scikit-learn中，您可以通过设置 &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt; 。F分数将较低，因为它更现实。</target>
        </trans-unit>
        <trans-unit id="b44ace677df67ec762b5f7d213266d4181953b1c" translate="yes" xml:space="preserve">
          <source>When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a &lt;strong&gt;development set&lt;/strong&gt; (to be fed to the &lt;code&gt;GridSearchCV&lt;/code&gt; instance) and an &lt;strong&gt;evaluation set&lt;/strong&gt; to compute performance metrics.</source>
          <target state="translated">在评估结果模型时，重要的是对在网格搜索过程中未看到的保留样本进行处理：建议将数据拆分为&lt;strong&gt;开发集&lt;/strong&gt;（供入 &lt;code&gt;GridSearchCV&lt;/code&gt; 实例）和&lt;strong&gt;评估集&lt;/strong&gt;计算性能指标。</target>
        </trans-unit>
        <trans-unit id="1a86b5b9ee94c593acad1b7968fd00ab3b487df9" translate="yes" xml:space="preserve">
          <source>When feature values are strings, this transformer will do a binary one-hot (aka one-of-K) coding: one boolean-valued feature is constructed for each of the possible string values that the feature can take on. For instance, a feature &amp;ldquo;f&amp;rdquo; that can take on the values &amp;ldquo;ham&amp;rdquo; and &amp;ldquo;spam&amp;rdquo; will become two features in the output, one signifying &amp;ldquo;f=ham&amp;rdquo;, the other &amp;ldquo;f=spam&amp;rdquo;.</source>
          <target state="translated">当特征值是字符串时，此转换器将执行二进制一键式（又名K之一）编码：为该功能可以采用的每个可能的字符串值构造一个布尔值特征。例如，可以采用值&amp;ldquo; ham&amp;rdquo;和&amp;ldquo; spam&amp;rdquo;的功能&amp;ldquo; f&amp;rdquo;将成为输出中的两个功能，一个表示&amp;ldquo; f = ham&amp;rdquo;，另一个表示&amp;ldquo; f = spam&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="81d685e408d1bc940e50f235a77cb7283ea2909d" translate="yes" xml:space="preserve">
          <source>When features are collinear, permutating one feature will have little effect on the models performance because it can get the same information from a correlated feature. One way to handle multicollinear features is by performing hierarchical clustering on the Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster. First, we plot a heatmap of the correlated features:</source>
          <target state="translated">当特征是准线的时候,换一个特征对模型的性能影响不大,因为它可以从相关的特征中获得相同的信息。处理多线性特征的一种方法是对Spearman秩序相关性进行分层聚类,选取一个阈值,并从每个聚类中保留一个特征。首先,我们绘制相关特征的热图。</target>
        </trans-unit>
        <trans-unit id="e3d8c3576d6baaf6f77dc4e34223e91a48a8c662" translate="yes" xml:space="preserve">
          <source>When fitting a model to a matrix X_train and evaluating it against a matrix X_test, it is essential that X_train and X_test have the same number of features (X_train.shape[1] == X_test.shape[1]). This may not be the case if you load the files individually with load_svmlight_file.</source>
          <target state="translated">当将模型拟合到一个矩阵X_train并对矩阵X_test进行评估时,X_train和X_test必须具有相同数量的特征(X_train.shape[1]==X_test.shape[1])。如果您使用 load_svmlight_file 单独加载文件,情况可能不是这样。</target>
        </trans-unit>
        <trans-unit id="618912ddd6add9bc398f8cf8343e255bb5f0ac59" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</source>
          <target state="translated">如有疑问，请使用&lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4150d19b2bd7fadd0941f6ca06455157d317e492" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;.</source>
          <target state="translated">如有疑问，请使用&lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7ebc317e66e94c9c3ce7d1b975021eefa97b880b" translate="yes" xml:space="preserve">
          <source>When individual estimators are fast to train or predict using &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; can result in slower performance due to the overhead of spawning processes.</source>
          <target state="translated">当使用 &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; 快速估计或预测单个估计量时，由于生成过程的开销而导致性能降低。</target>
        </trans-unit>
        <trans-unit id="5223d409a8ec7650bd8559a52e22ddb32a950ada" translate="yes" xml:space="preserve">
          <source>When loss=&amp;rdquo;modified_huber&amp;rdquo;, probability estimates may be hard zeros and ones, so taking the logarithm is not possible.</source>
          <target state="translated">当损失=&amp;ldquo; modified_huber&amp;rdquo;时，概率估计可能是硬零和一，因此不可能采用对数。</target>
        </trans-unit>
        <trans-unit id="3169e6d4a043a16249e2b124b1d248f9aac1b1e2" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics, with \(K\) corresponding to &lt;code&gt;n_components&lt;/code&gt; in the API:</source>
          <target state="translated">在为文本语料库建模时，模型假设具有\（D \）文档和\（K \）主题的语料库具有以下生成过程，其中\（K \）对应于API中的 &lt;code&gt;n_components&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="63fb46936ec9f0c71e69b897d1f9d91941d422e3" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics:</source>
          <target state="translated">当对文本语料库进行建模时,该模型假设一个语料库具有 \(D\)文档和 \(K\)主题的生成过程如下。</target>
        </trans-unit>
        <trans-unit id="744347c999c68da3080dd50ae1b985e4b97e385e" translate="yes" xml:space="preserve">
          <source>When one has insufficiently many points per mixture, estimating the covariance matrices becomes difficult, and the algorithm is known to diverge and find solutions with infinite likelihood unless one regularizes the covariances artificially.</source>
          <target state="translated">当人们对每个混合物的点数不够多时,估计协方差矩阵就会变得很困难,除非人为地将协方差正则化,否则该算法就会出现分歧,并找到具有无限似然的解。</target>
        </trans-unit>
        <trans-unit id="e24f09e860711fd3a63a21415134601f90e4efc0" translate="yes" xml:space="preserve">
          <source>When parametrized by error using the parameter &lt;code&gt;tol&lt;/code&gt;: argmin ||gamma||_0 subject to ||y - Xgamma||^2 &amp;lt;= tol</source>
          <target state="translated">使用参数 &lt;code&gt;tol&lt;/code&gt; 进行参数错误设置时：argmin || gamma || _0服从|| y-Xgamma || ^ 2 &amp;lt;= tol</target>
        </trans-unit>
        <trans-unit id="70b3334d846e26366c45a04fb1a4a39af8e3ec45" translate="yes" xml:space="preserve">
          <source>When parametrized by the number of non-zero coefficients using &lt;code&gt;n_nonzero_coefs&lt;/code&gt;: argmin ||y - Xgamma||^2 subject to ||gamma||_0 &amp;lt;= n_{nonzero coefs}</source>
          <target state="translated">当使用 &lt;code&gt;n_nonzero_coefs&lt;/code&gt; 对非零系数的数量进行参数化时：argmin || y-Xgamma || ^ 2服从|| gamma || _0 &amp;lt;= n_ {nonzero coefs}</target>
        </trans-unit>
        <trans-unit id="10d326cee514d3b967129b254954126bcda90793" translate="yes" xml:space="preserve">
          <source>When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to display how well calibrated the predicted probabilities are and how to calibrate an uncalibrated classifier.</source>
          <target state="translated">在进行分类时,人们往往不仅要预测类标签,还要预测相关的概率。这个概率给了预测的某种信心。这个例子演示了如何显示预测概率的校准情况,以及如何校准未校准的分类器。</target>
        </trans-unit>
        <trans-unit id="533cc79868c5585705042f97bd64dbf9b1c6133f" translate="yes" xml:space="preserve">
          <source>When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.</source>
          <target state="translated">在进行分类时,你往往不仅要预测类标签,还要获得各自标签的概率。这个概率给你对预测的某种信心。有些模型可以给你很差的类概率估计,有些甚至不支持概率预测。校准模块可以让你更好地校准给定模型的概率,或者增加对概率预测的支持。</target>
        </trans-unit>
        <trans-unit id="ede14543224daf4bd7da97ebebdbcb4bdb8fe514" translate="yes" xml:space="preserve">
          <source>When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&amp;rsquo;s score (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt;).</source>
          <target state="translated">执行分类时，您通常不仅要预测类别标签，还要预测相关的概率。这种可能性使您对预测有某种信心。但是，并非所有分类器都提供了经过良好校准的概率，有些分类器过于自信，而另一些分类器则不太自信。因此，通常期望对预测概率进行单独的校准作为后处理。本示例说明了此校准的两种不同方法，并使用Brier分数评估了返回的概率的质量（请参见&lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="47397daaf8d579706c38eeae4f614a41b7464779" translate="yes" xml:space="preserve">
          <source>When performing cross-validation for the &lt;code&gt;power&lt;/code&gt; parameter of &lt;code&gt;TweedieRegressor&lt;/code&gt;, it is advisable to specify an explicit &lt;code&gt;scoring&lt;/code&gt; function, because the default scorer &lt;a href=&quot;generated/sklearn.linear_model.tweedieregressor#sklearn.linear_model.TweedieRegressor.score&quot;&gt;&lt;code&gt;TweedieRegressor.score&lt;/code&gt;&lt;/a&gt; is a function of &lt;code&gt;power&lt;/code&gt; itself.</source>
          <target state="translated">当对 &lt;code&gt;TweedieRegressor&lt;/code&gt; 的 &lt;code&gt;power&lt;/code&gt; 参数执行交叉验证时，建议指定一个显式的 &lt;code&gt;scoring&lt;/code&gt; 函数，因为默认评分器&lt;a href=&quot;generated/sklearn.linear_model.tweedieregressor#sklearn.linear_model.TweedieRegressor.score&quot;&gt; &lt;code&gt;TweedieRegressor.score&lt;/code&gt; &lt;/a&gt;是 &lt;code&gt;power&lt;/code&gt; 本身的函数。</target>
        </trans-unit>
        <trans-unit id="e99cb78745b2020137c83400ee3d8d22f37293c0" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified, ensuring X is C-contiguous. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean, in this case it will also not ensure that data is C-contiguous which may cause a significant slowdown.</source>
          <target state="translated">在预计算距离时,先将数据居中,在数值上更准确。如果copy_x为True(默认),则不修改原始数据,保证X是C-contiguous。如果False,则修改原始数据,在函数返回之前放回原处,但可能会通过减去数据均值再加上数据均值而引入小的数值差异,这种情况下也不能保证数据是C-连续的,可能会造成明显的减速。</target>
        </trans-unit>
        <trans-unit id="785dafae54d31c04c4a974bc00da768d9cfae46f" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean. Note that if the original data is not C-contiguous, a copy will be made even if copy_x is False. If the original data is sparse, but not in CSR format, a copy will be made even if copy_x is False.</source>
          <target state="translated">当预先计算距离时,先将数据居中,在数值上更准确。如果copy_x为True(默认),则不修改原始数据。如果False,则修改原始数据,并在函数返回前放回原数据,但可能会通过减去数据均值再加上数据均值引入小的数值差异。需要注意的是,如果原始数据不是C连续的,即使copy_x为False,也会进行复制。如果原始数据是稀疏的,但不是CSR格式,即使copy_x为False,也会进行复制。</target>
        </trans-unit>
        <trans-unit id="55ac178846c6596090a6f8d0133ba62fcd26aebb" translate="yes" xml:space="preserve">
          <source>When predicting, the true labels will not be available. Instead the predictions of each model are passed on to the subsequent models in the chain to be used as features.</source>
          <target state="translated">在预测时,将无法获得真实的标签。相反,每个模型的预测将被传递给链中的后续模型,作为特征使用。</target>
        </trans-unit>
        <trans-unit id="441463f4c28b96b4ca0739417ce251a6d1637336" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt;.</source>
          <target state="translated">当将数据集的随机子集绘制为要素的随机子集时，该方法称为随机子空间&lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ed3a388f4c5d9809937b1b2fceecd5d5d41437fc" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt;.</source>
          <target state="translated">当将数据集的随机子集绘制为样本的随机子集时，该算法称为粘贴&lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f494cf947867cf3181ff2c5eaa996adc8d0ce783" translate="yes" xml:space="preserve">
          <source>When requesting a dataset with a name that is in mock_datasets, this object creates a fake dataset in a StringIO object and returns it. Otherwise, it raises an HTTPError.</source>
          <target state="translated">当请求一个名字在mock_datasets中的数据集时,这个对象会在StringIO对象中创建一个假的数据集并返回。否则,它会引发一个HTTPError。</target>
        </trans-unit>
        <trans-unit id="f6f6725ccb736a3cf59a107563029dd1f92b7eb9" translate="yes" xml:space="preserve">
          <source>When sample_weight is provided, the selected hyperparameter may depend on whether we use generalized cross-validation (cv=None or cv=&amp;rsquo;auto&amp;rsquo;) or another form of cross-validation, because only generalized cross-validation takes the sample weights into account when computing the validation score.</source>
          <target state="translated">当提供sample_weight时，所选的超参数可能取决于我们使用广义交叉验证（cv = None还是cv ='auto'）还是另一种形式的交叉验证，因为只有广义交叉验证才将样本权重考虑在内。计算验证分数。</target>
        </trans-unit>
        <trans-unit id="d66c9681351cfa02a7cc3145d8e8cc7e7a3877b3" translate="yes" xml:space="preserve">
          <source>When samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt;.</source>
          <target state="translated">当抽取样本进行替换时，该方法称为Bagging &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b67d588266cee585b7c0608db5b116728771921f" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt;, i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">当self.fit_intercept为True时，实例向量x变为 &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt; ，即，将具有等于intercept_scaling的恒定值的&amp;ldquo;合成&amp;rdquo;特征附加到实例向量。截距变为intercept_scaling *综合特征权重注意！与所有其他特征一样，合成特征权重也要经过l1 / l2正则化。为了减轻正则化对合成特征权重（以及因此对截距）的影响，必须增加intercept_scaling。</target>
        </trans-unit>
        <trans-unit id="339fba0d20ce2052ad9daa9e3c6cc55589d832bc" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">当self.fit_intercept为True时，实例矢量x变为[x，self.intercept_scaling]，即，将常量值等于intercept_scaling的&amp;ldquo;合成&amp;rdquo;特征附加到实例矢量。截距变为intercept_scaling *综合特征权重注意！与所有其他特征一样，合成特征权重也要经过l1 / l2正则化。为了减轻正则化对合成特征权重（以及因此对截距）的影响，必须增加intercept_scaling。</target>
        </trans-unit>
        <trans-unit id="ad06c0ce7c1fc91387cf888768a953ddfc43c4b6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;False&lt;/code&gt;, ignore special characters for PostScript compatibility.</source>
          <target state="translated">设置为 &lt;code&gt;False&lt;/code&gt; 时，请忽略特殊字符以实现PostScript兼容性。</target>
        </trans-unit>
        <trans-unit id="d1b93df55570608a785000a0ebdde0c1a478b680" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, change the display of &amp;lsquo;values&amp;rsquo; and/or &amp;lsquo;samples&amp;rsquo; to be proportions and percentages respectively.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，将&amp;ldquo;值&amp;rdquo;和/或&amp;ldquo;样本&amp;rdquo;的显示分别更改为比例和百分比。</target>
        </trans-unit>
        <trans-unit id="3843d20a53a1ef3b59460be1fa7cb77d3c2ee1f6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw all leaf nodes at the bottom of the tree.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，在树的底部绘制所有叶节点。</target>
        </trans-unit>
        <trans-unit id="1dd8441b2d9ea649f69d55eb070005c43dff3ea1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw node boxes with rounded corners and use Helvetica fonts instead of Times-Roman.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，绘制带有圆角的节点框，并使用Helvetica字体代替Times-Roman。</target>
        </trans-unit>
        <trans-unit id="37e5e7c90dcc2881b20280bd58a636a2601aa0c6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, forces the coefficients to be positive.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，将系数强制为正。</target>
        </trans-unit>
        <trans-unit id="a556178389cf10e9a8f97ab94b5cbc137168d877" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, orient tree left to right rather than top-down.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，将树从左到右而不是自上而下定向。</target>
        </trans-unit>
        <trans-unit id="db2d0a81092e78238cdb916143e482a964d5a789" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，绘制节点以表示多数类用于分类，值的极值用于回归，或表示节点的纯度用于多输出。</target>
        </trans-unit>
        <trans-unit id="387704ecb7f5fc4e8c941c08ae18f72e58104663" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，请重用上一个调用的解决方案以适合并在集合中添加更多的估计量，否则，只需擦除以前的解决方案即可。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="42b61336d9e93453cd22782ddee266aae253af56" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，请重用上一个调用的解决方案以适应并在集合中添加更多的估计量，否则，只需擦除之前的解决方案即可。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e08becb1d7f3dabb059c61e3163efbfc5e9d6bd5" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，请重用上一个调用的解决方案以适合并在集合中添加更多估计量，否则，仅适合整个新森林。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4ca94f8cc22fb05a614eaf938146928a9cad01e1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，请重用上一个调用的解决方案以适合并在集合中添加更多估计量，否则，仅适合整个新森林。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b034ef6cd843a9c71bbf2f16594203b3e34675bd" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble. For results to be valid, the estimator should be re-trained on the same data only. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，重用上一个调用的解决方案以适合并向集合添加更多估计量。为了使结果有效，应仅对相同数据重新训练估计量。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1ddb18c96e1fca0312edb00f224f2db160c80a30" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，请重用上一个调用的解决方案以适合初始化，否则，只需擦除之前的解决方案即可。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="06f93e3e87621fa903e7cdd20131cea02e9878ba" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，请重用上一个调用的解决方案以适合初始化，否则，只需擦除以前的解决方案即可。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="303e5cc9af6656c2592224b864d50a2e7f014b54" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the ID number on each node.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，在每个节点上显示ID号。</target>
        </trans-unit>
        <trans-unit id="d19057d05dc608969ed0862b9054b2defc3fb482" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the impurity at each node.</source>
          <target state="translated">设置为 &lt;code&gt;True&lt;/code&gt; 时，显示每个节点上的杂质。</target>
        </trans-unit>
        <trans-unit id="ee8efaddcdb7929ada76230c032dd700897cd47f" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights accross all updates and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches &lt;code&gt;average&lt;/code&gt;. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="translated">设置为True时，将计算所有更新的平均SGD权重并将结果存储在 &lt;code&gt;coef_&lt;/code&gt; 属性中。如果将int设置为大于1，则一旦看到的样本总数达到 &lt;code&gt;average&lt;/code&gt; ，就会开始平均。因此， &lt;code&gt;average=10&lt;/code&gt; 将在看到10个样本后开始平均。</target>
        </trans-unit>
        <trans-unit id="0199409f1eeb1aa7581c717d5c23e182af166761" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="translated">设置为True时，将计算平均SGD权重并将结果存储在 &lt;code&gt;coef_&lt;/code&gt; 属性中。如果将int设置为大于1，则一旦看到的样本总数达到平均值，就会开始平均。因此， &lt;code&gt;average=10&lt;/code&gt; 将在看到10个样本后开始平均。</target>
        </trans-unit>
        <trans-unit id="19c4ca669b90d48df2f3aa161b89103ea08c0cbd" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.</source>
          <target state="translated">设置为True时，将计算平均SGD权重并将结果存储在 &lt;code&gt;coef_&lt;/code&gt; 属性中。如果将int设置为大于1，则一旦看到的样本总数达到平均值，就会开始平均。因此，平均值= 10将在看到10个样本后开始平均。</target>
        </trans-unit>
        <trans-unit id="e60b70114bd43f63c876204c608aaaaca2e5c6d2" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为True时，请重用上一个调用的解决方案以适合并为集合添加更多估计量，否则，仅适合一个全新的集合。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="fb1187119affc46cd36d1e1403f76ef562249b84" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为True时，请重用上一个调用的解决方案以进行拟合，并向集合中添加更多的估计量，否则，只需拟合一个全新的集合即可。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0615ecfccfe9c12eea86adfdd92570d0b3a6f9cf" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为True时，请重用上一个调用的解决方案以适合初始化，否则，只需擦除以前的解决方案即可。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b9ddbc0f60da434a4d403c500c89b585a3aeef7d" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为True时，请重用上一个调用的解决方案以适合初始化，否则，只需擦除以前的解决方案即可。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="869683b3c71be56286e995de01f21c989fc735d8" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为True时，请重用上一个调用的解决方案以适合初始化，否则，只需擦除以前的解决方案即可。对于liblinear求解器无用。请参阅&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="90df9a75b07a1010dc74b460f30a26d769910e81" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">设置为True时，请重用上一个调用的解决方案以适合初始化，否则，只需擦除以前的解决方案即可。对于liblinear求解器无用。请参阅&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="61362ce0a02977970071e88e9dc71d066251fcde" translate="yes" xml:space="preserve">
          <source>When specifying multiple metrics, the &lt;code&gt;refit&lt;/code&gt; parameter must be set to the metric (string) for which the &lt;code&gt;best_params_&lt;/code&gt; will be found and used to build the &lt;code&gt;best_estimator_&lt;/code&gt; on the whole dataset. If the search should not be refit, set &lt;code&gt;refit=False&lt;/code&gt;. Leaving refit to the default value &lt;code&gt;None&lt;/code&gt; will result in an error when using multiple metrics.</source>
          <target state="translated">当指定多个指标时，必须将 &lt;code&gt;refit&lt;/code&gt; 参数设置为将为其找到 &lt;code&gt;best_params_&lt;/code&gt; 的指标（字符串），并用于在整个数据集上构建 &lt;code&gt;best_estimator_&lt;/code&gt; 。如果搜索不应该进行调整，则设置 &lt;code&gt;refit=False&lt;/code&gt; 。如果将调整保留为默认值&amp;ldquo; &lt;code&gt;None&lt;/code&gt; 则在使用多个指标时将导致错误。</target>
        </trans-unit>
        <trans-unit id="8303fa1cd1689a65bba6fc9b59c3502d4f370e6f" translate="yes" xml:space="preserve">
          <source>When starting from the default values (alpha_init = 1.90, lambda_init = 1.), the bias of the resulting curve is large, and the variance is small. So, lambda_init should be relatively small (1.e-3) so as to reduce the bias.</source>
          <target state="translated">当从默认值(alpha_init=1.90,lambda_init=1.)开始计算时,得出的曲线偏差较大,方差较小。所以,lambda_init应该相对较小(1.e-3),这样才能减少偏差。</target>
        </trans-unit>
        <trans-unit id="765386eefc1dd2e9ed203024ee007c99e07f6618" translate="yes" xml:space="preserve">
          <source>When strategy == &amp;ldquo;constant&amp;rdquo;, fill_value is used to replace all occurrences of missing_values. If left to the default, fill_value will be 0 when imputing numerical data and &amp;ldquo;missing_value&amp;rdquo; for strings or object data types.</source>
          <target state="translated">当strategy ==&amp;ldquo; constant&amp;rdquo;时，fill_value用于替换所有missing_values出现的情况。如果保留默认值，则在填充数字数据时fill_value将为0，而对于字符串或对象数据类型则为&amp;ldquo; missing_value&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="234c27f3e17ce7a8cf496679483a69e65bcabb05" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;Pipeline&lt;/code&gt; is printed out in a jupyter notebook an HTML representation of the estimator is displayed as follows:</source>
          <target state="translated">当在jupyter笔记本中打印出 &lt;code&gt;Pipeline&lt;/code&gt; 时，估算器的HTML表示将显示如下：</target>
        </trans-unit>
        <trans-unit id="b3973bbeeefced2bd7eb8aaa05fcc0fadc5e600b" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;cv&lt;/code&gt; argument is an integer, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; uses the &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; strategies by default, the latter being used if the estimator derives from &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt;&lt;code&gt;ClassifierMixin&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">当 &lt;code&gt;cv&lt;/code&gt; 参数是整数时，默认情况下，&lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt;使用&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;策略，如果估计器派生自&lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt; &lt;code&gt;ClassifierMixin&lt;/code&gt; &lt;/a&gt;，则使用后者。</target>
        </trans-unit>
        <trans-unit id="c7d238875ff93bafa2620f7a2d7675b937a2183b" translate="yes" xml:space="preserve">
          <source>When the algorithm does not converge, it returns an empty array as &lt;code&gt;cluster_center_indices&lt;/code&gt; and &lt;code&gt;-1&lt;/code&gt; as label for each training sample.</source>
          <target state="translated">当算法不收敛，则返回一个空数组作为 &lt;code&gt;cluster_center_indices&lt;/code&gt; 和 &lt;code&gt;-1&lt;/code&gt; 作为标签每个训练样本。</target>
        </trans-unit>
        <trans-unit id="b4fdfb364ee084bf57bd04a0f7c8f0c41739edf4" translate="yes" xml:space="preserve">
          <source>When the data is not initially in the &lt;code&gt;(n_samples, n_features)&lt;/code&gt; shape, it needs to be preprocessed in order to be used by scikit-learn.</source>
          <target state="translated">当数据最初不是 &lt;code&gt;(n_samples, n_features)&lt;/code&gt; 形状时，需要对其进行预处理，以供scikit-learn使用。</target>
        </trans-unit>
        <trans-unit id="4b1639b675f158aa2d42c71150242e159f59e266" translate="yes" xml:space="preserve">
          <source>When the missingness pattern is predictive, the splits can be done on whether the feature value is missing or not:</source>
          <target state="translated">当缺失性模式具有预测性时,可以对特征值是否缺失进行拆分。</target>
        </trans-unit>
        <trans-unit id="90e4401cde0f238342524a25385b7071cd57b4a0" translate="yes" xml:space="preserve">
          <source>When the underlying implementation uses joblib, the number of workers (threads or processes) that are spawned in parallel can be controlled via the &lt;code&gt;n_jobs&lt;/code&gt; parameter.</source>
          <target state="translated">当基础实现使用joblib时，可以通过 &lt;code&gt;n_jobs&lt;/code&gt; 参数控制并行产生的工作程序（线程或进程）的数量。</target>
        </trans-unit>
        <trans-unit id="aaeec02a52e8579f06c37808c9e18fa50d637a08" translate="yes" xml:space="preserve">
          <source>When there are more than two labels, the value of the MCC will no longer range between -1 and +1. Instead the minimum value will be somewhere between -1 and 0 depending on the number and distribution of ground true labels. The maximum value is always +1.</source>
          <target state="translated">当有两个以上的标签时,MCC的值将不再在-1和+1之间。取而代之的是,最小值将介于-1和0之间,这取决于地面真标签的数量和分布。最大值总是+1。</target>
        </trans-unit>
        <trans-unit id="5c69ffd1e0dc71befa67c00726bc6370582b5df5" translate="yes" xml:space="preserve">
          <source>When there is no correlation between the outputs, a very simple way to solve this kind of problem is to build n independent models, i.e. one for each output, and then to use those models to independently predict each one of the n outputs. However, because it is likely that the output values related to the same input are themselves correlated, an often better way is to build a single model capable of predicting simultaneously all n outputs. First, it requires lower training time since only a single estimator is built. Second, the generalization accuracy of the resulting estimator may often be increased.</source>
          <target state="translated">当输出之间不存在相关性时,解决这类问题的一个非常简单的方法是建立n个独立的模型,即每个输出一个模型,然后用这些模型独立预测n个输出中的每一个。然而,由于与同一输入相关的输出值本身很可能是相关的,所以一个通常更好的方法是建立一个能够同时预测所有n个输出的单一模型。首先,由于只建立一个估计器,所以需要的训练时间较少。其次,所得到的估计器的泛化精度往往可以提高。</target>
        </trans-unit>
        <trans-unit id="ebcc7b732996f47559f9fb2cca7527f873584d5f" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikit-learn and joblib need to be compatible. Currently, joblib 0.11+ is supported. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="translated">当这个环境变量被设置为非零时,scikit-learn会使用站点的joblib而不是它的销售版本。因此,scikit-learn必须安装joblib才能运行。请注意,使用站点joblib是要自己承担风险的:scikit-learn和joblib的版本需要兼容。目前,支持joblib 0.11+。此外,来自joblib.Memory的转储可能不兼容,你可能会丢失一些缓存,不得不重新下载一些数据集。</target>
        </trans-unit>
        <trans-unit id="8c7fa59e2b8c1ce3abb542d1d5f76caddd1816f1" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikt-learn and joblib need to be compatible. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="translated">当这个环境变量被设置为非零时,scikit-learn会使用站点的joblib而不是它的销售版本。因此,scikit-learn必须安装joblib才能运行。请注意,使用 site joblib 是要自己承担风险的:scikt-learn 和 joblib 的版本需要兼容。此外,来自 joblib.Memory 的转储可能不兼容,你可能会丢失一些缓存,不得不重新下载一些数据集。</target>
        </trans-unit>
        <trans-unit id="743d4762d28a3d61488ddf12d10bce762b152657" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, the tests that need network access are skipped.</source>
          <target state="translated">当这个环境变量被设置为非零时,需要网络访问的测试将被跳过。</target>
        </trans-unit>
        <trans-unit id="beb3490e0a85d3bcf9f4888cb75a6b1ea2e1e6a8" translate="yes" xml:space="preserve">
          <source>When training an SVM with the &lt;em&gt;Radial Basis Function&lt;/em&gt; (RBF) kernel, two parameters must be considered: &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. The parameter &lt;code&gt;C&lt;/code&gt;, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low &lt;code&gt;C&lt;/code&gt; makes the decision surface smooth, while a high &lt;code&gt;C&lt;/code&gt; aims at classifying all training examples correctly. &lt;code&gt;gamma&lt;/code&gt; defines how much influence a single training example has. The larger &lt;code&gt;gamma&lt;/code&gt; is, the closer other examples must be to be affected.</source>
          <target state="translated">当使用&lt;em&gt;径向基函数&lt;/em&gt;（RBF）内核训练SVM时，必须考虑两个参数： &lt;code&gt;C&lt;/code&gt; 和 &lt;code&gt;gamma&lt;/code&gt; 。所有SVM内核共有的参数 &lt;code&gt;C&lt;/code&gt; 权衡了训练示例的错误分类和决策面的简单性。低 &lt;code&gt;C&lt;/code&gt; 可使决策表面平滑，而高 &lt;code&gt;C&lt;/code&gt; 旨在正确分类所有训练示例。 &lt;code&gt;gamma&lt;/code&gt; 定义单个培训示例的影响力。 &lt;code&gt;gamma&lt;/code&gt; 值越大，其他示例必须受到的影响越近。</target>
        </trans-unit>
        <trans-unit id="4f5d7a3d8a7ab119798fbec5ead8471db219e63d" translate="yes" xml:space="preserve">
          <source>When true, the result is adjusted for chance, so that random performance would score 0, and perfect performance scores 1.</source>
          <target state="translated">当为真时,根据偶然性对结果进行调整,因此随机表现将得0分,完美表现得1分。</target>
        </trans-unit>
        <trans-unit id="7dbd1175230450ef2444fe8de9e5557001f2473c" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt;), this transformation is known as &lt;a href=&quot;https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="translated">当将截短的SVD应用于术语文档矩阵（由&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;或&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; &lt;/a&gt;返回）时，此转换称为&lt;a href=&quot;https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;潜在语义分析&lt;/a&gt;（LSA），因为它将此类矩阵转换为低维的&amp;ldquo;语义&amp;rdquo;空间。尤其是，众所周知，LSA可以消除同义词和多义性的影响（这两者均大致意味着每个单词具有多种含义），这会导致术语文档矩阵过于稀疏，并且在诸如余弦相似度的度量下显示出较差的相似度。</target>
        </trans-unit>
        <trans-unit id="a756308318fb23f07be0498c8c83a0d088f9279a" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;code&gt;CountVectorizer&lt;/code&gt; or &lt;code&gt;TfidfVectorizer&lt;/code&gt;), this transformation is known as &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="translated">当将截短的SVD应用于术语文档矩阵（由 &lt;code&gt;CountVectorizer&lt;/code&gt; 或 &lt;code&gt;TfidfVectorizer&lt;/code&gt; 返回）时，此转换称为&lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;潜在语义分析&lt;/a&gt;（LSA），因为它将此类矩阵转换为低维的&amp;ldquo;语义&amp;rdquo;空间。尤其是，众所周知，LSA可以消除同义词和多义性的影响（这两者都大致意味着每个单词具有多种含义），这会导致术语文档矩阵过于稀疏，并且在诸如余弦相似度的测量下显示出较差的相似度。</target>
        </trans-unit>
        <trans-unit id="38dbd2ff8901fd68988a77a08c59409f80468575" translate="yes" xml:space="preserve">
          <source>When two features are correlated and one of the features is permuted, the model will still have access to the feature through its correlated feature. This will result in a lower importance value for both features, where they might &lt;em&gt;actually&lt;/em&gt; be important.</source>
          <target state="translated">当两个特征相关联并且其中一个特征被置换时，模型仍然可以通过其相关联的特征访问特征。这将导致两个功能的重要性值降低，而这两个功能&lt;em&gt;实际上&lt;/em&gt;可能很重要。</target>
        </trans-unit>
        <trans-unit id="726430099b436b4edbed2772b4e46aec59296fe0" translate="yes" xml:space="preserve">
          <source>When used for text classification with tf-idf vectors, this classifier is also known as the Rocchio classifier.</source>
          <target state="translated">当使用tf-idf向量进行文本分类时,这种分类器也被称为Rocchio分类器。</target>
        </trans-unit>
        <trans-unit id="b1373e66b4937bbac8defef2fa925bed61a8d596" translate="yes" xml:space="preserve">
          <source>When used to &lt;em&gt;transform&lt;/em&gt; data, PCA can reduce the dimensionality of the data by projecting on a principal subspace.</source>
          <target state="translated">当用于&lt;em&gt;转换&lt;/em&gt;数据时，PCA可以通过投影在主要子空间上来降低数据的维数。</target>
        </trans-unit>
        <trans-unit id="93429c223efcd8d6622a4c8e5f0e71f13358e226" translate="yes" xml:space="preserve">
          <source>When using &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;multiclass classifiers&lt;/code&gt;&lt;/a&gt;, the learning and prediction task that is performed is dependent on the format of the target data fit upon:</source>
          <target state="translated">使用&lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;multiclass classifiers&lt;/code&gt; &lt;/a&gt;，执行的学习和预测任务取决于适合的目标数据的格式：</target>
        </trans-unit>
        <trans-unit id="bf430655a414d830d0ddbbfedf78ab7c208919a9" translate="yes" xml:space="preserve">
          <source>When using Averaged SGD (with the &lt;code&gt;average&lt;/code&gt; parameter), &lt;code&gt;coef_&lt;/code&gt; is set to the average weight across all updates: &lt;code&gt;coef_&lt;/code&gt;\(= \frac{1}{T} \sum_{t=0}^{T-1} w^{(t)}\), where \(T\) is the total number of updates, found in the &lt;code&gt;t_&lt;/code&gt; attribute.</source>
          <target state="translated">使用平均SGD（带有 &lt;code&gt;average&lt;/code&gt; 参数）时， &lt;code&gt;coef_&lt;/code&gt; 设置为所有更新的平均权重： &lt;code&gt;coef_&lt;/code&gt; \（= \ frac {1} {T} \ sum_ {t = 0} ^ {T-1} w ^ { （t）} \），其中\（T \）是在 &lt;code&gt;t_&lt;/code&gt; 属性中找到的更新总数。</target>
        </trans-unit>
        <trans-unit id="cb56aa339cbb48c9a75d42d2c7bf7e7858b3170b" translate="yes" xml:space="preserve">
          <source>When using ensemble methods base upon bagging, i.e. generating new training sets using sampling with replacement, part of the training set remains unused. For each classifier in the ensemble, a different part of the training set is left out.</source>
          <target state="translated">当使用基于袋的合集方法时,即使用采样与替换的方法生成新的训练集,部分训练集仍未使用。对于合集中的每一个分类器,训练集的不同部分都会被遗漏。</target>
        </trans-unit>
        <trans-unit id="7a60d247990a32a468cae00d5ed7b0c825a81e35" translate="yes" xml:space="preserve">
          <source>When using the &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; in a &lt;code&gt;Pipeline&lt;/code&gt;, be sure to use the &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt; to add the indicator features to the regular features. First we obtain the &lt;code&gt;iris&lt;/code&gt; dataset, and add some missing values to it.</source>
          <target state="translated">在 &lt;code&gt;Pipeline&lt;/code&gt; 使用&lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt;时，请确保使用 &lt;code&gt;FeatureUnion&lt;/code&gt; 或 &lt;code&gt;ColumnTransformer&lt;/code&gt; 将指示器功能添加到常规功能中。首先，我们获取 &lt;code&gt;iris&lt;/code&gt; 数据集，并向其中添加一些缺失值。</target>
        </trans-unit>
        <trans-unit id="a9696826aefafecc5b32845bc270f3c2cabe6664" translate="yes" xml:space="preserve">
          <source>When using these images, please give credit to AT&amp;amp;T Laboratories Cambridge.</source>
          <target state="translated">使用这些图像时，请归功于AT＆T剑桥实验室。</target>
        </trans-unit>
        <trans-unit id="5a6f9e7437ff7d6762455e24a46c4771dc2e0a37" translate="yes" xml:space="preserve">
          <source>When using, for example, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;, to set the amount of regularization with &lt;code&gt;C&lt;/code&gt;, there will be a different amount of samples between the main problem and the smaller problems within the folds of the cross validation.</source>
          <target state="translated">例如，当使用&lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;交叉验证&lt;/a&gt;来设置 &lt;code&gt;C&lt;/code&gt; 的正则化量时，在交叉验证范围内，主要问题和较小问题之间将存在不同数量的样本。</target>
        </trans-unit>
        <trans-unit id="5dae0cb2a4d8c33bb8e68ee9ffd452db73e27eb2" translate="yes" xml:space="preserve">
          <source>When we apply clustering to the data, we find that the clustering reflects what was in the distance matrices. Indeed, for the Euclidean distance, the classes are ill-separated because of the noise, and thus the clustering does not separate the waveforms. For the cityblock distance, the separation is good and the waveform classes are recovered. Finally, the cosine distance does not separate at all waveform 1 and 2, thus the clustering puts them in the same cluster.</source>
          <target state="translated">当我们对数据应用聚类时,我们发现聚类反映了距离矩阵中的内容。事实上,对于欧氏距离,由于噪声的存在,类的分离度不高,因此聚类不能分离波形。对于城块距离,分离度很好,波形类被恢复。最后,余弦距离完全不能分离波形1和2,因此聚类将它们放在同一个聚类中。</target>
        </trans-unit>
        <trans-unit id="8975b7dd097c19a6af3c2b4b090f357f96aab52d" translate="yes" xml:space="preserve">
          <source>When working with covariance estimation, the usual approach is to use a maximum likelihood estimator, such as the &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;. It is unbiased, i.e. it converges to the true (population) covariance when given many observations. However, it can also be beneficial to regularize it, in order to reduce its variance; this, in turn, introduces some bias. This example illustrates the simple regularization used in &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;Shrunk Covariance&lt;/a&gt; estimators. In particular, it focuses on how to set the amount of regularization, i.e. how to choose the bias-variance trade-off.</source>
          <target state="translated">使用协方差估计时，通常的方法是使用最大似然估计器，例如&lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;。它是无偏的，即，在进行大量观察时，它收敛到真实的（种群）协方差。但是，对它进行正则化以减少其方差也可能是有益的。这反过来带来了一些偏见。此示例说明了&lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;收缩协方差&lt;/a&gt;估计器中使用的简单正则化。特别是，它着重于如何设置正则化量，即如何选择偏差方差折衷。</target>
        </trans-unit>
        <trans-unit id="17b704aa73a46ef6f9edddecff620d33c0b705d7" translate="yes" xml:space="preserve">
          <source>When you want to apply different transformations to each field of the data, see the related class &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; (see &lt;a href=&quot;#column-transformer&quot;&gt;user guide&lt;/a&gt;).</source>
          <target state="translated">如果要对数据的每个字段应用不同的转换，请参见相关的类&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt;（请参阅&lt;a href=&quot;#column-transformer&quot;&gt;用户指南&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="8d5450715de6c511faca4e5034a6c5d189b2299d" translate="yes" xml:space="preserve">
          <source>Where (and how) parallelization happens in the estimators is currently poorly documented. Please help us by improving our docs and tackle &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14228&quot;&gt;issue 14228&lt;/a&gt;!</source>
          <target state="translated">目前，有关估计器中并行化发生在何处（以及如何进行）的文献很少。请通过改善文档来解决&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14228&quot;&gt;问题14228来&lt;/a&gt;帮助我们！</target>
        </trans-unit>
        <trans-unit id="ffd889b6ef09600260c419603787a00c67ae551d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in both the true labels and the predicted labels), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in the true labels and not in the predicted labels) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in the predicted labels and not in the true labels).</source>
          <target state="translated">其中 &lt;code&gt;TP&lt;/code&gt; 是&lt;strong&gt;True Positive&lt;/strong&gt;的数量（即，在真标签和预测标签中属于同一聚类的点对的数量）， &lt;code&gt;FP&lt;/code&gt; 是&lt;strong&gt;False Positive&lt;/strong&gt;的数量（即属于&lt;strong&gt;正&lt;/strong&gt;标签的点对的数量）表示真实标签而不是预测标签中的相同聚类）， &lt;code&gt;FN&lt;/code&gt; 是&lt;strong&gt;假阴性&lt;/strong&gt;（即，在预测标签中而不是真实标签中属于同一聚类的点对的数量）。</target>
        </trans-unit>
        <trans-unit id="276f699fa82da6208d110c0a23b40d61550922dd" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in both &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;labels_pred&lt;/code&gt;), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_true&lt;/code&gt; and not in &lt;code&gt;labels_pred&lt;/code&gt;) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_pred&lt;/code&gt; and not in &lt;code&gt;labels_True&lt;/code&gt;).</source>
          <target state="translated">其中 &lt;code&gt;TP&lt;/code&gt; 是&lt;strong&gt;True正数&lt;/strong&gt;（即， &lt;code&gt;labels_true&lt;/code&gt; 和 &lt;code&gt;labels_pred&lt;/code&gt; 中属于同一群集的点对的数量）， &lt;code&gt;FP&lt;/code&gt; 是&lt;strong&gt;False Positive&lt;/strong&gt;（即，同一簇中的点对的数量）在 &lt;code&gt;labels_true&lt;/code&gt; 中而不在 &lt;code&gt;labels_pred&lt;/code&gt; 中），并且 &lt;code&gt;FN&lt;/code&gt; 是&lt;strong&gt;假负数&lt;/strong&gt;（即，在 &lt;code&gt;labels_pred&lt;/code&gt; 中属于同一集群而不在 &lt;code&gt;labels_True&lt;/code&gt; 中的点对的数量）。</target>
        </trans-unit>
        <trans-unit id="e78195e2eb2711f3bb8a0d7f4e3c56eea492c48d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;delta&lt;/code&gt; is a free parameter representing the width of the Gaussian kernel.</source>
          <target state="translated">其中 &lt;code&gt;delta&lt;/code&gt; 是代表高斯核宽度的自由参数。</target>
        </trans-unit>
        <trans-unit id="6d88fb8179777bb060d39d8e880a1a6ec89efb59" translate="yes" xml:space="preserve">
          <source>Where C is the number of permutations whose score &amp;gt;= the true score.</source>
          <target state="translated">其中C是其分数&amp;gt; =真实分数的排列数量。</target>
        </trans-unit>
        <trans-unit id="0426d1b8d26623c0079356962f68cf2595f6d67a" translate="yes" xml:space="preserve">
          <source>Where D is the matrix of distances for the input data X, D_fit is the matrix of distances for the output embedding X_fit, and K is the isomap kernel:</source>
          <target state="translated">其中,D为输入数据X的距离矩阵,D_fit为输出嵌入X_fit的距离矩阵,K为同构核。</target>
        </trans-unit>
        <trans-unit id="77844a8258430d31f41a5c27fd5c3c817a4c46f5" translate="yes" xml:space="preserve">
          <source>Where \(C_2^{n_{samples}}\) is the total number of possible pairs in the dataset (without ordering).</source>
          <target state="translated">其中/(C_2^{n_{samples}}/)是数据集中可能的数据对总数(不排序)。</target>
        </trans-unit>
        <trans-unit id="45f9706f8e40bfee3b8f4082279b7c1694d8aead" translate="yes" xml:space="preserve">
          <source>Where \(K\) is the precision matrix to be estimated, and \(S\) is the sample covariance matrix. \(\|K\|_1\) is the sum of the absolute values of off-diagonal coefficients of \(K\). The algorithm employed to solve this problem is the GLasso algorithm, from the Friedman 2008 Biostatistics paper. It is the same algorithm as in the R &lt;code&gt;glasso&lt;/code&gt; package.</source>
          <target state="translated">其中\（K \）是要估计的精度矩阵，\（S \）是样本协方差矩阵。\（\ | K \ | _1 \）是\（K \）的非对角系数的绝对值之和。用于解决此问题的算法是GLasso算法，该算法来自Friedman 2008 Biostatistics论文。它与R &lt;code&gt;glasso&lt;/code&gt; 软件包中的算法相同。</target>
        </trans-unit>
        <trans-unit id="23038cc6fb25ab648004d5485267f6db76cb9eda" translate="yes" xml:space="preserve">
          <source>Where \(N(x_i)\) is the neighborhood of samples within a given distance around \(x_i\) and \(m\) is the &lt;em&gt;mean shift&lt;/em&gt; vector that is computed for each centroid that points towards a region of the maximum increase in the density of points. This is computed using the following equation, effectively updating a centroid to be the mean of the samples within its neighborhood:</source>
          <target state="translated">其中\（N（x_i）\）是在\（x_i \）周围给定距离内的样本邻域，而\（m \）是针对每个指向最大增加区域的质心计算的&lt;em&gt;平均偏移&lt;/em&gt;矢量在点的密度。这是使用以下公式计算的，可以有效地将质心更新为其附近样本的平均值：</target>
        </trans-unit>
        <trans-unit id="c4be16a40b65a723b122e1219966e4db066c1f56" translate="yes" xml:space="preserve">
          <source>Where \(R\) is the diagonal matrix with entry \(i\) equal to \(\sum_{j} A_{ij}\) and \(C\) is the diagonal matrix with entry \(j\) equal to \(\sum_{i} A_{ij}\).</source>
          <target state="translated">其中/(R/\)是对角矩阵,条目/(i/)等于/(sum_{j}A_{ij}/),而/(C/)是对角矩阵,条目/(j)等于/(sum_{i}A_{ij}/)。</target>
        </trans-unit>
        <trans-unit id="06bd15907339a321f45a7707ee037e3bf4bb294c" translate="yes" xml:space="preserve">
          <source>Where \(\langle \cdot, \cdot \rangle\) denotes the inner product in the Hilbert space.</source>
          <target state="translated">其中,(langle cdot,cdot rangle/)表示Hilbert空间的内积。</target>
        </trans-unit>
        <trans-unit id="b505305e3f68e0055136674f6671623549265da7" translate="yes" xml:space="preserve">
          <source>Where \(\log_e (x)\) means the natural logarithm of \(x\). This metric is best to use when targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.</source>
          <target state="translated">其中\(\log_e (x)\)是指\(x)的自然对数。当目标具有指数增长时,如人口数量、某商品多年的平均销售量等,最好使用这种度量方法。需要注意的是,这一指标对预测不足的估计值比预测过高的估计值进行惩罚。</target>
        </trans-unit>
        <trans-unit id="dc652afd01d2a671ac597240d27fcb8fb6f2cb88" translate="yes" xml:space="preserve">
          <source>Where \(s(i, k)\) is the similarity between samples \(i\) and \(k\). The availability of sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">其中,(s(i,k))是样本(i)和(k)之间的相似度。样本(k)是否能成为样本(i)的典范由以下公式给出:</target>
        </trans-unit>
        <trans-unit id="9fa1e5b532b4ed4720d23061371103281dda3d83" translate="yes" xml:space="preserve">
          <source>Where r is defined per sample, we need to make use of &lt;code&gt;start&lt;/code&gt;:</source>
          <target state="translated">其中每个样本定义了r，我们需要使用 &lt;code&gt;start&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="c16b06fa7e959786262fbf5823a1d1a66514be0c" translate="yes" xml:space="preserve">
          <source>Where the step length \(\gamma_m\) is chosen using line search:</source>
          <target state="translated">其中步长/(gamma_m/)是用行搜索选择的。</target>
        </trans-unit>
        <trans-unit id="096f899281fbd2d32d659004bce326784eacf79e" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given &lt;code&gt;cv_results_&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="translated">在选择最佳估算器时，除了最大分数之外，还可以考虑将 &lt;code&gt;refit&lt;/code&gt; 设置为一个函数，该函数在给定 &lt;code&gt;cv_results_&lt;/code&gt; 的情况下返回所选的 &lt;code&gt;best_index_&lt;/code&gt; 。在这种情况下，将根据返回的 &lt;code&gt;best_index_&lt;/code&gt; 设置 &lt;code&gt;best_estimator_&lt;/code&gt; 和 &lt;code&gt;best_params_&lt;/code&gt; ,而 &lt;code&gt;best_score_&lt;/code&gt; 属性将不可用。</target>
        </trans-unit>
        <trans-unit id="be446fd5f2cab9d9132f73b7df79724fa271f7f8" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given the &lt;code&gt;cv_results&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="translated">在选择最佳估算器时，除了最大分数之外，还可以考虑将 &lt;code&gt;refit&lt;/code&gt; 设置为一个函数，该函数在给定 &lt;code&gt;cv_results&lt;/code&gt; 的情况下返回所选的 &lt;code&gt;best_index_&lt;/code&gt; 。在这种情况下，将根据返回的 &lt;code&gt;best_index_&lt;/code&gt; 设置 &lt;code&gt;best_estimator_&lt;/code&gt; 和 &lt;code&gt;best_params_&lt;/code&gt; ,而 &lt;code&gt;best_score_&lt;/code&gt; 属性将不可用。</target>
        </trans-unit>
        <trans-unit id="1e4c7785f80a06d28d2e2b965c377764abc1c026" translate="yes" xml:space="preserve">
          <source>Where to from here</source>
          <target state="translated">从这里去哪里</target>
        </trans-unit>
        <trans-unit id="17eb390ca1dec9880beb722610077dafb8edc9ac" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features] and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">其中u和v是从形状为[n_样本,n_特征]的数据集中取出的任意行,p是由形状为[n_成分,n_特征]的随机高斯N(0,1)矩阵(或稀疏的Achlioptas矩阵)进行投影。</target>
        </trans-unit>
        <trans-unit id="c5759c4abe89df832c23e0269eba38e4f1ad0ad7" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features], eps is in ]0, 1[ and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">其中u和v是从形状为[n_samples,n_features]的数据集中取出的任意行,eps是在]0,1[中,p是由形状为[n_components,n_features]的随机高斯N(0,1)矩阵(或稀疏的Achlioptas矩阵)投影。</target>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="translated">Where:</target>
        </trans-unit>
        <trans-unit id="16270a9447d061ffaba6de4c25d0370619ae5579" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting.</source>
          <target state="translated">拟合时是否应该对 &lt;code&gt;feature_names_&lt;/code&gt; 和 &lt;code&gt;vocabulary_&lt;/code&gt; 进行排序。</target>
        </trans-unit>
        <trans-unit id="07f1abf8acdb3dcd49bde3ee8a201c3421831b31" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting. True by default.</source>
          <target state="translated">拟合时是否应该对 &lt;code&gt;feature_names_&lt;/code&gt; 和 &lt;code&gt;vocabulary_&lt;/code&gt; 进行排序。默认为True。</target>
        </trans-unit>
        <trans-unit id="e61b5eefa6a0d8caaa65c0cf06600523e6eded8c" translate="yes" xml:space="preserve">
          <source>Whether a forced copy will be triggered. If copy=False, a copy might be triggered by a conversion.</source>
          <target state="translated">是否会触发强制复制。如果copy=False,则可能通过转换来触发复制。</target>
        </trans-unit>
        <trans-unit id="6817dee267fec06b200988a35092c9fafdb28df4" translate="yes" xml:space="preserve">
          <source>Whether a prefit model is expected to be passed into the constructor directly or not. If True, &lt;code&gt;transform&lt;/code&gt; must be called directly and SelectFromModel cannot be used with &lt;code&gt;cross_val_score&lt;/code&gt;, &lt;code&gt;GridSearchCV&lt;/code&gt; and similar utilities that clone the estimator. Otherwise train the model using &lt;code&gt;fit&lt;/code&gt; and then &lt;code&gt;transform&lt;/code&gt; to do feature selection.</source>
          <target state="translated">预设模型是否应该直接传递给构造函数。如果为True，则必须直接调用 &lt;code&gt;transform&lt;/code&gt; ,并且SelectFromModel不能与 &lt;code&gt;cross_val_score&lt;/code&gt; ， &lt;code&gt;GridSearchCV&lt;/code&gt; 和克隆估算器的类似实用程序一起使用。否则，使用 &lt;code&gt;fit&lt;/code&gt; 训练模型，然后进行 &lt;code&gt;transform&lt;/code&gt; 以进行特征选择。</target>
        </trans-unit>
        <trans-unit id="e67f675f1639113224879739e0229eb2671df0d3" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style.</source>
          <target state="translated">一个数组是否会被强制为fortran或c-style。</target>
        </trans-unit>
        <trans-unit id="57d1f88164d54372295bc307285273118c662089" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style. When order is None (default), then if copy=False, nothing is ensured about the memory layout of the output array; otherwise (copy=True) the memory layout of the returned array is kept as close as possible to the original array.</source>
          <target state="translated">数组是否会被强制为fortran或c-style。当order为None(默认)时,如果copy=False,则不保证输出数组的内存布局;否则(copy=True),返回数组的内存布局将尽可能地接近原始数组。</target>
        </trans-unit>
        <trans-unit id="f6541283616583040ce3e73f070cbb436dbc5da9" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees.</source>
          <target state="translated">建树时是否使用引导样本。</target>
        </trans-unit>
        <trans-unit id="1349327857b1cdc30e7f508422cffd4b74a570bf" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.</source>
          <target state="translated">构建树时是否使用引导样本。如果为假,则使用整个数据集来构建每棵树。</target>
        </trans-unit>
        <trans-unit id="344e324f858395af07d0534305d3cd485a522869" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; is passed. If &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to &lt;code&gt;zero_based=True&lt;/code&gt; to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">f中的列索引是从零开始（真）还是从一开始（假）。如果列索引基于1，则将其转换为基于0的索引，以匹配Python / NumPy约定。如果设置为&amp;ldquo;自动&amp;rdquo;，则将应用启发式检查从文件内容中确定。两种文件都&amp;ldquo;野外&amp;rdquo;出现，但不幸的是它们无法自我识别。当没有 &lt;code&gt;offset&lt;/code&gt; 或 &lt;code&gt;length&lt;/code&gt; 传递时，使用&amp;ldquo; auto&amp;rdquo;或&amp;ldquo; True&amp;rdquo;应该总是安全的。如果传递了 &lt;code&gt;offset&lt;/code&gt; 或 &lt;code&gt;length&lt;/code&gt; ，则&amp;ldquo;自动&amp;rdquo;模式会退回到 &lt;code&gt;zero_based=True&lt;/code&gt; ,以避免在文件的不同段上启发式检查产生不一致的结果。</target>
        </trans-unit>
        <trans-unit id="f00bfe1387e4927051573cb3d574287560206c66" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no offset or length is passed. If offset or length are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to zero_based=True to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">f中的列索引是从零开始（真）还是从一开始（假）。如果列索引基于1，则将其转换为基于0的索引，以匹配Python / NumPy约定。如果设置为&amp;ldquo;自动&amp;rdquo;，则将应用启发式检查从文件内容中确定。两种文件都&amp;ldquo;野外&amp;rdquo;出现，但不幸的是它们无法自我识别。当没有偏移或长度传递时，使用&amp;ldquo; auto&amp;rdquo;或&amp;ldquo; True&amp;rdquo;应该总是安全的。如果传递了偏移量或长度，则&amp;ldquo;自动&amp;rdquo;模式会退回到zero_based = True，以避免在文件的不同段上启发式检查产生不一致的结果。</target>
        </trans-unit>
        <trans-unit id="be05ee9a303aba9073e602f5af4606db8dba467c" translate="yes" xml:space="preserve">
          <source>Whether column indices should be written zero-based (True) or one-based (False).</source>
          <target state="translated">列索引是否应该写成基于零的(True)或基于一的(False)。</target>
        </trans-unit>
        <trans-unit id="426c392bb98aa08b186e867710abfa024378fa01" translate="yes" xml:space="preserve">
          <source>Whether features are drawn with replacement.</source>
          <target state="translated">是否特征画与替换。</target>
        </trans-unit>
        <trans-unit id="b1153e9c8e50c0d286811aaf218a31fa047ae93d" translate="yes" xml:space="preserve">
          <source>Whether or not a second normalization of the weights is performed. The default behavior mirrors the implementations found in Mahout and Weka, which do not follow the full algorithm described in Table 9 of the paper.</source>
          <target state="translated">是否对权重进行第二次归一化。默认行为反映了Mahout和Weka中的实现,它们没有遵循本文表9中描述的完整算法。</target>
        </trans-unit>
        <trans-unit id="1500a013d74d8899d6c67c8489e35470d425474d" translate="yes" xml:space="preserve">
          <source>Whether or not the model should use an intercept, i.e. a biased hyperplane, is controlled by the parameter &lt;code&gt;fit_intercept&lt;/code&gt;.</source>
          <target state="translated">模型是否应使用截距（即，偏置超平面）由参数 &lt;code&gt;fit_intercept&lt;/code&gt; 控制。</target>
        </trans-unit>
        <trans-unit id="c17699d69c93a1c9674665b22c836f689e7a71a8" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch.</source>
          <target state="translated">是否应该在每个纪元后对训练数据进行洗牌。</target>
        </trans-unit>
        <trans-unit id="2f96d4cd24a907c94c91a597b369db5ae9d183fe" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch. Defaults to True.</source>
          <target state="translated">训练数据是否应该在每个纪元后进行洗牌。默认值为True。</target>
        </trans-unit>
        <trans-unit id="21e287c040da0ab9f7612eda4a9df397d21447be" translate="yes" xml:space="preserve">
          <source>Whether or not to compute labels for each fit.</source>
          <target state="translated">是否为每个拟合计算标签。</target>
        </trans-unit>
        <trans-unit id="ae7627e3aed47d9187a8dde354d4bd8908f66e18" translate="yes" xml:space="preserve">
          <source>Whether or not to consider raw Mahalanobis distances as the decision function. Must be False (default) for compatibility with the others outlier detection tools.</source>
          <target state="translated">是否考虑原始马哈兰诺比距离作为决策函数。必须为False(默认),以便与其他异常点检测工具兼容。</target>
        </trans-unit>
        <trans-unit id="d7d36162415efc2dece0359749393df764e8f212" translate="yes" xml:space="preserve">
          <source>Whether or not to fit the intercept. This can be set to False if the data is already centered around the origin.</source>
          <target state="translated">是否拟合截距。如果数据已经以原点为中心,可以设置为False。</target>
        </trans-unit>
        <trans-unit id="99ecd63bc30b233e173e08d6a58d2b609112b08a" translate="yes" xml:space="preserve">
          <source>Whether or not to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">是否对给定的数据进行复制,如果设置为False,则会覆盖初始数据。如果设置为False,初始数据将被覆盖。</target>
        </trans-unit>
        <trans-unit id="95950f270865da71d578c03fd7275708de2f1edb" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &amp;lsquo;auto&amp;rsquo;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo;.</source>
          <target state="translated">是否将每个样本标记为其自身的第一个最近邻居。如果为'auto'，则将True用于mode ='connectivity'，将False用于mode ='distance'。</target>
        </trans-unit>
        <trans-unit id="0d8aa347bdbdfa6dd79051c8fee2f95fc5666522" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &lt;code&gt;None&lt;/code&gt;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo; as this will preserve backwards compatibility.</source>
          <target state="translated">是否将每个样本标记为其自身的第一个最近邻居。如果为 &lt;code&gt;None&lt;/code&gt; ，则将true用作mode ='connectivity'，将False用作mode ='distance'，因为这将保留向后兼容性。</target>
        </trans-unit>
        <trans-unit id="a1d6eb056f01f6a77d40d6f787612d8008f1be4b" translate="yes" xml:space="preserve">
          <source>Whether or not to return a sparse CSR matrix, as default behavior, or to return a dense array compatible with dense pipeline operators.</source>
          <target state="translated">是否返回一个稀疏的CSR矩阵,作为默认行为,或者返回一个与密集管道操作者兼容的密集数组。</target>
        </trans-unit>
        <trans-unit id="8f592bf838896fb605ecc15c063970bf58250eab" translate="yes" xml:space="preserve">
          <source>Whether or not to return the number of iterations.</source>
          <target state="translated">是否返回迭代次数。</target>
        </trans-unit>
        <trans-unit id="3433b032133d6a741db0a6ccce9ce8005a84877d" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.</source>
          <target state="translated">是否在分割前对数据进行洗牌。如果shuffle=False,那么stratify必须为None。</target>
        </trans-unit>
        <trans-unit id="d797771ee8d7ac8a664344b3d1655c54bf4a7c5a" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data: might be important for models that make the assumption that the samples are independent and identically distributed (i.i.d.), such as stochastic gradient descent.</source>
          <target state="translated">是否对数据进行洗牌:对于假设样本是独立和同分布(i.i.d.)的模型来说可能很重要,比如随机梯度下降模型。</target>
        </trans-unit>
        <trans-unit id="169aa17090e9b82766c818a4a09acd1cb51fcb24" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement.</source>
          <target state="translated">是否抽样与更换。</target>
        </trans-unit>
        <trans-unit id="11994582207268a83009eceee1185d13dd22bd86" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement. If False, sampling without replacement is performed.</source>
          <target state="translated">是否在更换的情况下抽取样品。如果为 &quot;False&quot;,则进行无替换的抽样。</target>
        </trans-unit>
        <trans-unit id="b61c81ce74fc75ce6a90c790bfafe984d14c7994" translate="yes" xml:space="preserve">
          <source>Whether score_func is a score function (default), meaning high is good, or a loss function, meaning low is good. In the latter case, the scorer object will sign-flip the outcome of the score_func.</source>
          <target state="translated">score_func是一个得分函数(默认),意思是高就是好,还是一个损失函数,意思是低就是好。在后一种情况下,评分器对象将对 score_func 的结果进行符号翻转。</target>
        </trans-unit>
        <trans-unit id="01c7a3b4947bb7aed2272a78dd753a14b9e24fdc" translate="yes" xml:space="preserve">
          <source>Whether score_func requires predict_proba to get probability estimates out of a classifier.</source>
          <target state="translated">score_func是否需要predict_proba来获得分类器的概率估计。</target>
        </trans-unit>
        <trans-unit id="e86601bb1c2db478564381eb9b1a33fc72f3ad69" translate="yes" xml:space="preserve">
          <source>Whether score_func takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method.</source>
          <target state="translated">score_func是否采取连续的决策确定性。这只适用于使用具有decision_function或predict_proba方法的估计器的二元分类。</target>
        </trans-unit>
        <trans-unit id="62e384e32324c7d8c05ac06534cda98d3cbc0def" translate="yes" xml:space="preserve">
          <source>Whether support is a list of indices.</source>
          <target state="translated">支持是否是一个指数列表。</target>
        </trans-unit>
        <trans-unit id="970ea0e030e6e4be6469b0282edfb558e0e9066d" translate="yes" xml:space="preserve">
          <source>Whether the algorithm should be applied to M.T instead of M. The result should approximately be the same. The &amp;lsquo;auto&amp;rsquo; mode will trigger the transposition if M.shape[1] &amp;gt; M.shape[0] since this implementation of randomized SVD tend to be a little faster in that case.</source>
          <target state="translated">该算法是否应应用于MT而不是M。结果应大致相同。如果M.shape [1]&amp;gt; M.shape [0]，则&amp;ldquo;自动&amp;rdquo;模式将触发换位，因为在这种情况下，这种随机化SVD的实现往往会更快一些。</target>
        </trans-unit>
        <trans-unit id="3226951d2ead1297a694651602f8538f5e93757c" translate="yes" xml:space="preserve">
          <source>Whether the covariance vector Xy must be copied by the algorithm. If False, it may be overwritten.</source>
          <target state="translated">协方差向量Xy是否必须被算法复制。如果为False,则可能被覆盖。</target>
        </trans-unit>
        <trans-unit id="d2b667c3b7746e3e678455d8b2d703997aeb5e60" translate="yes" xml:space="preserve">
          <source>Whether the deflation be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effects</source>
          <target state="translated">是否在副本上进行紧缩。除非您不关心副作用，否则将默认值设置为True</target>
        </trans-unit>
        <trans-unit id="1cba92780e42c1ebe55ada467260206516898de8" translate="yes" xml:space="preserve">
          <source>Whether the deflation should be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effect</source>
          <target state="translated">是否应在副​​本上进行紧缩。除非您不关心副作用，否则将默认值设置为True</target>
        </trans-unit>
        <trans-unit id="99f0df0508624fcfafef99671905c951f197a398" translate="yes" xml:space="preserve">
          <source>Whether the design matrix X must be copied by the algorithm. A false value is only helpful if X is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">设计矩阵X是否必须被算法复制。假值只有在X已经是Fortran排序的情况下才有帮助,否则还是会复制。</target>
        </trans-unit>
        <trans-unit id="6f829dc8dcc41b94f325536e7999d7feb34a89f1" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word n-gram or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="translated">该功能部件应由单词n-gram还是字符n-gram组成。选项'char_wb'仅从单词边界内的文本创建字符n-gram；单词边缘的n-gram用空格填充。</target>
        </trans-unit>
        <trans-unit id="f62ef19aafedabcbf9aa2a6c1cbcccaa900e840f" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams.</source>
          <target state="translated">该功能是由字词还是字符n格组成。</target>
        </trans-unit>
        <trans-unit id="9c1354d44a66effd212e821b1aba74fe08612248" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="translated">该功能部件应由单词还是字符n-gram组成。选项&amp;ldquo; char_wb&amp;rdquo;仅从单词边界内的文本创建字符n-gram；单词边缘的n-gram用空格填充。</target>
        </trans-unit>
        <trans-unit id="824ad07968fefbc8aa1fba0ade7c849f0d099562" translate="yes" xml:space="preserve">
          <source>Whether the gram matrix must be copied by the algorithm. A false value is only helpful if it is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">克矩阵是否必须被算法复制。假值只有在已经是Fortran排序的情况下才有帮助,否则还是会复制。</target>
        </trans-unit>
        <trans-unit id="23571fa5c9f0e8d5b2ce0915807aa480e23639d3" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask format should be sparse or dense.</source>
          <target state="translated">imputer mask格式应该是稀疏的还是密集的。</target>
        </trans-unit>
        <trans-unit id="b70758cdff0513f8822d9fb7393f16dda3f13af9" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask should represent all or a subset of features.</source>
          <target state="translated">imputer掩码是应该代表全部特征还是子集特征。</target>
        </trans-unit>
        <trans-unit id="11709e37813efd2480c1d891188cf0d8201c8a69" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If &lt;code&gt;False&lt;/code&gt;, the data is assumed to be already centered.</source>
          <target state="translated">是否应该估计截距。如果为 &lt;code&gt;False&lt;/code&gt; ，则假定数据已经居中。</target>
        </trans-unit>
        <trans-unit id="0ccd5f6458ed970eecf03c787120d2831e50f140" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.</source>
          <target state="translated">是否应该估计截距。如果为 &quot;False&quot;,则假设数据已经居中。</target>
        </trans-unit>
        <trans-unit id="2fafec857734808cd372cb104d91a568d25acbf6" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.</source>
          <target state="translated">是否应该估计截距。如果为False,则假设数据已经居中。默认值为True。</target>
        </trans-unit>
        <trans-unit id="1369ea0f90c1ab8c31f4e5d5e2b327950f322e67" translate="yes" xml:space="preserve">
          <source>Whether the kernel works only on fixed-length feature vectors.</source>
          <target state="translated">内核是否只工作在固定长度的特征向量上。</target>
        </trans-unit>
        <trans-unit id="efe887a2120302f3ddf508ce39115dacb905298c" translate="yes" xml:space="preserve">
          <source>Whether the parameter was found to be a named parameter of the estimator&amp;rsquo;s fit method.</source>
          <target state="translated">是否发现参数是估计器的fit方法的命名参数。</target>
        </trans-unit>
        <trans-unit id="e3e6070e7b1bf06bd46c63ade906ee83f84569ff" translate="yes" xml:space="preserve">
          <source>Whether the power iterations are normalized with step-by-step QR factorization (the slowest but most accurate), &amp;lsquo;none&amp;rsquo; (the fastest but numerically unstable when &lt;code&gt;n_iter&lt;/code&gt; is large, e.g. typically 5 or larger), or &amp;lsquo;LU&amp;rsquo; factorization (numerically stable but can lose slightly in accuracy). The &amp;lsquo;auto&amp;rsquo; mode applies no normalization if &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2 and switches to LU otherwise.</source>
          <target state="translated">功率迭代是通过逐步QR因式分解（最慢但最准确），&amp;ldquo;无&amp;rdquo;（当 &lt;code&gt;n_iter&lt;/code&gt; 大（例如通常为5或更大）时最快但在数值上不稳定）或&amp;ldquo; LU&amp;rdquo;因式分解（以数字方式）进行归一化稳定，但精度可能会略有下降）。如果 &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2，则&amp;ldquo;自动&amp;rdquo;模式不应用规范化，否则切换到LU。</target>
        </trans-unit>
        <trans-unit id="00c2bc5048e0182a905dad0c4dec40740dd521b8" translate="yes" xml:space="preserve">
          <source>Whether the relationship is increasing or decreasing.</source>
          <target state="translated">关系是增加还是减少。</target>
        </trans-unit>
        <trans-unit id="dc0314689b038e45038d5534e1499b2766f8b916" translate="yes" xml:space="preserve">
          <source>Whether the return value is an array of sparse matrix depends on the type of the input X.</source>
          <target state="translated">返回值是否是稀疏矩阵的数组,取决于输入X的类型。</target>
        </trans-unit>
        <trans-unit id="ed44b1dc96dab239fb6ac2dc375f2ee5fe3ae793" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, i.e., the mean of the observed target values become zero. This parameter should be set to True if the target values&amp;rsquo; mean is expected to differ considerable from zero. When enabled, the normalization effectively modifies the GP&amp;rsquo;s prior based on the data, which contradicts the likelihood principle; normalization is thus disabled per default.</source>
          <target state="translated">目标值y是否被归一化，即观察到的目标值的平均值变为零。如果期望目标值的均值与零的差值很大，则应将此参数设置为True。启用后，归一化会根据数据有效地修改GP的先验，这与似然原理相矛盾；因此默认情况下禁用标准化。</target>
        </trans-unit>
        <trans-unit id="cb8d2af32f6e15f6d8381b5609652e77d17356c4" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, the mean and variance of the target values are set equal to 0 and 1 respectively. This is recommended for cases where zero-mean, unit-variance priors are used. Note that, in this implementation, the normalisation is reversed before the GP predictions are reported.</source>
          <target state="translated">目标值y是否归一化,目标值的均值和方差分别设为等于0和1。对于使用零均值、单位方差前值的情况,建议采用这种方式。需要注意的是,在本实施例中,在报告GP预测值之前,归一化是反向的。</target>
        </trans-unit>
        <trans-unit id="4d56de522c2f2c8fa83698a0d6921644d35a5428" translate="yes" xml:space="preserve">
          <source>Whether the task is a classification task, in which case stratified KFold will be used.</source>
          <target state="translated">任务是否为分类任务,在这种情况下将使用分层KFold。</target>
        </trans-unit>
        <trans-unit id="667f96156fffe3e4c7c8342ead32f8ae00d3d84f" translate="yes" xml:space="preserve">
          <source>Whether the value of this hyperparameter is fixed, i.e., cannot be changed during hyperparameter tuning. If None is passed, the &amp;ldquo;fixed&amp;rdquo; is derived based on the given bounds.</source>
          <target state="translated">此超参数的值是否固定，即在超参数调整期间无法更改。如果未通过，则基于给定的边界派生&amp;ldquo;固定&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="6cb255093bce0eff775d5414b35fcd6fbd07931b" translate="yes" xml:space="preserve">
          <source>Whether this is a multilabel classifier</source>
          <target state="translated">是否为多标签分类器</target>
        </trans-unit>
        <trans-unit id="b1be5efdade94da8e67722b4ba2f983efa0225c5" translate="yes" xml:space="preserve">
          <source>Whether to allow 2-d y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="translated">是否允许2-d的y(数组或稀疏矩阵),如果为false,y将被验证为向量。如果multi_output=True,y将被验证为一个向量。如果multi_output=True,y不能有np.nan或np.inf值。</target>
        </trans-unit>
        <trans-unit id="110cd422886570c5a4fe2834aa70ff221b2cdcaf" translate="yes" xml:space="preserve">
          <source>Whether to allow 2D y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="translated">是否允许2D y(数组或稀疏矩阵)。如果multi_output=True,y将被验证为一个向量。如果multi_output=True,y不能有np.nan或np.inf值。</target>
        </trans-unit>
        <trans-unit id="8ecc2d4e014d3f2172c25597969963bd34e18f05" translate="yes" xml:space="preserve">
          <source>Whether to allow X.ndim &amp;gt; 2.</source>
          <target state="translated">是否允许X.ndim&amp;gt; 2。</target>
        </trans-unit>
        <trans-unit id="7a4a847db3917eeca38ca476c1ad3e57930cf992" translate="yes" xml:space="preserve">
          <source>Whether to allow array.ndim &amp;gt; 2.</source>
          <target state="translated">是否允许array.ndim&amp;gt; 2。</target>
        </trans-unit>
        <trans-unit id="d5dcbf9253f384309cfbc4a594ef7b057c1cb7e6" translate="yes" xml:space="preserve">
          <source>Whether to also return the code U or just the dictionary V.</source>
          <target state="translated">是否也返回代码U或只返回字典V。</target>
        </trans-unit>
        <trans-unit id="c6289192e1f815e2a760fe289e8841e73f51c42c" translate="yes" xml:space="preserve">
          <source>Whether to be verbose.</source>
          <target state="translated">是否要啰嗦。</target>
        </trans-unit>
        <trans-unit id="ccada94fe77cfa7bf4094a2aaa2265ce9f9f4e5f" translate="yes" xml:space="preserve">
          <source>Whether to cache downloaded datasets using joblib.</source>
          <target state="translated">是否使用joblib缓存下载的数据集。</target>
        </trans-unit>
        <trans-unit id="86614eccba121d18979d29b5e6a1aceed9dc9343" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为 &quot;假&quot;,则在计算中不使用截距(例如,预计数据已经居中)。</target>
        </trans-unit>
        <trans-unit id="7285fa12a56fc9f408db5bd27934d6f0654e6093" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为 &quot;假&quot;,则在计算中不使用截距(即数据预期居中)。</target>
        </trans-unit>
        <trans-unit id="943768cddf06aea5cdead26cd3dff69cb74196ef" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为false,在计算中不使用截距(例如,预计数据已经居中)。</target>
        </trans-unit>
        <trans-unit id="27f8a383f138130dd1f45baee7b1d68ad4ce59f4" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be already centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为false,则计算中不使用截距(即预计数据已经居中)。</target>
        </trans-unit>
        <trans-unit id="34dd726eec26b92f0d7e507bd65e8b16cfaec4c8" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="translated">是否计算该模型的截距。如果设置为false,在计算中不使用截距(即数据预期是居中的)。</target>
        </trans-unit>
        <trans-unit id="0336ff17d311b84566800e5cf35b415ab2b27f38" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations.</source>
          <target state="translated">是否计算该模型的截距。如果设置为false,则计算中不使用截距。</target>
        </trans-unit>
        <trans-unit id="7c201504f17506a2291f5d939998458e72428d3b" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. The intercept is not treated as a probabilistic parameter and thus has no associated variance. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="translated">是否计算该模型的截距。截距不作为概率参数处理,因此没有相关方差。如果设置为 &quot;假&quot;,则在计算中不使用截距(即预计数据是居中的)。</target>
        </trans-unit>
        <trans-unit id="471ed2aff4494fad57e380482ee0a58232333b20" translate="yes" xml:space="preserve">
          <source>Whether to check that &lt;code&gt;transform&lt;/code&gt; followed by &lt;code&gt;inverse_transform&lt;/code&gt; or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original targets.</source>
          <target state="translated">是否检查 &lt;code&gt;transform&lt;/code&gt; 后跟 &lt;code&gt;inverse_transform&lt;/code&gt; 还是检查 &lt;code&gt;func&lt;/code&gt; 跟 &lt;code&gt;inverse_func&lt;/code&gt; 导致原始目标。</target>
        </trans-unit>
        <trans-unit id="3c61d748141856e990caff79c0b01fd8a4086321" translate="yes" xml:space="preserve">
          <source>Whether to check that or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original inputs. It can be used for a sanity check, raising a warning when the condition is not fulfilled.</source>
          <target state="translated">是先检查还是在 &lt;code&gt;func&lt;/code&gt; 后面加上 &lt;code&gt;inverse_func&lt;/code&gt; 导致原始输入。它可以用于完整性检查，在不满足条件时发出警告。</target>
        </trans-unit>
        <trans-unit id="50850a0df7fa2328560b0d7ebe31ee1142901517" translate="yes" xml:space="preserve">
          <source>Whether to compute &lt;code&gt;y_&lt;/code&gt; is increasing (if set to True) or decreasing (if set to False)</source>
          <target state="translated">计算 &lt;code&gt;y_&lt;/code&gt; 是增加（如果设置为True）还是减少（如果设置为False）</target>
        </trans-unit>
        <trans-unit id="5fbe7e9ef9385d70942ace9201de11e6cead8f8d" translate="yes" xml:space="preserve">
          <source>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</source>
          <target state="translated">是否计算平方误差法线或误差法线。如果为真(默认),返回平方误差法线。如果为False,则返回误差法线。</target>
        </trans-unit>
        <trans-unit id="01086dba4779bb032a62d90a9f9152dc1b833baf" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place computations.</source>
          <target state="translated">是复制X和Y,还是进行原地计算。</target>
        </trans-unit>
        <trans-unit id="725302de0fd34aabdbfc0e0affbd4f4fb754127c" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place normalization.</source>
          <target state="translated">是复制X和Y,还是进行就地归一化。</target>
        </trans-unit>
        <trans-unit id="7462b314a4fe2fff7847f10014abb6b1183fa84f" translate="yes" xml:space="preserve">
          <source>Whether to copy X and operate on the copy or perform in-place operations.</source>
          <target state="translated">是复制X并对副本进行操作,还是进行原地操作。</target>
        </trans-unit>
        <trans-unit id="3692936737114d51a6bb410cb3531454c9ad1d68" translate="yes" xml:space="preserve">
          <source>Whether to copy the precomputed covariance matrix; if False, it may be overwritten.</source>
          <target state="translated">是否复制预先计算的协方差矩阵;如果为False,则可能被覆盖。</target>
        </trans-unit>
        <trans-unit id="324d6fe1307968790ddbb142ded331e1979517da" translate="yes" xml:space="preserve">
          <source>Whether to create a copy of X and operate on it or to perform inplace computation (default behaviour).</source>
          <target state="translated">是创建一个X的副本并对其进行操作,还是进行inplace计算(默认行为)。</target>
        </trans-unit>
        <trans-unit id="62527ff1b5ed50e080e833b6d4fd94a862b78590" translate="yes" xml:space="preserve">
          <source>Whether to drop some suboptimal thresholds which would not appear on a plotted ROC curve. This is useful in order to create lighter ROC curves.</source>
          <target state="translated">是否放弃一些不会出现在绘制的ROC曲线上的次优阈值。这对于创建更轻的ROC曲线很有用。</target>
        </trans-unit>
        <trans-unit id="9851e7fdf1748b99ff7c24c940b7ce5f334a6a27" translate="yes" xml:space="preserve">
          <source>Whether to drop the first eigenvector. For spectral embedding, this should be True as the first eigenvector should be constant vector for connected graph, but for spectral clustering, this should be kept as False to retain the first eigenvector.</source>
          <target state="translated">是否放弃第一特征向量。对于频谱嵌入,应该为True,因为第一特征向量应该是连接图的常量向量,但对于频谱聚类,应该保持为False,以保留第一特征向量。</target>
        </trans-unit>
        <trans-unit id="5f99ffcc1bc3b15acf95363130c37cd5b381a91e" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, and will slow down that method.</source>
          <target state="translated">是否启用概率估计。必须在调用 &lt;code&gt;fit&lt;/code&gt; 之前将其启用，并且会降低该方法的速度。</target>
        </trans-unit>
        <trans-unit id="1a58ce6c20ca7e5e36327e21b19b4ffc278a0174" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, will slow down that method as it internally uses 5-fold cross-validation, and &lt;code&gt;predict_proba&lt;/code&gt; may be inconsistent with &lt;code&gt;predict&lt;/code&gt;. Read more in the &lt;a href=&quot;../svm#scores-probabilities&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">是否启用概率估计。必须在调用 &lt;code&gt;fit&lt;/code&gt; 之前启用此功能，因为该方法在内部使用5倍交叉验证，因而会减慢该方法的速度，并且 &lt;code&gt;predict_proba&lt;/code&gt; 可能与 &lt;code&gt;predict&lt;/code&gt; 不一致。在《&lt;a href=&quot;../svm#scores-probabilities&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4a4497ffca40d00ae7a4f4bda08e5dece2337700" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the code.</source>
          <target state="translated">在找码时,是否要执行积极性。</target>
        </trans-unit>
        <trans-unit id="2920a1115fbc090ce8de93fb299e0d53a98e0404" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary</source>
          <target state="translated">在查找字典时是否要执行积极的态度</target>
        </trans-unit>
        <trans-unit id="cc323427a6369f3d4c345df0c7eab9b613a4b184" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary.</source>
          <target state="translated">在查找字典时,是否要执行积极性。</target>
        </trans-unit>
        <trans-unit id="0c86815e9d15a8d79f49100b7de99ab0894ffb4b" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the encoding.</source>
          <target state="translated">在寻找编码时,是否要强制执行正。</target>
        </trans-unit>
        <trans-unit id="67962e408072673f64867d41053d2df5bd8ffd92" translate="yes" xml:space="preserve">
          <source>Whether to ensure that y has a numeric type. If dtype of y is object, it is converted to float64. Should only be used for regression algorithms.</source>
          <target state="translated">是否确保y有一个数字类型。如果y的dtype是object,则转换为float64。应该只用于回归算法。</target>
        </trans-unit>
        <trans-unit id="a89a89f1fbc0cff73f883e4748e4c43034f0361e" translate="yes" xml:space="preserve">
          <source>Whether to filter invalid parameters or not.</source>
          <target state="translated">是否过滤无效参数。</target>
        </trans-unit>
        <trans-unit id="8bd7eb051fe8793acf6505d7ff57ac8a40be3e89" translate="yes" xml:space="preserve">
          <source>Whether to fit an intercept for the model. In this case the shape of the returned array is (n_cs, n_features + 1).</source>
          <target state="translated">是否为模型拟合一个截距。在这种情况下,返回数组的形状是(n_cs,n_features+1)。</target>
        </trans-unit>
        <trans-unit id="86604814c1d6f6dc79ece6e1aa0e214e981e58a5" translate="yes" xml:space="preserve">
          <source>Whether to fit the intercept for this model. If set to false, no intercept will be used in calculations (i.e. &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are expected to be centered).</source>
          <target state="translated">是否适合此模型的截距。如果设置为false，则在计算中将不使用截距（即，预期 &lt;code&gt;X&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 居中）。</target>
        </trans-unit>
        <trans-unit id="8e39ad37924100e174516b8fe05585ae0c11a660" translate="yes" xml:space="preserve">
          <source>Whether to include &amp;ldquo;special&amp;rdquo; label estimator or test processors.</source>
          <target state="translated">是否包括&amp;ldquo;特殊&amp;rdquo;标签估计器或测试处理器。</target>
        </trans-unit>
        <trans-unit id="84818ba086581abd044063f9dd3c5b2beb12eda7" translate="yes" xml:space="preserve">
          <source>Whether to include meta-estimators that can be constructed using an estimator as their first argument. These are currently BaseEnsemble, OneVsOneClassifier, OutputCodeClassifier, OneVsRestClassifier, RFE, RFECV.</source>
          <target state="translated">是否包含可以使用估计器作为第一个参数来构造的元估计器,目前有BaseEnsemble、OneVsOneClassifier、OutputCodeClassifier、OneVsRestClassifier、RFE、RFECV。目前有BaseEnsemble、OneVsOneClassifier、OutputCodeClassifier、OneVsRestClassifier、RFE、RFECV。</target>
        </trans-unit>
        <trans-unit id="74d7014a87bc3e04b7cb4d5881013af41aaf9d5f" translate="yes" xml:space="preserve">
          <source>Whether to include train scores.</source>
          <target state="translated">是否纳入火车成绩。</target>
        </trans-unit>
        <trans-unit id="5a33027c8dd2a3a26ddc387706fe4e97d00f5eae" translate="yes" xml:space="preserve">
          <source>Whether to include train scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.</source>
          <target state="translated">是否包含训练分数。计算训练分数是用来深入了解不同的参数设置如何影响过拟合/欠拟合的权衡。然而计算训练集上的分数可能计算成本很高,并不是严格要求选择产生最佳泛化性能的参数。</target>
        </trans-unit>
        <trans-unit id="b770fc1f2ccfc02ef3107a2ecac741b2276c37e8" translate="yes" xml:space="preserve">
          <source>Whether to learn class prior probabilities or not. If false, a uniform prior will be used.</source>
          <target state="translated">是否学习类先验概率。如果为假,将使用统一的先验概率。</target>
        </trans-unit>
        <trans-unit id="8606bf192804810fba78c6bd2b8805fda4483156" translate="yes" xml:space="preserve">
          <source>Whether to load only 10 percent of the data.</source>
          <target state="translated">是否只加载10%的数据。</target>
        </trans-unit>
        <trans-unit id="3156faf4c491e77c08d3500dd2b8c76947137632" translate="yes" xml:space="preserve">
          <source>Whether to load or not the content of the different files. If true a &amp;lsquo;data&amp;rsquo; attribute containing the text information is present in the data structure returned. If not, a filenames attribute gives the path to the files.</source>
          <target state="translated">是否加载不同文件的内容。如果为true，则在返回的数据结构中包含包含文本信息的'data'属性。如果不是，则使用filenames属性提供文件的路径。</target>
        </trans-unit>
        <trans-unit id="81f8d6a01f7cffb7f53496e9cfd84f1ce27de740" translate="yes" xml:space="preserve">
          <source>Whether to make X at least 2d.</source>
          <target state="translated">是否让X至少2d。</target>
        </trans-unit>
        <trans-unit id="2a578215f5e1bceb4eddd518c894532f84a10916" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of X. If &lt;code&gt;False&lt;/code&gt;, the input X gets overwritten during fitting.</source>
          <target state="translated">是否制作X的副本。如果为 &lt;code&gt;False&lt;/code&gt; ，则在拟合期间输入X被覆盖。</target>
        </trans-unit>
        <trans-unit id="e2abdc017941ef25090c0789fe34541086dc5677" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">是否对给定的数据进行复制,如果设置为False,则会覆盖初始数据。如果设置为False,初始数据将被覆盖。</target>
        </trans-unit>
        <trans-unit id="df62a350cab30808585d28e267100de2daf97811" translate="yes" xml:space="preserve">
          <source>Whether to normalize the output matrix to make the leading diagonal elements all 1</source>
          <target state="translated">是否对输出矩阵进行归一化处理,使其前导对角线元素全部为1。</target>
        </trans-unit>
        <trans-unit id="ba6415e4db38e5cea33cf7fab1a514fcf5285867" translate="yes" xml:space="preserve">
          <source>Whether to perform precomputations. Improves performance when n_targets or n_samples is very large.</source>
          <target state="translated">是否进行预计算。当n_targets或n_samples非常大时,提高性能。</target>
        </trans-unit>
        <trans-unit id="4010b2bff9133aaf08486f7fb645e8e39634583e" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. Auto mode by default will use presorting on dense data and default to normal sorting on sparse data. Setting presort to true on sparse data will raise an error.</source>
          <target state="translated">是否对数据进行预排序,以加快在拟合中寻找最佳分割。自动模式默认会对密集数据使用预排序,对稀疏数据默认为正常排序。在稀疏数据上将预排序设置为true,会出现错误。</target>
        </trans-unit>
        <trans-unit id="29f75c6794195c888ce8399680c96d5b14e65048" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. For the default settings of a decision tree on large datasets, setting this to true may slow down the training process. When using either a smaller dataset or a restricted depth, this may speed up the training.</source>
          <target state="translated">是否对数据进行预排序,以加快在拟合中寻找最佳分割。对于大数据集上决策树的默认设置,将此设置为true可能会减慢训练过程。当使用较小的数据集或限制深度时,这可能会加快训练速度。</target>
        </trans-unit>
        <trans-unit id="cc4d3f96c9bc487e50b4fc4701212f323c65bca6" translate="yes" xml:space="preserve">
          <source>Whether to print progress messages to stdout.</source>
          <target state="translated">是否将进度信息打印到stdout。</target>
        </trans-unit>
        <trans-unit id="1ef1345441f84cbc6b06cbfc2b69b730789a6079" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2D.</source>
          <target state="translated">如果X不是2D,是否会引发数值错误。</target>
        </trans-unit>
        <trans-unit id="b44ea19ee67df3ef30c54f3be25f24e67c4f3a60" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2d.</source>
          <target state="translated">如果X不是2d,是否会引发数值错误。</target>
        </trans-unit>
        <trans-unit id="64b755e00dbefa679127012ca837c554b0c217d7" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if array is not 2D.</source>
          <target state="translated">如果数组不是二维的,是否会引发数值错误。</target>
        </trans-unit>
        <trans-unit id="b5d06b3c83946e2cd2c05192b834ad6e01c6a1d5" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. The possibilities are:</source>
          <target state="translated">是否要对X中的np.inf和np.nan提出错误,可能性有。</target>
        </trans-unit>
        <trans-unit id="eaa329f6263ead71ba810671bba1e6a99379040d" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. This parameter does not influence whether y can have np.inf or np.nan values. The possibilities are:</source>
          <target state="translated">是否对X中的np.inf和np.nan产生错误,这个参数不影响y是否有np.inf或np.nan值。可能性有:</target>
        </trans-unit>
        <trans-unit id="ec8573b1162223970fd6725eca010725203428e3" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. The possibilities are:</source>
          <target state="translated">是否对X中的np.inf、np.nan、pd.NA提出错误,可能性是:</target>
        </trans-unit>
        <trans-unit id="68ace26fa0c8880f45dfa331c844e7939329fec1" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. This parameter does not influence whether y can have np.inf, np.nan, pd.NA values. The possibilities are:</source>
          <target state="translated">是否对X中的np.inf、np.nan、pd.NA产生错误,该参数不影响y是否可以有np.inf、np.nan、pd.NA值。可能性有:</target>
        </trans-unit>
        <trans-unit id="3bbeec18546bd2f3b8cccf2897d9a3a9aee68173" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in array. The possibilities are:</source>
          <target state="translated">是否对阵列中的 np.inf,np.nan,pd.NA 产生错误。可能的情况是:</target>
        </trans-unit>
        <trans-unit id="c551edd4edb4cf1081c3e3d3eb3a36ad8f839a51" translate="yes" xml:space="preserve">
          <source>Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to &amp;lsquo;ignore&amp;rsquo; and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.</source>
          <target state="translated">在转换过程中是否引发错误或忽略是否存在未知分类特征（默认为引发）。当此参数设置为&amp;ldquo;忽略&amp;rdquo;并且在转换过程中遇到未知类别时，此功能生成的一键编码列将全为零。在逆变换中，未知类别将表示为&amp;ldquo;无&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="55b5cf4021bca4319afc6cff07e1e1c5a8e21c80" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).</source>
          <target state="translated">是否返回形状（n_samples，n_classes）的一对一（ovr）决策函数作为所有其他分类器，还是返回形状为（n_samples）的libsvm原始一对一（'ov'）决策函数，n_classes *（n_classes-1）/ 2）。</target>
        </trans-unit>
        <trans-unit id="3e008ca3901c2f4656b69b334cd2bbf88df838cc" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy.</source>
          <target state="translated">是否返回形状（n_samples，n_classes）的一对一（ovr）决策函数作为所有其他分类器，还是返回形状为（n_samples）的libsvm原始一对一（'ov'）决策函数，n_classes *（n_classes-1）/ 2）。但是，始终将&amp;ldquo;一对一&amp;rdquo;（'ovo'）用作多类别策略。</target>
        </trans-unit>
        <trans-unit id="7af50893420dd3e6c393c168dece6ee3ddea82a0" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy. The parameter is ignored for binary classification.</source>
          <target state="translated">是否返回形状（n_samples，n_classes）的一对一（ovr）决策函数作为所有其他分类器，还是返回形状为（n_samples）的libsvm原始一对一（'ovo'）决策函数，n_classes *（n_classes-1）/ 2）。但是，始终将&amp;ldquo;一对一&amp;rdquo;（'ovo'）用作多类别策略。对于二进制分类，将忽略该参数。</target>
        </trans-unit>
        <trans-unit id="ebccc28d7f21db5d9325894eec5fc9e6d02d15c3" translate="yes" xml:space="preserve">
          <source>Whether to return dense output even when the input is sparse. If &lt;code&gt;False&lt;/code&gt;, the output is sparse if both input arrays are sparse.</source>
          <target state="translated">是否即使输入稀疏也返回密集输出。如果为 &lt;code&gt;False&lt;/code&gt; ，则两个输入数组均为稀疏时，输出为稀疏。</target>
        </trans-unit>
        <trans-unit id="12da7a3ff0421b885caca94ef2caa65b1b016c5f" translate="yes" xml:space="preserve">
          <source>Whether to return every value of the nonzero coefficients along the forward path. Useful for cross-validation.</source>
          <target state="translated">是否沿正向路径返回非零系数的每个值。对交叉验证有用。</target>
        </trans-unit>
        <trans-unit id="6a16a084b2e44866fb8e9c04ea892f46ef9407d0" translate="yes" xml:space="preserve">
          <source>Whether to return the estimators fitted on each split.</source>
          <target state="translated">是否返回每次拆分时拟合的估计子。</target>
        </trans-unit>
        <trans-unit id="5e04c1a3b3a800f3b607834e4028e06fab1a7b16" translate="yes" xml:space="preserve">
          <source>Whether to return the fit and score times.</source>
          <target state="translated">是否归还契合度和得分时间。</target>
        </trans-unit>
        <trans-unit id="a0296def7d7feccd7f063d12d572b0bb6de2b0cd" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations or not.</source>
          <target state="translated">是否返回迭代次数。</target>
        </trans-unit>
        <trans-unit id="642c6fa9e4316671c7770b59f9d72b6641ef628f" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations.</source>
          <target state="translated">是否返回迭代次数。</target>
        </trans-unit>
        <trans-unit id="b549a24da790409f4ec3623e7b38a8b83191c416" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction.</source>
          <target state="translated">是否返回后置预测的标准差。</target>
        </trans-unit>
        <trans-unit id="b33ff2a27948731af021590a907c614a500fc29d" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction. All zeros in this case.</source>
          <target state="translated">是否返回后验预测的标准差。这种情况下全部为零。</target>
        </trans-unit>
        <trans-unit id="7f1c62ca9183e80a5d93cc97ae0f6b09aa7ca43f" translate="yes" xml:space="preserve">
          <source>Whether to sample from the (Gaussian) predictive posterior of the fitted estimator for each imputation. Estimator must support &lt;code&gt;return_std&lt;/code&gt; in its &lt;code&gt;predict&lt;/code&gt; method if set to &lt;code&gt;True&lt;/code&gt;. Set to &lt;code&gt;True&lt;/code&gt; if using &lt;code&gt;IterativeImputer&lt;/code&gt; for multiple imputations.</source>
          <target state="translated">是否从每个估算的拟合估计量的（高斯）预测后验中采样。如果设置为 &lt;code&gt;True&lt;/code&gt; ,则估计器必须在其 &lt;code&gt;predict&lt;/code&gt; 方法中支持 &lt;code&gt;return_std&lt;/code&gt; 。如果对多个插值使用 &lt;code&gt;IterativeImputer&lt;/code&gt; ，则设置为 &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ef9a1d5fe208dc604ffba3d0e60394e32f61bdb0" translate="yes" xml:space="preserve">
          <source>Whether to scale X and Y.</source>
          <target state="translated">是否缩放X和Y。</target>
        </trans-unit>
        <trans-unit id="06ccde346dfb7273af2d0810793b1fb5e47df0dc" translate="yes" xml:space="preserve">
          <source>Whether to show informative labels for impurity, etc. Options include &amp;lsquo;all&amp;rsquo; to show at every node, &amp;lsquo;root&amp;rsquo; to show only at the top root node, or &amp;lsquo;none&amp;rsquo; to not show at any node.</source>
          <target state="translated">是否显示杂质的信息性标签等。选项包括&amp;ldquo; all&amp;rdquo;显示在每个节点上，&amp;ldquo; root&amp;rdquo;显示在顶部根节点上，或&amp;ldquo; none&amp;rdquo;显示在任何节点上不显示。</target>
        </trans-unit>
        <trans-unit id="bcd035c2f558018eebfd4e5534f5df5bef89069a" translate="yes" xml:space="preserve">
          <source>Whether to shuffle dataset.</source>
          <target state="translated">是否要洗牌数据集。</target>
        </trans-unit>
        <trans-unit id="9ebdad6142b719150be2c8f67618dba47007c5fd" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each class&amp;rsquo;s samples before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="translated">在拆分成批次之前是否对每个班级的样本进行混洗。请注意，每个拆分内的样本都不会被混洗。</target>
        </trans-unit>
        <trans-unit id="8704d580bb26c2f6617363a0297f26abfb9fda30" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each stratification of the data before splitting into batches.</source>
          <target state="translated">是否在分批前对每个分层数据进行洗牌。</target>
        </trans-unit>
        <trans-unit id="5de7b9303caa771da78304a93ebeac224ba77f9b" translate="yes" xml:space="preserve">
          <source>Whether to shuffle samples in each iteration. Only used when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;.</source>
          <target state="translated">是否在每次迭代中随机播放样本。仅在Solver ='sgd'或'adam'时使用。</target>
        </trans-unit>
        <trans-unit id="3558a0c3a77b9ce3c242cc621a2d776c46a133af" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches.</source>
          <target state="translated">是否在分批前对数据进行洗牌。</target>
        </trans-unit>
        <trans-unit id="2b23f04bb0d66dad8fab9e868398f1780b26b6ed" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="translated">是否在将数据分割成批次之前进行洗牌。请注意,每次分割的样本不会被洗牌。</target>
        </trans-unit>
        <trans-unit id="ddc8f26baf73b311e3fd82ce49af7a5449330660" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting it in batches.</source>
          <target state="translated">是否要先洗牌再分批处理数据。</target>
        </trans-unit>
        <trans-unit id="f23a63355a4e388bf6ee14cbad5c7c9c8b8c8007" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the samples.</source>
          <target state="translated">是否要对样品进行洗牌。</target>
        </trans-unit>
        <trans-unit id="a5c75421672ae29d738aa02687f5d9f3ec0cf20c" translate="yes" xml:space="preserve">
          <source>Whether to shuffle training data before taking prefixes of it based on``train_sizes``.</source>
          <target state="translated">是否根据``train_sizes``对训练数据进行洗牌后再取其前缀。</target>
        </trans-unit>
        <trans-unit id="ce33fd98a79a5db67d420efb6fcabed70acb96c4" translate="yes" xml:space="preserve">
          <source>Whether to sort x before computing. If False, assume that x must be either monotonic increasing or monotonic decreasing. If True, y is used to break ties when sorting x. Make sure that y has a monotonic relation to x when setting reorder to True.</source>
          <target state="translated">计算前是否对x进行排序。如果False,假设x必须是单调递增或单调递减。如果为True,则在对x进行排序时,y是用来打破平局的,当将重排序设置为True时,要确保y与x有单调关系。</target>
        </trans-unit>
        <trans-unit id="5091491cac888f3972a1197cfef1256978c18b5f" translate="yes" xml:space="preserve">
          <source>Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.</source>
          <target state="translated">是否将稀疏特征向量拆分为其负向部分和正向部分的并集。这样可以提高下游分类器的性能。</target>
        </trans-unit>
        <trans-unit id="8b58e41338c55eaf50346244bd6082e4f3c1a628" translate="yes" xml:space="preserve">
          <source>Whether to use Nesterov&amp;rsquo;s momentum. Only used when solver=&amp;rsquo;sgd&amp;rsquo; and momentum &amp;gt; 0.</source>
          <target state="translated">是否使用内斯特罗夫的势头。仅在Solver ='sgd'且动量&amp;gt; 0时使用。</target>
        </trans-unit>
        <trans-unit id="6cb6c1fd9950933ec2b1bd309d3cbc04da69eccd" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-targets&quot;&gt;n_targets&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-samples&quot;&gt;n_samples&lt;/a&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="translated">是否使用预先计算的Gram和Xy矩阵来加快计算速度。当&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-targets&quot;&gt;n_targets&lt;/a&gt;或&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-samples&quot;&gt;n_samples&lt;/a&gt;非常大时，可提高性能。请注意，如果您已经有这样的矩阵，则可以将它们直接传递给fit方法。</target>
        </trans-unit>
        <trans-unit id="d97545296a16ed9ee24e38ded3551b9344d66c64" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;code&gt;n_targets&lt;/code&gt; or &lt;code&gt;n_samples&lt;/code&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="translated">是否使用预先计算的Gram和Xy矩阵来加快计算速度。当 &lt;code&gt;n_targets&lt;/code&gt; 或 &lt;code&gt;n_samples&lt;/code&gt; 非常大时提高性能。请注意，如果您已经有这样的矩阵，则可以将它们直接传递给fit方法。</target>
        </trans-unit>
        <trans-unit id="7dc600168d6ae4c500452eb14badcdfddafb11ff" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &amp;lsquo;auto&amp;rsquo; let us decide. The Gram matrix can also be passed as argument, but it will be used only for the selection of parameter alpha, if alpha is &amp;lsquo;aic&amp;rsquo; or &amp;lsquo;bic&amp;rsquo;.</source>
          <target state="translated">是否使用预先计算的Gram矩阵来加快计算速度。如果设置为&amp;ldquo;自动&amp;rdquo;，请让我们决定。Gram矩阵也可以作为参数传递，但是如果alpha是'aic'或'bic'，则它将仅用于参数alpha的选择。</target>
        </trans-unit>
        <trans-unit id="0057a82fcc5e3ed086a2d1961e27e45b3f58597f" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument.</source>
          <target state="translated">是否使用预先计算的Gram矩阵来加快计算速度。如果设置为 &lt;code&gt;'auto'&lt;/code&gt; 让我们决定。语法矩阵也可以作为参数传递。</target>
        </trans-unit>
        <trans-unit id="419f7e60c7c4f4f84360a1078ab4b36ce5bf208a" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">是否使用预先计算的Gram矩阵来加快计算速度。如果设置为 &lt;code&gt;'auto'&lt;/code&gt; 让我们决定。语法矩阵也可以作为参数传递。对于稀疏输入，此选项始终为 &lt;code&gt;True&lt;/code&gt; 以保留稀疏性。</target>
        </trans-unit>
        <trans-unit id="18cfe378dd4d6390fca460de4e70af73f097cdf4" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.</source>
          <target state="translated">是否使用预先计算的Gram矩阵来加快计算速度。如果设置为 &lt;code&gt;'auto'&lt;/code&gt; 让我们决定。不能将Gram矩阵作为参数传递，因为我们将仅使用X的子集。</target>
        </trans-unit>
        <trans-unit id="2bc24bd08e69b99e2a7b63ee3e5ac92e16a75bc1" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">是否使用预先计算的Gram矩阵来加快计算速度。语法矩阵也可以作为参数传递。对于稀疏输入，此选项始终为 &lt;code&gt;True&lt;/code&gt; 以保留稀疏性。</target>
        </trans-unit>
        <trans-unit id="1efc80d653c0b8715eb15bdf1b19f3becd74a957" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">当验证得分没有提高时,是否使用提前停止来终止训练。如果设置为True,则会自动预留一部分训练数据作为验证,当验证得分在连续的n_iter_no_change epoch中至少tol以上没有改善时,终止训练。</target>
        </trans-unit>
        <trans-unit id="46750b1ddce70e8be53fc930ce5b9a753b67b8f6" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs.</source>
          <target state="translated">当验证分数没有提高时，是否使用提前停止来终止训练。如果设置为TRUE时，会自动拨出的训练数据作为验证的一部分，并终止训练当由返回的确认得分 &lt;code&gt;score&lt;/code&gt; 方法不受至少改善 &lt;code&gt;tol&lt;/code&gt; 为 &lt;code&gt;n_iter_no_change&lt;/code&gt; 连续时期。</target>
        </trans-unit>
        <trans-unit id="febff6e36a4dd65c498e48c75789d34dc34067ef" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">当验证分数没有提高时，是否使用提前停止来终止训练。如果设置为True，它将自动将训练数据的分层部分留作验证，并在 &lt;code&gt;score&lt;/code&gt; 方法返回的验证得分没有连续n个改善至少tol的情况下终止训练。</target>
        </trans-unit>
        <trans-unit id="9af303ba091050935df1b1843777cae63d69ca4c" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">当验证分数没有提高时是否使用提前停止来终止训练。如果设置为true，它会自动设置的训练数据，验证预留10％，结束训练的时候验证比分没有被至少提高 &lt;code&gt;tol&lt;/code&gt; 为 &lt;code&gt;n_iter_no_change&lt;/code&gt; 连续的时期。仅在Solver ='sgd'或'adam'时有效</target>
        </trans-unit>
        <trans-unit id="998484dc55c21823abb36e2b54f5b8f623a0a41f" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">当验证分数没有提高时是否使用提前停止来终止训练。如果设置为true，它将自动预留10％的训练数据作为验证，并在 &lt;code&gt;n_iter_no_change&lt;/code&gt; 连续时期验证分数没有改善至少tol时终止训练。仅在Solver ='sgd'或'adam'时有效</target>
        </trans-unit>
        <trans-unit id="87617bcbcc672722844a1d3a57de3b252ff02aa0" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">当验证分数没有提高时，是否使用提前停止来终止训练。如果设置为true，它将自动将训练数据的10％ &lt;code&gt;n_iter_no_change&lt;/code&gt; 验证，并在n_iter_no_change连续时期验证分数没有改善至少tol时终止训练。除多标签设置外，拆分是分层的。仅在Solver ='sgd'或'adam'时有效</target>
        </trans-unit>
        <trans-unit id="cec695b146ca339e70be6934dce1a5005aa741f4" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">当验证得分没有提高时,是否使用提前停止来终止训练。如果设置为True,则会自动预留一部分训练数据作为验证,当验证得分在连续的n_iter_no_change epoch中至少tol没有改善时,终止训练。</target>
        </trans-unit>
        <trans-unit id="09b2b6c8cb36dc98a800b35af81d1805bc50fee1" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">当验证得分没有提高时,是否使用提前停止来终止训练。如果设置为True,则会自动将训练数据中的分层部分作为验证数据,当验证得分在连续的n_iter_no_change epoch中至少tol以上没有改善时,终止训练。</target>
        </trans-unit>
        <trans-unit id="aad0324e5e5b11eda436b08ef9513e34456be6fd" translate="yes" xml:space="preserve">
          <source>Whether to use mini-batch k-means, which is faster but may get different results.</source>
          <target state="translated">是否使用mini-batch k-means,这样速度更快,但可能会得到不同的结果。</target>
        </trans-unit>
        <trans-unit id="098e9f05a9707c21daca2709c375c5f67a6fc326" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the R^2 on unseen data.</source>
          <target state="translated">是否使用袋外样本来估计未见数据的R^2。</target>
        </trans-unit>
        <trans-unit id="cf1378e2f07c46392b05b68a8d3fb4a1b87de256" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization accuracy.</source>
          <target state="translated">是否使用袋外样本来估计泛化精度。</target>
        </trans-unit>
        <trans-unit id="b9d7a8d80bd713aecc3b75a6342d626d4ac28b69" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization error.</source>
          <target state="translated">是否使用袋外样本来估计泛化误差。</target>
        </trans-unit>
        <trans-unit id="3aa24f38e2caae33363ee03e7cecc2915d7b4a6e" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic.</source>
          <target state="translated">是否使用缩水启发式。</target>
        </trans-unit>
        <trans-unit id="f030250afefd9a8186bdcbf55c79f9c30e8d6a17" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic. See the &lt;a href=&quot;../svm#shrinking-svm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">是否使用缩小的启发式方法。请参阅《&lt;a href=&quot;../svm#shrinking-svm&quot;&gt;用户指南》&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0fcee6cb3493ee9e39e4cf5b70ffc63bc5b7fc72" translate="yes" xml:space="preserve">
          <source>Whether to zip the stored data on disk. If an integer is given, it should be between 1 and 9, and sets the amount of compression. Note that compressed arrays cannot be read by memmapping.</source>
          <target state="translated">是否将存储的数据压缩到磁盘上。如果给出一个整数,应该在1到9之间,并设置压缩量。注意,压缩后的数组不能通过memmapping读取。</target>
        </trans-unit>
        <trans-unit id="67c666eda0eb6c9f89cf06ca0fe8ba3d19260935" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices.</source>
          <target state="translated">变换是否应该产生scipy.sparse矩阵。</target>
        </trans-unit>
        <trans-unit id="a8c18609d5573425cb13e22e1562611896bad931" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices. True by default.</source>
          <target state="translated">变换是否应该生成 scipy.sparse 矩阵。默认为true。</target>
        </trans-unit>
        <trans-unit id="a2a2f7408a4ab356f12406498e7b656415a8f8e4" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the [0, 1] interval, i.e. is not a proper probability. If True, the smallest value in y_prob is linearly mapped onto 0 and the largest one onto 1.</source>
          <target state="translated">y_prob 是否需要归一化到 [0,1]区间,即不是一个合适的概率。如果为真,y_prob中最小的值线性映射到0,最大的值映射到1。</target>
        </trans-unit>
        <trans-unit id="96e3c213b0373954a6f42c2953a288bf58e9c8e1" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the bin [0, 1], i.e. is not a proper probability. If True, the smallest value in y_prob is mapped onto 0 and the largest one onto 1.</source>
          <target state="translated">y_prob 是否需要归一化到bin [0,1],即不是一个合适的概率。如果为True,则y_prob中的最小值映射到0,最大值映射到1。</target>
        </trans-unit>
        <trans-unit id="673ccf9c3156ee120e948d124a09a8f79d0986df" translate="yes" xml:space="preserve">
          <source>Which SVD method to use. If &amp;lsquo;lapack&amp;rsquo; use standard SVD from scipy.linalg, if &amp;lsquo;randomized&amp;rsquo; use fast &lt;code&gt;randomized_svd&lt;/code&gt; function. Defaults to &amp;lsquo;randomized&amp;rsquo;. For most applications &amp;lsquo;randomized&amp;rsquo; will be sufficiently precise while providing significant speed gains. Accuracy can also be improved by setting higher values for &lt;code&gt;iterated_power&lt;/code&gt;. If this is not sufficient, for maximum precision you should choose &amp;lsquo;lapack&amp;rsquo;.</source>
          <target state="translated">使用哪种SVD方法。如果&amp;ldquo; lapack&amp;rdquo;使用scipy.linalg中的标准SVD，如果&amp;ldquo;随机化&amp;rdquo;，则使用快速 &lt;code&gt;randomized_svd&lt;/code&gt; 函数。默认为&amp;ldquo;随机化&amp;rdquo;。对于大多数应用程序，&amp;ldquo;随机化&amp;rdquo;将足够精确，同时可显着提高速度。通过为 &lt;code&gt;iterated_power&lt;/code&gt; 设置更高的值也可以提高精度。如果这还不够，为了获得最大的精度，您应该选择&amp;ldquo; lapack&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="3f4bd36722594cddb9c4f04fa1feac290cb2c703" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &amp;lsquo;precomputed&amp;rsquo; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &amp;lsquo;euclidean&amp;rsquo; uses the negative squared euclidean distance between points.</source>
          <target state="translated">使用哪个亲和力。目前支持&amp;ldquo;预计算&amp;rdquo;和 &lt;code&gt;euclidean&lt;/code&gt; 。&amp;ldquo;欧几里得&amp;rdquo;使用点之间的负平方欧几里得距离。</target>
        </trans-unit>
        <trans-unit id="f51286fa5438dabdb2fdc9e6a35c79244bd208d2" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &lt;code&gt;precomputed&lt;/code&gt; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &lt;code&gt;euclidean&lt;/code&gt; uses the negative squared euclidean distance between points.</source>
          <target state="translated">使用哪个亲和力。目前支持 &lt;code&gt;precomputed&lt;/code&gt; 和 &lt;code&gt;euclidean&lt;/code&gt; 。 &lt;code&gt;euclidean&lt;/code&gt; 使用点之间的负平方欧几里得距离。</target>
        </trans-unit>
        <trans-unit id="0a291d7f5d694ce4dae77d370f938e385f2f41cf" translate="yes" xml:space="preserve">
          <source>Which kind of estimators should be returned. If None, no filter is applied and all estimators are returned. Possible values are &amp;lsquo;classifier&amp;rsquo;, &amp;lsquo;regressor&amp;rsquo;, &amp;lsquo;cluster&amp;rsquo; and &amp;lsquo;transformer&amp;rsquo; to get estimators only of these specific types, or a list of these to get the estimators that fit at least one of the types.</source>
          <target state="translated">应该返回哪种估计量。如果为None，则不应用任何过滤器，并返回所有估算器。可能的值是'classifier'，'regressor'，'cluster'和'transformer'，以仅获取这些特定类型的估计量，或者是这些列表以获取至少适合这些类型之一的估计量。</target>
        </trans-unit>
        <trans-unit id="9ab873abc046d5e79c6628d1e73d15a9a8c8a011" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of features. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">使用哪种联系标准。链接准则决定了在特征集之间使用哪个距离。算法将合并最小化这个标准的聚类对。</target>
        </trans-unit>
        <trans-unit id="17ba6fc895d15866ea1e60a4db791726755dc58f" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">使用哪种联系标准。联结准则决定了观察集之间使用哪个距离。算法将合并最小化该标准的簇对。</target>
        </trans-unit>
        <trans-unit id="7c032065ee1e199d65a12de581955d2510001155" translate="yes" xml:space="preserve">
          <source>Which metric to use for computing pairwise distances between samples from the original input space. If metric is &amp;lsquo;precomputed&amp;rsquo;, X must be a matrix of pairwise distances or squared distances. Otherwise, see the documentation of argument metric in sklearn.pairwise.pairwise_distances for a list of available metrics.</source>
          <target state="translated">用于计算距原始输入空间的样本之间的成对距离的度量标准。如果度量是&amp;ldquo;预先计算的&amp;rdquo;，则X必须是成对距离或平方距离的矩阵。否则，请参阅sklearn.pairwise.pairwise_distances中的参数度量文档，以获取可用度量的列表。</target>
        </trans-unit>
        <trans-unit id="7ca40022d1c5dcd68056f855d9cb29fbb48c9062" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgement: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="translated">哪种模型是最好的,这是一个主观判断的问题:我们是要偏向于只抓住大局来总结和解释数据的大部分结构而忽略细节的模型,还是偏向于紧跟信号高密度区域的模型?</target>
        </trans-unit>
        <trans-unit id="3bad9460d63c46d91cb72ce5e70c801fdf7d8e5b" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgment: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="translated">哪种模型是最好的,这是一个主观判断的问题:我们是要偏向于只抓住全局来总结和解释数据的大部分结构而忽略细节的模型,还是偏向于紧跟信号高密度区域的模型?</target>
        </trans-unit>
        <trans-unit id="f9b07db46ccf2aab5a3f471f9311e28ace0c3658" translate="yes" xml:space="preserve">
          <source>Which strategy to use to initialize the missing values. Same as the &lt;code&gt;strategy&lt;/code&gt; parameter in &lt;a href=&quot;sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt; Valid values: {&amp;ldquo;mean&amp;rdquo;, &amp;ldquo;median&amp;rdquo;, &amp;ldquo;most_frequent&amp;rdquo;, or &amp;ldquo;constant&amp;rdquo;}.</source>
          <target state="translated">用于初始化缺失值的策略。与&lt;a href=&quot;sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt; 中&lt;/a&gt;的 &lt;code&gt;strategy&lt;/code&gt; 参数相同有效值：{&amp;ldquo; mean&amp;rdquo;，&amp;ldquo; median&amp;rdquo;，&amp;ldquo; most_frequent&amp;rdquo;或&amp;ldquo; constant&amp;rdquo;}。</target>
        </trans-unit>
        <trans-unit id="e8cddae54ed0b1b16ee030ff58543e83ff547ded" translate="yes" xml:space="preserve">
          <source>While Isomap, LLE and variants are best suited to unfold a single continuous low dimensional manifold, t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples as highlighted on the S-curve example. This ability to group samples based on the local structure might be beneficial to visually disentangle a dataset that comprises several manifolds at once as is the case in the digits dataset.</source>
          <target state="translated">Isomap、LLE和变体最适合展开单个连续的低维歧管,而t-SNE将关注数据的局部结构,并倾向于提取S曲线示例上突出显示的聚类局部样本组。这种基于局部结构对样本进行分组的能力可能有利于直观地拆分一个同时由多个歧管组成的数据集,就像数字数据集的情况一样。</target>
        </trans-unit>
        <trans-unit id="d80a7676bafb31f5f9bcb99f7aed7e1817a9d535" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="translated">虽然从&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;和&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt;派生的SVM模型使用 &lt;code&gt;C&lt;/code&gt; 作为正则化参数，但大多数其他估计量都使用 &lt;code&gt;alpha&lt;/code&gt; 。两个模型的正则化量之间的确切等价关系取决于模型优化的精确目标函数。例如，当使用的估计量为 &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; 回归时，它们之间的关系为\（C = \ frac {1} {alpha} \）。</target>
        </trans-unit>
        <trans-unit id="e19b90ac75c89776c8025a4fe5ef49998061f2d2" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="translated">虽然从&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;和&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt;派生的SVM模型使用 &lt;code&gt;C&lt;/code&gt; 作为正则化参数，但大多数其他估计量都使用 &lt;code&gt;alpha&lt;/code&gt; 。两个模型的正则化量之间的确切等价关系取决于模型优化的确切目标函数。例如，当使用的估计量为 &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; 回归时，它们之间的关系为\（C = \ frac {1} {alpha} \）。</target>
        </trans-unit>
        <trans-unit id="b688dd0a76a7a11c780bc8304b263ca13e9c529b" translate="yes" xml:space="preserve">
          <source>While both methods should be close in general, they might differ in some specific settings. The &amp;lsquo;brute&amp;rsquo; method assumes the existence of the data points \((x_S, x_C^{(i)})\). When the features are correlated, such artificial samples may have a very low probability mass. The &amp;lsquo;brute&amp;rsquo; and &amp;lsquo;recursion&amp;rsquo; methods will likely disagree regarding the value of the partial dependence, because they will treat these unlikely samples differently. Remember, however, that the primary assumption for interpreting PDPs is that the features should be independent.</source>
          <target state="translated">虽然这两种方法通常应该很接近，但是它们在某些特定的设置上可能会有所不同。 'brute'方法假定存在数据点\（（x_S，x_C ^ {（i）}）\）。当特征相关时，这样的人工样本可能具有非常低的概率质量。 &amp;ldquo;粗略&amp;rdquo;和&amp;ldquo;递归&amp;rdquo;方法在部分依赖的值上可能会存在分歧，因为它们将对这些不太可能的样本进行不同的处理。但是请记住，解释PDP的主要假设是功能应独立。</target>
        </trans-unit>
        <trans-unit id="fb6c7d447c33735b14bfab3f939085b49d50d551" translate="yes" xml:space="preserve">
          <source>While defining the custom scoring function alongside the calling function should work out of the box with the default joblib backend (loky), importing it from another module will be a more robust approach and work independently of the joblib backend.</source>
          <target state="translated">虽然在调用函数的同时定义自定义的评分函数,应该可以在默认的joblib后台(loky)下运行,但从其他模块导入它将是一种更强大的方法,并且可以独立于joblib后台运行。</target>
        </trans-unit>
        <trans-unit id="c20daeb41107431c48223b43ad4fe138aa4845d5" translate="yes" xml:space="preserve">
          <source>While experimenting with any learning algorithm, it is important not to test the prediction of an estimator on the data used to fit the estimator as this would not be evaluating the performance of the estimator on &lt;strong&gt;new data&lt;/strong&gt;. This is why datasets are often split into &lt;em&gt;train&lt;/em&gt; and &lt;em&gt;test&lt;/em&gt; data.</source>
          <target state="translated">在尝试使用任何学习算法进行实验时，重要的是不要在用于拟合估计器的数据上测试估计器的预测，因为这将不会在&lt;strong&gt;新数据&lt;/strong&gt;上评估估计器的性能。这就是为什么数据集经常被分成&lt;em&gt;训练&lt;/em&gt;和&lt;em&gt;测试&lt;/em&gt;数据的原因。</target>
        </trans-unit>
        <trans-unit id="f8808630553e3f4de197fcbd8d96757a9a769400" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt;. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="translated">尽管iid数据是机器学习理论中的常见假设，但在实践中却很少见。如果知道样品是使用与时间有关的过程生成的，则使用具有&lt;a href=&quot;#timeseries-cv&quot;&gt;时间序列意识的交叉验证方案&lt;/a&gt;会更安全。同样，如果我们知道生成过程具有组结构（从不同主题，实验，测量设备收集的样本），则使用&lt;a href=&quot;#group-cv&quot;&gt;逐组交叉验证&lt;/a&gt;会更安全。</target>
        </trans-unit>
        <trans-unit id="d04cd5b9d0463d9bc89f841d571873fec4953569" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it&amp;rsquo;s safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt; Similarly if we know that the generative process has a group structure (samples from collected from different subjects, experiments, measurement devices) it safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="translated">尽管iid数据是机器学习理论中的常见假设，但在实践中却很少见。如果知道样品是使用时间相关的过程生成的，则使用具有&lt;a href=&quot;#timeseries-cv&quot;&gt;时间序列意识的交叉验证方案会&lt;/a&gt;更安全。类似地，如果我们知道生成过程具有组结构（从不同受试者收集的样品，实验，测量设备）更安全地使用&lt;a href=&quot;#group-cv&quot;&gt;逐组交叉验证&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0526a7a936d1a8c691dcdaa23691304fc8ebc7ef" translate="yes" xml:space="preserve">
          <source>While in the spirit of an online algorithm, the class &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt; does not implement &lt;code&gt;partial_fit&lt;/code&gt; because the algorithm is online along the features direction, not the samples direction.</source>
          <target state="translated">尽管本着在线算法的精神，但&lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt;类不实现 &lt;code&gt;partial_fit&lt;/code&gt; ,因为该算法沿要素方向而不是样本方向在线。</target>
        </trans-unit>
        <trans-unit id="c8d4a37562dd2bb8e9910fd82f43df80f682c63a" translate="yes" xml:space="preserve">
          <source>While many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized, intuitively we can think of Principle Component Analysis (PCA) as being a prime example of when normalization is important. In PCA we are interested in the components that maximize the variance. If one component (e.g. human height) varies less than another (e.g. weight) because of their respective scales (meters vs. kilos), PCA might determine that the direction of maximal variance more closely corresponds with the &amp;lsquo;weight&amp;rsquo; axis, if those features are not scaled. As a change in height of one meter can be considered much more important than the change in weight of one kilogram, this is clearly incorrect.</source>
          <target state="translated">尽管许多算法（例如SVM，K近邻算法和逻辑回归）都需要对功能进行规范化，但直觉上我们可以将主成分分析（PCA）视为规范化非常重要的主要示例。在PCA中，我们对最大化方差的组件感兴趣。如果一个组件（例如，人类身高）因其各自的尺度（米与公斤）而变化的幅度小于另一组件（例如，体重），则PCA可能会确定最大方差的方向与&amp;ldquo;体重&amp;rdquo;轴更接近，如果这些特征不缩放。因为一米的高度变化比一公斤的重量变化重要得多，所以这显然是不正确的。</target>
        </trans-unit>
        <trans-unit id="3e272f5577ff59f34cc0835d41b4f8bd0e7fa207" translate="yes" xml:space="preserve">
          <source>While models saved using one version of scikit-learn might load in other versions, this is entirely unsupported and inadvisable. It should also be kept in mind that operations performed on such data could give different and unexpected results.</source>
          <target state="translated">虽然使用一个版本的 scikit-learn 保存的模型可能会在其他版本中加载,但这是完全不支持也不可取的。还应该记住,对这些数据进行的操作可能会得到不同的、意想不到的结果。</target>
        </trans-unit>
        <trans-unit id="5cdd1c0f02e03a5a1b156076678017404f8561ab" translate="yes" xml:space="preserve">
          <source>While multiclass data is provided to the metric, like binary targets, as an array of class labels, multilabel data is specified as an indicator matrix, in which cell &lt;code&gt;[i, j]&lt;/code&gt; has value 1 if sample &lt;code&gt;i&lt;/code&gt; has label &lt;code&gt;j&lt;/code&gt; and value 0 otherwise.</source>
          <target state="translated">虽然将多类数据（如二进制目标）作为类标签数组提供给度量标准，但将多标签数据指定为指标矩阵，如果样本 &lt;code&gt;i&lt;/code&gt; 具有标签 &lt;code&gt;j&lt;/code&gt; ，则单元格 &lt;code&gt;[i, j]&lt;/code&gt; 值为1 ，否则为0 。</target>
        </trans-unit>
        <trans-unit id="ed422f68a65d31027201e13d55d1a7c59ba06f45" translate="yes" xml:space="preserve">
          <source>While not particularly fast to process, Python&amp;rsquo;s &lt;code&gt;dict&lt;/code&gt; has the advantages of being convenient to use, being sparse (absent features need not be stored) and storing feature names in addition to values.</source>
          <target state="translated">尽管处理起来不是特别快，但是Python的 &lt;code&gt;dict&lt;/code&gt; 具有以下优点：易于使用，稀疏（无需存储缺少的功能）以及除值外还存储功能名称。</target>
        </trans-unit>
        <trans-unit id="6575e62afd8d9d86f5e5759f0c1f4bf12add49e4" translate="yes" xml:space="preserve">
          <source>While some local positioning information can be preserved by extracting n-grams instead of individual words, bag of words and bag of n-grams destroy most of the inner structure of the document and hence most of the meaning carried by that internal structure.</source>
          <target state="translated">虽然通过提取n-gram而不是单个单词,可以保留一些局部定位信息,但单词袋和n-gram袋破坏了文档的大部分内部结构,从而破坏了该内部结构所承载的大部分意义。</target>
        </trans-unit>
        <trans-unit id="f9eb71a899b2efe02a5e86463ae919f1b60ed0f7" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any (sparse) feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="translated">尽管&lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt;转换器可与任何（稀疏）特征矩阵配合使用，但建议在LSA /文档处理设置中的原始频率计数上，在tf&amp;ndash;idf矩阵上使用它。特别是，应该打开亚线性缩放和逆文档频率（ &lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt; ），以使特征值更接近高斯分布，从而补偿LSA对文本数据的错误假设。</target>
        </trans-unit>
        <trans-unit id="f9e8e04743afddc659f8d58efbc124813976ac9e" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="translated">尽管&lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt;转换器可与任何特征矩阵配合使用，但建议在tf&amp;ndash;idf矩阵上使用它而不是LSA /文档处理设置中的原始频率计数。特别是，应该打开亚线性缩放和逆文档频率（ &lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt; ）以使特征值更接近高斯分布，以补偿LSA关于文本数据的错误假设。</target>
        </trans-unit>
        <trans-unit id="29a2650e25fbd5181744282ce886a2b96e4ac93d" translate="yes" xml:space="preserve">
          <source>While the above example sets the &lt;code&gt;standardize&lt;/code&gt; option to &lt;code&gt;False&lt;/code&gt;, &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; will apply zero-mean, unit-variance normalization to the transformed output by default.</source>
          <target state="translated">尽管上面的示例将 &lt;code&gt;standardize&lt;/code&gt; 选项设置为 &lt;code&gt;False&lt;/code&gt; ，但&lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt; &lt;code&gt;PowerTransformer&lt;/code&gt; &lt;/a&gt;默认将零均值，单位方差归一化应用于转换后的输出。</target>
        </trans-unit>
        <trans-unit id="e50cabfff84e84e9590f53c8299406f023e4e46d" translate="yes" xml:space="preserve">
          <source>While the hyperparameters chosen by optimizing LML have a considerable larger LML, they perform slightly worse according to the log-loss on test data. The figure shows that this is because they exhibit a steep change of the class probabilities at the class boundaries (which is good) but have predicted probabilities close to 0.5 far away from the class boundaries (which is bad) This undesirable effect is caused by the Laplace approximation used internally by GPC.</source>
          <target state="translated">虽然通过优化LML选择的超参数具有相当大的LML,但根据测试数据上的对数损失,它们的表现稍差。从图中可以看出,这是因为它们在类边界处表现出类概率的陡峭变化(这是好的),但在远离类边界处的预测概率接近0.5(这是坏的)这种不良影响是由GPC内部使用的拉普拉斯近似引起的。</target>
        </trans-unit>
        <trans-unit id="2c9458b61e67bda12a1df752c0cc6921b6ff30dd" translate="yes" xml:space="preserve">
          <source>While the parameter &lt;code&gt;min_samples&lt;/code&gt; primarily controls how tolerant the algorithm is towards noise (on noisy and large data sets it may be desirable to increase this parameter), the parameter &lt;code&gt;eps&lt;/code&gt; is &lt;em&gt;crucial to choose appropriately&lt;/em&gt; for the data set and distance function and usually cannot be left at the default value. It controls the local neighborhood of the points. When chosen too small, most data will not be clustered at all (and labeled as &lt;code&gt;-1&lt;/code&gt; for &amp;ldquo;noise&amp;rdquo;). When chosen too large, it causes close clusters to be merged into one cluster, and eventually the entire data set to be returned as a single cluster. Some heuristics for choosing this parameter have been discussed in the literature, for example based on a knee in the nearest neighbor distances plot (as discussed in the references below).</source>
          <target state="translated">虽然参数 &lt;code&gt;min_samples&lt;/code&gt; 主要控制算法如何耐受是朝着噪声（在嘈杂和大的数据集，可能希望增加该参数），该参数 &lt;code&gt;eps&lt;/code&gt; 是&lt;em&gt;至关重要的适当地选择&lt;/em&gt;用于所述数据集和距离函数，通常不能留为默认值。它控制点的本地邻域。如果选择的值太小，则大多数数据将根本不会聚类（并标记为 &lt;code&gt;-1&lt;/code&gt; 代表&amp;ldquo;噪音&amp;rdquo;）。当选择了过大，它会导致靠近簇被合并成一个集群，并且最终整个数据集被返回作为单个集群。在文献中已经讨论了一些用于选择该参数的试探法，例如基于最近邻居距离图中的膝盖（如以下参考文献中所述）。</target>
        </trans-unit>
        <trans-unit id="17e6df329175ba9fee759ed839a4afe469b184fd" translate="yes" xml:space="preserve">
          <source>While the tf&amp;ndash;idf normalization is often very useful, there might be cases where the binary occurrence markers might offer better features. This can be achieved by using the &lt;code&gt;binary&lt;/code&gt; parameter of &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. In particular, some estimators such as &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes&lt;/a&gt; explicitly model discrete boolean random variables. Also, very short texts are likely to have noisy tf&amp;ndash;idf values while the binary occurrence info is more stable.</source>
          <target state="translated">尽管tf&amp;ndash;idf归一化通常非常有用，但在某些情况下，二进制出现标记可能会提供更好的功能。这可以通过使用&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;binary&lt;/code&gt; 参数来实现。特别是，某些估计器（例如&lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes）&lt;/a&gt;明确地对离散布尔随机变量建模。同样，很短的文本可能带有嘈杂的tf&amp;ndash;idf值，而二进制出现信息则更稳定。</target>
        </trans-unit>
        <trans-unit id="ed181b0221327c005991b804ef6da84808fa6b75" translate="yes" xml:space="preserve">
          <source>While these examples give some intuition about the algorithms, this intuition might not apply to very high dimensional data.</source>
          <target state="translated">虽然这些例子给出了一些关于算法的直觉,但这种直觉可能不适用于非常高维的数据。</target>
        </trans-unit>
        <trans-unit id="20e141fdf1f5d5d16051f029790d3b9e841c723d" translate="yes" xml:space="preserve">
          <source>While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:</source>
          <target state="translated">尽管使用参数设置网格是当前最广泛用于参数优化的方法，但其他搜索方法具有更有利的属性。&lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt;实现对参数的随机搜索，其中每个设置都是从​​可能的参数值的分布中采样的。与详尽搜索相比，这有两个主要优点：</target>
        </trans-unit>
        <trans-unit id="37619fc13053f82b7cb7da3d24ceb1598ab6d05c" translate="yes" xml:space="preserve">
          <source>White</source>
          <target state="translated">White</target>
        </trans-unit>
        <trans-unit id="ae7c1638fd1917cb535ca7c68b4bd5f19a47ea30" translate="yes" xml:space="preserve">
          <source>White kernel.</source>
          <target state="translated">白仁。</target>
        </trans-unit>
        <trans-unit id="6eaf9e8193566018ccba0d72a95d7647c23f2585" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.</source>
          <target state="translated">白化会从变换后的信号中去除一些信息(分量的相对方差尺度),但有时可以通过使其数据尊重一些硬性假设来提高下游估计器的预测精度。</target>
        </trans-unit>
        <trans-unit id="07aaa00ad7b994406ce70b8bd7598f7e15e6859a" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometimes improve the predictive accuracy of the downstream estimators by making data respect some hard-wired assumptions.</source>
          <target state="translated">白化会从变换后的信号中删除一些信息(分量的相对方差尺度),但有时可以通过使数据尊重一些硬性假设来提高下游估计器的预测精度。</target>
        </trans-unit>
        <trans-unit id="c6caecec2578a0de52910be667f4fa7e322f3d31" translate="yes" xml:space="preserve">
          <source>Why does the plot above suggest that an increase in age leads to a decrease in wage? Why the &lt;a href=&quot;#marginal-dependencies&quot;&gt;initial pairplot&lt;/a&gt; is telling the opposite?</source>
          <target state="translated">为什么上面的图暗示年龄的增加导致工资的减少？为什么&lt;a href=&quot;#marginal-dependencies&quot;&gt;最初的pairplot&lt;/a&gt;会说明相反的情况？</target>
        </trans-unit>
        <trans-unit id="b5ed864ec9d16ad31c6639d1d4c3bf64e3372001" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Davies-Bouldin index.</source>
          <target state="translated">维基百科上的Davies-Bouldin索引条目。</target>
        </trans-unit>
        <trans-unit id="3ce8e9b9f756deae78c09a314c4cf49a1aacdb66" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Discounted Cumulative Gain</source>
          <target state="translated">维基百科上的 &quot;折扣累计收益 &quot;词条。</target>
        </trans-unit>
        <trans-unit id="a0184957526e21d06d99d8f077fe30eb4aaec4f9" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for contingency matrix</source>
          <target state="translated">维基百科上的应急矩阵条目</target>
        </trans-unit>
        <trans-unit id="55a3b17abc1268c1d436ba897c97b456b993b4ea" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the (normalized) Mutual Information</source>
          <target state="translated">维基百科上的(标准化)相互信息条目</target>
        </trans-unit>
        <trans-unit id="1f069c9fec7504cb4f8a493de2e1b54ffc547081" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Adjusted Mutual Information</source>
          <target state="translated">维基百科上的调整后相互信息条目</target>
        </trans-unit>
        <trans-unit id="8030a2f6eb81271b3b56dfad08af7aaea7fcfc10" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Average precision</source>
          <target state="translated">维基百科上的平均精度条目</target>
        </trans-unit>
        <trans-unit id="ca2fe3eff096e2c0ff94d3c0f6ce61af74cc646f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Brier score.</source>
          <target state="translated">维基百科上的布里尔得分条目。</target>
        </trans-unit>
        <trans-unit id="ffd655e9eb3a21416da69aac696bc5ce043a000f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Cohen&amp;rsquo;s kappa.</source>
          <target state="translated">维基百科中有关科恩（Cohen）的kappa的条目。</target>
        </trans-unit>
        <trans-unit id="8d8ae14fc3bcf00321ca2d4b9c37c609195c6275" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the F1-score</source>
          <target state="translated">维基百科的F1分数条目</target>
        </trans-unit>
        <trans-unit id="0d85777073541b6f8aecb3488f1962f6903fd77c" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Fowlkes-Mallows Index</source>
          <target state="translated">维基百科上的Fowlkes-Mallows索引条目</target>
        </trans-unit>
        <trans-unit id="738fb31d9583a6207339f58c0335e89437aa096f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Jaccard index</source>
          <target state="translated">维基百科上的贾卡德索引条目</target>
        </trans-unit>
        <trans-unit id="d69dce297a7e32abae3549494346594b424875bc" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Matthews Correlation Coefficient</source>
          <target state="translated">马修斯相关系数的维基百科词条</target>
        </trans-unit>
        <trans-unit id="d1c0692994293b3fef98ac5de7dd74e23175c8d1" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Precision and recall</source>
          <target state="translated">维基百科上的精密和召回条目</target>
        </trans-unit>
        <trans-unit id="6c2dd7ccbd3afed766d1ee6ce92b068445c27bbb" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Receiver operating characteristic</source>
          <target state="translated">维基百科上的接收机工作特性条目</target>
        </trans-unit>
        <trans-unit id="caae1d529b64ebeb0d4804273e9107122a389ac6" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the adjusted Rand index</source>
          <target state="translated">维基百科上关于调整后的兰德指数的条目</target>
        </trans-unit>
        <trans-unit id="ccc412d2bb1bb2397fbce7363889e5816eda01a2" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis</source>
          <target state="translated">维基百科上关于邻域成分分析的条目。</target>
        </trans-unit>
        <trans-unit id="3b36309de0386ff9491f5f72624bcd77d6a05e19" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis &lt;a href=&quot;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&quot;&gt;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&lt;/a&gt;</source>
          <target state="translated">Wikipedia关于邻里成分分析的条目&lt;a href=&quot;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&quot;&gt;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="af0472efa729237e92d89bb05e9ca0c8e7f37b5f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Coefficient of determination</source>
          <target state="translated">维基百科上关于测定系数的条目</target>
        </trans-unit>
        <trans-unit id="e345be5719f19335870d8d3a8cdd20b6bd307aa0" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hamming distance</source>
          <target state="translated">维基百科关于汉明距离的词条</target>
        </trans-unit>
        <trans-unit id="1857fa6b095ad66d104ea60f4be3df45f12529a3" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hinge loss</source>
          <target state="translated">维基百科关于铰链损失的条目</target>
        </trans-unit>
        <trans-unit id="d4ccd1b47442c7552ebe73794cdd38515c5ffdef" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Lasso</source>
          <target state="translated">维基百科上的拉索条目</target>
        </trans-unit>
        <trans-unit id="8751f23b19110bb289e70c6d8c900548f6c9b761" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Least-angle regression</source>
          <target state="translated">维基百科上关于最小角度回归的条目。</target>
        </trans-unit>
        <trans-unit id="ed8f4a303fe71f9ad0ec1e1b74ef6fe644dad80d" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Silhouette Coefficient</source>
          <target state="translated">维基百科上关于剪影系数的条目。</target>
        </trans-unit>
        <trans-unit id="0b665174747365aef367583fb0c32fb021d06a22" translate="yes" xml:space="preserve">
          <source>Wikipedia principal eigenvector</source>
          <target state="translated">维基百科主特征向量</target>
        </trans-unit>
        <trans-unit id="713348b23d025b202ea7f033591c046a82a1973b" translate="yes" xml:space="preserve">
          <source>Will be ignored when &lt;code&gt;y_true&lt;/code&gt; is binary.</source>
          <target state="translated">当 &lt;code&gt;y_true&lt;/code&gt; 为二进制时将被忽略。</target>
        </trans-unit>
        <trans-unit id="af498f4dd6f24dbc1f93745e77fe6ed29d0b9d0c" translate="yes" xml:space="preserve">
          <source>Will return sparse matrix if set True else will return an array.</source>
          <target state="translated">如果设置为True,将返回稀疏矩阵,否则将返回一个数组。</target>
        </trans-unit>
        <trans-unit id="f02c359862a5df44abc185413e06bdb77cfc5770" translate="yes" xml:space="preserve">
          <source>Williams, C.K.I. and Seeger, M. &amp;ldquo;Using the Nystroem method to speed up kernel machines&amp;rdquo;, Advances in neural information processing systems 2001</source>
          <target state="translated">CKI的Williams和M.的Seeger，M。&amp;ldquo;使用Nystroem方法加速内核机器&amp;rdquo;，神经信息处理系统的进步，2001年</target>
        </trans-unit>
        <trans-unit id="a20af0cf6ba0496377888d152bfba536fcfdefc1" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{\text{n\_classes}}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="translated">与 &lt;code&gt;adjusted=True&lt;/code&gt; ，平衡准确性报告从\（\ texttt {平衡精度}（Y，\ mathbf {0}，W）= \压裂{1} {\文本{N \ _classes}} \）的相对增加。在二进制情况下，这也称为&lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;* Youden's J statistic *&lt;/a&gt;或&lt;em&gt;notifyness&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="ad0e52061072794be72972cbf40b994abb34f953" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{n\_classes}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="translated">与 &lt;code&gt;adjusted=True&lt;/code&gt; ，平衡准确性报告从\（\ texttt {平衡精度}（Y，\ mathbf {0}，W）= \压裂{1} {N \ _classes} \）的相对增加。在二进制情况下，这也称为&lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;* Youden's J statistic *&lt;/a&gt;或&lt;em&gt;notifyness&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="8a7d860e7dc8979710329f97e747eaff0d3415d3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the input data.</source>
          <target state="translated">如果 &lt;code&gt;early_stopping=False&lt;/code&gt; ，则将模型拟合到整个输入数据上，并且停止条件基于在输入数据上计算出的目标函数。</target>
        </trans-unit>
        <trans-unit id="3fe735414475494b49457f76f31eea3026d08560" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the training data.</source>
          <target state="translated">如果 &lt;code&gt;early_stopping=False&lt;/code&gt; ，则将模型拟合到整个输入数据上，并且停止标准基于在训练数据上计算出的目标函数。</target>
        </trans-unit>
        <trans-unit id="5515c693f110557bb04dd8dc133e8927dc9c68e0" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score (using the &lt;code&gt;score&lt;/code&gt; method) computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="translated">使用 &lt;code&gt;early_stopping=True&lt;/code&gt; ，输入数据分为训练集和验证集。然后将模型拟合到训练集上，并且停止标准基于在验证集上计算出的预测得分（使用 &lt;code&gt;score&lt;/code&gt; 方法）。验证集的大小可以使用参数 &lt;code&gt;validation_fraction&lt;/code&gt; 进行更改。</target>
        </trans-unit>
        <trans-unit id="4ceb9e226f3e04a8a66252e3801eed93f740afd9" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="translated">使用 &lt;code&gt;early_stopping=True&lt;/code&gt; ，输入数据分为训练集和验证集。然后将模型拟合到训练集上，并且停止标准基于在验证集上计算出的预测得分。验证集的大小可以使用参数 &lt;code&gt;validation_fraction&lt;/code&gt; 进行更改。</target>
        </trans-unit>
        <trans-unit id="318aced6d4dfc924ad223bd54e79ede301143b06" translate="yes" xml:space="preserve">
          <source>With SGD or Adam, training supports online and mini-batch learning.</source>
          <target state="translated">使用SGD或Adam,培训支持在线和小批量学习。</target>
        </trans-unit>
        <trans-unit id="bebfaf6a5f7ee4311c7425773ef87a0b1b61dcc0" translate="yes" xml:space="preserve">
          <source>With SVMs and logistic-regression, the parameter C controls the sparsity: the smaller C the fewer features selected. With Lasso, the higher the alpha parameter, the fewer features selected.</source>
          <target state="translated">对于SVM和逻辑回归,参数C控制了稀疏度:C越小,选择的特征越少。对于Lasso,α参数越大,选择的特征越少。</target>
        </trans-unit>
        <trans-unit id="2e07775067fbbb8cee792ed1d4b4b0282fd223be" translate="yes" xml:space="preserve">
          <source>With \(P'(j) = |V_j| / N\). The mutual information (MI) between \(U\) and \(V\) is calculated by:</source>
          <target state="translated">随着(P'(j)=|V_j|/N\)。(U)和(V)之间的相互信息(MI)计算如下:</target>
        </trans-unit>
        <trans-unit id="2042997590ba0f656467c3f6df43427a875d6409" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image.</source>
          <target state="translated">通过聚类聚类,可以通过给出一个连接图来指定哪些样本可以聚在一起。scikit-learn中的图由它们的邻接矩阵来表示。通常情况下,会使用一个稀疏矩阵。例如,在对图像进行聚类时,这对检索连接区域(有时也称为连接成分)很有用。</target>
        </trans-unit>
        <trans-unit id="5313dd287c9c493fc21b86c81282cea7d0608304" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image:</source>
          <target state="translated">通过聚类聚类,可以通过给出一个连接图来指定哪些样本可以聚在一起。scikit-learn中的图由它们的邻接矩阵来表示。通常情况下,会使用一个稀疏矩阵。例如,在对图像进行聚类时,这对检索连接区域(有时也称为连接成分)很有用。</target>
        </trans-unit>
        <trans-unit id="ebae629f7af13ae26b867ab75161458173d10bdc" translate="yes" xml:space="preserve">
          <source>With regard to decision trees, this strategy can readily be used to support multi-output problems. This requires the following changes:</source>
          <target state="translated">关于决策树,这种策略可以很容易地用于支持多产出问题。这就需要作出以下改变:</target>
        </trans-unit>
        <trans-unit id="d6eab2b8513179355ba20cab88473d0665849027" translate="yes" xml:space="preserve">
          <source>With such an abundance of clues that distinguish newsgroups, the classifiers barely have to identify topics from text at all, and they all perform at the same high level.</source>
          <target state="translated">在如此丰富的区分新闻组的线索下,分类器几乎完全不需要从文本中识别主题,它们的表现都是一样的高水准。</target>
        </trans-unit>
        <trans-unit id="ba25a12704b8225df22eb5cee35ebe73afb76c8b" translate="yes" xml:space="preserve">
          <source>With sum_over_features equal to False it returns the componentwise distances.</source>
          <target state="translated">当sum_over_features等于False时,它返回分量的距离。</target>
        </trans-unit>
        <trans-unit id="54cc29b6387240d37c6717d5c94b33d650c1152c" translate="yes" xml:space="preserve">
          <source>With the &amp;lsquo;brute&amp;rsquo; method, the parameter &lt;code&gt;X&lt;/code&gt; is used both for generating the grid of values \(x_S\) and the complement feature values \(x_C\). However with the &amp;lsquo;recursion&amp;rsquo; method, &lt;code&gt;X&lt;/code&gt; is only used for the grid values: implicitly, the \(x_C\) values are those of the training data.</source>
          <target state="translated">通过'brute'方法，参数 &lt;code&gt;X&lt;/code&gt; 既用于生成值\（x_S \）的网格，又用于生成补数特征值\（x_C \）的网格。但是，使用&amp;ldquo;递归&amp;rdquo;方法时， &lt;code&gt;X&lt;/code&gt; 仅用于网格值：隐式地，\（x_C \）值是训练数据的值。</target>
        </trans-unit>
        <trans-unit id="67616371d2f2a0ec7fd27c8038627dc9ef441900" translate="yes" xml:space="preserve">
          <source>With the fitted model, we compute the predictions of the model on the test dataset. These predictions are used to compute the confustion matrix which is plotted with the &lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">使用拟合的模型，我们可以在测试数据集上计算模型的预测。这些预测用于计算使用&lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt; &lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt; &lt;/a&gt;绘制的混淆矩阵</target>
        </trans-unit>
        <trans-unit id="03d84c3da120d3c6633bcd8017a1f00e1bb6dad8" translate="yes" xml:space="preserve">
          <source>With this class, the base_estimator is fit on the train set of the cross-validation generator and the test set is used for calibration. The probabilities for each of the folds are then averaged for prediction. In case that cv=&amp;rdquo;prefit&amp;rdquo; is passed to __init__, it is assumed that base_estimator has been fitted already and all data is used for calibration. Note that data for fitting the classifier and for calibrating it must be disjoint.</source>
          <target state="translated">对于此类，将base_estimator拟合到交叉验证生成器的训练集上，并使用测试集进行校准。然后将每个折痕的概率取平均值进行预测。如果将cv =&amp;ldquo; prefit&amp;rdquo;传递给__init__，则假定base_estimator已被拟合，并且所有数据都用于校准。注意，用于分类器和校准的数据必须是不相交的。</target>
        </trans-unit>
        <trans-unit id="07ec442186310e3d4d8de1ef730f033183a12d2a" translate="yes" xml:space="preserve">
          <source>With this re-labeling of the data, our problem can be written</source>
          <target state="translated">通过这种对数据的重新标注,我们的问题可以写为</target>
        </trans-unit>
        <trans-unit id="bb9dc2936468de0109f9958206c68ba68552df6f" translate="yes" xml:space="preserve">
          <source>With this setup, a single distance calculation between a test point and the centroid is sufficient to determine a lower and upper bound on the distance to all points within the node. Because of the spherical geometry of the ball tree nodes, it can out-perform a &lt;em&gt;KD-tree&lt;/em&gt; in high dimensions, though the actual performance is highly dependent on the structure of the training data. In scikit-learn, ball-tree-based neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt;, and are computed using the class &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt;&lt;/a&gt;. Alternatively, the user can work with the &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class directly.</source>
          <target state="translated">使用此设置，测试点和质心之间的单个距离计算就足以确定到节点内所有点的距离的上下限。由于球树节点的球形几何形状，因此它在高维度上的性能可能&lt;em&gt;优于KD树&lt;/em&gt;，尽管实际性能在很大程度上取决于训练数据的结构。在scikit-learn中，使用关键字 &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt; 指定基于球树的邻居搜索，并使用&lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt; &lt;/a&gt;类进行计算。或者，用户可以直接使用&lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt;类。</target>
        </trans-unit>
        <trans-unit id="c5b891d6db4b2b53f2c329c62187e665d9759f8a" translate="yes" xml:space="preserve">
          <source>Without any prior information on the sample, the number of projections required to reconstruct the image is of the order of the linear size &lt;code&gt;l&lt;/code&gt; of the image (in pixels). For simplicity we consider here a sparse image, where only pixels on the boundary of objects have a non-zero value. Such data could correspond for example to a cellular material. Note however that most images are sparse in a different basis, such as the Haar wavelets. Only &lt;code&gt;l/7&lt;/code&gt; projections are acquired, therefore it is necessary to use prior information available on the sample (its sparsity): this is an example of &lt;strong&gt;compressive sensing&lt;/strong&gt;.</source>
          <target state="translated">在样本上没有任何先验信息的情况下，重建图像所需的投影数量约为图像的线性大小 &lt;code&gt;l&lt;/code&gt; （以像素为单位）。为简单起见，我们在这里考虑一个稀疏图像，其中只有对象边界上的像素具有非零值。这样的数据可以例如对应于蜂窝材料。但是请注意，大多数图像在不同的基础上都是稀疏的，例如Haar小波。仅 &lt;code&gt;l/7&lt;/code&gt; 突起被获取，因此，有必要使用可在样品（其稀疏性）先验信息：这是一个例子&lt;strong&gt;压缩感测&lt;/strong&gt;。</target>
        </trans-unit>
        <trans-unit id="087783a9ac4373b41b03a4f66d5eaf61d7d47ff1" translate="yes" xml:space="preserve">
          <source>Without reduce_func:</source>
          <target state="translated">没有reduce_func。</target>
        </trans-unit>
        <trans-unit id="e6002e635270be50830b0534ba0aafc304922d8b" translate="yes" xml:space="preserve">
          <source>Without shuffling, &lt;code&gt;X&lt;/code&gt; horizontally stacks features in the following order: the primary &lt;code&gt;n_informative&lt;/code&gt; features, followed by &lt;code&gt;n_redundant&lt;/code&gt; linear combinations of the informative features, followed by &lt;code&gt;n_repeated&lt;/code&gt; duplicates, drawn randomly with replacement from the informative and redundant features. The remaining features are filled with random noise. Thus, without shuffling, all useful features are contained in the columns &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt;.</source>
          <target state="translated">在不进行改组的情况下， &lt;code&gt;X&lt;/code&gt; 按以下顺序水平堆叠 &lt;code&gt;n_informative&lt;/code&gt; ：主要的n_informative特征，然后是 &lt;code&gt;n_redundant&lt;/code&gt; 线性的信息特征组合，然后是 &lt;code&gt;n_repeated&lt;/code&gt; 重复，从信息和冗余特征中随机替换。其余功能充满了随机噪声。因此，无需混洗，所有有用的功能都包含在 &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6943d5826611d6c30be0d7d32e8882ddb2f3e560" translate="yes" xml:space="preserve">
          <source>Wolpert, David H. &amp;ldquo;Stacked generalization.&amp;rdquo; Neural networks 5.2 (1992): 241-259.</source>
          <target state="translated">Wolpert，DavidH。&amp;ldquo;堆叠泛化&amp;rdquo;。神经网络5.2（1992）：241-259。</target>
        </trans-unit>
        <trans-unit id="d2a146386973596d64e5c0f348ec45ab36bab658" translate="yes" xml:space="preserve">
          <source>Working With Text Data</source>
          <target state="translated">使用文本数据</target>
        </trans-unit>
        <trans-unit id="61f49f0587c5992cc8f414bbf22889f09b8f3976" translate="yes" xml:space="preserve">
          <source>Working with text documents</source>
          <target state="translated">处理文本文件</target>
        </trans-unit>
        <trans-unit id="5b5ef6667bd92ea247084ea267c265251f4aa7de" translate="yes" xml:space="preserve">
          <source>Works with sparse matrices. Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">适用于稀疏矩阵。仅当存在 &lt;code&gt;rows_&lt;/code&gt; 和 &lt;code&gt;columns_&lt;/code&gt; 属性时有效。</target>
        </trans-unit>
        <trans-unit id="926da419b9cc98b9060a6d00fb8d48cd55be86f9" translate="yes" xml:space="preserve">
          <source>Wrapper for kernels in sklearn.metrics.pairwise.</source>
          <target state="translated">sklearn.metrics.pairwise中kernels的封装器。</target>
        </trans-unit>
        <trans-unit id="f986c2ac1f7dce99239d5b1ba2c2c97de265f3fa" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline to classify movie reviews as either positive or negative.</source>
          <target state="translated">编写一个文本分类流水线,将电影评论分为正面或负面。</target>
        </trans-unit>
        <trans-unit id="c1b32a0493a32a44864910f6b6b9c9398af4b20e" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline using a custom preprocessor and &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; using data from Wikipedia articles as training set.</source>
          <target state="translated">使用自定义预处理器和 &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; (使用Wikipedia文章中的数据作为训练集）编写文本分类管道。</target>
        </trans-unit>
        <trans-unit id="c72e193d2469d6cfb2918ba7a00dbc8ed1d451d6" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="translated">Wu，Lin和Weng，&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;通过成对耦合的多类别分类的概率估计&amp;rdquo;&lt;/a&gt;，JMLR 5：975-1005，2004。</target>
        </trans-unit>
        <trans-unit id="11ab439af4c255f5f8d3594c0dad27bd31f9055a" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="translated">Wu，Lin和Weng，&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;通过成对耦合的多类分类的概率估计&amp;rdquo;&lt;/a&gt;，JMLR 5：975-1005，2004。</target>
        </trans-unit>
        <trans-unit id="c8c1574205d07b839af62817660ba2b78f320cd0" translate="yes" xml:space="preserve">
          <source>X block loadings vectors.</source>
          <target state="translated">X块载荷向量。</target>
        </trans-unit>
        <trans-unit id="b8076ad410e1a569012d16107ff003e5d358439f" translate="yes" xml:space="preserve">
          <source>X block to latents rotations.</source>
          <target state="translated">X块到潜伏旋转。</target>
        </trans-unit>
        <trans-unit id="a6b8640132f42899bc713ee5acc307439a5b7049" translate="yes" xml:space="preserve">
          <source>X block weights vectors.</source>
          <target state="translated">X块权重向量。</target>
        </trans-unit>
        <trans-unit id="51ee8a5ebc2ecb45284445a844d1c86426452ff9" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set, using minibatches of size batch_size if X is sparse.</source>
          <target state="translated">X在之前从训练集提取的第一主成分上进行投影,如果X是稀疏的,则使用大小为batch_size的minibatches。</target>
        </trans-unit>
        <trans-unit id="e6bc2e58339df2a473a9897261f25e31780f738c" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set.</source>
          <target state="translated">X投射在之前从训练集提取的第一主成分上。</target>
        </trans-unit>
        <trans-unit id="81850902f59e77236b068c4b29af3fcf5c8ba36f" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;a href=&quot;#sklearn.isotonic.IsotonicRegression.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; needs X to interpolate new input data.</source>
          <target state="translated">X存储起来供将来使用，因为&lt;a href=&quot;#sklearn.isotonic.IsotonicRegression.transform&quot;&gt; &lt;code&gt;transform&lt;/code&gt; &lt;/a&gt;需要X插入新的输入数据。</target>
        </trans-unit>
        <trans-unit id="7228d382c859d348525ccb5bce51e5752c38bc04" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;code&gt;transform&lt;/code&gt; needs X to interpolate new input data.</source>
          <target state="translated">X存储起来供将来使用，因为 &lt;code&gt;transform&lt;/code&gt; 需要X插入新的输入数据。</target>
        </trans-unit>
        <trans-unit id="3074bef8d8da5f206ce501f5438e3d5abb038064" translate="yes" xml:space="preserve">
          <source>X must have been produced by this DictVectorizer&amp;rsquo;s transform or fit_transform method; it may only have passed through transformers that preserve the number of features and their order.</source>
          <target state="translated">X必须是由DictVectorizer的transform或fit_transform方法产生的；它可能只通过了保留特征数量及其顺序的变压器。</target>
        </trans-unit>
        <trans-unit id="d0ad8e13f68af13dec8ad59c4f3a6a0df7a4de08" translate="yes" xml:space="preserve">
          <source>X scores.</source>
          <target state="translated">X分。</target>
        </trans-unit>
        <trans-unit id="28a3e4c54c0fde2f1aaa67a11fe405d430c2fe41" translate="yes" xml:space="preserve">
          <source>X transformed in the new space.</source>
          <target state="translated">X在新的空间里转化。</target>
        </trans-unit>
        <trans-unit id="ae3643384dc9ac54889b85ea1da357f34b173e6e" translate="yes" xml:space="preserve">
          <source>X_embedded: ndarray of shape (n_samples, n_components)</source>
          <target state="translated">X_embedded:形状的ndarray(n_samples,n_components)</target>
        </trans-unit>
        <trans-unit id="d925cac037a82cae915e8a0893b59ac5a4590490" translate="yes" xml:space="preserve">
          <source>X_new array, shape (n_samples, n_components)</source>
          <target state="translated">X_new数组,shape (n_samples,n_components)</target>
        </trans-unit>
        <trans-unit id="b0e804c93132e5ef73393b841ae090d872aa2191" translate="yes" xml:space="preserve">
          <source>X_original array-like, shape (n_samples, n_features)</source>
          <target state="translated">X_original array-like,shape (n_samples,n_features)</target>
        </trans-unit>
        <trans-unit id="feedfda54d7431e28acb98075b2c2bd9cf8331f2" translate="yes" xml:space="preserve">
          <source>Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002 &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</source>
          <target state="translated">朱小金和邹斌&amp;middot;格哈拉玛尼。通过标签传播从标记和未标记的数据中学习。卡内基梅隆大学技术报告CMU-CALD-02-107，2002年&lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5c986ee528dd9bdf7a6c8d0101f77976c47ae9d2" translate="yes" xml:space="preserve">
          <source>Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;Theil-Sen Estimators in a Multiple Linear Regression Model.&lt;/a&gt;</source>
          <target state="translated">当心，彭汉祥，王学勤和张和平：&lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;多元线性回归模型中的Theil-Sen估计。&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3674e6b71697b8f4a5e14e694db26daa53371e84" translate="yes" xml:space="preserve">
          <source>Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.</source>
          <target state="translated">Xt[i,j]被分配了连接i和j的边缘的权重,只有邻居有一个显式的值。对角线始终是显式的。矩阵是CSR格式。</target>
        </trans-unit>
        <trans-unit id="c93217dd923de34853280b8058e56203ef9ee737" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.</source>
          <target state="translated">Xy=np.dot(X.T,y),可以预先计算。只有在预计算Gram矩阵时才有用。</target>
        </trans-unit>
        <trans-unit id="700502aa71883c1784c7b4df71f7526cabc3833b" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y).</source>
          <target state="translated">Xy=np.dot(X.T,y)。</target>
        </trans-unit>
        <trans-unit id="23eb4d3f4155395a74e9d534f97ff4c1908f5aac" translate="yes" xml:space="preserve">
          <source>Y</source>
          <target state="translated">Y</target>
        </trans-unit>
        <trans-unit id="aac13ced89d2b311880e53ba16f36f4513402a98" translate="yes" xml:space="preserve">
          <source>Y block loadings vectors.</source>
          <target state="translated">Y块载荷向量。</target>
        </trans-unit>
        <trans-unit id="148708c0aec99251158277d2fc4d038d62f32551" translate="yes" xml:space="preserve">
          <source>Y block to latents rotations.</source>
          <target state="translated">Y块到潜伏旋转。</target>
        </trans-unit>
        <trans-unit id="8f4ded8aca1a84f4452774f8bc622751045ade48" translate="yes" xml:space="preserve">
          <source>Y block weights vectors.</source>
          <target state="translated">Y块权重向量。</target>
        </trans-unit>
        <trans-unit id="780dd8f1641062cfc0af001d2fcfedba3262be26" translate="yes" xml:space="preserve">
          <source>Y scores.</source>
          <target state="translated">Y的成绩。</target>
        </trans-unit>
        <trans-unit id="93b5936ef31b077aecad8b961838c412166e9fd0" translate="yes" xml:space="preserve">
          <source>Y. Freund, R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting&amp;rdquo;, 1995.</source>
          <target state="translated">Y. Freund，R。Schapire，&amp;ldquo;在线学习的决策理论概括及其对Boosting的应用&amp;rdquo;，1995年。</target>
        </trans-unit>
        <trans-unit id="bf931371fe813e68af145bc28f1f0c59ead42876" translate="yes" xml:space="preserve">
          <source>Y. Freund, and R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting&amp;rdquo;, 1997.</source>
          <target state="translated">Y. Freund和R. Schapire，&amp;ldquo;在线学习的决策理论概括及其对Boosting的应用&amp;rdquo;，1997年。</target>
        </trans-unit>
        <trans-unit id="982b5c305af507a5853864a0280fe0330e5fb9d9" translate="yes" xml:space="preserve">
          <source>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</source>
          <target state="translated">Y[argmin[i],:]是Y中最接近X[i,:]的行。</target>
        </trans-unit>
        <trans-unit id="6cc2acee87fd2b4d368d7294a14e1666de3c66f0" translate="yes" xml:space="preserve">
          <source>Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="translated">Yang，Algesheimer和Tessone，（2016年）。&amp;ldquo;人工网络上社区检测算法的比较分析&amp;rdquo;。科学报告6：30750。doi &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;：10.1038 / srep30750&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3526f607bcd4f51ad0bc05f814579a42c2c0ba57" translate="yes" xml:space="preserve">
          <source>Yellow</source>
          <target state="translated">Yellow</target>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="translated">Yields</target>
        </trans-unit>
        <trans-unit id="44e848b37858df8125129ee3d3911783b05fb21f" translate="yes" xml:space="preserve">
          <source>Yields indices to split data into training and test sets.</source>
          <target state="translated">产生指数,将数据分割成训练和测试集。</target>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="translated">Yields:</target>
        </trans-unit>
        <trans-unit id="e285a8203a02b899c727c909bb971f8a5290d1a9" translate="yes" xml:space="preserve">
          <source>You can &lt;a href=&quot;grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; over parameters of all estimators in the pipeline at once.</source>
          <target state="translated">您可以一次对管道中所有估计量的参数进行&lt;a href=&quot;grid_search#grid-search&quot;&gt;网格搜索&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="afc09f41b74c7e769c70223fd4fc6ea043be4f9a" translate="yes" xml:space="preserve">
          <source>You can access the newly created figure and Axes objects using &lt;code&gt;plt.gcf()&lt;/code&gt; and &lt;code&gt;plt.gca()&lt;/code&gt;.</source>
          <target state="translated">您可以使用 &lt;code&gt;plt.gcf()&lt;/code&gt; 和 &lt;code&gt;plt.gca()&lt;/code&gt; 访问新创建的图形和轴对象。</target>
        </trans-unit>
        <trans-unit id="e4f0eb08d1e594cb4ba39dda583b2124c29e8d3e" translate="yes" xml:space="preserve">
          <source>You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them.</source>
          <target state="translated">你可以通过给数据集加载器赋予它们的名称来调整类别的数量,或者将它们设置为 &quot;无 &quot;来获得其中的20个类别。</target>
        </trans-unit>
        <trans-unit id="d6a91645b832623d5d5110588ef04aebdc451880" translate="yes" xml:space="preserve">
          <source>You can already copy the skeletons into a new folder somewhere on your hard-drive named &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; where you will edit your own files for the exercises while keeping the original skeletons intact:</source>
          <target state="translated">您已经可以将骨骼复制到硬盘上名为 &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; 的新文件夹中，您将在练习中编辑自己的文件，同时保持原始骨骼完整：</target>
        </trans-unit>
        <trans-unit id="1cf0d94595a131d36f8236532aeafb049eaa6dbc" translate="yes" xml:space="preserve">
          <source>You can also specify both the name and the version, which also uniquely identifies the dataset:</source>
          <target state="translated">你也可以同时指定名称和版本,这也是对数据集的唯一标识。</target>
        </trans-unit>
        <trans-unit id="ae5f0da778f6ff8c0d5d1c2ccd6f86bebea3d9e0" translate="yes" xml:space="preserve">
          <source>You can also use your own defined kernels by passing a function to the keyword &lt;code&gt;kernel&lt;/code&gt; in the constructor.</source>
          <target state="translated">您还可以通过将函数传递给构造函数中的关键字 &lt;code&gt;kernel&lt;/code&gt; 来使用自己定义的内核。</target>
        </trans-unit>
        <trans-unit id="c90fd70bc9584ad72350fadce865213cd8c472be" translate="yes" xml:space="preserve">
          <source>You can combine &lt;code&gt;KBinsDiscretizer&lt;/code&gt; with &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; if you only want to preprocess part of the features.</source>
          <target state="translated">如果只想预处理部分功能，则可以将 &lt;code&gt;KBinsDiscretizer&lt;/code&gt; 与&lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt;结合使用。</target>
        </trans-unit>
        <trans-unit id="b37a62ca838923df55452889a68156ed8900e3e5" translate="yes" xml:space="preserve">
          <source>You can control the exact number of threads that are used via the &lt;code&gt;OMP_NUM_THREADS&lt;/code&gt; environment variable:</source>
          <target state="translated">您可以通过 &lt;code&gt;OMP_NUM_THREADS&lt;/code&gt; 环境变量来控制所使用的确切线程数：</target>
        </trans-unit>
        <trans-unit id="579522a3d8d5bf3b4958e7c2d681266388521dce" translate="yes" xml:space="preserve">
          <source>You can define your own kernels by either giving the kernel as a python function or by precomputing the Gram matrix.</source>
          <target state="translated">你可以通过将内核以python函数的形式给出,或者通过预先计算Gram矩阵来定义自己的内核。</target>
        </trans-unit>
        <trans-unit id="5a14b3f83e3bd81fa3adef5b677dc7c591d450db" translate="yes" xml:space="preserve">
          <source>You can display the BLAS / LAPACK implementation used by your NumPy / SciPy / scikit-learn install with the following commands:</source>
          <target state="translated">您可以使用以下命令显示您的NumPy/SciPy/scikit-learn安装所使用的BLAS/LAPACK实现。</target>
        </trans-unit>
        <trans-unit id="929abd63168ac2d721d4708b8ef8be3cd51b08a0" translate="yes" xml:space="preserve">
          <source>You can ensure that &lt;code&gt;func&lt;/code&gt; and &lt;code&gt;inverse_func&lt;/code&gt; are the inverse of each other by setting &lt;code&gt;check_inverse=True&lt;/code&gt; and calling &lt;code&gt;fit&lt;/code&gt; before &lt;code&gt;transform&lt;/code&gt;. Please note that a warning is raised and can be turned into an error with a &lt;code&gt;filterwarnings&lt;/code&gt;:</source>
          <target state="translated">您可以通过设置 &lt;code&gt;check_inverse=True&lt;/code&gt; 并在 &lt;code&gt;transform&lt;/code&gt; 之前调用 &lt;code&gt;fit&lt;/code&gt; 来确保 &lt;code&gt;func&lt;/code&gt; 和 &lt;code&gt;inverse_func&lt;/code&gt; 彼此相反。请注意，将发出警告，并可以通过 &lt;code&gt;filterwarnings&lt;/code&gt; 变成错误：</target>
        </trans-unit>
        <trans-unit id="8fe8cd91261eb27750ae7b2f82fa15c24077f346" translate="yes" xml:space="preserve">
          <source>You can generate even more flexible model scorers by constructing your own scoring object from scratch, without using the &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt; factory. For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:</source>
          <target state="translated">您可以通过从头开始构建自己的评分对象而无需使用&lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt;工厂来生成更加灵活的模型评分器。要使可呼叫者成为记分员，它需要满足以下两个规则所指定的协议：</target>
        </trans-unit>
        <trans-unit id="cb07d258c61c328d902779de990b642f82ba2beb" translate="yes" xml:space="preserve">
          <source>You can get more information on the dataset by looking at the &lt;code&gt;DESCR&lt;/code&gt; and &lt;code&gt;details&lt;/code&gt; attributes:</source>
          <target state="translated">您可以通过查看 &lt;code&gt;DESCR&lt;/code&gt; 和 &lt;code&gt;details&lt;/code&gt; 属性来获取有关数据集的更多信息：</target>
        </trans-unit>
        <trans-unit id="316dc294ff0e2890db335b30189c691f1a723809" translate="yes" xml:space="preserve">
          <source>You can now see many things that these features have overfit to:</source>
          <target state="translated">你现在可以看到很多东西,这些功能已经过度到。</target>
        </trans-unit>
        <trans-unit id="e2cf6b0ce385c4e9fb3f4b5189c83feb905d92cf" translate="yes" xml:space="preserve">
          <source>You can pass pre-computed kernels by using the &lt;code&gt;kernel='precomputed'&lt;/code&gt; option. You should then pass Gram matrix instead of X to the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods. The kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided:</source>
          <target state="translated">您可以使用 &lt;code&gt;kernel='precomputed'&lt;/code&gt; 选项传递预计算的内核。然后，您应该将Gram矩阵而不是X传递给 &lt;code&gt;fit&lt;/code&gt; 和 &lt;code&gt;predict&lt;/code&gt; 方法。必须提供&lt;em&gt;所有&lt;/em&gt;训练向量和测试向量之间的内核值：</target>
        </trans-unit>
        <trans-unit id="ee86b8b814976ee239ecfc8e86907133be9d3afc" translate="yes" xml:space="preserve">
          <source>You can see that 16 non-zero feature tokens were extracted in the vector output: this is less than the 19 non-zeros extracted previously by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; on the same toy corpus. The discrepancy comes from hash function collisions because of the low value of the &lt;code&gt;n_features&lt;/code&gt; parameter.</source>
          <target state="translated">您可以看到在向量输出中提取了16个非零特征标记：这比&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;先前在同一玩具主体上提取的19个非零标记少。由于 &lt;code&gt;n_features&lt;/code&gt; 参数的值较低，因此差异来自哈希函数冲突。</target>
        </trans-unit>
        <trans-unit id="6b3885cd10ec182cb98af7964ed686cdd6c77762" translate="yes" xml:space="preserve">
          <source>You can specify a monotonic constraint on each feature using the &lt;code&gt;monotonic_cst&lt;/code&gt; parameter. For each feature, a value of 0 indicates no constraint, while -1 and 1 indicate a negative and positive constraint, respectively:</source>
          <target state="translated">您可以使用 &lt;code&gt;monotonic_cst&lt;/code&gt; 参数在每个要素上指定单调约束。对于每个要素，值0表示无约束，而值-1和1表示负约束和正约束：</target>
        </trans-unit>
        <trans-unit id="c31033fd31d22147ea7534b97a7d63f646fe3e48" translate="yes" xml:space="preserve">
          <source>You can then edit the content of the workspace without fear of losing the original exercise instructions.</source>
          <target state="translated">然后,你可以编辑工作区的内容,而不用担心丢失原来的练习指令。</target>
        </trans-unit>
        <trans-unit id="bc5b6b055370779ded34375c059372bbad8d8da3" translate="yes" xml:space="preserve">
          <source>You can use your own defined kernels by passing a function to the &lt;code&gt;kernel&lt;/code&gt; parameter.</source>
          <target state="translated">您可以通过将函数传递给 &lt;code&gt;kernel&lt;/code&gt; 参数来使用自己定义的内核。</target>
        </trans-unit>
        <trans-unit id="e21dcf7dc4d8353d8949b3e6ddc2c35c364a9b4a" translate="yes" xml:space="preserve">
          <source>You cannot nest objects with parallel computing (&lt;code&gt;n_jobs&lt;/code&gt; different than 1).</source>
          <target state="translated">您不能使用并行计算嵌套对象（ &lt;code&gt;n_jobs&lt;/code&gt; 不同于1）。</target>
        </trans-unit>
        <trans-unit id="d086a1b811e8ad563a3cd7d98758c535aff811c7" translate="yes" xml:space="preserve">
          <source>You could try UTF-8 and disregard the errors. You can decode byte strings with &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; to replace all decoding errors with a meaningless character, or set &lt;code&gt;decode_error='replace'&lt;/code&gt; in the vectorizer. This may damage the usefulness of your features.</source>
          <target state="translated">您可以尝试使用UTF-8，而忽略错误。您可以使用 &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; 解码字节字符串，以将所有解码错误替换为无意义的字符，或者在矢量化器中设置 &lt;code&gt;decode_error='replace'&lt;/code&gt; 。这可能会损害功能的实用性。</target>
        </trans-unit>
        <trans-unit id="c0d5a5afa92ed6aa301d13299623473f530c94ba" translate="yes" xml:space="preserve">
          <source>You may also load two (or more) datasets at once:</source>
          <target state="translated">你也可以同时加载两个(或多个)数据集。</target>
        </trans-unit>
        <trans-unit id="a822ec525f0ce269b9b885feec474e1f8b512e04" translate="yes" xml:space="preserve">
          <source>You may also retain the estimator fitted on each training set by setting &lt;code&gt;return_estimator=True&lt;/code&gt;.</source>
          <target state="translated">您还可以通过设置 &lt;code&gt;return_estimator=True&lt;/code&gt; 来保留适合每个训练集的估计器。</target>
        </trans-unit>
        <trans-unit id="c9bcd37e9efb4d07a927274f7ad017afc3f094c8" translate="yes" xml:space="preserve">
          <source>You may be able to find out what kind of encoding it is in general using the UNIX command &lt;code&gt;file&lt;/code&gt;. The Python &lt;code&gt;chardet&lt;/code&gt; module comes with a script called &lt;code&gt;chardetect.py&lt;/code&gt; that will guess the specific encoding, though you cannot rely on its guess being correct.</source>
          <target state="translated">使用UNIX命令 &lt;code&gt;file&lt;/code&gt; 您也许可以找到一般的编码方式。Python &lt;code&gt;chardet&lt;/code&gt; 模块带有一个名为 &lt;code&gt;chardetect.py&lt;/code&gt; 的脚本，该脚本将猜测特定的编码，尽管您不能依靠其猜测是正确的。</target>
        </trans-unit>
        <trans-unit id="04405b99190799597dab92e2ef615219d1447404" translate="yes" xml:space="preserve">
          <source>You may load a dataset like as follows:</source>
          <target state="translated">你可以加载一个数据集,如下所示。</target>
        </trans-unit>
        <trans-unit id="f9f71500b978e09c529098f893f05269c79caaff" translate="yes" xml:space="preserve">
          <source>You may want to include the parameters of the preprocessors in a &lt;a href=&quot;grid_search#grid-search&quot;&gt;parameter search&lt;/a&gt;.</source>
          <target state="translated">您可能需要在&lt;a href=&quot;grid_search#grid-search&quot;&gt;参数搜索中&lt;/a&gt;包括预处理器的参数。</target>
        </trans-unit>
        <trans-unit id="4cbe0908270a3a4effe7f03ed10c6fc1b573bdb1" translate="yes" xml:space="preserve">
          <source>You might get slightly different results with the solver liblinear than with the others since this uses LIBLINEAR which penalizes the intercept.</source>
          <target state="translated">你用liblinear解算器得到的结果可能会与其他解算器略有不同,因为它使用的是LIBLINEAR,会对截距进行惩罚。</target>
        </trans-unit>
        <trans-unit id="eacc5e93bbce61c3d762f60af9c0b85d6ab90006" translate="yes" xml:space="preserve">
          <source>You might have noticed that the samples were shuffled randomly when we called &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt;: this is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later.</source>
          <target state="translated">您可能已经注意到，当我们调用 &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt; 时，样本是随机洗牌的：如果您希望仅选择样本子集以快速训练模型并获得第一个样本，则这很有用在重新训练完整的数据集之前，先对结果有想法。</target>
        </trans-unit>
        <trans-unit id="c8c03561e45bae9c49c8b8f096417e119a986f38" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="translated">你只需要调用&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;合适的&lt;/a&gt;和&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;预测&lt;/a&gt;的数据一次，以适应估计的整个序列。</target>
        </trans-unit>
        <trans-unit id="1c0c1bb33d891f47deca1c516d19aa08bd8443b9" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="translated">你只需要调用 &lt;code&gt;fit&lt;/code&gt; 和 &lt;code&gt;predict&lt;/code&gt; 的数据一次，以适应估计的整个序列。</target>
        </trans-unit>
        <trans-unit id="8f00f0e599f4c3a7b71dcab47e41c43fc685f526" translate="yes" xml:space="preserve">
          <source>You should also make sure that the stop word list has had the same preprocessing and tokenization applied as the one used in the vectorizer. The word &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is split into &lt;em&gt;we&lt;/em&gt; and &lt;em&gt;ve&lt;/em&gt; by CountVectorizer&amp;rsquo;s default tokenizer, so if &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is in &lt;code&gt;stop_words&lt;/code&gt;, but &lt;em&gt;ve&lt;/em&gt; is not, &lt;em&gt;ve&lt;/em&gt; will be retained from &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; in transformed text. Our vectorizers will try to identify and warn about some kinds of inconsistencies.</source>
          <target state="translated">您还应该确保停用词列表的预处理和标记化与矢量化程序中使用的预处理和标记化相同。这个词&lt;em&gt;我们已经&lt;/em&gt;被分成&lt;em&gt;我们&lt;/em&gt;和&lt;em&gt;已经&lt;/em&gt;通过CountVectorizer的默认标记生成器，所以如果&lt;em&gt;我们已经&lt;/em&gt;在 &lt;code&gt;stop_words&lt;/code&gt; ，但&lt;em&gt;已经&lt;/em&gt;不大，&lt;em&gt;已经&lt;/em&gt;从将被保留&lt;em&gt;，我们已经&lt;/em&gt;在转化文本。我们的矢量化程序将尝试识别并警告某些不一致之处。</target>
        </trans-unit>
        <trans-unit id="c05eee82bc79ecab0104c0f165ab54dde97d70eb" translate="yes" xml:space="preserve">
          <source>You will find additional details about joblib mitigation of oversubscription in &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-ressources&quot;&gt;joblib documentation&lt;/a&gt;.</source>
          <target state="translated">您可以在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-ressources&quot;&gt;joblib文档中&lt;/a&gt;找到有关缓解joblib过度订阅的更多详细信息。</target>
        </trans-unit>
        <trans-unit id="03e4dbf3891b38cb2bcd04772f91e994b5e9c01b" translate="yes" xml:space="preserve">
          <source>Your dataset consists of heterogeneous data types (e.g. raster images and text captions)</source>
          <target state="translated">您的数据集由不同的数据类型组成(如栅格图像和文本标题)。</target>
        </trans-unit>
        <trans-unit id="7b0a68e70dc900bed821b4c342a07edfa667e451" translate="yes" xml:space="preserve">
          <source>Your dataset is stored in a Pandas DataFrame and different columns require different processing pipelines.</source>
          <target state="translated">你的数据集存储在Pandas DataFrame中,不同的列需要不同的处理管道。</target>
        </trans-unit>
        <trans-unit id="cf246e4fd612425ede440737acf49a3220f42916" translate="yes" xml:space="preserve">
          <source>Your kernel must take as arguments two matrices of shape &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt;, &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; and return a kernel matrix of shape &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt;.</source>
          <target state="translated">你的内核必须采取作为参数形状的两个矩阵 &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt; ， &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; 并返回形状的核心矩阵 &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a97cec9f16597107c699027a6e02cf1c0426b74a" translate="yes" xml:space="preserve">
          <source>ZN proportion of residential land zoned for lots over 25,000 sq.ft.</source>
          <target state="translated">ZN劃作25,000平方呎以上地段的住宅用地比例。</target>
        </trans-unit>
        <trans-unit id="712d097b167e76a6e9d59b3e5e274cb4dc4edfe4" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;lsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">Zadrozny和Elkan，&amp;ldquo;将分类器分数转换为多类概率估计&amp;rdquo;，SIGKDD'02，&lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http：//www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2a3a7f6ae69d75cdee1953a2daa7e044766fcafc" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;rsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">Zadrozny和Elkan，&amp;ldquo;将分类器分数转换为多类概率估计&amp;rdquo;，SIGKDD'02，&lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http：//www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="100bba0bbb404bee5dfe86694ccdaa4c87071002" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;rsquo;02, &lt;a href=&quot;https://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">Zadrozny和Elkan，&amp;ldquo;将分类器分数转换为多类概率估计&amp;rdquo;，SIGKDD'02，&lt;a href=&quot;https://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http：//www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f05a65af97509516c00dcac126500e3f1415b5be" translate="yes" xml:space="preserve">
          <source>Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">多项式和sigmoid核的系数为零。被其他核忽略。</target>
        </trans-unit>
        <trans-unit id="e35caa5ca631cf4323249c1e10ca37b600a29376" translate="yes" xml:space="preserve">
          <source>Zero is the lowest possible score. Values closer to zero indicate a better partition.</source>
          <target state="translated">零是可能的最低分数。接近零的数值表示更好的分区。</target>
        </trans-unit>
        <trans-unit id="4196df3003bc4705f3359c145eca39ac9042a13b" translate="yes" xml:space="preserve">
          <source>Zero-one classification loss.</source>
          <target state="translated">零一分类损失。</target>
        </trans-unit>
        <trans-unit id="ee137211a128584365e4b492f8f1e31e317a831d" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="translated">Zhang，J.和Marszalek，M.和Lazebnik，S.和Schmid，C.用于纹理和对象类别分类的局部特征和内核：全面研究International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/ zh-cn / um / people / manik / projects / trade-off / papers / ZhangIJCV06.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="78f8c38e7e05f7b4f27cc97ecbaeea34135ce110" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="translated">Zhang，J.和Marszalek，M.和Lazebnik，S.和Schmid，C.用于纹理和对象类别分类的局部特征和内核：全面研究International Journal of Computer Vision 2007 &lt;a href=&quot;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;https://research.microsoft.com/ zh-cn / um / people / manik / projects / trade-off / papers / ZhangIJCV06.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0c6fefb0786b59f4ca28434a9adf73a14f912b16" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Wang, J. MLLE: Modified Locally Linear Embedding Using Multiple Weights. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&lt;/a&gt;</source>
          <target state="translated">Zhang，Z.＆Wang，J. MLLE：使用多个权重的局部线性嵌入修改。&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e40887e48b748aeda9c07d81d6206e919ed1f726" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Zha, H. Principal manifolds and nonlinear dimensionality reduction via tangent space alignment. Journal of Shanghai Univ. 8:406 (2004)</source>
          <target state="translated">Zhang，Z.＆Zha，H.主流形和通过切线空间对齐减少非线性维数。上海大学学报 8：406（2004）</target>
        </trans-unit>
        <trans-unit id="2f2ef1b5180fd57b17245a5c505519733d35270d" translate="yes" xml:space="preserve">
          <source>Zhu, H. Zou, S. Rosset, T. Hastie, &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">Zhu H. Zou，S。Rosset，T。Hastie，&amp;ldquo;多类AdaBoost&amp;rdquo;，2009年。</target>
        </trans-unit>
        <trans-unit id="8ce45cc584babf565a133f667c041638840fdfd3" translate="yes" xml:space="preserve">
          <source>Zoubir A., Koivunen V., Chakhchoukh Y. and Muma M. (2012). Robust estimation in signal processing: A tutorial-style treatment of fundamental concepts. IEEE Signal Processing Magazine 29(4), 61-80.</source>
          <target state="translated">Zoubir A.、Koivunen V.、Chakhchoukh Y.和Muma M.(2012)。信号处理中的稳健估计。基本概念的教程式处理。IEEE信号处理杂志29(4),61-80。</target>
        </trans-unit>
        <trans-unit id="e2b89a96fcf50192e8235c2260c291f63c7f4fa9" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;additive_chi2&amp;rsquo;, &amp;lsquo;chi2&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;laplacian&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="translated">['additive_chi2'，'chi2'，'linear'，'poly'，'polynomial'，'rbf'，'laplacian'，'Sigmoid'，'cosine']</target>
        </trans-unit>
        <trans-unit id="cd3417b4282b09dc45879fe7c77bee8859983780" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="translated">['rbf'，'sigmoid'，'多项式'，'poly'，'linear'，'cosine']</target>
        </trans-unit>
        <trans-unit id="7c0453b88eaf6a5b1a0ac2faa1dec6c20e0dda6a" translate="yes" xml:space="preserve">
          <source>[1, x_2, x_2 ** 2, x_2 ** 3, &amp;hellip;], &amp;hellip;]</source>
          <target state="translated">[1，x_2，x_2 ** 2，x_2 ** 3，&amp;hellip;]，&amp;hellip;]</target>
        </trans-unit>
        <trans-unit id="af237073ca841ce40d3b1c3f9ec3b84ba9e8c1ce" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Online Learning for Latent Dirichlet Allocation&amp;rdquo;, Matthew D. Hoffman,</source>
          <target state="translated">[1]&amp;ldquo;在线学习以进行潜在狄利克雷分配&amp;rdquo;，Matthew D. Hoffman，</target>
        </trans-unit>
        <trans-unit id="a5828c16246e11e0eda2596d27fdd402ee57d009" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">[1]&amp;ldquo; MMSE协方差估计的收缩算法&amp;rdquo; Chen等人，IEEE Trans。在标志上。Proc。，第58卷，第10期，2010年10月。</target>
        </trans-unit>
        <trans-unit id="c5ae55965c66d78c700f954c5d28c9832964e702" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="translated">[1] A. Rahimi和Benjamin Recht的&amp;ldquo;加权随机厨房水槽之和：用学习中的随机性代替最小化&amp;rdquo;。（&lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="4bdc516c4c0b901726d527e6df8200cdc4a8acc8" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="translated">[1] A. Rahimi和Benjamin Recht的&amp;ldquo;加权随机厨房水槽之和：用学习中的随机性代替最小化&amp;rdquo;。（&lt;a href=&quot;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="066cf0134c1716b5ce53bcaba6c6b8d7e86263f5" translate="yes" xml:space="preserve">
          <source>[1] Hastie, T., Tibshirani, R.,, Friedman, J. (2001). Model Assessment and Selection. The Elements of Statistical Learning (pp. 219-260). New York, NY, USA: Springer New York Inc..</source>
          <target state="translated">[1] Hastie，T.，Tibshirani，R。,, Friedman，J.（2001）。模型评估和选择。统计学习的要素（第219-260页）。美国纽约州：Springer New York Inc.。</target>
        </trans-unit>
        <trans-unit id="851ede0920efe80a8308115ddfdc22058d99b224" translate="yes" xml:space="preserve">
          <source>[1] Hinton, G. E., Osindero, S. and Teh, Y. A fast learning algorithm for</source>
          <target state="translated">[1] Hinton，GE，Osindero，S。和Teh，Y。一种快速学习算法，用于</target>
        </trans-unit>
        <trans-unit id="3208128766e3298f0714b3eacb4e2ecfc88475e9" translate="yes" xml:space="preserve">
          <source>[1] L. Breiman, &amp;ldquo;Random Forests&amp;rdquo;, Machine Learning, 45(1), 5-32,</source>
          <target state="translated">[1] L. Breiman，&amp;ldquo;随机森林&amp;rdquo;，机器学习，45（1），5-32，</target>
        </trans-unit>
        <trans-unit id="c4ab6918e1971671fbb440a7f8e61bfcc4315791" translate="yes" xml:space="preserve">
          <source>[1] P. J. Rousseeuw. Least median of squares regression. J. Am</source>
          <target state="translated">[1] PJ Rousseeuw。平方回归的最小中位数。J.安</target>
        </trans-unit>
        <trans-unit id="4becf43125cdaf0ec29f63ac1f954b679ab8e6bc" translate="yes" xml:space="preserve">
          <source>[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216</source>
          <target state="translated">[1] Yoshua Bengio，Olivier Delalleau，Nicolas Le Roux。在《半监督学习》（2006年），第193-216页</target>
        </trans-unit>
        <trans-unit id="9a201577697a06c9ac689a946ae70d44d48c0e7c" translate="yes" xml:space="preserve">
          <source>[1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data</source>
          <target state="translated">[1] van der Maaten，LJP；GE的Hinton，可视化高维数据</target>
        </trans-unit>
        <trans-unit id="8eeff125eef3cfca1ff3f8b3157054b95e0b3509" translate="yes" xml:space="preserve">
          <source>[2] &amp;ldquo;Stochastic Variational Inference&amp;rdquo;, Matthew D. Hoffman, David M. Blei,</source>
          <target state="translated">[2]&amp;ldquo;随机变分推论&amp;rdquo;，马修&amp;middot;霍夫曼，大卫&amp;middot;布雷</target>
        </trans-unit>
        <trans-unit id="ea3c887d7b7624a41f686043b166f388d3617ff3" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="translated">[2] Olivier Delalleau，Yoshua Bengio，Nicolas Le Roux。半监督学习中的有效非参数函数归纳。AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/ficient_ssl.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="73434047889c8334ffffe648547654fa2862e107" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="translated">[2] Olivier Delalleau，Yoshua Bengio，Nicolas Le Roux。半监督学习中的有效非参数函数归纳。AISTAT 2005 &lt;a href=&quot;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;https://research.microsoft.com/en-us/people/nicolasl/efficiency_ssl.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="390f7912993134abee39b500fe8ff987c558bcc7" translate="yes" xml:space="preserve">
          <source>[2] Tieleman, T. Training Restricted Boltzmann Machines using</source>
          <target state="translated">[2] Tieleman，T.使用限制训练Boltzmann机器</target>
        </trans-unit>
        <trans-unit id="936e8131576c3002ff436671f77d81f6c95e71d7" translate="yes" xml:space="preserve">
          <source>[2] Wilson, E. B., &amp;amp; Hilferty, M. M. (1931). The distribution of chi-square.</source>
          <target state="translated">[2]威尔逊（EB）和希尔法蒂（MM）（1931）。卡方的分布。</target>
        </trans-unit>
        <trans-unit id="5cccbf6c7fe7c1f50410b68e37c12f00b67f9330" translate="yes" xml:space="preserve">
          <source>[2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding</source>
          <target state="translated">[2] van der Maaten，LJP t分布随机邻居嵌入</target>
        </trans-unit>
        <trans-unit id="740947d1c8302c56dc8a9209234aab173f75acad" translate="yes" xml:space="preserve">
          <source>[3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.</source>
          <target state="translated">[3] LJP van der Maaten。使用基于树的算法加速t-SNE。</target>
        </trans-unit>
        <trans-unit id="a16dde9090b3c419b1ba6d8027b90785ddf73263" translate="yes" xml:space="preserve">
          <source>[3] Matthew D. Hoffman&amp;rsquo;s onlineldavb code. Link:</source>
          <target state="translated">[3] Matthew D. Hoffman的onlineldavb代码。链接：</target>
        </trans-unit>
        <trans-unit id="2091fb37b7afd77ae2e8e60855d4cad2538ba378" translate="yes" xml:space="preserve">
          <source>[B1996]</source>
          <target state="translated">[B1996]</target>
        </trans-unit>
        <trans-unit id="66fa89cedf249bba6f8bbd7ca59a6edba1eb2520" translate="yes" xml:space="preserve">
          <source>[B1998]</source>
          <target state="translated">[B1998]</target>
        </trans-unit>
        <trans-unit id="7665023d9511c3ea5a7a3e7baca06057eba900d6" translate="yes" xml:space="preserve">
          <source>[B1999]</source>
          <target state="translated">[B1999]</target>
        </trans-unit>
        <trans-unit id="5c075f95c1e65a7e49dec5ad30ee36d1fb13b2b6" translate="yes" xml:space="preserve">
          <source>[B2001]</source>
          <target state="translated">[B2001]</target>
        </trans-unit>
        <trans-unit id="04bec92cc809290da2bf608da574e1877293633f" translate="yes" xml:space="preserve">
          <source>[B2011]</source>
          <target state="translated">[B2011]</target>
        </trans-unit>
        <trans-unit id="2b6c9f7f2623b948c281da789073abc37bb7f8fa" translate="yes" xml:space="preserve">
          <source>[ButlerDavies]</source>
          <target state="translated">[ButlerDavies]</target>
        </trans-unit>
        <trans-unit id="1d442f2d1661e89f1bc869a582a8d649d24881e4" translate="yes" xml:space="preserve">
          <source>[D1997]</source>
          <target state="translated">[D1997]</target>
        </trans-unit>
        <trans-unit id="20e70caf2f764d35f0c5f51eb6c2cc52a6f947f2" translate="yes" xml:space="preserve">
          <source>[Davis2006]</source>
          <target state="translated">[Davis2006]</target>
        </trans-unit>
        <trans-unit id="3b0f17e8250c1e7b54512123b77c31bb0899ae7a" translate="yes" xml:space="preserve">
          <source>[Everingham2010]</source>
          <target state="translated">[Everingham2010]</target>
        </trans-unit>
        <trans-unit id="e5ff04dac92d8d5710e2d4ade54a4899d9a01662" translate="yes" xml:space="preserve">
          <source>[F1999]</source>
          <target state="translated">[F1999]</target>
        </trans-unit>
        <trans-unit id="ddfaba8b68f822d387eefcc49dbcf89bee83fcbe" translate="yes" xml:space="preserve">
          <source>[F2001]</source>
          <target state="translated">[F2001]</target>
        </trans-unit>
        <trans-unit id="5712ff07224dea2f09976ad1b5f9060cea098ee8" translate="yes" xml:space="preserve">
          <source>[FS1995]</source>
          <target state="translated">[FS1995]</target>
        </trans-unit>
        <trans-unit id="111b120f6e2f3a7d9723c16133fcfb1ce7b7557b" translate="yes" xml:space="preserve">
          <source>[Flach2015]</source>
          <target state="translated">[Flach2015]</target>
        </trans-unit>
        <trans-unit id="0be1b91bf292e6f295e73f8ba1626aa315ca1709" translate="yes" xml:space="preserve">
          <source>[Guyon2015]</source>
          <target state="translated">[Guyon2015]</target>
        </trans-unit>
        <trans-unit id="16deff704a4f867ca18d98b22e63afcb70ec96d2" translate="yes" xml:space="preserve">
          <source>[H1998]</source>
          <target state="translated">[H1998]</target>
        </trans-unit>
        <trans-unit id="346ddc10d1a23f1ff0ba05ea1da881f4666595c5" translate="yes" xml:space="preserve">
          <source>[HTF2009]</source>
          <target state="translated">[HTF2009]</target>
        </trans-unit>
        <trans-unit id="2b6bce181ae06e6796d39628b4dc12ca65767e20" translate="yes" xml:space="preserve">
          <source>[HTF]</source>
          <target state="translated">[HTF]</target>
        </trans-unit>
        <trans-unit id="8f4756ba18c793a637ad7568fd4450479f47b718" translate="yes" xml:space="preserve">
          <source>[Hubert1985]</source>
          <target state="translated">[Hubert1985]</target>
        </trans-unit>
        <trans-unit id="1c2acae56920363d695dc395b30aa0dac0656aa7" translate="yes" xml:space="preserve">
          <source>[Jen09]</source>
          <target state="translated">[Jen09]</target>
        </trans-unit>
        <trans-unit id="52833f723be6af6645b6622da4d471b65e89d942" translate="yes" xml:space="preserve">
          <source>[Kelleher2015]</source>
          <target state="translated">[Kelleher2015]</target>
        </trans-unit>
        <trans-unit id="8d63f432cd9715591fb04662784fbed01426124f" translate="yes" xml:space="preserve">
          <source>[L2014]</source>
          <target state="translated">[L2014]</target>
        </trans-unit>
        <trans-unit id="e6f810474b9d9bf1966e66d024bfd2d0d9af7983" translate="yes" xml:space="preserve">
          <source>[LG2012]</source>
          <target state="translated">[LG2012]</target>
        </trans-unit>
        <trans-unit id="4108a351bec333bc41371d8be81bbf1f0bd216a0" translate="yes" xml:space="preserve">
          <source>[LS2010]</source>
          <target state="translated">[LS2010]</target>
        </trans-unit>
        <trans-unit id="36c1f9470816b8da81a8ed80471ace8df2456c31" translate="yes" xml:space="preserve">
          <source>[M2012]</source>
          <target state="translated">[M2012]</target>
        </trans-unit>
        <trans-unit id="536dc6f43e65eedbc7dcd92d64ef850b0a7951d3" translate="yes" xml:space="preserve">
          <source>[MRS2008]</source>
          <target state="translated">[MRS2008]</target>
        </trans-unit>
        <trans-unit id="350f14f810397ce0cd7520f35f0fae7d54d72023" translate="yes" xml:space="preserve">
          <source>[Manning2008]</source>
          <target state="translated">[Manning2008]</target>
        </trans-unit>
        <trans-unit id="0cc214a1564fbbf90b4daa0b0972b6f8408e3afc" translate="yes" xml:space="preserve">
          <source>[Mosley2013]</source>
          <target state="translated">[Mosley2013]</target>
        </trans-unit>
        <trans-unit id="73be0b37b87d3c88f49438b3a7ca251dc3d3c1d2" translate="yes" xml:space="preserve">
          <source>[Mrl09]</source>
          <target state="translated">[Mrl09]</target>
        </trans-unit>
        <trans-unit id="690e639d5d468ec30ab9e54cb03287a1d07d286f" translate="yes" xml:space="preserve">
          <source>[NQY18]</source>
          <target state="translated">[NQY18]</target>
        </trans-unit>
        <trans-unit id="95849b59dfe0de62fa4f930bc19ca3b64ad51c5b" translate="yes" xml:space="preserve">
          <source>[R2007]</source>
          <target state="translated">[R2007]</target>
        </trans-unit>
        <trans-unit id="d27f89b25dd2806ef3b69d37ac341ea761b1f775" translate="yes" xml:space="preserve">
          <source>[RR2007]</source>
          <target state="translated">[RR2007]</target>
        </trans-unit>
        <trans-unit id="99aae3a9e5135b3c3c9e6f81c5583f53ea54b161" translate="yes" xml:space="preserve">
          <source>[RVD]</source>
          <target state="translated">[RVD]</target>
        </trans-unit>
        <trans-unit id="7fc4fd0834c6c78f63966f47416f1e672a05b032" translate="yes" xml:space="preserve">
          <source>[RVDriessen]</source>
          <target state="translated">[RVDriessen]</target>
        </trans-unit>
        <trans-unit id="9a3d290ec7e0cf466e2e530b732c430fd93742e5" translate="yes" xml:space="preserve">
          <source>[RW2006]</source>
          <target state="translated">[RW2006]</target>
        </trans-unit>
        <trans-unit id="ab40883d6ce3b576febad86ad20a220ae60fc722" translate="yes" xml:space="preserve">
          <source>[Rouseeuw1984]</source>
          <target state="translated">[Rouseeuw1984]</target>
        </trans-unit>
        <trans-unit id="f4ff5aad65e1461e94ef70a659337011d0c58126" translate="yes" xml:space="preserve">
          <source>[Rousseeuw]</source>
          <target state="translated">[Rousseeuw]</target>
        </trans-unit>
        <trans-unit id="74f2d2c5b044f5dc96afc1e0482d2495c57d5370" translate="yes" xml:space="preserve">
          <source>[Urbanowicz2015]</source>
          <target state="translated">[Urbanowicz2015]</target>
        </trans-unit>
        <trans-unit id="34cb3f1593778c84c25ed6665ee9a323140a68d9" translate="yes" xml:space="preserve">
          <source>[VEB2009] Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="translated">[VEB2009] Vinh，Epps和Bailey，（2009年）。&amp;ldquo;用于聚类比较的信息理论方法&amp;rdquo;。第26届年度机器学习国际会议论文集-ICML '09。&lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi：10.1145 / 1553374.1553511&lt;/a&gt;。ISBN 9781605585161。</target>
        </trans-unit>
        <trans-unit id="48a5d15f42b24744d500812bf01a83ad55ecae83" translate="yes" xml:space="preserve">
          <source>[VEB2010] Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="translated">[VEB2010] Vinh，Epps和Bailey，（2010年）。&amp;ldquo;用于聚类比较的信息理论方法：变异，属性，归一化和机会校正&amp;rdquo;。JMLR &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt; &amp;gt;</target>
        </trans-unit>
        <trans-unit id="0cb878c6eb08bc32d947d6ddc4baaa42377cefd9" translate="yes" xml:space="preserve">
          <source>[VVZ2010]</source>
          <target state="translated">[VVZ2010]</target>
        </trans-unit>
        <trans-unit id="3db6db2379703ce194c034f1bb123b847f702832" translate="yes" xml:space="preserve">
          <source>[VZ2010]</source>
          <target state="translated">[VZ2010]</target>
        </trans-unit>
        <trans-unit id="4f385f25921c7c64a43d9b5e0a8904686fbad4ed" translate="yes" xml:space="preserve">
          <source>[X1, y1, &amp;hellip;, Xn, yn]</source>
          <target state="translated">[X1, y1, &amp;hellip;, Xn, yn]</target>
        </trans-unit>
        <trans-unit id="70b15e6dab0cb6917fd158eac29a9ddf08fcef21" translate="yes" xml:space="preserve">
          <source>[YAT2016] Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="translated">[YAT2016] Yang，Algesheimer和Tessone，（2016年）。&amp;ldquo;人工网络上社区检测算法的比较分析&amp;rdquo;。科学报告6：30750。doi &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;：10.1038 / srep30750&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="652e235b7dc2f3d75c7f909152b3819c6c97a6ec" translate="yes" xml:space="preserve">
          <source>[Yates2011]</source>
          <target state="translated">[Yates2011]</target>
        </trans-unit>
        <trans-unit id="e3b9ec6790a1b2a9d7bcca67037f67b282ccc4ee" translate="yes" xml:space="preserve">
          <source>[ZZRH2009]</source>
          <target state="translated">[ZZRH2009]</target>
        </trans-unit>
        <trans-unit id="96b76160e0ad993ba5f0d18a67c96f386933b35a" translate="yes" xml:space="preserve">
          <source>[[1, x_1, x_1 ** 2, x_1 ** 3, &amp;hellip;],</source>
          <target state="translated">[[1，x_1，x_1 ** 2，x_1 ** 3，&amp;hellip;]，</target>
        </trans-unit>
        <trans-unit id="2eab98aedd6e4787cc1b6ed7c5288a5a2279237c" translate="yes" xml:space="preserve">
          <source>[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.</source>
          <target state="translated">[callable]：用户定义的函数，它接受距离数组，并返回包含权重的相同形状的数组。</target>
        </trans-unit>
        <trans-unit id="b622702bcf4592f09f68d731f0a4b9f486da53eb" translate="yes" xml:space="preserve">
          <source>[n_samples_a, n_features] otherwise Array of pairwise distances between samples, or a feature array.</source>
          <target state="translated">[n_samples_a，n_features]否则为样本之间的成对距离数组或要素数组。</target>
        </trans-unit>
        <trans-unit id="361169bda90a02e4e54f39ff838115b39a75d83d" translate="yes" xml:space="preserve">
          <source>[wk]</source>
          <target state="translated">[wk]</target>
        </trans-unit>
        <trans-unit id="a4fcb5a87f4e322ea14fa74b5213a00a6d8c1551" translate="yes" xml:space="preserve">
          <source>\((y-\hat{y})^2\)</source>
          <target state="translated">\((y-\hat{y})^2\)</target>
        </trans-unit>
        <trans-unit id="b66b6613ed1a2db616d592d66bc160b7abcc7139" translate="yes" xml:space="preserve">
          <source>\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</source>
          <target state="translated">\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</target>
        </trans-unit>
        <trans-unit id="764bb49b144ee69e8d51ad0d7a5cedd15acf75d9" translate="yes" xml:space="preserve">
          <source>\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</source>
          <target state="translated">\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</target>
        </trans-unit>
        <trans-unit id="cade30b6baa03b8bc431f6cb3586bc5b1d642a6f" translate="yes" xml:space="preserve">
          <source>\(C\) is used to set the amount of regularization</source>
          <target state="translated">\（C \）用于设置正则化量</target>
        </trans-unit>
        <trans-unit id="ad93e4d23ea1b4d81a2b3f3c3d29dff7d49b5d27" translate="yes" xml:space="preserve">
          <source>\(D\) : input dimension</source>
          <target state="translated">\（D \）：输入尺寸</target>
        </trans-unit>
        <trans-unit id="a32e93d880aaba8a860e59edd1cb39f288e59537" translate="yes" xml:space="preserve">
          <source>\(F1 = 2\frac{P \times R}{P+R}\)</source>
          <target state="translated">\（F1 = 2 \ frac {P \ times R} {P + R} \）</target>
        </trans-unit>
        <trans-unit id="6e8b3587e80a2131c2360cdeb81572614017e523" translate="yes" xml:space="preserve">
          <source>\(F_\beta(A, B) := \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}\)</source>
          <target state="translated">\（F_ \ beta（A，B）：= \ left（1 + \ beta ^ 2 \ right）\ frac {P（A，B）\ times R（A，B）} {\ beta ^ 2 P（A ，B）+ R（A，B）} \）</target>
        </trans-unit>
        <trans-unit id="9a350d9475f7eafeffa8a9835bca28d431bee93e" translate="yes" xml:space="preserve">
          <source>\(F_\beta(y, \hat{y})\)</source>
          <target state="translated">\（F_ \ beta（y，\ hat {y}）\）</target>
        </trans-unit>
        <trans-unit id="09eb5f139bd0c207766706ffe3b5d171a556d4ec" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - \frac{x^2}{h^2}\)</source>
          <target state="translated">\（K（x; h）\ propto 1-\ frac {x ^ 2} {h ^ 2} \）</target>
        </trans-unit>
        <trans-unit id="95dfc8e81899d8cb940cb0df0bfaa1052ffb36d2" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - x/h\) if \(x &amp;lt; h\)</source>
          <target state="translated">\（K（x; h）\ propto 1-x / h \）如果\（x &amp;lt;h \）</target>
        </trans-unit>
        <trans-unit id="2a910118bdbf495d82747952ba6971367b93dfac" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1\) if \(x &amp;lt; h\)</source>
          <target state="translated">\（K（x; h）\ propto 1 \）如果\（x &amp;lt;h \）</target>
        </trans-unit>
        <trans-unit id="4b298d5bd2fdf7182db10bf076925db3745527a8" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \cos(\frac{\pi x}{2h})\) if \(x &amp;lt; h\)</source>
          <target state="translated">\（K（x; h）\ propto \ cos（\ frac {\ pi x} {2h}）\）如果\（x &amp;lt;h \）</target>
        </trans-unit>
        <trans-unit id="a4443829e2c48ab72daedb9b74f9dc8debc9681a" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(- \frac{x^2}{2h^2} )\)</source>
          <target state="translated">\（K（x; h）\ propto \ exp（-\ frac {x ^ 2} {2h ^ 2}）\）</target>
        </trans-unit>
        <trans-unit id="c70853c06adf6986de8dcbc5a8f801fc0502ae1b" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(-x/h)\)</source>
          <target state="translated">\（K（x; h）\ propto \ exp（-x / h）\）</target>
        </trans-unit>
        <trans-unit id="7d9776eac061dd7f197e8155c6784a047082de92" translate="yes" xml:space="preserve">
          <source>\(L\) the set of labels</source>
          <target state="translated">\（L \）标签集</target>
        </trans-unit>
        <trans-unit id="f0f78908f9cef66c5c39e39b004aba794a24d223" translate="yes" xml:space="preserve">
          <source>\(N\) : number of training data points</source>
          <target state="translated">\（N \）：训练数据点数</target>
        </trans-unit>
        <trans-unit id="85d811223bbd2564d928a5184adabae9693a9903" translate="yes" xml:space="preserve">
          <source>\(P = \frac{T_p}{T_p+F_p}\)</source>
          <target state="translated">\（P = \ frac {T_p} {T_p + F_p} \）</target>
        </trans-unit>
        <trans-unit id="5c7b5d8ee367861eab9617a9df8debede099fe4a" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\)</source>
          <target state="translated">\（P（A，B）：= \ frac {\ left | A \ cap B \ right |} {\ left | A \ right |} \）</target>
        </trans-unit>
        <trans-unit id="b2e10949fc710189ed8a464185eb0fbad995ab8d" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\) for some sets \(A\) and \(B\)</source>
          <target state="translated">\（P（A，B）：= \ frac {\ left | A \ cap B \ right |} {\ left | A \ right |} \）对于某些集合\（A \）和\（B \）</target>
        </trans-unit>
        <trans-unit id="c180cdb6205e02ec243b8a0c392cb71991d0a3d0" translate="yes" xml:space="preserve">
          <source>\(P(y, \hat{y})\)</source>
          <target state="translated">\（P（y，\ hat {y}）\）</target>
        </trans-unit>
        <trans-unit id="c753c8fc287915fbc16c3d512099716031e38eb4" translate="yes" xml:space="preserve">
          <source>\(R = \frac{T_p}{T_p + F_n}\)</source>
          <target state="translated">\（R = \ frac {T_p} {T_p + F_n} \）</target>
        </trans-unit>
        <trans-unit id="2d1e6161821a7c78dd1e8cc86ac7329f67bfcf0c" translate="yes" xml:space="preserve">
          <source>\(R(A, B) := \frac{\left| A \cap B \right|}{\left|B\right|}\) (Conventions vary on handling \(B = \emptyset\); this implementation uses \(R(A, B):=0\), and similar for \(P\).)</source>
          <target state="translated">\（R（A，B）：= \ frac {\ left | A \ cap B \ right |} {\ left | B \ right |} \）（处理\（B = \ emptyset \）的惯例有所不同；这实现使用\（R（A，B）：= 0 \），对于\（P \）类似。）</target>
        </trans-unit>
        <trans-unit id="76e12b53dc747a452508648de37b3bbf1292886a" translate="yes" xml:space="preserve">
          <source>\(R(y, \hat{y})\)</source>
          <target state="translated">\（R（y，\ hat {y}）\）</target>
        </trans-unit>
        <trans-unit id="fe30e7d28d145393d116de8ccfdb95f1930cc647" translate="yes" xml:space="preserve">
          <source>\(S\) the set of samples</source>
          <target state="translated">\（S \）样本集</target>
        </trans-unit>
        <trans-unit id="4d975b6c5632f1c81d6cf8cc9f674c8e0d143548" translate="yes" xml:space="preserve">
          <source>\(X\): data</source>
          <target state="translated">\（X \）：数据</target>
        </trans-unit>
        <trans-unit id="59b5b0f07758a431bbb7dbf6ebe63bc98b0cd7dd" translate="yes" xml:space="preserve">
          <source>\(\Omega\) is a &lt;code&gt;penalty&lt;/code&gt; function of our model parameters</source>
          <target state="translated">\（\ Omega \）是模型参数的 &lt;code&gt;penalty&lt;/code&gt; 函数</target>
        </trans-unit>
        <trans-unit id="d82693345c0acee22512b8f82f5807d2eafe4d72" translate="yes" xml:space="preserve">
          <source>\(\Psi = \mathrm{diag}(\psi_1, \psi_2, \dots, \psi_n)\): This model is called &lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt;&lt;code&gt;FactorAnalysis&lt;/code&gt;&lt;/a&gt;, a classical statistical model. The matrix W is sometimes called the &amp;ldquo;factor loading matrix&amp;rdquo;.</source>
          <target state="translated">\（\ Psi = \ mathrm {diag}（\ psi_1，\ psi_2，\ dots，\ psi_n）\）：此模型称为&lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt; &lt;code&gt;FactorAnalysis&lt;/code&gt; &lt;/a&gt;，这是一种经典的统计模型。矩阵W有时被称为&amp;ldquo;因子加载矩阵&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="fbd9ea497a59df8b22d9aee98766b15298f6f7b0" translate="yes" xml:space="preserve">
          <source>\(\Psi = \sigma^2 \mathbf{I}\): This assumption leads to the probabilistic model of &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">\（\ Psi = \ sigma ^ 2 \ mathbf {I} \）：此假设导致&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;的概率模型。</target>
        </trans-unit>
        <trans-unit id="01f8f0e3a7f60922aad934db70b43f4626579a4f" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,1}\)</source>
          <target state="translated">\(\alpha^{0}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="51f4c7f6d4e230692f7f7ca95d3a951f2ccb6900" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,2}\)</source>
          <target state="translated">\(\alpha^{0}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="fc59eea930c0650810949c61616237e10d7608e7" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,0}\)</source>
          <target state="translated">\(\alpha^{0}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="b7a1987ec2f1ae255445b9203ba76dab46f8180e" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,2}\)</source>
          <target state="translated">\(\alpha^{0}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="ddda7bd4dda2cccb6220d08cd96b97d2564703fc" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,0}\)</source>
          <target state="translated">\(\alpha^{0}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="cd76d3a6ac27cf4608fdba8c1bcefea98e40a082" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,1}\)</source>
          <target state="translated">\(\alpha^{0}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="670a0c506ecd80ad22241edc90899b4ca5a65063" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,1}\)</source>
          <target state="translated">\(\alpha^{1}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="715b85177f34a3aec41f1d6aca5ea943c045452d" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,2}\)</source>
          <target state="translated">\(\alpha^{1}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="9bafd2e8e2343917301e41ef344db246b60c40d3" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,0}\)</source>
          <target state="translated">\(\alpha^{1}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="bd6409137f75a05bb280bc5000840c3e16f9d850" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,2}\)</source>
          <target state="translated">\(\alpha^{1}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="e31f66e6ca63dbde84a383e5d61ebb97f39d2fa6" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,0}\)</source>
          <target state="translated">\(\alpha^{1}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="603e33877eb24d9878fa7efb61a9c926fb80dd71" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,1}\)</source>
          <target state="translated">\(\alpha^{1}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="9ffe8c9fb6dee2771ab0ca39575e1df479c8a1ca" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,1}\)</source>
          <target state="translated">\(\alpha^{2}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="7f0fc3efbc7900034a8626635972b65d78e7a257" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,2}\)</source>
          <target state="translated">\(\alpha^{2}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="69166f5380836f7b04cceea34acce5263efbceff" translate="yes" xml:space="preserve">
          <source>\(\beta\): Coefficients</source>
          <target state="translated">\（\ beta \）：系数</target>
        </trans-unit>
        <trans-unit id="fec074bbf7d22c3b3d841bc5e89270a0a2f32779" translate="yes" xml:space="preserve">
          <source>\(\epsilon\): Observation noise</source>
          <target state="translated">\（\ epsilon \）：观察噪声</target>
        </trans-unit>
        <trans-unit id="12791ef36495d018e1daf82140fd4c3db8180c28" translate="yes" xml:space="preserve">
          <source>\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</source>
          <target state="translated">\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</target>
        </trans-unit>
        <trans-unit id="08cc56772d86f4dfece03ec8003aba4f776d2aab" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} F_ \ beta（y_l，\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="8c4693b66d3ba7a40d8a9abfe000616818f55aaf" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} P（y_l，\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="52e6ce52e9b8ae2877c124e769de40084f5638d9" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} R（y_l，\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="7f2d1bc16a43e60170cc4d3e4429f1eaefb3b9b2" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} F_\beta(y_s, \hat{y}_s)\)</source>
          <target state="translated">\（\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} F_ \ beta（y_s，\ hat {y} _s）\）</target>
        </trans-unit>
        <trans-unit id="301209259a59426be923af21027651f698a1adbb" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} P(y_s, \hat{y}_s)\)</source>
          <target state="translated">\（\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} P（y_s，\ hat {y} _s）\）</target>
        </trans-unit>
        <trans-unit id="76d3b6c7bb7266c85c29df970c85d63d00762934" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} R(y_s, \hat{y}_s)\)</source>
          <target state="translated">\（\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} R（y_s，\ hat {y} _s）\）</target>
        </trans-unit>
        <trans-unit id="771a76dcfeccc7d1c5c81729270313804a1579cd" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | F_ \ beta（y_l，\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="8c17ed8e7ab856a74c9c5ce2466ffe22f7bfd45b" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ inL} \ left | \ hat {y} _l \ right | P （y_l，\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="084995f248284e6186e09f61b6402476e717eb20" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | R （y_l，\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="6e89e30113ce1a3053ff34b9257e3d282abe2f88" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 1.8473]}{\sqrt{\big(3^2 + 0^2 + 1.8473^2\big)}} = [0.8515, 0, 0.5243]\):</source>
          <target state="translated">\（\ frac {[3，0，1.8473]} {\ sqrt {\ big（3 ^ 2 + 0 ^ 2 + 1.8473 ^ 2 \ big）}} = [0.8515，0，0.5243] \）：</target>
        </trans-unit>
        <trans-unit id="673551b6d125b3cd94d7674f49f994c6afdd6f65" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 2.0986]}{\sqrt{\big(3^2 + 0^2 + 2.0986^2\big)}} = [ 0.819, 0, 0.573].\)</source>
          <target state="translated">\（\ frac {[3，0，2.0986]} {\ sqrt {\ big（3 ^ 2 + 0 ^ 2 + 2.0986 ^ 2 \ big）}} = [0.819，0，0.573]。\）</target>
        </trans-unit>
        <trans-unit id="1a5082b9d05f10e66dae95fed7849c72d0a8cfc1" translate="yes" xml:space="preserve">
          <source>\(\gamma\) is known as slope</source>
          <target state="translated">\（\ gamma \）被称为斜率</target>
        </trans-unit>
        <trans-unit id="126898e7757cd77e4cefb87e42f683763bf54571" translate="yes" xml:space="preserve">
          <source>\(\hat{y}\) the set of &lt;em&gt;true&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\（\ hat {y} \）一组&lt;em&gt;真实的&lt;/em&gt;（（sample，label）\）对</target>
        </trans-unit>
        <trans-unit id="9f39f60cd1f2428420af5f2dec2780245432c521" translate="yes" xml:space="preserve">
          <source>\(\langle F_\beta(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\（\ langle F_ \ beta（y_l，\ hat {y} _l）| l \ in L \ rangle \）</target>
        </trans-unit>
        <trans-unit id="f3dc3b8f8243a37f6cfc63694bfee10bbc8dbb16" translate="yes" xml:space="preserve">
          <source>\(\langle P(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\（\ langle P（y_l，\ hat {y} _l）| l \ in L \ rangle \）</target>
        </trans-unit>
        <trans-unit id="1c6337bdf58558dfa45a337181a8da415d8b489c" translate="yes" xml:space="preserve">
          <source>\(\langle R(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\（\ langle R（y_l，\ hat {y} _l）| l \ in L \ rangle \）</target>
        </trans-unit>
        <trans-unit id="825ca6208fb0c99a89fb31d3479b162477b3c1b6" translate="yes" xml:space="preserve">
          <source>\(\mathcal{L}\) is a &lt;code&gt;loss&lt;/code&gt; function of our samples and our model parameters.</source>
          <target state="translated">\（\ mathcal {L} \）是我们的样本和模型参数的 &lt;code&gt;loss&lt;/code&gt; 函数。</target>
        </trans-unit>
        <trans-unit id="2a02f90f2b2001d6562373a7ae2a2e1dfb4565e2" translate="yes" xml:space="preserve">
          <source>\(\text{AP} = \sum_n (R_n - R_{n-1}) P_n\)</source>
          <target state="translated">\（\ text {AP} = \ sum_n（R_n-R_ {n-1}）P_n \）</target>
        </trans-unit>
        <trans-unit id="db505c609ecce8b6164765bd7848f3b41ea35f0d" translate="yes" xml:space="preserve">
          <source>\(\text{df}(d, t)_{\text{term1}} = 6\)</source>
          <target state="translated">\（\ text {df}（d，t）_ {\ text {term1}} = 6 \）</target>
        </trans-unit>
        <trans-unit id="e0997db48a8d87bf8ee1c7a8fcaa36916a54e707" translate="yes" xml:space="preserve">
          <source>\(\text{df}(t)_{\text{term1}} = 6\)</source>
          <target state="translated">\(\text{df}(t)_{\text{term1}} = 6\)</target>
        </trans-unit>
        <trans-unit id="3761c41a5e61f125696abaab3d6ab5e6c9467a9a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(d, t)_{\text{term1}} = log \frac{n_d}{\text{df}(d, t)} + 1 = log(1)+1 = 1\)</source>
          <target state="translated">\（\ text {idf}（d，t）_ {\ text {term1}} = log \ frac {n_d} {\ text {df}（d，t）} + 1 = log（1）+1 = 1 \）</target>
        </trans-unit>
        <trans-unit id="aa5a67b1ed0374bd72cf6f0e10b3fe3a74615260" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\)</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\)</target>
        </trans-unit>
        <trans-unit id="528e4287e895ebbf7910677616d1f6077d104040" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\),</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\),</target>
        </trans-unit>
        <trans-unit id="61843849cf83ac9cc60022c827bcec315d11ec03" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{1+\text{df}(t)}}.\)</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{n}{1+\text{df}(t)}}.\)</target>
        </trans-unit>
        <trans-unit id="3943a22b1a933b8cec2e621f9da837d0f8e0bccb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{\text{df}(t)}} + 1\)</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{n}{\text{df}(t)}} + 1\)</target>
        </trans-unit>
        <trans-unit id="418ed87bb3a9ff83d64cef6c0afed152e2ce9063" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\（\ text {idf}（t）= log {\ frac {1 + n_d} {1+ \ text {df}（d，t）}} + 1 \）</target>
        </trans-unit>
        <trans-unit id="cbf2fa82ddd1456d42b5d1023dd8e97cfb8e3a89" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\),</source>
          <target state="translated">\（\ text {idf}（t）= log {\ frac {1 + n_d} {1+ \ text {df}（d，t）}} + 1 \），</target>
        </trans-unit>
        <trans-unit id="4b7b756caf347e71181dfa1202016ab8356f261a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{1+\text{df}(d,t)}}.\)</source>
          <target state="translated">\（\ text {idf}（t）= log {\ frac {n_d} {1+ \ text {df}（d，t）}}。\\）。</target>
        </trans-unit>
        <trans-unit id="4034a1550b8c7d630dbd8eba4c06d1a4f1d30dc5" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\（\ text {idf}（t）=日志{\ frac {n_d} {\ text {df}（d，t）}} + 1 \）</target>
        </trans-unit>
        <trans-unit id="96edf4cb5b96d644ba339f4099a39ef286ca85fb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t)_{\text{term1}} = \log \frac{n}{\text{df}(t)} + 1 = \log(1)+1 = 1\)</source>
          <target state="translated">\(\text{idf}(t)_{\text{term1}} = \log \frac{n}{\text{df}(t)} + 1 = \log(1)+1 = 1\)</target>
        </trans-unit>
        <trans-unit id="f18c6689111b29d4354e7fffcee7cc0802b481a5" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{raw}} = [3, 0, 2.0986].\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {raw}} = [3，0，2.0986]。\）</target>
        </trans-unit>
        <trans-unit id="80aba8c317a078e4609ae8bd36660d65edad7083" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term1}} = \text{tf} \times \text{idf} = 3 \times 1 = 3\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term1}} = \ text {tf} \ times \ text {idf} = 3 \ times 1 = 3 \）</target>
        </trans-unit>
        <trans-unit id="1d70946637e51aace1378ca1a204825107f21cdf" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (\log(6/1)+1) = 0\)</source>
          <target state="translated">\(\text{tf-idf}_{\text{term2}} = 0 \times (\log(6/1)+1) = 0\)</target>
        </trans-unit>
        <trans-unit id="7f8322f95350f60ce08c7cdd3032f22e074bd2b1" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (log(6/1)+1) = 0\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term2}} = 0 \ times（log（6/1）+1）= 0 \）</target>
        </trans-unit>
        <trans-unit id="a326be18c218e6683afc2f56f1612584e40eaa79" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (\log(6/2)+1) \approx 2.0986\)</source>
          <target state="translated">\(\text{tf-idf}_{\text{term3}} = 1 \times (\log(6/2)+1) \approx 2.0986\)</target>
        </trans-unit>
        <trans-unit id="dcd228feb463195495d0b530544c87a8f5f36307" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (log(6/2)+1) \approx 2.0986\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term3}} = 1 \ times（log（6/2）+1）\ approx 2.0986 \）</target>
        </trans-unit>
        <trans-unit id="9c4af8e7df634860beafeba835d8777813396030" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times \log(7/3)+1 \approx 1.8473\)</source>
          <target state="translated">\(\text{tf-idf}_{\text{term3}} = 1 \times \log(7/3)+1 \approx 1.8473\)</target>
        </trans-unit>
        <trans-unit id="a8c4b99bd2ff2af3e5f2b8ace2008c6e0a9ef2e7" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times log(7/3)+1 \approx 1.8473\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term3}} = 1 \ times log（7/3）+1 \ approx 1.8473 \）</target>
        </trans-unit>
        <trans-unit id="b1e424267dd17efa4321c87fe24219eaad1c3249" translate="yes" xml:space="preserve">
          <source>\(a\), the number of pairs of elements that are in the same set in C and in the same set in K</source>
          <target state="translated">\（a \），在C中相同集合中在K中相同集合中的元素对数</target>
        </trans-unit>
        <trans-unit id="ffa07cceebbfadc52e2be9cdf6b9599e34083b82" translate="yes" xml:space="preserve">
          <source>\(b\), the number of pairs of elements that are in different sets in C and in different sets in K</source>
          <target state="translated">\（b \），C中不同集合中和K中不同集合中的元素对数</target>
        </trans-unit>
        <trans-unit id="9634b82eb2f3a1a53f10d0105fa96b96683012b1" translate="yes" xml:space="preserve">
          <source>\(c=\sum_{k}^{K} C_{kk}\) the total number of samples correctly predicted,</source>
          <target state="translated">\（c = \ sum_ {k} ^ {K} C_ {kk} \）正确预测的样本总数，</target>
        </trans-unit>
        <trans-unit id="e0b006e0f953d2967208fad0e101db9a95b1773e" translate="yes" xml:space="preserve">
          <source>\(c_0\) is known as intercept</source>
          <target state="translated">\（c_0 \）被称为拦截</target>
        </trans-unit>
        <trans-unit id="20f463b5231561db0d1529b308e8cd1a67579869" translate="yes" xml:space="preserve">
          <source>\(d\) : output dimension</source>
          <target state="translated">\（d \）：输出尺寸</target>
        </trans-unit>
        <trans-unit id="3c2644dcb6baee3a2f0954ec1f4febb35c2c968e" translate="yes" xml:space="preserve">
          <source>\(d_{ij}\), the distance between cluster centroids \(i\) and \(j\).</source>
          <target state="translated">\（d_ {ij} \），簇质心\（i \）和\（j \）之间的距离。</target>
        </trans-unit>
        <trans-unit id="464de6af9c88cdb5c8c4a2137401febf7a5e41c7" translate="yes" xml:space="preserve">
          <source>\(k\) : number of nearest neighbors</source>
          <target state="translated">\（k \）：最近邻居的数量</target>
        </trans-unit>
        <trans-unit id="ded29692d567c68006b5e22274ae992999727d77" translate="yes" xml:space="preserve">
          <source>\(n = 6\)</source>
          <target state="translated">\(n = 6\)</target>
        </trans-unit>
        <trans-unit id="8f8783323f752c7593ada8acf8c4d67282a83607" translate="yes" xml:space="preserve">
          <source>\(n_{d} = 6\)</source>
          <target state="translated">\（n_ {d} = 6 \）</target>
        </trans-unit>
        <trans-unit id="13e265f7db3a9509d50f014f7170db211a73f394" translate="yes" xml:space="preserve">
          <source>\(p_k=\sum_{i}^{K} C_{ki}\) the number of times class \(k\) was predicted,</source>
          <target state="translated">\（p_k = \ sum_ {i} ^ {K} C_ {ki} \）预测类\（k \）的次数，</target>
        </trans-unit>
        <trans-unit id="cc4e2c50ba94767cc02eead7002753560f0219c2" translate="yes" xml:space="preserve">
          <source>\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\) the total number of samples.</source>
          <target state="translated">\（s = \ sum_ {i} ^ {K} \ sum_ {j} ^ {K} C_ {ij} \）样本总数。</target>
        </trans-unit>
        <trans-unit id="6eb93fac640cf512d1e63922116e7722c92fabe0" translate="yes" xml:space="preserve">
          <source>\(s_i\), the average distance between each point of cluster \(i\) and the centroid of that cluster &amp;ndash; also know as cluster diameter.</source>
          <target state="translated">\（s_i \），聚类\（i \）每个点与该聚类的质心之间的平均距离-也称为聚类直径。</target>
        </trans-unit>
        <trans-unit id="2904d711734ca668dfddae3cff9c273e4d482636" translate="yes" xml:space="preserve">
          <source>\(t_k=\sum_{i}^{K} C_{ik}\) the number of times class \(k\) truly occurred,</source>
          <target state="translated">\（t_k = \ sum_ {i} ^ {K} C_ {ik} \）类别\（k \）实际发生的次数，</target>
        </trans-unit>
        <trans-unit id="0a59d79c97bec565e1c47b5aab7109c37d7376fa" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\)</source>
          <target state="translated">\（v_ {norm} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \）</target>
        </trans-unit>
        <trans-unit id="ef3a9e22b14c74ec22385c615853f9e45898420d" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\).</source>
          <target state="translated">\（v_ {norm} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \）。</target>
        </trans-unit>
        <trans-unit id="e9fe36499695707a4fa25e6312e0decc4b5ce11a" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \geq F(x_1', x_2)\).</source>
          <target state="translated">\(x_1 \leq x_1' \implies F(x_1, x_2) \geq F(x_1', x_2)\).</target>
        </trans-unit>
        <trans-unit id="12ab6bd6cdfcad92f2c8d9cd45d8531fb50b8225" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2)\), where \(F\) is the predictor with two features.</source>
          <target state="translated">\（x_1 \ leq x_1'\隐含F（x_1，x_2）\ leq F（x_1'，x_2）\），其中\（F \）是具有两个特征的预测变量。</target>
        </trans-unit>
        <trans-unit id="d224f9dd671e9669fa16b0ba657459625c42e63b" translate="yes" xml:space="preserve">
          <source>\(y \in (-\infty, \infty)\)</source>
          <target state="translated">\(y \in (-\infty, \infty)\)</target>
        </trans-unit>
        <trans-unit id="7fb9264ce64cd7d5e1a33f2fcf663917cc9226ab" translate="yes" xml:space="preserve">
          <source>\(y \in (0, \infty)\)</source>
          <target state="translated">\(y \in (0, \infty)\)</target>
        </trans-unit>
        <trans-unit id="6ffefe23f049210303238c3770c5a3a8cbf9ad47" translate="yes" xml:space="preserve">
          <source>\(y \in [0, \infty)\)</source>
          <target state="translated">\(y \in [0, \infty)\)</target>
        </trans-unit>
        <trans-unit id="2f32f66d76e16029cdb54470231bf86f45c56290" translate="yes" xml:space="preserve">
          <source>\(y\) the set of &lt;em&gt;predicted&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\（y \）&lt;em&gt;预测&lt;/em&gt; \（（样本，标签）\）对的集合</target>
        </trans-unit>
        <trans-unit id="84dbf0f25232d7453b4b36e6d3fffb9c5594408b" translate="yes" xml:space="preserve">
          <source>\(y\): target variable</source>
          <target state="translated">\（y \）：目标变量</target>
        </trans-unit>
        <trans-unit id="29655c66149656107eee3658832dbefda0f10f88" translate="yes" xml:space="preserve">
          <source>\(y_l\) the subset of \(y\) with label \(l\)</source>
          <target state="translated">\（y_l \）标签为\（l \）的\（y \）的子集</target>
        </trans-unit>
        <trans-unit id="2e082165475a8fcee912e7d794c4b87072c02854" translate="yes" xml:space="preserve">
          <source>\(y_s\) the subset of \(y\) with sample \(s\), i.e. \(y_s := \left\{(s', l) \in y | s' = s\right\}\)</source>
          <target state="translated">\（y_s \）具有样本\（s \）的\（y \）的子集，即\（y_s：= \ left \ {（s'，l）\ in y | s'= s \ right \} \ ）</target>
        </trans-unit>
        <trans-unit id="83a2c7fcc781f513174d7284ba894e2de571456a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)\\\Downarrow\\\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y),\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} P（y \ mid x_1，\ dots，x_n）\ propto P（y）\ prod_ {i = 1} ^ {n} P（x_i \ mid y）\\ \ Downarrow \\\ hat {y} = \ arg \ max_y P（y）\ prod_ {i = 1} ^ {n} P（x_i \ mid y），\ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="c500aca02db178fd925a59974dd45ddee8face02" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}Q_{left}(\theta) = {(x, y) | x_j &amp;lt;= t_m}\\Q_{right}(\theta) = Q \setminus Q_{left}(\theta)\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} Q_ {left}（\ theta）= {（x，y）| x_j &amp;lt;= t_m} \\ Q_ {right}（\ theta）= Q \ setminus Q_ {left}（\ theta）\ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6d63d132be650c44cbd8191fea374d6099c68415" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} (y_i - \bar{y}_m)^2\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H（X_m）= \ frac {1} {N_m } \ sum_ {i \ in N_m}（y_i-\ bar {y} _m）^ 2 \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="09657abb97474afe531f716bc21393139a923381" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - \bar{y}_m|\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H（X_m）= \ frac {1} {N_m } \ sum_ {i \ in N_m} | y_i-\ bar {y} _m | \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="a6a013161b26d9345009bc657a0fa52bacc545a7" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\hat{\theta}_{ci} = \frac{\alpha_i + \sum_{j:y_j \neq c} d_{ij}} {\alpha + \sum_{j:y_j \neq c} \sum_{k} d_{kj}}\\w_{ci} = \log \hat{\theta}_{ci}\\w_{ci} = \frac{w_{ci}}{\sum_{j} |w_{cj}|}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ hat {\ theta} _ {ci} = \ frac {\ alpha_i + \ sum_ {j：y_j \ neq c} d_ {ij}} {\ alpha + \ sum_ {j：y_j \ neq c} \ sum_ {k} d_ {kj}} \\ w_ {ci} = \ log \ hat {\ theta} _ {ci} \\ w_ {ci} = \ frac {w_ {ci }} {\ sum_ {j} | w_ {cj} |} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="3d5da4b9043141ddac28de63232838abbbe5a18b" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\log\left(\frac{P(y=k|X)}{P(y=l|X)}\right)= \log\left(\frac{P(X|y=k)P(y=k)}{P(X|y=l)P(y=l)}\right)=0 \Leftrightarrow\\(\mu_k-\mu_l)^t\Sigma^{-1} X = \frac{1}{2} (\mu_k^t \Sigma^{-1} \mu_k - \mu_l^t \Sigma^{-1} \mu_l) - \log\frac{P(y=k)}{P(y=l)}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ log \ left（\ frac {P（y = k | X）} {P（y = l | X）} \ right）= \ log \ left（\ frac {P（X | y = k）P（y = k）} {P（X | y = l）P（y = l）} \ right）= 0 \ Leftrightarrow \\（\ mu_k- \ mu_l）^ t \ Sigma ^ {-1} X = \ frac {1} {2}（\ mu_k ^ t \ Sigma ^ {-1} \ mu_k-\ mu_l ^ t \ Sigma ^ {-1} \ mu_l）-\ log \ frac {P（y = k）} {P（y = l）} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="970228f13e58c5000f67243636530c2e6768a476" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta, \zeta^*} \frac{1}{2} w^T w + C \sum_{i=1}^{n} (\zeta_i + \zeta_i^*)\\\begin{split}\textrm {subject to } &amp;amp; y_i - w^T \phi (x_i) - b \leq \varepsilon + \zeta_i,\\ &amp;amp; w^T \phi (x_i) + b - y_i \leq \varepsilon + \zeta_i^*,\\ &amp;amp; \zeta_i, \zeta_i^* \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min_ {w，b，\ zeta，\ zeta ^ *} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ { n}（\ zeta_i + \ zeta_i ^ *）\\\ begin {split} \ textrm {subject to}＆y_i-w ^ T \ phi（x_i）-b \ leq \ varepsilon + \ zeta_i，\\＆w ^ T \ phi（x_i）+ b-y_i \ leq \ varepsilon + \ zeta_i ^ *，\\＆\ zeta_i，\ zeta_i ^ * \ geq 0，i = 1，...，n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="e7cf54257feefa3a1cdfa65288e5d1230916a9ce" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta} \frac{1}{2} w^T w + C \sum_{i=1}^{n} \zeta_i\\\begin{split}\textrm {subject to } &amp;amp; y_i (w^T \phi (x_i) + b) \geq 1 - \zeta_i,\\ &amp;amp; \zeta_i \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min_ {w，b，\ zeta} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ {n} \ zeta_i \ \\ begin {split} \ textrm {subject to}＆y_i（w ^ T \ phi（x_i）+ b）\ geq 1-\ zeta_i，\\＆\ zeta_i \ geq 0，i = 1，...， n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="80291068f9bc632282f639938cf37593076f7e40" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha, \alpha^*} \frac{1}{2} (\alpha - \alpha^*)^T Q (\alpha - \alpha^*) + \varepsilon e^T (\alpha + \alpha^*) - y^T (\alpha - \alpha^*)\\\begin{split} \textrm {subject to } &amp;amp; e^T (\alpha - \alpha^*) = 0\\ &amp;amp; 0 \leq \alpha_i, \alpha_i^* \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min _ {\ alpha，\ alpha ^ *} \ frac {1} {2}（\ alpha-\ alpha ^ *）^ TQ（\ alpha-\ alpha ^ * ）+ \ varepsilon e ^ T（\ alpha + \ alpha ^ *）-y ^ T（\ alpha-\ alpha ^ *）\\\ begin {split} \ textrm {subject to}＆e ^ T（\ alpha- \ alpha ^ *）= 0 \\＆0 \ leq \ alpha_i，\ alpha_i ^ * \ leq C，i = 1，...，n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6c7b70ef69da1a978d3d70eb6e72d1cfe185904a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha} \frac{1}{2} \alpha^T Q \alpha - e^T \alpha\\\begin{split} \textrm {subject to } &amp;amp; y^T \alpha = 0\\ &amp;amp; 0 \leq \alpha_i \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min _ {\ alpha} \ frac {1} {2} \ alpha ^ TQ \ alpha-e ^ T \ alpha \\\ begin {split} \ textrm { }＆y ^ T \ alpha = 0 \\＆0 \ leq \ alpha_i \ leq C，i = 1，...，n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="b61ecb24510d037b2f103f5394b305a25a58f23a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}median(y)_m = \underset{i \in N_m}{\mathrm{median}}(y_i)\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - median(y)_m|\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} median（y）_m = \ underset {i \ in N_m} {\ mathrm {median}}（y_i）\\ H（X_m）= \ frac {1} {N_m } \ sum_ {i \ in N_m} | y_i-中位数（y）_m | \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="d6188a7c021d3288e439ea7246a74358b63a884c" translate="yes" xml:space="preserve">
          <source>\[(1 - eps) \|u - v\|^2 &amp;lt; \|p(u) - p(v)\|^2 &amp;lt; (1 + eps) \|u - v\|^2\]</source>
          <target state="translated">\ [（（1-eps）\ | u-v \ | ^ 2 &amp;lt;\ | p（u）-p（v）\ | ^ 2 &amp;lt;（1 + eps）\ | u-v \ | ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c4407dbb151e2710b04032ff6939f68ed3c7179c" translate="yes" xml:space="preserve">
          <source>\[A_n = R^{-1/2} A C^{-1/2}\]</source>
          <target state="translated">\ [A_n = R ^ {-1/2} AC ^ {-1/2} \]</target>
        </trans-unit>
        <trans-unit id="f6b0d9bcf51ca0db910abd2831694b2e6df3d3e4" translate="yes" xml:space="preserve">
          <source>\[BS = \frac{1}{N} \sum_{t=1}^{N}(f_t - o_t)^2\]</source>
          <target state="translated">\ [BS = \ frac {1} {N} \ sum_ {t = 1} ^ {N}（f_t-o_t）^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c92a9c50030567e1c914fdb60f6f36c624d7857a" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_q n_q (c_q - c) (c_q - c)^T\]</source>
          <target state="translated">\ [B_k = \ sum_q n_q（c_q-c）（c_q-c）^ T \]</target>
        </trans-unit>
        <trans-unit id="ba2a7d3bd989e0c77672451c8ebf6d95f02e79e3" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</source>
          <target state="translated">\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</target>
        </trans-unit>
        <trans-unit id="f7004892a8adf03dbfdffcdcf3787b7ebb419e77" translate="yes" xml:space="preserve">
          <source>\[C \sum_{i=1, n} \mathcal{L} (f(x_i), y_i) + \Omega (w)\]</source>
          <target state="translated">\ [C \ sum_ {i = 1，n} \ mathcal {L}（f（x_i），y_i）+ \ Omega（w）\]</target>
        </trans-unit>
        <trans-unit id="cdd0300688de915acfc1a115df5a69adf7a6197d" translate="yes" xml:space="preserve">
          <source>\[D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2) + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]\]</source>
          <target state="translated">\[D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2) + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]\]</target>
        </trans-unit>
        <trans-unit id="24e7ca264d5b1b5ecf81452a44a55176b2008b8c" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="translated">\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</target>
        </trans-unit>
        <trans-unit id="69d401f524d7e967afe2dcb64dc99487200dfcd8" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="translated">\ [DB = \ frac {1} {k} \ sum {i = 1} ^ k \ max_ {i \ neq j} R_ {ij} \]</target>
        </trans-unit>
        <trans-unit id="0e40c0ff9b9201b3e6cc8ee7f729672fe6ce4c93" translate="yes" xml:space="preserve">
          <source>\[E(\mathbf{v}, \mathbf{h}) = -\sum_i \sum_j w_{ij}v_ih_j - \sum_i b_iv_i - \sum_j c_jh_j\]</source>
          <target state="translated">\ [E（\ mathbf {v}，\ mathbf {h}）=-\ sum_i \ sum_j w_ {ij} v_ih_j-\ sum_i b_iv_i-\ sum_j c_jh_j \]</target>
        </trans-unit>
        <trans-unit id="783de3e797180d6f4ba6c3e9379606ecef2ead2a" translate="yes" xml:space="preserve">
          <source>\[E(w,b) = \frac{1}{n}\sum_{i=1}^{n} L(y_i, f(x_i)) + \alpha R(w)\]</source>
          <target state="translated">\ [E（w，b）= \ frac {1} {n} \ sum_ {i = 1} ^ {n} L（y_i，f（x_i））+ \ alpha R（w）\]</target>
        </trans-unit>
        <trans-unit id="365f54944565346973bba6038073efb7e313ed11" translate="yes" xml:space="preserve">
          <source>\[E[\text{MI}(U,V)]=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \sum_{n_{ij}=(a_i+b_j-N)^+ }^{\min(a_i, b_j)} \frac{n_{ij}}{N}\log \left( \frac{ N.n_{ij}}{a_i b_j}\right) \frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})! (N-a_i-b_j+n_{ij})!}\]</source>
          <target state="translated">\ [E [\ text {MI}（U，V）] = \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ sum_ {n_ {ij} = （a_i + b_j-N）^ +} ^ {\ min（a_i，b_j）} \ frac {n_ {ij}} {N} \ log \ left（\ frac {N.n_ {ij}} {a_i b_j} \ right）\ frac {a_i！b_j！（N-a_i）！（N-b_j）！} {N！n_ {ij}！（a_i-n_ {ij}）！（b_j-n_ {ij}）！（N-a_i-b_j + n_ {ij}）！} \]</target>
        </trans-unit>
        <trans-unit id="fa1ff8faa81d9e66252f62a095f5cf70ca1078c1" translate="yes" xml:space="preserve">
          <source>\[F(x) = \sum_{m=1}^{M} \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F（x）= \ sum_ {m = 1} ^ {M} \ gamma_m h_m（x）\]</target>
        </trans-unit>
        <trans-unit id="8b0368e365c0b4ab2c5226a46b2b8384821b7abd" translate="yes" xml:space="preserve">
          <source>\[F_\beta = (1 + \beta^2) \frac{\text{precision} \times \text{recall}}{\beta^2 \text{precision} + \text{recall}}.\]</source>
          <target state="translated">\ [F_ \ beta =（1 + \ beta ^ 2）\ frac {\ text {precision} \ times \ text {recall}} {\ beta ^ 2 \ text {precision} + \ text {recall}}。\]</target>
        </trans-unit>
        <trans-unit id="c9eeb87b260c2954980548a507a8b1393c039854" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \arg\min_{h} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + h(x))\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）+ \ arg \ min_ {h} \ sum_ {i = 1} ^ {n} L（y_i，F_ {m-1}（x_i）+ h （X））\]</target>
        </trans-unit>
        <trans-unit id="c3b959c536d9b51ce676e93f30895d0c6d681eae" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）+ \ gamma_m h_m（x）\]</target>
        </trans-unit>
        <trans-unit id="9b119698c7b1cbf47db5678415973bc69f053f0c" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）+ \ nu \ gamma_m h_m（x）\]</target>
        </trans-unit>
        <trans-unit id="f67ac5f779f99408bbddee5aabe3119d85a325aa" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu h_m(x)\]</source>
          <target state="translated">\[F_m(x) = F_{m-1}(x) + \nu h_m(x)\]</target>
        </trans-unit>
        <trans-unit id="53cc4ef6b492c65482e59fea0173cd005acf6ca7" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + h_m(x),\]</source>
          <target state="translated">\[F_m(x) = F_{m-1}(x) + h_m(x),\]</target>
        </trans-unit>
        <trans-unit id="79620d3f64f3ecc0a5f216eb6a57691d801c15cd" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) - \gamma_m \sum_{i=1}^{n} \nabla_F L(y_i, F_{m-1}(x_i))\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）-\ gamma_m \ sum_ {i = 1} ^ {n} \ nabla_F L（y_i，F_ {m-1}（x_i））\]</target>
        </trans-unit>
        <trans-unit id="90cafad385d21b4d4db9860dff7480af31e6cc3a" translate="yes" xml:space="preserve">
          <source>\[G(Q, \theta) = \frac{n_{left}}{N_m} H(Q_{left}(\theta)) + \frac{n_{right}}{N_m} H(Q_{right}(\theta))\]</source>
          <target state="translated">\ [G（Q，\ theta）= \ frac {n_ {left}} {N_m} H（Q_ {left}（\ theta））+ \ frac {n_ {right}} {N_m} H（Q_ {right} （\ theta））\]</target>
        </trans-unit>
        <trans-unit id="a3b30c3461532826adfe7425f51daed9aaf98e97" translate="yes" xml:space="preserve">
          <source>\[H(C) = - \sum_{c=1}^{|C|} \frac{n_c}{n} \cdot \log\left(\frac{n_c}{n}\right)\]</source>
          <target state="translated">\ [H（C）=-\ sum_ {c = 1} ^ {| C |} \ frac {n_c} {n} \ cdot \ log \ left（\ frac {n_c} {n} \ right）\]</target>
        </trans-unit>
        <trans-unit id="672f9873cccc012ff842c8c7fce069ac5cd92675" translate="yes" xml:space="preserve">
          <source>\[H(C|K) = - \sum_{c=1}^{|C|} \sum_{k=1}^{|K|} \frac{n_{c,k}}{n} \cdot \log\left(\frac{n_{c,k}}{n_k}\right)\]</source>
          <target state="translated">\ [H（C | K）=-\ sum_ {c = 1} ^ {| C |} \ sum_ {k = 1} ^ {| K |} \ frac {n_ {c，k}} {n} \ cdot \ log \ left（\ frac {n_ {c，k}} {n_k} \ right）\]</target>
        </trans-unit>
        <trans-unit id="9dcc776906a998f47112457373d3636e82b5c382" translate="yes" xml:space="preserve">
          <source>\[H(U) = - \sum_{i=1}^{|U|}P(i)\log(P(i))\]</source>
          <target state="translated">\ [H（U）=-\ sum_ {i = 1} ^ {| U |} P（i）\ log（P（i））\]</target>
        </trans-unit>
        <trans-unit id="bf873d01bafa66fa00d4a9abe244e71c3ad5c483" translate="yes" xml:space="preserve">
          <source>\[H(V) = - \sum_{j=1}^{|V|}P'(j)\log(P'(j))\]</source>
          <target state="translated">\ [H（V）=-\ sum_ {j = 1} ^ {| V |} P'（j）\ log（P'（j））\]</target>
        </trans-unit>
        <trans-unit id="825bd8051092a0ff4da11fbb8a018da499318440" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = - \sum_k p_{mk} \log(p_{mk})\]</source>
          <target state="translated">\ [H（X_m）=-\ sum_k p_ {mk} \ log（p_ {mk}）\]</target>
        </trans-unit>
        <trans-unit id="86fb9fbe52343d6db8c412062ca26e8b3a61d7f8" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = 1 - \max(p_{mk})\]</source>
          <target state="translated">\ [H（X_m）= 1-\ max（p_ {mk}）\]</target>
        </trans-unit>
        <trans-unit id="471e679a9a1baa18ae5b83f786849ce5561bcf62" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = \sum_k p_{mk} (1 - p_{mk})\]</source>
          <target state="translated">\ [H（X_m）= \ sum_k p_ {mk}（1-p_ {mk}）\]</target>
        </trans-unit>
        <trans-unit id="d07612141f923e53a5d822ae265800fc511ebfa2" translate="yes" xml:space="preserve">
          <source>\[J(A, B) = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}\]</source>
          <target state="translated">\ [J（A，B）= \ frac {| A \ cap B |} {| A | + | B | -| A \ cap B |} \]</target>
        </trans-unit>
        <trans-unit id="b38d8ccb5f6105408ebebb5c4de384f0bcc0244c" translate="yes" xml:space="preserve">
          <source>\[J(y_i, \hat{y}_i) = \frac{|y_i \cap \hat{y}_i|}{|y_i \cup \hat{y}_i|}.\]</source>
          <target state="translated">\ [J（y_i，\ hat {y} _i）= \ frac {| y_i \ cap \ hat {y} _i |} {| y_i \ cup \ hat {y} _i |}。\]</target>
        </trans-unit>
        <trans-unit id="d318f9ea1800cd74dd7a27a0e7aa26e39a217efa" translate="yes" xml:space="preserve">
          <source>\[K_{ij} = L_{ij} - \overline{L_{i \cdot}} - \overline{L_{\cdot j}} + \overline{L_{\cdot \cdot}}\]</source>
          <target state="translated">\ [K_ {ij} = L_ {ij}-\ overline {L_ {i \ cdot}}-\ overline {L _ {\ cdot j}} + \ overline {L _ {\ cdot \ cdot}} \]</target>
        </trans-unit>
        <trans-unit id="4f142a1b3f1a25b7844f5bd577802840d9086424" translate="yes" xml:space="preserve">
          <source>\[LRAP(y, \hat{f}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0} \sum_{j:y_{ij} = 1} \frac{|\mathcal{L}_{ij}|}{\text{rank}_{ij}}\]</source>
          <target state="translated">\ [LRAP（y，\ hat {f}）= \ frac {1} {n _ {\ text {samples}}} \ sum_ {i = 0} ^ {n _ {\ text {samples}}-1} \ frac {1} {|| y_i || _0} \ sum_ {j：y_ {ij} = 1} \ frac {| \ mathcal {L} _ {ij} |} {\ text {rank} _ {ij}} \\ ]</target>
        </trans-unit>
        <trans-unit id="ce318e5aa62c88285e6dbc3450ddc43884867d96" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y, w) = \max\left\{1 - wy, 0\right\} = \left|1 - wy\right|_+\]</source>
          <target state="translated">\ [L_ \ text {Hinge}（y，w）= \ max \ left \ {1-wy，0 \ right \} = \ left | 1-wy \ right | _ + \]</target>
        </trans-unit>
        <trans-unit id="ba42e2e6c73e49cc69262971d98739da8f3de127" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y_w, y_t) = \max\left\{1 + y_t - y_w, 0\right\}\]</source>
          <target state="translated">\ [L_ \ text {Hinge}（y_w，y_t）= \ max \ left \ {1 + y_t-y_w，0 \ right \} \]</target>
        </trans-unit>
        <trans-unit id="7d42c3e71601b07673f2ff67be6498a9b9b5b660" translate="yes" xml:space="preserve">
          <source>\[L_{0-1}(y_i, \hat{y}_i) = 1(\hat{y}_i \not= y_i)\]</source>
          <target state="translated">\ [L_ {0-1}（y_i，\ hat {y} _i）= 1（\ hat {y} _i \ not = y_i）\]</target>
        </trans-unit>
        <trans-unit id="2d55be0d74f5ef605272bd6c32e6867b2bf3e8e6" translate="yes" xml:space="preserve">
          <source>\[L_{Hamming}(y, \hat{y}) = \frac{1}{n_\text{labels}} \sum_{j=0}^{n_\text{labels} - 1} 1(\hat{y}_j \not= y_j)\]</source>
          <target state="translated">\ [L_ {Hamming}（y，\ hat {y}）= \ frac {1} {n_ \ text {labels}} \ sum_ {j = 0} ^ {n_ \ text {labels}-1} 1（\帽子{y} _j \ not = y_j）\]</target>
        </trans-unit>
        <trans-unit id="b3092c91dac051243dcdc2b0e51b2cc71f3f1851" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(Y, P) = -\log \operatorname{Pr}(Y|P) = - \frac{1}{N} \sum_{i=0}^{N-1} \sum_{k=0}^{K-1} y_{i,k} \log p_{i,k}\]</source>
          <target state="translated">\ [L _ {\ log}（Y，P）=-\ log \ operatorname {Pr}（Y | P）=-\ frac {1} {N} \ sum_ {i = 0} ^ {N-1} \ sum_ {k = 0} ^ {K-1} y_ {i，k} \ log p_ {i，k} \]</target>
        </trans-unit>
        <trans-unit id="253a9ad7d14147f9b4d52f808d7adc29f4f1d369" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(y, p) = -\log \operatorname{Pr}(y|p) = -(y \log (p) + (1 - y) \log (1 - p))\]</source>
          <target state="translated">\ [L _ {\ log}（y，p）=-\ log \操作员名称{Pr}（y | p）=-（y \ log（p）+（1- y）\ log（1- p））\ ]</target>
        </trans-unit>
        <trans-unit id="2efbeda9bdd157cc2d7a3c7780634a18e9cf252c" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = -y \ln {\hat{y}} - (1-y) \ln{(1-\hat{y})} + \alpha ||W||_2^2\]</source>
          <target state="translated">\ [损失（\ hat {y}，y，W）= -y \ ln {\ hat {y}}-（1-y）\ ln {（1- \ hat {y}）} + \ alpha || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ad216be468be053e061c385b7f1c21d710fe84a9" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = \frac{1}{2}||\hat{y} - y ||_2^2 + \frac{\alpha}{2} ||W||_2^2\]</source>
          <target state="translated">\ [损失（\ hat {y}，y，W）= \ frac {1} {2} || \ hat {y}-y || _2 ^ 2 + \ frac {\ alpha} {2} || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="3d4d43e0aa8af2572cd4c7afaa27772d600c52ba" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{ c \times s - \sum_{k}^{K} p_k \times t_k }{\sqrt{ (s^2 - \sum_{k}^{K} p_k^2) \times (s^2 - \sum_{k}^{K} t_k^2) }}\]</source>
          <target state="translated">\ [MCC = \ frac {c \ times s-\ sum_ {k} ^ {K} p_k \ times t_k} {\ sqrt {（s ^ 2-\ sum_ {k} ^ {K} p_k ^ 2）\ times （s ^ 2-\ sum_ {k} ^ {K} t_k ^ 2）}} \]</target>
        </trans-unit>
        <trans-unit id="f5497e39840904c9cb7d2472c1ab3621a66cd485" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{tp \times tn - fp \times fn}{\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\]</source>
          <target state="translated">\ [MCC = \ frac {tp \ times tn-fp \ times fn} {\ sqrt {（tp + fp）（tp + fn）（tn + fp）（tn + fn）}}。\]。</target>
        </trans-unit>
        <trans-unit id="a3da3c85336ea30ff991df5f7886c792d671d3d1" translate="yes" xml:space="preserve">
          <source>\[MI(U,V)=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \frac{|U_i\cap V_j|}{N} \log\frac{N|U_i \cap V_j|}{|U_i||V_j|}\]</source>
          <target state="translated">\ [MI（U，V）= \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ frac {| U_i \ cap V_j |} {N} \ log \ frac {N | U_i \ cap V_j |} {| U_i || V_j |} \]</target>
        </trans-unit>
        <trans-unit id="c94cfec038c55c60afa9fef476e0a1aad2563170" translate="yes" xml:space="preserve">
          <source>\[P(X | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (X-\mu_k)^t \Sigma_k^{-1} (X-\mu_k)\right)\]</source>
          <target state="translated">\ [P（X | y = k）= \ frac {1} {（2 \ pi）^ {d / 2} | \ Sigma_k | ^ {1/2}} \ exp \ left（-\ frac {1} {2}（X- \ mu_k）^ t \ Sigma_k ^ {-1}（X- \ mu_k）\ right）\]</target>
        </trans-unit>
        <trans-unit id="cd893dbc741157abd91341aed411a740724f85fa" translate="yes" xml:space="preserve">
          <source>\[P(\mathbf{v}, \mathbf{h}) = \frac{e^{-E(\mathbf{v}, \mathbf{h})}}{Z}\]</source>
          <target state="translated">\ [P（\ mathbf {v}，\ mathbf {h}）= \ frac {e ^ {-E（\ mathbf {v}，\ mathbf {h}）}} {Z} \]</target>
        </trans-unit>
        <trans-unit id="7e8396a93e6bd3272f4718e7de218023882d7d31" translate="yes" xml:space="preserve">
          <source>\[P(x | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k)\right)\]</source>
          <target state="translated">\[P(x | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k)\right)\]</target>
        </trans-unit>
        <trans-unit id="f84acbf7827b429f5edf701fe90ef79259a19956" translate="yes" xml:space="preserve">
          <source>\[P(x_i = t \mid y = c \: ;\, \alpha) = \frac{ N_{tic} + \alpha}{N_{c} + \alpha n_i},\]</source>
          <target state="translated">\[P(x_i = t \mid y = c \: ;\, \alpha) = \frac{ N_{tic} + \alpha}{N_{c} + \alpha n_i},\]</target>
        </trans-unit>
        <trans-unit id="0a8ab66c6ea03a89651facccbd08d5f0c9be8c6d" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = P(i \mid y) x_i + (1 - P(i \mid y)) (1 - x_i)\]</source>
          <target state="translated">\ [P（x_i \ mid y）= P（i \ mid y）x_i +（1-P（i \ mid y））（1-x_i）\]</target>
        </trans-unit>
        <trans-unit id="33b093ce0e5d6e386417ef609cc2f6a855343cc3" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = \frac{1}{\sqrt{2\pi\sigma^2_y}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma^2_y}\right)\]</source>
          <target state="translated">\ [P（x_i \ mid y）= \ frac {1} {\ sqrt {2 \ pi \ sigma ^ 2_y}} \ exp \ left（-\ frac {（x_i-\ mu_y）^ 2} {2 \ sigma ^ 2_y} \ right）\]</target>
        </trans-unit>
        <trans-unit id="1f013d2ae1dd46efa06019f68c7849dc72ce7f4e" translate="yes" xml:space="preserve">
          <source>\[P(x_i | y, x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n) = P(x_i | y),\]</source>
          <target state="translated">\ [P（x_i | y，x_1，\ dots，x_ {i-1}，x_ {i + 1}，\ dots，x_n）= P（x_i | y），\]</target>
        </trans-unit>
        <trans-unit id="c732ad1752bec3f2371482df4bfec3ce784d1ec4" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P（y \ mid x_1，\ dots，x_n）= \ frac {P（y）P（x_1，\ dots x_n \ mid y）} {P（x_1，\ dots，x_n）} \]</target>
        </trans-unit>
        <trans-unit id="facd455c5147b9177420e6f465438d2ec052942b" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots, x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots, x_n \mid y)} {P(x_1, \dots, x_n)}\]</target>
        </trans-unit>
        <trans-unit id="84c8d40000ffaabc15011af6c72fc5efaa03e40c" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P（y \ mid x_1，\ dots，x_n）= \ frac {P（y）\ prod_ {i = 1} ^ {n} P（x_i \ mid y）} {P（x_1，\ dots，x_n ）} \]</target>
        </trans-unit>
        <trans-unit id="edcd72a09735a7f6adceea22c0b30c20fbfbd80a" translate="yes" xml:space="preserve">
          <source>\[P(y=k | X) = \frac{P(X | y=k) P(y=k)}{P(X)} = \frac{P(X | y=k) P(y = k)}{ \sum_{l} P(X | y=l) \cdot P(y=l)}\]</source>
          <target state="translated">\ [P（y = k | X）= \ frac {P（X | y = k）P（y = k）} {P（X）} = \ frac {P（X | y = k）P（y = k）} {\ sum_ {l} P（X | y = l）\ cdot P（y = l）} \]</target>
        </trans-unit>
        <trans-unit id="d0d051ebe8e5f14c78017b6beb24cfde6b45cc0c" translate="yes" xml:space="preserve">
          <source>\[P(y=k | x) = \frac{P(x | y=k) P(y=k)}{P(x)} = \frac{P(x | y=k) P(y = k)}{ \sum_{l} P(x | y=l) \cdot P(y=l)}\]</source>
          <target state="translated">\[P(y=k | x) = \frac{P(x | y=k) P(y=k)}{P(x)} = \frac{P(x | y=k) P(y = k)}{ \sum_{l} P(x | y=l) \cdot P(y=l)}\]</target>
        </trans-unit>
        <trans-unit id="b5a07827e49a88167851d8970eaa9edda3b99d65" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=0}^{n_{\text{samples}} - 1} (y_i - \hat{y}_i)^2}{\sum_{i=0}^{n_\text{samples} - 1} (y_i - \bar{y})^2}\]</source>
          <target state="translated">\ [R ^ 2（y，\ hat {y}）= 1-\ frac {\ sum_ {i = 0} ^ {n _ {\ text {samples}}-1}（y_i-\ hat {y} _i） ^ 2} {\ sum_ {i = 0} ^ {n_ \ text {samples}-1}（y_i-\ bar {y}）^ 2} \]</target>
        </trans-unit>
        <trans-unit id="75a581e81c894ca3d5a39bbe361df977932542f2" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</source>
          <target state="translated">\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</target>
        </trans-unit>
        <trans-unit id="e9b98e0db2ea75d1dfbeda81f631985feb91e53a" translate="yes" xml:space="preserve">
          <source>\[R_\alpha(T) = R(T) + \alpha|T|\]</source>
          <target state="translated">\[R_\alpha(T) = R(T) + \alpha|T|\]</target>
        </trans-unit>
        <trans-unit id="c4a8061b9eb9628b02ec75d4e5fc5a21d09cd880" translate="yes" xml:space="preserve">
          <source>\[R_{ij} = \frac{s_i + s_j}{d_{ij}}\]</source>
          <target state="translated">\ [R_ {ij} = \ frac {s_i + s_j} {d_ {ij}} \]</target>
        </trans-unit>
        <trans-unit id="a0fa8b8fb90971dc259d470e1011abda5608da98" translate="yes" xml:space="preserve">
          <source>\[T(k) = 1 - \frac{2}{nk (2n - 3k - 1)} \sum^n_{i=1} \sum_{j \in \mathcal{N}_{i}^{k}} \max(0, (r(i, j) - k))\]</source>
          <target state="translated">\[T(k) = 1 - \frac{2}{nk (2n - 3k - 1)} \sum^n_{i=1} \sum_{j \in \mathcal{N}_{i}^{k}} \max(0, (r(i, j) - k))\]</target>
        </trans-unit>
        <trans-unit id="7faa52dada966b566ea53656a8bd94425e2b50a6" translate="yes" xml:space="preserve">
          <source>\[W^{i+1} = W^i - \epsilon \nabla {Loss}_{W}^{i}\]</source>
          <target state="translated">\ [W ^ {i + 1} = W ^ i-\ epsilon \ nabla {损失} _ {W} ^ {i} \]</target>
        </trans-unit>
        <trans-unit id="e598814b9bd2e3db200ccff196ebf646bf738ec7" translate="yes" xml:space="preserve">
          <source>\[W_k = \sum_{q=1}^k \sum_{x \in C_q} (x - c_q) (x - c_q)^T\]</source>
          <target state="translated">\ [W_k = \ sum_ {q = 1} ^ k \ sum_ {x \ in C_q}（x-c_q）（x-c_q）^ T \]</target>
        </trans-unit>
        <trans-unit id="7eb30be4ba7f05878cf003c46dfa54b35d57c946" translate="yes" xml:space="preserve">
          <source>\[X \approx X_k = U_k \Sigma_k V_k^\top\]</source>
          <target state="translated">\ [X \ approx X_k = U_k \ Sigma_k V_k ^ \ top \]</target>
        </trans-unit>
        <trans-unit id="c7c03179d6deebc1c581ff68076935c59051f655" translate="yes" xml:space="preserve">
          <source>\[X' = X V_k\]</source>
          <target state="translated">\ [X'= X V_k \]</target>
        </trans-unit>
        <trans-unit id="1b12fce875e4a7610479762a7e27b3b69634b6af" translate="yes" xml:space="preserve">
          <source>\[X^* = D^{-1/2}U^t X\text{ with }\Sigma = UDU^t\]</source>
          <target state="translated">\ [X ^ * = D ^ {-1/2} U ^ t X \ text {与} \ Sigma = UDU ^ t \]</target>
        </trans-unit>
        <trans-unit id="15463a9b27ce80c407246ad66ee390a5bc003068" translate="yes" xml:space="preserve">
          <source>\[\alpha \rho ||W||_1 + \alpha \rho ||H||_1 + \frac{\alpha(1-\rho)}{2} ||W||_{\mathrm{Fro}} ^ 2 + \frac{\alpha(1-\rho)}{2} ||H||_{\mathrm{Fro}} ^ 2\]</source>
          <target state="translated">\ [\ alpha \ rho || W || _1 + \ alpha \ rho || H || _1 + \ frac {\ alpha（1- \ rho）} {2} || W || _ {\ mathrm {Fro }} ^ 2 + \ frac {\ alpha（1- \ rho）} {2} || H || _ {\ mathrm {Fro}} ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ecb4b9fe8fc24f73a20eeac8e7781ad331ab3cc6" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||U||_1 \\ \text{subject to } &amp;amp; ||V_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{\mathrm{atoms}}\end{split}\]</source>
          <target state="translated">\ [\ begin {split}（U ^ *，V ^ *）= \ underset {U，V} {\ operatorname {arg \，min \，}}＆\ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || U || _1 \\ \ text {受}＆|| V_k || _2 = 1 \ text {对于所有} 0 \ leq k &amp;lt;n _ {\ mathrm {atoms}} \ end {拆分} \]</target>
        </trans-unit>
        <trans-unit id="113192b0908b5ad7f78568d56440ab2d30ef92e9" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||V||_1 \\ \text{subject to } &amp;amp; ||U_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{components}\end{split}\]</source>
          <target state="translated">\ [\ begin {split}（U ^ *，V ^ *）= \ underset {U，V} {\ operatorname {arg \，min \，}}＆\ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || V || _1 \\ \ text {受}＆|| U_k || _2 = 1 \ text {对于所有} 0 \ leq k &amp;lt;n_ {components} \ end {split } \]</target>
        </trans-unit>
        <trans-unit id="3136579a6b2a85a0be46315eb9cbc3ba1e261551" translate="yes" xml:space="preserve">
          <source>\[\begin{split}H_{\epsilon}(z) = \begin{cases} z^2, &amp;amp; \text {if } |z| &amp;lt; \epsilon, \\ 2\epsilon|z| - \epsilon^2, &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} H _ {\ epsilon}（z）= \ begin {cases} z ^ 2和\ text {if} | z | &amp;lt;\ epsilon，\\ 2 \ epsilon | z | -\ epsilon ^ 2和＆text {否则} \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="b46cf81ba2e913dc611a985b07c8255c093eef0a" translate="yes" xml:space="preserve">
          <source>\[\begin{split}P(v_i=1|\mathbf{h}) = \sigma(\sum_j w_{ij}h_j + b_i) \\ P(h_i=1|\mathbf{v}) = \sigma(\sum_i w_{ij}v_i + c_j)\end{split}\]</source>
          <target state="translated">\ [\ begin {split} P（v_i = 1 | \ mathbf {h}）= \ sigma（\ sum_j w_ {ij} h_j + b_i）\\ P（h_i = 1 | \ mathbf {v}）= \ sigma （\ sum_i w_ {ij} v_i + c_j）\ end {split} \]</target>
        </trans-unit>
        <trans-unit id="2a61de83e06a531ec76671fed3f61a04aabc9bf7" translate="yes" xml:space="preserve">
          <source>\[\begin{split}Z = \begin{bmatrix} R^{-1/2} U \\\\ C^{-1/2} V \end{bmatrix}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} Z = \ begin {bmatrix} R ^ {-1/2} U \\\\ C ^ {-1/2} V \ end {bmatrix} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="8fd5d1a7323dcc269879eaa3da3604856f3eb3a0" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\left\{ \begin{array}{c c l} -\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ 0 &amp;amp;\text{with probability} &amp;amp; 1 - 1 / s \\ +\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ \end{array} \right.\end{split}\]</source>
          <target state="translated">\ [\\ begin {split} \ left \ {\ begin {array} {ccl}-\ sqrt {\ frac {s} {n _ {\ text {components}}}}}＆＆1 / 2s \\ 0＆\ text {以概率}＆1-1 / s \\ + \ sqrt {\ frac {s} {n _ {\ text {components}}}}}＆＆1-2 s \\ \ end {array} \ right。\ end {分裂}\]</target>
        </trans-unit>
        <trans-unit id="240e6564ced61b1bc331dcf97a462834371b6641" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\log P(y=k | x) &amp;amp;= \log P(x | y=k) + \log P(y = k) + Cst \\ &amp;amp;= -\frac{1}{2} \log |\Sigma_k| -\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k) + \log P(y = k) + Cst,\end{split}\]</source>
          <target state="translated">\ [\ begin {split} \ log P（y = k | x）＆= \ log P（x | y = k）+ \ log P（y = k）+ Cst \\＆=-\ frac {1} {2} \ log | \ Sigma_k | -\ frac {1} {2}（x- \ mu_k）^ t \ Sigma_k ^ {-1}（x- \ mu_k）+ \ log P（y = k）+ Cst，\ end {split} \]</target>
        </trans-unit>
        <trans-unit id="cce5812b4c3daf727144c68d463e8caf50c7bfbb" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\text{D}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} \begin{cases} (y_i-\hat{y}_i)^2, &amp;amp; \text{for }p=0\text{ (Normal)}\\ 2(y_i \log(y/\hat{y}_i) + \hat{y}_i - y_i), &amp;amp; \text{for}p=1\text{ (Poisson)}\\ 2(\log(\hat{y}_i/y_i) + y_i/\hat{y}_i - 1), &amp;amp; \text{for}p=2\text{ (Gamma)}\\ 2\left(\frac{\max(y_i,0)^{2-p}}{(1-p)(2-p)}- \frac{y\,\hat{y}^{1-p}_i}{1-p}+\frac{\hat{y}^{2-p}_i}{2-p}\right), &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} \ text {D}（y，\ hat {y}）= \ frac {1} {n_ \ text {samples}} \ sum_ {i = 0} ^ {n_ \ text {samples} -1} \ begin {cases（y_i- \ hat {y} _i）^ 2，＆\ text {for} p = 0 \ text {（Normal）} \\ 2（y_i \ log（y / \ hat { y} _i）+ \ hat {y} _i-y_i）＆\ text {for} p = 1 \ text {（Poisson）} \\ 2（\ log（\ hat {y} _i / y_i）+ y_i / \ hat {y} _i-1）和\ text {for} p = 2 \ text {（Gamma）} \\ 2 \ left（\ frac {\ max（y_i，0）^ {2-p}} { （1-p）（2-p）}-\ frac {y \，\ hat {y} ^ {1-p} _i} {1-p} + \ frac {\ hat {y} ^ {2-p } _i} {2-p} \ right）和\ text {otherwise} \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="64d0ec223c44ca16fb23a31d32e7c757a5e38ba8" translate="yes" xml:space="preserve">
          <source>\[\begin{split}h_i \bot h_j | \mathbf{v} \\ v_i \bot v_j | \mathbf{h}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} h_i \ bot h_j | \ mathbf {v} \\ v_i \ bot v_j | \ mathbf {h} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="3a84b3b0085920a5dafc19e08421419f997fff14" translate="yes" xml:space="preserve">
          <source>\[\begin{split}pd_{X_S}(x_S) &amp;amp;\overset{def}{=} \mathbb{E}_{X_C}\left[ f(x_S, X_C) \right]\\ &amp;amp;= \int f(x_S, x_C) p(x_C) dx_C,\end{split}\]</source>
          <target state="translated">\ [\ begin {split} pd_ {X_S}（x_S）＆\ overset {def} {=} \ mathbb {E} _ {X_C} \ left [f（x_S，X_C）\ right] \\＆= \ int f（x_S，x_C）p（x_C）dx_C，\ end {split} \]</target>
        </trans-unit>
        <trans-unit id="6675ac3debfec98638ba1f9b136883988a6a0c0b" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i + 1)} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {（\ lambda）} = \ begin {cases] [（x_i + 1）^ \ lambda-1] / \ lambda和\ text {if} \ lambda \ neq 0，x_i \ geq 0，\\ [8pt] \ ln {（x_i + 1）}＆\ text {if} \ lambda = 0，x_i \ geq 0 \\ [8pt]-[（-x_i + 1）^ {2-\ lambda}-1] /（2-\ lambda）＆\ text {if} \ lambda \ neq 2，x_i &amp;lt;0，\\ [8pt]-\ ln（-x_i + 1）＆\ text {if} \ lambda = 2，x_i &amp;lt;0 \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="3198bb38407bb1554dc0d1959561349fcfcad349" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i) + 1} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {（\ lambda）} = \ begin {cases] [（x_i + 1）^ \ lambda-1] / \ lambda和\ text {if} \ lambda \ neq 0，x_i \ geq 0，\\ [8pt] \ ln {（x_i）+ 1}和\​​ text {if} \ lambda = 0，x_i \ geq 0 \\ [8pt]-[（-x_i + 1）^ {2-\ lambda}-1] /（2-\ lambda）＆\ text {if} \ lambda \ neq 2，x_i &amp;lt;0，\\ [8pt]-\ ln（-x_i + 1）＆\ text {if} \ lambda = 2，x_i &amp;lt;0 \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="dc87ecfd4801e13673bdd8bb567f720368f1d00c" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} \dfrac{x_i^\lambda - 1}{\lambda} &amp;amp; \text{if } \lambda \neq 0, \\[8pt] \ln{(x_i)} &amp;amp; \text{if } \lambda = 0, \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {（\ lambda）} = \ begin {cases} \ dfrac {x_i ^ \ lambda-1} {\ lambda}和\ text {if} \ lambda \ neq 0，\\ [ 8pt] \ ln {（x_i）}和\ text {if} \ lambda = 0，\ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="4537e01f403cf1db6a1704e87011ad05c2900083" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</source>
          <target state="translated">\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</target>
        </trans-unit>
        <trans-unit id="a73d653ad8356da32b64d5107d59910b4574da8f" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{samples}}{n_{subsamples}}\]</source>
          <target state="translated">\[\binom{n_{samples}}{n_{subsamples}}\]</target>
        </trans-unit>
        <trans-unit id="ac1ff82d2bb9be7a891279ff19e58ef9606ac1e2" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac {1}{\alpha (t_0 + t)}\]</source>
          <target state="translated">\ [\ eta ^ {（t）} = \ frac {1} {\ alpha（t_0 + t）} \]</target>
        </trans-unit>
        <trans-unit id="94fa32af9a54520431e5e0db6110f5f4be3adb89" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac{eta_0}{t^{power\_t}}\]</source>
          <target state="translated">\ [\ eta ^ {（t）} = \ frac {eta_0} {t ^ {power \ _t}} \]</target>
        </trans-unit>
        <trans-unit id="5914d3325cfa1135b23fa0bc1a30756771d61bd1" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c (\text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="translated">\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c (\text{AUC}(j | k) + \text{AUC}(k | j))\]</target>
        </trans-unit>
        <trans-unit id="23f7d8421e9f7d86dc62315499303963443744dd" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c p(j \cup k)( \text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="translated">\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c p(j \cup k)( \text{AUC}(j | k) + \text{AUC}(k | j))\]</target>
        </trans-unit>
        <trans-unit id="0ab74fa9a47831af7bc26708f2eb4bb36eb7c478" translate="yes" xml:space="preserve">
          <source>\[\gamma_m = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) - \gamma \frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)})\]</source>
          <target state="translated">\ [\ gamma_m = \ arg \ min _ {\ gamma} \ sum_ {i = 1} ^ {n} L（y_i，F_ {m-1}（x_i）-\ gamma \ frac {\ partial L（y_i，F_ {m-1}（x_i））} {\ partial F_ {m-1}（x_i）}）\]</target>
        </trans-unit>
        <trans-unit id="03488d7aa371e338e3a792b1ee0314e7750d1c23" translate="yes" xml:space="preserve">
          <source>\[\hat{K} = \mathrm{argmin}_K \big( \mathrm{tr} S K - \mathrm{log} \mathrm{det} K + \alpha \|K\|_1 \big)\]</source>
          <target state="translated">\ [\ hat {K} = \ mathrm {argmin} _K \ big（\ mathrm {tr} SK-\ mathrm {log} \ mathrm {det} K + \ alpha \ | K \ | _1 \ big）\]</target>
        </trans-unit>
        <trans-unit id="9d564db2d54a230e005c20037b5a37d139fd79dd" translate="yes" xml:space="preserve">
          <source>\[\hat{\theta}_{yi} = \frac{ N_{yi} + \alpha}{N_y + \alpha n}\]</source>
          <target state="translated">\ [\ hat {\ theta} _ {yi} = \ frac {N_ {yi} + \ alpha} {N_y + \ alpha n} \]</target>
        </trans-unit>
        <trans-unit id="c11c6e06d183bd2451c8cb2b3112bec0b1bc1ee8" translate="yes" xml:space="preserve">
          <source>\[\hat{c} = \arg\min_c \sum_{i} t_i w_{ci}\]</source>
          <target state="translated">\ [\ hat {c} = \ arg \ min_c \ sum_ {i} t_i w_ {ci} \]</target>
        </trans-unit>
        <trans-unit id="0d0878697ede61cc2d8e8a17d350fedc4b3570ca" translate="yes" xml:space="preserve">
          <source>\[\hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}\]</source>
          <target state="translated">\ [\ hat {w} _i = \ frac {w_i} {\ sum_j {1（y_j = y_i）w_j}} \\]</target>
        </trans-unit>
        <trans-unit id="2a9f64bd46b89b26f87a73f822e103df8215fc20" translate="yes" xml:space="preserve">
          <source>\[\hat{y_i} = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)\]</source>
          <target state="translated">\[\hat{y_i} = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)\]</target>
        </trans-unit>
        <trans-unit id="c4cf751319dcee1f0c7d13ac626ea9ed7a5bb6a9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, X) = h(Xw).\]</source>
          <target state="translated">\[\hat{y}(w, X) = h(Xw).\]</target>
        </trans-unit>
        <trans-unit id="463125ace329bbcbe2634beaad2a87856ea8f696" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p\]</source>
          <target state="translated">\ [\ hat {y}（w，x）= w_0 + w_1 x_1 + ... + w_p x_p \]</target>
        </trans-unit>
        <trans-unit id="d7104cc52e967d53cc9bb7db2f89101bc8dd84a8" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2\]</source>
          <target state="translated">\ [\ hat {y}（w，x）= w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1 ^ 2 + w_5 x_2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="658832cb765efda37a6b6c541d565e8e7abeaf9e" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2\]</source>
          <target state="translated">\ [\ hat {y}（w，x）= w_0 + w_1 x_1 + w_2 x_2 \]</target>
        </trans-unit>
        <trans-unit id="e16dea6416d3f9e94f0e5c1b50c7914fc96699e9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="translated">\ [\ hat {y}（w，x）= w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5 \]</target>
        </trans-unit>
        <trans-unit id="1ef6664dd57ac85f53b0ac082bd4ac87b3d1bc48" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="translated">\[\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</target>
        </trans-unit>
        <trans-unit id="7ee9d5e754305261d56bc754281eac2d4bc47e43" translate="yes" xml:space="preserve">
          <source>\[\kappa = (p_o - p_e) / (1 - p_e)\]</source>
          <target state="translated">\ [\ kappa =（p_o-p_e）/（1-p_e）\]</target>
        </trans-unit>
        <trans-unit id="167a98e04ab5b59774a90feac289ea3a97af6579" translate="yes" xml:space="preserve">
          <source>\[\log P(v) = \log \sum_h e^{-E(v, h)} - \log \sum_{x, y} e^{-E(x, y)}\]</source>
          <target state="translated">\ [\ log P（v）= \ log \ sum_h e ^ {-E（v，h）}-\ log \ sum_ {x，y} e ^ {-E（x，y）} \]</target>
        </trans-unit>
        <trans-unit id="3615a8591ff789e7148f8d4eaedd232d6f832187" translate="yes" xml:space="preserve">
          <source>\[\log P(y=k | x) = -\frac{1}{2} (x-\mu_k)^t \Sigma^{-1} (x-\mu_k) + \log P(y = k) + Cst.\]</source>
          <target state="translated">\[\log P(y=k | x) = -\frac{1}{2} (x-\mu_k)^t \Sigma^{-1} (x-\mu_k) + \log P(y = k) + Cst.\]</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
