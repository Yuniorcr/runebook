<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="zh-CN" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="8b02ae7bd0e5dc3ad9885f92e92e8dfc0759e655" translate="yes" xml:space="preserve">
          <source>Nearest neighbor and the curse of dimensionality</source>
          <target state="translated">最近的邻居和维度的诅咒</target>
        </trans-unit>
        <trans-unit id="5db95950f32dda99cc2cb722bb90ec8e1106f00f" translate="yes" xml:space="preserve">
          <source>Needless to say, the cross-validation involved in Platt scaling is an expensive operation for large datasets. In addition, the probability estimates may be inconsistent with the scores, in the sense that the &amp;ldquo;argmax&amp;rdquo; of the scores may not be the argmax of the probabilities. (E.g., in binary classification, a sample may be labeled by &lt;code&gt;predict&lt;/code&gt; as belonging to a class that has probability &amp;lt;&amp;frac12; according to &lt;code&gt;predict_proba&lt;/code&gt;.) Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">不用说，Platt缩放所涉及的交叉验证对于大型数据集而言是一项昂贵的操作。另外，在分数的&amp;ldquo; argmax&amp;rdquo;可能不是概率的argmax的意义上，概率估计可能与分数不一致。 （例如，在二进制分类中，根据 &lt;code&gt;predict_proba&lt;/code&gt; ，样本可能被 &lt;code&gt;predict&lt;/code&gt; 标记为属于概率&amp;lt;1/2的类别。）普氏方法也存在理论问题。如果需要的置信度，但是这些不必是概率，那么最好是集 &lt;code&gt;probability=False&lt;/code&gt; 和使用 &lt;code&gt;decision_function&lt;/code&gt; 代替 &lt;code&gt;predict_proba&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5d2390b5dea0fabfaec001753e4e7ab98989a540" translate="yes" xml:space="preserve">
          <source>Neighborhoods are restricted the points at a distance lower than radius.</source>
          <target state="translated">邻域是限制在距离小于半径的点。</target>
        </trans-unit>
        <trans-unit id="71b4c3c0886885b3bdb78dd9feb31a745b98d96e" translate="yes" xml:space="preserve">
          <source>Neighbors-based classification is a type of &lt;em&gt;instance-based learning&lt;/em&gt; or &lt;em&gt;non-generalizing learning&lt;/em&gt;: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</source>
          <target state="translated">邻居为基础的分类是一类&lt;em&gt;基于实例的学习&lt;/em&gt;或&lt;em&gt;不学习概括&lt;/em&gt;：它并不试图构建一个通用的内部模型，只是训练数据的存储情况。分类是根据每个点的最近邻居的简单多数票来计算的：向查询点分配数据类，该数据类在该点的最近邻居中具有最多的代表。</target>
        </trans-unit>
        <trans-unit id="f556f4d2d6fabe3a4b78772a04d1d08bf693d3a1" translate="yes" xml:space="preserve">
          <source>Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</source>
          <target state="translated">基于邻域的回归可以用于数据标签是连续而非离散变量的情况。分配给一个查询点的标签是根据其最近邻居标签的平均值计算的。</target>
        </trans-unit>
        <trans-unit id="f17c48105fdd248ad2de1f1ac3f1cabb43429cec" translate="yes" xml:space="preserve">
          <source>Nested cross-validation</source>
          <target state="translated">嵌套交叉验证</target>
        </trans-unit>
        <trans-unit id="029453980f1f56140cec84a6516b88cf4da43353" translate="yes" xml:space="preserve">
          <source>Nested versus non-nested cross-validation</source>
          <target state="translated">嵌套式与非嵌套式交叉验证</target>
        </trans-unit>
        <trans-unit id="8c7edd0d2fdd43b38d35974fe3274794c4023842" translate="yes" xml:space="preserve">
          <source>Never unpickle untrusted data as it could lead to malicious code being executed upon loading.</source>
          <target state="translated">千万不要解开不受信任的数据,因为这可能导致恶意代码在加载时被执行。</target>
        </trans-unit>
        <trans-unit id="5a7c69a057920dae02f0ceb2f6458cca465cc67b" translate="yes" xml:space="preserve">
          <source>New data point to be inserted into the LSH Forest.</source>
          <target state="translated">将插入LSH森林的新数据点。</target>
        </trans-unit>
        <trans-unit id="48ff6f532fccde3a69a322cc1151c107ad295ffd" translate="yes" xml:space="preserve">
          <source>New data to predict.</source>
          <target state="translated">新的数据来预测。</target>
        </trans-unit>
        <trans-unit id="e461db7b42b4e1d723a59598bcca510859163aef" translate="yes" xml:space="preserve">
          <source>New data to transform.</source>
          <target state="translated">新的数据要转化。</target>
        </trans-unit>
        <trans-unit id="329a026b697f0ae2b6fcf5ede884e3254ea37650" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">新数据,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="68d214f5c1780f5e1075a93cc2054064839f0ca3" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features. All values of X must be strictly greater than &amp;ldquo;-skewedness&amp;rdquo;.</source>
          <target state="translated">新数据，其中样本数量中的n_samples个，要素数量中的n_features个。X的所有值都必须严格大于&amp;ldquo;偏斜度&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="6e6bacb37aec6214dc7bc345656e9fc6be9d8645" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">新数据,其中n_samples为样本数,n_components为成分数。</target>
        </trans-unit>
        <trans-unit id="9774ac05294602db6164b128c08e5838d8dd2c30" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">新数据,其中n_samples为样本数,n_features为特征数。</target>
        </trans-unit>
        <trans-unit id="2cec1d1d13a623e2cead9e687223c0b43410804e" translate="yes" xml:space="preserve">
          <source>New data.</source>
          <target state="translated">新数据:</target>
        </trans-unit>
        <trans-unit id="2dcde8ec0560b6129ac7ceb94e6b76437cebda2e" translate="yes" xml:space="preserve">
          <source>New in version 0.10.</source>
          <target state="translated">0.10版本的新内容。</target>
        </trans-unit>
        <trans-unit id="b2a489d3a2d4dc51668c693a83253f531fff88d5" translate="yes" xml:space="preserve">
          <source>New in version 0.16: If the input is sparse, the output will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;. Else, output type is the same as the input type.</source>
          <target state="translated">版本0.16中的新增功能：如果输入稀疏，则输出将是 &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; 。否则，输出类型与输入类型相同。</target>
        </trans-unit>
        <trans-unit id="60b69c65bf1a3241e15d0d894ba32eab25d7cdd7" translate="yes" xml:space="preserve">
          <source>New in version 0.17.</source>
          <target state="translated">0.17版本的新内容。</target>
        </trans-unit>
        <trans-unit id="dc470080fe5f5c357c2ad73809b92faa7362d9a9" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="abf887094b036a443ef8f8f3b6efb216ee34cd24" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6b2ff85ecc2a1a01962dd33b1e34753285ca0790" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;alpha&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">版本0.17中的新功能：在坐标下降求解器中使用的&lt;em&gt;Alpha&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="6808fe2d57e6aeef92c976187ce0a06abf1ebec1" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;cd&lt;/em&gt;坐标下降法可提高速度。</target>
        </trans-unit>
        <trans-unit id="7b66bf990e4010a15f9d64925c054de502637170" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;class_weight=&amp;rsquo;balanced&amp;rsquo;&lt;/em&gt;</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;class_weight ='balanced'&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ea86dc59df4308dd8eeb6d9e2ae15359239ba528" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_max_&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;data_max_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="1f6c1c10d870e8e7d70fedf31cf3a9ee8c7d746d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_min_&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;data_min_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e853c35f6d282db32a11152441252fd53da7f57f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_range_&lt;/em&gt;</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;data_range_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="edb88b5a13c967ddfdc52fb30c87cf6cd8e55cef" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;decision_function_shape=&amp;rsquo;ovr&amp;rsquo;&lt;/em&gt; is recommended.</source>
          <target state="translated">0.17版中的新功能：建议&lt;em&gt;Decision_function_shape ='ovr'&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="18bd409dbab688800dc645ecf6dc2d319b6dc274" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;lasso_cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;lasso_cd&lt;/em&gt;坐标下降方法可提高速度。</target>
        </trans-unit>
        <trans-unit id="5c5696058be6bc7e1f1d8d04441e99d3b67a5a9d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;minmax_scale&lt;/em&gt; function interface to &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">在新版本0.17：&lt;em&gt;minmax_scale&lt;/em&gt;功能接口&lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="61491e91a5cc882c8d0472b81b77bf74b7ea4e3d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;presort&lt;/em&gt; parameter.</source>
          <target state="translated">版本0.17中的新功能：&lt;em&gt;预排序&lt;/em&gt;参数。</target>
        </trans-unit>
        <trans-unit id="b2b731bdc9bf8dfc47673f8abfcc6c2c7f1f838c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;random_state&lt;/em&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;random_state&lt;/em&gt;支持随机平均梯度。</target>
        </trans-unit>
        <trans-unit id="727acdfec60aa8d5fe01b0fab35aa36437da02bb" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to Classifier.</source>
          <target state="translated">0.17版中的新功能：对&lt;em&gt;classifier的sample_weight&lt;/em&gt;支持。</target>
        </trans-unit>
        <trans-unit id="6a9e702e6dde8c5e083d3061949d66f0c1cd0a95" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to LogisticRegression.</source>
          <target state="translated">0.17版中的新功能：对LogisticRegression的&lt;em&gt;sample_weight&lt;/em&gt;支持。</target>
        </trans-unit>
        <trans-unit id="8bf7c72c906a46e4bafab411161accafb9f3258f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt;</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;scale_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="26b994b5337cbc66d9e87cecbe064dc645c2d9c5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt; attribute.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;scale_&lt;/em&gt;属性。</target>
        </trans-unit>
        <trans-unit id="acaea6c314c50f12e63f6a31caa95dae9a93cb16" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;shuffle&lt;/em&gt; parameter used in the Coordinate Descent solver.</source>
          <target state="translated">版本0.17中的新增功能：在坐标下降求解器中使用的&lt;em&gt;洗牌&lt;/em&gt;参数。</target>
        </trans-unit>
        <trans-unit id="3c9ad8ece37a0ad66c0695ab197f051fc5c4f74b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; constructor parameter.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;warm_start&lt;/em&gt;构造函数参数。</target>
        </trans-unit>
        <trans-unit id="5d7ee9d78ae5139184086665f72ad9adc489e60f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; to support &lt;em&gt;lbfgs&lt;/em&gt;, &lt;em&gt;newton-cg&lt;/em&gt;, &lt;em&gt;sag&lt;/em&gt;, &lt;em&gt;saga&lt;/em&gt; solvers.</source>
          <target state="translated">0.17版中的新功能：&lt;em&gt;warm_start&lt;/em&gt;支持&lt;em&gt;lbfgs&lt;/em&gt;，&lt;em&gt;newton-cg&lt;/em&gt;，&lt;em&gt;sag&lt;/em&gt;和&lt;em&gt;saga&lt;/em&gt;求解器。</target>
        </trans-unit>
        <trans-unit id="6005792b774eeae7e9401b712800c9c602a22ebe" translate="yes" xml:space="preserve">
          <source>New in version 0.17: A function &lt;em&gt;label_ranking_loss&lt;/em&gt;</source>
          <target state="translated">版本0.17中的新功能：函数&lt;em&gt;label_ranking_loss&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e93da6946e01b1e23cbc1e7009a23425c993a384" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Approximate optimization &lt;em&gt;method&lt;/em&gt; via the Barnes-Hut.</source>
          <target state="translated">版本0.17中的新功能：通过Barnes-Hut的近似优化&lt;em&gt;方法&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="9365f66e13f87cb3bbf8aaf0ec5863c643029aff" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Coordinate Descent solver.</source>
          <target state="translated">0.17版本新增:坐标下降求解器。</target>
        </trans-unit>
        <trans-unit id="c589f3a156d1562e5e258c1483b29eaa7a3bb671" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Dummy Classifier now supports prior fitting strategy using parameter &lt;em&gt;prior&lt;/em&gt;.</source>
          <target state="translated">在新版本0.17：虚拟分类现在支持使用参数之前安装的策略&lt;em&gt;之前&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="4c1ba1a9df4e3f1eda2057a3d8675352ba0c6105" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Gaussian Naive Bayes supports fitting with &lt;em&gt;sample_weight&lt;/em&gt;.</source>
          <target state="translated">版本0.17中的新功能：高斯朴素贝叶斯支持使用&lt;em&gt;sample_weight进行&lt;/em&gt;拟合。</target>
        </trans-unit>
        <trans-unit id="b94e1008bb6bd8880b48f9c93c89015eb39cf414" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Parallel Execution using &lt;em&gt;n_jobs&lt;/em&gt;.</source>
          <target state="translated">0.17版中的新功能：使用&lt;em&gt;n_jobs&lt;/em&gt;并行执行。</target>
        </trans-unit>
        <trans-unit id="56295350a01a04673ce10a1274f3f2850857660f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Regularization parameter &lt;em&gt;l1_ratio&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">版本0.17中的新增功能：在坐标下降求解器中使用的正则化参数&lt;em&gt;l1_ratio&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="bfb15daea388e7bc4652a64e3ee368ec3ef32e45" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Stochastic Average Gradient descent solver.</source>
          <target state="translated">0.17版本新增:随机平均梯度下降求解器。</target>
        </trans-unit>
        <trans-unit id="90ee93ad6b0e53eed26b86779c90b9633cb9848b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: class_weight == &amp;lsquo;balanced&amp;rsquo;</source>
          <target state="translated">0.17版中的新功能：class_weight =='balanced'</target>
        </trans-unit>
        <trans-unit id="db422a34a0885d2d1033db36affb13affc0d2065" translate="yes" xml:space="preserve">
          <source>New in version 0.17: metric &lt;em&gt;precomputed&lt;/em&gt; to accept precomputed sparse matrix.</source>
          <target state="translated">版本0.17中的新功能：度量已&lt;em&gt;预先计算&lt;/em&gt;为接受预先计算的稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="545f1d599ea32d73544f4951073f7ce5e1f64bf6" translate="yes" xml:space="preserve">
          <source>New in version 0.17: optional parameter &lt;em&gt;presort&lt;/em&gt;.</source>
          <target state="translated">版本0.17中的新功能：可选参数&lt;em&gt;presort&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="1c0b7964a491c4c8234983325c356450f442446c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;code&gt;dense_output&lt;/code&gt; for dense output.</source>
          <target state="translated">版本0.17中的新功能：用于密集输出的参数 &lt;code&gt;dense_output&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="46c6419997a8eb39c61c2c50456a363282489838" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;class_weight&lt;/em&gt; to automatically weight samples.</source>
          <target state="translated">0.17版中的新功能：参数&lt;em&gt;class_weight&lt;/em&gt;可自动对样本加权。</target>
        </trans-unit>
        <trans-unit id="e8cbf38ab0cedfa95f7fc33391f9602285bd6e17" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;drop_intermediate&lt;/em&gt;.</source>
          <target state="translated">0.17版中的新功能：参数&lt;em&gt;drop_intermediate&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="960c43bc8538ca35574a01cc68a5f2b510105d22" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;multilabel&lt;/em&gt; to support multilabel datasets.</source>
          <target state="translated">0.17版中的新功能：参数&lt;em&gt;multilabel&lt;/em&gt;支持多标签数据集。</target>
        </trans-unit>
        <trans-unit id="3788b38f2b10aab217952de3365bf7b88f170f8d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;n_iter_without_progress&lt;/em&gt; to control stopping criteria.</source>
          <target state="translated">版本0.17中的新功能：参数&lt;em&gt;n_iter_without_progress&lt;/em&gt;用于控制停止条件。</target>
        </trans-unit>
        <trans-unit id="8db0c53c524e84f302dbc1a0dbd534321460f08f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to LinearRegression.</source>
          <target state="translated">0.17版中的新功能：LinearRegression支持参数&lt;em&gt;sample_weight&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="2a05312b3a418ca739af1c2a1750981f3df80101" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter to allow &lt;em&gt;sparse&lt;/em&gt; output.</source>
          <target state="translated">0.17版中的新功能：允许&lt;em&gt;稀疏&lt;/em&gt;输出的参数。</target>
        </trans-unit>
        <trans-unit id="8550f8dcfdefc5ee2595ff5a932287ae10047927" translate="yes" xml:space="preserve">
          <source>New in version 0.18.</source>
          <target state="translated">0.18版本的新内容。</target>
        </trans-unit>
        <trans-unit id="bc1978fea309e92ee1923ea481a6fd1eab915379" translate="yes" xml:space="preserve">
          <source>New in version 0.18.0.</source>
          <target state="translated">0.18.0版本的新内容。</target>
        </trans-unit>
        <trans-unit id="11462cefb53316ba0a8e0880815bfa04af36466b" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Mean Absolute Error (MAE) criterion.</source>
          <target state="translated">0.18版本新增:平均绝对误差(MAE)标准。</target>
        </trans-unit>
        <trans-unit id="f3588d83291a2be20994392c7201429910c5a8e9" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Stochastic Average Gradient descent solver for &amp;lsquo;multinomial&amp;rsquo; case.</source>
          <target state="translated">版本0.18中的新功能：用于&amp;ldquo;多项式&amp;rdquo;情况的随机平均梯度下降求解器。</target>
        </trans-unit>
        <trans-unit id="0eb4d3b4907b28878c6666a16cc5abd9e36f4f00" translate="yes" xml:space="preserve">
          <source>New in version 0.19.</source>
          <target state="translated">0.19版本的新内容。</target>
        </trans-unit>
        <trans-unit id="e10489dae5e0fb6aa174b77a26bd312889388c1d" translate="yes" xml:space="preserve">
          <source>New in version 0.19: Multiplicative Update solver.</source>
          <target state="translated">0.19版本新增:乘法更新求解器。</target>
        </trans-unit>
        <trans-unit id="c260a9e7caaac82377fee1bfeace2cf2272b4b1a" translate="yes" xml:space="preserve">
          <source>New in version 0.19: SAGA solver.</source>
          <target state="translated">0.19版本新增:SAGA解算器。</target>
        </trans-unit>
        <trans-unit id="d56c2d84411d9a6c91bdf6681efc0b4e653d1de5" translate="yes" xml:space="preserve">
          <source>New in version 0.19: l1 penalty with SAGA solver (allowing &amp;lsquo;multinomial&amp;rsquo; + L1)</source>
          <target state="translated">0.19版中的新功能：SAGA求解器的惩罚为l1（允许&amp;ldquo;多项式&amp;rdquo; + L1）</target>
        </trans-unit>
        <trans-unit id="69d687c70a1657bfe591a19056b06b9f07dd4b5e" translate="yes" xml:space="preserve">
          <source>New in version 0.19: parameter &lt;em&gt;average&lt;/em&gt; to use weights averaging in SGD</source>
          <target state="translated">版本0.19中的新功能：参数&lt;em&gt;平均值&lt;/em&gt;使用SGD中的权重平均值</target>
        </trans-unit>
        <trans-unit id="e6570e8764c255a027de40e9e3eb2d1c722d495c" translate="yes" xml:space="preserve">
          <source>New in version 0.20.</source>
          <target state="translated">0.20版本的新内容。</target>
        </trans-unit>
        <trans-unit id="92da9b59ee8f1aee40e76bd7e7f9a69e15158836" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;behaviour&lt;/code&gt; is added in 0.20 for back-compatibility purpose.</source>
          <target state="translated">0.20版中的新功能：在0.20中添加了 &lt;code&gt;behaviour&lt;/code&gt; ，以实现向后兼容。</target>
        </trans-unit>
        <trans-unit id="89ff3bd96af64e1a70d0744f65ccf966040b095d" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">0.20版中的新功能： &lt;code&gt;force_all_finite&lt;/code&gt; 接受字符串 &lt;code&gt;'allow-nan'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1468919e56b56c4ded7ab6dba66d158a1002d5be" translate="yes" xml:space="preserve">
          <source>New in version 0.20: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to BayesianRidge.</source>
          <target state="translated">0.20版中的新功能：BayesianRidge支持参数&lt;em&gt;sample_weight&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="7c256855a0d81868bca650e3f1d5676a1f0ae5da" translate="yes" xml:space="preserve">
          <source>New in version 0.20: strategy=&amp;rdquo;constant&amp;rdquo; for fixed value imputation.</source>
          <target state="translated">0.20版中的新功能：对于固定值插补，strategy =&amp;ldquo; constant&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="3dcb523c8b35ef7bba188a1b72a37583d73585c0" translate="yes" xml:space="preserve">
          <source>New in version 1.7.0.</source>
          <target state="translated">1.7.0版本的新内容。</target>
        </trans-unit>
        <trans-unit id="58fbaea601eebe84b9d8f8508a33c9a4b3025541" translate="yes" xml:space="preserve">
          <source>New to Scientific Python?</source>
          <target state="translated">科学Python的新手?</target>
        </trans-unit>
        <trans-unit id="9f6a58e9ea6f2ce3d4a15836e22f7c6b8aed6e50" translate="yes" xml:space="preserve">
          <source>Next we create 10 classifier chains. Each classifier chain contains a logistic regression model for each of the 14 labels. The models in each chain are ordered randomly. In addition to the 103 features in the dataset, each model gets the predictions of the preceding models in the chain as features (note that by default at training time each model gets the true labels as features). These additional features allow each chain to exploit correlations among the classes. The Jaccard similarity score for each chain tends to be greater than that of the set independent logistic models.</source>
          <target state="translated">接下来我们创建10条分类器链。每条分类器链都包含了14个标签中每个标签的逻辑回归模型。每个链中的模型是随机排序的。除了数据集中的103个特征外,每个模型都会得到链中前几个模型的预测作为特征(注意在训练时默认情况下,每个模型都会得到真实标签作为特征)。这些额外的特征允许每个链利用类之间的相关性。每个链的Jaccard相似度得分往往大于集合独立逻辑模型的相似度得分。</target>
        </trans-unit>
        <trans-unit id="1ae340c010af24c68842322aa72c1a3f11d7dacf" translate="yes" xml:space="preserve">
          <source>Next, let&amp;rsquo;s compare the accuracy of &lt;code&gt;SVC&lt;/code&gt; and &lt;code&gt;most_frequent&lt;/code&gt;:</source>
          <target state="translated">接下来，让我们比较 &lt;code&gt;SVC&lt;/code&gt; 和 &lt;code&gt;most_frequent&lt;/code&gt; 的准确性：</target>
        </trans-unit>
        <trans-unit id="cedfa60674e3afd543975ecc551b601711fc3043" translate="yes" xml:space="preserve">
          <source>Nick Street</source>
          <target state="translated">尼克街</target>
        </trans-unit>
        <trans-unit id="91b4478e43e149a2b1b071a76d13f7593530f726" translate="yes" xml:space="preserve">
          <source>No measurement errors, only modelling errors (fitting a sine with a polynomial)</source>
          <target state="translated">没有测量误差,只有建模误差(用多项式拟合正弦)。</target>
        </trans-unit>
        <trans-unit id="ea249cedbd757dbfa8a8d6da523734c90b706a5c" translate="yes" xml:space="preserve">
          <source>No-op.</source>
          <target state="translated">No-op.</target>
        </trans-unit>
        <trans-unit id="91eb5693ecb00a7deb087fb78e26bb4414167d8c" translate="yes" xml:space="preserve">
          <source>Noisy (non informative) features are added to the iris data and univariate feature selection is applied. For each feature, we plot the p-values for the univariate feature selection and the corresponding weights of an SVM. We can see that univariate feature selection selects the informative features and that these have larger SVM weights.</source>
          <target state="translated">在虹膜数据中添加有噪声(非信息)特征,并应用单变量特征选择。对于每个特征,我们绘制了单变量特征选择的p值和SVM的相应权重。我们可以看到,单变量特征选择选择了信息性特征,而且这些特征的SVM权重较大。</target>
        </trans-unit>
        <trans-unit id="79474361fd46a8f4ede8053ea7e6b01fe3e41cb6" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{kl}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">非度量&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;专注于数据的排序。如果\（S_ {ij} &amp;lt;S_ {kl} \），则嵌入应强制执行\（d_ {ij} &amp;lt;d_ {jk} \）。一个简单的强制算法是在\（S_ {ij} \）上使用\（d_ {ij} \）的单调回归，以相同顺序产生视差\（\ hat {d} _ {ij} \）为\（S_ {ij} \）。</target>
        </trans-unit>
        <trans-unit id="cde06657a13db59e2826469e9066556199cf0756" translate="yes" xml:space="preserve">
          <source>Non-Negative Matrix Factorization (NMF)</source>
          <target state="translated">非负矩阵分解(NMF)</target>
        </trans-unit>
        <trans-unit id="68976e33a3c8d43b10cc9525f441a8468ba55fa6" translate="yes" xml:space="preserve">
          <source>Non-adjusted measures such as the V-Measure show a dependency between the number of clusters and the number of samples: the mean V-Measure of random labeling increases significantly as the number of clusters is closer to the total number of samples used to compute the measure.</source>
          <target state="translated">非调整措施,如V-Measure,显示出聚类数量和样本数量之间的依赖性:随机标签的平均V-Measure随着聚类数量接近用于计算措施的样本总数而显著增加。</target>
        </trans-unit>
        <trans-unit id="f88076515287321d1c6a383215ea60241a35e283" translate="yes" xml:space="preserve">
          <source>Non-categorical features are always stacked to the right of the matrix.</source>
          <target state="translated">非分类特征总是堆积在矩阵的右边。</target>
        </trans-unit>
        <trans-unit id="24a06b494b2c3f21a83a9f0f9fdd0eb49c7e8dca" translate="yes" xml:space="preserve">
          <source>Non-deterministic iterable over random candidate combinations for hyper- parameter search. If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">超参数搜索的非确定性可迭代过随机候选组合。如果所有的参数都是以列表的形式出现,则采用无替换的抽样方式。如果至少有一个参数是以分布形式给出的,则采用带替换的抽样。对于连续参数,强烈建议使用连续分布。</target>
        </trans-unit>
        <trans-unit id="aed22ef611faa3f82d0b12f8491e5be1b5315c9c" translate="yes" xml:space="preserve">
          <source>Non-flat geometry clustering is useful when the clusters have a specific shape, i.e. a non-flat manifold, and the standard euclidean distance is not the right metric. This case arises in the two top rows of the figure above.</source>
          <target state="translated">非平面几何聚类在聚类具有特定形状,即非平面歧面,而标准欧氏距离不是正确的度量时,是很有用的。这种情况出现在上图最上面的两行中。</target>
        </trans-unit>
        <trans-unit id="d81a98cb7a8247dec56f2cf029b08c2754ab68be" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes</source>
          <target state="translated">非平坦的几何形状,不均匀的群集大小。</target>
        </trans-unit>
        <trans-unit id="7b7727887cb8285fcb9cde529e76207a2b5daf47" translate="yes" xml:space="preserve">
          <source>Non-linear SVM</source>
          <target state="translated">非线性SVM</target>
        </trans-unit>
        <trans-unit id="71ce2ef9edaad67f892b761574c731b5860fa36a" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through Isometric Mapping</source>
          <target state="translated">通过等距映射减少非线性尺寸</target>
        </trans-unit>
        <trans-unit id="ca7d812e2ac6b7f89b19c50d5270fc422c0be019" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through the use of kernels (see &lt;a href=&quot;../metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt;).</source>
          <target state="translated">通过使用内核减少非线性维数（请参阅&lt;a href=&quot;../metrics#metrics&quot;&gt;成对度量，亲和力和内核&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="69451865a7cd1607229864b3445a0d944d36c962" translate="yes" xml:space="preserve">
          <source>Non-negative Matrix Factorization is applied with two different objective functions: the Frobenius norm, and the generalized Kullback-Leibler divergence. The latter is equivalent to Probabilistic Latent Semantic Indexing.</source>
          <target state="translated">非负矩阵因子化应用了两个不同的目标函数:Frobenius norm,和广义Kullback-Leibler分歧。后者相当于概率性潜在语义索引(Probabilistic Latent Semantic Indexing)。</target>
        </trans-unit>
        <trans-unit id="049d9a61285421f1af788bdccc4c4d917a5eaaf1" translate="yes" xml:space="preserve">
          <source>Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.</source>
          <target state="translated">在协方差的对角线上加上非负的正则化。可以保证协方差矩阵都是正值。</target>
        </trans-unit>
        <trans-unit id="e703a00863d9d81a02bf7dd7a3e8359867bf5db3" translate="yes" xml:space="preserve">
          <source>Non-negativity: d(x, y) &amp;gt;= 0</source>
          <target state="translated">非负性：d（x，y）&amp;gt; = 0</target>
        </trans-unit>
        <trans-unit id="8ae68d0948137da9bc3c21e9e27af7e4326ecb8c" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that assign all classes members to the same clusters are still complete:</source>
          <target state="translated">非完美的标签,将所有的类成员分配到同一个簇中,仍然是完整的。</target>
        </trans-unit>
        <trans-unit id="3eebc1d955c5491410d251396ee4489d9155e3cb" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that further split classes into more clusters can be perfectly homogeneous:</source>
          <target state="translated">非完美的标签,进一步将类分成更多的簇,可以是完全同质的。</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="a7d85d18152a49d1da74509ce25fde6fe11019f7" translate="yes" xml:space="preserve">
          <source>None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs</source>
          <target state="translated">无,在这种情况下,所有作业都会被立即创建和生成。对于轻量级和快速运行的作业,可使用此选项,以避免因按需生成作业而造成延迟。</target>
        </trans-unit>
        <trans-unit id="bbd7e8e517d8f43bda3aa20760641b5d7e8f9cfa" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross validation,</source>
          <target state="translated">无,使用默认的3倍交叉验证。</target>
        </trans-unit>
        <trans-unit id="888271bd46afcca7669b4e3985d515e3c7e7f9d8" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross-validation,</source>
          <target state="translated">无,使用默认的3倍交叉验证。</target>
        </trans-unit>
        <trans-unit id="701ee91f692f57554848e1c6f0edff54e4f7d839" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation</source>
          <target state="translated">无,使用高效的留一漏一交叉验证。</target>
        </trans-unit>
        <trans-unit id="64b167835d86e0f7a116b1ea8c9009b09567d9bf" translate="yes" xml:space="preserve">
          <source>None: no shrinkage (default).</source>
          <target state="translated">无:无收缩(默认)。</target>
        </trans-unit>
        <trans-unit id="147e773e8ccd784cf7c8200779acc5978ecfc7ee" translate="yes" xml:space="preserve">
          <source>Nonflavanoid Phenols:</source>
          <target state="translated">非黄酮类酚类。</target>
        </trans-unit>
        <trans-unit id="906dd4b97159051d3691e718b04ffdc7a18ebb83" translate="yes" xml:space="preserve">
          <source>Nonflavanoid phenols</source>
          <target state="translated">非黄酮类酚类</target>
        </trans-unit>
        <trans-unit id="c5cf58c1ab6a436b96c0b6790ce2675b3d6917ee" translate="yes" xml:space="preserve">
          <source>Norm used to normalize term vectors. None for no normalization.</source>
          <target state="translated">用来归一化术语向量的规范。无表示不进行归一化。</target>
        </trans-unit>
        <trans-unit id="baeabcda0198bd70ffaabb333ee49b38a8e0ee34" translate="yes" xml:space="preserve">
          <source>Normal and Shrinkage Linear Discriminant Analysis for classification</source>
          <target state="translated">用于分类的正态和收缩线性判别分析。</target>
        </trans-unit>
        <trans-unit id="1c651aee92e671db7fa9048c6cdacbd12ea197da" translate="yes" xml:space="preserve">
          <source>Normalization matrix needed for embedding. Square root of the kernel matrix on &lt;code&gt;components_&lt;/code&gt;.</source>
          <target state="translated">嵌入所需的规范化矩阵。 &lt;code&gt;components_&lt;/code&gt; _上内核矩阵的平方根。</target>
        </trans-unit>
        <trans-unit id="b2dd009a742549bee9ad100542b0f67ba3a05708" translate="yes" xml:space="preserve">
          <source>Normalize samples individually to unit norm.</source>
          <target state="translated">将样本单独归一化为单位正态。</target>
        </trans-unit>
        <trans-unit id="1cc78071dce653cdb1a895ced93da41b36798ab2" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information</source>
          <target state="translated">归一化相互信息</target>
        </trans-unit>
        <trans-unit id="6d15c4ae0d04e936f901929872b9ad476ca9800b" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information (NMI) is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by some generalized mean of &lt;code&gt;H(labels_true)&lt;/code&gt; and &lt;code&gt;H(labels_pred))&lt;/code&gt;, defined by the &lt;code&gt;average_method&lt;/code&gt;.</source>
          <target state="translated">标准化互信息（NMI）是互信息（MI）分数的归一化，可在0（无互信息）和1（完美相关）之间缩放结果。在此函数中，互信息通过 &lt;code&gt;H(labels_true)&lt;/code&gt; 和 &lt;code&gt;H(labels_pred))&lt;/code&gt; 的一些广义均值归一化，均值由 &lt;code&gt;average_method&lt;/code&gt; 定义。</target>
        </trans-unit>
        <trans-unit id="2009d38e6ab058cf38d5f44a4aa1fda0316b3372" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information between two clusterings.</source>
          <target state="translated">两个聚类之间的归一化互信息。</target>
        </trans-unit>
        <trans-unit id="4f7979e77b9a0db2d6d4f14823a6b0012cc9a130" translate="yes" xml:space="preserve">
          <source>Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</source>
          <target state="translated">归一化的剪切和图像分割，2000年Jianbo Shi，Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bcdc09e5b38e3433007fe04c41bf1718c142c846" translate="yes" xml:space="preserve">
          <source>Normalized input X.</source>
          <target state="translated">归一化输入X。</target>
        </trans-unit>
        <trans-unit id="cf0305ad6a5172727382b32897870cffde3ce433" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels</source>
          <target state="translated">各类标签的归一化概率分布</target>
        </trans-unit>
        <trans-unit id="f4b126cd68b1eba9b799b0ffccc1898e8bfe924f" translate="yes" xml:space="preserve">
          <source>Normalizer</source>
          <target state="translated">Normalizer</target>
        </trans-unit>
        <trans-unit id="a19366221588f526c166820c530dd8f2268ea2b7" translate="yes" xml:space="preserve">
          <source>Not all models benefit from optimized BLAS and Lapack implementations. For instance models based on (randomized) decision trees typically do not rely on BLAS calls in their inner loops, nor do kernel SVMs (&lt;code&gt;SVC&lt;/code&gt;, &lt;code&gt;SVR&lt;/code&gt;, &lt;code&gt;NuSVC&lt;/code&gt;, &lt;code&gt;NuSVR&lt;/code&gt;). On the other hand a linear model implemented with a BLAS DGEMM call (via &lt;code&gt;numpy.dot&lt;/code&gt;) will typically benefit hugely from a tuned BLAS implementation and lead to orders of magnitude speedup over a non-optimized BLAS.</source>
          <target state="translated">并非所有模型都受益于优化的BLAS和Lapack实施。例如，基于（随机）决策树的模型通常不依赖于其内部循环中的BLAS调用，也不依赖于内核SVM（ &lt;code&gt;SVC&lt;/code&gt; ， &lt;code&gt;SVR&lt;/code&gt; ， &lt;code&gt;NuSVC&lt;/code&gt; ， &lt;code&gt;NuSVR&lt;/code&gt; ）。另一方面，通过BLAS DGEMM调用（通过 &lt;code&gt;numpy.dot&lt;/code&gt; ）实现的线性模型通常会从调整后的BLAS实现中受益匪浅，并会比未优化的BLAS提速几个数量级。</target>
        </trans-unit>
        <trans-unit id="d1a17af19f5388af9d6596cc0ea7dbb1d739e255" translate="yes" xml:space="preserve">
          <source>Not available</source>
          <target state="translated">未提供</target>
        </trans-unit>
        <trans-unit id="2f1306ffef95e5ddbb8f4b2f3a60c6ede1c9a1f3" translate="yes" xml:space="preserve">
          <source>Not scalable</source>
          <target state="translated">不可扩展</target>
        </trans-unit>
        <trans-unit id="6671bcf801635373715efa03216b0f9d13f34c22" translate="yes" xml:space="preserve">
          <source>Not scalable with &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; 使用n_samples进行扩展</target>
        </trans-unit>
        <trans-unit id="d70eb56b501fa2ef808df1c818502bbb5b800d19" translate="yes" xml:space="preserve">
          <source>Not scalable with n_samples</source>
          <target state="translated">不能扩展n_samples</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="14ba06ae5f3993adde2848620bcf508016c9c617" translate="yes" xml:space="preserve">
          <source>Note : Laplacian Eigenmaps is the actual algorithm implemented here.</source>
          <target state="translated">注:Laplacian Eigenmaps是这里实现的实际算法。</target>
        </trans-unit>
        <trans-unit id="21546711de316cf946ba53a498f41ae0550616cc" translate="yes" xml:space="preserve">
          <source>Note how some use the group/class information while others do not.</source>
          <target state="translated">请注意有些人如何使用组/类信息,而有些人则没有。</target>
        </trans-unit>
        <trans-unit id="c3c271844b997675d3bb1a8d39599227fbe7b490" translate="yes" xml:space="preserve">
          <source>Note how the optimal value of alpha varies for each fold. This illustrates why nested-cross validation is necessary when trying to evaluate the performance of a method for which a parameter is chosen by cross-validation: this choice of parameter may not be optimal for unseen data.</source>
          <target state="translated">请注意每个褶皱的α的最佳值是如何变化的。这说明了为什么在试图评估一个通过交叉验证选择参数的方法的性能时,嵌套交叉验证是必要的:这种参数的选择对于未见数据来说可能不是最优的。</target>
        </trans-unit>
        <trans-unit id="92e53ea7bdcc226c7bc1da5197dd56da468b26d1" translate="yes" xml:space="preserve">
          <source>Note on inappropriate usage of cross_val_predict</source>
          <target state="translated">关于不恰当使用cross_val_predict的说明。</target>
        </trans-unit>
        <trans-unit id="029f2db65bc50c936edb77149f903f8d03abd995" translate="yes" xml:space="preserve">
          <source>Note on the lookup process: depending on the type of name_or_id, will choose between integer id lookup or metadata name lookup by looking at the unzipped archives and metadata file.</source>
          <target state="translated">查找过程中的注意点:根据name_or_id的类型,将通过查看解压后的存档和元数据文件,选择整数id查找或元数据名称查找。</target>
        </trans-unit>
        <trans-unit id="637677b94f16fb377d9bcfbae4602956aad7da33" translate="yes" xml:space="preserve">
          <source>Note that &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</source>
          <target state="translated">请注意，只有在比例大致相同的要素上才能确保&amp;ldquo; sag&amp;rdquo;和&amp;ldquo; saga&amp;rdquo;快速收敛。您可以使用sklearn.preprocessing中的缩放器对数据进行预处理。</target>
        </trans-unit>
        <trans-unit id="fb2d865fbf24560bc423d4932883d3877000a02a" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; does not support &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods by default but only a &lt;code&gt;fit_predict&lt;/code&gt; method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">请注意，默认情况下，&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;不支持 &lt;code&gt;predict&lt;/code&gt; ， &lt;code&gt;decision_function&lt;/code&gt; 和 &lt;code&gt;score_samples&lt;/code&gt; 方法，而仅支持 &lt;code&gt;fit_predict&lt;/code&gt; 方法，因为该估算器最初是用于异常值检测的。可以通过 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性访问训练样本的异常分数。</target>
        </trans-unit>
        <trans-unit id="9cc23e915eab7d76b355d3d788a42c200a9cfa75" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;fit_predict&lt;/code&gt; is not available in this case.</source>
          <target state="translated">请注意，在这种情况下， &lt;code&gt;fit_predict&lt;/code&gt; 不可用。</target>
        </trans-unit>
        <trans-unit id="05da1e73517821e307ab23620f26a2cb5cf58320" translate="yes" xml:space="preserve">
          <source>Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.</source>
          <target state="translated">需要注意的是,稀疏PCA成分的正交性并不像PCA那样被强制执行,因此不能使用简单的线性投影。</target>
        </trans-unit>
        <trans-unit id="8a36ac6808e625c8a29705bcc1d1fb6cf63760b8" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space.</source>
          <target state="translated">请注意，在SciPy 0.16之前， &lt;code&gt;scipy.stats.distributions&lt;/code&gt; 不接受自定义RNG实例，并且始终使用 &lt;code&gt;numpy.random&lt;/code&gt; 中的单例RNG 。因此，每当使用 &lt;code&gt;scipy.stats&lt;/code&gt; 分布来定义参数搜索空间时，设置 &lt;code&gt;random_state&lt;/code&gt; 将不能保证确定性迭代。</target>
        </trans-unit>
        <trans-unit id="9a716693e5778e1463e7644515aedc4c9b2a1b82" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space. Deterministic behavior is however guaranteed from SciPy 0.16 onwards.</source>
          <target state="translated">请注意，在SciPy 0.16之前， &lt;code&gt;scipy.stats.distributions&lt;/code&gt; 不接受自定义RNG实例，并且始终使用 &lt;code&gt;numpy.random&lt;/code&gt; 中的单例RNG 。因此，每当使用 &lt;code&gt;scipy.stats&lt;/code&gt; 分布来定义参数搜索空间时，设置 &lt;code&gt;random_state&lt;/code&gt; 将不能保证确定性迭代。但是，从SciPy 0.16起可以保证确定性行为。</target>
        </trans-unit>
        <trans-unit id="8c441ea193159e43e5ae4f2f43b7cd455bbc50a0" translate="yes" xml:space="preserve">
          <source>Note that for floating-point input, the mean is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for &lt;code&gt;float32&lt;/code&gt; (see example below). Specifying a higher-precision accumulator using the &lt;code&gt;dtype&lt;/code&gt; keyword can alleviate this issue.</source>
          <target state="translated">请注意，对于浮点输入，将使用与输入相同的精度来计算平均值。根据输入数据，这可能导致结果不准确，尤其是对于 &lt;code&gt;float32&lt;/code&gt; （请参见下面的示例）。使用 &lt;code&gt;dtype&lt;/code&gt; 关键字指定更高精度的累加器可以缓解此问题。</target>
        </trans-unit>
        <trans-unit id="1c1b3dcae0a3cdb049378b61a52e8a6e218b843e" translate="yes" xml:space="preserve">
          <source>Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].</source>
          <target state="translated">需要注意的是,对于多输出(包括多标签)的权重应该在自己的dict中为每一列的每个类定义。例如,对于四类多标签分类权重应该是[{0:1,1:1},{0:1,1:5},{0:1,1:1},{0:1,1:1}],而不是[{1:1},{2:5},{3:1},{4:1}]。</target>
        </trans-unit>
        <trans-unit id="7f057f4a3cfb222efbfc3fdf93e59924824aafce" translate="yes" xml:space="preserve">
          <source>Note that if features have very different scaling or statistical properties, &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; may not be able to capture the links between related features. Using a &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; can be useful in these settings.</source>
          <target state="translated">请注意，如果要素具有不同的缩放比例或统计属性，则&lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt; &lt;/a&gt;可能无法捕获相关要素之间的链接。在这些设置中，使用&lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="daa34c655040f11fbac2193226735416d5ff6724" translate="yes" xml:space="preserve">
          <source>Note that if the values of your similarity matrix are not well distributed, e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable. In which case it is advised to apply a transformation to the entries of the matrix. For instance, in the case of a signed distance matrix, is common to apply a heat kernel:</source>
          <target state="translated">请注意,如果你的相似度矩阵的值分布不均匀,例如负值或使用距离矩阵而不是相似度,那么光谱问题将是奇异的,问题无法解决。在这种情况下,建议对矩阵的条目进行变换。例如,在有符号距离矩阵的情况下,通常应用热核。</target>
        </trans-unit>
        <trans-unit id="82c5d12dd2770bc5d00d9e0fd296f522b36a2aec" translate="yes" xml:space="preserve">
          <source>Note that in binary classification, recall of the positive class is also known as &amp;ldquo;sensitivity&amp;rdquo;; recall of the negative class is &amp;ldquo;specificity&amp;rdquo;.</source>
          <target state="translated">请注意，在二元分类中，对阳性分类的记忆也称为&amp;ldquo;敏感性&amp;rdquo;。否定类别的回忆是&amp;ldquo;特异性&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="56700fbea0a4382f56515fac76889ee512c8d3cb" translate="yes" xml:space="preserve">
          <source>Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path</source>
          <target state="translated">请注意,在某些情况下,Lars求解器实现该功能的速度可能会快很多。特别是,线性插值可以用于检索lars_path输出值之间的模型系数</target>
        </trans-unit>
        <trans-unit id="c065b9ad388e273aa3b214ab1297a55e0496eb57" translate="yes" xml:space="preserve">
          <source>Note that in general, robust fitting in high-dimensional setting (large &lt;code&gt;n_features&lt;/code&gt;) is very hard. The robust models here will probably not work in these settings.</source>
          <target state="translated">请注意，通常，在高维设置（大 &lt;code&gt;n_features&lt;/code&gt; ）中进行鲁棒拟合非常困难。这里的健壮模型可能无法在这些设置下工作。</target>
        </trans-unit>
        <trans-unit id="64011c56ebca18074907020d8d3e99112269576a" translate="yes" xml:space="preserve">
          <source>Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important.</source>
          <target state="translated">需要注意的是,在实际操作中,人们不会同时使用网格搜索在这么多不同的参数上进行搜索,而是只选择那些认为最重要的参数。</target>
        </trans-unit>
        <trans-unit id="b7d16723edd6b0c8a445c16934e7dfaedb2752ae" translate="yes" xml:space="preserve">
          <source>Note that in the case of &amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo; and &amp;lsquo;euclidean&amp;rsquo; (which are valid scipy.spatial.distance metrics), the scikit-learn implementation will be used, which is faster and has support for sparse matrices (except for &amp;lsquo;cityblock&amp;rsquo;). For a verbose description of the metrics from scikit-learn, see the __doc__ of the sklearn.pairwise.distance_metrics function.</source>
          <target state="translated">请注意，对于&amp;ldquo; cityblock&amp;rdquo;，&amp;ldquo; cosine&amp;rdquo;和&amp;ldquo; euclidean&amp;rdquo;（它们是有效的scipy.spatial.distance指标），将使用scikit-learn实现，它实现得更快，并且支持稀疏矩阵（除了'城市街区'）。有关scikit-learn中指标的详细说明，请参见sklearn.pairwise.distance_metrics函数的__doc__。</target>
        </trans-unit>
        <trans-unit id="81154799705dfac8836df66f3a0269041db1173b" translate="yes" xml:space="preserve">
          <source>Note that in the multilabel case, each sample can have any number of labels. This returns the marginal probability that the given sample has the label in question. For example, it is entirely consistent that two labels both have a 90% probability of applying to a given sample.</source>
          <target state="translated">注意,在多标签的情况下,每个样本可以有任意数量的标签。这将返回给定样本拥有相关标签的边际概率。例如,两个标签都有90%的概率适用于给定样本,这是完全一致的。</target>
        </trans-unit>
        <trans-unit id="01d7bf1a38a1f2f757397967cae9b7d66ce2602c" translate="yes" xml:space="preserve">
          <source>Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):</source>
          <target state="translated">请注意,在前一个语料库中,第一个和最后一个文档有完全相同的词,因此被编码为相等的向量。尤其是我们失去了最后一个文档是问句形式的信息。为了保留一些局部的排序信息,我们可以在1-grams(单个单词)之外提取2-grams的单词。</target>
        </trans-unit>
        <trans-unit id="8dcb354ad6f05344d318f25389a442779bd42bda" translate="yes" xml:space="preserve">
          <source>Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.</source>
          <target state="translated">需要注意的是,通常情况下,这些参数中的一小部分会对模型的预测或计算性能产生很大影响,而其他参数可以保持默认值。建议阅读估计器类的docstring,可能通过阅读所附的文献参考资料,对它们的预期行为有更深入的了解。</target>
        </trans-unit>
        <trans-unit id="38e7c6473cb1417f0189c236d54733065555b837" translate="yes" xml:space="preserve">
          <source>Note that it maximizes both the correlations between the scores and the intra-block variances.</source>
          <target state="translated">请注意,它能使分数和块内方差之间的相关性最大化。</target>
        </trans-unit>
        <trans-unit id="7fe083a60697e58d27f138d9ea26d77a87096c53" translate="yes" xml:space="preserve">
          <source>Note that it maximizes only the correlations between the scores.</source>
          <target state="translated">请注意,它只最大化了分数之间的相关性。</target>
        </trans-unit>
        <trans-unit id="9b4460fdb66af9bc149af45e106adc5f1d493bbf" translate="yes" xml:space="preserve">
          <source>Note that noisy data can &amp;ldquo;short-circuit&amp;rdquo; the manifold, in essence acting as a bridge between parts of the manifold that would otherwise be well-separated. Manifold learning on noisy and/or incomplete data is an active area of research.</source>
          <target state="translated">请注意，嘈杂的数据可能会使歧管&amp;ldquo;短路&amp;rdquo;，本质上是充当歧管各部分之间的桥梁，否则这些部分将被很好地分离。在嘈杂和/或不完整的数据上进行流形学习是研究的活跃领域。</target>
        </trans-unit>
        <trans-unit id="67d5dd89ca82637aa1c574ab8cabbf8ba39e4cb8" translate="yes" xml:space="preserve">
          <source>Note that pickle has some security and maintainability issues. Please refer to section &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;Model persistence&lt;/a&gt; for more detailed information about model persistence with scikit-learn.</source>
          <target state="translated">请注意，泡菜存在一些安全性和可维护性问题。有关使用scikit-learn的模型持久&lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;性&lt;/a&gt;的更多详细信息，请参阅模型持久性部分。</target>
        </trans-unit>
        <trans-unit id="23cd95765d94c327b5282b4a1fe3e5dffe405a3a" translate="yes" xml:space="preserve">
          <source>Note that polynomial features are used implicitly in &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel methods&lt;/a&gt; (e.g., &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;sklearn.svm.SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt;&lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt;&lt;/a&gt;) when using polynomial &lt;a href=&quot;svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">注意，使用多项式&lt;a href=&quot;svm#svm-kernels&quot;&gt;内核函数&lt;/a&gt;时，多项式特征在&lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;内核方法&lt;/a&gt;（例如&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;sklearn.svm.SVC&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt; &lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt; &lt;/a&gt;）中隐式使用。</target>
        </trans-unit>
        <trans-unit id="675c6d53180ed2915c2b59bf4a0a0e8fbac69215" translate="yes" xml:space="preserve">
          <source>Note that providing &lt;code&gt;y&lt;/code&gt; is sufficient to generate the splits and hence &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; may be used as a placeholder for &lt;code&gt;X&lt;/code&gt; instead of actual training data.</source>
          <target state="translated">请注意，提供 &lt;code&gt;y&lt;/code&gt; 足以生成拆分，因此可以将 &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; 用作 &lt;code&gt;X&lt;/code&gt; 的占位符，而不是实际的训练数据。</target>
        </trans-unit>
        <trans-unit id="df4d1f63cde2c26d664594a284ce306040d06cfb" translate="yes" xml:space="preserve">
          <source>Note that shrinkage works only with &amp;lsquo;lsqr&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="translated">请注意，收缩仅适用于&amp;ldquo; lsqr&amp;rdquo;和&amp;ldquo;本征&amp;rdquo;求解器。</target>
        </trans-unit>
        <trans-unit id="dd7adf0d494ffc5bcd4e70266fd05b000aa00dcc" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format.</source>
          <target state="translated">请注意，&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt;函数仅限于二进制情况。该&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;功能只在二元分类和多标指标格式。</target>
        </trans-unit>
        <trans-unit id="651372cf76a2e0eca2cd0e2ced075f5cfd44a313" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt;&lt;code&gt;Binarizer&lt;/code&gt;&lt;/a&gt; is similar to the &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt;&lt;code&gt;KBinsDiscretizer&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;k = 2&lt;/code&gt;, and when the bin edge is at the value &lt;code&gt;threshold&lt;/code&gt;.</source>
          <target state="translated">注意，&lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt; &lt;code&gt;Binarizer&lt;/code&gt; &lt;/a&gt;是类似于&lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt; &lt;code&gt;KBinsDiscretizer&lt;/code&gt; &lt;/a&gt;当 &lt;code&gt;k = 2&lt;/code&gt; ，而当箱边缘处的值 &lt;code&gt;threshold&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b78ef718e6ed1cb354d8ff189ba4de9e4443cf71" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. This method is consistent, which is not true for one-vs-rest classification. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">请注意，&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;还通过使用选项 &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; 实现了替代的多类策略，即由Crammer和Singer制定的所谓多类SVM 。此方法是一致的，对于&amp;ldquo;一对休息&amp;rdquo;分类是不正确的。实际上，通常首选&amp;ldquo;一对多&amp;rdquo;分类，因为结果大多相似，但运行时间明显较少。</target>
        </trans-unit>
        <trans-unit id="4b2885ce1a0d54c6be5b37dba1e7a9bea3c67ec1" translate="yes" xml:space="preserve">
          <source>Note that the Multiplicative Update (&amp;lsquo;mu&amp;rsquo;) solver cannot update zeros present in the initialization, so it leads to poorer results when used jointly with the basic NNDSVD algorithm which introduces a lot of zeros; in this case, NNDSVDa or NNDSVDar should be preferred.</source>
          <target state="translated">请注意，乘法更新（'mu'）求解器无法更新初始化中存在的零，因此与引入大量零的基本NNDSVD算法一起使用时，结果会更差。在这种情况下，应首选NNDSVDa或NNDSVDar。</target>
        </trans-unit>
        <trans-unit id="542b5d2a5a3926264004f7807400969fe48d422d" translate="yes" xml:space="preserve">
          <source>Note that the current implementation only supports regression estimators.</source>
          <target state="translated">请注意,目前的实现只支持回归估计器。</target>
        </trans-unit>
        <trans-unit id="5878ce2fa9f81f5b0b2794d8ccb7e40e7db1917d" translate="yes" xml:space="preserve">
          <source>Note that the dict values can either be scorer functions or one of the predefined metric strings.</source>
          <target state="translated">请注意,dict值可以是scorer函数,也可以是预定义的度量字符串之一。</target>
        </trans-unit>
        <trans-unit id="a97f1f4d24f812e6f4b824a150b492f876f8dbe2" translate="yes" xml:space="preserve">
          <source>Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (&lt;code&gt;LinearSVC(dual=True)&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;PassiveAggressive&lt;/code&gt;) but it does for algorithms that work with CSC matrices (&lt;code&gt;LinearSVC(dual=False)&lt;/code&gt;, &lt;code&gt;Lasso()&lt;/code&gt;, etc).</source>
          <target state="translated">请注意，维度不会影响在CSR矩阵（ &lt;code&gt;LinearSVC(dual=True)&lt;/code&gt; ， &lt;code&gt;Perceptron&lt;/code&gt; ， &lt;code&gt;SGDClassifier&lt;/code&gt; ， &lt;code&gt;PassiveAggressive&lt;/code&gt; ）上运行的算法的CPU训练时间，但会影响与CSC矩阵一起使用的算法（ &lt;code&gt;LinearSVC(dual=False)&lt;/code&gt; ， &lt;code&gt;Lasso()&lt;/code&gt; 等）。</target>
        </trans-unit>
        <trans-unit id="435cce9f843df9a5bdcdf7f7022599966bcaee8d" translate="yes" xml:space="preserve">
          <source>Note that the estimate_bandwidth function is much less scalable than the mean shift algorithm and will be the bottleneck if it is used.</source>
          <target state="translated">需要注意的是,估计带宽函数的可扩展性远不如均值移动算法,如果使用该函数,将是瓶颈。</target>
        </trans-unit>
        <trans-unit id="bce829a8923d634c66b8b2d36d28916cd48e0ab9" translate="yes" xml:space="preserve">
          <source>Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels &lt;code&gt;fit&lt;/code&gt; upon. With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:</source>
          <target state="translated">需要注意的是第四和第五实例返回的所有零，这表明它们没有相匹配的三个标签 &lt;code&gt;fit&lt;/code&gt; 于。使用多标签输出，也可以为一个实例分配多个标签：</target>
        </trans-unit>
        <trans-unit id="21f39572b525862541f5e3b74bb03e06aac617ef" translate="yes" xml:space="preserve">
          <source>Note that the heat map plot has a special colorbar with a midpoint value close to the score values of the best performing models so as to make it easy to tell them apart in the blink of an eye.</source>
          <target state="translated">需要注意的是,热力图图中有一个特殊的色条,其中点值与表现最好的模型的得分值接近,以便于在眨眼间就能分辨出它们。</target>
        </trans-unit>
        <trans-unit id="3f19bf1a17574ce6b7f5a8199cbb6b2ed04a3916" translate="yes" xml:space="preserve">
          <source>Note that the maximum likelihood estimate corresponds to no shrinkage, and thus performs poorly. The Ledoit-Wolf estimate performs really well, as it is close to the optimal and is computational not costly. In this example, the OAS estimate is a bit further away. Interestingly, both approaches outperform cross-validation, which is significantly most computationally costly.</source>
          <target state="translated">请注意,最大似然估计对应的是无收缩,因此表现很差。Ledoit-Wolf估计的表现非常好,因为它接近最优,而且计算成本不高。在这个例子中,OAS估计离得有点远。有趣的是,这两种方法的表现都优于交叉验证,而交叉验证的计算成本明显最高。</target>
        </trans-unit>
        <trans-unit id="be3cea96be539a6f36c7349851efbc1b4f539ceb" translate="yes" xml:space="preserve">
          <source>Note that the number of dimensions is independent of the original number of features but instead depends on the size of the dataset: the larger the dataset, the higher is the minimal dimensionality of an eps-embedding.</source>
          <target state="translated">请注意,维数与原始特征数无关,而是取决于数据集的大小:数据集越大,eps-embedding的最小维数越高。</target>
        </trans-unit>
        <trans-unit id="1426a0972df2ef3ae4847218faa4ab1a45e2a26b" translate="yes" xml:space="preserve">
          <source>Note that the parameter &lt;code&gt;alpha&lt;/code&gt; is applied as a Tikhonov regularization of the assumed covariance between the training points.</source>
          <target state="translated">请注意，参数 &lt;code&gt;alpha&lt;/code&gt; 用作训练点之间假定协方差的Tikhonov正则化。</target>
        </trans-unit>
        <trans-unit id="57bfd4549eb4e4a76c8eb0b9ddf20a2f4a52c8d2" translate="yes" xml:space="preserve">
          <source>Note that the precision may not decrease with recall. The definition of precision (\(\frac{T_p}{T_p + F_p}\)) shows that lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase precision. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing precision.</source>
          <target state="translated">请注意,精度可能不会随着召回率的提高而降低。精度的定义(\(frac{T_p}{T_p+F_p}\))表明,降低分类器的阈值可能会增加分母,通过增加返回的结果数量。如果之前的阈值设置得过高,新的结果可能都是真阳性,这将提高精度。如果之前的阈值差不多或太低,进一步降低阈值会引入假阳性,降低精度。</target>
        </trans-unit>
        <trans-unit id="07e181d114b5848fdd4cb0661edb49154d99e027" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the &lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space. Here the manifold problem matches fairly that of representing a flat map of the Earth, as with &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;map projection&lt;/a&gt;</source>
          <target state="translated">请注意，&lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt;的目的是找到数据的低维表示形式（此处为2D），其中距离很好地尊重了原始高维空间中的距离，这与其他流形学习算法不同，它不寻求低维空间中数据的各向同性表示。在这里，流形问题与表示地球平面图的问题相当匹配，就像&lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;地图投影一样&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="951ad93c2b6a49b38a3c4a8dabf905c9019bf128" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the MDS is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space.</source>
          <target state="translated">需要注意的是,MDS的目的是寻找数据的低维表示(这里是二维),其中的距离很好地尊重原高维空间中的距离,与其他显式学习算法不同的是,它并不寻求数据在低维空间中的同向表示。</target>
        </trans-unit>
        <trans-unit id="faff2f13ccab498a5068027cb2f2891a11c4c2ca" translate="yes" xml:space="preserve">
          <source>Note that the scalers accept both Compressed Sparse Rows and Compressed Sparse Columns format (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; and &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt;). Any other sparse input will be &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt;. To avoid unnecessary memory copies, it is recommended to choose the CSR or CSC representation upstream.</source>
          <target state="translated">请注意，缩放器接受压缩的稀疏行和压缩的稀疏列格式（请参阅 &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; 和 &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt; ）。任何其他稀疏输入都将&lt;strong&gt;转换为&amp;ldquo;压缩稀疏行&amp;rdquo;表示形式&lt;/strong&gt;。为避免不必要的内存复制，建议选择上游的CSR或CSC表示形式。</target>
        </trans-unit>
        <trans-unit id="0ac4948c4f86990406e6391d28cab3438b2d6038" translate="yes" xml:space="preserve">
          <source>Note that the transformations successfully map the data to a normal distribution when applied to certain datasets, but are ineffective with others. This highlights the importance of visualizing the data before and after transformation.</source>
          <target state="translated">请注意,当应用于某些数据集时,转换成功地将数据映射到正态分布,但对其他数据集无效。这凸显了在转换前后对数据进行可视化的重要性。</target>
        </trans-unit>
        <trans-unit id="c025c974076c003b893079ae24539cfe87c45c45" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;code&gt;memory&lt;/code&gt; to enable caching becomes interesting when the fitting of a transformer is costly.</source>
          <target state="translated">请注意，当变压器的安装成本很高时，使用 &lt;code&gt;memory&lt;/code&gt; 来启用缓存就变得很有趣。</target>
        </trans-unit>
        <trans-unit id="e3bd8ce7db50d77dd828df23ba8a7913ea07b656" translate="yes" xml:space="preserve">
          <source>Note that there are many different formulations for the Sparse PCA problem. The one implemented here is based on &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]&lt;/a&gt; . The optimization problem solved is a PCA problem (dictionary learning) with an \(\ell_1\) penalty on the components:</source>
          <target state="translated">请注意，稀疏PCA问题有许多不同的表述。此处实现的是基于&lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]的&lt;/a&gt;。解决的优化问题是PCA问题（字典学习），对组件的惩罚为\（\ ell_1 \）：</target>
        </trans-unit>
        <trans-unit id="3533aed52b9c93cbfd7c732492e759ef81f9eff6" translate="yes" xml:space="preserve">
          <source>Note that there exist a lot of different clustering criteria and associated algorithms. The simplest clustering algorithm is &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;.</source>
          <target state="translated">请注意，存在许多不同的聚类标准和相关算法。最简单的聚类算法是&lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="7a1a308b56337fe667b4a60765401b66807cafaf" translate="yes" xml:space="preserve">
          <source>Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.</source>
          <target state="translated">请注意,如果指定了 sample_weight,这些权重将与 sample_weight(通过拟合方法传递)相乘。</target>
        </trans-unit>
        <trans-unit id="523c4300803e2407441df32761d9ac234d32f175" translate="yes" xml:space="preserve">
          <source>Note that theta are typically the log-transformed values of the kernel&amp;rsquo;s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.</source>
          <target state="translated">请注意，&amp;theta;通常是内核超参数的对数转换值，因为搜索空间的这种表示形式更适合于超参数搜索，因为像长度标尺之类的超参数自然地生活在对数标尺上。</target>
        </trans-unit>
        <trans-unit id="18d756a791b41973e0843ab0a78a9e37c703da28" translate="yes" xml:space="preserve">
          <source>Note that this accuracy of this l1-penalized linear model is significantly below what can be reached by an l2-penalized linear model or a non-linear multi-layer perceptron model on this dataset.</source>
          <target state="translated">需要注意的是,这个l1-penalized线性模型的这个精度明显低于l2-penalized线性模型或非线性多层感知器模型在这个数据集上所能达到的精度。</target>
        </trans-unit>
        <trans-unit id="d1586f7c06fc3985d60451a7a19048e48e062430" translate="yes" xml:space="preserve">
          <source>Note that this compound kernel returns the results of all simple kernel stacked along an additional axis.</source>
          <target state="translated">需要注意的是,这个复合内核会返回所有简单内核沿一个附加轴堆叠的结果。</target>
        </trans-unit>
        <trans-unit id="70f8f8292a30b78b7e2885afabc408eef407b785" translate="yes" xml:space="preserve">
          <source>Note that this definition is not valid if \(\beta \in (0; 1)\), yet it can be continuously extended to the definitions of \(d_{KL}\) and \(d_{IS}\) respectively.</source>
          <target state="translated">请注意,如果(0;1)/)/)这个定义是不成立的,但它可以不断扩展到分别定义为(d_{KL}/)和(d_{IS}/)。</target>
        </trans-unit>
        <trans-unit id="5472d869ea9e0f8e4cfcc121937d62eb4599c58a" translate="yes" xml:space="preserve">
          <source>Note that this example is, however, only an illustration since for this specific case fitting PCA is not necessarily slower than loading the cache. Hence, use the &lt;code&gt;memory&lt;/code&gt; constructor parameter when the fitting of a transformer is costly.</source>
          <target state="translated">但是请注意，此示例仅是说明，因为在这种特定情况下，拟合PCA不一定比加载缓存慢。因此，当变压器的安装成本很高时，请使用 &lt;code&gt;memory&lt;/code&gt; 构造函数参数。</target>
        </trans-unit>
        <trans-unit id="1b5bac58d61d7142976dd586739448ed8787f73e" translate="yes" xml:space="preserve">
          <source>Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.</source>
          <target state="translated">请注意,这种格式不是用来隐式存储矩阵中的缺失值,因为它会在变换时使矩阵变稠。用0编码的缺失值必须与密集输入一起使用。</target>
        </trans-unit>
        <trans-unit id="ceed59ec0d8d185c9512413b150620f381e9c0c0" translate="yes" xml:space="preserve">
          <source>Note that this function does not regenerate the original data due to discretization rounding.</source>
          <target state="translated">请注意,由于离散化四舍五入,该函数不会再生原始数据。</target>
        </trans-unit>
        <trans-unit id="90f3882ef5e6cb2ec08d6d3659b834d53aaa84d9" translate="yes" xml:space="preserve">
          <source>Note that this gives us a different indication than the graph, as the graph reflects conditional relations between variables, while the clustering reflects marginal properties: variables clustered together can be considered as having a similar impact at the level of the full stock market.</source>
          <target state="translated">请注意,这给我们的指示与图表不同,因为图表反映的是变量之间的条件关系,而聚类反映的是边际属性:聚类在一起的变量可以被认为在完整的股票市场层面具有类似的影响。</target>
        </trans-unit>
        <trans-unit id="29fe04606c06b888c8ec9e6f0120963e08f606ce" translate="yes" xml:space="preserve">
          <source>Note that this is always a dense array.</source>
          <target state="translated">注意,这总是一个密集的数组。</target>
        </trans-unit>
        <trans-unit id="426217e7254990be151f425ed53a8b743a92e13d" translate="yes" xml:space="preserve">
          <source>Note that this two-dimensional example is very degenerate: generally the number of features would be much greater than the &amp;ldquo;document length&amp;rdquo;, while here we have much larger documents than vocabulary. Similarly, with &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt;, it is much less likely that a feature distinguishes a particular class.</source>
          <target state="translated">请注意，这个二维示例非常简陋：特征的数量通常会比&amp;ldquo;文档长度&amp;rdquo;大得多，而此处的文档比词汇量大得多。类似地，使用 &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt; ，特征区别特定类的可能性就小得多。</target>
        </trans-unit>
        <trans-unit id="dcf3e0855a66eb55e0eddd9daaf862dddfda1dac" translate="yes" xml:space="preserve">
          <source>Note that this type is the most specific type that can be inferred. For example:</source>
          <target state="translated">注意,这种类型是可以推断出的最具体的类型。例如:</target>
        </trans-unit>
        <trans-unit id="1fefb84f794ce8a86674757b08d8dabfe97347de" translate="yes" xml:space="preserve">
          <source>Note that this will affect all uses of &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt;&lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt;&lt;/a&gt; within the context.</source>
          <target state="translated">请注意，这将影响上下文中&lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt; &lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt; 的&lt;/a&gt;所有使用。</target>
        </trans-unit>
        <trans-unit id="ab32001c49d58b4f0c9d94bbfb77f7ddeaf05601" translate="yes" xml:space="preserve">
          <source>Note that those results can be highly dependent on the value of &lt;code&gt;learning_rate_init&lt;/code&gt;.</source>
          <target state="translated">请注意，这些结果可能高度依赖于 &lt;code&gt;learning_rate_init&lt;/code&gt; 的值。</target>
        </trans-unit>
        <trans-unit id="aa786acd948a782d7b514486d406120e9b9bf46a" translate="yes" xml:space="preserve">
          <source>Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.</source>
          <target state="translated">请注意,与标准的交叉验证方法不同,连续的训练集是前面的训练集的超集。</target>
        </trans-unit>
        <trans-unit id="b632488ec02d373b59188cfae81036b1d7135a34" translate="yes" xml:space="preserve">
          <source>Note that when using dictionary learning to extract a representation (e.g. for sparse coding) clustering can be a good proxy to learn the dictionary. For instance the &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; estimator is computationally efficient and implements on-line learning with a &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">请注意，当使用字典学习来提取表示形式（例如，用于稀疏编码）时，聚类可以是学习字典的良好代理。例如，&lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt;估计器的计算效率很高，并使用 &lt;code&gt;partial_fit&lt;/code&gt; 方法实现了在线学习。</target>
        </trans-unit>
        <trans-unit id="b38cc6be43472cae197ca98a60df5eafaa29d73f" translate="yes" xml:space="preserve">
          <source>Note that with all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data!</source>
          <target state="translated">注意，使用所有这些策略， &lt;code&gt;predict&lt;/code&gt; 方法将完全忽略输入数据！</target>
        </trans-unit>
        <trans-unit id="75c6be4694b9eabe59018390268fd820a052b7d5" translate="yes" xml:space="preserve">
          <source>Note that, by default, scikit-learn uses its embedded (vendored) version of joblib. A configuration switch (documented below) controls this behavior.</source>
          <target state="translated">请注意,默认情况下,scikit-learn 使用其嵌入式 (vendored)版本的 joblib。一个配置开关(如下文所述)可以控制这种行为。</target>
        </trans-unit>
        <trans-unit id="ae98ee9bcd2e5d0854b3eaebde47d02a011f815f" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the observation \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\).</source>
          <target state="translated">请注意，在这种表示法中，假设观察值\（y_i \）在试验\（i \）中采用集合\（{-1，1} \）中的值。</target>
        </trans-unit>
        <trans-unit id="79d7c15c2a930f99c60199078ea59a499e19fbc8" translate="yes" xml:space="preserve">
          <source>Note that, the color range of the precision matrices is tweaked to improve readability of the figure. The full range of values of the empirical precision is not displayed.</source>
          <target state="translated">需要注意的是,对精度矩阵的颜色范围进行了调整,以提高图的可读性。不显示经验精度的全部数值范围。</target>
        </trans-unit>
        <trans-unit id="5bd74df6988f671f3aaedf9864231e7cb14cad2a" translate="yes" xml:space="preserve">
          <source>Note the use of a generator comprehension, which introduces laziness into the feature extraction: tokens are only processed on demand from the hasher.</source>
          <target state="translated">请注意使用生成器理解,它将懒惰引入到特征提取中:代币只在哈希的需求下进行处理。</target>
        </trans-unit>
        <trans-unit id="1984eb2d93c7fabc5820f74c1a6deb67cdefe2d3" translate="yes" xml:space="preserve">
          <source>Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">注意!合成特征权重和其他所有特征一样,要经过l1/l2的正则化。为了减少正则化对合成特征权重的影响(因此对截距的影响),必须增加截距_scaling。</target>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="translated">Note:</target>
        </trans-unit>
        <trans-unit id="b85cf8e5cd9762e5dd866d246742bbab950fd9b8" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeaveOneOut()&lt;/code&gt; is equivalent to &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; and &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of samples.</source>
          <target state="translated">注意： &lt;code&gt;LeaveOneOut()&lt;/code&gt; 等效于 &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; 和 &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; ，其中 &lt;code&gt;n&lt;/code&gt; 是样本数。</target>
        </trans-unit>
        <trans-unit id="31e8baf167adcc23a2adc9382a5f1918c617d9e9" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeavePOut(p)&lt;/code&gt; is NOT equivalent to &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; which creates non-overlapping test sets.</source>
          <target state="translated">注意： &lt;code&gt;LeavePOut(p)&lt;/code&gt; 与创建非重叠测试集的 &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; 不等效。</target>
        </trans-unit>
        <trans-unit id="432e1c4e6e288e7db18e2c42d6e410c6adeb71c8" translate="yes" xml:space="preserve">
          <source>Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times &lt;code&gt;n_samples&lt;/code&gt; (i.e. the sum of squares of each column totals 1).</source>
          <target state="translated">注意：这10个特征变量中的每一个均已用标准偏差乘以 &lt;code&gt;n_samples&lt;/code&gt; （即，每列的平方和总计1）进行平均居中和缩放。</target>
        </trans-unit>
        <trans-unit id="02b388a51976f4b3884d316ec9ed343cbbaf27f0" translate="yes" xml:space="preserve">
          <source>Note: Evaluation of eval_gradient is not analytic but numeric and all</source>
          <target state="translated">注:eval_gradient的评估不是分析式的,而是数值式的,所有的</target>
        </trans-unit>
        <trans-unit id="a5290473efc5984775f303f01f61e6c7775623f5" translate="yes" xml:space="preserve">
          <source>Note: If a lambda is used as the function, then the resulting transformer will not be pickleable.</source>
          <target state="translated">注意:如果使用lambda作为函数,那么产生的变压器将不能被拾取。</target>
        </trans-unit>
        <trans-unit id="09a1c78e2b9dafeb4ae2773774e2099dbe747a0e" translate="yes" xml:space="preserve">
          <source>Note: Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">注意：我们的实现得分比Tsoumakas等人（2010年）给出的得分高1。这将其扩展为处理实例具有0个真实标签的简并情况。</target>
        </trans-unit>
        <trans-unit id="956d1e2ca58f2ab0bdb4afea5546244c422bc323" translate="yes" xml:space="preserve">
          <source>Note: See the &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;Introduction to machine learning with scikit-learn Tutorial&lt;/a&gt; for a quick run-through on the basic machine learning vocabulary used within scikit-learn.</source>
          <target state="translated">注意：有关&lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;scikit-learn中&lt;/a&gt;使用的基本机器学习词汇的快速介绍，请参见scikit-learn机器学习简介教程。</target>
        </trans-unit>
        <trans-unit id="7a9381252d0555984c45c1d913a85b0a19a4797d" translate="yes" xml:space="preserve">
          <source>Note: The default solver &amp;lsquo;adam&amp;rsquo; works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, &amp;lsquo;lbfgs&amp;rsquo; can converge faster and perform better.</source>
          <target state="translated">注意：就训练时间和验证分数而言，默认求解器&amp;ldquo; adam&amp;rdquo;在相对较大的数据集（具有数千个训练样本或更多）上的效果很好。但是，对于小型数据集，&amp;ldquo; lbfgs&amp;rdquo;可以收敛得更快并且性能更好。</target>
        </trans-unit>
        <trans-unit id="271df9bc769d4f6f6224f70e1c75a6c3d0d4e15f" translate="yes" xml:space="preserve">
          <source>Note: The parameters &lt;code&gt;test_size&lt;/code&gt; and &lt;code&gt;train_size&lt;/code&gt; refer to groups, and not to samples, as in ShuffleSplit.</source>
          <target state="translated">注意：如在ShuffleSplit中一样，参数 &lt;code&gt;test_size&lt;/code&gt; 和 &lt;code&gt;train_size&lt;/code&gt; 是指组，而不是样本。</target>
        </trans-unit>
        <trans-unit id="d9b8539222215de6f9b7a2dc0d47dad55ab9503a" translate="yes" xml:space="preserve">
          <source>Note: a one-hot encoding of y labels should use a LabelBinarizer instead.</source>
          <target state="translated">注意:y标签的一键编码应该使用LabelBinarizer代替。</target>
        </trans-unit>
        <trans-unit id="af48a21921f21ca5ba4feec03dc7cfdb83d643b6" translate="yes" xml:space="preserve">
          <source>Note: as k-means is optimizing a non-convex objective function, it will likely end up in a local optimum. Several runs with independent random init might be necessary to get a good convergence.</source>
          <target state="translated">注意:由于k-means优化的是一个非凸目标函数,它很可能最终会达到局部最优。为了获得良好的收敛性,可能需要进行多次独立的随机初始化运行。</target>
        </trans-unit>
        <trans-unit id="3bb7791854593a3b717f90311f25871cac16570c" translate="yes" xml:space="preserve">
          <source>Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:与其他交叉验证策略相反,随机拆分并不能保证所有的折线都是不同的,尽管这对于可观的数据集来说还是很有可能的。</target>
        </trans-unit>
        <trans-unit id="ec23f8c549cab8298e97ba96412d8acd5b97a819" translate="yes" xml:space="preserve">
          <source>Note: fitting on sparse input will override the setting of this parameter, using brute force.</source>
          <target state="translated">注意:在稀疏输入上的拟合将覆盖该参数的设置,使用蛮力。</target>
        </trans-unit>
        <trans-unit id="f2a5a8b06402f76d2a1b1f28ad2e90efb04ea841" translate="yes" xml:space="preserve">
          <source>Note: if you manage your own numerical data it is recommended to use an optimized file format such as HDF5 to reduce data load times. Various libraries such as H5Py, PyTables and pandas provides a Python interface for reading and writing data in that format.</source>
          <target state="translated">注意:如果你管理自己的数值数据,建议使用优化的文件格式,如HDF5,以减少数据加载时间。各种库如H5Py、PyTables和pandas提供了一个Python接口,用于读写该格式的数据。</target>
        </trans-unit>
        <trans-unit id="cb39d5746d1ab528272657961084b4241cfe3f85" translate="yes" xml:space="preserve">
          <source>Note: in the plot, &amp;ldquo;unlabeled samples&amp;rdquo; does not mean that we don&amp;rsquo;t know the labels (as in semi-supervised learning) but that the samples simply do &lt;em&gt;not&lt;/em&gt; have a label.</source>
          <target state="translated">注意：在图中，&amp;ldquo;未标记样本&amp;rdquo;并不意味着我们不知道标记（如在半监督学习中一样），而是样本根本&lt;em&gt;没有&lt;/em&gt;标记。</target>
        </trans-unit>
        <trans-unit id="403fd153dcfc1c72561472b5e34372d5de58734f" translate="yes" xml:space="preserve">
          <source>Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:和ShuffleSplit策略一样,分层随机拆分并不能保证所有的褶皱都是不同的,尽管这对于可观的数据集来说还是很有可能的。</target>
        </trans-unit>
        <trans-unit id="12964c4f090e67fee00edc80b29c8ee9b28b7b3b" translate="yes" xml:space="preserve">
          <source>Note: the implementation of &lt;code&gt;inverse_transform&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;svd_solver='randomized'&lt;/code&gt; is not the exact inverse transform of &lt;code&gt;transform&lt;/code&gt; even when &lt;code&gt;whiten=False&lt;/code&gt; (default).</source>
          <target state="translated">注：执行 &lt;code&gt;inverse_transform&lt;/code&gt; 在&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;与 &lt;code&gt;svd_solver='randomized'&lt;/code&gt; 是不准确的反变换的 &lt;code&gt;transform&lt;/code&gt; ，即使 &lt;code&gt;whiten=False&lt;/code&gt; （默认值）。</target>
        </trans-unit>
        <trans-unit id="f5990a880094bfe59d250a6cb72959923dee6858" translate="yes" xml:space="preserve">
          <source>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</source>
          <target state="translated">注意:每次调用该属性时都会重新创建列表,以便通过不存储采样数据来减少对象的内存占用。因此,获取属性的速度可能比预期的要慢。</target>
        </trans-unit>
        <trans-unit id="b4fa4a5f4c66fdf91fefb2f5d8a9d04622e730f8" translate="yes" xml:space="preserve">
          <source>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">注意：在找到至少一个有效的节点样本分区之前，分割的搜索不会停止，即使它需要有效检查多个 &lt;code&gt;max_features&lt;/code&gt; 功能也是如此。</target>
        </trans-unit>
        <trans-unit id="5af1722805bd08a73be9d8b2f383c0eb417bbdd9" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.</source>
          <target state="translated">注:本实施例仅限于标签指示器格式的二元分类任务或多标签分类任务。</target>
        </trans-unit>
        <trans-unit id="2dab9af505b98147ed8303644f1fce8db17174c7" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task.</source>
          <target state="translated">注:本实施例仅限于二元分类任务或多标签分类任务。</target>
        </trans-unit>
        <trans-unit id="229c71e40bdbb475df5a5f3c46414bb1e9fb11cf" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task.</source>
          <target state="translated">注意:本实施例仅限于二进制分类任务。</target>
        </trans-unit>
        <trans-unit id="77503a53930a4c6773bcfd9900ee0500aa085f94" translate="yes" xml:space="preserve">
          <source>Note: with the optional parameter &lt;code&gt;svd_solver='randomized'&lt;/code&gt;, we also need to give &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; the size of the lower-dimensional space &lt;code&gt;n_components&lt;/code&gt; as a mandatory input parameter.</source>
          <target state="translated">注意：使用可选参数 &lt;code&gt;svd_solver='randomized'&lt;/code&gt; ，我们还需要给&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;较低维空间 &lt;code&gt;n_components&lt;/code&gt; 的大小作为强制输入参数。</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="8365e7c537a7bde197e775fc685e729bf7dcde79" translate="yes" xml:space="preserve">
          <source>Notice that this class does not support sparse input. See &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; for an alternative with sparse data.</source>
          <target state="translated">请注意，此类不支持稀疏输入。有关稀疏数据的替代方法，请参见&lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="24a6d73ad577eece3a7c4a8079ee0685b19c5eef" translate="yes" xml:space="preserve">
          <source>Novelty detection</source>
          <target state="translated">新颖性检测</target>
        </trans-unit>
        <trans-unit id="0c6ce6f3a8c7f0ac9123407bf644e00c93b8a85c" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor (LOF)</source>
          <target state="translated">使用局部离群值因子(LOF)进行新奇度检测</target>
        </trans-unit>
        <trans-unit id="d039fa812c1beff75961eedb7fd0d56d4bd6cef8" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor is illustrated below.</source>
          <target state="translated">新颖性检测与局部离群因素如下图所示。</target>
        </trans-unit>
        <trans-unit id="0baacee2d29c362912e19aeae2a56e9b5de18251" translate="yes" xml:space="preserve">
          <source>November, 1995</source>
          <target state="translated">1995年11月</target>
        </trans-unit>
        <trans-unit id="f56b60fb36ba6e7108f33fd204674d75974c9ca0" translate="yes" xml:space="preserve">
          <source>Now looking at the computation time of the different parts, we see that the vectorization is much more expensive than learning itself. From the different algorithms, &lt;code&gt;MultinomialNB&lt;/code&gt; is the most expensive, but its overhead can be mitigated by increasing the size of the mini-batches (exercise: change &lt;code&gt;minibatch_size&lt;/code&gt; to 100 and 10000 in the program and compare).</source>
          <target state="translated">现在查看不同部分的计算时间，我们发现矢量化比学习本身要昂贵得多。从不同的算法来看， &lt;code&gt;MultinomialNB&lt;/code&gt; 是最昂贵的，但是可以通过增加小批量的大小来减轻开销（练习：在程序 &lt;code&gt;minibatch_size&lt;/code&gt; 更改为100和10000并进行比较）。</target>
        </trans-unit>
        <trans-unit id="703648eec6ac2a9ecd5332ac2370f3cbb5d40c50" translate="yes" xml:space="preserve">
          <source>Now that we have our features, we can train a classifier to try to predict the category of a post. Let&amp;rsquo;s start with a &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;na&amp;iuml;ve Bayes&lt;/a&gt; classifier, which provides a nice baseline for this task. &lt;code&gt;scikit-learn&lt;/code&gt; includes several variants of this classifier; the one most suitable for word counts is the multinomial variant:</source>
          <target state="translated">现在我们有了功能，我们可以训练分类器来尝试预测帖子的类别。让我们从&lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;朴素的贝叶斯&lt;/a&gt;分类器开始，它为该任务提供了一个很好的基准。 &lt;code&gt;scikit-learn&lt;/code&gt; 包括该分类器的多种变体；多项式最适合单词计数：</target>
        </trans-unit>
        <trans-unit id="39c382cf98b09c769e0ece49478f8e5a21269790" translate="yes" xml:space="preserve">
          <source>Now you can &lt;em&gt;predict&lt;/em&gt; new values. In this case, you&amp;rsquo;ll predict using the last image from &lt;code&gt;digits.data&lt;/code&gt;. By predicting, you&amp;rsquo;ll determine the image from the training set that best matches the last image.</source>
          <target state="translated">现在您可以&lt;em&gt;预测&lt;/em&gt;新值。在这种情况下，您将预测使用 &lt;code&gt;digits.data&lt;/code&gt; 中的最后一张图像。通过预测，您将从训练集中确定与最后一张图像最匹配的图像。</target>
        </trans-unit>
        <trans-unit id="4bde0a1195bac7469e935b78a194104a68da7a29" translate="yes" xml:space="preserve">
          <source>Now, if we repeat this computation for the remaining 2 terms in the document, we get</source>
          <target state="translated">现在,如果我们对文档中剩余的2个术语进行重复计算,我们得到的是</target>
        </trans-unit>
        <trans-unit id="ece88bcd9ec161c2a2872c2fb61e36a0d64c7a18" translate="yes" xml:space="preserve">
          <source>Now, without any further assumptions the idea of having a latent variable \(h\) would be superfluous &amp;ndash; \(x\) can be completely modelled with a mean and a covariance. We need to impose some more specific structure on one of these two parameters. A simple additional assumption regards the structure of the error covariance \(\Psi\):</source>
          <target state="translated">现在，无需任何进一步假设，具有潜在变量\（h \）的想法将是多余的&amp;ndash; \（x \）可以使用均值和协方差完全建模。我们需要对这两个参数之一施加一些更具体的结构。一个简单的附加假设涉及误差协方差\（\ Psi \）的结构：</target>
        </trans-unit>
        <trans-unit id="a31389fe4ff0ebc6e5c5d38e5dab56436f6bc483" translate="yes" xml:space="preserve">
          <source>Nu Support Vector Regression.</source>
          <target state="translated">Nu支持向量回归。</target>
        </trans-unit>
        <trans-unit id="a9b51312b4e809b61f7b24f233552372d8a4d343" translate="yes" xml:space="preserve">
          <source>Nu-Support Vector Classification.</source>
          <target state="translated">Nu-Support Vector分类。</target>
        </trans-unit>
        <trans-unit id="28831313b9efda1fb2d5e62ae541d82eeaf2e628" translate="yes" xml:space="preserve">
          <source>Number of Attributes:</source>
          <target state="translated">属性数:</target>
        </trans-unit>
        <trans-unit id="2bbc98640e09a456dee6d19b3fcc0a288b212310" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证循环中使用的CPU内核数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e056a5a70210c137f261290dad04190fbc9ce82b" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">如果multi_class ='ovr'&amp;rdquo;，则在对类进行并行化时使用的CPU内核数。当 &lt;code&gt;solver&lt;/code&gt; 设置为&amp;ldquo; liblinear&amp;rdquo;时，无论是否指定了&amp;ldquo; multi_class&amp;rdquo;，该参数都将被忽略。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="044a045266785f2237c066206c338baa3e1d5bb2" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证期间要使用的CPU数量。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="aaf36da587212084529abec535211c954c2e7c01" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">交叉验证期间要使用的CPU数量。请注意，仅当给定l1_ratio的多个值时，才使用此选项。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="52783b9f963f3f1690dd5d40572b3875e2a7ade7" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the resampling. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">重采样期间要使用的CPU数量。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a2666336978a0f4e8c547b7534c07249ba6000fd" translate="yes" xml:space="preserve">
          <source>Number of Instances:</source>
          <target state="translated">实例数:</target>
        </trans-unit>
        <trans-unit id="0bc3461e8033920222bec6b216692137eee9c091" translate="yes" xml:space="preserve">
          <source>Number of Monte Carlo samples per original feature. Equals the dimensionality of the computed feature space.</source>
          <target state="translated">每个原始特征的蒙特卡洛样本数。等于计算出的特征空间的维度。</target>
        </trans-unit>
        <trans-unit id="3262f2b1a48253ff0690a8a75cfdd12aae481720" translate="yes" xml:space="preserve">
          <source>Number of active features across every target for the model refit with the best hyperparameters got by cross-validating across all folds.</source>
          <target state="translated">在所有褶皱交叉验证得到的最佳超参数下,每个目标的活跃特征数量。</target>
        </trans-unit>
        <trans-unit id="4cbf5cb47ecd9996ec380ef5f0f19c258c9e11e4" translate="yes" xml:space="preserve">
          <source>Number of active features across every target.</source>
          <target state="translated">每个目标的活动特征数量。</target>
        </trans-unit>
        <trans-unit id="4d39e5d8b3efa9d6f8372f94e39a5395c837b600" translate="yes" xml:space="preserve">
          <source>Number of active features across every target. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">每个目标上的活动功能数量。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="e0c8a9190fa0a6b6567e6260a08bbc16ad38e0e1" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path</source>
          <target state="translated">正则化路径上的阿尔法数</target>
        </trans-unit>
        <trans-unit id="21389bf92cd8e8648f186478c091bf8c596c9371" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path, used for each l1_ratio.</source>
          <target state="translated">沿着正则化路径的阿尔法数,用于每个l1_ratio。</target>
        </trans-unit>
        <trans-unit id="cb76f13b1ca274d0ac0509e0599ee9f88692f95e" translate="yes" xml:space="preserve">
          <source>Number of best singular vectors to which to project the data for clustering.</source>
          <target state="translated">投射数据进行聚类的最佳奇异向量的数量。</target>
        </trans-unit>
        <trans-unit id="669eddc43c369820a90c37333994758dabadb237" translate="yes" xml:space="preserve">
          <source>Number of binary hidden units.</source>
          <target state="translated">二进制隐藏单元的数量。</target>
        </trans-unit>
        <trans-unit id="df5056a6b08a72e6eb298ef5a65870b5ddc8c698" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. An ignored feature at index &lt;code&gt;i&lt;/code&gt; will have &lt;code&gt;n_bins_[i] == 0&lt;/code&gt;.</source>
          <target state="translated">每个功能箱的数量。索引 &lt;code&gt;i&lt;/code&gt; 处被忽略的特征将具有 &lt;code&gt;n_bins_[i] == 0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9e19457800c5864e1fbdcc0291b0ef620abfd78c" translate="yes" xml:space="preserve">
          <source>Number of bins. A bigger number requires more data.</source>
          <target state="translated">仓的数量。数字越大,需要的数据越多。</target>
        </trans-unit>
        <trans-unit id="f70f556044c9d189136c9439d7b869763e660892" translate="yes" xml:space="preserve">
          <source>Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples.</source>
          <target state="translated">在最后的聚类步骤后的聚类数量,将叶子中的子聚类视为新样本。</target>
        </trans-unit>
        <trans-unit id="d93f166299b2fe351648697f50539b771bbcab5f" translate="yes" xml:space="preserve">
          <source>Number of clusters to extract.</source>
          <target state="translated">要提取的集群数量。</target>
        </trans-unit>
        <trans-unit id="eb68d1899db83f395f515eac11a92a2f39369f2a" translate="yes" xml:space="preserve">
          <source>Number of combinations taken into account from &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples.</source>
          <target state="translated">从&amp;ldquo; n选择k&amp;rdquo;中考虑的组合数，其中n是样本数，k是子样本数。</target>
        </trans-unit>
        <trans-unit id="cd12f5ccc87c2314d1a7462c1838eb4fba879a35" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt; n_classes - 1) for dimensionality reduction.</source>
          <target state="translated">用于降维的组件数（&amp;lt;n_classes-1）。</target>
        </trans-unit>
        <trans-unit id="678dcaccd382015a606461223e75a521f8c270e3" translate="yes" xml:space="preserve">
          <source>Number of components to keep</source>
          <target state="translated">需要保留的组件数量</target>
        </trans-unit>
        <trans-unit id="209051725a6de8e5e1e5fa7a1e74f7eb06a44fec" translate="yes" xml:space="preserve">
          <source>Number of components to keep.</source>
          <target state="translated">要保留的部件数量。</target>
        </trans-unit>
        <trans-unit id="d04623123bcfd2ce2b9c37b5c1e9535768de28a7" translate="yes" xml:space="preserve">
          <source>Number of components to keep. If &lt;code&gt;n_components `` is ``None&lt;/code&gt;, then &lt;code&gt;n_components&lt;/code&gt; is set to &lt;code&gt;min(n_samples, n_features)&lt;/code&gt;.</source>
          <target state="translated">要保留的组件数。如果 &lt;code&gt;n_components `` is ``None&lt;/code&gt; ，则 &lt;code&gt;n_components&lt;/code&gt; 设置为 &lt;code&gt;min(n_samples, n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="864a5ed4a409c99b07b3c02fc85e293c54d58811" translate="yes" xml:space="preserve">
          <source>Number of components to keep. if n_components is not set all components are kept:</source>
          <target state="translated">如果没有设置n_components,则保留所有组件。</target>
        </trans-unit>
        <trans-unit id="b681f0aabf7a4e88ff6e07d02e6d3053416c7e30" translate="yes" xml:space="preserve">
          <source>Number of components to use. If none is passed, all are used.</source>
          <target state="translated">要使用的组件数量。如果没有通过,则全部使用。</target>
        </trans-unit>
        <trans-unit id="a4c9442f9290e02b19f88b85f02bacea3cfec6f7" translate="yes" xml:space="preserve">
          <source>Number of components, if n_components is not set all features are kept.</source>
          <target state="translated">组件的数量,如果没有设置n_components,则会保留所有的特征。</target>
        </trans-unit>
        <trans-unit id="cd25fc9de4a04b081f0b9a2b60926bce89997152" translate="yes" xml:space="preserve">
          <source>Number of components. If None, all non-zero components are kept.</source>
          <target state="translated">组件的数量。如果为 &quot;无&quot;,则保留所有非零组件。</target>
        </trans-unit>
        <trans-unit id="45f800ea0c8bd716a5f59f6d34dd8fdf95b8f22e" translate="yes" xml:space="preserve">
          <source>Number of components:</source>
          <target state="translated">组成部分的数量。</target>
        </trans-unit>
        <trans-unit id="08ad46845beb5661bae33c15135ad1635029f790" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">跨折时要并行运行的芯数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0da9d602da12f13ca29bd75af12cc8c869e57a9f" translate="yes" xml:space="preserve">
          <source>Number of dictionary atoms to extract.</source>
          <target state="translated">要提取的字典原子的数量。</target>
        </trans-unit>
        <trans-unit id="5227337d1c8f00f0cc5985a46091828c912745d3" translate="yes" xml:space="preserve">
          <source>Number of digits for formatting output floating point values. When &lt;code&gt;output_dict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this will be ignored and the returned values will not be rounded.</source>
          <target state="translated">用于格式化输出浮点值的位数。当 &lt;code&gt;output_dict&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt; 时，它将被忽略，并且返回的值将不会四舍五入。</target>
        </trans-unit>
        <trans-unit id="393e0ab0962f61be4ea05f66f75cf83a58c8acb8" translate="yes" xml:space="preserve">
          <source>Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.</source>
          <target state="translated">每个节点的杂质、阈值和值属性的值中浮点的精度位数。</target>
        </trans-unit>
        <trans-unit id="857511ca3ff53ac74c7a9a64491518f8a98aa57b" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities.</source>
          <target state="translated">浸透异样的维度数。</target>
        </trans-unit>
        <trans-unit id="60a7a9ccef477eb7d360b15d4ec93323fc3722cf" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities. If an &lt;code&gt;init&lt;/code&gt; array is provided, this option is overridden and the shape of &lt;code&gt;init&lt;/code&gt; is used to determine the dimensionality of the embedding space.</source>
          <target state="translated">沉浸差异的维数。如果提供了 &lt;code&gt;init&lt;/code&gt; 数组，则会覆盖此选项，并且 &lt;code&gt;init&lt;/code&gt; 的形状用于确定嵌入空间的维数。</target>
        </trans-unit>
        <trans-unit id="f601fdb82b970f8ccae9e3060c9f42a8faed55c3" translate="yes" xml:space="preserve">
          <source>Number of documents to use in each EM iteration. Only used in online learning.</source>
          <target state="translated">每次EM迭代中使用的文件数量。仅用于在线学习。</target>
        </trans-unit>
        <trans-unit id="25fead66533b3559387b2fcbff51a361b6ce623f" translate="yes" xml:space="preserve">
          <source>Number of eigen vectors to use for the spectral embedding</source>
          <target state="translated">用于光谱嵌入的特征向量的数量。</target>
        </trans-unit>
        <trans-unit id="70fb7e9ad9dffd747feff757e8b6b2c3b8c3ad21" translate="yes" xml:space="preserve">
          <source>Number of examples per minibatch.</source>
          <target state="translated">每个小批量的例子数量。</target>
        </trans-unit>
        <trans-unit id="f3a87cabcd8ae2a3f47b41980367db8a154ace86" translate="yes" xml:space="preserve">
          <source>Number of features</source>
          <target state="translated">特征数量</target>
        </trans-unit>
        <trans-unit id="f26773f39b3b679c0daff789f714ad69f2880ea0" translate="yes" xml:space="preserve">
          <source>Number of features to construct. How many data points will be used to construct the mapping.</source>
          <target state="translated">要构建的特征数量。用多少数据点来构建图谱。</target>
        </trans-unit>
        <trans-unit id="8bfcb7d61331a9745e723fb4ee723054b5ce91e8" translate="yes" xml:space="preserve">
          <source>Number of folds. Must be at least 2.</source>
          <target state="translated">褶皱的数量。必须是至少2个。</target>
        </trans-unit>
        <trans-unit id="37148505c5ccd477f2cd9888510233bf49ab48d7" translate="yes" xml:space="preserve">
          <source>Number of grid points. The path is linearly reinterpolated on a grid between 0 and 1 before computing the scores.</source>
          <target state="translated">网格点的数量。在计算分数之前,路径在0和1之间的网格上线性重插。</target>
        </trans-unit>
        <trans-unit id="609fe53affef0db7e95afe01e9b3b2b42cfee225" translate="yes" xml:space="preserve">
          <source>Number of groups (&lt;code&gt;p&lt;/code&gt;) to leave out in the test split.</source>
          <target state="translated">要在测试分组中忽略的组数（ &lt;code&gt;p&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="7836a44e33451a2adc5e90b29cc50de43f4df6df" translate="yes" xml:space="preserve">
          <source>Number of iteration done before the next print.</source>
          <target state="translated">下一次打印前的迭代次数。</target>
        </trans-unit>
        <trans-unit id="c7ee7fcff30c38dbe60673fcfaba39d5dcac363e" translate="yes" xml:space="preserve">
          <source>Number of iterations corresponding to the best results. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">对应于最佳结果的迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="b89cf5a40a3578805b3d3e22f18c4e3365baf655" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;code&gt;randomized_svd&lt;/code&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">随机SVD求解器的迭代次数。ARPACK不使用。默认值大于 &lt;code&gt;randomized_svd&lt;/code&gt; 中的默认值，以处理可能具有较大的缓慢衰减频谱的稀疏矩阵。</target>
        </trans-unit>
        <trans-unit id="b158b03d08af1b718d3d75c350a03244a2d1a76a" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method computed by svd_solver == &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">svd_solver =='随机化'计算出的幂方法的迭代次数。</target>
        </trans-unit>
        <trans-unit id="ea8482c683ec2d466d38eba89e78f2c408d93dba" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method. 3 by default. Only used if &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;</source>
          <target state="translated">幂方法的迭代次数。默认为3。仅在 &lt;code&gt;svd_method&lt;/code&gt; 等于&amp;ldquo;随机化&amp;rdquo;时使用</target>
        </trans-unit>
        <trans-unit id="e2a3f7897a04130ec9ab6e8a06f184c73a2db962" translate="yes" xml:space="preserve">
          <source>Number of iterations needed for the spatial median.</source>
          <target state="translated">空间中位数所需的迭代次数。</target>
        </trans-unit>
        <trans-unit id="0a6f367644c8353f5e90ff32f9e722b8b3c35762" translate="yes" xml:space="preserve">
          <source>Number of iterations of the EM step.</source>
          <target state="translated">EM步骤的迭代次数。</target>
        </trans-unit>
        <trans-unit id="ca85b057132e8737cc9bd5d9895d1c2f0a3952a0" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component.</source>
          <target state="translated">每个组件的NIPALS内循环的迭代次数。</target>
        </trans-unit>
        <trans-unit id="38592412005a60e12235ac166647e6d24941d551" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component. Not useful if the algorithm provided is &amp;ldquo;svd&amp;rdquo;.</source>
          <target state="translated">每个组件的NIPALS内部循环的迭代次数。如果提供的算法是&amp;ldquo; svd&amp;rdquo;，则无用。</target>
        </trans-unit>
        <trans-unit id="b3f0661f5b6a537d1cfcf27ec4e37f08f53a4a65" translate="yes" xml:space="preserve">
          <source>Number of iterations run for the optimal alpha.</source>
          <target state="translated">最佳α的迭代次数。</target>
        </trans-unit>
        <trans-unit id="c9d82135ee15642aa7ae8817dc570334ab80622b" translate="yes" xml:space="preserve">
          <source>Number of iterations run.</source>
          <target state="translated">运行的迭代次数。</target>
        </trans-unit>
        <trans-unit id="cc453132656fb5fe083f1f7f5f3c0a7066108d51" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">运行的迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为 &lt;code&gt;True&lt;/code&gt; 时才返回。</target>
        </trans-unit>
        <trans-unit id="346838eb1c236609499116f6804a1aeab6029a68" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">运行的迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="bae285cae0e2d21ef6dbbaa8dd54db30234b47e0" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if return_n_iter is set to True.</source>
          <target state="translated">运行的迭代次数。只有return_n_iter设置为True时才会返回。</target>
        </trans-unit>
        <trans-unit id="6e040a3af3a9255e0d8c4455bc3543184ccbc3ff" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to an invalid model defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">由于 &lt;code&gt;is_model_valid&lt;/code&gt; 定义的模型无效，因此跳过了迭代次数。</target>
        </trans-unit>
        <trans-unit id="51f697c488b6017321338ddb492864c9436800d7" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to finding zero inliers.</source>
          <target state="translated">由于发现零离群值而跳过的迭代次数。</target>
        </trans-unit>
        <trans-unit id="6eebd535eebcad36fc18ca23295141a0bc8384b3" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt;.</source>
          <target state="translated">由于 &lt;code&gt;is_data_valid&lt;/code&gt; 定义的数据无效，因此跳过了迭代次数。</target>
        </trans-unit>
        <trans-unit id="2b48b7f3d47c667152c7041a648c896ae52b12ff" translate="yes" xml:space="preserve">
          <source>Number of iterations taken to converge.</source>
          <target state="translated">收敛的迭代次数。</target>
        </trans-unit>
        <trans-unit id="e35e76f80d1bcb32a849fe5cd7421a6593683d9d" translate="yes" xml:space="preserve">
          <source>Number of iterations that fmin_l_bfgs_b has run for.</source>
          <target state="translated">fmin_l_bfgs_b运行的次数。</target>
        </trans-unit>
        <trans-unit id="e6fe9562687f3b9f37db26e9dd5d7295821884aa" translate="yes" xml:space="preserve">
          <source>Number of iterations to perform.</source>
          <target state="translated">要执行的迭代次数。</target>
        </trans-unit>
        <trans-unit id="744edb5cd8af9d3cbdec3cef824f76ed36468258" translate="yes" xml:space="preserve">
          <source>Number of iterations with no change in the number of estimated clusters that stops the convergence.</source>
          <target state="translated">停止收敛的估计聚类数量不变的迭代次数。</target>
        </trans-unit>
        <trans-unit id="1bb6572e9c67b7f2e1d3c0099c8130bc63fa4d36" translate="yes" xml:space="preserve">
          <source>Number of iterations with no improvement to wait before early stopping.</source>
          <target state="translated">在提前停止之前,等待没有改善的迭代次数。</target>
        </trans-unit>
        <trans-unit id="427bd42a1575036c8163feb881b5305713a1194a" translate="yes" xml:space="preserve">
          <source>Number of iterations. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">迭代次数。仅当 &lt;code&gt;return_n_iter&lt;/code&gt; 设置为True 时才返回。</target>
        </trans-unit>
        <trans-unit id="20dbe7868d12b42e72b8007b758b8aa006423eb6" translate="yes" xml:space="preserve">
          <source>Number of iterations/sweeps over the training dataset to perform during training.</source>
          <target state="translated">训练过程中对训练数据集进行的迭代/扫频次数。</target>
        </trans-unit>
        <trans-unit id="805e89de9bc259ba0d4faba86a9892d5aeb2c894" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">要并行运行的作业数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="68e07911a64110ae2d25f4573c1be042d5d1283e" translate="yes" xml:space="preserve">
          <source>Number of label for each output.</source>
          <target state="translated">每个输出的标签数量。</target>
        </trans-unit>
        <trans-unit id="bd419af7c37c78ed35cd8f556746c5d780f24447" translate="yes" xml:space="preserve">
          <source>Number of layers.</source>
          <target state="translated">层数:</target>
        </trans-unit>
        <trans-unit id="4192e6479d3e36a298ef5ede4c2274eeba61eb5b" translate="yes" xml:space="preserve">
          <source>Number of leaves in the hierarchical tree.</source>
          <target state="translated">层次树的叶子数量。</target>
        </trans-unit>
        <trans-unit id="eff81c828ce86aeb5087b71b68182742b417d4b0" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors for nearest_neighbors graph building.</source>
          <target state="translated">构建nearest_neighbors图的最近邻居数量。</target>
        </trans-unit>
        <trans-unit id="37fe95cfc748f25efeacf97021fc7a2313be0b5a" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample.</source>
          <target state="translated">每个样本的邻居数量。</target>
        </trans-unit>
        <trans-unit id="51b538d5b2a3f95b9485557e25d620a9a782f3b4" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample. (default is value passed to the constructor).</source>
          <target state="translated">每个样本的邻域数量(默认为传递给构造函数的值)。(默认是传递给构造函数的值)。</target>
        </trans-unit>
        <trans-unit id="d3cee20cf7566ae95a6af940493b4c430f93d3a6" translate="yes" xml:space="preserve">
          <source>Number of neighbors required. If not provided, this will return the number specified at the initialization.</source>
          <target state="translated">需要的邻居数量。如果没有提供,将返回初始化时指定的数量。</target>
        </trans-unit>
        <trans-unit id="1e55799760cfa2d3bdbd572fe607c1fc4b77b9d7" translate="yes" xml:space="preserve">
          <source>Number of neighbors to be returned from query function when it is not provided to the &lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">未提供给&lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;方法的查询函数返回的邻居数。</target>
        </trans-unit>
        <trans-unit id="3262363328a422de3ed07567136a319deb9ad271" translate="yes" xml:space="preserve">
          <source>Number of neighbors to get (default is the value passed to the constructor).</source>
          <target state="translated">要获取的邻居数量(默认是传递给构造函数的值)。</target>
        </trans-unit>
        <trans-unit id="02076e172db6b5e77d67d9ae83e2b88dc66a094e" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。</target>
        </trans-unit>
        <trans-unit id="e28eb76463a74cc573864c82f5c8b8d60708a92f" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。</target>
        </trans-unit>
        <trans-unit id="4a844d73b7e4afd6cea1487cf59defb5c0385114" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries. If n_neighbors is larger than the number of samples provided, all samples will be used.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。如果n_neighbors大于提供的样本数，则将使用所有样本。</target>
        </trans-unit>
        <trans-unit id="7e98c15b26d0846d8c1e878d641afc0e3d115b38" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;查询的邻居数。</target>
        </trans-unit>
        <trans-unit id="70cd89c4110a42556e2c733194f1c90f3d647ddb" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">用于连续变量的MI估计的邻居数，请参见&lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;和&lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;。较高的值会减少估计的方差，但可能会带来偏差。</target>
        </trans-unit>
        <trans-unit id="237e706a6f5317f1b4ad85e94d1e882cb7b24021" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">用于连续变量的MI估计的邻居数，请参见&lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;和&lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;。较高的值会减少估计的方差，但可能会带来偏差。</target>
        </trans-unit>
        <trans-unit id="9f8819cc7687f8afeb7c24c0200033a234d0c39c" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use when constructing the affinity matrix using the nearest neighbors method. Ignored for &lt;code&gt;affinity='rbf'&lt;/code&gt;.</source>
          <target state="translated">使用最近邻居方法构造亲和力矩阵时要使用的邻居数量。被忽略为 &lt;code&gt;affinity='rbf'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c37287ec818bb6dad17b995ed5729153d9a8118d" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; and &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">在解决方案的每一列中定位的非零系数的数量。仅由 &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; 和 &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; ，在 &lt;code&gt;omp&lt;/code&gt; 情况下被 &lt;code&gt;alpha&lt;/code&gt; 覆盖。</target>
        </trans-unit>
        <trans-unit id="27f9bf5a85bc89aa70ea3dbacba13e73a444a9f8" translate="yes" xml:space="preserve">
          <source>Number of outputs.</source>
          <target state="translated">产出数量:</target>
        </trans-unit>
        <trans-unit id="a01758eccae198371ad1fbda71e0227c6924ab24" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">要运行的并行作业数。除非在&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;上下文中，否则 &lt;code&gt;None&lt;/code&gt; 表示1 。 &lt;code&gt;-1&lt;/code&gt; 表示使用所有处理器。有关更多详细信息，请参见&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;词汇表&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="89260d16706c6571daecae9b230dfb394e4f8e34" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are produced.</source>
          <target state="translated">产生的参数设置数量。</target>
        </trans-unit>
        <trans-unit id="26680dedc0c193794be077118d1d33ec7cee22de" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.</source>
          <target state="translated">n_iter对运行时间与解决方案的质量进行了权衡。</target>
        </trans-unit>
        <trans-unit id="9b3af5a87173ff58737497b2a7b2dff4ac22b716" translate="yes" xml:space="preserve">
          <source>Number of passes over the dataset.</source>
          <target state="translated">对数据集的访问次数。</target>
        </trans-unit>
        <trans-unit id="e919298382f2b30ec9254222b02df5121a7447b9" translate="yes" xml:space="preserve">
          <source>Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified &lt;code&gt;leaf_size&lt;/code&gt;, a leaf node is guaranteed to satisfy &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt;, except in the case that &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt;.</source>
          <target state="translated">切换为蛮力的点数。更改leaf_size不会影响查询的结果，但是会显着影响查询的速度以及存储构造的树所需的内存。存储树比例尺所需的内存量约为n_samples / leaf_size。对于指定的 &lt;code&gt;leaf_size&lt;/code&gt; ，保证叶子节点满足 &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt; ，除非 &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="74f0e4f1324b195e40b6b67840245cc6639acde5" translate="yes" xml:space="preserve">
          <source>Number of power iterations used to stabilize the result</source>
          <target state="translated">用于稳定结果的幂级迭代次数。</target>
        </trans-unit>
        <trans-unit id="3af0fded49ca0f3c99c5f4242edefb1980f1ee1e" translate="yes" xml:space="preserve">
          <source>Number of power iterations. It can be used to deal with very noisy problems. When &amp;lsquo;auto&amp;rsquo;, it is set to 4, unless &lt;code&gt;n_components&lt;/code&gt; is small (&amp;lt; .1 * min(X.shape)) &lt;code&gt;n_iter&lt;/code&gt; in which case is set to 7. This improves precision with few components.</source>
          <target state="translated">功率迭代次数。它可以用于处理非常嘈杂的问题。如果为'auto'，则将其设置为4，除非 &lt;code&gt;n_components&lt;/code&gt; 很小（&amp;lt;.1 * min（X.shape）），在这种情况下，将 &lt;code&gt;n_iter&lt;/code&gt; 设置为7。这将提高组件数量的精度。</target>
        </trans-unit>
        <trans-unit id="7c2b5ab18e2bf242894b9a2ecca14a388d432f49" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The string can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">并行执行的预调度作业数（默认为全部）。该选项可以减少分配的内存。该字符串可以是类似于&amp;ldquo; 2 * n_jobs&amp;rdquo;的表达式。</target>
        </trans-unit>
        <trans-unit id="344e1da2c8fa0e4b376ce3e457a99189b911e25a" translate="yes" xml:space="preserve">
          <source>Number of previous iterations completed on the dictionary used for initialization.</source>
          <target state="translated">用于初始化的字典上完成的前几次迭代次数。</target>
        </trans-unit>
        <trans-unit id="20853d9102158a366a61d28a6b2cb29c20c98681" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative density function.</source>
          <target state="translated">要计算的量子数。它与用于分解累积密度函数的地标数目相对应。</target>
        </trans-unit>
        <trans-unit id="e4aaf1e86836dfafd99ac1220487fd647e794f84" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried with the k-means algorithm.</source>
          <target state="translated">用k-means算法尝试的随机初始化次数。</target>
        </trans-unit>
        <trans-unit id="b43bc8af90e8df6a17a3d2db5f152fc9e0f7509e" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the &lt;code&gt;n_init&lt;/code&gt; initializations as measured by inertia.</source>
          <target state="translated">尝试的随机初始化的数量。与KMeans相反，该算法仅使用一次惯性测量的 &lt;code&gt;n_init&lt;/code&gt; 最佳初始化，仅运行一次。</target>
        </trans-unit>
        <trans-unit id="2a775249dab61ada8ba714fbef3fe2a6cd5e7f9a" translate="yes" xml:space="preserve">
          <source>Number of random selection trials until one of the stop criteria is met. It is always &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt;.</source>
          <target state="translated">达到停止标准之一之前的随机选择试验次数。它总是 &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ddb00b53d153c760e3c244cb1587828c964053be" translate="yes" xml:space="preserve">
          <source>Number of randomized models.</source>
          <target state="translated">随机模型的数量。</target>
        </trans-unit>
        <trans-unit id="6e7920a40024bb45accfba5d3a9412bad8885ccd" translate="yes" xml:space="preserve">
          <source>Number of re-shuffling &amp;amp; splitting iterations.</source>
          <target state="translated">重新改组和拆分迭代的次数。</target>
        </trans-unit>
        <trans-unit id="8c1de77526ac5586c3170ef35d398449f2b6a01e" translate="yes" xml:space="preserve">
          <source>Number of rows and columns (resp.) in the bicluster.</source>
          <target state="translated">双簇中的行数和列数(简称)。</target>
        </trans-unit>
        <trans-unit id="ad1b9067ab876b7409a0c802cf769015719aca95" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">拟合过程中每个(类、特征)遇到的样本数。这个值是由提供的样本权重加权的。</target>
        </trans-unit>
        <trans-unit id="c92a24738a539e752aec89fe917078bdb81b48d8" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">在拟合过程中,每个类所遇到的样本数量。这个值是由提供的样本权重加权的。</target>
        </trans-unit>
        <trans-unit id="7d9434e4be81d003217d0ff99bec2958d6cf8f1c" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each feature during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">在拟合过程中,每个特征遇到的样本数量。这个值是由提供的样本权重加权的。</target>
        </trans-unit>
        <trans-unit id="4189046e920c071a46d31153d30f2c5546e5d75d" translate="yes" xml:space="preserve">
          <source>Number of samples in a subcluster.</source>
          <target state="translated">一个子群中的样本数量。</target>
        </trans-unit>
        <trans-unit id="b1b8d68fdf55246f42bd4140ab8cdd3ea5232e3c" translate="yes" xml:space="preserve">
          <source>Number of samples seen so far, excluded X.</source>
          <target state="translated">迄今所见样本数,排除X。</target>
        </trans-unit>
        <trans-unit id="f3eb4ebcff443a5740a69d115e4c7d66ed2b7058" translate="yes" xml:space="preserve">
          <source>Number of samples to calculate the parameters. This is at least the number of features (plus 1 if fit_intercept=True) and the number of samples as a maximum. A lower number leads to a higher breakdown point and a low efficiency while a high number leads to a low breakdown point and a high efficiency. If None, take the minimum number of subsamples leading to maximal robustness. If n_subsamples is set to n_samples, Theil-Sen is identical to least squares.</source>
          <target state="translated">计算参数的样本数。这至少是特征数(如果fit_intercept=True,则加1)和最大样本数。较低的数字导致较高的击穿点和较低的效率,而较高的数字导致较低的击穿点和较高的效率。如果None,取导致最大鲁棒性的最小子样本数。如果n_subsamples设置为n_samples,则Theil-Sen与最小二乘法相同。</target>
        </trans-unit>
        <trans-unit id="fc350dda13f5c287c8548b6575ceb1d2c780f61c" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. Defaults to 1.</source>
          <target state="translated">要生成的样本数量。默认值为1。</target>
        </trans-unit>
        <trans-unit id="e94e897f1bb653d4e0feaefd5987d4a553f8af8b" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays.</source>
          <target state="translated">要生成的样本数量。如果将其设为 &quot;无&quot;,则会自动设置为数组的第一维。</target>
        </trans-unit>
        <trans-unit id="1a167b23f9bb21704b10da0ef2fc738d507dce40" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays. If replace is False it should not be larger than the length of arrays.</source>
          <target state="translated">要生成的样本数量。如果留为None,则自动设置为数组的第一维。如果替换为False,则不应大于数组的长度。</target>
        </trans-unit>
        <trans-unit id="37b65d0e64d2d03034e5f2f5fa109bac79447708" translate="yes" xml:space="preserve">
          <source>Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.</source>
          <target state="translated">为加快初始化速度而随机抽样的样本数(有时以牺牲精度为代价):唯一的算法是通过在数据的随机子集上运行批量KMeans来初始化的。这需要大于n_clusters。</target>
        </trans-unit>
        <trans-unit id="79fd133ee683290a8c4b438718235e4555547cff" translate="yes" xml:space="preserve">
          <source>Number of samples. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">样本数。如果给定一个数组,它将以数组的方式计算一个安全的成分数。</target>
        </trans-unit>
        <trans-unit id="ea4ca73ab41ec6033a853674e7fbc815a311d3cf" translate="yes" xml:space="preserve">
          <source>Number of samples. Pass n_samples when the slices are to be used for sparse matrix indexing; slicing off-the-end raises an exception, while it works for NumPy arrays.</source>
          <target state="translated">采样数,当切片用于稀疏矩阵索引时,传递n_samples。当切片要用于稀疏矩阵索引时,传递n_samples;在结束时切片会引发一个异常,而对于NumPy数组来说,它是可行的。</target>
        </trans-unit>
        <trans-unit id="a75d9ceb8c321c78e9909168b2356ee01f06d1c4" translate="yes" xml:space="preserve">
          <source>Number of singular values and vectors to extract.</source>
          <target state="translated">要提取的单值和向量的数量。</target>
        </trans-unit>
        <trans-unit id="9259a302604f8c3d052d9766a0665f74598f4a66" translate="yes" xml:space="preserve">
          <source>Number of singular vectors to check.</source>
          <target state="translated">要检查的奇异向量的数量。</target>
        </trans-unit>
        <trans-unit id="4e03fb606fcab969781bb42da4618d24e54a8291" translate="yes" xml:space="preserve">
          <source>Number of slices to generate.</source>
          <target state="translated">要生成的片数。</target>
        </trans-unit>
        <trans-unit id="c55cc369cb9552b44b4a575f3aae7b0b751a97c8" translate="yes" xml:space="preserve">
          <source>Number of sparse atoms to extract.</source>
          <target state="translated">要提取的稀疏原子的数量。</target>
        </trans-unit>
        <trans-unit id="133c33b7f976c18813a243c5632b24f2c8e81111" translate="yes" xml:space="preserve">
          <source>Number of splits. Must be at least 2.</source>
          <target state="translated">分割的数量。必须至少是2个。</target>
        </trans-unit>
        <trans-unit id="a6bce09538dcde7e7ff60020a73de4974cae38ac" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of EM to reach the convergence.</source>
          <target state="translated">EM的最佳拟合达到收敛所使用的步数。</target>
        </trans-unit>
        <trans-unit id="aec50834e9d4a500ee385c37d29d58bdc624bb7e" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of inference to reach the convergence.</source>
          <target state="translated">推理的最佳拟合达到收敛所使用的步数。</target>
        </trans-unit>
        <trans-unit id="ef96b42c053cf6cd51d23012a0a52b84b2a07604" translate="yes" xml:space="preserve">
          <source>Number of support vectors for each class.</source>
          <target state="translated">每个类的支持向量的数量。</target>
        </trans-unit>
        <trans-unit id="abc9da602c481111cdc9cad2b9a2ec618fddfb11" translate="yes" xml:space="preserve">
          <source>Number of test samples in this split.</source>
          <target state="translated">本次拆分的测试样本数量。</target>
        </trans-unit>
        <trans-unit id="35ccbd0ed91056f0b431a8e36f769a8655c75e9b" translate="yes" xml:space="preserve">
          <source>Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.</source>
          <target state="translated">k-means算法在不同中心点种子下运行的次数。最终结果将是n_init连续运行的惯性的最佳输出。</target>
        </trans-unit>
        <trans-unit id="f584f00fb96d0392221b2f107adcb2345328d3b9" translate="yes" xml:space="preserve">
          <source>Number of times cross-validator needs to be repeated.</source>
          <target state="translated">交叉验证器需要重复的次数。</target>
        </trans-unit>
        <trans-unit id="5d2e8dfe07ab898c902f4c479175b6b09037f98d" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress.</source>
          <target state="translated">SMACOF算法在不同初始化下运行的次数。最终结果将是所有运行中的最佳输出,由最终应力最小的运行确定。</target>
        </trans-unit>
        <trans-unit id="61d47a44584bfde40c1396e5d7fc8603c469e589" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress. If &lt;code&gt;init&lt;/code&gt; is provided, this option is overridden and a single run is performed.</source>
          <target state="translated">SMACOF算法将使用不同的初始化运行的次数。最终结果将是运行的最佳输出，取决于最终应力最小的运行。如果提供了 &lt;code&gt;init&lt;/code&gt; ，则将覆盖此选项并执行一次运行。</target>
        </trans-unit>
        <trans-unit id="279a7d188f8d456ddd160319a5480a2db5aa1c81" translate="yes" xml:space="preserve">
          <source>Number of times to permute &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; 的置换次数。</target>
        </trans-unit>
        <trans-unit id="69631a318e07c7e122bb29c914f2e0417bbb3ea3" translate="yes" xml:space="preserve">
          <source>Number of top features to select. The &amp;ldquo;all&amp;rdquo; option bypasses selection, for use in a parameter search.</source>
          <target state="translated">要选择的主要功能数。&amp;ldquo; all&amp;rdquo;选项绕过选择，用于参数搜索。</target>
        </trans-unit>
        <trans-unit id="da4c15da76668749b2d08dac7e93fa89fa01cae3" translate="yes" xml:space="preserve">
          <source>Number of topics.</source>
          <target state="translated">专题数量:</target>
        </trans-unit>
        <trans-unit id="fbddcfb20eac49b636d0567ae2783e45f24d5db9" translate="yes" xml:space="preserve">
          <source>Number of trees in the LSH Forest.</source>
          <target state="translated">LSH森林中的树木数量。</target>
        </trans-unit>
        <trans-unit id="f59a66952049f5c09c592626a93864184fb52de6" translate="yes" xml:space="preserve">
          <source>Number of trees in the forest.</source>
          <target state="translated">森林中的树木数量;</target>
        </trans-unit>
        <trans-unit id="883143c355bb70d9c124548ac182b0a674cf4c90" translate="yes" xml:space="preserve">
          <source>Number of values per feature.</source>
          <target state="translated">每个特征值的数量。</target>
        </trans-unit>
        <trans-unit id="3d3c8a841ea2fec708f92a22e6cb69db77e1725b" translate="yes" xml:space="preserve">
          <source>Number of vectors to use in calculating the SVD. Corresponds to &lt;code&gt;ncv&lt;/code&gt; when &lt;code&gt;svd_method=arpack&lt;/code&gt; and &lt;code&gt;n_oversamples&lt;/code&gt; when &lt;code&gt;svd_method&lt;/code&gt; is &amp;lsquo;randomized`.</source>
          <target state="translated">用于计算SVD的向量数。对应于 &lt;code&gt;ncv&lt;/code&gt; 当 &lt;code&gt;svd_method=arpack&lt;/code&gt; 和 &lt;code&gt;n_oversamples&lt;/code&gt; 当 &lt;code&gt;svd_method&lt;/code&gt; 是&amp;ldquo;randomized`。</target>
        </trans-unit>
        <trans-unit id="cfc2be0c624984ee3eedecc63144bb2eb0e00cd3" translate="yes" xml:space="preserve">
          <source>Numbers of training examples that has been used to generate the learning curve. Note that the number of ticks might be less than n_ticks because duplicate entries will be removed.</source>
          <target state="translated">用来生成学习曲线的训练例子的数量。请注意,ticks的数量可能会小于n_ticks,因为重复的条目会被删除。</target>
        </trans-unit>
        <trans-unit id="89c43bf4b62114e4d6b82aa7a39bcd64acde71ea" translate="yes" xml:space="preserve">
          <source>Numeric stopping criterion (WRITEME). 1e-3 by default.</source>
          <target state="translated">数值停止标准(WRITEME)。默认为1e-3。</target>
        </trans-unit>
        <trans-unit id="546b4b9a9bb1a271c23a369b5102c7b719bb257b" translate="yes" xml:space="preserve">
          <source>Numerical solver to use.</source>
          <target state="translated">数值求解器使用。</target>
        </trans-unit>
        <trans-unit id="1bda3e35c6cc189118f551c9ef807d4c37dc07f6" translate="yes" xml:space="preserve">
          <source>Numerical solver to use: &amp;lsquo;cd&amp;rsquo; is a Coordinate Descent solver. &amp;lsquo;mu&amp;rsquo; is a Multiplicative Update solver.</source>
          <target state="translated">要使用的数值求解器：'cd'是坐标下降求解器。'mu'是一个乘法更新求解器。</target>
        </trans-unit>
        <trans-unit id="c42d401e991cba0a784aff1388e26ed9b57a65e8" translate="yes" xml:space="preserve">
          <source>O. Ledoit and M. Wolf, &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">O. Ledoit和M. Wolf，&amp;ldquo;大尺寸协方差矩阵的适当条件估计器&amp;rdquo;，《多元分析杂志》，第88卷，第2期，2004年2月，第365-411页。</target>
        </trans-unit>
        <trans-unit id="e39d7c7a6dfc71c75f7fd3b1688e4255ab0569b5" translate="yes" xml:space="preserve">
          <source>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.</source>
          <target state="translated">O.L.Mangasarian,W.N.Street and W.H.Wolberg.乳腺癌诊断和预后通过线性编程。运营研究,43(4),570-577页,1995年7月-8月。</target>
        </trans-unit>
        <trans-unit id="dea6ae2f186812bc2bf8114a674ec0e8c8de8039" translate="yes" xml:space="preserve">
          <source>OAS is a particular form of shrinkage described in &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">Chen等人在IEEE Trans的&amp;ldquo; MMSE协方差估计的收缩算法&amp;rdquo;中描述了OAS是一种特殊的收缩形式。在标志上。Proc。，第58卷，第10期，2010年10月。</target>
        </trans-unit>
        <trans-unit id="f3fd8009dd2433d1a63abbabb480a18d05e74108" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines</source>
          <target state="translated">稀释葡萄酒的OD280/OD315</target>
        </trans-unit>
        <trans-unit id="2f76e133c144664f6ceed4509b6ad3d9fe14a67d" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines:</source>
          <target state="translated">稀释葡萄酒的OD280/OD315。</target>
        </trans-unit>
        <trans-unit id="9ce3bd4224c8c1780db56b4125ecf3f24bf748b7" translate="yes" xml:space="preserve">
          <source>OK</source>
          <target state="translated">OK</target>
        </trans-unit>
        <trans-unit id="8e8565eb895a4e523ac266f2a6f2af45cda869f8" translate="yes" xml:space="preserve">
          <source>OMP is based on a greedy algorithm that includes at each step the atom most highly correlated with the current residual. It is similar to the simpler matching pursuit (MP) method, but better in that at each iteration, the residual is recomputed using an orthogonal projection on the space of the previously chosen dictionary elements.</source>
          <target state="translated">OMP是基于一种贪婪的算法,在每一步都包含与当前残差相关性最高的原子。它类似于更简单的匹配追寻(MP)方法,但更好的是,在每次迭代时,残差都会在先前选择的字典元素的空间上使用正交投影重新计算。</target>
        </trans-unit>
        <trans-unit id="702567365ae2f6da8d5fc9650aab7f68f2e2b4bd" translate="yes" xml:space="preserve">
          <source>OOB Errors for Random Forests</source>
          <target state="translated">随机森林的OOB错误</target>
        </trans-unit>
        <trans-unit id="2b77a29777f0317be507e501f5c60c74e4daaff5" translate="yes" xml:space="preserve">
          <source>OR, if affinity==`precomputed`, a precomputed affinity matrix of shape (n_samples, n_samples)</source>
          <target state="translated">或者,如果affinity==`precomputed`,则预先计算一个形状为(n_samples,n_samples)的亲和力矩阵。</target>
        </trans-unit>
        <trans-unit id="c8f36dd22506f2db935605e7016ba4725ee8d954" translate="yes" xml:space="preserve">
          <source>OVR + L1 penalty</source>
          <target state="translated">普通车牌号码+L1罚款</target>
        </trans-unit>
        <trans-unit id="6fb4b4e4f3901ecb1795e224abe18919de690335" translate="yes" xml:space="preserve">
          <source>OVR + L2 penalty</source>
          <target state="translated">普通车牌号+二级罚款</target>
        </trans-unit>
        <trans-unit id="cb5d65d3f62b5d33c694bb026fc2cc2e2c9008af" translate="yes" xml:space="preserve">
          <source>Object that mocks the urlopen function to fake requests to mldata.</source>
          <target state="translated">模拟urlopen函数的对象,以伪造对mldata的请求。</target>
        </trans-unit>
        <trans-unit id="04c754a9ec758f22d2ae91b0fe2718c4051ca8ed" translate="yes" xml:space="preserve">
          <source>Object used to transform multiclass labels to binary labels and vice-versa.</source>
          <target state="translated">用于将多类标签转换为二进制标签,反之亦然。</target>
        </trans-unit>
        <trans-unit id="cdd1673e245cacca55f04fb3561b4eb5194072ad" translate="yes" xml:space="preserve">
          <source>Objects that will be checked for consistent length.</source>
          <target state="translated">要检查长度是否一致的对象。</target>
        </trans-unit>
        <trans-unit id="ca9385c00c56b402f0d7c8ffd3817a9453089565" translate="yes" xml:space="preserve">
          <source>Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</source>
          <target state="translated">从决策树和朴素的贝叶斯分类器中获得校准的概率估计，B。Zadrozny＆C. Elkan，ICML 2001</target>
        </trans-unit>
        <trans-unit id="e90a2c57a395bd5ca1744a90561d5ec67c512ffb" translate="yes" xml:space="preserve">
          <source>Obviously when the number of features increases so does the memory consumption of each example. Indeed, for a matrix of \(M\) instances with \(N\) features, the space complexity is in \(O(NM)\). From a computing perspective it also means that the number of basic operations (e.g., multiplications for vector-matrix products in linear models) increases too. Here is a graph of the evolution of the prediction latency with the number of features:</source>
          <target state="translated">显然,当特征数量增加时,每个实例的内存消耗也会增加。事实上,对于一个具有(N)特征的矩阵(M)实例,空间复杂度为(O(NM))。从计算的角度来看,这也意味着基本运算的数量(例如,线性模型中向量-矩阵乘积的乘法)也会增加。下面是预测延迟随特征数量的变化图。</target>
        </trans-unit>
        <trans-unit id="215c08c61e401481973fc6ab07ef3f7e0eb253cc" translate="yes" xml:space="preserve">
          <source>Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel with the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If we give this parameter a value of &lt;code&gt;-1&lt;/code&gt;, grid search will detect how many cores are installed and use them all:</source>
          <target state="translated">显然，这种详尽的搜索可能很昂贵。如果我们拥有多个CPU内核，我们可以告诉网格搜索器尝试将这8个参数组合与 &lt;code&gt;n_jobs&lt;/code&gt; 参数并行进行。如果我们将此参数的值设置为 &lt;code&gt;-1&lt;/code&gt; ，那么网格搜索将检测到已安装了多少个内核并全部使用了它们：</target>
        </trans-unit>
        <trans-unit id="b4b9ad57c64718cb6c7c5d4cbab51ee018de2ade" translate="yes" xml:space="preserve">
          <source>Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.</source>
          <target state="translated">出现次数是一个好的开始,但有一个问题:较长的文档会比较短的文档有更高的平均次数值,即使它们可能谈论相同的主题。</target>
        </trans-unit>
        <trans-unit id="64b2af0bc2328de785be4029344182e16e12fcc6" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. Assuming behaviour == &amp;lsquo;new&amp;rsquo;, &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training. Assuming the behaviour parameter is set to &amp;lsquo;old&amp;rsquo;, we always have &lt;code&gt;offset_ = -0.5&lt;/code&gt;, making the decision function independent from the contamination parameter.</source>
          <target state="translated">偏移量用于根据原始分数定义决策函数。我们具有以下关系： &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。假设行为=='new'，则 &lt;code&gt;offset_&lt;/code&gt; 定义如下。当污染参数设置为&amp;ldquo;自动&amp;rdquo;时，偏移量等于-0.5，这是因为离群值的分数接近0而离群值的分数接近-1。如果提供的污染参数不同于&amp;ldquo;自动&amp;rdquo;，则以这样的方式定义偏移量，即在训练中获得预期的异常值数量（决策函数&amp;lt;0的样本）。假设行为参数设置为&amp;ldquo;旧&amp;rdquo;，我们总是具有 &lt;code&gt;offset_ = -0.5&lt;/code&gt; ，从而使决策函数独立于污染参数。</target>
        </trans-unit>
        <trans-unit id="bbd227107da9d921e8bc12d3a3ca7fd4c0bd101f" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. The offset depends on the contamination parameter and is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">偏移量用于根据原始分数定义决策函数。我们具有以下关系： &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。偏移量取决于污染参数，其定义方式是在训练中获得预期的异常值数量（决策函数&amp;lt;0的样本）。</target>
        </trans-unit>
        <trans-unit id="4f4356395ebd6023fbdce24e12feab7e5ca80606" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt;. The offset is the opposite of &lt;code&gt;intercept_&lt;/code&gt; and is provided for consistency with other outlier detection algorithms.</source>
          <target state="translated">偏移量用于根据原始分数定义决策函数。我们具有以下关系：Decision_function = score_samples- &lt;code&gt;offset_&lt;/code&gt; 。偏移量与 &lt;code&gt;intercept_&lt;/code&gt; 相反，并且为与其他异常值检测算法保持一致而提供。</target>
        </trans-unit>
        <trans-unit id="9195b75fbc020bb9db88d8b131967914e6de2adf" translate="yes" xml:space="preserve">
          <source>Offset used to obtain binary labels from the raw scores. Observations having a negative_outlier_factor smaller than &lt;code&gt;offset_&lt;/code&gt; are detected as abnormal. The offset is set to -1.5 (inliers score around -1), except when a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided. In that case, the offset is defined in such a way we obtain the expected number of outliers in training.</source>
          <target state="translated">偏移量用于从原始分数获取二进制标签。 negative_outlier_factor小于 &lt;code&gt;offset_&lt;/code&gt; 的观测值被检测为异常。偏移设置为-1.5（内部分数约为-1），除非提供的污染参数不同于&amp;ldquo;自动&amp;rdquo;。在那种情况下，以这样的方式定义偏移量，即我们可以在训练中获得预期的异常值数量。</target>
        </trans-unit>
        <trans-unit id="36fd88d1882973048dccc0ac8ca74e6c4f6b2ec1" translate="yes" xml:space="preserve">
          <source>Often features are not given as continuous values but categorical. For example a person could have features &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt;. Such features can be efficiently coded as integers, for instance &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; could be expressed as &lt;code&gt;[0, 1, 3]&lt;/code&gt; while &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; would be &lt;code&gt;[1, 2, 1]&lt;/code&gt;.</source>
          <target state="translated">通常，功能不是连续值而是分类的。例如，某人可能具有以下特征： &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt; ， &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt; ， &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; 。此类功能可以有效地编码为整数，例如 &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; 可以表示为 &lt;code&gt;[0, 1, 3]&lt;/code&gt; 而 &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; 为 &lt;code&gt;[1, 2, 1]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3d1f21e77b74fb7449c1f9b0570088bab1bd6c20" translate="yes" xml:space="preserve">
          <source>Often features do not contribute equally to predict the target response; in many situations the majority of the features are in fact irrelevant. When interpreting a model, the first question usually is: what are those important features and how do they contributing in predicting the target response?</source>
          <target state="translated">通常情况下,特征对预测目标响应的贡献并不一样;在许多情况下,大多数特征实际上是不相关的。在解释一个模型时,第一个问题通常是:那些重要的特征是什么,它们对预测目标反应的贡献如何?</target>
        </trans-unit>
        <trans-unit id="cd4e41585434180ead957592fb3bbf7ed399aaf1" translate="yes" xml:space="preserve">
          <source>Often it&amp;rsquo;s useful to add complexity to the model by considering nonlinear features of the input data. A simple and common method to use is polynomial features, which can get features&amp;rsquo; high-order and interaction terms. It is implemented in &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">通常，考虑输入数据的非线性特征会增加模型的复杂性。多项式特征是一种简单而通用的方法，它可以获取特征的高阶和相互作用项。它在&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; 中&lt;/a&gt;实现：</target>
        </trans-unit>
        <trans-unit id="e408c9080a80cd5dee3de8b66c635dedc13aaef1" translate="yes" xml:space="preserve">
          <source>Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.</source>
          <target state="translated">通常情况下,解决机器学习问题最困难的部分可能是为工作找到合适的估计器。</target>
        </trans-unit>
        <trans-unit id="7b3890ce47285c29340d329412b63023825aa83a" translate="yes" xml:space="preserve">
          <source>Often, you will want to convert an existing Python function into a transformer to assist in data cleaning or processing. You can implement a transformer from an arbitrary function with &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt;. For example, to build a transformer that applies a log transformation in a pipeline, do:</source>
          <target state="translated">通常，您将需要将现有的Python函数转换为转换器，以帮助进行数据清理或处理。您可以使用&lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt;从任意函数实现转换器。例如，要构建在管道中应用对数转换的转换器，请执行以下操作：</target>
        </trans-unit>
        <trans-unit id="3a99e53e60f11cdf73347e45ac4d6a8ace6059f3" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11</source>
          <target state="translated">Ojala and Garriga.Permutation Tests for Studying Classifier Performance.机器学习研究杂志》(2010)第11卷。</target>
        </trans-unit>
        <trans-unit id="f9aa2dba7b6fd084ffccc78f5a1359dabe654fd3" translate="yes" xml:space="preserve">
          <source>On &amp;ldquo;small&amp;rdquo; datasets (less than a few hundred points), the quantile transformer is prone to overfitting. The use of the power transform is then recommended.</source>
          <target state="translated">在&amp;ldquo;小型&amp;rdquo;数据集（少于几百个点）上，分位数转换器容易过拟合。然后建议使用功率变换。</target>
        </trans-unit>
        <trans-unit id="d0f97ce49fc19f915019c9855a072a57bec1774a" translate="yes" xml:space="preserve">
          <source>On L2-normalized data, this function is equivalent to linear_kernel.</source>
          <target state="translated">在L2归一化数据上,这个函数相当于线性核。</target>
        </trans-unit>
        <trans-unit id="d978bf78cd4e4a7f593a82a72e7f97f769b529af" translate="yes" xml:space="preserve">
          <source>On Spectral Clustering: Analysis and an algorithm, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</source>
          <target state="translated">关于频谱聚类：分析和算法，2001年Andrew Y. Ng，Michael I. Jordan，Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c042431c0ae0ab161c8569f0669e312480d87b4b" translate="yes" xml:space="preserve">
          <source>On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640&amp;ndash;650., Wilks, D. S., 1990a</source>
          <target state="translated">关于连续降水期的预报概率的组合。威。Forecasting，5，640&amp;ndash;650。，Wilks，DS，1990a</target>
        </trans-unit>
        <trans-unit id="05fe02625303adf1ec7a757f80f079f0cfb615a5" translate="yes" xml:space="preserve">
          <source>On the contrary the classical finite mixture model with a Dirichlet distribution prior will favor more uniformly weighted components and therefore tends to divide natural clusters into unnecessary sub-components.</source>
          <target state="translated">相反,具有Dirichlet分布先验的经典有限混合模型会倾向于更均匀的加权成分,因此倾向于将自然簇划分为不必要的子成分。</target>
        </trans-unit>
        <trans-unit id="a881270be1f0c36e65b4d9407272c7539d9eb831" translate="yes" xml:space="preserve">
          <source>On the diabetes dataset, find the optimal regularization parameter alpha.</source>
          <target state="translated">在糖尿病数据集上,找到最佳正则化参数α。</target>
        </trans-unit>
        <trans-unit id="d20d94e86b214eba2d2a083bdeb7805cae8a5dbd" translate="yes" xml:space="preserve">
          <source>On the digits dataset, plot the cross-validation score of a &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; estimator with an linear kernel as a function of parameter &lt;code&gt;C&lt;/code&gt; (use a logarithmic grid of points, from 1 to 10).</source>
          <target state="translated">在数字数据集上，绘制具有线性核的&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;估计量的交叉验证得分作为参数 &lt;code&gt;C&lt;/code&gt; 的函数（使用点的对数网格，范围为1到10）。</target>
        </trans-unit>
        <trans-unit id="70934046ec7198c15e5255a457f5b5f8aad47e7d" translate="yes" xml:space="preserve">
          <source>On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from &lt;code&gt;predict_proba&lt;/code&gt; are not to be taken too seriously.</source>
          <target state="translated">另一方面，尽管朴素的贝叶斯被认为是一个体面的分类器，但是它被认为是一个不好的估计器，因此， &lt;code&gt;predict_proba&lt;/code&gt; 的概率输出不必太在意。</target>
        </trans-unit>
        <trans-unit id="11ff999f3cb9557f779d2d870e0da3265a08df2a" translate="yes" xml:space="preserve">
          <source>On the following figure we are fitting a dataset not well-depicted by a Gaussian mixture. Adjusting the &lt;code&gt;weight_concentration_prior&lt;/code&gt;, parameter of the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; controls the number of components used to fit this data. We also present on the last two plots a random sampling generated from the two resulting mixtures.</source>
          <target state="translated">在下图中，我们拟合的数据集没有被高斯混合很好地描述。调整&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt;的 &lt;code&gt;weight_concentration_prior&lt;/code&gt; 参数，可控制用于拟合此数据的组件数。我们还在最后两个图上显示了从这两种所得混合物生成的随机采样。</target>
        </trans-unit>
        <trans-unit id="e0986e74679be65bf8af00d65ae0c2feb9ddbaaf" translate="yes" xml:space="preserve">
          <source>On the graph of webpages and links those values are called the PageRank scores by Google.</source>
          <target state="translated">在网页和链接的图上,这些数值被Google称为PageRank分数。</target>
        </trans-unit>
        <trans-unit id="56dda47abffe67d113799c44a62fa9885afd300e" translate="yes" xml:space="preserve">
          <source>On the left side the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. On the right side we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples.</source>
          <target state="translated">左侧是一个奈夫贝叶斯分类器对数字数据集的学习曲线。注意,训练得分和交叉验证得分在最后都不是很好。然而,在更复杂的数据集中可以发现曲线的形状非常频繁:训练得分在开始时非常高,然后减少,交叉验证得分在开始时非常低,然后增加。在右侧我们看到了一个采用RBF内核的SVM的学习曲线。我们可以清楚地看到,训练得分仍然在最大值附近,验证得分可以通过更多的训练样本来提高。</target>
        </trans-unit>
        <trans-unit id="f954522d1ed09b2ae8779aaabe3dfa6c3ae4de4e" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained:</source>
          <target state="translated">另一方面，&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;实施了&amp;ldquo; 一对多 &amp;rdquo;策略，从而训练了n_class模型。如果只有两节课，则只训练一种模型：</target>
        </trans-unit>
        <trans-unit id="86b28d625cb14fb5485ff23b3eca337a06cecaf2" translate="yes" xml:space="preserve">
          <source>On the plots, train data is shown as dots, while test data is shown as crosses. The iris dataset is four-dimensional. Only the first two dimensions are shown here, and thus some points are separated in other dimensions.</source>
          <target state="translated">在图上,训练数据显示为点,而测试数据显示为十字。虹膜数据集是四维的。这里只显示了前两个维度,因此一些点在其他维度上是分开的。</target>
        </trans-unit>
        <trans-unit id="fc82fddedc10b52f931e2d57575d5196e2c6dd2d" translate="yes" xml:space="preserve">
          <source>On the twenty newsgroups on the other hand the dimensionality can be decreased from 56436 down to 10000 while reasonably preserving pairwise distances.</source>
          <target state="translated">另一方面,在20个新闻组上,维度可以从56436降到10000,同时合理地保留了配对距离。</target>
        </trans-unit>
        <trans-unit id="43f757b33d0dc72835f44fdaffe6492249fea14f" translate="yes" xml:space="preserve">
          <source>On this example, the first two rows represent linearly non-separable datasets (moons and concentric circles) while the third is approximately linearly separable. On the two linearly non-separable datasets, feature discretization largely increases the performance of linear classifiers. On the linearly separable dataset, feature discretization decreases the performance of linear classifiers. Two non-linear classifiers are also shown for comparison.</source>
          <target state="translated">在这个例子上,前两行代表线性不可分离的数据集(月亮和同心圆),而第三行是近似线性可分离的。在两个线性不可分离的数据集上,特征离散化很大程度上提高了线性分类器的性能。在线性可分离的数据集上,特征离散化降低了线性分类器的性能。还展示了两种非线性分类器进行比较。</target>
        </trans-unit>
        <trans-unit id="07aa293f8032a091371331fd78ad762690098968" translate="yes" xml:space="preserve">
          <source>Once trained, we can export the tree in &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with</source>
          <target state="translated">经过培训后，我们可以使用&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt;导出器以&lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt;格式导出树。如果使用&lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt;软件包管理器，则可以使用以下命令安装graphviz二进制文件和python软件包：</target>
        </trans-unit>
        <trans-unit id="e1a30cbb2660486e3a34f97fc6f2ebc285138723" translate="yes" xml:space="preserve">
          <source>One can observe here that logistic regression is well calibrated as its curve is nearly diagonal. Linear SVC&amp;rsquo;s calibration curve or reliability diagram has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors). Both kinds of calibration can fix this issue and yield nearly identical results. The next figure shows the calibration curve of Gaussian naive Bayes on the same data, with both kinds of calibration and also without calibration.</source>
          <target state="translated">在这里可以看到，逻辑回归的曲线接近对角线，因此可以很好地进行校准。线性SVC的校准曲线或可靠性图具有S型曲线，这对于自信不足的分类器而言是典型的。在LinearSVC的情况下，这是由铰链损失的裕度属性引起的，该属性使铰链损失可以集中在靠近决策边界（支持向量）的硬样本上。两种校准均可解决此问题，并产生几乎相同的结果。下图显示了高斯朴素贝叶斯在相同数据上的校准曲线，包括两种校准以及未校准。</target>
        </trans-unit>
        <trans-unit id="cce2911ccedb3667eaee804d61905917155ff5c2" translate="yes" xml:space="preserve">
          <source>One can observe that with homoscedastic noise both FA and PCA succeed in recovering the size of the low rank subspace. The likelihood with PCA is higher than FA in this case. However PCA fails and overestimates the rank when heteroscedastic noise is present. Under appropriate circumstances the low rank models are more likely than shrinkage models.</source>
          <target state="translated">我们可以观察到,在同序噪声的情况下,FA和PCA都能成功恢复低秩子空间的大小。在这种情况下,PCA的似然比FA高。然而PCA失败了,当存在异序噪声时,高估了秩。在适当的情况下,低秩模型比收缩模型的可能性更大。</target>
        </trans-unit>
        <trans-unit id="5282642c4183bcd75159c8592f0d08e21bceb6b2" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:</source>
          <target state="translated">可以将预测标签中的0和1进行换算,将2改名为3,得到同样的分数。</target>
        </trans-unit>
        <trans-unit id="f2e197fb258bad312502ac44a4234fe5a6877692" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3, and get the same score:</source>
          <target state="translated">可以将预测标签中的0和1进行换算,将2改名为3,得到同样的分数。</target>
        </trans-unit>
        <trans-unit id="e33d3feeafd2b2e6157812f722f3e7fb8358ba7c" translate="yes" xml:space="preserve">
          <source>One can see that Gaussian naive Bayes performs very badly but does so in an other way than linear SVC: While linear SVC exhibited a sigmoid calibration curve, Gaussian naive Bayes&amp;rsquo; calibration curve has a transposed-sigmoid shape. This is typical for an over-confident classifier. In this case, the classifier&amp;rsquo;s overconfidence is caused by the redundant features which violate the naive Bayes assumption of feature-independence.</source>
          <target state="translated">可以看到，高斯朴素贝叶斯的性能很差，但它的性能不同于线性SVC：线性SVC表现出S形的校准曲线，而高斯朴素贝叶斯的校准曲线却具有转位的S形。这对于过分自信的分类器来说是典型的。在这种情况下，分类器的过分自信是由多余的特征引起的，这些冗余的特征违反了朴素的贝叶斯独立于特征的假设。</target>
        </trans-unit>
        <trans-unit id="82900035fe0f11887cd04ee23edd3ee0d6e6bf18" translate="yes" xml:space="preserve">
          <source>One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.</source>
          <target state="translated">机器学习内的一种常见模式是使用在数据的非线性函数上训练的线性模型。这种方法保持了线性方法一般快速的性能,同时允许它们适应更广泛的数据。</target>
        </trans-unit>
        <trans-unit id="fa0690f9f0e7bd840855247cda57999b3e6dd175" translate="yes" xml:space="preserve">
          <source>One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). From this assumption, we generally try to define the &amp;ldquo;shape&amp;rdquo; of the data, and can define outlying observations as observations which stand far enough from the fit shape.</source>
          <target state="translated">执行离群值检测的一种常用方法是假设常规数据来自已知分布（例如，数据是高斯分布的）。从这个假设出发，我们通常尝试定义数据的&amp;ldquo;形状&amp;rdquo;，并且可以将外围观察定义为距离拟合形状足够远的观察。</target>
        </trans-unit>
        <trans-unit id="9d03fc67e51edb11ba912aa95289c786040f1c20" translate="yes" xml:space="preserve">
          <source>One drawback of kernel methods is, that it might be necessary to store many kernel values \(k(x_i, x_j)\) during optimization. If a kernelized classifier is applied to new data \(y_j\), \(k(x_i, y_j)\) needs to be computed to make predictions, possibly for many different \(x_i\) in the training set.</source>
          <target state="translated">核方法的一个缺点是,在优化过程中可能需要存储许多核值(k(x_i,x_j)\)。如果一个内核化的分类器被应用到新的数据中,就需要计算出许多不同的训练集中的内核值来进行预测。</target>
        </trans-unit>
        <trans-unit id="cdf9b1d4485b82e7ed1999a3fb7fb5adb4dbca12" translate="yes" xml:space="preserve">
          <source>One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; &amp;lsquo;isolates&amp;rsquo; observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</source>
          <target state="translated">在高维数据集中执行异常检测的一种有效方法是使用随机森林。所述&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;通过随机选择一个功能，然后随机选择所选择的特征的最大值和最小值之间的分裂值&amp;ldquo;分离的观察。</target>
        </trans-unit>
        <trans-unit id="b5c13007d70aa1a0e4a2816404f0d61b9e0ac135" translate="yes" xml:space="preserve">
          <source>One important thing to note is that the algorithms implemented in this module can take different kinds of matrix as input. All the methods accept standard data matrices of shape &lt;code&gt;[n_samples, n_features]&lt;/code&gt;. These can be obtained from the classes in the &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module. For &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt;&lt;code&gt;AffinityPropagation&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; one can also input similarity matrices of shape &lt;code&gt;[n_samples, n_samples]&lt;/code&gt;. These can be obtained from the functions in the &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">需要注意的重要一点是，此模块中实现的算法可以采用不同种类的矩阵作为输入。所有方法都接受形状为 &lt;code&gt;[n_samples, n_features]&lt;/code&gt; 标准数据矩阵。这些可以从&lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt;模块中的类获得。对于&lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt; &lt;code&gt;AffinityPropagation&lt;/code&gt; &lt;/a&gt;，&lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt; &lt;code&gt;SpectralClustering&lt;/code&gt; &lt;/a&gt;和&lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; ,&lt;/a&gt;也可以输入形状为 &lt;code&gt;[n_samples, n_samples]&lt;/code&gt; 相似度矩阵。这些可以从&lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt;模块中的函数获得。</target>
        </trans-unit>
        <trans-unit id="deab058e87e7d8cac343ed7483a7cf721eca4119" translate="yes" xml:space="preserve">
          <source>One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of &lt;em&gt;modified locally linear embedding&lt;/em&gt; (MLLE). MLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'modified'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt;.</source>
          <target state="translated">解决正则化问题的一种方法是在每个邻域中使用多个权重向量。这是&lt;em&gt;修改的局部线性嵌入&lt;/em&gt;（MLLE）的本质。 MLLE可以通过函数&lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt;或其面向对象的对等&lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt;来执行， &lt;code&gt;method = 'modified'&lt;/code&gt; 为关键字method ='modified'。它要求 &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8b0abef56ded5ecf131b35733971a4004aa542f0" translate="yes" xml:space="preserve">
          <source>One might alternatively consider a collection of character n-grams, a representation resilient against misspellings and derivations.</source>
          <target state="translated">我们也可以考虑一个字符n-grams的集合,一个对错别字和派生有弹性的表示。</target>
        </trans-unit>
        <trans-unit id="61c492958dc81c1a6d9f632bafd3909d2bb143b8" translate="yes" xml:space="preserve">
          <source>One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.</source>
          <target state="translated">这里面临的一个挑战是,求解器可能无法收敛到一个条件良好的估计值。相应的α值就会出现缺失值,但最优值可能接近这些缺失值。</target>
        </trans-unit>
        <trans-unit id="70a04d887115ca6d6700f00cd1afa9bf1cffed38" translate="yes" xml:space="preserve">
          <source>One of the earliest approaches to manifold learning is the Isomap algorithm, short for Isometric Mapping. Isomap can be viewed as an extension of Multi-dimensional Scaling (MDS) or Kernel PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points. Isomap can be performed with the object &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt;&lt;code&gt;Isomap&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Isomap算法是流形学习的最早方法之一，Isomap算法是Isometric Mapping（等距映射）的缩写。Isomap可以看作是多维缩放（MDS）或内核PCA的扩展。Isomap寻求维数较低的嵌入，以保持所有点之间的测地距离。可以使用对象&lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt; &lt;code&gt;Isomap&lt;/code&gt; &lt;/a&gt;执行Isomap。</target>
        </trans-unit>
        <trans-unit id="8d30b63915c687687af955c31a96ac094f06cb9f" translate="yes" xml:space="preserve">
          <source>One of the most straight-forward concerns one may have when using/choosing a machine learning toolkit is the latency at which predictions can be made in a production environment.</source>
          <target state="translated">在使用/选择机器学习工具包时,人们可能会有一个最直接的顾虑,那就是在生产环境中进行预测的延迟。</target>
        </trans-unit>
        <trans-unit id="e3967d3ba22f4ac7f4c1ab09bac9634bd847ca9c" translate="yes" xml:space="preserve">
          <source>One of:</source>
          <target state="translated">其中一个:</target>
        </trans-unit>
        <trans-unit id="d25b0126083dd51df31e94af07b51bd893fc80ee" translate="yes" xml:space="preserve">
          <source>One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:</source>
          <target state="translated">核密度估计的另一个有用的应用是学习一个数据集的非参数生成模型,以便有效地从这个生成模型中抽取新的样本。下面是一个使用这个过程来创建一组新的手写数字的例子,使用在数据的PCA投影上学习的高斯核。</target>
        </trans-unit>
        <trans-unit id="fee8a97f6bc38e5962a611f176ea8084294905c7" translate="yes" xml:space="preserve">
          <source>One possible difference with the &lt;code&gt;glasso&lt;/code&gt; R package is that the diagonal coefficients are not penalized.</source>
          <target state="translated">&lt;code&gt;glasso&lt;/code&gt; R包的一种可能差异是对角系数不会受到惩罚。</target>
        </trans-unit>
        <trans-unit id="ea6c78b875e9abbb9afb65361c14c4ab4fe517e5" translate="yes" xml:space="preserve">
          <source>One typical use case is to wrap an existing metric function from the library with non-default values for its parameters, such as the &lt;code&gt;beta&lt;/code&gt; parameter for the &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">一种典型的用例是使用非默认值为其参数包装库中的现有度量标准函数，例如&lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt;函数的 &lt;code&gt;beta&lt;/code&gt; 参数：</target>
        </trans-unit>
        <trans-unit id="d21d62671a1a16508e611633019b29f0b4ceb760" translate="yes" xml:space="preserve">
          <source>One way to avoid the query complexity is to pre-compute sparse neighborhoods in chunks using &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;mode='distance'&lt;/code&gt;, then using &lt;code&gt;metric='precomputed'&lt;/code&gt; here.</source>
          <target state="translated">避免查询复杂性的一种方法是使用&lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt; &lt;/a&gt;以 &lt;code&gt;mode='distance'&lt;/code&gt; 预先计算块中的稀疏邻域，然后在此处使用 &lt;code&gt;metric='precomputed'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7904a0df31dead1d3d1a1bdda9b6baa78b3e3ac4" translate="yes" xml:space="preserve">
          <source>One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter \(r\), which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as \(r \to 0\), the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for \(r &amp;gt; 0\). This problem manifests itself in embeddings which distort the underlying geometry of the manifold.</source>
          <target state="translated">LLE的一个众所周知的问题是正则化问题。当邻居数大于输入维数时，定义每个本地邻居的矩阵秩不足。为了解决这个问题，标准LLE应用了一个任意的正则化参数\（r \），该参数相对于局部权重矩阵的轨迹进行选择。尽管可以正式证明，当\（r \ to 0 \）时，解收敛于所需的嵌入，但不能保证将找到\（r&amp;gt; 0 \）的最优解。该问题以使歧管的基本几何形状变形的嵌入表现出来。</target>
        </trans-unit>
        <trans-unit id="4a89ac2f620199dd99f97fe1ad98300bc4f72269" translate="yes" xml:space="preserve">
          <source>One-class SVM with non-linear kernel (RBF)</source>
          <target state="translated">非线性内核(RBF)的一类SVM。</target>
        </trans-unit>
        <trans-unit id="b4a3aede9df40da523f973c7487f254218f78511" translate="yes" xml:space="preserve">
          <source>One-vs-one multiclass strategy</source>
          <target state="translated">一对一多类策略</target>
        </trans-unit>
        <trans-unit id="ee528cbd4b4f2e2829af351b64b6eb8bfd42a4f6" translate="yes" xml:space="preserve">
          <source>One-vs-the-rest (OvR) multiclass/multilabel strategy</source>
          <target state="translated">一对一(OvR)多类/多标签策略</target>
        </trans-unit>
        <trans-unit id="64ecee535f4fdc8be570462551ed8105268af715" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above Figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them.</source>
          <target state="translated">单向PDP告诉我们目标响应和目标特征之间的交互作用(如线性、非线性)。上图中左上角的图显示了一个地区的收入中位数对房价中位数的影响,我们可以清楚地看到它们之间的线性关系。</target>
        </trans-unit>
        <trans-unit id="aae2ee6c9851c7a4ce4cd6cfb817bfde607325bf" translate="yes" xml:space="preserve">
          <source>Online Passive-Aggressive Algorithms &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt;&amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</source>
          <target state="translated">在线被动攻击算法&amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt; &amp;gt; K. Crammer，O.Dekel，J.Keshat，S.Shalev-Shwartz，Y.Singer- JMLR（2006）</target>
        </trans-unit>
        <trans-unit id="59363dcf6a532d4c72655a5346d2c500295612f8" translate="yes" xml:space="preserve">
          <source>Online VB with Mini-Batch update.</source>
          <target state="translated">在线VB与小批量更新。</target>
        </trans-unit>
        <trans-unit id="829e73254cb47c834763ade46578341830688d18" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling.</source>
          <target state="translated">在线计算X的最大绝对值,以便于以后的缩放。</target>
        </trans-unit>
        <trans-unit id="1dffcf7d5a055d764cfb2adb13901c054d8691b3" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">在线计算X的最大绝对值，以便以后缩放。所有X都作为一个批处理。这适用于由于 &lt;code&gt;n_samples&lt;/code&gt; 数量过多或从连续流中读取X 而无法进行 &lt;code&gt;fit&lt;/code&gt; 情况。</target>
        </trans-unit>
        <trans-unit id="5b59fd4b2594ce8e5c7bbe150a07e7588723c96b" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling.</source>
          <target state="translated">在线计算X上的均值和std,以便以后进行缩放。</target>
        </trans-unit>
        <trans-unit id="98a787216e7563ac11e03cf3274711f17911c2c2" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">在线计算X上的均值和标准差，以便以后缩放。所有X都作为一个批处理。这适用于由于 &lt;code&gt;n_samples&lt;/code&gt; 数量过多或从连续流中读取X 而无法进行 &lt;code&gt;fit&lt;/code&gt; 情况。</target>
        </trans-unit>
        <trans-unit id="3a0a40bed8a368eb74567adc0b902d5438bbb233" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling.</source>
          <target state="translated">在线计算X上的最小值和最大值,以便于以后的缩放。</target>
        </trans-unit>
        <trans-unit id="245a52e0e0da8fa60b8bd0ab73c4b352a71c8d4a" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">在线计算X上的最小值和最大值，以便以后缩放。所有X都作为一个批处理。这适用于由于 &lt;code&gt;n_samples&lt;/code&gt; 数量过多或从连续流中读取X 而无法进行 &lt;code&gt;fit&lt;/code&gt; 情况。</target>
        </trans-unit>
        <trans-unit id="3bdeb493aeece54b83eea920715d4b7167b710bb" translate="yes" xml:space="preserve">
          <source>Online learning of a dictionary of parts of faces</source>
          <target state="translated">在线学习人脸部位词典。</target>
        </trans-unit>
        <trans-unit id="afbac89ba6ac8bba06d8e8f00f8db1d633c505b3" translate="yes" xml:space="preserve">
          <source>Online learning.</source>
          <target state="translated">在线学习。</target>
        </trans-unit>
        <trans-unit id="e15bae968fe9434653919edecb56e181cf3bdca0" translate="yes" xml:space="preserve">
          <source>Online learning. Prevents rebuilding of CFTree from scratch.</source>
          <target state="translated">在线学习。防止从头开始重建CFTree。</target>
        </trans-unit>
        <trans-unit id="fba366205dda8a9f9c620fa8147677029ec02688" translate="yes" xml:space="preserve">
          <source>Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">仅在backend =&amp;ldquo; loky&amp;rdquo;或&amp;ldquo; multiprocessing&amp;rdquo;时激活。</target>
        </trans-unit>
        <trans-unit id="302203b3b2bd4b6979838ea661e3dedb562a6303" translate="yes" xml:space="preserve">
          <source>Only adjusted measures can hence safely be used as a consensus index to evaluate the average stability of clustering algorithms for a given value of k on various overlapping sub-samples of the dataset.</source>
          <target state="translated">因此,只有调整后的测量方法才能安全地作为一种共识指数来评价聚类算法在给定的k值下,在数据集的各种重叠子样本上的平均稳定性。</target>
        </trans-unit>
        <trans-unit id="b41ade38f91e30c61b5c1030ad80447ac59509af" translate="yes" xml:space="preserve">
          <source>Only applies to sparse matrices. If True, the sparse entries of the matrix are discarded to compute the quantile statistics. If False, these entries are treated as zeros.</source>
          <target state="translated">仅适用于稀疏矩阵。如果为真,矩阵的稀疏条目将被丢弃以计算量化统计。如果为假,则这些条目被视为零。</target>
        </trans-unit>
        <trans-unit id="6239790ca1ea503b946542f5fd11362f9a8d181e" translate="yes" xml:space="preserve">
          <source>Only available for novelty detection (when novelty is set to True). The argument X is supposed to contain &lt;em&gt;new data&lt;/em&gt;: if X contains a point from training, it considers the later in its own neighborhood. Also, the samples in X are not considered in the neighborhood of any point. The score_samples on training data is available by considering the the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">仅可用于新颖性检测（新颖性设置为True时）。参数X应该包含&lt;em&gt;新数据&lt;/em&gt;：如果X包含来自训练的点，则它将在其自己的邻域中考虑后者。同样，在任何点附近都不会考虑X中的样本。可以通过考虑 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性来获得训练数据的score_samples 。</target>
        </trans-unit>
        <trans-unit id="42065a31e81b2581624e9d29e5e9b175fb835b62" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;decision_function&lt;/code&gt;.</source>
          <target state="translated">仅当 &lt;code&gt;refit=True&lt;/code&gt; 和底层估计支持 &lt;code&gt;decision_function&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b5f87bbc5994209afe765ecb3d4b6e3e28348b8b" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;refit=True&lt;/code&gt; 并且基础估算器支持 &lt;code&gt;predict&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="d2e232f30b7c8c685e1c17116e7dcb136df3f8ad" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_log_proba&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;refit=True&lt;/code&gt; 且基础估算器支持 &lt;code&gt;predict_log_proba&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="590883a61b4915ecfb6720c62deaa2c81b9eda84" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;refit=True&lt;/code&gt; 且基础估算器支持 &lt;code&gt;predict_proba&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="3fd90433c474723d07589bf28196170034c8822e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator implements &lt;code&gt;inverse_transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">仅在基础估算器实现 &lt;code&gt;inverse_transform&lt;/code&gt; 和 &lt;code&gt;refit=True&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="5b6ee95bb2d64ff7d78caebfb3e0ee07b947d80e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator supports &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">仅在基础估算器支持 &lt;code&gt;transform&lt;/code&gt; 和 &lt;code&gt;refit=True&lt;/code&gt; 时可用。</target>
        </trans-unit>
        <trans-unit id="91571ddad0f13d4b107795b8172bb8b9e0e57731" translate="yes" xml:space="preserve">
          <source>Only kernels that produce similarity scores (non-negative values that increase with similarity) should be used. This property is not checked by the clustering algorithm.</source>
          <target state="translated">只应使用产生相似度分数的内核(随着相似度增加而增加的非负值)。聚类算法不检查这一属性。</target>
        </trans-unit>
        <trans-unit id="91f57910319c7032022a687ad833db0e0811e172" translate="yes" xml:space="preserve">
          <source>Only report results for the class specified by &lt;code&gt;pos_label&lt;/code&gt;. This is applicable only if targets (&lt;code&gt;y_{true,pred}&lt;/code&gt;) are binary.</source>
          <target state="translated">仅报告 &lt;code&gt;pos_label&lt;/code&gt; 指定的类的结果。仅当目标（ &lt;code&gt;y_{true,pred}&lt;/code&gt; ）是二进制的时才适用。</target>
        </trans-unit>
        <trans-unit id="aa7683d2cc754187a7839c7481d51d4e421e244f" translate="yes" xml:space="preserve">
          <source>Only returned if return_distance is set to True (for compatibility). The distances between the centers of the nodes. &lt;code&gt;distances[i]&lt;/code&gt; corresponds to a weighted euclidean distance between the nodes &lt;code&gt;children[i, 1]&lt;/code&gt; and &lt;code&gt;children[i, 2]&lt;/code&gt;. If the nodes refer to leaves of the tree, then &lt;code&gt;distances[i]&lt;/code&gt; is their unweighted euclidean distance. Distances are updated in the following way (from scipy.hierarchy.linkage):</source>
          <target state="translated">仅在return_distance设置为True（出于兼容性）时返回。节点中心之间的距离。 &lt;code&gt;distances[i]&lt;/code&gt; 对应于节点child &lt;code&gt;children[i, 1]&lt;/code&gt; 和 &lt;code&gt;children[i, 2]&lt;/code&gt; 之间的加权欧几里得距离。如果节点引用树的叶子，则 &lt;code&gt;distances[i]&lt;/code&gt; 是其未加权的欧几里得距离。距离以以下方式更新（来自scipy.hierarchy.linkage）：</target>
        </trans-unit>
        <trans-unit id="b2ff6162a14531590c3fe05f5c4da22c170a731e" translate="yes" xml:space="preserve">
          <source>Only the first 4 features are informative. The remaining features are useless.</source>
          <target state="translated">只有前4个功能是有参考价值的。其余的特征都是无用的。</target>
        </trans-unit>
        <trans-unit id="ccdb28c17d5d885e725cff4c70b04cf05f415c05" translate="yes" xml:space="preserve">
          <source>Only used if method=&amp;rsquo;barnes_hut&amp;rsquo; This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. &amp;lsquo;angle&amp;rsquo; is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below &amp;lsquo;angle&amp;rsquo; then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.</source>
          <target state="translated">仅在method ='barnes_hut'时使用。这是Barnes-Hut T-SNE在速度和精度之间的权衡。&amp;ldquo;角度&amp;rdquo;是从点开始测量的远距离节点的角度大小（在[3]中称为theta）。如果该大小小于&amp;ldquo;角度&amp;rdquo;，则将其用作其中包含的所有点的汇总节点。此方法对此参数在0.2-0.8范围内的变化不太敏感。小于0.2的角度会迅速增加计算时间，大于0.8的角度会迅速增加误差。</target>
        </trans-unit>
        <trans-unit id="feeded53201cd1098b357f2543d3cc3ddaf2bc59" translate="yes" xml:space="preserve">
          <source>Only used in edge case with a single class in the training set.</source>
          <target state="translated">只用于训练集中只有一个类的边缘情况。</target>
        </trans-unit>
        <trans-unit id="e51e92f95034c804fc0810fdbc5d315daca2beb0" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;solver='sgd'&lt;/code&gt;.</source>
          <target state="translated">仅在 &lt;code&gt;solver='sgd'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3466b805d384e470c3d1ee2beb1b9b317ac5cc22" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">仅在Solver ='sgd'时使用。</target>
        </trans-unit>
        <trans-unit id="04fb050fa307025a8b877f9d2c83069449f7ca94" translate="yes" xml:space="preserve">
          <source>Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">仅当存在 &lt;code&gt;rows_&lt;/code&gt; 和 &lt;code&gt;columns_&lt;/code&gt; 属性时有效。</target>
        </trans-unit>
        <trans-unit id="516478ad62f05e00111ddd57ddd26de9d50efa29" translate="yes" xml:space="preserve">
          <source>Open problem: Stock Market Structure</source>
          <target state="translated">开放性问题:股票市场结构</target>
        </trans-unit>
        <trans-unit id="988a0621a69f95c126d429edd6ad72b8b9753d30" translate="yes" xml:space="preserve">
          <source>OpenBLAS</source>
          <target state="translated">OpenBLAS</target>
        </trans-unit>
        <trans-unit id="01e06dfe8463084e545b7490a5b6cab212cacc1b" translate="yes" xml:space="preserve">
          <source>OpenML ID of the dataset. The most specific way of retrieving a dataset. If data_id is not given, name (and potential version) are used to obtain a dataset.</source>
          <target state="translated">数据集的OpenML ID。检索数据集的最具体方式。如果没有给出data_id,则使用名称(和潜在的版本)来获取数据集。</target>
        </trans-unit>
        <trans-unit id="3c0cb6e8849966972823d3a411e3fa85cccc3662" translate="yes" xml:space="preserve">
          <source>Opposite of the Local Outlier Factor of X.</source>
          <target state="translated">X的局部离群因素的对立面。</target>
        </trans-unit>
        <trans-unit id="5e68f725eeef777e12b4d3a454a6208991fd24e6" translate="yes" xml:space="preserve">
          <source>Opposite of the Mahalanobis distances.</source>
          <target state="translated">对面的马哈兰博斯距离。</target>
        </trans-unit>
        <trans-unit id="b5fb56d4ea090bc2e90702500456ef35c8c80910" translate="yes" xml:space="preserve">
          <source>Opposite of the anomaly score defined in the original paper.</source>
          <target state="translated">与原论文中定义的异常得分相反。</target>
        </trans-unit>
        <trans-unit id="8d0235738e36c010f5cce0e1d51d26583f4fbd2f" translate="yes" xml:space="preserve">
          <source>Opposite of the value of X on the K-means objective.</source>
          <target state="translated">K-means目标上X值的相反。</target>
        </trans-unit>
        <trans-unit id="d4790d7d59a93c4896ec3d473b252d9c8e90d50a" translate="yes" xml:space="preserve">
          <source>Optimal choices for the sampling interval for certain data ranges can be computed (see the reference). The default values should be reasonable.</source>
          <target state="translated">可以计算出某些数据范围的采样间隔的最佳选择(见参考文献)。默认值应该是合理的。</target>
        </trans-unit>
        <trans-unit id="ce024d3ab746293c4c12993e7780e537aaab5bd3" translate="yes" xml:space="preserve">
          <source>Optimized BLAS / LAPACK implementations include:</source>
          <target state="translated">优化的BLAS/LAPACK实施包括:</target>
        </trans-unit>
        <trans-unit id="e7a4cb55708bbb7494e2613ab1d6bd3cf5f4ed80" translate="yes" xml:space="preserve">
          <source>Optimizing the KL divergence can be a little bit tricky sometimes. There are five parameters that control the optimization of t-SNE and therefore possibly the quality of the resulting embedding:</source>
          <target state="translated">优化KL分叉有时会有点棘手。有五个参数可以控制t-SNE的优化,从而可能控制结果嵌入的质量。</target>
        </trans-unit>
        <trans-unit id="59b7edea35dae0ba7f04b93972cd416b8729437e" translate="yes" xml:space="preserve">
          <source>Option to scale data</source>
          <target state="translated">缩放数据的选项</target>
        </trans-unit>
        <trans-unit id="b448cb50c967f57d438352622bd92cc83d5cd21c" translate="yes" xml:space="preserve">
          <source>Optional display names matching the labels (same order).</source>
          <target state="translated">可选择与标签相匹配的显示名称(顺序相同)。</target>
        </trans-unit>
        <trans-unit id="f7746b3179890337eeaaee24d3cefbf3e21f4716" translate="yes" xml:space="preserve">
          <source>Optional list of label indices to include in the report.</source>
          <target state="translated">报告中可选的标签索引列表。</target>
        </trans-unit>
        <trans-unit id="444d0152ba1b6a9d2f83b135dcad3591aef4140b" translate="yes" xml:space="preserve">
          <source>Optionally, weights can be provided for the individual classifiers:</source>
          <target state="translated">可选地,可以为各个分类器提供权重。</target>
        </trans-unit>
        <trans-unit id="bdffb8593fdda1fb06f464d41401bd543c75d539" translate="yes" xml:space="preserve">
          <source>Or as a dict mapping scorer name to a predefined or custom scoring function:</source>
          <target state="translated">或者作为一个将评分器名称映射到预定义或自定义评分功能的dict。</target>
        </trans-unit>
        <trans-unit id="2919d9f2f1803bd27d88cb6979d8731b9671873d" translate="yes" xml:space="preserve">
          <source>Or, the Itakura-Saito (IS) divergence:</source>
          <target state="translated">或者说,板仓-斋藤(IS)的分歧。</target>
        </trans-unit>
        <trans-unit id="2eae1790c8b18065a4e4be5e643bf49617d7e481" translate="yes" xml:space="preserve">
          <source>Oracle Approximating Shrinkage Estimator</source>
          <target state="translated">Oracle近似收缩估算器</target>
        </trans-unit>
        <trans-unit id="09fb6aaba7940a7b7ffdbc9cbb9b3498303c1bad" translate="yes" xml:space="preserve">
          <source>Orange</source>
          <target state="translated">Orange</target>
        </trans-unit>
        <trans-unit id="61e854a8201b91e00e8fdcbd770fb61bc8a83663" translate="yes" xml:space="preserve">
          <source>Order of the norm used to filter the vectors of coefficients below &lt;code&gt;threshold&lt;/code&gt; in the case where the &lt;code&gt;coef_&lt;/code&gt; attribute of the estimator is of dimension 2.</source>
          <target state="translated">在估算器的 &lt;code&gt;coef_&lt;/code&gt; 属性的尺寸为2 的情况下，用于过滤低于 &lt;code&gt;threshold&lt;/code&gt; 的系数矢量的范数的顺序。</target>
        </trans-unit>
        <trans-unit id="04f01a5d4b5e2de7c5bc38f04fe789073a85e1a0" translate="yes" xml:space="preserve">
          <source>Ordinary Least Squares and Ridge Regression Variance</source>
          <target state="translated">普通最小二乘法和山脊回归方差。</target>
        </trans-unit>
        <trans-unit id="69dfb38c02d49acfa60317532da350814008c91b" translate="yes" xml:space="preserve">
          <source>Ordinary least squares Linear Regression.</source>
          <target state="translated">普通最小二乘线性回归。</target>
        </trans-unit>
        <trans-unit id="c6a26fb9333dc9c04fcf0b8a8d439bec3529ccb6" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the book &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; by Radford M. Neal</source>
          <target state="translated">Radford M.Neal 在《 &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; 的贝叶斯学习》一书中详细介绍了原始算法。</target>
        </trans-unit>
        <trans-unit id="285a92205b1ae0ee38089b09c3441dcd00669592" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">Hastie等人在论文的&lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;最小角回归中&lt;/a&gt;详细介绍了原始算法。</target>
        </trans-unit>
        <trans-unit id="40e1a40682f2197d130d7160c72b099cf6445896" translate="yes" xml:space="preserve">
          <source>Original Owners:</source>
          <target state="translated">原主人。</target>
        </trans-unit>
        <trans-unit id="7ad091e9d90ec0296b62c3e5e44ac8d89a063912" translate="yes" xml:space="preserve">
          <source>Original data</source>
          <target state="translated">原始数据</target>
        </trans-unit>
        <trans-unit id="e08c8e7e7ce9b41fa431a10c664db0046193d186" translate="yes" xml:space="preserve">
          <source>Original indices of sorted hashed values in the fitted index.</source>
          <target state="translated">拟合指数中排序哈希值的原始指数。</target>
        </trans-unit>
        <trans-unit id="d62335c307cfd6338409df5c3eb510c3da387b07" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit</source>
          <target state="translated">正交匹配追求</target>
        </trans-unit>
        <trans-unit id="4b43e1fc477a65c488f6b885c65608062bcdd067" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">正交匹配追求(OMP)</target>
        </trans-unit>
        <trans-unit id="6f8635fe08116f66d41828127f270123a3daf2dc" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit model (OMP)</source>
          <target state="translated">正交匹配追求模型(OMP)</target>
        </trans-unit>
        <trans-unit id="b4cea4b2e1d94206efdd2c81ac084782051e04a0" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit (&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt;)</source>
          <target state="translated">正交匹配追踪（&lt;a href=&quot;linear_model#omp&quot;&gt;正交匹配追踪（OMP）&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="2d35a4350f19547a1df08de9c97e28d5eb4c4c18" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">正交匹配追踪是在G. Mallat，Z. Zhang中引入的，《时频字典的匹配追踪》，IEEE Transactions on Signal Processing，Vol。41，No.12（1993年12月），第3397-3415页。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="5e7d9b3e4cebb5843b9125c6b797beb3832d1f95" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">正交匹配追踪是在S. Mallat，Z. Zhang中引入的，《时频字典的匹配追踪》，IEEE Transactions on Signal Processing，Vol。41，No.12（1993年12月），第3397-3415页。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="0faa321ae463cf423d057b0fb19c09b0142f3c2a" translate="yes" xml:space="preserve">
          <source>Other Parameters:</source>
          <target state="translated">其他参数:</target>
        </trans-unit>
        <trans-unit id="f7488409b393eaa19a207155b56a3606cc42d9c5" translate="yes" xml:space="preserve">
          <source>Other Versions</source>
          <target state="translated">其他版本</target>
        </trans-unit>
        <trans-unit id="bf60b2f111b62bfaee7623785937d680b71fe343" translate="yes" xml:space="preserve">
          <source>Other distance functions can be used in NMF as, for example, the (generalized) Kullback-Leibler (KL) divergence, also referred as I-divergence:</source>
          <target state="translated">其他的距离函数也可以用在NMF中,例如,(广义的)Kullback-Leibler(KL)发散,也称为I发散。</target>
        </trans-unit>
        <trans-unit id="7ba50765d1cae4c4ed89d4ff332ed3b825d08abc" translate="yes" xml:space="preserve">
          <source>Other features match the names and e-mail addresses of particular people who were posting at the time.</source>
          <target state="translated">其他功能可匹配当时发帖的特定人员的姓名和电子邮件地址。</target>
        </trans-unit>
        <trans-unit id="51c966edfa7d64a0b7dcf68b92d77cfd5b366772" translate="yes" xml:space="preserve">
          <source>Other machine learning packages for Python and related projects. Also algorithms that are slightly out of scope or not well established enough for scikit-learn.</source>
          <target state="translated">其他Python和相关项目的机器学习包。也有稍微超出scikit-learn范围或不够成熟的算法。</target>
        </trans-unit>
        <trans-unit id="2ea8bcd548fe9ec11d17cc82aea4ab0fbdf7f8f3" translate="yes" xml:space="preserve">
          <source>Other regression generators generate functions deterministically from randomized features. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt;&lt;code&gt;make_sparse_uncorrelated&lt;/code&gt;&lt;/a&gt; produces a target as a linear combination of four features with fixed coefficients. Others encode explicitly non-linear relations: &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt;&lt;code&gt;make_friedman1&lt;/code&gt;&lt;/a&gt; is related by polynomial and sine transforms; &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt;&lt;code&gt;make_friedman2&lt;/code&gt;&lt;/a&gt; includes feature multiplication and reciprocation; and &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt;&lt;code&gt;make_friedman3&lt;/code&gt;&lt;/a&gt; is similar with an arctan transformation on the target.</source>
          <target state="translated">其他回归生成器根据随机特征确定性地生成函数。&lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt; &lt;code&gt;make_sparse_uncorrelated&lt;/code&gt; &lt;/a&gt;将目标生成为具有固定系数的四个特征的线性组合。其他的则编码明确的非线性关系：&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt; &lt;code&gt;make_friedman1&lt;/code&gt; &lt;/a&gt;通过多项式和正弦变换相关；&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt; &lt;code&gt;make_friedman2&lt;/code&gt; &lt;/a&gt;包含特征乘法和往复运算；和&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt; &lt;code&gt;make_friedman3&lt;/code&gt; &lt;/a&gt;与目标反正切变换相似。</target>
        </trans-unit>
        <trans-unit id="756226f83bdd3199110bcb639e6fbe93b81b2b14" translate="yes" xml:space="preserve">
          <source>Others also work in the multiclass case:</source>
          <target state="translated">其他的也是在多类情况下工作。</target>
        </trans-unit>
        <trans-unit id="bce48a0cb0a5e5960a4a35ec10cf25f56bf2f60b" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be the sequence strings or bytes items are expected to be analyzed directly.</source>
          <target state="translated">否则,预计将直接分析输入的序列字符串或字节项。</target>
        </trans-unit>
        <trans-unit id="1eb83bd09e16b910ee3986257ed6e80732bc066a" translate="yes" xml:space="preserve">
          <source>Our definition: &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;, &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; and &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;, where &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; adopt the adjusted version to ensure that random predictions have a score of \(0\) and perfect predictions have a score of \(1\)..</source>
          <target state="translated">我们的定义：&lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;，&lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt;和&lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;，其中&lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt;采用调整后的版本，以确保随机预测的得分为\（0 \）和完美预测的得分为\（1 \）。 。</target>
        </trans-unit>
        <trans-unit id="a60ce8fd0b60aee8ad7f5d9f917babe62e72b491" translate="yes" xml:space="preserve">
          <source>Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">我们的实现的得分比Tsoumakas等人（2010年）给出的得分高1。这将其扩展为可以处理实例具有0个真实标签的退化情况。</target>
        </trans-unit>
        <trans-unit id="c3f0fa9ade6f943d608603fdef87384f7f12b49b" translate="yes" xml:space="preserve">
          <source>Out of the &lt;code&gt;n_features&lt;/code&gt; features, only 5 are actually used to compute &lt;code&gt;y&lt;/code&gt;. The remaining features are independent of &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">在 &lt;code&gt;n_features&lt;/code&gt; 个特征中，实际上只有5个用于计算 &lt;code&gt;y&lt;/code&gt; 。其余特征与 &lt;code&gt;y&lt;/code&gt; 无关。</target>
        </trans-unit>
        <trans-unit id="de345f1c1e8c124d63c9ee465bc413813ba2423e" translate="yes" xml:space="preserve">
          <source>Out-of-bag (OOB) estimates can be a useful heuristic to estimate the &amp;ldquo;optimal&amp;rdquo; number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt;), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.</source>
          <target state="translated">袋外（OOB）估计可能是一种有用的启发式方法，用于估计增强迭代的&amp;ldquo;最佳&amp;rdquo;次数。OOB估计值几乎与交叉验证估计值相同，但是可以即时进行计算，而无需重复进行模型拟合。OOB估计仅适用于随机梯度增强（即 &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt; ），该估计是基于自举样本中未包含的示例（所谓的&amp;ldquo;袋外示例&amp;rdquo;）从损失的改善中得出的。OOB估计器是真实测试损失的悲观估计器，但是对于少量的树仍然是一个相当不错的近似值。</target>
        </trans-unit>
        <trans-unit id="0edae687594f6a8a4aaab025d755be89c91cf6e0" translate="yes" xml:space="preserve">
          <source>Out-of-core (or &amp;ldquo;external memory&amp;rdquo;) learning is a technique used to learn from data that cannot fit in a computer&amp;rsquo;s main memory (RAM).</source>
          <target state="translated">核外（或&amp;ldquo;外部内存&amp;rdquo;）学习是一种用于从无法容纳在计算机主内存（RAM）中的数据中学习的技术。</target>
        </trans-unit>
        <trans-unit id="9961951956a78a655327742f08dd6b72dea1283f" translate="yes" xml:space="preserve">
          <source>Out-of-core classification of text documents</source>
          <target state="translated">文本文件的核心外分类</target>
        </trans-unit>
        <trans-unit id="1ee8fea1697e4d708569e4bb179873c92ff19379" translate="yes" xml:space="preserve">
          <source>Out:</source>
          <target state="translated">Out:</target>
        </trans-unit>
        <trans-unit id="5dd0aa388360b95626a38da9b18844d684c8d25b" translate="yes" xml:space="preserve">
          <source>Outlier detection</source>
          <target state="translated">异常值检测</target>
        </trans-unit>
        <trans-unit id="875f738eb0e68cda4066331e25fac5af4c71d682" translate="yes" xml:space="preserve">
          <source>Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.</source>
          <target state="translated">离群点检测和新奇点检测都是用于异常点检测,人们对检测异常或不寻常的观察结果感兴趣。那么,离群值检测也被称为无监督异常检测,新奇度检测被称为半监督异常检测。在异常点检测的情况下,异常点/异常值不能形成一个密集的聚类,因为现有的估计器假设异常点/异常值位于低密度区域。相反,在新奇点检测的情况下,新奇点/异常点只要位于训练数据的低密度区域,就可以形成一个密集簇,在这种情况下被认为是正常的。</target>
        </trans-unit>
        <trans-unit id="e16ebe52f017c4437fca8210daa352b7f7a34559" translate="yes" xml:space="preserve">
          <source>Outlier detection from covariance estimation may break or not perform well in high-dimensional settings. In particular, one will always take care to work with &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt;.</source>
          <target state="translated">在高维设置中，根据协方差估计进行的异常值检测可能会中断或效果不佳。特别要注意的是，要始终使用 &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="eb5776745abd0907a25a2d19ca27c92845132829" translate="yes" xml:space="preserve">
          <source>Outlier detection is similar to novelty detection in the sense that the goal is to separate a core of regular observations from some polluting ones, called &lt;em&gt;outliers&lt;/em&gt;. Yet, in the case of outlier detection, we don&amp;rsquo;t have a clean data set representing the population of regular observations that can be used to train any tool.</source>
          <target state="translated">离群值检测与新颖性检测类似，在某种意义上，目标是将常规观测的核心与某些受污染的观测&lt;em&gt;值（离群值）&lt;/em&gt;分开。但是，在离群值检测的情况下，我们没有干净的数据集来表示可用于训练任何工具的常规观测值。</target>
        </trans-unit>
        <trans-unit id="1d8881b6614c5c1d87283378baf1dfbd30d62aa2" translate="yes" xml:space="preserve">
          <source>Outlier detection on a real data set</source>
          <target state="translated">真实数据集的离群值检测</target>
        </trans-unit>
        <trans-unit id="4567caf33a07f033c1e56ef9d81272da195ec4e4" translate="yes" xml:space="preserve">
          <source>Outlier detection with Local Outlier Factor (LOF)</source>
          <target state="translated">使用局部离群值因子(LOF)进行离群值检测。</target>
        </trans-unit>
        <trans-unit id="1d4ae6e212657597b75c35cebf362553af1f6b83" translate="yes" xml:space="preserve">
          <source>Outliers in the X direction</source>
          <target state="translated">X方向的离群值</target>
        </trans-unit>
        <trans-unit id="1280eb8e6f7378d868cfa7fd24acb5cb10594078" translate="yes" xml:space="preserve">
          <source>Outliers in the y direction</source>
          <target state="translated">y方向的离群值</target>
        </trans-unit>
        <trans-unit id="fd162763a0f66a902211a2d40da7afdfc74ea634" translate="yes" xml:space="preserve">
          <source>Output a list of n_output arrays of class probabilities upon &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">在输出级的概率n_output阵列的列表 &lt;code&gt;predict_proba&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8298d7fc7f7d06e9b0287b5d9b7af6acdbad01e4" translate="yes" xml:space="preserve">
          <source>Output n_output values upon &lt;code&gt;predict&lt;/code&gt;;</source>
          <target state="translated">根据 &lt;code&gt;predict&lt;/code&gt; 输出n_output值;</target>
        </trans-unit>
        <trans-unit id="0c950fe98702d8e76b55b31a01ec26c58021324c" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">基于输出代码的策略与剩下的一对一和一对一完全不同。使用这些策略，每个类都在一个欧几里得空间中表示，每个维只能是0或1。另一种表达方式是，每个类都由一个二进制代码（0和1的数组）表示。跟踪每个类的位置/代码的矩阵称为代码簿。代码大小是上述空间的维数。直观地，每个类都应由一个尽可能唯一的代码表示，并且应设计一个好的代码书来优化分类的准确性。在此实现中，我们仅使用&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]中&lt;/a&gt;提倡的随机生成的代码簿，尽管将来可能会添加更多复杂的方法。</target>
        </trans-unit>
        <trans-unit id="ce947ff733c2ff6c4c204d57e36546e6961c8fdc" translate="yes" xml:space="preserve">
          <source>Output-code based strategies consist in representing each class with a binary code (an array of 0s and 1s). At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen. The main advantage of these strategies is that the number of classifiers used can be controlled by the user, either for compressing the model (0 &amp;lt; code_size &amp;lt; 1) or for making the model more robust to errors (code_size &amp;gt; 1). See the documentation for more details.</source>
          <target state="translated">基于输出代码的策略包括用二进制代码（0和1的数组）表示每个类。在拟合时，在代码簿中每位装配一个二进制分类器。在预测时，分类器用于在类空间中投影新点，并选择最接近这些点的类。这些策略的主要优点是用户可以控制使用的分类器数量，以压缩模型（0 &amp;lt;code_size &amp;lt;1）或使模型对错误更健壮（code_size&amp;gt; 1）。有关更多详细信息，请参见文档。</target>
        </trans-unit>
        <trans-unit id="a7e6bae7017e237617a86072aea77d9c980daf13" translate="yes" xml:space="preserve">
          <source>Overall mean.</source>
          <target state="translated">总的平均数。</target>
        </trans-unit>
        <trans-unit id="39400cd6ec0520b5a4505f75497b844c4371060d" translate="yes" xml:space="preserve">
          <source>Overall you can expect the prediction time to increase at least linearly with the number of features (non-linear cases can happen depending on the global memory footprint and estimator).</source>
          <target state="translated">总的来说,你可以预期预测时间至少会随着特征数量的增加而线性增加(非线性情况可能发生,这取决于全局内存占用和估计器)。</target>
        </trans-unit>
        <trans-unit id="91bd96083d98dc97930a239b87544217767aceaf" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps.</source>
          <target state="translated">在保留tokenizing和n-grams生成步骤的同时,覆盖预处理(字符串转换)阶段。</target>
        </trans-unit>
        <trans-unit id="abd6316e00c26c25837bba2d69b86f216194acd8" translate="yes" xml:space="preserve">
          <source>Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">在保留预处理和n-gram生成步骤的同时，覆盖字符串标记化步骤。仅在 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9ed28a68908d4cdeb1448490b897df73855c6566" translate="yes" xml:space="preserve">
          <source>P. Geurts, D. Ernst., and L. Wehenkel, &amp;ldquo;Extremely randomized trees&amp;rdquo;, Machine Learning, 63(1), 3-42, 2006.</source>
          <target state="translated">P. Geurts，D。Ernst。和L. Wehenkel，&amp;ldquo;极端随机树&amp;rdquo;，Machine Learning，63（1），3-42，2006年。</target>
        </trans-unit>
        <trans-unit id="915eb2720a9af992fe72961a5e439fc3997b7b8e" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. Journal of American Statistical Ass., 79:871, 1984.</source>
          <target state="translated">P.J.Rousseeuw。二乘法回归的最小中值。Journal of American Statistical Ass.,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="b9c25cc16ba020ea92289241ec3d659cb7a5c1ce" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach，M.Kull，&lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;精确召回增益曲线：PR分析正确完成&lt;/a&gt;，NIPS 2015。</target>
        </trans-unit>
        <trans-unit id="492b92fdeb678aa5ea0a0b2e24c313120c5ad6a0" translate="yes" xml:space="preserve">
          <source>PCA example with Iris Data-set</source>
          <target state="translated">Iris数据集的PCA实例</target>
        </trans-unit>
        <trans-unit id="e783d8dc6810fed89a1dbeb972c615c5d6fa683c" translate="yes" xml:space="preserve">
          <source>PCA is used to decompose a multivariate dataset in a set of successive orthogonal components that explain a maximum amount of the variance. In scikit-learn, &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is implemented as a &lt;em&gt;transformer&lt;/em&gt; object that learns \(n\) components in its &lt;code&gt;fit&lt;/code&gt; method, and can be used on new data to project it on these components.</source>
          <target state="translated">PCA用于分解一组解释最大方差的连续正交分量中的多元数据集。在scikit-learn中，&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;被实现为一个&lt;em&gt;转换&lt;/em&gt;对象，该对象以其 &lt;code&gt;fit&lt;/code&gt; 方法学习\（n \）个组件，并可用于新数据以将其投影到这些组件上。</target>
        </trans-unit>
        <trans-unit id="a8428e4319c22658665567a92df72d0be42ed589" translate="yes" xml:space="preserve">
          <source>PCA, on the other hand, finds orthogonal directions in the raw feature space that correspond to directions accounting for maximum variance.</source>
          <target state="translated">PCA则是在原始特征空间中找到正交方向,对应占最大方差的方向。</target>
        </trans-unit>
        <trans-unit id="daf6b41a17ad64437397807edf4249f5c767d4f8" translate="yes" xml:space="preserve">
          <source>PDF documentation</source>
          <target state="translated">PDF文件</target>
        </trans-unit>
        <trans-unit id="83a2c673c060675dd48fb711d1c30c7deadadba5" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above Figure shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">具有两个目标特征的PDP显示了两个特征之间的相互作用。例如,上图中的两个变量PDP显示了房价中位数对房龄和每户平均居住人数联合值的依赖性。我们可以清楚地看到这两个特征之间的互动关系。对于平均住户数大于2的情况,房价几乎与房龄无关,而对于小于2的值,则对房龄有很大的依赖性。</target>
        </trans-unit>
        <trans-unit id="818b23313a5fe3e3ead33eeac95b3f83aefbbeb6" translate="yes" xml:space="preserve">
          <source>PLS regression</source>
          <target state="translated">PLS回归</target>
        </trans-unit>
        <trans-unit id="256d47be93e9a1da4b73eeee064926026bfad0da" translate="yes" xml:space="preserve">
          <source>PLSCanonical implements the 2 blocks canonical PLS of the original Wold algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</source>
          <target state="translated">PLSCanonical实现了原始Wold算法[Tenenhaus 1998]p.204的2块规范PLS,在[Wegelin 2000]中称为PLS-C2A。</target>
        </trans-unit>
        <trans-unit id="cbfe13649cb0f1ff547f98c2537765f522c1604e" translate="yes" xml:space="preserve">
          <source>PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1 in case of one dimensional response. This class inherits from _PLS with mode=&amp;rdquo;A&amp;rdquo;, deflation_mode=&amp;rdquo;regression&amp;rdquo;, norm_y_weights=False and algorithm=&amp;rdquo;nipals&amp;rdquo;.</source>
          <target state="translated">PLSRegression实现一维响应时称为PLS2或PLS1的PLS 2块回归。此类从_PLS继承，其模式为&amp;ldquo; A&amp;rdquo;，deflation_mode =&amp;ldquo;回归&amp;rdquo;，norm_y_weights = False，算法=&amp;ldquo; nipals&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="5bd004de10b3be3d62af4c772e0a783e4c8d0cf7" translate="yes" xml:space="preserve">
          <source>PTRATIO pupil-teacher ratio by town</source>
          <target state="translated">PTRATIO 按城市分列的学生-教师比率</target>
        </trans-unit>
        <trans-unit id="41c1bb8d3d0929f28ded963b3c507fc9ad31e847" translate="yes" xml:space="preserve">
          <source>Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions, Statistics and Probability Letters, 33 (1997) 291-297</source>
          <target state="translated">Pace,R.Kelley和Ronald Barry,《稀疏空间自回归》,《统计与概率学报》,33(1997)291-297。</target>
        </trans-unit>
        <trans-unit id="839107cb8051c220f3fa3546dd66b100d0cfaf46" translate="yes" xml:space="preserve">
          <source>Pairwise Euclidean distances between points in the dataset.</source>
          <target state="translated">数据集中各点之间的欧几里得距离。</target>
        </trans-unit>
        <trans-unit id="91ced6bbdf313e062ca8a5307f468c6f86bd6aab" translate="yes" xml:space="preserve">
          <source>Pairwise dissimilarities between the points. Must be symmetric.</source>
          <target state="translated">点之间的对偶异同。必须是对称的。</target>
        </trans-unit>
        <trans-unit id="d8020c04569a536923cc79cf93520b90edece8e9" translate="yes" xml:space="preserve">
          <source>Pairwise metrics</source>
          <target state="translated">配对指标</target>
        </trans-unit>
        <trans-unit id="0f7f7966f9f80e85baa6445a47b9d7c8941de99f" translate="yes" xml:space="preserve">
          <source>Parameter &lt;code&gt;nu&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;OneClassSVM&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; approximates the fraction of training errors and support vectors.</source>
          <target state="translated">参数 &lt;code&gt;nu&lt;/code&gt; 在&lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;OneClassSVM&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; &lt;/a&gt;近似于训练误差和支持向量的分数。</target>
        </trans-unit>
        <trans-unit id="539d705b4d5ce5e51b178019bd7f151f362e066d" translate="yes" xml:space="preserve">
          <source>Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogenous.</source>
          <target state="translated">控制核的不均匀性的参数,如果sigma_0=0,则核是均匀的。如果sigma_0=0,则内核是同质的。</target>
        </trans-unit>
        <trans-unit id="2462327ecfe7c5d6548ffb2d6d2c9cd234dbc30c" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level</source>
          <target state="translated">控制噪音水平的参数</target>
        </trans-unit>
        <trans-unit id="4958bb8c16cafb2697226165d2c132d7ac8dc77e" translate="yes" xml:space="preserve">
          <source>Parameter estimation using grid search with cross-validation</source>
          <target state="translated">利用交叉验证的网格搜索进行参数估计。</target>
        </trans-unit>
        <trans-unit id="c2428812e57708220766f99c6be2b35f70d17ffd" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel</source>
          <target state="translated">knn内核的参数</target>
        </trans-unit>
        <trans-unit id="1fe064660ce73ee246b908fe6ec0781ebb1b98a2" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel</source>
          <target state="translated">rbf内核的参数</target>
        </trans-unit>
        <trans-unit id="79b884107bc3e783bfcd688080df4a673a9117bc" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">&lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt; 指标的参数来自sklearn.metrics.pairwise.pairwise_distances。当p = 1时，这等效于对p = 2使用manhattan_distance（l1）和euclidean_distance（l2）。对于任意p，使用minkowski_distance（l_p）。</target>
        </trans-unit>
        <trans-unit id="2987673c5e2227c54e84a4c36c70d874959de513" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">来自sklearn.metrics.pairwise.pairwise_distances的Minkowski度量参数。当p=1时,相当于使用曼哈顿距离(l1),当p=2时,使用欧几里得距离(l2)。对于任意的p,使用minkowski_distance (l_p)。</target>
        </trans-unit>
        <trans-unit id="76b1a424a6610c92a4ff7dfc12b9deaa7fadd9d4" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric</source>
          <target state="translated">对核的参数gamma由度量器指定</target>
        </trans-unit>
        <trans-unit id="5f182d859d9049c92f489a6a5f8f861f198a0672" translate="yes" xml:space="preserve">
          <source>Parameter names mapped to their values.</source>
          <target state="translated">对应到其值的参数名称。</target>
        </trans-unit>
        <trans-unit id="6c7eaceb91dd3f01e9a6c5c6273381eb8837898b" translate="yes" xml:space="preserve">
          <source>Parameter of RBF kernel: exp(-gamma * x^2)</source>
          <target state="translated">参数或RBF核:exp(-gamma*x^2)</target>
        </trans-unit>
        <trans-unit id="0a55d1c3b23ce41ff45285111de0d234bf72191c" translate="yes" xml:space="preserve">
          <source>Parameter of the corresponding mode.</source>
          <target state="translated">对应模式的参数。</target>
        </trans-unit>
        <trans-unit id="bd306dfafa0f09eb6ebeeb4165e12648835ffbc7" translate="yes" xml:space="preserve">
          <source>Parameter setting that gave the best results on the hold out data.</source>
          <target state="translated">剔除数据后得到最佳结果的参数设置。</target>
        </trans-unit>
        <trans-unit id="feb33995ff27df7648c2862697f9ab2d916fc6ad" translate="yes" xml:space="preserve">
          <source>Parameter to control the quality of the embedding according to the Johnson-Lindenstrauss lemma when n_components is set to &amp;lsquo;auto&amp;rsquo;.</source>
          <target state="translated">当n_components设置为'auto'时，根据Johnson-Lindenstrauss引理控制嵌入质量的参数。</target>
        </trans-unit>
        <trans-unit id="9ebea54f905d700d979affa38d92638bb2ef6e53" translate="yes" xml:space="preserve">
          <source>Parameter tuning using grid search</source>
          <target state="translated">使用网格搜索进行参数调整</target>
        </trans-unit>
        <trans-unit id="025546b75e4d071d18ff381aef96422930bc33e9" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). If a 1D y is passed in at fit (non multi-task usage), &lt;code&gt;coef_&lt;/code&gt; is then a 1D array. Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">参数向量（成本函数公式中的W）。如果适当传递1D y（非多任务用法），则 &lt;code&gt;coef_&lt;/code&gt; 为一维数组。注意， &lt;code&gt;coef_&lt;/code&gt; 存储 &lt;code&gt;W&lt;/code&gt; ， &lt;code&gt;W.T&lt;/code&gt; 的转置。</target>
        </trans-unit>
        <trans-unit id="fe2cd82aa0b85722f1fb3f2651910fd5a1cb8bc3" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">参数向量（成本函数公式中的W）。注意， &lt;code&gt;coef_&lt;/code&gt; 存储 &lt;code&gt;W&lt;/code&gt; ， &lt;code&gt;W.T&lt;/code&gt; 的转置。</target>
        </trans-unit>
        <trans-unit id="40a18e293fedd48b8399b301e107b7d0fd89c55d" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the cost function formula),</source>
          <target state="translated">参数向量(成本函数公式中的w);</target>
        </trans-unit>
        <trans-unit id="f2cc602f72e28952a1109943af93a6b27340c9a5" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the formulation formula).</source>
          <target state="translated">参数向量(公式中的w);</target>
        </trans-unit>
        <trans-unit id="b98d4ebc4de7e076498469fbea1e480d774d01d2" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the problem formulation).</source>
          <target state="translated">参数向量(问题表述中的w);</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="561ad54783e422872a1f3fe4a9c36ebd61273494" translate="yes" xml:space="preserve">
          <source>Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.</source>
          <target state="translated">作为可调用对象传递的内核的参数(关键字参数)和值。被其他内核忽略。</target>
        </trans-unit>
        <trans-unit id="89febd358321017f18d670418f2852c0de1ee9c6" translate="yes" xml:space="preserve">
          <source>Parameters of the estimators in the pipeline can be accessed using the &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; syntax:</source>
          <target state="translated">可以使用 &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; 语法访问管道中估计器的参数：</target>
        </trans-unit>
        <trans-unit id="da0d463840d0f1c86c777dbae23f9ad6731982e6" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo; or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">可以使用变压器名称和以&amp;ldquo; __&amp;rdquo;分隔的参数名称来设置变压器的参数。可以通过将参数的名称设置为另一个变压器来完全替换一个变压器，也可以通过将其设置为'drop'或 &lt;code&gt;None&lt;/code&gt; 来移除它。</target>
        </trans-unit>
        <trans-unit id="b076b9abb4a3e4211d375c7fba667486c4754cb9" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of each step, where each parameter name is prefixed such that parameter &lt;code&gt;p&lt;/code&gt; for step &lt;code&gt;s&lt;/code&gt; has key &lt;code&gt;s__p&lt;/code&gt;.</source>
          <target state="translated">传递给每个步骤的 &lt;code&gt;fit&lt;/code&gt; 方法的参数，其中每个参数名称都带有前缀，使得步骤 &lt;code&gt;s&lt;/code&gt; 的参数 &lt;code&gt;p&lt;/code&gt; 具有键 &lt;code&gt;s__p&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1ab85e076de8886205c489db8ed7843daa19517c" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the estimator</source>
          <target state="translated">传递给估算器的 &lt;code&gt;fit&lt;/code&gt; 方法的参数</target>
        </trans-unit>
        <trans-unit id="0e8067debf1488481c61a1eaa4a0a76867521e4f" translate="yes" xml:space="preserve">
          <source>Parameters to be set on estimator for this grid point.</source>
          <target state="translated">该网格点的估计器上要设置的参数。</target>
        </trans-unit>
        <trans-unit id="191e3e986e6964fefdb746bdbd32d026ac54732c" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method of the estimator.</source>
          <target state="translated">传递给估计器拟合方法的参数。</target>
        </trans-unit>
        <trans-unit id="80e379dd51d34ce2dbedd57a975596631a95d883" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method.</source>
          <target state="translated">要传递给拟合方法的参数。</target>
        </trans-unit>
        <trans-unit id="36ccb38b123600d9fbc78ab0cd9b6b307a008e1c" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called at the end of all transformations in the pipeline. Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.</source>
          <target state="translated">在管道中所有转换结束时调用的 &lt;code&gt;predict&lt;/code&gt; 参数。请注意，虽然这可以用于从具有return_std或return_cov的某些模型返回不确定性，但是由管道中的转换生成的不确定性不会传播到最终估计器。</target>
        </trans-unit>
        <trans-unit id="381c775599d6e4185d4410725809e360928357cd" translate="yes" xml:space="preserve">
          <source>Parameters:</source>
          <target state="translated">Parameters:</target>
        </trans-unit>
        <trans-unit id="99be92c9a2dedb3674880d6acb8f2dcdcbd96ff3" translate="yes" xml:space="preserve">
          <source>Parsing a text based source can be expensive. When working on repeatedly on the same dataset, it is recommended to wrap this loader with joblib.Memory.cache to store a memmapped backup of the CSR results of the first call and benefit from the near instantaneous loading of memmapped structures for the subsequent calls.</source>
          <target state="translated">解析一个基于文本的源可能是昂贵的。当重复处理同一数据集时,建议用joblib.Memory.cache来封装这个加载器,以存储第一次调用的CSR结果的memmapped备份,并从后续调用的memmapped结构近乎瞬时的加载中获益。</target>
        </trans-unit>
        <trans-unit id="f8d5f258416422c57466cd67cc8a02c6b05a80fd" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plots</source>
          <target state="translated">部分依赖性图</target>
        </trans-unit>
        <trans-unit id="e9c89f964f1a01a36b42f3fe4848b74ccc63e0e6" translate="yes" xml:space="preserve">
          <source>Partial Least Square SVD</source>
          <target state="translated">部分最小平方SVD</target>
        </trans-unit>
        <trans-unit id="93cbd804a6e8e51bf70182f90134157ea23f1138" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;target_variables&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;target_variables&lt;/code&gt; 的部分依赖。</target>
        </trans-unit>
        <trans-unit id="8a65d01c56b56d7e6904a157392f75eb71dc3b44" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; as a function of the &amp;lsquo;target&amp;rsquo; features &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;.</source>
          <target state="translated">部分依赖图（PDP）显示了目标响应与一组&amp;ldquo;目标&amp;rdquo;特征之间的依赖关系，使所有其他特征（&amp;ldquo;互补&amp;rdquo;特征）的值处于边际位置。直观地，我们可以将部分依赖关系解释为预期目标响应&lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt;作为&amp;ldquo;目标&amp;rdquo;特征&lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;的函数。</target>
        </trans-unit>
        <trans-unit id="9fe71a24f95abe640c27c0bbf2214ad816fa5b2e" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">部分依赖地块的 &lt;code&gt;features&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="652e656223f58b0f5fc37309adb1b1ac47d155cf" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for tree ensembles.</source>
          <target state="translated">树形集合的部分依赖性图。</target>
        </trans-unit>
        <trans-unit id="c1a7be74107eb23fd9bfcd8698a88bc718aa4772" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the joint values of the &lt;code&gt;target_variables&lt;/code&gt; and the function represented by the &lt;code&gt;gbrt&lt;/code&gt;.</source>
          <target state="translated">部分依赖图显示了 &lt;code&gt;target_variables&lt;/code&gt; 的联合值与 &lt;code&gt;gbrt&lt;/code&gt; 表示的函数之间的依赖关系。</target>
        </trans-unit>
        <trans-unit id="04afc172d4359535322f4eeb08a601341437662b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features (see &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt;&lt;code&gt;feature_importances_&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">局部依赖性图显示了目标函数&lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;与一组&amp;ldquo;目标&amp;rdquo;特征之间的依赖性，从而边缘化了所有其他特征（互补特征）的值。由于人类感知的限制，目标特征集的大小必须很小（通常是一两个），因此通常在最重要的特征中选择目标特征（请参阅&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt; &lt;code&gt;feature_importances_&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="27028d4e93727066aec3e2e83aa74954e7719a8b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">具有两个目标特征的部分依赖图使我们能够直观地看到它们之间的相互作用。双向部分依赖图显示了房价中位数对房龄和每户平均居住人数联合值的依赖性。我们可以清楚地看到这两个特征之间的相互作用。对于平均居住人数大于2人的家庭,房价几乎与房龄无关,而对于小于2人的家庭,则对房龄有很大的依赖性。</target>
        </trans-unit>
        <trans-unit id="6e99bc5cb78022b1555bc70fa32795dba1ae5f4f" translate="yes" xml:space="preserve">
          <source>Partially fit underlying estimators</source>
          <target state="translated">部分拟合基本估算器</target>
        </trans-unit>
        <trans-unit id="0a5bfb5dfddbf187589aac0e6c6f726ea3a56e0f" translate="yes" xml:space="preserve">
          <source>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</source>
          <target state="translated">特别是在高维空间中,数据更容易被线性分离,而天真贝叶斯和线性SVM等分类器的简单性可能会带来比其他分类器更好的泛化效果。</target>
        </trans-unit>
        <trans-unit id="ee5c2f652fa0ba7331b6add7547b0b3f663aedd3" translate="yes" xml:space="preserve">
          <source>Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure.</source>
          <target state="translated">在假设数据具有基本棋盘结构的前提下,对行和列进行分区。例如,如果有两个行分区和三个列分区,那么每行将属于三个双簇,每列将属于两个双簇。对应的行、列标签向量的外积就可以得到这个棋盘结构。</target>
        </trans-unit>
        <trans-unit id="d9f564dc265e98a01f24f70d1576b62ca3b43bd3" translate="yes" xml:space="preserve">
          <source>Passing a 2D matrix for multilabel classification</source>
          <target state="translated">为多标签分类传递二维矩阵。</target>
        </trans-unit>
        <trans-unit id="144adab066cd5c92a6778f61a4778ef74c72b2a0" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Classifier</source>
          <target state="translated">被动攻击型分类器</target>
        </trans-unit>
        <trans-unit id="d61635eec17c853d9d6e1ff234afe50660f92701" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Regressor</source>
          <target state="translated">被动进攻型调节器</target>
        </trans-unit>
        <trans-unit id="291afa1da61effaacff4bf3e40a8045b9b8d343b" translate="yes" xml:space="preserve">
          <source>Patches are assumed to overlap and the image is constructed by filling in the patches from left to right, top to bottom, averaging the overlapping regions.</source>
          <target state="translated">假设斑点重叠,通过从左到右、从上到下填充斑点,对重叠区域进行平均,构建图像。</target>
        </trans-unit>
        <trans-unit id="18a1699e2836ba2addd008ee2015c4e0ca5931f6" translate="yes" xml:space="preserve">
          <source>Path to the main folder holding one subfolder per category</source>
          <target state="translated">通往主文件夹的路径,每个类别有一个子文件夹。</target>
        </trans-unit>
        <trans-unit id="98ee95181d901b366d1fe1c0df5a309cc7a3de65" translate="yes" xml:space="preserve">
          <source>Penalization parameter selected.</source>
          <target state="translated">选择处罚参数。</target>
        </trans-unit>
        <trans-unit id="3bbf431b41c522bd1eb1b65ea50fc21584275d87" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad) yes no no no no Faster for large datasets no no no yes yes Robust to unscaled datasets yes yes yes no no ============================ =========== ======= =========== ===== ======</source>
          <target state="translated">惩罚拦截(坏)是 否 否 否 否 对大型数据集更快 否 否 否 是 是 是 对未缩放的数据集有鲁棒性 是 是 是 否 ====================================================================。</target>
        </trans-unit>
        <trans-unit id="64a00002571bc14aac9e57cf087ec95ea0663632" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term.</source>
          <target state="translated">误差项的惩罚参数C。</target>
        </trans-unit>
        <trans-unit id="78e16aaecb446c766536c888cb2ab681d45d227a" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term. The penalty is a squared l2 penalty. The bigger this parameter, the less regularization is used.</source>
          <target state="translated">误差项的惩罚参数C。该惩罚是l2个惩罚的平方。该参数越大,正则化的使用越少。</target>
        </trans-unit>
        <trans-unit id="f4b4203fc28ce6d3a674721e39c00d5f8047107a" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;fmin_l_bfgs_b&amp;rsquo; algorithm from scipy.optimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">默认情况下，使用scipy.optimize中的&amp;ldquo; fmin_l_bfgs_b&amp;rdquo;算法。如果未传递任何参数，则内核参数保持固定。可用的内部优化器包括：</target>
        </trans-unit>
        <trans-unit id="6244b7856d25c3c666d36fccf077f85fa1982ad7" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum.</source>
          <target state="translated">每功能调整为最小。</target>
        </trans-unit>
        <trans-unit id="d1fcc9536b36965b70f539451057ec6f4f433503" translate="yes" xml:space="preserve">
          <source>Per feature maximum absolute value.</source>
          <target state="translated">每个特征最大绝对值。</target>
        </trans-unit>
        <trans-unit id="c5e7199d590adbeaea5c7d5a6fd8bd4755090a1c" translate="yes" xml:space="preserve">
          <source>Per feature maximum seen in the data</source>
          <target state="translated">数据中看到的每个特征最大值</target>
        </trans-unit>
        <trans-unit id="102581d144872704eb291cec69ea6b75f7b2f4ae" translate="yes" xml:space="preserve">
          <source>Per feature minimum seen in the data</source>
          <target state="translated">在数据中看到的每个特征最小值</target>
        </trans-unit>
        <trans-unit id="9af0de5bb3d05f02ad6ecd6ef96e244722359bc9" translate="yes" xml:space="preserve">
          <source>Per feature range &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt; seen in the data</source>
          <target state="translated">数据中看到的每个要素范围 &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3041c95c2bc4cf499751cc15dcfa6079b79d0c01" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data.</source>
          <target state="translated">每个特征数据的相对比例。</target>
        </trans-unit>
        <trans-unit id="2aca96873ba30a1f44a2ea13c9cca023c862496e" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">每个要素的数据相对缩放。当 &lt;code&gt;with_std=False&lt;/code&gt; 时等于 &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="03c5a380bfcbdfa271df31ac8e5033140b3c462f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">按功能的经验均值汇总在对 &lt;code&gt;partial_fit&lt;/code&gt; 的调用上。</target>
        </trans-unit>
        <trans-unit id="9b69855eee3f3bb7b79cdf586195cf71da93449f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set.</source>
          <target state="translated">每个特征的经验平均值,由训练集估计。</target>
        </trans-unit>
        <trans-unit id="78b2f336c949583f3bdffdc9a030b0f9e6170c47" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set. Equal to &lt;code&gt;X.mean(axis=0)&lt;/code&gt;.</source>
          <target state="translated">根据训练集估算的每特征经验均值。等于 &lt;code&gt;X.mean(axis=0)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a8c85c36120ad4d7e0ffc8553bf9d9bb4f653d40" translate="yes" xml:space="preserve">
          <source>Per-feature empirical variance, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">每个功能的经验方差，通过对 &lt;code&gt;partial_fit&lt;/code&gt; 的调用进行汇总。</target>
        </trans-unit>
        <trans-unit id="bb6e9ff3187e622eed5823426c5d8cc8b9a5e66d" translate="yes" xml:space="preserve">
          <source>Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</source>
          <target state="translated">每个样本的权重。重新调整每个样本的C。较高的权重迫使分类器更加重视这些点。</target>
        </trans-unit>
        <trans-unit id="022818083764d59bc1c545a8df2dfc49cf87ec2a" translate="yes" xml:space="preserve">
          <source>Per-topic word distributions are independently drawn, where in reality all would be affected by a sparse base distribution, and would be correlated.</source>
          <target state="translated">每题词分布都是独立绘制的,在现实中都会受到稀疏基数分布的影响,会有相关性。</target>
        </trans-unit>
        <trans-unit id="508100893e29e053d40024965b139e71658b7b80" translate="yes" xml:space="preserve">
          <source>Percent of features to keep.</source>
          <target state="translated">保留功能的百分比。</target>
        </trans-unit>
        <trans-unit id="510c90c1028713db83438ed3b7d7b97622c046bb" translate="yes" xml:space="preserve">
          <source>Percentage of the number of classes to be used to create the code book. A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. A number greater than 1 will require more classifiers than one-vs-the-rest.</source>
          <target state="translated">用于创建代码簿的类数的百分比。在0和1之间的数字将需要比一个对其余的分类器更少的分类器。大于1的数字将需要更多的分类器,而不是一个对其余的分类器。</target>
        </trans-unit>
        <trans-unit id="ab474311418f716aa90a18ba4aac10d5e0126b01" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components.</source>
          <target state="translated">每个选定的组成部分所解释的方差百分比。</target>
        </trans-unit>
        <trans-unit id="6b606c4b3521608268acaf8a83daf1d705edec66" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.</source>
          <target state="translated">每个选定组件解释的方差百分比。如果未设置 &lt;code&gt;n_components&lt;/code&gt; ,则将存储所有分量，并且解释的方差之和等于1.0。仅在使用特征或svd解算器时可用。</target>
        </trans-unit>
        <trans-unit id="d93d3d6b53ae20e2e020e6bfd5f07bc4328ff552" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0.</source>
          <target state="translated">每个选定的成分所解释的方差百分比。如果所有成分都被储存,则解释的方差之和等于1.0。</target>
        </trans-unit>
        <trans-unit id="5ae537dc31ff6e276137ba1f3f08f14e2d75b135" translate="yes" xml:space="preserve">
          <source>Perfect labeling is scored 1.0:</source>
          <target state="translated">完美标注得1.0分。</target>
        </trans-unit>
        <trans-unit id="e0246cf8e59488c8ec6f2dd495c80e88ab5e2c38" translate="yes" xml:space="preserve">
          <source>Perfect labelings are both homogeneous and complete, hence have score 1.0:</source>
          <target state="translated">完美的标签既是同质的又是完整的,因此得分为1.0。</target>
        </trans-unit>
        <trans-unit id="0b6e6a15e84a2c0c2b67bd408293381d6bde8086" translate="yes" xml:space="preserve">
          <source>Perfect labelings are complete:</source>
          <target state="translated">完美的标签是完整的。</target>
        </trans-unit>
        <trans-unit id="c929d898b15ba46b39cbe3a578cc048974dbb0f3" translate="yes" xml:space="preserve">
          <source>Perfect labelings are homogeneous:</source>
          <target state="translated">完美的标签是同质的。</target>
        </trans-unit>
        <trans-unit id="158762f0fcedf70ff27743eef2b9fe2391aaecf5" translate="yes" xml:space="preserve">
          <source>Perfectly matching labelings have a score of 1 even</source>
          <target state="translated">完全匹配的标签得1分,甚至是1分</target>
        </trans-unit>
        <trans-unit id="689d4751e15d0ca03ac4490cb60697622e5a7435" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data</source>
          <target state="translated">对数据进行亲和传播聚类。</target>
        </trans-unit>
        <trans-unit id="dee861689c2a0a2296c4bb43119e58f854cfe756" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data.</source>
          <target state="translated">对数据进行亲和传播聚类。</target>
        </trans-unit>
        <trans-unit id="463c2804b4b2c3d108889b17acd479af4436cc72" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix.</source>
          <target state="translated">根据特征或距离矩阵进行DBSCAN聚类。</target>
        </trans-unit>
        <trans-unit id="458d7c0c2b90dff326f89ad767c75f6a1812b730" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from vector array or distance matrix.</source>
          <target state="translated">从向量数组或距离矩阵执行DBSCAN聚类。</target>
        </trans-unit>
        <trans-unit id="959d910f7763a2ffdb63e2da58508fc0266c6120" translate="yes" xml:space="preserve">
          <source>Perform Fast Independent Component Analysis.</source>
          <target state="translated">进行快速独立成分分析。</target>
        </trans-unit>
        <trans-unit id="b44047366aaa6bbf25bda0720c2b9955136f4c83" translate="yes" xml:space="preserve">
          <source>Perform a Locally Linear Embedding analysis on the data.</source>
          <target state="translated">对数据进行局部线性嵌入分析。</target>
        </trans-unit>
        <trans-unit id="ac1255795fd03e9f556426224dcbfbd70ca25e88" translate="yes" xml:space="preserve">
          <source>Perform a shortest-path graph search on a positive directed or undirected graph.</source>
          <target state="translated">在正向或无向图上进行最短路径图搜索。</target>
        </trans-unit>
        <trans-unit id="5913acb65bcb3cfc0407c274e6a0ae6c08f54988" translate="yes" xml:space="preserve">
          <source>Perform binary classification using non-linear SVC with RBF kernel. The target to predict is a XOR of the inputs.</source>
          <target state="translated">使用非线性SVC与RBF内核进行二元分类。要预测的目标是输入的XOR。</target>
        </trans-unit>
        <trans-unit id="a259ca5c38306ae844a312467fcf634f7a4c4cb8" translate="yes" xml:space="preserve">
          <source>Perform classification on an array of test vectors X.</source>
          <target state="translated">对测试向量数组X进行分类。</target>
        </trans-unit>
        <trans-unit id="1af0f015c949bd1c16d805fdf5523bbcd5119678" translate="yes" xml:space="preserve">
          <source>Perform classification on samples in X.</source>
          <target state="translated">对X中的样本进行分类。</target>
        </trans-unit>
        <trans-unit id="b3b3f491b55f8b579a228793b65f99ca8d0d1a92" translate="yes" xml:space="preserve">
          <source>Perform classification on test vectors X.</source>
          <target state="translated">对测试向量X进行分类。</target>
        </trans-unit>
        <trans-unit id="db94ca6613eef6e933177aeabe20672ae9208bdf" translate="yes" xml:space="preserve">
          <source>Perform clustering.</source>
          <target state="translated">进行聚类。</target>
        </trans-unit>
        <trans-unit id="f9f7c30d76f5b933404ebf4eb86819fed33be90a" translate="yes" xml:space="preserve">
          <source>Perform dimensionality reduction on X.</source>
          <target state="translated">对X进行降维。</target>
        </trans-unit>
        <trans-unit id="6d24d9dcbe2141c7b30ceff371628950cd7ca425" translate="yes" xml:space="preserve">
          <source>Perform is_fitted validation for estimator.</source>
          <target state="translated">对估计器进行is_fitted验证。</target>
        </trans-unit>
        <trans-unit id="28c6ac8c77fceae308f63cb91c2fe135b4f5904f" translate="yes" xml:space="preserve">
          <source>Perform mapping to a normal distribution using a power transform.</source>
          <target state="translated">使用功率变换执行映射到正态分布。</target>
        </trans-unit>
        <trans-unit id="f154e55e13cfe215c964ae2fb4c3f06da46b83fe" translate="yes" xml:space="preserve">
          <source>Perform mean shift clustering of data using a flat kernel.</source>
          <target state="translated">使用平核对数据进行均值移动聚类。</target>
        </trans-unit>
        <trans-unit id="5d74999037a10ebb61d14a38ac3c1f58c8d3eb1c" translate="yes" xml:space="preserve">
          <source>Perform one Gibbs sampling step.</source>
          <target state="translated">执行一个吉布斯采样步骤。</target>
        </trans-unit>
        <trans-unit id="b97c414705aa3f4f9199ddb08da830ac54e8fe97" translate="yes" xml:space="preserve">
          <source>Perform regression on samples in X.</source>
          <target state="translated">对X中的样本进行回归。</target>
        </trans-unit>
        <trans-unit id="dd51e0250263d470cb8a4effc410185e24e99d6f" translate="yes" xml:space="preserve">
          <source>Perform robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">进行稳健的标准化,消除离群值的影响,但不把离群值和离群值放在同一尺度上。</target>
        </trans-unit>
        <trans-unit id="ebef79dfac2e65b8c25ad9bb7fdce83cd9513504" translate="yes" xml:space="preserve">
          <source>Perform standardization by centering and scaling</source>
          <target state="translated">通过居中和缩放进行标准化</target>
        </trans-unit>
        <trans-unit id="4bc7fa7479a101fbc87b729f92b16086a341ed9e" translate="yes" xml:space="preserve">
          <source>Perform standardization that is faster, but less robust to outliers.</source>
          <target state="translated">执行标准化,速度更快,但对异常值的鲁棒性较差。</target>
        </trans-unit>
        <trans-unit id="c8a1451466ddb25587dffc5d4da05875ebb74725" translate="yes" xml:space="preserve">
          <source>Performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.</source>
          <target state="translated">对夏宫(中国)图像进行像素向量量化(VQ),在保持整体外观质量的前提下,将显示图像所需的颜色数量从96,615种独特颜色减少到64种。</target>
        </trans-unit>
        <trans-unit id="7945877a79ee9606b9df91e80330316ac1099e28" translate="yes" xml:space="preserve">
          <source>Performs approximate nearest neighbor search using LSH forest.</source>
          <target state="translated">使用LSH森林进行近似近邻搜索。</target>
        </trans-unit>
        <trans-unit id="9bab7093aa44c52b527bcacee82e15ab827f7949" translate="yes" xml:space="preserve">
          <source>Performs binarization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行二进制化。</target>
        </trans-unit>
        <trans-unit id="9334db1899f0bba94453f1ee6fbd171b507e5ed1" translate="yes" xml:space="preserve">
          <source>Performs centering and scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行居中和缩放。</target>
        </trans-unit>
        <trans-unit id="506256c7ae18c8053ecaa6445590a98acf36aa0e" translate="yes" xml:space="preserve">
          <source>Performs clustering on X and returns cluster labels.</source>
          <target state="translated">对X进行聚类并返回聚类标签。</target>
        </trans-unit>
        <trans-unit id="38545772bd4529f41bf4bec322ebc7f80ab61f41" translate="yes" xml:space="preserve">
          <source>Performs inductive inference across the model.</source>
          <target state="translated">对整个模型进行归纳推理。</target>
        </trans-unit>
        <trans-unit id="de7dc9fb5a771d54ea7fadc4d86dd2f8269f14e4" translate="yes" xml:space="preserve">
          <source>Performs normalization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API 执行规范化（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）。</target>
        </trans-unit>
        <trans-unit id="72f57dd0021b24f09da3fde633d42235df9baa52" translate="yes" xml:space="preserve">
          <source>Performs outlier detection on X.</source>
          <target state="translated">对X进行异常值检测。</target>
        </trans-unit>
        <trans-unit id="c032681b9d32a5a7daa554f673be122edd3ede2b" translate="yes" xml:space="preserve">
          <source>Performs power transformation using the &lt;code&gt;Transformer&lt;/code&gt; API (as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API（作为&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;预处理的一部分）执行电源转换。</target>
        </trans-unit>
        <trans-unit id="9b0d235575d753630f72f479dd595fb051616b74" translate="yes" xml:space="preserve">
          <source>Performs quantile-based scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用 &lt;code&gt;Transformer&lt;/code&gt; API 执行基于分位数的缩放（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）。</target>
        </trans-unit>
        <trans-unit id="b88ebf81bb1a4e07e575709aa3160fcbaf33439c" translate="yes" xml:space="preserve">
          <source>Performs robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">进行稳健的标准化,消除离群值的影响,但不把离群值和离群值放在同一尺度上。</target>
        </trans-unit>
        <trans-unit id="269796266e3e34d93d181d30bdc48e574f3c9af7" translate="yes" xml:space="preserve">
          <source>Performs scaling to a given range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用&amp;ldquo; Transformer&amp;rdquo; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行缩放到给定范围的缩放。</target>
        </trans-unit>
        <trans-unit id="bd68fa80cce73218da8c0d7af21a3e3a79fd9429" translate="yes" xml:space="preserve">
          <source>Performs scaling to the [-1, 1] range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用Transformer API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分），将比例缩放到[-1，1]范围。</target>
        </trans-unit>
        <trans-unit id="a6c272533c048656769d2922baf310f99127bfa0" translate="yes" xml:space="preserve">
          <source>Performs scaling to unit variance using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">使用&amp;ldquo; Transformer&amp;rdquo; API（例如，作为预处理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; 的&lt;/a&gt;一部分）执行缩放至单位方差。</target>
        </trans-unit>
        <trans-unit id="ac7c14a68907c3e1c4fe02a23cc6348fd68ae158" translate="yes" xml:space="preserve">
          <source>Performs standardization that is faster, but less robust to outliers.</source>
          <target state="translated">执行标准化,速度更快,但对异常值的鲁棒性较差。</target>
        </trans-unit>
        <trans-unit id="d1ac21bb0cdcd78e01860cf682da905f50be135c" translate="yes" xml:space="preserve">
          <source>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</source>
          <target state="translated">即使它的假设在一定程度上被生成数据的真实模型所违反,也表现良好。</target>
        </trans-unit>
        <trans-unit id="1a9a31609b061b9c4c3ea5164d451f2cf664e34b" translate="yes" xml:space="preserve">
          <source>Perplexity is defined as exp(-1. * log-likelihood per word)</source>
          <target state="translated">迷惑性定义为exp(-1.*每个词的对数可能性)</target>
        </trans-unit>
        <trans-unit id="80863d8aea17a1c5fba5bee33e10fcfe3c3b5254" translate="yes" xml:space="preserve">
          <source>Perplexity score.</source>
          <target state="translated">困惑的分数。</target>
        </trans-unit>
        <trans-unit id="25e7450397b385690390d4cb490d54af7bb7f613" translate="yes" xml:space="preserve">
          <source>Perplexity tolerance in batch learning. Only used when &lt;code&gt;evaluate_every&lt;/code&gt; is greater than 0.</source>
          <target state="translated">批处理学习中的困惑容忍度。仅在 &lt;code&gt;evaluate_every&lt;/code&gt; 大于0时使用。</target>
        </trans-unit>
        <trans-unit id="bed69aed128c6d53c076bf23b1786ba34af67dfd" translate="yes" xml:space="preserve">
          <source>Persistent Contrastive Divergence addresses this. Instead of starting a new chain each time the gradient is needed, and performing only one Gibbs sampling step, in PCD we keep a number of chains (fantasy particles) that are updated \(k\) Gibbs steps after each weight update. This allows the particles to explore the space more thoroughly.</source>
          <target state="translated">持久性对比发散解决了这个问题。在PCD中,我们不需要每次需要梯度时都启动一个新的链,并且只执行一个Gibbs采样步,而是保留一些链(幻想粒子),在每次权重更新后,都会更新(k)个Gibbs步。这使得粒子可以更彻底地探索空间。</target>
        </trans-unit>
        <trans-unit id="d4d9d12e88278335e6c824e88af73f55a763004e" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti,Robust Statistics Concomitant scale estimates,pg 172.</target>
        </trans-unit>
        <trans-unit id="977cdb0f1102753846469a4e3ab78497c359fae5" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti:Robust Statistics,Concomitant scale estimates,第172页。</target>
        </trans-unit>
        <trans-unit id="f869e193262fa2d8e1a9ddde0485aa49aaa656aa" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi:10.1016/0377-0427(87)90125-7&lt;/a&gt;.</source>
          <target state="translated">Peter J.Rousseeuw（1987）。&amp;ldquo;剪影：对聚类分析的解释和验证的图形帮助&amp;rdquo;。计算和应用数学20：53&amp;ndash;65。&lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi：10.1016 / 0377-0427（87）90125-7&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="801ff1e5ba061302f2ef13b831a12ef30f616d52" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53-65.</source>
          <target state="translated">Peter J.Rousseeuw（1987）。&amp;ldquo;剪影：对聚类分析的解释和验证的图形帮助&amp;rdquo;。计算和应用数学20：53-65。</target>
        </trans-unit>
        <trans-unit id="6884db0930152b7581421b9e7df37cdc709bc0ae" translate="yes" xml:space="preserve">
          <source>Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.</source>
          <target state="translated">pickle和unpickle一棵树。请注意,树的状态在pickle操作中被保存:树在unpickling时不需要重建。</target>
        </trans-unit>
        <trans-unit id="4a6d28315bc21af0edd71a7862fc9db5f7a4917f" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">李平，T。哈斯提和KW教堂，2006年，&amp;ldquo;非常稀疏的随机投影&amp;rdquo;。&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3462e562173cab76115a1fabd23d03498a615dda" translate="yes" xml:space="preserve">
          <source>Ping Li, Trevor J. Hastie, and Kenneth W. Church. 2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;Very sparse random projections.&lt;/a&gt; In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD &amp;lsquo;06). ACM, New York, NY, USA, 287-296.</source>
          <target state="translated">李萍，Trevor J. Hastie和Kenneth W. Church。2006年。&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;非常稀疏的随机投影。&lt;/a&gt;在第12届ACM SIGKDD关于知识发现和数据挖掘的国际会议论文集（KDD '06）中。美国纽约州纽约市，ACM，287-296。</target>
        </trans-unit>
        <trans-unit id="5fcec2c4630ab50971732249756f691f50ae9f29" translate="yes" xml:space="preserve">
          <source>Pipeline Anova SVM</source>
          <target state="translated">管道 Anova SVM</target>
        </trans-unit>
        <trans-unit id="a041187d94eb589a1ba5ff98293ef896e00c97e7" translate="yes" xml:space="preserve">
          <source>Pipeline of transforms with a final estimator.</source>
          <target state="translated">带有最终估计器的变换流水线。</target>
        </trans-unit>
        <trans-unit id="52761af283a0d9e614a4e2ba9d4a353d3fd70a7b" translate="yes" xml:space="preserve">
          <source>Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.</source>
          <target state="translated">管道通过确保使用相同的样本来训练变换器和预测器,有助于避免在交叉验证中把统计数据从测试数据泄露到训练的模型中。</target>
        </trans-unit>
        <trans-unit id="3d31223cfe1830200469a76812f595efba107474" translate="yes" xml:space="preserve">
          <source>Pipelining</source>
          <target state="translated">Pipelining</target>
        </trans-unit>
        <trans-unit id="04ae27026f61a0e2fe9396849cac7271f4f56e69" translate="yes" xml:space="preserve">
          <source>Pipelining: chaining a PCA and a logistic regression</source>
          <target state="translated">管线化:将PCA和逻辑回归进行链式连接</target>
        </trans-unit>
        <trans-unit id="4d2bb7a399ca2f416aedb250a1c02b6dbddd98f5" translate="yes" xml:space="preserve">
          <source>Pixel importances with a parallel forest of trees</source>
          <target state="translated">平行树林的像素进口量。</target>
        </trans-unit>
        <trans-unit id="2ca4493c014c6673344a97eb7b5e5aaa17897b68" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo; SVM的概率输出以及与正规化似然方法的比较&amp;rdquo;&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0765f4dfcff27a39498ebd734357c5eb178852a5" translate="yes" xml:space="preserve">
          <source>Please note that in this example the data is non-noisy, hence it is possible to extract the exact coefficients.</source>
          <target state="translated">请注意,在这个例子中,数据是无噪声的,因此可以提取精确的系数。</target>
        </trans-unit>
        <trans-unit id="60f5c599778dc38cb8638a819c878af82379b06d" translate="yes" xml:space="preserve">
          <source>Please note that the dataset here is not large enough to show the benefits of kernel approximation, as the exact SVM is still reasonably fast.</source>
          <target state="translated">请注意,这里的数据集还不够大,不足以显示内核近似的好处,因为精确的SVM还是相当快的。</target>
        </trans-unit>
        <trans-unit id="580c520b29a7b706c6ee9312d3a6f880fe113df6" translate="yes" xml:space="preserve">
          <source>Please refer to the &lt;a href=&quot;http://scikit-learn.org/stable/install.html#installation-instructions&quot;&gt;installation instructions&lt;/a&gt; page for more information and for system-specific instructions.</source>
          <target state="translated">请参阅&lt;a href=&quot;http://scikit-learn.org/stable/install.html#installation-instructions&quot;&gt;安装说明&lt;/a&gt;页面以获取更多信息和特定于系统的说明。</target>
        </trans-unit>
        <trans-unit id="245a16d516483fde4bb90ded88adcf811c9e2c4f" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;#mlp-tips&quot;&gt;Tips on Practical Use&lt;/a&gt; section that addresses some of these disadvantages.</source>
          <target state="translated">请参阅&lt;a href=&quot;#mlp-tips&quot;&gt;&amp;ldquo;实用提示&amp;rdquo;&lt;/a&gt;部分中的部分缺点。</target>
        </trans-unit>
        <trans-unit id="1c1763d18d05bf3f25645375f32837b8195b549b" translate="yes" xml:space="preserve">
          <source>Please take care in choosing a stop word list. Popular stop word lists may include words that are highly informative to some tasks, such as &lt;em&gt;computer&lt;/em&gt;.</source>
          <target state="translated">请谨慎选择停用词列表。流行的停用词列表可能包含对某些任务（如&lt;em&gt;计算机）&lt;/em&gt;具有高度信息意义的词。</target>
        </trans-unit>
        <trans-unit id="8695c6b10616f55d08370738ac83b62df92988cf" translate="yes" xml:space="preserve">
          <source>Plot Precision-Recall curve for each class and iso-f1 curves</source>
          <target state="translated">绘制各等级的精度-召回曲线和iso-f1曲线。</target>
        </trans-unit>
        <trans-unit id="74b5d936c6a7142a9d0455e9b6b736449035ae4d" translate="yes" xml:space="preserve">
          <source>Plot ROC curves for the multiclass problem</source>
          <target state="translated">绘制多类问题的ROC曲线。</target>
        </trans-unit>
        <trans-unit id="2b92ac175dbafedc9ebadfa3064fcc8b95d12013" translate="yes" xml:space="preserve">
          <source>Plot Ridge coefficients as a function of the L2 regularization</source>
          <target state="translated">绘制Ridge系数作为L2正则化的函数。</target>
        </trans-unit>
        <trans-unit id="2786a51af34001a054f667eea5f5427aa4ac1cf2" translate="yes" xml:space="preserve">
          <source>Plot Ridge coefficients as a function of the regularization</source>
          <target state="translated">绘制Ridge系数作为正则化的函数。</target>
        </trans-unit>
        <trans-unit id="a465ec1964ec6fb41a10c223b00503371b098b22" translate="yes" xml:space="preserve">
          <source>Plot class probabilities calculated by the VotingClassifier</source>
          <target state="translated">绘制由VotingClassifier计算的类概率。</target>
        </trans-unit>
        <trans-unit id="b43d02980e353a273a01e17df2d13e81e7a80aee" translate="yes" xml:space="preserve">
          <source>Plot classification probability</source>
          <target state="translated">绘制分类概率</target>
        </trans-unit>
        <trans-unit id="c6389911af4059bed3f7dfa408ce8e7c1791da24" translate="yes" xml:space="preserve">
          <source>Plot decision function of a weighted dataset, where the size of points is proportional to its weight.</source>
          <target state="translated">绘制加权数据集的决策函数,其中点的大小与其权重成正比。</target>
        </trans-unit>
        <trans-unit id="2055a202b59cc1d82b030fc80b5879816af6142f" translate="yes" xml:space="preserve">
          <source>Plot decision surface of multi-class SGD on iris dataset. The hyperplanes corresponding to the three one-versus-all (OVA) classifiers are represented by the dashed lines.</source>
          <target state="translated">绘制多类SGD在虹膜数据集上的决策面。虚线表示对应于三个一比一(OVA)分类器的超平面。</target>
        </trans-unit>
        <trans-unit id="327297e49968a75dbce927b0b7ac7371a08d6d35" translate="yes" xml:space="preserve">
          <source>Plot decision surface of multinomial and One-vs-Rest Logistic Regression. The hyperplanes corresponding to the three One-vs-Rest (OVR) classifiers are represented by the dashed lines.</source>
          <target state="translated">多项式和One-vs-Rest Logistic Regression的决策面图。虚线表示对应三种One-vs-Rest(OVR)分类器的超平面。</target>
        </trans-unit>
        <trans-unit id="da6b79ecce62363042c6b7355c061b1d158cd29e" translate="yes" xml:space="preserve">
          <source>Plot different SVM classifiers in the iris dataset</source>
          <target state="translated">在虹膜数据集中绘制不同的SVM分类器图</target>
        </trans-unit>
        <trans-unit id="fec11ecd65159c6aa4dd2ed7bc70c42c80743b33" translate="yes" xml:space="preserve">
          <source>Plot multi-class SGD on the iris dataset</source>
          <target state="translated">在虹膜数据集上绘制多类SGD。</target>
        </trans-unit>
        <trans-unit id="ba32fad35c82296b19217e926ca784f8dc480aa6" translate="yes" xml:space="preserve">
          <source>Plot multinomial and One-vs-Rest Logistic Regression</source>
          <target state="translated">绘制多项式和单对单逻辑回归图。</target>
        </trans-unit>
        <trans-unit id="4b397af4573c8c3ff6fe276f1d3414d458173eb8" translate="yes" xml:space="preserve">
          <source>Plot of a ROC curve for a specific class</source>
          <target state="translated">特定类别的ROC曲线图。</target>
        </trans-unit>
        <trans-unit id="2e98f97179f7787be7e479df07e8c653a4456c6c" translate="yes" xml:space="preserve">
          <source>Plot randomly generated classification dataset</source>
          <target state="translated">绘制随机生成的分类数据集</target>
        </trans-unit>
        <trans-unit id="8635886c93f9f7bac9a25109d5aa81af0e2282a3" translate="yes" xml:space="preserve">
          <source>Plot randomly generated multilabel dataset</source>
          <target state="translated">绘制随机生成的多标签数据集。</target>
        </trans-unit>
        <trans-unit id="efb6adeaeb9b8fea32241dc4e81af8acb788aff0" translate="yes" xml:space="preserve">
          <source>Plot results</source>
          <target state="translated">绘图结果</target>
        </trans-unit>
        <trans-unit id="7114cafe0c0f8ef1073ae59db6d1ecdd4e9b786a" translate="yes" xml:space="preserve">
          <source>Plot several randomly generated 2D classification datasets. This example illustrates the &lt;code&gt;datasets.make_classification&lt;/code&gt;&lt;code&gt;datasets.make_blobs&lt;/code&gt; and &lt;code&gt;datasets.make_gaussian_quantiles&lt;/code&gt; functions.</source>
          <target state="translated">绘制几个随机生成的2D分类数据集。此示例说明了 &lt;code&gt;datasets.make_classification&lt;/code&gt; &lt;code&gt;datasets.make_blobs&lt;/code&gt; 集.make_blobs和 &lt;code&gt;datasets.make_gaussian_quantiles&lt;/code&gt; 函数。</target>
        </trans-unit>
        <trans-unit id="d93ec4735c14a13d9aac7a26f400c6a70dcf1259" translate="yes" xml:space="preserve">
          <source>Plot the Precision-Recall curve</source>
          <target state="translated">绘制精度-回收曲线</target>
        </trans-unit>
        <trans-unit id="56fc4a54784c2e98ce65c0720810139c4d68b5b2" translate="yes" xml:space="preserve">
          <source>Plot the class probabilities of the first sample in a toy dataset predicted by three different classifiers and averaged by the &lt;code&gt;VotingClassifier&lt;/code&gt;.</source>
          <target state="translated">在玩具数据集中由三个不同的分类器预测并由 &lt;code&gt;VotingClassifier&lt;/code&gt; 求平均值的第一个样本的分类概率图。</target>
        </trans-unit>
        <trans-unit id="2b41947dfde5208fe00cac90f2d4dc03f6823202" translate="yes" xml:space="preserve">
          <source>Plot the classification probability for different classifiers. We use a 3 class dataset, and we classify it with a Support Vector classifier, L1 and L2 penalized logistic regression with either a One-Vs-Rest or multinomial setting, and Gaussian process classification.</source>
          <target state="translated">绘制不同分类器的分类概率。我们使用一个3类数据集,我们用支持向量分类器、L1和L2惩罚性逻辑回归(One-Vs-Rest或多变量设置)和高斯过程分类进行分类。</target>
        </trans-unit>
        <trans-unit id="1cd8aee71b9f3c23870f222d4675d55da346d5dd" translate="yes" xml:space="preserve">
          <source>Plot the confidence ellipsoids of a mixture of two Gaussians obtained with Expectation Maximisation (&lt;code&gt;GaussianMixture&lt;/code&gt; class) and Variational Inference (&lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class models with a Dirichlet process prior).</source>
          <target state="translated">绘制通过期望最大化（ &lt;code&gt;GaussianMixture&lt;/code&gt; 类）和变分推断（ &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; 类模型先有Dirichlet过程）获得的两个高斯混合的置信椭圆体。</target>
        </trans-unit>
        <trans-unit id="00182c117782c7850baca00bf6cebe8035dd77e1" translate="yes" xml:space="preserve">
          <source>Plot the decision boundaries of a &lt;code&gt;VotingClassifier&lt;/code&gt; for two features of the Iris dataset.</source>
          <target state="translated">为Iris数据集的两个特征绘制 &lt;code&gt;VotingClassifier&lt;/code&gt; 的决策边界。</target>
        </trans-unit>
        <trans-unit id="1dc52c59ef7b06b62b5bf6227f1a878073dd4d70" translate="yes" xml:space="preserve">
          <source>Plot the decision boundaries of a VotingClassifier</source>
          <target state="translated">绘制投票分类器的决策边界。</target>
        </trans-unit>
        <trans-unit id="55185472d28511bfa0363da45cc5b619cef7f522" translate="yes" xml:space="preserve">
          <source>Plot the decision surface of a decision tree on the iris dataset</source>
          <target state="translated">在虹膜数据集上绘制决策树的决策面。</target>
        </trans-unit>
        <trans-unit id="d9594e701a87aa1711d08683ce0adfef724ecd27" translate="yes" xml:space="preserve">
          <source>Plot the decision surface of a decision tree trained on pairs of features of the iris dataset.</source>
          <target state="translated">绘制在虹膜数据集的一对特征上训练的决策树的决策面。</target>
        </trans-unit>
        <trans-unit id="f0bf861c9d54040e12c9cc05a6e2089c743c128d" translate="yes" xml:space="preserve">
          <source>Plot the decision surfaces of ensembles of trees on the iris dataset</source>
          <target state="translated">在虹膜数据集上绘制树群的决策面。</target>
        </trans-unit>
        <trans-unit id="f7cdddf773db21703dc8d829a947d9360d2b4b3d" translate="yes" xml:space="preserve">
          <source>Plot the decision surfaces of forests of randomized trees trained on pairs of features of the iris dataset.</source>
          <target state="translated">绘制在虹膜数据集的成对特征上训练的随机化树的森林的决策面。</target>
        </trans-unit>
        <trans-unit id="81590d4bb30da97000d973d7bab58a58c2e64092" translate="yes" xml:space="preserve">
          <source>Plot the density estimation of a mixture of two Gaussians. Data is generated from two Gaussians with different centers and covariance matrices.</source>
          <target state="translated">绘制两个高斯的混合物的密度估计图。数据由两个不同中心和协方差矩阵的高斯曲线生成。</target>
        </trans-unit>
        <trans-unit id="6861c16dbeca1a065533244a96ba3516d1d4c3a8" translate="yes" xml:space="preserve">
          <source>Plot the maximum margin separating hyperplane within a two-class separable dataset using a Support Vector Machine classifier with linear kernel.</source>
          <target state="translated">用线性核的支持向量机分类器绘制两类可分离数据集中的最大余量分离超平面。</target>
        </trans-unit>
        <trans-unit id="035aca7881cd7f9aa629a522da62a9cd8a6c5c8b" translate="yes" xml:space="preserve">
          <source>Plot the maximum margin separating hyperplane within a two-class separable dataset using a linear Support Vector Machines classifier trained using SGD.</source>
          <target state="translated">用SGD训练的线性支持向量机分类器绘制两类可分离数据集中的最大余量分离超平面。</target>
        </trans-unit>
        <trans-unit id="970f17834d8825a63cbdc2d99c8fc1d2edc7990a" translate="yes" xml:space="preserve">
          <source>Plot the micro-averaged Precision-Recall curve</source>
          <target state="translated">绘制微观平均精度-召回曲线。</target>
        </trans-unit>
        <trans-unit id="80cbcfd03f5ca970cf63eec27ccbc1b7f85e2ada" translate="yes" xml:space="preserve">
          <source>Plotting Cross-Validated Predictions</source>
          <target state="translated">绘制交叉验证的预测图。</target>
        </trans-unit>
        <trans-unit id="931865770541ce727daa93f7fa28b4bfb7a185e8" translate="yes" xml:space="preserve">
          <source>Plotting Learning Curves</source>
          <target state="translated">绘制学习曲线</target>
        </trans-unit>
        <trans-unit id="61375fe5074bc7ba726b7585b9c829f7928f0e90" translate="yes" xml:space="preserve">
          <source>Plotting Validation Curves</source>
          <target state="translated">绘制验证曲线</target>
        </trans-unit>
        <trans-unit id="86755acc87f18891f16b4684ed01b0376a7cdfb2" translate="yes" xml:space="preserve">
          <source>Plotting the result</source>
          <target state="translated">绘制结果</target>
        </trans-unit>
        <trans-unit id="515260d5ba710a1140cfc8c5e00df3878ade8efb" translate="yes" xml:space="preserve">
          <source>Point used as initial kernel locations. If None and bin_seeding=False, each data point is used as a seed. If None and bin_seeding=True, see bin_seeding.</source>
          <target state="translated">作为初始内核位置的点。如果None和bin_seeding=False,则每个数据点都被用作种子。如果None和bin_seeding=True,参见bin_seeding。</target>
        </trans-unit>
        <trans-unit id="f2900dffbacbabbaa3e41fbfbf606af904f4ea9a" translate="yes" xml:space="preserve">
          <source>Points are labeled as follows, where Y means the class is present:</source>
          <target state="translated">点的标示如下,其中Y表示类存在。</target>
        </trans-unit>
        <trans-unit id="bfa76eceb881251219024aa15126052b423fdc69" translate="yes" xml:space="preserve">
          <source>Points that are neighboring often share the same leaf of a tree and therefore share large parts of their hashed representation. This allows to separate two concentric circles simply based on the principal components of the transformed data with truncated SVD.</source>
          <target state="translated">相邻的点往往共享树的同一片叶子,因此共享其哈希表示的大部分。这就可以简单地根据变换后的数据的主成分,用截断的SVD来分离两个同心圆。</target>
        </trans-unit>
        <trans-unit id="2aa7f739412f96bbef950dc5131b827c8658cc0f" translate="yes" xml:space="preserve">
          <source>Polynomial interpolation</source>
          <target state="translated">多项式插值</target>
        </trans-unit>
        <trans-unit id="ea36423930650d6bde3fdec25656592fdb82be08" translate="yes" xml:space="preserve">
          <source>Popular choices for the regularization term \(R\) include:</source>
          <target state="translated">正则化术语的常用选择包括:</target>
        </trans-unit>
        <trans-unit id="5beb1d6b6cca44d23c554e4884a63a14968bd1fc" translate="yes" xml:space="preserve">
          <source>Population block population</source>
          <target state="translated">人口组别人口</target>
        </trans-unit>
        <trans-unit id="b6bfeaec43665e5045c5188dc50b287def6848b4" translate="yes" xml:space="preserve">
          <source>Portion of the largest variance of all features that is added to variances for calculation stability.</source>
          <target state="translated">为了计算的稳定性,所有特征中最大方差的部分被添加到方差中。</target>
        </trans-unit>
        <trans-unit id="71bbec1d0bc4c70d1bf578164b2f035df429e62c" translate="yes" xml:space="preserve">
          <source>Possible examples:</source>
          <target state="translated">可能的例子:</target>
        </trans-unit>
        <trans-unit id="b62496b0d745ebd826ec5e2a96a59ab92b59997a" translate="yes" xml:space="preserve">
          <source>Possible to validate a model using statistical tests. That makes it possible to account for the reliability of the model.</source>
          <target state="translated">可以用统计测试来验证一个模型。这就有可能说明模型的可靠性。</target>
        </trans-unit>
        <trans-unit id="1ef096a287ef80019501f0b7658be73c867011a0" translate="yes" xml:space="preserve">
          <source>Posterior log-probabilities of classification per class.</source>
          <target state="translated">每类分类的后对数概率。</target>
        </trans-unit>
        <trans-unit id="0167e7e78429608afa3a283f8dc4209c9081db39" translate="yes" xml:space="preserve">
          <source>Posterior probabilities of classification</source>
          <target state="translated">分类的后置概率</target>
        </trans-unit>
        <trans-unit id="eb0cff62f61d9c7621bc439a7c03422a0f7152b0" translate="yes" xml:space="preserve">
          <source>Posterior probabilities of classification per class.</source>
          <target state="translated">每类分类的后置概率。</target>
        </trans-unit>
        <trans-unit id="75700cecf794e529a76abd7d8bbf40d36053c816" translate="yes" xml:space="preserve">
          <source>Potential users of LOO for model selection should weigh a few known caveats. When compared with \(k\)-fold cross validation, one builds \(n\) models from \(n\) samples instead of \(k\) models, where \(n &amp;gt; k\). Moreover, each is trained on \(n - 1\) samples rather than \((k-1) n / k\). In both ways, assuming \(k\) is not too large and \(k &amp;lt; n\), LOO is more computationally expensive than \(k\)-fold cross validation.</source>
          <target state="translated">LOO的潜在用户在选择模型时应权衡一些已知的警告。与\（k \）倍交叉验证相比，人们可以从\（n \）个样本构建\（n \）个模型，而不是\（k \）个模型，其中\（n&amp;gt; k \）个模型。而且，每个样本都在\（n-1 \）个样本上而不是\（（k-1）n / k \）上训练。在两种方式下，假设\（k \）不太大且\（k &amp;lt;n \），LOO的计算开销要大于\（k \）倍交叉验证。</target>
        </trans-unit>
        <trans-unit id="a74e80361c78ad66c827d841d2f4673ac4c08e24" translate="yes" xml:space="preserve">
          <source>Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">Minkowski度量的功率参数。当p=1时,相当于使用manhattan_distance (l1),p=2时使用欧氏距离(l2)。对于任意的p,使用minkowski_distance (l_p)。</target>
        </trans-unit>
        <trans-unit id="944ca5a7bffc3b53cfa153e37ee8230d3113fab6" translate="yes" xml:space="preserve">
          <source>Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other situations where normality is desired.</source>
          <target state="translated">幂级变换是一系列参数化的单调变换,用于使数据更像高斯。这对与异方差(非恒定方差)有关的建模问题或其他需要正态性的情况很有用。</target>
        </trans-unit>
        <trans-unit id="fdeecbacef0f72dd39653fda27722b303c8b957f" translate="yes" xml:space="preserve">
          <source>PowerTransformer</source>
          <target state="translated">PowerTransformer</target>
        </trans-unit>
        <trans-unit id="87bf6e4911166a71371c673a1c349474b4b6bf5d" translate="yes" xml:space="preserve">
          <source>Pre-computed dissimilarities are passed directly to &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;fit_transform&lt;/code&gt;.</source>
          <target state="translated">预先计算的差异直接传递给 &lt;code&gt;fit&lt;/code&gt; 和 &lt;code&gt;fit_transform&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1eedfffdf42945a227f3b7652653d6d5b56201f3" translate="yes" xml:space="preserve">
          <source>Pre-computed dot-products of vectors in X (e.g., &lt;code&gt;(X**2).sum(axis=1)&lt;/code&gt;)</source>
          <target state="translated">X中向量的预先计算的点积（例如 &lt;code&gt;(X**2).sum(axis=1)&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="245447283cbdae836e2c3ef586ea5c6ddd53470e" translate="yes" xml:space="preserve">
          <source>Pre-computed dot-products of vectors in Y (e.g., &lt;code&gt;(Y**2).sum(axis=1)&lt;/code&gt;)</source>
          <target state="translated">Y中向量的预先计算的点积（例如 &lt;code&gt;(Y**2).sum(axis=1)&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="3dd4db5ce7ea626f59e720f0c27096a22aa1ecd0" translate="yes" xml:space="preserve">
          <source>Precision</source>
          <target state="translated">Precision</target>
        </trans-unit>
        <trans-unit id="3cadf6b155ea9cfa34e1c6ff646ed002dc6e267c" translate="yes" xml:space="preserve">
          <source>Precision (\(P\)) is defined as the number of true positives (\(T_p\)) over the number of true positives plus the number of false positives (\(F_p\)).</source>
          <target state="translated">精确度(P\)定义为真阳性数(T_p\))与真阳性数加假阳性数(F_p\))。</target>
        </trans-unit>
        <trans-unit id="48b3bfbc2fc9b1f176694a73c9f60562de8469bc" translate="yes" xml:space="preserve">
          <source>Precision of the positive class in binary classification or weighted average of the precision of each class for the multiclass task.</source>
          <target state="translated">二元分类中正类的精度或多类任务中各类精度的加权平均值。</target>
        </trans-unit>
        <trans-unit id="c7599672c1de408bde10c556da2d523e0bbc458a" translate="yes" xml:space="preserve">
          <source>Precision of the solution.</source>
          <target state="translated">解决方案的精度。</target>
        </trans-unit>
        <trans-unit id="145d1275fdbccedcff81a776436f980376926a4b" translate="yes" xml:space="preserve">
          <source>Precision values such that element i is the precision of predictions with score &amp;gt;= thresholds[i] and the last element is 1.</source>
          <target state="translated">精度值，以使元素i为得分&amp;gt; = thresholds [i]且最后一个元素为1的预测精度。</target>
        </trans-unit>
        <trans-unit id="9b8d6b4078699ef62eae215de2112bcae36a779b" translate="yes" xml:space="preserve">
          <source>Precision-Recall</source>
          <target state="translated">Precision-Recall</target>
        </trans-unit>
        <trans-unit id="c4dc9f01a91988c2185e5c4ff4abf1c68a5c776a" translate="yes" xml:space="preserve">
          <source>Precision-Recall is a useful measure of success of prediction when the classes are very imbalanced. In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned.</source>
          <target state="translated">精确度-召回率是衡量预测成功与否的一个有用指标,当类非常不平衡的时候。在信息检索中,精确性是对结果相关性的衡量,而召回是对返回多少真正相关结果的衡量。</target>
        </trans-unit>
        <trans-unit id="9d2c44ea940ec9160ea4212eaee48c117c9fec49" translate="yes" xml:space="preserve">
          <source>Precision-recall curves are typically used in binary classification to study the output of a classifier. In order to extend the precision-recall curve and average precision to multi-class or multi-label classification, it is necessary to binarize the output. One curve can be drawn per label, but one can also draw a precision-recall curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).</source>
          <target state="translated">精度-召回曲线通常用于二元分类中研究分类器的输出。为了将精度-回访曲线和平均精度扩展到多类或多标签分类中,有必要对输出进行二值化。每个标签可以绘制一条曲线,但也可以将标签指示矩阵中的每个元素视为二进制预测(微平均)来绘制精度-回落曲线。</target>
        </trans-unit>
        <trans-unit id="f9a6c763996d681deabdfef7b8476b0fb69e48e8" translate="yes" xml:space="preserve">
          <source>Precompute distances (faster but takes more memory).</source>
          <target state="translated">预先计算距离(速度更快,但需要更多内存)。</target>
        </trans-unit>
        <trans-unit id="74241dcd8b76a34a71276f4af2e1f247526d8ccf" translate="yes" xml:space="preserve">
          <source>Precomputed Gram matrix (X&amp;rsquo; * X), if &lt;code&gt;'auto'&lt;/code&gt;, the Gram matrix is precomputed from the given X, if there are more samples than features.</source>
          <target state="translated">预先计算的Gram矩阵（X'* X），如果为 &lt;code&gt;'auto'&lt;/code&gt; ，则如果样本多于特征，则从给定的X预先计算Gram矩阵。</target>
        </trans-unit>
        <trans-unit id="2a2e45fbf62fedaeebe0c8590ad60ff4174e5ab2" translate="yes" xml:space="preserve">
          <source>Precomputed Gram matrix, dictionary * dictionary&amp;rsquo;</source>
          <target state="translated">预计算的Gram矩阵，字典*字典'</target>
        </trans-unit>
        <trans-unit id="a48847353a3a5d95755a7a73ff3aa46a650e801f" translate="yes" xml:space="preserve">
          <source>Precomputed covariance, dictionary&amp;rsquo; * X</source>
          <target state="translated">预先计算的协方差，字典'* X</target>
        </trans-unit>
        <trans-unit id="fa26606f0ded4eeae827a5e13cb6b101bfb1dc41" translate="yes" xml:space="preserve">
          <source>Predefined split cross-validator</source>
          <target state="translated">预定义的分割交叉验证器</target>
        </trans-unit>
        <trans-unit id="4cb3beb22c8d3a092f661b0f558220d3851b4f5f" translate="yes" xml:space="preserve">
          <source>Predict class at each stage for X.</source>
          <target state="translated">预测X的每个阶段的等级。</target>
        </trans-unit>
        <trans-unit id="b37b3a68f8838806941f9d07a55fc66d496734de" translate="yes" xml:space="preserve">
          <source>Predict class for X.</source>
          <target state="translated">预测类为X。</target>
        </trans-unit>
        <trans-unit id="110127bb58167b2a44079253e6bdd9fb9d0322a0" translate="yes" xml:space="preserve">
          <source>Predict class labels for X.</source>
          <target state="translated">预测X的类标签。</target>
        </trans-unit>
        <trans-unit id="66f3d65c0d89bdce43ef6cf6e001f4ae1e150fa3" translate="yes" xml:space="preserve">
          <source>Predict class labels for samples in X.</source>
          <target state="translated">预测X中样本的类标签。</target>
        </trans-unit>
        <trans-unit id="ff9a33e306cb61b5d46880775730458dbfda1fc5" translate="yes" xml:space="preserve">
          <source>Predict class log-probabilities for X.</source>
          <target state="translated">预测X的类对数概率。</target>
        </trans-unit>
        <trans-unit id="90e5301af97afcc90d0c29c15774ada1b78e1932" translate="yes" xml:space="preserve">
          <source>Predict class log-probabilities of the input samples X.</source>
          <target state="translated">预测输入样本X的类对数概率。</target>
        </trans-unit>
        <trans-unit id="b3e79fd1959c8312a9a26cdaea691da2d340b21b" translate="yes" xml:space="preserve">
          <source>Predict class or regression value for X.</source>
          <target state="translated">预测X的类或回归值。</target>
        </trans-unit>
        <trans-unit id="ee407700821ff6ce9beed9f4cbb5c1de51181025" translate="yes" xml:space="preserve">
          <source>Predict class probabilities at each stage for X.</source>
          <target state="translated">预测X在每个阶段的类概率。</target>
        </trans-unit>
        <trans-unit id="d19c8a92fef6e1d8e00a4d018404a4763e36f5ad" translate="yes" xml:space="preserve">
          <source>Predict class probabilities for X.</source>
          <target state="translated">预测X的类概率。</target>
        </trans-unit>
        <trans-unit id="09dc322e274a3505c300cc07827d47dfbb399f93" translate="yes" xml:space="preserve">
          <source>Predict class probabilities of the input samples X.</source>
          <target state="translated">预测输入样本X的类概率。</target>
        </trans-unit>
        <trans-unit id="881f47898705d21006122f71ad4ab62a62a462be" translate="yes" xml:space="preserve">
          <source>Predict classes for X.</source>
          <target state="translated">预测X的类。</target>
        </trans-unit>
        <trans-unit id="296acbb4c624db7079fa54773a5e0ad84afb010f" translate="yes" xml:space="preserve">
          <source>Predict confidence scores for samples.</source>
          <target state="translated">预测样本的置信度分数。</target>
        </trans-unit>
        <trans-unit id="2494751d3a2d1a42d5313b28fcc4f83bac74cb1a" translate="yes" xml:space="preserve">
          <source>Predict data using the &lt;code&gt;centroids_&lt;/code&gt; of subclusters.</source>
          <target state="translated">使用子群集的 &lt;code&gt;centroids_&lt;/code&gt; 预测数据。</target>
        </trans-unit>
        <trans-unit id="92e8a0090ce03f45dfdf289779e466981411d7fa" translate="yes" xml:space="preserve">
          <source>Predict if a particular sample is an outlier or not.</source>
          <target state="translated">预测某个样本是否为离群值。</target>
        </trans-unit>
        <trans-unit id="015ccebc331620054f423244712d7856284722d0" translate="yes" xml:space="preserve">
          <source>Predict margin (libsvm name for this is predict_values)</source>
          <target state="translated">预测余量(libsvm的名字是predict_values)</target>
        </trans-unit>
        <trans-unit id="5363b2c32425812c2bcb3fbaa9bf8cfb2d5164a0" translate="yes" xml:space="preserve">
          <source>Predict multi-class targets using underlying estimators.</source>
          <target state="translated">使用基础估计器预测多类目标。</target>
        </trans-unit>
        <trans-unit id="236af7da07ddb0d9ed29a089f18dd28b81ac84bd" translate="yes" xml:space="preserve">
          <source>Predict multi-output variable using a model</source>
          <target state="translated">使用模型预测多产出变量。</target>
        </trans-unit>
        <trans-unit id="440aeb8d451f927f87cd14a1da1e1e06cfe27c30" translate="yes" xml:space="preserve">
          <source>Predict multi-output variable using a model trained for each target variable.</source>
          <target state="translated">使用为每个目标变量训练的模型预测多输出变量。</target>
        </trans-unit>
        <trans-unit id="57d6ee4b63567e7fa514630f74e07b2180223661" translate="yes" xml:space="preserve">
          <source>Predict new data by linear interpolation.</source>
          <target state="translated">通过线性插值预测新数据。</target>
        </trans-unit>
        <trans-unit id="24bee86083d9d8686237dff0aca9e15905f91489" translate="yes" xml:space="preserve">
          <source>Predict on the data matrix X using the ClassifierChain model.</source>
          <target state="translated">使用ClassifierChain模型对数据矩阵X进行预测。</target>
        </trans-unit>
        <trans-unit id="4966ba27ad7d2bb95b545e975edd2dd7639f0b61" translate="yes" xml:space="preserve">
          <source>Predict output may not match that of standalone liblinear in certain cases. See &lt;a href=&quot;../linear_model#liblinear-differences&quot;&gt;differences from liblinear&lt;/a&gt; in the narrative documentation.</source>
          <target state="translated">在某些情况下，预测输出可能与独立liblinear的输出不匹配。请参见叙述文档中&lt;a href=&quot;../linear_model#liblinear-differences&quot;&gt;与liblinear的区别&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="04fbb304d74e3ee1459f16173d84b52205d2990a" translate="yes" xml:space="preserve">
          <source>Predict posterior probability of each component given the data.</source>
          <target state="translated">预测给定数据的每个分量的后概率。</target>
        </trans-unit>
        <trans-unit id="bd6763b250c597082132af1f5682341c5d5ff8a5" translate="yes" xml:space="preserve">
          <source>Predict probabilities</source>
          <target state="translated">预测概率</target>
        </trans-unit>
        <trans-unit id="8106d8771f34f5eabc577fcdeb5e96fd7582dc17" translate="yes" xml:space="preserve">
          <source>Predict probability estimates.</source>
          <target state="translated">预测概率估计。</target>
        </trans-unit>
        <trans-unit id="e11ea3d8d0d16dd6b1042fa5aae9ca526b776539" translate="yes" xml:space="preserve">
          <source>Predict probability for each possible outcome.</source>
          <target state="translated">预测每个可能结果的概率。</target>
        </trans-unit>
        <trans-unit id="cab499225116c6c4381a969a0e7a2827b785a690" translate="yes" xml:space="preserve">
          <source>Predict regression target at each stage for X.</source>
          <target state="translated">预测X在每个阶段的回归目标。</target>
        </trans-unit>
        <trans-unit id="723d1df099023f4b7390aaaf6546a09600703da8" translate="yes" xml:space="preserve">
          <source>Predict regression target for X.</source>
          <target state="translated">预测X的回归目标。</target>
        </trans-unit>
        <trans-unit id="a7c5178b8c5f08e15306c326887476bcc207fa67" translate="yes" xml:space="preserve">
          <source>Predict regression value for X.</source>
          <target state="translated">预测X的回归值。</target>
        </trans-unit>
        <trans-unit id="11987bdd614b0d45fb0a30378442e5e664ee787f" translate="yes" xml:space="preserve">
          <source>Predict target values of X given a model (low-level method)</source>
          <target state="translated">预测给定模型的X的目标值(低级方法)</target>
        </trans-unit>
        <trans-unit id="1118ec744c70a9ced7c798b3344fa4f80e7f350c" translate="yes" xml:space="preserve">
          <source>Predict the class labels for the provided data</source>
          <target state="translated">预测所提供数据的类标签。</target>
        </trans-unit>
        <trans-unit id="0fd38b6b56decb7521e45313caadd70afab49eb9" translate="yes" xml:space="preserve">
          <source>Predict the closest cluster each sample in X belongs to.</source>
          <target state="translated">预测X中每个样本所属的最接近的簇。</target>
        </trans-unit>
        <trans-unit id="d04dc0ca95e918d737a8729bfb93bc4da7747280" translate="yes" xml:space="preserve">
          <source>Predict the labels (1 inlier, -1 outlier) of X according to LOF.</source>
          <target state="translated">根据LOF预测X的标签(1个inlier,-1个outlier)。</target>
        </trans-unit>
        <trans-unit id="9d1641b066b242cb2bf0042ad4cd1995e81ab6fa" translate="yes" xml:space="preserve">
          <source>Predict the labels (1 inlier, -1 outlier) of X according to the fitted model.</source>
          <target state="translated">根据拟合模型预测X的标签(1个inlier,-1个outlier)。</target>
        </trans-unit>
        <trans-unit id="85b48751710a59d1604b478a1cb0fe4558154254" translate="yes" xml:space="preserve">
          <source>Predict the labels for the data samples in X using trained model.</source>
          <target state="translated">使用训练好的模型预测X中数据样本的标签。</target>
        </trans-unit>
        <trans-unit id="6fcf85e4f9a2635469a3bc0f62b0508a0449c9c3" translate="yes" xml:space="preserve">
          <source>Predict the target for the provided data</source>
          <target state="translated">预测所提供数据的目标</target>
        </trans-unit>
        <trans-unit id="2071be7e8e1c641fcdd997af2eac5155a95c2002" translate="yes" xml:space="preserve">
          <source>Predict the target of new samples.</source>
          <target state="translated">预测新样本的目标。</target>
        </trans-unit>
        <trans-unit id="b036c338c8c7c8b8f3a7f9dfaafcc549ad9379b9" translate="yes" xml:space="preserve">
          <source>Predict the target of new samples. Can be different from the prediction of the uncalibrated classifier.</source>
          <target state="translated">预测新样本的目标。可以与未标定分类器的预测不同。</target>
        </trans-unit>
        <trans-unit id="058fb86a189ec6bee9925542c788fb4116728ab0" translate="yes" xml:space="preserve">
          <source>Predict using the Gaussian process regression model</source>
          <target state="translated">使用高斯过程回归模型进行预测。</target>
        </trans-unit>
        <trans-unit id="c5fa5a8d6dbf415899a0d8f5dbeeb100342ad788" translate="yes" xml:space="preserve">
          <source>Predict using the base regressor, applying inverse.</source>
          <target state="translated">用基础回归因子进行预测,应用反。</target>
        </trans-unit>
        <trans-unit id="16d6c91bb6247b0e3b2e7c1608acb6c6aaf1c58e" translate="yes" xml:space="preserve">
          <source>Predict using the estimated model.</source>
          <target state="translated">使用估计模型进行预测。</target>
        </trans-unit>
        <trans-unit id="6771834342807ce64511b84dad107250034aca9e" translate="yes" xml:space="preserve">
          <source>Predict using the kernel ridge model</source>
          <target state="translated">利用核脊模型进行预测。</target>
        </trans-unit>
        <trans-unit id="9cc445af0d47cc9e3fe5b5148b7b800c2621abb9" translate="yes" xml:space="preserve">
          <source>Predict using the linear model</source>
          <target state="translated">使用线性模型进行预测</target>
        </trans-unit>
        <trans-unit id="ea5afc9ecafd018284fd5a8011653647aab370f8" translate="yes" xml:space="preserve">
          <source>Predict using the linear model.</source>
          <target state="translated">使用线性模型进行预测。</target>
        </trans-unit>
        <trans-unit id="afe2e7622b6e98b5fd3219fbefabf19e5e27c19d" translate="yes" xml:space="preserve">
          <source>Predict using the multi-layer perceptron classifier</source>
          <target state="translated">使用多层感知器进行预测。</target>
        </trans-unit>
        <trans-unit id="418245d3416ded93f91e6f6a7f46db6d2bddb0b8" translate="yes" xml:space="preserve">
          <source>Predict using the multi-layer perceptron model.</source>
          <target state="translated">使用多层感知器模型进行预测。</target>
        </trans-unit>
        <trans-unit id="bbcfd227a4fd6a52cd15ff04b498dfd37817f646" translate="yes" xml:space="preserve">
          <source>Predicted class (expectation)</source>
          <target state="translated">预测等级(期望值)</target>
        </trans-unit>
        <trans-unit id="c23c0bade8db4a99bdd74a847d85f85436dde8e2" translate="yes" xml:space="preserve">
          <source>Predicted class label per sample.</source>
          <target state="translated">每个样本的预测类标签。</target>
        </trans-unit>
        <trans-unit id="6eb2b54a32f8badefb51abd9627abd2f4ed7175d" translate="yes" xml:space="preserve">
          <source>Predicted class labels.</source>
          <target state="translated">预测类标签。</target>
        </trans-unit>
        <trans-unit id="1c0fb7806758bcc1e05acba0f3c96fa3d7a5bb0f" translate="yes" xml:space="preserve">
          <source>Predicted decisions, as output by decision_function (floats).</source>
          <target state="translated">预测的决策,由decision_function输出(floats)。</target>
        </trans-unit>
        <trans-unit id="9d60d7541de11ead40040ebf55656138bfa06e54" translate="yes" xml:space="preserve">
          <source>Predicted labels for each sample.</source>
          <target state="translated">预测每个样本的标签。</target>
        </trans-unit>
        <trans-unit id="bda5186912ec2d3a4c3d985e04325968396dafa6" translate="yes" xml:space="preserve">
          <source>Predicted labels, as returned by a classifier.</source>
          <target state="translated">预测标签,由分类器返回。</target>
        </trans-unit>
        <trans-unit id="4206066a487d91e230020ac6b49a356a37221536" translate="yes" xml:space="preserve">
          <source>Predicted multi-class targets.</source>
          <target state="translated">预测多类目标。</target>
        </trans-unit>
        <trans-unit id="471345c03a0f6c76e771b685835d34aaa085be6f" translate="yes" xml:space="preserve">
          <source>Predicted probabilities, as returned by a classifier&amp;rsquo;s predict_proba method. If &lt;code&gt;y_pred.shape = (n_samples,)&lt;/code&gt; the probabilities provided are assumed to be that of the positive class. The labels in &lt;code&gt;y_pred&lt;/code&gt; are assumed to be ordered alphabetically, as done by &lt;code&gt;preprocessing.LabelBinarizer&lt;/code&gt;.</source>
          <target state="translated">由分类器的predict_proba方法返回的预测概率。如果 &lt;code&gt;y_pred.shape = (n_samples,)&lt;/code&gt; 则提供的概率假定为正类。假设 &lt;code&gt;y_pred&lt;/code&gt; 中的标签按字母顺序排序，就像 &lt;code&gt;preprocessing.LabelBinarizer&lt;/code&gt; 一样。</target>
        </trans-unit>
        <trans-unit id="30fa748f60591aa49ffa54b8625d19e6d3fa1caf" translate="yes" xml:space="preserve">
          <source>Predicted target values for X</source>
          <target state="translated">X的预测目标值</target>
        </trans-unit>
        <trans-unit id="ddfdf29590f8e61e5d8fd1e8af0625d097b22795" translate="yes" xml:space="preserve">
          <source>Predicted target values for X, values are from &lt;code&gt;classes_&lt;/code&gt;</source>
          <target state="translated">X的预测目标值，这些值来自 &lt;code&gt;classes_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0a5193d35f1d0747b0dcd37c2b58098d90dd9dc1" translate="yes" xml:space="preserve">
          <source>Predicted target values for X.</source>
          <target state="translated">X的预测目标值。</target>
        </trans-unit>
        <trans-unit id="0d4a1c77352b65574731921e931152dc6d67a7e6" translate="yes" xml:space="preserve">
          <source>Predicted target values per element in X.</source>
          <target state="translated">X中每个要素的预测目标值。</target>
        </trans-unit>
        <trans-unit id="a63f32ed146dbd0a036e7a6c9007fd28cb724f17" translate="yes" xml:space="preserve">
          <source>Predicted values.</source>
          <target state="translated">预测值:</target>
        </trans-unit>
        <trans-unit id="287963e14d12632f521b827a4e86495105e087d4" translate="yes" xml:space="preserve">
          <source>Predicting Good Probabilities with Supervised Learning, A. Niculescu-Mizil &amp;amp; R. Caruana, ICML 2005</source>
          <target state="translated">使用监督学习预测良好概率，A。Niculescu-Mizil和R. Caruana，ICML，2005年</target>
        </trans-unit>
        <trans-unit id="98782c3c25b19af8f6dafd01baf554b35ff65bf8" translate="yes" xml:space="preserve">
          <source>Prediction Intervals for Gradient Boosting Regression</source>
          <target state="translated">梯度提升回归的预测区间(Prediction Intervals for Gradient Boosting Regression)</target>
        </trans-unit>
        <trans-unit id="a5caca0a7f480ab2154877c6274ee9ed2e787327" translate="yes" xml:space="preserve">
          <source>Prediction Latency</source>
          <target state="translated">预测延迟</target>
        </trans-unit>
        <trans-unit id="feb11a8226645ea5da9a48d3bfe651df9033d87c" translate="yes" xml:space="preserve">
          <source>Prediction computed with out-of-bag estimate on the training set.</source>
          <target state="translated">在训练集上用袋外估计计算的预测。</target>
        </trans-unit>
        <trans-unit id="fc1fcdf0c524a30639c066dc749abc64a6524c06" translate="yes" xml:space="preserve">
          <source>Prediction computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, &lt;code&gt;oob_prediction_&lt;/code&gt; might contain NaN.</source>
          <target state="translated">使用训练集的实际估计值计算预测。如果n_estimators小，则有可能在引导过程中从未遗漏任何数据点。在这种情况下， &lt;code&gt;oob_prediction_&lt;/code&gt; 可能包含NaN。</target>
        </trans-unit>
        <trans-unit id="a41914a2f37714142ad691edd19c5e43a6241f77" translate="yes" xml:space="preserve">
          <source>Prediction latency is measured as the elapsed time necessary to make a prediction (e.g. in micro-seconds). Latency is often viewed as a distribution and operations engineers often focus on the latency at a given percentile of this distribution (e.g. the 90 percentile).</source>
          <target state="translated">预测延迟是以进行预测所需的时间(如微秒)来衡量的。延迟时间通常被看作是一个分布,而操作工程师通常关注的是这个分布的某一百分位数的延迟时间(例如90%的百分位数)。</target>
        </trans-unit>
        <trans-unit id="e5f06aeed95b293a7ec0cbb529b2dc2cbbf9b847" translate="yes" xml:space="preserve">
          <source>Prediction throughput is defined as the number of predictions the software can deliver in a given amount of time (e.g. in predictions per second).</source>
          <target state="translated">预测吞吐量是指软件在给定的时间内能提供的预测次数(如每秒预测次数)。</target>
        </trans-unit>
        <trans-unit id="adcc2378933b72e3446a85e4fe1b367ed4a8ee49" translate="yes" xml:space="preserve">
          <source>Predictions for input data</source>
          <target state="translated">对输入数据的预测</target>
        </trans-unit>
        <trans-unit id="ab27a2587edb12bb0d1fda3f488b5135e41df062" translate="yes" xml:space="preserve">
          <source>Predictive power</source>
          <target state="translated">预测力</target>
        </trans-unit>
        <trans-unit id="c883768bdfe473a1aa19e31d78108e10463a6ea5" translate="yes" xml:space="preserve">
          <source>Preferences for each point - points with larger values of preferences are more likely to be chosen as exemplars. The number of exemplars, i.e. of clusters, is influenced by the input preferences value. If the preferences are not passed as arguments, they will be set to the median of the input similarities (resulting in a moderate number of clusters). For a smaller amount of clusters, this can be set to the minimum value of the similarities.</source>
          <target state="translated">每个点的偏好--偏好值越大的点越有可能被选为样板。示范的数量,即集群的数量,受输入偏好值的影响。如果偏好值没有作为参数传递,它们将被设置为输入相似性的中值(导致聚类数量适中)。对于数量较少的聚类,可以设置为相似度的最小值。</target>
        </trans-unit>
        <trans-unit id="d950ed84434798aa79b3f6033bd1676939cb0d20" translate="yes" xml:space="preserve">
          <source>Preferences for each point - points with larger values of preferences are more likely to be chosen as exemplars. The number of exemplars, ie of clusters, is influenced by the input preferences value. If the preferences are not passed as arguments, they will be set to the median of the input similarities.</source>
          <target state="translated">每个点的偏好--偏好值越大的点越有可能被选为样板。模范的数量,即集群的数量,受输入偏好值的影响。如果偏好值没有作为参数传递,它们将被设置为输入相似性的中值。</target>
        </trans-unit>
        <trans-unit id="14b1d1212d8840ca9f7efb348e45b326762c69cc" translate="yes" xml:space="preserve">
          <source>Prefetch the tasks for the next batch and dispatch them.</source>
          <target state="translated">预取下一批任务,并进行调度。</target>
        </trans-unit>
        <trans-unit id="24c93aa4ab33374bb8e7198b2daeff3e433c0fbc" translate="yes" xml:space="preserve">
          <source>Preprocessing</source>
          <target state="translated">Preprocessing</target>
        </trans-unit>
        <trans-unit id="cc3693c3738c6f3fcbe2edd801580161673e54a4" translate="yes" xml:space="preserve">
          <source>Preprocessing programs made available by NIST were used to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions.</source>
          <target state="translated">NIST提供的预处理程序被用来从预打印的表格中提取手写数字的标准化位图。在总共43人中,30人参与了训练集,13人参与了测试集。32x32的位图被分成4x4的非重叠块,并计算每个块中的像素数。这就产生了一个8x8的输入矩阵,其中每个元素是0...16范围内的整数。这就降低了维度,并且对小的变形有不变性。</target>
        </trans-unit>
        <trans-unit id="b0a35de16d2edfd24f40881bf819fae5af7097e5" translate="yes" xml:space="preserve">
          <source>Preset for the class_weight fit parameter.</source>
          <target state="translated">预设class_weight配合参数。</target>
        </trans-unit>
        <trans-unit id="4b557eedfee718637d8501877f5a64be009b5a8b" translate="yes" xml:space="preserve">
          <source>Principal Component Analysis (PCA) applied to this data identifies the combination of attributes (principal components, or directions in the feature space) that account for the most variance in the data. Here we plot the different samples on the 2 first principal components.</source>
          <target state="translated">应用于该数据的主成分分析(PCA)可以识别出占数据方差最大的属性组合(主成分,或特征空间的方向)。这里我们绘制了不同样本在2个第一主成分上的情况。</target>
        </trans-unit>
        <trans-unit id="a6b94c1fa1c0329dae275075618af3ec11723e1c" translate="yes" xml:space="preserve">
          <source>Principal Component Analysis applied to the Iris dataset.</source>
          <target state="translated">主成分分析应用于Iris数据集。</target>
        </trans-unit>
        <trans-unit id="d6b546c117ff3cb1540fffde179b8cad5d53ba5e" translate="yes" xml:space="preserve">
          <source>Principal axes in feature space, representing the directions of maximum variance in the data. The components are sorted by &lt;code&gt;explained_variance_&lt;/code&gt;.</source>
          <target state="translated">特征空间中的主轴，表示数据中最大方差的方向。这些组件通过分类 &lt;code&gt;explained_variance_&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="30fe9e3940e590621d7f0bb9b0d0469c84793795" translate="yes" xml:space="preserve">
          <source>Principal component analysis (&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;) has the disadvantage that the components extracted by this method have exclusively dense expressions, i.e. they have non-zero coefficients when expressed as linear combinations of the original variables. This can make interpretation difficult. In many cases, the real underlying components can be more naturally imagined as sparse vectors; for example in face recognition, components might naturally map to parts of faces.</source>
          <target state="translated">主成分分析（&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;）的缺点是，用这种方法提取的成分仅具有密集的表达式，即当表达为原始变量的线性组合时，它们具有非零系数。这会使解释变得困难。在许多情况下，真实的基础成分可以更自然地想象为稀疏向量。例如，在人脸识别中，组件自然可以映射到人脸的各个部分。</target>
        </trans-unit>
        <trans-unit id="3c45b66bc9daa13e7d9c72ebcd199759fb365d43" translate="yes" xml:space="preserve">
          <source>Principal component analysis (PCA)</source>
          <target state="translated">主成分分析(PCA)</target>
        </trans-unit>
        <trans-unit id="27682a0d321ed3dea37d28f220c82e91ea47e974" translate="yes" xml:space="preserve">
          <source>Principal component analysis is also a latent linear variable model which however assumes equal noise variance for each feature. This extra assumption makes probabilistic PCA faster as it can be computed in closed form.</source>
          <target state="translated">主成分分析也是一种潜伏的线性变量模型,但是它假设每个特征的噪声方差相等。这种额外的假设使得概率PCA速度更快,因为它可以以封闭形式计算。</target>
        </trans-unit>
        <trans-unit id="1f6abb25251799b9e41b673896b30d2e7743cd31" translate="yes" xml:space="preserve">
          <source>Principal component analysis: PCA</source>
          <target state="translated">主成分分析。主成分分析:PCA</target>
        </trans-unit>
        <trans-unit id="1b8437a3fa4a1275d1ba1d12ed6963a22fc037c1" translate="yes" xml:space="preserve">
          <source>Principal components analysis (PCA)</source>
          <target state="translated">主成分分析(PCA)</target>
        </trans-unit>
        <trans-unit id="5a1174d6931171ffd7d3b357a535b3a3d607a9de" translate="yes" xml:space="preserve">
          <source>Print useful debugging information</source>
          <target state="translated">打印有用的调试信息</target>
        </trans-unit>
        <trans-unit id="c1c5200355e6830b00b9319b71d0145e5b700f71" translate="yes" xml:space="preserve">
          <source>Prior of document topic distribution &lt;code&gt;theta&lt;/code&gt;. If the value is None, defaults to &lt;code&gt;1 / n_components&lt;/code&gt;. In the literature, this is called &lt;code&gt;alpha&lt;/code&gt;.</source>
          <target state="translated">现有文献主题分布的 &lt;code&gt;theta&lt;/code&gt; 。如果值为None，则默认为 &lt;code&gt;1 / n_components&lt;/code&gt; 。在文献中，这称为 &lt;code&gt;alpha&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="30bbeaea3ad5ae5cca83fd5e61da629080788c50" translate="yes" xml:space="preserve">
          <source>Prior of topic word distribution &lt;code&gt;beta&lt;/code&gt;. If the value is None, defaults to &lt;code&gt;1 / n_components&lt;/code&gt;. In the literature, this is called &lt;code&gt;beta&lt;/code&gt;.</source>
          <target state="translated">主题词分布 &lt;code&gt;beta&lt;/code&gt; 。如果值为None，则默认为 &lt;code&gt;1 / n_components&lt;/code&gt; 。在文献中，这称为 &lt;code&gt;beta&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="bdfe015d1be4dfdea1f6788227d664c259407953" translate="yes" xml:space="preserve">
          <source>Prior probabilities of the classes. If specified the priors are not adjusted according to the data.</source>
          <target state="translated">类的前概率。如果指定,则不根据数据调整前值。</target>
        </trans-unit>
        <trans-unit id="8741a7d95e10089a15bca30c8cec0364251c1317" translate="yes" xml:space="preserve">
          <source>Prior probabilities of the classes. Not used.</source>
          <target state="translated">各类的事先概率。未使用。</target>
        </trans-unit>
        <trans-unit id="58369bd54ea62c9c483ab40eb23ad2254e33831b" translate="yes" xml:space="preserve">
          <source>Priors on classes</source>
          <target state="translated">班级的优先权</target>
        </trans-unit>
        <trans-unit id="371a276deaa5931894d10a44b79e47fcc68aec68" translate="yes" xml:space="preserve">
          <source>Proanthocyanins</source>
          <target state="translated">Proanthocyanins</target>
        </trans-unit>
        <trans-unit id="dc39071ac278ca69c49e2bb68c5d787fa71da3ba" translate="yes" xml:space="preserve">
          <source>Proanthocyanins:</source>
          <target state="translated">Proanthocyanins:</target>
        </trans-unit>
        <trans-unit id="436d6fac1ff357492b6144d87ad40d402972e325" translate="yes" xml:space="preserve">
          <source>Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods, J. Platt, (1999)</source>
          <target state="translated">支持向量机的概率输出和与正则化似然方法的比较,J.Platt,(1999年)</target>
        </trans-unit>
        <trans-unit id="65884b6f0c144a05ea5bb72b4a5f34604f98727e" translate="yes" xml:space="preserve">
          <source>Probabilistic PCA and Factor Analysis are probabilistic models. The consequence is that the likelihood of new data can be used for model selection and covariance estimation. Here we compare PCA and FA with cross-validation on low rank data corrupted with homoscedastic noise (noise variance is the same for each feature) or heteroscedastic noise (noise variance is the different for each feature). In a second step we compare the model likelihood to the likelihoods obtained from shrinkage covariance estimators.</source>
          <target state="translated">概率PCA和因子分析是概率模型。其结果是,新数据的可能性可以用于模型选择和协方差估计。在这里,我们比较了PCA和FA与交叉验证的低等级数据损坏的同质噪声(噪声方差是相同的每个特征)或异质噪声(噪声方差是不同的每个特征)。第二步,我们将模型似然与收缩协方差估计器得到的似然进行比较。</target>
        </trans-unit>
        <trans-unit id="a886f2d46c4d856f2d8ffc5bd193a83a0b30c5a7" translate="yes" xml:space="preserve">
          <source>Probabilistic predictions with Gaussian process classification (GPC)</source>
          <target state="translated">用高斯过程分类(GPC)进行概率预测。</target>
        </trans-unit>
        <trans-unit id="b8c5ce2ac34fb5da2d8b838f429e8648259a8b7d" translate="yes" xml:space="preserve">
          <source>Probabilities of the positive class.</source>
          <target state="translated">正类的概率。</target>
        </trans-unit>
        <trans-unit id="7a72cad0169f2057b1b8004ee1b90363ba0148de" translate="yes" xml:space="preserve">
          <source>Probability Calibration curves</source>
          <target state="translated">概率校准曲线</target>
        </trans-unit>
        <trans-unit id="7900c400e7cdc976660ffa4f0dee105d53367a1d" translate="yes" xml:space="preserve">
          <source>Probability Calibration for 3-class classification</source>
          <target state="translated">三类分类的概率校准</target>
        </trans-unit>
        <trans-unit id="f991b7ba9edae7642f119ae6ef707078bd3066c3" translate="yes" xml:space="preserve">
          <source>Probability calibration of classifiers</source>
          <target state="translated">分类器的概率校准</target>
        </trans-unit>
        <trans-unit id="d2584ee2a9c243a3c860610b53b4c4f8f0422b7b" translate="yes" xml:space="preserve">
          <source>Probability calibration with isotonic regression or sigmoid.</source>
          <target state="translated">用等差回归或sigmoid进行概率校准。</target>
        </trans-unit>
        <trans-unit id="7f0eccc6df8627c4942515691dfa00c7351059c0" translate="yes" xml:space="preserve">
          <source>Probability estimates.</source>
          <target state="translated">概率估计:</target>
        </trans-unit>
        <trans-unit id="d0d52fb38133a888fd3aa915d919f9ed6dbe0e0a" translate="yes" xml:space="preserve">
          <source>Probability estimates. Returns prediction probabilities for each class of each output.</source>
          <target state="translated">概率估计。返回每个输出类别的预测概率。</target>
        </trans-unit>
        <trans-unit id="0be5c62048ae898d969e355c844df7dab0872138" translate="yes" xml:space="preserve">
          <source>Probability of each class for each output.</source>
          <target state="translated">每一类输出的概率。</target>
        </trans-unit>
        <trans-unit id="a3469242fe22b27dd5f462fbaa08f5294924374d" translate="yes" xml:space="preserve">
          <source>Proceedings of the National Academy of Sciences of the United States of America, 17, 684-688.</source>
          <target state="translated">美利坚合众国国家科学院院刊,17,684-688。</target>
        </trans-unit>
        <trans-unit id="86eb67953eb5361e43195eeccf42c1fb9d6add56" translate="yes" xml:space="preserve">
          <source>Producing multilabel data as a list of sets of labels may be more intuitive. The &lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt; transformer can be used to convert between a collection of collections of labels and the indicator format.</source>
          <target state="translated">将多标签数据生成为标签集列表可能更直观。该&lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; &lt;/a&gt;变压器可用于标签的集合的集合和指标格式之间的转换。</target>
        </trans-unit>
        <trans-unit id="c38ce5d3aa68fdc5564263b0a75294394128f498" translate="yes" xml:space="preserve">
          <source>Product-kernel k1 * k2 of two kernels k1 and k2.</source>
          <target state="translated">两个核k1和k2的积核k1*k2。</target>
        </trans-unit>
        <trans-unit id="c68fd05a1da7c4a69a9f93ddd88df0d8f044754a" translate="yes" xml:space="preserve">
          <source>Project data to maximize class separation.</source>
          <target state="translated">项目数据,最大限度地实现类目分离。</target>
        </trans-unit>
        <trans-unit id="0deb0c8bb98c410f297f471bfa590b75799342d3" translate="yes" xml:space="preserve">
          <source>Project the data by using matrix product with the random matrix</source>
          <target state="translated">用随机矩阵的矩阵积来推算数据。</target>
        </trans-unit>
        <trans-unit id="3cafaf1856c5864caddd32d157eb3c94637dffac" translate="yes" xml:space="preserve">
          <source>Project the sample on the first eigenvectors of the graph Laplacian.</source>
          <target state="translated">将样本投射到图形拉普拉斯的第一特征向量上。</target>
        </trans-unit>
        <trans-unit id="eeba6a10d868ab69fe1fe32234efb9f05e44d5f7" translate="yes" xml:space="preserve">
          <source>Projected array.</source>
          <target state="translated">投射阵列。</target>
        </trans-unit>
        <trans-unit id="607a04b14a3061b3ee01cf35bf1821ab09c2621b" translate="yes" xml:space="preserve">
          <source>Projection of the fitted data on the kernel principal components. Only available when &lt;code&gt;fit_inverse_transform&lt;/code&gt; is True.</source>
          <target state="translated">拟合数据在内核主成分上的投影。仅在 &lt;code&gt;fit_inverse_transform&lt;/code&gt; 为True 时可用。</target>
        </trans-unit>
        <trans-unit id="5809589bdde4dffc3b2ba5d27cf1889c0519e160" translate="yes" xml:space="preserve">
          <source>Proline</source>
          <target state="translated">Proline</target>
        </trans-unit>
        <trans-unit id="7277492923bbc0874b58459caf363fcc7aa732fe" translate="yes" xml:space="preserve">
          <source>Proline:</source>
          <target state="translated">Proline:</target>
        </trans-unit>
        <trans-unit id="94bda99c1a5b7a6f489592ddeacfcc207544b838" translate="yes" xml:space="preserve">
          <source>Proper choice of &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; is critical to the SVM&amp;rsquo;s performance. One is advised to use &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; spaced exponentially far apart to choose good values.</source>
          <target state="translated">正确选择 &lt;code&gt;C&lt;/code&gt; 和 &lt;code&gt;gamma&lt;/code&gt; 对SVM的性能至关重要。建议使用&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; ,&lt;/a&gt;并将 &lt;code&gt;C&lt;/code&gt; 和 &lt;code&gt;gamma&lt;/code&gt; 指数间隔分开以选择合适的值。</target>
        </trans-unit>
        <trans-unit id="e8c0f82584351898447c0af1ff6fac83767fe6e2" translate="yes" xml:space="preserve">
          <source>Provide a custom 2D slice (height, width) to extract the &amp;lsquo;interesting&amp;rsquo; part of the jpeg files and avoid use statistical correlation from the background</source>
          <target state="translated">提供自定义2D切片（高度，宽度）以提取jpeg文件的&amp;ldquo;有趣&amp;rdquo;部分，并避免使用背景的统计相关性</target>
        </trans-unit>
        <trans-unit id="401552ccdc1a2b894fefbad77ce746fa94f1502b" translate="yes" xml:space="preserve">
          <source>Provides randomized train/test indices to split data according to a third-party provided group. This group information can be used to encode arbitrary domain specific stratifications of the samples as integers.</source>
          <target state="translated">提供随机化的训练/测试指数,根据第三方提供的组别来分割数据。该组信息可用于将样本的任意特定领域分层编码为整数。</target>
        </trans-unit>
        <trans-unit id="b95f7cbbc68460952b8007ef379d30753e697620" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data according to a third-party provided group. This group information can be used to encode arbitrary domain specific stratifications of the samples as integers.</source>
          <target state="translated">提供训练/测试指数,根据第三方提供的组别分割数据。该组信息可用于将样本的任意特定领域分层编码为整数。</target>
        </trans-unit>
        <trans-unit id="6798759d21441243ae32b56e342e6cf117102678" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets.</source>
          <target state="translated">提供训练/测试指数,以分割训练/测试集的数据。</target>
        </trans-unit>
        <trans-unit id="80c518815627489551da4e7aede124327387378b" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets. Each sample is used once as a test set (singleton) while the remaining samples form the training set.</source>
          <target state="translated">提供训练/测试指数,将数据分割成训练/测试集。每个样本作为测试集(单体)使用一次,其余的样本构成训练集。</target>
        </trans-unit>
        <trans-unit id="d92edad2bb7b04c8f656b2d3e1cacd4550e6c9b7" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default).</source>
          <target state="translated">提供训练/测试指数,以分割训练/测试集的数据。将数据集分割成k个连续的折线(默认情况下不进行洗牌)。</target>
        </trans-unit>
        <trans-unit id="c17c74386e1c6a7aabe03b07d13a8c489665dcde" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data in train/test sets. This results in testing on all distinct samples of size p, while the remaining n - p samples form the training set in each iteration.</source>
          <target state="translated">提供训练/测试指数,以在训练/测试集中分割数据。这将导致在所有大小为p的不同样本上进行测试,而剩余的n-p样本在每次迭代中形成训练集。</target>
        </trans-unit>
        <trans-unit id="0b345715ee21f67aa1ac76dcd84f4dd63b2400ec" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split data into train/test sets using a predefined scheme specified by the user with the &lt;code&gt;test_fold&lt;/code&gt; parameter.</source>
          <target state="translated">提供训练/测试索引，以使用用户通过 &lt;code&gt;test_fold&lt;/code&gt; 参数指定的预定义方案将数据分为训练/测试集。</target>
        </trans-unit>
        <trans-unit id="ee8342073c20f61dda821a037809875c94eefda5" translate="yes" xml:space="preserve">
          <source>Provides train/test indices to split time series data samples that are observed at fixed time intervals, in train/test sets. In each split, test indices must be higher than before, and thus shuffling in cross validator is inappropriate.</source>
          <target state="translated">提供了训练/测试指数,以分割在固定时间间隔观察的时间序列数据样本,在训练/测试集。在每次拆分时,测试指数必须比之前高,因此在交叉验证器中的洗牌是不合适的。</target>
        </trans-unit>
        <trans-unit id="945e7a8384d2da4b225924cb75d10785d215f6cf" translate="yes" xml:space="preserve">
          <source>Pseudo number generator state used for random sampling to use if &lt;code&gt;max_patches&lt;/code&gt; is not None. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">如果 &lt;code&gt;max_patches&lt;/code&gt; 不为None，则用于随机采样的伪数生成器状态。如果为int，则random_state是随机数生成器使用的种子；否则为false。如果是RandomState实例，则random_state是随机数生成器；如果没有，随机数生成器所使用的RandomState实例 &lt;code&gt;np.random&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="803474f379c178cad6e69fb90dfcf68b796a35e4" translate="yes" xml:space="preserve">
          <source>Pseudo random number generator state used for random uniform sampling from lists of possible values instead of scipy.stats distributions. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">伪随机数生成器状态，用于从可能值列表而不是scipy.stats分布进行随机统一采样。如果为int，则random_state是随机数生成器使用的种子；否则为false。如果是RandomState实例，则random_state是随机数生成器；如果没有，随机数生成器所使用的RandomState实例 &lt;code&gt;np.random&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="32576f4fedc07f63020353af6a8aac66c4452c4c" translate="yes" xml:space="preserve">
          <source>Purple</source>
          <target state="translated">Purple</target>
        </trans-unit>
        <trans-unit id="c148aded3d47eba6bad059e92b2038d207b0a750" translate="yes" xml:space="preserve">
          <source>Putting it all together</source>
          <target state="translated">把它整合在一起</target>
        </trans-unit>
        <trans-unit id="7bde8f50695aefe070915f77203ce68cdd0ec96c" translate="yes" xml:space="preserve">
          <source>PyFuncDistance</source>
          <target state="translated">PyFuncDistance</target>
        </trans-unit>
        <trans-unit id="f784952b2caa6ead69a91bdde883011035968631" translate="yes" xml:space="preserve">
          <source>Q&amp;amp;A communities with Machine Learning practitioners</source>
          <target state="translated">机器学习从业者问答社区</target>
        </trans-unit>
        <trans-unit id="448c1c19b8a6bb6b2012b55ce0301b3d1329f717" translate="yes" xml:space="preserve">
          <source>Quadratic Discriminant Analysis</source>
          <target state="translated">二次元判别分析</target>
        </trans-unit>
        <trans-unit id="2b0963d1d3fb9914f2ed8fd196a39ab8fff37584" translate="yes" xml:space="preserve">
          <source>Quantile (&lt;code&gt;'quantile'&lt;/code&gt;): A loss function for quantile regression. Use &lt;code&gt;0 &amp;lt; alpha &amp;lt; 1&lt;/code&gt; to specify the quantile. This loss function can be used to create prediction intervals (see &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_quantile#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py&quot;&gt;Prediction Intervals for Gradient Boosting Regression&lt;/a&gt;).</source>
          <target state="translated">分位数（ &lt;code&gt;'quantile'&lt;/code&gt; ）：分位数回归的损失函数。使用 &lt;code&gt;0 &amp;lt; alpha &amp;lt; 1&lt;/code&gt; 指定分位数。此损失函数可用于创建预测间隔（请参阅&lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_quantile#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py&quot;&gt;&amp;ldquo;梯度提升回归的预测间隔&amp;rdquo;&lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="5a4c3292979c373b2215d627b1f0e779a581f51d" translate="yes" xml:space="preserve">
          <source>QuantileTransformer (Gaussian output)</source>
          <target state="translated">量子转换器(高斯输出)</target>
        </trans-unit>
        <trans-unit id="50891a888ce3bdb733921e829099a1dfa838c084" translate="yes" xml:space="preserve">
          <source>QuantileTransformer (uniform output)</source>
          <target state="translated">量子化转换器(统一输出</target>
        </trans-unit>
        <trans-unit id="da4a84c34a00e3e1cb33c39f3ec53c51c9f24633" translate="yes" xml:space="preserve">
          <source>Quantiles of references.</source>
          <target state="translated">参考文献的数量级。</target>
        </trans-unit>
        <trans-unit id="3048da3a0073f2ccdb93631cd0e0196ff4c577ae" translate="yes" xml:space="preserve">
          <source>Query for k-nearest neighbors</source>
          <target state="translated">查询k-最近的邻居</target>
        </trans-unit>
        <trans-unit id="084cb8b1b8700d8f5e04c594627648c98a813511" translate="yes" xml:space="preserve">
          <source>Query for neighbors within a given radius</source>
          <target state="translated">查询给定半径内的邻居。</target>
        </trans-unit>
        <trans-unit id="04d13e86aec7343500316f89a39a673fcfb27484" translate="yes" xml:space="preserve">
          <source>Query points where the GP is evaluated</source>
          <target state="translated">评估GP的查询点</target>
        </trans-unit>
        <trans-unit id="3aa6f6433021c4ee60eb31aa3da49dd739b377c2" translate="yes" xml:space="preserve">
          <source>Query points where the GP samples are evaluated</source>
          <target state="translated">评估GP样本的查询点</target>
        </trans-unit>
        <trans-unit id="455083cac2ae96eabe3895762b6080aa09e6afa4" translate="yes" xml:space="preserve">
          <source>Quick Start</source>
          <target state="translated">快速入门</target>
        </trans-unit>
        <trans-unit id="a30289e02d2b2cc535be5bc56bf89de1f97250a5" translate="yes" xml:space="preserve">
          <source>Quick utility that wraps input validation and &lt;code&gt;next(ShuffleSplit().split(X, y))&lt;/code&gt; and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.</source>
          <target state="translated">快速实用程序，用于包装输入验证以及 &lt;code&gt;next(ShuffleSplit().split(X, y))&lt;/code&gt; 和应用程序，以将数据输入到单个调用中，以便在oneliner中拆分（以及可选地对子采样）数据。</target>
        </trans-unit>
        <trans-unit id="53fd6e58cc2ae2f146db69f1fd015c25bb18c639" translate="yes" xml:space="preserve">
          <source>Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</source>
          <target state="translated">Quinlan,R。(1993).Combining Instance-Based and Model-Based Learning.In Proceedings on the Tenth International Conference of Machine Learning,236-243,University of Massachusetts,Amherst.Morgan Kaufmann.</target>
        </trans-unit>
        <trans-unit id="3c95cd07e406f573d2cfd2507858b18867a12835" translate="yes" xml:space="preserve">
          <source>R. Baeza-Yates and B. Ribeiro-Neto (2011). Modern Information Retrieval. Addison Wesley, pp. 327-328.</source>
          <target state="translated">R.R.Baeza-Yates和B.Ribeiro-Neto(2011年)。Modern Information Retrieval.Addison Wesley,第327-328页。</target>
        </trans-unit>
        <trans-unit id="df834b32ec211735af556a020ed4c6c4292bf968" translate="yes" xml:space="preserve">
          <source>R. Bharat Rao, G. Fung, R. Rosales, &lt;a href=&quot;http://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf&quot;&gt;On the Dangers of Cross-Validation. An Experimental Evaluation&lt;/a&gt;, SIAM 2008;</source>
          <target state="translated">R. Bharat Rao，G。Fung，&lt;a href=&quot;http://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf&quot;&gt;R。Rosales，《交叉验证的危险》。实验评估&lt;/a&gt;，SIAM 2008；</target>
        </trans-unit>
        <trans-unit id="4a52a977177c4f8d61f3e67f49be99e2f11395f3" translate="yes" xml:space="preserve">
          <source>R. Kohavi, &lt;a href=&quot;http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf&quot;&gt;A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection&lt;/a&gt;, Intl. Jnt. Conf. AI</source>
          <target state="translated">R. Kohavi，&lt;a href=&quot;http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf&quot;&gt;《交叉验证和Bootstrap的准确性估计和模型选择研究》&lt;/a&gt;，国际 Jnt。Conf。人工智能</target>
        </trans-unit>
        <trans-unit id="f5beb165dbcf077fd6c3c894825f204dec27c8ce" translate="yes" xml:space="preserve">
          <source>R. Salakhutdinov, Lecture notes on Statistical Machine Learning, &lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&lt;/a&gt; Their beta is our &lt;code&gt;self.alpha_&lt;/code&gt; Their alpha is our &lt;code&gt;self.lambda_&lt;/code&gt;</source>
          <target state="translated">R. Salakhutdinov，统计机器学习讲义，&lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&lt;/a&gt;他们的测试是我们 &lt;code&gt;self.alpha_&lt;/code&gt; 他们的阿尔法是我们 &lt;code&gt;self.lambda_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="06a2c6e6810e408b785e7ba0833fdf5208de2658" translate="yes" xml:space="preserve">
          <source>R. Salakhutdinov, Lecture notes on Statistical Machine Learning, &lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&lt;/a&gt; Their beta is our &lt;code&gt;self.alpha_&lt;/code&gt; Their alpha is our &lt;code&gt;self.lambda_&lt;/code&gt; ARD is a little different than the slide: only dimensions/features for which &lt;code&gt;self.lambda_ &amp;lt; self.threshold_lambda&lt;/code&gt; are kept and the rest are discarded.</source>
          <target state="translated">R. Salakhutdinov，统计机器学习讲义，&lt;a href=&quot;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&quot;&gt;http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15&lt;/a&gt;他们的测试是我们 &lt;code&gt;self.alpha_&lt;/code&gt; 他们的阿尔法是我们 &lt;code&gt;self.lambda_&lt;/code&gt; ARD与幻灯片稍有不同：仅保留 &lt;code&gt;self.lambda_ &amp;lt; self.threshold_lambda&lt;/code&gt; 尺寸/特征，其余的均被丢弃。</target>
        </trans-unit>
        <trans-unit id="35207f47d4b817edd2ee6adcf1187c7a288d720f" translate="yes" xml:space="preserve">
          <source>R.A. Fisher</source>
          <target state="translated">R.A.Fisher</target>
        </trans-unit>
        <trans-unit id="c2cddd6bced899ad676535e0ceef48ff2d428d74" translate="yes" xml:space="preserve">
          <source>RAD index of accessibility to radial highways</source>
          <target state="translated">RAD 径向公路交通便利指数</target>
        </trans-unit>
        <trans-unit id="8eff9a296f9566c8db7b6b5b5fd0f247ff670023" translate="yes" xml:space="preserve">
          <source>RANSAC (RANdom SAmple Consensus) algorithm.</source>
          <target state="translated">RANSAC(RANdom SAmple Consensus)算法。</target>
        </trans-unit>
        <trans-unit id="295f973b9a9300cc4103fcf54629f3b800f88e4f" translate="yes" xml:space="preserve">
          <source>RANSAC (RANdom SAmple Consensus) fits a model from random subsets of inliers from the complete data set.</source>
          <target state="translated">RANSAC(RANdom SAmple Consensus)从完整数据集的离群值的随机子集拟合模型。</target>
        </trans-unit>
        <trans-unit id="4cf25210dfc0ed0440695332f6a59a107387063c" translate="yes" xml:space="preserve">
          <source>RANSAC is a non-deterministic algorithm producing only a reasonable result with a certain probability, which is dependent on the number of iterations (see &lt;code&gt;max_trials&lt;/code&gt; parameter). It is typically used for linear and non-linear regression problems and is especially popular in the fields of photogrammetric computer vision.</source>
          <target state="translated">RANSAC是一种不确定性算法，仅以一定概率生成合理结果，该结果取决于迭代次数（请参见 &lt;code&gt;max_trials&lt;/code&gt; 参数）。它通常用于线性和非线性回归问题，在摄影测量计算机视觉领域特别受欢迎。</target>
        </trans-unit>
        <trans-unit id="661ac344672202ee8ecff33a0aca47b5e992477c" translate="yes" xml:space="preserve">
          <source>RANSAC is an iterative algorithm for the robust estimation of parameters from a subset of inliers from the complete data set. More information can be found in the general documentation of linear models.</source>
          <target state="translated">RANSAC是一种迭代算法,用于从完整数据集的离群者子集中稳健估计参数。更多信息可以在线性模型的一般文档中找到。</target>
        </trans-unit>
        <trans-unit id="5d2efa163922c4ec9e798ae0634c77ba2e679034" translate="yes" xml:space="preserve">
          <source>RANSAC is good for strong outliers in the y direction</source>
          <target state="translated">RANSAC对y方向的强离群值有很好的作用。</target>
        </trans-unit>
        <trans-unit id="727c2ad1e5500736136b6da9e8482929b66a5466" translate="yes" xml:space="preserve">
          <source>RANSAC iteration stops if at least one outlier-free set of the training data is sampled in RANSAC. This requires to generate at least N samples (iterations):</source>
          <target state="translated">如果在RANSAC中至少有一个训练数据的无离群值集被采样,则RANSAC迭代停止。这需要至少生成N个样本(迭代)。</target>
        </trans-unit>
        <trans-unit id="a5b4d61d1cab95dc9e6144de1c3f9e94fd26ef69" translate="yes" xml:space="preserve">
          <source>RBF SVM parameters</source>
          <target state="translated">RBF SVM参数</target>
        </trans-unit>
        <trans-unit id="b8891243ca9d81f286f0231789762195095e1f07" translate="yes" xml:space="preserve">
          <source>RM average number of rooms per dwelling</source>
          <target state="translated">RM 每个住宅的平均房间数</target>
        </trans-unit>
        <trans-unit id="98a077cbb4113833d5208bfbafc39182a47953a4" translate="yes" xml:space="preserve">
          <source>ROC curves are typically used in binary classification to study the output of a classifier. In order to extend ROC curve and ROC area to multi-class or multi-label classification, it is necessary to binarize the output. One ROC curve can be drawn per label, but one can also draw a ROC curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).</source>
          <target state="translated">ROC曲线通常用于二元分类中研究分类器的输出。为了将ROC曲线和ROC面积扩展到多类或多标签分类中,有必要将输出进行二值化。每个标签可以绘制一条ROC曲线,但也可以将标签指标矩阵的每个元素视为二进制预测(微平均)来绘制ROC曲线。</target>
        </trans-unit>
        <trans-unit id="388c7e4d8a2582b488580ddabb4d2fdc26d0d1ba" translate="yes" xml:space="preserve">
          <source>ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the &amp;ldquo;ideal&amp;rdquo; point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.</source>
          <target state="translated">ROC曲线通常在Y轴上具有真正率，在X轴上具有假正率。这意味着该图的左上角是&amp;ldquo;理想&amp;rdquo;点-误报率为零，而正误报率为1。这不是很现实，但这确实意味着曲线下的较大区域（AUC）通常更好。</target>
        </trans-unit>
        <trans-unit id="69dad40e2617c9d14cd69fd75838d06f4d48f71b" translate="yes" xml:space="preserve">
          <source>R^2 (coefficient of determination) regression score function.</source>
          <target state="translated">R^2(决定系数)回归得分函数。</target>
        </trans-unit>
        <trans-unit id="b808463e306b97b5a3ff3b44e6d61af7bafdc346" translate="yes" xml:space="preserve">
          <source>R^2 is calculated by weighting all the targets equally using &lt;code&gt;multioutput=&amp;rsquo;uniform_average&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">R ^ 2是通过使用 &lt;code&gt;multioutput=&amp;rsquo;uniform_average&amp;rsquo;&lt;/code&gt; 所有目标平均加权来计算的。</target>
        </trans-unit>
        <trans-unit id="51faef534dffb60f7f795741b3c905f12ad6fcd4" translate="yes" xml:space="preserve">
          <source>R^2 of self.predict(X) wrt. y.</source>
          <target state="translated">self.predict(X)wrt.y的R^2。</target>
        </trans-unit>
        <trans-unit id="67a54398f816039662fed018be4b060a58e05be0" translate="yes" xml:space="preserve">
          <source>Radial-basis function kernel (aka squared-exponential kernel).</source>
          <target state="translated">径向基函数核(又名平方指数核)。</target>
        </trans-unit>
        <trans-unit id="b1c9a7baa5630e2f9f25e6f54a8403ae874316cf" translate="yes" xml:space="preserve">
          <source>Radius from the data point to its neighbors. This is the parameter space to use by default for the &lt;a href=&quot;#sklearn.neighbors.LSHForest.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">从数据点到其相邻点的半径。这是默认情况下用于&lt;a href=&quot;#sklearn.neighbors.LSHForest.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;查询的参数空间。</target>
        </trans-unit>
        <trans-unit id="52546dfd6d7c7fb64ada7c2055d0a73c0acf8a37" translate="yes" xml:space="preserve">
          <source>Radius of neighborhoods.</source>
          <target state="translated">邻居的半径。</target>
        </trans-unit>
        <trans-unit id="18a73d913fa1abfc301eb3a68cafe4343426b8e2" translate="yes" xml:space="preserve">
          <source>Radius of neighborhoods. (default is the value passed to the constructor).</source>
          <target state="translated">邻居的半径。(默认是传递给构造函数的值)。</target>
        </trans-unit>
        <trans-unit id="d0dee7bedc06eaed94a632203a4c4fa7194bffee" translate="yes" xml:space="preserve">
          <source>Raise DataConversionWarning if the dtype of the input data structure does not match the requested dtype, causing a memory copy.</source>
          <target state="translated">如果输入数据结构的dtype与请求的dtype不匹配,会引起DataConversionWarning,导致内存拷贝。</target>
        </trans-unit>
        <trans-unit id="fe6245a65da1996031b65e42c6ba6186170ca87f" translate="yes" xml:space="preserve">
          <source>Raises ValueError if the value is not present.</source>
          <target state="translated">如果该值不存在,则引发ValueError。</target>
        </trans-unit>
        <trans-unit id="e0eb5268f437200e3ca42ec2d178bdfb80e8e252" translate="yes" xml:space="preserve">
          <source>Raises:</source>
          <target state="translated">Raises:</target>
        </trans-unit>
        <trans-unit id="d16a67e334dfd48a0a32b29b147c93c066c816a2" translate="yes" xml:space="preserve">
          <source>Rand index adjusted for chance.</source>
          <target state="translated">兰德指数经过机会调整。</target>
        </trans-unit>
        <trans-unit id="eef943cf5777ab68b59f488d7a530508b73f81f0" translate="yes" xml:space="preserve">
          <source>Random Projection transformers</source>
          <target state="translated">随机投影变压器</target>
        </trans-unit>
        <trans-unit id="7ff48c336307e3c2ce6f2f979b7933b4de524c7a" translate="yes" xml:space="preserve">
          <source>Random Projections are a simple and computationally efficient way to reduce the dimensionality of the data by trading a controlled amount of accuracy (as additional variance) for faster processing times and smaller model sizes.</source>
          <target state="translated">随机投影是一种简单的、计算效率高的方法,通过控制精度(作为额外的方差)来减少数据的维度,以加快处理时间和缩小模型大小。</target>
        </trans-unit>
        <trans-unit id="a3f73f31693ddbad455b46a8d17e5abb90516927" translate="yes" xml:space="preserve">
          <source>Random matrix used for the projection.</source>
          <target state="translated">用于投影的随机矩阵。</target>
        </trans-unit>
        <trans-unit id="08cddbad297e64d14193f5b5d56ff553c1ead4e1" translate="yes" xml:space="preserve">
          <source>Random partitioning produces noticeable shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.</source>
          <target state="translated">随机分割会产生明显的较短路径的异常。因此,当一片随机树林对特定样本集体产生较短的路径长度时,它们极有可能是异常点。</target>
        </trans-unit>
        <trans-unit id="cdc045e1f132e01fd79e2d9fde788bc8349e0d53" translate="yes" xml:space="preserve">
          <source>Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.</source>
          <target state="translated">随机分割会产生明显较短的异常点路径。因此,当一片随机树林对特定样本集体产生较短的路径长度时,它们极有可能是异常。</target>
        </trans-unit>
        <trans-unit id="e902a98b1d56eb80837cfffbe014c142a3c23724" translate="yes" xml:space="preserve">
          <source>Random permutation cross-validator</source>
          <target state="translated">随机排列交叉验证器</target>
        </trans-unit>
        <trans-unit id="835fe40af3cd4f15aecec9da1e1cbde64b6f2679" translate="yes" xml:space="preserve">
          <source>Random state to be used to generate random state for each repetition.</source>
          <target state="translated">随机状态用于为每个重复生成随机状态。</target>
        </trans-unit>
        <trans-unit id="e77fd902e1e7bbe038e94aceba57278c27f39882" translate="yes" xml:space="preserve">
          <source>RandomForestClassifier shows the opposite behavior: the histograms show peaks at approx. 0.2 and 0.9 probability, while probabilities close to 0 or 1 are very rare. An explanation for this is given by Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;: &amp;ldquo;Methods such as bagging and random forests that average predictions from a base set of models can have difficulty making predictions near 0 and 1 because variance in the underlying base models will bias predictions that should be near zero or one away from these values. Because predictions are restricted to the interval [0,1], errors caused by variance tend to be one- sided near zero and one. For example, if a model should predict p = 0 for a case, the only way bagging can achieve this is if all bagged trees predict zero. If we add noise to the trees that bagging is averaging over, this noise will cause some trees to predict values larger than 0 for this case, thus moving the average prediction of the bagged ensemble away from 0. We observe this effect most strongly with random forests because the base-level trees trained with random forests have relatively high variance due to feature subsetting.&amp;rdquo; As a result, the calibration curve shows a characteristic sigmoid shape, indicating that the classifier could trust its &amp;ldquo;intuition&amp;rdquo; more and return probabilities closer to 0 or 1 typically.</source>
          <target state="translated">RandomForestClassifier表现出相反的行为：直方图显示的峰值约为。概率为0.2和0.9，而接近0或1的概率非常少。 Niculescu-Mizil和Caruana对此进行了解释&lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;：&amp;ldquo;套袋和随机森林之类的方法无法根据基本模型集进行平均预测，因此很难进行接近0和1的预测，因为基础模型的方差会使偏离这些值的预测偏差接近零或一。因为预测仅限于区间[0,1]，所以由方差引起的误差往往在接近零和一的一侧。例如，如果模型应针对某个情况预测p = 0，那么套袋可以实现的唯一方法是，如果所有套袋树都预测为零。如果我们向装袋平均的树上添加噪声，则此噪声将导致某些树木在这种情况下预测的值大于0，从而使装袋总体的平均预测远离0。我们在随机森林中最能观察到这种效果，因为使用随机森林训练的基本树由于特征子集而具有相对较高的方差。&amp;rdquo;结果，校准曲线显示出特征性的S型曲线，表明分类器可以更加相信其&amp;ldquo;直觉&amp;rdquo;，并且返回概率通常接近于0或1。</target>
        </trans-unit>
        <trans-unit id="b99b7c8dc6c457a8dec14cbefe28c82d1fdc19eb" translate="yes" xml:space="preserve">
          <source>RandomTreesEmbedding provides a way to map data to a very high-dimensional, sparse representation, which might be beneficial for classification. The mapping is completely unsupervised and very efficient.</source>
          <target state="translated">RandomTreesEmbedding提供了一种将数据映射到一个非常高维、稀疏的表示方式,这可能对分类有利。这种映射是完全无监督的,而且非常高效。</target>
        </trans-unit>
        <trans-unit id="fba143cc92cd33e7d750cb7779216504b5193fb4" translate="yes" xml:space="preserve">
          <source>Randomized CV splitters may return different results for each call of split. You can make the results identical by setting &lt;code&gt;random_state&lt;/code&gt; to an integer.</source>
          <target state="translated">随机CV分割器可能会为每个分割调用返回不同的结果。通过将 &lt;code&gt;random_state&lt;/code&gt; 设置为整数，可以使结果相同。</target>
        </trans-unit>
        <trans-unit id="7464de894f093d84c4a6e238c86ee9b0e6ef0d8b" translate="yes" xml:space="preserve">
          <source>Randomized Lasso works by subsampling the training data and computing a Lasso estimate where the penalty of a random subset of coefficients has been scaled. By performing this double randomization several times, the method assigns high scores to features that are repeatedly selected across randomizations. This is known as stability selection. In short, features selected more often are considered good features.</source>
          <target state="translated">随机化Lasso的工作原理是对训练数据进行子采样,并计算一个Lasso估计值,其中随机系数子集的惩罚已被缩放。通过多次执行这种双重随机化,该方法将高分分配给在随机化中反复选择的特征。这就是所谓的稳定性选择。简而言之,被选择次数较多的特征被认为是好特征。</target>
        </trans-unit>
        <trans-unit id="46be6112d7c7d476c8b2b96ef46abfdfb711fda9" translate="yes" xml:space="preserve">
          <source>Randomized Lasso.</source>
          <target state="translated">随机拉索。</target>
        </trans-unit>
        <trans-unit id="e0e91c3b39c638d46ace3d061876a15beae00989" translate="yes" xml:space="preserve">
          <source>Randomized Logistic Regression</source>
          <target state="translated">随机Logistic回归</target>
        </trans-unit>
        <trans-unit id="d7cc1de7e1283020198535d0f5589374b5b37f13" translate="yes" xml:space="preserve">
          <source>Randomized Logistic Regression works by subsampling the training data and fitting a L1-penalized LogisticRegression model where the penalty of a random subset of coefficients has been scaled. By performing this double randomization several times, the method assigns high scores to features that are repeatedly selected across randomizations. This is known as stability selection. In short, features selected more often are considered good features.</source>
          <target state="translated">随机化LogisticRegression的工作原理是对训练数据进行子采样,并拟合一个L1惩罚的LogisticRegression模型,其中随机系数子集的惩罚已经被缩放。通过多次执行这种双重随机化,该方法将高分分配给在随机化中反复选择的特征。这就是所谓的稳定性选择。简而言之,被选择次数较多的特征被认为是好特征。</target>
        </trans-unit>
        <trans-unit id="9c540f986182775d4f1b2b5266d9f715e8609064" translate="yes" xml:space="preserve">
          <source>Randomized search on hyper parameters.</source>
          <target state="translated">超参数的随机搜索。</target>
        </trans-unit>
        <trans-unit id="727b24e973f7ce53a485ba2d90a0fb546aaa5480" translate="yes" xml:space="preserve">
          <source>RandomizedSearchCV implements a &amp;ldquo;fit&amp;rdquo; and a &amp;ldquo;score&amp;rdquo; method. It also implements &amp;ldquo;predict&amp;rdquo;, &amp;ldquo;predict_proba&amp;rdquo;, &amp;ldquo;decision_function&amp;rdquo;, &amp;ldquo;transform&amp;rdquo; and &amp;ldquo;inverse_transform&amp;rdquo; if they are implemented in the estimator used.</source>
          <target state="translated">RandomizedSearchCV实现&amp;ldquo;拟合&amp;rdquo;和&amp;ldquo;得分&amp;rdquo;方法。如果在所使用的估计器中实现了&amp;ldquo;预测&amp;rdquo;，&amp;ldquo;预测_proba&amp;rdquo;，&amp;ldquo;决策功能&amp;rdquo;，&amp;ldquo;变换&amp;rdquo;和&amp;ldquo;逆变换&amp;rdquo;，则还可以实现它们。</target>
        </trans-unit>
        <trans-unit id="a124e99274671f5884ebb748c86ad3cc6e10ed0a" translate="yes" xml:space="preserve">
          <source>Randomly generated sample</source>
          <target state="translated">随机生成的样本</target>
        </trans-unit>
        <trans-unit id="6bc3f06c954afb75fec23342d87819aaba0adca2" translate="yes" xml:space="preserve">
          <source>Range of parameter space to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;查询的参数空间范围。</target>
        </trans-unit>
        <trans-unit id="d69f1c514ebc77e035c833c4b788288dbd9d7d3a" translate="yes" xml:space="preserve">
          <source>Range of parameter space to use by default for &lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsClassifier.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsClassifier.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;查询的参数空间范围。</target>
        </trans-unit>
        <trans-unit id="ccf6560d01359860d9981044e8888921c69a1ebc" translate="yes" xml:space="preserve">
          <source>Range of parameter space to use by default for &lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsRegressor.radius_neighbors&quot;&gt;&lt;code&gt;radius_neighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">默认情况下用于&lt;a href=&quot;#sklearn.neighbors.RadiusNeighborsRegressor.radius_neighbors&quot;&gt; &lt;code&gt;radius_neighbors&lt;/code&gt; &lt;/a&gt;查询的参数空间范围。</target>
        </trans-unit>
        <trans-unit id="f1e258c2a1109b8940bd4b1e4eed34edbe1fde37" translate="yes" xml:space="preserve">
          <source>Ratio of non-zero component in the random projection matrix.</source>
          <target state="translated">随机投影矩阵中非零分量的比率。</target>
        </trans-unit>
        <trans-unit id="8b08645b475105905425ba5f5c101503a63ea50f" translate="yes" xml:space="preserve">
          <source>Ratio used to resize the each face picture.</source>
          <target state="translated">用于调整每张脸部图片的比例。</target>
        </trans-unit>
        <trans-unit id="af6620521bd29965067000a75da79809db3afb7f" translate="yes" xml:space="preserve">
          <source>Rational Quadratic kernel.</source>
          <target state="translated">理性二次元内核。</target>
        </trans-unit>
        <trans-unit id="ea59ceaf3b393b30c1c8d72ec111e141f43eeeef" translate="yes" xml:space="preserve">
          <source>Ravel column or 1d numpy array, else raises an error</source>
          <target state="translated">Ravel列或1d numpy数组,否则引发错误</target>
        </trans-unit>
        <trans-unit id="8293b10d1c331b776cfe76bddf88b79c491fcbac" translate="yes" xml:space="preserve">
          <source>Raw estimates can be accessed as &lt;code&gt;raw_location_&lt;/code&gt; and &lt;code&gt;raw_covariance_&lt;/code&gt; attributes of a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; robust covariance estimator object.</source>
          <target state="translated">原始估算值可以作为&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt;健壮协方差估算器对象的 &lt;code&gt;raw_location_&lt;/code&gt; 和 &lt;code&gt;raw_covariance_&lt;/code&gt; 属性访问。</target>
        </trans-unit>
        <trans-unit id="7a51ea0e85a0f81236be43da3cb18bbf7d090e93" translate="yes" xml:space="preserve">
          <source>Raw image</source>
          <target state="translated">原始图像</target>
        </trans-unit>
        <trans-unit id="ec15241caecff75c6d32741bba14ecbe2c0152ff" translate="yes" xml:space="preserve">
          <source>Raw scoring function of the samples.</source>
          <target state="translated">样本的原始评分功能。</target>
        </trans-unit>
        <trans-unit id="443ae37519752c5de5e0cde248d4844d13b0b355" translate="yes" xml:space="preserve">
          <source>Re-weight observations using Rousseeuw&amp;rsquo;s method (equivalent to deleting outlying observations from the data set before computing location and covariance estimates) described in &lt;a href=&quot;#r9465bad4668c-rvdriessen&quot; id=&quot;id6&quot;&gt;[RVDriessen]&lt;/a&gt;.</source>
          <target state="translated">使用&lt;a href=&quot;#r9465bad4668c-rvdriessen&quot; id=&quot;id6&quot;&gt;[RVDriessen]中&lt;/a&gt;描述的Rousseeuw方法（相当于在计算位置和协方差估计之前从数据集中删除外围观测值）对观测值进行加权。</target>
        </trans-unit>
        <trans-unit id="811aa24c73d44be5265f8db35e1aba02e43f5167" translate="yes" xml:space="preserve">
          <source>Re-weight observations using Rousseeuw&amp;rsquo;s method (equivalent to deleting outlying observations from the data set before computing location and covariance estimates) described in &lt;a href=&quot;#rd2c89e63f1c9-rvdriessen&quot; id=&quot;id4&quot;&gt;[RVDriessen]&lt;/a&gt;.</source>
          <target state="translated">使用&lt;a href=&quot;#rd2c89e63f1c9-rvdriessen&quot; id=&quot;id4&quot;&gt;[RVDriessen]中&lt;/a&gt;描述的Rousseeuw方法（相当于在计算位置和协方差估计之前从数据集中删除外围观测值）对观测值进行加权。</target>
        </trans-unit>
        <trans-unit id="1fe70f858d89020443d7d8345c1f02d89d6ccd93" translate="yes" xml:space="preserve">
          <source>Re-weight raw Minimum Covariance Determinant estimates.</source>
          <target state="translated">重新加权原始最小协方差决定因素估计。</target>
        </trans-unit>
        <trans-unit id="6cb1bab89173046e86d32a76aea708a020205876" translate="yes" xml:space="preserve">
          <source>Re-weighted robust covariance estimate.</source>
          <target state="translated">重新加权的稳健协方差估计。</target>
        </trans-unit>
        <trans-unit id="7c1d2fed66b789c1352f92c94963e51426ea249d" translate="yes" xml:space="preserve">
          <source>Re-weighted robust location estimate.</source>
          <target state="translated">重新加权的稳健位置估计。</target>
        </trans-unit>
        <trans-unit id="b4cfab0f3b2467caeb2e1bedf3c18c73b01c7da8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#boston-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#boston-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="cb1e120b331b23a9ea1593b6a6404dddbbf78f2a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#breast-cancer-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#breast-cancer-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="45cb9dd939a999d831c07cc2e3e7ed643cf488a4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#california-housing-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#california-housing-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="eccf3b3816b9590ebdeba4771d3acc5f4e159b2e" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#covtype-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#covtype-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="d4bb3e966e3f5178d7f7c4a61126a58124c52a9d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#datasets&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#datasets&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="e4eedc3904e3680ac48f3d5f08f3a25ab49b2093" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#diabetes-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#diabetes-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="c9d0dc8f7e9cd1a47f16f6e56a93e432e5e7f1e3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#digits-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#digits-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="782264ebf6818f03e85e8b9bd3386d8a9677a337" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#iris-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#iris-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="d52fb8cbe534543faa8555a91b64dff64e3dea0d" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#kddcup99-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#kddcup99-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="6a4f56eaf393056504ca6ff95442d562e2504be6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#labeled-faces-in-the-wild-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#labeled-faces-in-the-wild-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4da395463b2e4202f4daff9e84c23d64de9c6f05" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#linnerrud-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#linnerrud-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="53a74e4331e38be5dfe4615ecb0251f124a205e3" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="dce5d9eecff0f524d4dec775f90afdf42f5a110a" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="21a9979f9639169e833f8c2f7d58dccf530dd101" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#openml&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#openml&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="716aae22fdfaa4b0a01611fc142c61fa672a0972" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#rcv1-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#rcv1-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="11adccfb6f94431df3dd0d991fe405585bda6ae8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#sample-generators&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#sample-generators&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="35447ff590c92f7b4f003f24713aa2c9a81298a5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#sample-images&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#sample-images&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4853b3528d5b03002784a57acc74b0ef73704bc1" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../../datasets/index#wine-dataset&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../../datasets/index#wine-dataset&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="ff64d1a0ea7fdf7ff58d5025e9e080a8cec7c72c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../biclustering#biclustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../biclustering#biclustering&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="c316b1ee3fa8c904650e89cb99da69896eccc6a5" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../biclustering#spectral-biclustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../biclustering#spectral-biclustering&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="33b53761153553cd62c19c209bb628778cf329c8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../biclustering#spectral-coclustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../biclustering#spectral-coclustering&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="8ad1d496a9fc7afe128ac29316cc3f3116982df6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../calibration#calibration&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../calibration#calibration&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="266b21640ba75b4def05823d912c707e5b485568" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#adjusted-rand-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#adjusted-rand-score&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="285800162cfb9496523169f1e324d5ca52f05105" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#affinity-propagation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#affinity-propagation&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="bee5e31231b24163a354acd1dc67b01773852fa9" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#birch&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#birch&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4601587ee80ec2a86d25242c642e0a55dac8fafc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#calinski-harabaz-index&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#calinski-harabaz-index&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="51dc466eb21d20d9b69c9e5f15e9274cedda7156" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#davies-bouldin-index&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#davies-bouldin-index&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5ef82ad65b3f026f0caf908c608841a43c0efa75" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#dbscan&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#dbscan&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="a6e99c3c80faf77fafc0a8d86085180cc6c84922" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#fowlkes-mallows-scores&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#fowlkes-mallows-scores&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="2deecce3a8534f9e96109e5f8de3632504534434" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#hierarchical-clustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#hierarchical-clustering&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="85746bd6fcaa1b3e9726613bf073ebbc8fc899ee" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#homogeneity-completeness&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#homogeneity-completeness&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="9388af5c27de2b75bebc64aefce142fa8b7c7d87" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#k-means&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#k-means&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="f3d022ba3260ebedaf289d3105c309efc9b6efaa" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#mean-shift&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#mean-shift&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="60456e22d7b43c1be16a5ffd202a73d0404f2ce4" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#mini-batch-kmeans&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#mini-batch-kmeans&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="b5f4de0554a7bf7d30905012caa1476a3b6b0b7b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#mutual-info-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#mutual-info-score&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="a801640f61fb99dac3001902d5642fc23f7f3e77" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#silhouette-coefficient&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#silhouette-coefficient&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="a2bf3b0c073eb6207b67b1a3e36c83ea6726e488" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../clustering#spectral-clustering&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../clustering#spectral-clustering&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4f8b5ece7223f5057b540fbbb2e0213374db36cc" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../compose#column-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../compose#column-transformer&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="b3ffa6d59d10581030d8ebaf923b865f27e71b6c" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../compose#feature-union&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../compose#feature-union&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5cda30dc9a38ecc38c0a084e727bc8f53bfeb83b" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../compose#pipeline&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../compose#pipeline&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="5e5e7bbc971353e91c75e63e500acb2d00125efb" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../covariance#covariance&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="4fd0b000ed57c1d00035b4f4b9abc2d7e21344ad" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#robust-covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../covariance#robust-covariance&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="593f740064fd46ca53be3aa05a901df13d8d0214" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#shrunk-covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../covariance#shrunk-covariance&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="539672df79f8f6a03d60ca9c514700c2198c23e8" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../covariance#sparse-inverse-covariance&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../covariance#sparse-inverse-covariance&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="31cb66e394f44d8290eaed833952db069ac6d5f6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../cross_decomposition#cross-decomposition&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../cross_decomposition#cross-decomposition&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="73b9c5b0bf3f15999aa7f6cf39a5cf5f9ac28e23" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../cross_validation#cross-validation&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="0a6b3a0c6a7adcce79528b7536a4eef927a01b03" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../cross_validation#multimetric-cross-validation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../cross_validation#multimetric-cross-validation&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="3933407dde4f24717b49d900bb199e83da0af6d6" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#dictionarylearning&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#dictionarylearning&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="692c1ee94a7258b331b868686a17925ad7fbb5f7" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#fa&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#fa&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="0b7c7e1938dbc6a19025fdf48af1845f47ea0202" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#ica&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#ica&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="64bc77c9ae79b3fad979d7f7107dc9933f245093" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#incrementalpca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#incrementalpca&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="6ef55752e42e18cb66d8ffbcf35815ce578503a7" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#kernel-pca&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#kernel-pca&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
        <trans-unit id="df1e3b94f33a2daaffb97b3f696d829a9acf5c23" translate="yes" xml:space="preserve">
          <source>Read more in the &lt;a href=&quot;../decomposition#latentdirichletallocation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">在《&lt;a href=&quot;../decomposition#latentdirichletallocation&quot;&gt;用户指南》中&lt;/a&gt;阅读更多内容。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
