<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="78bd06a1d3ff24b26b2d2d7bba48b35d89d447f8" translate="yes" xml:space="preserve">
          <source>NCA can be used to perform supervised dimensionality reduction. The input data are projected onto a linear subspace consisting of the directions which minimize the NCA objective. The desired dimensionality can be set using the parameter &lt;code&gt;n_components&lt;/code&gt;. For instance, the following figure shows a comparison of dimensionality reduction with Principal Component Analysis (&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt;), Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Neighborhood Component Analysis (&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) on the Digits dataset, a dataset with size \(n_{samples} = 1797\) and \(n_{features} = 64\). The data set is split into a training and a test set of equal size, then standardized. For evaluation the 3-nearest neighbor classification accuracy is computed on the 2-dimensional projected points found by each method. Each data sample belongs to one of 10 classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="178c8cecc0d6623e23a76bbb064f3967dc7aa43a" translate="yes" xml:space="preserve">
          <source>NCA classification has been shown to work well in practice for data sets of varying size and difficulty. In contrast to related methods such as Linear Discriminant Analysis, NCA does not make any assumptions about the class distributions. The nearest neighbor classification can naturally produce highly irregular decision boundaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a288a9444d289c6327b252974b74e26d9ed71a92" translate="yes" xml:space="preserve">
          <source>NCA stores a matrix of pairwise distances, taking &lt;code&gt;n_samples ** 2&lt;/code&gt; memory. Time complexity depends on the number of iterations done by the optimisation algorithm. However, one can set the maximum number of iterations with the argument &lt;code&gt;max_iter&lt;/code&gt;. For each iteration, time complexity is &lt;code&gt;O(n_components x n_samples x min(n_samples, n_features))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235c4fdc295d941494351e73dad0edc432affd04" translate="yes" xml:space="preserve">
          <source>NFF : number of dims in which both values are False</source>
          <target state="translated">NFF : 두 값이 모두 거짓 인 딤 수</target>
        </trans-unit>
        <trans-unit id="f242d8e1cdbbc8cb628621d8d57f10327047707d" translate="yes" xml:space="preserve">
          <source>NFT : number of dims in which the first value is False, second is True</source>
          <target state="translated">NFT : 첫 번째 값이 False이고 두 번째가 True 인 희미한 수</target>
        </trans-unit>
        <trans-unit id="ced12bb5137dbf26fd788e77cae54623cdb8b2e8" translate="yes" xml:space="preserve">
          <source>NMF is best used with the &lt;code&gt;fit_transform&lt;/code&gt; method, which returns the matrix W. The matrix H is stored into the fitted model in the &lt;code&gt;components_&lt;/code&gt; attribute; the method &lt;code&gt;transform&lt;/code&gt; will decompose a new matrix X_new based on these stored components:</source>
          <target state="translated">NMF는 행렬 W를 리턴 하는 &lt;code&gt;fit_transform&lt;/code&gt; 메소드 와 함께 사용하는 것이 가장 좋습니다 . 행렬 H는 &lt;code&gt;components_&lt;/code&gt; 속성으로 피팅 된 모델에 저장됩니다 . 메소드 &lt;code&gt;transform&lt;/code&gt; 은 저장된 구성 요소를 기반으로 새 행렬 X_new를 분해합니다.</target>
        </trans-unit>
        <trans-unit id="9546ef450bf032f2a099e2b8894066e314108bcc" translate="yes" xml:space="preserve">
          <source>NMI and MI are not adjusted against chance.</source>
          <target state="translated">NMI와 MI는 우연히 조정되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="ec8506cc20e415f16975d43b2c6e163b63b7c223" translate="yes" xml:space="preserve">
          <source>NNEQ / (NNEQ + 0.5 * NTT)</source>
          <target state="translated">NNEQ / (NNEQ + 0.5 * NTT)</target>
        </trans-unit>
        <trans-unit id="64142d93685b184d0f4668dd2d38de67d364504a" translate="yes" xml:space="preserve">
          <source>NNEQ / (NTT + NNZ)</source>
          <target state="translated">NNEQ / (NTT + NNZ)</target>
        </trans-unit>
        <trans-unit id="9e2ca45598fef4852f298770d7c7037071a195c1" translate="yes" xml:space="preserve">
          <source>NNEQ / N</source>
          <target state="translated">NNEQ / N</target>
        </trans-unit>
        <trans-unit id="bd22d441438dd8339012b8925c55919834498020" translate="yes" xml:space="preserve">
          <source>NNEQ / NNZ</source>
          <target state="translated">NNEQ / NNZ</target>
        </trans-unit>
        <trans-unit id="a4e22ff89a7f8daef1da10b2c311e81f8eb57054" translate="yes" xml:space="preserve">
          <source>NNEQ : number of non-equal dimensions, NNEQ = NTF + NFT</source>
          <target state="translated">NNEQ : 같지 않은 치수 수, NNEQ = NTF + NFT</target>
        </trans-unit>
        <trans-unit id="80bfd3623c0e507836f83286688a2ee41b18b00e" translate="yes" xml:space="preserve">
          <source>NNZ / N</source>
          <target state="translated">NNZ / ​​N</target>
        </trans-unit>
        <trans-unit id="93209a2edd337e6dc4e7c870a3c72537cea28fdf" translate="yes" xml:space="preserve">
          <source>NNZ : number of nonzero dimensions, NNZ = NTF + NFT + NTT</source>
          <target state="translated">NNZ : 0이 아닌 차원 수, NNZ = NTF + NFT + NTT</target>
        </trans-unit>
        <trans-unit id="a8ad860c15810cce0e7beac1c91da3ab2cb22c47" translate="yes" xml:space="preserve">
          <source>NOTE</source>
          <target state="translated">NOTE</target>
        </trans-unit>
        <trans-unit id="b81cbdff62e50c72d48e4feea8a9ed88bea18bef" translate="yes" xml:space="preserve">
          <source>NOTE that when using custom scorers, each scorer should return a single value. Metric functions returning a list/array of values can be wrapped into multiple scorers that return one value each.</source>
          <target state="translated">사용자 지정 채점자를 사용할 때 각 채점자는 단일 값을 반환해야합니다. 값 목록 / 배열을 반환하는 메트릭 함수는 각각 하나의 값을 반환하는 여러 스코어러로 래핑 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9764dfb854390dc404102ac64200b55e363e83df" translate="yes" xml:space="preserve">
          <source>NOX nitric oxides concentration (parts per 10 million)</source>
          <target state="translated">NOX 산화 질소 농도 (1,000 만 부)</target>
        </trans-unit>
        <trans-unit id="99542bc2231d38286b9a1dbe4685e8690203b845" translate="yes" xml:space="preserve">
          <source>NTF : number of dims in which the first value is True, second is False</source>
          <target state="translated">NTF : 첫 번째 값이 True이고 두 번째 값이 False 인 딤 수</target>
        </trans-unit>
        <trans-unit id="d7aff2fba38c5d47fc1d509779237efeccf9cd66" translate="yes" xml:space="preserve">
          <source>NTT : number of dims in which both values are True</source>
          <target state="translated">NTT : 두 값이 모두 참인 디딤 수</target>
        </trans-unit>
        <trans-unit id="f7fd9c68f804acda665d2ab082217bb1583318f2" translate="yes" xml:space="preserve">
          <source>NaN</source>
          <target state="translated">NaN</target>
        </trans-unit>
        <trans-unit id="6e2518fe965a665a40ec6f1bf71cbacd3d7014df" translate="yes" xml:space="preserve">
          <source>NaNs are ignored in the algorithm.</source>
          <target state="translated">알고리즘에서 NaN은 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="bce02ea83698a345c8e67696ff8bdcc86ad6e774" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in &lt;code&gt;fit&lt;/code&gt;, and maintained in &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b2cc2bc3bfa4ab2fba6e73cce899558220dd79a" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in fit, and maintained in transform.</source>
          <target state="translated">NaN은 결 측값으로 취급됩니다. 적합하지 않고 변환 상태로 유지됩니다.</target>
        </trans-unit>
        <trans-unit id="d13d7452647efb26ab0d2b1a3596526a7f4ca5d6" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded to compute the statistics, and maintained during the data transformation.</source>
          <target state="translated">NaN은 결 측값으로 처리됩니다. 통계 계산을 무시하고 데이터 변환 중에 유지됩니다.</target>
        </trans-unit>
        <trans-unit id="d5c044a4b683787e1d22f3d89c2071d25a271b09" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for categorical features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80d8f13b4e334c4342adf34b360ad118e5e25aa3" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multinomial models</source>
          <target state="translated">다항식 모델을위한 Naive Bayes 분류기</target>
        </trans-unit>
        <trans-unit id="92990e6c1a566f0d055f974e25026ec604b9ccd9" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multivariate Bernoulli models.</source>
          <target state="translated">다변량 베르누이 모델에 대한 나이브 베이 즈 분류기.</target>
        </trans-unit>
        <trans-unit id="c95f9acb4985f23ad6962fd01ae91dec549e7273" translate="yes" xml:space="preserve">
          <source>Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.</source>
          <target state="translated">Naive Bayes 학습자와 분류기는보다 복잡한 방법에 비해 매우 빠릅니다. 클래스 조건부 특징 분포의 분리는 각 분포가 1 차원 분포로 독립적으로 추정 될 수 있음을 의미합니다. 이는 차원의 저주로 인한 문제를 완화하는 데 도움이됩니다.</target>
        </trans-unit>
        <trans-unit id="bb7ceea48fd3728ed03cf0ba21b4839b323fc974" translate="yes" xml:space="preserve">
          <source>Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes&amp;rsquo; theorem with the &amp;ldquo;naive&amp;rdquo; assumption of conditional independence between every pair of features given the value of the class variable. Bayes&amp;rsquo; theorem states the following relationship, given class variable \(y\) and dependent feature vector \(x_1\) through \(x_n\), :</source>
          <target state="translated">Naive Bayes 방법은 클래스 변수의 값이 주어지면 모든 기능 쌍 사이에 조건부 독립성을 &quot;순진한&quot;가정으로 Bayes 정리를 적용한 것에 기반한 일련의 감독 학습 알고리즘입니다. 베이 즈 정리는 클래스 변수 \ (y \)와 종속 피처 벡터 \ (x_1 \)에서 \ (x_n \)까지 주어진 관계를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="f65600325bc091b7b293639582ad70691e2ac960" translate="yes" xml:space="preserve">
          <source>Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;MultinomialNB&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt;&lt;code&gt;BernoulliNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt; expose a &lt;code&gt;partial_fit&lt;/code&gt; method that can be used incrementally as done with other classifiers as demonstrated in &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. All naive Bayes classifiers support sample weighting.</source>
          <target state="translated">Naive Bayes 모델을 사용하면 전체 교육 세트가 메모리에 맞지 않을 수있는 대규모 분류 문제를 해결할 수 있습니다. 이 경우를 처리하기 위해 &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;MultinomialNB&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt; &lt;code&gt;BernoulliNB&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;GaussianNB&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt; 는 텍스트 문서의 핵심 외 분류&lt;/a&gt; 에서 설명 된 것처럼 다른 분류기와 마찬가지로 점진적으로 사용할 수 있는 &lt;code&gt;partial_fit&lt;/code&gt; 메소드를 제공 합니다 . 모든 순진 Bayes 분류기는 샘플 가중치를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="f07ca99358e3e69c28471fb128e9c221473a78cf" translate="yes" xml:space="preserve">
          <source>Name for labeling curve. If &lt;code&gt;None&lt;/code&gt;, the name of the estimator is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44b4a8733a267298aba42ed906f0510d314435b0" translate="yes" xml:space="preserve">
          <source>Name of ROC Curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="048c56c2b44d92cd1c41343db29430d22afe211f" translate="yes" xml:space="preserve">
          <source>Name of columns containing this regex pattern will be included. If None, column selection will not be selected based on pattern.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f39a3bd9bee33098b86f18fcaf23fc1b1f211a0" translate="yes" xml:space="preserve">
          <source>Name of dataset</source>
          <target state="translated">데이터 세트 이름</target>
        </trans-unit>
        <trans-unit id="325b56c17b8389991fec124de840a19f36bc1993" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i.</source>
          <target state="translated">각 기능의 이름 feature_names [i]는 색인 i를 가진 기능의 이름을 보유합니다.</target>
        </trans-unit>
        <trans-unit id="f379c68cd7abf28a38376a7f9401ab9de0d511e5" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i. By default, the name of the feature corresponds to their numerical index for NumPy array and their column name for pandas dataframe.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ea3134d139c317d0bc4edf673307764ffe8b0cd" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, the estimator name is not shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8c1daded10cddfabf9a6fd7ee9e2ee679e1adbf" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, then the estimator name is not shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed7e838c9509fe0de6c00e0d7bd5bf221ec76bc1" translate="yes" xml:space="preserve">
          <source>Name of precision recall curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d63bfd9357f039d867c5652a85ab61996c87f94" translate="yes" xml:space="preserve">
          <source>Name of the data set on mldata.org, e.g.: &amp;ldquo;leukemia&amp;rdquo;, &amp;ldquo;Whistler Daily Snowfall&amp;rdquo;, etc. The raw name is automatically converted to a mldata.org URL .</source>
          <target state="translated">mldata.org에 설정된 데이터 이름 (예 : &quot;leukemia&quot;, &quot;Whistler Daily Snowfall&quot;등) 원시 이름은 자동으로 mldata.org URL로 변환됩니다.</target>
        </trans-unit>
        <trans-unit id="866f4401ef93cfed3b044fff6753dc1e913659b2" translate="yes" xml:space="preserve">
          <source>Name of the output activation function.</source>
          <target state="translated">출력 활성화 기능의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="5a3a86d298c7e4314e724bb2623d8c6979ee2b6e" translate="yes" xml:space="preserve">
          <source>Name of the parameter that will be varied.</source>
          <target state="translated">변경 될 매개 변수의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="d08ba4e92bc82e0b0eddb2db204950ac5386e156" translate="yes" xml:space="preserve">
          <source>Name of the sub-estimator that can be accessed as an attribute of the base object. If a list or a tuple of names are provided, the first sub-estimator that is an attribute of the base object will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce3ec81584fa2d87df12f144e2480deecc5a975a" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the data.</source>
          <target state="translated">데이터가 포함 된 열의 이름 또는 색인입니다.</target>
        </trans-unit>
        <trans-unit id="0ae5e537b1c061ee0b3ccea7c63ace2088ca02dd" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the target values.</source>
          <target state="translated">대상 값을 포함하는 열의 이름 또는 색인</target>
        </trans-unit>
        <trans-unit id="3170e49e906772d2e2d83c510613a736bad3f541" translate="yes" xml:space="preserve">
          <source>Named features not encountered during fit or fit_transform will be silently ignored.</source>
          <target state="translated">fit 또는 fit_transform 중에 발생하지 않는 명명 된 기능은 자동으로 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="dd3283d9f71127c2e2cb8ea6f07a41ece4a049ce" translate="yes" xml:space="preserve">
          <source>Names of each of the features.</source>
          <target state="translated">각 기능의 이름</target>
        </trans-unit>
        <trans-unit id="99983f06243c41c70b7f7a98a21b26cf2a2ec6a9" translate="yes" xml:space="preserve">
          <source>Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If &lt;code&gt;True&lt;/code&gt;, shows a symbolic representation of the class name.</source>
          <target state="translated">각 대상 클래스의 이름은 오름차순으로 표시됩니다. 분류에만 관련되며 다중 출력에는 지원되지 않습니다. &lt;code&gt;True&lt;/code&gt; 인 경우 클래스 이름을 상징적으로 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="e9e6ba24a1711383d87f42cc11bb29b29e568b73" translate="yes" xml:space="preserve">
          <source>Names of each target (RCV1 topics), as ordered in dataset.target.</source>
          <target state="translated">dataset.target에서 주문한 각 대상의 이름 (RCV1 주제).</target>
        </trans-unit>
        <trans-unit id="5ee798b80fce1c26ac31847940e2cbb9594ee08b" translate="yes" xml:space="preserve">
          <source>Names of the features produced by transform.</source>
          <target state="translated">변환에 의해 생성 된 기능의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="8769733c023d80ccc969e39d7e721f7eef2c8e42" translate="yes" xml:space="preserve">
          <source>Native support for missing values for gradient boosting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aded465f8c4c45d7d7ec8d437901909b15f0b3f" translate="yes" xml:space="preserve">
          <source>Natural handling of data of mixed type (= heterogeneous features)</source>
          <target state="translated">혼합 유형의 데이터 자연 처리 (= 이기종 기능)</target>
        </trans-unit>
        <trans-unit id="0a4d2a1303aed1ff654767155d9269907f0d020c" translate="yes" xml:space="preserve">
          <source>Nearest Centroid Classification</source>
          <target state="translated">가장 가까운 중심 분류</target>
        </trans-unit>
        <trans-unit id="bfa0969ff4ed25d459c6eac3badc5bf9f79ee3f4" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa1459036257eab60db8e1afe6d9886bbc5e8a42" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors Classification</source>
          <target state="translated">가장 가까운 이웃 분류</target>
        </trans-unit>
        <trans-unit id="c7b70d3a90c9b413590f1c3fdfeae8dc16304398" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors regression</source>
          <target state="translated">가장 가까운 이웃 회귀</target>
        </trans-unit>
        <trans-unit id="cc8575a20e3e28eef4bfc70e48146f9994bd7318" translate="yes" xml:space="preserve">
          <source>Nearest centroid classifier.</source>
          <target state="translated">가장 가까운 중심 분류기.</target>
        </trans-unit>
        <trans-unit id="8b02ae7bd0e5dc3ad9885f92e92e8dfc0759e655" translate="yes" xml:space="preserve">
          <source>Nearest neighbor and the curse of dimensionality</source>
          <target state="translated">가장 가까운 이웃과 차원의 저주</target>
        </trans-unit>
        <trans-unit id="5db95950f32dda99cc2cb722bb90ec8e1106f00f" translate="yes" xml:space="preserve">
          <source>Needless to say, the cross-validation involved in Platt scaling is an expensive operation for large datasets. In addition, the probability estimates may be inconsistent with the scores, in the sense that the &amp;ldquo;argmax&amp;rdquo; of the scores may not be the argmax of the probabilities. (E.g., in binary classification, a sample may be labeled by &lt;code&gt;predict&lt;/code&gt; as belonging to a class that has probability &amp;lt;&amp;frac12; according to &lt;code&gt;predict_proba&lt;/code&gt;.) Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">말할 필요도없이, Platt 스케일링과 관련된 교차 유효성 검사는 큰 데이터 세트에 대해 비싼 작업입니다. 또한, 확률 추정치는 스코어의 &quot;argmax&quot;가 확률의 argmax가 아닐 수 있다는 점에서 스코어와 일치하지 않을 수있다. (예를 들어, 이진 분류에서, 샘플은 &lt;code&gt;predict_proba&lt;/code&gt; 에 따라 확률이 &amp;lt;1/2 인 클래스에 속하는 &lt;code&gt;predict&lt;/code&gt; 하여 라벨링 될 수있다 .) Platt의 방법은 또한 이론적 인 문제를 갖는 것으로 알려져있다. 신뢰 점수가 필요하지만 확률이 아니어야하는 경우 &lt;code&gt;probability=False&lt;/code&gt; 을 설정 하고 &lt;code&gt;predict_proba&lt;/code&gt; 대신 &lt;code&gt;decision_function&lt;/code&gt; 을 사용하는 것이 좋습니다 .</target>
        </trans-unit>
        <trans-unit id="5040421db1ecb4c2ff96e24808174eee959aab93" translate="yes" xml:space="preserve">
          <source>Neighborhood Component Analysis (NCA) is a machine learning algorithm for metric learning. It learns a linear transformation in a supervised fashion to improve the classification accuracy of a stochastic nearest neighbors rule in the transformed space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e58fc95c9278805803f18a9db5fe3ea3f42040b6" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba8f206becb6fe0a43da0c0c40642a7520c206e1" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA) tries to find a feature space such that a stochastic nearest neighbor algorithm will give the best accuracy. Like LDA, it is a supervised method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aee814d8b405edd4d076224daf37938472d0e4bb" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA, &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) is a distance metric learning algorithm which aims to improve the accuracy of nearest neighbors classification compared to the standard Euclidean distance. The algorithm directly maximizes a stochastic variant of the leave-one-out k-nearest neighbors (KNN) score on the training set. It can also learn a low-dimensional linear projection of data that can be used for data visualization and fast classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e267b3659f7643549165a2fa213a97174cdd61c0" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis Illustration</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d2390b5dea0fabfaec001753e4e7ab98989a540" translate="yes" xml:space="preserve">
          <source>Neighborhoods are restricted the points at a distance lower than radius.</source>
          <target state="translated">이웃은 반경보다 낮은 거리에서 점이 제한됩니다.</target>
        </trans-unit>
        <trans-unit id="71b4c3c0886885b3bdb78dd9feb31a745b98d96e" translate="yes" xml:space="preserve">
          <source>Neighbors-based classification is a type of &lt;em&gt;instance-based learning&lt;/em&gt; or &lt;em&gt;non-generalizing learning&lt;/em&gt;: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</source>
          <target state="translated">이웃 기반 분류는 &lt;em&gt;인스턴스 기반 학습&lt;/em&gt; 또는 &lt;em&gt;일반화되지 않은 &lt;/em&gt;&lt;em&gt;학습&lt;/em&gt; 의 한 유형입니다 . 일반적인 내부 모델을 구성하지 않고 단순히 훈련 데이터의 인스턴스를 저장합니다. 분류는 각 포인트의 가장 가까운 이웃에 대한 간단한 다수 투표로 계산됩니다. 쿼리 포인트에는 해당 지점의 가장 가까운 이웃 내에서 가장 많은 대표자가있는 데이터 클래스가 할당됩니다.</target>
        </trans-unit>
        <trans-unit id="f556f4d2d6fabe3a4b78772a04d1d08bf693d3a1" translate="yes" xml:space="preserve">
          <source>Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</source>
          <target state="translated">데이터 레이블이 이산 변수가 아닌 연속적인 경우 이웃 기반 회귀를 사용할 수 있습니다. 쿼리 지점에 할당 된 레이블은 가장 가까운 이웃 레이블의 평균을 기준으로 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="f17c48105fdd248ad2de1f1ac3f1cabb43429cec" translate="yes" xml:space="preserve">
          <source>Nested cross-validation</source>
          <target state="translated">중첩 교차 검증</target>
        </trans-unit>
        <trans-unit id="029453980f1f56140cec84a6516b88cf4da43353" translate="yes" xml:space="preserve">
          <source>Nested versus non-nested cross-validation</source>
          <target state="translated">중첩 된 교차 유효성 검사와 중첩되지 않은 교차 ​​유효성 검사</target>
        </trans-unit>
        <trans-unit id="3991fd2dc72259103c5d9e42cbe59d2a7e448f31" translate="yes" xml:space="preserve">
          <source>Neural Networks</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c7edd0d2fdd43b38d35974fe3274794c4023842" translate="yes" xml:space="preserve">
          <source>Never unpickle untrusted data as it could lead to malicious code being executed upon loading.</source>
          <target state="translated">신뢰할 수없는 데이터는 피킹시 악성 코드가 실행될 수 있으므로 절대 피클 링하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="5a7c69a057920dae02f0ceb2f6458cca465cc67b" translate="yes" xml:space="preserve">
          <source>New data point to be inserted into the LSH Forest.</source>
          <target state="translated">LSH 포리스트에 삽입 할 새 데이터 포인트.</target>
        </trans-unit>
        <trans-unit id="48ff6f532fccde3a69a322cc1151c107ad295ffd" translate="yes" xml:space="preserve">
          <source>New data to predict.</source>
          <target state="translated">예측할 새로운 데이터.</target>
        </trans-unit>
        <trans-unit id="b9599b4d9149cfd51951922f7155a3dc95944ff0" translate="yes" xml:space="preserve">
          <source>New data to predict. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e461db7b42b4e1d723a59598bcca510859163aef" translate="yes" xml:space="preserve">
          <source>New data to transform.</source>
          <target state="translated">새로운 데이터 변환.</target>
        </trans-unit>
        <trans-unit id="329a026b697f0ae2b6fcf5ede884e3254ea37650" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">새로운 데이터. 여기서 샘플 수의 n_samples 및 n_features는 피처 수입니다.</target>
        </trans-unit>
        <trans-unit id="68d214f5c1780f5e1075a93cc2054064839f0ca3" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features. All values of X must be strictly greater than &amp;ldquo;-skewedness&amp;rdquo;.</source>
          <target state="translated">새로운 데이터. 여기서 샘플 수의 n_samples 및 n_features는 피처 수입니다. X의 모든 값은 &quot;왜곡&quot;보다 엄격하게 커야합니다.</target>
        </trans-unit>
        <trans-unit id="6e6bacb37aec6214dc7bc345656e9fc6be9d8645" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">새 데이터. 여기서 n_samples는 샘플 수이고 n_components는 구성 요소 수입니다.</target>
        </trans-unit>
        <trans-unit id="ed0f15ab3ccef84bd24b03af80dd2d8f760b3551" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of pls components.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9774ac05294602db6164b128c08e5838d8dd2c30" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">n_samples는 샘플 수이고 n_features는 피처 수인 새 데이터입니다.</target>
        </trans-unit>
        <trans-unit id="2cec1d1d13a623e2cead9e687223c0b43410804e" translate="yes" xml:space="preserve">
          <source>New data.</source>
          <target state="translated">새로운 데이터.</target>
        </trans-unit>
        <trans-unit id="2dcde8ec0560b6129ac7ceb94e6b76437cebda2e" translate="yes" xml:space="preserve">
          <source>New in version 0.10.</source>
          <target state="translated">버전 0.10의 새로운 기능.</target>
        </trans-unit>
        <trans-unit id="d68d01022d3e4f6b4abc88815d154b4b27565257" translate="yes" xml:space="preserve">
          <source>New in version 0.12.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc28b70929f839a69ed3e45ea011105ea33d52a9" translate="yes" xml:space="preserve">
          <source>New in version 0.13.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52ebd0001be9ad2ddaeba3e98fe57c162ffbf813" translate="yes" xml:space="preserve">
          <source>New in version 0.14.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73af4998c8d20c7743147253e8c7d8a51d34634f" translate="yes" xml:space="preserve">
          <source>New in version 0.15.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81c56a91b55dc7fbe4322466c0b6b3d2def29380" translate="yes" xml:space="preserve">
          <source>New in version 0.16.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2a489d3a2d4dc51668c693a83253f531fff88d5" translate="yes" xml:space="preserve">
          <source>New in version 0.16: If the input is sparse, the output will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;. Else, output type is the same as the input type.</source>
          <target state="translated">버전 0.16의 새로운 기능 : 입력이 드문 경우, 출력은 &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; 가 됩니다. 그렇지 않으면 출력 유형이 입력 유형과 동일합니다.</target>
        </trans-unit>
        <trans-unit id="60b69c65bf1a3241e15d0d894ba32eab25d7cdd7" translate="yes" xml:space="preserve">
          <source>New in version 0.17.</source>
          <target state="translated">버전 0.17의 새로운 기능.</target>
        </trans-unit>
        <trans-unit id="21cf2264569599d5dcc312306fa70dfc0eda22f5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;code&gt;random_state&lt;/code&gt; to support Stochastic Average Gradient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc470080fe5f5c357c2ad73809b92faa7362d9a9" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="abf887094b036a443ef8f8f3b6efb216ee34cd24" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6b2ff85ecc2a1a01962dd33b1e34753285ca0790" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;alpha&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">0.17 버전의 새로운 기능 : Coordinate Descent 솔버에 사용 된 &lt;em&gt;알파&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="6808fe2d57e6aeef92c976187ce0a06abf1ebec1" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 속도를 향상시키기위한 &lt;em&gt;cd&lt;/em&gt; 좌표 하강 방법.</target>
        </trans-unit>
        <trans-unit id="7b66bf990e4010a15f9d64925c054de502637170" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;class_weight=&amp;rsquo;balanced&amp;rsquo;&lt;/em&gt;</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;class_weight = 'balanced'&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ea86dc59df4308dd8eeb6d9e2ae15359239ba528" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_max_&lt;/em&gt;</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;data_max_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="1f6c1c10d870e8e7d70fedf31cf3a9ee8c7d746d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_min_&lt;/em&gt;</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;data_min_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e853c35f6d282db32a11152441252fd53da7f57f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_range_&lt;/em&gt;</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;data_range_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="edb88b5a13c967ddfdc52fb30c87cf6cd8e55cef" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;decision_function_shape=&amp;rsquo;ovr&amp;rsquo;&lt;/em&gt; is recommended.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;decision_function_shape = 'ovr'&lt;/em&gt; 이 권장됩니다.</target>
        </trans-unit>
        <trans-unit id="18bd409dbab688800dc645ecf6dc2d319b6dc274" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;lasso_cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 속도를 향상시키는 &lt;em&gt;lasso_cd&lt;/em&gt; 좌표 하강 방법.</target>
        </trans-unit>
        <trans-unit id="5c5696058be6bc7e1f1d8d04441e99d3b67a5a9d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;minmax_scale&lt;/em&gt; function interface to &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;minmax_scale&lt;/em&gt; 에 기능 인터페이스 &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="61491e91a5cc882c8d0472b81b77bf74b7ea4e3d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;presort&lt;/em&gt; parameter.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt; 사전 정렬&lt;/em&gt; 매개 변수.</target>
        </trans-unit>
        <trans-unit id="b2b731bdc9bf8dfc47673f8abfcc6c2c7f1f838c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;random_state&lt;/em&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;random_state&lt;/em&gt; Stochastic Average Gradient를 지원하는</target>
        </trans-unit>
        <trans-unit id="727acdfec60aa8d5fe01b0fab35aa36437da02bb" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to Classifier.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;sample_weight&lt;/em&gt; 대한 지원.</target>
        </trans-unit>
        <trans-unit id="6a9e702e6dde8c5e083d3061949d66f0c1cd0a95" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to LogisticRegression.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;sample_weight&lt;/em&gt; LogisticRegression에 지원.</target>
        </trans-unit>
        <trans-unit id="8bf7c72c906a46e4bafab411161accafb9f3258f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt;</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;scale_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="26b994b5337cbc66d9e87cecbe064dc645c2d9c5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt; attribute.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;scale_&lt;/em&gt; attribute.</target>
        </trans-unit>
        <trans-unit id="acaea6c314c50f12e63f6a31caa95dae9a93cb16" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;shuffle&lt;/em&gt; parameter used in the Coordinate Descent solver.</source>
          <target state="translated">버전 0.17의 새로운 기능 : Coordinate Descent 솔버에 사용 된 &lt;em&gt;셔플&lt;/em&gt; 매개 변수.</target>
        </trans-unit>
        <trans-unit id="3c9ad8ece37a0ad66c0695ab197f051fc5c4f74b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; constructor parameter.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;warm_start&lt;/em&gt; 생성자 매개 변수.</target>
        </trans-unit>
        <trans-unit id="5d7ee9d78ae5139184086665f72ad9adc489e60f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; to support &lt;em&gt;lbfgs&lt;/em&gt;, &lt;em&gt;newton-cg&lt;/em&gt;, &lt;em&gt;sag&lt;/em&gt;, &lt;em&gt;saga&lt;/em&gt; solvers.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;lbfgs&lt;/em&gt; 를 지원하기위한 &lt;em&gt;warm_start&lt;/em&gt; , &lt;em&gt;newton-cg&lt;/em&gt; , &lt;em&gt;sag&lt;/em&gt; , &lt;em&gt;saga&lt;/em&gt; 솔버를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="6005792b774eeae7e9401b712800c9c602a22ebe" translate="yes" xml:space="preserve">
          <source>New in version 0.17: A function &lt;em&gt;label_ranking_loss&lt;/em&gt;</source>
          <target state="translated">버전 0.17의 새로운 기능 : function &lt;em&gt;label_ranking_loss&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e93da6946e01b1e23cbc1e7009a23425c993a384" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Approximate optimization &lt;em&gt;method&lt;/em&gt; via the Barnes-Hut.</source>
          <target state="translated">버전 0.17의 새로운 기능 : Barnes-Hut를 통한 대략적인 최적화 &lt;em&gt;방법&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="9365f66e13f87cb3bbf8aaf0ec5863c643029aff" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Coordinate Descent solver.</source>
          <target state="translated">버전 0.17의 새로운 기능 : Coordinate Descent 솔버.</target>
        </trans-unit>
        <trans-unit id="c589f3a156d1562e5e258c1483b29eaa7a3bb671" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Dummy Classifier now supports prior fitting strategy using parameter &lt;em&gt;prior&lt;/em&gt;.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 더미 분류기는 이제 매개 변수를 사용하여 사전 피팅 전략을 지원합니다. &lt;em&gt; 사전을&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="4c1ba1a9df4e3f1eda2057a3d8675352ba0c6105" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Gaussian Naive Bayes supports fitting with &lt;em&gt;sample_weight&lt;/em&gt;.</source>
          <target state="translated">버전 0.17의 새로운 기능 : Gaussian Naive Bayes는 &lt;em&gt; sample_weight&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="b94e1008bb6bd8880b48f9c93c89015eb39cf414" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Parallel Execution using &lt;em&gt;n_jobs&lt;/em&gt;.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;n_jobs를&lt;/em&gt; 사용한 병렬 실행&lt;em&gt;&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="56295350a01a04673ce10a1274f3f2850857660f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Regularization parameter &lt;em&gt;l1_ratio&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 정규화 매개 변수 &lt;em&gt;l1_ratio&lt;/em&gt; Coordinate Descent 솔버에 사용되는 .</target>
        </trans-unit>
        <trans-unit id="bfb15daea388e7bc4652a64e3ee368ec3ef32e45" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Stochastic Average Gradient descent solver.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 확률 적 평균 그라디언트 디센트 솔버.</target>
        </trans-unit>
        <trans-unit id="90ee93ad6b0e53eed26b86779c90b9633cb9848b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: class_weight == &amp;lsquo;balanced&amp;rsquo;</source>
          <target state="translated">버전 0.17의 새로운 기능 : class_weight == 'balanced'</target>
        </trans-unit>
        <trans-unit id="db422a34a0885d2d1033db36affb13affc0d2065" translate="yes" xml:space="preserve">
          <source>New in version 0.17: metric &lt;em&gt;precomputed&lt;/em&gt; to accept precomputed sparse matrix.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 메트릭 &lt;em&gt;사전 계산&lt;/em&gt; 계산 된 희소 행렬을 허용하도록 미리 계산 된 .</target>
        </trans-unit>
        <trans-unit id="545f1d599ea32d73544f4951073f7ce5e1f64bf6" translate="yes" xml:space="preserve">
          <source>New in version 0.17: optional parameter &lt;em&gt;presort&lt;/em&gt;.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 선택적 매개 변수 &lt;em&gt;사전 정렬&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="1c0b7964a491c4c8234983325c356450f442446c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;code&gt;dense_output&lt;/code&gt; for dense output.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 매개 변수 &lt;code&gt;dense_output&lt;/code&gt; 고밀도 출력을위한 .</target>
        </trans-unit>
        <trans-unit id="46c6419997a8eb39c61c2c50456a363282489838" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;class_weight&lt;/em&gt; to automatically weight samples.</source>
          <target state="translated">버전 0.17의 새로운 기능 : parameter &lt;em&gt;class_weight&lt;/em&gt; 에서 자동으로 샘플 무게 측정.</target>
        </trans-unit>
        <trans-unit id="e8cbf38ab0cedfa95f7fc33391f9602285bd6e17" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;drop_intermediate&lt;/em&gt;.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 매개 변수 &lt;em&gt;drop_intermediate&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="960c43bc8538ca35574a01cc68a5f2b510105d22" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;multilabel&lt;/em&gt; to support multilabel datasets.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 매개 변수 &lt;em&gt;다중 레이블&lt;/em&gt; 레이블 데이터 세트를 지원하는 레이블.</target>
        </trans-unit>
        <trans-unit id="3788b38f2b10aab217952de3365bf7b88f170f8d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;n_iter_without_progress&lt;/em&gt; to control stopping criteria.</source>
          <target state="translated">버전 0.17의 새로운 기능 : 매개 변수 &lt;em&gt;n_iter_without_progress&lt;/em&gt; 중지 기준을 제어하기위한 .</target>
        </trans-unit>
        <trans-unit id="8db0c53c524e84f302dbc1a0dbd534321460f08f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to LinearRegression.</source>
          <target state="translated">버전 0.17의 새로운 기능 : parameter &lt;em&gt;sample_weight&lt;/em&gt; 대한 sample_weight 지원.</target>
        </trans-unit>
        <trans-unit id="2a05312b3a418ca739af1c2a1750981f3df80101" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter to allow &lt;em&gt;sparse&lt;/em&gt; output.</source>
          <target state="translated">버전 0.17의 새로운 기능 : &lt;em&gt;스파 스&lt;/em&gt; 를 허용하는 매개 변수&lt;em&gt;&lt;/em&gt; 출력 .</target>
        </trans-unit>
        <trans-unit id="8550f8dcfdefc5ee2595ff5a932287ae10047927" translate="yes" xml:space="preserve">
          <source>New in version 0.18.</source>
          <target state="translated">버전 0.18의 새로운 기능.</target>
        </trans-unit>
        <trans-unit id="bc1978fea309e92ee1923ea481a6fd1eab915379" translate="yes" xml:space="preserve">
          <source>New in version 0.18.0.</source>
          <target state="translated">버전 0.18.0의 새로운 기능</target>
        </trans-unit>
        <trans-unit id="f6899efa546ca366fb803a6a6fcb7b4b47706e4f" translate="yes" xml:space="preserve">
          <source>New in version 0.18: ..</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11462cefb53316ba0a8e0880815bfa04af36466b" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Mean Absolute Error (MAE) criterion.</source>
          <target state="translated">버전 0.18의 새로운 기능 : MAE (Mean Absolute Error) 기준.</target>
        </trans-unit>
        <trans-unit id="f3588d83291a2be20994392c7201429910c5a8e9" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Stochastic Average Gradient descent solver for &amp;lsquo;multinomial&amp;rsquo; case.</source>
          <target state="translated">버전 0.18의 새로운 기능 : '다항식'사례에 대한 확률 적 평균 그라디언트 디센트 솔버.</target>
        </trans-unit>
        <trans-unit id="0eb4d3b4907b28878c6666a16cc5abd9e36f4f00" translate="yes" xml:space="preserve">
          <source>New in version 0.19.</source>
          <target state="translated">버전 0.19의 새로운 기능.</target>
        </trans-unit>
        <trans-unit id="e10489dae5e0fb6aa174b77a26bd312889388c1d" translate="yes" xml:space="preserve">
          <source>New in version 0.19: Multiplicative Update solver.</source>
          <target state="translated">버전 0.19의 새로운 기능 : Multiplicative Update 솔버.</target>
        </trans-unit>
        <trans-unit id="c260a9e7caaac82377fee1bfeace2cf2272b4b1a" translate="yes" xml:space="preserve">
          <source>New in version 0.19: SAGA solver.</source>
          <target state="translated">버전 0.19의 새로운 기능 : SAGA 솔버.</target>
        </trans-unit>
        <trans-unit id="d56c2d84411d9a6c91bdf6681efc0b4e653d1de5" translate="yes" xml:space="preserve">
          <source>New in version 0.19: l1 penalty with SAGA solver (allowing &amp;lsquo;multinomial&amp;rsquo; + L1)</source>
          <target state="translated">버전 0.19의 새로운 기능 : SAGA 솔버를 사용한 l1 페널티 ( '다항식'+ L1 허용)</target>
        </trans-unit>
        <trans-unit id="69d687c70a1657bfe591a19056b06b9f07dd4b5e" translate="yes" xml:space="preserve">
          <source>New in version 0.19: parameter &lt;em&gt;average&lt;/em&gt; to use weights averaging in SGD</source>
          <target state="translated">버전 0.19의 새로운 기능 : 파라미터 &lt;em&gt;평균&lt;/em&gt; SGD에서 가중치를 평균화하는</target>
        </trans-unit>
        <trans-unit id="e6570e8764c255a027de40e9e3eb2d1c722d495c" translate="yes" xml:space="preserve">
          <source>New in version 0.20.</source>
          <target state="translated">버전 0.20의 새로운 기능.</target>
        </trans-unit>
        <trans-unit id="6c617d40b81d2b01909932fc5a27e561e533ba93" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;SimpleImputer&lt;/code&gt; replaces the previous &lt;code&gt;sklearn.preprocessing.Imputer&lt;/code&gt; estimator which is now removed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92da9b59ee8f1aee40e76bd7e7f9a69e15158836" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;behaviour&lt;/code&gt; is added in 0.20 for back-compatibility purpose.</source>
          <target state="translated">버전 0.20의 새로운 기능 : 이전 버전 과의 호환성을 위해 &lt;code&gt;behaviour&lt;/code&gt; 이 0.20에 추가되었습니다.</target>
        </trans-unit>
        <trans-unit id="89ff3bd96af64e1a70d0744f65ccf966040b095d" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">버전 0.20의 새로운 기능 : &lt;code&gt;force_all_finite&lt;/code&gt; 는 &lt;code&gt;'allow-nan'&lt;/code&gt; 문자열을 허용합니다 .</target>
        </trans-unit>
        <trans-unit id="fe256f44bbbbc2bd0c867a8e63ec681a6240ed59" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;adaptive&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c29982d75481689af02d31b620cd5f76c827f04a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;early_stopping&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="383b2bc5e9967f26e0b4b20cd947fb1316e6616a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;n_iter_no_change&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5896f9ff4dd021dab607afd66ed0a221195a00c5" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;validation_fraction&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="646e72bed85791f997c7991fa5af303d05883478" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added the &amp;lsquo;single&amp;rsquo; option</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1468919e56b56c4ded7ab6dba66d158a1002d5be" translate="yes" xml:space="preserve">
          <source>New in version 0.20: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to BayesianRidge.</source>
          <target state="translated">버전 0.20의 새로운 기능 : 매개 변수 &lt;em&gt;sample_weight&lt;/em&gt; 는 BayesianRidge를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="7c256855a0d81868bca650e3f1d5676a1f0ae5da" translate="yes" xml:space="preserve">
          <source>New in version 0.20: strategy=&amp;rdquo;constant&amp;rdquo; for fixed value imputation.</source>
          <target state="translated">버전 0.20의 새로운 기능 : 고정 값 대치에 대한 전략 = &quot;일정한&quot;.</target>
        </trans-unit>
        <trans-unit id="6371a324a0f9b28d52fcce7a713bd8acc7b321e0" translate="yes" xml:space="preserve">
          <source>New in version 0.21.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28bbafe212871917c1ae23be319d534da486ed2c" translate="yes" xml:space="preserve">
          <source>New in version 0.21: &lt;code&gt;n_connected_components_&lt;/code&gt; was added to replace &lt;code&gt;n_components_&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8b989c4868c5bd7f2040240742c5509b13b840" translate="yes" xml:space="preserve">
          <source>New in version 0.22.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69cdaee84ba92c12f0c1ee7d5ea78cec5fb3129d" translate="yes" xml:space="preserve">
          <source>New in version 0.22: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fed47321851e7513d73e52b53e589471c95ed14" translate="yes" xml:space="preserve">
          <source>New in version 0.23.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3131ca254bc6ccc53b97a121b7c7087eb729d9ad" translate="yes" xml:space="preserve">
          <source>New in version 0.23: this parameter was previously hardcoded as 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c41c95cafce09fc00bdb02d31fa4b185ade21eb" translate="yes" xml:space="preserve">
          <source>New in version 0.5.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48e2833e629833b7582fc86a591171cccb4a2aa1" translate="yes" xml:space="preserve">
          <source>New in version 0.8.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0798e2f31cc8f6f05534a395874ff516c037ea2" translate="yes" xml:space="preserve">
          <source>New in version 0.9.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dcb523c8b35ef7bba188a1b72a37583d73585c0" translate="yes" xml:space="preserve">
          <source>New in version 1.7.0.</source>
          <target state="translated">버전 1.7.0의 새로운 기능</target>
        </trans-unit>
        <trans-unit id="382bf23b05f69ca7724427a219843811ca7f86bf" translate="yes" xml:space="preserve">
          <source>New plotting API</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58fbaea601eebe84b9d8f8508a33c9a4b3025541" translate="yes" xml:space="preserve">
          <source>New to Scientific Python?</source>
          <target state="translated">Scientific Python을 처음 사용하십니까?</target>
        </trans-unit>
        <trans-unit id="9f6a58e9ea6f2ce3d4a15836e22f7c6b8aed6e50" translate="yes" xml:space="preserve">
          <source>Next we create 10 classifier chains. Each classifier chain contains a logistic regression model for each of the 14 labels. The models in each chain are ordered randomly. In addition to the 103 features in the dataset, each model gets the predictions of the preceding models in the chain as features (note that by default at training time each model gets the true labels as features). These additional features allow each chain to exploit correlations among the classes. The Jaccard similarity score for each chain tends to be greater than that of the set independent logistic models.</source>
          <target state="translated">다음으로 10 개의 분류기 체인을 만듭니다. 각 분류 자 ​​체인에는 14 개 레이블 각각에 대한 로지스틱 회귀 모델이 포함됩니다. 각 체인의 모델은 무작위로 주문됩니다. 데이터 세트의 103 개 기능 외에도 각 모델은 체인에서 이전 모델의 예측을 기능으로 가져옵니다 (기본적으로 훈련시 각 모델은 실제 레이블을 기능으로 가져옵니다). 이러한 추가 기능을 통해 각 체인은 클래스 간의 상관 관계를 활용할 수 있습니다. 각 체인의 Jaccard 유사성 점수는 설정된 독립 물류 모델의 Jaccard 유사성 점수보다 큰 경향이 있습니다.</target>
        </trans-unit>
        <trans-unit id="d753c88a8af3a7221324f1f115e965ef2e7003fc" translate="yes" xml:space="preserve">
          <source>Next we fit the Poisson regressor on the target variable. We set the regularization strength &lt;code&gt;alpha&lt;/code&gt; to approximately 1e-6 over number of samples (i.e. &lt;code&gt;1e-12&lt;/code&gt;) in order to mimic the Ridge regressor whose L2 penalty term scales differently with the number of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ae340c010af24c68842322aa72c1a3f11d7dacf" translate="yes" xml:space="preserve">
          <source>Next, let&amp;rsquo;s compare the accuracy of &lt;code&gt;SVC&lt;/code&gt; and &lt;code&gt;most_frequent&lt;/code&gt;:</source>
          <target state="translated">다음으로 &lt;code&gt;SVC&lt;/code&gt; 와 &lt;code&gt;most_frequent&lt;/code&gt; 의 정확도를 비교해 보겠습니다 .</target>
        </trans-unit>
        <trans-unit id="c6c64a04d2e12fed93b98d6c01ec2531f747d55c" translate="yes" xml:space="preserve">
          <source>Next, we manually pick a threshold by visual inspection of the dendrogram to group our features into clusters and choose a feature from each cluster to keep, select those features from our dataset, and train a new random forest. The test accuracy of the new random forest did not change much compared to the random forest trained on the complete dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60abf98c19bebf728f6b765cf9ba6a0bbf19fa43" translate="yes" xml:space="preserve">
          <source>Next, we plot the ROC curve with a single call to &lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt;&lt;code&gt;sklearn.metrics.plot_roc_curve&lt;/code&gt;&lt;/a&gt;. The returned &lt;code&gt;svc_disp&lt;/code&gt; object allows us to continue using the already computed ROC curve for the SVC in future plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e2a2edce50f17d924871b306d2618d9b3454954" translate="yes" xml:space="preserve">
          <source>Next, we plot the tree based feature importance and the permutation importance. The permutation importance plot shows that permuting a feature drops the accuracy by at most &lt;code&gt;0.012&lt;/code&gt;, which would suggest that none of the features are important. This is in contradiction with the high test accuracy computed above: some feature must be important. The permutation importance is calculated on the training set to show how much the model relies on each feature during training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4301caa6a55515044571ecdaaa2f60c152ef3c59" translate="yes" xml:space="preserve">
          <source>Next, we train a decision tree using the effective alphas. The last value in &lt;code&gt;ccp_alphas&lt;/code&gt; is the alpha value that prunes the whole tree, leaving the tree, &lt;code&gt;clfs[-1]&lt;/code&gt;, with one node.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19146388ab896a5ab7b0d5fd5a0ecbdbda416e05" translate="yes" xml:space="preserve">
          <source>Next, we will split our dataset to use 90% for training and leave the rest for testing. We will also set the regression model parameters. You can play with these parameters to see how the results change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cedfa60674e3afd543975ecc551b601711fc3043" translate="yes" xml:space="preserve">
          <source>Nick Street</source>
          <target state="translated">닉 스트리트</target>
        </trans-unit>
        <trans-unit id="91b4478e43e149a2b1b071a76d13f7593530f726" translate="yes" xml:space="preserve">
          <source>No measurement errors, only modelling errors (fitting a sine with a polynomial)</source>
          <target state="translated">측정 오차 없음, 모델링 오차 만 (사인을 다항식에 맞추기)</target>
        </trans-unit>
        <trans-unit id="53e801c8ef7a5f95a28c0516586238c464a24031" translate="yes" xml:space="preserve">
          <source>No penalty (&amp;lsquo;none&amp;rsquo;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea249cedbd757dbfa8a8d6da523734c90b706a5c" translate="yes" xml:space="preserve">
          <source>No-op.</source>
          <target state="translated">No-op.</target>
        </trans-unit>
        <trans-unit id="91eb5693ecb00a7deb087fb78e26bb4414167d8c" translate="yes" xml:space="preserve">
          <source>Noisy (non informative) features are added to the iris data and univariate feature selection is applied. For each feature, we plot the p-values for the univariate feature selection and the corresponding weights of an SVM. We can see that univariate feature selection selects the informative features and that these have larger SVM weights.</source>
          <target state="translated">노이즈 (비 정보) 기능이 홍채 데이터에 추가되고 일 변량 기능 선택이 적용됩니다. 각 피처에 대해 일 변량 피처 선택에 대한 p- 값과 SVM의 해당 가중치를 플로팅합니다. 일 변량 기능 선택이 유익한 기능을 선택하고 SVM 가중치가 더 큰 것을 알 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7bfbed76958c0127f9523f9a22b3af54ca060586" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{jk}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79474361fd46a8f4ede8053ea7e6b01fe3e41cb6" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{kl}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">비 메트릭 &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; 는 데이터의 안수에 중점을 둡니다. \ (S_ {ij} &amp;lt;S_ {kl} \) 인 경우 임베드시 \ (d_ {ij} &amp;lt;d_ {jk} \)가 적용됩니다. 이를 강제하는 간단한 알고리즘은 \ (S_ {ij} \)에 \ (d_ {ij} \)의 단조 회귀를 사용하여 동일한 순서로 불일치 \ (\ hat {d} _ {ij} \)를 생성하는 것입니다 \ (S_ {ij} \)로</target>
        </trans-unit>
        <trans-unit id="cde06657a13db59e2826469e9066556199cf0756" translate="yes" xml:space="preserve">
          <source>Non-Negative Matrix Factorization (NMF)</source>
          <target state="translated">비음 수 행렬 분해 (NMF)</target>
        </trans-unit>
        <trans-unit id="68976e33a3c8d43b10cc9525f441a8468ba55fa6" translate="yes" xml:space="preserve">
          <source>Non-adjusted measures such as the V-Measure show a dependency between the number of clusters and the number of samples: the mean V-Measure of random labeling increases significantly as the number of clusters is closer to the total number of samples used to compute the measure.</source>
          <target state="translated">V-Measure와 같이 조정되지 않은 측정 값은 군집 수와 샘플 수 사이의 종속성을 나타냅니다. 무작위 레이블링의 평균 V- 측정 값은 군집 수가 계산에 사용 된 총 샘플 수에 가까워 질수록 크게 증가합니다. 측정.</target>
        </trans-unit>
        <trans-unit id="f88076515287321d1c6a383215ea60241a35e283" translate="yes" xml:space="preserve">
          <source>Non-categorical features are always stacked to the right of the matrix.</source>
          <target state="translated">비범 주형 특징은 항상 행렬의 오른쪽에 쌓입니다.</target>
        </trans-unit>
        <trans-unit id="24a06b494b2c3f21a83a9f0f9fdd0eb49c7e8dca" translate="yes" xml:space="preserve">
          <source>Non-deterministic iterable over random candidate combinations for hyper- parameter search. If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">하이퍼 파라미터 검색을위한 랜덤 후보 조합에 대해 비 결정적 반복 가능. 모든 매개 변수가 목록으로 표시되면 교체하지 않은 샘플링이 수행됩니다. 분포로 적어도 하나의 매개 변수가 제공되면 대체 샘플링이 사용됩니다. 연속 모수에 연속 분포를 사용하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="aed22ef611faa3f82d0b12f8491e5be1b5315c9c" translate="yes" xml:space="preserve">
          <source>Non-flat geometry clustering is useful when the clusters have a specific shape, i.e. a non-flat manifold, and the standard euclidean distance is not the right metric. This case arises in the two top rows of the figure above.</source>
          <target state="translated">비평면 지오메트리 클러스터링은 클러스터가 특정 모양, 즉 비평면 매니 폴드이고 표준 유클리드 거리가 올바른 메트릭이 아닌 경우에 유용합니다. 이 경우는 위 그림의 맨 위 두 행에서 발생합니다.</target>
        </trans-unit>
        <trans-unit id="d81a98cb7a8247dec56f2cf029b08c2754ab68be" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes</source>
          <target state="translated">평평하지 않은 형상, 고르지 않은 클러스터 크기</target>
        </trans-unit>
        <trans-unit id="e75d67cb225b885154dd48c75a213bc3e9636016" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes, variable cluster density</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b7727887cb8285fcb9cde529e76207a2b5daf47" translate="yes" xml:space="preserve">
          <source>Non-linear SVM</source>
          <target state="translated">비선형 SVM</target>
        </trans-unit>
        <trans-unit id="71ce2ef9edaad67f892b761574c731b5860fa36a" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through Isometric Mapping</source>
          <target state="translated">아이소 메트릭 매핑을 통한 비선형 차원 축소</target>
        </trans-unit>
        <trans-unit id="ca7d812e2ac6b7f89b19c50d5270fc422c0be019" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through the use of kernels (see &lt;a href=&quot;../metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt;).</source>
          <target state="translated">커널 사용을 통한 비선형 차원 감소 ( &lt;a href=&quot;../metrics#metrics&quot;&gt;쌍별 메트릭, 선호도 및 커널 참조&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="69451865a7cd1607229864b3445a0d944d36c962" translate="yes" xml:space="preserve">
          <source>Non-negative Matrix Factorization is applied with two different objective functions: the Frobenius norm, and the generalized Kullback-Leibler divergence. The latter is equivalent to Probabilistic Latent Semantic Indexing.</source>
          <target state="translated">음이 아닌 행렬 인수 분해는 Frobenius 표준과 일반화 된 Kullback-Leibler 발산이라는 두 가지 다른 목적 함수로 적용됩니다. 후자는 확률 론적 시맨틱 인덱싱과 동일하다.</target>
        </trans-unit>
        <trans-unit id="049d9a61285421f1af788bdccc4c4d917a5eaaf1" translate="yes" xml:space="preserve">
          <source>Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.</source>
          <target state="translated">음이 아닌 정규화가 공분산의 대각선에 추가되었습니다. 공분산 행렬이 모두 양수임을 보장 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="e703a00863d9d81a02bf7dd7a3e8359867bf5db3" translate="yes" xml:space="preserve">
          <source>Non-negativity: d(x, y) &amp;gt;= 0</source>
          <target state="translated">비 음성 : d (x, y)&amp;gt; = 0</target>
        </trans-unit>
        <trans-unit id="8ae68d0948137da9bc3c21e9e27af7e4326ecb8c" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that assign all classes members to the same clusters are still complete:</source>
          <target state="translated">모든 클래스 멤버를 동일한 클러스터에 지정하는 완벽하지 않은 레이블링은 여전히 ​​완료되었습니다.</target>
        </trans-unit>
        <trans-unit id="3eebc1d955c5491410d251396ee4489d9155e3cb" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that further split classes into more clusters can be perfectly homogeneous:</source>
          <target state="translated">클래스를 더 많은 클러스터로 더 분할하는 완벽하지 않은 레이블링은 완전히 균질 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="cc144a8b86207cd903656d8b31d75d721fe9dfb7" translate="yes" xml:space="preserve">
          <source>None : retain all features (the default).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff2ddb49167696f5a698e9f0e7cdd839b8eb8d6f" translate="yes" xml:space="preserve">
          <source>None : when any outlier is detected, ValueError will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7d85d18152a49d1da74509ce25fde6fe11019f7" translate="yes" xml:space="preserve">
          <source>None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs</source>
          <target state="translated">이 경우 모든 작업이 즉시 생성되어 생성됩니다. 주문형 작업 생성으로 인한 지연을 피하기 위해 가볍고 빠르게 실행되는 작업에 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="bbd7e8e517d8f43bda3aa20760641b5d7e8f9cfa" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross validation,</source>
          <target state="translated">기본 3 중 교차 검증을 사용하려면</target>
        </trans-unit>
        <trans-unit id="888271bd46afcca7669b4e3985d515e3c7e7f9d8" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross-validation,</source>
          <target state="translated">기본 3 중 교차 검증을 사용하려면</target>
        </trans-unit>
        <trans-unit id="13182ccf32b1d9cf4c4c76a99a35a2cf619a1e90" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross validation,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93be41b6686f4cc42a91be2da8610759134def66" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross-validation,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="701ee91f692f57554848e1c6f0edff54e4f7d839" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation</source>
          <target state="translated">효율적인 Leave-One-Out 교차 검증을 사용하려면</target>
        </trans-unit>
        <trans-unit id="d7a547edfb07309939d3c23d0b3c605eac4c310a" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation (also known as Generalized Cross-Validation).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb8094c10799533f02930dac24b80933c23d4beb" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt; n_features, otherwise &amp;lsquo;random&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac08cb5e83064548a9a5dbf3f70202653e682537" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt;= min(n_samples, n_features),</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64b167835d86e0f7a116b1ea8c9009b09567d9bf" translate="yes" xml:space="preserve">
          <source>None: no shrinkage (default).</source>
          <target state="translated">없음 : 수축 없음 (기본값).</target>
        </trans-unit>
        <trans-unit id="147e773e8ccd784cf7c8200779acc5978ecfc7ee" translate="yes" xml:space="preserve">
          <source>Nonflavanoid Phenols:</source>
          <target state="translated">비 플라 바 노이드 페놀 :</target>
        </trans-unit>
        <trans-unit id="906dd4b97159051d3691e718b04ffdc7a18ebb83" translate="yes" xml:space="preserve">
          <source>Nonflavanoid phenols</source>
          <target state="translated">비 플라 바 노이드 페놀</target>
        </trans-unit>
        <trans-unit id="c5cf58c1ab6a436b96c0b6790ce2675b3d6917ee" translate="yes" xml:space="preserve">
          <source>Norm used to normalize term vectors. None for no normalization.</source>
          <target state="translated">용어 벡터를 정규화하는 데 사용되는 규범. 정규화가없는 경우 없음</target>
        </trans-unit>
        <trans-unit id="45e118d0563ea8581f830f46e85b60ae714faae4" translate="yes" xml:space="preserve">
          <source>Normal</source>
          <target state="translated">Normal</target>
        </trans-unit>
        <trans-unit id="baeabcda0198bd70ffaabb333ee49b38a8e0ee34" translate="yes" xml:space="preserve">
          <source>Normal and Shrinkage Linear Discriminant Analysis for classification</source>
          <target state="translated">분류를위한 정규 및 수축 선형 판별 분석</target>
        </trans-unit>
        <trans-unit id="1c651aee92e671db7fa9048c6cdacbd12ea197da" translate="yes" xml:space="preserve">
          <source>Normalization matrix needed for embedding. Square root of the kernel matrix on &lt;code&gt;components_&lt;/code&gt;.</source>
          <target state="translated">임베딩에 필요한 정규화 행렬 &lt;code&gt;components_&lt;/code&gt; 에서 커널 매트릭스의 제곱근 .</target>
        </trans-unit>
        <trans-unit id="b2dd009a742549bee9ad100542b0f67ba3a05708" translate="yes" xml:space="preserve">
          <source>Normalize samples individually to unit norm.</source>
          <target state="translated">단위 규범에 따라 개별적으로 샘플을 표준화합니다.</target>
        </trans-unit>
        <trans-unit id="1cc78071dce653cdb1a895ced93da41b36798ab2" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information</source>
          <target state="translated">정규화 된 상호 정보</target>
        </trans-unit>
        <trans-unit id="6d15c4ae0d04e936f901929872b9ad476ca9800b" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information (NMI) is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by some generalized mean of &lt;code&gt;H(labels_true)&lt;/code&gt; and &lt;code&gt;H(labels_pred))&lt;/code&gt;, defined by the &lt;code&gt;average_method&lt;/code&gt;.</source>
          <target state="translated">정규화 된 상호 정보 (NMI)는 상호 정보가없는 0과 1 (완벽한 상관) 사이의 결과를 스케일링하기 위해 상호 정보 (MI) 점수의 정규화입니다. 이 함수에서 상호 정보는 &lt;code&gt;average_method&lt;/code&gt; 에 의해 정의 된 &lt;code&gt;H(labels_true)&lt;/code&gt; 및 &lt;code&gt;H(labels_pred))&lt;/code&gt; 의 일반화 된 평균으로 정규화됩니다 .</target>
        </trans-unit>
        <trans-unit id="2009d38e6ab058cf38d5f44a4aa1fda0316b3372" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information between two clusterings.</source>
          <target state="translated">두 군집 간의 정규화 된 상호 정보.</target>
        </trans-unit>
        <trans-unit id="4f7979e77b9a0db2d6d4f14823a6b0012cc9a130" translate="yes" xml:space="preserve">
          <source>Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</source>
          <target state="translated">정규화 된 컷 및 이미지 분할, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bcdc09e5b38e3433007fe04c41bf1718c142c846" translate="yes" xml:space="preserve">
          <source>Normalized input X.</source>
          <target state="translated">정규화 된 입력 X.</target>
        </trans-unit>
        <trans-unit id="cf0305ad6a5172727382b32897870cffde3ce433" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels</source>
          <target state="translated">클래스 레이블에 대한 정규화 된 확률 분포</target>
        </trans-unit>
        <trans-unit id="53f158b7f3551b0f974a1547fdea15ef3000e7be" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dd51ff507e0ed7c736dd049baf65846cc243ec4" translate="yes" xml:space="preserve">
          <source>Normalized total reduction of criteria by feature (Gini importance).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4b126cd68b1eba9b799b0ffccc1898e8bfe924f" translate="yes" xml:space="preserve">
          <source>Normalizer</source>
          <target state="translated">Normalizer</target>
        </trans-unit>
        <trans-unit id="2b3ec4d083535b907de33251ab28d9b72b55d74b" translate="yes" xml:space="preserve">
          <source>Normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. If None, confusion matrix will not be normalized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a19366221588f526c166820c530dd8f2268ea2b7" translate="yes" xml:space="preserve">
          <source>Not all models benefit from optimized BLAS and Lapack implementations. For instance models based on (randomized) decision trees typically do not rely on BLAS calls in their inner loops, nor do kernel SVMs (&lt;code&gt;SVC&lt;/code&gt;, &lt;code&gt;SVR&lt;/code&gt;, &lt;code&gt;NuSVC&lt;/code&gt;, &lt;code&gt;NuSVR&lt;/code&gt;). On the other hand a linear model implemented with a BLAS DGEMM call (via &lt;code&gt;numpy.dot&lt;/code&gt;) will typically benefit hugely from a tuned BLAS implementation and lead to orders of magnitude speedup over a non-optimized BLAS.</source>
          <target state="translated">모든 모델이 최적화 된 BLAS 및 Lapack 구현의 혜택을받는 것은 아닙니다. 예를 들어 (무작위 화) 의사 결정 트리를 기반으로하는 모델은 일반적으로 내부 루프의 BLAS 호출에 의존하지 않으며 커널 SVM ( &lt;code&gt;SVC&lt;/code&gt; , &lt;code&gt;SVR&lt;/code&gt; , &lt;code&gt;NuSVC&lt;/code&gt; , &lt;code&gt;NuSVR&lt;/code&gt; ) 도 사용하지 않습니다 . 반면에 numpy.dot를 통해 BLAS DGEMM 호출로 구현 된 선형 모델 은 일반적으로 튜닝 된 BLAS 구현에서 큰 이점을 얻을 수 있으며 최적화되지 않은 BLAS보다 속도가 &lt;code&gt;numpy.dot&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d1a17af19f5388af9d6596cc0ea7dbb1d739e255" translate="yes" xml:space="preserve">
          <source>Not available</source>
          <target state="translated">사용 불가</target>
        </trans-unit>
        <trans-unit id="2f1306ffef95e5ddbb8f4b2f3a60c6ede1c9a1f3" translate="yes" xml:space="preserve">
          <source>Not scalable</source>
          <target state="translated">확장 불가능</target>
        </trans-unit>
        <trans-unit id="6671bcf801635373715efa03216b0f9d13f34c22" translate="yes" xml:space="preserve">
          <source>Not scalable with &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; 로 확장 불가능</target>
        </trans-unit>
        <trans-unit id="d70eb56b501fa2ef808df1c818502bbb5b800d19" translate="yes" xml:space="preserve">
          <source>Not scalable with n_samples</source>
          <target state="translated">n_samples로 확장 불가능</target>
        </trans-unit>
        <trans-unit id="5f0f2378acb52b70e08107dc0bdd42ae2edf4fdf" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistence purpose.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c8ec850c7c26d11c7ae99e5fae0ce11ac404b3f" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistency by convention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abfeb2bc66d46ae118c694d4f663b42a0b277b39" translate="yes" xml:space="preserve">
          <source>Not used, present here for API consistency by convention.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f8740a7ea28a56477d25ad1aaaf52d864b49a7d" translate="yes" xml:space="preserve">
          <source>NotFittedError</source>
          <target state="translated">NotFittedError</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="14ba06ae5f3993adde2848620bcf508016c9c617" translate="yes" xml:space="preserve">
          <source>Note : Laplacian Eigenmaps is the actual algorithm implemented here.</source>
          <target state="translated">참고 : Laplacian Eigenmaps는 여기서 구현 된 실제 알고리즘입니다.</target>
        </trans-unit>
        <trans-unit id="21546711de316cf946ba53a498f41ae0550616cc" translate="yes" xml:space="preserve">
          <source>Note how some use the group/class information while others do not.</source>
          <target state="translated">어떤 사람들은 그룹 / 클래스 정보를 사용하는 반면 다른 사람들은 그렇지 않은 방법에 유의하십시오.</target>
        </trans-unit>
        <trans-unit id="c3c271844b997675d3bb1a8d39599227fbe7b490" translate="yes" xml:space="preserve">
          <source>Note how the optimal value of alpha varies for each fold. This illustrates why nested-cross validation is necessary when trying to evaluate the performance of a method for which a parameter is chosen by cross-validation: this choice of parameter may not be optimal for unseen data.</source>
          <target state="translated">최적의 알파 값이 각 접기마다 어떻게 다른지 확인하십시오. 이는 교차 검증으로 매개 변수를 선택하는 방법의 성능을 평가할 때 중첩 교차 검증이 필요한 이유를 보여줍니다.이 매개 변수 선택은 보이지 않는 데이터에 적합하지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="92e53ea7bdcc226c7bc1da5197dd56da468b26d1" translate="yes" xml:space="preserve">
          <source>Note on inappropriate usage of cross_val_predict</source>
          <target state="translated">cross_val_predict의 부적절한 사용에 대한 참고 사항</target>
        </trans-unit>
        <trans-unit id="b437e168efe2a06e08f52a3ad3a931f217ecf431" translate="yes" xml:space="preserve">
          <source>Note on notations presented in the graphical model above, which can be found in Hoffman et al. (2013):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="029f2db65bc50c936edb77149f903f8d03abd995" translate="yes" xml:space="preserve">
          <source>Note on the lookup process: depending on the type of name_or_id, will choose between integer id lookup or metadata name lookup by looking at the unzipped archives and metadata file.</source>
          <target state="translated">조회 프로세스에 대한 참고 사항 : name_or_id의 유형에 따라 압축 해제 된 아카이브 및 메타 데이터 파일을보고 정수 ID 조회 또는 메타 데이터 이름 조회 중에서 선택합니다.</target>
        </trans-unit>
        <trans-unit id="637677b94f16fb377d9bcfbae4602956aad7da33" translate="yes" xml:space="preserve">
          <source>Note that &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</source>
          <target state="translated">'sag'및 'saga'빠른 수렴은 대략 동일한 규모의 기능에서만 보장됩니다. sklearn.preprocessing에서 스케일러로 데이터를 사전 처리 할 수 ​​있습니다.</target>
        </trans-unit>
        <trans-unit id="92f3fcd7326295f6a74b7d0528bb22c0cf404ba4" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsregressor#sklearn.neighbors.KNeighborsRegressor&quot;&gt;&lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt;&lt;/a&gt; is different from KNN imputation, which learns from samples with missing values by using a distance metric that accounts for missing values, rather than imputing them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfc6f56d0d9af5825aa3c5bc1de0fcc87a2bde36" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; calculates unadjusted R&amp;sup2; without correcting for bias in sample variance of y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb2d865fbf24560bc423d4932883d3877000a02a" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; does not support &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods by default but only a &lt;code&gt;fit_predict&lt;/code&gt; method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">참고 &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; 가&lt;/a&gt; 지원하지 않는 &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; 및 &lt;code&gt;score_samples&lt;/code&gt; 기본하지만 만에 의한 방법 &lt;code&gt;fit_predict&lt;/code&gt; 의 이 추정 원래 특이 검출에 적용 할 예정되면서 방법. 훈련 샘플의 비정상 점수는 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 속성을 통해 액세스 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="c2b0ede00caa9f24f249766b854d734ce8a77594" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;estimators_&lt;/code&gt; are fitted on the full &lt;code&gt;X&lt;/code&gt; while &lt;code&gt;final_estimator_&lt;/code&gt; is trained using cross-validated predictions of the base estimators using &lt;code&gt;cross_val_predict&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cc23e915eab7d76b355d3d788a42c200a9cfa75" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;fit_predict&lt;/code&gt; is not available in this case.</source>
          <target state="translated">참고 &lt;code&gt;fit_predict&lt;/code&gt; 은 이 경우 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="a64277fe0445c7a49bb63f1b3128c36db8f44687" translate="yes" xml:space="preserve">
          <source>Note that &lt;strong&gt;early-stopping is enabled by default if the number of samples is larger than 10,000&lt;/strong&gt;. The early-stopping behaviour is controlled via the &lt;code&gt;early-stopping&lt;/code&gt;, &lt;code&gt;scoring&lt;/code&gt;, &lt;code&gt;validation_fraction&lt;/code&gt;, &lt;code&gt;n_iter_no_change&lt;/code&gt;, and &lt;code&gt;tol&lt;/code&gt; parameters. It is possible to early-stop using an arbitrary &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scorer&quot;&gt;scorer&lt;/a&gt;, or just the training or validation loss. Note that for technical reasons, using a scorer is significantly slower than using the loss. By default, early-stopping is performed if there are at least 10,000 samples in the training set, using the validation loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05da1e73517821e307ab23620f26a2cb5cf58320" translate="yes" xml:space="preserve">
          <source>Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.</source>
          <target state="translated">Sparse PCA 구성 요소 직교성은 PCA에서와 같이 시행되지 않으므로 간단한 선형 투영을 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="6d11171b334a15c9f3a0ed71d47a8e76e15de782" translate="yes" xml:space="preserve">
          <source>Note that a call to the &lt;code&gt;transform&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; is not allowed to change the number of samples. Therefore multiple imputations cannot be achieved by a single call to &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38919ec8aa75d45b22406b99670380fbc01ee90e" translate="yes" xml:space="preserve">
          <source>Note that all classifiers handling multioutput-multiclass (also known as multitask classification) tasks, support the multilabel classification task as a special case. Multitask classification is similar to the multioutput classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a04205581b19a745020f7a71bf7734034b648ca" translate="yes" xml:space="preserve">
          <source>Note that backwards compatibility may not be supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a36ac6808e625c8a29705bcc1d1fb6cf63760b8" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space.</source>
          <target state="translated">SciPy 0.16 이전에는 &lt;code&gt;scipy.stats.distributions&lt;/code&gt; 가 사용자 정의 RNG 인스턴스를 허용하지 않으며 항상 &lt;code&gt;numpy.random&lt;/code&gt; 의 싱글 톤 RNG를 사용합니다 . 따라서 &lt;code&gt;random_state&lt;/code&gt; 를 설정 하면 &lt;code&gt;scipy.stats&lt;/code&gt; 분포를 사용하여 매개 변수 검색 공간을 정의 할 때마다 결정적인 반복이 보장되지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="9a716693e5778e1463e7644515aedc4c9b2a1b82" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space. Deterministic behavior is however guaranteed from SciPy 0.16 onwards.</source>
          <target state="translated">SciPy 0.16 이전에는 &lt;code&gt;scipy.stats.distributions&lt;/code&gt; 가 사용자 정의 RNG 인스턴스를 허용하지 않으며 항상 &lt;code&gt;numpy.random&lt;/code&gt; 의 싱글 톤 RNG를 사용합니다 . 따라서 &lt;code&gt;random_state&lt;/code&gt; 를 설정 하면 &lt;code&gt;scipy.stats&lt;/code&gt; 분포를 사용하여 매개 변수 검색 공간을 정의 할 때마다 결정적인 반복이 보장되지 않습니다 . 그러나 SciPy 0.16부터는 결정적인 동작이 보장됩니다.</target>
        </trans-unit>
        <trans-unit id="8803233984e598253564c68adac3c470cc868526" translate="yes" xml:space="preserve">
          <source>Note that even for a classification task, the \(h_m\) sub-estimator is still a regressor, not a classifier. This is because the sub-estimators are trained to predict (negative) &lt;em&gt;gradients&lt;/em&gt;, which are always continuous quantities.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45e5cb26ef2b019b9c0f33d27cd0fca50cc9bb8f" translate="yes" xml:space="preserve">
          <source>Note that for any single value of &lt;code&gt;eps&lt;/code&gt;, DBSCAN will tend to have a shorter run time than OPTICS; however, for repeated runs at varying &lt;code&gt;eps&lt;/code&gt; values, a single run of OPTICS may require less cumulative runtime than DBSCAN. It is also important to note that OPTICS&amp;rsquo; output is close to DBSCAN&amp;rsquo;s only if &lt;code&gt;eps&lt;/code&gt; and &lt;code&gt;max_eps&lt;/code&gt; are close.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c441ea193159e43e5ae4f2f43b7cd455bbc50a0" translate="yes" xml:space="preserve">
          <source>Note that for floating-point input, the mean is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for &lt;code&gt;float32&lt;/code&gt; (see example below). Specifying a higher-precision accumulator using the &lt;code&gt;dtype&lt;/code&gt; keyword can alleviate this issue.</source>
          <target state="translated">부동 소수점 입력의 경우 평균은 입력과 동일한 정밀도를 사용하여 계산됩니다. 입력 데이터에 따라, 특히 &lt;code&gt;float32&lt;/code&gt; 의 경우 결과가 정확하지 않을 수 있습니다 (아래 예 참조). &lt;code&gt;dtype&lt;/code&gt; 키워드를 사용하여 고정밀 누산기를 지정 하면이 문제를 완화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="1c1b3dcae0a3cdb049378b61a52e8a6e218b843e" translate="yes" xml:space="preserve">
          <source>Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].</source>
          <target state="translated">다중 출력 (다중 레이블 포함)의 경우 가중치는 모든 열의 각 클래스에 대해 자체 dict로 정의해야합니다. 예를 들어, 4 클래스 다중 레이블 분류 가중치의 경우 [{0 : 1, 1 : 1}, {0 : 1, 1 : 5}, {0 : 1, 1 : 1}, {0 : 1, 1 :이어야합니다. [{1 : 1}, {2 : 5}, {3 : 1}, {4 : 1}] 대신 1}].</target>
        </trans-unit>
        <trans-unit id="7f057f4a3cfb222efbfc3fdf93e59924824aafce" translate="yes" xml:space="preserve">
          <source>Note that if features have very different scaling or statistical properties, &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; may not be able to capture the links between related features. Using a &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; can be useful in these settings.</source>
          <target state="translated">기능의 스케일링 또는 통계 속성이 매우 다른 경우 &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt; &lt;/a&gt; 이 관련 기능 간의 링크를 캡처하지 못할 수 있습니다. &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt; 사용 .이 설정에서 StandardScaler 가 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="daa34c655040f11fbac2193226735416d5ff6724" translate="yes" xml:space="preserve">
          <source>Note that if the values of your similarity matrix are not well distributed, e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable. In which case it is advised to apply a transformation to the entries of the matrix. For instance, in the case of a signed distance matrix, is common to apply a heat kernel:</source>
          <target state="translated">유사도 행렬의 값이 예를 들어 음수 값이나 유사성이 아닌 거리 행렬로 잘 분포되어 있지 않은 경우 스펙트럼 문제는 특이하며 문제를 해결할 수 없습니다. 이 경우 행렬 항목에 변환을 적용하는 것이 좋습니다. 예를 들어 부호있는 거리 행렬의 경우 히트 커널을 적용하는 것이 일반적입니다.</target>
        </trans-unit>
        <trans-unit id="82c5d12dd2770bc5d00d9e0fd296f522b36a2aec" translate="yes" xml:space="preserve">
          <source>Note that in binary classification, recall of the positive class is also known as &amp;ldquo;sensitivity&amp;rdquo;; recall of the negative class is &amp;ldquo;specificity&amp;rdquo;.</source>
          <target state="translated">이진 분류에서 포지티브 클래스의 리콜은 &quot;민감도&quot;라고도합니다. 네거티브 클래스의 리콜은 &quot;특성&quot;입니다.</target>
        </trans-unit>
        <trans-unit id="56700fbea0a4382f56515fac76889ee512c8d3cb" translate="yes" xml:space="preserve">
          <source>Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path</source>
          <target state="translated">경우에 따라 Lars 솔버가이 기능을 구현하는 데 훨씬 빠를 수 있습니다. 특히 선형 보간법을 사용하여 lars_path에 의해 출력 된 값 사이의 모델 계수를 검색 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c065b9ad388e273aa3b214ab1297a55e0496eb57" translate="yes" xml:space="preserve">
          <source>Note that in general, robust fitting in high-dimensional setting (large &lt;code&gt;n_features&lt;/code&gt;) is very hard. The robust models here will probably not work in these settings.</source>
          <target state="translated">일반적으로 고차원 설정 (대형 &lt;code&gt;n_features&lt;/code&gt; ) 에서 강력한 피팅 은 매우 어렵습니다. 여기서 강력한 모델은 이러한 설정에서 작동하지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="64011c56ebca18074907020d8d3e99112269576a" translate="yes" xml:space="preserve">
          <source>Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important.</source>
          <target state="translated">실제로 그리드 검색을 사용하여이 여러 가지 매개 변수를 동시에 검색하지는 않지만 가장 중요한 것으로 간주되는 매개 변수 만 선택합니다.</target>
        </trans-unit>
        <trans-unit id="b7d16723edd6b0c8a445c16934e7dfaedb2752ae" translate="yes" xml:space="preserve">
          <source>Note that in the case of &amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo; and &amp;lsquo;euclidean&amp;rsquo; (which are valid scipy.spatial.distance metrics), the scikit-learn implementation will be used, which is faster and has support for sparse matrices (except for &amp;lsquo;cityblock&amp;rsquo;). For a verbose description of the metrics from scikit-learn, see the __doc__ of the sklearn.pairwise.distance_metrics function.</source>
          <target state="translated">'cityblock', 'cosine'및 'euclidean'(유효한 scipy.spatial.distance 메트릭)의 경우 scikit-learn 구현이 사용되며, 더 빠르며 희소 행렬을 지원합니다 ( 'cityblock'). scikit-learn의 메트릭에 대한 자세한 설명은 sklearn.pairwise.distance_metrics 함수의 __doc__을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="81154799705dfac8836df66f3a0269041db1173b" translate="yes" xml:space="preserve">
          <source>Note that in the multilabel case, each sample can have any number of labels. This returns the marginal probability that the given sample has the label in question. For example, it is entirely consistent that two labels both have a 90% probability of applying to a given sample.</source>
          <target state="translated">다중 레이블의 경우 각 샘플에는 여러 개의 레이블이있을 수 있습니다. 주어진 샘플에 해당 레이블이있는 한계 확률을 반환합니다. 예를 들어 두 레이블이 모두 주어진 샘플에 90 %의 확률로 적용된다는 것은 전적으로 일관됩니다.</target>
        </trans-unit>
        <trans-unit id="01d7bf1a38a1f2f757397967cae9b7d66ce2602c" translate="yes" xml:space="preserve">
          <source>Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):</source>
          <target state="translated">이전 모음에서 첫 번째 문서와 마지막 문서는 정확히 같은 단어를 가지므로 동일한 벡터로 인코딩됩니다. 특히 우리는 마지막 문서가 질문 형식이라는 정보를 잃어 버립니다. 일부 현지 주문 정보를 보존하기 위해 1 그램 (개별 단어) 외에 2 그램의 단어를 추출 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="61d12fb0837cc546c2865fefff8f9a5fb5f27798" translate="yes" xml:space="preserve">
          <source>Note that it is also possible to get the output of the stacked &lt;code&gt;estimators&lt;/code&gt; using the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dcb354ad6f05344d318f25389a442779bd42bda" translate="yes" xml:space="preserve">
          <source>Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.</source>
          <target state="translated">이러한 매개 변수의 작은 하위 집합이 모델의 예측 또는 계산 성능에 큰 영향을 줄 수있는 반면 다른 매개 변수는 기본값으로 남겨 둘 수 있습니다. 예상되는 행동을 더 잘 이해하려면 추정기 클래스의 docstring을 읽는 것이 좋습니다. 가능하면 문헌에 동봉 된 참조를 읽으십시오.</target>
        </trans-unit>
        <trans-unit id="e39d258640f71b07567efcd3611fa0f4dfc35df8" translate="yes" xml:space="preserve">
          <source>Note that it is important to check that the model is accurate enough on a test set before plotting the partial dependence since there would be little use in explaining the impact of a given feature on the prediction function of a poor model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38e7c6473cb1417f0189c236d54733065555b837" translate="yes" xml:space="preserve">
          <source>Note that it maximizes both the correlations between the scores and the intra-block variances.</source>
          <target state="translated">점수와 블록 내 분산 간의 상관 관계를 모두 최대화합니다.</target>
        </trans-unit>
        <trans-unit id="7fe083a60697e58d27f138d9ea26d77a87096c53" translate="yes" xml:space="preserve">
          <source>Note that it maximizes only the correlations between the scores.</source>
          <target state="translated">점수 간의 상관 관계 만 최대화합니다.</target>
        </trans-unit>
        <trans-unit id="4ad685eaf7c64ded5f9210b1f3461deac7d47f1a" translate="yes" xml:space="preserve">
          <source>Note that monotonic constraints only constraint the output &amp;ldquo;all else being equal&amp;rdquo;. Indeed, the following relation &lt;strong&gt;is not enforced&lt;/strong&gt; by a positive constraint: \(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2')\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b4460fdb66af9bc149af45e106adc5f1d493bbf" translate="yes" xml:space="preserve">
          <source>Note that noisy data can &amp;ldquo;short-circuit&amp;rdquo; the manifold, in essence acting as a bridge between parts of the manifold that would otherwise be well-separated. Manifold learning on noisy and/or incomplete data is an active area of research.</source>
          <target state="translated">노이즈가 많은 데이터는 매니 폴드의 단락을 유발할 수 있으며, 그 결과 매니 폴드 부분 사이의 브리지 역할을하므로 잘 분리 될 수 있습니다. 시끄 럽거나 불완전한 데이터에 대한 다양한 학습은 활발한 연구 분야입니다.</target>
        </trans-unit>
        <trans-unit id="cf4033d0f4ffad84f5c58c4e0d89634a33d57e14" translate="yes" xml:space="preserve">
          <source>Note that on this tabular dataset, Gradient Boosting Machines are both significantly faster to train and more accurate than neural networks. It is also significantly cheaper to tune their hyperparameters (the default tend to work well while this is not often the case for neural networks).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67d5dd89ca82637aa1c574ab8cabbf8ba39e4cb8" translate="yes" xml:space="preserve">
          <source>Note that pickle has some security and maintainability issues. Please refer to section &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;Model persistence&lt;/a&gt; for more detailed information about model persistence with scikit-learn.</source>
          <target state="translated">피클에는 몇 가지 보안 및 유지 관리 문제가 있습니다. 섹션을 참조하십시오 &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;모델 지속성&lt;/a&gt; scikit - 배우와 모델의 지속성에 대한 더 자세한 정보는.</target>
        </trans-unit>
        <trans-unit id="23cd95765d94c327b5282b4a1fe3e5dffe405a3a" translate="yes" xml:space="preserve">
          <source>Note that polynomial features are used implicitly in &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel methods&lt;/a&gt; (e.g., &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;sklearn.svm.SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt;&lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt;&lt;/a&gt;) when using polynomial &lt;a href=&quot;svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">다항식 기능은 다항식 &lt;a href=&quot;svm#svm-kernels&quot;&gt;커널 함수를&lt;/a&gt; 사용할 때 &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;커널 방법&lt;/a&gt; (예 : &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;sklearn.svm.SVC&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt; &lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt; &lt;/a&gt; ) 에서 암시 적으로 사용 됩니다 .</target>
        </trans-unit>
        <trans-unit id="675c6d53180ed2915c2b59bf4a0a0e8fbac69215" translate="yes" xml:space="preserve">
          <source>Note that providing &lt;code&gt;y&lt;/code&gt; is sufficient to generate the splits and hence &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; may be used as a placeholder for &lt;code&gt;X&lt;/code&gt; instead of actual training data.</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; 를 제공 하면 분할을 생성하기에 충분하므로 &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; 는 실제 학습 데이터 대신 &lt;code&gt;X&lt;/code&gt; 의 자리 표시 자로 사용될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="df4d1f63cde2c26d664594a284ce306040d06cfb" translate="yes" xml:space="preserve">
          <source>Note that shrinkage works only with &amp;lsquo;lsqr&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="translated">수축은 'lsqr'및 'eigen'솔버에서만 작동합니다.</target>
        </trans-unit>
        <trans-unit id="dd7adf0d494ffc5bcd4e70266fd05b000aa00dcc" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format.</source>
          <target state="translated">있습니다 &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; 의&lt;/a&gt; 기능이 진 경우로 제한됩니다. &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; 기능은 바이너리 분류 및 다중 레벨 표시 형식으로 작동합니다.</target>
        </trans-unit>
        <trans-unit id="8d400c4e81cd0336ee43fd779c1c25e212117f34" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format. The &lt;a href=&quot;generated/sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt;&lt;code&gt;plot_precision_recall_curve&lt;/code&gt;&lt;/a&gt; function plots the precision recall as follows.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651372cf76a2e0eca2cd0e2ced075f5cfd44a313" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt;&lt;code&gt;Binarizer&lt;/code&gt;&lt;/a&gt; is similar to the &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt;&lt;code&gt;KBinsDiscretizer&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;k = 2&lt;/code&gt;, and when the bin edge is at the value &lt;code&gt;threshold&lt;/code&gt;.</source>
          <target state="translated">참고 것을 &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt; &lt;code&gt;Binarizer&lt;/code&gt; &lt;/a&gt; 받는 비슷 &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt; &lt;code&gt;KBinsDiscretizer&lt;/code&gt; &lt;/a&gt; 때 &lt;code&gt;k = 2&lt;/code&gt; , 및 빈 에지 값에있을 때 &lt;code&gt;threshold&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="96049a1871e8f004cea40c870be340fc85046579" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer &lt;a href=&quot;#id18&quot; id=&quot;id1&quot;&gt;16&lt;/a&gt;, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b78ef718e6ed1cb354d8ff189ba4de9e4443cf71" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. This method is consistent, which is not true for one-vs-rest classification. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">있습니다 &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; 은&lt;/a&gt; 또한 옵션을 사용하여 다른 멀티 클래스 전략, 입시 준비 학원과 가수에 의해 공식화 소위 멀티 클래스 SVM을 구현 &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; . 이 방법은 일관성이 있으며 일대일 분류에는 적용되지 않습니다. 실제로 결과는 대부분 비슷하지만 런타임은 상당히 적기 때문에 일대일 분류가 일반적으로 선호됩니다.</target>
        </trans-unit>
        <trans-unit id="6d0f75c58b62c96c540e90be5dd6446b78869fb4" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__add__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Sum(RBF(), RBF())&lt;/code&gt; is equivalent to using the + operator with &lt;code&gt;RBF() + RBF()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="acd06ce9a0926c4eda997a94789bc82988610943" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__mul__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Product(RBF(), RBF())&lt;/code&gt; is equivalent to using the * operator with &lt;code&gt;RBF() * RBF()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d495fb41e55b7018b37ac27eeb250fbaf347d05a" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__pow__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Exponentiation(RBF(), 2)&lt;/code&gt; is equivalent to using the ** operator with &lt;code&gt;RBF() ** 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a88b0087b5b199ea4beb800b3ce5a1f6c9022a8" translate="yes" xml:space="preserve">
          <source>Note that the Gini index only characterize the ranking performance of the model but not its calibration: any monotonic transformation of the predictions leaves the Gini index of the model unchanged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b2885ce1a0d54c6be5b37dba1e7a9bea3c67ec1" translate="yes" xml:space="preserve">
          <source>Note that the Multiplicative Update (&amp;lsquo;mu&amp;rsquo;) solver cannot update zeros present in the initialization, so it leads to poorer results when used jointly with the basic NNDSVD algorithm which introduces a lot of zeros; in this case, NNDSVDa or NNDSVDar should be preferred.</source>
          <target state="translated">Multiplicative Update ( 'mu') 솔버는 초기화에있는 0을 업데이트 할 수 없으므로 많은 zero를 도입하는 기본 NNDSVD 알고리즘과 함께 사용하면 결과가 저하됩니다. 이 경우 NNDSVDa 또는 NNDSVDar가 선호되어야합니다.</target>
        </trans-unit>
        <trans-unit id="542b5d2a5a3926264004f7807400969fe48d422d" translate="yes" xml:space="preserve">
          <source>Note that the current implementation only supports regression estimators.</source>
          <target state="translated">현재 구현은 회귀 추정기만 지원합니다.</target>
        </trans-unit>
        <trans-unit id="7ac1e23398a8f2960b2ec6ee5eea4c00d3f041dd" translate="yes" xml:space="preserve">
          <source>Note that the dataset contains categorical and numerical variables. We will need to take this into account when preprocessing the dataset thereafter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5878ce2fa9f81f5b0b2794d8ccb7e40e7db1917d" translate="yes" xml:space="preserve">
          <source>Note that the dict values can either be scorer functions or one of the predefined metric strings.</source>
          <target state="translated">dict 값은 스코어러 함수이거나 사전 정의 된 메트릭 문자열 중 하나 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="a97f1f4d24f812e6f4b824a150b492f876f8dbe2" translate="yes" xml:space="preserve">
          <source>Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (&lt;code&gt;LinearSVC(dual=True)&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;PassiveAggressive&lt;/code&gt;) but it does for algorithms that work with CSC matrices (&lt;code&gt;LinearSVC(dual=False)&lt;/code&gt;, &lt;code&gt;Lasso()&lt;/code&gt;, etc).</source>
          <target state="translated">차원은 CSR 행렬 ( &lt;code&gt;LinearSVC(dual=True)&lt;/code&gt; , &lt;code&gt;Perceptron&lt;/code&gt; , &lt;code&gt;SGDClassifier&lt;/code&gt; , &lt;code&gt;PassiveAggressive&lt;/code&gt; ) 에서 작동하는 알고리즘의 CPU 교육 시간에는 영향을 미치지 않지만 CSC 행렬 ( &lt;code&gt;LinearSVC(dual=False)&lt;/code&gt; , &lt;code&gt;Lasso()&lt;/code&gt; 등).</target>
        </trans-unit>
        <trans-unit id="435cce9f843df9a5bdcdf7f7022599966bcaee8d" translate="yes" xml:space="preserve">
          <source>Note that the estimate_bandwidth function is much less scalable than the mean shift algorithm and will be the bottleneck if it is used.</source>
          <target state="translated">추정 _ 대역폭 함수는 평균 이동 알고리즘보다 확장 성이 떨어지며 사용되는 경우 병목 현상이 발생합니다.</target>
        </trans-unit>
        <trans-unit id="bce829a8923d634c66b8b2d36d28916cd48e0ab9" translate="yes" xml:space="preserve">
          <source>Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels &lt;code&gt;fit&lt;/code&gt; upon. With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:</source>
          <target state="translated">네 번째와 다섯 번째 인스턴스가 세 개의 레이블의 그들은 아무도 일치 없음을 나타내는, 모두 0을 반환합니다 &lt;code&gt;fit&lt;/code&gt; 에. 다중 레이블 출력을 사용하면 인스턴스에 여러 레이블을 할당 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="21f39572b525862541f5e3b74bb03e06aac617ef" translate="yes" xml:space="preserve">
          <source>Note that the heat map plot has a special colorbar with a midpoint value close to the score values of the best performing models so as to make it easy to tell them apart in the blink of an eye.</source>
          <target state="translated">히트 맵 플롯에는 눈이 깜박일 때 쉽게 구별 할 수 있도록 최고 성능 모델의 점수 값에 가까운 중간 점 값을 가진 특수 색상 막대가 있습니다.</target>
        </trans-unit>
        <trans-unit id="8c847c9ef93d363951399eb5e5ddd91d785490b8" translate="yes" xml:space="preserve">
          <source>Note that the importance values for the top features represent a large fraction of the reference score of 0.356.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f19bf1a17574ce6b7f5a8199cbb6b2ed04a3916" translate="yes" xml:space="preserve">
          <source>Note that the maximum likelihood estimate corresponds to no shrinkage, and thus performs poorly. The Ledoit-Wolf estimate performs really well, as it is close to the optimal and is computational not costly. In this example, the OAS estimate is a bit further away. Interestingly, both approaches outperform cross-validation, which is significantly most computationally costly.</source>
          <target state="translated">최대 우도 추정치는 수축이 없기 때문에 성능이 저하됩니다. Ledoit-Wolf 추정치는 최적에 가깝고 계산 비용이 많이 들지 않으므로 실제로 잘 수행됩니다. 이 예에서 OAS 추정치는 조금 더 떨어져 있습니다. 흥미롭게도 두 방법 모두 교차 유효성 검사보다 성능이 뛰어나므로 계산 비용이 가장 많이 듭니다.</target>
        </trans-unit>
        <trans-unit id="be3cea96be539a6f36c7349851efbc1b4f539ceb" translate="yes" xml:space="preserve">
          <source>Note that the number of dimensions is independent of the original number of features but instead depends on the size of the dataset: the larger the dataset, the higher is the minimal dimensionality of an eps-embedding.</source>
          <target state="translated">치수 수는 원래 피처 수와 무관하지만 대신 데이터 세트의 크기에 따라 달라집니다. 데이터 세트가 클수록 eps 임베딩의 최소 치수는 더 높습니다.</target>
        </trans-unit>
        <trans-unit id="1426a0972df2ef3ae4847218faa4ab1a45e2a26b" translate="yes" xml:space="preserve">
          <source>Note that the parameter &lt;code&gt;alpha&lt;/code&gt; is applied as a Tikhonov regularization of the assumed covariance between the training points.</source>
          <target state="translated">모수 &lt;code&gt;alpha&lt;/code&gt; 는 훈련 지점 사이의 추정 된 공분산의 Tikhonov 정규화로 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="57bfd4549eb4e4a76c8eb0b9ddf20a2f4a52c8d2" translate="yes" xml:space="preserve">
          <source>Note that the precision may not decrease with recall. The definition of precision (\(\frac{T_p}{T_p + F_p}\)) shows that lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase precision. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing precision.</source>
          <target state="translated">리콜에 따라 정밀도가 감소하지 않을 수 있습니다. 정밀도의 정의 (\ (\ frac {T_p} {T_p + F_p} \))는 분류기의 임계 값을 낮추면 반환 된 결과 수가 증가하여 분모가 증가 할 수 있음을 보여줍니다. 임계 값이 이전에 너무 높게 설정되면 새 결과가 모두 양수일 수 있으며 정밀도가 증가합니다. 이전 임계 값이 거의 또는 너무 낮 으면 임계 값을 더 낮추면 오 탐지 (false positive)가 발생하여 정밀도가 떨어집니다.</target>
        </trans-unit>
        <trans-unit id="07e181d114b5848fdd4cb0661edb49154d99e027" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the &lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space. Here the manifold problem matches fairly that of representing a flat map of the Earth, as with &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;map projection&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; 의 목적은 다른 매니 폴드 학습 알고리즘과 달리 거리가 원본 고차원 공간의 거리를 잘 존중하는 데이터 (여기서는 2D)의 저 차원 표현을 찾는 것입니다. 저 차원 공간에서 데이터의 등방성 표현. 여기서 매니 폴드 문제는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;지도 투영&lt;/a&gt; 과 같이 지구의 평평한지도를 나타내는 것과 상당히 일치합니다.</target>
        </trans-unit>
        <trans-unit id="951ad93c2b6a49b38a3c4a8dabf905c9019bf128" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the MDS is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space.</source>
          <target state="translated">MDS의 목적은 다른 매니 폴드 학습 알고리즘과 달리 거리가 원본 고차원 공간의 거리를 잘 존중하는 데이터 (여기서는 2D)의 저 차원 표현을 찾는 것입니다. 저 차원 공간에서 데이터의 등방성 표현.</target>
        </trans-unit>
        <trans-unit id="6c07e8b80629c5d24a4c78874f28fde4e1598ff3" translate="yes" xml:space="preserve">
          <source>Note that the resulting model is the average claim amount per claim. As such, it is conditional on having at least one claim, and cannot be used to predict the average claim amount per policy in general.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="faff2f13ccab498a5068027cb2f2891a11c4c2ca" translate="yes" xml:space="preserve">
          <source>Note that the scalers accept both Compressed Sparse Rows and Compressed Sparse Columns format (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; and &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt;). Any other sparse input will be &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt;. To avoid unnecessary memory copies, it is recommended to choose the CSR or CSC representation upstream.</source>
          <target state="translated">스케일러는 압축 스파 스 행 및 압축 스파 스 열 형식을 모두 허용합니다 ( &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; 및 &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt; 참조 ). 다른 스파 스 입력은 &lt;strong&gt;압축 스파 스 행 표현&lt;/strong&gt; 으로 &lt;strong&gt;변환됩니다&lt;/strong&gt; . 불필요한 메모리 복사를 피하려면 업스트림에서 CSR 또는 CSC 표현을 선택하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="0ac4948c4f86990406e6391d28cab3438b2d6038" translate="yes" xml:space="preserve">
          <source>Note that the transformations successfully map the data to a normal distribution when applied to certain datasets, but are ineffective with others. This highlights the importance of visualizing the data before and after transformation.</source>
          <target state="translated">변환은 특정 데이터 세트에 적용될 때 데이터를 정규 분포에 성공적으로 매핑하지만 다른 데이터 세트에는 적용되지 않습니다. 이는 변환 전후 데이터 시각화의 중요성을 강조합니다.</target>
        </trans-unit>
        <trans-unit id="c025c974076c003b893079ae24539cfe87c45c45" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;code&gt;memory&lt;/code&gt; to enable caching becomes interesting when the fitting of a transformer is costly.</source>
          <target state="translated">를 사용하는 것을 주 &lt;code&gt;memory&lt;/code&gt; 변압기의 피팅 비용이 많이 드는 경우 캐싱을 사용하는 재미가된다.</target>
        </trans-unit>
        <trans-unit id="e3bd8ce7db50d77dd828df23ba8a7913ea07b656" translate="yes" xml:space="preserve">
          <source>Note that there are many different formulations for the Sparse PCA problem. The one implemented here is based on &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]&lt;/a&gt; . The optimization problem solved is a PCA problem (dictionary learning) with an \(\ell_1\) penalty on the components:</source>
          <target state="translated">Sparse PCA 문제에 대한 여러 가지 공식이 있습니다. 여기에 구현 된 것은 &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]를&lt;/a&gt; 기반으로 합니다. 해결 된 최적화 문제는 구성 요소에 대해 \ (\ ell_1 \) 페널티가있는 PCA 문제 (사전 학습)입니다.</target>
        </trans-unit>
        <trans-unit id="3533aed52b9c93cbfd7c732492e759ef81f9eff6" translate="yes" xml:space="preserve">
          <source>Note that there exist a lot of different clustering criteria and associated algorithms. The simplest clustering algorithm is &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;.</source>
          <target state="translated">다른 클러스터링 기준과 관련 알고리즘이 많이 있습니다. 가장 간단한 군집 알고리즘은 &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="7a1a308b56337fe667b4a60765401b66807cafaf" translate="yes" xml:space="preserve">
          <source>Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.</source>
          <target state="translated">sample_weight를 지정하면 이러한 가중치에 sample_weight (맞춤 방법을 통해 전달됨)가 곱해집니다.</target>
        </trans-unit>
        <trans-unit id="523c4300803e2407441df32761d9ac234d32f175" translate="yes" xml:space="preserve">
          <source>Note that theta are typically the log-transformed values of the kernel&amp;rsquo;s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.</source>
          <target state="translated">길이 스케일과 같은 하이퍼 파라미터는 자연스럽게 로그 스케일에 존재하기 때문에 검색 공간의 이러한 표현은 하이퍼 파라미터 검색에 더 적합하기 때문에 theta는 일반적으로 커널 하이퍼 파라미터의 로그 변환 된 값입니다.</target>
        </trans-unit>
        <trans-unit id="18d756a791b41973e0843ab0a78a9e37c703da28" translate="yes" xml:space="preserve">
          <source>Note that this accuracy of this l1-penalized linear model is significantly below what can be reached by an l2-penalized linear model or a non-linear multi-layer perceptron model on this dataset.</source>
          <target state="translated">이 l1 처벌 선형 모형의이 정확도는이 데이터 세트에서 l2 처벌 선형 모형 또는 비선형 다층 퍼셉트론 모형에 의해 도달 할 수있는 것보다 상당히 낮습니다.</target>
        </trans-unit>
        <trans-unit id="fe64330213465e1693b793ed059df249f5fb9ff2" translate="yes" xml:space="preserve">
          <source>Note that this component typically should not be used in a vanilla &lt;code&gt;Pipeline&lt;/code&gt; consisting of transformers and a classifier, but rather could be added using a &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1586f7c06fc3985d60451a7a19048e48e062430" translate="yes" xml:space="preserve">
          <source>Note that this compound kernel returns the results of all simple kernel stacked along an additional axis.</source>
          <target state="translated">이 복합 커널은 추가 축을 따라 쌓인 모든 단순 커널의 결과를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="31acdd30123a3b6dcbfca492a99f8cbc9dc2455a" translate="yes" xml:space="preserve">
          <source>Note that this computation of feature importance is based on entropy, and it is distinct from &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; which is based on permutation of the features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70f8f8292a30b78b7e2885afabc408eef407b785" translate="yes" xml:space="preserve">
          <source>Note that this definition is not valid if \(\beta \in (0; 1)\), yet it can be continuously extended to the definitions of \(d_{KL}\) and \(d_{IS}\) respectively.</source>
          <target state="translated">\ (\ beta \ in (0; 1) \) 인 경우이 정의는 유효하지 않지만 각각 \ (d_ {KL} \) 및 \ (d_ {IS} \)의 정의로 지속적으로 확장 될 수 있습니다. .</target>
        </trans-unit>
        <trans-unit id="7550e059eb4d092ae42a40cda726bb20131c9e24" translate="yes" xml:space="preserve">
          <source>Note that this estimator is different from the R implementation of Robust Regression (&lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt;) because the R implementation does a weighted least squares implementation with weights given to each sample on the basis of how much the residual is greater than a certain threshold.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5472d869ea9e0f8e4cfcc121937d62eb4599c58a" translate="yes" xml:space="preserve">
          <source>Note that this example is, however, only an illustration since for this specific case fitting PCA is not necessarily slower than loading the cache. Hence, use the &lt;code&gt;memory&lt;/code&gt; constructor parameter when the fitting of a transformer is costly.</source>
          <target state="translated">그러나이 예는 PCA에 맞는이 특정한 경우 PCA가 캐시를로드하는 것보다 느릴 필요가 없기 때문에 단지 예시 일 뿐이라는 점에 유의하십시오. 따라서 변압기를 장착하는 데 비용이 많이 드는 경우 &lt;code&gt;memory&lt;/code&gt; 생성자 매개 변수를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="1b5bac58d61d7142976dd586739448ed8787f73e" translate="yes" xml:space="preserve">
          <source>Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.</source>
          <target state="translated">이 형식은 변환 시간에 밀도를 높이기 때문에 행렬에 누락 된 값을 암시 적으로 저장하는 데 사용되지 않습니다. 0으로 인코딩 된 결 측값은 조밀 한 입력과 함께 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="ceed59ec0d8d185c9512413b150620f381e9c0c0" translate="yes" xml:space="preserve">
          <source>Note that this function does not regenerate the original data due to discretization rounding.</source>
          <target state="translated">이 기능은 이산화 반올림으로 인해 원래 데이터를 재생성하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="90f3882ef5e6cb2ec08d6d3659b834d53aaa84d9" translate="yes" xml:space="preserve">
          <source>Note that this gives us a different indication than the graph, as the graph reflects conditional relations between variables, while the clustering reflects marginal properties: variables clustered together can be considered as having a similar impact at the level of the full stock market.</source>
          <target state="translated">그래프는 변수 간의 조건 적 관계를 반영하고 클러스터링은 한계 속성을 반영하므로 그래프와는 다른 표시를 제공합니다. 함께 묶인 변수는 전체 주식 시장 수준에서 유사한 영향을 미치는 것으로 간주 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="29fe04606c06b888c8ec9e6f0120963e08f606ce" translate="yes" xml:space="preserve">
          <source>Note that this is always a dense array.</source>
          <target state="translated">이것은 항상 조밀 한 배열입니다.</target>
        </trans-unit>
        <trans-unit id="8400da57b096333e7a778582f2569282a236fe34" translate="yes" xml:space="preserve">
          <source>Note that this is stochastic, and that if random_state is not fixed, repeated calls, or permuted input, will yield different results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="426217e7254990be151f425ed53a8b743a92e13d" translate="yes" xml:space="preserve">
          <source>Note that this two-dimensional example is very degenerate: generally the number of features would be much greater than the &amp;ldquo;document length&amp;rdquo;, while here we have much larger documents than vocabulary. Similarly, with &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt;, it is much less likely that a feature distinguishes a particular class.</source>
          <target state="translated">이 2 차원 예제는 매우 축약합니다. 일반적으로 지형지 물의 수는 &quot;문서 길이&quot;보다 훨씬 많지만 여기서는 어휘보다 문서가 훨씬 큽니다. 마찬가지로, &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt; 를 사용하면 기능이 특정 클래스를 구별 할 가능성이 훨씬 줄어 듭니다.</target>
        </trans-unit>
        <trans-unit id="dcf3e0855a66eb55e0eddd9daaf862dddfda1dac" translate="yes" xml:space="preserve">
          <source>Note that this type is the most specific type that can be inferred. For example:</source>
          <target state="translated">이 유형은 유추 할 수있는 가장 구체적인 유형입니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="1fefb84f794ce8a86674757b08d8dabfe97347de" translate="yes" xml:space="preserve">
          <source>Note that this will affect all uses of &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt;&lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt;&lt;/a&gt; within the context.</source>
          <target state="translated">이는 컨텍스트 내에서 &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt; &lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt; 의&lt;/a&gt; 모든 사용에 영향을 미칩니다 .</target>
        </trans-unit>
        <trans-unit id="ab32001c49d58b4f0c9d94bbfb77f7ddeaf05601" translate="yes" xml:space="preserve">
          <source>Note that those results can be highly dependent on the value of &lt;code&gt;learning_rate_init&lt;/code&gt;.</source>
          <target state="translated">이러한 결과는 &lt;code&gt;learning_rate_init&lt;/code&gt; 값에 따라 크게 달라질 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="aa786acd948a782d7b514486d406120e9b9bf46a" translate="yes" xml:space="preserve">
          <source>Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.</source>
          <target state="translated">표준 교차 검증 방법과 달리, 연속적인 훈련 세트는 그 앞에 오는 것들의 상위 세트입니다.</target>
        </trans-unit>
        <trans-unit id="be1d5d21cf434df3c562c8f7229d77ef9e790ff3" translate="yes" xml:space="preserve">
          <source>Note that we could have used the least squares loss for the &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; model. This would wrongly assume a normal distributed response variable as does the &lt;code&gt;Ridge&lt;/code&gt; model, and possibly also lead to slightly negative predictions. However the gradient boosted trees would still perform relatively well and in particular better than &lt;code&gt;PoissonRegressor&lt;/code&gt; thanks to the flexibility of the trees combined with the large number of training samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b632488ec02d373b59188cfae81036b1d7135a34" translate="yes" xml:space="preserve">
          <source>Note that when using dictionary learning to extract a representation (e.g. for sparse coding) clustering can be a good proxy to learn the dictionary. For instance the &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; estimator is computationally efficient and implements on-line learning with a &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">사전 학습을 사용하여 표현을 추출 할 때 (예 : 스파 스 코딩의 경우) 클러스터링은 사전을 배우기에 좋은 프록시가 될 수 있습니다. 예를 들어 &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt; 추정기는 계산 효율이 높으며 &lt;code&gt;partial_fit&lt;/code&gt; 메소드를 사용하여 온라인 학습을 구현합니다 .</target>
        </trans-unit>
        <trans-unit id="b38cc6be43472cae197ca98a60df5eafaa29d73f" translate="yes" xml:space="preserve">
          <source>Note that with all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data!</source>
          <target state="translated">이러한 모든 전략에서 &lt;code&gt;predict&lt;/code&gt; 방법은 입력 데이터를 완전히 무시합니다!</target>
        </trans-unit>
        <trans-unit id="75c6be4694b9eabe59018390268fd820a052b7d5" translate="yes" xml:space="preserve">
          <source>Note that, by default, scikit-learn uses its embedded (vendored) version of joblib. A configuration switch (documented below) controls this behavior.</source>
          <target state="translated">기본적으로 scikit-learn은 내장 (공급 업체) 버전의 joblib를 사용합니다. 구성 스위치 (아래에 설명되어 있음)가이 동작을 제어합니다.</target>
        </trans-unit>
        <trans-unit id="ae98ee9bcd2e5d0854b3eaebde47d02a011f815f" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the observation \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\).</source>
          <target state="translated">이 표기법에서 관측 값 \ (y_i \)는 시행 착오 \ (i \)에서 \ ({-1, 1} \) 집합의 값을 취하는 것으로 가정합니다.</target>
        </trans-unit>
        <trans-unit id="e6bd4762fd372de20f9b98cd74d805456dc39e3e" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the target \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\). We can also see that Elastic-Net is equivalent to \(\ell_1\) when \(\rho = 1\) and equivalent to \(\ell_2\) when \(\rho=0\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79d7c15c2a930f99c60199078ea59a499e19fbc8" translate="yes" xml:space="preserve">
          <source>Note that, the color range of the precision matrices is tweaked to improve readability of the figure. The full range of values of the empirical precision is not displayed.</source>
          <target state="translated">정밀 행렬의 색상 범위는 그림의 가독성을 향상시키기 위해 조정되었습니다. 경험적 정밀도의 전체 값 범위는 표시되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="285f98e8d01e4962eff6724b78a3c6724d0931e6" translate="yes" xml:space="preserve">
          <source>Note that:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bd74df6988f671f3aaedf9864231e7cb14cad2a" translate="yes" xml:space="preserve">
          <source>Note the use of a generator comprehension, which introduces laziness into the feature extraction: tokens are only processed on demand from the hasher.</source>
          <target state="translated">피처 추출에 게으름을 유발하는 생성기 이해의 사용에 주목하십시오. 토큰은 요청자 만 처리해야합니다.</target>
        </trans-unit>
        <trans-unit id="1984eb2d93c7fabc5820f74c1a6deb67cdefe2d3" translate="yes" xml:space="preserve">
          <source>Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">노트! 합성 피처 중량은 다른 모든 피처와 마찬가지로 l1 / l2 정규화에 적용됩니다. 합성 피처 가중치 (따라서 인터셉트)에 대한 정규화의 영향을 줄이려면 intercept_scaling을 늘려야합니다.</target>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="translated">Note:</target>
        </trans-unit>
        <trans-unit id="b85cf8e5cd9762e5dd866d246742bbab950fd9b8" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeaveOneOut()&lt;/code&gt; is equivalent to &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; and &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of samples.</source>
          <target state="translated">참고 : &lt;code&gt;LeaveOneOut()&lt;/code&gt; 은 &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; 및 &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; 과 같습니다. 여기서 &lt;code&gt;n&lt;/code&gt; 은 샘플 수입니다.</target>
        </trans-unit>
        <trans-unit id="31e8baf167adcc23a2adc9382a5f1918c617d9e9" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeavePOut(p)&lt;/code&gt; is NOT equivalent to &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; which creates non-overlapping test sets.</source>
          <target state="translated">참고 : &lt;code&gt;LeavePOut(p)&lt;/code&gt; 는 겹치지 않는 테스트 세트를 생성 하는 &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; 와 동일하지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="bea1be387c131c6f224a4e72fba375bf5b015ed7" translate="yes" xml:space="preserve">
          <source>Note: Currently &lt;code&gt;TSNE(metric='precomputed')&lt;/code&gt; does not modify the precomputed distances, and thus assumes that precomputed euclidean distances are squared. In future versions, a parameter in TSNE will control the optional squaring of precomputed distances (see #12401).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="432e1c4e6e288e7db18e2c42d6e410c6adeb71c8" translate="yes" xml:space="preserve">
          <source>Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times &lt;code&gt;n_samples&lt;/code&gt; (i.e. the sum of squares of each column totals 1).</source>
          <target state="translated">참고 :이 10 개의 특징 변수는 각각 표준 편차 시간 &lt;code&gt;n_samples&lt;/code&gt; (즉, 각 열의 제곱합 합계 1)에 의해 중심이 맞춰지고 크기가 조정됩니다 .</target>
        </trans-unit>
        <trans-unit id="02b388a51976f4b3884d316ec9ed343cbbaf27f0" translate="yes" xml:space="preserve">
          <source>Note: Evaluation of eval_gradient is not analytic but numeric and all</source>
          <target state="translated">참고 : eval_gradient의 평가는 분석이 아니라 숫자 및 모두입니다.</target>
        </trans-unit>
        <trans-unit id="f97fa8efa81cc34898992868ec31edd01fe1abf9" translate="yes" xml:space="preserve">
          <source>Note: For larger datasets (n_samples &amp;gt;= 10000), please refer to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5290473efc5984775f303f01f61e6c7775623f5" translate="yes" xml:space="preserve">
          <source>Note: If a lambda is used as the function, then the resulting transformer will not be pickleable.</source>
          <target state="translated">참고 : 람다가 함수로 사용되면 결과 트랜스포머를 피클 할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="78c3e35dab7ccbe33bae1787c55dabbd050c5a91" translate="yes" xml:space="preserve">
          <source>Note: In KNeighborsTransformer we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;, and for compatibility reasons, one extra neighbor is computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. Please note that we do the same in the proposed wrappers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab7df665871a4d2a9feffe69dfea4e192c2cd75e" translate="yes" xml:space="preserve">
          <source>Note: L2 normalization is also known as spatial sign preprocessing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09a1c78e2b9dafeb4ae2773774e2099dbe747a0e" translate="yes" xml:space="preserve">
          <source>Note: Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">참고 : 구현의 점수는 Tsoumakas et al., 2010에 제공된 것보다 1 더 높습니다. 이는 인스턴스에 0 개의 실제 레이블이있는 퇴화 사례를 처리하도록 확장됩니다.</target>
        </trans-unit>
        <trans-unit id="956d1e2ca58f2ab0bdb4afea5546244c422bc323" translate="yes" xml:space="preserve">
          <source>Note: See the &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;Introduction to machine learning with scikit-learn Tutorial&lt;/a&gt; for a quick run-through on the basic machine learning vocabulary used within scikit-learn.</source>
          <target state="translated">참고 : &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;scikit-learn&lt;/a&gt; 에서 사용되는 기본 기계 학습 어휘에 대한 빠른 실행 은 scikit-learn 자습서 를 통한 기계 학습 소개를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="7a9381252d0555984c45c1d913a85b0a19a4797d" translate="yes" xml:space="preserve">
          <source>Note: The default solver &amp;lsquo;adam&amp;rsquo; works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, &amp;lsquo;lbfgs&amp;rsquo; can converge faster and perform better.</source>
          <target state="translated">참고 : 기본 솔버 'adam'은 훈련 시간과 유효성 검사 점수 측면에서 비교적 큰 데이터 세트 (수천 개의 훈련 샘플 이상)에서 꽤 잘 작동합니다. 그러나 작은 데이터 세트의 경우 'lbfgs'가 더 빨리 수렴하고 더 잘 수행 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="271df9bc769d4f6f6224f70e1c75a6c3d0d4e15f" translate="yes" xml:space="preserve">
          <source>Note: The parameters &lt;code&gt;test_size&lt;/code&gt; and &lt;code&gt;train_size&lt;/code&gt; refer to groups, and not to samples, as in ShuffleSplit.</source>
          <target state="translated">참고 : &lt;code&gt;test_size&lt;/code&gt; 및 &lt;code&gt;train_size&lt;/code&gt; 매개 변수는 ShuffleSplit에서 와 같이 샘플이 아닌 그룹을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="d9b8539222215de6f9b7a2dc0d47dad55ab9503a" translate="yes" xml:space="preserve">
          <source>Note: a one-hot encoding of y labels should use a LabelBinarizer instead.</source>
          <target state="translated">참고 : y 레이블의 원 핫 인코딩은 대신 LabelBinarizer를 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="1ed0914b13c92897638e72f9758df4b91ef77876" translate="yes" xml:space="preserve">
          <source>Note: although we will make new pipelines with the processors which we wrote in the previous section for the 3 learners, the final estimator RidgeCV() does not need preprocessing of the data as it will be fed with the already preprocessed output from the 3 learners.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af48a21921f21ca5ba4feec03dc7cfdb83d643b6" translate="yes" xml:space="preserve">
          <source>Note: as k-means is optimizing a non-convex objective function, it will likely end up in a local optimum. Several runs with independent random init might be necessary to get a good convergence.</source>
          <target state="translated">참고 : k- 평균은 볼록하지 않은 객관적인 기능을 최적화하기 때문에 현지 최적의 결과를 낳을 수 있습니다. 좋은 수렴을 얻으려면 독립적 인 무작위 초기화를 가진 여러 실행이 필요할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="3bb7791854593a3b717f90311f25871cac16570c" translate="yes" xml:space="preserve">
          <source>Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">참고 : 다른 교차 유효성 검사 전략과 달리 임의 분할은 모든 크기가 다를 수 있다고 보장하지는 않지만 여전히 상당한 규모의 데이터 집합에 대해서는 가능성이 높습니다.</target>
        </trans-unit>
        <trans-unit id="ec23f8c549cab8298e97ba96412d8acd5b97a819" translate="yes" xml:space="preserve">
          <source>Note: fitting on sparse input will override the setting of this parameter, using brute force.</source>
          <target state="translated">참고 : 스파 스 입력에 피팅하면 무차별 대입을 사용하여이 매개 변수 설정이 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="f2a5a8b06402f76d2a1b1f28ad2e90efb04ea841" translate="yes" xml:space="preserve">
          <source>Note: if you manage your own numerical data it is recommended to use an optimized file format such as HDF5 to reduce data load times. Various libraries such as H5Py, PyTables and pandas provides a Python interface for reading and writing data in that format.</source>
          <target state="translated">참고 : 자체 숫자 데이터를 관리하는 경우 데이터로드 시간을 줄이기 위해 HDF5와 같은 최적화 된 파일 형식을 사용하는 것이 좋습니다. H5Py, PyTables 및 pandas와 같은 다양한 라이브러리는 해당 형식의 데이터를 읽고 쓰는 Python 인터페이스를 제공합니다.</target>
        </trans-unit>
        <trans-unit id="cb39d5746d1ab528272657961084b4241cfe3f85" translate="yes" xml:space="preserve">
          <source>Note: in the plot, &amp;ldquo;unlabeled samples&amp;rdquo; does not mean that we don&amp;rsquo;t know the labels (as in semi-supervised learning) but that the samples simply do &lt;em&gt;not&lt;/em&gt; have a label.</source>
          <target state="translated">참고 : 도표에서 &quot;비 표지 샘플&quot;은 우리가 라벨을 알지 못한다는 것을 의미하지는 않지만 (반지도 학습에서와 같이) 샘플에는 단순히 라벨 이 &lt;em&gt;없다는&lt;/em&gt; 것을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="403fd153dcfc1c72561472b5e34372d5de58734f" translate="yes" xml:space="preserve">
          <source>Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">참고 : ShuffleSplit 전략과 같이 계층화 된 무작위 분할은 모든 크기가 다를 수 있다고 보장하지는 않지만 여전히 크기가 큰 데이터 세트에 대해서는 가능성이 높습니다.</target>
        </trans-unit>
        <trans-unit id="12964c4f090e67fee00edc80b29c8ee9b28b7b3b" translate="yes" xml:space="preserve">
          <source>Note: the implementation of &lt;code&gt;inverse_transform&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;svd_solver='randomized'&lt;/code&gt; is not the exact inverse transform of &lt;code&gt;transform&lt;/code&gt; even when &lt;code&gt;whiten=False&lt;/code&gt; (default).</source>
          <target state="translated">참고 :의 구현 &lt;code&gt;inverse_transform&lt;/code&gt; 에서 &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; 와 &lt;code&gt;svd_solver='randomized'&lt;/code&gt; (가) 정확한 역의 변환하지 &lt;code&gt;transform&lt;/code&gt; 에도 &lt;code&gt;whiten=False&lt;/code&gt; (기본값).</target>
        </trans-unit>
        <trans-unit id="f5990a880094bfe59d250a6cb72959923dee6858" translate="yes" xml:space="preserve">
          <source>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</source>
          <target state="translated">참고 : 샘플링 데이터를 저장하지 않음으로써 개체 메모리 공간을 줄이기 위해 속성을 호출 할 때마다 목록이 다시 만들어집니다. 따라서 속성을 가져 오는 것이 예상보다 느릴 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b4fa4a5f4c66fdf91fefb2f5d8a9d04622e730f8" translate="yes" xml:space="preserve">
          <source>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">참고 : &lt;code&gt;max_features&lt;/code&gt; 이상의 기능 을 효과적으로 검사해야하는 경우에도 노드 샘플의 유효한 파티션이 하나 이상 발견 될 때까지 분할 검색이 중지되지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="4064827fd69033d32661395cc63853ae193f7d3a" translate="yes" xml:space="preserve">
          <source>Note: this implementation can be used with binary, multiclass and multilabel classification, but some restrictions apply (see Parameters).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5af1722805bd08a73be9d8b2f383c0eb417bbdd9" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.</source>
          <target state="translated">참고 :이 구현은 레이블 표시기 형식의 이진 분류 작업 또는 다중 레이블 분류 작업으로 제한됩니다.</target>
        </trans-unit>
        <trans-unit id="2dab9af505b98147ed8303644f1fce8db17174c7" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task.</source>
          <target state="translated">참고 :이 구현은 이진 분류 작업 또는 다중 레이블 분류 작업으로 제한됩니다.</target>
        </trans-unit>
        <trans-unit id="229c71e40bdbb475df5a5f3c46414bb1e9fb11cf" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task.</source>
          <target state="translated">참고 :이 구현은 이진 분류 작업으로 제한됩니다.</target>
        </trans-unit>
        <trans-unit id="77503a53930a4c6773bcfd9900ee0500aa085f94" translate="yes" xml:space="preserve">
          <source>Note: with the optional parameter &lt;code&gt;svd_solver='randomized'&lt;/code&gt;, we also need to give &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; the size of the lower-dimensional space &lt;code&gt;n_components&lt;/code&gt; as a mandatory input parameter.</source>
          <target state="translated">참고 : 선택적 매개 변수 &lt;code&gt;svd_solver='randomized'&lt;/code&gt; 를 사용하면 &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; 에 하위 공간 &lt;code&gt;n_components&lt;/code&gt; 의 크기를 필수 입력 매개 변수로 지정해야합니다.</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="8365e7c537a7bde197e775fc685e729bf7dcde79" translate="yes" xml:space="preserve">
          <source>Notice that this class does not support sparse input. See &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; for an alternative with sparse data.</source>
          <target state="translated">이 클래스는 스파 스 입력을 지원하지 않습니다. 희소 데이터의 대안에 대해서는 &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="24a6d73ad577eece3a7c4a8079ee0685b19c5eef" translate="yes" xml:space="preserve">
          <source>Novelty detection</source>
          <target state="translated">참신 탐지</target>
        </trans-unit>
        <trans-unit id="0c6ce6f3a8c7f0ac9123407bf644e00c93b8a85c" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor (LOF)</source>
          <target state="translated">LOF (Local Outlier Factor)를 사용한 참신 탐지</target>
        </trans-unit>
        <trans-unit id="d039fa812c1beff75961eedb7fd0d56d4bd6cef8" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor is illustrated below.</source>
          <target state="translated">Local Outlier Factor를 사용한 참신 탐지는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="0baacee2d29c362912e19aeae2a56e9b5de18251" translate="yes" xml:space="preserve">
          <source>November, 1995</source>
          <target state="translated">1995 년 11 월</target>
        </trans-unit>
        <trans-unit id="f56b60fb36ba6e7108f33fd204674d75974c9ca0" translate="yes" xml:space="preserve">
          <source>Now looking at the computation time of the different parts, we see that the vectorization is much more expensive than learning itself. From the different algorithms, &lt;code&gt;MultinomialNB&lt;/code&gt; is the most expensive, but its overhead can be mitigated by increasing the size of the mini-batches (exercise: change &lt;code&gt;minibatch_size&lt;/code&gt; to 100 and 10000 in the program and compare).</source>
          <target state="translated">이제 다른 부분의 계산 시간을 살펴보면 벡터화가 학습 자체보다 훨씬 비쌉니다. 다른 알고리즘에서 &lt;code&gt;MultinomialNB&lt;/code&gt; 가 가장 비싸지 만 미니 배치의 크기를 늘리면 오버 헤드를 완화 할 수 있습니다 (운동 : 프로그램에서 &lt;code&gt;minibatch_size&lt;/code&gt; 를 100 및 10000으로 변경 하고 비교하십시오).</target>
        </trans-unit>
        <trans-unit id="e921254526b0e2e9cacf92a70632a272e818cfb0" translate="yes" xml:space="preserve">
          <source>Now that the coefficients have been scaled, we can safely compare them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="703648eec6ac2a9ecd5332ac2370f3cbb5d40c50" translate="yes" xml:space="preserve">
          <source>Now that we have our features, we can train a classifier to try to predict the category of a post. Let&amp;rsquo;s start with a &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;na&amp;iuml;ve Bayes&lt;/a&gt; classifier, which provides a nice baseline for this task. &lt;code&gt;scikit-learn&lt;/code&gt; includes several variants of this classifier; the one most suitable for word counts is the multinomial variant:</source>
          <target state="translated">이제 기능을 갖추 었으므로 게시물 분류를 예측하도록 분류자를 훈련시킬 수 있습니다. 이 작업에 대한 좋은 기준을 제공하는 &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;순진한 Bayes&lt;/a&gt; 분류기로 시작하겠습니다 . &lt;code&gt;scikit-learn&lt;/code&gt; 에는이 분류기의 여러 변형이 포함됩니다. 단어 수에 가장 적합한 것은 다항식 변형입니다.</target>
        </trans-unit>
        <trans-unit id="88e8cd01d787ca5c585c186900aea23cd932893c" translate="yes" xml:space="preserve">
          <source>Now we can use Ames Housing dataset to make the predictions. We check the performance of each individual predictor as well as of the stack of the regressors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c77da09ad9df95918caa9589e1cfa5804c7aace6" translate="yes" xml:space="preserve">
          <source>Now we create a &lt;code&gt;FeatureUnion&lt;/code&gt;. All features will be imputed using &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt;, in order to enable classifiers to work with this data. Additionally, it adds the the indicator variables from &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e66fc30e8519d1cd12806317bc82ad0b2345f16" translate="yes" xml:space="preserve">
          <source>Now we want to select the two features which are the most important. SelectFromModel() allows for setting the threshold. Only the features with the &lt;code&gt;coef_&lt;/code&gt; higher than the threshold will remain. Here, we want to set the threshold slightly above the third highest &lt;code&gt;coef_&lt;/code&gt; calculated by LassoCV() from our data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c18c8137b5b9d8aae8dc57c26f7d6b41951afd4" translate="yes" xml:space="preserve">
          <source>Now we will estimate the score on the data where the missing values are replaced by 0:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b6f8334bd6af42d0add5e2131513b016d9f6e6d" translate="yes" xml:space="preserve">
          <source>Now we will initiate the gradient boosting regressors and fit it with our training data. Let&amp;rsquo;s also look and the mean squared error on the test data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c5cf2d42930f189f93938b87f35b21f55ff5f6c" translate="yes" xml:space="preserve">
          <source>Now we will use each of the regressors to make the 20 first predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="936a8dbed55baf9b2e1ebda09b75843de98173ab" translate="yes" xml:space="preserve">
          <source>Now we will write a function which will score the results on the differently imputed data. Let&amp;rsquo;s look at each imputer separately:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39c382cf98b09c769e0ece49478f8e5a21269790" translate="yes" xml:space="preserve">
          <source>Now you can &lt;em&gt;predict&lt;/em&gt; new values. In this case, you&amp;rsquo;ll predict using the last image from &lt;code&gt;digits.data&lt;/code&gt;. By predicting, you&amp;rsquo;ll determine the image from the training set that best matches the last image.</source>
          <target state="translated">이제 새로운 가치를 &lt;em&gt;예측할&lt;/em&gt; 수 있습니다 . 이 경우 &lt;code&gt;digits.data&lt;/code&gt; 의 마지막 이미지를 사용하여 예측합니다 . 예측하여 훈련 이미지에서 마지막 이미지와 가장 일치하는 이미지를 결정합니다.</target>
        </trans-unit>
        <trans-unit id="4bde0a1195bac7469e935b78a194104a68da7a29" translate="yes" xml:space="preserve">
          <source>Now, if we repeat this computation for the remaining 2 terms in the document, we get</source>
          <target state="translated">이제 문서의 나머지 2 개 항에 대해이 계산을 반복하면</target>
        </trans-unit>
        <trans-unit id="ece88bcd9ec161c2a2872c2fb61e36a0d64c7a18" translate="yes" xml:space="preserve">
          <source>Now, without any further assumptions the idea of having a latent variable \(h\) would be superfluous &amp;ndash; \(x\) can be completely modelled with a mean and a covariance. We need to impose some more specific structure on one of these two parameters. A simple additional assumption regards the structure of the error covariance \(\Psi\):</source>
          <target state="translated">이제 더 이상의 가정없이 잠복 변수 \ (h \)를 갖는 아이디어는 불필요 할 것입니다. \ (x \)는 평균과 공분산으로 완전히 모델링 될 수 있습니다. 이 두 매개 변수 중 하나에 좀 더 구체적인 구조를 적용해야합니다. 간단한 추가 가정은 오차 공분산 \ (\ Psi \)의 구조와 관련이 있습니다.</target>
        </trans-unit>
        <trans-unit id="a31389fe4ff0ebc6e5c5d38e5dab56436f6bc483" translate="yes" xml:space="preserve">
          <source>Nu Support Vector Regression.</source>
          <target state="translated">Nu 지원 벡터 회귀.</target>
        </trans-unit>
        <trans-unit id="a9b51312b4e809b61f7b24f233552372d8a4d343" translate="yes" xml:space="preserve">
          <source>Nu-Support Vector Classification.</source>
          <target state="translated">Nu-Support 벡터 분류.</target>
        </trans-unit>
        <trans-unit id="3fd1d9cda92e08af6fee8cba19fd970cf1f0632b" translate="yes" xml:space="preserve">
          <source>Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). &lt;code&gt;l1_ratio=1&lt;/code&gt; corresponds to the Lasso.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7957f8886c98fbf5a70e65a8ee06b411dfa2ec9d" translate="yes" xml:space="preserve">
          <source>Number of Attributes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28831313b9efda1fb2d5e62ae541d82eeaf2e628" translate="yes" xml:space="preserve">
          <source>Number of Attributes:</source>
          <target state="translated">속성 수 :</target>
        </trans-unit>
        <trans-unit id="2bbc98640e09a456dee6d19b3fcc0a288b212310" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">교차 유효성 검사 루프 동안 사용 된 CPU 코어 수 &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="e0f96f6f23ce740144b8c92df340b8480f6b786d" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e056a5a70210c137f261290dad04190fbc9ce82b" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">multi_class = 'ovr'&amp;rdquo;인 경우 클래스를 병렬 처리 할 때 사용되는 CPU 코어 수 'multi_class'의 지정 여부에 관계없이 &lt;code&gt;solver&lt;/code&gt; 가 'liblinear'로 설정 되면이 매개 변수는 무시됩니다 . &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="ba00da4689fb46c7f1453ab4c4d840dda819bf30" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="044a045266785f2237c066206c338baa3e1d5bb2" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">교차 검증 중에 사용할 CPU 수입니다. &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="299b1e18443f4440c97e32fcbc5b33894e6807aa" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaf36da587212084529abec535211c954c2e7c01" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">교차 검증 중에 사용할 CPU 수입니다. 이는 l1_ratio에 여러 값이 제공된 경우에만 사용됩니다. &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="abb87aba72afe118ccbcfcbd98130537908df821" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52783b9f963f3f1690dd5d40572b3875e2a7ade7" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the resampling. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">리샘플링 중에 사용할 CPU 수입니다. &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="9b0888ca0284a2c854ae8715c4ccbdf2a4510807" translate="yes" xml:space="preserve">
          <source>Number of Instances</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2666336978a0f4e8c547b7534c07249ba6000fd" translate="yes" xml:space="preserve">
          <source>Number of Instances:</source>
          <target state="translated">인스턴스 수 :</target>
        </trans-unit>
        <trans-unit id="0bc3461e8033920222bec6b216692137eee9c091" translate="yes" xml:space="preserve">
          <source>Number of Monte Carlo samples per original feature. Equals the dimensionality of the computed feature space.</source>
          <target state="translated">원래 기능 당 Monte Carlo 샘플 수 계산 된 피처 공간의 차원과 같습니다.</target>
        </trans-unit>
        <trans-unit id="3262f2b1a48253ff0690a8a75cfdd12aae481720" translate="yes" xml:space="preserve">
          <source>Number of active features across every target for the model refit with the best hyperparameters got by cross-validating across all folds.</source>
          <target state="translated">모든 접기에 대해 교차 검증함으로써 얻은 최고의 하이퍼 파라미터로 모델을 개조하기 위해 모든 대상에서 활성화 된 기능의 수.</target>
        </trans-unit>
        <trans-unit id="4cbf5cb47ecd9996ec380ef5f0f19c258c9e11e4" translate="yes" xml:space="preserve">
          <source>Number of active features across every target.</source>
          <target state="translated">모든 대상에서 활성 기능의 수입니다.</target>
        </trans-unit>
        <trans-unit id="4d39e5d8b3efa9d6f8372f94e39a5395c837b600" translate="yes" xml:space="preserve">
          <source>Number of active features across every target. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">모든 대상에서 활성 기능의 수입니다. &lt;code&gt;return_n_iter&lt;/code&gt; 가 True로 설정된 경우에만 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="e0c8a9190fa0a6b6567e6260a08bbc16ad38e0e1" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path</source>
          <target state="translated">정규화 경로를 따라 알파 수</target>
        </trans-unit>
        <trans-unit id="21389bf92cd8e8648f186478c091bf8c596c9371" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path, used for each l1_ratio.</source>
          <target state="translated">각 l1_ratio에 사용되는 정규화 경로를 따르는 알파 수입니다.</target>
        </trans-unit>
        <trans-unit id="cbe7afb5599ad451cab3f599179a64fd19bd9311" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb76f13b1ca274d0ac0509e0599ee9f88692f95e" translate="yes" xml:space="preserve">
          <source>Number of best singular vectors to which to project the data for clustering.</source>
          <target state="translated">클러스터링을 위해 데이터를 투영 할 최상의 특이 벡터의 수입니다.</target>
        </trans-unit>
        <trans-unit id="669eddc43c369820a90c37333994758dabadb237" translate="yes" xml:space="preserve">
          <source>Number of binary hidden units.</source>
          <target state="translated">이진 숨김 단위 수</target>
        </trans-unit>
        <trans-unit id="df5056a6b08a72e6eb298ef5a65870b5ddc8c698" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. An ignored feature at index &lt;code&gt;i&lt;/code&gt; will have &lt;code&gt;n_bins_[i] == 0&lt;/code&gt;.</source>
          <target state="translated">기능 당 구간 수 인덱스 &lt;code&gt;i&lt;/code&gt; 에서 무시 된 피처 는 &lt;code&gt;n_bins_[i] == 0&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="d7a7f2e004236d911cb66cf34176f3d71e43ecca" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. Bins whose width are too small (i.e., &amp;lt;= 1e-8) are removed with a warning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a230a570a7b298a4731493b5111f06efb3bd3e1c" translate="yes" xml:space="preserve">
          <source>Number of bins to discretize the [0, 1] interval. A bigger number requires more data. Bins with no samples (i.e. without corresponding values in &lt;code&gt;y_prob&lt;/code&gt;) will not be returned, thus the returned arrays may have less than &lt;code&gt;n_bins&lt;/code&gt; values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e19457800c5864e1fbdcc0291b0ef620abfd78c" translate="yes" xml:space="preserve">
          <source>Number of bins. A bigger number requires more data.</source>
          <target state="translated">쓰레기통 수 숫자가 클수록 더 많은 데이터가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="0c552ab63ca0f87bf2127208daa3692ef5597992" translate="yes" xml:space="preserve">
          <source>Number of classes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe9989009b56729007d1b9895a9883c9be1c338" translate="yes" xml:space="preserve">
          <source>Number of classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f70f556044c9d189136c9439d7b869763e660892" translate="yes" xml:space="preserve">
          <source>Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples.</source>
          <target state="translated">마지막 클러스터링 단계 이후의 클러스터 수로, 리프의 하위 클러스터를 새 샘플로 처리합니다.</target>
        </trans-unit>
        <trans-unit id="d93f166299b2fe351648697f50539b771bbcab5f" translate="yes" xml:space="preserve">
          <source>Number of clusters to extract.</source>
          <target state="translated">추출 할 클러스터 수</target>
        </trans-unit>
        <trans-unit id="eb68d1899db83f395f515eac11a92a2f39369f2a" translate="yes" xml:space="preserve">
          <source>Number of combinations taken into account from &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples.</source>
          <target state="translated">'n choose k'에서 고려 된 조합 수. 여기서 n은 샘플 수이고 k는 서브 샘플 수입니다.</target>
        </trans-unit>
        <trans-unit id="7fdc37b73d2c326edb84e2aac0aaad0a3921fc6b" translate="yes" xml:space="preserve">
          <source>Number of components</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd12f5ccc87c2314d1a7462c1838eb4fba879a35" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt; n_classes - 1) for dimensionality reduction.</source>
          <target state="translated">차원 축소를위한 구성 요소 수 (&amp;lt;n_classes-1)</target>
        </trans-unit>
        <trans-unit id="dfb009c80642e429ebd085f522e99f9888546747" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt;= min(n_classes - 1, n_features)) for dimensionality reduction. If None, will be set to min(n_classes - 1, n_features). This parameter only affects the &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="678dcaccd382015a606461223e75a521f8c270e3" translate="yes" xml:space="preserve">
          <source>Number of components to keep</source>
          <target state="translated">보관할 부품 수</target>
        </trans-unit>
        <trans-unit id="209051725a6de8e5e1e5fa7a1e74f7eb06a44fec" translate="yes" xml:space="preserve">
          <source>Number of components to keep.</source>
          <target state="translated">유지할 구성 요소 수</target>
        </trans-unit>
        <trans-unit id="d04623123bcfd2ce2b9c37b5c1e9535768de28a7" translate="yes" xml:space="preserve">
          <source>Number of components to keep. If &lt;code&gt;n_components `` is ``None&lt;/code&gt;, then &lt;code&gt;n_components&lt;/code&gt; is set to &lt;code&gt;min(n_samples, n_features)&lt;/code&gt;.</source>
          <target state="translated">유지할 구성 요소 수 만약 &lt;code&gt;n_components `` is ``None&lt;/code&gt; 다음 &lt;code&gt;n_components&lt;/code&gt; 가 설정되어 &lt;code&gt;min(n_samples, n_features)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="864a5ed4a409c99b07b3c02fc85e293c54d58811" translate="yes" xml:space="preserve">
          <source>Number of components to keep. if n_components is not set all components are kept:</source>
          <target state="translated">유지할 구성 요소 수 n_components가 설정되지 않은 경우 모든 구성 요소가 유지됩니다.</target>
        </trans-unit>
        <trans-unit id="b681f0aabf7a4e88ff6e07d02e6d3053416c7e30" translate="yes" xml:space="preserve">
          <source>Number of components to use. If none is passed, all are used.</source>
          <target state="translated">사용할 구성 요소 수 전달되지 않으면 모두 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="a4c9442f9290e02b19f88b85f02bacea3cfec6f7" translate="yes" xml:space="preserve">
          <source>Number of components, if n_components is not set all features are kept.</source>
          <target state="translated">구성 요소 수 (n_components가 설정되지 않은 경우 모든 기능이 유지됨).</target>
        </trans-unit>
        <trans-unit id="cd25fc9de4a04b081f0b9a2b60926bce89997152" translate="yes" xml:space="preserve">
          <source>Number of components. If None, all non-zero components are kept.</source>
          <target state="translated">구성 요소 수 None 인 경우 0이 아닌 모든 구성 요소가 유지됩니다.</target>
        </trans-unit>
        <trans-unit id="45f800ea0c8bd716a5f59f6d34dd8fdf95b8f22e" translate="yes" xml:space="preserve">
          <source>Number of components:</source>
          <target state="translated">구성 요소 수 :</target>
        </trans-unit>
        <trans-unit id="08ad46845beb5661bae33c15135ad1635029f790" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">접는 부분에 끼우면 서 병렬로 실행할 코어 수입니다. &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="858edfcde96e4df6617cbdeba5e365378b873cbb" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c854de6ce1141c59e336a0d697b5a2d467a137a" translate="yes" xml:space="preserve">
          <source>Number of decimal digits to display.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0da9d602da12f13ca29bd75af12cc8c869e57a9f" translate="yes" xml:space="preserve">
          <source>Number of dictionary atoms to extract.</source>
          <target state="translated">추출 할 사전 원자 수</target>
        </trans-unit>
        <trans-unit id="5227337d1c8f00f0cc5985a46091828c912745d3" translate="yes" xml:space="preserve">
          <source>Number of digits for formatting output floating point values. When &lt;code&gt;output_dict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this will be ignored and the returned values will not be rounded.</source>
          <target state="translated">출력 부동 소수점 값을 형식화하기위한 자릿수입니다. 때 &lt;code&gt;output_dict&lt;/code&gt; 가 있다 &lt;code&gt;True&lt;/code&gt; ,이 무시되고 반환 값은 반올림하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="393e0ab0962f61be4ea05f66f75cf83a58c8acb8" translate="yes" xml:space="preserve">
          <source>Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.</source>
          <target state="translated">각 노드의 불순물, 임계 값 및 값 속성 값의 부동 소수점 정밀도 자릿수입니다.</target>
        </trans-unit>
        <trans-unit id="857511ca3ff53ac74c7a9a64491518f8a98aa57b" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities.</source>
          <target state="translated">비 유사성을 담그는 차원 수입니다.</target>
        </trans-unit>
        <trans-unit id="60a7a9ccef477eb7d360b15d4ec93323fc3722cf" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities. If an &lt;code&gt;init&lt;/code&gt; array is provided, this option is overridden and the shape of &lt;code&gt;init&lt;/code&gt; is used to determine the dimensionality of the embedding space.</source>
          <target state="translated">비 유사성을 담그는 차원 수입니다. 는 IF &lt;code&gt;init&lt;/code&gt; 어레이가 제공되며,이 옵션은 무시되고 형상 &lt;code&gt;init&lt;/code&gt; 매립 공간의 차원을 결정하는 데 사용된다.</target>
        </trans-unit>
        <trans-unit id="f601fdb82b970f8ccae9e3060c9f42a8faed55c3" translate="yes" xml:space="preserve">
          <source>Number of documents to use in each EM iteration. Only used in online learning.</source>
          <target state="translated">각 EM 반복에 사용할 문서 수 온라인 학습에서만 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="25fead66533b3559387b2fcbff51a361b6ce623f" translate="yes" xml:space="preserve">
          <source>Number of eigen vectors to use for the spectral embedding</source>
          <target state="translated">스펙트럼 임베딩에 사용할 고유 벡터 수</target>
        </trans-unit>
        <trans-unit id="70fb7e9ad9dffd747feff757e8b6b2c3b8c3ad21" translate="yes" xml:space="preserve">
          <source>Number of examples per minibatch.</source>
          <target state="translated">미니 배치 당 예제 수입니다.</target>
        </trans-unit>
        <trans-unit id="f3a87cabcd8ae2a3f47b41980367db8a154ace86" translate="yes" xml:space="preserve">
          <source>Number of features</source>
          <target state="translated">기능 수</target>
        </trans-unit>
        <trans-unit id="c43d2150a87097029c4596d560aaf86e8bb6b759" translate="yes" xml:space="preserve">
          <source>Number of features in the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="577fe93a084a93466c74dd6388a400050adba06b" translate="yes" xml:space="preserve">
          <source>Number of features of each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48c9c477edb63770940bc1b8209cb208de55d13b" translate="yes" xml:space="preserve">
          <source>Number of features seen during &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f26773f39b3b679c0daff789f714ad69f2880ea0" translate="yes" xml:space="preserve">
          <source>Number of features to construct. How many data points will be used to construct the mapping.</source>
          <target state="translated">구성 할 기능의 수입니다. 매핑을 구성하는 데 사용되는 데이터 포인트 수</target>
        </trans-unit>
        <trans-unit id="d56ef4ad6a94ab0bc79a9c8a295f26cabf4e9608" translate="yes" xml:space="preserve">
          <source>Number of features with missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bfcb7d61331a9745e723fb4ee723054b5ce91e8" translate="yes" xml:space="preserve">
          <source>Number of folds. Must be at least 2.</source>
          <target state="translated">접기 수 2 이상이어야합니다.</target>
        </trans-unit>
        <trans-unit id="37148505c5ccd477f2cd9888510233bf49ab48d7" translate="yes" xml:space="preserve">
          <source>Number of grid points. The path is linearly reinterpolated on a grid between 0 and 1 before computing the scores.</source>
          <target state="translated">그리드 포인트 수 점수는 계산하기 전에 0과 1 사이의 그리드에서 선형으로 보간됩니다.</target>
        </trans-unit>
        <trans-unit id="609fe53affef0db7e95afe01e9b3b2b42cfee225" translate="yes" xml:space="preserve">
          <source>Number of groups (&lt;code&gt;p&lt;/code&gt;) to leave out in the test split.</source>
          <target state="translated">테스트 스플릿에서 제외 할 그룹 수 ( &lt;code&gt;p&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="7836a44e33451a2adc5e90b29cc50de43f4df6df" translate="yes" xml:space="preserve">
          <source>Number of iteration done before the next print.</source>
          <target state="translated">다음 인쇄 전에 수행 된 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="58ef557aa3516e101a9370d2bf015690817ac32f" translate="yes" xml:space="preserve">
          <source>Number of iteration rounds that occurred. Will be less than &lt;code&gt;self.max_iter&lt;/code&gt; if early stopping criterion was reached.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7ee7fcff30c38dbe60673fcfaba39d5dcac363e" translate="yes" xml:space="preserve">
          <source>Number of iterations corresponding to the best results. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">최상의 결과에 해당하는 반복 횟수입니다. &lt;code&gt;return_n_iter&lt;/code&gt; 가 True로 설정된 경우에만 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="b6dedae4e35c925119d2eb7b698bd022b8304ae7" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;randomized_svd&lt;/code&gt;&lt;/a&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b89cf5a40a3578805b3d3e22f18c4e3365baf655" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;code&gt;randomized_svd&lt;/code&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">무작위 SVD 솔버에 대한 반복 횟수입니다. ARPACK에서는 사용하지 않습니다. 느리게 감쇠하는 큰 스펙트럼을 가질 수있는 희소 행렬을 처리하기 위해 기본값은 &lt;code&gt;randomized_svd&lt;/code&gt; 의 기본값보다 큽니다.</target>
        </trans-unit>
        <trans-unit id="b158b03d08af1b718d3d75c350a03244a2d1a76a" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method computed by svd_solver == &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">svd_solver == 'randomized'에 의해 계산 된 전력 방법의 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="ea8482c683ec2d466d38eba89e78f2c408d93dba" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method. 3 by default. Only used if &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;</source>
          <target state="translated">전력 방법의 반복 횟수입니다. 기본적으로 3입니다. &lt;code&gt;svd_method&lt;/code&gt; 가 'randomized'와 같은 경우에만 사용</target>
        </trans-unit>
        <trans-unit id="e2a3f7897a04130ec9ab6e8a06f184c73a2db962" translate="yes" xml:space="preserve">
          <source>Number of iterations needed for the spatial median.</source>
          <target state="translated">공간 중앙값에 필요한 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="0a6f367644c8353f5e90ff32f9e722b8b3c35762" translate="yes" xml:space="preserve">
          <source>Number of iterations of the EM step.</source>
          <target state="translated">EM 단계의 반복 횟수</target>
        </trans-unit>
        <trans-unit id="ca85b057132e8737cc9bd5d9895d1c2f0a3952a0" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component.</source>
          <target state="translated">각 구성 요소에 대한 NIPALS 내부 루프의 반복 횟수</target>
        </trans-unit>
        <trans-unit id="38592412005a60e12235ac166647e6d24941d551" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component. Not useful if the algorithm provided is &amp;ldquo;svd&amp;rdquo;.</source>
          <target state="translated">각 구성 요소에 대한 NIPALS 내부 루프의 반복 횟수 제공된 알고리즘이 &quot;svd&quot;인 경우 유용하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="b3f0661f5b6a537d1cfcf27ec4e37f08f53a4a65" translate="yes" xml:space="preserve">
          <source>Number of iterations run for the optimal alpha.</source>
          <target state="translated">최적의 알파에 대해 반복 횟수가 실행됩니다.</target>
        </trans-unit>
        <trans-unit id="c9d82135ee15642aa7ae8817dc570334ab80622b" translate="yes" xml:space="preserve">
          <source>Number of iterations run.</source>
          <target state="translated">반복 횟수</target>
        </trans-unit>
        <trans-unit id="cc453132656fb5fe083f1f7f5f3c0a7066108d51" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">반복 횟수 &lt;code&gt;return_n_iter&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 로 설정된 경우에만 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="346838eb1c236609499116f6804a1aeab6029a68" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">반복 횟수 &lt;code&gt;return_n_iter&lt;/code&gt; 가 True로 설정된 경우에만 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="bae285cae0e2d21ef6dbbaa8dd54db30234b47e0" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if return_n_iter is set to True.</source>
          <target state="translated">반복 횟수 return_n_iter가 True로 설정된 경우에만 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="6e040a3af3a9255e0d8c4455bc3543184ccbc3ff" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to an invalid model defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;is_model_valid&lt;/code&gt; 에 의해 정의 된 유효하지 않은 모델로 인해 건너 뛴 반복 수입니다 .</target>
        </trans-unit>
        <trans-unit id="51f697c488b6017321338ddb492864c9436800d7" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to finding zero inliers.</source>
          <target state="translated">0의 내부자를 찾아서 반복 횟수를 건너 뛰었습니다.</target>
        </trans-unit>
        <trans-unit id="6eebd535eebcad36fc18ca23295141a0bc8384b3" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;is_data_valid&lt;/code&gt; 에 의해 정의 된 유효하지 않은 데이터로 인해 건너 뛴 반복 수입니다 .</target>
        </trans-unit>
        <trans-unit id="2b48b7f3d47c667152c7041a648c896ae52b12ff" translate="yes" xml:space="preserve">
          <source>Number of iterations taken to converge.</source>
          <target state="translated">수렴되는 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="63b22566940c8c05aad34ed364e32e6bea85ba5f" translate="yes" xml:space="preserve">
          <source>Number of iterations that &lt;code&gt;scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)&lt;/code&gt; has run for.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e35e76f80d1bcb32a849fe5cd7421a6593683d9d" translate="yes" xml:space="preserve">
          <source>Number of iterations that fmin_l_bfgs_b has run for.</source>
          <target state="translated">fmin_l_bfgs_b가 실행 한 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="e6fe9562687f3b9f37db26e9dd5d7295821884aa" translate="yes" xml:space="preserve">
          <source>Number of iterations to perform.</source>
          <target state="translated">수행 할 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="744edb5cd8af9d3cbdec3cef824f76ed36468258" translate="yes" xml:space="preserve">
          <source>Number of iterations with no change in the number of estimated clusters that stops the convergence.</source>
          <target state="translated">수렴을 중지하는 예상 군집 수의 변경이없는 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="1bb6572e9c67b7f2e1d3c0099c8130bc63fa4d36" translate="yes" xml:space="preserve">
          <source>Number of iterations with no improvement to wait before early stopping.</source>
          <target state="translated">조기 중지 전에 대기 할 개선이없는 반복 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="427bd42a1575036c8163feb881b5305713a1194a" translate="yes" xml:space="preserve">
          <source>Number of iterations. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">반복 횟수 &lt;code&gt;return_n_iter&lt;/code&gt; 가 True로 설정된 경우에만 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="20dbe7868d12b42e72b8007b758b8aa006423eb6" translate="yes" xml:space="preserve">
          <source>Number of iterations/sweeps over the training dataset to perform during training.</source>
          <target state="translated">훈련 중에 수행 할 훈련 데이터 세트에 대한 반복 / 스윕 수입니다.</target>
        </trans-unit>
        <trans-unit id="805e89de9bc259ba0d4faba86a9892d5aeb2c894" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">병렬로 실행할 작업 수 &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="f64638965b4156e5561d4f1aeb7b5023899255aa" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68e07911a64110ae2d25f4573c1be042d5d1283e" translate="yes" xml:space="preserve">
          <source>Number of label for each output.</source>
          <target state="translated">각 출력의 레이블 수</target>
        </trans-unit>
        <trans-unit id="bd419af7c37c78ed35cd8f556746c5d780f24447" translate="yes" xml:space="preserve">
          <source>Number of layers.</source>
          <target state="translated">레이어 수</target>
        </trans-unit>
        <trans-unit id="4192e6479d3e36a298ef5ede4c2274eeba61eb5b" translate="yes" xml:space="preserve">
          <source>Number of leaves in the hierarchical tree.</source>
          <target state="translated">계층 트리의 잎 수입니다.</target>
        </trans-unit>
        <trans-unit id="ba1aa7966ff18979251514a0f2aad7e015769458" translate="yes" xml:space="preserve">
          <source>Number of leaves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfcbfd1023f8a82de0be1bdb45b84e4fb92fdade" translate="yes" xml:space="preserve">
          <source>Number of mini-batch iterations to perform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bc27955a0ba30e7799dd7d637ec50bb558a2a01" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors effectively used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eff81c828ce86aeb5087b71b68182742b417d4b0" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors for nearest_neighbors graph building.</source>
          <target state="translated">가장 가까운 이웃 그래프 빌딩에 대한 가장 가까운 이웃의 수입니다.</target>
        </trans-unit>
        <trans-unit id="f4b6da30fa273de202c93a0a24f9b983a9a2a207" translate="yes" xml:space="preserve">
          <source>Number of neighboring samples to use for imputation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="216e3472c822df844cda9519c2636b73cd479f24" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample in the transformed sparse graph. For compatibility reasons, as each sample is considered as its own neighbor, one extra neighbor will be computed when mode == &amp;lsquo;distance&amp;rsquo;. In this case, the sparse graph contains (n_neighbors + 1) neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37fe95cfc748f25efeacf97021fc7a2313be0b5a" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample.</source>
          <target state="translated">각 샘플의 이웃 수입니다.</target>
        </trans-unit>
        <trans-unit id="51b538d5b2a3f95b9485557e25d620a9a782f3b4" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample. (default is value passed to the constructor).</source>
          <target state="translated">각 샘플의 이웃 수입니다. (기본값은 생성자에게 전달되는 값입니다).</target>
        </trans-unit>
        <trans-unit id="efd458290903df55801a7ce6bf62f9ba73dd0009" translate="yes" xml:space="preserve">
          <source>Number of neighbors k that will be considered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3cee20cf7566ae95a6af940493b4c430f93d3a6" translate="yes" xml:space="preserve">
          <source>Number of neighbors required. If not provided, this will return the number specified at the initialization.</source>
          <target state="translated">필요한 이웃 수 제공하지 않으면 초기화시 지정된 숫자가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="1e55799760cfa2d3bdbd572fe607c1fc4b77b9d7" translate="yes" xml:space="preserve">
          <source>Number of neighbors to be returned from query function when it is not provided to the &lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; 메소드에 제공되지 않은 경우 쿼리 함수에서 리턴되는 이웃 수입니다 .</target>
        </trans-unit>
        <trans-unit id="3262363328a422de3ed07567136a319deb9ad271" translate="yes" xml:space="preserve">
          <source>Number of neighbors to get (default is the value passed to the constructor).</source>
          <target state="translated">가져올 이웃의 수입니다 (기본값은 생성자에게 전달 된 값입니다).</target>
        </trans-unit>
        <trans-unit id="02076e172db6b5e77d67d9ae83e2b88dc66a094e" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; 쿼리 에 기본적으로 사용할 이웃 수입니다 .</target>
        </trans-unit>
        <trans-unit id="e28eb76463a74cc573864c82f5c8b8d60708a92f" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; 쿼리 에 기본적으로 사용할 이웃 수입니다 .</target>
        </trans-unit>
        <trans-unit id="4a844d73b7e4afd6cea1487cf59defb5c0385114" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries. If n_neighbors is larger than the number of samples provided, all samples will be used.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; 쿼리 에 기본적으로 사용할 이웃 수입니다 . n_neighbors가 제공된 샘플 수보다 크면 모든 샘플이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="7e98c15b26d0846d8c1e878d641afc0e3d115b38" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; 쿼리 에 기본적으로 사용할 이웃 수입니다 .</target>
        </trans-unit>
        <trans-unit id="70cd89c4110a42556e2c733194f1c90f3d647ddb" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">연속 변수에 대한 MI 추정에 사용할 이웃의 수는 &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; 및 &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]을&lt;/a&gt; 참조하십시오 . 값이 클수록 추정의 분산이 감소하지만 편향이 발생할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="237e706a6f5317f1b4ad85e94d1e882cb7b24021" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">연속 변수에 대한 MI 추정에 사용할 이웃의 수는 &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; 및 &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]을&lt;/a&gt; 참조하십시오 . 값이 클수록 추정의 분산이 감소하지만 편향이 발생할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9f8819cc7687f8afeb7c24c0200033a234d0c39c" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use when constructing the affinity matrix using the nearest neighbors method. Ignored for &lt;code&gt;affinity='rbf'&lt;/code&gt;.</source>
          <target state="translated">가장 가까운 이웃 방법을 사용하여 선호도 매트릭스를 구성 할 때 사용할 이웃의 수입니다. &lt;code&gt;affinity='rbf'&lt;/code&gt; 에 대해 무시되었습니다 .</target>
        </trans-unit>
        <trans-unit id="c37287ec818bb6dad17b995ed5729153d9a8118d" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; and &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">솔루션의 각 열에서 타겟팅 할 0이 아닌 계수의 수입니다. 이것은 &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; 및 &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; 에서만 사용되며 &lt;code&gt;omp&lt;/code&gt; 경우 &lt;code&gt;alpha&lt;/code&gt; 로 대체됩니다 .</target>
        </trans-unit>
        <trans-unit id="3d8a9b81dd6bc7c054449c6745360802b0f076b9" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm='lars'&lt;/code&gt; and &lt;code&gt;algorithm='omp'&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0be2c79389c0a56a89ad2014f6366b3f95d2bca8" translate="yes" xml:space="preserve">
          <source>Number of other features to use to estimate the missing values of each feature column. Nearness between features is measured using the absolute correlation coefficient between each feature pair (after initial imputation). To ensure coverage of features throughout the imputation process, the neighbor features are not necessarily nearest, but are drawn with probability proportional to correlation for each imputed target feature. Can provide significant speed-up when the number of features is huge. If &lt;code&gt;None&lt;/code&gt;, all features will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27f9bf5a85bc89aa70ea3dbacba13e73a444a9f8" translate="yes" xml:space="preserve">
          <source>Number of outputs.</source>
          <target state="translated">출력 수</target>
        </trans-unit>
        <trans-unit id="a01758eccae198371ad1fbda71e0227c6924ab24" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">실행할 병렬 작업 수 &lt;code&gt;None&lt;/code&gt; 수단 1에서 않는 &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; 의&lt;/a&gt; 콘텍스트. &lt;code&gt;-1&lt;/code&gt; 은 모든 프로세서를 사용한다는 의미입니다. 자세한 내용은 &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;용어집&lt;/a&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="aec9eb1029d40469b12f590579b2421b0ac783c2" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89260d16706c6571daecae9b230dfb394e4f8e34" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are produced.</source>
          <target state="translated">생성 된 매개 변수 설정 수</target>
        </trans-unit>
        <trans-unit id="26680dedc0c193794be077118d1d33ec7cee22de" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.</source>
          <target state="translated">샘플링 된 매개 변수 설정 수 n_iter는 런타임과 솔루션의 품질을 교환합니다.</target>
        </trans-unit>
        <trans-unit id="9b3af5a87173ff58737497b2a7b2dff4ac22b716" translate="yes" xml:space="preserve">
          <source>Number of passes over the dataset.</source>
          <target state="translated">데이터 세트를 통한 패스 수입니다.</target>
        </trans-unit>
        <trans-unit id="e919298382f2b30ec9254222b02df5121a7447b9" translate="yes" xml:space="preserve">
          <source>Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified &lt;code&gt;leaf_size&lt;/code&gt;, a leaf node is guaranteed to satisfy &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt;, except in the case that &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt;.</source>
          <target state="translated">무차별 대입으로 전환 할 지점 수 leaf_size를 변경해도 쿼리 결과에는 영향을 미치지 않지만 쿼리 속도와 생성 된 트리를 저장하는 데 필요한 메모리에는 큰 영향을 줄 수 있습니다. 트리 스케일을 저장하는 데 필요한 메모리 양은 대략 n_samples / leaf_size로 조정됩니다. 지정된 &lt;code&gt;leaf_size&lt;/code&gt; 의 경우, 리프 노드는 &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt; 경우를 제외하고 &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt; 를 충족 시킵니다 .</target>
        </trans-unit>
        <trans-unit id="74f0e4f1324b195e40b6b67840245cc6639acde5" translate="yes" xml:space="preserve">
          <source>Number of power iterations used to stabilize the result</source>
          <target state="translated">결과 안정화에 사용 된 전력 반복 횟수</target>
        </trans-unit>
        <trans-unit id="3af0fded49ca0f3c99c5f4242edefb1980f1ee1e" translate="yes" xml:space="preserve">
          <source>Number of power iterations. It can be used to deal with very noisy problems. When &amp;lsquo;auto&amp;rsquo;, it is set to 4, unless &lt;code&gt;n_components&lt;/code&gt; is small (&amp;lt; .1 * min(X.shape)) &lt;code&gt;n_iter&lt;/code&gt; in which case is set to 7. This improves precision with few components.</source>
          <target state="translated">전원 반복 횟수 시끄러운 문제를 해결하는 데 사용할 수 있습니다. 'auto'인 경우 &lt;code&gt;n_components&lt;/code&gt; 가 작지 않은 경우 (&amp;lt;.1 * min (X.shape)) &lt;code&gt;n_iter&lt;/code&gt; 가 7이 아닌 경우 4로 설정됩니다. 이렇게하면 구성 요소가 거의 없어 정밀도가 향상됩니다.</target>
        </trans-unit>
        <trans-unit id="01905db27e1b09268197900ceb99a1346e890115" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The str can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c2b5ab18e2bf242894b9a2ecca14a388d432f49" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The string can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">병렬 실행을위한 사전 디스패치 된 작업 수 (기본값은 all) 이 옵션은 할당 된 메모리를 줄일 수 있습니다. 문자열은 '2 * n_jobs'와 같은 표현식 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="344e1da2c8fa0e4b376ce3e457a99189b911e25a" translate="yes" xml:space="preserve">
          <source>Number of previous iterations completed on the dictionary used for initialization.</source>
          <target state="translated">초기화에 사용 된 사전에서 완료된 이전 반복 수입니다.</target>
        </trans-unit>
        <trans-unit id="20853d9102158a366a61d28a6b2cb29c20c98681" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative density function.</source>
          <target state="translated">계산할 Quantile 수입니다. 누적 밀도 함수를 이산화시키는 데 사용되는 랜드 마크 수에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="548caec42d172e8575f71a33916af24287471704" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative distribution function. If n_quantiles is larger than the number of samples, n_quantiles is set to the number of samples as a larger number of quantiles does not give a better approximation of the cumulative distribution function estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4aaf1e86836dfafd99ac1220487fd647e794f84" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried with the k-means algorithm.</source>
          <target state="translated">k- 평균 알고리즘으로 시도한 임의 초기화 수입니다.</target>
        </trans-unit>
        <trans-unit id="b43bc8af90e8df6a17a3d2db5f152fc9e0f7509e" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the &lt;code&gt;n_init&lt;/code&gt; initializations as measured by inertia.</source>
          <target state="translated">시도한 임의 초기화 수입니다. KMeans와 달리 알고리즘은 관성으로 측정 된 최상의 &lt;code&gt;n_init&lt;/code&gt; 초기화를 사용하여 한 번만 실행 됩니다.</target>
        </trans-unit>
        <trans-unit id="2a775249dab61ada8ba714fbef3fe2a6cd5e7f9a" translate="yes" xml:space="preserve">
          <source>Number of random selection trials until one of the stop criteria is met. It is always &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt;.</source>
          <target state="translated">정지 기준 중 하나가 충족 될 때까지 무작위 선택 시험 횟수. 항상 &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="ddb00b53d153c760e3c244cb1587828c964053be" translate="yes" xml:space="preserve">
          <source>Number of randomized models.</source>
          <target state="translated">무작위 모델의 수</target>
        </trans-unit>
        <trans-unit id="6e7920a40024bb45accfba5d3a9412bad8885ccd" translate="yes" xml:space="preserve">
          <source>Number of re-shuffling &amp;amp; splitting iterations.</source>
          <target state="translated">재 셔플 링 및 분할 반복 횟수</target>
        </trans-unit>
        <trans-unit id="8c1de77526ac5586c3170ef35d398449f2b6a01e" translate="yes" xml:space="preserve">
          <source>Number of rows and columns (resp.) in the bicluster.</source>
          <target state="translated">bicluster의 행 및 열 수 (각각)입니다.</target>
        </trans-unit>
        <trans-unit id="ad1b9067ab876b7409a0c802cf769015719aca95" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">피팅 중 각 (클래스, 피처)에 대해 발생한 샘플 수입니다. 이 값은 제공된 경우 샘플 무게로 가중치가 부여됩니다.</target>
        </trans-unit>
        <trans-unit id="c92a24738a539e752aec89fe917078bdb81b48d8" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">피팅하는 동안 각 클래스에 대해 발생한 샘플 수입니다. 이 값은 제공된 경우 샘플 무게로 가중치가 부여됩니다.</target>
        </trans-unit>
        <trans-unit id="7d9434e4be81d003217d0ff99bec2958d6cf8f1c" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each feature during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">피팅하는 동안 각 기능에 대해 발생한 샘플 수입니다. 이 값은 제공된 경우 샘플 무게로 가중치가 부여됩니다.</target>
        </trans-unit>
        <trans-unit id="4189046e920c071a46d31153d30f2c5546e5d75d" translate="yes" xml:space="preserve">
          <source>Number of samples in a subcluster.</source>
          <target state="translated">서브 클러스터의 샘플 수</target>
        </trans-unit>
        <trans-unit id="d6a1b136f66f610a4896adec7fc65cb72260eca1" translate="yes" xml:space="preserve">
          <source>Number of samples in the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1b8d68fdf55246f42bd4140ab8cdd3ea5232e3c" translate="yes" xml:space="preserve">
          <source>Number of samples seen so far, excluded X.</source>
          <target state="translated">지금까지 본 샘플 수 (X 제외)</target>
        </trans-unit>
        <trans-unit id="f3eb4ebcff443a5740a69d115e4c7d66ed2b7058" translate="yes" xml:space="preserve">
          <source>Number of samples to calculate the parameters. This is at least the number of features (plus 1 if fit_intercept=True) and the number of samples as a maximum. A lower number leads to a higher breakdown point and a low efficiency while a high number leads to a low breakdown point and a high efficiency. If None, take the minimum number of subsamples leading to maximal robustness. If n_subsamples is set to n_samples, Theil-Sen is identical to least squares.</source>
          <target state="translated">매개 변수를 계산할 샘플 수입니다. 이것은 최소한 피처 수 (fit_intercept = True 인 경우 1을 더한 값)와 최대 샘플 수입니다. 숫자가 작을수록 고 장점 및 효율이 낮고 숫자가 클수록 고 장점 및 효율이 높습니다. 없음 인 경우 최대 수의 하위 샘플을 사용하여 최대의 견고성을 확보하십시오. n_subsamples가 n_samples로 설정되면 Theil-Sen은 최소 제곱과 동일합니다.</target>
        </trans-unit>
        <trans-unit id="fc350dda13f5c287c8548b6575ceb1d2c780f61c" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. Defaults to 1.</source>
          <target state="translated">생성 할 샘플 수입니다. 기본값은 1입니다.</target>
        </trans-unit>
        <trans-unit id="e94e897f1bb653d4e0feaefd5987d4a553f8af8b" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays.</source>
          <target state="translated">생성 할 샘플 수입니다. None으로두면 배열의 첫 번째 차원으로 자동 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="1a167b23f9bb21704b10da0ef2fc738d507dce40" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays. If replace is False it should not be larger than the length of arrays.</source>
          <target state="translated">생성 할 샘플 수입니다. None으로두면 배열의 첫 번째 차원으로 자동 설정됩니다. replace가 False이면 배열의 길이보다 크지 않아야합니다.</target>
        </trans-unit>
        <trans-unit id="37b65d0e64d2d03034e5f2f5fa109bac79447708" translate="yes" xml:space="preserve">
          <source>Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.</source>
          <target state="translated">초기화 속도를 높이기 위해 무작위로 샘플링 할 샘플 수 (때로는 정확성을 희생 함) : 임의의 데이터 하위 집합에서 배치 KMeans를 실행하여 유일한 알고리즘을 초기화합니다. n_clusters보다 커야합니다.</target>
        </trans-unit>
        <trans-unit id="79fd133ee683290a8c4b438718235e4555547cff" translate="yes" xml:space="preserve">
          <source>Number of samples. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">샘플 수 배열이 제공되면 안전한 배열의 구성 요소를 배열별로 계산합니다.</target>
        </trans-unit>
        <trans-unit id="ea4ca73ab41ec6033a853674e7fbc815a311d3cf" translate="yes" xml:space="preserve">
          <source>Number of samples. Pass n_samples when the slices are to be used for sparse matrix indexing; slicing off-the-end raises an exception, while it works for NumPy arrays.</source>
          <target state="translated">샘플 수 슬라이스가 희소 행렬 인덱싱에 사용될 경우 n_samples를 전달하십시오. NumPy 배열에서 작동하는 동안 최첨단 슬라이스는 예외를 발생시킵니다.</target>
        </trans-unit>
        <trans-unit id="a75d9ceb8c321c78e9909168b2356ee01f06d1c4" translate="yes" xml:space="preserve">
          <source>Number of singular values and vectors to extract.</source>
          <target state="translated">추출 할 특이 값 및 벡터 수입니다.</target>
        </trans-unit>
        <trans-unit id="9259a302604f8c3d052d9766a0665f74598f4a66" translate="yes" xml:space="preserve">
          <source>Number of singular vectors to check.</source>
          <target state="translated">확인할 특이 벡터의 수입니다.</target>
        </trans-unit>
        <trans-unit id="4e03fb606fcab969781bb42da4618d24e54a8291" translate="yes" xml:space="preserve">
          <source>Number of slices to generate.</source>
          <target state="translated">생성 할 슬라이스 수입니다.</target>
        </trans-unit>
        <trans-unit id="2834c0f8a56b1dcfce6f6e78db200759bce6dd7b" translate="yes" xml:space="preserve">
          <source>Number of spaces between edges. The higher it is, the wider the result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c55cc369cb9552b44b4a575f3aae7b0b751a97c8" translate="yes" xml:space="preserve">
          <source>Number of sparse atoms to extract.</source>
          <target state="translated">추출 할 희소 원자의 수입니다.</target>
        </trans-unit>
        <trans-unit id="133c33b7f976c18813a243c5632b24f2c8e81111" translate="yes" xml:space="preserve">
          <source>Number of splits. Must be at least 2.</source>
          <target state="translated">스플릿 수 2 이상이어야합니다.</target>
        </trans-unit>
        <trans-unit id="a6bce09538dcde7e7ff60020a73de4974cae38ac" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of EM to reach the convergence.</source>
          <target state="translated">수렴에 도달하기 위해 EM에 가장 잘 맞는 단계 수입니다.</target>
        </trans-unit>
        <trans-unit id="aec50834e9d4a500ee385c37d29d58bdc624bb7e" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of inference to reach the convergence.</source>
          <target state="translated">수렴에 도달하기 위해 가장 적합한 유추에 의해 사용 된 단계 수입니다.</target>
        </trans-unit>
        <trans-unit id="ef96b42c053cf6cd51d23012a0a52b84b2a07604" translate="yes" xml:space="preserve">
          <source>Number of support vectors for each class.</source>
          <target state="translated">각 클래스의 지원 벡터 수</target>
        </trans-unit>
        <trans-unit id="424ae2b2f85d63b5b83778ea64c14167e1acf984" translate="yes" xml:space="preserve">
          <source>Number of targets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abc9da602c481111cdc9cad2b9a2ec618fddfb11" translate="yes" xml:space="preserve">
          <source>Number of test samples in this split.</source>
          <target state="translated">이 분할의 테스트 샘플 수입니다.</target>
        </trans-unit>
        <trans-unit id="35ccbd0ed91056f0b431a8e36f769a8655c75e9b" translate="yes" xml:space="preserve">
          <source>Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.</source>
          <target state="translated">k- 평균 알고리즘이 다른 중심 시드로 실행될 시간입니다. 최종 결과는 관성 측면에서 n_init 연속 실행의 최상의 결과입니다.</target>
        </trans-unit>
        <trans-unit id="f584f00fb96d0392221b2f107adcb2345328d3b9" translate="yes" xml:space="preserve">
          <source>Number of times cross-validator needs to be repeated.</source>
          <target state="translated">교차 유효성 검사기를 반복해야하는 횟수입니다.</target>
        </trans-unit>
        <trans-unit id="5d2e8dfe07ab898c902f4c479175b6b09037f98d" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress.</source>
          <target state="translated">SMACOF 알고리즘이 다른 초기화로 실행되는 횟수입니다. 최종 결과는 최종 응력이 가장 작은 런에 의해 결정된 런의 최상의 결과가됩니다.</target>
        </trans-unit>
        <trans-unit id="61d47a44584bfde40c1396e5d7fc8603c469e589" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress. If &lt;code&gt;init&lt;/code&gt; is provided, this option is overridden and a single run is performed.</source>
          <target state="translated">SMACOF 알고리즘이 다른 초기화로 실행되는 횟수입니다. 최종 결과는 최종 응력이 가장 작은 런에 의해 결정된 런의 최상의 결과가됩니다. 경우 &lt;code&gt;init&lt;/code&gt; 제공되며,이 옵션을 무시하고 하나의 실행을 수행한다.</target>
        </trans-unit>
        <trans-unit id="279a7d188f8d456ddd160319a5480a2db5aa1c81" translate="yes" xml:space="preserve">
          <source>Number of times to permute &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; 를 순회하는 횟수 입니다.</target>
        </trans-unit>
        <trans-unit id="463dac0c15a56b554ec940dbcedbd42982c379fb" translate="yes" xml:space="preserve">
          <source>Number of times to permute a feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69631a318e07c7e122bb29c914f2e0417bbb3ea3" translate="yes" xml:space="preserve">
          <source>Number of top features to select. The &amp;ldquo;all&amp;rdquo; option bypasses selection, for use in a parameter search.</source>
          <target state="translated">선택할 최고 기능 수입니다. &amp;ldquo;모두&amp;rdquo;옵션은 매개 변수 검색에 사용하기 위해 선택을 무시합니다.</target>
        </trans-unit>
        <trans-unit id="da4c15da76668749b2d08dac7e93fa89fa01cae3" translate="yes" xml:space="preserve">
          <source>Number of topics.</source>
          <target state="translated">주제 수</target>
        </trans-unit>
        <trans-unit id="fbddcfb20eac49b636d0567ae2783e45f24d5db9" translate="yes" xml:space="preserve">
          <source>Number of trees in the LSH Forest.</source>
          <target state="translated">LSH 숲에있는 나무의 수.</target>
        </trans-unit>
        <trans-unit id="f59a66952049f5c09c592626a93864184fb52de6" translate="yes" xml:space="preserve">
          <source>Number of trees in the forest.</source>
          <target state="translated">숲에서 나무의 수입니다.</target>
        </trans-unit>
        <trans-unit id="883143c355bb70d9c124548ac182b0a674cf4c90" translate="yes" xml:space="preserve">
          <source>Number of values per feature.</source>
          <target state="translated">기능 당 값 수</target>
        </trans-unit>
        <trans-unit id="3d3c8a841ea2fec708f92a22e6cb69db77e1725b" translate="yes" xml:space="preserve">
          <source>Number of vectors to use in calculating the SVD. Corresponds to &lt;code&gt;ncv&lt;/code&gt; when &lt;code&gt;svd_method=arpack&lt;/code&gt; and &lt;code&gt;n_oversamples&lt;/code&gt; when &lt;code&gt;svd_method&lt;/code&gt; is &amp;lsquo;randomized`.</source>
          <target state="translated">SVD 계산에 사용할 벡터 수입니다. 대응한다합니다 &lt;code&gt;ncv&lt;/code&gt; 때 &lt;code&gt;svd_method=arpack&lt;/code&gt; 및 &lt;code&gt;n_oversamples&lt;/code&gt; 때 &lt;code&gt;svd_method&lt;/code&gt; 가 'randomized`입니다.</target>
        </trans-unit>
        <trans-unit id="16bf53dde5c63fb6777b19bf3ca8bb646d21ca57" translate="yes" xml:space="preserve">
          <source>Number of weight updates performed during training. Same as &lt;code&gt;(n_iter_ * n_samples)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfc2be0c624984ee3eedecc63144bb2eb0e00cd3" translate="yes" xml:space="preserve">
          <source>Numbers of training examples that has been used to generate the learning curve. Note that the number of ticks might be less than n_ticks because duplicate entries will be removed.</source>
          <target state="translated">학습 곡선을 생성하는 데 사용 된 교육 예제 수 중복 항목이 제거되므로 틱 수는 n_ticks보다 작을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="a28c04c9b4b005997c9b362ad026f41b8cd86540" translate="yes" xml:space="preserve">
          <source>Numeric Features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89c43bf4b62114e4d6b82aa7a39bcd64acde71ea" translate="yes" xml:space="preserve">
          <source>Numeric stopping criterion (WRITEME). 1e-3 by default.</source>
          <target state="translated">숫자 정지 기준 (WRITEME). 기본적으로 1e-3.</target>
        </trans-unit>
        <trans-unit id="546b4b9a9bb1a271c23a369b5102c7b719bb257b" translate="yes" xml:space="preserve">
          <source>Numerical solver to use.</source>
          <target state="translated">사용할 수치 솔버.</target>
        </trans-unit>
        <trans-unit id="e91bee1467e40de4d946ed662375c173925b59f5" translate="yes" xml:space="preserve">
          <source>Numerical solver to use:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bda3e35c6cc189118f551c9ef807d4c37dc07f6" translate="yes" xml:space="preserve">
          <source>Numerical solver to use: &amp;lsquo;cd&amp;rsquo; is a Coordinate Descent solver. &amp;lsquo;mu&amp;rsquo; is a Multiplicative Update solver.</source>
          <target state="translated">사용할 수치 솔버 : 'cd'는 좌표 하강 솔버입니다. 'mu'는 Multiplicative Update 솔버입니다.</target>
        </trans-unit>
        <trans-unit id="c42d401e991cba0a784aff1388e26ed9b57a65e8" translate="yes" xml:space="preserve">
          <source>O. Ledoit and M. Wolf, &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">O. Ledoit 및 M. Wolf,&amp;ldquo;대규모 공분산 행렬에 대한 잘 구성된 추정량&amp;rdquo;, 다변량 분석 저널, 88 권, 2004 년 2 월 2 호, 365-411 페이지.</target>
        </trans-unit>
        <trans-unit id="e39d7c7a6dfc71c75f7fd3b1688e4255ab0569b5" translate="yes" xml:space="preserve">
          <source>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.</source>
          <target state="translated">OL Mangasarian, WN Street 및 WH Wolberg. 선형 프로그래밍을 통한 유방암 진단 및 예후. 운영 연구, 43 (4), 570-577 페이지, 1995 년 7 월 -8 월.</target>
        </trans-unit>
        <trans-unit id="dea6ae2f186812bc2bf8114a674ec0e8c8de8039" translate="yes" xml:space="preserve">
          <source>OAS is a particular form of shrinkage described in &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">OAS는 &quot;MMSE 공분산 추정을위한 수축 알고리즘&quot;Chen et al., IEEE Trans. 서명. Proc., Volume 58, Issue 10, 2010 년 10 월.</target>
        </trans-unit>
        <trans-unit id="516f97783bd415e3a50d6dad8302febb07d2e198" translate="yes" xml:space="preserve">
          <source>OCCUPATION</source>
          <target state="translated">OCCUPATION</target>
        </trans-unit>
        <trans-unit id="d588c2d5cad6e344a9a328bc0dcc94f63bfe1c53" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Clerical</source>
          <target state="translated">OCCUPATION_Clerical</target>
        </trans-unit>
        <trans-unit id="b725bc8de0a483c5d88499d9e7c87c7ae4685ba8" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Management</source>
          <target state="translated">OCCUPATION_Management</target>
        </trans-unit>
        <trans-unit id="0e54eeff266f2a17bed8c69e66148a30421390e0" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Other</source>
          <target state="translated">OCCUPATION_Other</target>
        </trans-unit>
        <trans-unit id="d50ba20894189c3830106f0cfb4a70b0e6554b4e" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Professional</source>
          <target state="translated">OCCUPATION_Professional</target>
        </trans-unit>
        <trans-unit id="d9264bc2d4c97fd3584da75ee0731d202c6b28fe" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Sales</source>
          <target state="translated">OCCUPATION_Sales</target>
        </trans-unit>
        <trans-unit id="7c720959f75a9b22fee1afe843481ec6692d4aa6" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Service</source>
          <target state="translated">OCCUPATION_Service</target>
        </trans-unit>
        <trans-unit id="f3fd8009dd2433d1a63abbabb480a18d05e74108" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines</source>
          <target state="translated">희석 된 와인의 OD280 / OD315</target>
        </trans-unit>
        <trans-unit id="2f76e133c144664f6ceed4509b6ad3d9fe14a67d" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines:</source>
          <target state="translated">희석 된 와인의 OD280 / OD315 :</target>
        </trans-unit>
        <trans-unit id="9ce3bd4224c8c1780db56b4125ecf3f24bf748b7" translate="yes" xml:space="preserve">
          <source>OK</source>
          <target state="translated">OK</target>
        </trans-unit>
        <trans-unit id="8e8565eb895a4e523ac266f2a6f2af45cda869f8" translate="yes" xml:space="preserve">
          <source>OMP is based on a greedy algorithm that includes at each step the atom most highly correlated with the current residual. It is similar to the simpler matching pursuit (MP) method, but better in that at each iteration, the residual is recomputed using an orthogonal projection on the space of the previously chosen dictionary elements.</source>
          <target state="translated">OMP는 각 단계에서 현재 잔차와 가장 밀접한 상관 관계를 갖는 탐욕 알고리즘을 기반으로합니다. 이는 단순한 매칭 추구 (MP) 방법과 유사하지만, 각 반복에서 잔차는 이전에 선택한 사전 요소의 공간에서 직교 투영을 사용하여 재 계산된다는 점에서 더 좋습니다.</target>
        </trans-unit>
        <trans-unit id="702567365ae2f6da8d5fc9650aab7f68f2e2b4bd" translate="yes" xml:space="preserve">
          <source>OOB Errors for Random Forests</source>
          <target state="translated">임의 포리스트의 OOB 오류</target>
        </trans-unit>
        <trans-unit id="7556880ffb905f4996fa16b161902fde13e5d1be" translate="yes" xml:space="preserve">
          <source>OPTICS</source>
          <target state="translated">OPTICS</target>
        </trans-unit>
        <trans-unit id="3921b01080f70880ca169ee2dd262001f08a9a03" translate="yes" xml:space="preserve">
          <source>OPTICS (Ordering Points To Identify the Clustering Structure), closely related to DBSCAN, finds core sample of high density and expands clusters from them &lt;a href=&quot;#r2c55e37003fe-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. Unlike DBSCAN, keeps cluster hierarchy for a variable neighborhood radius. Better suited for usage on large datasets than the current sklearn implementation of DBSCAN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3657cfede2d1ca1450e1e96704c7fe1e79174b7f" translate="yes" xml:space="preserve">
          <source>OPTICS ordered point indices (&lt;code&gt;ordering_&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b77a29777f0317be507e501f5c60c74e4daaff5" translate="yes" xml:space="preserve">
          <source>OR, if affinity==`precomputed`, a precomputed affinity matrix of shape (n_samples, n_samples)</source>
          <target state="translated">또는 선호도가 = 사전 계산 된 경우 사전 계산 된 형태의 선호도 행렬 (n_samples, n_samples)</target>
        </trans-unit>
        <trans-unit id="c8f36dd22506f2db935605e7016ba4725ee8d954" translate="yes" xml:space="preserve">
          <source>OVR + L1 penalty</source>
          <target state="translated">OVR + L1 페널티</target>
        </trans-unit>
        <trans-unit id="6fb4b4e4f3901ecb1795e224abe18919de690335" translate="yes" xml:space="preserve">
          <source>OVR + L2 penalty</source>
          <target state="translated">OVR + L2 페널티</target>
        </trans-unit>
        <trans-unit id="cb5d65d3f62b5d33c694bb026fc2cc2e2c9008af" translate="yes" xml:space="preserve">
          <source>Object that mocks the urlopen function to fake requests to mldata.</source>
          <target state="translated">mldata에 대한 요청을 가짜로 만들기 위해 urlopen 함수를 조롱하는 객체입니다.</target>
        </trans-unit>
        <trans-unit id="e59a9b80a8b5844a54b21160c3e6341a042b77f2" translate="yes" xml:space="preserve">
          <source>Object that stores computed values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04c754a9ec758f22d2ae91b0fe2718c4051ca8ed" translate="yes" xml:space="preserve">
          <source>Object used to transform multiclass labels to binary labels and vice-versa.</source>
          <target state="translated">멀티 클래스 레이블을 이진 레이블로 또는 그 반대로 변환하는 데 사용되는 객체입니다.</target>
        </trans-unit>
        <trans-unit id="cdd1673e245cacca55f04fb3561b4eb5194072ad" translate="yes" xml:space="preserve">
          <source>Objects that will be checked for consistent length.</source>
          <target state="translated">일관된 길이를 확인할 객체입니다.</target>
        </trans-unit>
        <trans-unit id="ca9385c00c56b402f0d7c8ffd3817a9453089565" translate="yes" xml:space="preserve">
          <source>Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</source>
          <target state="translated">의사 결정 트리와 순진한 베이지안 분류기에서 보정 된 확률 추정값 얻기, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</target>
        </trans-unit>
        <trans-unit id="e90a2c57a395bd5ca1744a90561d5ec67c512ffb" translate="yes" xml:space="preserve">
          <source>Obviously when the number of features increases so does the memory consumption of each example. Indeed, for a matrix of \(M\) instances with \(N\) features, the space complexity is in \(O(NM)\). From a computing perspective it also means that the number of basic operations (e.g., multiplications for vector-matrix products in linear models) increases too. Here is a graph of the evolution of the prediction latency with the number of features:</source>
          <target state="translated">분명히 기능의 수가 증가하면 각 예제의 메모리 소비도 증가합니다. 실제로 \ (N \) 기능이있는 \ (M \) 인스턴스의 행렬의 경우 공간 복잡도는 \ (O (NM) \)입니다. 컴퓨팅 관점에서 볼 때 이는 기본 연산의 수 (예 : 선형 모델에서 벡터 행렬 제품의 곱셈)도 증가 함을 의미합니다. 다음은 기능 수에 따른 예측 대기 시간의 진화 그래프입니다.</target>
        </trans-unit>
        <trans-unit id="215c08c61e401481973fc6ab07ef3f7e0eb253cc" translate="yes" xml:space="preserve">
          <source>Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel with the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If we give this parameter a value of &lt;code&gt;-1&lt;/code&gt;, grid search will detect how many cores are installed and use them all:</source>
          <target state="translated">분명히, 이러한 철저한 검색은 비용이 많이들 수 있습니다. 처분에 여러 개의 CPU 코어가있는 경우 그리드 검색 자에게 &lt;code&gt;n_jobs&lt;/code&gt; 매개 변수 와 병렬로이 8 가지 매개 변수 조합을 시도하도록 지시 할 수 있습니다. 이 매개 변수에 &lt;code&gt;-1&lt;/code&gt; 값을 지정 하면 그리드 검색은 설치된 코어 수를 감지하여 모두 사용합니다.</target>
        </trans-unit>
        <trans-unit id="b4b9ad57c64718cb6c7c5d4cbab51ee018de2ade" translate="yes" xml:space="preserve">
          <source>Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.</source>
          <target state="translated">발생 횟수는 좋은 시작이지만 문제가 있습니다. 동일한 주제에 대해 이야기하더라도 긴 문서는 짧은 문서보다 평균 카운트 값이 더 높습니다.</target>
        </trans-unit>
        <trans-unit id="ca59a1039148105183d8291ca83a4fbed4483e6f" translate="yes" xml:space="preserve">
          <source>Of course, we cannot use the transformer to make any predictions. We should wrap this in a &lt;code&gt;Pipeline&lt;/code&gt; with a classifier (e.g., a &lt;code&gt;DecisionTreeClassifier&lt;/code&gt;) to be able to make predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d31e6b35c3a4fbda0c959d2368ee4f77d248cc70" translate="yes" xml:space="preserve">
          <source>Of particular interest is the ability of &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt; to mimic the behavior of missForest, a popular imputation package for R. In this example, we have chosen to use &lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; instead of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestRegressor&lt;/code&gt;&lt;/a&gt; (as in missForest) due to its increased speed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2bfdaca8f6fadc90e32a081ace94f3ad9884e84" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64b2af0bc2328de785be4029344182e16e12fcc6" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. Assuming behaviour == &amp;lsquo;new&amp;rsquo;, &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training. Assuming the behaviour parameter is set to &amp;lsquo;old&amp;rsquo;, we always have &lt;code&gt;offset_ = -0.5&lt;/code&gt;, making the decision function independent from the contamination parameter.</source>
          <target state="translated">원시 점수에서 의사 결정 기능을 정의하는 데 사용되는 오프셋. 우리는 &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 관계가 있습니다 . behavior == 'new'라고 가정하면 &lt;code&gt;offset_&lt;/code&gt; 은 다음과 같이 정의됩니다. 오염 매개 변수가 &quot;auto&quot;로 설정되면, 이너의 점수가 0에 가까워지고, 이상치의 점수가 -1에 가까워지면 오프셋은 -0.5와 같습니다. &quot;auto&quot;와 다른 오염 매개 변수가 제공 될 때, 오프셋은 훈련에서 예상 개수의 이상치 (결정 기능이 &amp;lt;0 인 샘플)를 얻는 방식으로 정의됩니다. 행동 매개 변수가 'old'로 설정되어 있다고 가정하면, 우리는 항상 &lt;code&gt;offset_ = -0.5&lt;/code&gt; 가지며 , 결정 기능을 오염 매개 변수와 독립적으로 만듭니다.</target>
        </trans-unit>
        <trans-unit id="bbd227107da9d921e8bc12d3a3ca7fd4c0bd101f" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. The offset depends on the contamination parameter and is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">원시 점수에서 의사 결정 기능을 정의하는 데 사용되는 오프셋. 우리는 &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 관계가 있습니다 . 오프셋은 오염 매개 변수에 따라 다르며 훈련에서 예상 개수의 특이 치 (결정 기능이 &amp;lt;0 인 샘플)를 얻는 방식으로 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="4f4356395ebd6023fbdce24e12feab7e5ca80606" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt;. The offset is the opposite of &lt;code&gt;intercept_&lt;/code&gt; and is provided for consistency with other outlier detection algorithms.</source>
          <target state="translated">원시 점수에서 의사 결정 기능을 정의하는 데 사용되는 오프셋. 우리는 관계를 가지고 decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt; 을 . 오프셋은 &lt;code&gt;intercept_&lt;/code&gt; 와 반대이며 다른 이상치 탐지 알고리즘과의 일관성을 위해 제공됩니다.</target>
        </trans-unit>
        <trans-unit id="9195b75fbc020bb9db88d8b131967914e6de2adf" translate="yes" xml:space="preserve">
          <source>Offset used to obtain binary labels from the raw scores. Observations having a negative_outlier_factor smaller than &lt;code&gt;offset_&lt;/code&gt; are detected as abnormal. The offset is set to -1.5 (inliers score around -1), except when a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided. In that case, the offset is defined in such a way we obtain the expected number of outliers in training.</source>
          <target state="translated">원시 점수에서 이진 레이블을 얻는 데 사용되는 오프셋입니다. &lt;code&gt;offset_&lt;/code&gt; 보다 작은 negative_outlier_factor를 갖는 관찰 은 비정상으로 감지됩니다. &quot;auto&quot;와 다른 오염 매개 변수가 제공되는 경우를 제외하고 오프셋은 -1.5 (내부 점수 -1 정도)로 설정됩니다. 이 경우 오프셋은 훈련에서 예상되는 이상치 수를 얻는 방식으로 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="36fd88d1882973048dccc0ac8ca74e6c4f6b2ec1" translate="yes" xml:space="preserve">
          <source>Often features are not given as continuous values but categorical. For example a person could have features &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt;. Such features can be efficiently coded as integers, for instance &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; could be expressed as &lt;code&gt;[0, 1, 3]&lt;/code&gt; while &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; would be &lt;code&gt;[1, 2, 1]&lt;/code&gt;.</source>
          <target state="translated">기능은 연속적인 값으로 제공되지 않고 범주 형인 경우가 많습니다. 예를 들어 사람에게 &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt; , &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt; , &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; . 이러한 기능은 정수로 효율적으로 코딩 할 수 있습니다. 예를 들어 &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; 은 &lt;code&gt;[0, 1, 3]&lt;/code&gt; 으로 표현할 수 있지만 &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; 은 &lt;code&gt;[1, 2, 1]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="3d1f21e77b74fb7449c1f9b0570088bab1bd6c20" translate="yes" xml:space="preserve">
          <source>Often features do not contribute equally to predict the target response; in many situations the majority of the features are in fact irrelevant. When interpreting a model, the first question usually is: what are those important features and how do they contributing in predicting the target response?</source>
          <target state="translated">종종 특징은 목표 반응을 예측하는 데 똑같이 기여하지 않습니다. 많은 상황에서 기능의 대부분은 실제로 관련이 없습니다. 모델을 해석 할 때 첫 번째 질문은 일반적으로 중요한 기능은 무엇이며 목표 응답을 예측하는 데 어떻게 기여 하는가입니다.</target>
        </trans-unit>
        <trans-unit id="cd4e41585434180ead957592fb3bbf7ed399aaf1" translate="yes" xml:space="preserve">
          <source>Often it&amp;rsquo;s useful to add complexity to the model by considering nonlinear features of the input data. A simple and common method to use is polynomial features, which can get features&amp;rsquo; high-order and interaction terms. It is implemented in &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">입력 데이터의 비선형 기능을 고려하여 모델에 복잡성을 추가하는 것이 유용한 경우가 많습니다. 사용하는 단순하고 일반적인 방법은 다항식 피처로 피처의 고차 및 상호 작용 항을 얻을 수 있습니다. &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; 기능으로 구현됩니다 .</target>
        </trans-unit>
        <trans-unit id="e408c9080a80cd5dee3de8b66c635dedc13aaef1" translate="yes" xml:space="preserve">
          <source>Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.</source>
          <target state="translated">기계 학습 문제를 해결하는 데있어 가장 어려운 부분은 직무에 적합한 견적서를 찾는 것입니다.</target>
        </trans-unit>
        <trans-unit id="7b3890ce47285c29340d329412b63023825aa83a" translate="yes" xml:space="preserve">
          <source>Often, you will want to convert an existing Python function into a transformer to assist in data cleaning or processing. You can implement a transformer from an arbitrary function with &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt;. For example, to build a transformer that applies a log transformation in a pipeline, do:</source>
          <target state="translated">종종 데이터 정리 또는 처리를 돕기 위해 기존 Python 함수를 변환기로 변환하려고 할 수 있습니다. &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt; 를 사용하여 임의의 함수에서 변환기를 구현할 수 있습니다 . 예를 들어, 파이프 라인에 로그 변환을 적용하는 변환기를 작성하려면 다음을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="3a99e53e60f11cdf73347e45ac4d6a8ace6059f3" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11</source>
          <target state="translated">오 잘라와 가리가. 분류기 성능 연구를위한 순열 테스트. 기계 학습 연구 저널 (2010) vol. 11</target>
        </trans-unit>
        <trans-unit id="4a78f8007754f084c0abbe2f8fe08318ed671586" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11 &lt;a href=&quot;http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf&quot;&gt;[pdf]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d82f7d71018bfffc818f9af5a47b640ae31345cd" translate="yes" xml:space="preserve">
          <source>Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tibshirani, David Botstein and Russ B. Altman, Missing value estimation methods for DNA microarrays, BIOINFORMATICS Vol. 17 no. 6, 2001 Pages 520-525.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9aa2dba7b6fd084ffccc78f5a1359dabe654fd3" translate="yes" xml:space="preserve">
          <source>On &amp;ldquo;small&amp;rdquo; datasets (less than a few hundred points), the quantile transformer is prone to overfitting. The use of the power transform is then recommended.</source>
          <target state="translated">&quot;소형&quot;데이터 세트 (수백 포인트 미만)에서 Quantile 변환기는 과적 합되기 쉽습니다. 그런 다음 전력 변환을 사용하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="d0f97ce49fc19f915019c9855a072a57bec1774a" translate="yes" xml:space="preserve">
          <source>On L2-normalized data, this function is equivalent to linear_kernel.</source>
          <target state="translated">L2 정규화 된 데이터에서이 함수는 linear_kernel과 같습니다.</target>
        </trans-unit>
        <trans-unit id="d978bf78cd4e4a7f593a82a72e7f97f769b529af" translate="yes" xml:space="preserve">
          <source>On Spectral Clustering: Analysis and an algorithm, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</source>
          <target state="translated">스펙트럼 클러스터링 : 분석 및 알고리즘, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c042431c0ae0ab161c8569f0669e312480d87b4b" translate="yes" xml:space="preserve">
          <source>On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640&amp;ndash;650., Wilks, D. S., 1990a</source>
          <target state="translated">연속 강우 기간에 대한 예측 확률의 조합. Wea. 예측, 5, 640&amp;ndash;650., Wilks, DS, 1990a</target>
        </trans-unit>
        <trans-unit id="05fe02625303adf1ec7a757f80f079f0cfb615a5" translate="yes" xml:space="preserve">
          <source>On the contrary the classical finite mixture model with a Dirichlet distribution prior will favor more uniformly weighted components and therefore tends to divide natural clusters into unnecessary sub-components.</source>
          <target state="translated">반대로, 이전에 Dirichlet 분포를 갖는 고전적인 유한 혼합물 모델은보다 균일하게 가중 된 성분을 선호하므로 자연 클러스터를 불필요한 하위 성분으로 나누는 경향이 있습니다.</target>
        </trans-unit>
        <trans-unit id="a881270be1f0c36e65b4d9407272c7539d9eb831" translate="yes" xml:space="preserve">
          <source>On the diabetes dataset, find the optimal regularization parameter alpha.</source>
          <target state="translated">당뇨병 데이터 세트에서 최적의 정규화 매개 변수 알파를 찾으십시오.</target>
        </trans-unit>
        <trans-unit id="d20d94e86b214eba2d2a083bdeb7805cae8a5dbd" translate="yes" xml:space="preserve">
          <source>On the digits dataset, plot the cross-validation score of a &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; estimator with an linear kernel as a function of parameter &lt;code&gt;C&lt;/code&gt; (use a logarithmic grid of points, from 1 to 10).</source>
          <target state="translated">숫자 데이터 세트에서 선형 커널을 사용하여 &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; 추정기 의 교차 검증 점수 를 매개 변수 &lt;code&gt;C&lt;/code&gt; 의 함수로 플로팅합니다 (1에서 10까지의 로그 그리드 사용).</target>
        </trans-unit>
        <trans-unit id="70934046ec7198c15e5255a457f5b5f8aad47e7d" translate="yes" xml:space="preserve">
          <source>On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from &lt;code&gt;predict_proba&lt;/code&gt; are not to be taken too seriously.</source>
          <target state="translated">반면에 순진한 베이 즈 ( &lt;code&gt;predict_proba&lt;/code&gt; Bayes)는 괜찮은 분류기로 알려져 있지만 나쁜 추정기로 알려져 있으므로 predict_proba 의 확률 결과가 너무 심각하게 고려되지는 않습니다.</target>
        </trans-unit>
        <trans-unit id="11ff999f3cb9557f779d2d870e0da3265a08df2a" translate="yes" xml:space="preserve">
          <source>On the following figure we are fitting a dataset not well-depicted by a Gaussian mixture. Adjusting the &lt;code&gt;weight_concentration_prior&lt;/code&gt;, parameter of the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; controls the number of components used to fit this data. We also present on the last two plots a random sampling generated from the two resulting mixtures.</source>
          <target state="translated">다음 그림에서 우리는 가우시안 혼합으로 잘 묘사되지 않은 데이터 세트를 피팅하고 있습니다. &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; 의 &lt;code&gt;weight_concentration_prior&lt;/code&gt; 매개 변수를 조정하면 이 데이터에 맞는 구성 요소의 수를 제어합니다. 우리는 또한 마지막 두 줄거리에 두 개의 결과 혼합물에서 생성 된 무작위 샘플링을 제시합니다.</target>
        </trans-unit>
        <trans-unit id="e0986e74679be65bf8af00d65ae0c2feb9ddbaaf" translate="yes" xml:space="preserve">
          <source>On the graph of webpages and links those values are called the PageRank scores by Google.</source>
          <target state="translated">웹 페이지 및 링크 그래프에서 이러한 값을 Google의 PageRank 점수라고합니다.</target>
        </trans-unit>
        <trans-unit id="56dda47abffe67d113799c44a62fa9885afd300e" translate="yes" xml:space="preserve">
          <source>On the left side the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. On the right side we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples.</source>
          <target state="translated">왼쪽에는 순진한 베이 즈 분류기의 학습 곡선이 숫자 데이터 세트에 대해 표시됩니다. 훈련 점수와 교차 유효성 검사 점수는 모두 마지막에는 좋지 않습니다. 그러나 곡선의 모양은보다 복잡한 데이터 세트에서 매우 자주 발견 될 수 있습니다. 처음에는 훈련 점수가 매우 높고 감소하며 교차 유효성 검사 점수는 매우 낮으며 증가합니다. 오른쪽에는 RBF 커널이있는 SVM의 학습 곡선이 있습니다. 우리는 훈련 점수가 여전히 최대치에 가까워지고 더 많은 훈련 샘플로 검증 점수가 높아질 수 있음을 분명히 알 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="8734edc10a3853b319869c6d2b6c4a8a8cc0d2c2" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training &lt;code&gt;n_classes&lt;/code&gt; models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f954522d1ed09b2ae8779aaabe3dfa6c3ae4de4e" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained:</source>
          <target state="translated">반면에 &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; 는 &quot;일대일&quot;멀티 클래스 전략을 구현하여 n_class 모델을 교육합니다. 두 개의 클래스 만있는 경우 하나의 모델 만 학습됩니다.</target>
        </trans-unit>
        <trans-unit id="b6899866fd2175cc1abac032537947b3dc26ecc5" translate="yes" xml:space="preserve">
          <source>On the other hand, the weights obtained with regularization are more stable (see the &lt;a href=&quot;../../modules/linear_model#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; User Guide section). This increased stability is visible from the plot, obtained from data perturbations, in a cross validation. This plot can be compared with the &lt;a href=&quot;#covariation&quot;&gt;previous one&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86b28d625cb14fb5485ff23b3eca337a06cecaf2" translate="yes" xml:space="preserve">
          <source>On the plots, train data is shown as dots, while test data is shown as crosses. The iris dataset is four-dimensional. Only the first two dimensions are shown here, and thus some points are separated in other dimensions.</source>
          <target state="translated">플롯에서 열차 데이터는 점으로 표시되고 테스트 데이터는 십자가로 표시됩니다. 홍채 데이터 세트는 4 차원입니다. 여기에는 처음 두 치수 만 표시되므로 일부 점은 다른 치수로 분리됩니다.</target>
        </trans-unit>
        <trans-unit id="fc82fddedc10b52f931e2d57575d5196e2c6dd2d" translate="yes" xml:space="preserve">
          <source>On the twenty newsgroups on the other hand the dimensionality can be decreased from 56436 down to 10000 while reasonably preserving pairwise distances.</source>
          <target state="translated">반면 20 개의 뉴스 그룹에서는 차원을 56436에서 10000으로 줄이면서 쌍방향 거리를 합리적으로 보존 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="43f757b33d0dc72835f44fdaffe6492249fea14f" translate="yes" xml:space="preserve">
          <source>On this example, the first two rows represent linearly non-separable datasets (moons and concentric circles) while the third is approximately linearly separable. On the two linearly non-separable datasets, feature discretization largely increases the performance of linear classifiers. On the linearly separable dataset, feature discretization decreases the performance of linear classifiers. Two non-linear classifiers are also shown for comparison.</source>
          <target state="translated">이 예에서 처음 두 행은 선형으로 분리 할 수없는 데이터 집합 (달 및 동심원)을 나타내고 세 번째는 대략 선형으로 분리 할 수 ​​있습니다. 선형으로 분리 할 수없는 두 데이터 세트에서 기능 이산화는 선형 분류기의 성능을 크게 향상시킵니다. 선형으로 분리 가능한 데이터 집합에서 기능 이산화는 선형 분류기의 성능을 저하시킵니다. 비교를 위해 두 개의 비선형 분류기도 표시됩니다.</target>
        </trans-unit>
        <trans-unit id="3162e7b183de96ba6bf8f8587d34db62edc4b217" translate="yes" xml:space="preserve">
          <source>Once the optimization problem is solved, the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; for a given sample \(x\) becomes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07aa293f8032a091371331fd78ad762690098968" translate="yes" xml:space="preserve">
          <source>Once trained, we can export the tree in &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with</source>
          <target state="translated">훈련을 마치면 &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt; 내보내기를 사용하여 트리를 &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; 형식으로 내보낼 수 있습니다 . &lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt; 패키지 관리자 를 사용하면 graphviz 바이너리 및 python 패키지를</target>
        </trans-unit>
        <trans-unit id="ed70a2ff6fe86d781de8936cfd7e74b27161e201" translate="yes" xml:space="preserve">
          <source>Once trained, you can plot the tree with the &lt;a href=&quot;generated/sklearn.tree.plot_tree#sklearn.tree.plot_tree&quot;&gt;&lt;code&gt;plot_tree&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28066560ad38f3f5dad45c5652f6a508803ee2c3" translate="yes" xml:space="preserve">
          <source>One can always drop the first column for each feature:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0471206705323c6d53e55b1c35697675c16b2c95" translate="yes" xml:space="preserve">
          <source>One can discard categories not seen during &lt;code&gt;fit&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1a30cbb2660486e3a34f97fc6f2ebc285138723" translate="yes" xml:space="preserve">
          <source>One can observe here that logistic regression is well calibrated as its curve is nearly diagonal. Linear SVC&amp;rsquo;s calibration curve or reliability diagram has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors). Both kinds of calibration can fix this issue and yield nearly identical results. The next figure shows the calibration curve of Gaussian naive Bayes on the same data, with both kinds of calibration and also without calibration.</source>
          <target state="translated">여기서 로지스틱 회귀 분석은 곡선이 거의 대각선이므로 보정이 잘되어 있음을 알 수 있습니다. Linear SVC의 캘리브레이션 곡선 또는 신뢰성 다이어그램에는 시그 모이 드 곡선이 있으며, 이는 과소 분류기에서 일반적입니다. LinearSVC의 경우 힌지 손실의 마진 속성으로 인해 결정 경계 (지원 벡터)에 가까운 하드 샘플에 모델이 초점을 맞출 수 있습니다. 두 종류의 교정 모두이 문제를 해결하고 거의 동일한 결과를 얻을 수 있습니다. 다음 그림은 동일한 종류의 가우스 순 베이의 보정 곡선을 보여줍니다.</target>
        </trans-unit>
        <trans-unit id="cce2911ccedb3667eaee804d61905917155ff5c2" translate="yes" xml:space="preserve">
          <source>One can observe that with homoscedastic noise both FA and PCA succeed in recovering the size of the low rank subspace. The likelihood with PCA is higher than FA in this case. However PCA fails and overestimates the rank when heteroscedastic noise is present. Under appropriate circumstances the low rank models are more likely than shrinkage models.</source>
          <target state="translated">FA와 PCA 모두 동종 이계 잡음을 이용하여 하위 랭크 서브 스페이스의 크기를 성공적으로 복구 할 수 있음을 알 수있다. 이 경우 PCA의 가능성은 FA보다 높습니다. 그러나이 분산 잡음이 존재할 때 PCA는 실패하고 순위를 과대 평가합니다. 적절한 상황에서 하위 모델은 수축 모델보다 더 가능성이 높습니다.</target>
        </trans-unit>
        <trans-unit id="5282642c4183bcd75159c8592f0d08e21bceb6b2" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:</source>
          <target state="translated">예측 된 레이블에서 0과 1을 치환하고 2에서 3으로 이름을 바꾸고 동일한 점수를 얻을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f2e197fb258bad312502ac44a4234fe5a6877692" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3, and get the same score:</source>
          <target state="translated">예측 된 레이블에서 0과 1을 치환하고 2의 이름을 3으로 바꾸고 동일한 점수를 얻을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="e33d3feeafd2b2e6157812f722f3e7fb8358ba7c" translate="yes" xml:space="preserve">
          <source>One can see that Gaussian naive Bayes performs very badly but does so in an other way than linear SVC: While linear SVC exhibited a sigmoid calibration curve, Gaussian naive Bayes&amp;rsquo; calibration curve has a transposed-sigmoid shape. This is typical for an over-confident classifier. In this case, the classifier&amp;rsquo;s overconfidence is caused by the redundant features which violate the naive Bayes assumption of feature-independence.</source>
          <target state="translated">Gaussian naive Bayes는 성능이 좋지만 linear SVC와는 다른 방식으로 수행한다는 것을 알 수 있습니다. linear SVC는 S 자형 보정 곡선을 나타내지 만 Gaussian naive Bayes의 보정 곡선은 변형 된 시그 모이 드 모양입니다. 이는 과도하게 분류 된 분류기에서 일반적입니다. 이 경우 분류 자의 과잉 신뢰는 중복 베이직 피처에 의해 발생하며 이는 피처 독립성에 대한 순진한 베이 즈 가정을 위반합니다.</target>
        </trans-unit>
        <trans-unit id="15c1fc9ad0e4ecc150e99497720122e04673bd38" translate="yes" xml:space="preserve">
          <source>One can see that NCA enforces a clustering of the data that is visually meaningful despite the large reduction in dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82900035fe0f11887cd04ee23edd3ee0d6e6bf18" translate="yes" xml:space="preserve">
          <source>One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.</source>
          <target state="translated">머신 러닝의 일반적인 패턴 중 하나는 데이터의 비선형 함수에 대해 학습 된 선형 모델을 사용하는 것입니다. 이 방법은 일반적으로 선형 방법의 빠른 성능을 유지하면서 훨씬 넓은 범위의 데이터에 맞출 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="fa0690f9f0e7bd840855247cda57999b3e6dd175" translate="yes" xml:space="preserve">
          <source>One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). From this assumption, we generally try to define the &amp;ldquo;shape&amp;rdquo; of the data, and can define outlying observations as observations which stand far enough from the fit shape.</source>
          <target state="translated">이상 값 탐지를 수행하는 일반적인 방법 중 하나는 정규 데이터가 알려진 분포 (예 : 데이터가 가우시안 분포)에서 나온 것으로 가정하는 것입니다. 이 가정에서 우리는 일반적으로 데이터의&amp;ldquo;모양&amp;rdquo;을 정의하려고 시도하고 외형 관측치를 적합 형태와 충분히 멀리 떨어져있는 관측치로 정의 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9d03fc67e51edb11ba912aa95289c786040f1c20" translate="yes" xml:space="preserve">
          <source>One drawback of kernel methods is, that it might be necessary to store many kernel values \(k(x_i, x_j)\) during optimization. If a kernelized classifier is applied to new data \(y_j\), \(k(x_i, y_j)\) needs to be computed to make predictions, possibly for many different \(x_i\) in the training set.</source>
          <target state="translated">커널 메소드의 한 가지 단점은 최적화 중에 많은 커널 값 \ (k (x_i, x_j) \)을 저장해야 할 수도 있다는 것입니다. 커널 화 된 분류 기가 새 데이터 \ (y_j \)에 적용되는 경우, 훈련 세트의 많은 다른 \ (x_i \)에 대해 예측을하기 위해 \ (k (x_i, y_j) \)를 계산해야합니다.</target>
        </trans-unit>
        <trans-unit id="cdf9b1d4485b82e7ed1999a3fb7fb5adb4dbca12" translate="yes" xml:space="preserve">
          <source>One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; &amp;lsquo;isolates&amp;rsquo; observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</source>
          <target state="translated">고차원 데이터 집합에서 이상 값 탐지를 수행하는 효율적인 방법 중 하나는 임의 포리스트를 사용하는 것입니다. &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; 임의로 기능을 선택하고, 무작위 선택된 피처의 최대 값과 최소값 사이의 분할 값을 선택하여 '분리의 관찰.</target>
        </trans-unit>
        <trans-unit id="b5c13007d70aa1a0e4a2816404f0d61b9e0ac135" translate="yes" xml:space="preserve">
          <source>One important thing to note is that the algorithms implemented in this module can take different kinds of matrix as input. All the methods accept standard data matrices of shape &lt;code&gt;[n_samples, n_features]&lt;/code&gt;. These can be obtained from the classes in the &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module. For &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt;&lt;code&gt;AffinityPropagation&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; one can also input similarity matrices of shape &lt;code&gt;[n_samples, n_samples]&lt;/code&gt;. These can be obtained from the functions in the &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">주목해야 할 중요한 사항은이 모듈에서 구현 된 알고리즘이 다른 종류의 매트릭스를 입력으로 사용할 수 있다는 것입니다. 모든 메소드는 형태 &lt;code&gt;[n_samples, n_features]&lt;/code&gt; 의 표준 데이터 행렬을 허용합니다 . 이것들은 &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt; 모듈 의 클래스에서 얻을 수 있습니다 . 용 &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt; &lt;code&gt;AffinityPropagation&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt; &lt;code&gt;SpectralClustering&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt; 한 수 형상을 입력 유사도 행렬 &lt;code&gt;[n_samples, n_samples]&lt;/code&gt; . 이는 &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt; 모듈 의 기능에서 얻을 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="deab058e87e7d8cac343ed7483a7cf721eca4119" translate="yes" xml:space="preserve">
          <source>One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of &lt;em&gt;modified locally linear embedding&lt;/em&gt; (MLLE). MLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'modified'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt;.</source>
          <target state="translated">정규화 문제를 해결하는 한 가지 방법은 각 이웃에 여러 가중치 벡터를 사용하는 것입니다. 이것이 &lt;em&gt;수정 된 로컬 선형 임베딩&lt;/em&gt; (MLLE) 의 본질입니다 . MLLE는 함수로 수행 될 수 &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; 또는 객체 지향 상대 &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; 키워드와 &lt;code&gt;method = 'modified'&lt;/code&gt; . &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt; 가 필요합니다 .</target>
        </trans-unit>
        <trans-unit id="8b0abef56ded5ecf131b35733971a4004aa542f0" translate="yes" xml:space="preserve">
          <source>One might alternatively consider a collection of character n-grams, a representation resilient against misspellings and derivations.</source>
          <target state="translated">대안 적으로, 문자 철자법 및 유도에 대해 탄력적 인 표현 인 문자 n- 그램의 집합을 고려할 수있다.</target>
        </trans-unit>
        <trans-unit id="9787d541696df0f6a8e4fd9ada866862db9e0d0c" translate="yes" xml:space="preserve">
          <source>One might want to drop one of the two columns only for features with 2 categories. In this case, you can set the parameter &lt;code&gt;drop='if_binary'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61c492958dc81c1a6d9f632bafd3909d2bb143b8" translate="yes" xml:space="preserve">
          <source>One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.</source>
          <target state="translated">여기서 직면 한 문제 중 하나는 솔버가 잘 조정 된 추정치로 수렴하지 못하는 것입니다. 그러면 해당하는 알파 값이 결 측값으로 나오지만 최적은이 결 측값에 가까울 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="70a04d887115ca6d6700f00cd1afa9bf1cffed38" translate="yes" xml:space="preserve">
          <source>One of the earliest approaches to manifold learning is the Isomap algorithm, short for Isometric Mapping. Isomap can be viewed as an extension of Multi-dimensional Scaling (MDS) or Kernel PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points. Isomap can be performed with the object &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt;&lt;code&gt;Isomap&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">매니 폴드 학습에 대한 가장 초기 접근 방법 중 하나는 아이소 메트릭 매핑 (Isometric Mapping)의 약자 인 아이소 맵 알고리즘입니다. 아이소 맵은 MDS (Multi-dimensional Scaling) 또는 커널 PCA의 확장으로 볼 수 있습니다. Isomap은 모든 점 사이의 측지 거리를 유지하는 저 차원 임베딩을 찾습니다. Isomap 객체로 &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt; &lt;code&gt;Isomap&lt;/code&gt; 을&lt;/a&gt; 수행 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="8d30b63915c687687af955c31a96ac094f06cb9f" translate="yes" xml:space="preserve">
          <source>One of the most straight-forward concerns one may have when using/choosing a machine learning toolkit is the latency at which predictions can be made in a production environment.</source>
          <target state="translated">머신 러닝 툴킷을 사용할 때 선택할 수있는 가장 간단한 문제 중 하나는 프로덕션 환경에서 예측을 수행 할 수있는 대기 시간입니다.</target>
        </trans-unit>
        <trans-unit id="e3967d3ba22f4ac7f4c1ab09bac9634bd847ca9c" translate="yes" xml:space="preserve">
          <source>One of:</source>
          <target state="translated">다음 중 하나 :</target>
        </trans-unit>
        <trans-unit id="d25b0126083dd51df31e94af07b51bd893fc80ee" translate="yes" xml:space="preserve">
          <source>One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:</source>
          <target state="translated">커널 밀도 추정의 또 다른 유용한 응용은이 생성 모델에서 새로운 샘플을 효율적으로 추출하기 위해 데이터 세트의 비모수 생성 모델을 학습하는 것입니다. 다음은이 프로세스를 사용하여 데이터의 PCA 투영에서 얻은 가우시안 커널을 사용하여 손으로 쓴 새 숫자 세트를 작성하는 예입니다.</target>
        </trans-unit>
        <trans-unit id="fee8a97f6bc38e5962a611f176ea8084294905c7" translate="yes" xml:space="preserve">
          <source>One possible difference with the &lt;code&gt;glasso&lt;/code&gt; R package is that the diagonal coefficients are not penalized.</source>
          <target state="translated">&lt;code&gt;glasso&lt;/code&gt; R 패키지 와의 한 가지 가능한 차이점 은 대각선 계수가 불이익을받지 않는다는 것입니다.</target>
        </trans-unit>
        <trans-unit id="a927f9db65135d8f0443d271707e3494a0dc3ae7" translate="yes" xml:space="preserve">
          <source>One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. &lt;code&gt;impute.SimpleImputer&lt;/code&gt;). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. &lt;code&gt;impute.IterativeImputer&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea6c78b875e9abbb9afb65361c14c4ab4fe517e5" translate="yes" xml:space="preserve">
          <source>One typical use case is to wrap an existing metric function from the library with non-default values for its parameters, such as the &lt;code&gt;beta&lt;/code&gt; parameter for the &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">일반적인 사용 사례 중 하나는 라이브러리의 기존 메트릭 함수를 &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; 함수 의 &lt;code&gt;beta&lt;/code&gt; 매개 변수 와 같이 해당 매개 변수의 기본값이 아닌 값으로 래핑하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="d21d62671a1a16508e611633019b29f0b4ceb760" translate="yes" xml:space="preserve">
          <source>One way to avoid the query complexity is to pre-compute sparse neighborhoods in chunks using &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;mode='distance'&lt;/code&gt;, then using &lt;code&gt;metric='precomputed'&lt;/code&gt; here.</source>
          <target state="translated">쿼리 복잡성을 피하는 한 가지 방법은 &lt;code&gt;mode='distance'&lt;/code&gt; 와 함께 &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt; &lt;/a&gt; 를 사용하고 여기서 &lt;code&gt;metric='precomputed'&lt;/code&gt; 를 사용하여 청크에서 희소 이웃을 사전 계산하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="cfb9ef5c0f82cd02b0fe2a37197cc7c17a10edff" translate="yes" xml:space="preserve">
          <source>One way to handle this is to cluster features that are correlated and only keep one feature from each cluster. This strategy is explored in the following example: &lt;a href=&quot;../auto_examples/inspection/plot_permutation_importance_multicollinear#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py&quot;&gt;Permutation Importance with Multicollinear or Correlated Features&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4307d41eb1bb94d21cc13cd8d41c0af8c2af52b" translate="yes" xml:space="preserve">
          <source>One way to plot the curves is to place them in the same figure, with the curves of each model on each row. First, we create a figure with two axes within two rows and one column. The two axes are passed to the &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; functions of &lt;code&gt;tree_disp&lt;/code&gt; and &lt;code&gt;mlp_disp&lt;/code&gt;. The given axes will be used by the plotting function to draw the partial dependence. The resulting plot places the decision tree partial dependence curves in the first row of the multi-layer perceptron in the second row.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7904a0df31dead1d3d1a1bdda9b6baa78b3e3ac4" translate="yes" xml:space="preserve">
          <source>One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter \(r\), which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as \(r \to 0\), the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for \(r &amp;gt; 0\). This problem manifests itself in embeddings which distort the underlying geometry of the manifold.</source>
          <target state="translated">LLE의 잘 알려진 문제는 정규화 문제입니다. 이웃의 수가 입력 차원의 수보다 큰 경우, 각 로컬 이웃을 정의하는 매트릭스는 순위가 부족하다. 이 문제를 해결하기 위해 표준 LLE는 임의의 정규화 매개 변수 \ (r \)를 적용합니다.이 매개 변수는 로컬 가중치 행렬의 트레이스를 기준으로 선택됩니다. 공식적으로 \ (r \ to 0 \)로 솔루션이 원하는 임베딩으로 수렴됨을 알 수 있지만 \ (r&amp;gt; 0 \)에 대해 최적의 솔루션을 찾을 것이라는 보장은 없습니다. 이 문제는 매니 폴드의 기본 형상을 왜곡하는 임베딩에서 나타납니다.</target>
        </trans-unit>
        <trans-unit id="4a89ac2f620199dd99f97fe1ad98300bc4f72269" translate="yes" xml:space="preserve">
          <source>One-class SVM with non-linear kernel (RBF)</source>
          <target state="translated">비선형 커널 (RBF)을 갖춘 1 급 SVM</target>
        </trans-unit>
        <trans-unit id="a699b63cc6020c9e087bddfc75a6724c5b45ee5c" translate="yes" xml:space="preserve">
          <source>One-hot encoded discretized features can make a model more expressive, while maintaining interpretability. For instance, pre-processing with a discretizer can introduce nonlinearity to linear models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4a3aede9df40da523f973c7487f254218f78511" translate="yes" xml:space="preserve">
          <source>One-vs-one multiclass strategy</source>
          <target state="translated">일대일 멀티 클래스 전략</target>
        </trans-unit>
        <trans-unit id="ee528cbd4b4f2e2829af351b64b6eb8bfd42a4f6" translate="yes" xml:space="preserve">
          <source>One-vs-the-rest (OvR) multiclass/multilabel strategy</source>
          <target state="translated">OvR (One-vs-the-rest) 멀티 클래스 / 멀티 라벨 전략</target>
        </trans-unit>
        <trans-unit id="64ecee535f4fdc8be570462551ed8105268af715" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above Figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them.</source>
          <target state="translated">단방향 PDP는 대상 응답과 대상 기능 간의 상호 작용에 대해 알려줍니다 (예 : 선형, 비선형). 위 그림의 왼쪽 위 그림은 지구의 중간 소득이 중간 주택 가격에 미치는 영향을 보여줍니다. 우리는 그들 사이의 선형 관계를 분명히 볼 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0d4f461fa5ad14a45b8d87efade862b196a923a9" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them. Note that PDPs assume that the target features are independent from the complement features, and this assumption is often violated in practice.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="624143e59cce6d91c0d6bbc328865a41ed589524" translate="yes" xml:space="preserve">
          <source>OneHotEncoder</source>
          <target state="translated">OneHotEncoder</target>
        </trans-unit>
        <trans-unit id="aae2ee6c9851c7a4ce4cd6cfb817bfde607325bf" translate="yes" xml:space="preserve">
          <source>Online Passive-Aggressive Algorithms &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt;&amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</source>
          <target state="translated">온라인 수동 공격적 알고리즘 &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt; &amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer- JMLR (2006)</target>
        </trans-unit>
        <trans-unit id="59363dcf6a532d4c72655a5346d2c500295612f8" translate="yes" xml:space="preserve">
          <source>Online VB with Mini-Batch update.</source>
          <target state="translated">미니 배치 업데이트가 포함 된 온라인 VB</target>
        </trans-unit>
        <trans-unit id="829e73254cb47c834763ade46578341830688d18" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling.</source>
          <target state="translated">이후 스케일링을위한 X의 최대 절대 값에 대한 온라인 계산.</target>
        </trans-unit>
        <trans-unit id="1dffcf7d5a055d764cfb2adb13901c054d8691b3" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">이후 스케일링을위한 X의 최대 절대 값에 대한 온라인 계산. 모든 X는 단일 배치로 처리됩니다. 이것은 &lt;code&gt;n_samples&lt;/code&gt; 수가 매우 많아서 적합하지 않거나 연속 스트림에서 X를 읽은 경우에 &lt;code&gt;fit&lt;/code&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="5b59fd4b2594ce8e5c7bbe150a07e7588723c96b" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling.</source>
          <target state="translated">나중에 스케일링하기 위해 X에서 평균 및 표준의 온라인 계산.</target>
        </trans-unit>
        <trans-unit id="98a787216e7563ac11e03cf3274711f17911c2c2" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">나중에 스케일링하기 위해 X에서 평균 및 표준의 온라인 계산. 모든 X는 단일 배치로 처리됩니다. 이것은 &lt;code&gt;n_samples&lt;/code&gt; 수가 매우 많아서 적합하지 않거나 연속 스트림에서 X를 읽은 경우에 &lt;code&gt;fit&lt;/code&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="3a0a40bed8a368eb74567adc0b902d5438bbb233" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling.</source>
          <target state="translated">나중에 스케일링하기 위해 X에서 최소 및 최대의 온라인 계산.</target>
        </trans-unit>
        <trans-unit id="245a52e0e0da8fa60b8bd0ab73c4b352a71c8d4a" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">나중에 스케일링하기 위해 X에서 최소 및 최대 온라인 계산. 모든 X는 단일 배치로 처리됩니다. 이것은 &lt;code&gt;n_samples&lt;/code&gt; 수가 매우 많아서 적합하지 않거나 연속 스트림에서 X를 읽은 경우에 &lt;code&gt;fit&lt;/code&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="3bdeb493aeece54b83eea920715d4b7167b710bb" translate="yes" xml:space="preserve">
          <source>Online learning of a dictionary of parts of faces</source>
          <target state="translated">얼굴의 일부 사전에 대한 온라인 학습</target>
        </trans-unit>
        <trans-unit id="afbac89ba6ac8bba06d8e8f00f8db1d633c505b3" translate="yes" xml:space="preserve">
          <source>Online learning.</source>
          <target state="translated">온라인 학습.</target>
        </trans-unit>
        <trans-unit id="e15bae968fe9434653919edecb56e181cf3bdca0" translate="yes" xml:space="preserve">
          <source>Online learning. Prevents rebuilding of CFTree from scratch.</source>
          <target state="translated">온라인 학습. CFTree의 재 구축을 방지합니다.</target>
        </trans-unit>
        <trans-unit id="fba366205dda8a9f9c620fa8147677029ec02688" translate="yes" xml:space="preserve">
          <source>Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">백엔드 =&amp;rdquo;loky&amp;rdquo;또는&amp;ldquo;multiprocessing&amp;rdquo;인 경우에만 활성화됩니다.</target>
        </trans-unit>
        <trans-unit id="302203b3b2bd4b6979838ea661e3dedb562a6303" translate="yes" xml:space="preserve">
          <source>Only adjusted measures can hence safely be used as a consensus index to evaluate the average stability of clustering algorithms for a given value of k on various overlapping sub-samples of the dataset.</source>
          <target state="translated">따라서 조정 된 측정 값 만 데이터 세트의 다양한 중첩 서브 샘플에서 주어진 k 값에 대한 군집 알고리즘의 평균 안정성을 평가하기위한 합의 지수로 안전하게 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b41ade38f91e30c61b5c1030ad80447ac59509af" translate="yes" xml:space="preserve">
          <source>Only applies to sparse matrices. If True, the sparse entries of the matrix are discarded to compute the quantile statistics. If False, these entries are treated as zeros.</source>
          <target state="translated">희소 행렬에만 적용됩니다. True이면 Quantile 통계를 계산하기 위해 행렬의 희소 항목이 삭제됩니다. False 인 경우 이러한 항목은 0으로 처리됩니다.</target>
        </trans-unit>
        <trans-unit id="6239790ca1ea503b946542f5fd11362f9a8d181e" translate="yes" xml:space="preserve">
          <source>Only available for novelty detection (when novelty is set to True). The argument X is supposed to contain &lt;em&gt;new data&lt;/em&gt;: if X contains a point from training, it considers the later in its own neighborhood. Also, the samples in X are not considered in the neighborhood of any point. The score_samples on training data is available by considering the the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">참신 탐지에만 사용할 수 있습니다 (참신이 True로 설정된 경우). 인수 X는 &lt;em&gt;새로운 데이터&lt;/em&gt; 를 포함해야한다 . 만약 X가 훈련의 포인트를 포함한다면, 그것은 자신의 이웃에서 나중에 고려한다. 또한 X의 샘플은 어떤 점에서도 고려되지 않습니다. &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 속성 을 고려하여 교육 데이터의 score_samples를 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="42065a31e81b2581624e9d29e5e9b175fb835b62" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;decision_function&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; 이고 기본 추정기가 &lt;code&gt;decision_function&lt;/code&gt; 을 지원하는 경우에만 사용 가능합니다 .</target>
        </trans-unit>
        <trans-unit id="b5f87bbc5994209afe765ecb3d4b6e3e28348b8b" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; 이고 기본 추정기가 &lt;code&gt;predict&lt;/code&gt; 를 지원 하는 경우에만 사용 가능합니다 .</target>
        </trans-unit>
        <trans-unit id="d2e232f30b7c8c685e1c17116e7dcb136df3f8ad" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_log_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;predict_log_proba&lt;/code&gt; &lt;code&gt;refit=True&lt;/code&gt; 이고 기본 추정기가 predict_log_proba를 지원하는 경우에만 사용 가능합니다 .</target>
        </trans-unit>
        <trans-unit id="590883a61b4915ecfb6720c62deaa2c81b9eda84" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;predict_proba&lt;/code&gt; &lt;code&gt;refit=True&lt;/code&gt; 이고 기본 추정기가 predict_proba를 지원하는 경우에만 사용 가능합니다 .</target>
        </trans-unit>
        <trans-unit id="3fd90433c474723d07589bf28196170034c8822e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator implements &lt;code&gt;inverse_transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">기본 추정기가 &lt;code&gt;inverse_transform&lt;/code&gt; 및 refit &lt;code&gt;refit=True&lt;/code&gt; 구현하는 경우에만 사용 가능합니다 .</target>
        </trans-unit>
        <trans-unit id="5b6ee95bb2d64ff7d78caebfb3e0ee07b947d80e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator supports &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">기본 추정기가 &lt;code&gt;transform&lt;/code&gt; 및 &lt;code&gt;refit=True&lt;/code&gt; 를 지원하는 경우에만 사용 가능합니다 .</target>
        </trans-unit>
        <trans-unit id="551c945d5055fc75c52f88f345bac01b44b1a207" translate="yes" xml:space="preserve">
          <source>Only consider the highest k scores in the ranking. If None, use all outputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91571ddad0f13d4b107795b8172bb8b9e0e57731" translate="yes" xml:space="preserve">
          <source>Only kernels that produce similarity scores (non-negative values that increase with similarity) should be used. This property is not checked by the clustering algorithm.</source>
          <target state="translated">유사성 점수 (유사성에 따라 증가하는 음이 아닌 값)를 생성하는 커널 만 사용해야합니다. 이 속성은 클러스터링 알고리즘으로 확인되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="78ed917f99bf2dac895a03ac7d7777a9a2c30e89" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;as_frame=True&lt;/code&gt;. DataFrame with &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fcc91c5ac8dfa2c9d74fba74f9744bbfabacd86" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;load_content=True&lt;/code&gt;. The raw text data to learn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f57910319c7032022a687ad833db0e0811e172" translate="yes" xml:space="preserve">
          <source>Only report results for the class specified by &lt;code&gt;pos_label&lt;/code&gt;. This is applicable only if targets (&lt;code&gt;y_{true,pred}&lt;/code&gt;) are binary.</source>
          <target state="translated">&lt;code&gt;pos_label&lt;/code&gt; 로 지정된 클래스에 대한 결과 만보고 . 이는 대상 ( &lt;code&gt;y_{true,pred}&lt;/code&gt; )이 이진 인 경우에만 적용 가능합니다 .</target>
        </trans-unit>
        <trans-unit id="aa7683d2cc754187a7839c7481d51d4e421e244f" translate="yes" xml:space="preserve">
          <source>Only returned if return_distance is set to True (for compatibility). The distances between the centers of the nodes. &lt;code&gt;distances[i]&lt;/code&gt; corresponds to a weighted euclidean distance between the nodes &lt;code&gt;children[i, 1]&lt;/code&gt; and &lt;code&gt;children[i, 2]&lt;/code&gt;. If the nodes refer to leaves of the tree, then &lt;code&gt;distances[i]&lt;/code&gt; is their unweighted euclidean distance. Distances are updated in the following way (from scipy.hierarchy.linkage):</source>
          <target state="translated">return_distance가 True (호환성을 위해)로 설정된 경우에만 반환됩니다. 노드 중심 사이의 거리입니다. &lt;code&gt;distances[i]&lt;/code&gt; 는 노드 &lt;code&gt;children[i, 1]&lt;/code&gt; 과 &lt;code&gt;children[i, 2]&lt;/code&gt; 사이의 가중 유클리드 거리에 해당합니다 . . 노드가 나무의 잎을 참조하면 &lt;code&gt;distances[i]&lt;/code&gt; 는 비가 중 유클리드 거리입니다. 거리는 scipy.hierarchy.linkage에서 다음과 같은 방식으로 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="76cbc59243676edd420339801c25adc86e4aefb2" translate="yes" xml:space="preserve">
          <source>Only set if whiten is &amp;lsquo;True&amp;rsquo;. This is the pre-whitening matrix that projects data onto the first &lt;code&gt;n_components&lt;/code&gt; principal components.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2ff6162a14531590c3fe05f5c4da22c170a731e" translate="yes" xml:space="preserve">
          <source>Only the first 4 features are informative. The remaining features are useless.</source>
          <target state="translated">처음 4 가지 기능 만 유익합니다. 나머지 기능은 쓸모가 없습니다.</target>
        </trans-unit>
        <trans-unit id="9ccbc07fdd81d8170c7e3632973044099dfe4b4c" translate="yes" xml:space="preserve">
          <source>Only the first max_depth levels of the tree are exported. Truncated branches will be marked with &amp;ldquo;&amp;hellip;&amp;rdquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccdb28c17d5d885e725cff4c70b04cf05f415c05" translate="yes" xml:space="preserve">
          <source>Only used if method=&amp;rsquo;barnes_hut&amp;rsquo; This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. &amp;lsquo;angle&amp;rsquo; is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below &amp;lsquo;angle&amp;rsquo; then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.</source>
          <target state="translated">method = 'barnes_hut'인 경우에만 사용됩니다. 이는 Barnes-Hut T-SNE의 속도와 정확도 간의 균형입니다. '각도'는 점에서 측정 한 먼 노드의 각도 크기 ([3]의 세타라고 함)입니다. 이 크기가 'angle'보다 작 으면 그 안에 포함 된 모든 포인트의 요약 노드로 사용됩니다. 이 방법은 0.2-0.8 범위에서이 파라미터의 변화에 ​​크게 민감하지 않습니다. 0.2보다 작은 각도는 계산 시간을 빠르게 늘리고 0.8보다 큰 각도는 오류를 빠르게 증가시킵니다.</target>
        </trans-unit>
        <trans-unit id="feeded53201cd1098b357f2543d3cc3ddaf2bc59" translate="yes" xml:space="preserve">
          <source>Only used in edge case with a single class in the training set.</source>
          <target state="translated">트레이닝 세트에서 단일 클래스가있는 엣지 케이스에서만 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="e51e92f95034c804fc0810fdbc5d315daca2beb0" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;solver='sgd'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;solver='sgd'&lt;/code&gt; 인 경우에만 사용 .</target>
        </trans-unit>
        <trans-unit id="593a45b59b3c39f850f6d06cebef909401c1e524" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da0ee672f8455720f39dadc83f429b90e16b4655" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of function calls. Note that number of function calls will be greater than or equal to the number of iterations for the MLPRegressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f33d0ac38f880719381151e0f77c153552e9c099" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of loss function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of loss function calls. Note that number of loss function calls will be greater than or equal to the number of iterations for the &lt;code&gt;MLPClassifier&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3466b805d384e470c3d1ee2beb1b9b317ac5cc22" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">solver = 'sgd'인 경우에만 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="04fb050fa307025a8b877f9d2c83069449f7ca94" translate="yes" xml:space="preserve">
          <source>Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">&lt;code&gt;rows_&lt;/code&gt; 및 &lt;code&gt;columns_&lt;/code&gt; 인 경우에만 작동 속성이 존재하는 합니다.</target>
        </trans-unit>
        <trans-unit id="516478ad62f05e00111ddd57ddd26de9d50efa29" translate="yes" xml:space="preserve">
          <source>Open problem: Stock Market Structure</source>
          <target state="translated">공개 된 문제 : 주식 시장 구조</target>
        </trans-unit>
        <trans-unit id="988a0621a69f95c126d429edd6ad72b8b9753d30" translate="yes" xml:space="preserve">
          <source>OpenBLAS</source>
          <target state="translated">OpenBLAS</target>
        </trans-unit>
        <trans-unit id="01e06dfe8463084e545b7490a5b6cab212cacc1b" translate="yes" xml:space="preserve">
          <source>OpenML ID of the dataset. The most specific way of retrieving a dataset. If data_id is not given, name (and potential version) are used to obtain a dataset.</source>
          <target state="translated">데이터 세트의 OpenML ID입니다. 데이터 세트를 검색하는 가장 구체적인 방법입니다. data_id를 지정하지 않으면 이름 (및 잠재적 버전)을 사용하여 데이터 세트를 얻습니다.</target>
        </trans-unit>
        <trans-unit id="b73a248fb134eb9cb2d0288db81a01291423c17b" translate="yes" xml:space="preserve">
          <source>OpenMP is used to parallelize code written in Cython or C, relying on multi-threading exclusively. By default (and unless joblib is trying to avoid oversubscription), the implementation will use as many threads as possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c0cb6e8849966972823d3a411e3fa85cccc3662" translate="yes" xml:space="preserve">
          <source>Opposite of the Local Outlier Factor of X.</source>
          <target state="translated">X의 로컬 특이 치 요인의 반대.</target>
        </trans-unit>
        <trans-unit id="5e68f725eeef777e12b4d3a454a6208991fd24e6" translate="yes" xml:space="preserve">
          <source>Opposite of the Mahalanobis distances.</source>
          <target state="translated">Mahalanobis 거리의 반대.</target>
        </trans-unit>
        <trans-unit id="b5fb56d4ea090bc2e90702500456ef35c8c80910" translate="yes" xml:space="preserve">
          <source>Opposite of the anomaly score defined in the original paper.</source>
          <target state="translated">원본 논문에 정의 된 이상 점수의 반대.</target>
        </trans-unit>
        <trans-unit id="8d0235738e36c010f5cce0e1d51d26583f4fbd2f" translate="yes" xml:space="preserve">
          <source>Opposite of the value of X on the K-means objective.</source>
          <target state="translated">K- 평균 목표에서 X 값의 반대.</target>
        </trans-unit>
        <trans-unit id="d4790d7d59a93c4896ec3d473b252d9c8e90d50a" translate="yes" xml:space="preserve">
          <source>Optimal choices for the sampling interval for certain data ranges can be computed (see the reference). The default values should be reasonable.</source>
          <target state="translated">특정 데이터 범위에 대한 샘플링 간격에 대한 최적의 선택을 계산할 수 있습니다 (참조 참조). 기본값은 합리적이어야합니다.</target>
        </trans-unit>
        <trans-unit id="ce024d3ab746293c4c12993e7780e537aaab5bd3" translate="yes" xml:space="preserve">
          <source>Optimized BLAS / LAPACK implementations include:</source>
          <target state="translated">최적화 된 BLAS / LAPACK 구현은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="e7a4cb55708bbb7494e2613ab1d6bd3cf5f4ed80" translate="yes" xml:space="preserve">
          <source>Optimizing the KL divergence can be a little bit tricky sometimes. There are five parameters that control the optimization of t-SNE and therefore possibly the quality of the resulting embedding:</source>
          <target state="translated">KL 발산을 최적화하는 것은 때때로 약간 까다로울 수 있습니다. t-SNE의 최적화 및 결과로 임베딩 품질을 제어하는 ​​5 가지 매개 변수가 있습니다.</target>
        </trans-unit>
        <trans-unit id="59b7edea35dae0ba7f04b93972cd416b8729437e" translate="yes" xml:space="preserve">
          <source>Option to scale data</source>
          <target state="translated">데이터 스케일링 옵션</target>
        </trans-unit>
        <trans-unit id="b448cb50c967f57d438352622bd92cc83d5cd21c" translate="yes" xml:space="preserve">
          <source>Optional display names matching the labels (same order).</source>
          <target state="translated">레이블과 일치하는 선택적 표시 이름 (동일한 순서).</target>
        </trans-unit>
        <trans-unit id="f7746b3179890337eeaaee24d3cefbf3e21f4716" translate="yes" xml:space="preserve">
          <source>Optional list of label indices to include in the report.</source>
          <target state="translated">보고서에 포함 할 선택적 레이블 색인 목록입니다.</target>
        </trans-unit>
        <trans-unit id="444d0152ba1b6a9d2f83b135dcad3591aef4140b" translate="yes" xml:space="preserve">
          <source>Optionally, weights can be provided for the individual classifiers:</source>
          <target state="translated">선택적으로 개별 분류 자에 가중치를 제공 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="53297f66af025e9af455b9620b74f88cfef40f7b" translate="yes" xml:space="preserve">
          <source>Or a confusion matrix can be constructed for each sample&amp;rsquo;s labels:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdffb8593fdda1fb06f464d41401bd543c75d539" translate="yes" xml:space="preserve">
          <source>Or as a dict mapping scorer name to a predefined or custom scoring function:</source>
          <target state="translated">또는 사전 스코어링 기능 또는 사용자 정의 스코어링 기능에 점수 매기기 이름을 맵핑하는 dict :</target>
        </trans-unit>
        <trans-unit id="568b3f93d3d74f4712d93109fe9bc1b3579dc2ff" translate="yes" xml:space="preserve">
          <source>Or drop a column for feature only having 2 categories:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2919d9f2f1803bd27d88cb6979d8731b9671873d" translate="yes" xml:space="preserve">
          <source>Or, the Itakura-Saito (IS) divergence:</source>
          <target state="translated">또는 Itakura-Saito (IS) 발산 :</target>
        </trans-unit>
        <trans-unit id="2eae1790c8b18065a4e4be5e643bf49617d7e481" translate="yes" xml:space="preserve">
          <source>Oracle Approximating Shrinkage Estimator</source>
          <target state="translated">Oracle 근사 수축량 추정기</target>
        </trans-unit>
        <trans-unit id="09fb6aaba7940a7b7ffdbc9cbb9b3498303c1bad" translate="yes" xml:space="preserve">
          <source>Orange</source>
          <target state="translated">Orange</target>
        </trans-unit>
        <trans-unit id="1b5910554dc9c47445df182faeace08d47d3ef72" translate="yes" xml:space="preserve">
          <source>Order of output array in the dense case. &amp;lsquo;F&amp;rsquo; order is faster to compute, but may slow down subsequent estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61e854a8201b91e00e8fdcbd770fb61bc8a83663" translate="yes" xml:space="preserve">
          <source>Order of the norm used to filter the vectors of coefficients below &lt;code&gt;threshold&lt;/code&gt; in the case where the &lt;code&gt;coef_&lt;/code&gt; attribute of the estimator is of dimension 2.</source>
          <target state="translated">추정기 의 &lt;code&gt;coef_&lt;/code&gt; 속성이 차원 2 인 경우 &lt;code&gt;threshold&lt;/code&gt; 미만의 계수 벡터를 필터링하는 데 사용되는 표준 순서입니다 .</target>
        </trans-unit>
        <trans-unit id="04f01a5d4b5e2de7c5bc38f04fe789073a85e1a0" translate="yes" xml:space="preserve">
          <source>Ordinary Least Squares and Ridge Regression Variance</source>
          <target state="translated">정규 최소 제곱 및 릿지 회귀 분산</target>
        </trans-unit>
        <trans-unit id="69dfb38c02d49acfa60317532da350814008c91b" translate="yes" xml:space="preserve">
          <source>Ordinary least squares Linear Regression.</source>
          <target state="translated">보통 최소 제곱 선형 회귀.</target>
        </trans-unit>
        <trans-unit id="c6a26fb9333dc9c04fcf0b8a8d439bec3529ccb6" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the book &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; by Radford M. Neal</source>
          <target state="translated">Original Algorithm은 Radford M. Neal의 &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; 책에 자세히 설명되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="285a92205b1ae0ee38089b09c3441dcd00669592" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">Original Algorithm은 Hastie et al.의 &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; 논문에 자세히 설명되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="b56fc3a445b7bdb3d075f8c4b435d8408f7cbd6d" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;https://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40e1a40682f2197d130d7160c72b099cf6445896" translate="yes" xml:space="preserve">
          <source>Original Owners:</source>
          <target state="translated">원래 소유자 :</target>
        </trans-unit>
        <trans-unit id="7ad091e9d90ec0296b62c3e5e44ac8d89a063912" translate="yes" xml:space="preserve">
          <source>Original data</source>
          <target state="translated">원본 데이터</target>
        </trans-unit>
        <trans-unit id="e08c8e7e7ce9b41fa431a10c664db0046193d186" translate="yes" xml:space="preserve">
          <source>Original indices of sorted hashed values in the fitted index.</source>
          <target state="translated">적합 인덱스에서 정렬 된 해시 값의 원래 인덱스</target>
        </trans-unit>
        <trans-unit id="7bcdd254a48ca093c51f99fbea960c8ba5abba3d" translate="yes" xml:space="preserve">
          <source>Original points</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d62335c307cfd6338409df5c3eb510c3da387b07" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit</source>
          <target state="translated">직교 매칭 추구</target>
        </trans-unit>
        <trans-unit id="4b43e1fc477a65c488f6b885c65608062bcdd067" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">직교 매칭 추구 (OMP)</target>
        </trans-unit>
        <trans-unit id="6f8635fe08116f66d41828127f270123a3daf2dc" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit model (OMP)</source>
          <target state="translated">직교 매칭 추구 모델 (OMP)</target>
        </trans-unit>
        <trans-unit id="b4cea4b2e1d94206efdd2c81ac084782051e04a0" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit (&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt;)</source>
          <target state="translated">직교 &lt;a href=&quot;linear_model#omp&quot;&gt;매칭 추구 (OMP&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="2d35a4350f19547a1df08de9c97e28d5eb4c4c18" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">직교 매칭 추구는 G. Mallat, Z. Zhang에서 도입되었으며, 시간-주파수 사전과의 매칭 추구, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (1993 년 12 월), pp. 3397-3415. ( &lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="5e7d9b3e4cebb5843b9125c6b797beb3832d1f95" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">직교 매칭 추구는 S. Mallat, Z. Zhang에서 시간-주파수 사전과의 매칭 추구, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (1993 년 12 월), pp. 3397-3415. ( &lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="6e6a6f2086bb5fe5dbfd17d8d5f502d48759834b" translate="yes" xml:space="preserve">
          <source>Other</source>
          <target state="translated">Other</target>
        </trans-unit>
        <trans-unit id="708bf6f62e354ff314651598e7eebc62fd8d2bb2" translate="yes" xml:space="preserve">
          <source>Other Parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0faa321ae463cf423d057b0fb19c09b0142f3c2a" translate="yes" xml:space="preserve">
          <source>Other Parameters:</source>
          <target state="translated">다른 매개 변수 :</target>
        </trans-unit>
        <trans-unit id="f7488409b393eaa19a207155b56a3606cc42d9c5" translate="yes" xml:space="preserve">
          <source>Other Versions</source>
          <target state="translated">다른 버전</target>
        </trans-unit>
        <trans-unit id="bf60b2f111b62bfaee7623785937d680b71fe343" translate="yes" xml:space="preserve">
          <source>Other distance functions can be used in NMF as, for example, the (generalized) Kullback-Leibler (KL) divergence, also referred as I-divergence:</source>
          <target state="translated">NMF에서는 다른 거리 함수를 예를 들어 I- 분화라고도하는 (일반화 된) KL (Kullback-Leibler) 발산으로 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7ba50765d1cae4c4ed89d4ff332ed3b825d08abc" translate="yes" xml:space="preserve">
          <source>Other features match the names and e-mail addresses of particular people who were posting at the time.</source>
          <target state="translated">다른 기능은 당시에 게시 한 특정 사람들의 이름과 전자 메일 주소와 일치합니다.</target>
        </trans-unit>
        <trans-unit id="51c966edfa7d64a0b7dcf68b92d77cfd5b366772" translate="yes" xml:space="preserve">
          <source>Other machine learning packages for Python and related projects. Also algorithms that are slightly out of scope or not well established enough for scikit-learn.</source>
          <target state="translated">Python 및 관련 프로젝트를위한 기타 머신 러닝 패키지. 또한 범위를 약간 벗어 났거나 scikit-learn에 대해 충분히 확립되지 않은 알고리즘.</target>
        </trans-unit>
        <trans-unit id="2ea8bcd548fe9ec11d17cc82aea4ab0fbdf7f8f3" translate="yes" xml:space="preserve">
          <source>Other regression generators generate functions deterministically from randomized features. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt;&lt;code&gt;make_sparse_uncorrelated&lt;/code&gt;&lt;/a&gt; produces a target as a linear combination of four features with fixed coefficients. Others encode explicitly non-linear relations: &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt;&lt;code&gt;make_friedman1&lt;/code&gt;&lt;/a&gt; is related by polynomial and sine transforms; &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt;&lt;code&gt;make_friedman2&lt;/code&gt;&lt;/a&gt; includes feature multiplication and reciprocation; and &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt;&lt;code&gt;make_friedman3&lt;/code&gt;&lt;/a&gt; is similar with an arctan transformation on the target.</source>
          <target state="translated">다른 회귀 생성기는 무작위 기능에서 결정적 기능을 생성합니다. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt; &lt;code&gt;make_sparse_uncorrelated&lt;/code&gt; &lt;/a&gt; 는 고정 계수를 가진 네 가지 피처의 선형 조합으로 대상을 생성합니다. 다른 사람들은 명시 적으로 비선형 관계를 인코딩합니다. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt; &lt;code&gt;make_friedman1&lt;/code&gt; &lt;/a&gt; 은 다항식과 사인 변환과 관련이 있습니다. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt; &lt;code&gt;make_friedman2&lt;/code&gt; &lt;/a&gt; 는 특징 곱셈과 왕복을 포함합니다. 그리고 &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt; &lt;code&gt;make_friedman3&lt;/code&gt; &lt;/a&gt; 대상에서 아크 탄젠트 변환과 유사하다.</target>
        </trans-unit>
        <trans-unit id="756226f83bdd3199110bcb639e6fbe93b81b2b14" translate="yes" xml:space="preserve">
          <source>Others also work in the multiclass case:</source>
          <target state="translated">다른 사람들도 멀티 클래스 사례에서 일합니다.</target>
        </trans-unit>
        <trans-unit id="31c4dae2edc1b6ad8f22c0a6f68a8f7ab2bd8316" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be a sequence of items that can be of type string or byte.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bce48a0cb0a5e5960a4a35ec10cf25f56bf2f60b" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be the sequence strings or bytes items are expected to be analyzed directly.</source>
          <target state="translated">그렇지 않으면 입력이 시퀀스 문자열이거나 바이트 항목이 직접 분석 될 것으로 예상됩니다.</target>
        </trans-unit>
        <trans-unit id="1eb83bd09e16b910ee3986257ed6e80732bc066a" translate="yes" xml:space="preserve">
          <source>Our definition: &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;, &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; and &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;, where &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; adopt the adjusted version to ensure that random predictions have a score of \(0\) and perfect predictions have a score of \(1\)..</source>
          <target state="translated">정의 : &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt; , &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; 및 &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt; , 여기서 &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; 는 임의 예측의 점수가 \ (0 \)이고 완벽한 예측의 점수가 \ (1 \)이되도록 조정 된 버전을 채택합니다. .</target>
        </trans-unit>
        <trans-unit id="4dd148768e9c37b7c74e1f4e4e0bf60f2fa1ec4e" translate="yes" xml:space="preserve">
          <source>Our goal is to predict the expected frequency of claims following car accidents for a new policyholder given the historical data over a population of policyholders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51a30e97a793068228d5bb8b3efc1038cb1f9689" translate="yes" xml:space="preserve">
          <source>Our implementation of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; was inspired by the R MICE package (Multivariate Imputation by Chained Equations) &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;, but differs from it by returning a single imputation instead of multiple imputations. However, &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; can also be used for multiple imputations by applying it repeatedly to the same dataset with different random seeds when &lt;code&gt;sample_posterior=True&lt;/code&gt;. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;, chapter 4 for more discussion on multiple vs. single imputations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a60ce8fd0b60aee8ad7f5d9f917babe62e72b491" translate="yes" xml:space="preserve">
          <source>Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">우리의 구현 점수는 Tsoumakas et al., 2010에 주어진 것보다 1 더 큽니다. 이는 인스턴스에 0 개의 실제 레이블이있는 퇴화 사례를 처리하도록 확장됩니다.</target>
        </trans-unit>
        <trans-unit id="fe0259b257120510b76da78ac976bdfb1e816c30" translate="yes" xml:space="preserve">
          <source>Our target for prediction: the wage. Wages are described as floating-point number in dollars per hour.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3f0fa9ade6f943d608603fdef87384f7f12b49b" translate="yes" xml:space="preserve">
          <source>Out of the &lt;code&gt;n_features&lt;/code&gt; features, only 5 are actually used to compute &lt;code&gt;y&lt;/code&gt;. The remaining features are independent of &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">의 아웃 &lt;code&gt;n_features&lt;/code&gt; 의 기능, 5 실제로 계산하는 데 사용됩니다 &lt;code&gt;y&lt;/code&gt; . 나머지 기능은 &lt;code&gt;y&lt;/code&gt; 와 무관 합니다.</target>
        </trans-unit>
        <trans-unit id="de345f1c1e8c124d63c9ee465bc413813ba2423e" translate="yes" xml:space="preserve">
          <source>Out-of-bag (OOB) estimates can be a useful heuristic to estimate the &amp;ldquo;optimal&amp;rdquo; number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt;), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.</source>
          <target state="translated">OOB (Out-of-bag) 추정은 &quot;최적의&quot;부스팅 반복 횟수를 추정하는 데 유용한 휴리스틱이 될 수 있습니다. OOB 추정값은 교차 검증 추정값과 거의 동일하지만 반복되는 모델 피팅 없이도 즉시 계산할 수 있습니다. OOB 추정치는 확률 적 그라디언트 부스팅 (즉, &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt; 대해서만 사용할 수 있습니다. )에 , 추정치는 부트 스트랩 샘플에 포함되지 않은 예 (소위 비 가방 예)에 기초한 손실 개선으로부터 도출됩니다. OOB 추정기는 실제 테스트 손실에 대한 비관적 추정기이지만 소수의 나무에 대해서는 상당히 좋은 근사치입니다.</target>
        </trans-unit>
        <trans-unit id="0edae687594f6a8a4aaab025d755be89c91cf6e0" translate="yes" xml:space="preserve">
          <source>Out-of-core (or &amp;ldquo;external memory&amp;rdquo;) learning is a technique used to learn from data that cannot fit in a computer&amp;rsquo;s main memory (RAM).</source>
          <target state="translated">코어 외부 (또는 &quot;외부 메모리&quot;) 학습은 컴퓨터의 주 메모리 (RAM)에 맞지 않는 데이터를 학습하는 데 사용되는 기술입니다.</target>
        </trans-unit>
        <trans-unit id="9961951956a78a655327742f08dd6b72dea1283f" translate="yes" xml:space="preserve">
          <source>Out-of-core classification of text documents</source>
          <target state="translated">텍스트 문서의 핵심 외 분류</target>
        </trans-unit>
        <trans-unit id="1ee8fea1697e4d708569e4bb179873c92ff19379" translate="yes" xml:space="preserve">
          <source>Out:</source>
          <target state="translated">Out:</target>
        </trans-unit>
        <trans-unit id="5dd0aa388360b95626a38da9b18844d684c8d25b" translate="yes" xml:space="preserve">
          <source>Outlier detection</source>
          <target state="translated">이상치 탐지</target>
        </trans-unit>
        <trans-unit id="875f738eb0e68cda4066331e25fac5af4c71d682" translate="yes" xml:space="preserve">
          <source>Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.</source>
          <target state="translated">이상치 탐지 및 신규성 탐지는 이상 탐지에 사용되며 비정상 또는 비정상적인 탐지를 탐지하는 데 관심이 있습니다. 그런 다음 이상치 탐지는 비 감독 이상 탐지 및 반감기 이상 탐지라고도합니다. 이상 값 탐지와 관련하여, 가능한 추정값이 이상치 / 이상이 저밀도 지역에 있다고 가정하기 때문에 이상치 / 이상은 밀도가 높은 군집을 형성 할 수 없습니다. 반대로, 신규성 검출의 맥락에서, 신규성 / 이상은 훈련 데이터의 저밀도 영역에있는 한 밀도가 높은 군집을 형성 할 수 있으며, 이러한 맥락에서 정상으로 간주된다.</target>
        </trans-unit>
        <trans-unit id="e16ebe52f017c4437fca8210daa352b7f7a34559" translate="yes" xml:space="preserve">
          <source>Outlier detection from covariance estimation may break or not perform well in high-dimensional settings. In particular, one will always take care to work with &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt;.</source>
          <target state="translated">공분산 추정을 통한 이상치 탐지는 고차원 설정에서 깨지거나 제대로 수행되지 않을 수 있습니다. 특히, &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt; 하려면 항상주의를 기울여야합니다 .</target>
        </trans-unit>
        <trans-unit id="eb5776745abd0907a25a2d19ca27c92845132829" translate="yes" xml:space="preserve">
          <source>Outlier detection is similar to novelty detection in the sense that the goal is to separate a core of regular observations from some polluting ones, called &lt;em&gt;outliers&lt;/em&gt;. Yet, in the case of outlier detection, we don&amp;rsquo;t have a clean data set representing the population of regular observations that can be used to train any tool.</source>
          <target state="translated">이상치 탐지는 목표는 정기적 인 관측의 핵심을 &lt;em&gt;이상치 (outliers&lt;/em&gt; )라고 불리는 일부 오염 된 것으로부터 분리하는 것 입니다. 그러나 이상치 탐지의 경우 도구를 교육하는 데 사용할 수있는 정기 관측치 모집단을 나타내는 깨끗한 데이터 세트가 없습니다.</target>
        </trans-unit>
        <trans-unit id="1d8881b6614c5c1d87283378baf1dfbd30d62aa2" translate="yes" xml:space="preserve">
          <source>Outlier detection on a real data set</source>
          <target state="translated">실제 데이터 세트에서 이상치 탐지</target>
        </trans-unit>
        <trans-unit id="4567caf33a07f033c1e56ef9d81272da195ec4e4" translate="yes" xml:space="preserve">
          <source>Outlier detection with Local Outlier Factor (LOF)</source>
          <target state="translated">LOF (Local Outlier Factor)를 사용한 이상치 탐지</target>
        </trans-unit>
        <trans-unit id="fd5effe3fc538ea2a8eadf46c1fdeca372b53b13" translate="yes" xml:space="preserve">
          <source>Outlier-robust regressors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d4ae6e212657597b75c35cebf362553af1f6b83" translate="yes" xml:space="preserve">
          <source>Outliers in the X direction</source>
          <target state="translated">X 방향의 특이 치</target>
        </trans-unit>
        <trans-unit id="1280eb8e6f7378d868cfa7fd24acb5cb10594078" translate="yes" xml:space="preserve">
          <source>Outliers in the y direction</source>
          <target state="translated">y 방향의 특이 치</target>
        </trans-unit>
        <trans-unit id="fd162763a0f66a902211a2d40da7afdfc74ea634" translate="yes" xml:space="preserve">
          <source>Output a list of n_output arrays of class probabilities upon &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">출력에 따라 클래스 확률의 n_output 배열의 목록 &lt;code&gt;predict_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8298d7fc7f7d06e9b0287b5d9b7af6acdbad01e4" translate="yes" xml:space="preserve">
          <source>Output n_output values upon &lt;code&gt;predict&lt;/code&gt;;</source>
          <target state="translated">&lt;code&gt;predict&lt;/code&gt; 시 출력 n_ 출력 값 ;</target>
        </trans-unit>
        <trans-unit id="c9a682f0f812fa2f90e0a2d7878d2c9702a9c510" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;3&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c950fe98702d8e76b55b31a01ec26c58021324c" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">출력 코드 기반 전략은 일대일 및 일대일과 상당히 다릅니다. 이 전략을 사용하면 각 클래스는 유클리드 공간에 표시되며 각 차원은 0 또는 1 만 가능합니다. 또 다른 방법은 각 클래스가 이진 코드 (0과 1의 배열)로 표시되는 것입니다. 각 클래스의 위치 / 코드를 추적하는 매트릭스를 코드북이라고합니다. 코드 크기는 위에서 언급 한 공간의 차원입니다. 직관적으로, 각 클래스는 가능한 한 고유 한 코드로 표시되어야하며 분류 정확도를 최적화하도록 올바른 코드북을 설계해야합니다. 이 구현에서, 우리는 &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; 에서 주장한대로 무작위로 생성 된 코드북을 사용 하지만, 앞으로 더 정교한 방법이 추가 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ce947ff733c2ff6c4c204d57e36546e6961c8fdc" translate="yes" xml:space="preserve">
          <source>Output-code based strategies consist in representing each class with a binary code (an array of 0s and 1s). At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen. The main advantage of these strategies is that the number of classifiers used can be controlled by the user, either for compressing the model (0 &amp;lt; code_size &amp;lt; 1) or for making the model more robust to errors (code_size &amp;gt; 1). See the documentation for more details.</source>
          <target state="translated">출력 코드 기반 전략은 이진 코드 (0과 1의 배열)로 각 클래스를 나타내는 것으로 구성됩니다. 피팅 타임에, 코드북에서 비트 당 하나의 이진 분류 기가 장착된다. 예측시, 분류기는 클래스 공간에서 새로운 포인트를 투사하는 데 사용되며 포인트에 가장 가까운 클래스가 선택됩니다. 이러한 전략의 주요 장점은 모델을 압축하거나 (0 &amp;lt;code_size &amp;lt;1) 오류에 대해 모델을보다 강력하게 (code_size&amp;gt; 1) 사용자가 사용하는 분류기의 수를 제어 할 수 있다는 것입니다. 자세한 내용은 설명서를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="a7e6bae7017e237617a86072aea77d9c980daf13" translate="yes" xml:space="preserve">
          <source>Overall mean.</source>
          <target state="translated">전반적인 평균.</target>
        </trans-unit>
        <trans-unit id="870624bf4593bb4fe243ffdc55690c0daf6811c5" translate="yes" xml:space="preserve">
          <source>Overall mean. Only present if solver is &amp;lsquo;svd&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39400cd6ec0520b5a4505f75497b844c4371060d" translate="yes" xml:space="preserve">
          <source>Overall you can expect the prediction time to increase at least linearly with the number of features (non-linear cases can happen depending on the global memory footprint and estimator).</source>
          <target state="translated">전반적으로 예측 횟수가 기능 수에 따라 선형 적으로 증가 할 것으로 예상 할 수 있습니다 (비선형 경우는 전역 메모리 풋 프린트 및 추정기에 따라 발생할 수 있음).</target>
        </trans-unit>
        <trans-unit id="3ee1d3fb4e75cd6c2d707958304caf7e92bfaa8b" translate="yes" xml:space="preserve">
          <source>Overall, the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;) has a weak impact on the claim severity, both in observed and predicted data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91bd96083d98dc97930a239b87544217767aceaf" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps.</source>
          <target state="translated">토큰 화 및 n- 그램 생성 단계를 유지하면서 전처리 (문자열 변환) 단계를 대체하십시오.</target>
        </trans-unit>
        <trans-unit id="acdc2f08598a5d995bb4a299bbeb6695fc569906" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps. Only applies if &lt;code&gt;analyzer is not callable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abd6316e00c26c25837bba2d69b86f216194acd8" translate="yes" xml:space="preserve">
          <source>Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">전처리 및 n-gram 생성 단계를 유지하면서 문자열 토큰 화 단계를 대체하십시오. &lt;code&gt;analyzer == 'word'&lt;/code&gt; 경우에만 적용됩니다 .</target>
        </trans-unit>
        <trans-unit id="33411261f8481ce8d25af4edfb3eb882b6e66f99" translate="yes" xml:space="preserve">
          <source>Oversubscription can arise in the exact same fashion with parallelized routines from MKL, OpenBLAS or BLIS that are nested in joblib calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ed28a68908d4cdeb1448490b897df73855c6566" translate="yes" xml:space="preserve">
          <source>P. Geurts, D. Ernst., and L. Wehenkel, &amp;ldquo;Extremely randomized trees&amp;rdquo;, Machine Learning, 63(1), 3-42, 2006.</source>
          <target state="translated">P. Geurts, D. Ernst. 및 L. Wehenkel,&amp;ldquo;극도로 무작위 화 된 나무&amp;rdquo;, Machine Learning, 63 (1), 3-42, 2006.</target>
        </trans-unit>
        <trans-unit id="12d77ff2c2e2faf889fa68d60f9acbbdadb178db" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. J. Am Stat Ass, 79:871, 1984.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="915eb2720a9af992fe72961a5e439fc3997b7b8e" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. Journal of American Statistical Ass., 79:871, 1984.</source>
          <target state="translated">PJ Rousseeuw. 최소 제곱 회귀 분석 Journal of American Statistical Ass., 79 : 871, 1984 년.</target>
        </trans-unit>
        <trans-unit id="b9c25cc16ba020ea92289241ec3d659cb7a5c1ce" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;정밀 리콜 게인 곡선 : PR 분석이 올바르게 완료되었습니다&lt;/a&gt; ., NIPS 2015.</target>
        </trans-unit>
        <trans-unit id="6732b8c3c2862c9a25623cf97fcdcc10a13cb40d" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df9f68f22da202cd6a48417661656eae814961f2" translate="yes" xml:space="preserve">
          <source>PCA centers but does not scale the input data for each feature before applying the SVD. The optional parameter &lt;code&gt;whiten=True&lt;/code&gt; makes it possible to project the data onto the singular space while scaling each component to unit variance. This is often useful if the models down-stream make strong assumptions on the isotropy of the signal: this is for example the case for Support Vector Machines with the RBF kernel and the K-Means clustering algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="492b92fdeb678aa5ea0a0b2e24c313120c5ad6a0" translate="yes" xml:space="preserve">
          <source>PCA example with Iris Data-set</source>
          <target state="translated">Iris 데이터 세트가있는 PCA 예</target>
        </trans-unit>
        <trans-unit id="e783d8dc6810fed89a1dbeb972c615c5d6fa683c" translate="yes" xml:space="preserve">
          <source>PCA is used to decompose a multivariate dataset in a set of successive orthogonal components that explain a maximum amount of the variance. In scikit-learn, &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is implemented as a &lt;em&gt;transformer&lt;/em&gt; object that learns \(n\) components in its &lt;code&gt;fit&lt;/code&gt; method, and can be used on new data to project it on these components.</source>
          <target state="translated">PCA는 최대 분산 량을 설명하는 연속 직교 성분 세트에서 다변량 데이터 세트를 분해하는 데 사용됩니다. scikit-learn에서 &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; 는 &lt;code&gt;fit&lt;/code&gt; 방법으로 \ (n \) 구성 요소를 학습 하는 &lt;em&gt;변환기&lt;/em&gt; 객체 로 구현되며 새 데이터에서 이러한 구성 요소에 투영 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="a8428e4319c22658665567a92df72d0be42ed589" translate="yes" xml:space="preserve">
          <source>PCA, on the other hand, finds orthogonal directions in the raw feature space that correspond to directions accounting for maximum variance.</source>
          <target state="translated">반면 PCA는 원시 피쳐 공간에서 최대 분산을 설명하는 방향에 해당하는 직교 방향을 찾습니다.</target>
        </trans-unit>
        <trans-unit id="daf6b41a17ad64437397807edf4249f5c767d4f8" translate="yes" xml:space="preserve">
          <source>PDF documentation</source>
          <target state="translated">PDF 문서</target>
        </trans-unit>
        <trans-unit id="39addbbc6b853c00475e9525bae3e13c16a88c57" translate="yes" xml:space="preserve">
          <source>PDF of a random variable Y following Poisson, Tweedie (power=1.5) and Gamma distributions with different mean values (\(\mu\)). Observe the point mass at \(Y=0\) for the Poisson distribution and the Tweedie (power=1.5) distribution, but not for the Gamma distribution which has a strictly positive target domain.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83a2c673c060675dd48fb711d1c30c7deadadba5" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above Figure shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">두 개의 대상 기능이있는 PDP는 두 기능 간의 상호 작용을 보여줍니다. 예를 들어, 위의 그림에서 2 변수 PDP는 평균 주택 가격과 주택 연령 및 평균 공동 가치에 대한 의존성을 보여줍니다. 가구당 입주자 수 우리는 두 기능 사이의 상호 작용을 분명히 볼 수 있습니다. 2보다 큰 점유율은 주택 가격이 주택 연령과 거의 독립적 인 반면, 2보다 작은 값의 경우 연령에 대한 강한 의존성이 있습니다.</target>
        </trans-unit>
        <trans-unit id="eb9628323c2e00c334e5176712c96c9098e56078" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above figure shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than 2 there is a strong dependence on age.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="818b23313a5fe3e3ead33eeac95b3f83aefbbeb6" translate="yes" xml:space="preserve">
          <source>PLS regression</source>
          <target state="translated">PLS 회귀</target>
        </trans-unit>
        <trans-unit id="256d47be93e9a1da4b73eeee064926026bfad0da" translate="yes" xml:space="preserve">
          <source>PLSCanonical implements the 2 blocks canonical PLS of the original Wold algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</source>
          <target state="translated">PLSCanonical은 [Wegelin 2000]에서 PLS-C2A라고하는 원래의 Wold 알고리즘 [Tenenhaus 1998] p.204의 2 블록 표준 PLS를 구현합니다.</target>
        </trans-unit>
        <trans-unit id="cbfe13649cb0f1ff547f98c2537765f522c1604e" translate="yes" xml:space="preserve">
          <source>PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1 in case of one dimensional response. This class inherits from _PLS with mode=&amp;rdquo;A&amp;rdquo;, deflation_mode=&amp;rdquo;regression&amp;rdquo;, norm_y_weights=False and algorithm=&amp;rdquo;nipals&amp;rdquo;.</source>
          <target state="translated">PLSRegression은 1 차원 응답의 경우 PLS2 또는 PLS1으로 알려진 PLS 2 블록 회귀를 구현합니다. 이 클래스는 mode =&amp;rdquo;A&amp;rdquo;, deflation_mode =&amp;rdquo;regression&amp;rdquo;, norm_y_weights = False 및 algorithm =&amp;rdquo;nipals&amp;rdquo;인 _PLS에서 상속합니다.</target>
        </trans-unit>
        <trans-unit id="5bd004de10b3be3d62af4c772e0a783e4c8d0cf7" translate="yes" xml:space="preserve">
          <source>PTRATIO pupil-teacher ratio by town</source>
          <target state="translated">도시 별 PTRATIO 학생-교사 비율</target>
        </trans-unit>
        <trans-unit id="41c1bb8d3d0929f28ded963b3c507fc9ad31e847" translate="yes" xml:space="preserve">
          <source>Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions, Statistics and Probability Letters, 33 (1997) 291-297</source>
          <target state="translated">Pace, R. Kelley and Ronald Barry, 스파 스 공간 자기 회귀, 통계 및 확률 서한, 33 (1997) 291-297</target>
        </trans-unit>
        <trans-unit id="839107cb8051c220f3fa3546dd66b100d0cfaf46" translate="yes" xml:space="preserve">
          <source>Pairwise Euclidean distances between points in the dataset.</source>
          <target state="translated">데이터 세트의 점 사이의 쌍별 유클리드 거리.</target>
        </trans-unit>
        <trans-unit id="91ced6bbdf313e062ca8a5307f468c6f86bd6aab" translate="yes" xml:space="preserve">
          <source>Pairwise dissimilarities between the points. Must be symmetric.</source>
          <target state="translated">점 사이의 쌍별 상 이성. 대칭이어야합니다.</target>
        </trans-unit>
        <trans-unit id="d8020c04569a536923cc79cf93520b90edece8e9" translate="yes" xml:space="preserve">
          <source>Pairwise metrics</source>
          <target state="translated">쌍별 측정 항목</target>
        </trans-unit>
        <trans-unit id="0f7f7966f9f80e85baa6445a47b9d7c8941de99f" translate="yes" xml:space="preserve">
          <source>Parameter &lt;code&gt;nu&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;OneClassSVM&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; approximates the fraction of training errors and support vectors.</source>
          <target state="translated">매개 변수 &lt;code&gt;nu&lt;/code&gt; 에서 &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;OneClassSVM&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; 는&lt;/a&gt; 교육 오류 및 지원 벡터의 분율을 가깝다.</target>
        </trans-unit>
        <trans-unit id="539d705b4d5ce5e51b178019bd7f151f362e066d" translate="yes" xml:space="preserve">
          <source>Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogenous.</source>
          <target state="translated">커널의 비균질성을 제어하는 ​​매개 변수. sigma_0 = 0이면 커널은 동종입니다.</target>
        </trans-unit>
        <trans-unit id="2462327ecfe7c5d6548ffb2d6d2c9cd234dbc30c" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level</source>
          <target state="translated">노이즈 레벨을 제어하는 ​​파라미터</target>
        </trans-unit>
        <trans-unit id="c00b33b8475549fd87f899268c585bfb7eff3c97" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level (variance)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4958bb8c16cafb2697226165d2c132d7ac8dc77e" translate="yes" xml:space="preserve">
          <source>Parameter estimation using grid search with cross-validation</source>
          <target state="translated">교차 검증을 통한 그리드 검색을 사용한 파라미터 추정</target>
        </trans-unit>
        <trans-unit id="c2428812e57708220766f99c6be2b35f70d17ffd" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel</source>
          <target state="translated">knn 커널의 매개 변수</target>
        </trans-unit>
        <trans-unit id="3b0d1a590649f050970c31b6418be3790d6a82df" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which is a strictly positive integer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="849fb657e2772ba4166207f98cd952ea68adf842" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which need to be strictly positive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fe064660ce73ee246b908fe6ec0781ebb1b98a2" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel</source>
          <target state="translated">rbf 커널의 매개 변수</target>
        </trans-unit>
        <trans-unit id="deecb0cfdd93d212c57e43f85e54500d3ea12cc6" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="766ac73c1e3445a4aa75bd4ec364753f58d7ba1c" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt;&lt;/a&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79b884107bc3e783bfcd688080df4a673a9117bc" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">&lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt; 의 Minkowski 지표에 대한 매개 변수입니다 . p = 1 인 경우 manhattan_distance (l1) 및 euclidean_distance (l2)를 p = 2로 사용하는 것과 같습니다. 임의의 p의 경우 minkowski_distance (l_p)가 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="2987673c5e2227c54e84a4c36c70d874959de513" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">sklearn.metrics.pairwise.pairwise_distances의 Minkowski 메트릭에 대한 매개 변수입니다. p = 1 인 경우 manhattan_distance (l1) 및 euclidean_distance (l2)를 p = 2로 사용하는 것과 같습니다. 임의의 p의 경우 minkowski_distance (l_p)가 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="76b1a424a6610c92a4ff7dfc12b9deaa7fadd9d4" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric</source>
          <target state="translated">메트릭으로 지정된 페어 와이즈 커널의 매개 변수 감마</target>
        </trans-unit>
        <trans-unit id="1a54a92f7211f800d04136c5d7139c5f372c6e37" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric. It should be positive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f182d859d9049c92f489a6a5f8f861f198a0672" translate="yes" xml:space="preserve">
          <source>Parameter names mapped to their values.</source>
          <target state="translated">매개 변수 이름이 해당 값에 맵핑되었습니다.</target>
        </trans-unit>
        <trans-unit id="6c7eaceb91dd3f01e9a6c5c6273381eb8837898b" translate="yes" xml:space="preserve">
          <source>Parameter of RBF kernel: exp(-gamma * x^2)</source>
          <target state="translated">RBF 커널의 매개 변수 : exp (-gamma * x ^ 2)</target>
        </trans-unit>
        <trans-unit id="0a55d1c3b23ce41ff45285111de0d234bf72191c" translate="yes" xml:space="preserve">
          <source>Parameter of the corresponding mode.</source>
          <target state="translated">해당 모드의 파라미터.</target>
        </trans-unit>
        <trans-unit id="bd306dfafa0f09eb6ebeeb4165e12648835ffbc7" translate="yes" xml:space="preserve">
          <source>Parameter setting that gave the best results on the hold out data.</source>
          <target state="translated">홀드 아웃 데이터에서 최상의 결과를 제공하는 파라미터 설정.</target>
        </trans-unit>
        <trans-unit id="feb33995ff27df7648c2862697f9ab2d916fc6ad" translate="yes" xml:space="preserve">
          <source>Parameter to control the quality of the embedding according to the Johnson-Lindenstrauss lemma when n_components is set to &amp;lsquo;auto&amp;rsquo;.</source>
          <target state="translated">n_components가 'auto'로 설정된 경우 Johnson-Lindenstrauss의 정리에 따라 임베드의 품질을 제어하는 ​​매개 변수입니다.</target>
        </trans-unit>
        <trans-unit id="9ebea54f905d700d979affa38d92638bb2ef6e53" translate="yes" xml:space="preserve">
          <source>Parameter tuning using grid search</source>
          <target state="translated">그리드 검색을 사용한 파라미터 튜닝</target>
        </trans-unit>
        <trans-unit id="025546b75e4d071d18ff381aef96422930bc33e9" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). If a 1D y is passed in at fit (non multi-task usage), &lt;code&gt;coef_&lt;/code&gt; is then a 1D array. Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">모수 벡터 (비용 함수 공식에서 W). 1D y가 멀티 &lt;code&gt;coef_&lt;/code&gt; 이 아닌 적절한 상태로 전달되면 coef_ 는 1D 배열입니다. 참고 &lt;code&gt;coef_&lt;/code&gt; 의 점포의 전치를 &lt;code&gt;W&lt;/code&gt; , &lt;code&gt;W.T&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fe2cd82aa0b85722f1fb3f2651910fd5a1cb8bc3" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">모수 벡터 (비용 함수 공식에서 W). 참고 &lt;code&gt;coef_&lt;/code&gt; 의 점포의 전치를 &lt;code&gt;W&lt;/code&gt; , &lt;code&gt;W.T&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="40a18e293fedd48b8399b301e107b7d0fd89c55d" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the cost function formula),</source>
          <target state="translated">모수 벡터 (비용 함수 공식에서 w),</target>
        </trans-unit>
        <trans-unit id="f2cc602f72e28952a1109943af93a6b27340c9a5" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the formulation formula).</source>
          <target state="translated">매개 변수 벡터 (공식 공식에서 w).</target>
        </trans-unit>
        <trans-unit id="b98d4ebc4de7e076498469fbea1e480d774d01d2" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the problem formulation).</source>
          <target state="translated">모수 벡터 (문제 공식에서 w).</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="561ad54783e422872a1f3fe4a9c36ebd61273494" translate="yes" xml:space="preserve">
          <source>Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.</source>
          <target state="translated">호출 가능한 객체로 전달 된 커널의 매개 변수 (키워드 인수) 및 값 다른 커널에서는 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="80f07c17ffcb9ce6c39eaf0025d7648367dfab02" translate="yes" xml:space="preserve">
          <source>Parameters for the metric used to compute distances to neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89febd358321017f18d670418f2852c0de1ee9c6" translate="yes" xml:space="preserve">
          <source>Parameters of the estimators in the pipeline can be accessed using the &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; syntax:</source>
          <target state="translated">파이프 라인에서 추정기의 매개 변수는 &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; 구문을 사용하여 액세스 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="da0d463840d0f1c86c777dbae23f9ad6731982e6" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo; or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">변압기의 파라미터는 이름과 파라미터 이름을 '__'으로 구분하여 설정할 수 있습니다. 매개 변수의 이름을 다른 변환기로 설정하여 변환기를 완전히 대체하거나 'drop'또는 &lt;code&gt;None&lt;/code&gt; 으로 설정하여 제거 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="689a87c23200ec6fa5f83b0f33b09b3222cdab89" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc1660202c57ce270668effe7d8743477471db0d" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;estimator.fit&lt;/code&gt; method of each step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdc9ca5309db0dd08f8314e5e5818e96afcd9144" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method at each step of the regressor chain.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b076b9abb4a3e4211d375c7fba667486c4754cb9" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of each step, where each parameter name is prefixed such that parameter &lt;code&gt;p&lt;/code&gt; for step &lt;code&gt;s&lt;/code&gt; has key &lt;code&gt;s__p&lt;/code&gt;.</source>
          <target state="translated">각 단계 의 &lt;code&gt;fit&lt;/code&gt; 메소드로 전달 된 매개 변수 . 여기서 각 매개 변수 이름 앞에는 단계 &lt;code&gt;s&lt;/code&gt; 의 매개 변수 &lt;code&gt;p&lt;/code&gt; 에 키 &lt;code&gt;s__p&lt;/code&gt; 가 있습니다.</target>
        </trans-unit>
        <trans-unit id="1ab85e076de8886205c489db8ed7843daa19517c" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the estimator</source>
          <target state="translated">추정기 의 &lt;code&gt;fit&lt;/code&gt; 방법으로 전달되는 매개 변수</target>
        </trans-unit>
        <trans-unit id="6dde0ba4e8565b39355c42aec6126c1947540a58" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the underlying regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e8067debf1488481c61a1eaa4a0a76867521e4f" translate="yes" xml:space="preserve">
          <source>Parameters to be set on estimator for this grid point.</source>
          <target state="translated">이 그리드 포인트에 대한 추정기에서 설정할 매개 변수입니다.</target>
        </trans-unit>
        <trans-unit id="191e3e986e6964fefdb746bdbd32d026ac54732c" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method of the estimator.</source>
          <target state="translated">추정기의 적합 방법에 전달할 매개 변수입니다.</target>
        </trans-unit>
        <trans-unit id="80e379dd51d34ce2dbedd57a975596631a95d883" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method.</source>
          <target state="translated">fit 메소드에 전달할 매개 변수입니다.</target>
        </trans-unit>
        <trans-unit id="36ccb38b123600d9fbc78ab0cd9b6b307a008e1c" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called at the end of all transformations in the pipeline. Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.</source>
          <target state="translated">파이프 라인의 모든 변환이 끝날 때 호출 되는 &lt;code&gt;predict&lt;/code&gt; 매개 변수 입니다. return_std 또는 return_cov가있는 일부 모델에서 불확실성을 반환하는 데 사용될 수 있지만 파이프 라인의 변환에 의해 생성 된 불확실성은 최종 추정기로 전파되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="b3a7c9dd881e64a7f41aafeb58e4f8bfcc6a5b4f" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called by the &lt;code&gt;final_estimator&lt;/code&gt;. Note that this may be used to return uncertainties from some estimators with &lt;code&gt;return_std&lt;/code&gt; or &lt;code&gt;return_cov&lt;/code&gt;. Be aware that it will only accounts for uncertainty in the final estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="381c775599d6e4185d4410725809e360928357cd" translate="yes" xml:space="preserve">
          <source>Parameters:</source>
          <target state="translated">Parameters:</target>
        </trans-unit>
        <trans-unit id="99be92c9a2dedb3674880d6acb8f2dcdcbd96ff3" translate="yes" xml:space="preserve">
          <source>Parsing a text based source can be expensive. When working on repeatedly on the same dataset, it is recommended to wrap this loader with joblib.Memory.cache to store a memmapped backup of the CSR results of the first call and benefit from the near instantaneous loading of memmapped structures for the subsequent calls.</source>
          <target state="translated">텍스트 기반 소스를 파싱하는 것은 비용이 많이들 수 있습니다. 동일한 데이터 세트에서 반복적으로 작업 할 때 첫 번째 호출의 CSR 결과에 대한 맵핑 된 백업을 저장하기 위해이 로더를 joblib.Memory.cache로 랩핑하고 후속 호출에 대해 거의 즉시 맵핑 된 구조를로드하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="9dffe51138babd8f1ead215ce660a1e946197066" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plot (PDP) visualization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8d5f258416422c57466cd67cc8a02c6b05a80fd" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plots</source>
          <target state="translated">부분 의존도</target>
        </trans-unit>
        <trans-unit id="07df4cbd5294e07465f804b7c9b36c5d5a43e82b" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for Gradient Boosting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b282664cc1d0ff2c6d0b320162703f3341719289" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for multi-layer perceptron</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9c89f964f1a01a36b42f3fe4848b74ccc63e0e6" translate="yes" xml:space="preserve">
          <source>Partial Least Square SVD</source>
          <target state="translated">부분 최소 제곱 SVD</target>
        </trans-unit>
        <trans-unit id="0af696b5fd6af6b13c25a86aed283f8f2b249126" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93cbd804a6e8e51bf70182f90134157ea23f1138" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;target_variables&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;target_variables&lt;/code&gt; 의 부분 의존성 .</target>
        </trans-unit>
        <trans-unit id="abf44f40a8ead68e3c71b46bec075211dc75d783" translate="yes" xml:space="preserve">
          <source>Partial dependence of a feature (or a set of features) corresponds to the average response of an estimator for each possible value of the feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c99d4545385034142f3b81de241245acbbd2acd6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response as a function of the &amp;lsquo;target&amp;rsquo; features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a65d01c56b56d7e6904a157392f75eb71dc3b44" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; as a function of the &amp;lsquo;target&amp;rsquo; features &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;.</source>
          <target state="translated">부분 의존도 (PDP)는 목표 반응과 일련의 '목표'특징 사이의 의존성을 보여 주어 다른 모든 특징 ( '보완'특징)의 값보다 소폭합니다. 직관적으로, 우리는 부분적 의존성을 예상 된 목표 응답으로 해석 할 수있다 &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; '목표'특징의 함수로서 &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9fe71a24f95abe640c27c0bbf2214ad816fa5b2e" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;features&lt;/code&gt; 대한 부분 의존도 .</target>
        </trans-unit>
        <trans-unit id="652e656223f58b0f5fc37309adb1b1ac47d155cf" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for tree ensembles.</source>
          <target state="translated">나무 앙상블에 대한 부분 의존도.</target>
        </trans-unit>
        <trans-unit id="c1a7be74107eb23fd9bfcd8698a88bc718aa4772" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the joint values of the &lt;code&gt;target_variables&lt;/code&gt; and the function represented by the &lt;code&gt;gbrt&lt;/code&gt;.</source>
          <target state="translated">부분 의존도 도표는 &lt;code&gt;target_variables&lt;/code&gt; 의 결합 값 과 &lt;code&gt;gbrt&lt;/code&gt; 로 표시되는 함수 사이의 의존성을 보여줍니다 .</target>
        </trans-unit>
        <trans-unit id="fc1161112f98108492921350df0f600984c6b3b0" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;2&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception, the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04afc172d4359535322f4eeb08a601341437662b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features (see &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt;&lt;code&gt;feature_importances_&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">부분 의존도 도표는 목표 함수 &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; 와 일련의 '목표'특징 사이의 의존성을 보여 주며, 다른 모든 특징 (보완 특징)의 값보다 조금 더 중요합니다. 인간 인식의 한계로 인해 대상 기능 세트의 크기가 작아야 (보통 1 또는 2) 대상 기능이 가장 중요한 기능 중에서 선택됩니다 ( &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt; &lt;code&gt;feature_importances_&lt;/code&gt; &lt;/a&gt; 참조 ).</target>
        </trans-unit>
        <trans-unit id="a4a9c59e85db7b4787e5c0d6935be7408b0e1749" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27028d4e93727066aec3e2e83aa74954e7719a8b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">두 가지 대상 피처가있는 부분 의존도를 사용하면 상호 작용을 시각화 할 수 있습니다. 양방향 부분 의존도 도표는 주택 연령과 평균의 공동 가치에 대한 중간 주택 가격의 의존성을 보여줍니다. 가구당 입주자 수 우리는 두 기능 사이의 상호 작용을 분명히 볼 수 있습니다. 2보다 큰 점유율은 주택 가격이 주택 연령과 거의 독립적 인 반면, 2보다 작은 값의 경우 연령에 대한 강한 의존성이 있습니다.</target>
        </trans-unit>
        <trans-unit id="b6af299fa9b94db48e98129e260b1eeb813719a6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e99bc5cb78022b1555bc70fa32795dba1ae5f4f" translate="yes" xml:space="preserve">
          <source>Partially fit underlying estimators</source>
          <target state="translated">기본 추정량에 부분적으로 적합</target>
        </trans-unit>
        <trans-unit id="0a5bfb5dfddbf187589aac0e6c6f726ea3a56e0f" translate="yes" xml:space="preserve">
          <source>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</source>
          <target state="translated">특히 고차원 공간에서 데이터를보다 쉽게 ​​선형으로 분리 할 수 ​​있으며 순진 베이 및 선형 SVM과 같은 분류기의 단순성이 다른 분류기보다 달성하기가 더 일반화 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ee5c2f652fa0ba7331b6add7547b0b3f663aedd3" translate="yes" xml:space="preserve">
          <source>Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure.</source>
          <target state="translated">데이터에 기본 바둑판 구조가 있다고 가정하여 행과 열을 분할합니다. 예를 들어, 2 개의 행 파티션과 3 개의 열 파티션이있는 경우 각 행은 3 개의 biclusters에 속하고 각 열은 2 개의 biclusters에 속합니다. 해당 행 및 열 레이블 벡터의 외부 곱은이 바둑판 구조를 제공합니다.</target>
        </trans-unit>
        <trans-unit id="364b4c71a5c83a360f4fe86b4c60a48d2e33f726" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible output for permutation of &lt;code&gt;y&lt;/code&gt; values among samples. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa828ddb159ddfa77238aad6f870c00db1af477d" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9f564dc265e98a01f24f70d1576b62ca3b43bd3" translate="yes" xml:space="preserve">
          <source>Passing a 2D matrix for multilabel classification</source>
          <target state="translated">멀티 라벨 분류를위한 2D 매트릭스 전달</target>
        </trans-unit>
        <trans-unit id="cd2bb1a7aa8efcc1bd63306134f3100f91fc6ef3" translate="yes" xml:space="preserve">
          <source>Passing these predictions into an evaluation metric may not be a valid way to measure generalization performance. Results can differ from &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; unless all tests sets have equal size and the metric decomposes over samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="144adab066cd5c92a6778f61a4778ef74c72b2a0" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Classifier</source>
          <target state="translated">수동 공격적 분류기</target>
        </trans-unit>
        <trans-unit id="d61635eec17c853d9d6e1ff234afe50660f92701" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Regressor</source>
          <target state="translated">패시브 공격적인 회귀</target>
        </trans-unit>
        <trans-unit id="291afa1da61effaacff4bf3e40a8045b9b8d343b" translate="yes" xml:space="preserve">
          <source>Patches are assumed to overlap and the image is constructed by filling in the patches from left to right, top to bottom, averaging the overlapping regions.</source>
          <target state="translated">패치는 겹치는 것으로 가정하고 이미지는 왼쪽에서 오른쪽, 위에서 아래로 패치를 채우고 겹치는 영역을 평균화하여 구성됩니다.</target>
        </trans-unit>
        <trans-unit id="18a1699e2836ba2addd008ee2015c4e0ca5931f6" translate="yes" xml:space="preserve">
          <source>Path to the main folder holding one subfolder per category</source>
          <target state="translated">범주 당 하나의 하위 폴더를 포함하는 기본 폴더의 경로</target>
        </trans-unit>
        <trans-unit id="98ee95181d901b366d1fe1c0df5a309cc7a3de65" translate="yes" xml:space="preserve">
          <source>Penalization parameter selected.</source>
          <target state="translated">벌칙 매개 변수가 선택되었습니다.</target>
        </trans-unit>
        <trans-unit id="269c93d9d03f37f0d0341535ce102e3bd06fa60f" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bbf431b41c522bd1eb1b65ea50fc21584275d87" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad) yes no no no no Faster for large datasets no no no yes yes Robust to unscaled datasets yes yes yes no no ============================ =========== ======= =========== ===== ======</source>
          <target state="translated">가로 채기 (나쁜)에 불이익을줍니다 예 아니요 아니요 아니요 아니요 큰 데이터 세트의 경우 더 빠름 아니요 아니요 예 예 ======= =========== ======= =========== ============</target>
        </trans-unit>
        <trans-unit id="64a00002571bc14aac9e57cf087ec95ea0663632" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term.</source>
          <target state="translated">에러 항의 페널티 파라미터 C.</target>
        </trans-unit>
        <trans-unit id="78e16aaecb446c766536c888cb2ab681d45d227a" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term. The penalty is a squared l2 penalty. The bigger this parameter, the less regularization is used.</source>
          <target state="translated">에러 항의 페널티 파라미터 C. 페널티는 제곱 L2 페널티입니다. 이 매개 변수가 클수록 정규화가 덜 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="92dc577567bc10903722a0cd6bc84fd8cb538ac8" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BFGS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36c27027dd1d6e2db082fc2d8518ad5ddec8cac4" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BGFS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4b4203fc28ce6d3a674721e39c00d5f8047107a" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;fmin_l_bfgs_b&amp;rsquo; algorithm from scipy.optimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">기본적으로 scipy.optimize의 'fmin_l_bfgs_b'알고리즘이 사용됩니다. None이 전달되면 커널의 매개 변수는 고정 된 상태로 유지됩니다. 사용 가능한 내부 최적화 프로그램은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="6244b7856d25c3c666d36fccf077f85fa1982ad7" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum.</source>
          <target state="translated">기능별 최소 조정.</target>
        </trans-unit>
        <trans-unit id="3b00bbffe150e7b8c58881b0f3768ad4c9012a12" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum. Equivalent to &lt;code&gt;min - X.min(axis=0) * self.scale_&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1fcc9536b36965b70f539451057ec6f4f433503" translate="yes" xml:space="preserve">
          <source>Per feature maximum absolute value.</source>
          <target state="translated">기능별 최대 절대 값.</target>
        </trans-unit>
        <trans-unit id="c5e7199d590adbeaea5c7d5a6fd8bd4755090a1c" translate="yes" xml:space="preserve">
          <source>Per feature maximum seen in the data</source>
          <target state="translated">데이터에서 볼 수있는 최대 기능</target>
        </trans-unit>
        <trans-unit id="102581d144872704eb291cec69ea6b75f7b2f4ae" translate="yes" xml:space="preserve">
          <source>Per feature minimum seen in the data</source>
          <target state="translated">데이터에서 볼 수있는 기능별 최소</target>
        </trans-unit>
        <trans-unit id="9af0de5bb3d05f02ad6ecd6ef96e244722359bc9" translate="yes" xml:space="preserve">
          <source>Per feature range &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt; seen in the data</source>
          <target state="translated">데이터에서 볼 수있는 기능별 범위 &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3041c95c2bc4cf499751cc15dcfa6079b79d0c01" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data.</source>
          <target state="translated">데이터의 기능별 스케일링.</target>
        </trans-unit>
        <trans-unit id="2aca96873ba30a1f44a2ea13c9cca023c862496e" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">데이터의 기능별 스케일링. 같음 &lt;code&gt;None&lt;/code&gt; 때 &lt;code&gt;with_std=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="add1f6f8b0508a85231ee2c9d67b3d85e4b4574a" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equivalent to &lt;code&gt;(max - min) / (X.max(axis=0) - X.min(axis=0))&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f0850ba910ca1120662899ac545a63448e94c53" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. This is calculated using &lt;code&gt;np.sqrt(var_)&lt;/code&gt;. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03c5a380bfcbdfa271df31ac8e5033140b3c462f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">기능별 경험적 평균, &lt;code&gt;partial_fit&lt;/code&gt; 호출에 대한 집계 입니다.</target>
        </trans-unit>
        <trans-unit id="9b69855eee3f3bb7b79cdf586195cf71da93449f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set.</source>
          <target state="translated">훈련 세트에서 추정 된 기능별 경험적 평균.</target>
        </trans-unit>
        <trans-unit id="78b2f336c949583f3bdffdc9a030b0f9e6170c47" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set. Equal to &lt;code&gt;X.mean(axis=0)&lt;/code&gt;.</source>
          <target state="translated">훈련 세트에서 추정 된 기능별 경험적 평균. 동일 &lt;code&gt;X.mean(axis=0)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a8c85c36120ad4d7e0ffc8553bf9d9bb4f653d40" translate="yes" xml:space="preserve">
          <source>Per-feature empirical variance, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">당 기능 경험적 분산, 호출을 통해 집계 &lt;code&gt;partial_fit&lt;/code&gt; 을 .</target>
        </trans-unit>
        <trans-unit id="bb6e9ff3187e622eed5823426c5d8cc8b9a5e66d" translate="yes" xml:space="preserve">
          <source>Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</source>
          <target state="translated">샘플 당 중량. 샘플 당 C를 재조정하십시오. 가중치가 클수록 분류 기가이 점에 더 중점을 둡니다.</target>
        </trans-unit>
        <trans-unit id="022818083764d59bc1c545a8df2dfc49cf87ec2a" translate="yes" xml:space="preserve">
          <source>Per-topic word distributions are independently drawn, where in reality all would be affected by a sparse base distribution, and would be correlated.</source>
          <target state="translated">주제별 단어 분포는 독립적으로 그려지며, 실제로는 모두 희소 한 기본 분포의 영향을 받고 상관됩니다.</target>
        </trans-unit>
        <trans-unit id="508100893e29e053d40024965b139e71658b7b80" translate="yes" xml:space="preserve">
          <source>Percent of features to keep.</source>
          <target state="translated">유지할 기능의 백분율입니다.</target>
        </trans-unit>
        <trans-unit id="510c90c1028713db83438ed3b7d7b97622c046bb" translate="yes" xml:space="preserve">
          <source>Percentage of the number of classes to be used to create the code book. A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. A number greater than 1 will require more classifiers than one-vs-the-rest.</source>
          <target state="translated">코드북을 작성하는 데 사용되는 클래스 수의 백분율입니다. 0과 1 사이의 숫자는 나머지 하나보다 분류 기가 더 적습니다. 1보다 큰 숫자는 나머지 하나보다 많은 분류 기가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="ab474311418f716aa90a18ba4aac10d5e0126b01" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components.</source>
          <target state="translated">선택한 각 성분에 의해 설명 된 분산의 백분율입니다.</target>
        </trans-unit>
        <trans-unit id="6b606c4b3521608268acaf8a83daf1d705edec66" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.</source>
          <target state="translated">선택한 각 성분에 의해 설명 된 분산의 백분율입니다. 경우 &lt;code&gt;n_components&lt;/code&gt; 가 설정되지 않는 모든 구성 요소는 저장하고 설명 차이의 합은 1.0와 동일한다. 고유 또는 svd 솔버를 사용하는 경우에만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d93d3d6b53ae20e2e020e6bfd5f07bc4328ff552" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0.</source>
          <target state="translated">선택한 각 성분에 의해 설명 된 분산의 백분율입니다. 모든 구성 요소가 저장된 경우 설명 된 분산의 합은 1.0과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b76d05a7855a1137343582656ace6f381d34c7bd" translate="yes" xml:space="preserve">
          <source>Perceptron: \(L(y_i, f(x_i)) = \max(0, - y_i f(x_i))\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ae537dc31ff6e276137ba1f3f08f14e2d75b135" translate="yes" xml:space="preserve">
          <source>Perfect labeling is scored 1.0:</source>
          <target state="translated">완벽한 라벨링은 1.0 점입니다 :</target>
        </trans-unit>
        <trans-unit id="e0246cf8e59488c8ec6f2dd495c80e88ab5e2c38" translate="yes" xml:space="preserve">
          <source>Perfect labelings are both homogeneous and complete, hence have score 1.0:</source>
          <target state="translated">완벽한 라벨링은 균질하고 완전하므로 점수가 1.0입니다.</target>
        </trans-unit>
        <trans-unit id="0b6e6a15e84a2c0c2b67bd408293381d6bde8086" translate="yes" xml:space="preserve">
          <source>Perfect labelings are complete:</source>
          <target state="translated">완벽한 라벨링이 완료되었습니다 :</target>
        </trans-unit>
        <trans-unit id="c929d898b15ba46b39cbe3a578cc048974dbb0f3" translate="yes" xml:space="preserve">
          <source>Perfect labelings are homogeneous:</source>
          <target state="translated">완벽한 라벨링은 균질합니다 :</target>
        </trans-unit>
        <trans-unit id="158762f0fcedf70ff27743eef2b9fe2391aaecf5" translate="yes" xml:space="preserve">
          <source>Perfectly matching labelings have a score of 1 even</source>
          <target state="translated">완벽하게 일치하는 라벨의 점수는 1입니다.</target>
        </trans-unit>
        <trans-unit id="689d4751e15d0ca03ac4490cb60697622e5a7435" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data</source>
          <target state="translated">데이터의 선호도 전파 클러스터링 수행</target>
        </trans-unit>
        <trans-unit id="dee861689c2a0a2296c4bb43119e58f854cfe756" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data.</source>
          <target state="translated">데이터의 선호도 전파 클러스터링을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="5a1975729819b04264272cf944b37eeff6c54bb5" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix, and return cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="463c2804b4b2c3d108889b17acd479af4436cc72" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix.</source>
          <target state="translated">피쳐 또는 거리 매트릭스에서 DBSCAN 클러스터링을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="b65b6612279cd3a62fed32683d01c69787a97da2" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features, or distance matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="458d7c0c2b90dff326f89ad767c75f6a1812b730" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from vector array or distance matrix.</source>
          <target state="translated">벡터 배열 또는 거리 행렬에서 DBSCAN 클러스터링을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="959d910f7763a2ffdb63e2da58508fc0266c6120" translate="yes" xml:space="preserve">
          <source>Perform Fast Independent Component Analysis.</source>
          <target state="translated">빠른 독립 성분 분석을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="c424661559fd4111ae395a81a440da23c2d8b00f" translate="yes" xml:space="preserve">
          <source>Perform OPTICS clustering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b44047366aaa6bbf25bda0720c2b9955136f4c83" translate="yes" xml:space="preserve">
          <source>Perform a Locally Linear Embedding analysis on the data.</source>
          <target state="translated">데이터에 대해 로컬 선형 임베딩 분석을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="ac1255795fd03e9f556426224dcbfbd70ca25e88" translate="yes" xml:space="preserve">
          <source>Perform a shortest-path graph search on a positive directed or undirected graph.</source>
          <target state="translated">양의 직접 또는 비 방향 그래프에서 최단 경로 그래프 검색을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="5913acb65bcb3cfc0407c274e6a0ae6c08f54988" translate="yes" xml:space="preserve">
          <source>Perform binary classification using non-linear SVC with RBF kernel. The target to predict is a XOR of the inputs.</source>
          <target state="translated">RBF 커널과 함께 비선형 SVC를 사용하여 이진 분류를 수행하십시오. 예측 대상은 입력의 XOR입니다.</target>
        </trans-unit>
        <trans-unit id="a259ca5c38306ae844a312467fcf634f7a4c4cb8" translate="yes" xml:space="preserve">
          <source>Perform classification on an array of test vectors X.</source>
          <target state="translated">일련의 테스트 벡터 X에 대해 분류를 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="1af0f015c949bd1c16d805fdf5523bbcd5119678" translate="yes" xml:space="preserve">
          <source>Perform classification on samples in X.</source>
          <target state="translated">X에서 샘플을 분류합니다.</target>
        </trans-unit>
        <trans-unit id="b3b3f491b55f8b579a228793b65f99ca8d0d1a92" translate="yes" xml:space="preserve">
          <source>Perform classification on test vectors X.</source>
          <target state="translated">테스트 벡터 X에 대한 분류를 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="2cc5f65a2c2c90fbeebd06f8fc6c4b4510abcc97" translate="yes" xml:space="preserve">
          <source>Perform clustering on X and returns cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db94ca6613eef6e933177aeabe20672ae9208bdf" translate="yes" xml:space="preserve">
          <source>Perform clustering.</source>
          <target state="translated">클러스터링을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="f9f7c30d76f5b933404ebf4eb86819fed33be90a" translate="yes" xml:space="preserve">
          <source>Perform dimensionality reduction on X.</source>
          <target state="translated">X에서 차원 축소를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="ea3d4bd6b3c1842187bced8b218fbec04eb7bd42" translate="yes" xml:space="preserve">
          <source>Perform fit on X and returns labels for X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d24d9dcbe2141c7b30ceff371628950cd7ca425" translate="yes" xml:space="preserve">
          <source>Perform is_fitted validation for estimator.</source>
          <target state="translated">추정기에 대해 is_fitted 검증을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="28c6ac8c77fceae308f63cb91c2fe135b4f5904f" translate="yes" xml:space="preserve">
          <source>Perform mapping to a normal distribution using a power transform.</source>
          <target state="translated">전력 변환을 사용하여 정규 분포에 대한 매핑을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="f154e55e13cfe215c964ae2fb4c3f06da46b83fe" translate="yes" xml:space="preserve">
          <source>Perform mean shift clustering of data using a flat kernel.</source>
          <target state="translated">플랫 커널을 사용하여 데이터의 평균 교대 클러스터링을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="5d74999037a10ebb61d14a38ac3c1f58c8d3eb1c" translate="yes" xml:space="preserve">
          <source>Perform one Gibbs sampling step.</source>
          <target state="translated">하나의 Gibbs 샘플링 단계를 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="a608c191f0cb8597865dd893c202fb7da2ab975c" translate="yes" xml:space="preserve">
          <source>Perform one epoch of stochastic gradient descent on given samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b97c414705aa3f4f9199ddb08da830ac54e8fe97" translate="yes" xml:space="preserve">
          <source>Perform regression on samples in X.</source>
          <target state="translated">X의 샘플에서 회귀를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="dd51e0250263d470cb8a4effc410185e24e99d6f" translate="yes" xml:space="preserve">
          <source>Perform robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">특이 치의 영향을 제거하지만 특이 치와 특이 치를 동일한 척도로 설정하지 않는 강력한 표준화를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="1506956d6558b19c7df6e1dc69b0a99dea667d55" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix, and return cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="557e6799397c88d4bc14664b365f9609412e8548" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebef79dfac2e65b8c25ad9bb7fdce83cd9513504" translate="yes" xml:space="preserve">
          <source>Perform standardization by centering and scaling</source>
          <target state="translated">중심 및 스케일링으로 표준화 수행</target>
        </trans-unit>
        <trans-unit id="4bc7fa7479a101fbc87b729f92b16086a341ed9e" translate="yes" xml:space="preserve">
          <source>Perform standardization that is faster, but less robust to outliers.</source>
          <target state="translated">더 빠르지 만 특이 치에 대해서는 덜 표준화 된 표준화를 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="3c9e3951bcb75f5ea77167c7144b5b5a81bd6690" translate="yes" xml:space="preserve">
          <source>Performs DBSCAN extraction for an arbitrary epsilon.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b688f62a3ad12b1d7c84b19ede9050b44271064d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of categorical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d75208cdd518398a274b5c66a99a07cd1c4674d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of dictionary items (also handles string-valued features).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8a1451466ddb25587dffc5d4da05875ebb74725" translate="yes" xml:space="preserve">
          <source>Performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.</source>
          <target state="translated">이화원 (중국) 이미지의 픽셀 단위 벡터 양자화 (VQ)를 수행하여 전체 모양 품질을 유지하면서 이미지를 표시하는 데 필요한 색상 수를 96,615 개의 고유 색상에서 64로 줄입니다.</target>
        </trans-unit>
        <trans-unit id="b9ac5dd9fc2e45481e3dd5c8a6199a86e1da0656" translate="yes" xml:space="preserve">
          <source>Performs an approximate one-hot encoding of dictionary items or strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d01f1a997cf8a75714d83a10021fc81a3a7d1f94" translate="yes" xml:space="preserve">
          <source>Performs an ordinal (integer) encoding of the categorical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7945877a79ee9606b9df91e80330316ac1099e28" translate="yes" xml:space="preserve">
          <source>Performs approximate nearest neighbor search using LSH forest.</source>
          <target state="translated">LSH 포리스트를 사용하여 가장 가까운 이웃 검색을 수행합니다.</target>
        </trans-unit>
        <trans-unit id="9bab7093aa44c52b527bcacee82e15ab827f7949" translate="yes" xml:space="preserve">
          <source>Performs binarization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API를 사용하여 이진화를 수행 합니다 (예 : 전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="9334db1899f0bba94453f1ee6fbd171b507e5ed1" translate="yes" xml:space="preserve">
          <source>Performs centering and scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API를 사용하여 센터링 및 스케일링을 수행 합니다 (예 : 전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="506256c7ae18c8053ecaa6445590a98acf36aa0e" translate="yes" xml:space="preserve">
          <source>Performs clustering on X and returns cluster labels.</source>
          <target state="translated">X에서 클러스터링을 수행하고 클러스터 레이블을 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="38545772bd4529f41bf4bec322ebc7f80ab61f41" translate="yes" xml:space="preserve">
          <source>Performs inductive inference across the model.</source>
          <target state="translated">모델에서 유도 성 추론을 수행합니다.</target>
        </trans-unit>
        <trans-unit id="de7dc9fb5a771d54ea7fadc4d86dd2f8269f14e4" translate="yes" xml:space="preserve">
          <source>Performs normalization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API를 사용하여 정규화를 수행 합니다 (예 : 전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="72f57dd0021b24f09da3fde633d42235df9baa52" translate="yes" xml:space="preserve">
          <source>Performs outlier detection on X.</source>
          <target state="translated">X에서 이상 값 탐지를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="c032681b9d32a5a7daa554f673be122edd3ede2b" translate="yes" xml:space="preserve">
          <source>Performs power transformation using the &lt;code&gt;Transformer&lt;/code&gt; API (as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API를 사용하여 (전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ) 전력 변환을 수행 합니다.</target>
        </trans-unit>
        <trans-unit id="9b0d235575d753630f72f479dd595fb051616b74" translate="yes" xml:space="preserve">
          <source>Performs quantile-based scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API를 사용하여 Quantile 기반 스케일링을 수행 합니다 (예 : 전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="b88ebf81bb1a4e07e575709aa3160fcbaf33439c" translate="yes" xml:space="preserve">
          <source>Performs robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">특이 치의 영향을 제거하지만 특이 치와 특이 치를 동일한 척도로 설정하지 않는 강력한 표준화를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="269796266e3e34d93d181d30bdc48e574f3c9af7" translate="yes" xml:space="preserve">
          <source>Performs scaling to a given range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">``Transformer ''API를 사용하여 지정된 범위로 스케일링을 수행합니다 (예 : 전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="bd68fa80cce73218da8c0d7af21a3e3a79fd9429" translate="yes" xml:space="preserve">
          <source>Performs scaling to the [-1, 1] range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">``Transformer ''API를 사용하여 [-1, 1] 범위로 스케일링을 수행합니다 (예 : 전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="a6c272533c048656769d2922baf310f99127bfa0" translate="yes" xml:space="preserve">
          <source>Performs scaling to unit variance using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">``Transformer ''API를 사용하여 단위 분산으로 스케일링을 수행합니다 (예 : 전처리 &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="ac7c14a68907c3e1c4fe02a23cc6348fd68ae158" translate="yes" xml:space="preserve">
          <source>Performs standardization that is faster, but less robust to outliers.</source>
          <target state="translated">더 빠르지 만 특이 치에 대해서는 덜 표준화 된 표준화를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="1607c75c65b63f50e007f7f133bc5dda8dc230b2" translate="yes" xml:space="preserve">
          <source>Performs the TF-IDF transformation from a provided matrix of counts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1ac21bb0cdcd78e01860cf682da905f50be135c" translate="yes" xml:space="preserve">
          <source>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</source>
          <target state="translated">데이터가 생성 된 실제 모델이 가정을 다소 위반하더라도 성능이 우수합니다.</target>
        </trans-unit>
        <trans-unit id="692363e79545ccc206eddd0f61af20f5fd6d3794" translate="yes" xml:space="preserve">
          <source>Permutation Importance vs Random Forest Feature Importance (MDI)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dbaba5e5cc669da918a57d2be9cb7dc2cc9dadb" translate="yes" xml:space="preserve">
          <source>Permutation Importance with Multicollinear or Correlated Features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a4bc8d95c0343a8677dd56e966704c1868adf4a" translate="yes" xml:space="preserve">
          <source>Permutation feature importance is a model inspection technique that can be used for any &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fitted&quot;&gt;fitted&lt;/a&gt;&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;estimator&lt;/a&gt; when the data is tabular. This is especially useful for non-linear or opaque &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;estimators&lt;/a&gt;. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fc1a156ae6d2a8be8ad1b31632c3738303816a9" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;#rd9e56ef97513-bre&quot; id=&quot;id1&quot;&gt;[BRE]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcae56d3241bbe2509401411f131fd455126611a" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#rd9e56ef97513-bre&quot; id=&quot;id2&quot;&gt;[Rd9e56ef97513-BRE]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0604878bcce5e380bc3c27303af860b5876e2620" translate="yes" xml:space="preserve">
          <source>Permutation importances can be computed either on the training set or on a held-out testing or validation set. Using a held-out set makes it possible to highlight which features contribute the most to the generalization power of the inspected model. Features that are important on the training set but not on the held-out set might cause the model to overfit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff7711423fb41bb0ca16132a11855fff8a63fa44" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importance</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2babb881bd9df0cbbe32387aebb8f1fc14de7576" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importances do not exhibit such a bias. Additionally, the permutation feature importance may be computed performance metric on the model predictions predictions and can be used to analyze any model class (not just tree-based models).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a9a31609b061b9c4c3ea5164d451f2cf664e34b" translate="yes" xml:space="preserve">
          <source>Perplexity is defined as exp(-1. * log-likelihood per word)</source>
          <target state="translated">당황은 exp (-1. * 단어 당 로그 우도)로 정의됩니다</target>
        </trans-unit>
        <trans-unit id="80863d8aea17a1c5fba5bee33e10fcfe3c3b5254" translate="yes" xml:space="preserve">
          <source>Perplexity score.</source>
          <target state="translated">당황 점수.</target>
        </trans-unit>
        <trans-unit id="25e7450397b385690390d4cb490d54af7bb7f613" translate="yes" xml:space="preserve">
          <source>Perplexity tolerance in batch learning. Only used when &lt;code&gt;evaluate_every&lt;/code&gt; is greater than 0.</source>
          <target state="translated">배치 학습의 당혹감. &lt;code&gt;evaluate_every&lt;/code&gt; 가 0보다 큰 경우에만 사용됩니다 .</target>
        </trans-unit>
        <trans-unit id="bed69aed128c6d53c076bf23b1786ba34af67dfd" translate="yes" xml:space="preserve">
          <source>Persistent Contrastive Divergence addresses this. Instead of starting a new chain each time the gradient is needed, and performing only one Gibbs sampling step, in PCD we keep a number of chains (fantasy particles) that are updated \(k\) Gibbs steps after each weight update. This allows the particles to explore the space more thoroughly.</source>
          <target state="translated">지속적인 대조적 발산이이를 해결합니다. 그래디언트가 필요할 때마다 새 체인을 시작하고 하나의 Gibbs 샘플링 단계 만 수행하는 대신 PCD에서 각 가중치 업데이트 후 \ (k \) Gibbs 단계로 업데이트되는 여러 체인 (판타지 입자)을 유지합니다. 이를 통해 파티클이 공간을보다 철저하게 탐색 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d4d9d12e88278335e6c824e88af73f55a763004e" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J. Huber, Elvezio M. Ronchetti, 강력한 통계 동시 스케일 추정, pg 172</target>
        </trans-unit>
        <trans-unit id="977cdb0f1102753846469a4e3ab78497c359fae5" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J. Huber, Elvezio M. Ronchetti : 강력한 통계, 동시 규모 추정, pg 172</target>
        </trans-unit>
        <trans-unit id="f869e193262fa2d8e1a9ddde0485aa49aaa656aa" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi:10.1016/0377-0427(87)90125-7&lt;/a&gt;.</source>
          <target state="translated">Peter J. Rousseeuw (1987). &amp;ldquo;실루엣 : 클러스터 분석의 해석 및 검증을위한 그래픽 지원&amp;rdquo;. 전산 및 응용 수학 20 : 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi : 10.1016 / 0377-0427 (87) 90125-7&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="801ff1e5ba061302f2ef13b831a12ef30f616d52" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53-65.</source>
          <target state="translated">Peter J. Rousseeuw (1987). &amp;ldquo;실루엣 : 클러스터 분석의 해석 및 검증을위한 그래픽 지원&amp;rdquo;. 전산 및 응용 수학 20 : 53-65.</target>
        </trans-unit>
        <trans-unit id="6884db0930152b7581421b9e7df37cdc709bc0ae" translate="yes" xml:space="preserve">
          <source>Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.</source>
          <target state="translated">나무를 피클하고 피클 링하십시오. 트리의 상태는 피클 작업에 저장됩니다. 피클 링 해제시 트리를 재 구축 할 필요가 없습니다.</target>
        </trans-unit>
        <trans-unit id="4a6d28315bc21af0edd71a7862fc9db5f7a4917f" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">Ping Li, T. Hastie 및 KW Church, 2006,&amp;ldquo;매우 드물게 임의의 투영&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fb3d4adf8ec429eb640cc1eefb0227abf08a6683" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3462e562173cab76115a1fabd23d03498a615dda" translate="yes" xml:space="preserve">
          <source>Ping Li, Trevor J. Hastie, and Kenneth W. Church. 2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;Very sparse random projections.&lt;/a&gt; In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD &amp;lsquo;06). ACM, New York, NY, USA, 287-296.</source>
          <target state="translated">Ping Li, Trevor J. Hastie 및 Kenneth W. Church. 2006 &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;매우 스파 스 무작위 전망. &lt;/a&gt;지식 발견 및 데이터 마이닝에 관한 제 12 회 ACM SIGKDD 국제 컨퍼런스 (KDD '06)의 진행. ACM, 뉴욕, 뉴욕, 미국, 287-296.</target>
        </trans-unit>
        <trans-unit id="32b1d5a78493496dd5152fd2d504f7e21009e3f2" translate="yes" xml:space="preserve">
          <source>Pipeline</source>
          <target state="translated">Pipeline</target>
        </trans-unit>
        <trans-unit id="5fcec2c4630ab50971732249756f691f50ae9f29" translate="yes" xml:space="preserve">
          <source>Pipeline Anova SVM</source>
          <target state="translated">파이프 라인 Anova SVM</target>
        </trans-unit>
        <trans-unit id="a041187d94eb589a1ba5ff98293ef896e00c97e7" translate="yes" xml:space="preserve">
          <source>Pipeline of transforms with a final estimator.</source>
          <target state="translated">최종 추정기로 변환 파이프 라인.</target>
        </trans-unit>
        <trans-unit id="b728ae3e883ea99a9d120fc06880b19e80fef86a" translate="yes" xml:space="preserve">
          <source>Pipeline&amp;rsquo;s &lt;code&gt;named_steps&lt;/code&gt; attribute allows accessing steps by name with tab completion in interactive environments:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73de4ddfaf9a511a59191faaa0679d43b9d9c3eb" translate="yes" xml:space="preserve">
          <source>Pipelines and composite estimators</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52761af283a0d9e614a4e2ba9d4a353d3fd70a7b" translate="yes" xml:space="preserve">
          <source>Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.</source>
          <target state="translated">파이프 라인은 동일한 샘플을 사용하여 변환기와 예측 변수를 학습하도록하여 교차 검증에서 테스트 데이터에서 훈련 된 모델로 통계가 유출되는 것을 방지합니다.</target>
        </trans-unit>
        <trans-unit id="3d31223cfe1830200469a76812f595efba107474" translate="yes" xml:space="preserve">
          <source>Pipelining</source>
          <target state="translated">Pipelining</target>
        </trans-unit>
        <trans-unit id="04ae27026f61a0e2fe9396849cac7271f4f56e69" translate="yes" xml:space="preserve">
          <source>Pipelining: chaining a PCA and a logistic regression</source>
          <target state="translated">파이프 라이닝 : PCA와 로지스틱 회귀 연결</target>
        </trans-unit>
        <trans-unit id="4d2bb7a399ca2f416aedb250a1c02b6dbddd98f5" translate="yes" xml:space="preserve">
          <source>Pixel importances with a parallel forest of trees</source>
          <target state="translated">병렬 숲의 나무와 픽셀의 중요성</target>
        </trans-unit>
        <trans-unit id="2ca4493c014c6673344a97eb7b5e5aaa17897b68" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;SVM에 대한 확률 적 결과 및 정규화 된 가능성 방법과의 비교&amp;rdquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="94b48515f27c2ba66dc001876eed954b37962189" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cd3fc864a17260622e839224271f277841ca1af" translate="yes" xml:space="preserve">
          <source>Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70c63a8d9604c9bbaac5b8d8c1c0f788b01f994f" translate="yes" xml:space="preserve">
          <source>Platt, John (1999). &amp;ldquo;Probabilistic outputs for support vector machines and comparison to regularizedlikelihood methods.&amp;rdquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0765f4dfcff27a39498ebd734357c5eb178852a5" translate="yes" xml:space="preserve">
          <source>Please note that in this example the data is non-noisy, hence it is possible to extract the exact coefficients.</source>
          <target state="translated">이 예에서 데이터는 노이즈가 없으므로 정확한 계수를 추출 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d5ef05af023849c89b4ecfb2ae2cb84ee4a80076" translate="yes" xml:space="preserve">
          <source>Please note that scikit-learn has no direct control over these implementations. Scikit-learn solely relies on Numpy and Scipy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60f5c599778dc38cb8638a819c878af82379b06d" translate="yes" xml:space="preserve">
          <source>Please note that the dataset here is not large enough to show the benefits of kernel approximation, as the exact SVM is still reasonably fast.</source>
          <target state="translated">정확한 SVM이 여전히 상당히 빠르기 때문에 여기의 데이터 세트는 커널 근사치의 이점을 보여줄만큼 충분히 크지 않습니다.</target>
        </trans-unit>
        <trans-unit id="bd47c9cedab12c75fd43c458d1842b3e68fe1e8f" translate="yes" xml:space="preserve">
          <source>Please note that when &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; and &lt;code&gt;n_classes &amp;gt; 2&lt;/code&gt;, unlike &lt;code&gt;decision_function&lt;/code&gt;, the &lt;code&gt;predict&lt;/code&gt; method does not try to break ties by default. You can set &lt;code&gt;break_ties=True&lt;/code&gt; for the output of &lt;code&gt;predict&lt;/code&gt; to be the same as &lt;code&gt;np.argmax(clf.decision_function(...), axis=1)&lt;/code&gt;, otherwise the first class among the tied classes will always be returned; but have in mind that it comes with a computational cost. See &lt;a href=&quot;../auto_examples/svm/plot_svm_tie_breaking#sphx-glr-auto-examples-svm-plot-svm-tie-breaking-py&quot;&gt;SVM Tie Breaking Example&lt;/a&gt; for an example on tie breaking.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
