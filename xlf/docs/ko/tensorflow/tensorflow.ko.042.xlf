<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="af423eb943d44142b4ba2df380bb45f9370ab357" translate="yes" xml:space="preserve">
          <source>This is useful to eliminate per-test boilerplate when context managers are used. For example, instead of decorating every test with &lt;code&gt;@mock.patch&lt;/code&gt;, simply do &lt;code&gt;self.foo = self.enter_context(mock.patch(...))' in&lt;/code&gt;setUp()`.</source>
          <target state="translated">컨텍스트 관리자를 사용할 때 테스트 별 상용구를 제거하는 데 유용합니다. 예를 들어, 대신에 모든 테스트를 장식의 &lt;code&gt;@mock.patch&lt;/code&gt; , 단순히 수행 &lt;code&gt;self.foo = self.enter_context(mock.patch(...))' in&lt;/code&gt; `) (설정.</target>
        </trans-unit>
        <trans-unit id="2f67d0f15d4bd847d95e4812f46c68a7b2ce669c" translate="yes" xml:space="preserve">
          <source>This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs.</source>
          <target state="translated">이는 과적 합을 완화하는 데 유용합니다 (임의의 데이터 증가 형태로 볼 수 있음). 가우시안 잡음 (GS)은 실제 가치있는 입력에 대한 손상 프로세스로 자연스럽게 선택됩니다.</target>
        </trans-unit>
        <trans-unit id="0a10808c724fd5007563891cae49997723f67e26" translate="yes" xml:space="preserve">
          <source>This is useful when starting a dedicated dispatch process.</source>
          <target state="translated">This is useful when starting a dedicated dispatch process.</target>
        </trans-unit>
        <trans-unit id="16e0781bd49ec3a98f90bdf48daf84789ac4527c" translate="yes" xml:space="preserve">
          <source>This is useful when starting a dedicated worker process.</source>
          <target state="translated">This is useful when starting a dedicated worker process.</target>
        </trans-unit>
        <trans-unit id="d38a2f7346a2a0766d59c6174961d13ece4817fb" translate="yes" xml:space="preserve">
          <source>This is useful when validating the result of a broadcasting operation when the tensors do not have statically known shapes.</source>
          <target state="translated">이것은 텐서가 정적으로 알려진 모양을 가지고 있지 않을 때 방송 작업의 결과를 검증 할 때 유용합니다.</target>
        </trans-unit>
        <trans-unit id="50937613d6e3934b243fbeba16769c301a7b4618" translate="yes" xml:space="preserve">
          <source>This is useful when validating the result of a broadcasting operation when the tensors have statically known shapes.</source>
          <target state="translated">이것은 텐서가 정적으로 알려진 모양을 가질 때 방송 작업의 결과를 검증 할 때 유용합니다.</target>
        </trans-unit>
        <trans-unit id="d56f48520fc92b32fe411b251279af631392c0d0" translate="yes" xml:space="preserve">
          <source>This is useful when you need to extract a subset of slices in an &lt;code&gt;IndexedSlices&lt;/code&gt; object.</source>
          <target state="translated">&lt;code&gt;IndexedSlices&lt;/code&gt; 에서 슬라이스 하위 집합을 추출해야 할 때 유용합니다 객체 합니다.</target>
        </trans-unit>
        <trans-unit id="7324163610c415fe69e9edf14d1514614e0096c2" translate="yes" xml:space="preserve">
          <source>This is where the layer's logic lives.</source>
          <target state="translated">이것이 계층의 논리가있는 곳입니다.</target>
        </trans-unit>
        <trans-unit id="51b266b637bd972731e9b8ded931808387760c03" translate="yes" xml:space="preserve">
          <source>This iterator-constructing method can be used to create an iterator that is reusable with many different datasets.</source>
          <target state="translated">이 반복자 구성 방법을 사용하면 다양한 데이터 집합에서 재사용 할 수있는 반복자를 만들 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="e4b84ee23970a9ba1fae231b7f3281c7ddfd3c7d" translate="yes" xml:space="preserve">
          <source>This kernel op implements the following mathematical equations:</source>
          <target state="translated">This kernel op implements the following mathematical equations:</target>
        </trans-unit>
        <trans-unit id="6651501cdbb63552c7881c732a891c9b596e4cd4" translate="yes" xml:space="preserve">
          <source>This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor.</source>
          <target state="translated">이 레이어는 이미지 텐서의 위쪽, 아래쪽, 왼쪽 및 오른쪽에 0의 행과 열을 추가 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c8f7de7a90e40a1acb832cfeb3e997b1fdd42909" translate="yes" xml:space="preserve">
          <source>This layer can be called multiple times with different features.</source>
          <target state="translated">이 레이어는 다른 기능으로 여러 번 호출 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b23ebdf3426b29c2bb4017b933209c527b0b2eaf" translate="yes" xml:space="preserve">
          <source>This layer can only be used as the first layer in a model.</source>
          <target state="translated">이 레이어는 모델의 첫 번째 레이어로만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="8d2bf436fb7b0b2292ba74c82ed9e0b6359c6446" translate="yes" xml:space="preserve">
          <source>This layer can perform einsum calculations of arbitrary dimensionality.</source>
          <target state="translated">This layer can perform einsum calculations of arbitrary dimensionality.</target>
        </trans-unit>
        <trans-unit id="28df12740051102a73475796ca5f477471a88b56" translate="yes" xml:space="preserve">
          <source>This layer concatenates multiple categorical inputs into a single categorical output (similar to Cartesian product). The output dtype is string.</source>
          <target state="translated">This layer concatenates multiple categorical inputs into a single categorical output (similar to Cartesian product). The output dtype is string.</target>
        </trans-unit>
        <trans-unit id="fbd759fae81bda98338ee6eb24eac5b449a08594" translate="yes" xml:space="preserve">
          <source>This layer creates a convolution kernel that is convolved (actually cross-correlated) with the layer input to produce a tensor of outputs. If &lt;code&gt;use_bias&lt;/code&gt; is True (and a &lt;code&gt;bias_initializer&lt;/code&gt; is provided), a bias vector is created and added to the outputs. Finally, if &lt;code&gt;activation&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, it is applied to the outputs as well.</source>
          <target state="translated">이 레이어는 출력 텐서를 생성하기 위해 레이어 입력과 관련되어 (실제로 상호 상관 된) 컨볼 루션 커널을 만듭니다. &lt;code&gt;use_bias&lt;/code&gt; 가 True 이면 ( &lt;code&gt;bias_initializer&lt;/code&gt; 가 제공됨) 바이어스 벡터가 생성되어 출력에 추가됩니다. 마지막으로 &lt;code&gt;activation&lt;/code&gt; 가 &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 출력에도 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="a9977284bd794456f41f5d8f8d36aed1d3801d36" translate="yes" xml:space="preserve">
          <source>This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If &lt;code&gt;use_bias&lt;/code&gt; is True, a bias vector is created and added to the outputs. Finally, if &lt;code&gt;activation&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, it is applied to the outputs as well.</source>
          <target state="translated">이 레이어는 단일 공간 (또는 시간) 차원에 걸쳐 레이어 입력과 함께 컨벌루션 커널을 생성하여 출력 텐서를 생성합니다. 경우 &lt;code&gt;use_bias&lt;/code&gt; 가 True 인 바이어스 벡터 생성 및 출력에 추가된다. 마지막으로 &lt;code&gt;activation&lt;/code&gt; 가 &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 출력에도 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="d01bf01ba17a42cbf8ad8412a4cd7bfe52f00c78" translate="yes" xml:space="preserve">
          <source>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If &lt;code&gt;use_bias&lt;/code&gt; is True, a bias vector is created and added to the outputs. Finally, if &lt;code&gt;activation&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, it is applied to the outputs as well.</source>
          <target state="translated">이 레이어는 출력 텐서를 생성하기 위해 레이어 입력과 관련된 컨볼 루션 커널을 만듭니다. 경우 &lt;code&gt;use_bias&lt;/code&gt; 가 True 인 바이어스 벡터 생성 및 출력에 추가된다. 마지막으로 &lt;code&gt;activation&lt;/code&gt; 가 &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 출력에도 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="884d29443e655c08f257cc412193f76628fd846b" translate="yes" xml:space="preserve">
          <source>This layer has basic options for managing text in a Keras model. It transforms a batch of strings (one sample = one string) into either a list of token indices (one sample = 1D tensor of integer token indices) or a dense representation (one sample = 1D tensor of float values representing data about the sample's tokens).</source>
          <target state="translated">이 레이어에는 Keras 모델에서 텍스트를 관리하기위한 기본 옵션이 있습니다. 일련의 문자열 (하나의 샘플 = 하나의 문자열)을 토큰 인덱스 목록 (하나의 샘플 = 정수 토큰 인덱스의 1D 텐서) 또는 조밀 한 표현 (하나의 샘플 = 샘플의 토큰에 대한 데이터를 나타내는 부동 소수점 값의 1D 텐서)으로 변환합니다. ).</target>
        </trans-unit>
        <trans-unit id="0b7b099051eae116bfa4a2ca036f64c30b769c6d" translate="yes" xml:space="preserve">
          <source>This layer implements a mapping from input space to a space with &lt;code&gt;output_dim&lt;/code&gt; dimensions, which approximates shift-invariant kernels. A kernel function &lt;code&gt;K(x, y)&lt;/code&gt; is shift-invariant if &lt;code&gt;K(x, y) == k(x - y)&lt;/code&gt; for some function &lt;code&gt;k&lt;/code&gt;. Many popular Radial Basis Functions (RBF), including Gaussian and Laplacian kernels, are shift-invariant.</source>
          <target state="translated">This layer implements a mapping from input space to a space with &lt;code&gt;output_dim&lt;/code&gt; dimensions, which approximates shift-invariant kernels. A kernel function &lt;code&gt;K(x, y)&lt;/code&gt; is shift-invariant if &lt;code&gt;K(x, y) == k(x - y)&lt;/code&gt; for some function &lt;code&gt;k&lt;/code&gt; . Many popular Radial Basis Functions (RBF), including Gaussian and Laplacian kernels, are shift-invariant.</target>
        </trans-unit>
        <trans-unit id="bca79ddc4abf3d361de2fa2d5bdf3c1e02faac7e" translate="yes" xml:space="preserve">
          <source>This layer implements the operation: &lt;code&gt;outputs = activation(inputs * kernel + bias)&lt;/code&gt; Where &lt;code&gt;activation&lt;/code&gt; is the activation function passed as the &lt;code&gt;activation&lt;/code&gt; argument (if not &lt;code&gt;None&lt;/code&gt;), &lt;code&gt;kernel&lt;/code&gt; is a weights matrix created by the layer, and &lt;code&gt;bias&lt;/code&gt; is a bias vector created by the layer (only if &lt;code&gt;use_bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;).</source>
          <target state="translated">이 레이어는 다음과 같은 연산을 구현합니다. &lt;code&gt;outputs = activation(inputs * kernel + bias)&lt;/code&gt; 여기서 &lt;code&gt;activation&lt;/code&gt; 은 &lt;code&gt;activation&lt;/code&gt; 인수 로 전달 된 활성화 함수 ( &lt;code&gt;None&lt;/code&gt; 이 아닌 경우 )이고, &lt;code&gt;kernel&lt;/code&gt; 은 레이어에 의해 생성 된 가중치 행렬이며, &lt;code&gt;bias&lt;/code&gt; 는 생성 된 바이어스 벡터입니다. 레이어에 의해 ( &lt;code&gt;use_bias&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 인 경우에만 ).</target>
        </trans-unit>
        <trans-unit id="35e71e883bb0be18fa94fd4d0a457376805923f0" translate="yes" xml:space="preserve">
          <source>This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels. If &lt;code&gt;use_bias&lt;/code&gt; is True and a bias initializer is provided, it adds a bias vector to the output. It then optionally applies an activation function to produce the final output.</source>
          <target state="translated">이 레이어는 채널에서 개별적으로 작동하는 깊이 컨벌루션을 수행 한 다음 채널을 혼합하는 포인트 컨벌루션을 수행합니다. &lt;code&gt;use_bias&lt;/code&gt; 인 경우 참이고 바이어스 초기화가 제공되고, 상기 출력에 대한 바이어스 벡터를 추가한다. 그런 다음 선택적으로 활성화 기능을 적용하여 최종 출력을 생성합니다.</target>
        </trans-unit>
        <trans-unit id="886b50c9aa90bb61796488bc8efaa41bf9f78825" translate="yes" xml:space="preserve">
          <source>This layer provides options for condensing data into a categorical encoding. It accepts integer values as inputs and outputs a dense representation (one sample = 1-index tensor of float values representing data about the sample's tokens) of those inputs.</source>
          <target state="translated">This layer provides options for condensing data into a categorical encoding. It accepts integer values as inputs and outputs a dense representation (one sample = 1-index tensor of float values representing data about the sample's tokens) of those inputs.</target>
        </trans-unit>
        <trans-unit id="47be8fc04afe99661c4ed5ab6b6d7ef9885d2eff" translate="yes" xml:space="preserve">
          <source>This layer provides options for condensing input data into denser representations. It accepts either integer values or strings as inputs, allows users to map those inputs into a contiguous integer space, and outputs either those integer values (one sample = 1D tensor of integer token indices) or a dense representation (one sample = 1D tensor of float values representing data about the sample's tokens).</source>
          <target state="translated">This layer provides options for condensing input data into denser representations. It accepts either integer values or strings as inputs, allows users to map those inputs into a contiguous integer space, and outputs either those integer values (one sample = 1D tensor of integer token indices) or a dense representation (one sample = 1D tensor of float values representing data about the sample's tokens).</target>
        </trans-unit>
        <trans-unit id="344f6b570b33a446c2eb6dc9ce40efd08ad87ee8" translate="yes" xml:space="preserve">
          <source>This layer supports masking for input data with a variable number of timesteps. To introduce masks to your data, use an [tf.keras.layers.Embedding] layer with the &lt;code&gt;mask_zero&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">이 계층은 다양한 시간 간격으로 입력 데이터에 대한 마스킹을 지원합니다. 데이터에 마스크를 도입하려면 &lt;code&gt;mask_zero&lt;/code&gt; 매개 변수가 &lt;code&gt;True&lt;/code&gt; 로 설정된 [tf.keras.layers.Embedding] 레이어를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="f1e7b36e17487480357995623584b1cdfb115de4" translate="yes" xml:space="preserve">
          <source>This layer transforms single or multiple categorical inputs to hashed output. It converts a sequence of int or string to a sequence of int. The stable hash function uses tensorflow::ops::Fingerprint to produce universal output that is consistent across platforms.</source>
          <target state="translated">This layer transforms single or multiple categorical inputs to hashed output. It converts a sequence of int or string to a sequence of int. The stable hash function uses tensorflow::ops::Fingerprint to produce universal output that is consistent across platforms.</target>
        </trans-unit>
        <trans-unit id="d1b7379fe2dc54f750afe7d401d80af36bad9408" translate="yes" xml:space="preserve">
          <source>This layer translates a set of arbitrary integers into an integer output via a table-based lookup, with optional out-of-vocabulary handling.</source>
          <target state="translated">This layer translates a set of arbitrary integers into an integer output via a table-based lookup, with optional out-of-vocabulary handling.</target>
        </trans-unit>
        <trans-unit id="bbcf3f69a06cbdc5f32560a16983b32541e31aaf" translate="yes" xml:space="preserve">
          <source>This layer translates a set of arbitrary strings into an integer output via a table-based lookup, with optional out-of-vocabulary handling.</source>
          <target state="translated">This layer translates a set of arbitrary strings into an integer output via a table-based lookup, with optional out-of-vocabulary handling.</target>
        </trans-unit>
        <trans-unit id="f87526b4a527a8b2c085b4914d68a929b0016554" translate="yes" xml:space="preserve">
          <source>This layer uses &lt;a href=&quot;https://github.com/google/farmhash&quot;&gt;FarmHash64&lt;/a&gt; by default, which provides a consistent hashed output across different platforms and is stable across invocations, regardless of device and context, by mixing the input bits thoroughly.</source>
          <target state="translated">This layer uses &lt;a href=&quot;https://github.com/google/farmhash&quot;&gt;FarmHash64&lt;/a&gt; by default, which provides a consistent hashed output across different platforms and is stable across invocations, regardless of device and context, by mixing the input bits thoroughly.</target>
        </trans-unit>
        <trans-unit id="951c6b01ab8359114ccb88b8a93d70dd8a953954" translate="yes" xml:space="preserve">
          <source>This layer will coerce its inputs into a distribution centered around 0 with standard deviation 1. It accomplishes this by precomputing the mean and variance of the data, and calling (input-mean)/sqrt(var) at runtime.</source>
          <target state="translated">This layer will coerce its inputs into a distribution centered around 0 with standard deviation 1. It accomplishes this by precomputing the mean and variance of the data, and calling (input-mean)/sqrt(var) at runtime.</target>
        </trans-unit>
        <trans-unit id="fe1b0f3431a8ec7d138b525163f2ad9cf543ffa7" translate="yes" xml:space="preserve">
          <source>This layer will coerce its inputs into a normal distribution centered around 0 with standard deviation 1. It accomplishes this by precomputing the mean and variance of the data, and calling (input-mean)/sqrt(var) at runtime.</source>
          <target state="translated">이 계층은 표준 편차 1을 사용하여 0을 중심으로하는 정규 분포로 입력을 강제합니다. 데이터의 평균과 분산을 사전 계산하고 런타임에 (입력-평균) / sqrt (var)를 호출하여이를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="bf78e85c045cf32b4df68b19ac70fe5f256ed641" translate="yes" xml:space="preserve">
          <source>This layer will crop all the images in the same batch to the same cropping location. By default, random cropping is only applied during training. At inference time, the images will be first rescaled to preserve the shorter side, and center cropped. If you need to apply random cropping at inference time, set &lt;code&gt;training&lt;/code&gt; to True when calling the layer.</source>
          <target state="translated">This layer will crop all the images in the same batch to the same cropping location. By default, random cropping is only applied during training. At inference time, the images will be first rescaled to preserve the shorter side, and center cropped. If you need to apply random cropping at inference time, set &lt;code&gt;training&lt;/code&gt; to True when calling the layer.</target>
        </trans-unit>
        <trans-unit id="bc9e9462205fcd047a049604a7917fbea53a1a7d" translate="yes" xml:space="preserve">
          <source>This layer will flip the images based on the &lt;code&gt;mode&lt;/code&gt; attribute. During inference time, the output will be identical to input. Call the layer with &lt;code&gt;training=True&lt;/code&gt; to flip the input.</source>
          <target state="translated">This layer will flip the images based on the &lt;code&gt;mode&lt;/code&gt; attribute. During inference time, the output will be identical to input. Call the layer with &lt;code&gt;training=True&lt;/code&gt; to flip the input.</target>
        </trans-unit>
        <trans-unit id="a3d352f01824e505c14a980e99a24ac05a3a55ba" translate="yes" xml:space="preserve">
          <source>This layer will place each element of its input data into one of several contiguous ranges and output an integer index indicating which range each element was placed in.</source>
          <target state="translated">This layer will place each element of its input data into one of several contiguous ranges and output an integer index indicating which range each element was placed in.</target>
        </trans-unit>
        <trans-unit id="fbf50d844249a2e7240d57251d949994666050a2" translate="yes" xml:space="preserve">
          <source>This library contains all implementations of ClusterResolvers. ClusterResolvers are a way of specifying cluster information for distributed execution. Built on top of existing &lt;code&gt;ClusterSpec&lt;/code&gt; framework, ClusterResolvers are a way for TensorFlow to communicate with various cluster management systems (e.g. GCE, AWS, etc...).</source>
          <target state="translated">이 라이브러리에는 모든 ClusterResolvers 구현이 포함되어 있습니다. ClusterResolvers는 분산 실행을 위해 클러스터 정보를 지정하는 방법입니다. 기존 &lt;code&gt;ClusterSpec&lt;/code&gt; 을 기반으로 구축 프레임 워크 ClusterResolvers는 TensorFlow가 다양한 클러스터 관리 시스템 (예 : GCE, AWS 등)과 통신 할 수있는 방법입니다.</target>
        </trans-unit>
        <trans-unit id="b6b2d72a41e6a38bd121d03e086a0c141b5bab2a" translate="yes" xml:space="preserve">
          <source>This makes the TensorFlow Lite interpreter accessible in Python. It is possible to use this interpreter in a multithreaded Python environment, but you must be sure to call functions of a particular instance from only one thread at a time. So if you want to have 4 threads running different inferences simultaneously, create an interpreter for each one as thread-local data. Similarly, if you are calling invoke() in one thread on a single interpreter but you want to use tensor() on another thread once it is done, you must use a synchronization primitive between the threads to ensure invoke has returned before calling tensor().</source>
          <target state="translated">이를 통해 Python에서 TensorFlow Lite 인터프리터에 액세스 할 수 있습니다. 다중 스레드 Python 환경에서이 인터프리터를 사용할 수 있지만 한 번에 하나의 스레드에서만 특정 인스턴스의 함수를 호출해야합니다. 따라서 서로 다른 추론을 동시에 실행하는 4 개의 스레드를 가지려면 각 스레드에 대한 인터프리터를 스레드 로컬 데이터로 작성하십시오. 마찬가지로 단일 인터프리터의 한 스레드에서 invoke ()를 호출하고 있지만 일단 다른 스레드에서 tensor ()를 사용하려면 스레드 사이에 동기화 프리미티브를 사용하여 tensor ( ).</target>
        </trans-unit>
        <trans-unit id="6846fc96931fb6bb57a7f6152c9caf47e33ab2da" translate="yes" xml:space="preserve">
          <source>This makes the summary tag more predictable and consistent for the user.</source>
          <target state="translated">이것은 사용자에게 요약 태그를보다 예측 가능하고 일관성있게 만듭니다.</target>
        </trans-unit>
        <trans-unit id="ac535677c50e98c6e0ce0364a9b0ce341c3f0a28" translate="yes" xml:space="preserve">
          <source>This matches the behavior of If and While for determining if a tensor counts as true/false for a branch condition.</source>
          <target state="translated">This matches the behavior of If and While for determining if a tensor counts as true/false for a branch condition.</target>
        </trans-unit>
        <trans-unit id="99fc0b3a4e959624cfdd7190647db3380c4e327c" translate="yes" xml:space="preserve">
          <source>This may be useful for checking HTML output.</source>
          <target state="translated">HTML 출력을 확인하는 데 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="381d4e4134c335f7e7e4d713df90044462182059" translate="yes" xml:space="preserve">
          <source>This may occur, for example, if an operation receives an input tensor that has an invalid value or shape. For example, the &lt;a href=&quot;../linalg/matmul&quot;&gt;&lt;code&gt;tf.matmul&lt;/code&gt;&lt;/a&gt; op will raise this error if it receives an input that is not a matrix, and the &lt;a href=&quot;../reshape&quot;&gt;&lt;code&gt;tf.reshape&lt;/code&gt;&lt;/a&gt; op will raise this error if the new shape does not match the number of elements in the input tensor.</source>
          <target state="translated">예를 들어, 조작이 유효하지 않은 값 또는 모양의 입력 텐서를 수신하는 경우에 발생할 수 있습니다. 예를 들어, &lt;a href=&quot;../linalg/matmul&quot;&gt; &lt;code&gt;tf.matmul&lt;/code&gt; &lt;/a&gt; op는 행렬이 아닌 입력을 수신하면 이 오류를 발생시키고, 새로운 모양이 입력 텐서의 요소 수와 일치하지 않으면 &lt;a href=&quot;../reshape&quot;&gt; &lt;code&gt;tf.reshape&lt;/code&gt; &lt;/a&gt; op가이 오류를 발생시킵니다.</target>
        </trans-unit>
        <trans-unit id="5c451c9f3d5af265bc5daacf860461f46903194b" translate="yes" xml:space="preserve">
          <source>This may only be used inside &lt;code&gt;self.scope()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self.scope()&lt;/code&gt; 내부에서만 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="8407349f1434fe18f1d4f684e5cf94ad12755be8" translate="yes" xml:space="preserve">
          <source>This means that the result of matrix multiplication &lt;code&gt;v = Au&lt;/code&gt; has &lt;code&gt;Lth&lt;/code&gt; column given circular convolution between &lt;code&gt;h&lt;/code&gt; with the &lt;code&gt;Lth&lt;/code&gt; column of &lt;code&gt;u&lt;/code&gt;.</source>
          <target state="translated">행렬 곱셈 결과한다는 수단이 &lt;code&gt;v = Au&lt;/code&gt; 갖는 &lt;code&gt;Lth&lt;/code&gt; 열 사이 순환 컨벌루션 주어진 &lt;code&gt;h&lt;/code&gt; 과 &lt;code&gt;Lth&lt;/code&gt; 의 열의 &lt;code&gt;u&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="54a591701bef9e5baac7a364b34d92ce1a314391" translate="yes" xml:space="preserve">
          <source>This means the layout when converted and saved as an image is rotated 90 degrees clockwise from a typical spectrogram. Time is descending down the Y axis, and the frequency decreases from left to right.</source>
          <target state="translated">This means the layout when converted and saved as an image is rotated 90 degrees clockwise from a typical spectrogram. Time is descending down the Y axis, and the frequency decreases from left to right.</target>
        </trans-unit>
        <trans-unit id="7bac1b11600b86163afb8ed50f9d2fd7c08c803e" translate="yes" xml:space="preserve">
          <source>This method allows you to define a &quot;feedable&quot; iterator where you can choose between concrete iterators by feeding a value in a &lt;code&gt;tf.Session.run&lt;/code&gt; call. In that case, &lt;code&gt;string_handle&lt;/code&gt; would be a &lt;a href=&quot;../placeholder&quot;&gt;&lt;code&gt;tf.compat.v1.placeholder&lt;/code&gt;&lt;/a&gt;, and you would feed it with the value of &lt;code&gt;tf.data.Iterator.string_handle&lt;/code&gt; in each step.</source>
          <target state="translated">이 메소드를 사용하면 &lt;code&gt;tf.Session.run&lt;/code&gt; 호출 에서 값을 제공하여 콘크리트 반복자 중에서 선택할 수있는 &quot;공급 가능&quot;반복자를 정의 할 수 있습니다 . 이 경우, &lt;code&gt;string_handle&lt;/code&gt; 는 것 &lt;a href=&quot;../placeholder&quot;&gt; &lt;code&gt;tf.compat.v1.placeholder&lt;/code&gt; &lt;/a&gt; , 당신은의 값으로 공급 것 &lt;code&gt;tf.data.Iterator.string_handle&lt;/code&gt; 각 단계에있다.</target>
        </trans-unit>
        <trans-unit id="3ed29b40d37b37daebb7172d60a5cb7452fb1937" translate="yes" xml:space="preserve">
          <source>This method also allows multi-arity &lt;code&gt;elems&lt;/code&gt; and accumulator. If &lt;code&gt;elems&lt;/code&gt; is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The second argument of &lt;code&gt;fn&lt;/code&gt; must match the structure of &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="translated">이 방법은 또한 다중 &lt;code&gt;elems&lt;/code&gt; 와 누산기를 허용합니다. 경우 &lt;code&gt;elems&lt;/code&gt; 은 텐서의 (아마도 중첩) 목록 또는 튜플이며, 이들 텐서의 각이 일치하는 첫 번째 (압축 풀기) 차원이 있어야합니다. &lt;code&gt;fn&lt;/code&gt; 의 두 번째 인수 는 &lt;code&gt;elems&lt;/code&gt; 의 구조와 일치해야합니다 .</target>
        </trans-unit>
        <trans-unit id="11d1041ad958b2d24d55eb0ab2e6d83f39085f6b" translate="yes" xml:space="preserve">
          <source>This method also allows multi-arity &lt;code&gt;elems&lt;/code&gt; and output of &lt;code&gt;fn&lt;/code&gt;. If &lt;code&gt;elems&lt;/code&gt; is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The signature of &lt;code&gt;fn&lt;/code&gt; may match the structure of &lt;code&gt;elems&lt;/code&gt;. That is, if &lt;code&gt;elems&lt;/code&gt; is &lt;code&gt;(t1, [t2, t3, [t4, t5]])&lt;/code&gt;, then an appropriate signature for &lt;code&gt;fn&lt;/code&gt; is: &lt;code&gt;fn = lambda (t1, [t2, t3, [t4, t5]]):&lt;/code&gt;.</source>
          <target state="translated">이 방법을 사용하면 다중 &lt;code&gt;elems&lt;/code&gt; 와 &lt;code&gt;fn&lt;/code&gt; 출력 도 허용 됩니다. 경우 &lt;code&gt;elems&lt;/code&gt; 은 텐서의 (아마도 중첩) 목록 또는 튜플이며, 이들 텐서의 각이 일치하는 첫 번째 (압축 풀기) 차원이 있어야합니다. &lt;code&gt;fn&lt;/code&gt; 의 서명은 &lt;code&gt;elems&lt;/code&gt; 의 구조와 일치 할 수 있습니다 . 즉, &lt;code&gt;elems&lt;/code&gt; 가 &lt;code&gt;(t1, [t2, t3, [t4, t5]])&lt;/code&gt; 인 경우 &lt;code&gt;fn&lt;/code&gt; 에 대한 적절한 서명 은 다음과 같습니다. &lt;code&gt;fn = lambda (t1, [t2, t3, [t4, t5]]):&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="766a4862e3d658751f25e8ca0813b9af0856b88d" translate="yes" xml:space="preserve">
          <source>This method behaves differently than self.session(): for performance reasons &lt;code&gt;cached_session&lt;/code&gt; will by default reuse the same session within the same test. The session returned by this function will only be closed at the end of the test (in the TearDown function).</source>
          <target state="translated">이 메소드는 self.session ()과 다르게 작동합니다. 성능상의 이유로 &lt;code&gt;cached_session&lt;/code&gt; 은 기본적으로 동일한 테스트 내에서 동일한 세션을 재사용합니다. 이 함수에 의해 반환 된 세션은 테스트가 끝날 때만 (TearDown 함수에서) 닫힙니다.</target>
        </trans-unit>
        <trans-unit id="c7294d73f60860f63726337f7edc669a47fd434f" translate="yes" xml:space="preserve">
          <source>This method builds a new graph by first calling the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; to obtain feature &lt;code&gt;Tensor&lt;/code&gt;s, and then calling this &lt;code&gt;Estimator&lt;/code&gt;'s &lt;code&gt;model_fn&lt;/code&gt; to generate the model graph based on those features. It restores the given checkpoint (or, lacking that, the most recent checkpoint) into this graph in a fresh session. Finally it creates a timestamped export directory below the given &lt;code&gt;export_dir_base&lt;/code&gt;, and writes a &lt;code&gt;SavedModel&lt;/code&gt; into it containing a single &lt;code&gt;tf.MetaGraphDef&lt;/code&gt; saved from this session.</source>
          <target state="translated">이 메소드는 먼저 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 을 호출하여 기능 &lt;code&gt;Tensor&lt;/code&gt; 를 확보 한 다음이 &lt;code&gt;Estimator&lt;/code&gt; 의 &lt;code&gt;model_fn&lt;/code&gt; 을 호출 하여 해당 기능을 기반으로 모델 그래프를 생성하여 새 그래프를 작성합니다. 새로운 세션에서 주어진 체크 포인트 (또는 가장 최근의 체크 포인트가없는)를이 그래프로 복원합니다. 마지막으로 주어진 &lt;code&gt;export_dir_base&lt;/code&gt; 아래에 타임 스탬프 된 내보내기 디렉토리를 생성 하고이 세션에서 저장된 단일 &lt;code&gt;tf.MetaGraphDef&lt;/code&gt; 를 포함하는 &lt;code&gt;SavedModel&lt;/code&gt; 을 작성합니다 .</target>
        </trans-unit>
        <trans-unit id="c6ee7778196b7d2b41326a073f8b56a7c8a9a62d" translate="yes" xml:space="preserve">
          <source>This method can also be called directly on a Functional Model during construction. In this case, any loss Tensors passed to this Model must be symbolic and be able to be traced back to the model's &lt;code&gt;Input&lt;/code&gt;s. These losses become part of the model's topology and are tracked in &lt;code&gt;get_config&lt;/code&gt;.</source>
          <target state="translated">이 방법은 구성하는 동안 기능 모델에서 직접 호출 할 수도 있습니다. 이 경우이 모델에 전달 된 손실 텐서는 반드시 상징적이어야하며 모델의 &lt;code&gt;Input&lt;/code&gt; 다시 추적 할 수 있어야합니다 . 이러한 손실은 모델 토폴로지의 일부가되며 &lt;code&gt;get_config&lt;/code&gt; 에서 추적됩니다 .</target>
        </trans-unit>
        <trans-unit id="3e9d9d9b289f8d837ef3c68f7420c8739fcddb82" translate="yes" xml:space="preserve">
          <source>This method can also be called directly on a Functional Model during construction. In this case, any tensor passed to this Model must be symbolic and be able to be traced back to the model's &lt;code&gt;Input&lt;/code&gt;s. These metrics become part of the model's topology and are tracked when you save the model via &lt;code&gt;save()&lt;/code&gt;.</source>
          <target state="translated">This method can also be called directly on a Functional Model during construction. In this case, any tensor passed to this Model must be symbolic and be able to be traced back to the model's &lt;code&gt;Input&lt;/code&gt; s. These metrics become part of the model's topology and are tracked when you save the model via &lt;code&gt;save()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="72b1f5316c49fd45d1ca1593424ee77777a4e789" translate="yes" xml:space="preserve">
          <source>This method can be called multiple times, and will merge the given &lt;code&gt;shape&lt;/code&gt; with the current shape of this tensor. It can be used to provide additional information about the shape of this tensor that cannot be inferred from the graph alone. For example, this can be used to provide additional information about the shapes of images:</source>
          <target state="translated">이 방법은 여러 번 호출 할 수 있으며, 주어진 병합합니다 &lt;code&gt;shape&lt;/code&gt; 이 텐서의 현재 모양. 그래프에서만 유추 할 수없는이 텐서의 모양에 대한 추가 정보를 제공하는 데 사용할 수 있습니다. 예를 들어, 이미지 모양에 대한 추가 정보를 제공하는 데 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="312e4a6b05fc4ebb6ca2b98fbc58b54373467b4c" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;../model#evaluate&quot;&gt;&lt;code&gt;Model.evaluate&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../model#test_on_batch&quot;&gt;&lt;code&gt;Model.test_on_batch&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;../model#evaluate&quot;&gt; &lt;code&gt;Model.evaluate&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../model#test_on_batch&quot;&gt; &lt;code&gt;Model.test_on_batch&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="ec15a46dc0420f052e7d9fc2485824bcb8d59546" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;../model#make_test_function&quot;&gt;&lt;code&gt;Model.make_test_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;../model#make_test_function&quot;&gt; &lt;code&gt;Model.make_test_function&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="24b263a87142b52faa1e21dbe53ee04255d04a75" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;model#evaluate&quot;&gt;&lt;code&gt;Model.evaluate&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;model#test_on_batch&quot;&gt;&lt;code&gt;Model.test_on_batch&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;model#evaluate&quot;&gt; &lt;code&gt;Model.evaluate&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;model#test_on_batch&quot;&gt; &lt;code&gt;Model.test_on_batch&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="00b8ab943979a68d8e7d563dec5f7eda81840f4f" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;model#make_test_function&quot;&gt;&lt;code&gt;Model.make_test_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom evaluation logic. This method is called by &lt;a href=&quot;model#make_test_function&quot;&gt; &lt;code&gt;Model.make_test_function&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="4740c061fca2f7ba4333f6609ad3d2119d60a6e9" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;../model#make_predict_function&quot;&gt;&lt;code&gt;Model.make_predict_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;../model#make_predict_function&quot;&gt; &lt;code&gt;Model.make_predict_function&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="9231f9e258188fbf7d82d2b745ff3bd729ba7207" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;../model#predict&quot;&gt;&lt;code&gt;Model.predict&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../model#predict_on_batch&quot;&gt;&lt;code&gt;Model.predict_on_batch&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;../model#predict&quot;&gt; &lt;code&gt;Model.predict&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../model#predict_on_batch&quot;&gt; &lt;code&gt;Model.predict_on_batch&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="d12957750990229d94e78212f50e83f538705ddf" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;model#make_predict_function&quot;&gt;&lt;code&gt;Model.make_predict_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;model#make_predict_function&quot;&gt; &lt;code&gt;Model.make_predict_function&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="4ecd8d8943012dca870b082ac2069dbad2ddff8d" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;model#predict&quot;&gt;&lt;code&gt;Model.predict&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;model#predict_on_batch&quot;&gt;&lt;code&gt;Model.predict_on_batch&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom inference logic. This method is called by &lt;a href=&quot;model#predict&quot;&gt; &lt;code&gt;Model.predict&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;model#predict_on_batch&quot;&gt; &lt;code&gt;Model.predict_on_batch&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="52dfa555331eece2b509081a1f3acc2117560cba" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;../model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../model#train_on_batch&quot;&gt;&lt;code&gt;Model.train_on_batch&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;../model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../model#train_on_batch&quot;&gt; &lt;code&gt;Model.train_on_batch&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="655f9f9c1b7ccd7db3e5c665ed02881a9dad1b2f" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;../model#make_train_function&quot;&gt;&lt;code&gt;Model.make_train_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;../model#make_train_function&quot;&gt; &lt;code&gt;Model.make_train_function&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="678799c210cac42289c8d3efd485d53c6086509d" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;model#train_on_batch&quot;&gt;&lt;code&gt;Model.train_on_batch&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;model#train_on_batch&quot;&gt; &lt;code&gt;Model.train_on_batch&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="ab33fe36b3e6b63aa5f9d2cddc383b1eeb7bd2db" translate="yes" xml:space="preserve">
          <source>This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;model#make_train_function&quot;&gt;&lt;code&gt;Model.make_train_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This method can be overridden to support custom training logic. This method is called by &lt;a href=&quot;model#make_train_function&quot;&gt; &lt;code&gt;Model.make_train_function&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="a7f74b2952869b5420047da9ad72bf8f755d938b" translate="yes" xml:space="preserve">
          <source>This method can be used after a call to &lt;a href=&quot;enable_check_numerics&quot;&gt;&lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt;&lt;/a&gt; to disable the numerics-checking mechanism that catches infinity and NaN values output by ops executed eagerly or in tf.function-compiled graphs.</source>
          <target state="translated">This method can be used after a call to &lt;a href=&quot;enable_check_numerics&quot;&gt; &lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt; &lt;/a&gt; to disable the numerics-checking mechanism that catches infinity and NaN values output by ops executed eagerly or in tf.function-compiled graphs.</target>
        </trans-unit>
        <trans-unit id="7667fea48f6e7bf7add0c54e02f390885694a1d8" translate="yes" xml:space="preserve">
          <source>This method can be used after a call to &lt;a href=&quot;enable_check_numerics&quot;&gt;&lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt;&lt;/a&gt; to disable the numerics-checking mechanism that catches inifnity and NaN values output by ops executed eagerly or in tf.function-compiled graphs.</source>
          <target state="translated">이 메소드는 &lt;a href=&quot;enable_check_numerics&quot;&gt; &lt;code&gt;tf.debugging.enable_check_numerics()&lt;/code&gt; &lt;/a&gt; 를 호출 한 후 열성적으로 또는 tf.function-compiled graphs에서 실행 된 op에 의해 출력되는 inifnity 및 NaN 값을 포착하는 숫자 확인 메커니즘을 비활성화 하기 위해 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ab134bc99ff08cb5e34c3578ec66ab8ee325437d" translate="yes" xml:space="preserve">
          <source>This method can be used for several purposes. For example, where &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; is unable to shard the input files, this method might be used to manually shard the dataset (avoiding the slow fallback behavior in &lt;code&gt;experimental_distribute_dataset&lt;/code&gt;). In cases where the dataset is infinite, this sharding can be done by creating dataset replicas that differ only in their random seed. &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; may also sometimes fail to split the batch across replicas on a worker. In that case, this method can be used where that limitation does not exist.</source>
          <target state="translated">이 방법은 여러 가지 목적으로 사용될 수 있습니다. 예를 들어, &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 가 입력 파일을 샤딩 할 수없는 경우,이 방법을 사용하여 수동으로 데이터 세트를 샤딩 할 수 있습니다 ( &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 의 느린 폴백 동작 방지 ). 데이터 세트가 무한한 경우 임의의 시드에서만 다른 데이터 세트 복제본을 만들어이 샤딩을 수행 할 수 있습니다. &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; 는 때때로 작업자의 복제본간에 배치를 분할하지 못할 수도 있습니다. 이 경우이 방법은 해당 제한이없는 경우에 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4d445a1a8ccfc13d2cbb47a0cd8852bd14137cba" translate="yes" xml:space="preserve">
          <source>This method can be used inside a subclassed layer or model's &lt;code&gt;call&lt;/code&gt; function, in which case &lt;code&gt;losses&lt;/code&gt; should be a Tensor or list of Tensors.</source>
          <target state="translated">이 방법은 서브 클래스 계층 또는 모델의 &lt;code&gt;call&lt;/code&gt; 함수 내에서 사용될 수 있으며 ,이 경우 &lt;code&gt;losses&lt;/code&gt; 은 텐서 또는 텐서 목록이어야합니다.</target>
        </trans-unit>
        <trans-unit id="1d54c9015867d4032542a340799e853563723710" translate="yes" xml:space="preserve">
          <source>This method can be used inside the &lt;code&gt;call()&lt;/code&gt; method of a subclassed layer or model.</source>
          <target state="translated">This method can be used inside the &lt;code&gt;call()&lt;/code&gt; method of a subclassed layer or model.</target>
        </trans-unit>
        <trans-unit id="0a08143c632d6d9a6c3bb58abdfe351796aa7d61" translate="yes" xml:space="preserve">
          <source>This method can be used to assert that there exists a shape that both &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; represent.</source>
          <target state="translated">이 방법은 &lt;code&gt;self&lt;/code&gt; 과 &lt;code&gt;other&lt;/code&gt; 이 모두 나타내는 모양이 있다고 주장하는 데 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="311f5dd67cb7916aeab132002e12e94284e8fdb8" translate="yes" xml:space="preserve">
          <source>This method can be used to create &lt;code&gt;RaggedTensor&lt;/code&gt;s with multiple uniform outer dimensions. For example, a &lt;code&gt;RaggedTensor&lt;/code&gt; with shape &lt;code&gt;[2, 2, None]&lt;/code&gt; can be constructed with this method from a &lt;code&gt;RaggedTensor&lt;/code&gt; values with shape &lt;code&gt;[4, None]&lt;/code&gt;:</source>
          <target state="translated">이 메소드는 여러 개의 균일 한 외부 치수로 &lt;code&gt;RaggedTensor&lt;/code&gt; 를 작성하는 데 사용할 수 있습니다 . 예를 들어, &lt;code&gt;RaggedTensor&lt;/code&gt; 형상 &lt;code&gt;[2, 2, None]&lt;/code&gt; (A)로부터이 방법으로 구성 될 수 &lt;code&gt;RaggedTensor&lt;/code&gt; 의 형상과 값 &lt;code&gt;[4, None]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="53a52d98446448532e361c5ab0b1a6a4bc35f1f2" translate="yes" xml:space="preserve">
          <source>This method can be used to merge partitions created by &lt;code&gt;dynamic_partition&lt;/code&gt; as illustrated on the following example:</source>
          <target state="translated">이 방법을 사용 하면 다음 예제와 같이 &lt;code&gt;dynamic_partition&lt;/code&gt; 으로 만든 파티션을 병합 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="d34cdddad9212e7710a82e27967cd30b8fc5e14d" translate="yes" xml:space="preserve">
          <source>This method can be used to run a step function for training a number of times using input from a dataset.</source>
          <target state="translated">이 방법을 사용하면 데이터 세트의 입력을 사용하여 여러 번 훈련하기위한 단계 함수를 실행할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9c709bdcba30505f75d83241dd8ba3817ec876a1" translate="yes" xml:space="preserve">
          <source>This method currently blocks forever.</source>
          <target state="translated">이 방법은 현재 영원히 차단됩니다.</target>
        </trans-unit>
        <trans-unit id="0f39f81e0d455fd570ceb61e61e1722fce44270e" translate="yes" xml:space="preserve">
          <source>This method enables setting metadata in a trace event after it is created.</source>
          <target state="translated">This method enables setting metadata in a trace event after it is created.</target>
        </trans-unit>
        <trans-unit id="bc0fd4004c973da3102a123f7521a19f6c88fb03" translate="yes" xml:space="preserve">
          <source>This method generalizes to higher-dimensions by simply providing a list for both the sp_ids as well as the vocab_size. In this case the resulting &lt;code&gt;SparseTensor&lt;/code&gt; has the following properties:</source>
          <target state="translated">This method generalizes to higher-dimensions by simply providing a list for both the sp_ids as well as the vocab_size. In this case the resulting &lt;code&gt;SparseTensor&lt;/code&gt; has the following properties:</target>
        </trans-unit>
        <trans-unit id="a08e7549042177e7c94f4230a7e19c5cac25a2de" translate="yes" xml:space="preserve">
          <source>This method generalizes to higher-dimensions by simply providing a list for both the sp_ids as well as the vocab_size. In this case the resulting &lt;code&gt;SparseTensor&lt;/code&gt; has the following properties: - &lt;code&gt;indices&lt;/code&gt; is equivalent to &lt;code&gt;sp_ids[0].indices&lt;/code&gt; with the last dimension discarded and concatenated with &lt;code&gt;sp_ids[0].values, sp_ids[1].values, ...&lt;/code&gt;. - &lt;code&gt;values&lt;/code&gt; is simply &lt;code&gt;sp_values.values&lt;/code&gt;. - If &lt;code&gt;sp_ids.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt;, then &lt;code&gt;output.shape = [D0, D1, ..., Dn] + vocab_size&lt;/code&gt;.</source>
          <target state="translated">이 방법은 sp_id와 vocab_size에 대한 목록을 제공하여보다 높은 차원으로 일반화합니다. 이 경우 결과 &lt;code&gt;SparseTensor&lt;/code&gt; 의 속성은 다음과 같습니다.- &lt;code&gt;indices&lt;/code&gt; 는 &lt;code&gt;sp_ids[0].indices&lt;/code&gt; 과 같습니다. 마지막 차원은 버리고 연결됩니다. &lt;code&gt;sp_ids[0].values, sp_ids[1].values, ...&lt;/code&gt; . - &lt;code&gt;values&lt;/code&gt; 단순히 &lt;code&gt;sp_values.values&lt;/code&gt; . - 만약 &lt;code&gt;sp_ids.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt; 다음 &lt;code&gt;output.shape = [D0, D1, ..., Dn] + vocab_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e7e44aa7677b60789a9ebef54c74a9714ec4de2a" translate="yes" xml:space="preserve">
          <source>This method has similar semantics to the built-in &lt;code&gt;zip()&lt;/code&gt; function in Python, with the main difference being that the &lt;code&gt;datasets&lt;/code&gt; argument can be an arbitrary nested structure of &lt;code&gt;Dataset&lt;/code&gt; objects.</source>
          <target state="translated">이 메소드는 파이썬 의 내장 &lt;code&gt;zip()&lt;/code&gt; 함수 와 비슷한 의미를 가지는데 , 주요 차이점은 &lt;code&gt;datasets&lt;/code&gt; 인수가 &lt;code&gt;Dataset&lt;/code&gt; 객체 의 임의의 중첩 구조가 될 수 있다는 것 입니다.</target>
        </trans-unit>
        <trans-unit id="1925370323ce05b6dc0cdc8787e9c0d6ebf8403a" translate="yes" xml:space="preserve">
          <source>This method is a convenience wrapper for creating a &lt;a href=&quot;server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; with a &lt;a href=&quot;../train/serverdef&quot;&gt;&lt;code&gt;tf.train.ServerDef&lt;/code&gt;&lt;/a&gt; that specifies a single-process cluster containing a single task in a job called &lt;code&gt;&quot;local&quot;&lt;/code&gt;.</source>
          <target state="translated">이 메소드는 &lt;a href=&quot;server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 를 작성하기위한 편리한 랩퍼입니다. 로모그래퍼 &lt;a href=&quot;../train/serverdef&quot;&gt; &lt;code&gt;tf.train.ServerDef&lt;/code&gt; &lt;/a&gt; 지정이라는 작업에서 하나의 작업을 포함하는 단일 프로세스 클러스터 &lt;code&gt;&quot;local&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="05c81c4b69f5f8cdea4eba6f7d8bb00b2d7cd37f" translate="yes" xml:space="preserve">
          <source>This method is automatically called when the StubOutForTesting() object is deleted; there is no need to call it explicitly.</source>
          <target state="translated">이 메소드는 StubOutForTesting () 오브젝트가 삭제 될 때 자동으로 호출됩니다. 명시 적으로 호출 할 필요가 없습니다.</target>
        </trans-unit>
        <trans-unit id="992fe7b39731079182b90eaf498e1ed5e5a20148" translate="yes" xml:space="preserve">
          <source>This method is completely compatible with the &lt;code&gt;tf.Session.run()&lt;/code&gt; method.</source>
          <target state="translated">이 메소드는 &lt;code&gt;tf.Session.run()&lt;/code&gt; 메소드 와 완전히 호환됩니다 .</target>
        </trans-unit>
        <trans-unit id="9074766f6510dcf3975a88d8985dc7d0e99f0a13" translate="yes" xml:space="preserve">
          <source>This method is deprecated, use is_alive() instead.</source>
          <target state="translated">This method is deprecated, use is_alive() instead.</target>
        </trans-unit>
        <trans-unit id="a744f7951fcb63381ecb2ea91dcc061d08e7d4a0" translate="yes" xml:space="preserve">
          <source>This method is exposed in TensorFlow's API so that library developers can register dispatching for &lt;a href=&quot;tensor#__eq__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;eq&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; to allow it to handle custom composite tensors &amp;amp; other custom objects.</source>
          <target state="translated">This method is exposed in TensorFlow's API so that library developers can register dispatching for &lt;a href=&quot;tensor#__eq__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;eq&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; to allow it to handle custom composite tensors &amp;amp; other custom objects.</target>
        </trans-unit>
        <trans-unit id="8a699437e1c2aa279788c76128e6e5f624c7c0a7" translate="yes" xml:space="preserve">
          <source>This method is exposed in TensorFlow's API so that library developers can register dispatching for &lt;a href=&quot;tensor#__getitem__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; to allow it to handle custom composite tensors &amp;amp; other custom objects.</source>
          <target state="translated">This method is exposed in TensorFlow's API so that library developers can register dispatching for &lt;a href=&quot;tensor#__getitem__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; to allow it to handle custom composite tensors &amp;amp; other custom objects.</target>
        </trans-unit>
        <trans-unit id="ca897118350393caa56db53d55d7ff23f3ea66bf" translate="yes" xml:space="preserve">
          <source>This method is exposed in TensorFlow's API so that library developers can register dispatching for &lt;a href=&quot;tensor#__ne__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;ne&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; to allow it to handle custom composite tensors &amp;amp; other custom objects.</source>
          <target state="translated">This method is exposed in TensorFlow's API so that library developers can register dispatching for &lt;a href=&quot;tensor#__ne__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;ne&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; to allow it to handle custom composite tensors &amp;amp; other custom objects.</target>
        </trans-unit>
        <trans-unit id="a7dd7ea7386a00c65842a1da48fad6c58e2f712f" translate="yes" xml:space="preserve">
          <source>This method is for use by TestCase subclasses that need to register their own type equality functions to provide nicer error messages.</source>
          <target state="translated">이 메소드는 더 나은 오류 메시지를 제공하기 위해 자체 유형 평등 함수를 등록해야하는 TestCase 서브 클래스에서 사용합니다.</target>
        </trans-unit>
        <trans-unit id="66283121e6883c956c7613fffa84d220528690f4" translate="yes" xml:space="preserve">
          <source>This method is idempotent. Calling it multiple times has the same effect as calling it once.</source>
          <target state="translated">이 방법은 dem 등원입니다. 여러 번 호출하면 한 번 호출하는 것과 같은 효과가 있습니다.</target>
        </trans-unit>
        <trans-unit id="26e25dbe646e6bb109fc819d323736b4d761ed81" translate="yes" xml:space="preserve">
          <source>This method is intended to be used to load checkpoints created by &lt;code&gt;save()&lt;/code&gt;. For checkpoints created by &lt;code&gt;write()&lt;/code&gt; use the &lt;code&gt;read()&lt;/code&gt; method which does not expect the &lt;code&gt;save_counter&lt;/code&gt; variable added by &lt;code&gt;save()&lt;/code&gt;.</source>
          <target state="translated">This method is intended to be used to load checkpoints created by &lt;code&gt;save()&lt;/code&gt; . For checkpoints created by &lt;code&gt;write()&lt;/code&gt; use the &lt;code&gt;read()&lt;/code&gt; method which does not expect the &lt;code&gt;save_counter&lt;/code&gt; variable added by &lt;code&gt;save()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="887c8b37e88faa620b24a828f5dc104598906d79" translate="yes" xml:space="preserve">
          <source>This method is just like &lt;code&gt;restore()&lt;/code&gt; but does not expect the &lt;code&gt;save_counter&lt;/code&gt; variable in the checkpoint. It only restores the objects that the checkpoint already depends on.</source>
          <target state="translated">This method is just like &lt;code&gt;restore()&lt;/code&gt; but does not expect the &lt;code&gt;save_counter&lt;/code&gt; variable in the checkpoint. It only restores the objects that the checkpoint already depends on.</target>
        </trans-unit>
        <trans-unit id="d1d2fc5aba91c121cb755ded927621c464c711dd" translate="yes" xml:space="preserve">
          <source>This method is only needed if you compute gradients manually, e.g. with &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. In that case, call this method to scale the loss before passing the loss to &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. If you use &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt;&lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt;&lt;/a&gt;, loss scaling is automatically applied and this method is unneeded.</source>
          <target state="translated">이 방법은 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 와 같이 그라디언트를 수동으로 계산하는 경우에만 필요합니다 . 이 경우 손실을 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 로&lt;/a&gt; 전달하기 전에 손실을 스케일링하려면이 메소드를 호출하십시오 . &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt; &lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt; &lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt; &lt;/a&gt; 를 사용하는 경우 손실 스케일링이 자동으로 적용 메소드는 필요하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="2ffe062127379160c3973cd4f84270b4f4f8ccf9" translate="yes" xml:space="preserve">
          <source>This method is only needed if you compute gradients manually, e.g. with &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. In that case, call this method to unscale the gradients after computing them with &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. If you use &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt;&lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt;&lt;/a&gt;, loss scaling is automatically applied and this method is unneeded.</source>
          <target state="translated">이 방법은 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 와 같이 그라디언트를 수동으로 계산하는 경우에만 필요합니다 . 이 경우, 그들을 계산 후 그라디언트 unscale이 메소드를 호출 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; . &lt;a href=&quot;../../optimizers/optimizer#minimize&quot;&gt; &lt;code&gt;LossScaleOptimizer.minimize&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;lossscaleoptimizer#get_gradients&quot;&gt; &lt;code&gt;LossScaleOptimizer.get_gradients&lt;/code&gt; &lt;/a&gt; 를 사용하면 손실 스케일링이 자동으로 적용 되며이 메소드는 필요하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="2d15ade5009ad723801c2c48bded790a3845587f" translate="yes" xml:space="preserve">
          <source>This method is optional if you are just training and executing models, exporting to and from SavedModels, or using weight checkpoints.</source>
          <target state="translated">이 방법은 모델을 교육 및 실행하거나 저장된 모델로 내보내거나 저장된 모델에서 또는 중량 검사 점을 사용하는 경우 선택 사항입니다.</target>
        </trans-unit>
        <trans-unit id="2ed4e772dabffd01cfde2b74159ef69c9f3e04f5" translate="yes" xml:space="preserve">
          <source>This method is required for Keras &lt;code&gt;model_to_estimator&lt;/code&gt;, saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON.</source>
          <target state="translated">이 방법은 &lt;code&gt;model_to_estimator&lt;/code&gt; 필요하며 모델을 HDF5 형식으로 저장 및로드, Keras 모델 복제, 일부 시각화 유틸리티 및 JSON과 모델을 내보내는 데 필요합니다.</target>
        </trans-unit>
        <trans-unit id="6fdad9c5ed22f16c319e244d8261ea4ee3d279dd" translate="yes" xml:space="preserve">
          <source>This method is smart and works at the module, class, and instance level while preserving proper inheritance. It will not stub out C types however unless that has been explicitly allowed by the type.</source>
          <target state="translated">이 방법은 똑똑하며 적절한 상속을 유지하면서 모듈, 클래스 및 인스턴스 수준에서 작동합니다. 그러나 C 유형에서 명시 적으로 허용하지 않는 한 C 유형을 스텁 아웃하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="feecb6a599cedcf2305768be36a750d8591e9329" translate="yes" xml:space="preserve">
          <source>This method is the reverse of &lt;code&gt;get_config&lt;/code&gt;, capable of instantiating the same layer from the config dictionary. It does not handle layer connectivity (handled by Network), nor weights (handled by &lt;code&gt;set_weights&lt;/code&gt;).</source>
          <target state="translated">이 메소드는 &lt;code&gt;get_config&lt;/code&gt; 와 반대로 구성 사전에서 동일한 계층을 인스턴스화 할 수 있습니다. 계층 연결 (네트워크에서 처리) 또는 가중치 ( &lt;code&gt;set_weights&lt;/code&gt; 로 처리)를 처리하지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="422559cd09a8b37855dfa1becf9159996c55a88c" translate="yes" xml:space="preserve">
          <source>This method is the reverse of &lt;code&gt;get_config&lt;/code&gt;, capable of instantiating the same optimizer from the config dictionary.</source>
          <target state="translated">이 메소드는 &lt;code&gt;get_config&lt;/code&gt; 와 반대로 구성 사전에서 동일한 최적화 프로그램을 인스턴스화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c7d6ed78b790787a16f4abeccc0ecd949df6cc2b" translate="yes" xml:space="preserve">
          <source>This method is the reverse of &lt;code&gt;get_config&lt;/code&gt;, capable of instantiating the same regularizer from the config dictionary.</source>
          <target state="translated">이 메소드는 &lt;code&gt;get_config&lt;/code&gt; 와 반대로 구성 사전에서 동일한 정규화 프로그램을 인스턴스화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="64a729de3228c199e6f42ec9b13a781c1672f7d1" translate="yes" xml:space="preserve">
          <source>This method is the same as setting &lt;code&gt;minval&lt;/code&gt; and &lt;code&gt;maxval&lt;/code&gt; to &lt;code&gt;None&lt;/code&gt; in the &lt;code&gt;uniform&lt;/code&gt; method.</source>
          <target state="translated">This method is the same as setting &lt;code&gt;minval&lt;/code&gt; and &lt;code&gt;maxval&lt;/code&gt; to &lt;code&gt;None&lt;/code&gt; in the &lt;code&gt;uniform&lt;/code&gt; method.</target>
        </trans-unit>
        <trans-unit id="188de6cc0c368ed4ab40eeabc0c2f0a4587200cc" translate="yes" xml:space="preserve">
          <source>This method is thread-safe.</source>
          <target state="translated">이 방법은 스레드로부터 안전합니다.</target>
        </trans-unit>
        <trans-unit id="430e31afd2b8ce36dbd30c0726de058dc4716f34" translate="yes" xml:space="preserve">
          <source>This method is used by Keras &lt;code&gt;model_to_estimator&lt;/code&gt;, saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON.</source>
          <target state="translated">이 방법은 &lt;code&gt;model_to_estimator&lt;/code&gt; 에서 모델을 HDF5 형식으로 저장 및로드, 모델 복제, 일부 시각화 유틸리티 및 JSON과 모델을 내보내는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="457bbe494ff8a7cc3168e5b2acb3fc1d7df09a01" translate="yes" xml:space="preserve">
          <source>This method is used to convert a dictionary into a sequence of parameters for a binary that parses arguments using this module.</source>
          <target state="translated">이 메소드는 사전을이 모듈을 사용하여 인수를 구문 분석하는 2 진의 매개 변수 시퀀스로 변환하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="5f40fabbeaa1bcaea8e9654a487713070e7848ee" translate="yes" xml:space="preserve">
          <source>This method is useful for recovering the &quot;self._last_checkpoints&quot; state.</source>
          <target state="translated">이 방법은 &quot;self._last_checkpoints&quot;상태를 복구하는 데 유용합니다.</target>
        </trans-unit>
        <trans-unit id="5eb2940a1b8924b3a2b4c6c370fcb87bd404d70c" translate="yes" xml:space="preserve">
          <source>This method may be called concurrently from multiple threads.</source>
          <target state="translated">이 메소드는 여러 스레드에서 동시에 호출 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="879b4ac0bfff915fe8733219e840864c530b0386" translate="yes" xml:space="preserve">
          <source>This method must be used as a context manager, and will yield a recording object with two attributes: &lt;code&gt;output&lt;/code&gt; and &lt;code&gt;records&lt;/code&gt;. At the end of the context manager, the &lt;code&gt;output&lt;/code&gt; attribute will be a list of the matching formatted log messages and the &lt;code&gt;records&lt;/code&gt; attribute will be a list of the corresponding LogRecord objects.</source>
          <target state="translated">이 메소드는 컨텍스트 관리자로 사용해야하며 &lt;code&gt;output&lt;/code&gt; 및 &lt;code&gt;records&lt;/code&gt; 속성이있는 레코딩 오브젝트를 생성 합니다 . 컨텍스트 관리자의 끝에서 &lt;code&gt;output&lt;/code&gt; 속성은 일치하는 형식화 된 로그 메시지 목록이고 &lt;code&gt;records&lt;/code&gt; 속성은 해당 LogRecord 객체의 목록입니다.</target>
        </trans-unit>
        <trans-unit id="45b78faa33c30a4ca2de4d4a2a7e0ea54433a6aa" translate="yes" xml:space="preserve">
          <source>This method overrides unittest.TestCase.shortDescription(), which only returns the first line of the docstring, obscuring the name of the test upon failure.</source>
          <target state="translated">이 메소드는 unittest.TestCase.shortDescription ()을 대체합니다.이 메소드는 docstring의 첫 번째 행만 리턴하고 실패시 테스트 이름을 숨 깁니다.</target>
        </trans-unit>
        <trans-unit id="ee5a67ef5f4ab3abd49e8e0aa6ab37b4c495718e" translate="yes" xml:space="preserve">
          <source>This method promotes a completely unknown shape to one with a known rank.</source>
          <target state="translated">이 방법은 완전히 알려지지 않은 모양을 알려진 순위의 모양으로 승격시킵니다.</target>
        </trans-unit>
        <trans-unit id="f08536c5c4bd5b0bf81a621ac1af31ff012f949c" translate="yes" xml:space="preserve">
          <source>This method requires a session in which the graph was launched. It creates a list of threads, optionally starting them. There is one thread for each op passed in &lt;code&gt;enqueue_ops&lt;/code&gt;.</source>
          <target state="translated">이 방법에는 그래프가 시작된 세션이 필요합니다. 스레드 목록을 작성하고 선택적으로 시작합니다. &lt;code&gt;enqueue_ops&lt;/code&gt; 에 전달 된 각 op에 대해 하나의 스레드가 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ed37572237615338abb9afe9f97f9e51444c9050" translate="yes" xml:space="preserve">
          <source>This method requires that you are running in eager mode and the dataset's element_spec contains only &lt;code&gt;TensorSpec&lt;/code&gt; components.</source>
          <target state="translated">이 방법을 사용하려면 열망 모드에서 실행 중이고 데이터 세트의 element_spec에 &lt;code&gt;TensorSpec&lt;/code&gt; 구성 요소 만 포함되어 있어야 합니다.</target>
        </trans-unit>
        <trans-unit id="ba66428fee92af2921958313c4abbe6a414d3356" translate="yes" xml:space="preserve">
          <source>This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;../../../../data/dataset#cardinality&quot;&gt;&lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;../../../../data/dataset#cardinality&quot;&gt; &lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt; &lt;/a&gt; instead.</target>
        </trans-unit>
        <trans-unit id="c229102fa2fa8b3a631fa2db6ca01f20dd5c2adc" translate="yes" xml:space="preserve">
          <source>This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;../../../data/dataset#cardinality&quot;&gt;&lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;../../../data/dataset#cardinality&quot;&gt; &lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt; &lt;/a&gt; instead.</target>
        </trans-unit>
        <trans-unit id="2bff5648ed0712c0feea6c45e6290da036f8f217" translate="yes" xml:space="preserve">
          <source>This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;../dataset#cardinality&quot;&gt;&lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;../dataset#cardinality&quot;&gt; &lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt; &lt;/a&gt; instead.</target>
        </trans-unit>
        <trans-unit id="4d8d6fb6d8be4a1c2d9cfd5ec8103395810dc8de" translate="yes" xml:space="preserve">
          <source>This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;dataset#cardinality&quot;&gt;&lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">This method requires that you are running in eager mode, and that the length of the dataset is known and non-infinite. When the length may be unknown or infinite, or if you are running in graph mode, use &lt;a href=&quot;dataset#cardinality&quot;&gt; &lt;code&gt;tf.data.Dataset.cardinality&lt;/code&gt; &lt;/a&gt; instead.</target>
        </trans-unit>
        <trans-unit id="df938127180a900a9c0ee2c326f70990ca05bad0" translate="yes" xml:space="preserve">
          <source>This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads.</source>
          <target state="translated">이 메소드는 run () 메소드가 종료되기 직전까지 run () 메소드가 시작되기 직전에 True를 리턴합니다. 모듈 함수 enumerate ()는 모든 활성 스레드 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="843186b661a979f57d76fd131bdb6daf25004a63" translate="yes" xml:space="preserve">
          <source>This method returns a context manager, and is used as follows:</source>
          <target state="translated">This method returns a context manager, and is used as follows:</target>
        </trans-unit>
        <trans-unit id="67c5a6af4d2a477a788bf93645d98e3fc1667925" translate="yes" xml:space="preserve">
          <source>This method runs one &quot;step&quot; of TensorFlow computation, by running the necessary graph fragment to execute every &lt;code&gt;Operation&lt;/code&gt; and evaluate every &lt;code&gt;Tensor&lt;/code&gt; in &lt;code&gt;fetches&lt;/code&gt;, substituting the values in &lt;code&gt;feed_dict&lt;/code&gt; for the corresponding input values.</source>
          <target state="translated">이 메소드는 필요한 그래프 단편을 실행하여 모든 &lt;code&gt;Operation&lt;/code&gt; 을 실행 하고 &lt;code&gt;fetches&lt;/code&gt; 에서 모든 &lt;code&gt;Tensor&lt;/code&gt; 를 평가 하여 해당 입력 값에 대해 &lt;code&gt;feed_dict&lt;/code&gt; 의 값을 대체하여 TensorFlow 계산의 한 단계를 실행 합니다.</target>
        </trans-unit>
        <trans-unit id="7ef4f95365ffd49356edce6309d3da564feb3d3b" translate="yes" xml:space="preserve">
          <source>This method runs the ops added by the constructor for restoring variables. It requires a session in which the graph was launched. The variables to restore do not have to have been initialized, as restoring is itself a way to initialize variables.</source>
          <target state="translated">이 메소드는 변수를 복원하기 위해 생성자가 추가 한 op를 실행합니다. 그래프가 시작된 세션이 필요합니다. 복원 자체는 변수를 초기화하는 방법이므로 복원 할 변수를 초기화하지 않아도됩니다.</target>
        </trans-unit>
        <trans-unit id="6a0628c028c0b695f5ff3c6935b2aad50149fac6" translate="yes" xml:space="preserve">
          <source>This method runs the ops added by the constructor for saving variables. It requires a session in which the graph was launched. The variables to save must also have been initialized.</source>
          <target state="translated">이 메소드는 변수를 저장하기 위해 생성자가 추가 한 op를 실행합니다. 그래프가 시작된 세션이 필요합니다. 저장할 변수도 초기화해야합니다.</target>
        </trans-unit>
        <trans-unit id="9df50570004b7fc9f261d6b98cab329e6a66afe0" translate="yes" xml:space="preserve">
          <source>This method sets the vocabulary and DF data for this layer directly, instead of analyzing a dataset through 'adapt'. It should be used whenever the vocab (and optionally document frequency) information is already known. If vocabulary data is already present in the layer, this method will either replace it, if 'append' is set to False, or append to it (if 'append' is set to True).</source>
          <target state="translated">이 방법은 'adapt'를 통해 데이터 세트를 분석하는 대신이 레이어의 어휘 및 DF 데이터를 직접 설정합니다. vocab (및 선택적으로 문서 빈도) 정보가 이미 알려질 때마다 사용해야합니다. 어휘 데이터가 이미 계층에 존재하는 경우이 방법은 'append'가 False로 설정되어 있으면 추가하거나 추가합니다 ( 'append'가 True로 설정되어있는 경우).</target>
        </trans-unit>
        <trans-unit id="98a596750a8e57f7c4dd92233c96d160228e7339" translate="yes" xml:space="preserve">
          <source>This method sets the vocabulary and DF data for this layer directly, instead of analyzing a dataset through 'adapt'. It should be used whenever the vocab (and optionally document frequency) information is already known. If vocabulary data is already present in the layer, this method will replace it.</source>
          <target state="translated">This method sets the vocabulary and DF data for this layer directly, instead of analyzing a dataset through 'adapt'. It should be used whenever the vocab (and optionally document frequency) information is already known. If vocabulary data is already present in the layer, this method will replace it.</target>
        </trans-unit>
        <trans-unit id="f39e288c36cc30e58aa384f98451d54174eefdc7" translate="yes" xml:space="preserve">
          <source>This method sets the vocabulary for this layer directly, instead of analyzing a dataset through 'adapt'. It should be used whenever the vocab information is already known. If vocabulary data is already present in the layer, this method will either replace it</source>
          <target state="translated">This method sets the vocabulary for this layer directly, instead of analyzing a dataset through 'adapt'. It should be used whenever the vocab information is already known. If vocabulary data is already present in the layer, this method will either replace it</target>
        </trans-unit>
        <trans-unit id="381d5d74ef1ba876c849eaf0c748814799df311b" translate="yes" xml:space="preserve">
          <source>This method should be used if you want to create multiple graphs in the same process. For convenience, a global default graph is provided, and all ops will be added to this graph if you do not create a new graph explicitly.</source>
          <target state="translated">동일한 프로세스에서 여러 그래프를 작성하려는 경우이 방법을 사용해야합니다. 편의상 전역 기본 그래프가 제공되며 새 그래프를 명시 적으로 만들지 않으면 모든 작업이이 그래프에 추가됩니다.</target>
        </trans-unit>
        <trans-unit id="801d04a3f8f77fe9f713a4af6184910c6103cec6" translate="yes" xml:space="preserve">
          <source>This method should be used to create all threads in test cases, as otherwise there is a risk that a thread will silently fail, and/or assertions made in the thread will not be respected.</source>
          <target state="translated">이 방법은 테스트 케이스에서 모든 스레드를 작성하는 데 사용해야합니다. 그렇지 않으면 스레드가 자동으로 실패 할 수 있으며 스레드에서 작성된 어설 션이 존중되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0840a5953e72a61137caa721b5cce35c70dbd3d8" translate="yes" xml:space="preserve">
          <source>This method should contain the mathemetical logic for one step of inference. This typically includes the forward pass.</source>
          <target state="translated">This method should contain the mathemetical logic for one step of inference. This typically includes the forward pass.</target>
        </trans-unit>
        <trans-unit id="eebfd3cd848c16a7d254cfeece5ae46941b7f986" translate="yes" xml:space="preserve">
          <source>This method should contain the mathemetical logic for one step of training. This typically includes the forward pass, loss calculation, backpropagation, and metric updates.</source>
          <target state="translated">This method should contain the mathemetical logic for one step of training. This typically includes the forward pass, loss calculation, backpropagation, and metric updates.</target>
        </trans-unit>
        <trans-unit id="84ddde0d41fb950f979365b1dd4b04e51a4464b1" translate="yes" xml:space="preserve">
          <source>This method simply combines calls &lt;code&gt;compute_gradients()&lt;/code&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt;. If you want to process the gradient before applying them call &lt;code&gt;compute_gradients()&lt;/code&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt; explicitly instead of using this function.</source>
          <target state="translated">이 메소드는 단순히 &lt;code&gt;compute_gradients()&lt;/code&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출을 결합합니다 . 그라디언트를 적용하기 전에 그라디언트를 처리하려면 이 함수를 사용하는 대신 명시 적으로 &lt;code&gt;compute_gradients()&lt;/code&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출하십시오.</target>
        </trans-unit>
        <trans-unit id="5f6d383158cc853c41c5bc430e4c2e31944ed6aa" translate="yes" xml:space="preserve">
          <source>This method simply computes gradient using &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and calls &lt;code&gt;apply_gradients()&lt;/code&gt;. If you want to process the gradient before applying then call &lt;a href=&quot;../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt; explicitly instead of using this function.</source>
          <target state="translated">이 메소드는 단순히 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 를&lt;/a&gt; 사용하여 그래디언트를 계산 하고 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출합니다 . 적용하기 전에 그라디언트를 처리하려면 이 함수를 사용하는 대신 &lt;a href=&quot;../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 명시 적으로 호출 하십시오 .</target>
        </trans-unit>
        <trans-unit id="7c45540d5f88e8d63143978a302ef3be7b4897a3" translate="yes" xml:space="preserve">
          <source>This method simply computes gradient using &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and calls &lt;code&gt;apply_gradients()&lt;/code&gt;. If you want to process the gradient before applying then call &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;apply_gradients()&lt;/code&gt; explicitly instead of using this function.</source>
          <target state="translated">이 메소드는 단순히 &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; 를&lt;/a&gt; 사용하여 그래디언트를 계산 하고 &lt;code&gt;apply_gradients()&lt;/code&gt; 호출합니다 . 적용하기 전에 그라디언트를 처리하려면 이 함수를 사용하는 대신 &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; 및 &lt;code&gt;apply_gradients()&lt;/code&gt; 명시 적으로 호출 하십시오 .</target>
        </trans-unit>
        <trans-unit id="9fbf54940adbbc3b34153fb181199a19b56bd888" translate="yes" xml:space="preserve">
          <source>This method supports the case where attr_name is a staticmethod or a classmethod of obj.</source>
          <target state="translated">이 메소드는 attr_name이 정적 메소드이거나 obj의 클래스 메소드 인 경우를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="b1e95fe0c7a12cd011cb442b54315c64dbbef85c" translate="yes" xml:space="preserve">
          <source>This method supports the case where child_name is a staticmethod or a classmethod of parent.</source>
          <target state="translated">이 메소드는 child_name이 정적 메소드이거나 상위 클래스 메소드 인 경우를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="3c5357e5e49a58f1873923787332f7877e186b5d" translate="yes" xml:space="preserve">
          <source>This method takes effect only on the thread in which it is called.</source>
          <target state="translated">이 메소드는 호출 된 스레드에만 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="dc69067a62ba3479c811e1ffb95925d4cb95f817" translate="yes" xml:space="preserve">
          <source>This method takes the same args as the DeviceSpec constructor</source>
          <target state="translated">This method takes the same args as the DeviceSpec constructor</target>
        </trans-unit>
        <trans-unit id="7cd6047c37611c4ef1b1add7ec4d3db22681db24" translate="yes" xml:space="preserve">
          <source>This method will also be called as a result of recovering a wrapped session, not only at the beginning of the overall session.</source>
          <target state="translated">이 메소드는 전체 세션의 시작뿐만 아니라 랩핑 된 세션을 복구 한 결과로도 호출됩니다.</target>
        </trans-unit>
        <trans-unit id="b524a4798bc6e14abf1530810ef4205d0b748932" translate="yes" xml:space="preserve">
          <source>This method will block caller thread until it receives tracing result. This method supports CPU, GPU, and Cloud TPU. This method supports profiling a single host for CPU, GPU, TPU, as well as multiple TPU workers. The profiled results will be saved to your specified TensorBoard log directory (e.g. the directory you save your model checkpoints). Use the TensorBoard profile plugin to view the visualization and analysis results.</source>
          <target state="translated">This method will block caller thread until it receives tracing result. This method supports CPU, GPU, and Cloud TPU. This method supports profiling a single host for CPU, GPU, TPU, as well as multiple TPU workers. The profiled results will be saved to your specified TensorBoard log directory (e.g. the directory you save your model checkpoints). Use the TensorBoard profile plugin to view the visualization and analysis results.</target>
        </trans-unit>
        <trans-unit id="80c9b1eb0c3b33d3a7e2274259517a077b4c895e" translate="yes" xml:space="preserve">
          <source>This method will first try to restore from the most recent checkpoint in &lt;code&gt;directory&lt;/code&gt;. If no checkpoints exist in &lt;code&gt;directory&lt;/code&gt;, and &lt;code&gt;init_fn&lt;/code&gt; is specified, this method will call &lt;code&gt;init_fn&lt;/code&gt; to do customized initialization. This can be used to support initialization from pretrained models.</source>
          <target state="translated">This method will first try to restore from the most recent checkpoint in &lt;code&gt;directory&lt;/code&gt; . If no checkpoints exist in &lt;code&gt;directory&lt;/code&gt; , and &lt;code&gt;init_fn&lt;/code&gt; is specified, this method will call &lt;code&gt;init_fn&lt;/code&gt; to do customized initialization. This can be used to support initialization from pretrained models.</target>
        </trans-unit>
        <trans-unit id="72f0ec32b5d6b0d5f31ec5a44977c2b73ae22a24" translate="yes" xml:space="preserve">
          <source>This method will raise a RuntimeError if called more than once on the same thread object.</source>
          <target state="translated">이 메소드는 같은 스레드 객체에서 두 번 이상 호출되면 RuntimeError를 발생시킵니다.</target>
        </trans-unit>
        <trans-unit id="5450168f56def10b3805f1b87bf923f81daadea9" translate="yes" xml:space="preserve">
          <source>This method works similar to tf.map_fn but is optimized to run much faster, possibly with a much larger memory footprint. The speedups are obtained by vectorization (see &lt;a href=&quot;https://arxiv.org/pdf/1903.04243.pdf&quot;&gt;https://arxiv.org/pdf/1903.04243.pdf&lt;/a&gt;). The idea behind vectorization is to semantically launch all the invocations of &lt;code&gt;fn&lt;/code&gt; in parallel and fuse corresponding operations across all these invocations. This fusion is done statically at graph generation time and the generated code is often similar in performance to a manually fused version.</source>
          <target state="translated">This method works similar to tf.map_fn but is optimized to run much faster, possibly with a much larger memory footprint. The speedups are obtained by vectorization (see &lt;a href=&quot;https://arxiv.org/pdf/1903.04243.pdf&quot;&gt;https://arxiv.org/pdf/1903.04243.pdf&lt;/a&gt;). The idea behind vectorization is to semantically launch all the invocations of &lt;code&gt;fn&lt;/code&gt; in parallel and fuse corresponding operations across all these invocations. This fusion is done statically at graph generation time and the generated code is often similar in performance to a manually fused version.</target>
        </trans-unit>
        <trans-unit id="218a6eaea58d633bb4c07cebec2cce2a54164fc8" translate="yes" xml:space="preserve">
          <source>This method works similar to tf.map_fn but is optimized to run much faster, possibly with a much larger memory footprint. The speedups are obtained by vectorization (see https://arxiv.org/pdf/1903.04243.pdf). The idea behind vectorization is to semantically launch all the invocations of &lt;code&gt;fn&lt;/code&gt; in parallel and fuse corresponding operations across all these invocations. This fusion is done statically at graph generation time and the generated code is often similar in performance to a manually fused version.</source>
          <target state="translated">이 방법은 tf.map_fn과 유사하게 작동하지만 훨씬 더 큰 메모리 풋 프린트로 훨씬 빠르게 실행되도록 최적화되었습니다. 속도는 벡터화를 통해 얻을 수 있습니다 (https://arxiv.org/pdf/1903.04243.pdf 참조). 벡터화의 기본 개념은 의미 적으로 &lt;code&gt;fn&lt;/code&gt; 의 모든 호출을 병렬로 시작하고 이러한 모든 호출에서 해당 작업을 통합하는 것입니다. 이 융합은 그래프 생성시 정적으로 수행되며 생성 된 코드는 성능이 수동으로 융합 된 버전과 종종 유사합니다.</target>
        </trans-unit>
        <trans-unit id="fe5b3fca46a696592f5d3933d9a6c2e14a59d105" translate="yes" xml:space="preserve">
          <source>This method wraps the provided session in an &lt;code&gt;Event&lt;/code&gt; protocol buffer and adds it to the event file.</source>
          <target state="translated">이 메소드는 제공된 세션을 &lt;code&gt;Event&lt;/code&gt; 프로토콜 버퍼로 랩핑 하여 이벤트 파일에 추가합니다.</target>
        </trans-unit>
        <trans-unit id="0b654fd9b9bcfd951b8584e5c172fdf88b6f87e9" translate="yes" xml:space="preserve">
          <source>This method wraps the provided summary in an &lt;code&gt;Event&lt;/code&gt; protocol buffer and adds it to the event file.</source>
          <target state="translated">이 메소드는 제공된 요약을 &lt;code&gt;Event&lt;/code&gt; 프로토콜 버퍼 에 랩하여 이를 이벤트 파일에 추가합니다.</target>
        </trans-unit>
        <trans-unit id="e573192331e3d216aaf00fffe24f089e83e9c9ad" translate="yes" xml:space="preserve">
          <source>This method, unlike assertCountEqual, doesn't care about any duplicates in the expected and actual sequences.</source>
          <target state="translated">assertCountEqual과 달리이 메소드는 예상 및 실제 시퀀스의 중복에 대해서는 신경 쓰지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0b693febd3a0c9fc69fb14a0f914449cb9729097" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the AUC. To discretize the AUC curve, a linearly spaced set of thresholds is used to compute pairs of recall and precision values. The area under the ROC-curve is therefore computed using the height of the recall values by the false positive rate, while the area under the PR-curve is the computed using the height of the precision values by the recall.</source>
          <target state="translated">이 메트릭은 AUC를 계산하는 데 사용되는 네 가지 로컬 변수 인 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성 합니다. AUC 곡선을 이산화시키기 위해 선형 간격의 임계 값 세트를 사용하여 리콜 및 정밀 값 쌍을 계산합니다. 따라서 ROC- 커브 아래 영역은 리콜 값의 높이를 가양 성 비율로 사용하여 계산되는 반면 PR- 커브 아래 영역은 리콜에 의해 정밀도 값의 높이를 사용하여 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="8310e01ff09f3ad784585cc77cdb8fe7f1ac0213" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the precision at the given recall. The threshold for the given recall value is computed and used to evaluate the corresponding precision.</source>
          <target state="translated">이 메트릭은 지정된 리콜에서 정밀도를 계산하는 데 사용되는 네 개의 로컬 변수 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성합니다. 주어진 리콜 값의 임계 값이 계산되어 해당 정밀도를 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="cd97f6783f485e9e31fe2474cb3ca5414d0a738b" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the recall at the given precision. The threshold for the given precision value is computed and used to evaluate the corresponding recall.</source>
          <target state="translated">This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the recall at the given precision. The threshold for the given precision value is computed and used to evaluate the corresponding recall.</target>
        </trans-unit>
        <trans-unit id="a469d6ce618a21614949a4828cde8383fb0456e0" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the sensitivity at the given specificity. The threshold for the given specificity value is computed and used to evaluate the corresponding sensitivity.</source>
          <target state="translated">이 메트릭은 주어진 특이성에서 민감도를 계산하는 데 사용되는 네 개의 로컬 변수 인 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성 합니다. 주어진 특이성 값에 대한 임계 값이 계산되어 해당 감도를 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="ff9252130946c80b57ae4c5ee9b47938ca02b839" translate="yes" xml:space="preserve">
          <source>This metric creates four local variables, &lt;code&gt;true_positives&lt;/code&gt;, &lt;code&gt;true_negatives&lt;/code&gt;, &lt;code&gt;false_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt; that are used to compute the specificity at the given sensitivity. The threshold for the given sensitivity value is computed and used to evaluate the corresponding specificity.</source>
          <target state="translated">이 메트릭은 주어진 감도에서 특이성을 계산하는 데 사용되는 네 가지 로컬 변수 인 &lt;code&gt;true_positives&lt;/code&gt; , &lt;code&gt;true_negatives&lt;/code&gt; , &lt;code&gt;false_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성합니다. 주어진 감도 값에 대한 임계 값이 계산되어 해당 특이성을 평가하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="fb652b4471c79604ae7dfb8ff87ca222abc482c6" translate="yes" xml:space="preserve">
          <source>This metric creates one variable, &lt;code&gt;total&lt;/code&gt;, that is used to compute the sum of &lt;code&gt;values&lt;/code&gt;. This is ultimately returned as &lt;code&gt;sum&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 &lt;code&gt;values&lt;/code&gt; 의 합계를 계산하는 데 사용되는 하나의 변수 &lt;code&gt;total&lt;/code&gt; 을 만듭니다 . 이것은 궁극적으로 &lt;code&gt;sum&lt;/code&gt; 로 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="77a69992763ecf548ab84fef5482d353d7a9cba3" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;y_pred&lt;/code&gt; matches &lt;code&gt;y_true&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;binary accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 통계는 두 지역 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 되는 빈도를 계산하는 데 사용되는 &lt;code&gt;y_pred&lt;/code&gt; 일치 &lt;code&gt;y_true&lt;/code&gt; 를 . 이 주파수는 궁극적으로 반환된다 &lt;code&gt;binary accuracy&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="10a549b6038018b3cebc025343c39cb24e67e040" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;y_pred&lt;/code&gt; matches &lt;code&gt;y_true&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;categorical accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 통계는 두 지역 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 되는 빈도를 계산하는 데 사용되는 &lt;code&gt;y_pred&lt;/code&gt; 일치 &lt;code&gt;y_true&lt;/code&gt; 를 . 이 주파수는 궁극적으로 반환된다 &lt;code&gt;categorical accuracy&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2d4e9dd5712eaf45fc10b998b8c6d4caf2e34bae" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the frequency with which &lt;code&gt;y_pred&lt;/code&gt; matches &lt;code&gt;y_true&lt;/code&gt;. This frequency is ultimately returned as &lt;code&gt;sparse categorical accuracy&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 통계는 두 지역 변수 생성 &lt;code&gt;total&lt;/code&gt; 과 &lt;code&gt;count&lt;/code&gt; 되는 빈도를 계산하는 데 사용되는 &lt;code&gt;y_pred&lt;/code&gt; 일치 &lt;code&gt;y_true&lt;/code&gt; 를 . 이 주파수는 궁극적으로 반환된다 &lt;code&gt;sparse categorical accuracy&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="300536328f19b08910251bd6b961009b9a37a3b7" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean relative absolute error. This average is weighted by &lt;code&gt;sample_weight&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_relative_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 평균 상대 절대 오차를 계산하는 데 사용되는 &lt;code&gt;total&lt;/code&gt; 와 &lt;code&gt;count&lt;/code&gt; 라는 두 개의 로컬 변수를 만듭니다 . 이 평균에 의해 가중된다 &lt;code&gt;sample_weight&lt;/code&gt; 하고, 궁극적으로 반환된다 &lt;code&gt;mean_relative_error&lt;/code&gt; : 단순히 분할가 멱등 동작 &lt;code&gt;total&lt;/code&gt; 로 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aea998ffd50f56931370c8f2e5952f5d92b92150" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean relative error. This is weighted by &lt;code&gt;sample_weight&lt;/code&gt;, and it is ultimately returned as &lt;code&gt;mean_relative_error&lt;/code&gt;: an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">This metric creates two local variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the mean relative error. This is weighted by &lt;code&gt;sample_weight&lt;/code&gt; , and it is ultimately returned as &lt;code&gt;mean_relative_error&lt;/code&gt; : an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0bf885c318184cc4d7f8536f5a3a6cfc0be45917" translate="yes" xml:space="preserve">
          <source>This metric creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;, that are used to compute the recall. This value is ultimately returned as &lt;code&gt;recall&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_negatives&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 재 호출을 계산하는 데 사용되는 두 개의 로컬 변수 &lt;code&gt;true_positives&lt;/code&gt; 및 &lt;code&gt;false_negatives&lt;/code&gt; 를 작성합니다. 이 값은 궁극적 으로 &lt;code&gt;true_positives&lt;/code&gt; 를 &lt;code&gt;true_positives&lt;/code&gt; 와 &lt;code&gt;false_negatives&lt;/code&gt; 의 합으로 나누는 dem 등원 연산 인 &lt;code&gt;recall&lt;/code&gt; 으로 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="093560f8538560280d9ed1cd9a3cab29a6cbb355" translate="yes" xml:space="preserve">
          <source>This metric creates two variables, &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;count&lt;/code&gt; that are used to compute the average of &lt;code&gt;values&lt;/code&gt;. This average is ultimately returned as &lt;code&gt;mean&lt;/code&gt; which is an idempotent operation that simply divides &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">이 메트릭은 &lt;code&gt;values&lt;/code&gt; 의 평균을 계산하는 데 사용되는 &lt;code&gt;total&lt;/code&gt; 와 &lt;code&gt;count&lt;/code&gt; 두 가지 변수를 만듭니다 . 이 평균은 궁극적으로 반환 &lt;code&gt;mean&lt;/code&gt; 단순히 분할가 멱등 동작되는 &lt;code&gt;total&lt;/code&gt; 의해 &lt;code&gt;count&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0c9b94b35f1d2e4eb96d2ecbbedfd0249ca4dde6" translate="yes" xml:space="preserve">
          <source>This metric keeps the average cosine similarity between &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt; over a stream of data.</source>
          <target state="translated">이 메트릭 은 데이터 스트림에 대한 &lt;code&gt;predictions&lt;/code&gt; 과 &lt;code&gt;labels&lt;/code&gt; 간의 평균 코사인 유사성을 유지합니다 .</target>
        </trans-unit>
        <trans-unit id="418d70f20044dbd3397385f2c468b1eaa3216144" translate="yes" xml:space="preserve">
          <source>This model accepts sparse float inputs as well:</source>
          <target state="translated">이 모델은 스파 스 플로트 입력도 허용합니다.</target>
        </trans-unit>
        <trans-unit id="3a4737a2c04c7eb94694e1e82664a0b0d934f20d" translate="yes" xml:space="preserve">
          <source>This model approximates the following function:</source>
          <target state="translated">이 모델은 다음 기능과 유사합니다.</target>
        </trans-unit>
        <trans-unit id="82e7fe60bedc5bc6c52d1131a24d660c1d1e5baf" translate="yes" xml:space="preserve">
          <source>This model jointly train a linear and a dnn model.</source>
          <target state="translated">이 모델은 선형 및 dnn 모델을 공동으로 학습합니다.</target>
        </trans-unit>
        <trans-unit id="e8ea575479c33e1d3b54efb7336850606e620ed3" translate="yes" xml:space="preserve">
          <source>This module contains experimental &lt;code&gt;Dataset&lt;/code&gt; sources and transformations that can be used in conjunction with the &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; API. Note that the &lt;a href=&quot;../../../data/experimental&quot;&gt;&lt;code&gt;tf.data.experimental&lt;/code&gt;&lt;/a&gt; API is not subject to the same backwards compatibility guarantees as &lt;a href=&quot;../../../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt;, but we will provide deprecation advice in advance of removing existing functionality.</source>
          <target state="translated">이 모듈에는 &lt;a href=&quot;../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; API 와 함께 사용할 수있는 실험 &lt;code&gt;Dataset&lt;/code&gt; 소스 및 변환 이 포함되어 있습니다 . 참고는 것을 &lt;a href=&quot;../../../data/experimental&quot;&gt; &lt;code&gt;tf.data.experimental&lt;/code&gt; &lt;/a&gt; API는 같은 이전 버전과의 호환성 보장이 적용되지 않습니다 &lt;a href=&quot;../../../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; , 그러나 우리는 기존 기능을 제거 사전에 중단 조언을 제공 할 것입니다.</target>
        </trans-unit>
        <trans-unit id="048da49888cbf092642d30c4a165ddde49bb4a0b" translate="yes" xml:space="preserve">
          <source>This module contains experimental &lt;code&gt;Dataset&lt;/code&gt; sources and transformations that can be used in conjunction with the &lt;a href=&quot;dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; API. Note that the &lt;a href=&quot;experimental&quot;&gt;&lt;code&gt;tf.data.experimental&lt;/code&gt;&lt;/a&gt; API is not subject to the same backwards compatibility guarantees as &lt;a href=&quot;../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt;, but we will provide deprecation advice in advance of removing existing functionality.</source>
          <target state="translated">이 모듈에는 &lt;a href=&quot;dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; API 와 함께 사용할 수있는 실험 &lt;code&gt;Dataset&lt;/code&gt; 소스 및 변환 이 포함되어 있습니다 . 참고는 것을 &lt;a href=&quot;experimental&quot;&gt; &lt;code&gt;tf.data.experimental&lt;/code&gt; &lt;/a&gt; API는 같은 이전 버전과의 호환성 보장이 적용되지 않습니다 &lt;a href=&quot;../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; , 그러나 우리는 기존 기능을 제거 사전에 중단 조언을 제공 할 것입니다.</target>
        </trans-unit>
        <trans-unit id="458fef549ca5bb1cdd37d04e9f0b5b8e3b96d46e" translate="yes" xml:space="preserve">
          <source>This must be called by the constructors of subclasses.</source>
          <target state="translated">서브 클래스의 생성자가 호출해야합니다.</target>
        </trans-unit>
        <trans-unit id="b854be37a7975d22746ea61f4632ebd3ee101333" translate="yes" xml:space="preserve">
          <source>This must be called by the constructors of subclasses. Note that Optimizer instances should not bind to a single graph, and so shouldn't keep Tensors as member variables. Generally you should be able to use the _set_hyper()/state.get_hyper() facility instead.</source>
          <target state="translated">서브 클래스의 생성자가 호출해야합니다. Optimizer 인스턴스는 단일 그래프에 바인딩되지 않아야하므로 Tensor를 멤버 변수로 유지해서는 안됩니다. 일반적으로 _set_hyper () / state.get_hyper () 기능을 대신 사용할 수 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="10ca194e65aab7cdbd21fa158a845dc67377d2ce" translate="yes" xml:space="preserve">
          <source>This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False.</source>
          <target state="translated">start ()를 호출하기 전에 설정해야하며, 그렇지 않으면 RuntimeError가 발생합니다. 초기 값은 작성 스레드에서 상속됩니다. 기본 스레드는 데몬 스레드가 아니므로 기본 스레드에서 작성된 모든 스레드의 기본값은 daemon = False입니다.</target>
        </trans-unit>
        <trans-unit id="0329801ef1692f0ddc2ae7e5af20ed6a131c6c7c" translate="yes" xml:space="preserve">
          <source>This only ensures that the data has made its way out of the process without any guarantees on whether it's written to disk. This means that the data would survive an application crash but not necessarily an OS crash.</source>
          <target state="translated">이렇게하면 데이터가 디스크에 기록되는지 여부에 대한 보장없이 데이터가 프로세스에서 벗어날 수 있습니다. 이는 데이터가 응용 프로그램 충돌에도 불구하고 OS 충돌 일 필요는 없음을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="739d09cc347d37887487c132a76071a68cf15e0c" translate="yes" xml:space="preserve">
          <source>This op accepts a ragged tensor with 1 ragged dimension containing only strings and outputs a ragged tensor with 1 ragged dimension containing ngrams of that string, joined along the innermost axis.</source>
          <target state="translated">This op accepts a ragged tensor with 1 ragged dimension containing only strings and outputs a ragged tensor with 1 ragged dimension containing ngrams of that string, joined along the innermost axis.</target>
        </trans-unit>
        <trans-unit id="93e1dc6b2d1103564814280c522ceb3f62da8aaa" translate="yes" xml:space="preserve">
          <source>This op adds entries with the specified &lt;code&gt;default_value&lt;/code&gt; at index &lt;code&gt;[row, 0]&lt;/code&gt; for any row in the input that does not already have a value.</source>
          <target state="translated">이 op는 값이없는 입력의 행에 대해 인덱스 &lt;code&gt;[row, 0]&lt;/code&gt; 에서 지정된 &lt;code&gt;default_value&lt;/code&gt; 를 가진 항목을 추가합니다 .</target>
        </trans-unit>
        <trans-unit id="5fa1114f375b9880e62fbc5a662e7acc5ce57fbe" translate="yes" xml:space="preserve">
          <source>This op also returns an indicator vector shaped &lt;code&gt;[dense_shape[0]]&lt;/code&gt; such that</source>
          <target state="translated">This op also returns an indicator vector shaped &lt;code&gt;[dense_shape[0]]&lt;/code&gt; such that</target>
        </trans-unit>
        <trans-unit id="9c96c116d1d672bbaf2e116ec518227e07309624" translate="yes" xml:space="preserve">
          <source>This op also returns an indicator vector such that</source>
          <target state="translated">이 op는 또한 지표 벡터를 반환하여</target>
        </trans-unit>
        <trans-unit id="63eba777b467e98e8d9a395e0dc5bdd68e038be1" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and PNGs, though it is cleaner to use &lt;a href=&quot;../io/decode_image&quot;&gt;&lt;code&gt;tf.io.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op also supports decoding JPEGs and PNGs, though it is cleaner to use &lt;a href=&quot;../io/decode_image&quot;&gt; &lt;code&gt;tf.io.decode_image&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="f0a295b7a7559c4062aef820bad409706b47254e" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and PNGs, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.image.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 연산은 JPEG 및 PNG 디코딩도 지원하지만 &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.image.decode_image&lt;/code&gt; &lt;/a&gt; 를 사용하는 것이 더 깨끗합니다 .</target>
        </trans-unit>
        <trans-unit id="483bb07454239e8342211e5a15919059fc6155be" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and PNGs, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.io.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op also supports decoding JPEGs and PNGs, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.io.decode_image&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="18fa4a39fc572b40f8f4dacf2470cf5be8ddff15" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;../io/decode_image&quot;&gt;&lt;code&gt;tf.io.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op also supports decoding JPEGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;../io/decode_image&quot;&gt; &lt;code&gt;tf.io.decode_image&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="7b09a5c52da344b1eb6cdb8c06bc391b1939c62f" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.image.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">인터페이스는 동일하지만 &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.image.decode_image&lt;/code&gt; &lt;/a&gt; 를 사용하는 것이 더 깨끗하기 때문에이 연산은 JPEG 및 애니메이션이없는 GIF 디코딩도 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="c9a007b21ccb02db71e5f851437184affd13ed0e" translate="yes" xml:space="preserve">
          <source>This op also supports decoding JPEGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.io.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op also supports decoding JPEGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.io.decode_image&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="5122fab2d6910f76eb99cdafcfcf3c05b7df8003" translate="yes" xml:space="preserve">
          <source>This op also supports decoding PNGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;../io/decode_image&quot;&gt;&lt;code&gt;tf.io.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op also supports decoding PNGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;../io/decode_image&quot;&gt; &lt;code&gt;tf.io.decode_image&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="42b9c8de7bcd9a44756c5acb1ef87661725abb7d" translate="yes" xml:space="preserve">
          <source>This op also supports decoding PNGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.image.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">인터페이스는 동일하지만 &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.image.decode_image&lt;/code&gt; &lt;/a&gt; 를 사용하는 것이 더 깨끗하므로 PNG 및 애니메이션이 아닌 GIF의 디코딩도 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="4126fd2328e7484c2f21d905e8ae694800311e37" translate="yes" xml:space="preserve">
          <source>This op also supports decoding PNGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt;&lt;code&gt;tf.io.decode_image&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op also supports decoding PNGs and non-animated GIFs since the interface is the same, though it is cleaner to use &lt;a href=&quot;decode_image&quot;&gt; &lt;code&gt;tf.io.decode_image&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="fd4491d1a6601d1e84570bcd363e85b0e7d5c12e" translate="yes" xml:space="preserve">
          <source>This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids (i.e. there are no rows with empty features), and that all the indices of sp_ids are in canonical row-major order.</source>
          <target state="translated">이 op는 sp_ids로 표시되는 조밀 한 텐서의 각 행에 대해 하나 이상의 id가 있고 (즉, 빈 피처가있는 행이 없음) sp_ids의 모든 인덱스가 표준 행 주요 순서에 있다고 가정합니다.</target>
        </trans-unit>
        <trans-unit id="ff99bdd028bae5711c127316ae24a743c30a9349" translate="yes" xml:space="preserve">
          <source>This op can be substantially more efficient than &lt;a href=&quot;case&quot;&gt;&lt;code&gt;tf.case&lt;/code&gt;&lt;/a&gt; when exactly one branch will be selected. &lt;a href=&quot;switch_case&quot;&gt;&lt;code&gt;tf.switch_case&lt;/code&gt;&lt;/a&gt; is more like a C++ switch/case statement than &lt;a href=&quot;case&quot;&gt;&lt;code&gt;tf.case&lt;/code&gt;&lt;/a&gt;, which is more like an if/elif/elif/else chain.</source>
          <target state="translated">이 연산은 정확히 하나의 브랜치를 선택할 때 &lt;a href=&quot;case&quot;&gt; &lt;code&gt;tf.case&lt;/code&gt; &lt;/a&gt; 보다 훨씬 효율적일 수 있습니다 . &lt;a href=&quot;switch_case&quot;&gt; &lt;code&gt;tf.switch_case&lt;/code&gt; 은&lt;/a&gt; 이상 C ++ 스위치 / case 문처럼 &lt;a href=&quot;case&quot;&gt; &lt;code&gt;tf.case&lt;/code&gt; &lt;/a&gt; 더는 IF / ELIF / ELIF / 다른 체인과 같다.</target>
        </trans-unit>
        <trans-unit id="88d4e65ada667e4924bd61aa913d0b719a3489bc" translate="yes" xml:space="preserve">
          <source>This op can be used to override the gradient for complicated functions. For example, suppose y = f(x) and we wish to apply a custom function g for backprop such that dx = g(dy). In Python,</source>
          <target state="translated">이 op는 복잡한 기능에 대한 그래디언트를 재정의하는 데 사용할 수 있습니다. 예를 들어, y = f (x)라고 가정하고 dx = g (dy)와 같은 백프로 프에 사용자 정의 함수 g를 적용하려고합니다. 파이썬에서</target>
        </trans-unit>
        <trans-unit id="a70d4bf94e1aa31fec2daa089308a302909ea19e" translate="yes" xml:space="preserve">
          <source>This op collects patches from the input image, as if applying a convolution. All extracted patches are stacked in the depth (last) dimension of the output.</source>
          <target state="translated">이 연산은 컨볼 루션을 적용하는 것처럼 입력 이미지에서 패치를 수집합니다. 추출 된 모든 패치는 출력의 깊이 (마지막) 치수에 쌓입니다.</target>
        </trans-unit>
        <trans-unit id="b607b039f446accd9cc9d66850f0e1a0f18bc805" translate="yes" xml:space="preserve">
          <source>This op consumes a lock created by &lt;code&gt;MutexLock&lt;/code&gt;.</source>
          <target state="translated">This op consumes a lock created by &lt;code&gt;MutexLock&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6c18dad5d5d6899466a10670d53475ca56625c85" translate="yes" xml:space="preserve">
          <source>This op converts between data types, scaling the values appropriately before casting.</source>
          <target state="translated">이 op는 데이터 유형간에 변환하여 캐스팅 전에 값을 적절하게 조정합니다.</target>
        </trans-unit>
        <trans-unit id="cc622534ae3fa62514818ea7bebb60dccd64c26d" translate="yes" xml:space="preserve">
          <source>This op creates a &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt;&lt;code&gt;Summary&lt;/code&gt;&lt;/a&gt; protocol buffer that contains the union of all the values in the input summaries.</source>
          <target state="translated">이 op 는 입력 요약에있는 모든 값의 합집합을 포함 하는 &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt; &lt;code&gt;Summary&lt;/code&gt; &lt;/a&gt; 프로토콜 버퍼를 만듭니다 .</target>
        </trans-unit>
        <trans-unit id="9d0ac8a3b320dffdcce993580747b2ce812c1930" translate="yes" xml:space="preserve">
          <source>This op creates a hash table, specifying the type of its keys and values. Before using the table you will have to initialize it. After initialization the table will be immutable.</source>
          <target state="translated">This op creates a hash table, specifying the type of its keys and values. Before using the table you will have to initialize it. After initialization the table will be immutable.</target>
        </trans-unit>
        <trans-unit id="656267a02d31eb1fe3e2f93fe32ae0ecba89ac70" translate="yes" xml:space="preserve">
          <source>This op creates a mutable hash table, specifying the type of its keys and values. Each value must be a scalar. Data can be inserted into the table using the insert operations. It does not support the initialization operation.</source>
          <target state="translated">This op creates a mutable hash table, specifying the type of its keys and values. Each value must be a scalar. Data can be inserted into the table using the insert operations. It does not support the initialization operation.</target>
        </trans-unit>
        <trans-unit id="889ef924ddf97837ebe886303d19b68a45247ddd" translate="yes" xml:space="preserve">
          <source>This op creates a mutable hash table, specifying the type of its keys and values. Each value must be a vector. Data can be inserted into the table using the insert operations. It does not support the initialization operation.</source>
          <target state="translated">This op creates a mutable hash table, specifying the type of its keys and values. Each value must be a vector. Data can be inserted into the table using the insert operations. It does not support the initialization operation.</target>
        </trans-unit>
        <trans-unit id="26981876c06a781e2a944a631697cc4482c0e90e" translate="yes" xml:space="preserve">
          <source>This op cuts a rectangular part out of &lt;code&gt;image&lt;/code&gt;. The top-left corner of the returned image is at &lt;code&gt;offset_height, offset_width&lt;/code&gt; in &lt;code&gt;image&lt;/code&gt;, and its lower-right corner is at &lt;code&gt;offset_height + target_height, offset_width + target_width&lt;/code&gt;.</source>
          <target state="translated">이 op는 &lt;code&gt;image&lt;/code&gt; 에서 직사각형 부분을 잘라냅니다 . 반환 된 이미지의 왼쪽 상단 모서리는 &lt;code&gt;offset_height, offset_width&lt;/code&gt; in &lt;code&gt;image&lt;/code&gt; 이며 오른쪽 하단 모서리는 &lt;code&gt;offset_height + target_height, offset_width + target_width&lt;/code&gt; 있습니다.</target>
        </trans-unit>
        <trans-unit id="b6b4a71613ffb1856f3dff1fb3fb7c9c68b7515a" translate="yes" xml:space="preserve">
          <source>This op decompresses each element of the &lt;code&gt;bytes&lt;/code&gt; input &lt;code&gt;Tensor&lt;/code&gt;, which is assumed to be compressed using the given &lt;code&gt;compression_type&lt;/code&gt;.</source>
          <target state="translated">이 op는 &lt;code&gt;bytes&lt;/code&gt; 입력 &lt;code&gt;Tensor&lt;/code&gt; 의 각 요소를 압축 해제 하는데, 이는 주어진 &lt;code&gt;compression_type&lt;/code&gt; 을 사용하여 압축 된 것으로 가정합니다 .</target>
        </trans-unit>
        <trans-unit id="3ca6b920060424a35214647a956bfc883925dbdc" translate="yes" xml:space="preserve">
          <source>This op determines the maximum scale_factor that would map the initial [input_min, input_max] range to a range that lies within the representable quantized range.</source>
          <target state="translated">This op determines the maximum scale_factor that would map the initial [input_min, input_max] range to a range that lies within the representable quantized range.</target>
        </trans-unit>
        <trans-unit id="9e56e06059315b7dda1620664824a84ff8d7bc3c" translate="yes" xml:space="preserve">
          <source>This op does not &lt;a href=&quot;https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html&quot;&gt;broadcast&lt;/a&gt; its inputs. If you need broadcasting, use &lt;a href=&quot;add&quot;&gt;&lt;code&gt;tf.math.add&lt;/code&gt;&lt;/a&gt; (or the &lt;code&gt;+&lt;/code&gt; operator) instead.</source>
          <target state="translated">이 op는 입력을 &lt;a href=&quot;https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html&quot;&gt;브로드 캐스트&lt;/a&gt; 하지 않습니다 . 브로드 캐스트가 필요한 경우 &lt;a href=&quot;add&quot;&gt; &lt;code&gt;tf.math.add&lt;/code&gt; &lt;/a&gt; (또는 &lt;code&gt;+&lt;/code&gt; 연산자)를 대신 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="32ac8411f8421961cf71053e4e574031251a142f" translate="yes" xml:space="preserve">
          <source>This op does nothing if &lt;code&gt;offset_*&lt;/code&gt; is zero and the image already has size &lt;code&gt;target_height&lt;/code&gt; by &lt;code&gt;target_width&lt;/code&gt;.</source>
          <target state="translated">이 op는 &lt;code&gt;offset_*&lt;/code&gt; 가 0이고 이미지의 크기가 &lt;code&gt;target_height&lt;/code&gt; by &lt;code&gt;target_width&lt;/code&gt; 인 경우 아무 것도 수행하지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="59b86b1f9adf8ca0901c6f9e9aeaabfe44733a8c" translate="yes" xml:space="preserve">
          <source>This op exists to consume a tensor created by &lt;code&gt;MutexLock&lt;/code&gt; (other than direct control dependencies). It should be the only that consumes the tensor, and will raise an error if it is not. Its only purpose is to keep the mutex lock tensor alive until it is consumed by this op.</source>
          <target state="translated">This op exists to consume a tensor created by &lt;code&gt;MutexLock&lt;/code&gt; (other than direct control dependencies). It should be the only that consumes the tensor, and will raise an error if it is not. Its only purpose is to keep the mutex lock tensor alive until it is consumed by this op.</target>
        </trans-unit>
        <trans-unit id="fd2475b0227c59a4b9b579ebadb0eb003bb5c048" translate="yes" xml:space="preserve">
          <source>This op expects to receive audio data as an input, stored as floats in the range -1 to 1, together with a window width in samples, and a stride specifying how far to move the window between slices. From this it generates a three dimensional output. The first dimension is for the channels in the input, so a stereo audio input would have two here for example. The second dimension is time, with successive frequency slices. The third dimension has an amplitude value for each frequency during that time slice.</source>
          <target state="translated">This op expects to receive audio data as an input, stored as floats in the range -1 to 1, together with a window width in samples, and a stride specifying how far to move the window between slices. From this it generates a three dimensional output. The first dimension is for the channels in the input, so a stereo audio input would have two here for example. The second dimension is time, with successive frequency slices. The third dimension has an amplitude value for each frequency during that time slice.</target>
        </trans-unit>
        <trans-unit id="25438ddc9615e500386687f63662f19536c3cd65" translate="yes" xml:space="preserve">
          <source>This op first slices &lt;code&gt;input&lt;/code&gt; along the dimension &lt;code&gt;batch_axis&lt;/code&gt;, and for each slice &lt;code&gt;i&lt;/code&gt;, reverses the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; elements along the dimension &lt;code&gt;seq_axis&lt;/code&gt;.</source>
          <target state="translated">이 op 우선 슬라이스 는 &lt;code&gt;batch_axis&lt;/code&gt; 차원을 따라 &lt;code&gt;input&lt;/code&gt; 을 분할 하고 각 슬라이스 &lt;code&gt;i&lt;/code&gt; 에 대해 차원 seq_axis를 따라 첫 번째 &lt;code&gt;seq_lengths[i]&lt;/code&gt; 요소를 반전 &lt;code&gt;seq_axis&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5c2da47231c9225efc906681c480ffa9fdcb8257" translate="yes" xml:space="preserve">
          <source>This op first slices &lt;code&gt;input&lt;/code&gt; along the dimension &lt;code&gt;batch_dim&lt;/code&gt;, and for each slice &lt;code&gt;i&lt;/code&gt;, reverses the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; elements along the dimension &lt;code&gt;seq_dim&lt;/code&gt;.</source>
          <target state="translated">This op first slices &lt;code&gt;input&lt;/code&gt; along the dimension &lt;code&gt;batch_dim&lt;/code&gt; , and for each slice &lt;code&gt;i&lt;/code&gt; , reverses the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; elements along the dimension &lt;code&gt;seq_dim&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4fb605b6d0eb10d714ac2254180881c3166d465a" translate="yes" xml:space="preserve">
          <source>This op implements the CTC loss as presented in (Graves et al., 2006).</source>
          <target state="translated">This op implements the CTC loss as presented in (Graves et al., 2006).</target>
        </trans-unit>
        <trans-unit id="0d8869736a8a0caa172690fd78df7a0c80acf40c" translate="yes" xml:space="preserve">
          <source>This op implements the CTC loss as presented in (Graves et al., 2016).</source>
          <target state="translated">This op implements the CTC loss as presented in (Graves et al., 2016).</target>
        </trans-unit>
        <trans-unit id="d7225b3ea22ec4deb1adfd4a695bd1a7623e154b" translate="yes" xml:space="preserve">
          <source>This op implements the CTC loss as presented in the article:</source>
          <target state="translated">이 op는 기사에 제시된대로 CTC 손실을 구현합니다.</target>
        </trans-unit>
        <trans-unit id="6fcde341bc16f91f21275b0c9eb0d836f06faca1" translate="yes" xml:space="preserve">
          <source>This op inserts a single entry for every row that doesn't have any values. The index is created as &lt;code&gt;[row, 0, ..., 0]&lt;/code&gt; and the inserted value is &lt;code&gt;default_value&lt;/code&gt;.</source>
          <target state="translated">This op inserts a single entry for every row that doesn't have any values. The index is created as &lt;code&gt;[row, 0, ..., 0]&lt;/code&gt; and the inserted value is &lt;code&gt;default_value&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2221b86f1776b0a82d12fa22eaebb9f19fcdaeda" translate="yes" xml:space="preserve">
          <source>This op is a convenience wrapper around &lt;code&gt;sparse_to_dense&lt;/code&gt; for &lt;code&gt;SparseTensor&lt;/code&gt;s.</source>
          <target state="translated">이 연산은 약 래퍼 편의입니다 &lt;code&gt;sparse_to_dense&lt;/code&gt; 에 대한 &lt;code&gt;SparseTensor&lt;/code&gt; 의.</target>
        </trans-unit>
        <trans-unit id="9bcf7c2af4594b54e144cbf824cb1c395a0dff7e" translate="yes" xml:space="preserve">
          <source>This op is being phased out in favor of TensorSummaryV2, which lets callers pass a tag as well as a serialized SummaryMetadata proto string that contains plugin-specific data. We will keep this op to maintain backwards compatibility.</source>
          <target state="translated">This op is being phased out in favor of TensorSummaryV2, which lets callers pass a tag as well as a serialized SummaryMetadata proto string that contains plugin-specific data. We will keep this op to maintain backwards compatibility.</target>
        </trans-unit>
        <trans-unit id="498581ecde1f847b44ae5faacdf090686c5a82aa" translate="yes" xml:space="preserve">
          <source>This op is conceptually identical to,</source>
          <target state="translated">이 op는 개념적으로 동일합니다.</target>
        </trans-unit>
        <trans-unit id="e11c482ba528e17a7aaf9d69ed66f29f71a93708" translate="yes" xml:space="preserve">
          <source>This op is deprecated and will be removed in the future. Prefer &lt;a href=&quot;../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op is deprecated and will be removed in the future. Prefer &lt;a href=&quot;../nn/batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="939958da045f886ccce510657fd3f21292de978d" translate="yes" xml:space="preserve">
          <source>This op is deprecated. Prefer &lt;a href=&quot;../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op is deprecated. Prefer &lt;a href=&quot;../nn/batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="d1fddd748b0417b58ea1729816edada8cf15be10" translate="yes" xml:space="preserve">
          <source>This op is deprecated. See &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 op는 더 이상 사용되지 않습니다. &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; 을&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="faec970c7a84c7f84287e5993964bd296d88974e" translate="yes" xml:space="preserve">
          <source>This op is deprecated. See &lt;a href=&quot;../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This op is deprecated. See &lt;a href=&quot;../nn/batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="350e179bf73709c36862e34c13946cb30d6be41a" translate="yes" xml:space="preserve">
          <source>This op is deprecated. See &lt;a href=&quot;batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 op는 더 이상 사용되지 않습니다. &lt;a href=&quot;batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; 을&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="f5f21db00ede271aa47c92ca1afb2548ebae0215" translate="yes" xml:space="preserve">
          <source>This op is equivalent to applying the normal &lt;a href=&quot;../nn/softmax&quot;&gt;&lt;code&gt;tf.nn.softmax()&lt;/code&gt;&lt;/a&gt; to each innermost logical submatrix with shape &lt;code&gt;[B, C]&lt;/code&gt;, but with the catch that &lt;em&gt;the implicitly zero elements do not participate&lt;/em&gt;. Specifically, the algorithm is equivalent to the following:</source>
          <target state="translated">This op is equivalent to applying the normal &lt;a href=&quot;../nn/softmax&quot;&gt; &lt;code&gt;tf.nn.softmax()&lt;/code&gt; &lt;/a&gt; to each innermost logical submatrix with shape &lt;code&gt;[B, C]&lt;/code&gt; , but with the catch that &lt;em&gt;the implicitly zero elements do not participate&lt;/em&gt;. Specifically, the algorithm is equivalent to the following:</target>
        </trans-unit>
        <trans-unit id="bfe73bfb3165baeb1cd799227e5df39e5edc40e8" translate="yes" xml:space="preserve">
          <source>This op is equivalent to applying the normal &lt;a href=&quot;../nn/softmax&quot;&gt;&lt;code&gt;tf.nn.softmax()&lt;/code&gt;&lt;/a&gt; to each innermost logical submatrix with shape &lt;code&gt;[B, C]&lt;/code&gt;, but with the catch that &lt;em&gt;the implicitly zero elements do not participate&lt;/em&gt;. Specifically, the algorithm is equivalent to:</source>
          <target state="translated">이 op는 모양이 &lt;code&gt;[B, C]&lt;/code&gt; 인 각 가장 안쪽의 논리 서브 매트릭스에 일반 &lt;a href=&quot;../nn/softmax&quot;&gt; &lt;code&gt;tf.nn.softmax()&lt;/code&gt; &lt;/a&gt; 를 적용하는 것과 동일 하지만 &lt;em&gt;내재적으로 0 개의 요소가 참여하지 않는&lt;/em&gt; 캐치가 있습니다. 특히 알고리즘은 다음과 같습니다.&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="9f3c57195c3a48d6087d2de6a616b3e7ac7825fb" translate="yes" xml:space="preserve">
          <source>This op is hidden from public in Python. It is used by TensorFlow Debugger to register gradient tensors for gradient debugging. This op operates on non-reference-type tensors.</source>
          <target state="translated">This op is hidden from public in Python. It is used by TensorFlow Debugger to register gradient tensors for gradient debugging. This op operates on non-reference-type tensors.</target>
        </trans-unit>
        <trans-unit id="5208058dc424b56d5683c09cc9ca79f806771d57" translate="yes" xml:space="preserve">
          <source>This op is hidden from public in Python. It is used by TensorFlow Debugger to register gradient tensors for gradient debugging. This op operates on reference-type tensors.</source>
          <target state="translated">This op is hidden from public in Python. It is used by TensorFlow Debugger to register gradient tensors for gradient debugging. This op operates on reference-type tensors.</target>
        </trans-unit>
        <trans-unit id="42f43d3073e8761b09396618e2f19e046d1dc61b" translate="yes" xml:space="preserve">
          <source>This op is meant only for debugging / testing, and its interface is not expected to be stable.</source>
          <target state="translated">This op is meant only for debugging / testing, and its interface is not expected to be stable.</target>
        </trans-unit>
        <trans-unit id="cf3e5eda158a5f12c2f2da1b9b93833d5ff71185" translate="yes" xml:space="preserve">
          <source>This op is only defined for complex matrices. If A is positive-definite and real, then casting to a complex matrix, taking the logarithm and casting back to a real matrix will give the correct result.</source>
          <target state="translated">이 op는 복잡한 행렬에 대해서만 정의됩니다. A가 양의 정답이고 실수 인 경우 복잡한 행렬로 캐스팅하고 로그를 취하고 실제 행렬로 다시 캐스팅하면 올바른 결과를 얻을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b4088dd89f372d9134efcda4f21dccb2a4e43e51" translate="yes" xml:space="preserve">
          <source>This op is similar to &lt;code&gt;tf.strings.decode(...)&lt;/code&gt;, but it also returns the start offset for each character in its respective string. This information can be used to align the characters with the original byte sequence.</source>
          <target state="translated">이 op는 &lt;code&gt;tf.strings.decode(...)&lt;/code&gt; 와 비슷 하지만 각 문자열에서 각 문자의 시작 오프셋을 반환합니다. 이 정보를 사용하여 문자를 원래 바이트 순서에 맞출 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="231193f912eb9ecede37b6d2bd24ac7965dab82e" translate="yes" xml:space="preserve">
          <source>This op is used as a placeholder in If branch functions. It doesn't provide a</source>
          <target state="translated">This op is used as a placeholder in If branch functions. It doesn't provide a</target>
        </trans-unit>
        <trans-unit id="30dc65726d5913cc5cf094798e27be8207b68832" translate="yes" xml:space="preserve">
          <source>This op is used during session initialization when a Scaffold is initialized without specifying the local_init_op arg. It includes &lt;a href=&quot;../local_variables_initializer&quot;&gt;&lt;code&gt;tf.compat.v1.local_variables_initializer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../tables_initializer&quot;&gt;&lt;code&gt;tf.compat.v1.tables_initializer&lt;/code&gt;&lt;/a&gt;, and also initializes local session resources.</source>
          <target state="translated">이 op는 local_init_op arg를 지정하지 않고 스캐 폴드를 초기화 할 때 세션 초기화 중에 사용됩니다. &lt;a href=&quot;../local_variables_initializer&quot;&gt; &lt;code&gt;tf.compat.v1.local_variables_initializer&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;../tables_initializer&quot;&gt; &lt;code&gt;tf.compat.v1.tables_initializer&lt;/code&gt; 를&lt;/a&gt; 포함 하고 로컬 세션 자원을 초기화합니다.</target>
        </trans-unit>
        <trans-unit id="27d759b10e3031b72c69cecb21d0a5f2a1e56b50" translate="yes" xml:space="preserve">
          <source>This op is used together with &lt;code&gt;Exit&lt;/code&gt; to create loops in the graph. The unique &lt;code&gt;frame_name&lt;/code&gt; is used by the &lt;code&gt;Executor&lt;/code&gt; to identify frames. If &lt;code&gt;is_constant&lt;/code&gt; is true, &lt;code&gt;output&lt;/code&gt; is a constant in the child frame; otherwise it may be changed in the child frame. At most &lt;code&gt;parallel_iterations&lt;/code&gt; iterations are run in parallel in the child frame.</source>
          <target state="translated">This op is used together with &lt;code&gt;Exit&lt;/code&gt; to create loops in the graph. The unique &lt;code&gt;frame_name&lt;/code&gt; is used by the &lt;code&gt;Executor&lt;/code&gt; to identify frames. If &lt;code&gt;is_constant&lt;/code&gt; is true, &lt;code&gt;output&lt;/code&gt; is a constant in the child frame; otherwise it may be changed in the child frame. At most &lt;code&gt;parallel_iterations&lt;/code&gt; iterations are run in parallel in the child frame.</target>
        </trans-unit>
        <trans-unit id="4d539ed4cc2d3820ae7fed70f08ee95780da8755" translate="yes" xml:space="preserve">
          <source>This op may use some OS-provided source of non-determinism (e.g. an RNG), so each execution will give different results.</source>
          <target state="translated">This op may use some OS-provided source of non-determinism (e.g. an RNG), so each execution will give different results.</target>
        </trans-unit>
        <trans-unit id="7494eb2e4d00b6f1a2a80a896b2a97c11ea84bbb" translate="yes" xml:space="preserve">
          <source>This op only parses the image header, so it is much faster than DecodeJpeg.</source>
          <target state="translated">이 op는 이미지 헤더 만 구문 분석하므로 DecodeJpeg보다 훨씬 빠릅니다.</target>
        </trans-unit>
        <trans-unit id="256678fd9ba7a89e98c94dad29bebb27865a6123" translate="yes" xml:space="preserve">
          <source>This op parses a serialized sequence example into a tuple of dictionaries, each mapping keys to &lt;code&gt;Tensor&lt;/code&gt; and &lt;code&gt;SparseTensor&lt;/code&gt; objects. The first dictionary contains mappings for keys appearing in &lt;code&gt;context_features&lt;/code&gt;, and the second dictionary contains mappings for keys appearing in &lt;code&gt;sequence_features&lt;/code&gt;.</source>
          <target state="translated">이 op는 직렬화 된 시퀀스 예제를 사전의 튜플로 구문 분석합니다. 각 &lt;code&gt;SparseTensor&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 및 SparseTensor 객체에 매핑 됩니다. 첫 번째 사전에는 &lt;code&gt;context_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함되고 두 번째 사전에는 &lt;code&gt;sequence_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함 됩니다 .</target>
        </trans-unit>
        <trans-unit id="b74d19b6cde7e379b7fc76473e78e58968efe064" translate="yes" xml:space="preserve">
          <source>This op parses serialized examples into a dictionary mapping keys to &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, and &lt;code&gt;RaggedTensor&lt;/code&gt; objects. &lt;code&gt;features&lt;/code&gt; is a dict from keys to &lt;code&gt;VarLenFeature&lt;/code&gt;, &lt;code&gt;RaggedFeature&lt;/code&gt;, &lt;code&gt;SparseFeature&lt;/code&gt;, and &lt;code&gt;FixedLenFeature&lt;/code&gt; objects. Each &lt;code&gt;VarLenFeature&lt;/code&gt; and &lt;code&gt;SparseFeature&lt;/code&gt; is mapped to a &lt;code&gt;SparseTensor&lt;/code&gt;; each &lt;code&gt;RaggedFeature&lt;/code&gt; is mapped to a &lt;code&gt;RaggedTensor&lt;/code&gt;; and each &lt;code&gt;FixedLenFeature&lt;/code&gt; is mapped to a &lt;code&gt;Tensor&lt;/code&gt;. See &lt;a href=&quot;../../io/parse_example&quot;&gt;&lt;code&gt;tf.io.parse_example&lt;/code&gt;&lt;/a&gt; for more details about feature dictionaries.</source>
          <target state="translated">이 op는 직렬화 된 예제를 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; 및 &lt;code&gt;RaggedTensor&lt;/code&gt; 오브젝트 에 대한 사전 맵핑 키로 구문 분석 합니다. &lt;code&gt;features&lt;/code&gt; 은 키에서 &lt;code&gt;VarLenFeature&lt;/code&gt; , &lt;code&gt;RaggedFeature&lt;/code&gt; , &lt;code&gt;SparseFeature&lt;/code&gt; 및 &lt;code&gt;FixedLenFeature&lt;/code&gt; 객체에 대한 사전입니다 . 각 &lt;code&gt;VarLenFeature&lt;/code&gt; 및 &lt;code&gt;SparseFeature&lt;/code&gt; 는 A와 매핑되는 &lt;code&gt;SparseTensor&lt;/code&gt; ; 각 &lt;code&gt;RaggedFeature&lt;/code&gt; 는 (A)에 맵핑된다 &lt;code&gt;RaggedTensor&lt;/code&gt; ; 각 &lt;code&gt;FixedLenFeature&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 에 매핑됩니다 . &lt;a href=&quot;../../io/parse_example&quot;&gt; &lt;code&gt;tf.io.parse_example&lt;/code&gt; &lt;/a&gt; 참조 기능 사전에 대한 자세한 내용은</target>
        </trans-unit>
        <trans-unit id="845b399d2e9c5818b169dacff650d84da1b8a72a" translate="yes" xml:space="preserve">
          <source>This op parses serialized examples into a dictionary mapping keys to &lt;code&gt;Tensor&lt;/code&gt;&lt;code&gt;SparseTensor&lt;/code&gt;, and &lt;code&gt;RaggedTensor&lt;/code&gt; objects. &lt;code&gt;features&lt;/code&gt; is a dict from keys to &lt;code&gt;VarLenFeature&lt;/code&gt;, &lt;code&gt;SparseFeature&lt;/code&gt;, &lt;code&gt;RaggedFeature&lt;/code&gt;, and &lt;code&gt;FixedLenFeature&lt;/code&gt; objects. Each &lt;code&gt;VarLenFeature&lt;/code&gt; and &lt;code&gt;SparseFeature&lt;/code&gt; is mapped to a &lt;code&gt;SparseTensor&lt;/code&gt;; each &lt;code&gt;FixedLenFeature&lt;/code&gt; is mapped to a &lt;code&gt;Tensor&lt;/code&gt;; and each &lt;code&gt;RaggedFeature&lt;/code&gt; is mapped to a &lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="translated">이 op는 직렬화 된 예제를 &lt;code&gt;Tensor&lt;/code&gt; &lt;code&gt;SparseTensor&lt;/code&gt; 및 &lt;code&gt;RaggedTensor&lt;/code&gt; 오브젝트 에 대한 사전 맵핑 키로 구문 분석 합니다. &lt;code&gt;features&lt;/code&gt; 은 키에서 &lt;code&gt;VarLenFeature&lt;/code&gt; , &lt;code&gt;SparseFeature&lt;/code&gt; , &lt;code&gt;RaggedFeature&lt;/code&gt; 및 &lt;code&gt;FixedLenFeature&lt;/code&gt; 객체에 대한 사전입니다 . 각 &lt;code&gt;VarLenFeature&lt;/code&gt; 및 &lt;code&gt;SparseFeature&lt;/code&gt; 는 A와 매핑되는 &lt;code&gt;SparseTensor&lt;/code&gt; ; 각 &lt;code&gt;FixedLenFeature&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 에 맵핑됩니다 . 각 &lt;code&gt;RaggedFeature&lt;/code&gt; 는 A와 매핑되는 &lt;code&gt;RaggedTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="787b46fef668ea2442d8cf59e886173e8f1beeb1" translate="yes" xml:space="preserve">
          <source>This op parses serialized sequence examples into a tuple of dictionaries, each mapping keys to &lt;code&gt;Tensor&lt;/code&gt; and &lt;code&gt;SparseTensor&lt;/code&gt; objects. The first dictionary contains mappings for keys appearing in &lt;code&gt;context_features&lt;/code&gt;, and the second dictionary contains mappings for keys appearing in &lt;code&gt;sequence_features&lt;/code&gt;.</source>
          <target state="translated">이 op는 직렬화 된 시퀀스 예제를 튜플 사전으로 구문 분석 합니다. 각 &lt;code&gt;SparseTensor&lt;/code&gt; 는 &lt;code&gt;Tensor&lt;/code&gt; 및 SparseTensor 객체에 매핑 됩니다. 첫 번째 사전에는 &lt;code&gt;context_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함되고 두 번째 사전에는 &lt;code&gt;sequence_features&lt;/code&gt; 에 나타나는 키에 대한 매핑이 포함 됩니다 .</target>
        </trans-unit>
        <trans-unit id="4fe7f65a801aad08671f34a64293fcb18c9780f3" translate="yes" xml:space="preserve">
          <source>This op produces Region of Interests from given bounding boxes(bbox_deltas) encoded wrt anchors according to eq.2 in arXiv:1506.01497</source>
          <target state="translated">This op produces Region of Interests from given bounding boxes(bbox_deltas) encoded wrt anchors according to eq.2 in arXiv:1506.01497</target>
        </trans-unit>
        <trans-unit id="4ca1b1701aa5c064253c44ce1aad741cb653df7b" translate="yes" xml:space="preserve">
          <source>This op reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if any value is not finite.</source>
          <target state="translated">이 op는 값이 유한하지 않은 경우 &lt;code&gt;InvalidArgument&lt;/code&gt; 오류를 보고합니다 .</target>
        </trans-unit>
        <trans-unit id="a524bdef26722689a646035ff3a30a89b59c896f" translate="yes" xml:space="preserve">
          <source>This op runs in &lt;code&gt;O(M log M)&lt;/code&gt; time, where &lt;code&gt;M&lt;/code&gt; is the total number of non-empty values across all inputs. This is due to the need for an internal sort in order to concatenate efficiently across an arbitrary dimension.</source>
          <target state="translated">이 op는 &lt;code&gt;O(M log M)&lt;/code&gt; 시간으로 실행되며 여기서 &lt;code&gt;M&lt;/code&gt; 은 모든 입력에서 비어 있지 않은 값의 총 수입니다. 이는 임의의 차원에서 효율적으로 연결하기 위해 내부 정렬이 필요하기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="7aad9bcdb175c316d0cd0c518023c08cbf3d7ccf" translate="yes" xml:space="preserve">
          <source>This op simply returns its first input, which is assumed to have been sliced from the Tensors returned by TPUEmbeddingDequeueActivations. The presence of this op, and its first argument being a trainable Variable, enables automatic differentiation of graphs containing embeddings via the TPU Embedding Python libraries.</source>
          <target state="translated">This op simply returns its first input, which is assumed to have been sliced from the Tensors returned by TPUEmbeddingDequeueActivations. The presence of this op, and its first argument being a trainable Variable, enables automatic differentiation of graphs containing embeddings via the TPU Embedding Python libraries.</target>
        </trans-unit>
        <trans-unit id="d483631861e7a19423d30b1c89ca7bd9af9deb77" translate="yes" xml:space="preserve">
          <source>This op simulates the precision loss from the quantized forward pass by:</source>
          <target state="translated">This op simulates the precision loss from the quantized forward pass by:</target>
        </trans-unit>
        <trans-unit id="82f92515415e66dd8fe55e82e86a429d52767b5f" translate="yes" xml:space="preserve">
          <source>This op takes an N-dimensional &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;RaggedTensor&lt;/code&gt;, or &lt;code&gt;SparseTensor&lt;/code&gt;, and returns an N-dimensional int64 SparseTensor where element &lt;code&gt;[i0...i[axis], j]&lt;/code&gt; contains the number of times the value &lt;code&gt;j&lt;/code&gt; appears in slice &lt;code&gt;[i0...i[axis], :]&lt;/code&gt; of the input tensor. Currently, only N=0 and N=-1 are supported.</source>
          <target state="translated">This op takes an N-dimensional &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;RaggedTensor&lt;/code&gt; , or &lt;code&gt;SparseTensor&lt;/code&gt; , and returns an N-dimensional int64 SparseTensor where element &lt;code&gt;[i0...i[axis], j]&lt;/code&gt; contains the number of times the value &lt;code&gt;j&lt;/code&gt; appears in slice &lt;code&gt;[i0...i[axis], :]&lt;/code&gt; of the input tensor. Currently, only N=0 and N=-1 are supported.</target>
        </trans-unit>
        <trans-unit id="ad5fa7632826618c2d76f2d4a4592c97b627433a" translate="yes" xml:space="preserve">
          <source>This op takes in the upstream gradient w.r.t. non-empty values of the sliced &lt;code&gt;SparseTensor&lt;/code&gt;, and outputs the gradients w.r.t. the non-empty values of input &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="translated">This op takes in the upstream gradient w.r.t. non-empty values of the sliced &lt;code&gt;SparseTensor&lt;/code&gt; , and outputs the gradients w.r.t. the non-empty values of input &lt;code&gt;SparseTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="edecba4e86376242d273ba622ca63b2965a5a438" translate="yes" xml:space="preserve">
          <source>This op translates a tensor containing Example records, encoded using the &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#json&quot;&gt;standard JSON mapping&lt;/a&gt;, into a tensor containing the same records encoded as binary protocol buffers. The resulting tensor can then be fed to any of the other Example-parsing ops.</source>
          <target state="translated">이 op는 &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#json&quot;&gt;표준 JSON 매핑을&lt;/a&gt; 사용하여 인코딩 된 Example 레코드를 포함 하는 텐서를 이진 프로토콜 버퍼와 인코딩 된 동일한 레코드를 포함하는 텐서로 변환합니다. 그런 다음 결과 텐서는 다른 예제 구문 분석 작업에 제공 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="aed6dcb7e60458715d6ef5c3c8eddc95029d6141" translate="yes" xml:space="preserve">
          <source>This op uses the algorithm by Marsaglia et al. to acquire samples via transformation-rejection from pairs of uniform and normal random variables. See &lt;a href=&quot;http://dl.acm.org/citation.cfm?id=358414&quot;&gt;http://dl.acm.org/citation.cfm?id=358414&lt;/a&gt;</source>
          <target state="translated">This op uses the algorithm by Marsaglia et al. to acquire samples via transformation-rejection from pairs of uniform and normal random variables. See &lt;a href=&quot;http://dl.acm.org/citation.cfm?id=358414&quot;&gt;http://dl.acm.org/citation.cfm?id=358414&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c381caf80ba3167793d4166edbbb6bfbc8d1b9b9" translate="yes" xml:space="preserve">
          <source>This op uses two algorithms, depending on rate. If rate &amp;gt;= 10, then the algorithm by Hormann is used to acquire samples via transformation-rejection. See &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/0167668793909974&quot;&gt;http://www.sciencedirect.com/science/article/pii/0167668793909974&lt;/a&gt;</source>
          <target state="translated">This op uses two algorithms, depending on rate. If rate &amp;gt;= 10, then the algorithm by Hormann is used to acquire samples via transformation-rejection. See &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/0167668793909974&quot;&gt;http://www.sciencedirect.com/science/article/pii/0167668793909974&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="49b534f6ddaaf2bd4e7772b31b4be9cf92fcfbd7" translate="yes" xml:space="preserve">
          <source>This operation blocks until that finishes.</source>
          <target state="translated">이 작업은 완료 될 때까지 차단됩니다.</target>
        </trans-unit>
        <trans-unit id="14d876872d62a220ab5753fd3b852a5a6bcb76ef" translate="yes" xml:space="preserve">
          <source>This operation can be used with &lt;code&gt;output_encoding = input_encoding&lt;/code&gt; to enforce correct formatting for inputs even if they are already in the desired encoding.</source>
          <target state="translated">이 연산은 &lt;code&gt;output_encoding = input_encoding&lt;/code&gt; 과 함께 사용하여 입력이 이미 원하는 인코딩으로되어 있어도 입력에 올바른 형식을 적용 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="bf8af72c7ec5c03a0a302901ae0b02f8840934f4" translate="yes" xml:space="preserve">
          <source>This operation computes</source>
          <target state="translated">이 작업은 계산</target>
        </trans-unit>
        <trans-unit id="df2c8f127a35805203dd552ccd88657669212f89" translate="yes" xml:space="preserve">
          <source>This operation computes the inverse of an index permutation. It takes a 1-D integer tensor &lt;code&gt;x&lt;/code&gt;, which represents the indices of a zero-based array, and swaps each value with its index position. In other words, for an output tensor &lt;code&gt;y&lt;/code&gt; and an input tensor &lt;code&gt;x&lt;/code&gt;, this operation computes the following:</source>
          <target state="translated">이 연산은 인덱스 순열의 역수를 계산합니다. 0부터 시작하는 배열의 인덱스를 나타내는 1 차원 정수 텐서 &lt;code&gt;x&lt;/code&gt; 를 취하고 각 값을 인덱스 위치로 바꿉니다. 다시 말해, 출력 텐서 &lt;code&gt;y&lt;/code&gt; 및 입력 텐서 &lt;code&gt;x&lt;/code&gt; 의 경우이 작업은 다음을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="9ce96baa1d2aec98a8f7f3b28803c0d5bf74ec4e" translate="yes" xml:space="preserve">
          <source>This operation concatenates completed-element component tensors along the 0th dimension to make a single component tensor.</source>
          <target state="translated">This operation concatenates completed-element component tensors along the 0th dimension to make a single component tensor.</target>
        </trans-unit>
        <trans-unit id="d8b4d24b16bc4a84c7216a06caa8665f602e4b2d" translate="yes" xml:space="preserve">
          <source>This operation concatenates queue-element component tensors along the 0th dimension to make a single component tensor. All of the components in the dequeued tuple will have size &lt;code&gt;n&lt;/code&gt; in the 0th dimension.</source>
          <target state="translated">이 작업은 단일 요소 텐서를 만들기 위해 0 차원을 따라 큐 요소 구성 요소 텐서를 연결합니다. 디큐 튜플의 모든 구성 요소는 크기가됩니다 &lt;code&gt;n&lt;/code&gt; 은 0 번째 차원을.</target>
        </trans-unit>
        <trans-unit id="45d38aafbd1acaa44920f79c8c0c3ecc6bbcdeda" translate="yes" xml:space="preserve">
          <source>This operation concatenates queue-element component tensors along the 0th dimension to make a single component tensor. All of the components in the dequeued tuple will have size n in the 0th dimension.</source>
          <target state="translated">This operation concatenates queue-element component tensors along the 0th dimension to make a single component tensor. All of the components in the dequeued tuple will have size n in the 0th dimension.</target>
        </trans-unit>
        <trans-unit id="50e9d3be55bb6834daac8ca12d0b390851428378" translate="yes" xml:space="preserve">
          <source>This operation concatenates queue-element component tensors along the 0th dimension to make a single component tensor. If the queue has not been closed, all of the components in the dequeued tuple will have size &lt;code&gt;n&lt;/code&gt; in the 0th dimension.</source>
          <target state="translated">이 작업은 단일 요소 텐서를 만들기 위해 0 차원을 따라 큐 요소 구성 요소 텐서를 연결합니다. 큐가 폐쇄되지 않은 경우, 대기열 튜플의 모든 구성 요소는 크기가됩니다 &lt;code&gt;n&lt;/code&gt; 은 0 번째 차원을.</target>
        </trans-unit>
        <trans-unit id="15bf39234c37f046f148fb34f3d92a5f21991cd5" translate="yes" xml:space="preserve">
          <source>This operation converts Unicode code points to script codes corresponding to each code point. Script codes correspond to International Components for Unicode (ICU) UScriptCode values. See &lt;a href=&quot;http://icu-project.org/apiref/icu4c/uscript_8h.html&quot;&gt;http://icu-project.org/apiref/icu4c/uscript_8h.html&lt;/a&gt; Returns -1 (USCRIPT_INVALID_CODE) for invalid codepoints. Output shape will match input shape.</source>
          <target state="translated">This operation converts Unicode code points to script codes corresponding to each code point. Script codes correspond to International Components for Unicode (ICU) UScriptCode values. See &lt;a href=&quot;http://icu-project.org/apiref/icu4c/uscript_8h.html&quot;&gt;http://icu-project.org/apiref/icu4c/uscript_8h.html&lt;/a&gt; Returns -1 (USCRIPT_INVALID_CODE) for invalid codepoints. Output shape will match input shape.</target>
        </trans-unit>
        <trans-unit id="45295c6769989505efcf8c49b52125eb620acebf" translate="yes" xml:space="preserve">
          <source>This operation converts Unicode code points to script codes corresponding to each code point. Script codes correspond to International Components for Unicode (ICU) UScriptCode values. See http://icu-project.org/apiref/icu4c/uscript_8h.html. Returns -1 (USCRIPT_INVALID_CODE) for invalid codepoints. Output shape will match input shape.</source>
          <target state="translated">이 작업은 유니 코드 코드 포인트를 각 코드 포인트에 해당하는 스크립트 코드로 변환합니다. 스크립트 코드는 ICU (International Components for Unicode) UScriptCode 값에 해당합니다. http://icu-project.org/apiref/icu4c/uscript_8h.html을 참조하십시오. 유효하지 않은 코드 포인트에 대해 -1 (USCRIPT_INVALID_CODE)을 반환합니다. 출력 형태는 입력 형태와 일치합니다.</target>
        </trans-unit>
        <trans-unit id="46e590d89bb172f52098449de9dab107e8dbb7d2" translate="yes" xml:space="preserve">
          <source>This operation corresponds to &lt;code&gt;numpy.tensordot(a, b, axes)&lt;/code&gt;.</source>
          <target state="translated">이 연산은 &lt;code&gt;numpy.tensordot(a, b, axes)&lt;/code&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="11cc84360970a3caa94b4965487c085edd1841b7" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by adding sparse &lt;code&gt;updates&lt;/code&gt; to the passed in &lt;code&gt;tensor&lt;/code&gt;. This operation is very similar to &lt;code&gt;tf.scatter_nd_add&lt;/code&gt;, except that the updates are added onto an existing tensor (as opposed to a variable). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</source>
          <target state="translated">이 작업은 전달 된 &lt;code&gt;tensor&lt;/code&gt; 스파 스 &lt;code&gt;updates&lt;/code&gt; 를 추가하여 새 텐서를 만듭니다 . 이 작업은 변수가 아닌 기존 텐서에 업데이트가 추가된다는 점을 제외하고 &lt;code&gt;tf.scatter_nd_add&lt;/code&gt; 와 매우 유사합니다 . 기존 텐서의 메모리를 재사용 할 수 없으면 사본이 만들어지고 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="ffa4c89af08b8794e18efa910261002f2ad8a60e" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by applying sparse &lt;code&gt;updates&lt;/code&gt; to the passed in &lt;code&gt;tensor&lt;/code&gt;. This operation is very similar to &lt;a href=&quot;../scatter_nd&quot;&gt;&lt;code&gt;tf.scatter_nd&lt;/code&gt;&lt;/a&gt;, except that the updates are scattered onto an existing tensor (as opposed to a zero-tensor). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</source>
          <target state="translated">This operation creates a new tensor by applying sparse &lt;code&gt;updates&lt;/code&gt; to the passed in &lt;code&gt;tensor&lt;/code&gt; . This operation is very similar to &lt;a href=&quot;../scatter_nd&quot;&gt; &lt;code&gt;tf.scatter_nd&lt;/code&gt; &lt;/a&gt;, except that the updates are scattered onto an existing tensor (as opposed to a zero-tensor). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</target>
        </trans-unit>
        <trans-unit id="c390e65b4cc57f97f7e73aea3a4e81f629906485" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by applying sparse &lt;code&gt;updates&lt;/code&gt; to the passed in &lt;code&gt;tensor&lt;/code&gt;. This operation is very similar to &lt;a href=&quot;scatter_nd&quot;&gt;&lt;code&gt;tf.scatter_nd&lt;/code&gt;&lt;/a&gt;, except that the updates are scattered onto an existing tensor (as opposed to a zero-tensor). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</source>
          <target state="translated">이 작업은 전달 된 &lt;code&gt;tensor&lt;/code&gt; 스파 스 &lt;code&gt;updates&lt;/code&gt; 를 적용하여 새 텐서를 만듭니다 . 이 작업은 &lt;a href=&quot;scatter_nd&quot;&gt; &lt;code&gt;tf.scatter_nd&lt;/code&gt; &lt;/a&gt; 와 매우 유사합니다. 단 , 업데이트는 기존 텐서에 흩어져 있습니다 (제로 텐서가 아님). 기존 텐서의 메모리를 재사용 할 수 없으면 사본이 만들어지고 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="35ada26abd351b9c5bf627e9862c2252c700b1b5" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by replicating &lt;code&gt;input&lt;/code&gt;&lt;code&gt;multiples&lt;/code&gt; times. The output tensor's i'th dimension has &lt;code&gt;input.dims(i) * multiples[i]&lt;/code&gt; elements, and the values of &lt;code&gt;input&lt;/code&gt; are replicated &lt;code&gt;multiples[i]&lt;/code&gt; times along the 'i'th dimension. For example, tiling &lt;code&gt;[a b c d]&lt;/code&gt; by &lt;code&gt;[2]&lt;/code&gt; produces &lt;code&gt;[a b c d a b c d]&lt;/code&gt;.</source>
          <target state="translated">이 작업은 &lt;code&gt;input&lt;/code&gt; &lt;code&gt;multiples&lt;/code&gt; 번 복제하여 새 텐서를 만듭니다 . 출력 텐서의 i 번째 차원에는 &lt;code&gt;input.dims(i) * multiples[i]&lt;/code&gt; 요소가 있으며 &lt;code&gt;input&lt;/code&gt; 값은 'i'번째 차원을 따라 &lt;code&gt;multiples[i]&lt;/code&gt; 회 복제 됩니다. 예를 들어, &lt;code&gt;[2]&lt;/code&gt; 에 의해 &lt;code&gt;[a b c d]&lt;/code&gt; 를 타일링 하면 &lt;code&gt;[a b c d a b c d]&lt;/code&gt; 생성 됩니다.</target>
        </trans-unit>
        <trans-unit id="5c90c8c96fbb8b355bef6addc97e2ca668679eab" translate="yes" xml:space="preserve">
          <source>This operation creates a new tensor by subtracting sparse &lt;code&gt;updates&lt;/code&gt; from the passed in &lt;code&gt;tensor&lt;/code&gt;. This operation is very similar to &lt;code&gt;tf.scatter_nd_sub&lt;/code&gt;, except that the updates are subtracted from an existing tensor (as opposed to a variable). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</source>
          <target state="translated">이 작업은 전달 된 &lt;code&gt;tensor&lt;/code&gt; 에서 스파 스 &lt;code&gt;updates&lt;/code&gt; 를 빼서 새 텐서를 만듭니다 . 이 작업은 변수가 아닌 기존 텐서에서 업데이트를 뺀다는 점을 제외하고 &lt;code&gt;tf.scatter_nd_sub&lt;/code&gt; 와 매우 유사합니다 . 기존 텐서의 메모리를 재사용 할 수 없으면 사본이 만들어지고 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="52687eaf04e092c6367552afd7b0ecbe304d63d1" translate="yes" xml:space="preserve">
          <source>This operation creates a sequence of numbers that begins at &lt;code&gt;start&lt;/code&gt; and extends by increments of &lt;code&gt;delta&lt;/code&gt; up to but not including &lt;code&gt;limit&lt;/code&gt;.</source>
          <target state="translated">This operation creates a sequence of numbers that begins at &lt;code&gt;start&lt;/code&gt; and extends by increments of &lt;code&gt;delta&lt;/code&gt; up to but not including &lt;code&gt;limit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="92df0de1d5e9953fcab8fedab1e1918021371c50" translate="yes" xml:space="preserve">
          <source>This operation creates a tensor of &lt;code&gt;shape&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">This operation creates a tensor of &lt;code&gt;shape&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0aaf5e994752ce058c39711d4638a06e40443f56" translate="yes" xml:space="preserve">
          <source>This operation creates a tensor of shape &lt;code&gt;dims&lt;/code&gt; and fills it with &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">이 작업은 모양이 &lt;code&gt;dims&lt;/code&gt; 텐서를 만들고 &lt;code&gt;value&lt;/code&gt; 채 웁니다 .</target>
        </trans-unit>
        <trans-unit id="2acd7b755c2b5e055f5081527ae8768ab15af691" translate="yes" xml:space="preserve">
          <source>This operation divides &quot;spatial&quot; dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; of the input into a grid of blocks of shape &lt;code&gt;block_shape&lt;/code&gt;, and interleaves these blocks with the &quot;batch&quot; dimension (0) such that in the output, the spatial dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; correspond to the position within the grid, and the batch dimension combines both the position within a spatial block and the original batch position. Prior to division into blocks, the spatial dimensions of the input are optionally zero padded according to &lt;code&gt;paddings&lt;/code&gt;. See below for a precise description.</source>
          <target state="translated">이 연산 은 입력의 &quot;공간&quot;치수 &lt;code&gt;[1, ..., M]&lt;/code&gt; 을 블록 블록 모양의 블록 격자로 &lt;code&gt;block_shape&lt;/code&gt; 출력에서 공간 치수가되도록 &quot;배치&quot;치수 (0)로 이러한 블록을 인터리브합니다. &lt;code&gt;[1, ..., M]&lt;/code&gt; 은 그리드 내의 위치에 해당하며 배치 차원은 공간 블록 내의 위치와 원래 배치 위치를 모두 결합합니다. 블록으로 분할하기 전에, 입력의 공간적 차원에있어서 선택적으로 제로 패딩되어 &lt;code&gt;paddings&lt;/code&gt; . 자세한 설명은 아래를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="41e0f15b392354d26d2756845f1cfcd72200eb6d" translate="yes" xml:space="preserve">
          <source>This operation either returns a tensor &lt;code&gt;y&lt;/code&gt; containing unique elements along the &lt;code&gt;axis&lt;/code&gt; of a tensor. The returned unique elements is sorted in the same order as they occur along &lt;code&gt;axis&lt;/code&gt; in &lt;code&gt;x&lt;/code&gt;. This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; and a tensor &lt;code&gt;count&lt;/code&gt; that are the same size as the number of the elements in &lt;code&gt;x&lt;/code&gt; along the &lt;code&gt;axis&lt;/code&gt; dimension. The &lt;code&gt;idx&lt;/code&gt; contains the index in the unique output &lt;code&gt;y&lt;/code&gt; and the &lt;code&gt;count&lt;/code&gt; contains the count in the unique output &lt;code&gt;y&lt;/code&gt;. In other words, for an &lt;code&gt;1-D&lt;/code&gt; tensor &lt;code&gt;x&lt;/code&gt; with `axis = None:</source>
          <target state="translated">This operation either returns a tensor &lt;code&gt;y&lt;/code&gt; containing unique elements along the &lt;code&gt;axis&lt;/code&gt; of a tensor. The returned unique elements is sorted in the same order as they occur along &lt;code&gt;axis&lt;/code&gt; in &lt;code&gt;x&lt;/code&gt; . This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; and a tensor &lt;code&gt;count&lt;/code&gt; that are the same size as the number of the elements in &lt;code&gt;x&lt;/code&gt; along the &lt;code&gt;axis&lt;/code&gt; dimension. The &lt;code&gt;idx&lt;/code&gt; contains the index in the unique output &lt;code&gt;y&lt;/code&gt; and the &lt;code&gt;count&lt;/code&gt; contains the count in the unique output &lt;code&gt;y&lt;/code&gt; . In other words, for an &lt;code&gt;1-D&lt;/code&gt; tensor &lt;code&gt;x&lt;/code&gt; with `axis = None:</target>
        </trans-unit>
        <trans-unit id="2fb9300ba4c7f909238dc4fbd9e13292c10f4740" translate="yes" xml:space="preserve">
          <source>This operation either returns a tensor &lt;code&gt;y&lt;/code&gt; containing unique elements along the &lt;code&gt;axis&lt;/code&gt; of a tensor. The returned unique elements is sorted in the same order as they occur along &lt;code&gt;axis&lt;/code&gt; in &lt;code&gt;x&lt;/code&gt;. This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; that is the same size as the number of the elements in &lt;code&gt;x&lt;/code&gt; along the &lt;code&gt;axis&lt;/code&gt; dimension. It contains the index in the unique output &lt;code&gt;y&lt;/code&gt;. In other words, for an &lt;code&gt;1-D&lt;/code&gt; tensor &lt;code&gt;x&lt;/code&gt; with `axis = None:</source>
          <target state="translated">This operation either returns a tensor &lt;code&gt;y&lt;/code&gt; containing unique elements along the &lt;code&gt;axis&lt;/code&gt; of a tensor. The returned unique elements is sorted in the same order as they occur along &lt;code&gt;axis&lt;/code&gt; in &lt;code&gt;x&lt;/code&gt; . This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; that is the same size as the number of the elements in &lt;code&gt;x&lt;/code&gt; along the &lt;code&gt;axis&lt;/code&gt; dimension. It contains the index in the unique output &lt;code&gt;y&lt;/code&gt; . In other words, for an &lt;code&gt;1-D&lt;/code&gt; tensor &lt;code&gt;x&lt;/code&gt; with `axis = None:</target>
        </trans-unit>
        <trans-unit id="a631f52c0283f6c97e9168ae9c2c1920fc673e57" translate="yes" xml:space="preserve">
          <source>This operation ensures the underlying data memory is ready when returns.</source>
          <target state="translated">This operation ensures the underlying data memory is ready when returns.</target>
        </trans-unit>
        <trans-unit id="5d3e7305e25146c306e9ca9dac7912d7b2d4ded2" translate="yes" xml:space="preserve">
          <source>This operation extracts a slice of size &lt;code&gt;size&lt;/code&gt; from a tensor &lt;code&gt;input_&lt;/code&gt; starting at the location specified by &lt;code&gt;begin&lt;/code&gt;. The slice &lt;code&gt;size&lt;/code&gt; is represented as a tensor shape, where &lt;code&gt;size[i]&lt;/code&gt; is the number of elements of the 'i'th dimension of &lt;code&gt;input_&lt;/code&gt; that you want to slice. The starting location (&lt;code&gt;begin&lt;/code&gt;) for the slice is represented as an offset in each dimension of &lt;code&gt;input_&lt;/code&gt;. In other words, &lt;code&gt;begin[i]&lt;/code&gt; is the offset into the i'th dimension of &lt;code&gt;input_&lt;/code&gt; that you want to slice from.</source>
          <target state="translated">이 작업 은 &lt;code&gt;begin&lt;/code&gt; 에 지정된 위치에서 시작 하는 텐서 &lt;code&gt;input_&lt;/code&gt; 에서 크기 &lt;code&gt;size&lt;/code&gt; 의 슬라이스를 추출 합니다 . 슬라이스 &lt;code&gt;size&lt;/code&gt; 는 텐서 모양으로 표시됩니다. 여기서 &lt;code&gt;size[i]&lt;/code&gt; 는 슬라이스하려는 'i'차원의 &lt;code&gt;input_&lt;/code&gt; 요소 수입니다 . 슬라이스 의 시작 위치 ( &lt;code&gt;begin&lt;/code&gt; )는 &lt;code&gt;input_&lt;/code&gt; 의 각 차원에서 오프셋으로 표시됩니다 . 즉, &lt;code&gt;begin[i]&lt;/code&gt; 는 슬라이스하려는 &lt;code&gt;input_&lt;/code&gt; 의 i 번째 차원에 대한 오프셋 입니다.</target>
        </trans-unit>
        <trans-unit id="29ab911f3d597d49d14cf454f1533a4b19e5e15b" translate="yes" xml:space="preserve">
          <source>This operation extracts the specified region from the tensor. The notation is similar to NumPy with the restriction that currently only support basic indexing. That means that using a non-scalar tensor as input is not currently allowed.</source>
          <target state="translated">이 작업은 텐서에서 지정된 영역을 추출합니다. 이 표기법은 현재 기본 색인 만 지원하는 제한 사항이있는 NumPy와 유사합니다. 즉, 스칼라 이외의 텐서를 입력으로 사용하는 것은 현재 허용되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="c488d4bcca92a0ac54244fdbb1f9925da2e5d927" translate="yes" xml:space="preserve">
          <source>This operation folds the padded areas of &lt;code&gt;input&lt;/code&gt; by &lt;code&gt;MirrorPad&lt;/code&gt; according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; must be the same as &lt;code&gt;paddings&lt;/code&gt; argument given to the corresponding &lt;code&gt;MirrorPad&lt;/code&gt; op.</source>
          <target state="translated">This operation folds the padded areas of &lt;code&gt;input&lt;/code&gt; by &lt;code&gt;MirrorPad&lt;/code&gt; according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; must be the same as &lt;code&gt;paddings&lt;/code&gt; argument given to the corresponding &lt;code&gt;MirrorPad&lt;/code&gt; op.</target>
        </trans-unit>
        <trans-unit id="2f4879a7545e74fa85acacd4cf01d74137ecf234" translate="yes" xml:space="preserve">
          <source>This operation has &lt;code&gt;k&lt;/code&gt; outputs, where &lt;code&gt;k&lt;/code&gt; is the number of components in the tuples stored in the given queue, and output &lt;code&gt;i&lt;/code&gt; is the ith component of the dequeued tuple.</source>
          <target state="translated">This operation has &lt;code&gt;k&lt;/code&gt; outputs, where &lt;code&gt;k&lt;/code&gt; is the number of components in the tuples stored in the given queue, and output &lt;code&gt;i&lt;/code&gt; is the ith component of the dequeued tuple.</target>
        </trans-unit>
        <trans-unit id="2d3ec2c39ae0a5c24c1de4e22eea70e184fc371a" translate="yes" xml:space="preserve">
          <source>This operation has a gradient and thus allows for training &lt;code&gt;min&lt;/code&gt; and &lt;code&gt;max&lt;/code&gt; values.</source>
          <target state="translated">이 작업에는 기울기가 있으므로 &lt;code&gt;min&lt;/code&gt; 과 &lt;code&gt;max&lt;/code&gt; 값 을 학습 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ac2e08c9a87871e0d33d02bc30d3bfc7e328d76d" translate="yes" xml:space="preserve">
          <source>This operation has k outputs, where &lt;code&gt;k&lt;/code&gt; is the number of components in the tuples stored in the given queue, and output &lt;code&gt;i&lt;/code&gt; is the ith component of the dequeued tuple.</source>
          <target state="translated">This operation has k outputs, where &lt;code&gt;k&lt;/code&gt; is the number of components in the tuples stored in the given queue, and output &lt;code&gt;i&lt;/code&gt; is the ith component of the dequeued tuple.</target>
        </trans-unit>
        <trans-unit id="701111c6d7bceddee66d3b31a146ad5d2ba5dd35" translate="yes" xml:space="preserve">
          <source>This operation has k outputs, where k is the number of components in the tuples stored in the given queue, and output i is the ith component of the dequeued tuple.</source>
          <target state="translated">This operation has k outputs, where k is the number of components in the tuples stored in the given queue, and output i is the ith component of the dequeued tuple.</target>
        </trans-unit>
        <trans-unit id="b78d17d35c34babe04bca7ab5360f7b9d4aad4d2" translate="yes" xml:space="preserve">
          <source>This operation has the same semantics as &lt;code&gt;reshape&lt;/code&gt; on the represented dense tensor. The indices of non-empty values in &lt;code&gt;sp_input&lt;/code&gt; are recomputed based on the new dense shape, and a new &lt;code&gt;SparseTensor&lt;/code&gt; is returned containing the new indices and new shape. The order of non-empty values in &lt;code&gt;sp_input&lt;/code&gt; is unchanged.</source>
          <target state="translated">이 작업은 대표 밀도 텐서의 &lt;code&gt;reshape&lt;/code&gt; 과 동일한 의미를 갖습니다 . &lt;code&gt;sp_input&lt;/code&gt; 에서 비어 있지 않은 값의 인덱스는 새로운 조밀 한 모양을 기반으로 다시 계산 되며 새 인덱스와 새로운 모양을 포함 하는 새로운 &lt;code&gt;SparseTensor&lt;/code&gt; 가 반환됩니다. &lt;code&gt;sp_input&lt;/code&gt; 에서 비어 있지 않은 값의 순서 는 변경되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="920eea1003570a2934a5442842f0411a9537123b" translate="yes" xml:space="preserve">
          <source>This operation has the same semantics as reshape on the represented dense tensor. The &lt;code&gt;input_indices&lt;/code&gt; are recomputed based on the requested &lt;code&gt;new_shape&lt;/code&gt;.</source>
          <target state="translated">This operation has the same semantics as reshape on the represented dense tensor. The &lt;code&gt;input_indices&lt;/code&gt; are recomputed based on the requested &lt;code&gt;new_shape&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f987eeda9053c7636415898332c77d1e39acd9d4" translate="yes" xml:space="preserve">
          <source>This operation holds a replicated input to a &lt;code&gt;tpu.replicate()&lt;/code&gt; computation subgraph. Each replicated input has the same shape and type alongside the output.</source>
          <target state="translated">This operation holds a replicated input to a &lt;code&gt;tpu.replicate()&lt;/code&gt; computation subgraph. Each replicated input has the same shape and type alongside the output.</target>
        </trans-unit>
        <trans-unit id="8d663f608fa1c649097379c4a16273931656d413" translate="yes" xml:space="preserve">
          <source>This operation holds a replicated output from a &lt;code&gt;tpu.replicate()&lt;/code&gt; computation subgraph. Each replicated output has the same shape and type alongside the input.</source>
          <target state="translated">This operation holds a replicated output from a &lt;code&gt;tpu.replicate()&lt;/code&gt; computation subgraph. Each replicated output has the same shape and type alongside the input.</target>
        </trans-unit>
        <trans-unit id="ddc1067cff13fb19a5da325542d16f1e694e62d1" translate="yes" xml:space="preserve">
          <source>This operation holds the metadata common to operations of a &lt;code&gt;tpu.replicate()&lt;/code&gt; computation subgraph.</source>
          <target state="translated">This operation holds the metadata common to operations of a &lt;code&gt;tpu.replicate()&lt;/code&gt; computation subgraph.</target>
        </trans-unit>
        <trans-unit id="1bd3f36c5bf6b7e281276b8f3d298543774510a1" translate="yes" xml:space="preserve">
          <source>This operation is a no-op when executing eagerly.</source>
          <target state="translated">이 작업은 간절히 실행할 때 작동하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="7c3a2eaa25ce85f5bc726adb4e2f6e321fc3ad96" translate="yes" xml:space="preserve">
          <source>This operation is a synchronous version IteratorGetNext. It should only be used in situations where the iterator does not block the calling thread, or where the calling thread is not a member of the thread pool used to execute parallel operations (e.g. in eager mode).</source>
          <target state="translated">This operation is a synchronous version IteratorGetNext. It should only be used in situations where the iterator does not block the calling thread, or where the calling thread is not a member of the thread pool used to execute parallel operations (e.g. in eager mode).</target>
        </trans-unit>
        <trans-unit id="834adca0b6e8190426dd82e3dc679bdfc3901af6" translate="yes" xml:space="preserve">
          <source>This operation is considered stateful. For a stateless version, see PyFuncStateless.</source>
          <target state="translated">This operation is considered stateful. For a stateless version, see PyFuncStateless.</target>
        </trans-unit>
        <trans-unit id="c77c133cb2aa87b66c50cea9b24338cf94df91e2" translate="yes" xml:space="preserve">
          <source>This operation is equivalent to the following steps:</source>
          <target state="translated">이 작업은 다음 단계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="a85336f9b64b0941e75fed8873dd343470ffb664" translate="yes" xml:space="preserve">
          <source>This operation is for training only. It is generally an underestimate of the full softmax loss.</source>
          <target state="translated">이 작업은 훈련 전용입니다. 일반적으로 전체 최대 손실을 과소 평가합니다.</target>
        </trans-unit>
        <trans-unit id="197a06d7811b56e8d6bce80b3c815e4a4c56a4a7" translate="yes" xml:space="preserve">
          <source>This operation is not supported by all queues. If a queue does not support DequeueUpTo, then an Unimplemented error is returned.</source>
          <target state="translated">This operation is not supported by all queues. If a queue does not support DequeueUpTo, then an Unimplemented error is returned.</target>
        </trans-unit>
        <trans-unit id="6db0a8622252241b3dd8e4da9fc3d6ba84977a9c" translate="yes" xml:space="preserve">
          <source>This operation is related to &lt;code&gt;squeeze()&lt;/code&gt;, which removes dimensions of size 1.</source>
          <target state="translated">이 작업은 크기 1의 크기를 제거 하는 &lt;code&gt;squeeze()&lt;/code&gt; 와 관련이 있습니다 .</target>
        </trans-unit>
        <trans-unit id="49c94ac01402b2bd4ac870cdfc937202b7e69050" translate="yes" xml:space="preserve">
          <source>This operation is related to:</source>
          <target state="translated">이 작업은 다음과 관련이 있습니다.</target>
        </trans-unit>
        <trans-unit id="f8a4568939439baca88acb2c04e8494963c44c55" translate="yes" xml:space="preserve">
          <source>This operation is significantly more numerically stable than the equivalent tensorflow operation &lt;code&gt;tf.math.log(tf.math.cumsum(tf.math.exp(x)))&lt;/code&gt;, although computes the same result given infinite numerical precision. However, note that in some cases, it may be less stable than &lt;a href=&quot;reduce_logsumexp&quot;&gt;&lt;code&gt;tf.math.reduce_logsumexp&lt;/code&gt;&lt;/a&gt; for a given element, as it applies the &quot;log-sum-exp trick&quot; in a different way.</source>
          <target state="translated">이 연산은 등가 tensorflow 연산 &lt;code&gt;tf.math.log(tf.math.cumsum(tf.math.exp(x)))&lt;/code&gt; 보다 훨씬 수치 적으로 안정적 이지만, 무한한 수치 정밀도로 동일한 결과를 계산합니다. 그러나 어떤 경우 에는 &quot;log-sum-exp exp trick&quot;을 다른 방식으로 적용하기 때문에 주어진 요소에 대해 &lt;a href=&quot;reduce_logsumexp&quot;&gt; &lt;code&gt;tf.math.reduce_logsumexp&lt;/code&gt; &lt;/a&gt; 보다 덜 안정적 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="c9fb91f09ebc4c3acce5ac821344d6140f7e24da" translate="yes" xml:space="preserve">
          <source>This operation is similar to tensor_scatter_add, except that the tensor is zero-initialized. Calling &lt;a href=&quot;../scatter_nd&quot;&gt;&lt;code&gt;tf.scatter_nd(indices, values, shape)&lt;/code&gt;&lt;/a&gt; is identical to &lt;code&gt;tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)&lt;/code&gt;</source>
          <target state="translated">This operation is similar to tensor_scatter_add, except that the tensor is zero-initialized. Calling &lt;a href=&quot;../scatter_nd&quot;&gt; &lt;code&gt;tf.scatter_nd(indices, values, shape)&lt;/code&gt; &lt;/a&gt; is identical to &lt;code&gt;tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0cce4836efcc5d3f1c90cad3d4974cf4b16512f4" translate="yes" xml:space="preserve">
          <source>This operation is similar to tensor_scatter_add, except that the tensor is zero-initialized. Calling &lt;a href=&quot;scatter_nd&quot;&gt;&lt;code&gt;tf.scatter_nd(indices, values, shape)&lt;/code&gt;&lt;/a&gt; is identical to &lt;code&gt;tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)&lt;/code&gt;</source>
          <target state="translated">이 작업은 tensor가 0으로 초기화된다는 점을 제외하고 tensor_scatter_add와 유사합니다. &lt;a href=&quot;scatter_nd&quot;&gt; &lt;code&gt;tf.scatter_nd(indices, values, shape)&lt;/code&gt; &lt;/a&gt; 호출 은 &lt;code&gt;tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3ef068c49d35ae40fdbd6e0290914a410da40aff" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is actually the transpose (gradient) of &lt;code&gt;conv1d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is actually the transpose (gradient) of &lt;code&gt;conv1d&lt;/code&gt; rather than an actual deconvolution.</target>
        </trans-unit>
        <trans-unit id="f5e02776737c55d9c6ad653f1cc95f3511e5d57b" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is really the transpose (gradient) of &lt;code&gt;atrous_conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is really the transpose (gradient) of &lt;code&gt;atrous_conv2d&lt;/code&gt; rather than an actual deconvolution.</target>
        </trans-unit>
        <trans-unit id="00a748a99cc55d86cf7d8d7f88c1133466c7c32f" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is really the transpose (gradient) of &lt;code&gt;conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is really the transpose (gradient) of &lt;code&gt;conv2d&lt;/code&gt; rather than an actual deconvolution.</target>
        </trans-unit>
        <trans-unit id="c47ed45caa79111f8c5fa46b428a6d5a1fe8d370" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is really the transpose (gradient) of &lt;code&gt;conv3d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">This operation is sometimes called &quot;deconvolution&quot; after (Zeiler et al., 2010), but is really the transpose (gradient) of &lt;code&gt;conv3d&lt;/code&gt; rather than an actual deconvolution.</target>
        </trans-unit>
        <trans-unit id="50f836730593fffe361ee867e1bf79d15e8af917" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is actually the transpose (gradient) of &lt;code&gt;conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv2d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="cdd40bbfb18d0876cdd3d1bf655721101051d082" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is actually the transpose (gradient) of &lt;code&gt;convolution&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 디컨 볼 &lt;code&gt;convolution&lt;/code&gt; 아닌 컨볼 루션 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="a80e63d8e3617ef22a7c11bc4ac5ce2aac92b83c" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;atrous_conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아닌 &lt;code&gt;atrous_conv2d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="3e16e89f92d27118cbc90336d321edbdccabf257" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;conv1d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv1d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="74c54a1240dd3ebac671477622bdae5730c68b14" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;conv2d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv2d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="78632da26e5444bf46256b6e1c192a603e6c3c00" translate="yes" xml:space="preserve">
          <source>This operation is sometimes called &quot;deconvolution&quot; after &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt;, but is really the transpose (gradient) of &lt;code&gt;conv3d&lt;/code&gt; rather than an actual deconvolution.</source>
          <target state="translated">이 작업은 &lt;a href=&quot;https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf&quot;&gt;Deconvolutional Networks&lt;/a&gt; 이후 &quot;deconvolution&quot;이라고도 하지만 실제로 실제 deconvolution이 아니라 &lt;code&gt;conv3d&lt;/code&gt; 의 조옮김 (그라데이션)입니다 .</target>
        </trans-unit>
        <trans-unit id="20f728b5bb5e16f6250024eb3cf614e43cfbbe07" translate="yes" xml:space="preserve">
          <source>This operation is typically used to clip gradients before applying them with an optimizer.</source>
          <target state="translated">이 작업은 일반적으로 옵티 마이저로 그라디언트를 적용하기 전에 그라디언트를 클리핑하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="7b06c412ab3afb65378a71bcff3a6e6664ba2503" translate="yes" xml:space="preserve">
          <source>This operation is typically used to clip gradients before applying them with an optimizer. Most gradient data is a collection of different shaped tensors for different parts of the model. Thus, this is a common usage:</source>
          <target state="translated">This operation is typically used to clip gradients before applying them with an optimizer. Most gradient data is a collection of different shaped tensors for different parts of the model. Thus, this is a common usage:</target>
        </trans-unit>
        <trans-unit id="a39ff6aff1d832bca041bbe0ecd1ce428c1522da" translate="yes" xml:space="preserve">
          <source>This operation is useful for Locality-Sensitive-Hashing (LSH) and other algorithms that use hashing approximations of cosine and &lt;code&gt;L2&lt;/code&gt; distances; codes can be generated from an input via:</source>
          <target state="translated">This operation is useful for Locality-Sensitive-Hashing (LSH) and other algorithms that use hashing approximations of cosine and &lt;code&gt;L2&lt;/code&gt; distances; codes can be generated from an input via:</target>
        </trans-unit>
        <trans-unit id="5397809ea0e6b96d049101c13960159515304d67" translate="yes" xml:space="preserve">
          <source>This operation is useful for resizing the activations between convolutions (but keeping all data), e.g. instead of pooling. It is also useful for training purely convolutional models.</source>
          <target state="translated">이 작업은 풀링 대신 컨볼 루션 간의 활성화 크기를 조정하지만 모든 데이터를 유지하는 데 유용합니다. 순전히 컨볼 루션 모델을 훈련하는 데에도 유용합니다.</target>
        </trans-unit>
        <trans-unit id="e6cbba91c74639c8cb40de16428e2bef0563e905" translate="yes" xml:space="preserve">
          <source>This operation is useful if you want to add a batch dimension to a single element. For example, if you have a single image of shape &lt;code&gt;[height, width, channels]&lt;/code&gt;, you can make it a batch of 1 image with &lt;code&gt;expand_dims(image, 0)&lt;/code&gt;, which will make the shape &lt;code&gt;[1, height, width, channels]&lt;/code&gt;.</source>
          <target state="translated">이 작업은 단일 요소에 배치 차원을 추가하려는 경우에 유용합니다. 예를 들어, 모양 &lt;code&gt;[height, width, channels]&lt;/code&gt; 의 단일 이미지가있는 경우 &lt;code&gt;expand_dims(image, 0)&lt;/code&gt; 을 사용하여 모양이 &lt;code&gt;[1, height, width, channels]&lt;/code&gt; 인 1 개의 이미지를 일괄 적으로 만들 수 있습니다 . .</target>
        </trans-unit>
        <trans-unit id="6316e455129ed9fa859e28aacc9886a66315035c" translate="yes" xml:space="preserve">
          <source>This operation is useful if you want to add a batch dimension to a single element. For example, if you have a single image of shape &lt;code&gt;[height, width, channels]&lt;/code&gt;, you can make it a batch of one image with &lt;code&gt;expand_dims(image, 0)&lt;/code&gt;, which will make the shape &lt;code&gt;[1, height, width, channels]&lt;/code&gt;.</source>
          <target state="translated">이 작업은 단일 요소에 배치 차원을 추가하려는 경우에 유용합니다. 예를 들어, &lt;code&gt;[height, width, channels]&lt;/code&gt; 모양의 단일 이미지가있는 경우 &lt;code&gt;expand_dims(image, 0)&lt;/code&gt; 하여 하나의 이미지를 일괄 처리 하여 모양을 &lt;code&gt;[1, height, width, channels]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e351d2492bb6908fd7d460e61be31a9eca71f43d" translate="yes" xml:space="preserve">
          <source>This operation is useful to:</source>
          <target state="translated">This operation is useful to:</target>
        </trans-unit>
        <trans-unit id="183fa485124f0558dfb1f2c40c10151a91905ce9" translate="yes" xml:space="preserve">
          <source>This operation may be executed multiple times. Each execution will reset the iterator in &lt;code&gt;iterator&lt;/code&gt; to the first element of &lt;code&gt;dataset&lt;/code&gt;.</source>
          <target state="translated">This operation may be executed multiple times. Each execution will reset the iterator in &lt;code&gt;iterator&lt;/code&gt; to the first element of &lt;code&gt;dataset&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="082051a9c25e40abb9ca51ba30204e50cec28855" translate="yes" xml:space="preserve">
          <source>This operation outputs &quot;ref&quot; after the assignment is done. This makes it easier to chain operations that need to use the reset value.</source>
          <target state="translated">This operation outputs &quot;ref&quot; after the assignment is done. This makes it easier to chain operations that need to use the reset value.</target>
        </trans-unit>
        <trans-unit id="45e5d0f78a3a33704d46216d94caf563cfac246a" translate="yes" xml:space="preserve">
          <source>This operation outputs &quot;ref&quot; after the update is done. This makes it easier to chain operations that need to use the reset value.</source>
          <target state="translated">This operation outputs &quot;ref&quot; after the update is done. This makes it easier to chain operations that need to use the reset value.</target>
        </trans-unit>
        <trans-unit id="7d1d3aca1842cf510032065cfce3509b5c793096" translate="yes" xml:space="preserve">
          <source>This operation outputs &quot;ref&quot; after the update is done. This makes it easier to chain operations that need to use the reset value. Unlike &lt;a href=&quot;../../math/add&quot;&gt;&lt;code&gt;tf.math.add&lt;/code&gt;&lt;/a&gt;, this op does not broadcast. &lt;code&gt;ref&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt; must have the same shape.</source>
          <target state="translated">이 작업은 업데이트가 완료된 후 &quot;ref&quot;를 출력합니다. 따라서 재설정 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다. &lt;a href=&quot;../../math/add&quot;&gt; &lt;code&gt;tf.math.add&lt;/code&gt; &lt;/a&gt; 와 달리이 op는 브로드 캐스트되지 않습니다. &lt;code&gt;ref&lt;/code&gt; 과 &lt;code&gt;value&lt;/code&gt; 는 같은 모양이어야합니다.</target>
        </trans-unit>
        <trans-unit id="7e16eef80cf37c2d9c02fad5e714a6e559684854" translate="yes" xml:space="preserve">
          <source>This operation outputs &lt;code&gt;ref&lt;/code&gt; after the update is done. This makes it easier to chain operations that need to use the reset value.</source>
          <target state="translated">이 작업 은 업데이트가 완료된 후 &lt;code&gt;ref&lt;/code&gt; 을 출력 합니다. 따라서 재설정 값을 사용해야하는 작업을 쉽게 연결할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="80080e1227c1f588b580293eb11f01d8754cc2fa" translate="yes" xml:space="preserve">
          <source>This operation outputs &lt;code&gt;ref&lt;/code&gt; after the update is done. This makes it easier to chain operations that need to use the reset value. Unlike &lt;a href=&quot;../../math/subtract&quot;&gt;&lt;code&gt;tf.math.subtract&lt;/code&gt;&lt;/a&gt;, this op does not broadcast. &lt;code&gt;ref&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt; must have the same shape.</source>
          <target state="translated">이 작업 은 업데이트가 완료된 후 &lt;code&gt;ref&lt;/code&gt; 을 출력 합니다. 따라서 재설정 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다. &lt;a href=&quot;../../math/subtract&quot;&gt; &lt;code&gt;tf.math.subtract&lt;/code&gt; &lt;/a&gt; 와 달리이 op는 브로드 캐스트되지 않습니다. &lt;code&gt;ref&lt;/code&gt; 과 &lt;code&gt;value&lt;/code&gt; 는 같은 모양이어야합니다.</target>
        </trans-unit>
        <trans-unit id="211cf88f878719f0fdbc3eba7700cfd25f62b94c" translate="yes" xml:space="preserve">
          <source>This operation outputs &lt;code&gt;ref&lt;/code&gt; after the update is done. This makes it easier to chain operations that need to use the updated value. Duplicate entries are handled correctly: if multiple &lt;code&gt;indices&lt;/code&gt; reference the same location, their contributions add.</source>
          <target state="translated">이 작업 은 업데이트가 완료된 후 &lt;code&gt;ref&lt;/code&gt; 을 출력 합니다. 따라서 업데이트 된 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다. 중복 항목이 올바르게 처리됩니다. 여러 &lt;code&gt;indices&lt;/code&gt; 가 동일한 위치를 참조하는 경우 기여가 추가됩니다.</target>
        </trans-unit>
        <trans-unit id="f7141134307e0a174b2d64cd3ba50899cf746d15" translate="yes" xml:space="preserve">
          <source>This operation outputs a Tensor that holds the new value of &lt;code&gt;ref&lt;/code&gt; after the value has been assigned. This makes it easier to chain operations that need to use the reset value.</source>
          <target state="translated">이 작업 은 값이 할당 된 후 새로운 &lt;code&gt;ref&lt;/code&gt; 값을 유지하는 Tensor를 출력합니다 . 따라서 재설정 값을 사용해야하는 작업을보다 쉽게 ​​연결할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ff9194e8e7be6d4ad4f022b42bf00a1d9dcc3aad" translate="yes" xml:space="preserve">
          <source>This operation pads &lt;code&gt;input&lt;/code&gt; according to the &lt;code&gt;paddings&lt;/code&gt; and &lt;code&gt;constant_values&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[Dn, 2]&lt;/code&gt;, where n is the rank of &lt;code&gt;input&lt;/code&gt;. For each dimension D of &lt;code&gt;input&lt;/code&gt;, &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many padding values to add before the contents of &lt;code&gt;input&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many padding values to add after the contents of &lt;code&gt;input&lt;/code&gt; in that dimension. &lt;code&gt;constant_values&lt;/code&gt; is a scalar tensor of the same type as &lt;code&gt;input&lt;/code&gt; that indicates the value to use for padding &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">This operation pads &lt;code&gt;input&lt;/code&gt; according to the &lt;code&gt;paddings&lt;/code&gt; and &lt;code&gt;constant_values&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[Dn, 2]&lt;/code&gt; , where n is the rank of &lt;code&gt;input&lt;/code&gt; . For each dimension D of &lt;code&gt;input&lt;/code&gt; , &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many padding values to add before the contents of &lt;code&gt;input&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many padding values to add after the contents of &lt;code&gt;input&lt;/code&gt; in that dimension. &lt;code&gt;constant_values&lt;/code&gt; is a scalar tensor of the same type as &lt;code&gt;input&lt;/code&gt; that indicates the value to use for padding &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c7dac094042ba8225a6a7449892b847dafe951a8" translate="yes" xml:space="preserve">
          <source>This operation pads a &lt;code&gt;input&lt;/code&gt; with mirrored values according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[n, 2]&lt;/code&gt;, where n is the rank of &lt;code&gt;input&lt;/code&gt;. For each dimension D of &lt;code&gt;input&lt;/code&gt;, &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many values to add before the contents of &lt;code&gt;input&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many values to add after the contents of &lt;code&gt;input&lt;/code&gt; in that dimension. Both &lt;code&gt;paddings[D, 0]&lt;/code&gt; and &lt;code&gt;paddings[D, 1]&lt;/code&gt; must be no greater than &lt;code&gt;input.dim_size(D)&lt;/code&gt; (or &lt;code&gt;input.dim_size(D) - 1&lt;/code&gt;) if &lt;code&gt;copy_border&lt;/code&gt; is true (if false, respectively).</source>
          <target state="translated">This operation pads a &lt;code&gt;input&lt;/code&gt; with mirrored values according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[n, 2]&lt;/code&gt; , where n is the rank of &lt;code&gt;input&lt;/code&gt; . For each dimension D of &lt;code&gt;input&lt;/code&gt; , &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many values to add before the contents of &lt;code&gt;input&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many values to add after the contents of &lt;code&gt;input&lt;/code&gt; in that dimension. Both &lt;code&gt;paddings[D, 0]&lt;/code&gt; and &lt;code&gt;paddings[D, 1]&lt;/code&gt; must be no greater than &lt;code&gt;input.dim_size(D)&lt;/code&gt; (or &lt;code&gt;input.dim_size(D) - 1&lt;/code&gt; ) if &lt;code&gt;copy_border&lt;/code&gt; is true (if false, respectively).</target>
        </trans-unit>
        <trans-unit id="98dc6d3604c67365b92527ae5f26da565365534d" translate="yes" xml:space="preserve">
          <source>This operation pads a &lt;code&gt;input&lt;/code&gt; with zeros according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[Dn, 2]&lt;/code&gt;, where n is the rank of &lt;code&gt;input&lt;/code&gt;. For each dimension D of &lt;code&gt;input&lt;/code&gt;, &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many zeros to add before the contents of &lt;code&gt;input&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many zeros to add after the contents of &lt;code&gt;input&lt;/code&gt; in that dimension.</source>
          <target state="translated">This operation pads a &lt;code&gt;input&lt;/code&gt; with zeros according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[Dn, 2]&lt;/code&gt; , where n is the rank of &lt;code&gt;input&lt;/code&gt; . For each dimension D of &lt;code&gt;input&lt;/code&gt; , &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many zeros to add before the contents of &lt;code&gt;input&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many zeros to add after the contents of &lt;code&gt;input&lt;/code&gt; in that dimension.</target>
        </trans-unit>
        <trans-unit id="d8dcb952f1fd946dc8a99ab12f18c6c9f3bad230" translate="yes" xml:space="preserve">
          <source>This operation pads a &lt;code&gt;tensor&lt;/code&gt; according to the &lt;code&gt;paddings&lt;/code&gt; you specify. &lt;code&gt;paddings&lt;/code&gt; is an integer tensor with shape &lt;code&gt;[n, 2]&lt;/code&gt;, where n is the rank of &lt;code&gt;tensor&lt;/code&gt;. For each dimension D of &lt;code&gt;input&lt;/code&gt;, &lt;code&gt;paddings[D, 0]&lt;/code&gt; indicates how many values to add before the contents of &lt;code&gt;tensor&lt;/code&gt; in that dimension, and &lt;code&gt;paddings[D, 1]&lt;/code&gt; indicates how many values to add after the contents of &lt;code&gt;tensor&lt;/code&gt; in that dimension. If &lt;code&gt;mode&lt;/code&gt; is &quot;REFLECT&quot; then both &lt;code&gt;paddings[D, 0]&lt;/code&gt; and &lt;code&gt;paddings[D, 1]&lt;/code&gt; must be no greater than &lt;code&gt;tensor.dim_size(D) - 1&lt;/code&gt;. If &lt;code&gt;mode&lt;/code&gt; is &quot;SYMMETRIC&quot; then both &lt;code&gt;paddings[D, 0]&lt;/code&gt; and &lt;code&gt;paddings[D, 1]&lt;/code&gt; must be no greater than &lt;code&gt;tensor.dim_size(D)&lt;/code&gt;.</source>
          <target state="translated">이 작업은 지정한 &lt;code&gt;paddings&lt;/code&gt; 에 따라 &lt;code&gt;tensor&lt;/code&gt; 를 채 웁니다 . &lt;code&gt;paddings&lt;/code&gt; 은 모양 &lt;code&gt;[n, 2]&lt;/code&gt; 의 정수 텐서이며 , 여기서 n은 &lt;code&gt;tensor&lt;/code&gt; 의 순위입니다 . 각각의 치수 D의 경우 &lt;code&gt;input&lt;/code&gt; , &lt;code&gt;paddings[D, 0]&lt;/code&gt; 의 내용 전에 추가하는 방법은 많은 값 나타내는 &lt;code&gt;tensor&lt;/code&gt; 그 치수 및 &lt;code&gt;paddings[D, 1]&lt;/code&gt; 의 내용을 후에 추가하는 방법은 많은 값 나타내는 &lt;code&gt;tensor&lt;/code&gt; 그 사이즈에있다. 경우 &lt;code&gt;mode&lt;/code&gt; 이며 다음 모두 &quot;REFLECT&quot; &lt;code&gt;paddings[D, 0]&lt;/code&gt; 및 &lt;code&gt;paddings[D, 1]&lt;/code&gt; 보다 크지 않아야 &lt;code&gt;tensor.dim_size(D) - 1&lt;/code&gt; . 경우 &lt;code&gt;mode&lt;/code&gt; &quot;대칭 적&quot;이다 후 양쪽 &lt;code&gt;paddings[D, 0]&lt;/code&gt; 및 &lt;code&gt;paddings[D, 1]&lt;/code&gt; 보다 크지 않아야 &lt;code&gt;tensor.dim_size(D)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ece6bb1bca3b5a4f71fcb2a4c7bb7def98bb6471" translate="yes" xml:space="preserve">
          <source>This operation performs non_max_suppression on the inputs per batch, across all classes. Prunes away boxes that have high intersection-over-union (IOU) overlap with previously selected boxes. Bounding boxes are supplied as [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Note that this algorithm is agnostic to where the origin is in the coordinate system. Also note that this algorithm is invariant to orthogonal transformations and translations of the coordinate system; thus translating or reflections of the coordinate system result in the same boxes being selected by the algorithm. The output of this operation is the final boxes, scores and classes tensor returned after performing non_max_suppression.</source>
          <target state="translated">이 작업은 모든 클래스에서 배치 당 입력에 대해 non_max_suppression을 수행합니다. 높은 IOU (교집합 교차)가있는 상자를 이전에 선택한 상자와 겹치십시오. 경계 상자는 [y1, x1, y2, x2]로 제공되며, 여기서 (y1, x1) 및 (y2, x2)는 상자 모서리의 대각선 쌍의 좌표이며 좌표는 정규화 된대로 제공 할 수 있습니다 (즉, 간격 [0, 1]) 또는 절대 값. 이 알고리즘은 원점이 좌표계의 위치와 관계가 없습니다. 또한이 알고리즘은 좌표계의 직교 변환 및 변환에 변하지 않습니다. 따라서 좌표계의 변환 또는 반사는 알고리즘에 의해 동일한 박스가 선택되게한다. 이 작업의 결과는 마지막 상자입니다.non_max_suppression을 수행 한 후 점수 및 클래스 텐서가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="92bf8506361b0c3190382a71e7f126a1495f07cd" translate="yes" xml:space="preserve">
          <source>This operation randomly samples a tensor of sampled classes (&lt;code&gt;sampled_candidates&lt;/code&gt;) from the range of integers &lt;code&gt;[0, range_max)&lt;/code&gt;.</source>
          <target state="translated">이 연산 은 정수 범위 &lt;code&gt;[0, range_max)&lt;/code&gt; 에서 샘플링 된 클래스 ( &lt;code&gt;sampled_candidates&lt;/code&gt; ) 의 텐서를 무작위로 샘플링합니다 .</target>
        </trans-unit>
        <trans-unit id="ef1ed12213e6ff487e80edd0040d70890d84414e" translate="yes" xml:space="preserve">
          <source>This operation requires that &lt;code&gt;axis&lt;/code&gt; is a valid index for &lt;code&gt;input.shape&lt;/code&gt;, following Python indexing rules:</source>
          <target state="translated">This operation requires that &lt;code&gt;axis&lt;/code&gt; is a valid index for &lt;code&gt;input.shape&lt;/code&gt; , following Python indexing rules:</target>
        </trans-unit>
        <trans-unit id="d5bc7ae5c1b93f8f5a6a390a4d228223c7c191dd" translate="yes" xml:space="preserve">
          <source>This operation requires that &lt;code&gt;axis&lt;/code&gt; is a valid index for &lt;code&gt;input.shape&lt;/code&gt;, following python indexing rules:</source>
          <target state="translated">This operation requires that &lt;code&gt;axis&lt;/code&gt; is a valid index for &lt;code&gt;input.shape&lt;/code&gt; , following python indexing rules:</target>
        </trans-unit>
        <trans-unit id="2656ea13a552cbb0836e0031c2afa8bfe371a2e1" translate="yes" xml:space="preserve">
          <source>This operation requires that:</source>
          <target state="translated">이 작업에는 다음이 필요합니다.</target>
        </trans-unit>
        <trans-unit id="b27b171e2cb8132634ecffed1d0dfa123640e238" translate="yes" xml:space="preserve">
          <source>This operation reshapes the &quot;batch&quot; dimension 0 into &lt;code&gt;M + 1&lt;/code&gt; dimensions of shape &lt;code&gt;block_shape + [batch]&lt;/code&gt;, interleaves these blocks back into the grid defined by the spatial dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt;, to obtain a result with the same rank as the input. The spatial dimensions of this intermediate result are then optionally cropped according to &lt;code&gt;crops&lt;/code&gt; to produce the output. This is the reverse of SpaceToBatch (see &lt;a href=&quot;space_to_batch&quot;&gt;&lt;code&gt;tf.space_to_batch&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">This operation reshapes the &quot;batch&quot; dimension 0 into &lt;code&gt;M + 1&lt;/code&gt; dimensions of shape &lt;code&gt;block_shape + [batch]&lt;/code&gt; , interleaves these blocks back into the grid defined by the spatial dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; , to obtain a result with the same rank as the input. The spatial dimensions of this intermediate result are then optionally cropped according to &lt;code&gt;crops&lt;/code&gt; to produce the output. This is the reverse of SpaceToBatch (see &lt;a href=&quot;space_to_batch&quot;&gt; &lt;code&gt;tf.space_to_batch&lt;/code&gt; &lt;/a&gt;).</target>
        </trans-unit>
        <trans-unit id="85455e262fab5e8f9fc55d0016d69887ed46e6fb" translate="yes" xml:space="preserve">
          <source>This operation reshapes the &quot;batch&quot; dimension 0 into &lt;code&gt;M + 1&lt;/code&gt; dimensions of shape &lt;code&gt;block_shape + [batch]&lt;/code&gt;, interleaves these blocks back into the grid defined by the spatial dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt;, to obtain a result with the same rank as the input. The spatial dimensions of this intermediate result are then optionally cropped according to &lt;code&gt;crops&lt;/code&gt; to produce the output. This is the reverse of SpaceToBatch. See below for a precise description.</source>
          <target state="translated">이 작업은 &quot;일괄 처리&quot;차원 0을 형태 &lt;code&gt;block_shape + [batch]&lt;/code&gt; 의 &lt;code&gt;M + 1&lt;/code&gt; 차원으로 재구성 하고 공간 블록 &lt;code&gt;[1, ..., M]&lt;/code&gt; 의해 정의 된 그리드로이 블록을 인터리브 하여 입력과 같은 순위입니다. 이어서,이 중간 결과의 공간 치수는 &lt;code&gt;crops&lt;/code&gt; 에 따라 선택적으로 크롭 되어 출력을 생성한다. 이것은 SpaceToBatch의 반대입니다. 자세한 설명은 아래를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="9858054bc42ba5d711abfe7b471684870f12eb28" translate="yes" xml:space="preserve">
          <source>This operation returns N 1-D integer tensors representing shape of &lt;code&gt;input[i]s&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe8665b789d92e174b87e3b8d8b3131e0c5a95d4" translate="yes" xml:space="preserve">
          <source>This operation returns a 1-D integer tensor representing the shape of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">이 연산은 &lt;code&gt;input&lt;/code&gt; 의 모양을 나타내는 1 차원 정수 텐서를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="7a59463d2fe92b4018e2beec28525b7ad3bbf202" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor &lt;code&gt;y&lt;/code&gt; containing all of the unique elements of &lt;code&gt;x&lt;/code&gt; sorted in the same order that they occur in &lt;code&gt;x&lt;/code&gt;. This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; the same size as &lt;code&gt;x&lt;/code&gt; that contains the index of each value of &lt;code&gt;x&lt;/code&gt; in the unique output &lt;code&gt;y&lt;/code&gt;. Finally, it returns a third tensor &lt;code&gt;count&lt;/code&gt; that contains the count of each element of &lt;code&gt;y&lt;/code&gt; in &lt;code&gt;x&lt;/code&gt;. In other words:</source>
          <target state="translated">이 조작은 텐서 반환 &lt;code&gt;y&lt;/code&gt; 의 고유 한 모든 요소를 포함하는 &lt;code&gt;x&lt;/code&gt; 그들이 발생하는 것과 동일한 순서로 정렬 &lt;code&gt;x&lt;/code&gt; . 이 연산은 또한 고유 출력 &lt;code&gt;y&lt;/code&gt; 에 &lt;code&gt;x&lt;/code&gt; 의 각 값 인덱스를 포함하는 &lt;code&gt;x&lt;/code&gt; 와 동일한 크기 의 텐서 &lt;code&gt;idx&lt;/code&gt; 를 반환합니다 . 마지막으로, 제 텐서 반환 &lt;code&gt;count&lt;/code&gt; 의 각 요소의 카운트가 포함 &lt;code&gt;y&lt;/code&gt; 에서 &lt;code&gt;x&lt;/code&gt; . 다시 말해:</target>
        </trans-unit>
        <trans-unit id="536871e049e74061332eb50e7568b95429f16ba6" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor &lt;code&gt;y&lt;/code&gt; containing all of the unique elements of &lt;code&gt;x&lt;/code&gt; sorted in the same order that they occur in &lt;code&gt;x&lt;/code&gt;; &lt;code&gt;x&lt;/code&gt; does not need to be sorted. This operation also returns a tensor &lt;code&gt;idx&lt;/code&gt; the same size as &lt;code&gt;x&lt;/code&gt; that contains the index of each value of &lt;code&gt;x&lt;/code&gt; in the unique output &lt;code&gt;y&lt;/code&gt;. In other words:</source>
          <target state="translated">이 조작은 텐서 반환 &lt;code&gt;y&lt;/code&gt; 의 고유 한 모든 요소를 포함하는 &lt;code&gt;x&lt;/code&gt; 그들이 발생하는 것과 동일한 순서로 정렬 &lt;code&gt;x&lt;/code&gt; ; &lt;code&gt;x&lt;/code&gt; 는 정렬 할 필요가 없습니다. 이 연산은 또한 고유 출력 &lt;code&gt;y&lt;/code&gt; 에 &lt;code&gt;x&lt;/code&gt; 의 각 값 인덱스를 포함하는 &lt;code&gt;x&lt;/code&gt; 와 동일한 크기 의 텐서 &lt;code&gt;idx&lt;/code&gt; 를 반환합니다 . 다시 말해:</target>
        </trans-unit>
        <trans-unit id="08bfd9d4b0608003900efe52523c1412fe2e10f1" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor of type &lt;code&gt;dtype&lt;/code&gt; with shape &lt;code&gt;shape&lt;/code&gt; and all elements set to one.</source>
          <target state="translated">이 연산은 모양 &lt;code&gt;shape&lt;/code&gt; 과 모든 요소가 1로 설정된 &lt;code&gt;dtype&lt;/code&gt; 유형의 텐서를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="46403ed383d4150a23258a456b0faa0e79d56dbe" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor of type &lt;code&gt;dtype&lt;/code&gt; with shape &lt;code&gt;shape&lt;/code&gt; and all elements set to zero.</source>
          <target state="translated">이 연산은 모양 &lt;code&gt;shape&lt;/code&gt; 과 모든 요소가 0으로 설정된 &lt;code&gt;dtype&lt;/code&gt; 유형의 텐서를 반환 합니다.</target>
        </trans-unit>
        <trans-unit id="476cbc978c015f266a3353221077ac3bad3036de" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor with the &lt;code&gt;diagonal&lt;/code&gt; part of the &lt;code&gt;input&lt;/code&gt;. The &lt;code&gt;diagonal&lt;/code&gt; part is computed as follows:</source>
          <target state="translated">이 작업은 &lt;code&gt;input&lt;/code&gt; 의 &lt;code&gt;diagonal&lt;/code&gt; 부분이 있는 텐서를 반환합니다 . &lt;code&gt;diagonal&lt;/code&gt; 다음 부분이 계산된다 :</target>
        </trans-unit>
        <trans-unit id="4aefd218f88fe56a44f84be48601325a8bfff9a5" translate="yes" xml:space="preserve">
          <source>This operation returns a tensor with the &lt;code&gt;diagonal&lt;/code&gt; part of the batched &lt;code&gt;input&lt;/code&gt;. The &lt;code&gt;diagonal&lt;/code&gt; part is computed as follows:</source>
          <target state="translated">This operation returns a tensor with the &lt;code&gt;diagonal&lt;/code&gt; part of the batched &lt;code&gt;input&lt;/code&gt; . The &lt;code&gt;diagonal&lt;/code&gt; part is computed as follows:</target>
        </trans-unit>
        <trans-unit id="19c9a08587b8ac6d36c602ec8cf419295278168f" translate="yes" xml:space="preserve">
          <source>This operation returns an integer representing the number of elements in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">This operation returns an integer representing the number of elements in &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="283ea59f55046522de219f0f2dc075ad8e2f3a65" translate="yes" xml:space="preserve">
          <source>This operation returns an integer representing the rank of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">This operation returns an integer representing the rank of &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c7e2028f3f49e171315c3ed603528d9f2314c768" translate="yes" xml:space="preserve">
          <source>This operation returns the coordinates of true elements in &lt;code&gt;condition&lt;/code&gt;. The coordinates are returned in a 2-D tensor where the first dimension (rows) represents the number of true elements, and the second dimension (columns) represents the coordinates of the true elements. Keep in mind, the shape of the output tensor can vary depending on how many true values there are in &lt;code&gt;condition&lt;/code&gt;. Indices are output in row-major order.</source>
          <target state="translated">This operation returns the coordinates of true elements in &lt;code&gt;condition&lt;/code&gt; . The coordinates are returned in a 2-D tensor where the first dimension (rows) represents the number of true elements, and the second dimension (columns) represents the coordinates of the true elements. Keep in mind, the shape of the output tensor can vary depending on how many true values there are in &lt;code&gt;condition&lt;/code&gt; . Indices are output in row-major order.</target>
        </trans-unit>
        <trans-unit id="9768f017e85a1cd0efa99d0dd71cd4a51ae98fd1" translate="yes" xml:space="preserve">
          <source>This operation returns the result of a TPU compilation as a serialized CompilationResultProto, which holds a status and an error message if an error occurred during compilation.</source>
          <target state="translated">This operation returns the result of a TPU compilation as a serialized CompilationResultProto, which holds a status and an error message if an error occurred during compilation.</target>
        </trans-unit>
        <trans-unit id="e2b8bbf455ec7dda7bf033c368dcb34b158ee06e" translate="yes" xml:space="preserve">
          <source>This operation returns the same result as the C++ std::nextafter function.</source>
          <target state="translated">이 작업은 C ++ std :: nextafter 함수와 동일한 결과를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="cba2fef602700f559d54f64ca39679c7fe5a39cf" translate="yes" xml:space="preserve">
          <source>This operation returns true if the queue is closed and false if the queue is open.</source>
          <target state="translated">이 작업은 큐가 닫혀 있으면 true를, 큐가 열려 있으면 false를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="dc131f95b04b052706f9dc5a2e0863ccce212278" translate="yes" xml:space="preserve">
          <source>This operation signals that no more elements will be enqueued in the given queue. Subsequent &lt;code&gt;enqueue&lt;/code&gt; and &lt;code&gt;enqueue_many&lt;/code&gt; operations will fail. Subsequent &lt;code&gt;dequeue&lt;/code&gt; and &lt;code&gt;dequeue_many&lt;/code&gt; operations will continue to succeed if sufficient elements remain in the queue. Subsequently dequeue and dequeue_many operations that would otherwise block waiting for more elements (if close hadn't been called) will now fail immediately.</source>
          <target state="translated">이 작업은 주어진 큐에 더 이상 요소가 큐에 들어 가지 않음을 나타냅니다. 후속 &lt;code&gt;enqueue&lt;/code&gt; 및 &lt;code&gt;enqueue_many&lt;/code&gt; 작업이 실패합니다. &lt;code&gt;dequeue&lt;/code&gt; 충분한 요소가 남아 있으면 후속 dequeue 및 &lt;code&gt;dequeue_many&lt;/code&gt; 작업이 계속 성공합니다. 결과적으로 더 많은 요소 (닫지 않은 경우)를 기다리는 것을 차단하는 dequeue 및 dequeue_many 작업이 즉시 실패합니다.</target>
        </trans-unit>
        <trans-unit id="03d601007c00ecaaf281c99e7ccdb7f989fc3f40" translate="yes" xml:space="preserve">
          <source>This operation signals that no more elements will be enqueued in the given queue. Subsequent Enqueue(Many) operations will fail. Subsequent Dequeue(Many) operations will continue to succeed if sufficient elements remain in the queue. Subsequent Dequeue(Many) operations that would block will fail immediately.</source>
          <target state="translated">This operation signals that no more elements will be enqueued in the given queue. Subsequent Enqueue(Many) operations will fail. Subsequent Dequeue(Many) operations will continue to succeed if sufficient elements remain in the queue. Subsequent Dequeue(Many) operations that would block will fail immediately.</target>
        </trans-unit>
        <trans-unit id="5ec52846420c7cbfc81445413d50c93e2addb827" translate="yes" xml:space="preserve">
          <source>This operation signals that no more new elements will be inserted in the given barrier. Subsequent InsertMany that try to introduce a new key will fail. Subsequent InsertMany operations that just add missing components to already existing elements will continue to succeed. Subsequent TakeMany operations will continue to succeed if sufficient completed elements remain in the barrier. Subsequent TakeMany operations that would block will fail immediately.</source>
          <target state="translated">This operation signals that no more new elements will be inserted in the given barrier. Subsequent InsertMany that try to introduce a new key will fail. Subsequent InsertMany operations that just add missing components to already existing elements will continue to succeed. Subsequent TakeMany operations will continue to succeed if sufficient completed elements remain in the barrier. Subsequent TakeMany operations that would block will fail immediately.</target>
        </trans-unit>
        <trans-unit id="ed8ef290710f5b794405ab349bc8048a526b3051" translate="yes" xml:space="preserve">
          <source>This operation slices each component tensor along the 0th dimension to make multiple queue elements. All of the tensors in &lt;code&gt;vals&lt;/code&gt; must have the same size in the 0th dimension.</source>
          <target state="translated">이 작업은 각 구성 요소 텐서를 0 차원을 따라 슬라이스하여 여러 큐 요소를 만듭니다. 에서 텐서의 모든 &lt;code&gt;vals&lt;/code&gt; 0 번째 차원의 크기가 동일해야합니다.</target>
        </trans-unit>
        <trans-unit id="b7a9602cce6855f9551ec64964df2f6660343d5e" translate="yes" xml:space="preserve">
          <source>This operation slices each component tensor along the 0th dimension to make multiple queue elements. All of the tuple components must have the same size in the 0th dimension.</source>
          <target state="translated">This operation slices each component tensor along the 0th dimension to make multiple queue elements. All of the tuple components must have the same size in the 0th dimension.</target>
        </trans-unit>
        <trans-unit id="b06acef6473406f9a6972f0bdd65c856a80109e7" translate="yes" xml:space="preserve">
          <source>This operation takes variable-length sequences (&lt;code&gt;hypothesis&lt;/code&gt; and &lt;code&gt;truth&lt;/code&gt;), each provided as a &lt;code&gt;SparseTensor&lt;/code&gt;, and computes the Levenshtein distance. You can normalize the edit distance by length of &lt;code&gt;truth&lt;/code&gt; by setting &lt;code&gt;normalize&lt;/code&gt; to true.</source>
          <target state="translated">이 연산은 각각 &lt;code&gt;SparseTensor&lt;/code&gt; 로 제공되는 가변 길이 시퀀스 ( &lt;code&gt;hypothesis&lt;/code&gt; 및 &lt;code&gt;truth&lt;/code&gt; )를 취하고 Levenshtein 거리를 계산합니다. &lt;code&gt;normalize&lt;/code&gt; 를 true 로 설정 하여 &lt;code&gt;truth&lt;/code&gt; 길이별로 편집 거리를 정규화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="4b844fb17a610af4c2dfbda43ce1ac8c2ea894a7" translate="yes" xml:space="preserve">
          <source>This operation tends to perform well when &lt;code&gt;A&lt;/code&gt; is more sparse, if the column size of the product is small (e.g. matrix-vector multiplication), if &lt;code&gt;sp_a.dense_shape&lt;/code&gt; takes on large values.</source>
          <target state="translated">&lt;code&gt;sp_a.dense_shape&lt;/code&gt; 가 큰 값을 사용하는 경우 곱의 열 크기가 작은 경우 (예 : 행렬-벡터 곱셈) &lt;code&gt;A&lt;/code&gt; 가 더 희소 한 경우이 연산이 잘 수행되는 경향이 있습니다.</target>
        </trans-unit>
        <trans-unit id="656ae1e1362cbc36310acc8deee39f6903aad8f9" translate="yes" xml:space="preserve">
          <source>This operation will block indefinitely until data is available.</source>
          <target state="translated">This operation will block indefinitely until data is available.</target>
        </trans-unit>
        <trans-unit id="ca0db1beb7905bc51f7f1596562bcd98102255d3" translate="yes" xml:space="preserve">
          <source>This operation will block indefinitely until data is available. Output &lt;code&gt;i&lt;/code&gt; corresponds to XLA tuple element &lt;code&gt;i&lt;/code&gt;.</source>
          <target state="translated">This operation will block indefinitely until data is available. Output &lt;code&gt;i&lt;/code&gt; corresponds to XLA tuple element &lt;code&gt;i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1051e1cb11d005837380c93974db8cb36d834ab5" translate="yes" xml:space="preserve">
          <source>This operation will generate a string suitable to be saved out to create a .wav audio file. It will be encoded in the 16-bit PCM format. It takes in float values in the range -1.0f to 1.0f, and any outside that value will be clamped to that range.</source>
          <target state="translated">이 작업은 .wav 오디오 파일을 만들기 위해 저장하기에 적합한 문자열을 생성합니다. 16 비트 PCM 형식으로 인코딩됩니다. -1.0f ~ 1.0f 범위의 부동 소수점 값을 취하며 해당 값 이외의 값은 해당 범위에 고정됩니다.</target>
        </trans-unit>
        <trans-unit id="bf6b9f0d6051cd83422b6ad2cb1617b5b6c44a65" translate="yes" xml:space="preserve">
          <source>This operation will output a tensor of shape &lt;code&gt;[1, 1, 1, 4]&lt;/code&gt;:</source>
          <target state="translated">이 작업은 모양 &lt;code&gt;[1, 1, 1, 4]&lt;/code&gt; 의 텐서를 출력합니다 .</target>
        </trans-unit>
        <trans-unit id="01c0abdcd1d63eef5d525eb4d621b9072cafca4f" translate="yes" xml:space="preserve">
          <source>This operation will output a tensor of shape &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt;:</source>
          <target state="translated">이 작업은 모양 &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; 의 텐서를 출력합니다 .</target>
        </trans-unit>
        <trans-unit id="f9c1bb170834121c155816075bc30535b34c3026" translate="yes" xml:space="preserve">
          <source>This operation would return the following:</source>
          <target state="translated">이 작업은 다음을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="c09d355015c640623e774187c625203da78fb3a6" translate="yes" xml:space="preserve">
          <source>This operation would return:</source>
          <target state="translated">이 작업은 다음을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="6585b279d1753d7936601f5ce821925656bfd5b2" translate="yes" xml:space="preserve">
          <source>This operation, for block size of 2, will return the following tensor of shape &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt;</source>
          <target state="translated">블록 크기가 2 인 경우이 작업은 다음 모양의 텐서를 반환합니다. &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="123e5c864ddc20e423825601cb576b64af53b67e" translate="yes" xml:space="preserve">
          <source>This operation, for block_size of 2, will return the following tensor of shape &lt;code&gt;[1, 1, 1, 12]&lt;/code&gt;</source>
          <target state="translated">이 작업은 block_size가 2 인 경우 다음 모양 &lt;code&gt;[1, 1, 1, 12]&lt;/code&gt; 텐서를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="2a0a130eb7e8314a609a2db135e21936c4a0de8b" translate="yes" xml:space="preserve">
          <source>This operator acts like a (batch) matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;m x n&lt;/code&gt; matrix. Again, this matrix &lt;code&gt;A&lt;/code&gt; may not be materialized, but for purposes of identifying and working with compatible arguments the shape is relevant.</source>
          <target state="translated">이것은 운영자가 (배치) 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;m x n&lt;/code&gt; 행렬입니다. 다시,이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않을 수 있지만, 호환 가능한 인수를 식별하고 작업하기 위해 형태가 관련이 있습니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9624d2140d2af8604c19c56292430ec7141d96ff" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] Toeplitz matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치]처럼 퇴 플리츠 행렬 작용 &lt;code&gt;A&lt;/code&gt; 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="ae991b61103c038a5ab6e26593ecbc7152e117f2" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] diagonal matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치] 대각 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5eea0437af7326077ca375b7627f553585750e30" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] identity matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치] 아이덴티티 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7036bf9c433fed406d0eb267aee69b2fb875c75f" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] lower triangular matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix.</source>
          <target state="translated">이것은 운영자가 삼각 행렬 낮은 [배치]처럼 행동 &lt;code&gt;A&lt;/code&gt; 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="0d5825859d807d72eb10161ef6b5b940c6fe0b9b" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;M x N&lt;/code&gt; matrix.</source>
          <target state="translated">이것은 오퍼레이터가 [배치] 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;M x N&lt;/code&gt; 행렬입니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6f99131310964b3eb6cd5147dace10a254e9fff2" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] of householder reflections with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이 연산자 형상 호주 반사의 [배치]처럼 행동 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="2c9497726784db48f14f606b75baa3af89ad92c3" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] of permutations with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이 연산자 형상으로 치환 한 [배치]처럼 행동 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="583ba682dbf34a68e239431a7d0b3d3bb383323a" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] square tridiagonal matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x M&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">This operator acts like a [batch] square tridiagonal matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt; , &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x M&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</target>
        </trans-unit>
        <trans-unit id="400eb5597c413c726e34a9f1e1bb7b69ea62bb78" translate="yes" xml:space="preserve">
          <source>This operator acts like a [batch] zero matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, M]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x M&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 오퍼레이터가 [배치]와 같은 영 행렬이 작용 &lt;code&gt;A&lt;/code&gt; 형상 &lt;code&gt;[B1,...,Bb, N, M]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x M&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다.</target>
        </trans-unit>
        <trans-unit id="b7102c53ecb6c13af874ea168315014a6e7dc84b" translate="yes" xml:space="preserve">
          <source>This operator acts like a block circulant matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이 연산자 블록 순환 행렬 같은 역할 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4c216274d20b8ffa480f3dfffdabad95ff0cda74" translate="yes" xml:space="preserve">
          <source>This operator acts like a circulant matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;N x N&lt;/code&gt; matrix. This matrix &lt;code&gt;A&lt;/code&gt; is not materialized, but for purposes of broadcasting this shape will be relevant.</source>
          <target state="translated">이것은 조작자가 순환 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 행렬입니다. 이 행렬 &lt;code&gt;A&lt;/code&gt; 는 구체화되지 않았지만 브로드 캐스팅 목적으로이 모양이 적합합니다. &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0f0a750eb3c4adb095723453eef766bb4bcd89f8" translate="yes" xml:space="preserve">
          <source>This operator acts like a scaled [batch] identity matrix &lt;code&gt;A&lt;/code&gt; with shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is a scaled version of the &lt;code&gt;N x N&lt;/code&gt; identity matrix.</source>
          <target state="translated">이 연산자 스케일링 [배치] 아이덴티티 매트릭스와 같은 역할을 형상 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;N x N&lt;/code&gt; 항등 행렬 의 스케일 된 버전입니다 . &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8b1442fc44774d80a4540791883d0146d00de836" translate="yes" xml:space="preserve">
          <source>This operator acts on [batch] matrix with compatible shape. &lt;code&gt;x&lt;/code&gt; is a batch matrix with compatible shape for &lt;code&gt;matmul&lt;/code&gt; and &lt;code&gt;solve&lt;/code&gt; if</source>
          <target state="translated">이 연산자는 호환 가능한 모양의 [일괄 처리] 매트릭스에서 작동합니다. &lt;code&gt;x&lt;/code&gt; 호환 형상으로 배치 행렬 &lt;code&gt;matmul&lt;/code&gt; 은 및 &lt;code&gt;solve&lt;/code&gt; 한다면</target>
        </trans-unit>
        <trans-unit id="a4840abea8050987eeb44a958dc938a96dc5772f" translate="yes" xml:space="preserve">
          <source>This operator acts on batch matrices with compatible shape. FILL IN WHAT IS MEANT BY COMPATIBLE SHAPE</source>
          <target state="translated">이 연산자는 모양이 호환되는 배치 매트릭스에서 작동합니다. 호환 가능한 쉐이프의 의미</target>
        </trans-unit>
        <trans-unit id="5cfb7dc84da5837b6c81afa0e3c1dd415d37bda4" translate="yes" xml:space="preserve">
          <source>This operator broadcasts the batch dimensions of &lt;code&gt;bands&lt;/code&gt; and the batch dimensions of &lt;code&gt;rhs&lt;/code&gt;.</source>
          <target state="translated">This operator broadcasts the batch dimensions of &lt;code&gt;bands&lt;/code&gt; and the batch dimensions of &lt;code&gt;rhs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="53228a3fac3cf2f50966b1ada24ef3b0466deb1e" translate="yes" xml:space="preserve">
          <source>This operator combines one or more linear operators &lt;code&gt;[op1,...,opJ]&lt;/code&gt;, building a new &lt;code&gt;LinearOperator&lt;/code&gt;, whose underlying matrix representation is square and has each operator &lt;code&gt;opi&lt;/code&gt; on the main diagonal, and zero's elsewhere.</source>
          <target state="translated">이 조작을 결합하는 하나 이상의 선형 연산자 &lt;code&gt;[op1,...,opJ]&lt;/code&gt; , 새로운 건물 &lt;code&gt;LinearOperator&lt;/code&gt; 그 기본 행렬 표현 정사각형 각 오퍼레이터 가지고 &lt;code&gt;opi&lt;/code&gt; 주 대각선을 다른 곳의 제로한다.</target>
        </trans-unit>
        <trans-unit id="564367f646774e8a861547adb060150a45779d5f" translate="yes" xml:space="preserve">
          <source>This operator composes one or more linear operators &lt;code&gt;[op1,...,opJ]&lt;/code&gt;, building a new &lt;code&gt;LinearOperator&lt;/code&gt; representing the Kronecker product: &lt;code&gt;op1 x op2 x .. opJ&lt;/code&gt; (we omit parentheses as the Kronecker product is associative).</source>
          <target state="translated">이 연산자는 하나 이상의 선형 연산자 &lt;code&gt;[op1,...,opJ]&lt;/code&gt; 를 구성 하여 Kronecker 제품을 나타내는 새로운 &lt;code&gt;LinearOperator&lt;/code&gt; 를 작성합니다. &lt;code&gt;op1 x op2 x .. opJ&lt;/code&gt; (Kronecker 제품이 연관되어 있으므로 괄호는 생략합니다).</target>
        </trans-unit>
        <trans-unit id="0c0d85ebac206e74618bf7317ca7c96fff15c835" translate="yes" xml:space="preserve">
          <source>This operator composes one or more linear operators &lt;code&gt;[op1,...,opJ]&lt;/code&gt;, building a new &lt;code&gt;LinearOperator&lt;/code&gt; with action defined by:</source>
          <target state="translated">이 연산자는 하나 이상의 선형 연산자 &lt;code&gt;[op1,...,opJ]&lt;/code&gt; 를 &lt;code&gt;LinearOperator&lt;/code&gt; 하여 다음에 의해 정의 된 동작 으로 새 LinearOperator 를 작성합니다.</target>
        </trans-unit>
        <trans-unit id="8e7241eaa8846c5c4338cb18a140b07ab3b606ae" translate="yes" xml:space="preserve">
          <source>This operator corresponds to a real matrix if and only if &lt;code&gt;H&lt;/code&gt; is Hermitian.</source>
          <target state="translated">이 연산자 는 &lt;code&gt;H&lt;/code&gt; 가 Hermitian 인 경우에만 실제 행렬에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="6f9242e838252063460c0276fd01dfac0ef01ff4" translate="yes" xml:space="preserve">
          <source>This operator corresponds to a real-valued matrix if and only if its spectrum is Hermitian.</source>
          <target state="translated">이 연산자는 스펙트럼이 에르 미트 인 경우에만 실수 값 행렬에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="3bcff2453a32e7e855e1bf28e92cc09521b4d919" translate="yes" xml:space="preserve">
          <source>This operator has two modes: in one mode both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are provided, in another mode neither are provided. &lt;code&gt;condition&lt;/code&gt; is always expected to be a &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt;.</source>
          <target state="translated">This operator has two modes: in one mode both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are provided, in another mode neither are provided. &lt;code&gt;condition&lt;/code&gt; is always expected to be a &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; of type &lt;code&gt;bool&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c618e51b272c823eef5139b9cc3a948f981f98e8" translate="yes" xml:space="preserve">
          <source>This operator is able to broadcast the leading (batch) dimensions, which sometimes requires copying data. If &lt;code&gt;batch_shape&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the operator can take arguments of any batch shape without copying. See examples.</source>
          <target state="translated">이 연산자는 선행 (일괄 처리) 차원을 브로드 캐스트 할 수 있으며 때로는 데이터를 복사해야합니다. 경우 &lt;code&gt;batch_shape&lt;/code&gt; 가 없습니다 &lt;code&gt;None&lt;/code&gt; , 운영자는 복사하지 않고 임의의 배치 형태의 인수를 취할 수 있습니다. 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="66cb218ad1e2e8f68e038b90d3bfb45bd6e74e63" translate="yes" xml:space="preserve">
          <source>This operator is able to broadcast the leading (batch) dimensions.</source>
          <target state="translated">이 연산자는 선행 (일괄) 차원을 브로드 캐스트 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="348a23cb6559c85829c515ac4244685e0efb46f2" translate="yes" xml:space="preserve">
          <source>This operator is considered non-singular if</source>
          <target state="translated">이 연산자는 다음과 같은 경우 단수로 간주됩니다</target>
        </trans-unit>
        <trans-unit id="b5e0ce71bd6146dbac079f3d21ad0a2a2a8c2054" translate="yes" xml:space="preserve">
          <source>This operator is initialized with a nested list of linear operators, which are combined into a new &lt;code&gt;LinearOperator&lt;/code&gt; whose underlying matrix representation is square and has each operator on or below the main diagonal, and zero's elsewhere. Each element of the outer list is a list of &lt;code&gt;LinearOperators&lt;/code&gt; corresponding to a row-partition of the blockwise structure. The number of &lt;code&gt;LinearOperator&lt;/code&gt;s in row-partion &lt;code&gt;i&lt;/code&gt; must be equal to &lt;code&gt;i&lt;/code&gt;.</source>
          <target state="translated">This operator is initialized with a nested list of linear operators, which are combined into a new &lt;code&gt;LinearOperator&lt;/code&gt; whose underlying matrix representation is square and has each operator on or below the main diagonal, and zero's elsewhere. Each element of the outer list is a list of &lt;code&gt;LinearOperators&lt;/code&gt; corresponding to a row-partition of the blockwise structure. The number of &lt;code&gt;LinearOperator&lt;/code&gt; s in row-partion &lt;code&gt;i&lt;/code&gt; must be equal to &lt;code&gt;i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d06a5054c0e8f5a488a0e50140ca1317d8ee8b76" translate="yes" xml:space="preserve">
          <source>This operator is positive definite if and only if &lt;code&gt;Real{H} &amp;gt; 0&lt;/code&gt;.</source>
          <target state="translated">이 연산자는 &lt;code&gt;Real{H} &amp;gt; 0&lt;/code&gt; 인 경우에만 양수 입니다.</target>
        </trans-unit>
        <trans-unit id="fa787331edbdbf77b6543a837e62e8acfa555fdd" translate="yes" xml:space="preserve">
          <source>This operator is self-adjoint if and only if &lt;code&gt;H&lt;/code&gt; is real.</source>
          <target state="translated">이 연산자는 &lt;code&gt;H&lt;/code&gt; 가 실수 인 경우에만 자체 인접합니다 .</target>
        </trans-unit>
        <trans-unit id="0434efb4cb6fe37aceabe23ccb563dea7d82d49a" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the maximum such that:</source>
          <target state="translated">이 연산자는 분류되지 않은 세그먼트 합계 연산자 found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt; 와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 다음과 같은 최대 값을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="f0203b5b1fedf802a969aad64e740ba2ad439f1c" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the minimum such that:</source>
          <target state="translated">이 연산자는 분류되지 않은 세그먼트 합계 연산자 found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt; 와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 다음과 같은 최소값을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="9b525fce235ebc8f800bcb2ded78049fa74f120a" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the product of all entries belonging to a segment such that:</source>
          <target state="translated">이 연산자는 분류되지 않은 세그먼트 합계 연산자 found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt; 와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 세그먼트에 속하는 모든 항목의 곱을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="59fd9e153dcbd12bffedb241b5f88000e9237c11" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Additionally to computing the sum over segments, it divides the results by sqrt(N).</source>
          <target state="translated">이 연산자는 &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;여기&lt;/a&gt; 에있는 분류되지 않은 세그먼트 합계 연산자와 유사합니다 . 또한 세그먼트에 대한 합계를 계산할 때 결과를 sqrt (N)로 나눕니다.</target>
        </trans-unit>
        <trans-unit id="a4a7cb1afea6269197bd76bbd4732c1dbecdf7fc" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Instead of computing the sum over segments, it computes the mean of all entries belonging to a segment such that:</source>
          <target state="translated">이 연산자는 &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;여기&lt;/a&gt; 에있는 분류되지 않은 세그먼트 합계 연산자와 유사합니다 . 세그먼트에 대한 합계를 계산하는 대신 세그먼트에 속하는 모든 항목의 평균을 다음과 같이 계산합니다.</target>
        </trans-unit>
        <trans-unit id="52ed4dad04ede72e0a76f0501a2814cdc539eef1" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the maximum such that:</source>
          <target state="translated">This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the maximum such that:</target>
        </trans-unit>
        <trans-unit id="d5555cd5610bd14e5cd5be64e806dbe517b909cf" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the minimum such that:</source>
          <target state="translated">This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the minimum such that:</target>
        </trans-unit>
        <trans-unit id="5626f77bd1ee157ca8ad5f5950e88d3290b6e7a5" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the product of all entries belonging to a segment such that:</source>
          <target state="translated">This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;(here)&lt;/a&gt;. Instead of computing the sum over segments, it computes the product of all entries belonging to a segment such that:</target>
        </trans-unit>
        <trans-unit id="b4490e7220bb7e840d8af406c98df4879f8c31ca" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Additionally to computing the sum over segments, it divides the results by sqrt(N).</source>
          <target state="translated">This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Additionally to computing the sum over segments, it divides the results by sqrt(N).</target>
        </trans-unit>
        <trans-unit id="5fcc2d9bddedbecbae737fa85ec20cea5d89c2f2" translate="yes" xml:space="preserve">
          <source>This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Instead of computing the sum over segments, it computes the mean of all entries belonging to a segment such that:</source>
          <target state="translated">This operator is similar to the unsorted segment sum operator found &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/python/math_ops#UnsortedSegmentSum&quot;&gt;here&lt;/a&gt;. Instead of computing the sum over segments, it computes the mean of all entries belonging to a segment such that:</target>
        </trans-unit>
        <trans-unit id="83929e057e5aae77fa1c5e82493e5f81ffd7c7d5" translate="yes" xml:space="preserve">
          <source>This operator represents the adjoint of another operator.</source>
          <target state="translated">이 연산자는 다른 연산자의 인접자를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="011faa1fcbdac7f7db43d7798ee8f420d25df1c3" translate="yes" xml:space="preserve">
          <source>This operator represents the inverse of another operator.</source>
          <target state="translated">이 연산자는 다른 연산자의 역수를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="d243b49a16809ba508894c3eb53aaf2744d8ff3a" translate="yes" xml:space="preserve">
          <source>This operator represents the loop termination condition used by the &quot;pivot&quot; switches of a loop.</source>
          <target state="translated">This operator represents the loop termination condition used by the &quot;pivot&quot; switches of a loop.</target>
        </trans-unit>
        <trans-unit id="efbc958735ecb1b79fddfae66e71db4081b1ceb7" translate="yes" xml:space="preserve">
          <source>This operator takes the given &lt;code&gt;SparseTensor&lt;/code&gt; and adds it to a container object (a &lt;code&gt;SparseTensorsMap&lt;/code&gt;). A unique key within this container is generated in the form of an &lt;code&gt;int64&lt;/code&gt;, and this is the value that is returned.</source>
          <target state="translated">This operator takes the given &lt;code&gt;SparseTensor&lt;/code&gt; and adds it to a container object (a &lt;code&gt;SparseTensorsMap&lt;/code&gt; ). A unique key within this container is generated in the form of an &lt;code&gt;int64&lt;/code&gt; , and this is the value that is returned.</target>
        </trans-unit>
        <trans-unit id="8beab818ce538eb5919197a98807ea337b127bd0" translate="yes" xml:space="preserve">
          <source>This operator tries to squeeze as much precision as possible into an output with a lower bit depth by calculating the actual min and max values found in the data. For example, maybe that quint16 input has no values lower than 16,384 and none higher than 49,152. That means only half the range is actually needed, all the float interpretations are between -0.5f and 0.5f, so if we want to compress the data into a quint8 output, we can use that range rather than the theoretical -1.0f to 1.0f that is suggested by the input min and max.</source>
          <target state="translated">This operator tries to squeeze as much precision as possible into an output with a lower bit depth by calculating the actual min and max values found in the data. For example, maybe that quint16 input has no values lower than 16,384 and none higher than 49,152. That means only half the range is actually needed, all the float interpretations are between -0.5f and 0.5f, so if we want to compress the data into a quint8 output, we can use that range rather than the theoretical -1.0f to 1.0f that is suggested by the input min and max.</target>
        </trans-unit>
        <trans-unit id="caac5d3bbf4d0945a7bd985970cd4106cce90915" translate="yes" xml:space="preserve">
          <source>This operator wraps a [batch] matrix &lt;code&gt;A&lt;/code&gt; (which is a &lt;code&gt;Tensor&lt;/code&gt;) with shape &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; for some &lt;code&gt;b &amp;gt;= 0&lt;/code&gt;. The first &lt;code&gt;b&lt;/code&gt; indices index a batch member. For every batch index &lt;code&gt;(i1,...,ib)&lt;/code&gt;, &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; is an &lt;code&gt;M x N&lt;/code&gt; matrix.</source>
          <target state="translated">이 연산자 는 일부 &lt;code&gt;b &amp;gt;= 0&lt;/code&gt; 대해 &lt;code&gt;[B1,...,Bb, M, N]&lt;/code&gt; 모양 의 [일괄 처리] 행렬 &lt;code&gt;A&lt;/code&gt; ( &lt;code&gt;Tensor&lt;/code&gt; )를 래핑합니다 . 첫 번째 &lt;code&gt;b&lt;/code&gt; 인덱스는 배치 멤버를 색인화합니다. 모든 배치 인덱스 &lt;code&gt;(i1,...,ib)&lt;/code&gt; 에 대해 &lt;code&gt;A[i1,...,ib, : :]&lt;/code&gt; 는 &lt;code&gt;M x N&lt;/code&gt; 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="b7a64029550dddacbaa84a5c9b1e8fcd91b9538b" translate="yes" xml:space="preserve">
          <source>This optimizer class is &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; aware, which means it automatically sums gradients across all replicas. To average gradients, you divide your loss by the global batch size, which is done automatically if you use &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; built-in training or evaluation loops. See the &lt;code&gt;reduction&lt;/code&gt; argument of your loss which should be set to &lt;a href=&quot;../losses/reduction#SUM_OVER_BATCH_SIZE&quot;&gt;&lt;code&gt;tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE&lt;/code&gt;&lt;/a&gt; for averaging or &lt;a href=&quot;../losses/reduction#SUM&quot;&gt;&lt;code&gt;tf.keras.losses.Reduction.SUM&lt;/code&gt;&lt;/a&gt; for not.</source>
          <target state="translated">이 최적화 프로그램 클래스는 &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; 를&lt;/a&gt; 인식하므로 모든 복제본에서 그라디언트를 자동으로 합합니다. 그라디언트를 평균화하려면 손실을 전역 배치 크기로 &lt;a href=&quot;../../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; 기본 제공 교육 또는 평가 루프 를 사용하면 자동으로 수행됩니다 . 참고 항목 &lt;code&gt;reduction&lt;/code&gt; 로 설정해야합니다 귀하의 손실의 인수 &lt;a href=&quot;../losses/reduction#SUM_OVER_BATCH_SIZE&quot;&gt; &lt;code&gt;tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE&lt;/code&gt; &lt;/a&gt; 평균 또는 대한 &lt;a href=&quot;../losses/reduction#SUM&quot;&gt; &lt;code&gt;tf.keras.losses.Reduction.SUM&lt;/code&gt; &lt;/a&gt; 하지 않는합니다.</target>
        </trans-unit>
        <trans-unit id="f9ca3ab79a1177cb06784d426253ffabbbc2a6a4" translate="yes" xml:space="preserve">
          <source>This optimizer takes care of regularization of unseen features in a mini batch by updating them when they are seen with a closed form update rule that is equivalent to having updated them on every mini-batch.</source>
          <target state="translated">이 옵티마이 저는 미니 배치에서 보이지 않는 기능을 모든 미니 배치에서 업데이트 한 것과 동일한 닫힌 양식 업데이트 규칙으로 표시 될 때 업데이트함으로써 정규화를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="9a8b5c268bde39d241894c5b95721103ebdbc425" translate="yes" xml:space="preserve">
          <source>This optimizer wraps another optimizer and applies loss scaling to it via a &lt;code&gt;LossScale&lt;/code&gt;. Loss scaling is applied whenever gradients are computed, either through &lt;code&gt;minimize()&lt;/code&gt; or &lt;code&gt;get_gradients()&lt;/code&gt;. The loss scale is updated via &lt;a href=&quot;../../../mixed_precision/experimental/lossscale#update&quot;&gt;&lt;code&gt;LossScale.update()&lt;/code&gt;&lt;/a&gt; whenever gradients are applied, either through &lt;code&gt;minimize()&lt;/code&gt; or &lt;code&gt;apply_gradients()&lt;/code&gt;. For example:</source>
          <target state="translated">이 옵티마이 저는 다른 옵티 마이저를 감싸고 &lt;code&gt;LossScale&lt;/code&gt; 을 통해 손실 스케일링을 적용 합니다. 손실 스케일링은 &lt;code&gt;minimize()&lt;/code&gt; 또는 &lt;code&gt;get_gradients()&lt;/code&gt; 통해 그래디언트가 계산 될 때마다 적용됩니다 . 손실 스케일은 &lt;code&gt;minimize()&lt;/code&gt; 또는 &lt;code&gt;apply_gradients()&lt;/code&gt; 통해 그래디언트가 적용될 때마다 &lt;a href=&quot;../../../mixed_precision/experimental/lossscale#update&quot;&gt; &lt;code&gt;LossScale.update()&lt;/code&gt; &lt;/a&gt; 를 통해 업데이트됩니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="a13f36128710145f1603618c3c0bcd6462911f2d" translate="yes" xml:space="preserve">
          <source>This optimizer wraps another optimizer and applies loss scaling to it via a &lt;code&gt;LossScale&lt;/code&gt;. Loss scaling is applied whenever gradients are computed, such as through &lt;code&gt;minimize()&lt;/code&gt;.</source>
          <target state="translated">이 옵티마이 저는 다른 옵티 마이저를 감싸고 &lt;code&gt;LossScale&lt;/code&gt; 을 통해 손실 스케일링을 적용 합니다. 그래디언트가 계산 될 때마다 감소 스케일링 등을 통해 같은인가 &lt;code&gt;minimize()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="64e321c394397e96aca6614583438da557ccee0e" translate="yes" xml:space="preserve">
          <source>This option can be used to override the default policy for how to handle external state when serializing a dataset or checkpointing its iterator. There are three settings available - IGNORE: in which we completely ignore any state; WARN: We warn the user that some state might be thrown away; FAIL: We fail if any state is being captured.</source>
          <target state="translated">This option can be used to override the default policy for how to handle external state when serializing a dataset or checkpointing its iterator. There are three settings available - IGNORE: in which we completely ignore any state; WARN: We warn the user that some state might be thrown away; FAIL: We fail if any state is being captured.</target>
        </trans-unit>
        <trans-unit id="fa77eb4223231696da9576378f71e5fd1b4c5fa1" translate="yes" xml:space="preserve">
          <source>This outputs a &lt;code&gt;batch_size&lt;/code&gt; bool array, an entry &lt;code&gt;out[i]&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt; if the prediction for the target class is among the top &lt;code&gt;k&lt;/code&gt; predictions among all predictions for example &lt;code&gt;i&lt;/code&gt;. Note that the behavior of &lt;code&gt;InTopK&lt;/code&gt; differs from the &lt;code&gt;TopK&lt;/code&gt; op in its handling of ties; if multiple classes have the same prediction value and straddle the top-&lt;code&gt;k&lt;/code&gt; boundary, all of those classes are considered to be in the top &lt;code&gt;k&lt;/code&gt;.</source>
          <target state="translated">This outputs a &lt;code&gt;batch_size&lt;/code&gt; bool array, an entry &lt;code&gt;out[i]&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt; if the prediction for the target class is among the top &lt;code&gt;k&lt;/code&gt; predictions among all predictions for example &lt;code&gt;i&lt;/code&gt; . Note that the behavior of &lt;code&gt;InTopK&lt;/code&gt; differs from the &lt;code&gt;TopK&lt;/code&gt; op in its handling of ties; if multiple classes have the same prediction value and straddle the top- &lt;code&gt;k&lt;/code&gt; boundary, all of those classes are considered to be in the top &lt;code&gt;k&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="43b5cb445e044712f2e69a5344f02f5be0ddda93" translate="yes" xml:space="preserve">
          <source>This outputs a &lt;code&gt;batch_size&lt;/code&gt; bool array, an entry &lt;code&gt;out[i]&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt; if the prediction for the target class is finite (not inf, -inf, or nan) and among the top &lt;code&gt;k&lt;/code&gt; predictions among all predictions for example &lt;code&gt;i&lt;/code&gt;. Note that the behavior of &lt;code&gt;InTopK&lt;/code&gt; differs from the &lt;code&gt;TopK&lt;/code&gt; op in its handling of ties; if multiple classes have the same prediction value and straddle the top-&lt;code&gt;k&lt;/code&gt; boundary, all of those classes are considered to be in the top &lt;code&gt;k&lt;/code&gt;.</source>
          <target state="translated">이것은 &lt;code&gt;batch_size&lt;/code&gt; bool 배열을 출력합니다 . 대상 클래스에 대한 예측이 유한 한 경우 (inf, -inf 또는 nan 아님) 모든 예측 중 예를 들어 &lt;code&gt;i&lt;/code&gt; &lt;code&gt;k&lt;/code&gt; 중 최상위 k 예측 중 하나 인 경우 &lt;code&gt;out[i]&lt;/code&gt; 은 &lt;code&gt;true&lt;/code&gt; 입니다. &lt;code&gt;InTopK&lt;/code&gt; 의 동작 은 관계 처리에서 &lt;code&gt;TopK&lt;/code&gt; op 와 다릅니다 . 여러 클래스가 동일한 예측 값을 갖고 상위 &lt;code&gt;k&lt;/code&gt; 경계에 걸치면 모든 클래스가 상위 &lt;code&gt;k&lt;/code&gt; 에있는 것으로 간주됩니다 .</target>
        </trans-unit>
        <trans-unit id="345380820e023cc35c074a4e6039205226041719" translate="yes" xml:space="preserve">
          <source>This overload raises a &lt;code&gt;TypeError&lt;/code&gt; when the user inadvertently treats a &lt;code&gt;Tensor&lt;/code&gt; as a boolean (most commonly in an &lt;code&gt;if&lt;/code&gt; or &lt;code&gt;while&lt;/code&gt; statement), in code that was not converted by AutoGraph. For example:</source>
          <target state="translated">이 오버로드 는 사용자 가 AutoGraph에 의해 변환되지 않은 코드 에서 사용자가 실수로 &lt;code&gt;Tensor&lt;/code&gt; 를 부울 (대부분 &lt;code&gt;if&lt;/code&gt; 또는 &lt;code&gt;while&lt;/code&gt; 문에서) 로 취급 할 때 &lt;code&gt;TypeError&lt;/code&gt; 를 발생시킵니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="5f63c68c6b6d06032eeae666e8d05a28d8b6e750" translate="yes" xml:space="preserve">
          <source>This package defines ops for manipulating ragged tensors (&lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;), which are tensors with non-uniform shapes. In particular, each &lt;code&gt;RaggedTensor&lt;/code&gt; has one or more &lt;em&gt;ragged dimensions&lt;/em&gt;, which are dimensions whose slices may have different lengths. For example, the inner (column) dimension of &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; is ragged, since the column slices (&lt;code&gt;rt[0, :]&lt;/code&gt;, ..., &lt;code&gt;rt[4, :]&lt;/code&gt;) have different lengths. For a more detailed description of ragged tensors, see the &lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt; class documentation and the &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide&lt;/a&gt;.</source>
          <target state="translated">이 패키지는 비정형 모양의 텐서 인 비정형 텐서 ( &lt;a href=&quot;../../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; ) 조작을위한 ops를 정의합니다 . 특히, 각각의 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 하나 이상의 &lt;em&gt;비정형 치수를 가지며&lt;/em&gt; , 이는 슬라이스의 길이가 다를 수있는 치수이다. 예를 들면, 내측 (열) 치수 &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; 울퉁불퉁하고, 열 슬라이스 사람 ( &lt;code&gt;rt[0, :]&lt;/code&gt; , ..., &lt;code&gt;rt[4, :]&lt;/code&gt; )는 길이가 다릅니다. 비정형 텐서에 대한 자세한 설명은 &lt;a href=&quot;../../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 클래스 문서 및 &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide를 참조하십시오&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3e4f0989d73eb8b679bcdf7fff408eece47a531f" translate="yes" xml:space="preserve">
          <source>This package defines ops for manipulating ragged tensors (&lt;a href=&quot;raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;), which are tensors with non-uniform shapes. In particular, each &lt;code&gt;RaggedTensor&lt;/code&gt; has one or more &lt;em&gt;ragged dimensions&lt;/em&gt;, which are dimensions whose slices may have different lengths. For example, the inner (column) dimension of &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; is ragged, since the column slices (&lt;code&gt;rt[0, :]&lt;/code&gt;, ..., &lt;code&gt;rt[4, :]&lt;/code&gt;) have different lengths. For a more detailed description of ragged tensors, see the &lt;a href=&quot;raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt; class documentation and the &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide&lt;/a&gt;.</source>
          <target state="translated">이 패키지는 비정형 모양의 텐서 인 비정형 텐서 ( &lt;a href=&quot;raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; ) 조작을위한 ops를 정의합니다 . 특히, 각각의 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 하나 이상의 &lt;em&gt;비정형 치수를 가지며&lt;/em&gt; , 이는 슬라이스의 길이가 다를 수있는 치수이다. 예를 들면, 내측 (열) 치수 &lt;code&gt;rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]&lt;/code&gt; 울퉁불퉁하고, 열 슬라이스 사람 ( &lt;code&gt;rt[0, :]&lt;/code&gt; , ..., &lt;code&gt;rt[4, :]&lt;/code&gt; )는 길이가 다릅니다. 비정형 텐서에 대한 자세한 설명은 &lt;a href=&quot;raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 클래스 문서 및 &lt;a href=&quot;https://www.tensorflow.org/guide/ragged_tensors&quot;&gt;Ragged Tensor Guide를 참조하십시오&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ca381bc7587c1d86ccea71cf77a3f51f18c01785" translate="yes" xml:space="preserve">
          <source>This partitioner will shard a Variable along one axis, attempting to keep the maximum shard size below &lt;code&gt;max_shard_bytes&lt;/code&gt;. In practice, this is not always possible when sharding along only one axis. When this happens, this axis is sharded as much as possible (i.e., every dimension becomes a separate shard).</source>
          <target state="translated">이 파티 &lt;code&gt;max_shard_bytes&lt;/code&gt; 최대 샤드 크기를 max_shard_bytes 미만으로 유지하려고 한 축을 따라 변수를 샤딩합니다 . 실제로, 이것은 하나의 축만을 따라 샤딩 할 때 항상 가능하지는 않습니다. 이 경우이 축은 가능한 한 샤드됩니다 (즉, 모든 치수가 별도의 샤드가 됨).</target>
        </trans-unit>
        <trans-unit id="fd457ac6c886ad4d6a9b1c2c9ed70e07ea8ad467" translate="yes" xml:space="preserve">
          <source>This produces files called &quot;timeline-</source>
          <target state="translated">&quot;타임 라인-</target>
        </trans-unit>
        <trans-unit id="9f7b45ed5e5688563844dafc256f1f022fd16e33" translate="yes" xml:space="preserve">
          <source>This property only works when the &lt;code&gt;TPUEmbedding&lt;/code&gt; object is created under a non-TPU strategy. This is intended to be used to for CPU based lookup when creating a serving checkpoint.</source>
          <target state="translated">This property only works when the &lt;code&gt;TPUEmbedding&lt;/code&gt; object is created under a non-TPU strategy. This is intended to be used to for CPU based lookup when creating a serving checkpoint.</target>
        </trans-unit>
        <trans-unit id="650852868a3688b5e43945d526af2b7a7abb7659" translate="yes" xml:space="preserve">
          <source>This regressor ignores feature values and will learn to predict the average value of each label.</source>
          <target state="translated">이 회귀 분석에서는 피처 값을 무시하고 각 레이블의 평균값을 예측하는 방법을 배웁니다.</target>
        </trans-unit>
        <trans-unit id="6b4e11e2fc93d180cb8cb79e60f96113138df290" translate="yes" xml:space="preserve">
          <source>This returns a ClusterSpec object for use based on information from the specified initialization parameters and Slurm environment variables. The cluster specification is resolved each time this function is called. The resolver extract hostnames of nodes by scontrol and pack tasks in that order until a node a has number of tasks that is equal to specification. GPUs on nodes are allocated to tasks by specification through setting CUDA_VISIBLE_DEVICES environment variable.</source>
          <target state="translated">지정된 초기화 매개 변수 및 Slurm 환경 변수의 정보를 기반으로 사용할 ClusterSpec 객체를 반환합니다. 이 기능이 호출 될 때마다 클러스터 사양이 해결됩니다. 리졸버는 노드 a가 스펙과 동일한 수의 태스크를 가질 때까지 scontrol에 의해 노드의 호스트 이름을 추출하고 순서대로 태스크를 압축합니다. CUDA_VISIBLE_DEVICES 환경 변수 설정을 통해 사양에 따라 노드의 GPU가 작업에 할당됩니다.</target>
        </trans-unit>
        <trans-unit id="ce42bdd47f55adee51dc4ae146a85efc32785746" translate="yes" xml:space="preserve">
          <source>This returns a ClusterSpec object for use based on information from the specified instance group. We will retrieve the information from the GCE APIs every time this method is called.</source>
          <target state="translated">지정된 인스턴스 그룹의 정보를 기반으로 사용할 ClusterSpec 객체를 반환합니다. 이 메소드가 호출 될 때마다 GCE API에서 정보를 검색합니다.</target>
        </trans-unit>
        <trans-unit id="d4e36425f3d932370ce3f31b5b37e6bd2c5dbb8b" translate="yes" xml:space="preserve">
          <source>This returns a function outputting &lt;code&gt;features&lt;/code&gt; and &lt;code&gt;targets&lt;/code&gt; based on the dict of numpy arrays. The dict &lt;code&gt;features&lt;/code&gt; has the same keys as the &lt;code&gt;x&lt;/code&gt;. The dict &lt;code&gt;targets&lt;/code&gt; has the same keys as the &lt;code&gt;y&lt;/code&gt; if &lt;code&gt;y&lt;/code&gt; is a dict.</source>
          <target state="translated">이것은 numpy 배열의 dict를 기반으로 &lt;code&gt;features&lt;/code&gt; 및 &lt;code&gt;targets&lt;/code&gt; 출력하는 함수를 반환 합니다. dict &lt;code&gt;features&lt;/code&gt; 은 &lt;code&gt;x&lt;/code&gt; 와 동일한 키를 갖습니다 . 딕셔너리의 &lt;code&gt;targets&lt;/code&gt; 은 AS 동일한 키를 가지고 &lt;code&gt;y&lt;/code&gt; 경우 &lt;code&gt;y&lt;/code&gt; 는 사전인가된다.</target>
        </trans-unit>
        <trans-unit id="091f487524e5d0cdc7f2f7122f0e27fecc0512d2" translate="yes" xml:space="preserve">
          <source>This returns the job name and task index for the process which calls this function according to its rank and cluster specification. The job name and task index are set after a cluster is constructed by cluster_spec otherwise defaults to None.</source>
          <target state="translated">순위 및 클러스터 스펙에 따라이 함수를 호출하는 프로세스의 작업 이름 및 작업 색인을 리턴합니다. 작업 이름 및 작업 색인은 cluster_spec에 의해 클러스터가 구성된 후에 설정되며 그렇지 않으면 기본값은 없음입니다.</target>
        </trans-unit>
        <trans-unit id="9e86e167f9dfaedec2287e6304deddcf9a677504" translate="yes" xml:space="preserve">
          <source>This returns the number of accelerator cores (such as GPUs and TPUs) available per worker.</source>
          <target state="translated">이렇게하면 작업 자당 사용 가능한 가속기 코어 (GPU 및 TPU 등) 수가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="43f97f599a6e5c9f5b6d870e441e77232b9c4ee2" translate="yes" xml:space="preserve">
          <source>This sampler is useful when the target classes approximately follow such a distribution - for example, if the classes represent words in a lexicon sorted in decreasing order of frequency. If your classes are not ordered by decreasing frequency, do not use this op.</source>
          <target state="translated">이 샘플러는 대상 클래스가 대략 같은 분포를 따르는 경우에 유용합니다 (예를 들어 클래스가 어휘의 단어를 빈도의 내림차순으로 정렬 한 경우). 수업 횟수를 줄이면서 수업을 주문하지 않으면이 op를 사용하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="f4116f5a13b723775fce909b3d142c6ace24a3f4" translate="yes" xml:space="preserve">
          <source>This set may grow over time, so it's important the signature of creators is as mentioned above.</source>
          <target state="translated">이 세트는 시간이 지남에 따라 커질 수 있으므로 제작자의 서명이 위에 언급 된대로 중요합니다.</target>
        </trans-unit>
        <trans-unit id="642d4b5b813040e42f63e66f6c2fcb5de77a52c5" translate="yes" xml:space="preserve">
          <source>This should only be used when the if then/else body functions do not have stateful ops.</source>
          <target state="translated">This should only be used when the if then/else body functions do not have stateful ops.</target>
        </trans-unit>
        <trans-unit id="5fc235c555c96c210745b72880b680aa6b17dbdb" translate="yes" xml:space="preserve">
          <source>This should only be used when the while condition and body functions do not have stateful ops.</source>
          <target state="translated">This should only be used when the while condition and body functions do not have stateful ops.</target>
        </trans-unit>
        <trans-unit id="6fe6f784df295b3702cbf845894c09377130127e" translate="yes" xml:space="preserve">
          <source>This simply wraps &lt;code&gt;compute_gradients()&lt;/code&gt; from the real optimizer. The gradients will be aggregated in &lt;code&gt;apply_gradients()&lt;/code&gt; so that user can modify the gradients like clipping with per replica global norm if needed. The global norm with aggregated gradients can be bad as one replica's huge gradients can hurt the gradients from other replicas.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 &lt;code&gt;compute_gradients()&lt;/code&gt; 를 래핑 합니다. 그라디언트는 &lt;code&gt;apply_gradients()&lt;/code&gt; 집계 되므로 사용자는 필요한 경우 복제본 전역 표준을 사용한 클리핑과 같은 그라디언트를 수정할 수 있습니다. 하나의 복제본의 거대한 그라디언트가 다른 복제본의 그라디언트를 손상시킬 수 있으므로 집계 된 그라디언트가있는 전역 표준은 나쁠 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="8231e710a02b190ee62057d8ce9e6843f584733f" translate="yes" xml:space="preserve">
          <source>This simply wraps the compute_gradients() from the real optimizer. The gradients will be aggregated in the apply_gradients() so that user can modify the gradients like clipping with per replica global norm if needed. The global norm with aggregated gradients can be bad as one replica's huge gradients can hurt the gradients from other replicas.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 compute_gradients ()를 래핑합니다. apply_gradients ()에서 그라디언트가 집계되므로 사용자는 필요한 경우 복제본 전역 표준을 사용한 클리핑과 같은 그라디언트를 수정할 수 있습니다. 하나의 복제본의 거대한 그라디언트가 다른 복제본의 그라디언트를 손상시킬 수 있으므로 집계 된 그라디언트가있는 전역 표준은 나쁠 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9535c2c156931877173be6ce0ef4fcc7c39ade4d" translate="yes" xml:space="preserve">
          <source>This simply wraps the get_slot() from the actual optimizer.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 get_slot ()을 래핑합니다.</target>
        </trans-unit>
        <trans-unit id="627b6a914c45360f47c7270bf7239e5630834ac1" translate="yes" xml:space="preserve">
          <source>This simply wraps the get_slot_names() from the actual optimizer.</source>
          <target state="translated">이것은 단순히 실제 최적화 프로그램에서 get_slot_names ()를 래핑합니다.</target>
        </trans-unit>
        <trans-unit id="481aba790f7180557002a29e34e41b2834d82d24" translate="yes" xml:space="preserve">
          <source>This starts services in the background. The services started depend on the parameters to the constructor and may include:</source>
          <target state="translated">백그라운드에서 서비스를 시작합니다. 시작된 서비스는 생성자에 대한 매개 변수에 따라 다음을 포함 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="61ba97b856d34fcc84e3cd4a4201db78d7018540" translate="yes" xml:space="preserve">
          <source>This strategy implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar to &lt;a href=&quot;../../../../distribute/mirroredstrategy&quot;&gt;&lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt;&lt;/a&gt;, it creates copies of all variables in the model on each device across all workers.</source>
          <target state="translated">이 전략은 잠재적으로 여러 GPU가있는 여러 작업자에게 동기식 분산 교육을 구현합니다. &lt;a href=&quot;../../../../distribute/mirroredstrategy&quot;&gt; &lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt; &lt;/a&gt; 와 유사하게 모든 작업자의 각 장치에서 모델의 모든 변수 사본을 작성합니다.</target>
        </trans-unit>
        <trans-unit id="f19046d3b0cb6c64ecb2b4f8764cc9d33c4854f1" translate="yes" xml:space="preserve">
          <source>This strategy implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar to &lt;a href=&quot;../mirroredstrategy&quot;&gt;&lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt;&lt;/a&gt;, it creates copies of all variables in the model on each device across all workers.</source>
          <target state="translated">이 전략은 잠재적으로 여러 GPU가있는 여러 작업자에게 동기식 분산 교육을 구현합니다. &lt;a href=&quot;../mirroredstrategy&quot;&gt; &lt;code&gt;tf.distribute.MirroredStrategy&lt;/code&gt; &lt;/a&gt; 와 유사하게 모든 작업자의 각 장치에서 모델의 모든 변수 사본을 작성합니다.</target>
        </trans-unit>
        <trans-unit id="04f8a8d0444c29ec6e24f3fc468a55853c986597" translate="yes" xml:space="preserve">
          <source>This strategy is typically used for training on one machine with multiple GPUs. For TPUs, use &lt;a href=&quot;../../../distribute/tpustrategy&quot;&gt;&lt;code&gt;tf.distribute.TPUStrategy&lt;/code&gt;&lt;/a&gt;. To use &lt;code&gt;MirroredStrategy&lt;/code&gt; with multiple workers, please refer to &lt;a href=&quot;../../../distribute/experimental/multiworkermirroredstrategy&quot;&gt;&lt;code&gt;tf.distribute.experimental.MultiWorkerMirroredStrategy&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This strategy is typically used for training on one machine with multiple GPUs. For TPUs, use &lt;a href=&quot;../../../distribute/tpustrategy&quot;&gt; &lt;code&gt;tf.distribute.TPUStrategy&lt;/code&gt; &lt;/a&gt;. To use &lt;code&gt;MirroredStrategy&lt;/code&gt; with multiple workers, please refer to &lt;a href=&quot;../../../distribute/experimental/multiworkermirroredstrategy&quot;&gt; &lt;code&gt;tf.distribute.experimental.MultiWorkerMirroredStrategy&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="7c008960642435f7f796dcc4d6d07c58ad8a9370" translate="yes" xml:space="preserve">
          <source>This strategy is typically used for training on one machine with multiple GPUs. For TPUs, use &lt;a href=&quot;tpustrategy&quot;&gt;&lt;code&gt;tf.distribute.TPUStrategy&lt;/code&gt;&lt;/a&gt;. To use &lt;code&gt;MirroredStrategy&lt;/code&gt; with multiple workers, please refer to &lt;a href=&quot;experimental/multiworkermirroredstrategy&quot;&gt;&lt;code&gt;tf.distribute.experimental.MultiWorkerMirroredStrategy&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This strategy is typically used for training on one machine with multiple GPUs. For TPUs, use &lt;a href=&quot;tpustrategy&quot;&gt; &lt;code&gt;tf.distribute.TPUStrategy&lt;/code&gt; &lt;/a&gt;. To use &lt;code&gt;MirroredStrategy&lt;/code&gt; with multiple workers, please refer to &lt;a href=&quot;experimental/multiworkermirroredstrategy&quot;&gt; &lt;code&gt;tf.distribute.experimental.MultiWorkerMirroredStrategy&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="648f5d6b8ceebd17f689c7c0ab8ef16660a7747c" translate="yes" xml:space="preserve">
          <source>This strategy requires two jobs: workers and parameter servers. Variables and updates to those variables will be assigned to parameter servers and other operations are assigned to workers.</source>
          <target state="translated">이 전략에는 작업자와 매개 변수 서버라는 두 가지 작업이 필요합니다. 변수 및 해당 변수에 대한 업데이트는 매개 변수 서버에 지정되고 다른 작업은 작업자에게 지정됩니다.</target>
        </trans-unit>
        <trans-unit id="e44a68c24a5012e2f287321dc3d6da6b35bca174" translate="yes" xml:space="preserve">
          <source>This strategy requires two roles: workers and parameter servers. Variables and updates to those variables will be assigned to parameter servers and other operations are assigned to workers.</source>
          <target state="translated">This strategy requires two roles: workers and parameter servers. Variables and updates to those variables will be assigned to parameter servers and other operations are assigned to workers.</target>
        </trans-unit>
        <trans-unit id="609b539c1ba8e5fb73c25fa137b65336a8f05b90" translate="yes" xml:space="preserve">
          <source>This strategy uses one replica per device and sync replication for its multi-GPU version.</source>
          <target state="translated">이 전략은 장치 당 하나의 복제본을 사용하고 다중 GPU 버전에 대해 복제 복제를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="a028b1379398bc12b06afc7b36060473f028c25d" translate="yes" xml:space="preserve">
          <source>This symbol is also exported to v2 in tf.estimator namespace. See &lt;a href=&quot;https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py&quot;&gt;https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py&lt;/a&gt;</source>
          <target state="translated">This symbol is also exported to v2 in tf.estimator namespace. See &lt;a href=&quot;https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py&quot;&gt;https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f77a1c7f27ca177eb5967fdc02f021a08479ef96" translate="yes" xml:space="preserve">
          <source>This symbol is also exported to v2 in tf.estimator namespace. See https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py</source>
          <target state="translated">이 기호는 tf.estimator 네임 스페이스의 v2로도 내보내집니다. https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/hooks/basic_session_run_hooks.py를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="ee30a785484036470f77ee9c09ff132832518ed4" translate="yes" xml:space="preserve">
          <source>This takes an ordinary &lt;code&gt;dataset&lt;/code&gt; and &lt;code&gt;replica_fn&lt;/code&gt; and runs it distributed using a particular &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; named &lt;code&gt;my_strategy&lt;/code&gt; above. Any variables created in &lt;code&gt;replica_fn&lt;/code&gt; are created using &lt;code&gt;my_strategy&lt;/code&gt;'s policy, and library functions called by &lt;code&gt;replica_fn&lt;/code&gt; can use the &lt;code&gt;get_replica_context()&lt;/code&gt; API to implement distributed-specific behavior.</source>
          <target state="translated">이것은 보통 소요 &lt;code&gt;dataset&lt;/code&gt; 및 &lt;code&gt;replica_fn&lt;/code&gt; 을 하고 특정 사용하여 분산 실행 &lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 이름 &lt;code&gt;my_strategy&lt;/code&gt; 위. 에서 만든 모든 변수 &lt;code&gt;replica_fn&lt;/code&gt; 를 사용하여 만들어집니다 &lt;code&gt;my_strategy&lt;/code&gt; 의 정책 및 호출 라이브러리 함수 &lt;code&gt;replica_fn&lt;/code&gt; 사용 할 수 &lt;code&gt;get_replica_context()&lt;/code&gt; 분산 특정 동작을 구현하기 위해 API를.</target>
        </trans-unit>
        <trans-unit id="f43e50d6d041bdda53ec0ccc184fa3940b822601" translate="yes" xml:space="preserve">
          <source>This takes in a few parameters and creates a GCEClusterResolver project. It will then use these parameters to query the GCE API for the IP addresses of each instance in the instance group.</source>
          <target state="translated">몇 가지 매개 변수를 사용하고 GCEClusterResolver 프로젝트를 만듭니다. 그런 다음이 매개 변수를 사용하여 인스턴스 그룹에있는 각 인스턴스의 IP 주소에 대한 GCE API를 쿼리합니다.</target>
        </trans-unit>
        <trans-unit id="dcbb15c135f93b202dd4afc6d928c452a899b686" translate="yes" xml:space="preserve">
          <source>This takes in parameters and creates a SlurmClusterResolver object. It uses those parameters to check which nodes will processes reside on and resolves their hostnames. With the number of the GPUs on each node and number of GPUs for each task it offsets the port number for each process and allocates GPUs to tasks by setting environment variables. The resolver currently supports homogeneous tasks and default Slurm process allocation.</source>
          <target state="translated">매개 변수를 사용하여 SlurmClusterResolver 개체를 만듭니다. 이 매개 변수를 사용하여 프로세스가 상주 할 노드를 확인하고 호스트 이름을 분석합니다. 각 노드의 GPU 수와 각 작업의 GPU 수를 통해 각 프로세스의 포트 번호를 오프셋하고 환경 변수를 설정하여 작업에 GPU를 할당합니다. 리졸버는 현재 동종 작업 및 기본 Slurm 프로세스 할당을 지원합니다.</target>
        </trans-unit>
        <trans-unit id="c32e52f6772f69af41778414a120795e360f2147" translate="yes" xml:space="preserve">
          <source>This thread class is intended to be used with a &lt;code&gt;Coordinator&lt;/code&gt;. It repeatedly runs code specified either as &lt;code&gt;target&lt;/code&gt; and &lt;code&gt;args&lt;/code&gt; or by the &lt;code&gt;run_loop()&lt;/code&gt; method.</source>
          <target state="translated">이 스레드 클래스는 &lt;code&gt;Coordinator&lt;/code&gt; 와 함께 사용하기위한 것 입니다. &lt;code&gt;target&lt;/code&gt; 및 &lt;code&gt;args&lt;/code&gt; 또는 &lt;code&gt;run_loop()&lt;/code&gt; 메소드 로 지정된 코드를 반복적으로 실행합니다 .</target>
        </trans-unit>
        <trans-unit id="cbe44aae232eb7beccd1bb717d150f53dfed09d2" translate="yes" xml:space="preserve">
          <source>This tracking then allows saving variable values to &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;training checkpoints&lt;/a&gt;, or to &lt;a href=&quot;https://www.tensorflow.org/guide/saved_model&quot;&gt;SavedModels&lt;/a&gt; which include serialized TensorFlow graphs.</source>
          <target state="translated">이 추적을 통해 변수 값을 &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;훈련 체크 포인트&lt;/a&gt; 또는 직렬화 된 TensorFlow 그래프를 포함 하는 &lt;a href=&quot;https://www.tensorflow.org/guide/saved_model&quot;&gt;저장된 모델에 저장할&lt;/a&gt; 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="84d3d178d35882538e5cb6113338132ed1567a47" translate="yes" xml:space="preserve">
          <source>This transformation applies &lt;code&gt;map_func&lt;/code&gt; to each element of this dataset, and returns a new dataset containing the transformed elements, in the same order as they appeared in the input. &lt;code&gt;map_func&lt;/code&gt; can be used to change both the values and the structure of a dataset's elements. For example, adding 1 to each element, or projecting a subset of element components.</source>
          <target state="translated">이 변환은 &lt;code&gt;map_func&lt;/code&gt; 를이 데이터 세트의 각 요소에 적용 하고 변환 된 요소를 포함하는 새 데이터 세트를 입력에 표시된 순서대로 반환합니다. &lt;code&gt;map_func&lt;/code&gt; 를 사용하여 데이터 세트 요소의 값과 구조를 모두 변경할 수 있습니다. 예를 들어, 각 요소에 1을 추가하거나 요소 구성 요소의 서브 세트를 투영합니다.</target>
        </trans-unit>
        <trans-unit id="ba79b19e287af6ccbf373678af86969066d66587" translate="yes" xml:space="preserve">
          <source>This transformation checks whether the camel-case names (i.e. &quot;FlatMap&quot;, not &quot;flat_map&quot;) of the transformations following this transformation match the list of names in the &lt;code&gt;transformations&lt;/code&gt; argument. If there is a mismatch, the transformation raises an exception.</source>
          <target state="translated">This transformation checks whether the camel-case names (i.e. &quot;FlatMap&quot;, not &quot;flat_map&quot;) of the transformations following this transformation match the list of names in the &lt;code&gt;transformations&lt;/code&gt; argument. If there is a mismatch, the transformation raises an exception.</target>
        </trans-unit>
        <trans-unit id="b91ea223c9ec8adff0faaecc5c9b88a252c4af69" translate="yes" xml:space="preserve">
          <source>This transformation combines multiple consecutive elements of the input dataset into a single element.</source>
          <target state="translated">이 변환은 입력 데이터 집합의 여러 연속 요소를 단일 요소로 결합합니다.</target>
        </trans-unit>
        <trans-unit id="35f6c3c6efa792b9215faf94c8c00f35d19886a0" translate="yes" xml:space="preserve">
          <source>This transformation is a stateful relative of &lt;a href=&quot;../dataset#map&quot;&gt;&lt;code&gt;tf.data.Dataset.map&lt;/code&gt;&lt;/a&gt;. In addition to mapping &lt;code&gt;scan_func&lt;/code&gt; across the elements of the input dataset, &lt;code&gt;scan()&lt;/code&gt; accumulates one or more state tensors, whose initial values are &lt;code&gt;initial_state&lt;/code&gt;.</source>
          <target state="translated">이 변환은 &lt;a href=&quot;../dataset#map&quot;&gt; &lt;code&gt;tf.data.Dataset.map&lt;/code&gt; &lt;/a&gt; 의 상태 저장 상대입니다 . &lt;code&gt;scan()&lt;/code&gt; 은 입력 데이터 집합의 요소에 걸쳐 &lt;code&gt;scan_func&lt;/code&gt; 를 매핑하는 것 외에도 초기 값이 &lt;code&gt;initial_state&lt;/code&gt; 인 하나 이상의 상태 텐서를 누적 합니다.</target>
        </trans-unit>
        <trans-unit id="8e7258027c5f693626ed2b2e68a04576c8a8c285" translate="yes" xml:space="preserve">
          <source>This transformation maps each consecutive element in a dataset to a key using &lt;code&gt;key_func&lt;/code&gt; and groups the elements by key. It then applies &lt;code&gt;reduce_func&lt;/code&gt; to at most &lt;code&gt;window_size_func(key)&lt;/code&gt; elements matching the same key. All except the final window for each key will contain &lt;code&gt;window_size_func(key)&lt;/code&gt; elements; the final window may be smaller.</source>
          <target state="translated">이 변환은 &lt;code&gt;key_func&lt;/code&gt; 를 사용하여 데이터 집합의 각 연속 요소를 키에 매핑 하고 요소를 키별로 그룹화합니다. 그런 다음 &lt;code&gt;reduce_func&lt;/code&gt; 를 동일한 키와 일치하는 최대 &lt;code&gt;window_size_func(key)&lt;/code&gt; 요소에 적용합니다. 각 키의 마지막 창을 제외한 모든 창에는 &lt;code&gt;window_size_func(key)&lt;/code&gt; 요소 가 포함됩니다 . 최종 창이 더 작을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="a21aaa6c0a7b4d11f0bde650d661805100a01ad7" translate="yes" xml:space="preserve">
          <source>This transformation maps element of a dataset to a key using &lt;code&gt;key_func&lt;/code&gt; and groups the elements by key. The &lt;code&gt;reducer&lt;/code&gt; is used to process each group; its &lt;code&gt;init_func&lt;/code&gt; is used to initialize state for each group when it is created, the &lt;code&gt;reduce_func&lt;/code&gt; is used to update the state every time an element is mapped to the matching group, and the &lt;code&gt;finalize_func&lt;/code&gt; is used to map the final state to an output value.</source>
          <target state="translated">이 변환은 &lt;code&gt;key_func&lt;/code&gt; 를 사용하여 데이터 집합 의 요소를 키에 매핑 하고 요소를 키별로 그룹화합니다. &lt;code&gt;reducer&lt;/code&gt; 각 그룹을 처리하는 데 사용된다; 그 &lt;code&gt;init_func&lt;/code&gt; 가 생성 될 때, 각 그룹의 상태를 초기화하는데 사용되는 상기 &lt;code&gt;reduce_func&lt;/code&gt; 는 상태에게 요소가 일치하는 그룹에 매핑 될 때마다 갱신하는데 사용되며, &lt;code&gt;finalize_func&lt;/code&gt; 은 출력값에 최종 상태를 매핑하는데 사용된다.</target>
        </trans-unit>
        <trans-unit id="24ab6194aaa04fc157672b906f20ba2e1b1ec8cc" translate="yes" xml:space="preserve">
          <source>This updates the checkpoint file containing a CheckpointState proto.</source>
          <target state="translated">CheckpointState 프로토가 포함 된 검사 점 파일을 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="5bb7cb617dbb67bdd4c7f55f6d436fa2f1b33e3c" translate="yes" xml:space="preserve">
          <source>This uses &lt;a href=&quot;../norm&quot;&gt;&lt;code&gt;tf.linalg.norm&lt;/code&gt;&lt;/a&gt; to compute the norm along &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="translated">이것은 &lt;a href=&quot;../norm&quot;&gt; &lt;code&gt;tf.linalg.norm&lt;/code&gt; &lt;/a&gt; 을 사용하여 &lt;code&gt;axis&lt;/code&gt; 따라 규범을 계산합니다 .</target>
        </trans-unit>
        <trans-unit id="7945ebd1b4ae121cdd796a53759129e7e59a0846" translate="yes" xml:space="preserve">
          <source>This usually returns the master from the first ClusterResolver passed in, but you can override this by specifying the task_type and task_id.</source>
          <target state="translated">일반적으로 전달 된 첫 번째 ClusterResolver에서 마스터를 반환하지만 task_type 및 task_id를 지정하여이를 무시할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4285af5e3616d9c051e0b5382ab0649693cc39b6" translate="yes" xml:space="preserve">
          <source>This utility function provides consistent behavior for both local (non-distributed) and distributed configurations. The default distribution configuration is parameter server-based between-graph replication. For other types of distribution configurations such as all-reduce training, please use &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;DistributionStrategies&lt;/a&gt;.</source>
          <target state="translated">이 유틸리티 기능은 로컬 (비 분산) 및 분산 구성 모두에 일관된 동작을 제공합니다. 기본 배포 구성은 매개 변수 서버 기반 그래프 간 복제입니다. 전체 감소 교육과 같은 다른 유형의 배포 구성의 경우 &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;DistributionStrategies&lt;/a&gt; 를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="50e5c41b60a6dacb228de3d2a27ac083ca26570e" translate="yes" xml:space="preserve">
          <source>This utility function trains, evaluates, and (optionally) exports the model by using the given &lt;code&gt;estimator&lt;/code&gt;. All training related specification is held in &lt;code&gt;train_spec&lt;/code&gt;, including training &lt;code&gt;input_fn&lt;/code&gt; and training max steps, etc. All evaluation and export related specification is held in &lt;code&gt;eval_spec&lt;/code&gt;, including evaluation &lt;code&gt;input_fn&lt;/code&gt;, steps, etc.</source>
          <target state="translated">이 유틸리티 함수는 주어진 &lt;code&gt;estimator&lt;/code&gt; 를 사용하여 모델을 학습, 평가 및 선택적으로 내 보냅니다 . 훈련 &lt;code&gt;input_fn&lt;/code&gt; 및 훈련 최대 단계 등을 포함하여 모든 훈련 관련 사양은 &lt;code&gt;train_spec&lt;/code&gt; 에 보관됩니다 . 모든 평가 및 수출 관련 사양은 평가 &lt;code&gt;input_fn&lt;/code&gt; , 단계 등을 포함하여 &lt;code&gt;eval_spec&lt;/code&gt; 에 보관됩니다 .</target>
        </trans-unit>
        <trans-unit id="370bf5deaf68ca405b51cda0b005ed741251919f" translate="yes" xml:space="preserve">
          <source>This utility method replaces the deprecated-in-V2 &lt;code&gt;tf.compat.v1.Dataset.output_classes&lt;/code&gt; property.</source>
          <target state="translated">이 유틸리티 메소드는 더 이상 사용되지 않는 V2 &lt;code&gt;tf.compat.v1.Dataset.output_classes&lt;/code&gt; 특성을 대체합니다 .</target>
        </trans-unit>
        <trans-unit id="46213afe2d7d2a75cd43b97252d79901207a3be4" translate="yes" xml:space="preserve">
          <source>This utility method replaces the deprecated-in-V2 &lt;code&gt;tf.compat.v1.Dataset.output_shapes&lt;/code&gt; property.</source>
          <target state="translated">이 유틸리티 메소드는 더 이상 사용되지 않는 V2 &lt;code&gt;tf.compat.v1.Dataset.output_shapes&lt;/code&gt; 특성을 대체합니다 .</target>
        </trans-unit>
        <trans-unit id="917e4af53cd9619ae0480dec3aee8643df47493a" translate="yes" xml:space="preserve">
          <source>This utility method replaces the deprecated-in-V2 &lt;code&gt;tf.compat.v1.Dataset.output_types&lt;/code&gt; property.</source>
          <target state="translated">이 유틸리티 메소드는 더 이상 사용되지 않는 V2 &lt;code&gt;tf.compat.v1.Dataset.output_types&lt;/code&gt; 특성을 대체합니다 .</target>
        </trans-unit>
        <trans-unit id="e1997fea43a5c765a33c5bb8c3d18f8bd998811c" translate="yes" xml:space="preserve">
          <source>This value is ultimately returned as &lt;code&gt;auc&lt;/code&gt;, an idempotent operation that computes the area under a discretized curve of precision versus recall values (computed using the aforementioned variables). The &lt;code&gt;num_thresholds&lt;/code&gt; variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on &lt;code&gt;num_thresholds&lt;/code&gt;.</source>
          <target state="translated">이 값은 궁극적으로 &lt;code&gt;auc&lt;/code&gt; pot 으로 반환 되는데 , 이는 위와 같은 변수를 사용하여 계산 된 이산 정밀도 곡선과 리콜 값 곡선 아래 면적을 계산하는 dem 등원 연산입니다. &lt;code&gt;num_thresholds&lt;/code&gt; 의 변수 컨트롤보다 밀접하게 진정한 AUC를 근사 임계 값의 큰 숫자 이산화 정도. 근사치의 품질은 &lt;code&gt;num_thresholds&lt;/code&gt; 에 따라 크게 달라질 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="65677d697851bf6819d55d4ff4251a12696e0771" translate="yes" xml:space="preserve">
          <source>This value is ultimately returned as &lt;code&gt;auc&lt;/code&gt;, an idempotent operation that computes the area under a discretized curve of precision versus recall values (computed using the aforementioned variables). The &lt;code&gt;num_thresholds&lt;/code&gt; variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on &lt;code&gt;num_thresholds&lt;/code&gt;. The &lt;code&gt;thresholds&lt;/code&gt; parameter can be used to manually specify thresholds which split the predictions more evenly.</source>
          <target state="translated">이 값은 궁극적으로 &lt;code&gt;auc&lt;/code&gt; pot 으로 반환 되는데 , 이는 위와 같은 변수를 사용하여 계산 된 이산 정밀도 곡선과 리콜 값 곡선 아래 면적을 계산하는 dem 등원 연산입니다. &lt;code&gt;num_thresholds&lt;/code&gt; 의 변수 컨트롤보다 밀접하게 진정한 AUC를 근사 임계 값의 큰 숫자 이산화 정도. 근사치의 품질은 &lt;code&gt;num_thresholds&lt;/code&gt; 에 따라 크게 달라질 수 있습니다 . &lt;code&gt;thresholds&lt;/code&gt; 수동 균등 예측 분할 임계치를 지정할 수있는 파라미터.</target>
        </trans-unit>
        <trans-unit id="ca17fcf3f560f3e845deeb7ae0f38bd32e476e10" translate="yes" xml:space="preserve">
          <source>This version enqueues a different list of tensors in different threads. It adds the following to the current &lt;code&gt;Graph&lt;/code&gt;:</source>
          <target state="translated">이 버전은 다른 스레드에서 다른 텐서 목록을 큐에 넣습니다. 현재 &lt;code&gt;Graph&lt;/code&gt; 다음을 추가합니다 .</target>
        </trans-unit>
        <trans-unit id="3dd9104e524c4af8048275ef1cca44df52153ae4" translate="yes" xml:space="preserve">
          <source>This version has support for both online L2 (McMahan et al., 2013) and shrinkage-type L2, which is the addition of an L2 penalty to the loss function.</source>
          <target state="translated">This version has support for both online L2 (McMahan et al., 2013) and shrinkage-type L2, which is the addition of an L2 penalty to the loss function.</target>
        </trans-unit>
        <trans-unit id="56d946ffec0b3da9d0ec8b7171e5c9d7eac7532e" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">이 버전은 Dropout과 동일한 기능을 수행하지만 개별 요소 대신 전체 1D 기능 맵을 삭제합니다. 피처 맵 내의 인접 프레임이 (초기 컨볼 루션 레이어의 경우와 같이) 밀접하게 상관되어 있으면 규칙적인 드롭 아웃이 활성화를 정규화하지 않고 효과적인 학습 속도 감소를 초래합니다. 이 경우 SpatialDropout1D는 기능 맵 간의 독립성을 높이는 데 도움이되므로 대신 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="a36f7273ef31d9cbeb00b22a3f221c68cd1e40a0" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">이 버전은 Dropout과 동일한 기능을 수행하지만 개별 요소 대신 전체 2D 기능 맵을 삭제합니다. 피쳐 맵 내의 인접 픽셀이 초기 컨볼 루션 레이어에서와 같이 강한 상관 관계가있는 경우 규칙적인 드롭 아웃이 활성화를 정규화하지 않고 효과적인 학습 속도 감소를 초래합니다. 이 경우 SpatialDropout2D는 기능 맵 간의 독립성을 높이는 데 도움이되므로 대신 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="d0ef991814863883d725a0aaf896bf4a46fb3d16" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">이 버전은 Dropout과 동일한 기능을 수행하지만 개별 요소 대신 전체 3D 기능 맵을 삭제합니다. 특징 맵 내의 인접 복셀이 (초기 컨볼 루션 레이어의 경우와 같이) 밀접하게 상관되어 있으면 규칙적인 드롭 아웃이 활성화를 정규화하지 않고 효과적인 학습 속도 감소를 초래합니다. 이 경우 SpatialDropout3D는 기능 맵 간의 독립성을 높이는 데 도움이되므로 대신 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="3b754cc618ce29bdbcce941232103d369933ab97" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however, it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">This version performs the same function as Dropout, however, it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.</target>
        </trans-unit>
        <trans-unit id="669d1fce226733b310b6c063bbb1478bd8960685" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however, it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">This version performs the same function as Dropout, however, it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.</target>
        </trans-unit>
        <trans-unit id="ef292e83a5c48c6c48f427ef4821dec22b8cd18d" translate="yes" xml:space="preserve">
          <source>This version performs the same function as Dropout, however, it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">This version performs the same function as Dropout, however, it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.</target>
        </trans-unit>
        <trans-unit id="28fed8917e83f005a3a2493f518294b2e184da80" translate="yes" xml:space="preserve">
          <source>This was originally generated by parsing and preprocessing the classic Reuters-21578 dataset, but the preprocessing code is no longer packaged with Keras. See this &lt;a href=&quot;https://github.com/keras-team/keras/issues/12072&quot;&gt;github discussion&lt;/a&gt; for more info.</source>
          <target state="translated">This was originally generated by parsing and preprocessing the classic Reuters-21578 dataset, but the preprocessing code is no longer packaged with Keras. See this &lt;a href=&quot;https://github.com/keras-team/keras/issues/12072&quot;&gt;github discussion&lt;/a&gt; for more info.</target>
        </trans-unit>
        <trans-unit id="4d54f43064a89a76630348aa955f910392f5b82d" translate="yes" xml:space="preserve">
          <source>This will clear all caches, even those that are maintained through sequential calls to tf.tpu.experimental.initialize_tpu_system, such as the compilation cache.</source>
          <target state="translated">이렇게하면 컴파일 캐시와 같이 tf.tpu.experimental.initialize_tpu_system에 대한 순차적 호출을 통해 유지 관리되는 캐시까지도 모든 캐시가 지워집니다.</target>
        </trans-unit>
        <trans-unit id="d806ab1c15562f7cef5ecfb73dfc54f37420bf0f" translate="yes" xml:space="preserve">
          <source>This will match and replace multiple sig defs iff tags is None (i.e when multiple &lt;code&gt;MetaGraph&lt;/code&gt;s have a signature_def with the same key). If tags is not None, this will only replace a single signature_def in the &lt;code&gt;MetaGraph&lt;/code&gt; with matching tags.</source>
          <target state="translated">This will match and replace multiple sig defs iff tags is None (i.e when multiple &lt;code&gt;MetaGraph&lt;/code&gt; s have a signature_def with the same key). If tags is not None, this will only replace a single signature_def in the &lt;code&gt;MetaGraph&lt;/code&gt; with matching tags.</target>
        </trans-unit>
        <trans-unit id="8c497916c950017d377f8b22ce65b7642e7fe656" translate="yes" xml:space="preserve">
          <source>This works for both single worker and multi-worker mode, only MirroredStrategy and MultiWorkerMirroredStrategy are supported for now.</source>
          <target state="translated">This works for both single worker and multi-worker mode, only MirroredStrategy and MultiWorkerMirroredStrategy are supported for now.</target>
        </trans-unit>
        <trans-unit id="d1d5a90de0626fc107829e4415b87374a7e5143d" translate="yes" xml:space="preserve">
          <source>This wrapper allows to apply a layer to every temporal slice of an input.</source>
          <target state="translated">이 랩퍼는 입력의 모든 시간적 슬라이스에 레이어를 적용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="e4911cf935e00a37c587b392c63c4d1259cd5359" translate="yes" xml:space="preserve">
          <source>This wraps &lt;code&gt;func_&lt;/code&gt; in a Template and partially evaluates it. Templates are functions that create variables the first time they are called and reuse them thereafter. In order for &lt;code&gt;func_&lt;/code&gt; to be compatible with a &lt;code&gt;Template&lt;/code&gt; it must have the following properties:</source>
          <target state="translated">이것은 &lt;code&gt;func_&lt;/code&gt; 를 Template에 싸서 부분적으로 평가합니다. 템플릿은 변수를 처음 호출 할 때 변수를 생성 한 다음 재사용합니다. 위해에 대한 &lt;code&gt;func_&lt;/code&gt; 는 A를 호환하는 &lt;code&gt;Template&lt;/code&gt; 은 다음과 같은 속성이 있어야합니다</target>
        </trans-unit>
        <trans-unit id="9934a34210519520663a7f89fe0d027dd3ebea0c" translate="yes" xml:space="preserve">
          <source>This wraps &lt;code&gt;variables()&lt;/code&gt; from the actual optimizer. It does not include the &lt;code&gt;SyncReplicasOptimizer&lt;/code&gt;'s local step.</source>
          <target state="translated">실제 옵티마이 저의 &lt;code&gt;variables()&lt;/code&gt; 를 래핑 합니다 . &lt;code&gt;SyncReplicasOptimizer&lt;/code&gt; 의 로컬 단계 는 포함되지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="cea56f6fda7d999d314aba39c0fdf92a26a4a3d0" translate="yes" xml:space="preserve">
          <source>Thread Compatibility</source>
          <target state="translated">스레드 호환성</target>
        </trans-unit>
        <trans-unit id="c707a1c58a3c28cb78f0eb8786b82d358ba76091" translate="yes" xml:space="preserve">
          <source>Thread code:</source>
          <target state="translated">스레드 코드 :</target>
        </trans-unit>
        <trans-unit id="a1bfe9290c9416a7b4254caec7ab391081602a4c" translate="yes" xml:space="preserve">
          <source>Thread identifier of this thread or None if it has not been started.</source>
          <target state="translated">이 스레드의 스레드 식별자이거나 시작되지 않은 경우 없음입니다.</target>
        </trans-unit>
        <trans-unit id="51781b51dab5c68c5071966ab81a91a116a5c345" translate="yes" xml:space="preserve">
          <source>ThreadPoolDataset</source>
          <target state="translated">ThreadPoolDataset</target>
        </trans-unit>
        <trans-unit id="c1e81f3f498c6f28feb25121d03bcd7897368f6a" translate="yes" xml:space="preserve">
          <source>ThreadPoolHandle</source>
          <target state="translated">ThreadPoolHandle</target>
        </trans-unit>
        <trans-unit id="b296a2588708c5eab00cc272e74d54b936f28305" translate="yes" xml:space="preserve">
          <source>ThreadUnsafeUnigramCandidateSampler</source>
          <target state="translated">ThreadUnsafeUnigramCandidateSampler</target>
        </trans-unit>
        <trans-unit id="673246c2e28b595a5660cad8b7dc6e0bcb64f903" translate="yes" xml:space="preserve">
          <source>Threshold below which the singular value is counted as 'zero'. Default value: &lt;code&gt;None&lt;/code&gt; (i.e., &lt;code&gt;eps * max(rows, cols) * max(singular_val)&lt;/code&gt;).</source>
          <target state="translated">Threshold below which the singular value is counted as 'zero'. Default value: &lt;code&gt;None&lt;/code&gt; (i.e., &lt;code&gt;eps * max(rows, cols) * max(singular_val)&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="bf8ab928262e89058d10a418722762edfa599e46" translate="yes" xml:space="preserve">
          <source>Thresholded Rectified Linear Unit.</source>
          <target state="translated">임계 정류 선형 단위.</target>
        </trans-unit>
        <trans-unit id="9c1b3e348c5e658c9f04296e21ad3e2315006119" translate="yes" xml:space="preserve">
          <source>Throws:</source>
          <target state="translated">Throws:</target>
        </trans-unit>
        <trans-unit id="19453fe8b327db6c16c490630fc6fcb997c1883b" translate="yes" xml:space="preserve">
          <source>Thus the saved model can be reinstantiated in the exact same state, without any of the code used for model definition or training.</source>
          <target state="translated">따라서 저장된 모델은 모델 정의 또는 교육에 사용되는 코드없이 정확히 동일한 상태로 다시 인스턴스화 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2dd2c660983753cf7cd7ed0bfc6dd2c1219c9bc2" translate="yes" xml:space="preserve">
          <source>Tile</source>
          <target state="translated">Tile</target>
        </trans-unit>
        <trans-unit id="04d349170a16840309d778c9a6bc280d1695cf69" translate="yes" xml:space="preserve">
          <source>TileGrad</source>
          <target state="translated">TileGrad</target>
        </trans-unit>
        <trans-unit id="ec15d67c587aeda01fdee12aac8f67ec1f6fc946" translate="yes" xml:space="preserve">
          <source>Time (in seconds) to wait for process cleanup to propagate.</source>
          <target state="translated">Time (in seconds) to wait for process cleanup to propagate.</target>
        </trans-unit>
        <trans-unit id="c5071117f474d7a0d851f7b8b532519d4fe0b2f5" translate="yes" xml:space="preserve">
          <source>Time boundaries at which to call Run(), or None if it should be called back to back.</source>
          <target state="translated">Time boundaries at which to call Run(), or None if it should be called back to back.</target>
        </trans-unit>
        <trans-unit id="ea13a52ff3b11f3a3cff17d94eddba0db805c4f1" translate="yes" xml:space="preserve">
          <source>Time series forecasting</source>
          <target state="translated">시계열 예측</target>
        </trans-unit>
        <trans-unit id="3e5a5aa6d16549aefb0642b61016bd76ed1a572d" translate="yes" xml:space="preserve">
          <source>Time step at which the gradient was computed.</source>
          <target state="translated">Time step at which the gradient was computed.</target>
        </trans-unit>
        <trans-unit id="d96b16498245359e1fc62fcf077cd9c20e575ff4" translate="yes" xml:space="preserve">
          <source>Timer that triggers at most once every N seconds or once every N steps.</source>
          <target state="translated">최대 N 초마다 한 번 또는 N 단계마다 한 번씩 트리거되는 타이머.</target>
        </trans-unit>
        <trans-unit id="19eabc961735d78f12fc7be906ffcb033853cf85" translate="yes" xml:space="preserve">
          <source>Timestamp</source>
          <target state="translated">Timestamp</target>
        </trans-unit>
        <trans-unit id="b0bee40a202555900d8a3e86b930a56b855407cd" translate="yes" xml:space="preserve">
          <source>To &lt;code&gt;run&lt;/code&gt; without hooks.</source>
          <target state="translated">하려면 &lt;code&gt;run&lt;/code&gt; 후크없이.</target>
        </trans-unit>
        <trans-unit id="40336213cb93ad585f6a3a6e3ff018601cc59a2a" translate="yes" xml:space="preserve">
          <source>To achieve a performance improvement, you can also wrap the &lt;code&gt;strategy.run&lt;/code&gt; call with a &lt;a href=&quot;../range&quot;&gt;&lt;code&gt;tf.range&lt;/code&gt;&lt;/a&gt; inside a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. This runs multiple steps in a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. Autograph will convert it to a &lt;a href=&quot;../while_loop&quot;&gt;&lt;code&gt;tf.while_loop&lt;/code&gt;&lt;/a&gt; on the worker. However, it is less flexible comparing with running a single step inside &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. For example, you cannot run things eagerly or arbitrary python code within the steps.</source>
          <target state="translated">To achieve a performance improvement, you can also wrap the &lt;code&gt;strategy.run&lt;/code&gt; call with a &lt;a href=&quot;../range&quot;&gt; &lt;code&gt;tf.range&lt;/code&gt; &lt;/a&gt; inside a &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;. This runs multiple steps in a &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;. Autograph will convert it to a &lt;a href=&quot;../while_loop&quot;&gt; &lt;code&gt;tf.while_loop&lt;/code&gt; &lt;/a&gt; on the worker. However, it is less flexible comparing with running a single step inside &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;. For example, you cannot run things eagerly or arbitrary python code within the steps.</target>
        </trans-unit>
        <trans-unit id="f375d91c07ec3d845eaa0b13fb5e2121d93801bc" translate="yes" xml:space="preserve">
          <source>To add an inner vector length axis to a tensor of scalars.</source>
          <target state="translated">To add an inner vector length axis to a tensor of scalars.</target>
        </trans-unit>
        <trans-unit id="bd6eda6c08067795995f955381394f94ccb8826e" translate="yes" xml:space="preserve">
          <source>To aggregate gradients yourself, call &lt;code&gt;apply_gradients&lt;/code&gt; with &lt;code&gt;experimental_aggregate_gradients&lt;/code&gt; set to False. This is useful if you need to process aggregated gradients.</source>
          <target state="translated">To aggregate gradients yourself, call &lt;code&gt;apply_gradients&lt;/code&gt; with &lt;code&gt;experimental_aggregate_gradients&lt;/code&gt; set to False. This is useful if you need to process aggregated gradients.</target>
        </trans-unit>
        <trans-unit id="010eecd6ae7f583a0121a3a0180c941339655bd9" translate="yes" xml:space="preserve">
          <source>To apply a functional operation to the nonzero elements of a SparseTensor one of the following methods is recommended. First, if the function is expressible as TensorFlow ops, use</source>
          <target state="translated">SparseTensor의 0이 아닌 요소에 기능 조작을 적용하려면 다음 방법 중 하나를 권장합니다. 먼저 TensorFlow ops로 기능을 표현할 수있는 경우</target>
        </trans-unit>
        <trans-unit id="3eb084feee66304e2da16fe914a839b30b34c9ff" translate="yes" xml:space="preserve">
          <source>To associate a &lt;code&gt;StatsAggregator&lt;/code&gt; with a &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; object, use the following pattern:</source>
          <target state="translated">&lt;code&gt;StatsAggregator&lt;/code&gt; 를 &lt;a href=&quot;../../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; 오브젝트 와 연관 시키려면 다음 패턴을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="c154cd080332e723a840721f93b48724110f7c06" translate="yes" xml:space="preserve">
          <source>To associate a &lt;code&gt;StatsAggregator&lt;/code&gt; with a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; object, use the following pattern:</source>
          <target state="translated">&lt;code&gt;StatsAggregator&lt;/code&gt; 를 &lt;a href=&quot;../dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; 오브젝트 와 연관 시키려면 다음 패턴을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="936085b5545471dc42df6c7c7d391847c9751475" translate="yes" xml:space="preserve">
          <source>To avoid copies, if the consumer of the returned value is on the same device as the variable, this actually returns the live value of the variable, not a copy. Updates to the variable are seen by the consumer. If the consumer is on a different device it will get a copy of the variable.</source>
          <target state="translated">복사를 피하기 위해 리턴 값의 소비자가 변수와 동일한 디바이스에있는 경우 실제로 사본이 아닌 변수의 실제 값을 리턴합니다. 변수에 대한 업데이트는 소비자가 볼 수 있습니다. 소비자가 다른 장치에있는 경우 변수 사본을 얻습니다.</target>
        </trans-unit>
        <trans-unit id="7c1421196dd351f3e8d18229f5901c13e59818be" translate="yes" xml:space="preserve">
          <source>To avoid this operation one can looping over the first &lt;code&gt;ndims&lt;/code&gt; of the variable and using &lt;code&gt;scatter_update&lt;/code&gt; on the subtensors that result of slicing the first dimension. This is a valid option for &lt;code&gt;ndims = 1&lt;/code&gt;, but less efficient than this implementation.</source>
          <target state="translated">이 작업을 피하기 위해 변수 의 첫 번째 &lt;code&gt;ndims&lt;/code&gt; 을 반복 하고 첫 번째 차원을 슬라이싱 한 결과로 하위 테너에서 &lt;code&gt;scatter_update&lt;/code&gt; 를 사용할 수 있습니다. 이것은 &lt;code&gt;ndims = 1&lt;/code&gt; 유효한 옵션 이지만이 구현보다 비효율적입니다.</target>
        </trans-unit>
        <trans-unit id="cfcb9f867b92956487a659195717febb57a22acc" translate="yes" xml:space="preserve">
          <source>To avoid this operation there would be 2 alternatives:</source>
          <target state="translated">To avoid this operation there would be 2 alternatives:</target>
        </trans-unit>
        <trans-unit id="d93bb75610f7b39567f5b306f3397077993ff8e1" translate="yes" xml:space="preserve">
          <source>To avoid this operation there would be 2 alternatives: 1) Reshaping the variable by merging the first &lt;code&gt;ndims&lt;/code&gt; dimensions. However, this is not possible because &lt;a href=&quot;../../reshape&quot;&gt;&lt;code&gt;tf.reshape&lt;/code&gt;&lt;/a&gt; returns a Tensor, which we cannot use &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt; on. 2) Looping over the first &lt;code&gt;ndims&lt;/code&gt; of the variable and using &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt; on the subtensors that result of slicing the first dimension. This is a valid option for &lt;code&gt;ndims = 1&lt;/code&gt;, but less efficient than this implementation.</source>
          <target state="translated">이 작업을 피하기 위해 두 가지 대안이 있습니다. 1) 첫 번째 &lt;code&gt;ndims&lt;/code&gt; 치수를 병합하여 변수를 재구성 합니다. 그러나 &lt;a href=&quot;../../reshape&quot;&gt; &lt;code&gt;tf.reshape&lt;/code&gt; &lt;/a&gt; 는 텐서를 반환 하므로 tf.compat.v1.scatter_update를 사용할 수 없으므로 &lt;a href=&quot;scatter_update&quot;&gt; &lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt; &lt;/a&gt; 합니다. 2) 위에 루핑 제 &lt;code&gt;ndims&lt;/code&gt; 변수 및 사용 &lt;a href=&quot;scatter_update&quot;&gt; &lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt; 을&lt;/a&gt; subtensors에 제 차원 슬라이스의 결과. 이것은 &lt;code&gt;ndims = 1&lt;/code&gt; 유효한 옵션 이지만이 구현보다 비효율적입니다.</target>
        </trans-unit>
        <trans-unit id="c9183a300f45fff79988522f16235dc4e2de646c" translate="yes" xml:space="preserve">
          <source>To be implemented by subclasses:</source>
          <target state="translated">서브 클래스로 구현하려면 :</target>
        </trans-unit>
        <trans-unit id="52f2d1556ade9e7f9e4af5a180af2690b66cec6f" translate="yes" xml:space="preserve">
          <source>To be used together with &lt;code&gt;initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')&lt;/code&gt;. For correct dropout, use &lt;code&gt;tf.contrib.nn.alpha_dropout&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')&lt;/code&gt; 와 함께 사용합니다 . 올바른 드롭 아웃을 위해서는 &lt;code&gt;tf.contrib.nn.alpha_dropout&lt;/code&gt; 을 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="ea58afe1c10fb928517e860a0db2a381e664fd3c" translate="yes" xml:space="preserve">
          <source>To be used together with the &lt;a href=&quot;../initializers/lecunnormal&quot;&gt;&lt;code&gt;tf.keras.initializers.LecunNormal&lt;/code&gt;&lt;/a&gt; initializer.</source>
          <target state="translated">To be used together with the &lt;a href=&quot;../initializers/lecunnormal&quot;&gt; &lt;code&gt;tf.keras.initializers.LecunNormal&lt;/code&gt; &lt;/a&gt; initializer.</target>
        </trans-unit>
        <trans-unit id="067aa09e87c256fc4280bb7886d1747104dcfb5d" translate="yes" xml:space="preserve">
          <source>To be used together with the dropout variant &lt;a href=&quot;../layers/alphadropout&quot;&gt;&lt;code&gt;tf.keras.layers.AlphaDropout&lt;/code&gt;&lt;/a&gt; (not regular dropout).</source>
          <target state="translated">To be used together with the dropout variant &lt;a href=&quot;../layers/alphadropout&quot;&gt; &lt;code&gt;tf.keras.layers.AlphaDropout&lt;/code&gt; &lt;/a&gt; (not regular dropout).</target>
        </trans-unit>
        <trans-unit id="53dd8873954bfa79dfd0bea43d6ef54fe742261a" translate="yes" xml:space="preserve">
          <source>To build a SavedModel, the first meta graph must be saved with variables. Subsequent meta graphs will simply be saved with their graph definitions. If assets need to be saved and written or copied to disk, they can be provided when the meta graph def is added. If multiple meta graph defs are associated an asset of the same name, only the first version is retained.</source>
          <target state="translated">SavedModel을 빌드하려면 첫 번째 메타 그래프를 변수와 함께 저장해야합니다. 후속 메타 그래프는 그래프 정의와 함께 저장됩니다. 자산을 저장하고 쓰거나 디스크에 복사해야하는 경우 메타 그래프 정의가 추가 될 때 제공 될 수 있습니다. 여러 메타 그래프 정의가 동일한 이름의 자산과 연관된 경우 첫 번째 버전 만 유지됩니다.</target>
        </trans-unit>
        <trans-unit id="44fe360fd9bf0e087ab467407a9221a32654e234" translate="yes" xml:space="preserve">
          <source>To construct a TPUStrategy object, you need to run the initialization code as below:</source>
          <target state="translated">TPUStrategy 객체를 생성하려면 아래와 같이 초기화 코드를 실행해야합니다.</target>
        </trans-unit>
        <trans-unit id="83c7623c3022948b14096264ce7d526cb9408c74" translate="yes" xml:space="preserve">
          <source>To consume the statistics, associate a &lt;code&gt;StatsAggregator&lt;/code&gt; with the output dataset.</source>
          <target state="translated">통계를 사용하려면 &lt;code&gt;StatsAggregator&lt;/code&gt; 를 출력 데이터 세트와 연관 시키십시오 .</target>
        </trans-unit>
        <trans-unit id="d2287264f43a3ef6c22b5d232bbf5118319287d4" translate="yes" xml:space="preserve">
          <source>To create a &lt;a href=&quot;../compat/v1/session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; that connects to this server, use the following snippet:</source>
          <target state="translated">이 서버에 연결 하는 &lt;a href=&quot;../compat/v1/session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; 을 작성하려면 다음 스 니펫을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="d6382ce12824513eb2d0429e1935eb788cf98fff" translate="yes" xml:space="preserve">
          <source>To create a cluster with two jobs and five tasks, you specify the mapping from job names to lists of network addresses (typically hostname-port pairs).</source>
          <target state="translated">두 개의 작업과 다섯 개의 작업으로 클러스터를 만들려면 작업 이름에서 네트워크 주소 목록 (일반적으로 호스트 이름-포트 쌍)으로의 매핑을 지정합니다.</target>
        </trans-unit>
        <trans-unit id="162a52ef0e892f8de2d469fbf8a8ede583aeb2c2" translate="yes" xml:space="preserve">
          <source>To create a dataset of all files matching a pattern, use &lt;a href=&quot;dataset#list_files&quot;&gt;&lt;code&gt;tf.data.Dataset.list_files&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">패턴과 일치하는 모든 파일의 데이터 세트를 작성하려면 &lt;a href=&quot;dataset#list_files&quot;&gt; &lt;code&gt;tf.data.Dataset.list_files&lt;/code&gt; 를&lt;/a&gt; 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="d3f4ab00aa69fb40cd693922a5c483368cf34082" translate="yes" xml:space="preserve">
          <source>To customize the estimator &lt;code&gt;eval_metric_ops&lt;/code&gt; names, you can pass in the &lt;code&gt;metric_names_map&lt;/code&gt; dictionary mapping the keras model output metric names to the custom names as follows:</source>
          <target state="translated">To customize the estimator &lt;code&gt;eval_metric_ops&lt;/code&gt; names, you can pass in the &lt;code&gt;metric_names_map&lt;/code&gt; dictionary mapping the keras model output metric names to the custom names as follows:</target>
        </trans-unit>
        <trans-unit id="baed8fb95bde1dbbdafd79f549daf02185ceb494" translate="yes" xml:space="preserve">
          <source>To enable a public method, subclasses should implement the leading-underscore version of the method. The argument signature should be identical except for the omission of &lt;code&gt;name=&quot;...&quot;&lt;/code&gt;. For example, to enable &lt;code&gt;matmul(x, adjoint=False, name=&quot;matmul&quot;)&lt;/code&gt; a subclass should implement &lt;code&gt;_matmul(x, adjoint=False)&lt;/code&gt;.</source>
          <target state="translated">퍼블릭 메소드를 사용 가능하게하려면 서브 클래스에서 밑줄 버전의 메소드를 구현해야합니다. &lt;code&gt;name=&quot;...&quot;&lt;/code&gt; 생략을 제외하고 인수 서명은 동일해야합니다 . 예를 들어, &lt;code&gt;matmul(x, adjoint=False, name=&quot;matmul&quot;)&lt;/code&gt; 을 사용하려면 서브 클래스에서 &lt;code&gt;_matmul(x, adjoint=False)&lt;/code&gt; 구현해야합니다 .</target>
        </trans-unit>
        <trans-unit id="a64f441e5dd84fd06f79adb0f1f3a053a7155dea" translate="yes" xml:space="preserve">
          <source>To enable and control broadcasting, use an ellipsis. For example, to perform batch matrix multiplication with NumPy-style broadcasting across the batch dimensions, use:</source>
          <target state="translated">방송을 활성화하고 제어하려면 줄임표를 사용하십시오. 예를 들어 배치 차원에서 NumPy 스타일 브로드 캐스팅을 사용하여 배치 행렬 곱셈을 수행하려면 다음을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="afa60615bea13e940acd80b65497cda8c8de7ef9" translate="yes" xml:space="preserve">
          <source>To enable statefulness:</source>
          <target state="translated">To enable statefulness:</target>
        </trans-unit>
        <trans-unit id="01b6fd9e2269c63a7f1c5eddbf780087a139a252" translate="yes" xml:space="preserve">
          <source>To enable statefulness: - Specify &lt;code&gt;stateful=True&lt;/code&gt; in the layer constructor. - Specify a fixed batch size for your model, by passing If sequential model: &lt;code&gt;batch_input_shape=(...)&lt;/code&gt; to the first layer in your model. Else for functional model with 1 or more Input layers: &lt;code&gt;batch_shape=(...)&lt;/code&gt; to all the first layers in your model. This is the expected shape of your inputs &lt;em&gt;including the batch size&lt;/em&gt;. It should be a tuple of integers, e.g. &lt;code&gt;(32, 10, 100)&lt;/code&gt;. - Specify &lt;code&gt;shuffle=False&lt;/code&gt; when calling fit().</source>
          <target state="translated">상태 저장을 활성화하려면 :- 레이어 생성자에서 &lt;code&gt;stateful=True&lt;/code&gt; 를 지정 하십시오. -순차적 모델 인 경우 &lt;code&gt;batch_input_shape=(...)&lt;/code&gt; 을 모델의 첫 번째 레이어 로 전달하여 모델의 고정 배치 크기를 지정 하십시오. 하나 이상의 입력 레이어가있는 기능 모델의 경우 : 모델의 모든 첫 번째 레이어에 &lt;code&gt;batch_shape=(...)&lt;/code&gt; . &lt;em&gt;배치 크기를 포함&lt;/em&gt; 하여 입력의 예상 모양입니다 . 정수의 튜플이어야합니다 &lt;code&gt;(32, 10, 100)&lt;/code&gt; 예 : (32, 10, 100)) . &lt;code&gt;shuffle=False&lt;/code&gt; ()을 호출 할 때 shuffle = False를 지정하십시오 .</target>
        </trans-unit>
        <trans-unit id="d5e380bc52096caf61cf4a0e2ca23ca08f41f03b" translate="yes" xml:space="preserve">
          <source>To enable this Soft-NMS mode, set the &lt;code&gt;soft_nms_sigma&lt;/code&gt; parameter to be larger than 0. When &lt;code&gt;soft_nms_sigma&lt;/code&gt; equals 0, the behavior of &lt;a href=&quot;non_max_suppression_padded&quot;&gt;&lt;code&gt;tf.image.non_max_suppression_padded&lt;/code&gt;&lt;/a&gt; is identical to that of &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt; (except for the extra output) both in function and in running time.</source>
          <target state="translated">To enable this Soft-NMS mode, set the &lt;code&gt;soft_nms_sigma&lt;/code&gt; parameter to be larger than 0. When &lt;code&gt;soft_nms_sigma&lt;/code&gt; equals 0, the behavior of &lt;a href=&quot;non_max_suppression_padded&quot;&gt; &lt;code&gt;tf.image.non_max_suppression_padded&lt;/code&gt; &lt;/a&gt; is identical to that of &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt; (except for the extra output) both in function and in running time.</target>
        </trans-unit>
        <trans-unit id="63aaf92714daf46639926647a3d0a69e133b8f2a" translate="yes" xml:space="preserve">
          <source>To enable this Soft-NMS mode, set the &lt;code&gt;soft_nms_sigma&lt;/code&gt; parameter to be larger than 0. When &lt;code&gt;soft_nms_sigma&lt;/code&gt; equals 0, the behavior of &lt;code&gt;tf.image.non_max_suppression_v2&lt;/code&gt; is identical to that of &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt; (except for the extra output) both in function and in running time.</source>
          <target state="translated">이 소프트 NMS 모드를 설정하기위한 설정 &lt;code&gt;soft_nms_sigma&lt;/code&gt; 의 0보다 큰 될 파라미터 &lt;code&gt;soft_nms_sigma&lt;/code&gt; 가 0 등호의 동작 &lt;code&gt;tf.image.non_max_suppression_v2&lt;/code&gt; 는 동일하다 &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt; (추가 출력 제외) 모두를 기능 및 실행 시간.</target>
        </trans-unit>
        <trans-unit id="30dc95cd6fb2fe82cb6bde586b190076a23204d3" translate="yes" xml:space="preserve">
          <source>To ensure forward compatibility of generated graphs (see &lt;code&gt;forward_compatible&lt;/code&gt;) with older binaries, new features can be gated with:</source>
          <target state="translated">이전 바이너리와 생성 된 그래프 ( &lt;code&gt;forward_compatible&lt;/code&gt; 참조 ) 의 순방향 호환성을 보장하기 위해 다음 과 같은 새로운 기능을 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2a6dfd40e1c087316d123358f0bfd9c6696a8b43" translate="yes" xml:space="preserve">
          <source>To ensure that loading is complete and no more assignments will take place, use the &lt;code&gt;assert_consumed()&lt;/code&gt; method of the status object returned by &lt;code&gt;restore()&lt;/code&gt;:</source>
          <target state="translated">To ensure that loading is complete and no more assignments will take place, use the &lt;code&gt;assert_consumed()&lt;/code&gt; method of the status object returned by &lt;code&gt;restore()&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="6fdc8715d19df576a528e05d54600b3b8b7e951d" translate="yes" xml:space="preserve">
          <source>To ensure that loading is complete and no more assignments will take place, use the &lt;code&gt;assert_consumed()&lt;/code&gt; method of the status object returned by &lt;code&gt;restore&lt;/code&gt;:</source>
          <target state="translated">로드가 완료되고 더 이상 할당이 발생하지 않도록하려면 &lt;code&gt;restore&lt;/code&gt; 에서 반환 한 상태 객체 의 &lt;code&gt;assert_consumed()&lt;/code&gt; 메서드를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="7f9135f3ba27360a5d60098a844664f0e165caf9" translate="yes" xml:space="preserve">
          <source>To extend, inherit from this class; from the subclass &lt;strong&gt;init&lt;/strong&gt;, call</source>
          <target state="translated">확장하려면이 클래스에서 상속하십시오. 서브 클래스 &lt;strong&gt;init&lt;/strong&gt; 에서</target>
        </trans-unit>
        <trans-unit id="a5d8cbeafaa3eeb0c6165bfa56b4aafe15d6a9db" translate="yes" xml:space="preserve">
          <source>To generate different sequences across sessions, set neither graph-level nor op-level seeds:</source>
          <target state="translated">여러 세션에서 다른 시퀀스를 생성하려면 그래프 수준 또는 op 수준 시드를 설정하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="8b8fda9f12ffa5af323a889062c3aa890309e2cb" translate="yes" xml:space="preserve">
          <source>To generate the same repeatable sequence for an op across sessions, set the seed for the op:</source>
          <target state="translated">여러 세션에서 op에 대해 동일한 반복 가능한 시퀀스를 생성하려면 op에 대한 시드를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="ff3af5efb2174b5bcd82487648e50b8ae5b6afb0" translate="yes" xml:space="preserve">
          <source>To get a more intuitive and visual look at what this operation does, you can run tensorflow/examples/wav_to_spectrogram to read in an audio file and save out the resulting spectrogram as a PNG image.</source>
          <target state="translated">To get a more intuitive and visual look at what this operation does, you can run tensorflow/examples/wav_to_spectrogram to read in an audio file and save out the resulting spectrogram as a PNG image.</target>
        </trans-unit>
        <trans-unit id="ec9fe6e91399876e841634556ab27d6bee162948" translate="yes" xml:space="preserve">
          <source>To get a protocol buffer summary of the currently aggregated statistics, use the &lt;code&gt;StatsAggregator.get_summary()&lt;/code&gt; tensor. The easiest way to do this is to add the returned tensor to the &lt;code&gt;tf.GraphKeys.SUMMARIES&lt;/code&gt; collection, so that the summaries will be included with any existing summaries.</source>
          <target state="translated">현재 집계 된 통계의 프로토콜 버퍼 요약을 가져 오려면 &lt;code&gt;StatsAggregator.get_summary()&lt;/code&gt; 텐서를 사용하십시오 . 가장 쉬운 방법은 반환 된 텐서를 &lt;code&gt;tf.GraphKeys.SUMMARIES&lt;/code&gt; 컬렉션 에 추가 하여 요약이 기존 요약에 포함되도록하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="eecdfb3013e20388a17f33fbb93597b30d4ef349" translate="yes" xml:space="preserve">
          <source>To get the current default session, use &lt;a href=&quot;get_default_session&quot;&gt;&lt;code&gt;tf.compat.v1.get_default_session&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">현재 기본 세션을 얻으려면 &lt;a href=&quot;get_default_session&quot;&gt; &lt;code&gt;tf.compat.v1.get_default_session&lt;/code&gt; 을&lt;/a&gt; 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="273ca78fffe894af5651288f4a1f4c051d209749" translate="yes" xml:space="preserve">
          <source>To illustrate the user-visible effects, consider these examples:</source>
          <target state="translated">사용자가 볼 수있는 효과를 설명하려면 다음 예를 고려하십시오.</target>
        </trans-unit>
        <trans-unit id="ce5890e8d9ded5f833a93abef51a8a4c147da863" translate="yes" xml:space="preserve">
          <source>To instead reorder the data to rearrange the dimensions of a tensor, see &lt;a href=&quot;transpose&quot;&gt;&lt;code&gt;tf.transpose&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">대신 텐서의 치수를 재정렬하기 위해 데이터를 재정렬하려면 &lt;a href=&quot;transpose&quot;&gt; &lt;code&gt;tf.transpose&lt;/code&gt; 를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="58521b85b5941fed07e375b8c580b661cb67962d" translate="yes" xml:space="preserve">
          <source>To load a network from a JSON save file, use &lt;a href=&quot;../models/model_from_json&quot;&gt;&lt;code&gt;keras.models.model_from_json(json_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">JSON 저장 파일에서 네트워크를로드하려면 &lt;a href=&quot;../models/model_from_json&quot;&gt; &lt;code&gt;keras.models.model_from_json(json_string, custom_objects={})&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="fc1f35de200c65966b97907804a085417fa2674d" translate="yes" xml:space="preserve">
          <source>To load a network from a JSON save file, use &lt;a href=&quot;models/model_from_json&quot;&gt;&lt;code&gt;keras.models.model_from_json(json_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">JSON 저장 파일에서 네트워크를로드하려면 &lt;a href=&quot;models/model_from_json&quot;&gt; &lt;code&gt;keras.models.model_from_json(json_string, custom_objects={})&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="171ed2725b41e726794d8676fc06308b4d649fcf" translate="yes" xml:space="preserve">
          <source>To load a network from a yaml save file, use &lt;a href=&quot;../models/model_from_yaml&quot;&gt;&lt;code&gt;keras.models.model_from_yaml(yaml_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">yaml 저장 파일에서 네트워크를로드하려면 &lt;a href=&quot;../models/model_from_yaml&quot;&gt; &lt;code&gt;keras.models.model_from_yaml(yaml_string, custom_objects={})&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="32acfa401b4c952f2dcfef233deb7f737a491a64" translate="yes" xml:space="preserve">
          <source>To load a network from a yaml save file, use &lt;a href=&quot;models/model_from_yaml&quot;&gt;&lt;code&gt;keras.models.model_from_yaml(yaml_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">yaml 저장 파일에서 네트워크를로드하려면 &lt;a href=&quot;models/model_from_yaml&quot;&gt; &lt;code&gt;keras.models.model_from_yaml(yaml_string, custom_objects={})&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="84dbf2d04bfcc507efa1aac8fcfb0ed50455e091" translate="yes" xml:space="preserve">
          <source>To make the random sequences generated by all ops be repeatable across sessions, set a graph-level seed:</source>
          <target state="translated">모든 op에 의해 생성 된 랜덤 시퀀스를 세션 전체에서 반복 가능하게하려면 그래프 레벨 시드를 설정하십시오.</target>
        </trans-unit>
        <trans-unit id="8bca5a7e3515ab70d1734fcf9290f94f57a539f3" translate="yes" xml:space="preserve">
          <source>To mimic the behavior of &lt;code&gt;np.flatten&lt;/code&gt; (which flattens all dimensions), use &lt;code&gt;rt.merge_dims(0, -1). To mimic the behavior of&lt;/code&gt;tf.layers.Flatten&lt;code&gt;(which flattens all dimensions except the outermost batch dimension), use&lt;/code&gt;rt.merge_dims(1, -1)`.</source>
          <target state="translated">&lt;code&gt;np.flatten&lt;/code&gt; (모든 치수를 평평하게 함) 의 동작을 모방하려면 &lt;code&gt;rt.merge_dims(0, -1). To mimic the behavior of&lt;/code&gt; tf.layers.Flatten &lt;code&gt;(which flattens all dimensions except the outermost batch dimension), use&lt;/code&gt; 의 동작을 모방하려면 rt.merge_dims (1, -1)`를 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="f9a3e8831e7d974549f1a0383e7928bbabcfacd7" translate="yes" xml:space="preserve">
          <source>To obtain an individual graph, use the &lt;code&gt;get_concrete_function&lt;/code&gt; method of the callable created by &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. It can be called with the same arguments as &lt;code&gt;func&lt;/code&gt; and returns a special &lt;a href=&quot;graph&quot;&gt;&lt;code&gt;tf.Graph&lt;/code&gt;&lt;/a&gt; object:</source>
          <target state="translated">개별 그래프를 얻기 위해 사용 &lt;code&gt;get_concrete_function&lt;/code&gt; 에 의해 생성 된 호출 방법 &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; 를&lt;/a&gt; . &lt;code&gt;func&lt;/code&gt; 와 동일한 인수로 호출 할 수 있으며 특수한 &lt;a href=&quot;graph&quot;&gt; &lt;code&gt;tf.Graph&lt;/code&gt; &lt;/a&gt; 객체를 반환 합니다.</target>
        </trans-unit>
        <trans-unit id="9e83f95895428f42e71becadca9982d2894dba04" translate="yes" xml:space="preserve">
          <source>To pass sample weights when training or evaluating the Estimator, the first item returned by the input function should be a dictionary with keys &lt;code&gt;features&lt;/code&gt; and &lt;code&gt;sample_weights&lt;/code&gt;. Example below:</source>
          <target state="translated">To pass sample weights when training or evaluating the Estimator, the first item returned by the input function should be a dictionary with keys &lt;code&gt;features&lt;/code&gt; and &lt;code&gt;sample_weights&lt;/code&gt; . Example below:</target>
        </trans-unit>
        <trans-unit id="a0110a07b243d67a47edf557bd54d79fd2de9674" translate="yes" xml:space="preserve">
          <source>To perform the clipping, the values &lt;code&gt;t_list[i]&lt;/code&gt; are set to:</source>
          <target state="translated">클리핑을 수행하기 위해, &lt;code&gt;t_list[i]&lt;/code&gt; 값 은 다음과 같이 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="5e552f3cce7d0e03051d89f4e0255d1c49f37d1b" translate="yes" xml:space="preserve">
          <source>To prevent accidental sharing of variables, we raise an exception when getting an existing variable in a non-reusing scope.</source>
          <target state="translated">실수로 변수를 공유하는 것을 방지하기 위해 재사용하지 않는 범위에서 기존 변수를 가져올 때 예외가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="b90b39244fd5711de404a1ed79326b6635b08950" translate="yes" xml:space="preserve">
          <source>To process lines from files, use &lt;a href=&quot;textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">파일에서 행을 처리하려면 &lt;a href=&quot;textlinedataset&quot;&gt; &lt;code&gt;tf.data.TextLineDataset&lt;/code&gt; 을&lt;/a&gt; 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="aa139b98ea790b72d4805462346af0f7c690db65" translate="yes" xml:space="preserve">
          <source>To process records written in the &lt;code&gt;TFRecord&lt;/code&gt; format, use &lt;code&gt;TFRecordDataset&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;TFRecord&lt;/code&gt; 형식으로 작성된 레코드를 처리하려면 TFRecordDataset을 사용 &lt;code&gt;TFRecordDataset&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="862cc9660449fcff05a0a9d8dd83a651e63fd705" translate="yes" xml:space="preserve">
          <source>To provide an API that is close to Python's file I/O objects, and</source>
          <target state="translated">To provide an API that is close to Python's file I/O objects, and</target>
        </trans-unit>
        <trans-unit id="e93ce7e6602bc5d8a646cce42b0e2f27a7ee545d" translate="yes" xml:space="preserve">
          <source>To provide an implementation based on TensorFlow's C++ FileSystem API.</source>
          <target state="translated">To provide an implementation based on TensorFlow's C++ FileSystem API.</target>
        </trans-unit>
        <trans-unit id="b683767243ad0f37ed1467c8125bf95f601a1fc4" translate="yes" xml:space="preserve">
          <source>To read back the elements, use &lt;code&gt;TFRecordDataset&lt;/code&gt;.</source>
          <target state="translated">요소를 다시 읽으려면 &lt;code&gt;TFRecordDataset&lt;/code&gt; 을 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="ff235c20472c16fd213bae4a4af01054d920d420" translate="yes" xml:space="preserve">
          <source>To reconstruct an original waveform, a complementary window function should be used with &lt;code&gt;inverse_stft&lt;/code&gt;. Such a window function can be constructed with &lt;a href=&quot;inverse_stft_window_fn&quot;&gt;&lt;code&gt;tf.signal.inverse_stft_window_fn&lt;/code&gt;&lt;/a&gt;. Example:</source>
          <target state="translated">원래 파형을 재구성하려면 &lt;code&gt;inverse_stft&lt;/code&gt; 와 함께 보완적인 창 함수를 사용해야합니다 . 이러한 윈도우 함수는 &lt;a href=&quot;inverse_stft_window_fn&quot;&gt; &lt;code&gt;tf.signal.inverse_stft_window_fn&lt;/code&gt; &lt;/a&gt; 으로 구성 할 수 있습니다 . 예:</target>
        </trans-unit>
        <trans-unit id="a1cda1853dc2b4c5ea41c6c734bd8df45e09a74c" translate="yes" xml:space="preserve">
          <source>To reconstruct an original waveform, the same window function should be used with &lt;code&gt;mdct&lt;/code&gt; and &lt;code&gt;inverse_mdct&lt;/code&gt;.</source>
          <target state="translated">To reconstruct an original waveform, the same window function should be used with &lt;code&gt;mdct&lt;/code&gt; and &lt;code&gt;inverse_mdct&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ca5c9dd44204672cbbbbaf3d7ffdd096d2e60573" translate="yes" xml:space="preserve">
          <source>To record statistics, use one of the custom transformation functions defined in this module when defining your &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;. All statistics will be aggregated by the &lt;code&gt;StatsAggregator&lt;/code&gt; that is associated with a particular iterator (see below). For example, to record the latency of producing each element by iterating over a dataset:</source>
          <target state="translated">통계를 기록하려면 &lt;a href=&quot;../../../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 을&lt;/a&gt; 정의 할 때이 모듈에 정의 된 사용자 정의 변환 함수 중 하나를 사용하십시오 . 모든 통계는 특정 반복자와 연관된 &lt;code&gt;StatsAggregator&lt;/code&gt; 에 의해 집계됩니다 (아래 참조). 예를 들어, 데이터 세트를 반복하여 각 요소를 생성하는 대기 시간을 기록하려면 다음을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="84004f640543424d2c71289d24eec0f0b8df9f20" translate="yes" xml:space="preserve">
          <source>To record statistics, use one of the custom transformation functions defined in this module when defining your &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;. All statistics will be aggregated by the &lt;code&gt;StatsAggregator&lt;/code&gt; that is associated with a particular iterator (see below). For example, to record the latency of producing each element by iterating over a dataset:</source>
          <target state="translated">통계를 기록하려면 &lt;a href=&quot;../dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 을&lt;/a&gt; 정의 할 때이 모듈에 정의 된 사용자 정의 변환 함수 중 하나를 사용하십시오 . 모든 통계는 특정 반복자와 연관된 &lt;code&gt;StatsAggregator&lt;/code&gt; 에 의해 집계됩니다 (아래 참조). 예를 들어, 데이터 세트를 반복하여 각 요소를 생성하는 대기 시간을 기록하려면 다음을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="6601eea42af302d30ea25dfb68ead4d332e25000" translate="yes" xml:space="preserve">
          <source>To rescale an input in the &lt;code&gt;[0, 255]&lt;/code&gt; range to be in the &lt;code&gt;[-1, 1]&lt;/code&gt; range, you would pass &lt;code&gt;scale=1./127.5, offset=-1&lt;/code&gt;.</source>
          <target state="translated">To rescale an input in the &lt;code&gt;[0, 255]&lt;/code&gt; range to be in the &lt;code&gt;[-1, 1]&lt;/code&gt; range, you would pass &lt;code&gt;scale=1./127.5, offset=-1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="878d90bc13f047ae3b3be5ee736a5ab7a5fd6624" translate="yes" xml:space="preserve">
          <source>To rescale an input in the &lt;code&gt;[0, 255]&lt;/code&gt; range to be in the &lt;code&gt;[0, 1]&lt;/code&gt; range, you would pass &lt;code&gt;scale=1./255&lt;/code&gt;.</source>
          <target state="translated">To rescale an input in the &lt;code&gt;[0, 255]&lt;/code&gt; range to be in the &lt;code&gt;[0, 1]&lt;/code&gt; range, you would pass &lt;code&gt;scale=1./255&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9bf5571681c9436431c1ed224b52ea46ea226e1b" translate="yes" xml:space="preserve">
          <source>To reset the states of your model, call &lt;code&gt;.reset_states()&lt;/code&gt; on either a specific layer, or on your entire model.</source>
          <target state="translated">모델 상태를 재설정하려면 특정 레이어 또는 전체 모델에서 &lt;code&gt;.reset_states()&lt;/code&gt; 를 호출 하십시오.</target>
        </trans-unit>
        <trans-unit id="5f2fb526cb8dbaa2bd872bcdf1bffcdc847f4f4f" translate="yes" xml:space="preserve">
          <source>To restore variables, you have to know the name of the shadow variables. That name and the original variable can then be passed to a &lt;code&gt;Saver()&lt;/code&gt; object to restore the variable from the moving average value with: &lt;code&gt;saver = tf.compat.v1.train.Saver({ema.average_name(var): var})&lt;/code&gt;</source>
          <target state="translated">변수를 복원하려면 그림자 변수의 이름을 알아야합니다. 그런 다음 해당 이름과 원래 변수를 &lt;code&gt;Saver()&lt;/code&gt; 객체로 전달하여 &lt;code&gt;saver = tf.compat.v1.train.Saver({ema.average_name(var): var})&lt;/code&gt; 를 사용하여 이동 평균 값에서 변수를 복원 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="61b9174bc024e647c5c9bf1631b4141790c76fd9" translate="yes" xml:space="preserve">
          <source>To run TF2 programs on TPUs, you can either use &lt;code&gt;.compile&lt;/code&gt; and &lt;code&gt;.fit&lt;/code&gt; APIs in &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; with TPUStrategy, or write your own customized training loop by calling &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; directly. Note that TPUStrategy doesn't support pure eager execution, so please make sure the function passed into &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; is a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; us called inside a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; if running in eager mode.</source>
          <target state="translated">TPU에서 TF2 프로그램을 실행하려면 &lt;a href=&quot;../../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; 와 함께 tf.keras 에서 &lt;code&gt;.compile&lt;/code&gt; 및 &lt;code&gt;.fit&lt;/code&gt; API를 사용 하거나 &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; 를 직접 호출하여 사용자 정의 된 교육 루프를 작성할 수 있습니다. TPUStrategy 그래서, 순수한 열망 실행을 지원하시기 바랍니다하지 않습니다 확신에 전달하는 기능 &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; 는 A는 &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; 또는 &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; 우리가 내에서 호출 &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; 열망 모드에서 실행합니다.</target>
        </trans-unit>
        <trans-unit id="75d6af2437dac9afdbd259194ca306ea0df7ba35" translate="yes" xml:space="preserve">
          <source>To run TF2 programs on TPUs, you can either use &lt;code&gt;.compile&lt;/code&gt; and &lt;code&gt;.fit&lt;/code&gt; APIs in &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; with TPUStrategy, or write your own customized training loop by calling &lt;code&gt;strategy.run&lt;/code&gt; directly. Note that TPUStrategy doesn't support pure eager execution, so please make sure the function passed into &lt;code&gt;strategy.run&lt;/code&gt; is a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;strategy.run&lt;/code&gt; is called inside a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; if eager behavior is enabled.</source>
          <target state="translated">To run TF2 programs on TPUs, you can either use &lt;code&gt;.compile&lt;/code&gt; and &lt;code&gt;.fit&lt;/code&gt; APIs in &lt;a href=&quot;../../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; with TPUStrategy, or write your own customized training loop by calling &lt;code&gt;strategy.run&lt;/code&gt; directly. Note that TPUStrategy doesn't support pure eager execution, so please make sure the function passed into &lt;code&gt;strategy.run&lt;/code&gt; is a &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; or &lt;code&gt;strategy.run&lt;/code&gt; is called inside a &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; if eager behavior is enabled.</target>
        </trans-unit>
        <trans-unit id="1d76e97ea1150910b642e3424cedffc8e064a46d" translate="yes" xml:space="preserve">
          <source>To run TF2 programs on TPUs, you can either use &lt;code&gt;.compile&lt;/code&gt; and &lt;code&gt;.fit&lt;/code&gt; APIs in &lt;a href=&quot;../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; with TPUStrategy, or write your own customized training loop by calling &lt;code&gt;strategy.run&lt;/code&gt; directly. Note that TPUStrategy doesn't support pure eager execution, so please make sure the function passed into &lt;code&gt;strategy.run&lt;/code&gt; is a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;strategy.run&lt;/code&gt; is called inside a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; if eager behavior is enabled. See more details in https://www.tensorflow.org/guide/tpu.</source>
          <target state="translated">To run TF2 programs on TPUs, you can either use &lt;code&gt;.compile&lt;/code&gt; and &lt;code&gt;.fit&lt;/code&gt; APIs in &lt;a href=&quot;../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; with TPUStrategy, or write your own customized training loop by calling &lt;code&gt;strategy.run&lt;/code&gt; directly. Note that TPUStrategy doesn't support pure eager execution, so please make sure the function passed into &lt;code&gt;strategy.run&lt;/code&gt; is a &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; or &lt;code&gt;strategy.run&lt;/code&gt; is called inside a &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; if eager behavior is enabled. See more details in https://www.tensorflow.org/guide/tpu.</target>
        </trans-unit>
        <trans-unit id="e990fa899ccbe4b80cb8729867536ff2b0542458" translate="yes" xml:space="preserve">
          <source>To save and restore.</source>
          <target state="translated">저장하고 복원합니다.</target>
        </trans-unit>
        <trans-unit id="b35673692b203b1580cc459164c684b7c71fe1e4" translate="yes" xml:space="preserve">
          <source>To shard a &lt;code&gt;dataset&lt;/code&gt; across multiple TFRecord files:</source>
          <target state="translated">여러 TFRecord 파일 에서 &lt;code&gt;dataset&lt;/code&gt; 를 분할 하려면 다음을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="fc6bb2051a5897d4a8d4dac929c8a069356b9e0c" translate="yes" xml:space="preserve">
          <source>To simplify the thread implementation, the Coordinator provides a context handler &lt;code&gt;stop_on_exception()&lt;/code&gt; that automatically requests a stop if an exception is raised. Using the context handler the thread code above can be written as:</source>
          <target state="translated">스레드 구현을 단순화하기 위해 코디네이터는 예외가 발생하면 자동으로 중지를 요청하는 컨텍스트 핸들러 &lt;code&gt;stop_on_exception()&lt;/code&gt; 을 제공합니다 . 컨텍스트 핸들러를 사용하여 위의 스레드 코드를 다음과 같이 작성할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="a72b5fda5da9fdf55b3bf54113912820e04f4679" translate="yes" xml:space="preserve">
          <source>To stop the trace and export the collected information, use &lt;a href=&quot;trace_export&quot;&gt;&lt;code&gt;tf.summary.trace_export&lt;/code&gt;&lt;/a&gt;. To stop the trace without exporting, use &lt;a href=&quot;trace_off&quot;&gt;&lt;code&gt;tf.summary.trace_off&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">추적을 중지하고 수집 된 정보를 내보내려면 &lt;a href=&quot;trace_export&quot;&gt; &lt;code&gt;tf.summary.trace_export&lt;/code&gt; 를&lt;/a&gt; 사용 하십시오 . 내 &lt;a href=&quot;trace_off&quot;&gt; &lt;code&gt;tf.summary.trace_off&lt;/code&gt; &lt;/a&gt; 않고 추적을 중지하려면 tf.summary.trace_off를 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="25b078e238adc2f2bf2f225cb3a76dafd2b5b18d" translate="yes" xml:space="preserve">
          <source>To take the transpose of the matrices in dimension-0 (such as when you are transposing matrices where 0 is the batch dimesnion), you would set &lt;code&gt;perm=[0,2,1]&lt;/code&gt;.</source>
          <target state="translated">To take the transpose of the matrices in dimension-0 (such as when you are transposing matrices where 0 is the batch dimesnion), you would set &lt;code&gt;perm=[0,2,1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="78edbe912a6ec7dfbde2fa6ca3dbd293be354b5e" translate="yes" xml:space="preserve">
          <source>To train with replicas you deploy the same program in a &lt;code&gt;Cluster&lt;/code&gt;. One of the tasks must be identified as the &lt;em&gt;chief&lt;/em&gt;: the task that handles initialization, checkpoints, summaries, and recovery. The other tasks depend on the &lt;em&gt;chief&lt;/em&gt; for these services.</source>
          <target state="translated">복제본을 학습하려면 동일한 프로그램을 &lt;code&gt;Cluster&lt;/code&gt; 에 배포합니다 . 작업 중 하나는 &lt;em&gt;최고로&lt;/em&gt; 식별해야 합니다. 초기화, 검사 점, 요약 및 복구를 처리하는 작업입니다. 다른 작업은 이러한 서비스 의 &lt;em&gt;책임자&lt;/em&gt; 에 따라 다릅니다 .</target>
        </trans-unit>
        <trans-unit id="0a01c3edc32585755d57328d40fa48f8fdb3ab82" translate="yes" xml:space="preserve">
          <source>To treat a sparse input as dense, provide &lt;code&gt;allow_missing=True&lt;/code&gt;; otherwise, the parse functions will fail on any examples missing this feature.</source>
          <target state="translated">희소 입력을 조밀하게 처리하려면 &lt;code&gt;allow_missing=True&lt;/code&gt; 를 제공 하십시오 . 그렇지 않으면이 기능이없는 예에서 구문 분석 기능이 실패합니다.</target>
        </trans-unit>
        <trans-unit id="f70a87293b647de36d39cf376105ebfad1b65755" translate="yes" xml:space="preserve">
          <source>To treat sparse input as dense, provide a &lt;code&gt;default_value&lt;/code&gt;; otherwise, the parse functions will fail on any examples missing this feature.</source>
          <target state="translated">희소 입력을 조밀하게 처리하려면 &lt;code&gt;default_value&lt;/code&gt; 를 제공하십시오 . 그렇지 않으면이 기능이없는 예에서 구문 분석 기능이 실패합니다.</target>
        </trans-unit>
        <trans-unit id="2cf2713de328f732331e0697fff7bd058371175a" translate="yes" xml:space="preserve">
          <source>To use &lt;code&gt;MirroredStrategy&lt;/code&gt; with multiple workers, please refer to &lt;code&gt;tf.distribute.MultiWorkerMirroredStrategy&lt;/code&gt;.</source>
          <target state="translated">여러 작업자와 함께 &lt;code&gt;MirroredStrategy&lt;/code&gt; 를 사용하려면 &lt;code&gt;tf.distribute.MultiWorkerMirroredStrategy&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="12770f5e5f15720c161e4a87129f9d9bb0774bc6" translate="yes" xml:space="preserve">
          <source>To use SyncReplicasOptimizer with an &lt;code&gt;Estimator&lt;/code&gt;, you need to send sync_replicas_hook while calling the fit.</source>
          <target state="translated">&lt;code&gt;Estimator&lt;/code&gt; 와 함께 SyncReplicasOptimizer를 사용하려면 적합을 호출하는 동안 sync_replicas_hook을 보내야합니다.</target>
        </trans-unit>
        <trans-unit id="783180a85bf045e00f72afe9cf4aeba0310e67f8" translate="yes" xml:space="preserve">
          <source>To use a listener, implement a class and pass the listener to a &lt;code&gt;CheckpointSaverHook&lt;/code&gt;, as in this example:</source>
          <target state="translated">리스너를 사용하려면 다음 예제 와 같이 클래스를 구현하고 리스너를 &lt;code&gt;CheckpointSaverHook&lt;/code&gt; 에 전달하십시오 .</target>
        </trans-unit>
        <trans-unit id="dc7556a3e1ddbbfb55342d1204bfb7cd99d3d15a" translate="yes" xml:space="preserve">
          <source>To use another kernel, just replace the layer creation line with:</source>
          <target state="translated">To use another kernel, just replace the layer creation line with:</target>
        </trans-unit>
        <trans-unit id="82a8f0d7938dca39dd9baa444dbabf12a6beff73" translate="yes" xml:space="preserve">
          <source>To use crossed column in DNN model, you need to add it in an embedding column as in this example:</source>
          <target state="translated">DNN 모델에서 교차 열을 사용하려면 다음 예와 같이 포함 열에 추가해야합니다.</target>
        </trans-unit>
        <trans-unit id="df232f0149a3304cb55f19e9533d29d033c88a07" translate="yes" xml:space="preserve">
          <source>To use it with Keras &lt;code&gt;compile&lt;/code&gt;/&lt;code&gt;fit&lt;/code&gt;, &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_keras&quot;&gt;please read&lt;/a&gt;.</source>
          <target state="translated">Keras의와 함께 사용하기 위해 &lt;code&gt;compile&lt;/code&gt; / &lt;code&gt;fit&lt;/code&gt; , &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_keras&quot;&gt;읽어 보시기 바랍니다&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="52761ad57b4e88f15825661793f52089d3153688" translate="yes" xml:space="preserve">
          <source>To use mixed precision in a Keras model, the &lt;code&gt;'mixed_float16'&lt;/code&gt; or &lt;code&gt;'mixed_bfloat16'&lt;/code&gt; policy can be used. &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt; can be used to set the default policy for layers if no policy is passed to them. For example:</source>
          <target state="translated">&lt;code&gt;'mixed_float16'&lt;/code&gt; 모델에서 혼합 정밀도를 사용하려면 'mixed_float16' 또는 &lt;code&gt;'mixed_bfloat16'&lt;/code&gt; 정책을 사용할 수 있습니다. 정책이 전달되지 않은 경우 &lt;a href=&quot;set_policy&quot;&gt; &lt;code&gt;tf.keras.mixed_precision.experimental.set_policy&lt;/code&gt; &lt;/a&gt; 를 사용하여 레이어의 기본 정책을 설정할 수 있습니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="e3bc90b596c6a06641f646fd21855a01a15f891a" translate="yes" xml:space="preserve">
          <source>To use partial execution, a user first calls &lt;code&gt;partial_run_setup()&lt;/code&gt; and then a sequence of &lt;code&gt;partial_run()&lt;/code&gt;. &lt;code&gt;partial_run_setup&lt;/code&gt; specifies the list of feeds and fetches that will be used in the subsequent &lt;code&gt;partial_run&lt;/code&gt; calls.</source>
          <target state="translated">부분 실행을 사용하려면 사용자가 먼저 &lt;code&gt;partial_run_setup()&lt;/code&gt; 호출 한 다음 &lt;code&gt;partial_run()&lt;/code&gt; 시퀀스를 호출합니다 . &lt;code&gt;partial_run_setup&lt;/code&gt; 은 후속 &lt;code&gt;partial_run&lt;/code&gt; 호출에 사용될 피드 및 페치 목록을 지정 합니다.</target>
        </trans-unit>
        <trans-unit id="0486110c8c71e38a21a240cd6d1c94b9eb3a8e49" translate="yes" xml:space="preserve">
          <source>To use the pprof file:</source>
          <target state="translated">pprof 파일을 사용하려면</target>
        </trans-unit>
        <trans-unit id="77972f247631f66b18016dae59b6ae8450d1266a" translate="yes" xml:space="preserve">
          <source>To use the replacement for variables which does not have these issues:</source>
          <target state="translated">이러한 문제가없는 변수를 대체하려면 :</target>
        </trans-unit>
        <trans-unit id="49e82f46abbf85f6d932a9d996d53b01fa3132b2" translate="yes" xml:space="preserve">
          <source>To use this API on TPU you should use a custom training loop. Below is an example of a training and evaluation step:</source>
          <target state="translated">To use this API on TPU you should use a custom training loop. Below is an example of a training and evaluation step:</target>
        </trans-unit>
        <trans-unit id="d9fed22a474957718b6e8cceaa345a94b692ff2f" translate="yes" xml:space="preserve">
          <source>To use, enqueue filenames in a Queue. The output of Read will be a filename (key) and the contents of that file (value).</source>
          <target state="translated">사용하려면 대기열에 파일 이름을 넣으십시오. Read의 출력은 파일 이름 (키)과 해당 파일의 내용 (값)이됩니다.</target>
        </trans-unit>
        <trans-unit id="22500ae27d7e8f143eaf335c0b5e17ab00f9b916" translate="yes" xml:space="preserve">
          <source>To use, enqueue filenames in a Queue. The output of ReaderRead will be a filename (key) and the contents of that file (value).</source>
          <target state="translated">To use, enqueue filenames in a Queue. The output of ReaderRead will be a filename (key) and the contents of that file (value).</target>
        </trans-unit>
        <trans-unit id="936bb6e71e849ce05ab2a85d8c98f04120f3012d" translate="yes" xml:space="preserve">
          <source>To use, enqueue strings in a Queue. Read will take the front work string and output (work, work).</source>
          <target state="translated">사용하려면 대기열에 문자열을 넣으십시오. 읽기는 전면 작업 문자열과 출력 (작업, 작업)을 가져옵니다.</target>
        </trans-unit>
        <trans-unit id="c154b7f61f883ef570a45770d3ff51fd323c7da3" translate="yes" xml:space="preserve">
          <source>To use, enqueue strings in a Queue. ReaderRead will take the front work string and output (work, work).</source>
          <target state="translated">To use, enqueue strings in a Queue. ReaderRead will take the front work string and output (work, work).</target>
        </trans-unit>
        <trans-unit id="3b5c6be676ffa47f64b992a379fa3a687addb427" translate="yes" xml:space="preserve">
          <source>To warm-start an &lt;code&gt;Estimator&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;Estimator&lt;/code&gt; 를 예열하려면 다음을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="4e303367b1554b64249c563b8cdde01d47543e39" translate="yes" xml:space="preserve">
          <source>ToBool</source>
          <target state="translated">ToBool</target>
        </trans-unit>
        <trans-unit id="487247adcb71f2786b8b26a837b3a8f982eb5eb2" translate="yes" xml:space="preserve">
          <source>Toeplitz and Circulant Matrices - A Review: &lt;a href=&quot;https://www.nowpublishers.com/article/Details/CIT-006&quot;&gt;Gray, 2006&lt;/a&gt; (&lt;a href=&quot;https://ee.stanford.edu/%7Egray/toeplitz.pdf&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="translated">Toeplitz and Circulant Matrices - A Review: &lt;a href=&quot;https://www.nowpublishers.com/article/Details/CIT-006&quot;&gt;Gray, 2006&lt;/a&gt; (&lt;a href=&quot;https://ee.stanford.edu/%7Egray/toeplitz.pdf&quot;&gt;pdf&lt;/a&gt;)</target>
        </trans-unit>
        <trans-unit id="33d27663923e948257deb0ac3f48e158f539a021" translate="yes" xml:space="preserve">
          <source>Toeplitz means that &lt;code&gt;A&lt;/code&gt; has constant diagonals. Hence, &lt;code&gt;A&lt;/code&gt; can be generated with two vectors. One represents the first column of the matrix, and the other represents the first row.</source>
          <target state="translated">Toeplitz는 &lt;code&gt;A&lt;/code&gt; 에 대각선이 일정 하다는 것을 의미합니다 . 따라서, &lt;code&gt;A&lt;/code&gt; 는 2 개의 벡터로 생성 될 수있다. 하나는 행렬의 첫 번째 열을 나타내고 다른 하나는 첫 번째 행을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="0b92ef92f904efdaf4c897b9d82c8d8bc711a6dd" translate="yes" xml:space="preserve">
          <source>Top K categorical accuracy value.</source>
          <target state="translated">Top K categorical accuracy value.</target>
        </trans-unit>
        <trans-unit id="00a0204649835b513c94e7dcd17a04a18748c48f" translate="yes" xml:space="preserve">
          <source>TopK</source>
          <target state="translated">TopK</target>
        </trans-unit>
        <trans-unit id="9be91f59904e4556becc788662db35f00e8e37f9" translate="yes" xml:space="preserve">
          <source>TopKV2</source>
          <target state="translated">TopKV2</target>
        </trans-unit>
        <trans-unit id="ecc5f00336dd7a221505890680888796ae7ad79b" translate="yes" xml:space="preserve">
          <source>Total length of printed lines (e.g. set this to adapt the display to different terminal window sizes).</source>
          <target state="translated">Total length of printed lines (e.g. set this to adapt the display to different terminal window sizes).</target>
        </trans-unit>
        <trans-unit id="18b8da40b59609823f34b2eae31c92eb13b8a1df" translate="yes" xml:space="preserve">
          <source>Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of &lt;code&gt;None&lt;/code&gt;. If x is a &lt;a href=&quot;../../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; dataset and &lt;code&gt;steps&lt;/code&gt; is None, &lt;code&gt;predict&lt;/code&gt; will run until the input dataset is exhausted.</source>
          <target state="translated">Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of &lt;code&gt;None&lt;/code&gt; . If x is a &lt;a href=&quot;../../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; dataset and &lt;code&gt;steps&lt;/code&gt; is None, &lt;code&gt;predict&lt;/code&gt; will run until the input dataset is exhausted.</target>
        </trans-unit>
        <trans-unit id="d64736c6b92cc8a7d61eecd538f81edd562b347c" translate="yes" xml:space="preserve">
          <source>Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of &lt;code&gt;None&lt;/code&gt;. If x is a &lt;a href=&quot;../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; dataset and &lt;code&gt;steps&lt;/code&gt; is None, &lt;code&gt;predict&lt;/code&gt; will run until the input dataset is exhausted.</source>
          <target state="translated">Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of &lt;code&gt;None&lt;/code&gt; . If x is a &lt;a href=&quot;../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; dataset and &lt;code&gt;steps&lt;/code&gt; is None, &lt;code&gt;predict&lt;/code&gt; will run until the input dataset is exhausted.</target>
        </trans-unit>
        <trans-unit id="f9b71747c87f2120b712f35eff6cd2daf9f890ef" translate="yes" xml:space="preserve">
          <source>Total number of steps expected, None if unknown.</source>
          <target state="translated">Total number of steps expected, None if unknown.</target>
        </trans-unit>
        <trans-unit id="2b273e7fcad30a2510d0545ec0ed37f53fcc2226" translate="yes" xml:space="preserve">
          <source>Total number of tasks/workers/replicas, could be different from replicas_to_aggregate. If total_num_replicas &amp;gt; replicas_to_aggregate: it is backup_replicas + replicas_to_aggregate. If total_num_replicas &amp;lt; replicas_to_aggregate: Replicas compute multiple batches per update to variables.</source>
          <target state="translated">Total number of tasks/workers/replicas, could be different from replicas_to_aggregate. If total_num_replicas &amp;gt; replicas_to_aggregate: it is backup_replicas + replicas_to_aggregate. If total_num_replicas &amp;lt; replicas_to_aggregate: Replicas compute multiple batches per update to variables.</target>
        </trans-unit>
        <trans-unit id="3c766217ff2603fec7b0d19fd0e734ed0a36b0a6" translate="yes" xml:space="preserve">
          <source>Trace events are created only when the profiler is enabled. More information on how to use the profiler can be found at &lt;a href=&quot;https://tensorflow.org/guide/profiler&quot;&gt;https://tensorflow.org/guide/profiler&lt;/a&gt;</source>
          <target state="translated">Trace events are created only when the profiler is enabled. More information on how to use the profiler can be found at &lt;a href=&quot;https://tensorflow.org/guide/profiler&quot;&gt;https://tensorflow.org/guide/profiler&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="121fe412af2d5e916662ca3ec0794ef40b1e2f67" translate="yes" xml:space="preserve">
          <source>Trace of the linear operator, equal to sum of &lt;code&gt;self.diag_part()&lt;/code&gt;.</source>
          <target state="translated">선형 연산자의 추적 결과의 합 &lt;code&gt;self.diag_part()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="865739f4547ef1507e787549027075c5e994644c" translate="yes" xml:space="preserve">
          <source>Trace the function</source>
          <target state="translated">Trace the function</target>
        </trans-unit>
        <trans-unit id="36823bd4f0f4f117aef52940f9d3cfb4969f8d54" translate="yes" xml:space="preserve">
          <source>Trace the function, see the &lt;a href=&quot;https://www.tensorflow.org/guide/concrete_function&quot;&gt;Concrete Functions Guide&lt;/a&gt; for details.</source>
          <target state="translated">Trace the function, see the &lt;a href=&quot;https://www.tensorflow.org/guide/concrete_function&quot;&gt;Concrete Functions Guide&lt;/a&gt; for details.</target>
        </trans-unit>
        <trans-unit id="a3cd08d7e53167c39ff4df8ac6fd7573ac51ea11" translate="yes" xml:space="preserve">
          <source>Traces argument information at compilation time.</source>
          <target state="translated">컴파일시 인수 정보를 추적합니다.</target>
        </trans-unit>
        <trans-unit id="0eed61bd40a0f60d630ca02fa135c76ba2b343a8" translate="yes" xml:space="preserve">
          <source>Tracing may fail if a shape missmatch can be detected:</source>
          <target state="translated">Tracing may fail if a shape missmatch can be detected:</target>
        </trans-unit>
        <trans-unit id="235a91222dd28e8e16c0e133dc2cba6c6d12742f" translate="yes" xml:space="preserve">
          <source>Train a linear model to classify instances into one of multiple possible classes. When number of possible classes is 2, this is binary classification.</source>
          <target state="translated">선형 모델을 훈련시켜 인스턴스를 여러 가능한 클래스 중 하나로 분류합니다. 가능한 클래스 수가 2 인 경우 이진 분류입니다.</target>
        </trans-unit>
        <trans-unit id="ee3c9790cb66e90ecfd717511a371fde17bac07c" translate="yes" xml:space="preserve">
          <source>Train a linear regression model to predict label value given observation of feature values.</source>
          <target state="translated">피처 값을 관측하여 레이블 값을 예측하도록 선형 회귀 모델을 학습합니다.</target>
        </trans-unit>
        <trans-unit id="3efa73c7139b833a96e690294f1f5dee0c8dafcf" translate="yes" xml:space="preserve">
          <source>Train and evaluate the &lt;code&gt;estimator&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;estimator&lt;/code&gt; 훈련시키고 평가하십시오 .</target>
        </trans-unit>
        <trans-unit id="beb3053fd8366acd014d9b2f3ece6098b4b72e55" translate="yes" xml:space="preserve">
          <source>Train and evaluate with Keras</source>
          <target state="translated">Keras를 통한 교육 및 평가</target>
        </trans-unit>
        <trans-unit id="cc6f15e9d8d0df93c841a4bfbdce1ebcc8b8e338" translate="yes" xml:space="preserve">
          <source>Trainable variables (created by &lt;a href=&quot;variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;compat/v1/get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt;&lt;/a&gt;, where &lt;code&gt;trainable=True&lt;/code&gt; is default in both cases) are automatically watched. Tensors can be manually watched by invoking the &lt;code&gt;watch&lt;/code&gt; method on this context manager.</source>
          <target state="translated">학습 가능한 변수 ( &lt;a href=&quot;variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;compat/v1/get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt; 에&lt;/a&gt; 의해 생성됨 ( 여기서 &lt;code&gt;trainable=True&lt;/code&gt; 가 기본값 임)는 자동으로 감시됩니다. 이 컨텍스트 관리자 에서 &lt;code&gt;watch&lt;/code&gt; 메소드를 호출하여 텐서를 수동으로 볼 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="d85aa0db75043b2fc7e6d076a658d6108e846757" translate="yes" xml:space="preserve">
          <source>Training checkpoints</source>
          <target state="translated">훈련 검문소</target>
        </trans-unit>
        <trans-unit id="10de55a426007543588aad0c26e9034f2ddc3a47" translate="yes" xml:space="preserve">
          <source>Training graph visualization</source>
          <target state="translated">훈련 그래프 시각화</target>
        </trans-unit>
        <trans-unit id="7db0d855207cb66583c78145b39525c5633639da" translate="yes" xml:space="preserve">
          <source>Training helper that restores from checkpoint and creates session.</source>
          <target state="translated">검사 점에서 복원하고 세션을 만드는 교육 도우미.</target>
        </trans-unit>
        <trans-unit id="fb6f2aff4ed7bb3a59f319dbd5466e071cc53fba" translate="yes" xml:space="preserve">
          <source>Training loss &lt;code&gt;Tensor&lt;/code&gt;. Must be either scalar, or with shape &lt;code&gt;[1]&lt;/code&gt;.</source>
          <target state="translated">Training loss &lt;code&gt;Tensor&lt;/code&gt; . Must be either scalar, or with shape &lt;code&gt;[1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7079a2991739ec717b2df9e546127d4ec5f23f66" translate="yes" xml:space="preserve">
          <source>Training step to trigger on.</source>
          <target state="translated">Training step to trigger on.</target>
        </trans-unit>
        <trans-unit id="bf6759c44ad41b3091516c81e1bc49fed1c443ea" translate="yes" xml:space="preserve">
          <source>Trains a model given training data &lt;code&gt;input_fn&lt;/code&gt;.</source>
          <target state="translated">훈련 데이터 &lt;code&gt;input_fn&lt;/code&gt; 이 지정된 모델을 훈련 시킵니다 .</target>
        </trans-unit>
        <trans-unit id="3b7a7a43991418e3ac5adb5f5a2111146e234e48" translate="yes" xml:space="preserve">
          <source>Trains a recurrent neural network model to classify instances into one of multiple classes.</source>
          <target state="translated">반복 신경망 모델을 훈련시켜 인스턴스를 여러 클래스 중 하나로 분류합니다.</target>
        </trans-unit>
        <trans-unit id="03d8eb1e5694e7e09ad702ee89cbe5988334450c" translate="yes" xml:space="preserve">
          <source>Trains the model for a fixed number of epochs (iterations on a dataset).</source>
          <target state="translated">고정 된 수의 에포크 (데이터 세트에서 반복)에 대해 모델을 학습시킵니다.</target>
        </trans-unit>
        <trans-unit id="e5238d35744e76f113cfe81d17fbfa29f295ac05" translate="yes" xml:space="preserve">
          <source>Transcode the input text from a source encoding to a destination encoding.</source>
          <target state="translated">입력 텍스트를 소스 인코딩에서 대상 인코딩으로 코드 변환하십시오.</target>
        </trans-unit>
        <trans-unit id="983dff86700d17b79a819dfaab7edfc9d23e3e22" translate="yes" xml:space="preserve">
          <source>Transfer learning with TensorFlow Hub</source>
          <target state="translated">TensorFlow Hub를 통한 전송 학습</target>
        </trans-unit>
        <trans-unit id="db752c46f6cefcfd15e6ab5a7acbda3b3ec8bdb7" translate="yes" xml:space="preserve">
          <source>Transfer learning with a pretrained ConvNet</source>
          <target state="translated">사전 훈련 된 ConvNet을 통한 학습 학습</target>
        </trans-unit>
        <trans-unit id="d3f4cdda163a694c3d7aafb554148d5d45b68f92" translate="yes" xml:space="preserve">
          <source>Transform [batch] matrix &lt;code&gt;x&lt;/code&gt; with left multiplication: &lt;code&gt;x --&amp;gt; Ax&lt;/code&gt;.</source>
          <target state="translated">왼쪽 곱셈으로 [batch] 행렬 &lt;code&gt;x&lt;/code&gt; 를 변환합니다 : &lt;code&gt;x --&amp;gt; Ax&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="42db4158efb02ff54237870e3243b8f49a10cb88" translate="yes" xml:space="preserve">
          <source>Transform [batch] vector &lt;code&gt;x&lt;/code&gt; with left multiplication: &lt;code&gt;x --&amp;gt; Ax&lt;/code&gt;.</source>
          <target state="translated">[ &lt;code&gt;x&lt;/code&gt; ] 벡터 x 를 왼쪽 곱셈으로 변환합니다 : &lt;code&gt;x --&amp;gt; Ax&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d685ad7c59aeb1945ef867b52857539b62c1b81c" translate="yes" xml:space="preserve">
          <source>Transformations</source>
          <target state="translated">Transformations</target>
        </trans-unit>
        <trans-unit id="74bb10df9a38f2595c0a343bb271e614fdcbbc79" translate="yes" xml:space="preserve">
          <source>Transformations:</source>
          <target state="translated">Transformations:</target>
        </trans-unit>
        <trans-unit id="a65cfd47338728767e1d8fe389f325154f22e3d2" translate="yes" xml:space="preserve">
          <source>Transformer model for language understanding</source>
          <target state="translated">언어 이해를위한 변압기 모델</target>
        </trans-unit>
        <trans-unit id="c6c688b7b4f9c9a55098909d8e4bbea04f915bb0" translate="yes" xml:space="preserve">
          <source>Transforms &lt;code&gt;elems&lt;/code&gt; by applying &lt;code&gt;fn&lt;/code&gt; to each element unstacked on axis 0. (deprecated arguments)</source>
          <target state="translated">Transforms &lt;code&gt;elems&lt;/code&gt; by applying &lt;code&gt;fn&lt;/code&gt; to each element unstacked on axis 0. (deprecated arguments)</target>
        </trans-unit>
        <trans-unit id="33d02a85618ebba62b643cdb3a4e3f69d88e4866" translate="yes" xml:space="preserve">
          <source>Transforms &lt;code&gt;input_dataset&lt;/code&gt; containing &lt;code&gt;Example&lt;/code&gt; protos as vectors of DT_STRING into a dataset of &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt; objects representing the parsed features.</source>
          <target state="translated">Transforms &lt;code&gt;input_dataset&lt;/code&gt; containing &lt;code&gt;Example&lt;/code&gt; protos as vectors of DT_STRING into a dataset of &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt; objects representing the parsed features.</target>
        </trans-unit>
        <trans-unit id="ae192d97c8bb43adae60e73f077c7a262798214c" translate="yes" xml:space="preserve">
          <source>Transforms a Tensor into a serialized TensorProto proto.</source>
          <target state="translated">Tensor를 직렬화 된 TensorProto 프로토로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="4999b7a71f3c11d96be3e3808c9e8fc9eb261a51" translate="yes" xml:space="preserve">
          <source>Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.</source>
          <target state="translated">Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.</target>
        </trans-unit>
        <trans-unit id="3fe37f8377ecffffde4f3405645d41e0b3b001bd" translate="yes" xml:space="preserve">
          <source>Transforms a serialized tensorflow.TensorProto proto into a Tensor.</source>
          <target state="translated">직렬화 된 tensorflow를 변형합니다.</target>
        </trans-unit>
        <trans-unit id="f6ffa885d4348734b93da08e4df5eb979eae50df" translate="yes" xml:space="preserve">
          <source>Transforms a spectrogram into a form that's useful for speech recognition.</source>
          <target state="translated">Transforms a spectrogram into a form that's useful for speech recognition.</target>
        </trans-unit>
        <trans-unit id="bd2f17793a2563570a330d4671f70e89b2937951" translate="yes" xml:space="preserve">
          <source>Transforms a tf.Example proto (as a string) into typed tensors.</source>
          <target state="translated">Transforms a tf.Example proto (as a string) into typed tensors.</target>
        </trans-unit>
        <trans-unit id="0b8677520a5e74e9b4b4788602fe7bc1e6fe1360" translate="yes" xml:space="preserve">
          <source>Transforms a vector of brain.Example protos (as strings) into typed tensors.</source>
          <target state="translated">Transforms a vector of brain.Example protos (as strings) into typed tensors.</target>
        </trans-unit>
        <trans-unit id="be5a4de021d7eadbe941c3409ada3c7b1dabaea1" translate="yes" xml:space="preserve">
          <source>Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.</source>
          <target state="translated">Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.</target>
        </trans-unit>
        <trans-unit id="eb363dfb8e50cc87a12a26568447baf08e0619fb" translate="yes" xml:space="preserve">
          <source>Transforms a vector of tf.Example protos (as strings) into typed tensors.</source>
          <target state="translated">Transforms a vector of tf.Example protos (as strings) into typed tensors.</target>
        </trans-unit>
        <trans-unit id="db88575dec31c88470bf932dd1fed9370a7d6c45" translate="yes" xml:space="preserve">
          <source>Transforms a vector of tf.io.SequenceExample protos (as strings) into</source>
          <target state="translated">Transforms a vector of tf.io.SequenceExample protos (as strings) into</target>
        </trans-unit>
        <trans-unit id="655ffb734eb7a488c9c872982dd743f0f56654c3" translate="yes" xml:space="preserve">
          <source>Transforms each input point to its distances to all cluster centers.</source>
          <target state="translated">각 입력 지점을 모든 클러스터 중심까지의 거리로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="fcd8235ad6fe846d496fe3b5ab9ef987b5075ab1" translate="yes" xml:space="preserve">
          <source>Transforms each sequence in &lt;code&gt;sequences&lt;/code&gt; to a list of texts(strings).</source>
          <target state="translated">각 시퀀스 변환 &lt;code&gt;sequences&lt;/code&gt; 텍스트 (문자열)의리스트.</target>
        </trans-unit>
        <trans-unit id="e5d4ddf915c1a321118b7e1927e1abe917834a51" translate="yes" xml:space="preserve">
          <source>Transforms each sequence into a list of text.</source>
          <target state="translated">각 시퀀스를 텍스트 목록으로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="15870f729495d9cc692bfd46436e8e2286a88257" translate="yes" xml:space="preserve">
          <source>Transforms each text in &lt;code&gt;texts&lt;/code&gt; to a sequence of integers.</source>
          <target state="translated">각 텍스트 변환 &lt;code&gt;texts&lt;/code&gt; 정수의 시퀀스를.</target>
        </trans-unit>
        <trans-unit id="86add4b4e27d9c231884be5bf0ca73d7ca67d517" translate="yes" xml:space="preserve">
          <source>Transforms each text in texts to a sequence of integers.</source>
          <target state="translated">텍스트의 각 텍스트를 일련의 정수로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="71016bf2a8086e5adaa42aba0ed39ec30d8c82a3" translate="yes" xml:space="preserve">
          <source>Transparently swap the tensors produced in forward inference but needed for back prop from GPU to CPU. This allows training RNNs which would typically not fit on a single GPU, with very minimal (or no) performance penalty.</source>
          <target state="translated">Transparently swap the tensors produced in forward inference but needed for back prop from GPU to CPU. This allows training RNNs which would typically not fit on a single GPU, with very minimal (or no) performance penalty.</target>
        </trans-unit>
        <trans-unit id="fa257429d8539a08df2ef78919507d4169cac2c8" translate="yes" xml:space="preserve">
          <source>Transpose</source>
          <target state="translated">Transpose</target>
        </trans-unit>
        <trans-unit id="c6f3940520a66558ccbf4deb29b8ad759ce2893f" translate="yes" xml:space="preserve">
          <source>Transpose image(s) by swapping the height and width dimension.</source>
          <target state="translated">높이와 너비 치수를 바꿔 이미지를 바꿉니다.</target>
        </trans-unit>
        <trans-unit id="aaef5878a51828ef045b24256f979251b2fa2f09" translate="yes" xml:space="preserve">
          <source>Transposed 2D convolution layer (sometimes called 2D Deconvolution).</source>
          <target state="translated">전치 된 2D 컨볼 루션 레이어 (때로는 2D 디콘 볼 루션이라고도 함).</target>
        </trans-unit>
        <trans-unit id="20b55b4579cc2c500b14b1401912fc234412af61" translate="yes" xml:space="preserve">
          <source>Transposed 3D convolution layer (sometimes called 3D Deconvolution).</source>
          <target state="translated">전치 된 3D 컨볼 루션 레이어 (때로는 3D 디컨 볼 루션이라고 함).</target>
        </trans-unit>
        <trans-unit id="8af454b225f62d0dcbcdc7d510f5d2a829dab734" translate="yes" xml:space="preserve">
          <source>Transposed convolution layer (sometimes called Deconvolution).</source>
          <target state="translated">전치 된 회선 레이어 (때로는 Deconvolution이라고도 함).</target>
        </trans-unit>
        <trans-unit id="c1808bb1215e7e8c12e0e53a29ab899fd06887f1" translate="yes" xml:space="preserve">
          <source>Transposes &lt;code&gt;a&lt;/code&gt;, where &lt;code&gt;a&lt;/code&gt; is a Tensor.</source>
          <target state="translated">Transposes &lt;code&gt;a&lt;/code&gt; , where &lt;code&gt;a&lt;/code&gt; is a Tensor.</target>
        </trans-unit>
        <trans-unit id="4559d9f372084e43321f8c8b67aa21b4b3be2db7" translate="yes" xml:space="preserve">
          <source>Transposes &lt;code&gt;a&lt;/code&gt;.</source>
          <target state="translated">이항 . &lt;code&gt;a&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5f6a95a7cfa0d75e4317493ed12e7c428f7e9164" translate="yes" xml:space="preserve">
          <source>Transposes a &lt;code&gt;SparseTensor&lt;/code&gt;</source>
          <target state="translated">이항 &lt;code&gt;SparseTensor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2262bf9a92872de90cc8f31b3040779445c53825" translate="yes" xml:space="preserve">
          <source>Transposes a tensor and returns it.</source>
          <target state="translated">텐서를 전치하여 반환합니다.</target>
        </trans-unit>
        <trans-unit id="52d7d3690c76e45b3f4ac6d7704301666eae2d1f" translate="yes" xml:space="preserve">
          <source>Transposes last two dimensions of tensor &lt;code&gt;a&lt;/code&gt;.</source>
          <target state="translated">텐서 &lt;code&gt;a&lt;/code&gt; 의 마지막 두 차원을 바꿉니다 .</target>
        </trans-unit>
        <trans-unit id="9979dd1e79bbad4d151836984b737dcb27347af2" translate="yes" xml:space="preserve">
          <source>Transposes the inner (matrix) dimensions of a CSRSparseMatrix.</source>
          <target state="translated">Transposes the inner (matrix) dimensions of a CSRSparseMatrix.</target>
        </trans-unit>
        <trans-unit id="3011a7a9922254d6bc94cbf852ba13e1faec6347" translate="yes" xml:space="preserve">
          <source>Transposes the inner (matrix) dimensions of a SparseMatrix and optionally conjugates its values.</source>
          <target state="translated">Transposes the inner (matrix) dimensions of a SparseMatrix and optionally conjugates its values.</target>
        </trans-unit>
        <trans-unit id="ad508b5e8ca6e24e73ed31c06d7f5a032986b9fa" translate="yes" xml:space="preserve">
          <source>Transposes the last two dimensions of and conjugates tensor &lt;code&gt;matrix&lt;/code&gt;.</source>
          <target state="translated">텐서 &lt;code&gt;matrix&lt;/code&gt; 의 마지막 두 차원을 전치하고 켤레로 만듭니다.</target>
        </trans-unit>
        <trans-unit id="50adcae727c1540c5f8c2710b6a31d5f9d861f46" translate="yes" xml:space="preserve">
          <source>TridiagonalMatMul</source>
          <target state="translated">TridiagonalMatMul</target>
        </trans-unit>
        <trans-unit id="90d5236e355acbf1f60d52716bcd6f0402f00405" translate="yes" xml:space="preserve">
          <source>TridiagonalSolve</source>
          <target state="translated">TridiagonalSolve</target>
        </trans-unit>
        <trans-unit id="06d45be632bf282d211af84cbad96e7a33a03b23" translate="yes" xml:space="preserve">
          <source>Trouser</source>
          <target state="translated">Trouser</target>
        </trans-unit>
        <trans-unit id="afd4d25dce087075230a2ce40818eed7a8b7c821" translate="yes" xml:space="preserve">
          <source>True and exponential_avg_factor != 1.0: Mean must be a &lt;code&gt;Tensor&lt;/code&gt; of the same shape as scale containing the exponential running mean.</source>
          <target state="translated">True and exponential_avg_factor != 1.0: Mean must be a &lt;code&gt;Tensor&lt;/code&gt; of the same shape as scale containing the exponential running mean.</target>
        </trans-unit>
        <trans-unit id="b0904ca48cae02b60d23262abfe2ce903cfefb1e" translate="yes" xml:space="preserve">
          <source>True and exponential_avg_factor == 1.0: Mean must be None. is_training</source>
          <target state="translated">True and exponential_avg_factor == 1.0: Mean must be None. is_training</target>
        </trans-unit>
        <trans-unit id="3c2872020c8add34a2cf2fcba50775a603f0d0e2" translate="yes" xml:space="preserve">
          <source>True if &lt;code&gt;v&lt;/code&gt; was created inside the scope, False if not.</source>
          <target state="translated">&lt;code&gt;v&lt;/code&gt; 가 범위 내에서 작성된 경우 True이고 , 그렇지 않은 경우 False입니다.</target>
        </trans-unit>
        <trans-unit id="ea6d3038da7212df43580d700019b440b6df39f7" translate="yes" xml:space="preserve">
          <source>True if a GPU device of the requested kind is available.</source>
          <target state="translated">요청 된 종류의 GPU 장치를 사용할 수 있으면 참입니다.</target>
        </trans-unit>
        <trans-unit id="0182552244a71267208d89b4ec5f7f593b52459d" translate="yes" xml:space="preserve">
          <source>True if a Tensor of the &lt;code&gt;other&lt;/code&gt;&lt;code&gt;DType&lt;/code&gt; will be implicitly converted to this &lt;code&gt;DType&lt;/code&gt;.</source>
          <target state="translated">의 텐서 경우는 true &lt;code&gt;other&lt;/code&gt; &lt;code&gt;DType&lt;/code&gt; 암시 적으로이 변환됩니다 &lt;code&gt;DType&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d65dfa1082053356f76fa7e32f60ffc009e106a5" translate="yes" xml:space="preserve">
          <source>True if a stop was requested.</source>
          <target state="translated">중지가 요청 된 경우 true입니다.</target>
        </trans-unit>
        <trans-unit id="fba54694bed7e972eba04ddb43445b6835518a56" translate="yes" xml:space="preserve">
          <source>True if inside a &lt;code&gt;with strategy.scope():&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;with strategy.scope():&lt;/code&gt; 안에 있으면 true 입니다.</target>
        </trans-unit>
        <trans-unit id="0d356c240016a0c32cb15a7f51543e8af63f4aad" translate="yes" xml:space="preserve">
          <source>True if spec_or_tensor is compatible with self.</source>
          <target state="translated">spec_or_tensor가 self와 호환 가능한 경우 true입니다.</target>
        </trans-unit>
        <trans-unit id="f031713f493f44a87f541097d9a6c4633a7c4174" translate="yes" xml:space="preserve">
          <source>True if the Coordinator is told stop, False if the timeout expired.</source>
          <target state="translated">코디네이터에게 중지를 알리면 true이고 시간 초과가 만료되면 False입니다.</target>
        </trans-unit>
        <trans-unit id="40e3b3363df1be71fab94fcf563145f01a88073c" translate="yes" xml:space="preserve">
          <source>True if the caller can expect that serialized TensorFlow graphs produced can be consumed by programs that are compiled with the TensorFlow library source code after (year, month, day).</source>
          <target state="translated">호출자가 생성 된 직렬화 된 TensorFlow 그래프가 (년, 월, 일) 이후에 TensorFlow 라이브러리 소스 코드로 컴파일 된 프로그램에 의해 사용될 수 있다고 예상 할 수있는 경우에 해당됩니다.</target>
        </trans-unit>
        <trans-unit id="5bee156ad7270160152bb6dbabfb7781157fb705" translate="yes" xml:space="preserve">
          <source>True if the constructor is being called by one of the factory methods. If false, an exception will be raised.</source>
          <target state="translated">True if the constructor is being called by one of the factory methods. If false, an exception will be raised.</target>
        </trans-unit>
        <trans-unit id="4faef914883a1a10aa15778c49f35fb98be8732e" translate="yes" xml:space="preserve">
          <source>True if the coordinator was told to stop, False otherwise.</source>
          <target state="translated">코디네이터에게 중지하라는 지시가 있으면 참, 그렇지 않으면 거짓.</target>
        </trans-unit>
        <trans-unit id="41bb9eed11faf580e5cf2243f1284401f224c42a" translate="yes" xml:space="preserve">
          <source>True if the difference between the current time and the time of the last trigger exceeds &lt;code&gt;every_secs&lt;/code&gt;, or if the difference between the current step and the last triggered step exceeds &lt;code&gt;every_steps&lt;/code&gt;. False otherwise.</source>
          <target state="translated">현재 시간과 마지막 트리거 시간의 차이 가 &lt;code&gt;every_secs&lt;/code&gt; 를 초과 하거나 현재 단계와 마지막 트리거 된 단계의 차이가 &lt;code&gt;every_steps&lt;/code&gt; 를 초과하는 경우 true 입니다. 그렇지 않으면 거짓입니다.</target>
        </trans-unit>
        <trans-unit id="bfc13f68b704941e80142d04a3ed7c6629e6c664" translate="yes" xml:space="preserve">
          <source>True if the export directory contains SavedModel files, False otherwise.</source>
          <target state="translated">내보내기 디렉토리에 저장된 모델 파일이 포함되어 있으면 true이고, 그렇지 않으면 False입니다.</target>
        </trans-unit>
        <trans-unit id="6a900b62e1edba1c0e27907e12139238da6afb94" translate="yes" xml:space="preserve">
          <source>True if the given node must run on CPU, otherwise False.</source>
          <target state="translated">주어진 노드가 CPU에서 실행되어야하면 true이고, 그렇지 않으면 False입니다.</target>
        </trans-unit>
        <trans-unit id="e5ad15e25e43eb5bd9cd393c44c117efba29c6f6" translate="yes" xml:space="preserve">
          <source>True if the path exists, whether it's a file or a directory. False if the path does not exist and there are no filesystem errors.</source>
          <target state="translated">경로가 파일이든 디렉토리이든 관계없이 true입니다. 경로가 존재하지 않고 파일 시스템 오류가 없으면 False입니다.</target>
        </trans-unit>
        <trans-unit id="2817ab94bf3761a7902a64b969f4ce8bf858694f" translate="yes" xml:space="preserve">
          <source>True if the quantization is signed or unsigned.</source>
          <target state="translated">True if the quantization is signed or unsigned.</target>
        </trans-unit>
        <trans-unit id="12521f184e32516a21dbe08fda414904f64f4716" translate="yes" xml:space="preserve">
          <source>True if the queue is closed and false if the queue is open.</source>
          <target state="translated">큐가 닫혀 있으면 true이고 큐가 열려 있으면 false입니다.</target>
        </trans-unit>
        <trans-unit id="8a6738c31462b3c1cdd66322c6255be278594bf2" translate="yes" xml:space="preserve">
          <source>True if the reader implementation can serialize its state.</source>
          <target state="translated">True if the reader implementation can serialize its state.</target>
        </trans-unit>
        <trans-unit id="b3d692e2a1a03f9a580cbe6af7887c076366f28a" translate="yes" xml:space="preserve">
          <source>True if the sequence is a not a string and is a collections.abc.Sequence or a dict.</source>
          <target state="translated">시퀀스가 문자열이 아니고 collections.abc.Sequence 또는 dict 인 경우 true입니다.</target>
        </trans-unit>
        <trans-unit id="e846d2ffe93240497692f8c335b561f9a3b5ca4b" translate="yes" xml:space="preserve">
          <source>True if this Dimension and &lt;code&gt;other&lt;/code&gt; are compatible.</source>
          <target state="translated">이 Dimension 및 &lt;code&gt;other&lt;/code&gt; Dimension 이 호환 가능한 경우 True 입니다.</target>
        </trans-unit>
        <trans-unit id="1af9f77f297353d13cc2052ce5add84a77143e29" translate="yes" xml:space="preserve">
          <source>True if this graph has been finalized.</source>
          <target state="translated">이 그래프가 완료되면 true입니다.</target>
        </trans-unit>
        <trans-unit id="13ac567ddd78dbff91bfa15ccdc8c27002125b9d" translate="yes" xml:space="preserve">
          <source>True iff &lt;code&gt;self&lt;/code&gt; is compatible with &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">진정한 iff &lt;code&gt;self&lt;/code&gt; 는 &lt;code&gt;other&lt;/code&gt; 호환됩니다 .</target>
        </trans-unit>
        <trans-unit id="3ea2041726102a7cb24768511dc474dfc2d2086e" translate="yes" xml:space="preserve">
          <source>True iff at most one predicate is allowed to evaluate to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">True iff at most one predicate is allowed to evaluate to &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="84ec63366604b21f0a1cd748c6c806b8cc035002" translate="yes" xml:space="preserve">
          <source>True on success, or false if no summary was emitted because no default summary writer was available.</source>
          <target state="translated">성공하면 true, 사용 가능한 기본 요약 작성기가 없어 요약이 생성되지 않으면 false입니다.</target>
        </trans-unit>
        <trans-unit id="fc591d62fe392ab5c3a30eaf5e21967f39695530" translate="yes" xml:space="preserve">
          <source>True on success, or false if no summary was written because no default summary writer was available.</source>
          <target state="translated">성공하면 true, 사용 가능한 기본 요약 작성기가 없어 요약이 작성되지 않은 경우 false입니다.</target>
        </trans-unit>
        <trans-unit id="c5ce5b285e7cceb24195ca6aafbc51395c9eec5d" translate="yes" xml:space="preserve">
          <source>True tries extracting the file as an Archive, like tar or zip.</source>
          <target state="translated">True tries extracting the file as an Archive, like tar or zip.</target>
        </trans-unit>
        <trans-unit id="64eb5b8ece15c07598a0a8b6e044d88bd144975f" translate="yes" xml:space="preserve">
          <source>True, False or None. None restores the default behavior.</source>
          <target state="translated">True, False or None. None restores the default behavior.</target>
        </trans-unit>
        <trans-unit id="f16aacc072df96e8b74050ff74d241c633ad1f94" translate="yes" xml:space="preserve">
          <source>True, if the path is a directory; False otherwise</source>
          <target state="translated">경로가 디렉토리이면 true입니다. 그렇지 않으면 거짓</target>
        </trans-unit>
        <trans-unit id="b14f591e5a76ce927e3d51f5d369ecadec7b9175" translate="yes" xml:space="preserve">
          <source>True, if variables should be casted.</source>
          <target state="translated">변수를 캐스트해야하는 경우에 해당됩니다.</target>
        </trans-unit>
        <trans-unit id="0398d49e6ea66afbb212b36d04e2616800d64ac3" translate="yes" xml:space="preserve">
          <source>True: executes each operation synchronously.</source>
          <target state="translated">True : 각 작업을 동 기적으로 실행합니다.</target>
        </trans-unit>
        <trans-unit id="4a2f0a78e05a23faa43333403bbc8e7bb4a127d9" translate="yes" xml:space="preserve">
          <source>TruncateDiv</source>
          <target state="translated">TruncateDiv</target>
        </trans-unit>
        <trans-unit id="88d5fe1e339e14bfa5e83a1a1041f877f78fa654" translate="yes" xml:space="preserve">
          <source>TruncateMod</source>
          <target state="translated">TruncateMod</target>
        </trans-unit>
        <trans-unit id="5b6f413272cd888b5af448b50b30ef69c71b431f" translate="yes" xml:space="preserve">
          <source>TruncatedNormal</source>
          <target state="translated">TruncatedNormal</target>
        </trans-unit>
        <trans-unit id="4d9fd66a7778c40e3dba2083356a599b52f25d88" translate="yes" xml:space="preserve">
          <source>Truncation designates that negative numbers will round fractional quantities toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different than Python semantics. See &lt;code&gt;FloorDiv&lt;/code&gt; for a division function that matches Python Semantics.</source>
          <target state="translated">잘림은 음수가 소수를 0으로 반올림 함을 나타냅니다. 즉 -7/5 = -1입니다. 이것은 C 시맨틱과 일치하지만 Python 시맨틱과 다릅니다. Python 시맨틱과 일치하는 나누기 함수는 &lt;code&gt;FloorDiv&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="aa758b468b210aad3c052427b42a0c7ac48798f6" translate="yes" xml:space="preserve">
          <source>Tuple in the format used in &lt;a href=&quot;../model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Tuple in the format used in &lt;a href=&quot;../model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="3c85382570b1156fafff522dc38424cdd757186e" translate="yes" xml:space="preserve">
          <source>Tuple of 2 integers, how many zeros to add at the start and end of dim 1.</source>
          <target state="translated">Tuple of 2 integers, how many zeros to add at the start and end of dim 1.</target>
        </trans-unit>
        <trans-unit id="d878205ddde8c656cd0c2ec819ef9a66c6db3326" translate="yes" xml:space="preserve">
          <source>Tuple of 2 integers.</source>
          <target state="translated">Tuple of 2 integers.</target>
        </trans-unit>
        <trans-unit id="9e902bb2fc5cab147bc391e40439b73d1a642c42" translate="yes" xml:space="preserve">
          <source>Tuple of 2 tuples, padding pattern.</source>
          <target state="translated">Tuple of 2 tuples, padding pattern.</target>
        </trans-unit>
        <trans-unit id="3e0b6b48776191185766960be076280c767a6bcd" translate="yes" xml:space="preserve">
          <source>Tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). &lt;code&gt;(2, 2, 2)&lt;/code&gt; will halve the size of the 3D input in each dimension.</source>
          <target state="translated">Tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). &lt;code&gt;(2, 2, 2)&lt;/code&gt; will halve the size of the 3D input in each dimension.</target>
        </trans-unit>
        <trans-unit id="a2a3aa7cb19c709e2aeca6ab2c5fbdce9372f47c" translate="yes" xml:space="preserve">
          <source>Tuple of 3 tuples, padding pattern.</source>
          <target state="translated">Tuple of 3 tuples, padding pattern.</target>
        </trans-unit>
        <trans-unit id="3b36302f1d8a1cd0c40fa6d16b6fe2aaaa964f68" translate="yes" xml:space="preserve">
          <source>Tuple of Numpy arrays: &lt;code&gt;(x_train, y_train), (x_test, y_test)&lt;/code&gt;.</source>
          <target state="translated">Numpy 배열의 튜플 : &lt;code&gt;(x_train, y_train), (x_test, y_test)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e5fcb3189bbbad2089b9134f58fe7fca941f8a70" translate="yes" xml:space="preserve">
          <source>Tuple of integers &lt;code&gt;(height, width)&lt;/code&gt;, defaults to &lt;code&gt;(256, 256)&lt;/code&gt;. The dimensions to which all images found will be resized.</source>
          <target state="translated">Tuple of integers &lt;code&gt;(height, width)&lt;/code&gt; , defaults to &lt;code&gt;(256, 256)&lt;/code&gt; . The dimensions to which all images found will be resized.</target>
        </trans-unit>
        <trans-unit id="80e3a7c1e14386c2b20631926430b4d65ddfff1f" translate="yes" xml:space="preserve">
          <source>Tuple of integers representing (min, max) range values for all arrays without a specified range. Intended for experimenting with quantization via &quot;dummy quantization&quot;. (default None)</source>
          <target state="translated">Tuple of integers representing (min, max) range values for all arrays without a specified range. Intended for experimenting with quantization via &quot;dummy quantization&quot;. (default None)</target>
        </trans-unit>
        <trans-unit id="7e26526855fdb022129c7cbbd982fef1427fddb1" translate="yes" xml:space="preserve">
          <source>Tuple of integers, shape of returned Keras variable.</source>
          <target state="translated">Tuple of integers, shape of returned Keras variable.</target>
        </trans-unit>
        <trans-unit id="b8ec74a912c043af498fdebd5ada0cb4d060e6f5" translate="yes" xml:space="preserve">
          <source>Tuple of integers. Permutation pattern does not include the samples dimension. Indexing starts at 1. For instance, &lt;code&gt;(2, 1)&lt;/code&gt; permutes the first and second dimensions of the input.</source>
          <target state="translated">Tuple of integers. Permutation pattern does not include the samples dimension. Indexing starts at 1. For instance, &lt;code&gt;(2, 1)&lt;/code&gt; permutes the first and second dimensions of the input.</target>
        </trans-unit>
        <trans-unit id="4d1f41be26f53eaa6f970fca60630a6f21855e44" translate="yes" xml:space="preserve">
          <source>Tuple of strings representing input tensor names and list of integers representing input shapes (e.g., [(&quot;foo&quot; : [1, 16, 16, 3])]). Use only when graph cannot be loaded into TensorFlow and when &lt;code&gt;input_tensors&lt;/code&gt; and &lt;code&gt;output_tensors&lt;/code&gt; are None. (default None)</source>
          <target state="translated">Tuple of strings representing input tensor names and list of integers representing input shapes (e.g., [(&quot;foo&quot; : [1, 16, 16, 3])]). Use only when graph cannot be loaded into TensorFlow and when &lt;code&gt;input_tensors&lt;/code&gt; and &lt;code&gt;output_tensors&lt;/code&gt; are None. (default None)</target>
        </trans-unit>
        <trans-unit id="4cbc0064b79f9aa3d7ea238c4e18ad22b86f3acb" translate="yes" xml:space="preserve">
          <source>Tuple or list of integers with target dimensions, or single integer. The sizes of &lt;code&gt;x.shape[axes[0]]&lt;/code&gt; and &lt;code&gt;y.shape[axes[1]]&lt;/code&gt; should be equal.</source>
          <target state="translated">Tuple or list of integers with target dimensions, or single integer. The sizes of &lt;code&gt;x.shape[axes[0]]&lt;/code&gt; and &lt;code&gt;y.shape[axes[1]]&lt;/code&gt; should be equal.</target>
        </trans-unit>
        <trans-unit id="082793c3bba9dd17881797f57bdfd7fbb926fad6" translate="yes" xml:space="preserve">
          <source>Tuple or list of integers, shape of returned Keras variable</source>
          <target state="translated">Tuple or list of integers, shape of returned Keras variable</target>
        </trans-unit>
        <trans-unit id="4531a58c8012cfb70552795a6d42bd391095a246" translate="yes" xml:space="preserve">
          <source>Tuple or list of two floats. Range for picking a brightness shift value from.</source>
          <target state="translated">Tuple or list of two floats. Range for picking a brightness shift value from.</target>
        </trans-unit>
        <trans-unit id="fcd91650680c7044999f313873fe057ab50db675" translate="yes" xml:space="preserve">
          <source>Tuple or list with positional arguments for &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="translated">Tuple or list with positional arguments for &lt;code&gt;fn&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b33b3b3fb1f8b255b7161c80b27363774e8f88ed" translate="yes" xml:space="preserve">
          <source>Tuple or list. Additional positional arguments to pass to &lt;code&gt;fn()&lt;/code&gt;.</source>
          <target state="translated">Tuple or list. Additional positional arguments to pass to &lt;code&gt;fn()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2613ea839d069df0d5c8d9c5f47854631d09fc20" translate="yes" xml:space="preserve">
          <source>Tuple used by LSTM Cells for &lt;code&gt;state_size&lt;/code&gt;, &lt;code&gt;zero_state&lt;/code&gt;, and output state.</source>
          <target state="translated">&lt;code&gt;state_size&lt;/code&gt; , &lt;code&gt;zero_state&lt;/code&gt; 및 출력 상태 에 LSTM 셀에서 사용되는 튜플 .</target>
        </trans-unit>
        <trans-unit id="5b48f912499203c94d01ac7a5a26aea7a05b21fa" translate="yes" xml:space="preserve">
          <source>Turn a nD tensor into a 2D tensor with same 0th dimension.</source>
          <target state="translated">nD 텐서를 같은 0 차원의 2D 텐서로 바꾸십시오.</target>
        </trans-unit>
        <trans-unit id="84c0c370c16aa336bb6f7381c737e4c2aba96f9e" translate="yes" xml:space="preserve">
          <source>Turns positive integers (indexes) into dense vectors of fixed size.</source>
          <target state="translated">양의 정수 (인덱스)를 고정 크기의 밀도가 높은 벡터로 바꿉니다.</target>
        </trans-unit>
        <trans-unit id="2c47d5c1924debfd2ddf97975d083f8b91fc55b1" translate="yes" xml:space="preserve">
          <source>Turns the serialized form of a Keras object back into an actual object.</source>
          <target state="translated">Turns the serialized form of a Keras object back into an actual object.</target>
        </trans-unit>
        <trans-unit id="0312b13c624e55c7e9bb5fdcfe0c38b37f8b9c61" translate="yes" xml:space="preserve">
          <source>Tutorials and examples can be found in: &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/python_api.md&quot;&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/python_api.md&lt;/a&gt;</source>
          <target state="translated">Tutorials and examples can be found in: &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/python_api.md&quot;&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/python_api.md&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e1970692bb6c07bd87f9682c04edd6a7dc8b64ed" translate="yes" xml:space="preserve">
          <source>Tutorials and examples can be found in: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md</source>
          <target state="translated">자습서 및 예제는 https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md에서 찾을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5392c950bdde4be7e5f5b8fdc6a1ca5f21e905cf" translate="yes" xml:space="preserve">
          <source>Twitter</source>
          <target state="translated">Twitter</target>
        </trans-unit>
        <trans-unit id="698a7f116a9d0145fa7461b0cd8612ceab6c65c3" translate="yes" xml:space="preserve">
          <source>Two 2-d numpy arrays representing the theoretical and numerical Jacobian for dy/dx. Each has &quot;x_size&quot; rows and &quot;y_size&quot; columns where &quot;x_size&quot; is the number of elements in x and &quot;y_size&quot; is the number of elements in y. If x is a list, returns a list of two numpy arrays.</source>
          <target state="translated">dy / dx에 대한 이론적이고 수치적인 Jacobian을 나타내는 2 개의 2 차원 숫자 배열. 각각에는 &quot;x_size&quot;행과 &quot;y_size&quot;열이 있습니다. 여기서 &quot;x_size&quot;는 x의 요소 수이고 &quot;y_size&quot;는 y의 요소 수입니다. x가 목록이면 두 개의 numpy 배열 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="ba15ec3492dd4bf582b4e766b61d26647d5ffcdc" translate="yes" xml:space="preserve">
          <source>Two &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</source>
          <target state="translated">Two &lt;a href=&quot;../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</target>
        </trans-unit>
        <trans-unit id="e2f8646d6f565d2ad7fc58a15043d6c2087ee7b6" translate="yes" xml:space="preserve">
          <source>Two &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</source>
          <target state="translated">Two &lt;a href=&quot;../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</target>
        </trans-unit>
        <trans-unit id="0e476c2f4924caa7e379cac892bc43188804bebb" translate="yes" xml:space="preserve">
          <source>Two &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</source>
          <target state="translated">Two &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</target>
        </trans-unit>
        <trans-unit id="34ab6873a8334c48d1673369412e608cd7417e10" translate="yes" xml:space="preserve">
          <source>Two &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</source>
          <target state="translated">Two &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</target>
        </trans-unit>
        <trans-unit id="31988105748d2b29509a18eb03ac4bcf2e98951c" translate="yes" xml:space="preserve">
          <source>Two &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</source>
          <target state="translated">Two &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical AND of the two input tensors.</target>
        </trans-unit>
        <trans-unit id="322bef22d5ff10923c851f4887f9752d9171cff1" translate="yes" xml:space="preserve">
          <source>Two &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</source>
          <target state="translated">Two &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; objects of type &lt;code&gt;bool&lt;/code&gt; of the same shape. In this case, the result will be the element-wise logical XOR of the two input tensors.</target>
        </trans-unit>
        <trans-unit id="e61ae5fa9a8a338e450ea4521d3c90e37b3fce55" translate="yes" xml:space="preserve">
          <source>Two &lt;code&gt;Tensor&lt;/code&gt; objects: &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;variance&lt;/code&gt;.</source>
          <target state="translated">두 개의 &lt;code&gt;Tensor&lt;/code&gt; 객체 : &lt;code&gt;mean&lt;/code&gt; 및 &lt;code&gt;variance&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="18f9e0ca8006912df25de0a98edea35700ad81f2" translate="yes" xml:space="preserve">
          <source>Two accumulation steps are required: 1) the accumulation of gradients squared, 2) the accumulation of updates squared.</source>
          <target state="translated">1) 그래디언트 누적 제곱, 2) 업데이트 누적 제곱의 두 가지 누적 단계가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="a1d8ed408945a366f45477724e8c9686614ca2d7" translate="yes" xml:space="preserve">
          <source>Two different templates are guaranteed to be unique, unless you reenter the same variable scope as the initial definition of a template and redefine it. An examples of this exception:</source>
          <target state="translated">템플릿의 초기 정의와 동일한 변수 범위를 다시 입력하여 재정의하지 않는 한 두 개의 서로 다른 템플릿이 고유성을 보장합니다. 이 예외의 예 :</target>
        </trans-unit>
        <trans-unit id="641506872a34040c078fdb14eeef6b25c62c6fc9" translate="yes" xml:space="preserve">
          <source>Two generators are independent of each other in the sense that the random-number streams they generate don't have statistically detectable correlations. The new generators are also independent of the old one. The old generator's state will be changed (like other random-number generating methods), so two calls of &lt;code&gt;split&lt;/code&gt; will return different new generators.</source>
          <target state="translated">두 개의 생성기는 그들이 생성하는 난수 스트림이 통계적으로 감지 가능한 상관 관계가 없다는 의미에서 서로 독립적입니다. 새로운 발전기도 기존 발전기와 독립적입니다. 이전 생성기의 상태는 다른 난수 생성 방법과 같이 변경되므로 두 번의 &lt;code&gt;split&lt;/code&gt; 호출은 다른 새로운 생성기를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="609ab801a6e4c68686c97569df58fbb61201051d" translate="yes" xml:space="preserve">
          <source>Two known Dimensions are compatible if they have the same value. An unknown Dimension is compatible with all other Dimensions.</source>
          <target state="translated">두 개의 알려진 차원이 동일한 값을 갖는 경우 호환됩니다. 알 수없는 차원은 다른 모든 차원과 호환됩니다.</target>
        </trans-unit>
        <trans-unit id="6133911db30a0e3197c09499734a8919b0cbd3bf" translate="yes" xml:space="preserve">
          <source>Two or more words may be assigned to the same index, due to possible collisions by the hashing function. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Birthday_problem#Probability_table&quot;&gt;probability&lt;/a&gt; of a collision is in relation to the dimension of the hashing space and the number of distinct objects.</source>
          <target state="translated">해싱 함수에 의한 충돌 가능성으로 인해 동일한 인덱스에 둘 이상의 단어가 할당 될 수 있습니다. &lt;a href=&quot;https://en.wikipedia.org/wiki/Birthday_problem#Probability_table&quot;&gt;확률&lt;/a&gt; 충돌은 해싱 공간의 차원과 구별되는 객체의 수에 관련된다.</target>
        </trans-unit>
        <trans-unit id="aa46f48d3d26a8be473e57169e56d3f2b7f57692" translate="yes" xml:space="preserve">
          <source>Two possibly-partially-defined shapes are compatible if there exists a fully-defined shape that both shapes can represent. Thus, compatibility allows the shape inference code to reason about partially-defined shapes. For example:</source>
          <target state="translated">두 모양이 모두 나타낼 수있는 완전히 정의 된 모양이 있으면 부분적으로 정의 된 두 가지 모양이 호환됩니다. 따라서 호환성으로 인해 모양 유추 코드가 부분적으로 정의 된 모양에 대해 추론 할 수 있습니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b556440bce1c841c1d10f79b38663d9dfe8ce6f6" translate="yes" xml:space="preserve">
          <source>Two single elements of type &lt;code&gt;bool&lt;/code&gt;</source>
          <target state="translated">Two single elements of type &lt;code&gt;bool&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8b0a6ae6ca7d62abe9867da93517fe68a65fffe7" translate="yes" xml:space="preserve">
          <source>Two static instances exist in the distributions library, signifying one of two possible properties for samples from a distribution:</source>
          <target state="translated">분포 라이브러리에는 두 개의 정적 인스턴스가 있으며, 분포에서 샘플에 대해 가능한 두 가지 속성 중 하나를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="304880baecfd0af0b3d1da16c178a413930af3d7" translate="yes" xml:space="preserve">
          <source>Two tensors are considered compatible if they have the same dtype and their shapes are compatible (see &lt;a href=&quot;tensorshape#is_compatible_with&quot;&gt;&lt;code&gt;tf.TensorShape.is_compatible_with&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">두 개의 텐서는 dtype이 같고 모양이 호환되는 경우 호환되는 것으로 간주됩니다 ( &lt;a href=&quot;tensorshape#is_compatible_with&quot;&gt; &lt;code&gt;tf.TensorShape.is_compatible_with&lt;/code&gt; &lt;/a&gt; 참조 ).</target>
        </trans-unit>
        <trans-unit id="6c808e735cf1d9acc205c12bc34a1db874936c96" translate="yes" xml:space="preserve">
          <source>Two tensors: &lt;code&gt;weighted_mean&lt;/code&gt; and &lt;code&gt;weighted_variance&lt;/code&gt;.</source>
          <target state="translated">두 텐서 : &lt;code&gt;weighted_mean&lt;/code&gt; 및 &lt;code&gt;weighted_variance&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="197f1a152813e8754c3ab4ada0aee8e8eb0ab0e1" translate="yes" xml:space="preserve">
          <source>Type collections</source>
          <target state="translated">타입 컬렉션</target>
        </trans-unit>
        <trans-unit id="70190875a976d04b6dbbdb76a76b8abab15ed20d" translate="yes" xml:space="preserve">
          <source>Type of reduction to apply to loss.</source>
          <target state="translated">Type of reduction to apply to loss.</target>
        </trans-unit>
        <trans-unit id="580ea2f11b5081d9834cac3a14574bfc02323a10" translate="yes" xml:space="preserve">
          <source>Type of the new or existing variable (defaults to &lt;code&gt;DT_FLOAT&lt;/code&gt;).</source>
          <target state="translated">Type of the new or existing variable (defaults to &lt;code&gt;DT_FLOAT&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="eda6e626972cf9e8cb577094d8e71478f4d87dc1" translate="yes" xml:space="preserve">
          <source>Type of the variables. Ignored if &lt;code&gt;initializer&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">Type of the variables. Ignored if &lt;code&gt;initializer&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8cb8d838a08c5043e95b8affed6f234ffe7a8fca" translate="yes" xml:space="preserve">
          <source>Type of weights, such as &lt;a href=&quot;../../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt;. Only float and integer weights are supported.</source>
          <target state="translated">Type of weights, such as &lt;a href=&quot;../../tf#float32&quot;&gt; &lt;code&gt;tf.float32&lt;/code&gt; &lt;/a&gt;. Only float and integer weights are supported.</target>
        </trans-unit>
        <trans-unit id="89bccb1027fad55abb521d6f7f2c0ac6a074c8f5" translate="yes" xml:space="preserve">
          <source>Type specification for &lt;a href=&quot;dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 의&lt;/a&gt; 형식 사양입니다 .</target>
        </trans-unit>
        <trans-unit id="712d9ffcd0e88abdb9eab9798af5f280ec9181bd" translate="yes" xml:space="preserve">
          <source>Type specification for &lt;a href=&quot;experimental/optional&quot;&gt;&lt;code&gt;tf.experimental.Optional&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Type specification for &lt;a href=&quot;experimental/optional&quot;&gt; &lt;code&gt;tf.experimental.Optional&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="546c3b422414d2acfe0b7b6df33ddda2e98f189c" translate="yes" xml:space="preserve">
          <source>Type specification for &lt;a href=&quot;iterator&quot;&gt;&lt;code&gt;tf.data.Iterator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Type specification for &lt;a href=&quot;iterator&quot;&gt; &lt;code&gt;tf.data.Iterator&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="7ffc6a6652502645af83819deceaf071d1bee7ae" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; 의&lt;/a&gt; 타입 사양입니다 .</target>
        </trans-unit>
        <trans-unit id="db38e64c6790f1fa6a4046e1608589e1baafdb4f" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; 의&lt;/a&gt; 타입 사양입니다 .</target>
        </trans-unit>
        <trans-unit id="506637460ca723fc98125655b0c45f16d689f183" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.SparseTensor&lt;/code&gt; 의&lt;/a&gt; 타입 사양입니다 .</target>
        </trans-unit>
        <trans-unit id="f8dc08024793f24e03dca43c23eba2de392c0936" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Type specification for a &lt;a href=&quot;sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="097420656a3bb835a98ade8d3c1d8d6e161e4abc" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;tensorarray&quot;&gt;&lt;code&gt;tf.TensorArray&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;tensorarray&quot;&gt; &lt;code&gt;tf.TensorArray&lt;/code&gt; 의&lt;/a&gt; 타입 사양입니다 .</target>
        </trans-unit>
        <trans-unit id="0fa80254c7cf732908a6ef92e8bcb16a8cbc3031" translate="yes" xml:space="preserve">
          <source>TypeError if &lt;code&gt;cluster&lt;/code&gt; is not a dictionary or &lt;code&gt;ClusterDef&lt;/code&gt; protocol buffer, or if &lt;code&gt;ps_strategy&lt;/code&gt; is provided but not a callable.</source>
          <target state="translated">형식 오류 경우 &lt;code&gt;cluster&lt;/code&gt; 사전인지 아닌지 &lt;code&gt;ClusterDef&lt;/code&gt; 의 프로토콜 버퍼, 또는 경우 &lt;code&gt;ps_strategy&lt;/code&gt; 은 제공하지만, 호출되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="7a7a3cb39cba799635ae97a5b59c3c35fb2a8e05" translate="yes" xml:space="preserve">
          <source>TypeError.</source>
          <target state="translated">TypeError.</target>
        </trans-unit>
        <trans-unit id="5bdcc3d1ee1c7b80e26206fa1de63397c5a2add9" translate="yes" xml:space="preserve">
          <source>TypeError: If the slice indices aren't int, slice, ellipsis, tf.newaxis or int32/int64 tensors.</source>
          <target state="translated">TypeError: If the slice indices aren't int, slice, ellipsis, tf.newaxis or int32/int64 tensors.</target>
        </trans-unit>
        <trans-unit id="0d6c4c2eeadfc7d013e2b2fb8940e520aa96954c" translate="yes" xml:space="preserve">
          <source>Types I, II, III and IV are supported. Type I is implemented using a length &lt;code&gt;2N&lt;/code&gt; padded &lt;a href=&quot;rfft&quot;&gt;&lt;code&gt;tf.signal.rfft&lt;/code&gt;&lt;/a&gt;. Type II is implemented using a length &lt;code&gt;2N&lt;/code&gt; padded &lt;a href=&quot;rfft&quot;&gt;&lt;code&gt;tf.signal.rfft&lt;/code&gt;&lt;/a&gt;, as described here: &lt;a href=&quot;https://dsp.stackexchange.com/a/10606&quot;&gt;Type 2 DCT using 2N FFT padded (Makhoul)&lt;/a&gt;. Type III is a fairly straightforward inverse of Type II (i.e. using a length &lt;code&gt;2N&lt;/code&gt; padded &lt;a href=&quot;irfft&quot;&gt;&lt;code&gt;tf.signal.irfft&lt;/code&gt;&lt;/a&gt;). Type IV is calculated through 2N length DCT2 of padded signal and picking the odd indices.</source>
          <target state="translated">Types I, II, III and IV are supported. Type I is implemented using a length &lt;code&gt;2N&lt;/code&gt; padded &lt;a href=&quot;rfft&quot;&gt; &lt;code&gt;tf.signal.rfft&lt;/code&gt; &lt;/a&gt;. Type II is implemented using a length &lt;code&gt;2N&lt;/code&gt; padded &lt;a href=&quot;rfft&quot;&gt; &lt;code&gt;tf.signal.rfft&lt;/code&gt; &lt;/a&gt;, as described here: &lt;a href=&quot;https://dsp.stackexchange.com/a/10606&quot;&gt;Type 2 DCT using 2N FFT padded (Makhoul)&lt;/a&gt;. Type III is a fairly straightforward inverse of Type II (i.e. using a length &lt;code&gt;2N&lt;/code&gt; padded &lt;a href=&quot;irfft&quot;&gt; &lt;code&gt;tf.signal.irfft&lt;/code&gt; &lt;/a&gt;). Type IV is calculated through 2N length DCT2 of padded signal and picking the odd indices.</target>
        </trans-unit>
        <trans-unit id="c9e719623f3a5418b899a4ace2cf4d169670e417" translate="yes" xml:space="preserve">
          <source>Types of loss reduction.</source>
          <target state="translated">손실 감소 유형.</target>
        </trans-unit>
        <trans-unit id="aa3c047f418cf4b489027ae070f266970331772f" translate="yes" xml:space="preserve">
          <source>Typical usage example:</source>
          <target state="translated">일반적인 사용 예 :</target>
        </trans-unit>
        <trans-unit id="f86aad613fa5c3ee99a3b5451654d3e3136022f7" translate="yes" xml:space="preserve">
          <source>Typical usage for the &lt;code&gt;SavedModelBuilder&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;SavedModelBuilder&lt;/code&gt; 의 일반적인 사용법 :</target>
        </trans-unit>
        <trans-unit id="1dc96cc06e4c88360c7be195760a73e5c44fb2f7" translate="yes" xml:space="preserve">
          <source>Typical usage of this strategy could be testing your code with the tf.distribute.Strategy API before switching to other strategies which actually distribute to multiple devices/machines.</source>
          <target state="translated">이 전략의 일반적인 사용법은 실제로 여러 장치 / 기계에 배포되는 다른 전략으로 전환하기 전에 tf.distribute.Strategy API로 코드를 테스트하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="9f433de3a09f2cf5cd13a827c57725457d725e39" translate="yes" xml:space="preserve">
          <source>Typical usage:</source>
          <target state="translated">일반적인 사용법 :</target>
        </trans-unit>
        <trans-unit id="86f2b70049641c1127233f5a7f23b12cf7d72298" translate="yes" xml:space="preserve">
          <source>Typical usages of the &lt;code&gt;MethodNameUpdater&lt;/code&gt;</source>
          <target state="translated">Typical usages of the &lt;code&gt;MethodNameUpdater&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0271771c7069a116c3373c269a63be4c6aca6198" translate="yes" xml:space="preserve">
          <source>Typical users will use one of the more specialized DEFINE_xxx functions, such as DEFINE_string or DEFINE_integer. But developers who need to create Flag objects themselves should use this function to register their flags.</source>
          <target state="translated">일반적인 사용자는 DEFINE_string 또는 DEFINE_integer와 같이보다 전문화 된 DEFINE_xxx 함수 중 하나를 사용합니다. 그러나 Flag 객체를 직접 만들어야하는 개발자는이 함수를 사용하여 플래그를 등록해야합니다.</target>
        </trans-unit>
        <trans-unit id="2637b9cc80067f35b6391fac2edcbf9be59d7ab4" translate="yes" xml:space="preserve">
          <source>Typically only used in a cross-replica context:</source>
          <target state="translated">일반적으로 교차 복제 컨텍스트에서만 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="770e50ed1c5b312d1ae6d0b8292c12f6aec34dd4" translate="yes" xml:space="preserve">
          <source>Typically this function is used to convert from TensorFlow GraphDef to TFLite. Conversion can be customized by providing arguments that are forwarded to &lt;code&gt;build_toco_convert_protos&lt;/code&gt; (see documentation for details). This function has been deprecated. Please use &lt;a href=&quot;../../../lite/tfliteconverter&quot;&gt;&lt;code&gt;lite.TFLiteConverter&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">일반적으로이 함수는 TensorFlow GraphDef에서 TFLite로 변환하는 데 사용됩니다. &lt;code&gt;build_toco_convert_protos&lt;/code&gt; 로 전달되는 인수를 제공하여 변환을 사용자 정의 할 수 있습니다 (자세한 내용은 설명서 참조). 이 기능은 더 이상 사용되지 않습니다. 사용하십시오 &lt;a href=&quot;../../../lite/tfliteconverter&quot;&gt; &lt;code&gt;lite.TFLiteConverter&lt;/code&gt; 을&lt;/a&gt; 대신.</target>
        </trans-unit>
        <trans-unit id="3fe4dd1700ccac29f3d0ae3fa02b865b65b1c45f" translate="yes" xml:space="preserve">
          <source>Typically this function is used to convert from TensorFlow GraphDef to TFLite. Conversion can be customized by providing arguments that are forwarded to &lt;code&gt;build_toco_convert_protos&lt;/code&gt; (see documentation for details). This function has been deprecated. Please use &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter&quot;&gt;&lt;code&gt;lite.TFLiteConverter&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">Typically this function is used to convert from TensorFlow GraphDef to TFLite. Conversion can be customized by providing arguments that are forwarded to &lt;code&gt;build_toco_convert_protos&lt;/code&gt; (see documentation for details). This function has been deprecated. Please use &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter&quot;&gt; &lt;code&gt;lite.TFLiteConverter&lt;/code&gt; &lt;/a&gt; instead.</target>
        </trans-unit>
        <trans-unit id="9f937cb551b8e8625cac21b8a54df64070d57507" translate="yes" xml:space="preserve">
          <source>Typically, constructing a file writer creates a new event file in &lt;code&gt;logdir&lt;/code&gt;. This event file will contain &lt;code&gt;Event&lt;/code&gt; protocol buffers constructed when you call one of the following functions: &lt;code&gt;add_summary()&lt;/code&gt;, &lt;code&gt;add_session_log()&lt;/code&gt;, &lt;code&gt;add_event()&lt;/code&gt;, or &lt;code&gt;add_graph()&lt;/code&gt;.</source>
          <target state="translated">일반적으로 파일 작성기를 구성하면 &lt;code&gt;logdir&lt;/code&gt; 에 새 이벤트 파일이 작성 됩니다. 이 이벤트 파일에는 &lt;code&gt;add_summary()&lt;/code&gt; , &lt;code&gt;add_session_log()&lt;/code&gt; , &lt;code&gt;add_event()&lt;/code&gt; 또는 &lt;code&gt;add_graph()&lt;/code&gt; 함수 중 하나를 호출 할 때 생성 된 &lt;code&gt;Event&lt;/code&gt; 프로토콜 버퍼 가 포함됩니다 .</target>
        </trans-unit>
        <trans-unit id="aff7b1a518fb0d16f85d64959ece4d247dd8cf1c" translate="yes" xml:space="preserve">
          <source>Typically, different numerical approximations can be used for the log survival function, which are more accurate than &lt;code&gt;1 - cdf(x)&lt;/code&gt; when &lt;code&gt;x &amp;gt;&amp;gt; 1&lt;/code&gt;.</source>
          <target state="translated">일반적으로, 로그 생존 함수에 대해 서로 다른 숫자 근사를 사용할 수 있으며 &lt;code&gt;x &amp;gt;&amp;gt; 1&lt;/code&gt; 때 &lt;code&gt;1 - cdf(x)&lt;/code&gt; 보다 더 정확 합니다.</target>
        </trans-unit>
        <trans-unit id="dc11d475cf6eeccc4ccad2799b660daf47f6e97d" translate="yes" xml:space="preserve">
          <source>Typically, this is used for contiguous ranges of integer indexes, but it doesn't have to be. This might be inefficient, however, if many of IDs are unused. Consider &lt;code&gt;categorical_column_with_hash_bucket&lt;/code&gt; in that case.</source>
          <target state="translated">일반적으로 이것은 연속적인 정수 인덱스 범위에 사용되지만 반드시 그럴 필요는 없습니다. 그러나 많은 ID를 사용하지 않는 경우 비효율적 일 수 있습니다. 이 경우 &lt;code&gt;categorical_column_with_hash_bucket&lt;/code&gt; 을 고려하십시오 .</target>
        </trans-unit>
        <trans-unit id="642d93bf7af9445a97651535e05ec594d4e074d2" translate="yes" xml:space="preserve">
          <source>Typically, this method directly controls &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;../model#predict_step&quot;&gt;&lt;code&gt;Model.predict_step&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Typically, this method directly controls &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;../model#predict_step&quot;&gt; &lt;code&gt;Model.predict_step&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="e09b882e09baa741494589bf82363a386761e573" translate="yes" xml:space="preserve">
          <source>Typically, this method directly controls &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;../model#test_step&quot;&gt;&lt;code&gt;Model.test_step&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Typically, this method directly controls &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;../model#test_step&quot;&gt; &lt;code&gt;Model.test_step&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="b89bd069f03bea0bc8a7420d63726498425c37ea" translate="yes" xml:space="preserve">
          <source>Typically, this method directly controls &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; settings, and delegates the actual training logic to &lt;a href=&quot;../model#train_step&quot;&gt;&lt;code&gt;Model.train_step&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Typically, this method directly controls &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; settings, and delegates the actual training logic to &lt;a href=&quot;../model#train_step&quot;&gt; &lt;code&gt;Model.train_step&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="6a9ed424e025572fe99563e115ac58ef9f0eecef" translate="yes" xml:space="preserve">
          <source>Typically, this method directly controls &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;model#predict_step&quot;&gt;&lt;code&gt;Model.predict_step&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Typically, this method directly controls &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;model#predict_step&quot;&gt; &lt;code&gt;Model.predict_step&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="88e682fbb9f04bb6f808d62f5cfd3cba250f9355" translate="yes" xml:space="preserve">
          <source>Typically, this method directly controls &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;model#test_step&quot;&gt;&lt;code&gt;Model.test_step&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Typically, this method directly controls &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; settings, and delegates the actual evaluation logic to &lt;a href=&quot;model#test_step&quot;&gt; &lt;code&gt;Model.test_step&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="39425f208b695839de1ae797673c90196ac3923f" translate="yes" xml:space="preserve">
          <source>Typically, this method directly controls &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; settings, and delegates the actual training logic to &lt;a href=&quot;model#train_step&quot;&gt;&lt;code&gt;Model.train_step&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Typically, this method directly controls &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; settings, and delegates the actual training logic to &lt;a href=&quot;model#train_step&quot;&gt; &lt;code&gt;Model.train_step&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="4872edff50fbbe6a9f917cabaf4b95b3b51cfbf5" translate="yes" xml:space="preserve">
          <source>UUID of function that this tracks arguments for.</source>
          <target state="translated">UUID of function that this tracks arguments for.</target>
        </trans-unit>
        <trans-unit id="028563b1e54555afd3216dd205c2179bff62edca" translate="yes" xml:space="preserve">
          <source>Unbatch</source>
          <target state="translated">Unbatch</target>
        </trans-unit>
        <trans-unit id="18de537cd188f9aa6703c0bcca0bdd3aa030d834" translate="yes" xml:space="preserve">
          <source>UnbatchDataset</source>
          <target state="translated">UnbatchDataset</target>
        </trans-unit>
        <trans-unit id="282c6a33f97fdaf72f77ce51ca56ef49ffc77747" translate="yes" xml:space="preserve">
          <source>UnbatchGrad</source>
          <target state="translated">UnbatchGrad</target>
        </trans-unit>
        <trans-unit id="0ed10c799418646f55b928fd78fe57ac0388bf1c" translate="yes" xml:space="preserve">
          <source>UncompressElement</source>
          <target state="translated">UncompressElement</target>
        </trans-unit>
        <trans-unit id="4b7dbe0386bf95cabb32b5ed231c8f56aae99b96" translate="yes" xml:space="preserve">
          <source>Uncompresses a compressed dataset element.</source>
          <target state="translated">Uncompresses a compressed dataset element.</target>
        </trans-unit>
        <trans-unit id="315f69cd0de49a2c6013b3acdede0a3586eb743f" translate="yes" xml:space="preserve">
          <source>Under &lt;code&gt;TPUStrategy&lt;/code&gt;, we allow access to the method &lt;code&gt;enqueue&lt;/code&gt;, &lt;code&gt;dequeue&lt;/code&gt; and &lt;code&gt;apply_gradients&lt;/code&gt;. We will show examples below of how to use these to train and evaluate your model. Under CPU, we only access to the &lt;code&gt;embedding_tables&lt;/code&gt; property which allow access to the embedding tables so that you can use them to run model evaluation/prediction on CPU.</source>
          <target state="translated">Under &lt;code&gt;TPUStrategy&lt;/code&gt; , we allow access to the method &lt;code&gt;enqueue&lt;/code&gt; , &lt;code&gt;dequeue&lt;/code&gt; and &lt;code&gt;apply_gradients&lt;/code&gt; . We will show examples below of how to use these to train and evaluate your model. Under CPU, we only access to the &lt;code&gt;embedding_tables&lt;/code&gt; property which allow access to the embedding tables so that you can use them to run model evaluation/prediction on CPU.</target>
        </trans-unit>
        <trans-unit id="e3e018efacc4788ac4991e79f9e0eac32efd113e" translate="yes" xml:space="preserve">
          <source>Under a scope &lt;code&gt;with custom_object_scope(objects_dict)&lt;/code&gt;, Keras methods such as &lt;a href=&quot;../models/load_model&quot;&gt;&lt;code&gt;tf.keras.models.load_model&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../models/model_from_config&quot;&gt;&lt;code&gt;tf.keras.models.model_from_config&lt;/code&gt;&lt;/a&gt; will be able to deserialize any custom object referenced by a saved config (e.g. a custom layer or metric).</source>
          <target state="translated">Under a scope &lt;code&gt;with custom_object_scope(objects_dict)&lt;/code&gt; , Keras methods such as &lt;a href=&quot;../models/load_model&quot;&gt; &lt;code&gt;tf.keras.models.load_model&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;../models/model_from_config&quot;&gt; &lt;code&gt;tf.keras.models.model_from_config&lt;/code&gt; &lt;/a&gt; will be able to deserialize any custom object referenced by a saved config (e.g. a custom layer or metric).</target>
        </trans-unit>
        <trans-unit id="505df01a0bd35a5e05151b2e08abe84fb66596dc" translate="yes" xml:space="preserve">
          <source>Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units: &lt;a href=&quot;http://proceedings.mlr.press/v48/shang16&quot;&gt;Shang et al., 2016&lt;/a&gt; (&lt;a href=&quot;http://proceedings.mlr.press/v48/shang16.pdf&quot;&gt;pdf&lt;/a&gt;)</source>
          <target state="translated">Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units: &lt;a href=&quot;http://proceedings.mlr.press/v48/shang16&quot;&gt;Shang et al., 2016&lt;/a&gt; (&lt;a href=&quot;http://proceedings.mlr.press/v48/shang16.pdf&quot;&gt;pdf&lt;/a&gt;)</target>
        </trans-unit>
        <trans-unit id="1f2505b6c39bb7db973660c096d38f1739c74197" translate="yes" xml:space="preserve">
          <source>Undoes all SmartSet() &amp;amp; Set() calls, restoring original definitions.</source>
          <target state="translated">모든 SmartSet () 및 Set () 호출을 취소하고 원래 정의를 복원합니다.</target>
        </trans-unit>
        <trans-unit id="1956e966c40ea031fb68e7fe6e402465c17b477c" translate="yes" xml:space="preserve">
          <source>Unicode encoding that should be used to encode each codepoint sequence. Can be &lt;code&gt;&quot;UTF-8&quot;&lt;/code&gt;, &lt;code&gt;&quot;UTF-16-BE&quot;&lt;/code&gt;, or &lt;code&gt;&quot;UTF-32-BE&quot;&lt;/code&gt;.</source>
          <target state="translated">Unicode encoding that should be used to encode each codepoint sequence. Can be &lt;code&gt;&quot;UTF-8&quot;&lt;/code&gt; , &lt;code&gt;&quot;UTF-16-BE&quot;&lt;/code&gt; , or &lt;code&gt;&quot;UTF-32-BE&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="90ac7bb3b01b32e952ee295aa92163d24d25615d" translate="yes" xml:space="preserve">
          <source>Unicode strings</source>
          <target state="translated">유니 코드 문자열</target>
        </trans-unit>
        <trans-unit id="5e0684d6d7d272631c8bbe44f41cfa3f5076b1d4" translate="yes" xml:space="preserve">
          <source>UnicodeDecode</source>
          <target state="translated">UnicodeDecode</target>
        </trans-unit>
        <trans-unit id="d7d59980b4ae5cf39a350faf2c470f5fc69d74d8" translate="yes" xml:space="preserve">
          <source>UnicodeDecodeWithOffsets</source>
          <target state="translated">UnicodeDecodeWithOffsets</target>
        </trans-unit>
        <trans-unit id="05ae41cc8fec2efee56c1fd3fc455b9ee887c661" translate="yes" xml:space="preserve">
          <source>UnicodeEncode</source>
          <target state="translated">UnicodeEncode</target>
        </trans-unit>
        <trans-unit id="d48a266454de5c99b64f1535df01a2aa732eb493" translate="yes" xml:space="preserve">
          <source>UnicodeScript</source>
          <target state="translated">UnicodeScript</target>
        </trans-unit>
        <trans-unit id="c03f6044710be2f868218b1b8ef3d1a0cb70d8e9" translate="yes" xml:space="preserve">
          <source>UnicodeTranscode</source>
          <target state="translated">UnicodeTranscode</target>
        </trans-unit>
        <trans-unit id="976c215ff49db1df66b6e17319495979c35769ef" translate="yes" xml:space="preserve">
          <source>Uniform Inner Dimensions</source>
          <target state="translated">균일 한 내부 치수</target>
        </trans-unit>
        <trans-unit id="8560175804cd279f78f66d9a95299a6ca618dbfc" translate="yes" xml:space="preserve">
          <source>Uniform Outer Dimensions</source>
          <target state="translated">균일 한 외형 치수</target>
        </trans-unit>
        <trans-unit id="877e52ac4e7248f2800c12c1d91696ac0ce4e843" translate="yes" xml:space="preserve">
          <source>Uniform and ragged outer dimensions may be interleaved, meaning that a tensor with any combination of ragged and uniform dimensions may be created. For example, a RaggedTensor &lt;code&gt;t4&lt;/code&gt; with shape &lt;code&gt;[3, None, 4, 8, None, 2]&lt;/code&gt; could be constructed as follows:</source>
          <target state="translated">균일하고 울퉁불퉁 한 외부 치수가 인터리브 될 수 있으며, 이는 울퉁불퉁하고 균일 한 치수의 임의의 조합을 갖는 텐서가 생성 될 수 있음을 의미한다. 예를 들어, 모양이 &lt;code&gt;[3, None, 4, 8, None, 2]&lt;/code&gt; RaggedTensor &lt;code&gt;t4&lt;/code&gt; 는 다음과 같이 구성 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9c91421a9e87411dcbfdcaf48e2c1f3430455339" translate="yes" xml:space="preserve">
          <source>Uniform dimensions are encoded using multidimensional numpy &lt;code&gt;array&lt;/code&gt;s. In the following example, the value returned by &lt;a href=&quot;raggedtensor#numpy&quot;&gt;&lt;code&gt;RaggedTensor.numpy()&lt;/code&gt;&lt;/a&gt; contains a single numpy &lt;code&gt;array&lt;/code&gt; object, with &lt;code&gt;rank=2&lt;/code&gt; and &lt;code&gt;dtype=int64&lt;/code&gt;:</source>
          <target state="translated">Uniform dimensions are encoded using multidimensional numpy &lt;code&gt;array&lt;/code&gt; s. In the following example, the value returned by &lt;a href=&quot;raggedtensor#numpy&quot;&gt; &lt;code&gt;RaggedTensor.numpy()&lt;/code&gt; &lt;/a&gt; contains a single numpy &lt;code&gt;array&lt;/code&gt; object, with &lt;code&gt;rank=2&lt;/code&gt; and &lt;code&gt;dtype=int64&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="f358f22f84035b210a806ebde2b7ba64470c6103" translate="yes" xml:space="preserve">
          <source>Uniform distribution on an integer type's entire range.</source>
          <target state="translated">정수 유형의 전체 범위에 대한 균일 분포.</target>
        </trans-unit>
        <trans-unit id="5a636a3f76b9605e2629209f45efcb9cace24843" translate="yes" xml:space="preserve">
          <source>Uniform distribution with &lt;code&gt;low&lt;/code&gt; and &lt;code&gt;high&lt;/code&gt; parameters.</source>
          <target state="translated">와 균일 한 분포 &lt;code&gt;low&lt;/code&gt; 및 &lt;code&gt;high&lt;/code&gt; 매개 변수.</target>
        </trans-unit>
        <trans-unit id="2408554486ca40a7df4bc74cb3619a293981c6a8" translate="yes" xml:space="preserve">
          <source>UniformCandidateSampler</source>
          <target state="translated">UniformCandidateSampler</target>
        </trans-unit>
        <trans-unit id="82b9b64659267074d1c1ba85abf6981423a4e4d2" translate="yes" xml:space="preserve">
          <source>UniformRowLength(length,)</source>
          <target state="translated">UniformRowLength(length,)</target>
        </trans-unit>
        <trans-unit id="338a58853d5b589d79285d729f26c7d598bf74eb" translate="yes" xml:space="preserve">
          <source>Union[Iterable[Enum], Iterable[Text], Enum, Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt;; only differences are documented here. If the value is a single Enum, it is treated as a single-item list of that Enum value. If it is an iterable, text values within the iterable will be converted to the equivalent Enum objects.</source>
          <target state="translated">Union[Iterable[Enum], Iterable[Text], Enum, Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt; ; only differences are documented here. If the value is a single Enum, it is treated as a single-item list of that Enum value. If it is an iterable, text values within the iterable will be converted to the equivalent Enum objects.</target>
        </trans-unit>
        <trans-unit id="04886f2c2934fa1074408cc7cc12b5f99af25706" translate="yes" xml:space="preserve">
          <source>Union[Iterable[T], Text, None], the default value of the flag. If the value is text, it will be parsed as if it was provided from the command line. If the value is a non-string iterable, it will be iterated over to create a shallow copy of the values. If it is None, it is left as-is.</source>
          <target state="translated">Union[Iterable[T], Text, None], the default value of the flag. If the value is text, it will be parsed as if it was provided from the command line. If the value is a non-string iterable, it will be iterated over to create a shallow copy of the values. If it is None, it is left as-is.</target>
        </trans-unit>
        <trans-unit id="737c59cf13411337a19af29f48783402b8ed06de" translate="yes" xml:space="preserve">
          <source>Union[Iterable[Text], Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt;.</source>
          <target state="translated">Union[Iterable[Text], Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6428fc2f5260465f511164c37261c5570e275cd5" translate="yes" xml:space="preserve">
          <source>Union[Iterable[float], Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt;.</source>
          <target state="translated">Union[Iterable[float], Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c19e99ab715ea5a714cc70c9ca1419999c89628b" translate="yes" xml:space="preserve">
          <source>Union[Iterable[int], Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt;.</source>
          <target state="translated">Union[Iterable[int], Text, None], the default value of the flag; see &lt;code&gt;DEFINE_multi&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="87c6f410754d2f5d42cbccc33576be0d5edc865c" translate="yes" xml:space="preserve">
          <source>Unique</source>
          <target state="translated">Unique</target>
        </trans-unit>
        <trans-unit id="0dd84a267eb06050e1d51577f84d2e5f9d140c27" translate="yes" xml:space="preserve">
          <source>Unique integer ID.</source>
          <target state="translated">고유 한 정수 ID</target>
        </trans-unit>
        <trans-unit id="b898bebda42c40e1bfed797240e3b6330402424d" translate="yes" xml:space="preserve">
          <source>UniqueDataset</source>
          <target state="translated">UniqueDataset</target>
        </trans-unit>
        <trans-unit id="936d3125f6165a80c34df14b2afdc4601cd8b763" translate="yes" xml:space="preserve">
          <source>UniqueV2</source>
          <target state="translated">UniqueV2</target>
        </trans-unit>
        <trans-unit id="6d7fb951e6346ddabc82f570397d0fd46ed74844" translate="yes" xml:space="preserve">
          <source>UniqueWithCounts</source>
          <target state="translated">UniqueWithCounts</target>
        </trans-unit>
        <trans-unit id="1c7a5d24b663759b635f7eb14541a1e553019f23" translate="yes" xml:space="preserve">
          <source>UniqueWithCountsV2</source>
          <target state="translated">UniqueWithCountsV2</target>
        </trans-unit>
        <trans-unit id="3716d64264f900396f1af7fc16d7b86fdf992a50" translate="yes" xml:space="preserve">
          <source>Unknown error.</source>
          <target state="translated">알수없는 오류.</target>
        </trans-unit>
        <trans-unit id="36714cf4410eee18e8f50df2ffea0a7fa2ac86eb" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../../data/dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt;. The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">Unlike &lt;a href=&quot;../../../../data/dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt; . The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</target>
        </trans-unit>
        <trans-unit id="9ecf9df1b9c446def763a4926348afbeccb07217" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../../data/dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">&lt;a href=&quot;../../../../data/dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt; 와 달리 배치 할 입력 요소의 모양은 다를 수 있으며이 변환은 각 구성 요소를 &lt;code&gt;padding_shapes&lt;/code&gt; 의 각 모양으로 채 웁니다 . &lt;code&gt;padding_shapes&lt;/code&gt; 의 인수는 출력 소자의 각 구성 요소의 각 차원 결과 형상을 결정</target>
        </trans-unit>
        <trans-unit id="576d359833afce4c0260f4d74f22330fd90213de" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../data/dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt;. The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">Unlike &lt;a href=&quot;../../../data/dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt; . The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</target>
        </trans-unit>
        <trans-unit id="cb9a4a5a4e9492ece2558573a0acc8a789ddc313" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../data/dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">&lt;a href=&quot;../../../data/dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt; 와 달리 배치 할 입력 요소의 모양은 다를 수 있으며이 변환은 각 구성 요소를 &lt;code&gt;padding_shapes&lt;/code&gt; 의 각 모양으로 채 웁니다 . &lt;code&gt;padding_shapes&lt;/code&gt; 의 인수는 출력 소자의 각 구성 요소의 각 차원 결과 형상을 결정</target>
        </trans-unit>
        <trans-unit id="e4abe35be36c6363497bfcbdede20ee0472e70d3" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;to_graph&lt;/code&gt; is a low-level transpiler that converts Python code to TensorFlow graph code. It does not implement any caching, variable management or create any actual ops, and is best used where greater control over the generated TensorFlow graph is desired. Another difference from &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; is that &lt;code&gt;to_graph&lt;/code&gt; will not wrap the graph into a TensorFlow function or a Python callable. Internally, &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; uses &lt;code&gt;to_graph&lt;/code&gt;.</source>
          <target state="translated">달리 &lt;a href=&quot;../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;to_graph&lt;/code&gt; 는 TensorFlow 그래프 코드 파이썬 코드 변환 저수준 transpiler이다. 캐싱, 변수 관리 또는 실제 ops를 구현하지 않으며 생성 된 TensorFlow 그래프를보다 강력하게 제어해야하는 경우에 가장 적합합니다. &lt;a href=&quot;../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; 의&lt;/a&gt; 또 다른 차이점은 to_graph 는 그래프를 TensorFlow 함수 또는 Python 호출 가능으로 랩핑하지 &lt;code&gt;to_graph&lt;/code&gt; 것입니다. 내부적으로 &lt;a href=&quot;../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; 은 to_graph를 사용 &lt;code&gt;to_graph&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c289f8aae64df7cd4ff7fdb8457061e6c012cdc6" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;wrap_function&lt;/code&gt; will only trace the Python function once. As with placeholders in TF 1.x, shapes and dtypes must be provided to &lt;code&gt;wrap_function&lt;/code&gt;'s &lt;code&gt;signature&lt;/code&gt; argument.</source>
          <target state="translated">달리 &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;wrap_function&lt;/code&gt; 는 한 번만 파이썬 기능을 추적합니다. TF 1.x의 플레이스 홀더와 마찬가지로 &lt;code&gt;wrap_function&lt;/code&gt; 의 &lt;code&gt;signature&lt;/code&gt; 인수에 모양 및 dtype을 제공해야합니다 .</target>
        </trans-unit>
        <trans-unit id="704bf993fd1f302cbdbbea9b08e8e2b996cf4dcb" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and each batch will be encoded as a &lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;. Example:</source>
          <target state="translated">&lt;a href=&quot;../dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt; 와 달리 배치 할 입력 요소의 모양은 다를 수 있으며 각 배치는 &lt;a href=&quot;../../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 로 인코딩됩니다 . 예:</target>
        </trans-unit>
        <trans-unit id="ab3fab341c82646fe8f085450f444bec807918c5" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt;. The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">Unlike &lt;a href=&quot;../dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt; . The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</target>
        </trans-unit>
        <trans-unit id="1ebb4bc2458197f2fb3172235869b74c91d350b2" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">&lt;a href=&quot;../dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt; 와 달리 배치 할 입력 요소의 모양은 다를 수 있으며이 변환은 각 구성 요소를 &lt;code&gt;padding_shapes&lt;/code&gt; 의 각 모양으로 채 웁니다 . &lt;code&gt;padding_shapes&lt;/code&gt; 의 인수는 출력 소자의 각 구성 요소의 각 차원 결과 형상을 결정</target>
        </trans-unit>
        <trans-unit id="0d34e57a1aa18be3c8484d7069cc1c8ad2db64a5" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes:</source>
          <target state="translated">Unlike &lt;a href=&quot;../dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt;, the input elements to be batched may have different shapes:</target>
        </trans-unit>
        <trans-unit id="69eb42951cde2b887407e0d83e6a95dc1668220b" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;to_graph&lt;/code&gt; is a low-level transpiler that converts Python code to TensorFlow graph code. It does not implement any caching, variable management or create any actual ops, and is best used where greater control over the generated TensorFlow graph is desired. Another difference from &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; is that &lt;code&gt;to_graph&lt;/code&gt; will not wrap the graph into a TensorFlow function or a Python callable. Internally, &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; uses &lt;code&gt;to_graph&lt;/code&gt;.</source>
          <target state="translated">달리 &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;to_graph&lt;/code&gt; 는 TensorFlow 그래프 코드 파이썬 코드 변환 저수준 transpiler이다. 캐싱, 변수 관리 또는 실제 ops를 구현하지 않으며 생성 된 TensorFlow 그래프를보다 강력하게 제어해야하는 경우에 가장 적합합니다. &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; 의&lt;/a&gt; 또 다른 차이점은 to_graph 는 그래프를 TensorFlow 함수 또는 Python 호출 가능으로 랩핑하지 &lt;code&gt;to_graph&lt;/code&gt; 것입니다. 내부적으로 &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; 은 to_graph를 사용 &lt;code&gt;to_graph&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="de7b7f502adc89ee96e98e3c06014fa1c272dc91" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt;. The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">Unlike &lt;a href=&quot;dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padded_shapes&lt;/code&gt; . The &lt;code&gt;padded_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</target>
        </trans-unit>
        <trans-unit id="dcde43ba32f97c1ff2549287396cb94e24747c3e" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="translated">&lt;a href=&quot;dataset#batch&quot;&gt; &lt;code&gt;tf.data.Dataset.batch&lt;/code&gt; &lt;/a&gt; 와 달리 배치 할 입력 요소의 모양은 다를 수 있으며이 변환은 각 구성 요소를 &lt;code&gt;padding_shapes&lt;/code&gt; 의 각 모양으로 채 웁니다 . &lt;code&gt;padding_shapes&lt;/code&gt; 의 인수는 출력 소자의 각 구성 요소의 각 차원 결과 형상을 결정</target>
        </trans-unit>
        <trans-unit id="e86a43f4e75dabc2059ed1937b3c30cb8a924b23" translate="yes" xml:space="preserve">
          <source>Unlike &lt;code&gt;SoftmaxCrossEntropyWithLogits&lt;/code&gt;, this operation does not accept a matrix of label probabilities, but rather a single label per row of features. This label is considered to have probability 1.0 for the given row.</source>
          <target state="translated">Unlike &lt;code&gt;SoftmaxCrossEntropyWithLogits&lt;/code&gt; , this operation does not accept a matrix of label probabilities, but rather a single label per row of features. This label is considered to have probability 1.0 for the given row.</target>
        </trans-unit>
        <trans-unit id="c42cd1138a7b09e8aab4b48a275bce9fecd055c5" translate="yes" xml:space="preserve">
          <source>Unlike &lt;code&gt;mean_squared_error&lt;/code&gt;, which is a measure of the differences between corresponding elements of &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;, &lt;code&gt;mean_pairwise_squared_error&lt;/code&gt; is a measure of the differences between pairs of corresponding elements of &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;.</source>
          <target state="translated">달리 &lt;code&gt;mean_squared_error&lt;/code&gt; 요소 대응하는 차이의 측정은, &lt;code&gt;predictions&lt;/code&gt; 및 &lt;code&gt;labels&lt;/code&gt; , &lt;code&gt;mean_pairwise_squared_error&lt;/code&gt; 는 요소의 대응하는 쌍들 사이의 차이의 측정은 &lt;code&gt;predictions&lt;/code&gt; 및 &lt;code&gt;labels&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="54b3e19f1658856fdd01905f7b1d827a5e2c7da2" translate="yes" xml:space="preserve">
          <source>Unlike &lt;code&gt;stack&lt;/code&gt;, &lt;code&gt;parallel_stack&lt;/code&gt; does NOT support backpropagation.</source>
          <target state="translated">&lt;code&gt;stack&lt;/code&gt; 과는 달리 , &lt;code&gt;parallel_stack&lt;/code&gt; 은 역 전파를 지원하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="3d3e8c9f8d19935be11b8a97738c865b48f3a40a" translate="yes" xml:space="preserve">
          <source>Unlike FractionalMaxPoolGrad, we don't need to find arg_max for FractionalAvgPoolGrad, we just need to evenly back-propagate each element of out_backprop to those indices that form the same pooling cell. Therefore, we just need to know the shape of original input tensor, instead of the whole tensor.</source>
          <target state="translated">Unlike FractionalMaxPoolGrad, we don't need to find arg_max for FractionalAvgPoolGrad, we just need to evenly back-propagate each element of out_backprop to those indices that form the same pooling cell. Therefore, we just need to know the shape of original input tensor, instead of the whole tensor.</target>
        </trans-unit>
        <trans-unit id="591f5490b4f3510f244c0007610068c1ceac25d0" translate="yes" xml:space="preserve">
          <source>Unlike MapDataset, the &lt;code&gt;f&lt;/code&gt; in FlatMapDataset is expected to return a Dataset variant, and FlatMapDataset will flatten successive results into a single Dataset.</source>
          <target state="translated">Unlike MapDataset, the &lt;code&gt;f&lt;/code&gt; in FlatMapDataset is expected to return a Dataset variant, and FlatMapDataset will flatten successive results into a single Dataset.</target>
        </trans-unit>
        <trans-unit id="c453e83691ce84ff295e7a2c1ef516446c3ab8d7" translate="yes" xml:space="preserve">
          <source>Unlike MapDataset, the &lt;code&gt;f&lt;/code&gt; in InterleaveDataset is expected to return a Dataset variant, and InterleaveDataset will flatten successive results into a single Dataset. Unlike FlatMapDataset, InterleaveDataset will interleave sequences of up to &lt;code&gt;block_length&lt;/code&gt; consecutive elements from &lt;code&gt;cycle_length&lt;/code&gt; input elements.</source>
          <target state="translated">Unlike MapDataset, the &lt;code&gt;f&lt;/code&gt; in InterleaveDataset is expected to return a Dataset variant, and InterleaveDataset will flatten successive results into a single Dataset. Unlike FlatMapDataset, InterleaveDataset will interleave sequences of up to &lt;code&gt;block_length&lt;/code&gt; consecutive elements from &lt;code&gt;cycle_length&lt;/code&gt; input elements.</target>
        </trans-unit>
        <trans-unit id="9c4c90486ba0091b8ea290c9a282ca7b97ffe78f" translate="yes" xml:space="preserve">
          <source>Unlike a &quot;MapDataset&quot;, which applies &lt;code&gt;f&lt;/code&gt; sequentially, this dataset invokes up to &lt;code&gt;batch_size * num_parallel_batches&lt;/code&gt; copies of &lt;code&gt;f&lt;/code&gt; in parallel.</source>
          <target state="translated">Unlike a &quot;MapDataset&quot;, which applies &lt;code&gt;f&lt;/code&gt; sequentially, this dataset invokes up to &lt;code&gt;batch_size * num_parallel_batches&lt;/code&gt; copies of &lt;code&gt;f&lt;/code&gt; in parallel.</target>
        </trans-unit>
        <trans-unit id="88b9771a4d40bd229bd2768494cd1206b15de019" translate="yes" xml:space="preserve">
          <source>Unlike a &quot;MapDataset&quot;, which applies &lt;code&gt;f&lt;/code&gt; sequentially, this dataset invokes up to &lt;code&gt;num_parallel_calls&lt;/code&gt; copies of &lt;code&gt;f&lt;/code&gt; in parallel.</source>
          <target state="translated">Unlike a &quot;MapDataset&quot;, which applies &lt;code&gt;f&lt;/code&gt; sequentially, this dataset invokes up to &lt;code&gt;num_parallel_calls&lt;/code&gt; copies of &lt;code&gt;f&lt;/code&gt; in parallel.</target>
        </trans-unit>
        <trans-unit id="13fc8fd7e6240efedf349e3dbe4446fea97e3c13" translate="yes" xml:space="preserve">
          <source>Unlike a TensorShape object, a TensorSpec object contains both shape and dtype information for a tensor. This method allows layers to provide output dtype information if it is different from the input dtype. For any layer that doesn't implement this function, the framework will fall back to use &lt;code&gt;compute_output_shape&lt;/code&gt;, and will assume that the output dtype matches the input dtype.</source>
          <target state="translated">TensorShape 객체와 달리 TensorSpec 객체에는 텐서의 모양 및 dtype 정보가 모두 포함되어 있습니다. 이 방법을 사용하면 입력 dtype과 다른 경우 레이어에서 출력 dtype 정보를 제공 할 수 있습니다. 이 함수를 구현하지 않는 계층의 경우 프레임 워크는 &lt;code&gt;compute_output_shape&lt;/code&gt; 를 사용하도록 폴백 하고 출력 dtype이 입력 dtype과 일치한다고 가정합니다.</target>
        </trans-unit>
        <trans-unit id="43b00e58be5bd1f34d6a3d43cebfb8995414356d" translate="yes" xml:space="preserve">
          <source>Unlike assertRaisesRegex, this method takes a literal string, not a regular expression.</source>
          <target state="translated">assertRaisesRegex와 달리이 메서드는 정규식이 아닌 리터럴 문자열을 사용합니다.</target>
        </trans-unit>
        <trans-unit id="b677c0df05da91282dc6309d244c4aedc109a5da" translate="yes" xml:space="preserve">
          <source>Unlike the Copy Op, this op has HostMemory constraint on its input or output.</source>
          <target state="translated">Unlike the Copy Op, this op has HostMemory constraint on its input or output.</target>
        </trans-unit>
        <trans-unit id="d5f7d3fe36850e7fa5811bed8af5b2d92d808d37" translate="yes" xml:space="preserve">
          <source>Unlike the CopyHost Op, this op does not have HostMemory constraint on its input or output.</source>
          <target state="translated">Unlike the CopyHost Op, this op does not have HostMemory constraint on its input or output.</target>
        </trans-unit>
        <trans-unit id="780bb9592c9dfb9fae30e2efc18623daa3e2cff4" translate="yes" xml:space="preserve">
          <source>Unlike the older op &lt;a href=&quot;compat/v1/squeeze&quot;&gt;&lt;code&gt;tf.compat.v1.squeeze&lt;/code&gt;&lt;/a&gt;, this op does not accept a deprecated &lt;code&gt;squeeze_dims&lt;/code&gt; argument.</source>
          <target state="translated">이전 op &lt;a href=&quot;compat/v1/squeeze&quot;&gt; &lt;code&gt;tf.compat.v1.squeeze&lt;/code&gt; &lt;/a&gt; 와 달리이 op는 더 이상 사용되지 않는 &lt;code&gt;squeeze_dims&lt;/code&gt; 인수를 허용하지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="33c0f5ca96c96a12269cd4ff95c4f773357fb44e" translate="yes" xml:space="preserve">
          <source>Unlike the original &lt;code&gt;accumulate_n&lt;/code&gt;, &lt;code&gt;accumulate_n_v2&lt;/code&gt; is differentiable.</source>
          <target state="translated">Unlike the original &lt;code&gt;accumulate_n&lt;/code&gt; , &lt;code&gt;accumulate_n_v2&lt;/code&gt; is differentiable.</target>
        </trans-unit>
        <trans-unit id="9828410fab6a8798616092f30a5aa2ae3611617b" translate="yes" xml:space="preserve">
          <source>Unordered dictionaries are not supported in eager mode when &lt;code&gt;exclusive=False&lt;/code&gt;. Use a list of tuples instead.</source>
          <target state="translated">&lt;code&gt;exclusive=False&lt;/code&gt; 인 경우 정렬되지 않은 사전은 열망 모드에서 지원되지 않습니다 . 대신 튜플 목록을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="e2231a91d542441b9a855a9095ab4fe46e316699" translate="yes" xml:space="preserve">
          <source>Unpack</source>
          <target state="translated">Unpack</target>
        </trans-unit>
        <trans-unit id="0657883ef20cc657b888740e46664440ff735ff1" translate="yes" xml:space="preserve">
          <source>Unpacking behavior for iterator-like inputs: A common pattern is to pass a tf.data.Dataset, generator, or tf.keras.utils.Sequence to the &lt;code&gt;x&lt;/code&gt; argument of fit, which will in fact yield not only features (x) but optionally targets (y) and sample weights. Keras requires that the output of such iterator-likes be unambiguous. The iterator should return a tuple of length 1, 2, or 3, where the optional second and third elements will be used for y and sample_weight respectively. Any other type provided will be wrapped in a length one tuple, effectively treating everything as 'x'. When yielding dicts, they should still adhere to the top-level tuple structure. e.g. &lt;code&gt;({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)&lt;/code&gt;. Keras will not attempt to separate features, targets, and weights from the keys of a single dict. A notable unsupported data type is the namedtuple. The reason is that it behaves like both an ordered datatype (tuple) and a mapping datatype (dict). So given a namedtuple of the form: &lt;code&gt;namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])&lt;/code&gt; it is ambiguous whether to reverse the order of the elements when interpreting the value. Even worse is a tuple of the form: &lt;code&gt;namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])&lt;/code&gt; where it is unclear if the tuple was intended to be unpacked into x, y, and sample_weight or passed through as a single element to &lt;code&gt;x&lt;/code&gt;. As a result the data processing code will simply raise a ValueError if it encounters a namedtuple. (Along with instructions to remedy the issue.)</source>
          <target state="translated">반복자와 같은 입력에 대한 압축 풀기 동작 : 일반적인 패턴은 tf.data.Dataset, generator 또는 tf.keras.utils.Sequence를 &lt;code&gt;x&lt;/code&gt; 의 적합 인수로 전달하는 것입니다. 이는 실제로 기능 (x)뿐만 아니라 임의로 표적 (y) 및 샘플 중량. Keras는 이러한 반복자 형식의 결과물이 명확해야합니다. 반복자는 길이 1, 2 또는 3의 튜플을 반환해야합니다. 여기서 선택적 두 번째 및 세 번째 요소는 각각 y 및 sample_weight에 사용됩니다. 제공된 다른 유형은 길이가 하나 인 튜플에 싸여 모든 것을 'x'로 효과적으로 처리합니다. 받아쓰기를 할 때 여전히 최상위 튜플 구조를 준수해야합니다. 예 : &lt;code&gt;({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)&lt;/code&gt; . Keras는 단일 dict의 키에서 기능, 대상 및 가중치를 분리하지 않습니다. 지원되지 않는 주목할만한 데이터 유형은 명명 된 튜플입니다. 그 이유는 순서가 지정된 데이터 유형 (튜플)과 매핑 데이터 유형 (dict) 모두처럼 작동하기 때문입니다. 따라서 &lt;code&gt;namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])&lt;/code&gt; 형식의 명명 된 튜플이 주어지면 값을 해석 할 때 요소의 순서를 바꿀지 모호합니다. : 심지어 악화 형태의 튜플 &lt;code&gt;namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])&lt;/code&gt; 튜플은 x, y 및 sample_weight이나 통과로 패킹되도록 의도 된 경우에 불분명 &lt;code&gt;x&lt;/code&gt; 에 단일 요소로. 결과적으로 데이터 처리 코드는 명명 된 튜플이 발생하면 단순히 ValueError를 발생시킵니다. (문제를 해결하기위한 지침과 함께)</target>
        </trans-unit>
        <trans-unit id="a70d7a46a185b9dd6d1158e08b8b8c0950e01eaa" translate="yes" xml:space="preserve">
          <source>Unpacks &lt;code&gt;num&lt;/code&gt; tensors from &lt;code&gt;value&lt;/code&gt; by chipping it along the &lt;code&gt;axis&lt;/code&gt; dimension. For example, given a tensor of shape &lt;code&gt;(A, B, C, D)&lt;/code&gt;;</source>
          <target state="translated">Unpacks &lt;code&gt;num&lt;/code&gt; tensors from &lt;code&gt;value&lt;/code&gt; by chipping it along the &lt;code&gt;axis&lt;/code&gt; dimension. For example, given a tensor of shape &lt;code&gt;(A, B, C, D)&lt;/code&gt; ;</target>
        </trans-unit>
        <trans-unit id="243ed91dcd10a0424df6d36deb350e6391df8548" translate="yes" xml:space="preserve">
          <source>Unpacks &lt;code&gt;num&lt;/code&gt; tensors from &lt;code&gt;value&lt;/code&gt; by chipping it along the &lt;code&gt;axis&lt;/code&gt; dimension. If &lt;code&gt;num&lt;/code&gt; is not specified (the default), it is inferred from &lt;code&gt;value&lt;/code&gt;'s shape. If &lt;code&gt;value.shape[axis]&lt;/code&gt; is not known, &lt;code&gt;ValueError&lt;/code&gt; is raised.</source>
          <target state="translated">압축이 &lt;code&gt;num&lt;/code&gt; 에서 텐서 &lt;code&gt;value&lt;/code&gt; 을 따라 치핑 의해 &lt;code&gt;axis&lt;/code&gt; 치수. 경우 &lt;code&gt;num&lt;/code&gt; (기본값)를 지정하지, 그것은로부터 추론되는 &lt;code&gt;value&lt;/code&gt; 의 형태. 경우 &lt;code&gt;value.shape[axis]&lt;/code&gt; 알려져 있지 않은, &lt;code&gt;ValueError&lt;/code&gt; 를가 상승한다.</target>
        </trans-unit>
        <trans-unit id="eb445a131ff25a35a36ff7e142e017c24f785cd1" translate="yes" xml:space="preserve">
          <source>Unpacks a given dimension of a rank-&lt;code&gt;R&lt;/code&gt; tensor into &lt;code&gt;num&lt;/code&gt; rank-&lt;code&gt;(R-1)&lt;/code&gt; tensors.</source>
          <target state="translated">Unpacks a given dimension of a rank- &lt;code&gt;R&lt;/code&gt; tensor into &lt;code&gt;num&lt;/code&gt; rank- &lt;code&gt;(R-1)&lt;/code&gt; tensors.</target>
        </trans-unit>
        <trans-unit id="48918b5563a8ceafb76129f6bc60ab73e49603cf" translate="yes" xml:space="preserve">
          <source>Unpacks the given dimension of a rank-&lt;code&gt;R&lt;/code&gt; tensor into rank-&lt;code&gt;(R-1)&lt;/code&gt; tensors.</source>
          <target state="translated">랭크 &lt;code&gt;R&lt;/code&gt; 텐서 의 주어진 치수 를 랭크- &lt;code&gt;(R-1)&lt;/code&gt; 텐서에 포장 을 풉니 다 .</target>
        </trans-unit>
        <trans-unit id="d65a83d865bb52fdcfa278aa190e57e05dce3f63" translate="yes" xml:space="preserve">
          <source>Unpacks user-provided data tuple.</source>
          <target state="translated">Unpacks user-provided data tuple.</target>
        </trans-unit>
        <trans-unit id="05dc9402d9793ff470926b16aca6821cb0999026" translate="yes" xml:space="preserve">
          <source>Unparses all flags to the point before any FLAGS(argv) was called.</source>
          <target state="translated">FLAGS (argv)가 호출되기 전에 모든 플래그를 해당 지점으로 구문 분석합니다.</target>
        </trans-unit>
        <trans-unit id="2c8018d2ec1edd743fc94f4ac501f4979aa67070" translate="yes" xml:space="preserve">
          <source>UnravelIndex</source>
          <target state="translated">UnravelIndex</target>
        </trans-unit>
        <trans-unit id="5abd8671c3b3e7c85742a7fbdf4fc8baadcb9032" translate="yes" xml:space="preserve">
          <source>UnrecognizedFlagError: if the referenced flag doesn't exist. DuplicateFlagError: if the alias name has been used by some existing flag.</source>
          <target state="translated">UnrecognizedFlagError: if the referenced flag doesn't exist. DuplicateFlagError: if the alias name has been used by some existing flag.</target>
        </trans-unit>
        <trans-unit id="d01190ad612aa7505976a06d2cc1e8836b163992" translate="yes" xml:space="preserve">
          <source>Unscaled log probabilities of shape &lt;code&gt;[d_0, d_1, ..., d_{r-1}, num_classes]&lt;/code&gt; and dtype &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt; or &lt;code&gt;float64&lt;/code&gt;.</source>
          <target state="translated">Unscaled log probabilities of shape &lt;code&gt;[d_0, d_1, ..., d_{r-1}, num_classes]&lt;/code&gt; and dtype &lt;code&gt;float16&lt;/code&gt; , &lt;code&gt;float32&lt;/code&gt; or &lt;code&gt;float64&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6b9238f8e545d4a2d2b6a4160c436067e5463ca7" translate="yes" xml:space="preserve">
          <source>Unscaled log probabilities of shape &lt;code&gt;[d_0, d_1, ..., d_{r-1}, num_classes]&lt;/code&gt; and dtype &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, or &lt;code&gt;float64&lt;/code&gt;.</source>
          <target state="translated">Unscaled log probabilities of shape &lt;code&gt;[d_0, d_1, ..., d_{r-1}, num_classes]&lt;/code&gt; and dtype &lt;code&gt;float16&lt;/code&gt; , &lt;code&gt;float32&lt;/code&gt; , or &lt;code&gt;float64&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6fd64ffd66a09162278b73ad3a2e108855905b4f" translate="yes" xml:space="preserve">
          <source>Unscaled log probabilities.</source>
          <target state="translated">Unscaled log probabilities.</target>
        </trans-unit>
        <trans-unit id="9e5da72ba27bb718f2dac7fc946f26f49a76ad43" translate="yes" xml:space="preserve">
          <source>Unscales the gradients by the loss scale.</source>
          <target state="translated">손실 스케일에 따라 그라디언트의 스케일을 해제합니다.</target>
        </trans-unit>
        <trans-unit id="9329b6002fc399b1c6e7eb106d68b0ce50955b52" translate="yes" xml:space="preserve">
          <source>UnsortedSegmentJoin</source>
          <target state="translated">UnsortedSegmentJoin</target>
        </trans-unit>
        <trans-unit id="0982334ce0fca73c3a5e3ea913a7e0313a459f82" translate="yes" xml:space="preserve">
          <source>UnsortedSegmentMax</source>
          <target state="translated">UnsortedSegmentMax</target>
        </trans-unit>
        <trans-unit id="366fa15ecb43d76a152b506219741a7b3f5f0bcd" translate="yes" xml:space="preserve">
          <source>UnsortedSegmentMin</source>
          <target state="translated">UnsortedSegmentMin</target>
        </trans-unit>
        <trans-unit id="6ef6286b2679e6c430cc36837f66e9730b079a8c" translate="yes" xml:space="preserve">
          <source>UnsortedSegmentProd</source>
          <target state="translated">UnsortedSegmentProd</target>
        </trans-unit>
        <trans-unit id="88334ca532d2e8466fab68a79d76f33ec76acf9a" translate="yes" xml:space="preserve">
          <source>UnsortedSegmentSum</source>
          <target state="translated">UnsortedSegmentSum</target>
        </trans-unit>
        <trans-unit id="c32922004f1cab6d2b368005f373dc639dc0003a" translate="yes" xml:space="preserve">
          <source>Unspecified run-time error.</source>
          <target state="translated">지정되지 않은 런타임 오류.</target>
        </trans-unit>
        <trans-unit id="b986cea6fdf9453b34548d5133226ff149db996f" translate="yes" xml:space="preserve">
          <source>Unstack the values of a &lt;code&gt;Tensor&lt;/code&gt; in the TensorArray.</source>
          <target state="translated">TensorArray에서 &lt;code&gt;Tensor&lt;/code&gt; 의 값을 언 스택하십시오 .</target>
        </trans-unit>
        <trans-unit id="7298d7ed988425fb6199864e49341c509f32d027" translate="yes" xml:space="preserve">
          <source>Unstage</source>
          <target state="translated">Unstage</target>
        </trans-unit>
        <trans-unit id="c5093a3d1578793a3f4e74f50d7ce016ac60ef3d" translate="yes" xml:space="preserve">
          <source>Untested. Very likely will not learn to output repeated classes.</source>
          <target state="translated">테스트되지 않았습니다. 반복되는 클래스를 출력하는 법을 배우지 못할 것입니다.</target>
        </trans-unit>
        <trans-unit id="5a0115166e5bef4246c231811f6b2ed301118eb7" translate="yes" xml:space="preserve">
          <source>Until the release of TF 2.0, we need the legacy behavior of &lt;code&gt;TensorShape&lt;/code&gt; to coexist with the new behavior. This utility is a bridge between the two.</source>
          <target state="translated">TF 2.0이 출시 될 때까지 새로운 동작과 공존하기 &lt;code&gt;TensorShape&lt;/code&gt; 의 레거시 동작이 필요합니다 . 이 유틸리티는 둘 사이의 다리입니다.</target>
        </trans-unit>
        <trans-unit id="f13be7738e1389f72c0f88aa84d17719f746bf4a" translate="yes" xml:space="preserve">
          <source>Unused.</source>
          <target state="translated">Unused.</target>
        </trans-unit>
        <trans-unit id="673367f4f1a26218e41caccf074dc2728214600f" translate="yes" xml:space="preserve">
          <source>UnwrapDatasetVariant</source>
          <target state="translated">UnwrapDatasetVariant</target>
        </trans-unit>
        <trans-unit id="45306172633156360fe411da89aad86bcba27d77" translate="yes" xml:space="preserve">
          <source>Unwrapping and merging: Consider calling a function &lt;code&gt;fn&lt;/code&gt; on multiple replicas, like &lt;code&gt;experimental_run_v2(fn, args=[w])&lt;/code&gt; with an argument &lt;code&gt;w&lt;/code&gt; that is a wrapped value. This means &lt;code&gt;w&lt;/code&gt; will have a map taking replica id &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;w0&lt;/code&gt;, replica id &lt;code&gt;11&lt;/code&gt; to &lt;code&gt;w1&lt;/code&gt;, etc. &lt;code&gt;experimental_run_v2()&lt;/code&gt; unwraps &lt;code&gt;w&lt;/code&gt; before calling &lt;code&gt;fn&lt;/code&gt;, so it calls &lt;code&gt;fn(w0)&lt;/code&gt; on &lt;code&gt;d0&lt;/code&gt;, &lt;code&gt;fn(w1)&lt;/code&gt; on &lt;code&gt;d1&lt;/code&gt;, etc. It then merges the return values from &lt;code&gt;fn()&lt;/code&gt;, which can possibly result in wrapped values. For example, let's say &lt;code&gt;fn()&lt;/code&gt; returns a tuple with three components: &lt;code&gt;(x, a, v0)&lt;/code&gt; from replica 0, &lt;code&gt;(x, b, v1)&lt;/code&gt; on replica 1, etc. If the first component is the same object &lt;code&gt;x&lt;/code&gt; from every replica, then the first component of the merged result will also be &lt;code&gt;x&lt;/code&gt;. If the second component is different (&lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, ...) from each replica, then the merged value will have a wrapped map from replica device to the different values. If the third component is the members of a mirrored variable (&lt;code&gt;v&lt;/code&gt; maps &lt;code&gt;d0&lt;/code&gt; to &lt;code&gt;v0&lt;/code&gt;, &lt;code&gt;d1&lt;/code&gt; to &lt;a href=&quot;../../v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt;, etc.), then the merged result will be that mirrored variable (&lt;code&gt;v&lt;/code&gt;).</source>
          <target state="translated">랩핑 해제 및 병합 : 랩핑 된 값인 인수 &lt;code&gt;w&lt;/code&gt; 를 사용하여 &lt;code&gt;experimental_run_v2(fn, args=[w])&lt;/code&gt; 와 같은 여러 복제본에서 함수 &lt;code&gt;fn&lt;/code&gt; 을 호출하는 것이 좋습니다. 이 수단 &lt;code&gt;w&lt;/code&gt; 지도 복제본 ID를 복용해야합니다 &lt;code&gt;0&lt;/code&gt; 으로 &lt;code&gt;w0&lt;/code&gt; , 복제 ID &lt;code&gt;11&lt;/code&gt; 에 &lt;code&gt;w1&lt;/code&gt; 등 &lt;code&gt;experimental_run_v2()&lt;/code&gt; 펼쳤다 &lt;code&gt;w&lt;/code&gt; 호출하기 전에 &lt;code&gt;fn&lt;/code&gt; 가 호출하므로, &lt;code&gt;fn(w0)&lt;/code&gt; 에 &lt;code&gt;d0&lt;/code&gt; , &lt;code&gt;fn(w1)&lt;/code&gt; 에 &lt;code&gt;d1&lt;/code&gt; 등 그런 다음 &lt;code&gt;fn()&lt;/code&gt; 의 반환 값을 병합합니다.래핑 된 값이 발생할 수 있습니다. 예를 들어, &lt;code&gt;fn()&lt;/code&gt; 은 &lt;code&gt;(x, a, v0)&lt;/code&gt; 0, &lt;code&gt;(x, b, v1)&lt;/code&gt; 복제본 0에서 (x, a, v0)의 세 구성 요소가있는 튜플을 반환 한다고 가정 합니다. 첫 번째 구성 요소가 모든 개체에서 동일한 객체 &lt;code&gt;x&lt;/code&gt; 인 경우 복제 된 경우 병합 된 결과의 첫 번째 구성 요소도 &lt;code&gt;x&lt;/code&gt; 입니다. 두 번째 구성 요소가 각 복제본과 다른 경우 ( &lt;code&gt;a&lt;/code&gt; , &lt;code&gt;b&lt;/code&gt; , ...) 병합 된 값은 복제본 장치에서 다른 값으로 랩핑 된 맵을 갖습니다. 세 번째 구성 요소가 미러링 된 변수의 구성원 인 경우 ( &lt;code&gt;v&lt;/code&gt; 는 &lt;code&gt;d0&lt;/code&gt; 을 &lt;code&gt;v0&lt;/code&gt; 에 , &lt;code&gt;d1&lt;/code&gt; 을 &lt;a href=&quot;../../v1&quot;&gt; &lt;code&gt;v1&lt;/code&gt; 에&lt;/a&gt; 맵핑합니다.등을 합치면 병합 된 결과는 미러링 된 변수 ( &lt;code&gt;v&lt;/code&gt; )가됩니다.</target>
        </trans-unit>
        <trans-unit id="452d19a44e1939a79c6b1e46110b7518ec2e32f4" translate="yes" xml:space="preserve">
          <source>Unwrapping and merging: Consider calling a function &lt;code&gt;fn&lt;/code&gt; on multiple replicas, like &lt;code&gt;experimental_run_v2(fn, args=[w])&lt;/code&gt; with an argument &lt;code&gt;w&lt;/code&gt; that is a wrapped value. This means &lt;code&gt;w&lt;/code&gt; will have a map taking replica id &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;w0&lt;/code&gt;, replica id &lt;code&gt;11&lt;/code&gt; to &lt;code&gt;w1&lt;/code&gt;, etc. &lt;code&gt;experimental_run_v2()&lt;/code&gt; unwraps &lt;code&gt;w&lt;/code&gt; before calling &lt;code&gt;fn&lt;/code&gt;, so it calls &lt;code&gt;fn(w0)&lt;/code&gt; on &lt;code&gt;d0&lt;/code&gt;, &lt;code&gt;fn(w1)&lt;/code&gt; on &lt;code&gt;d1&lt;/code&gt;, etc. It then merges the return values from &lt;code&gt;fn()&lt;/code&gt;, which can possibly result in wrapped values. For example, let's say &lt;code&gt;fn()&lt;/code&gt; returns a tuple with three components: &lt;code&gt;(x, a, v0)&lt;/code&gt; from replica 0, &lt;code&gt;(x, b, v1)&lt;/code&gt; on replica 1, etc. If the first component is the same object &lt;code&gt;x&lt;/code&gt; from every replica, then the first component of the merged result will also be &lt;code&gt;x&lt;/code&gt;. If the second component is different (&lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, ...) from each replica, then the merged value will have a wrapped map from replica device to the different values. If the third component is the members of a mirrored variable (&lt;code&gt;v&lt;/code&gt; maps &lt;code&gt;d0&lt;/code&gt; to &lt;code&gt;v0&lt;/code&gt;, &lt;code&gt;d1&lt;/code&gt; to &lt;a href=&quot;../compat/v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt;, etc.), then the merged result will be that mirrored variable (&lt;code&gt;v&lt;/code&gt;).</source>
          <target state="translated">랩핑 해제 및 병합 : 랩핑 된 값인 인수 &lt;code&gt;w&lt;/code&gt; 를 사용하여 &lt;code&gt;experimental_run_v2(fn, args=[w])&lt;/code&gt; 와 같은 여러 복제본에서 함수 &lt;code&gt;fn&lt;/code&gt; 을 호출하는 것이 좋습니다. 이 수단 &lt;code&gt;w&lt;/code&gt; 지도 복제본 ID를 복용해야합니다 &lt;code&gt;0&lt;/code&gt; 으로 &lt;code&gt;w0&lt;/code&gt; , 복제 ID &lt;code&gt;11&lt;/code&gt; 에 &lt;code&gt;w1&lt;/code&gt; 등 &lt;code&gt;experimental_run_v2()&lt;/code&gt; 펼쳤다 &lt;code&gt;w&lt;/code&gt; 호출하기 전에 &lt;code&gt;fn&lt;/code&gt; 가 호출하므로, &lt;code&gt;fn(w0)&lt;/code&gt; 에 &lt;code&gt;d0&lt;/code&gt; , &lt;code&gt;fn(w1)&lt;/code&gt; 에 &lt;code&gt;d1&lt;/code&gt; 등 그런 다음 &lt;code&gt;fn()&lt;/code&gt; 의 반환 값을 병합합니다.래핑 된 값이 발생할 수 있습니다. 예를 들어, &lt;code&gt;fn()&lt;/code&gt; 은 &lt;code&gt;(x, a, v0)&lt;/code&gt; 0, &lt;code&gt;(x, b, v1)&lt;/code&gt; 복제본 0에서 (x, a, v0)의 세 구성 요소가있는 튜플을 반환 한다고 가정 합니다. 첫 번째 구성 요소가 모든 개체에서 동일한 객체 &lt;code&gt;x&lt;/code&gt; 인 경우 복제 된 경우 병합 된 결과의 첫 번째 구성 요소도 &lt;code&gt;x&lt;/code&gt; 입니다. 두 번째 구성 요소가 각 복제본과 다른 경우 ( &lt;code&gt;a&lt;/code&gt; , &lt;code&gt;b&lt;/code&gt; , ...) 병합 된 값은 복제본 장치에서 다른 값으로 랩핑 된 맵을 갖습니다. 세 번째 구성 요소가 미러링 된 변수의 구성원 인 경우 ( &lt;code&gt;v&lt;/code&gt; 는 &lt;code&gt;d0&lt;/code&gt; 을 &lt;code&gt;v0&lt;/code&gt; 에 , &lt;code&gt;d1&lt;/code&gt; 을 &lt;a href=&quot;../compat/v1&quot;&gt; &lt;code&gt;v1&lt;/code&gt; 에&lt;/a&gt; 맵핑합니다.등을 합치면 병합 된 결과는 미러링 된 변수 ( &lt;code&gt;v&lt;/code&gt; )가됩니다.</target>
        </trans-unit>
        <trans-unit id="447e8380a0660bcbaf0b5a0132d4263bb7475a27" translate="yes" xml:space="preserve">
          <source>Unwraps an object into a list of TFDecorators and a final target.</source>
          <target state="translated">오브젝트를 TFDecorators 및 최종 대상 목록으로 랩핑 해제합니다.</target>
        </trans-unit>
        <trans-unit id="f84ad806586080c9477df4b9148217324f31d72e" translate="yes" xml:space="preserve">
          <source>Up-to-date gradients (i.e., time step at which gradient was computed is equal to the accumulator's time step) are added to the accumulator.</source>
          <target state="translated">최신 기울기 (즉, 기울기가 계산 된 시간 단계가 누산기의 시간 단계와 동일 함)가 누산기에 추가됩니다.</target>
        </trans-unit>
        <trans-unit id="82d0fcae0670e010a42fb65be9daf931bbfd317f" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the AdaMax algorithm.</source>
          <target state="translated">Update '*var' according to the AdaMax algorithm.</target>
        </trans-unit>
        <trans-unit id="e38d308cee1cac8d9c2edb27c5ab629ef7fac7d9" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the Adam algorithm.</source>
          <target state="translated">Update '*var' according to the Adam algorithm.</target>
        </trans-unit>
        <trans-unit id="1b43e05874006f2166053362d39efb24c1da40cb" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the AddSign update.</source>
          <target state="translated">Update '*var' according to the AddSign update.</target>
        </trans-unit>
        <trans-unit id="52d1d116ee95e78e3bbfd1ce841dc358b8929317" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the Ftrl-proximal scheme.</source>
          <target state="translated">Update '*var' according to the Ftrl-proximal scheme.</target>
        </trans-unit>
        <trans-unit id="471071d3477d079bfcbcf7383ae1d699f1fecd50" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the RMSProp algorithm.</source>
          <target state="translated">Update '*var' according to the RMSProp algorithm.</target>
        </trans-unit>
        <trans-unit id="ff81ee48686edeb07f152d5d3567bb2505faedfb" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the adadelta scheme.</source>
          <target state="translated">Update '*var' according to the adadelta scheme.</target>
        </trans-unit>
        <trans-unit id="5d5ebbbd0b1837c20103e258d32dcbcdda20ba7d" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the adagrad scheme.</source>
          <target state="translated">Update '*var' according to the adagrad scheme.</target>
        </trans-unit>
        <trans-unit id="868d113999a0543f3fad5d44d43245c1668a6d37" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the centered RMSProp algorithm.</source>
          <target state="translated">Update '*var' according to the centered RMSProp algorithm.</target>
        </trans-unit>
        <trans-unit id="e800b9c7484bc8710e98c151f2fff6a2fd5d03ac" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the momentum scheme.</source>
          <target state="translated">Update '*var' according to the momentum scheme.</target>
        </trans-unit>
        <trans-unit id="9d77d08a52fed9d23da57628bfa85afe8cc236bc" translate="yes" xml:space="preserve">
          <source>Update '*var' according to the proximal adagrad scheme.</source>
          <target state="translated">Update '*var' according to the proximal adagrad scheme.</target>
        </trans-unit>
        <trans-unit id="787674ac15a7f58c7a9bd7dc691b153215067ce5" translate="yes" xml:space="preserve">
          <source>Update '*var' as FOBOS algorithm with fixed learning rate.</source>
          <target state="translated">Update '*var' as FOBOS algorithm with fixed learning rate.</target>
        </trans-unit>
        <trans-unit id="abf5d76205f9777481707bb7900ee4d7f09321a8" translate="yes" xml:space="preserve">
          <source>Update '*var' by subtracting 'alpha' * 'delta' from it.</source>
          <target state="translated">Update '*var' by subtracting 'alpha' * 'delta' from it.</target>
        </trans-unit>
        <trans-unit id="9efdd46b9ea48522d76a8280bde64699fbd0f6a5" translate="yes" xml:space="preserve">
          <source>Update '&lt;em&gt;var' and '&lt;/em&gt;accum' according to FOBOS with Adagrad learning rate.</source>
          <target state="translated">Update '&lt;em&gt;var' and '&lt;/em&gt;accum' according to FOBOS with Adagrad learning rate.</target>
        </trans-unit>
        <trans-unit id="fe20dc33f34485fdead6adf9d07e849e8a936d69" translate="yes" xml:space="preserve">
          <source>Update 'ref' by adding 'value' to it.</source>
          <target state="translated">Update 'ref' by adding 'value' to it.</target>
        </trans-unit>
        <trans-unit id="c9257701af71d4f765da34dcd01e8df105b8aa44" translate="yes" xml:space="preserve">
          <source>Update 'ref' by assigning 'value' to it.</source>
          <target state="translated">Update 'ref' by assigning 'value' to it.</target>
        </trans-unit>
        <trans-unit id="29365e08f06cd2686f25f0d377b66ff5415b759c" translate="yes" xml:space="preserve">
          <source>Update 'ref' by subtracting 'value' from it.</source>
          <target state="translated">Update 'ref' by subtracting 'value' from it.</target>
        </trans-unit>
        <trans-unit id="6fe8e246cbfb66ec49e8326c839db8c07c5c7366" translate="yes" xml:space="preserve">
          <source>Update (</source>
          <target state="translated">업데이트 (</target>
        </trans-unit>
        <trans-unit id="6509bc67c069e61a7a1a3a68aa4391deff81b6d2" translate="yes" xml:space="preserve">
          <source>Update &lt;code&gt;ref&lt;/code&gt; by adding &lt;code&gt;value&lt;/code&gt; to it.</source>
          <target state="translated">&lt;code&gt;value&lt;/code&gt; 을 추가하여 &lt;code&gt;ref&lt;/code&gt; 을 업데이트 하십시오.</target>
        </trans-unit>
        <trans-unit id="05a75e8ad72ec7a17916b0418183b2ae49757686" translate="yes" xml:space="preserve">
          <source>Update &lt;code&gt;ref&lt;/code&gt; by assigning &lt;code&gt;value&lt;/code&gt; to it.</source>
          <target state="translated">&lt;code&gt;value&lt;/code&gt; 을 지정하여 &lt;code&gt;ref&lt;/code&gt; 을 업데이트 하십시오.</target>
        </trans-unit>
        <trans-unit id="0da9a4ecf7a09eb5b3d6a68070c44c71f746dcb9" translate="yes" xml:space="preserve">
          <source>Update &lt;code&gt;ref&lt;/code&gt; by subtracting &lt;code&gt;value&lt;/code&gt; from it.</source>
          <target state="translated">&lt;code&gt;value&lt;/code&gt; 을 빼서 &lt;code&gt;ref&lt;/code&gt; 를 업데이트 하십시오.</target>
        </trans-unit>
        <trans-unit id="04cf114f82db9c03d560972fce4e303ff3f2a1fd" translate="yes" xml:space="preserve">
          <source>Update entries in '&lt;em&gt;var' and '&lt;/em&gt;accum' according to the proximal adagrad scheme.</source>
          <target state="translated">Update entries in '&lt;em&gt;var' and '&lt;/em&gt;accum' according to the proximal adagrad scheme.</target>
        </trans-unit>
        <trans-unit id="8d6d9dee5acd7031de9e9744560f0e2f29a28a2c" translate="yes" xml:space="preserve">
          <source>Update op.</source>
          <target state="translated">op를 업데이트하십시오.</target>
        </trans-unit>
        <trans-unit id="447e87cca9a900913e2b362703c44b530d8ad36e" translate="yes" xml:space="preserve">
          <source>Update relevant entries in '*var' according to the Ftrl-proximal scheme.</source>
          <target state="translated">Update relevant entries in '*var' according to the Ftrl-proximal scheme.</target>
        </trans-unit>
        <trans-unit id="97803936ee3881b955dd554c9048e1fb8c7cee65" translate="yes" xml:space="preserve">
          <source>Update relevant entries in '&lt;em&gt;var' and '&lt;/em&gt;accum' according to the adagrad scheme.</source>
          <target state="translated">Update relevant entries in '&lt;em&gt;var' and '&lt;/em&gt;accum' according to the adagrad scheme.</target>
        </trans-unit>
        <trans-unit id="d6438974b08aca642d6bcdb677ce1d3cc168f6c3" translate="yes" xml:space="preserve">
          <source>Update relevant entries in '&lt;em&gt;var' and '&lt;/em&gt;accum' according to the momentum scheme.</source>
          <target state="translated">Update relevant entries in '&lt;em&gt;var' and '&lt;/em&gt;accum' according to the momentum scheme.</target>
        </trans-unit>
        <trans-unit id="3f3b6f8527ee9f9f2b48e9baa56537bfbb1fe75d" translate="yes" xml:space="preserve">
          <source>Update rule for parameter &lt;code&gt;w&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; when &lt;code&gt;momentum&lt;/code&gt; is 0:</source>
          <target state="translated">Update rule for parameter &lt;code&gt;w&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; when &lt;code&gt;momentum&lt;/code&gt; is 0:</target>
        </trans-unit>
        <trans-unit id="63b0c5665a5cecb00d89f2c99aeee6da821e96bf" translate="yes" xml:space="preserve">
          <source>Update rule when &lt;code&gt;momentum&lt;/code&gt; is larger than 0:</source>
          <target state="translated">Update rule when &lt;code&gt;momentum&lt;/code&gt; is larger than 0:</target>
        </trans-unit>
        <trans-unit id="d3f52bac13b63cbb6e97bf073a84b716bbe078b6" translate="yes" xml:space="preserve">
          <source>Update step:</source>
          <target state="translated">업데이트 단계 :</target>
        </trans-unit>
        <trans-unit id="a77038db17ca8f9cacdb34920018f09eddc93c47" translate="yes" xml:space="preserve">
          <source>Update the last triggered time and step number.</source>
          <target state="translated">마지막으로 트리거 된 시간과 단계 번호를 업데이트하십시오.</target>
        </trans-unit>
        <trans-unit id="d386d7ccaa88b6dedf1b5040c55b451c526442d6" translate="yes" xml:space="preserve">
          <source>Update the value of &lt;code&gt;x&lt;/code&gt; by adding &lt;code&gt;increment&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;increment&lt;/code&gt; al 을 추가하여 &lt;code&gt;x&lt;/code&gt; 값을 업데이트하십시오 .</target>
        </trans-unit>
        <trans-unit id="bbd7754fb14c25638e64d5d064bb72937445b6c4" translate="yes" xml:space="preserve">
          <source>Update the value of &lt;code&gt;x&lt;/code&gt; by subtracting &lt;code&gt;decrement&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;decrement&lt;/code&gt; 를 빼서 &lt;code&gt;x&lt;/code&gt; 값을 업데이트하십시오 .</target>
        </trans-unit>
        <trans-unit id="bdd024c3635252f3a95af60168a7a02c85468f31" translate="yes" xml:space="preserve">
          <source>Updated base class for optimizers.</source>
          <target state="translated">최적화 프로그램에 대한 기본 클래스가 업데이트되었습니다.</target>
        </trans-unit>
        <trans-unit id="f63d62e4ed45a361aebb6397e1fccc02f07b3ec2" translate="yes" xml:space="preserve">
          <source>Updates eval metrics. See &lt;code&gt;base_head.Head&lt;/code&gt; for details.</source>
          <target state="translated">평가 지표를 업데이트합니다. 자세한 내용은 &lt;code&gt;base_head.Head&lt;/code&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="25882cbb9d1b53825b652d00bf42872915dbaa9e" translate="yes" xml:space="preserve">
          <source>Updates internal vocabulary based on a list of sequences.</source>
          <target state="translated">시퀀스 목록을 기반으로 내부 어휘를 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="852460ee15870b6e90ad0684cbc07e2e2a1a46d1" translate="yes" xml:space="preserve">
          <source>Updates internal vocabulary based on a list of texts.</source>
          <target state="translated">텍스트 목록을 기반으로 내부 어휘를 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="bf38595a5f74f710192dab7d4c5a5b9f35f64f69" translate="yes" xml:space="preserve">
          <source>Updates loss scale based on if gradients are finite in current step.</source>
          <target state="translated">현재 단계에서 그라디언트가 유한한지에 따라 손실 규모를 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="3ff6b49a83b568897a31a71591847bcb981cfe8c" translate="yes" xml:space="preserve">
          <source>Updates metric objects and returns a &lt;code&gt;dict&lt;/code&gt; of the updated metrics.</source>
          <target state="translated">메트릭 개체를 업데이트 하고 업데이트 된 메트릭 의 &lt;code&gt;dict&lt;/code&gt; 를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="c1444a8720b007d3bc3efc14cd0416a718bdfe20" translate="yes" xml:space="preserve">
          <source>Updates specified rows 'i' with values 'v'.</source>
          <target state="translated">Updates specified rows 'i' with values 'v'.</target>
        </trans-unit>
        <trans-unit id="da9e8385ef1cee6fd5a3ef89050fbd2471b13c5e" translate="yes" xml:space="preserve">
          <source>Updates the accumulator with a new value for global_step.</source>
          <target state="translated">Updates the accumulator with a new value for global_step.</target>
        </trans-unit>
        <trans-unit id="04014643289292114c04f072ec1d42a7ffcf535f" translate="yes" xml:space="preserve">
          <source>Updates the content of the 'checkpoint' file. (deprecated)</source>
          <target state="translated">'검사 점'파일의 내용을 업데이트합니다. (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="e27ee7c5bc27400dd7ff516cc28fe06e87e352bf" translate="yes" xml:space="preserve">
          <source>Updates the method name(s) of the SavedModel stored in the given path.</source>
          <target state="translated">Updates the method name(s) of the SavedModel stored in the given path.</target>
        </trans-unit>
        <trans-unit id="114215d83f25c29dd880192b62cf9c4d735d8aca" translate="yes" xml:space="preserve">
          <source>Updates the progress bar.</source>
          <target state="translated">진행률 표시 줄을 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="f3aa5183ae2c5fffe19c95fc5154e5548921fe2d" translate="yes" xml:space="preserve">
          <source>Updates the shape of a tensor and checks at runtime that the shape holds.</source>
          <target state="translated">텐서의 모양을 업데이트하고 런타임에 모양이 유지되는지 확인합니다.</target>
        </trans-unit>
        <trans-unit id="d45fc3ae1d9fcc9b117583faaa29b9c68525b6d1" translate="yes" xml:space="preserve">
          <source>Updates the shape of this tensor.</source>
          <target state="translated">이 텐서의 모양을 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="f590327e9570d8c3a01e570e103d03bfc643e1c5" translate="yes" xml:space="preserve">
          <source>Updates the table to associates keys with values.</source>
          <target state="translated">Updates the table to associates keys with values.</target>
        </trans-unit>
        <trans-unit id="cfb5af8bff1bdbad2b00e834b01497c1e3817b80" translate="yes" xml:space="preserve">
          <source>Updates the tree ensemble by adding a layer to the last tree being grown</source>
          <target state="translated">Updates the tree ensemble by adding a layer to the last tree being grown</target>
        </trans-unit>
        <trans-unit id="e6834941215f45b3c876acacc8e8c580f1e32c40" translate="yes" xml:space="preserve">
          <source>Updates the tree ensemble by either adding a layer to the last tree being grown</source>
          <target state="translated">Updates the tree ensemble by either adding a layer to the last tree being grown</target>
        </trans-unit>
        <trans-unit id="dd283fb80513334be997d84fc1ce654a3740f2f1" translate="yes" xml:space="preserve">
          <source>Updates the value of the loss scale.</source>
          <target state="translated">손실 척도의 값을 업데이트합니다.</target>
        </trans-unit>
        <trans-unit id="56d5a06c3dd0023752b72f3ca770e1ae3effe80d" translate="yes" xml:space="preserve">
          <source>Updates this variable with the max of &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="translated">이 변수를 최대 &lt;a href=&quot;../../indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt; 및 자체로 업데이트 합니다.</target>
        </trans-unit>
        <trans-unit id="0b0e1aa88bedb98a31d52dc0db2aabdbdc628dd2" translate="yes" xml:space="preserve">
          <source>Updates this variable with the max of &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="translated">이 변수를 최대 &lt;a href=&quot;indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt; 및 자체로 업데이트 합니다.</target>
        </trans-unit>
        <trans-unit id="729d65b580f1272ed91207fc8a10aa3312f5c72c" translate="yes" xml:space="preserve">
          <source>Updates this variable with the min of &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="translated">최소 &lt;a href=&quot;../../indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt; 및 그 자체 로이 변수를 업데이트 합니다.</target>
        </trans-unit>
        <trans-unit id="ee9c6cf89fa6d5d3bc7214b300a7628504d2e372" translate="yes" xml:space="preserve">
          <source>Updates this variable with the min of &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="translated">최소 &lt;a href=&quot;indexedslices&quot;&gt; &lt;code&gt;tf.IndexedSlices&lt;/code&gt; &lt;/a&gt; 및 그 자체 로이 변수를 업데이트 합니다.</target>
        </trans-unit>
        <trans-unit id="b62b62db1c38cdd8d87bd06d704758f1b3977490" translate="yes" xml:space="preserve">
          <source>Updating and clearing custom objects using &lt;code&gt;custom_object_scope&lt;/code&gt; is preferred, but &lt;code&gt;get_custom_objects&lt;/code&gt; can be used to directly access &lt;code&gt;_GLOBAL_CUSTOM_OBJECTS&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;custom_object_scope&lt;/code&gt; 를 사용하여 사용자 정의 객체를 업데이트하고 지우는 것이 바람직하지만 &lt;code&gt;get_custom_objects&lt;/code&gt; 를 사용하여 &lt;code&gt;_GLOBAL_CUSTOM_OBJECTS&lt;/code&gt; 에 직접 액세스 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="cd72d1503f9d3fb82ce4c9572b6d9a18a62eb0ba" translate="yes" xml:space="preserve">
          <source>Updating and clearing custom objects using &lt;code&gt;custom_object_scope&lt;/code&gt; is preferred, but &lt;code&gt;get_custom_objects&lt;/code&gt; can be used to directly access the current collection of custom objects.</source>
          <target state="translated">Updating and clearing custom objects using &lt;code&gt;custom_object_scope&lt;/code&gt; is preferred, but &lt;code&gt;get_custom_objects&lt;/code&gt; can be used to directly access the current collection of custom objects.</target>
        </trans-unit>
        <trans-unit id="281cba0fb3149b6c3774ed01f37649638874e882" translate="yes" xml:space="preserve">
          <source>Upon a load, the subset of variables and assets supplied as part of the specific meta graph def, will be restored into the supplied session. The values of the variables though will correspond to the saved values from the first meta graph added to the SavedModel using &lt;code&gt;add_meta_graph_and_variables(...)&lt;/code&gt; in &lt;code&gt;builder.py&lt;/code&gt;.</source>
          <target state="translated">로드되면 특정 메타 그래프 정의의 일부로 제공된 변수 및 자산의 하위 세트가 제공된 세션으로 복원됩니다. 변수 값은 &lt;code&gt;builder.py&lt;/code&gt; 에서 &lt;code&gt;add_meta_graph_and_variables(...)&lt;/code&gt; 를 사용하여 SavedModel에 추가 된 첫 번째 메타 그래프의 저장된 값에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="363a67d86f68374ba8c4a4cfbabbae29d79775ae" translate="yes" xml:space="preserve">
          <source>Upon removal from the active set, a checkpoint will be preserved if it has been at least &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt; since the last preserved checkpoint. The default setting of &lt;code&gt;None&lt;/code&gt; does not preserve any checkpoints in this way.</source>
          <target state="translated">Upon removal from the active set, a checkpoint will be preserved if it has been at least &lt;code&gt;keep_checkpoint_every_n_hours&lt;/code&gt; since the last preserved checkpoint. The default setting of &lt;code&gt;None&lt;/code&gt; does not preserve any checkpoints in this way.</target>
        </trans-unit>
        <trans-unit id="3ceee3a3a486ed4178c6d9fbac07e5800c6e5b47" translate="yes" xml:space="preserve">
          <source>Upper bound on the number of partitions. Defaults to 1.</source>
          <target state="translated">Upper bound on the number of partitions. Defaults to 1.</target>
        </trans-unit>
        <trans-unit id="5e44dc51c175ff5c0db1e82d8dfe21d3d95479e8" translate="yes" xml:space="preserve">
          <source>Upper boundary of the output interval.</source>
          <target state="translated">출력 간격의 상한.</target>
        </trans-unit>
        <trans-unit id="19aecdfa7cdf02c6ca74a44e34017ebb74fcec55" translate="yes" xml:space="preserve">
          <source>UpperBound</source>
          <target state="translated">UpperBound</target>
        </trans-unit>
        <trans-unit id="c31d78903813b3bcaeecbae756ddce1af8f35bae" translate="yes" xml:space="preserve">
          <source>Upsampling layer for 1D inputs.</source>
          <target state="translated">1D 입력을위한 업 샘플링 레이어.</target>
        </trans-unit>
        <trans-unit id="7b0d1a97658971e96b3f9be123da52362174eefa" translate="yes" xml:space="preserve">
          <source>Upsampling layer for 2D inputs.</source>
          <target state="translated">2D 입력을위한 업 샘플링 레이어.</target>
        </trans-unit>
        <trans-unit id="d8e99e181057faa2a85bca621f7cd639c1901c16" translate="yes" xml:space="preserve">
          <source>Upsampling layer for 3D inputs.</source>
          <target state="translated">3D 입력을위한 업 샘플링 레이어.</target>
        </trans-unit>
        <trans-unit id="0bb18642b70b9f8a9c12ccf39487328f306b8e19" translate="yes" xml:space="preserve">
          <source>Usage</source>
          <target state="translated">Usage</target>
        </trans-unit>
        <trans-unit id="9629fc5be7eebf84f66a1a4fe14d7eee29fbc498" translate="yes" xml:space="preserve">
          <source>Usage Example:</source>
          <target state="translated">사용 예 :</target>
        </trans-unit>
        <trans-unit id="c697e1f98f6b38e0ebf986cdde5209243dc5a1fb" translate="yes" xml:space="preserve">
          <source>Usage example with &lt;a href=&quot;../mobilenet&quot;&gt;&lt;code&gt;applications.MobileNet&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Usage example with &lt;a href=&quot;../mobilenet&quot;&gt; &lt;code&gt;applications.MobileNet&lt;/code&gt; &lt;/a&gt;:</target>
        </trans-unit>
        <trans-unit id="7878482cb2d732b2ccb44cbc91378bf291581491" translate="yes" xml:space="preserve">
          <source>Usage example with &lt;a href=&quot;../strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Usage example with &lt;a href=&quot;../strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;:</target>
        </trans-unit>
        <trans-unit id="b925d1a88d8e7cc54989fe4e8d7270088645c5c3" translate="yes" xml:space="preserve">
          <source>Usage example with tf.distribute.Strategy:</source>
          <target state="translated">Usage example with tf.distribute.Strategy:</target>
        </trans-unit>
        <trans-unit id="fec43ce445f974147bd0eb223a50147e7fb7202d" translate="yes" xml:space="preserve">
          <source>Usage example:</source>
          <target state="translated">사용 예 :</target>
        </trans-unit>
        <trans-unit id="77817d0a0c43f5e8811381e684f28870ad0caaef" translate="yes" xml:space="preserve">
          <source>Usage in a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">&lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; 에서의 사용법 :</target>
        </trans-unit>
        <trans-unit id="801e743874a5f137b8515158c4ad1c682d3d5c9a" translate="yes" xml:space="preserve">
          <source>Usage in a functional model:</source>
          <target state="translated">Usage in a functional model:</target>
        </trans-unit>
        <trans-unit id="f55d9b06976fb1e7cdaee8fa9d5e54cd7e87ed03" translate="yes" xml:space="preserve">
          <source>Usage in custom training loops</source>
          <target state="translated">Usage in custom training loops</target>
        </trans-unit>
        <trans-unit id="f7229b161af4f523b13ed9ebb0ca67db64df129d" translate="yes" xml:space="preserve">
          <source>Usage with &lt;code&gt;compile()&lt;/code&gt; API:</source>
          <target state="translated">Usage with &lt;code&gt;compile()&lt;/code&gt; API:</target>
        </trans-unit>
        <trans-unit id="e990e47405f0ff9e5047d2be7faad8352983c3d7" translate="yes" xml:space="preserve">
          <source>Usage with a canned estimator:</source>
          <target state="translated">Usage with a canned estimator:</target>
        </trans-unit>
        <trans-unit id="b7f68eccfb39ab6d5044b1fe94d8202e173daf81" translate="yes" xml:space="preserve">
          <source>Usage with distribution strategy and custom training loop:</source>
          <target state="translated">배포 전략 및 사용자 지정 교육 루프와 함께 사용 :</target>
        </trans-unit>
        <trans-unit id="e394973fc15ca8e6a0ab7b5e15b6537c110fcd61" translate="yes" xml:space="preserve">
          <source>Usage with tf.keras API:</source>
          <target state="translated">tf.keras API와 함께 사용 :</target>
        </trans-unit>
        <trans-unit id="b672bfd407587ac4347c7d14f539f0167c943965" translate="yes" xml:space="preserve">
          <source>Usage with the &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; API:</source>
          <target state="translated">&lt;a href=&quot;../../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; API 와 함께 사용 :</target>
        </trans-unit>
        <trans-unit id="96ba7c58b31b72cda1421876078e636d93a95906" translate="yes" xml:space="preserve">
          <source>Usage with the &lt;code&gt;compile()&lt;/code&gt; API:</source>
          <target state="translated">Usage with the &lt;code&gt;compile()&lt;/code&gt; API:</target>
        </trans-unit>
        <trans-unit id="c3a64fc9df2f2b5aa9b2b0f2f696a9fa962d415a" translate="yes" xml:space="preserve">
          <source>Usage with the &lt;code&gt;compile&lt;/code&gt; API:</source>
          <target state="translated">&lt;code&gt;compile&lt;/code&gt; API를 사용한 사용법 :</target>
        </trans-unit>
        <trans-unit id="861a0e430ffac5e4ae6e11b7a947f2c32d388cf4" translate="yes" xml:space="preserve">
          <source>Usage:</source>
          <target state="translated">Usage:</target>
        </trans-unit>
        <trans-unit id="030e432f7e4bb780778d21710d19d27e9dde09e7" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;../keras/models/load_model&quot;&gt;&lt;code&gt;tf.keras.models.load_model&lt;/code&gt;&lt;/a&gt; to restore the Keras model.</source>
          <target state="translated">&lt;a href=&quot;../keras/models/load_model&quot;&gt; &lt;code&gt;tf.keras.models.load_model&lt;/code&gt; &lt;/a&gt; 모델을 복원 하려면 tf.keras.models.load_model 을 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="d4c2fa90899bd40eef81dcc968f1e443a9a43ef7" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;global_variables&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt;&lt;/a&gt; instead. (deprecated)</source>
          <target state="translated">대신 &lt;a href=&quot;global_variables&quot;&gt; &lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt; &lt;/a&gt; 를 사용하십시오 . (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="3209823decab9f9b116ef0a97be20eccaaae6362" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;strategy#experimental_distribute_dataset&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset&lt;/code&gt;&lt;/a&gt; to convert a &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; to something that produces &quot;per-replica&quot; values. If you want to manually specify how the dataset should be partitioned across replicas, use &lt;a href=&quot;strategy#experimental_distribute_datasets_from_function&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_datasets_from_function&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">&lt;a href=&quot;strategy#experimental_distribute_dataset&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset&lt;/code&gt; &lt;/a&gt; 을 사용 하여 &lt;a href=&quot;../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; 을 &quot;복제 본당 &quot;값을 생성하는 것으로 변환 하십시오 . 복제본간에 데이터 세트를 분할하는 방법을 수동으로 지정하려면 대신 &lt;a href=&quot;strategy#experimental_distribute_datasets_from_function&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_distribute_datasets_from_function&lt;/code&gt; 을&lt;/a&gt; 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="8ee5b2fdcd82632d020da9ff566a06840585c6ea" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;strategy#experimental_run_v2&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt;&lt;/a&gt; to run a function once per replica, taking values that may be &quot;per-replica&quot; (e.g. from a distributed dataset) and returning &quot;per-replica&quot; values. This function is executed in &quot;replica context&quot;, which means each operation is performed separately on each replica.</source>
          <target state="translated">&lt;a href=&quot;strategy#experimental_run_v2&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt; &lt;/a&gt; 를 사용 하여 &quot;복제 본당 &quot;값 (예 : 분산 데이터 세트) 값을 가져 와서 &quot;복제 본당 &quot;값을 반환 하여 복제 본당 한 번 함수를 실행 하십시오 . 이 기능은 &quot;복제본 컨텍스트&quot;에서 실행됩니다. 즉, 각 복제본에서 각 작업이 개별적으로 수행됩니다.</target>
        </trans-unit>
        <trans-unit id="d62a49dd6dc46f4c7a9acf5f4db7938f8cbc782e" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;strategy#run&quot;&gt;&lt;code&gt;tf.distribute.Strategy.run&lt;/code&gt;&lt;/a&gt; to run a function once per replica, taking values that may be &quot;per-replica&quot; (e.g. from a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; object) and returning &quot;per-replica&quot; values. This function is executed in &quot;replica context&quot;, which means each operation is performed separately on each replica.</source>
          <target state="translated">Use &lt;a href=&quot;strategy#run&quot;&gt; &lt;code&gt;tf.distribute.Strategy.run&lt;/code&gt; &lt;/a&gt; to run a function once per replica, taking values that may be &quot;per-replica&quot; (e.g. from a &lt;a href=&quot;distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt; object) and returning &quot;per-replica&quot; values. This function is executed in &quot;replica context&quot;, which means each operation is performed separately on each replica.</target>
        </trans-unit>
        <trans-unit id="b44531c2feeada9ccb9c2de903665876111434ff" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;__floordiv__&lt;/code&gt; via &lt;code&gt;x // y&lt;/code&gt; instead.</source>
          <target state="translated">대신 &lt;code&gt;x // y&lt;/code&gt; 를 통해 &lt;code&gt;__floordiv__&lt;/code&gt; 를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="2767ed64c3817a4622daa8e917be1f662fce734c" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;as_numpy_iterator&lt;/code&gt; to inspect the content of your dataset. To see element shapes and types, print dataset elements directly instead of using &lt;code&gt;as_numpy_iterator&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;as_numpy_iterator&lt;/code&gt; 를 사용 하여 데이터 세트의 내용을 검사하십시오. 요소 모양과 유형을 보려면 &lt;code&gt;as_numpy_iterator&lt;/code&gt; 대신 데이터 세트 요소를 직접 인쇄 하십시오 .</target>
        </trans-unit>
        <trans-unit id="e94740ffc34912a09c1d4271d0d2a19f29965942" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;distribution&lt;/code&gt; to create a linear combination of &lt;code&gt;value&lt;/code&gt; with shape &lt;code&gt;[batch_size, Tq, dim]&lt;/code&gt;: &lt;code&gt;return tf.matmul(distribution, value)&lt;/code&gt;.</source>
          <target state="translated">Use &lt;code&gt;distribution&lt;/code&gt; to create a linear combination of &lt;code&gt;value&lt;/code&gt; with shape &lt;code&gt;[batch_size, Tq, dim]&lt;/code&gt; : &lt;code&gt;return tf.matmul(distribution, value)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5eb34124b3d3c72e61b1960b8b0273621cb17166" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;distribution&lt;/code&gt; to create a linear combination of &lt;code&gt;value&lt;/code&gt; with shape &lt;code&gt;batch_size, Tq, dim]&lt;/code&gt;: &lt;code&gt;return tf.matmul(distribution, value)&lt;/code&gt;.</source>
          <target state="translated">사용 &lt;code&gt;distribution&lt;/code&gt; 의 선형 조합 만드는 &lt;code&gt;value&lt;/code&gt; 형태로 &lt;code&gt;batch_size, Tq, dim]&lt;/code&gt; : &lt;code&gt;return tf.matmul(distribution, value)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="44e30be08758ea8ade80932cd95cdb8d64bb47a8" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;flat_map&lt;/code&gt; if you want to make sure that the order of your dataset stays the same. For example, to flatten a dataset of batches into a dataset of their elements:</source>
          <target state="translated">데이터 세트의 순서가 동일하게 유지되도록 하려면 &lt;code&gt;flat_map&lt;/code&gt; 을 사용하십시오. 예를 들어, 배치의 데이터 세트를 해당 요소의 데이터 세트로 병합하려면 다음을 수행하십시오.</target>
        </trans-unit>
        <trans-unit id="7a992c4c721de761461c5374c7bd3a4aff948363" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;get_slot_names()&lt;/code&gt; to get the list of slot names created by the &lt;code&gt;Optimizer&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;get_slot_names()&lt;/code&gt; 를 사용 하여 &lt;code&gt;Optimizer&lt;/code&gt; 가 작성한 슬롯 이름 목록을 가져 오십시오 .</target>
        </trans-unit>
        <trans-unit id="91f7ee28a1020db4d8680f6cfcc039630f6cf6c7" translate="yes" xml:space="preserve">
          <source>Use Keras-style variable management.</source>
          <target state="translated">Keras 스타일 변수 관리를 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="440e973c7f91d2791a9db2a23271859d554779a3" translate="yes" xml:space="preserve">
          <source>Use QuantizeAndDequantizeV2 instead.</source>
          <target state="translated">Use QuantizeAndDequantizeV2 instead.</target>
        </trans-unit>
        <trans-unit id="c72ad8c259b53b87feb4b811bfb9903790a506c0" translate="yes" xml:space="preserve">
          <source>Use RandomPoissonV2 instead.</source>
          <target state="translated">Use RandomPoissonV2 instead.</target>
        </trans-unit>
        <trans-unit id="2150f7b0818a8c9614aab9559af6a58afcb70753" translate="yes" xml:space="preserve">
          <source>Use VariableV2 instead.</source>
          <target state="translated">Use VariableV2 instead.</target>
        </trans-unit>
        <trans-unit id="9643c07a64899011c5e66444b786696c2c1f292c" translate="yes" xml:space="preserve">
          <source>Use a GPU</source>
          <target state="translated">GPU 사용</target>
        </trans-unit>
        <trans-unit id="0ef12200042309c3ec0320c88bb43b5872439b7c" translate="yes" xml:space="preserve">
          <source>Use a TPU</source>
          <target state="translated">TPU 사용</target>
        </trans-unit>
        <trans-unit id="55e615040b350f7d0e69b2efeab665769ae7dff0" translate="yes" xml:space="preserve">
          <source>Use cached_session instead. (deprecated)</source>
          <target state="translated">대신 cached_session을 사용하십시오. (더 이상 사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="a45a7fcfd0c3a826284614faab211360451f5baa" translate="yes" xml:space="preserve">
          <source>Use control flow v2.</source>
          <target state="translated">제어 흐름 v2를 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="370035f7e921eeac90f213974c56e368a0053937" translate="yes" xml:space="preserve">
          <source>Use for a single program</source>
          <target state="translated">단일 프로그램에 사용</target>
        </trans-unit>
        <trans-unit id="f43fa9092b2f91bd555938c5ea3e365d94b5e8be" translate="yes" xml:space="preserve">
          <source>Use for multiple replicas</source>
          <target state="translated">여러 복제본에 사용</target>
        </trans-unit>
        <trans-unit id="475c1ea44e2680d527418552a01d0d387b8889b0" translate="yes" xml:space="preserve">
          <source>Use is_tensor to differentiate types that can ingested by TensorFlow ops without any conversion (e.g., &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;) from types that need to be converted into tensors before they are ingested (e.g., numpy &lt;code&gt;ndarray&lt;/code&gt; and Python scalars).</source>
          <target state="translated">Use is_tensor to differentiate types that can ingested by TensorFlow ops without any conversion (e.g., &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt;, &lt;a href=&quot;sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.SparseTensor&lt;/code&gt; &lt;/a&gt;, and &lt;a href=&quot;raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt;) from types that need to be converted into tensors before they are ingested (e.g., numpy &lt;code&gt;ndarray&lt;/code&gt; and Python scalars).</target>
        </trans-unit>
        <trans-unit id="1492e12db8287cba745968988a12ad01c3a722bf" translate="yes" xml:space="preserve">
          <source>Use lazy Adam instead of Adam. Lazy Adam trains faster.</source>
          <target state="translated">Use lazy Adam instead of Adam. Lazy Adam trains faster.</target>
        </trans-unit>
        <trans-unit id="8bb5bf2a72112cde73c306a36e21803143fe65db" translate="yes" xml:space="preserve">
          <source>Use lazy Adam instead of Adam. Lazy Adam trains faster. Please see &lt;code&gt;optimization_parameters.proto&lt;/code&gt; for details.</source>
          <target state="translated">Use lazy Adam instead of Adam. Lazy Adam trains faster. Please see &lt;code&gt;optimization_parameters.proto&lt;/code&gt; for details.</target>
        </trans-unit>
        <trans-unit id="8399a93fbe608ceae7467ffa9f4443f49ecb43c5" translate="yes" xml:space="preserve">
          <source>Use regexes=[''] for a regex that will always pass.</source>
          <target state="translated">항상 통과 할 정규식에 대해 regexes = [ '']를 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="89fcdf03d75c5035154abf603c2a5d6a8e7923ee" translate="yes" xml:space="preserve">
          <source>Use scores to calculate a distribution with shape &lt;code&gt;[batch_size, Tq, Tv]&lt;/code&gt;: &lt;code&gt;distribution = tf.nn.softmax(scores)&lt;/code&gt;.</source>
          <target state="translated">점수를 사용하여 모양이 &lt;code&gt;[batch_size, Tq, Tv]&lt;/code&gt; 분포를 계산합니다 . &lt;code&gt;distribution = tf.nn.softmax(scores)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="434fa6ee48f96c719d58baf9d88af78b48a7c5de" translate="yes" xml:space="preserve">
          <source>Use the &lt;code&gt;use_gpu&lt;/code&gt; and &lt;code&gt;force_gpu&lt;/code&gt; options to control where ops are run. If &lt;code&gt;force_gpu&lt;/code&gt; is True, all ops are pinned to &lt;code&gt;/device:GPU:0&lt;/code&gt;. Otherwise, if &lt;code&gt;use_gpu&lt;/code&gt; is True, TensorFlow tries to run as many ops on the GPU as possible. If both &lt;code&gt;force_gpu and&lt;/code&gt;use_gpu` are False, all ops are pinned to the CPU.</source>
          <target state="translated">사용 &lt;code&gt;use_gpu&lt;/code&gt; 및 &lt;code&gt;force_gpu&lt;/code&gt; 작전이 실행 제어 옵션을. 경우 &lt;code&gt;force_gpu&lt;/code&gt; 은 True입니다, 모든 작전은 고정되어 &lt;code&gt;/device:GPU:0&lt;/code&gt; . 그렇지 않으면, &lt;code&gt;use_gpu&lt;/code&gt; 가 True 인 경우 , TensorFlow는 GPU에서 가능한 많은 연산을 실행하려고합니다. 두 경우 &lt;code&gt;force_gpu and&lt;/code&gt; use_gpu`은 거짓이며, 모든 작전은 CPU에 고정된다.</target>
        </trans-unit>
        <trans-unit id="af3eb58bfa11b2e816bf06bf154e9dd3eaba2e36" translate="yes" xml:space="preserve">
          <source>Use the adjoint of A in the matrix multiply. If A is complex, this is transpose(conj(A)). Otherwise it's transpose(A).</source>
          <target state="translated">Use the adjoint of A in the matrix multiply. If A is complex, this is transpose(conj(A)). Otherwise it's transpose(A).</target>
        </trans-unit>
        <trans-unit id="b81ee9831f55618dc71b894972452125c1c0e087" translate="yes" xml:space="preserve">
          <source>Use the adjoint of B in the matrix multiply. If B is complex, this is transpose(conj(B)). Otherwise it's transpose(B).</source>
          <target state="translated">Use the adjoint of B in the matrix multiply. If B is complex, this is transpose(conj(B)). Otherwise it's transpose(B).</target>
        </trans-unit>
        <trans-unit id="dd23d3f693402848b5c571179d734fa24d293240" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple enum values into the list.</source>
          <target state="translated">명령 행에서 플래그를 여러 번 사용하여 목록에 여러 열거 형 값을 배치하십시오.</target>
        </trans-unit>
        <trans-unit id="d2ec95228b5df088b9e12de695d7a5b48f073d13" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple enum values into the list. The 'default' may be a single string (which will be converted into a single-element list) or a list of strings.</source>
          <target state="translated">명령 행에서 플래그를 여러 번 사용하여 목록에 여러 열거 형 값을 배치하십시오. 'default'는 단일 문자열 (단일 요소 목록으로 변환 됨) 또는 문자열 목록 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7cd854f1deb653ced29c38efa8b46ec0bd203ec8" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple float values into the list. The 'default' may be a single float (which will be converted into a single-element list) or a list of floats.</source>
          <target state="translated">명령 행에서 플래그를 여러 번 사용하여 여러 부동 소수점 값을 목록에 배치하십시오. 'default'는 단일 float (단일 요소 목록으로 변환 됨) 또는 float 목록 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0ba777030d82e3febc7f170821e4862f2ace63cd" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple integer values into the list. The 'default' may be a single integer (which will be converted into a single-element list) or a list of integers.</source>
          <target state="translated">명령 행에서 플래그를 여러 번 사용하여 여러 정수 값을 목록에 배치하십시오. 'default'는 단일 정수 (단일 요소 목록으로 변환 됨) 또는 정수 목록 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b36c5e7734d6891179ff0616c0be42883b3178af" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple string values into the list. The 'default' may be a single string (which will be converted into a single-element list) or a list of strings.</source>
          <target state="translated">명령 행에서 플래그를 여러 번 사용하여 여러 문자열 값을 목록에 배치하십시오. 'default'는 단일 문자열 (단일 요소 목록으로 변환 됨) 또는 문자열 목록 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d3dd2345ae786232011837f1b50ba242eb1986f2" translate="yes" xml:space="preserve">
          <source>Use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). For each example, there should be a single floating-point value per prediction.</source>
          <target state="translated">두 개의 레이블 클래스 (0 및 1로 가정)가있을 때이 교차 엔트로피 손실을 사용하십시오. 각 예에서 예측 당 하나의 부동 소수점 값이 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="cea461fc9af427f5cd3544343b029f1c2bab9d0b" translate="yes" xml:space="preserve">
          <source>Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided as integers. If you want to provide labels using &lt;code&gt;one-hot&lt;/code&gt; representation, please use &lt;code&gt;CategoricalCrossentropy&lt;/code&gt; loss. There should be &lt;code&gt;# classes&lt;/code&gt; floating point values per feature for &lt;code&gt;y_pred&lt;/code&gt; and a single floating point value per feature for &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="translated">레이블 클래스가 둘 이상인 경우이 교차 엔트로피 손실 함수를 사용하십시오. 레이블이 정수로 제공 될 것으로 예상합니다. &lt;code&gt;one-hot&lt;/code&gt; 표현을 사용하여 레이블을 제공 하려면 &lt;code&gt;CategoricalCrossentropy&lt;/code&gt; loss 를 사용하십시오 . 이 있어야 &lt;code&gt;# classes&lt;/code&gt; 에 대한 기능에 따라 부동 소수점 값 &lt;code&gt;y_pred&lt;/code&gt; 및 대한 기능 당 하나의 부동 소수점 값 &lt;code&gt;y_true&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="78d33f54d7ac855026c26bfd507ca58a0c209d64" translate="yes" xml:space="preserve">
          <source>Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a &lt;code&gt;one_hot&lt;/code&gt; representation. If you want to provide labels as integers, please use &lt;code&gt;SparseCategoricalCrossentropy&lt;/code&gt; loss. There should be &lt;code&gt;# classes&lt;/code&gt; floating point values per feature.</source>
          <target state="translated">레이블 클래스가 둘 이상인 경우이 교차 엔트로피 손실 함수를 사용하십시오. 레이블은 &lt;code&gt;one_hot&lt;/code&gt; 표현 으로 제공 될 것으로 예상됩니다 . 레이블을 정수로 제공하려면 &lt;code&gt;SparseCategoricalCrossentropy&lt;/code&gt; loss 를 사용하십시오 . 기능 당 &lt;code&gt;# classes&lt;/code&gt; 부동 소수점 값 이 있어야 합니다.</target>
        </trans-unit>
        <trans-unit id="5c6c9c3f9fd66d91bb804a873975c909932a10ca" translate="yes" xml:space="preserve">
          <source>Use this crossentropy metric when there are two or more label classes. We expect labels to be provided as integers. If you want to provide labels using &lt;code&gt;one-hot&lt;/code&gt; representation, please use &lt;code&gt;CategoricalCrossentropy&lt;/code&gt; metric. There should be &lt;code&gt;# classes&lt;/code&gt; floating point values per feature for &lt;code&gt;y_pred&lt;/code&gt; and a single floating point value per feature for &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="translated">레이블 클래스가 둘 이상인 경우이 상호 엔트로피 메트릭을 사용하십시오. 레이블이 정수로 제공 될 것으로 예상합니다. &lt;code&gt;one-hot&lt;/code&gt; 표현을 사용하여 레이블을 제공 하려면 &lt;code&gt;CategoricalCrossentropy&lt;/code&gt; 메트릭을 사용하십시오 . 이 있어야 &lt;code&gt;# classes&lt;/code&gt; 에 대한 기능에 따라 부동 소수점 값 &lt;code&gt;y_pred&lt;/code&gt; 및 대한 기능 당 하나의 부동 소수점 값 &lt;code&gt;y_true&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2d8dc9e6eb45eed6afcf79258afbec19d798dabb" translate="yes" xml:space="preserve">
          <source>Use this function in place of &lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt;&lt;/a&gt; when you want to use the TPU to accelerate your embedding lookups via TPU embeddings.</source>
          <target state="translated">TPU를 사용하여 TPU 포함을 통해 포함 검색을 가속화하려는 경우 &lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt; &lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt; &lt;/a&gt; 대신이 기능 을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="3cc5d4e2629c110ebe8857052924d43b36a33d1a" translate="yes" xml:space="preserve">
          <source>Use this function in place of tf.compat.v1.feature_column.shared_embedding_columns` when you want to use the TPU to accelerate your embedding lookups via TPU embeddings.</source>
          <target state="translated">TPU를 사용하여 TPU 포함을 통해 포함 검색을 가속화하려는 경우 tf.compat.v1.feature_column.shared_embedding_columns 대신이 기능을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="e33c1dd0300e16f424a91617a667c9261bc9be4c" translate="yes" xml:space="preserve">
          <source>Use this function to prevent regularization of variables.</source>
          <target state="translated">변수의 정규화를 방지하려면이 기능을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="9622b2273be64542684f76f86eb661f385ac65c8" translate="yes" xml:space="preserve">
          <source>Use this function to wrap any op, maintaining its behavior in the forward pass, but replacing the original op in the backward graph with an identity. For example:</source>
          <target state="translated">이 기능을 사용하여 op를 래핑하고 순방향 패스에서 동작을 유지하면서 역방향 그래프의 원래 op를 ID로 바꿉니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="fe53876e652ed0ef4c2e62692c0a8476320563f1" translate="yes" xml:space="preserve">
          <source>Use this interface if you need to provide a custom loss/head. For example, the following will be equivalent to using BoostedTreesRegressor</source>
          <target state="translated">사용자 정의 손실 / 헤드를 제공해야하는 경우이 인터페이스를 사용하십시오. 예를 들어 다음은 BoostedTreesRegressor를 사용하는 것과 같습니다.</target>
        </trans-unit>
        <trans-unit id="1fc9a09a598f08be35c9b3e469cc86fb8ef5c5c8" translate="yes" xml:space="preserve">
          <source>Use this method with the &lt;code&gt;with&lt;/code&gt; keyword to specify that ops created within the scope of a block should be added to this graph. In this case, once the scope of the &lt;code&gt;with&lt;/code&gt; is exited, the previous default graph is set again as default. There is a stack, so it's ok to have multiple nested levels of &lt;code&gt;as_default&lt;/code&gt; calls.</source>
          <target state="translated">&lt;code&gt;with&lt;/code&gt; 키워드 와 함께이 방법을 사용 하여 블록 범위 내에서 작성된 op가이 그래프에 추가되도록 지정하십시오. 이 경우 &lt;code&gt;with&lt;/code&gt; 의 범위 가 종료되면 이전 기본 그래프가 다시 기본값으로 설정됩니다. 스택이 있으므로 여러 중첩 수준의 &lt;code&gt;as_default&lt;/code&gt; 호출을 사용하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="1cb0006ae0bc4a4d2c6cc55d9288fc8e40392087" translate="yes" xml:space="preserve">
          <source>Use this transformation to produce a dataset that contains one instance of each unique element in the input. For example:</source>
          <target state="translated">이 변환을 사용하여 입력에 각 고유 요소의 인스턴스 하나를 포함하는 데이터 세트를 생성하십시오. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="c1ae07580001407b54ea6c15a5ff62a49d8bc47c" translate="yes" xml:space="preserve">
          <source>Use this transformation to produce a dataset that contains the same elements as the input, but silently drops any elements that caused an error. For example:</source>
          <target state="translated">이 변환을 사용하여 입력과 동일한 요소를 포함하지만 오류를 일으킨 요소를 자동으로 삭제하는 데이터 세트를 생성하십시오. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="0ecb994c8af6ea20690f2149dd63292f77fb37b5" translate="yes" xml:space="preserve">
          <source>Use this when each of your sparse inputs has both an ID and a value. For example, if you're representing text documents as a collection of word frequencies, you can provide 2 parallel sparse input features ('terms' and 'frequencies' below).</source>
          <target state="translated">각 희소 입력에 ID와 값이 모두있는 경우이를 사용하십시오. 예를 들어, 텍스트 문서를 단어 빈도의 모음으로 표현하는 경우 2 개의 병렬 희소 입력 기능 (아래 '항'및 '주파수')을 제공 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="579c3daf1696275881a685fed877b2bca49537c7" translate="yes" xml:space="preserve">
          <source>Use this when the caller knows that this FlagValues has been parsed as if a &lt;strong&gt;call&lt;/strong&gt;() invocation has happened. This is only a public method for use by things like appcommands which do additional command like parsing.</source>
          <target state="translated">호출자가이 FlagValues가 &lt;strong&gt;호출&lt;/strong&gt; () 호출이 발생한 것처럼 구문 분석되었음을 알고있는 경우이를 사용하십시오 . 이것은 구문 분석과 같은 추가 명령을 수행하는 appcommand와 같은 것들에 의해 사용되는 공용 방법입니다.</target>
        </trans-unit>
        <trans-unit id="f2352dd0c45545d0dddd83edf7a87ae1c7d6a2a5" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are in string or integer format, and you have a vocabulary file that maps each value to an integer ID. By default, out-of-vocabulary values are ignored. Use either (but not both) of &lt;code&gt;num_oov_buckets&lt;/code&gt; and &lt;code&gt;default_value&lt;/code&gt; to specify how to include out-of-vocabulary values.</source>
          <target state="translated">입력이 문자열 또는 정수 형식이고 각 값을 정수 ID에 맵핑하는 어휘 파일이있는 경우이를 사용하십시오. 기본적으로 어휘 이외의 값은 무시됩니다. &lt;code&gt;num_oov_buckets&lt;/code&gt; 및 &lt;code&gt;default_value&lt;/code&gt; 중 하나 (둘다는 아님 ) 를 사용하여 어휘 이외의 값을 포함하는 방법을 지정하십시오.</target>
        </trans-unit>
        <trans-unit id="ebfbbc24af8cd5c1b3325ddc7e9b9110d158077e" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are in string or integer format, and you have an in-memory vocabulary mapping each value to an integer ID. By default, out-of-vocabulary values are ignored. Use either (but not both) of &lt;code&gt;num_oov_buckets&lt;/code&gt; and &lt;code&gt;default_value&lt;/code&gt; to specify how to include out-of-vocabulary values.</source>
          <target state="translated">입력이 문자열 또는 정수 형식이고 각 값을 정수 ID에 맵핑하는 메모리 내 어휘가있는 경우이를 사용하십시오. 기본적으로 어휘 이외의 값은 무시됩니다. &lt;code&gt;num_oov_buckets&lt;/code&gt; 및 &lt;code&gt;default_value&lt;/code&gt; 중 하나 (둘다는 아님 ) 를 사용하여 어휘 이외의 값을 포함하는 방법을 지정하십시오.</target>
        </trans-unit>
        <trans-unit id="5c2d5c81b6b22ab6aebbd8420d0922e66fb231ec" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are integers in the range &lt;code&gt;[0, num_buckets)&lt;/code&gt;, and you want to use the input value itself as the categorical ID. Values outside this range will result in &lt;code&gt;default_value&lt;/code&gt; if specified, otherwise it will fail.</source>
          <target state="translated">입력 값이 &lt;code&gt;[0, num_buckets)&lt;/code&gt; 범위의 정수이고 입력 값 자체를 범주 ID로 사용하려는 경우이를 사용하십시오. 이 범위를 벗어난 값은 지정된 경우 &lt;code&gt;default_value&lt;/code&gt; 가되며 그렇지 않으면 실패합니다.</target>
        </trans-unit>
        <trans-unit id="be55e7e6d26bbf4b36ff797d2545265b0a6866e3" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are sparse and of the same type (e.g. watched and impression video IDs that share the same vocabulary), and you want to convert them to a dense representation (e.g., to feed to a DNN).</source>
          <target state="translated">입력 내용이 희소하고 동일한 유형 (예 : 동일한 어휘를 공유하는 시청 및 노출 비디오 ID) 인 경우이를 밀도가 높은 표현으로 변환 (예 : DNN에 피드)하려는 경우에 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="ce58da03135c2b5ad93ed7aa78fffe6ae161dd6d" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are sparse, but you want to convert them to a dense representation (e.g., to feed to a DNN).</source>
          <target state="translated">입력이 드문 경우이지만이를 밀도가 높은 표현으로 변환하려는 경우 (예 : DNN에 피드하기 위해) 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="c980245437253028d09a527c56663fc1386fb381" translate="yes" xml:space="preserve">
          <source>Use this when your sparse features are in string or integer format, and you want to distribute your inputs into a finite number of buckets by hashing. output_id = Hash(input_feature_string) % bucket_size for string type input. For int type input, the value is converted to its string representation first and then hashed by the same formula.</source>
          <target state="translated">스파 스 기능이 문자열 또는 정수 형식이고 해시를 통해 입력을 한정된 수의 버킷으로 배포하려는 경우이 옵션을 사용하십시오. output_id = 문자열 유형 입력의 경우 해시 (input_feature_string) % bucket_size입니다. int 유형 입력의 경우 값이 먼저 문자열 표현으로 변환 된 다음 동일한 수식으로 해시됩니다.</target>
        </trans-unit>
        <trans-unit id="610337110a51eaf727f0158c31e03e81c30df87c" translate="yes" xml:space="preserve">
          <source>Use with &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Use with &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a0594027b100d87bb5949b9d94aec04e20184fe6" translate="yes" xml:space="preserve">
          <source>Use with &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 와 함께 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="7b2a8e4ff6f36d2ae408104e160d5b3b9371d34a" translate="yes" xml:space="preserve">
          <source>Use with the &lt;code&gt;with&lt;/code&gt; keyword to specify that all operations constructed within the context should have control dependencies on &lt;code&gt;control_inputs&lt;/code&gt;. For example:</source>
          <target state="translated">&lt;code&gt;with&lt;/code&gt; 키워드 와 함께 사용 하여 컨텍스트 내에 구성된 모든 조작에 &lt;code&gt;control_inputs&lt;/code&gt; 에 대한 제어 종속성이 있어야 함을 지정하십시오 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="69dd6dc7e65c4b9fe7cd1454b69ad4047ff65a5d" translate="yes" xml:space="preserve">
          <source>Use with the &lt;code&gt;with&lt;/code&gt; keyword to specify that calls to &lt;a href=&quot;../../operation#run&quot;&gt;&lt;code&gt;tf.Operation.run&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt; should be executed in this session.</source>
          <target state="translated">&lt;code&gt;with&lt;/code&gt; 키워드 와 함께 사용 하여 &lt;a href=&quot;../../operation#run&quot;&gt; &lt;code&gt;tf.Operation.run&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;../../tensor#eval&quot;&gt; &lt;code&gt;tf.Tensor.eval&lt;/code&gt; 에 대한&lt;/a&gt; 호출을 지정 하십시오. 하여이 세션에서 실행 .</target>
        </trans-unit>
        <trans-unit id="fefa29789a427f39795cb49ac3d13889fa028342" translate="yes" xml:space="preserve">
          <source>Used as the &lt;code&gt;_options&lt;/code&gt; argument to the &lt;code&gt;tf.Checkpoint&lt;/code&gt; constructor to adjust how variables are saved.</source>
          <target state="translated">Used as the &lt;code&gt;_options&lt;/code&gt; argument to the &lt;code&gt;tf.Checkpoint&lt;/code&gt; constructor to adjust how variables are saved.</target>
        </trans-unit>
        <trans-unit id="687844afc928e1515653eca2dc67313bcb251adb" translate="yes" xml:space="preserve">
          <source>Used for Tensor.&lt;strong&gt;div&lt;/strong&gt;.</source>
          <target state="translated">텐서에 사용됩니다. &lt;strong&gt;DIV&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="acb129729f63585d898dc89a0859fbaa068d1542" translate="yes" xml:space="preserve">
          <source>Used for backwards compatibility.</source>
          <target state="translated">Used for backwards compatibility.</target>
        </trans-unit>
        <trans-unit id="2ed98ab98b4d3bc08d8823f62d5fecc305aaf972" translate="yes" xml:space="preserve">
          <source>Used for generating the &lt;code&gt;sampling_table&lt;/code&gt; argument for &lt;code&gt;skipgrams&lt;/code&gt;. &lt;code&gt;sampling_table[i]&lt;/code&gt; is the probability of sampling the word i-th most common word in a dataset (more common words should be sampled less frequently, for balance).</source>
          <target state="translated">&lt;code&gt;skipgrams&lt;/code&gt; 의 &lt;code&gt;sampling_table&lt;/code&gt; 인수 를 생성하는 데 사용됩니다 . &lt;code&gt;sampling_table[i]&lt;/code&gt; 는 데이터 세트에서 i 번째로 가장 많이 사용되는 단어를 샘플링 할 확률입니다.</target>
        </trans-unit>
        <trans-unit id="838a9c1b2b1ad8d0483e3efe3752a2cfa857bf97" translate="yes" xml:space="preserve">
          <source>Used in &lt;code&gt;fit_generator&lt;/code&gt;, &lt;code&gt;evaluate_generator&lt;/code&gt;, &lt;code&gt;predict_generator&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fit_generator&lt;/code&gt; , &lt;code&gt;evaluate_generator&lt;/code&gt; , &lt;code&gt;predict_generator&lt;/code&gt; 에서 사용됩니다 .</target>
        </trans-unit>
        <trans-unit id="e032a2a6a3c13d10bf51a9e9b4ceb6f1b08ec11d" translate="yes" xml:space="preserve">
          <source>Used in a functional model:</source>
          <target state="translated">Used in a functional model:</target>
        </trans-unit>
        <trans-unit id="ce35a302d37a4e5f24d1589056ce4a8ade1153e6" translate="yes" xml:space="preserve">
          <source>Used in the guide:</source>
          <target state="translated">가이드에서 사용됨 :</target>
        </trans-unit>
        <trans-unit id="5d57c19f05b013abb121e6d7231e8fb33b04353e" translate="yes" xml:space="preserve">
          <source>Used in the tutorials:</source>
          <target state="translated">학습서에서 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="666e19bae41db98d774366b280a7568a18c7a7d0" translate="yes" xml:space="preserve">
          <source>Used to create a connection to a TPU master in order to retrieve the system metadata.</source>
          <target state="translated">Used to create a connection to a TPU master in order to retrieve the system metadata.</target>
        </trans-unit>
        <trans-unit id="0d5b31850f6cd998b34c1f803e97f421ab5e927c" translate="yes" xml:space="preserve">
          <source>Used to implement efficient stacked RNNs.</source>
          <target state="translated">효율적인 스택 RNN을 구현하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="1dc2e0b551da6f4f100efb7639cb33de1b18f9c4" translate="yes" xml:space="preserve">
          <source>Used to number checkpoints.</source>
          <target state="translated">체크 포인트 번호를 지정하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="f25ae0ac1af6f48ad552af7fd633f8cca6feb1bf" translate="yes" xml:space="preserve">
          <source>Used to prevent positional parameters. Internal, do not use.</source>
          <target state="translated">Used to prevent positional parameters. Internal, do not use.</target>
        </trans-unit>
        <trans-unit id="10ff5000f97f7693594d9bc2e58cecc4845e5222" translate="yes" xml:space="preserve">
          <source>Useful e.g. connecting RNNs and convnets.</source>
          <target state="translated">Useful e.g. connecting RNNs and convnets.</target>
        </trans-unit>
        <trans-unit id="33e1b276d404a935dc5326f961aab709a74eaaa4" translate="yes" xml:space="preserve">
          <source>Useful for e.g. connecting RNNs and convnets together.</source>
          <target state="translated">RNN과 convnet을 함께 연결하는 데 유용합니다.</target>
        </trans-unit>
        <trans-unit id="2c162068f6d2673c0d1e37e670b21e118d35909f" translate="yes" xml:space="preserve">
          <source>Useful special cases:</source>
          <target state="translated">유용한 특수 사례 :</target>
        </trans-unit>
        <trans-unit id="288dbdb9bfd68b877505e5e2d999c8a104f5d6ad" translate="yes" xml:space="preserve">
          <source>Useful to avoid clutter from old models / layers.</source>
          <target state="translated">오래된 모델 / 레이어에서 혼란을 피하는 데 유용합니다.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
