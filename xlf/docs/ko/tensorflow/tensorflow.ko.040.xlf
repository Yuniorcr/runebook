<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="6ed2ecdaa3bd96954ea77dce173719510eac3340" translate="yes" xml:space="preserve">
          <source>The ID of the module which registered the flag with this name. If no such module exists (i.e. no flag with this name exists), we return default.</source>
          <target state="translated">이 이름으로 플래그를 등록한 모듈의 ID입니다. 그러한 모듈이 존재하지 않으면 (즉,이 이름의 플래그가 존재하지 않는 경우), 기본값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="cc574746ad8c9b3dfc37ed70a6e4e32342676b91" translate="yes" xml:space="preserve">
          <source>The IDCT type to perform. Must be 1, 2, 3 or 4.</source>
          <target state="translated">The IDCT type to perform. Must be 1, 2, 3 or 4.</target>
        </trans-unit>
        <trans-unit id="87056d72e53edb8e1ee915616502d31a9e2351aa" translate="yes" xml:space="preserve">
          <source>The Keras functional API in TensorFlow</source>
          <target state="translated">TensorFlow의 Keras 기능 API</target>
        </trans-unit>
        <trans-unit id="4d52998a6cc31a940d4ebb5910a3ac5329dbc67f" translate="yes" xml:space="preserve">
          <source>The Kubernetes client (usually automatically retrieved using &lt;code&gt;from kubernetes import client as k8sclient&lt;/code&gt;). If you pass this in, you are responsible for setting Kubernetes credentials manually.</source>
          <target state="translated">The Kubernetes client (usually automatically retrieved using &lt;code&gt;from kubernetes import client as k8sclient&lt;/code&gt; ). If you pass this in, you are responsible for setting Kubernetes credentials manually.</target>
        </trans-unit>
        <trans-unit id="36e14ec6d1ffdc156a9c3f1daa6d9890ec3b1e0e" translate="yes" xml:space="preserve">
          <source>The L1 regularization penalty is computed as:</source>
          <target state="translated">L1 정규화 페널티는 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="542768df94a1b938a660f48e17ba6915139cc683" translate="yes" xml:space="preserve">
          <source>The L1 regularization penalty is computed as: &lt;code&gt;loss = l1 * reduce_sum(abs(x))&lt;/code&gt;</source>
          <target state="translated">The L1 regularization penalty is computed as: &lt;code&gt;loss = l1 * reduce_sum(abs(x))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5c4ad0ec53302f5554ee8c8eb2b239ae6b215ee1" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as</source>
          <target state="translated">L2 정규화 페널티는 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="d1be35376788281d0763761fe0b7decbcf96e523" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as &lt;code&gt;loss = l2 * reduce_sum(square(x))&lt;/code&gt;</source>
          <target state="translated">The L2 regularization penalty is computed as &lt;code&gt;loss = l2 * reduce_sum(square(x))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0f994e1d48c4b2ebd97fc4c0f1abd04009e95050" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as:</source>
          <target state="translated">L2 정규화 페널티는 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="3f0fa67aec74dc973d97bbb91f9762fcefa49c81" translate="yes" xml:space="preserve">
          <source>The L2 regularization penalty is computed as: &lt;code&gt;loss = l2 * reduce_sum(square(x))&lt;/code&gt;</source>
          <target state="translated">The L2 regularization penalty is computed as: &lt;code&gt;loss = l2 * reduce_sum(square(x))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e7557d40db7eef29f9f5cf0c8852c6278d915ffe" translate="yes" xml:space="preserve">
          <source>The Laplace distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="translated">위치와 라플라스 분포 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 매개 변수를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="cf61c2fbf2839d5025a99155287ab24829dc5c40" translate="yes" xml:space="preserve">
          <source>The Lightning Memory-Mapped Database Manager, or LMDB, is an embedded binary key-value database. This dataset can read the contents of LMDB database files, the names of which generally have the &lt;code&gt;.mdb&lt;/code&gt; suffix.</source>
          <target state="translated">The Lightning Memory-Mapped Database Manager, or LMDB, is an embedded binary key-value database. This dataset can read the contents of LMDB database files, the names of which generally have the &lt;code&gt;.mdb&lt;/code&gt; suffix.</target>
        </trans-unit>
        <trans-unit id="4f02ec145e8b375175cc81c541eb3f581408f36f" translate="yes" xml:space="preserve">
          <source>The Lpalce distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">Lpalce 배포판은 &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;위치 규모 제품군&lt;/a&gt; 의 구성원입니다. 즉, 다음과 같이 구성 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="179fc5d20bec0f4afac4c22aa43296f1c61f1b50" translate="yes" xml:space="preserve">
          <source>The Multinomial is a distribution over &lt;code&gt;K&lt;/code&gt;-class counts, i.e., a length-&lt;code&gt;K&lt;/code&gt; vector of non-negative integer &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt;.</source>
          <target state="translated">다항식은 &lt;code&gt;K&lt;/code&gt; 클래스 개수, 즉 음이 아닌 정수 &lt;code&gt;counts = n = [n_0, ..., n_{K-1}]&lt;/code&gt; 의 길이 &lt;code&gt;K&lt;/code&gt; 벡터에 대한 분포 입니다.</target>
        </trans-unit>
        <trans-unit id="024145881176dd778a381db52296681ba8110801" translate="yes" xml:space="preserve">
          <source>The Normal distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">정규 분포는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;위치 규모 패밀리&lt;/a&gt; 의 멤버입니다. 즉, 다음과 같이 구성 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7626aa48ba3874551b7938ac31ee1cdb369fcdfb" translate="yes" xml:space="preserve">
          <source>The Normal distribution with location &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; parameters.</source>
          <target state="translated">위치와 정규 분포 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 매개 변수를 설정합니다.</target>
        </trans-unit>
        <trans-unit id="a5d10a5e52f889fef0937f17600830c2e3265076" translate="yes" xml:space="preserve">
          <source>The OK difference between compared values.</source>
          <target state="translated">The OK difference between compared values.</target>
        </trans-unit>
        <trans-unit id="61bb4d6d17edca6217e2b2286030e9ba936a8932" translate="yes" xml:space="preserve">
          <source>The Optimizer instance to wrap.</source>
          <target state="translated">The Optimizer instance to wrap.</target>
        </trans-unit>
        <trans-unit id="20cd1c5b899f8db8c65884d1566d810b08070a16" translate="yes" xml:space="preserve">
          <source>The Python API &lt;a href=&quot;../data/experimental/parallel_interleave&quot;&gt;&lt;code&gt;tf.data.experimental.parallel_interleave&lt;/code&gt;&lt;/a&gt; creates instances of this op. &lt;a href=&quot;../data/experimental/parallel_interleave&quot;&gt;&lt;code&gt;tf.data.experimental.parallel_interleave&lt;/code&gt;&lt;/a&gt; is a deprecated API.</source>
          <target state="translated">The Python API &lt;a href=&quot;../data/experimental/parallel_interleave&quot;&gt; &lt;code&gt;tf.data.experimental.parallel_interleave&lt;/code&gt; &lt;/a&gt; creates instances of this op. &lt;a href=&quot;../data/experimental/parallel_interleave&quot;&gt; &lt;code&gt;tf.data.experimental.parallel_interleave&lt;/code&gt; &lt;/a&gt; is a deprecated API.</target>
        </trans-unit>
        <trans-unit id="b0bdc97d45fdd9ed6ed73f745bcb974b2865e78b" translate="yes" xml:space="preserve">
          <source>The Python string encoding to use. Defaults to &lt;code&gt;'utf-8'&lt;/code&gt;.</source>
          <target state="translated">The Python string encoding to use. Defaults to &lt;code&gt;'utf-8'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ef840b903d3e772791466fbdbfc1be244accb53f" translate="yes" xml:space="preserve">
          <source>The Python type for values that are compatible with this TypeSpec.</source>
          <target state="translated">이 TypeSpec과 호환되는 값의 Python 유형입니다.</target>
        </trans-unit>
        <trans-unit id="c6c5a52f571080e818c0861dc1504abe80f61cf9" translate="yes" xml:space="preserve">
          <source>The RGB tensor to convert. The last dimension must have size 3 and should contain RGB values.</source>
          <target state="translated">The RGB tensor to convert. The last dimension must have size 3 and should contain RGB values.</target>
        </trans-unit>
        <trans-unit id="55ebecb1d7e2330ca5e012023168889f2960e982" translate="yes" xml:space="preserve">
          <source>The RNG algorithm id (a Python integer or scalar integer Tensor).</source>
          <target state="translated">The RNG algorithm id (a Python integer or scalar integer Tensor).</target>
        </trans-unit>
        <trans-unit id="cb43dc4932964141b3fdd553bcbf71855032420a" translate="yes" xml:space="preserve">
          <source>The RNG algorithm.</source>
          <target state="translated">RNG 알고리즘.</target>
        </trans-unit>
        <trans-unit id="76339cee66ec7159c145a078be1135ca3e02b709" translate="yes" xml:space="preserve">
          <source>The RNN inputs. If &lt;code&gt;time_major == False&lt;/code&gt; (default), this must be a &lt;code&gt;Tensor&lt;/code&gt; of shape: &lt;code&gt;[batch_size, max_time, ...]&lt;/code&gt;, or a nested tuple of such elements. If &lt;code&gt;time_major == True&lt;/code&gt;, this must be a &lt;code&gt;Tensor&lt;/code&gt; of shape: &lt;code&gt;[max_time, batch_size, ...]&lt;/code&gt;, or a nested tuple of such elements. This may also be a (possibly nested) tuple of Tensors satisfying this property. The first two dimensions must match across all the inputs, but otherwise the ranks and other shape components may differ. In this case, input to &lt;code&gt;cell&lt;/code&gt; at each time-step will replicate the structure of these tuples, except for the time dimension (from which the time is taken). The input to &lt;code&gt;cell&lt;/code&gt; at each time step will be a &lt;code&gt;Tensor&lt;/code&gt; or (possibly nested) tuple of Tensors each with dimensions &lt;code&gt;[batch_size, ...]&lt;/code&gt;.</source>
          <target state="translated">The RNN inputs. If &lt;code&gt;time_major == False&lt;/code&gt; (default), this must be a &lt;code&gt;Tensor&lt;/code&gt; of shape: &lt;code&gt;[batch_size, max_time, ...]&lt;/code&gt; , or a nested tuple of such elements. If &lt;code&gt;time_major == True&lt;/code&gt; , this must be a &lt;code&gt;Tensor&lt;/code&gt; of shape: &lt;code&gt;[max_time, batch_size, ...]&lt;/code&gt; , or a nested tuple of such elements. This may also be a (possibly nested) tuple of Tensors satisfying this property. The first two dimensions must match across all the inputs, but otherwise the ranks and other shape components may differ. In this case, input to &lt;code&gt;cell&lt;/code&gt; at each time-step will replicate the structure of these tuples, except for the time dimension (from which the time is taken). The input to &lt;code&gt;cell&lt;/code&gt; at each time step will be a &lt;code&gt;Tensor&lt;/code&gt; or (possibly nested) tuple of Tensors each with dimensions &lt;code&gt;[batch_size, ...]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="86a6adce8d77079953ad4cee35e139a001725441" translate="yes" xml:space="preserve">
          <source>The RNN inputs. If time_major == False (default), this must be a tensor of shape: &lt;code&gt;[batch_size, max_time, ...]&lt;/code&gt;, or a nested tuple of such elements. If time_major == True, this must be a tensor of shape: &lt;code&gt;[max_time, batch_size, ...]&lt;/code&gt;, or a nested tuple of such elements.</source>
          <target state="translated">The RNN inputs. If time_major == False (default), this must be a tensor of shape: &lt;code&gt;[batch_size, max_time, ...]&lt;/code&gt; , or a nested tuple of such elements. If time_major == True, this must be a tensor of shape: &lt;code&gt;[max_time, batch_size, ...]&lt;/code&gt; , or a nested tuple of such elements.</target>
        </trans-unit>
        <trans-unit id="fbcdb35da9c3d356564a35feaefe2aec308e6f5b" translate="yes" xml:space="preserve">
          <source>The RNN output &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">The RNN output &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8edcb3ff2e37ea406f1dfe82fa8ca8a4f0949af0" translate="yes" xml:space="preserve">
          <source>The RPC layer TensorFlow should use to communicate across instances.</source>
          <target state="translated">The RPC layer TensorFlow should use to communicate across instances.</target>
        </trans-unit>
        <trans-unit id="5cf01358783b1025c197ff7c7e5d39c6fec8ac09" translate="yes" xml:space="preserve">
          <source>The RaggedTensor to slice.</source>
          <target state="translated">The RaggedTensor to slice.</target>
        </trans-unit>
        <trans-unit id="d5a45b5478a38a615eea2684c2d241f9352d6680" translate="yes" xml:space="preserve">
          <source>The SDCA algorithm was originally introduced in [1] and it was followed by the L1 proximal step [2], a distributed version [3] and adaptive sampling [4]. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] &lt;a href=&quot;https://arxiv.org/pdf/1309.2375.pdf&quot;&gt;https://arxiv.org/pdf/1309.2375.pdf&lt;/a&gt; [3] &lt;a href=&quot;https://arxiv.org/pdf/1502.03508.pdf&quot;&gt;https://arxiv.org/pdf/1502.03508.pdf&lt;/a&gt; [4] &lt;a href=&quot;https://arxiv.org/pdf/1502.08053.pdf&quot;&gt;https://arxiv.org/pdf/1502.08053.pdf&lt;/a&gt; Details specific to this implementation are provided in: &lt;a href=&quot;https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb&quot;&gt;https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb&lt;/a&gt;</source>
          <target state="translated">The SDCA algorithm was originally introduced in [1] and it was followed by the L1 proximal step [2], a distributed version [3] and adaptive sampling [4]. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] &lt;a href=&quot;https://arxiv.org/pdf/1309.2375.pdf&quot;&gt;https://arxiv.org/pdf/1309.2375.pdf&lt;/a&gt; [3] &lt;a href=&quot;https://arxiv.org/pdf/1502.03508.pdf&quot;&gt;https://arxiv.org/pdf/1502.03508.pdf&lt;/a&gt; [4] &lt;a href=&quot;https://arxiv.org/pdf/1502.08053.pdf&quot;&gt;https://arxiv.org/pdf/1502.08053.pdf&lt;/a&gt; Details specific to this implementation are provided in: &lt;a href=&quot;https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb&quot;&gt;https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="930b59a35037eb9f2e4f2e6718a1e37b8aaa1b56" translate="yes" xml:space="preserve">
          <source>The SDCA algorithm was originally introduced in [1] and it was followed by the L1 proximal step [2], a distributed version [3] and adaptive sampling [4]. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] https://arxiv.org/pdf/1309.2375.pdf [3] https://arxiv.org/pdf/1502.03508.pdf [4] https://arxiv.org/pdf/1502.08053.pdf Details specific to this implementation are provided in: https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb</source>
          <target state="translated">SDCA 알고리즘은 원래 [1]에 도입되었으며 L1 근위 단계 [2], 분산 버전 [3] 및 적응 형 샘플링 [4]이 뒤따 랐습니다. [1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf [2] https://arxiv.org/pdf/1309.2375.pdf [3] https://arxiv.org/pdf /1502.03508.pdf [4] https://arxiv.org/pdf/1502.08053.pdf이 구현에 대한 자세한 내용은 https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator에 제공됩니다. /canned/linear_optimizer/doc/sdca.ipynb</target>
        </trans-unit>
        <trans-unit id="f7780b9525d55737cd5cef56696d5858bdaaf0de" translate="yes" xml:space="preserve">
          <source>The SavedModel directory to load from.</source>
          <target state="translated">The SavedModel directory to load from.</target>
        </trans-unit>
        <trans-unit id="a77ce4bc58a785318ac8e94fd8eec273d01ff9a4" translate="yes" xml:space="preserve">
          <source>The SavedModel serialization path uses &lt;a href=&quot;../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; to save the model and all trackable objects attached to the model (e.g. layers and variables). &lt;code&gt;@tf.function&lt;/code&gt;-decorated methods are also saved. Additional trackable objects and functions are added to the SavedModel to allow the model to be loaded back as a Keras Model object.</source>
          <target state="translated">SavedModel 직렬화 경로는 &lt;a href=&quot;../../saved_model/save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; 를 사용하여 모델 및 모델에 연결된 모든 추적 가능한 객체 (예 : 레이어 및 변수)를 저장합니다. &lt;code&gt;@tf.function&lt;/code&gt; 메소드도 저장됩니다. 모델을 Keras 모델 오브젝트로 다시로드 할 수 있도록 추가 추적 가능한 오브젝트 및 기능이 SavedModel에 추가됩니다.</target>
        </trans-unit>
        <trans-unit id="303d5e3e630192c45b52ffe0ee781cadd1bb5c9c" translate="yes" xml:space="preserve">
          <source>The SavedModel will load in TensorFlow Serving and supports the &lt;a href=&quot;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/predict.proto&quot;&gt;Predict API&lt;/a&gt;. To use the Classify, Regress, or MultiInference APIs, please use either &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator&quot;&gt;tf.Estimator&lt;/a&gt; or the lower level &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md&quot;&gt;SavedModel APIs&lt;/a&gt;.</source>
          <target state="translated">The SavedModel will load in TensorFlow Serving and supports the &lt;a href=&quot;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/predict.proto&quot;&gt;Predict API&lt;/a&gt;. To use the Classify, Regress, or MultiInference APIs, please use either &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator&quot;&gt;tf.Estimator&lt;/a&gt; or the lower level &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md&quot;&gt;SavedModel APIs&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="ec1d78c7c8d9476450024b537502a2e94f916edd" translate="yes" xml:space="preserve">
          <source>The Scaled Exponential Linear Unit (SELU) activation function is defined as:</source>
          <target state="translated">The Scaled Exponential Linear Unit (SELU) activation function is defined as:</target>
        </trans-unit>
        <trans-unit id="60a134651d9227079722cdc9e74feb1653be5aa4" translate="yes" xml:space="preserve">
          <source>The Scaled Exponential Linear Unit (SELU) activation function is: &lt;code&gt;scale * x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;scale * alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; where &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are pre-defined constants (&lt;code&gt;alpha = 1.67326324&lt;/code&gt; and &lt;code&gt;scale = 1.05070098&lt;/code&gt;). The SELU activation function multiplies &lt;code&gt;scale&lt;/code&gt; &amp;gt; 1 with the &lt;code&gt;[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)&lt;/code&gt; (Exponential Linear Unit (ELU)) to ensure a slope larger than one for positive net inputs.</source>
          <target state="translated">스케일링 지수 선형 단위 (SELU) 활성화 함수이다 &lt;code&gt;scale * x&lt;/code&gt; 경우 &lt;code&gt;x &amp;gt; 0&lt;/code&gt; 및 &lt;code&gt;scale * alpha * (exp(x) - 1)&lt;/code&gt; 경우, &lt;code&gt;x &amp;lt; 0&lt;/code&gt; &lt;code&gt;alpha&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 미리 정의 된 상수 ( &lt;code&gt;alpha = 1.67326324&lt;/code&gt; 및 &lt;code&gt;scale = 1.05070098&lt;/code&gt; ). SELU 활성화 기능은 &lt;code&gt;scale&lt;/code&gt; &amp;gt; 1에 &lt;code&gt;[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)&lt;/code&gt; (ELU (Exponential Linear Unit))를 곱합니다. 양의 순 입력에 대해 1보다 큰 기울기를 보장합니다.</target>
        </trans-unit>
        <trans-unit id="8c9823ad487742ec2d729142bb77debf58c1e901" translate="yes" xml:space="preserve">
          <source>The SignatureDef will specify outputs as described in this ExportOutput, and will use the provided receiver_tensors as inputs.</source>
          <target state="translated">SignatureDef는이 ExportOutput에 설명 된대로 출력을 지정하고 제공된 receiver_tensors를 입력으로 사용합니다.</target>
        </trans-unit>
        <trans-unit id="f8a1119122b895a52e2361e72bc315143919a691" translate="yes" xml:space="preserve">
          <source>The SimpleClusterResolver does not do automatic detection of accelerators, and thus all arguments are unused and we simply return the value provided in the constructor.</source>
          <target state="translated">The SimpleClusterResolver does not do automatic detection of accelerators, and thus all arguments are unused and we simply return the value provided in the constructor.</target>
        </trans-unit>
        <trans-unit id="4545224fedce8f364aa3fd2d6cac68ea4817f884" translate="yes" xml:space="preserve">
          <source>The SimpleClusterResolver does not do automatic detection of accelerators, so a TensorFlow session will never be created, and thus all arguments are unused and we simply assume that the type of accelerator is a GPU and return the value in provided to us in the constructor.</source>
          <target state="translated">SimpleClusterResolver는 가속기의 자동 감지를 수행하지 않으므로 TensorFlow 세션이 작성되지 않으므로 모든 인수가 사용되지 않으므로 가속기 유형이 GPU라고 가정하고 생성자에서 제공된 값을 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="069bf31d9ffb91c874ca093882e0a6589ff1df14" translate="yes" xml:space="preserve">
          <source>The SparseAdd op calculates A + B, where A, B, and the sum are all represented as &lt;code&gt;SparseTensor&lt;/code&gt; objects. This op takes in the upstream gradient w.r.t. non-empty values of the sum, and outputs the gradients w.r.t. the non-empty values of A and B.</source>
          <target state="translated">The SparseAdd op calculates A + B, where A, B, and the sum are all represented as &lt;code&gt;SparseTensor&lt;/code&gt; objects. This op takes in the upstream gradient w.r.t. non-empty values of the sum, and outputs the gradients w.r.t. the non-empty values of A and B.</target>
        </trans-unit>
        <trans-unit id="3870013c51b6be5e7f15c3e32c4df520066f45b2" translate="yes" xml:space="preserve">
          <source>The SparseTensor to reduce. Should have numeric type.</source>
          <target state="translated">The SparseTensor to reduce. Should have numeric type.</target>
        </trans-unit>
        <trans-unit id="95d35b03ae5ea7cdb3cc356783df4e423a2dc6c1" translate="yes" xml:space="preserve">
          <source>The StudentT distribution is a member of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;location-scale family&lt;/a&gt;, i.e., it can be constructed as,</source>
          <target state="translated">StudentT 분포는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Location-scale_family&quot;&gt;위치 규모 제품군&lt;/a&gt; 의 구성원입니다. 즉, 다음과 같이 구성 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5c2d5184416b64215504aa1a967e583b20731ca8" translate="yes" xml:space="preserve">
          <source>The Supervisor is a small wrapper around a &lt;code&gt;Coordinator&lt;/code&gt;, a &lt;code&gt;Saver&lt;/code&gt;, and a &lt;code&gt;SessionManager&lt;/code&gt; that takes care of common needs of TensorFlow training programs.</source>
          <target state="translated">Supervisor는 TensorFlow 교육 프로그램의 일반적인 요구를 처리 하는 &lt;code&gt;Coordinator&lt;/code&gt; , &lt;code&gt;Saver&lt;/code&gt; 및 &lt;code&gt;SessionManager&lt;/code&gt; 를 둘러싼 작은 래퍼 입니다.</target>
        </trans-unit>
        <trans-unit id="41bd5ff6b458ccdec0fd96ba0408336a12a70400" translate="yes" xml:space="preserve">
          <source>The TF-TRT converted Function.</source>
          <target state="translated">TF-TRT가 기능을 변환했습니다.</target>
        </trans-unit>
        <trans-unit id="32c993dd695d77eb671cae70a4627b9e130bca1a" translate="yes" xml:space="preserve">
          <source>The TPU system performs the embedding lookups and aggregations specified by the arguments to TPUEmbeddingEnqueue(Integer/Sparse/SparseTensor)Batch. The results of these aggregations are visible to the Tensorflow Graph as the outputs of a RecvTPUEmbeddingActivations op. This op returns a list containing one Tensor of activations per table specified in the model. There can be at most one RecvTPUEmbeddingActivations op in the TPU graph.</source>
          <target state="translated">The TPU system performs the embedding lookups and aggregations specified by the arguments to TPUEmbeddingEnqueue(Integer/Sparse/SparseTensor)Batch. The results of these aggregations are visible to the Tensorflow Graph as the outputs of a RecvTPUEmbeddingActivations op. This op returns a list containing one Tensor of activations per table specified in the model. There can be at most one RecvTPUEmbeddingActivations op in the TPU graph.</target>
        </trans-unit>
        <trans-unit id="a05a9d3dc8221db263c61479e69d13cee15f7429" translate="yes" xml:space="preserve">
          <source>The TPUEmbedding mid level API.</source>
          <target state="translated">The TPUEmbedding mid level API.</target>
        </trans-unit>
        <trans-unit id="363164ea24b07b74dc51248150c976cfc6c56e68" translate="yes" xml:space="preserve">
          <source>The Tensor or SparseTensor or CompositeTensor in &lt;code&gt;graph&lt;/code&gt; described by &lt;code&gt;tensor_info&lt;/code&gt;.</source>
          <target state="translated">텐서에 또는 SparseTensor 또는 CompositeTensor &lt;code&gt;graph&lt;/code&gt; 설명 &lt;code&gt;tensor_info&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c0a0c7223ee1c65527cd175c2c03c00b8052eaee" translate="yes" xml:space="preserve">
          <source>The Tensor to be evaluated.</source>
          <target state="translated">The Tensor to be evaluated.</target>
        </trans-unit>
        <trans-unit id="2b213eabf8ccb6ff5bf4ab0a41158ab15e62ff3b" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;../model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="translated">TensorFlow 형식은 루트 객체에서 시작하여 객체 및 변수에 일치하는 &lt;code&gt;self&lt;/code&gt; 에 대한 &lt;code&gt;save_weights&lt;/code&gt; , 그리고 탐욕 일치하는 속성 이름. 들어 &lt;a href=&quot;../model#save&quot;&gt; &lt;code&gt;Model.save&lt;/code&gt; &lt;/a&gt; 이것은이다 &lt;code&gt;Model&lt;/code&gt; 및 대한 &lt;a href=&quot;../../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save&lt;/code&gt; &lt;/a&gt; 이는 것입니다 &lt;code&gt;Checkpoint&lt;/code&gt; 짝수 경우 &lt;code&gt;Checkpoint&lt;/code&gt; 부착 된 모델을 가지고있다. 즉, &lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; 사용하여 &lt;code&gt;save_weights&lt;/code&gt; 저장하고 &lt;code&gt;Model&lt;/code&gt; 이 첨부 된 (또는 그 반대) &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 로 로드 하면 &lt;code&gt;Model&lt;/code&gt; 변수 와 일치하지 않습니다 . &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;훈련 체크 포인트 가이드&lt;/a&gt; 참조 TensorFlow 형식에 대한 자세한 내용은</target>
        </trans-unit>
        <trans-unit id="9ab4684c965e60031ddf80734d60fea35c517d3d" translate="yes" xml:space="preserve">
          <source>The TensorFlow format matches objects and variables by starting at a root object, &lt;code&gt;self&lt;/code&gt; for &lt;code&gt;save_weights&lt;/code&gt;, and greedily matching attribute names. For &lt;a href=&quot;model#save&quot;&gt;&lt;code&gt;Model.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Model&lt;/code&gt;, and for &lt;a href=&quot;../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save&lt;/code&gt;&lt;/a&gt; this is the &lt;code&gt;Checkpoint&lt;/code&gt; even if the &lt;code&gt;Checkpoint&lt;/code&gt; has a model attached. This means saving a &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details on the TensorFlow format.</source>
          <target state="translated">TensorFlow 형식은 루트 객체에서 시작하여 객체 및 변수에 일치하는 &lt;code&gt;self&lt;/code&gt; 에 대한 &lt;code&gt;save_weights&lt;/code&gt; , 그리고 탐욕 일치하는 속성 이름. 들어 &lt;a href=&quot;model#save&quot;&gt; &lt;code&gt;Model.save&lt;/code&gt; &lt;/a&gt; 이것은이다 &lt;code&gt;Model&lt;/code&gt; 및 대한 &lt;a href=&quot;../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save&lt;/code&gt; &lt;/a&gt; 이는 것입니다 &lt;code&gt;Checkpoint&lt;/code&gt; 짝수 경우 &lt;code&gt;Checkpoint&lt;/code&gt; 부착 된 모델을 가지고있다. 즉, &lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; 사용하여 &lt;code&gt;save_weights&lt;/code&gt; 저장하고 &lt;code&gt;Model&lt;/code&gt; 이 첨부 된 (또는 그 반대) &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 로 로드 하면 &lt;code&gt;Model&lt;/code&gt; 변수 와 일치하지 않습니다 . &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;훈련 체크 포인트 가이드&lt;/a&gt; 참조 TensorFlow 형식에 대한 자세한 내용은</target>
        </trans-unit>
        <trans-unit id="b7638d4a5c348f022578401c2f1df999594f7eff" translate="yes" xml:space="preserve">
          <source>The TensorFlow process to which this session will connect.</source>
          <target state="translated">이 세션이 연결될 TensorFlow 프로세스.</target>
        </trans-unit>
        <trans-unit id="b91f22954ced4bccf875faf8127d8545ea485449" translate="yes" xml:space="preserve">
          <source>The TensorFlow session from which to save the meta graph and variables.</source>
          <target state="translated">The TensorFlow session from which to save the meta graph and variables.</target>
        </trans-unit>
        <trans-unit id="849cc5eecef306c2866f4ba201ccfdcdd2f534c9" translate="yes" xml:space="preserve">
          <source>The TensorFlow session to restore the variables.</source>
          <target state="translated">The TensorFlow session to restore the variables.</target>
        </trans-unit>
        <trans-unit id="16a70a758b7ef6d7fd0aad2771edf2a93446ebcd" translate="yes" xml:space="preserve">
          <source>The Tensors returned by computation.</source>
          <target state="translated">텐서는 계산에 의해 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="45ecd5a2e94b407ef5967be01d6aea7e5dfb3bca" translate="yes" xml:space="preserve">
          <source>The Variable has rank &lt;code&gt;P&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt; of rank &lt;code&gt;Q&lt;/code&gt;.</source>
          <target state="translated">변수의 순위는 &lt;code&gt;P&lt;/code&gt; 이고 &lt;code&gt;indices&lt;/code&gt; 는 순위 &lt;code&gt;Q&lt;/code&gt; 의 &lt;code&gt;Tensor&lt;/code&gt; 입니다 .</target>
        </trans-unit>
        <trans-unit id="f53a9ea2c1d95dd8b27a8885316c2bc7fb8ad0c0" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the input become the high order component of the output channel index.</source>
          <target state="translated">입력의 각 블록 내에서 Y, X 좌표는 출력 채널 인덱스의 상위 컴포넌트가됩니다.</target>
        </trans-unit>
        <trans-unit id="3d6c86d0708bda3da64a9da6d3c863b9ab737231" translate="yes" xml:space="preserve">
          <source>The Y, X coordinates within each block of the output image are determined by the high order component of the input channel index.</source>
          <target state="translated">출력 이미지의 각 블록 내의 Y, X 좌표는 입력 채널 인덱스의 상위 성분에 의해 결정됩니다.</target>
        </trans-unit>
        <trans-unit id="8cd36e977186fec64e8448a96228fbf260cd4605" translate="yes" xml:space="preserve">
          <source>The ZLIB compression level, &lt;code&gt;compression&lt;/code&gt;, can be -1 for the PNG-encoder default or a value from 0 to 9. 9 is the highest compression level, generating the smallest output, but is slower.</source>
          <target state="translated">ZLIB 압축 수준 &lt;code&gt;compression&lt;/code&gt; 은 PNG 인코더 기본값의 경우 -1이거나 0에서 9 사이의 값일 수 있습니다. 9는 가장 높은 압축 수준으로 가장 작은 출력을 생성하지만 느립니다.</target>
        </trans-unit>
        <trans-unit id="ce03da9cead6e86adf2a8009f5862736d75ecdca" translate="yes" xml:space="preserve">
          <source>The [batch] scalar &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt; in &lt;code&gt;cI&lt;/code&gt;.</source>
          <target state="translated">에서 [배치] 스칼라 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;c&lt;/code&gt; 의 &lt;code&gt;cI&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="875c6e8cec176a06af7a1f91d361f7f6428356f1" translate="yes" xml:space="preserve">
          <source>The above &lt;code&gt;matmul&lt;/code&gt; is equivalent to:</source>
          <target state="translated">The above &lt;code&gt;matmul&lt;/code&gt; is equivalent to:</target>
        </trans-unit>
        <trans-unit id="aaf6c09a17773617259c0e894f03f2f3f8ff8317" translate="yes" xml:space="preserve">
          <source>The above changes os.path.exists into a lambda that returns 1. Once the ... part of the code finishes, the CleanUp() looks up the old value of os.path.exists and restores it.</source>
          <target state="translated">위의 코드는 os.path.exists를 1을 반환하는 람다로 변경합니다. 코드의 ... 부분이 완료되면 CleanUp ()은 os.path.exists의 기존 값을 찾아서 복원합니다.</target>
        </trans-unit>
        <trans-unit id="c6eeb39f253767567cdcdb00a4d19d1c71b1dcf0" translate="yes" xml:space="preserve">
          <source>The above computation has a replicated input of two replicas.</source>
          <target state="translated">The above computation has a replicated input of two replicas.</target>
        </trans-unit>
        <trans-unit id="3d2ea5c0bd79dcd10faca424dbd0b0996316230c" translate="yes" xml:space="preserve">
          <source>The above computation has a replicated output of two replicas.</source>
          <target state="translated">The above computation has a replicated output of two replicas.</target>
        </trans-unit>
        <trans-unit id="f77b4838e9006d8d501115feb3f16fc46ba644b3" translate="yes" xml:space="preserve">
          <source>The above configuration has 2 tables, and three features. The first two features will be looked up in the first table and the third feature will be looked up in the second table.</source>
          <target state="translated">The above configuration has 2 tables, and three features. The first two features will be looked up in the first table and the third feature will be looked up in the second table.</target>
        </trans-unit>
        <trans-unit id="be70405fbae38c2509b5b1ab685f99f4d89a4d97" translate="yes" xml:space="preserve">
          <source>The above example corresponds to the case where you have only one device. If you have two devices, for example,</source>
          <target state="translated">The above example corresponds to the case where you have only one device. If you have two devices, for example,</target>
        </trans-unit>
        <trans-unit id="9ef3aa1fdfb679e9cef445f78d4851d53a003535" translate="yes" xml:space="preserve">
          <source>The above round function rounds the value based on the given round_mode.</source>
          <target state="translated">The above round function rounds the value based on the given round_mode.</target>
        </trans-unit>
        <trans-unit id="f2733c781ff4485ef11f43f16e3b526edaa1ff91" translate="yes" xml:space="preserve">
          <source>The accepted enum names, in lowercase if not case sensitive.</source>
          <target state="translated">The accepted enum names, in lowercase if not case sensitive.</target>
        </trans-unit>
        <trans-unit id="fa718bc26e2d4009bae4f7cc79776b6a1f114908" translate="yes" xml:space="preserve">
          <source>The accumulator accepts gradients marked with local_step greater or equal to the most recent global_step known to the accumulator. The average can be extracted from the accumulator, provided sufficient gradients have been accumulated. Extracting the average automatically resets the aggregate to 0, and increments the global_step recorded by the accumulator.</source>
          <target state="translated">The accumulator accepts gradients marked with local_step greater or equal to the most recent global_step known to the accumulator. The average can be extracted from the accumulator, provided sufficient gradients have been accumulated. Extracting the average automatically resets the aggregate to 0, and increments the global_step recorded by the accumulator.</target>
        </trans-unit>
        <trans-unit id="4f260205d3bbed38b27587f7081a1e0eb839bfaf" translate="yes" xml:space="preserve">
          <source>The accumulator accepts gradients marked with local_step greater or equal to the most recent global_step known to the accumulator. The average can be extracted from the accumulator, provided sufficient gradients have been accumulated. Extracting the average automatically resets the aggregate to 0, and increments the global_step recorded by the accumulator. This is a resource version of ConditionalAccumulator that will work in TF2.0 with tf.cond version 2.</source>
          <target state="translated">The accumulator accepts gradients marked with local_step greater or equal to the most recent global_step known to the accumulator. The average can be extracted from the accumulator, provided sufficient gradients have been accumulated. Extracting the average automatically resets the aggregate to 0, and increments the global_step recorded by the accumulator. This is a resource version of ConditionalAccumulator that will work in TF2.0 with tf.cond version 2.</target>
        </trans-unit>
        <trans-unit id="b8bb936a65c3ce409995481c6a4f6df5ec2956c6" translate="yes" xml:space="preserve">
          <source>The activation value.</source>
          <target state="translated">활성화 값.</target>
        </trans-unit>
        <trans-unit id="19792f4506e01a3e2d4abd5364a4484e6f9c0588" translate="yes" xml:space="preserve">
          <source>The actual numpy &lt;code&gt;ndarray&lt;/code&gt;, or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor), or any arbitrarily nested of structure of these.</source>
          <target state="translated">The actual numpy &lt;code&gt;ndarray&lt;/code&gt; , or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor), or any arbitrarily nested of structure of these.</target>
        </trans-unit>
        <trans-unit id="d36b573b08555814e732c53194782119f852b6d2" translate="yes" xml:space="preserve">
          <source>The actual optimizer that will be used to compute and apply the gradients. Must be one of the Optimizer classes.</source>
          <target state="translated">The actual optimizer that will be used to compute and apply the gradients. Must be one of the Optimizer classes.</target>
        </trans-unit>
        <trans-unit id="da7330feac6d473367759d5dd1a21e9334b8d8de" translate="yes" xml:space="preserve">
          <source>The added Keras attribute is: &lt;code&gt;_keras_history&lt;/code&gt;: Last layer applied to the tensor. the entire layer graph is retrievable from that layer, recursively.</source>
          <target state="translated">추가 된 &lt;code&gt;_keras_history&lt;/code&gt; 속성은 다음 과 같습니다 . _keras_history : 텐서에 마지막으로 적용된 레이어. 전체 레이어 그래프는 해당 레이어에서 재귀 적으로 검색 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f24861cc1a42612e73b3f3665071eeed2c9ea315" translate="yes" xml:space="preserve">
          <source>The additional robustness comes at a cost of roughly 4x higher compute time than &lt;code&gt;tf.string_to_hash_bucket_fast&lt;/code&gt;.</source>
          <target state="translated">추가적인 견고성은 &lt;code&gt;tf.string_to_hash_bucket_fast&lt;/code&gt; 보다 계산 시간이 약 4 배 빠릅니다 .</target>
        </trans-unit>
        <trans-unit id="1097b0db24625e152362ea61e1c9239db1bd02c3" translate="yes" xml:space="preserve">
          <source>The address of the coordinator (typically an ip:port pair). If set to None, a TF server will be started. If coordinator_name is None, a TF server will not be started even if coordinator_address is None.</source>
          <target state="translated">The address of the coordinator (typically an ip:port pair). If set to None, a TF server will be started. If coordinator_name is None, a TF server will not be started even if coordinator_address is None.</target>
        </trans-unit>
        <trans-unit id="92d822d5e3a4a473e569254158aeaed3f44c8de9" translate="yes" xml:space="preserve">
          <source>The address of the given task in the given job.</source>
          <target state="translated">주어진 작업에서 주어진 작업의 주소.</target>
        </trans-unit>
        <trans-unit id="1044e0e4428294ca84bc27c7d972e47ecc834421" translate="yes" xml:space="preserve">
          <source>The address of the master.</source>
          <target state="translated">마스터의 주소입니다.</target>
        </trans-unit>
        <trans-unit id="a671b38fc84a246388b74802d7c3903f8c308213" translate="yes" xml:space="preserve">
          <source>The adjoint (a.k.a. Hermitian transpose a.k.a. conjugate transpose) of matrix.</source>
          <target state="translated">매트릭스의 인접 (일명 에르 미트 (Hermitian) 전치 (일명 공역 전치)).</target>
        </trans-unit>
        <trans-unit id="2f35f817cc6a40c758997d4ca9d651aca344e6db" translate="yes" xml:space="preserve">
          <source>The adjoint case is solved similarly, beginning with &lt;code&gt;x_n = A_nn.solve(y_n, adjoint=True)&lt;/code&gt; and proceeding backwards.</source>
          <target state="translated">The adjoint case is solved similarly, beginning with &lt;code&gt;x_n = A_nn.solve(y_n, adjoint=True)&lt;/code&gt; and proceeding backwards.</target>
        </trans-unit>
        <trans-unit id="d26f5dd591fe207d72f8bf3767404f30851360da" translate="yes" xml:space="preserve">
          <source>The adjusted &lt;code&gt;min_range&lt;/code&gt; and &lt;code&gt;max_range&lt;/code&gt; are returned as outputs 2 and 3 of this operation. These outputs should be used as the range for any further calculations.</source>
          <target state="translated">조정 된 &lt;code&gt;min_range&lt;/code&gt; 및 &lt;code&gt;max_range&lt;/code&gt; 는이 작업의 출력 2 및 3으로 반환됩니다. 이 출력은 추가 계산을위한 범위로 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="23463dc8793b352e4536a04ab556ea601344e39c" translate="yes" xml:space="preserve">
          <source>The advantages of sampling candidates per-batch are simplicity and the possibility of efficient dense matrix multiplication. The disadvantage is that the sampled candidates must be chosen independently of the context and of the true labels.</source>
          <target state="translated">The advantages of sampling candidates per-batch are simplicity and the possibility of efficient dense matrix multiplication. The disadvantage is that the sampled candidates must be chosen independently of the context and of the true labels.</target>
        </trans-unit>
        <trans-unit id="34a7065e06c55b3339a4e1c47bf34bd00d072e70" translate="yes" xml:space="preserve">
          <source>The algorithm starts by setting the loss scale to an initial value. Every N steps that the gradients are finite, the loss scale is increased by some factor. However, if a NaN or Inf gradient is found, the gradients for that step are not applied, and the loss scale is decreased by the factor. This process tends to keep the loss scale as high as possible without gradients overflowing.</source>
          <target state="translated">알고리즘은 손실 스케일을 초기 값으로 설정하여 시작합니다. 그라디언트가 유한 한 모든 N 단계마다 손실 스케일이 어느 정도 증가합니다. 그러나 NaN 또는 Inf 그래디언트가 발견되면 해당 단계의 그래디언트가 적용되지 않고 손실 스케일이 요인에 의해 감소합니다. 이 프로세스는 그래디언트 오버플로없이 손실 규모를 최대한 높게 유지하는 경향이 있습니다.</target>
        </trans-unit>
        <trans-unit id="ec9f002d6d3b1e71963d9cf73b905f9b84153981" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;.</source>
          <target state="translated">&quot;slice_spec&quot;을 기반으로 한 &quot;tensor&quot;의 적절한 슬라이스입니다.</target>
        </trans-unit>
        <trans-unit id="821f24c959536d42cc6fec55c7d0ad6a3d16e3c7" translate="yes" xml:space="preserve">
          <source>The appropriate slice of &quot;tensor&quot;, based on &quot;slice_spec&quot;. As an operator. The operator also has a &lt;code&gt;assign()&lt;/code&gt; method that can be used to generate an assignment operator.</source>
          <target state="translated">&quot;slice_spec&quot;을 기반으로 한 &quot;tensor&quot;의 적절한 슬라이스입니다. 운영자로서. 운영자는 또한 &lt;code&gt;assign()&lt;/code&gt; 에는 할당 연산자를 생성하는 데 사용할 수 assign () 메서드도 있습니다.</target>
        </trans-unit>
        <trans-unit id="23ef91f4c9a43b0bf509fbf539d12c4d114f51e2" translate="yes" xml:space="preserve">
          <source>The area within the interval is (slope / total_pos_weight) times</source>
          <target state="translated">구간 내 면적은 (기울기 / total_pos_weight) 시간입니다</target>
        </trans-unit>
        <trans-unit id="6ecef333fac070655838aed6ec7905dde692ac00" translate="yes" xml:space="preserve">
          <source>The args to be substituted into the msg.</source>
          <target state="translated">The args to be substituted into the msg.</target>
        </trans-unit>
        <trans-unit id="d2d3e064486f4100aead5629a0acce01f2954896" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;normalized&lt;/code&gt; and &lt;code&gt;centered&lt;/code&gt; controls how the windows are built:</source>
          <target state="translated">논쟁은 &lt;code&gt;normalized&lt;/code&gt; 되고 &lt;code&gt;centered&lt;/code&gt; 는 창을 만드는 방법을 제어합니다.</target>
        </trans-unit>
        <trans-unit id="572a6d647b031b519cd29780ad535922e4e59db7" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;shape&lt;/code&gt; is optional. If present, it specifies the dimensions of the resulting tensor. If not present, the shape of &lt;code&gt;value&lt;/code&gt; is used.</source>
          <target state="translated">인수 &lt;code&gt;shape&lt;/code&gt; 는 선택 사항입니다. 존재하는 경우 결과 텐서의 크기를 지정합니다. 존재하지 않으면 &lt;code&gt;value&lt;/code&gt; 의 모양 이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="13e87601baeedfadd1e05e7b900ecdbd205d0bf6" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;tensors&lt;/code&gt; can be a list or a dictionary of tensors. The value returned by the function will be of the same type as &lt;code&gt;tensors&lt;/code&gt;.</source>
          <target state="translated">인수 &lt;code&gt;tensors&lt;/code&gt; 는 텐서 의 목록 또는 사전 일 수 있습니다. 함수가 반환 한 값은 &lt;code&gt;tensors&lt;/code&gt; 와 동일한 유형 입니다.</target>
        </trans-unit>
        <trans-unit id="a32d0e1dadf3135bed15ded733117d1a197ad906" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the &lt;code&gt;shape&lt;/code&gt; argument (if specified). In the case where the list length is less than the number of elements specified by &lt;code&gt;shape&lt;/code&gt;, the last element in the list will be used to fill the remaining entries.</source>
          <target state="translated">인수 &lt;code&gt;value&lt;/code&gt; 은 상수 값이거나 &lt;code&gt;dtype&lt;/code&gt; 유형의 값 목록 일 수 있습니다 . &lt;code&gt;value&lt;/code&gt; 가 목록 인 경우 목록의 길이는 &lt;code&gt;shape&lt;/code&gt; 인수에 의해 암시 된 요소 수보다 작거나 같아야합니다 (지정된 경우). 목록 길이가 다음에 의해 지정된 요소 수보다 작은 경우 &lt;code&gt;shape&lt;/code&gt; 로 의 마지막 요소가 나머지 항목을 채우는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="4f585d29c2b28791ced3d5b4a780f2d82b9f8bf3" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a constant value, or a list of values of type &lt;code&gt;dtype&lt;/code&gt;. If &lt;code&gt;value&lt;/code&gt; is a list, then the length of the list must be less than or equal to the number of elements implied by the desired shape of the tensor. In the case where the total number of elements in &lt;code&gt;value&lt;/code&gt; is less than the number of elements required by the tensor shape, the last element in &lt;code&gt;value&lt;/code&gt; will be used to fill the remaining entries. If the total number of elements in &lt;code&gt;value&lt;/code&gt; is greater than the number of elements required by the tensor shape, the initializer will raise a &lt;code&gt;ValueError&lt;/code&gt;.</source>
          <target state="translated">인수 &lt;code&gt;value&lt;/code&gt; 은 상수 값이거나 &lt;code&gt;dtype&lt;/code&gt; 유형의 값 목록 일 수 있습니다 . &lt;code&gt;value&lt;/code&gt; 가리스트 인 경우 ,리스트의 길이는 원하는 텐서 모양에 의해 암시되는 요소의 수보다 작거나 같아야합니다. &lt;code&gt;value&lt;/code&gt; 의 총 요소 수가 텐서 모양에 필요한 요소의 수보다 적은 경우, &lt;code&gt;value&lt;/code&gt; 의 마지막 요소 가 나머지 항목을 채우는 데 사용됩니다. &lt;code&gt;value&lt;/code&gt; 의 총 요소 수가 텐서 모양에 필요한 요소 수보다 큰 경우 이니셜 라이저는 &lt;code&gt;ValueError&lt;/code&gt; 를 발생 시킵니다.</target>
        </trans-unit>
        <trans-unit id="ce316117b38a170bc69e8657284f9032bf2d1a61" translate="yes" xml:space="preserve">
          <source>The argument &lt;code&gt;value&lt;/code&gt; can be a scalar constant value, or a list of values. Scalars broadcast to whichever shape is requested from the initializer.</source>
          <target state="translated">The argument &lt;code&gt;value&lt;/code&gt; can be a scalar constant value, or a list of values. Scalars broadcast to whichever shape is requested from the initializer.</target>
        </trans-unit>
        <trans-unit id="35b02213c63b22c6aa288eadb099101e8c7a8bb2" translate="yes" xml:space="preserve">
          <source>The argument returned by this function is of the form \(atan2(b, a)\). If &lt;code&gt;input&lt;/code&gt; is real, a tensor of all zeros is returned.</source>
          <target state="translated">이 함수가 반환하는 인수는 \ (atan2 (b, a) \) 형식입니다. &lt;code&gt;input&lt;/code&gt; 하면 진짜, 모두 제로의 텐서가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="1b8141113a16ee9c1ee49249a42c4ec753fd4479" translate="yes" xml:space="preserve">
          <source>The argument returned by this operation is of the form \(atan2(b, a)\).</source>
          <target state="translated">The argument returned by this operation is of the form \(atan2(b, a)\).</target>
        </trans-unit>
        <trans-unit id="c08c5bbd3a3384802afbf07c0b86453afc140d85" translate="yes" xml:space="preserve">
          <source>The argument tuple for the target invocation. Defaults to ().</source>
          <target state="translated">The argument tuple for the target invocation. Defaults to ().</target>
        </trans-unit>
        <trans-unit id="8925ea25cd72607e66cde54201ec4e13ca4e3936" translate="yes" xml:space="preserve">
          <source>The arguments to &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Tensor#__getitem__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The arguments to &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Tensor#__getitem__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="dd368055cee84276738860ec0ec0f93a1536f9fa" translate="yes" xml:space="preserve">
          <source>The arguments to &lt;a href=&quot;tensor#__getitem__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The arguments to &lt;a href=&quot;tensor#__getitem__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="08b05ba34abcf5462dc06534466ce94b701e498e" translate="yes" xml:space="preserve">
          <source>The arguments to Tensor.&lt;strong&gt;getitem&lt;/strong&gt;.</source>
          <target state="translated">The arguments to Tensor.&lt;strong&gt;getitem&lt;/strong&gt;.</target>
        </trans-unit>
        <trans-unit id="56bf9f2cd73c00e2baa02cf649b84dad59db80fe" translate="yes" xml:space="preserve">
          <source>The assertion is checked at runtime (when iterating the dataset) and an error is raised if the actual and expected cardinality differ.</source>
          <target state="translated">The assertion is checked at runtime (when iterating the dataset) and an error is raised if the actual and expected cardinality differ.</target>
        </trans-unit>
        <trans-unit id="bce43bdee979454925721c507561e0a29cfacb37" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., &lt;code&gt;local_step&lt;/code&gt; is less than the accumulator's global time step.</source>
          <target state="translated">그래디언트가 오래된 경우 (즉, &lt;code&gt;local_step&lt;/code&gt; 이 누산기의 글로벌 시간 단계보다 작 으면) 시도가 자동으로 삭제됩니다 .</target>
        </trans-unit>
        <trans-unit id="c2d9f9b7d3b4bc909dac3ec1179989967a68da98" translate="yes" xml:space="preserve">
          <source>The attempt is silently dropped if the gradient is stale, i.e., local_step is less than the accumulator's global time step.</source>
          <target state="translated">그래디언트가 오래된 경우 (즉, local_step이 누산기의 글로벌 시간 단계보다 작 으면) 시도가 자동으로 삭제됩니다.</target>
        </trans-unit>
        <trans-unit id="d8f6f1e67bc16f32d9f24b6bf9dc1327c99b4c20" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;block_size&lt;/code&gt; must be greater than one. It indicates the block size.</source>
          <target state="translated">attr &lt;code&gt;block_size&lt;/code&gt; 는 1보다 커야합니다. 블록 크기를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="b44ab2abacbb2efdb69194961a5971ce5296193c" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;channels&lt;/code&gt; indicates the desired number of color channels for the decoded image.</source>
          <target state="translated">attr &lt;code&gt;channels&lt;/code&gt; 은 디코딩 된 이미지에 대한 원하는 컬러 채널 수를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="60563f76a3b65c009555c6aca9d9b0a28f8e6c56" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;format&lt;/code&gt; can be used to override the color format of the encoded output. Values can be:</source>
          <target state="translated">attr &lt;code&gt;format&lt;/code&gt; 을 사용하여 인코딩 된 출력의 색상 형식을 재정의 할 수 있습니다. 값은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="ae606ee2da5f189375721f138e9665ac82e81365" translate="yes" xml:space="preserve">
          <source>The attr &lt;code&gt;ratio&lt;/code&gt; allows downscaling the image by an integer factor during decoding. Allowed values are: 1, 2, 4, and 8. This is much faster than downscaling the image later.</source>
          <target state="translated">attr &lt;code&gt;ratio&lt;/code&gt; 은 디코딩 중에 이미지를 정수로 축소 할 수 있습니다. 허용되는 값은 1, 2, 4 및 8입니다. 이것은 나중에 이미지를 축소하는 것보다 훨씬 빠릅니다.</target>
        </trans-unit>
        <trans-unit id="1dfd0d9d6161eef67f30788b5c5ad724fc4b4c90" translate="yes" xml:space="preserve">
          <source>The attribute &lt;code&gt;source&lt;/code&gt; is added as a suffix to the forward TensorArray's name when performing the creation / lookup, so that each separate gradient calculation gets its own TensorArray accumulator.</source>
          <target state="translated">The attribute &lt;code&gt;source&lt;/code&gt; is added as a suffix to the forward TensorArray's name when performing the creation / lookup, so that each separate gradient calculation gets its own TensorArray accumulator.</target>
        </trans-unit>
        <trans-unit id="2e6570b67f35dff908278e6c1092e20dca85cfcf" translate="yes" xml:space="preserve">
          <source>The attributes themselves are defined in the &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/boston&quot;&gt;StatLib website&lt;/a&gt;.</source>
          <target state="translated">The attributes themselves are defined in the &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/boston&quot;&gt;StatLib website&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="3c251209154f7690ac8f45548c2019ab6de3993b" translate="yes" xml:space="preserve">
          <source>The axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape &lt;code&gt;(batch, height, width, channels)&lt;/code&gt;, and you wish to share parameters across space so that each filter only has one set of parameters, set &lt;code&gt;shared_axes=[1, 2]&lt;/code&gt;.</source>
          <target state="translated">The axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape &lt;code&gt;(batch, height, width, channels)&lt;/code&gt; , and you wish to share parameters across space so that each filter only has one set of parameters, set &lt;code&gt;shared_axes=[1, 2]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ab2b7a67aab4c51b1e0d6376358a5f7e5c4b44b1" translate="yes" xml:space="preserve">
          <source>The axis along which to sort. The default is -1, which sorts the last axis.</source>
          <target state="translated">The axis along which to sort. The default is -1, which sorts the last axis.</target>
        </trans-unit>
        <trans-unit id="20b05f039f9c533c5583921e0ed9aed8213b7f85" translate="yes" xml:space="preserve">
          <source>The axis that the output values are concatenated along. Default is -1.</source>
          <target state="translated">The axis that the output values are concatenated along. Default is -1.</target>
        </trans-unit>
        <trans-unit id="eaf9bdc79969635901c1b7428a237e7743aef889" translate="yes" xml:space="preserve">
          <source>The axis to fill (default: -1, a new inner-most axis).</source>
          <target state="translated">The axis to fill (default: -1, a new inner-most axis).</target>
        </trans-unit>
        <trans-unit id="a537279d84220ef606eff7333b56720a53d5d752" translate="yes" xml:space="preserve">
          <source>The axis to partition along. Default: outermost axis.</source>
          <target state="translated">The axis to partition along. Default: outermost axis.</target>
        </trans-unit>
        <trans-unit id="a06b05d6c855c1eb850eace9884f0d972ce19029" translate="yes" xml:space="preserve">
          <source>The axis to slice over. Axes at and below &lt;code&gt;axis&lt;/code&gt; will be flattened before bin counting. Currently, only &lt;code&gt;0&lt;/code&gt;, and &lt;code&gt;-1&lt;/code&gt; are supported. If None, all axes will be flattened (identical to passing &lt;code&gt;0&lt;/code&gt;).</source>
          <target state="translated">The axis to slice over. Axes at and below &lt;code&gt;axis&lt;/code&gt; will be flattened before bin counting. Currently, only &lt;code&gt;0&lt;/code&gt; , and &lt;code&gt;-1&lt;/code&gt; are supported. If None, all axes will be flattened (identical to passing &lt;code&gt;0&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="735485241e46184aca9b9d13dea029d8a1bc84d8" translate="yes" xml:space="preserve">
          <source>The backend learning phase affects any code that calls &lt;a href=&quot;learning_phase&quot;&gt;&lt;code&gt;backend.learning&lt;em&gt;phase()&lt;/em&gt;&lt;/code&gt;&lt;/a&gt; In particular, all Keras built-in layers use the learning phase as the default for the &lt;code&gt;training&lt;/code&gt; arg to &amp;lt;a href=&quot;../../../tf/keras/layers/Layer#&lt;em&gt;call&lt;/em&gt;&lt;em&gt;&quot;&amp;gt;&lt;code&gt;Layer.&lt;/code&gt;&lt;/em&gt;&lt;em&gt;call&lt;/em&gt;_.</source>
          <target state="translated">The backend learning phase affects any code that calls &lt;a href=&quot;learning_phase&quot;&gt; &lt;code&gt;backend.learning&lt;em&gt;phase()&lt;/em&gt;&lt;/code&gt; &lt;/a&gt; In particular, all Keras built-in layers use the learning phase as the default for the &lt;code&gt;training&lt;/code&gt; arg to &amp;lt;a href=&quot;../../../tf/keras/layers/Layer#&lt;em&gt;call&lt;/em&gt;&lt;em&gt;&quot;&amp;gt; &lt;code&gt;Layer.&lt;/code&gt; &lt;/em&gt;&lt;em&gt;call&lt;/em&gt;_.</target>
        </trans-unit>
        <trans-unit id="e683aeb65a23e8619a38b301846fe9aa22a79e70" translate="yes" xml:space="preserve">
          <source>The backward operation for &quot;BiasAdd&quot; on the &quot;bias&quot; tensor.</source>
          <target state="translated">The backward operation for &quot;BiasAdd&quot; on the &quot;bias&quot; tensor.</target>
        </trans-unit>
        <trans-unit id="43192d2acab6f30a3fb88a081e4480c6a4eaf531" translate="yes" xml:space="preserve">
          <source>The base class for all flags errors.</source>
          <target state="translated">모든 플래그 오류의 기본 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="95fac0e9d908797873ec2155df12d61346d3ec3c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is an approximately log-uniform or Zipfian distribution:</source>
          <target state="translated">이 작업의 기본 분포는 대략 로그 균일 분포 또는 Zipfian 분포입니다.</target>
        </trans-unit>
        <trans-unit id="e03722f7ec155314d6d64a06632231a0220ddf21" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is constructed on the fly during training. It is a unigram distribution over the target classes seen so far during training. Every integer in &lt;code&gt;[0, range_max)&lt;/code&gt; begins with a weight of 1, and is incremented by 1 each time it is seen as a target class. The base distribution is not saved to checkpoints, so it is reset when the model is reloaded.</source>
          <target state="translated">이 작업의 기본 분포는 교육 중에 즉시 구성됩니다. 그것은 훈련 중에 지금까지 본 대상 클래스에 대한 유니 그램 분포입니다. &lt;code&gt;[0, range_max)&lt;/code&gt; 모든 정수 는 가중치 1로 시작하며 대상 클래스로 볼 때마다 1 씩 증가합니다. 기본 분포는 검사 점에 저장되지 않으므로 모델을 다시로드하면 재설정됩니다.</target>
        </trans-unit>
        <trans-unit id="9b285a7357154664da97ef50a86143b40cc66c8c" translate="yes" xml:space="preserve">
          <source>The base distribution for this operation is the uniform distribution over the range of integers &lt;code&gt;[0, range_max)&lt;/code&gt;.</source>
          <target state="translated">이 연산의 기본 분포는 정수 범위 &lt;code&gt;[0, range_max)&lt;/code&gt; 대한 균일 분포 입니다.</target>
        </trans-unit>
        <trans-unit id="77b83a8d332ed8aca766d79f4120f4e0ba2ea928" translate="yes" xml:space="preserve">
          <source>The base distribution is read from a file or passed in as an in-memory array. There is also an option to skew the distribution by applying a distortion power to the weights.</source>
          <target state="translated">기본 배포는 파일에서 읽거나 메모리 내 배열로 전달됩니다. 가중치에 왜곡 전력을 적용하여 분포를 왜곡하는 옵션도 있습니다.</target>
        </trans-unit>
        <trans-unit id="dbe1df14f66fa0efdc79542406d6783493a122af" translate="yes" xml:space="preserve">
          <source>The base type or tuple of base types for all objects that &lt;code&gt;conversion_func&lt;/code&gt; accepts.</source>
          <target state="translated">The base type or tuple of base types for all objects that &lt;code&gt;conversion_func&lt;/code&gt; accepts.</target>
        </trans-unit>
        <trans-unit id="742c5ef9e662d0b65e94999280201b89cf344cb4" translate="yes" xml:space="preserve">
          <source>The basename for checkpoint saving.</source>
          <target state="translated">The basename for checkpoint saving.</target>
        </trans-unit>
        <trans-unit id="ded41e0565ef5f400dbd93cc56863d8aef5c6704" translate="yes" xml:space="preserve">
          <source>The basic functionality is similar to dequeue with many fewer capabilities and options. This Op is optimized for performance.</source>
          <target state="translated">The basic functionality is similar to dequeue with many fewer capabilities and options. This Op is optimized for performance.</target>
        </trans-unit>
        <trans-unit id="dade1361cd3ab94fd2385c47804539cc6fda3a6a" translate="yes" xml:space="preserve">
          <source>The basic functionality of this Op is similar to a queue with many fewer capabilities and options. This Op is optimized for performance.</source>
          <target state="translated">The basic functionality of this Op is similar to a queue with many fewer capabilities and options. This Op is optimized for performance.</target>
        </trans-unit>
        <trans-unit id="7c0a22a2ecdff77c481cab7326fe4aaa0b144cf7" translate="yes" xml:space="preserve">
          <source>The batch dimensions are indexes into independent, non-identical parameterizations of this distribution.</source>
          <target state="translated">배치 차원은이 분포의 독립적이고 동일하지 않은 모수화에 대한 색인입니다.</target>
        </trans-unit>
        <trans-unit id="b55a5f5737af8dc7c66469a674fe7b35b3d67f61" translate="yes" xml:space="preserve">
          <source>The batch dimensions, denoted as &lt;code&gt;...&lt;/code&gt;, must be the same in &lt;code&gt;diagonals&lt;/code&gt; and &lt;code&gt;rhs&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;...&lt;/code&gt; 로 표시된 배치 치수 는 &lt;code&gt;diagonals&lt;/code&gt; 과 &lt;code&gt;rhs&lt;/code&gt; 에서 동일해야합니다. .</target>
        </trans-unit>
        <trans-unit id="b8d1e654d8a3893e3ebd1816b79375a5883dc270" translate="yes" xml:space="preserve">
          <source>The batch of the output tensor is &lt;code&gt;batch * block_size * block_size&lt;/code&gt;.</source>
          <target state="translated">출력 텐서의 &lt;code&gt;batch * block_size * block_size&lt;/code&gt; 는 batch * block_size * block_size 입니다.</target>
        </trans-unit>
        <trans-unit id="49fd2aeae8e83aee3d7e1d3b09e0905a7ad1a450" translate="yes" xml:space="preserve">
          <source>The below table describes the performance on ImageNet 2012:</source>
          <target state="translated">The below table describes the performance on ImageNet 2012:</target>
        </trans-unit>
        <trans-unit id="d9d6c8abb90d01f2c83046e4ffaae926e1136406" translate="yes" xml:space="preserve">
          <source>The biggest difference between this and MIN_COMBINED is that the minimum range is rounded first, before it's subtracted from the rounded value. With MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing and dequantizing will introduce a larger and larger error.</source>
          <target state="translated">이것과 MIN_COMBINED의 가장 큰 차이점은 반올림 값에서 빼기 전에 최소 범위가 먼저 반올림된다는 것입니다. MIN_COMBINED를 사용하면 반복적 인 양자화 및 역 양자화 반복이 더 큰 오류를 발생시키는 작은 바이어스가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="72445c1ce9af91d1b7756490161ef93a455800a7" translate="yes" xml:space="preserve">
          <source>The binomial distribution with parameters &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;p&lt;/code&gt; is the probability distribution of the number of successful Bernoulli process. Only supports &lt;code&gt;n&lt;/code&gt; = 1 for now.</source>
          <target state="translated">모수 &lt;code&gt;n&lt;/code&gt; 과 &lt;code&gt;p&lt;/code&gt; 를 갖는 이항 분포 는 성공적인 Bernoulli 프로세스 수의 확률 분포입니다. 현재 는 &lt;code&gt;n&lt;/code&gt; = 1 만 지원합니다 .</target>
        </trans-unit>
        <trans-unit id="1b8c51d786a68de27c6b4224613923d5f7bdaf37" translate="yes" xml:space="preserve">
          <source>The bitwidth of the quantization.</source>
          <target state="translated">The bitwidth of the quantization.</target>
        </trans-unit>
        <trans-unit id="9046a47f005a317609f27142cf924b36a45d9e12" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;GraphDef&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">함수 본문 (예 : &lt;code&gt;func&lt;/code&gt; )은 &lt;code&gt;GraphDef&lt;/code&gt; 에서 직렬화되지 않습니다. . 따라서 모델을 직렬화하고 다른 환경에서 복원해야하는 경우이 기능을 사용하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="794d80e295e24e3ff23cc23c744638ef8dd2ef67" translate="yes" xml:space="preserve">
          <source>The body of the function (i.e. &lt;code&gt;func&lt;/code&gt;) will not be serialized in a &lt;code&gt;tf.SavedModel&lt;/code&gt;. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</source>
          <target state="translated">함수의 본문 (예 : &lt;code&gt;func&lt;/code&gt; )은 &lt;code&gt;tf.SavedModel&lt;/code&gt; 에서 직렬화되지 않습니다 . 따라서 모델을 직렬화하고 다른 환경에서 복원해야하는 경우이 기능을 사용하지 마십시오.</target>
        </trans-unit>
        <trans-unit id="2f2bb2d689c89f9383b7eeefb755379869595cea" translate="yes" xml:space="preserve">
          <source>The boolean tensor to reduce.</source>
          <target state="translated">The boolean tensor to reduce.</target>
        </trans-unit>
        <trans-unit id="4e7703441ddf5ba9641cb1cc0ad74e7c6c58e3a7" translate="yes" xml:space="preserve">
          <source>The brightness-adjusted image(s).</source>
          <target state="translated">밝기 조정 이미지.</target>
        </trans-unit>
        <trans-unit id="0ed98e5a86a1390e9cad2bb3ecc49819e326a775" translate="yes" xml:space="preserve">
          <source>The broadcasted dimensions are placed in the corresponding location of the ellipsis in the output subscript. If the broadcasted dimensions are non-empty and the output subscripts do not contain ellipsis, then an InvalidArgument error is raised.</source>
          <target state="translated">The broadcasted dimensions are placed in the corresponding location of the ellipsis in the output subscript. If the broadcasted dimensions are non-empty and the output subscripts do not contain ellipsis, then an InvalidArgument error is raised.</target>
        </trans-unit>
        <trans-unit id="8fb502dacff4b6e562a2e1abdf5e1fedac860a6d" translate="yes" xml:space="preserve">
          <source>The byte count relative to the whence argument.</source>
          <target state="translated">The byte count relative to the whence argument.</target>
        </trans-unit>
        <trans-unit id="d1e48a233423d312fda6e60318a1f77840441ac1" translate="yes" xml:space="preserve">
          <source>The call arguments for this layer are the same as those of the wrapped RNN layer.</source>
          <target state="translated">이 계층의 호출 인수는 랩핑 된 RNN 계층의 호출 인수와 동일합니다.</target>
        </trans-unit>
        <trans-unit id="d95f69aee0e146ccee9411fd2276d3062c98c22d" translate="yes" xml:space="preserve">
          <source>The call arguments for this layer are the same as those of the wrapped RNN layer. Beware that when passing the &lt;code&gt;initial_state&lt;/code&gt; argument during the call of this layer, the first half in the list of elements in the &lt;code&gt;initial_state&lt;/code&gt; list will be passed to the forward RNN call and the last half in the list of elements will be passed to the backward RNN call.</source>
          <target state="translated">The call arguments for this layer are the same as those of the wrapped RNN layer. Beware that when passing the &lt;code&gt;initial_state&lt;/code&gt; argument during the call of this layer, the first half in the list of elements in the &lt;code&gt;initial_state&lt;/code&gt; list will be passed to the forward RNN call and the last half in the list of elements will be passed to the backward RNN call.</target>
        </trans-unit>
        <trans-unit id="3de2a1c81ff025749f22e62594b5197eb7231958" translate="yes" xml:space="preserve">
          <source>The callable taking two arguments and an optional msg= argument that raises self.failureException with a useful error message when the two arguments are not equal.</source>
          <target state="translated">The callable taking two arguments and an optional msg= argument that raises self.failureException with a useful error message when the two arguments are not equal.</target>
        </trans-unit>
        <trans-unit id="82b53f2208b8142725b57f3ebcfebf74479c1fc5" translate="yes" xml:space="preserve">
          <source>The callable to be performed if pred is false.</source>
          <target state="translated">The callable to be performed if pred is false.</target>
        </trans-unit>
        <trans-unit id="85b417d9584c69781a88c04ac220da15b4ffef62" translate="yes" xml:space="preserve">
          <source>The callable to be performed if pred is true.</source>
          <target state="translated">The callable to be performed if pred is true.</target>
        </trans-unit>
        <trans-unit id="6882837a3f25aad358b428438ef5466b3477a237" translate="yes" xml:space="preserve">
          <source>The callable to be performed.</source>
          <target state="translated">The callable to be performed.</target>
        </trans-unit>
        <trans-unit id="2d4c459c8aeff7109ccacc7811c716196afbf950" translate="yes" xml:space="preserve">
          <source>The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt;, and returns a possibly nested structure of Tensors and Operations, which may be different than the structure of &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="translated">The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt; , and returns a possibly nested structure of Tensors and Operations, which may be different than the structure of &lt;code&gt;elems&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f567f5385cd69b7cfcbd75d2a67b18740363cbef" translate="yes" xml:space="preserve">
          <source>The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt;. Its output must have the same structure as &lt;code&gt;fn_output_signature&lt;/code&gt; if one is provided; otherwise it must have the same structure as &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="translated">The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt; . Its output must have the same structure as &lt;code&gt;fn_output_signature&lt;/code&gt; if one is provided; otherwise it must have the same structure as &lt;code&gt;elems&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6fad8c402c4ad4c03ff5742a4c9d67125becbdeb" translate="yes" xml:space="preserve">
          <source>The callable to be performed. It accepts two arguments. The first will have the same structure as &lt;code&gt;initializer&lt;/code&gt; if one is provided, otherwise it will have the same structure as &lt;code&gt;elems&lt;/code&gt;. The second will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt;. Its output must have the same structure as &lt;code&gt;initializer&lt;/code&gt; if one is provided, otherwise it must have the same structure as &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="translated">The callable to be performed. It accepts two arguments. The first will have the same structure as &lt;code&gt;initializer&lt;/code&gt; if one is provided, otherwise it will have the same structure as &lt;code&gt;elems&lt;/code&gt; . The second will have the same (possibly nested) structure as &lt;code&gt;elems&lt;/code&gt; . Its output must have the same structure as &lt;code&gt;initializer&lt;/code&gt; if one is provided, otherwise it must have the same structure as &lt;code&gt;elems&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0f42894533083db2f0bd479a307d6b9de88ad2ac" translate="yes" xml:space="preserve">
          <source>The casting only occurs in TensorFlow 2, but can be enabled if &lt;a href=&quot;../../../compat/v1/disable_v2_behavior&quot;&gt;&lt;code&gt;tf.compat.v1.disable_v2_behavior()&lt;/code&gt;&lt;/a&gt; has been called with &lt;a href=&quot;../../../compat/v1/keras/layers/enable_v2_dtype_behavior&quot;&gt;&lt;code&gt;tf.compat.v1.keras.layers.enable_v2_dtype_behavior()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The casting only occurs in TensorFlow 2, but can be enabled if &lt;a href=&quot;../../../compat/v1/disable_v2_behavior&quot;&gt; &lt;code&gt;tf.compat.v1.disable_v2_behavior()&lt;/code&gt; &lt;/a&gt; has been called with &lt;a href=&quot;../../../compat/v1/keras/layers/enable_v2_dtype_behavior&quot;&gt; &lt;code&gt;tf.compat.v1.keras.layers.enable_v2_dtype_behavior()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="d65e2fd04371734d652468cc491b0cee4ff69e4f" translate="yes" xml:space="preserve">
          <source>The centered RMSProp algorithm uses an estimate of the centered second moment (i.e., the variance) for normalization, as opposed to regular RMSProp, which uses the (uncentered) second moment. This often helps with training, but is slightly more expensive in terms of computation and memory.</source>
          <target state="translated">The centered RMSProp algorithm uses an estimate of the centered second moment (i.e., the variance) for normalization, as opposed to regular RMSProp, which uses the (uncentered) second moment. This often helps with training, but is slightly more expensive in terms of computation and memory.</target>
        </trans-unit>
        <trans-unit id="33fbe725d21fc4d2840623043975b6cc7b98b5de" translate="yes" xml:space="preserve">
          <source>The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance.</source>
          <target state="translated">The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance.</target>
        </trans-unit>
        <trans-unit id="e327ae814821b8183785f0c019aba0430d092c8e" translate="yes" xml:space="preserve">
          <source>The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance:</source>
          <target state="translated">가운데 버전은 그라디언트의 이동 평균을 추가로 유지하고 해당 평균을 사용하여 분산을 추정합니다.</target>
        </trans-unit>
        <trans-unit id="bfef6db15137d8681f7bb35f6eac52b4909761b8" translate="yes" xml:space="preserve">
          <source>The character codepoints for all strings are returned using a single vector &lt;code&gt;char_values&lt;/code&gt;, with strings expanded to characters in row-major order.</source>
          <target state="translated">The character codepoints for all strings are returned using a single vector &lt;code&gt;char_values&lt;/code&gt; , with strings expanded to characters in row-major order.</target>
        </trans-unit>
        <trans-unit id="fa3eb72957dbe620013c33a95407b9be5d104b9f" translate="yes" xml:space="preserve">
          <source>The character codepoints for all strings are returned using a single vector &lt;code&gt;char_values&lt;/code&gt;, with strings expanded to characters in row-major order. Similarly, the character start byte offsets are returned using a single vector &lt;code&gt;char_to_byte_starts&lt;/code&gt;, with strings expanded in row-major order.</source>
          <target state="translated">The character codepoints for all strings are returned using a single vector &lt;code&gt;char_values&lt;/code&gt; , with strings expanded to characters in row-major order. Similarly, the character start byte offsets are returned using a single vector &lt;code&gt;char_to_byte_starts&lt;/code&gt; , with strings expanded in row-major order.</target>
        </trans-unit>
        <trans-unit id="c31a51be422fab4cffa6c991deea2add3c6021c8" translate="yes" xml:space="preserve">
          <source>The check occurs when iterating over the contents of the dataset, which means that the check happens &lt;em&gt;after&lt;/em&gt; any static optimizations are applied to the dataset graph.</source>
          <target state="translated">The check occurs when iterating over the contents of the dataset, which means that the check happens &lt;em&gt;after&lt;/em&gt; any static optimizations are applied to the dataset graph.</target>
        </trans-unit>
        <trans-unit id="cde4b2ea69bdd9358c33f59eb179d46a7db32c3c" translate="yes" xml:space="preserve">
          <source>The checkpoint file.</source>
          <target state="translated">The checkpoint file.</target>
        </trans-unit>
        <trans-unit id="ffd9bc04f2dc35c549a84231faac7f8f675d1f25" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;../../../train/checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;../../../train/checkpoint#write&quot;&gt; &lt;code&gt;Checkpoint.write()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="efb4974f19ee7156bcbc2c149c6eb12fbb9c2851" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;checkpoint#write&quot;&gt; &lt;code&gt;Checkpoint.write()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="38c24ccd874623d2c0df0fab88b6eb678631c447" translate="yes" xml:space="preserve">
          <source>The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#write&quot;&gt;&lt;code&gt;Checkpoint.write()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">The checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#write&quot;&gt; &lt;code&gt;Checkpoint.write()&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="ca19bcae5c51ffa24942d83670cdc3ac1b84f4ae" translate="yes" xml:space="preserve">
          <source>The checkpoint path to export.</source>
          <target state="translated">The checkpoint path to export.</target>
        </trans-unit>
        <trans-unit id="5dfa3f47f142cfb8c822aafba714441dd881e206" translate="yes" xml:space="preserve">
          <source>The checkpoint path to export. If &lt;code&gt;None&lt;/code&gt; (the default), the most recent checkpoint found within the model directory is chosen.</source>
          <target state="translated">The checkpoint path to export. If &lt;code&gt;None&lt;/code&gt; (the default), the most recent checkpoint found within the model directory is chosen.</target>
        </trans-unit>
        <trans-unit id="3cf3d251f72fdb454086ef22c80d6dfc9f2a709b" translate="yes" xml:space="preserve">
          <source>The checkpoint prefix. If there are no checkpoints, returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">검사 점 접두사 검사 점이 없으면 &lt;code&gt;None&lt;/code&gt; 을 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="2b84dcebdb9409917518369da2c415dffacda85b" translate="yes" xml:space="preserve">
          <source>The class dimension. Defaulted to -1 which is the last dimension.</source>
          <target state="translated">The class dimension. Defaulted to -1 which is the last dimension.</target>
        </trans-unit>
        <trans-unit id="54c52716619b24d86f051441e79e67309f282670" translate="yes" xml:space="preserve">
          <source>The class specifies the parameters to configure a &lt;a href=&quot;physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; as it is initialized to a &lt;a href=&quot;logicaldevice&quot;&gt;&lt;code&gt;tf.config.LogicalDevice&lt;/code&gt;&lt;/a&gt; during runtime initialization. Not all fields are valid for all device types.</source>
          <target state="translated">이 클래스 는 런타임 초기화 중에 &lt;a href=&quot;physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; &lt;/a&gt; 로 초기화 될 때 &lt;a href=&quot;logicaldevice&quot;&gt; &lt;code&gt;tf.config.LogicalDevice&lt;/code&gt; &lt;/a&gt; 를 구성하기위한 매개 변수를 지정합니다 . 모든 필드가 모든 장치 유형에 유효한 것은 아닙니다.</target>
        </trans-unit>
        <trans-unit id="8cadabc814bf5f30961f39db7a416141d019058e" translate="yes" xml:space="preserve">
          <source>The class uses optional peep-hole connections, optional cell clipping, and an optional projection layer.</source>
          <target state="translated">이 클래스는 선택적인 구멍 연결, 선택적인 셀 클리핑 및 선택적인 투영 레이어를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="a5550331649ac8852e50082985bc4347ae4ddf34" translate="yes" xml:space="preserve">
          <source>The classes &lt;code&gt;Tensor&lt;/code&gt; must provide string labels, not integer class IDs.</source>
          <target state="translated">클래스 &lt;code&gt;Tensor&lt;/code&gt; 는 정수 클래스 ID가 아닌 문자열 레이블을 제공해야합니다.</target>
        </trans-unit>
        <trans-unit id="69874b3cb85190e4e3a8170c5f59a6adad260ddf" translate="yes" xml:space="preserve">
          <source>The column name containing the example ids.</source>
          <target state="translated">The column name containing the example ids.</target>
        </trans-unit>
        <trans-unit id="11021faea4863b89bafde61f7853da18c9740ef5" translate="yes" xml:space="preserve">
          <source>The communication protocol, such as &lt;code&gt;&quot;grpc&quot;&lt;/code&gt;. If unspecified, will use the default from &lt;code&gt;python/platform/remote_utils.py&lt;/code&gt;.</source>
          <target state="translated">The communication protocol, such as &lt;code&gt;&quot;grpc&quot;&lt;/code&gt; . If unspecified, will use the default from &lt;code&gt;python/platform/remote_utils.py&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8055f38c5a2a613d3b7898156485e396610a7e44" translate="yes" xml:space="preserve">
          <source>The companion method &lt;code&gt;start_queue_runners()&lt;/code&gt; can be used to start threads for all the collected queue runners.</source>
          <target state="translated">컴패니언 메소드 &lt;code&gt;start_queue_runners()&lt;/code&gt; 를 사용하여 수집 된 모든 큐 러너의 스레드를 시작할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="97a9b8c4557a2e822deec22848a2c3bf8b143002" translate="yes" xml:space="preserve">
          <source>The compatibility module also provides the following aliases for common sets of python types:</source>
          <target state="translated">호환성 모듈은 일반적인 파이썬 유형 집합에 대해 다음과 같은 별칭을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="c76eb8b972301e83c208f809121c80f183543a3c" translate="yes" xml:space="preserve">
          <source>The compatibility relation is reflexive and symmetric, but not transitive. For example, TensorShape([32, 784]) is compatible with TensorShape(None), and TensorShape(None) is compatible with TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with TensorShape([4, 4]).</source>
          <target state="translated">호환성 관계는 반사적이고 대칭이지만 전이는 아닙니다. 예를 들어, TensorShape ([32, 784])는 TensorShape (None)과 호환되고 TensorShape (None)은 TensorShape ([4, 4])와 호환되지만 TensorShape ([32, 784])는 TensorShape와 호환되지 않습니다 ([4, 4]).</target>
        </trans-unit>
        <trans-unit id="bc1fe8d57fc26b638818429d0e0fce300365e0f7" translate="yes" xml:space="preserve">
          <source>The compilation flags.</source>
          <target state="translated">컴파일 플래그.</target>
        </trans-unit>
        <trans-unit id="004ddc3feaeb4999946bd055243271e6c1c5e458" translate="yes" xml:space="preserve">
          <source>The compilation is a hint and only supported on a best-effort basis.</source>
          <target state="translated">컴파일은 힌트이며 최선의 노력으로 만 지원됩니다.</target>
        </trans-unit>
        <trans-unit id="2a97fc9aeef3aac0ee7b0d6fc3913b5f131a8ce4" translate="yes" xml:space="preserve">
          <source>The complex conjugate returned by this operation is of the form \(a - bj\).</source>
          <target state="translated">이 오퍼레이션에 의해 리턴되는 켤레 복소수는 \ (a-bj \) 형식입니다.</target>
        </trans-unit>
        <trans-unit id="c2a070804637f1f7cd7f3478e19c13e4ff6876a9" translate="yes" xml:space="preserve">
          <source>The components input has k elements, which correspond to the components of tuples stored in the given queue.</source>
          <target state="translated">The components input has k elements, which correspond to the components of tuples stored in the given queue.</target>
        </trans-unit>
        <trans-unit id="9f00bf6687c043d2091a7a6b17f2dcc072382a50" translate="yes" xml:space="preserve">
          <source>The components of the resulting element will have an additional outer dimension, which will be &lt;code&gt;batch_size&lt;/code&gt; (or &lt;code&gt;N % batch_size&lt;/code&gt; for the last element if &lt;code&gt;batch_size&lt;/code&gt; does not divide the number of input elements &lt;code&gt;N&lt;/code&gt; evenly and &lt;code&gt;drop_remainder&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;). If your program depends on the batches having the same outer dimension, you should set the &lt;code&gt;drop_remainder&lt;/code&gt; argument to &lt;code&gt;True&lt;/code&gt; to prevent the smaller batch from being produced.</source>
          <target state="translated">결과 요소의 구성 요소에는 추가 외부 치수가 있습니다. 이는 &lt;code&gt;batch_size&lt;/code&gt; 입니다 (또는 &lt;code&gt;batch_size&lt;/code&gt; 가 입력 요소 수 &lt;code&gt;N&lt;/code&gt; 을 균등하게 &lt;code&gt;drop_remainder&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 인 경우 마지막 요소에 대한 &lt;code&gt;N % batch_size&lt;/code&gt; 입니다 ). 프로그램이 외부 치수가 동일한 배치에 의존 하는 경우 더 작은 배치가 생성되지 않도록 &lt;code&gt;drop_remainder&lt;/code&gt; 인수를 &lt;code&gt;True&lt;/code&gt; 로 설정해야합니다 .</target>
        </trans-unit>
        <trans-unit id="344c73fb9ddb71179637f498f0b34262b87c80b8" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy, or None if the compute dtype should be inferred from the inputs.</source>
          <target state="translated">이 정책의 계산 dtype 또는 입력에서 계산 dtype을 유추해야하는 경우 None입니다.</target>
        </trans-unit>
        <trans-unit id="205f439cb062a6f6e02604aa48a1bdc6926c8224" translate="yes" xml:space="preserve">
          <source>The compute dtype of this policy.</source>
          <target state="translated">이 정책의 계산 dtype입니다.</target>
        </trans-unit>
        <trans-unit id="e48ef827cb89494677d2274efaf5e966b8a2acf1" translate="yes" xml:space="preserve">
          <source>The computed norms with the same shape and dtype &lt;code&gt;tensor&lt;/code&gt; but the final axis is 1 instead. Same as running &lt;code&gt;tf.cast(tf.linalg.norm(tensor, ord, axis keepdims=True), tensor.dtype)&lt;/code&gt;.</source>
          <target state="translated">The computed norms with the same shape and dtype &lt;code&gt;tensor&lt;/code&gt; but the final axis is 1 instead. Same as running &lt;code&gt;tf.cast(tf.linalg.norm(tensor, ord, axis keepdims=True), tensor.dtype)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4a56e1ae6d24fcbef9729431047071ed9efb2c36" translate="yes" xml:space="preserve">
          <source>The concatenated rows for this ragged tensor.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 연결된 행입니다.</target>
        </trans-unit>
        <trans-unit id="2e975fea798f7bc222374c880c42a36989a17b66" translate="yes" xml:space="preserve">
          <source>The concatenated values for all rows in this tensor.</source>
          <target state="translated">이 텐서의 모든 행에 연결된 값입니다.</target>
        </trans-unit>
        <trans-unit id="853436dd51ebd4a92a981ee25b9140e01e3a8cb8" translate="yes" xml:space="preserve">
          <source>The concatenation of the lists trainable_weights and non_trainable_weights (in this order).</source>
          <target state="translated">The concatenation of the lists trainable_weights and non_trainable_weights (in this order).</target>
        </trans-unit>
        <trans-unit id="0f6fe2c98e185c3c57a927e557bcc1cd36a6a7d8" translate="yes" xml:space="preserve">
          <source>The concentration parameters represent mean total counts of a &lt;code&gt;1&lt;/code&gt; or a &lt;code&gt;0&lt;/code&gt;, i.e.,</source>
          <target state="translated">농도 파라미터는 &lt;code&gt;1&lt;/code&gt; 또는 &lt;code&gt;0&lt;/code&gt; 의 평균 총 카운트 , 즉</target>
        </trans-unit>
        <trans-unit id="8b33c64ef5a9a221894d1d8c3eff40c36b6dadba" translate="yes" xml:space="preserve">
          <source>The condition to evaluate.</source>
          <target state="translated">The condition to evaluate.</target>
        </trans-unit>
        <trans-unit id="b10cf771707704e5f421193cabc5bea06bcefd0e" translate="yes" xml:space="preserve">
          <source>The config of a layer does not include connectivity information, nor the layer class name. These are handled by &lt;code&gt;Network&lt;/code&gt; (one layer of abstraction above).</source>
          <target state="translated">계층 구성에는 연결 정보 나 계층 클래스 이름이 포함되지 않습니다. 이것들은 &lt;code&gt;Network&lt;/code&gt; (위의 추상화 계층)에 의해 처리됩니다 .</target>
        </trans-unit>
        <trans-unit id="8880562899c802327a9dcd3decd4ce5b9c9c4257" translate="yes" xml:space="preserve">
          <source>The configuration object.</source>
          <target state="translated">The configuration object.</target>
        </trans-unit>
        <trans-unit id="2e6cabe853a86fe4b25fb9e66ffa23b7c23ff8a8" translate="yes" xml:space="preserve">
          <source>The constraint function that was passed to the variable constructor. Can be &lt;code&gt;None&lt;/code&gt; if no constraint was passed.</source>
          <target state="translated">변수 생성자로 전달 된 제한 조건 함수입니다. 제한 조건이 전달되지 않은 경우 &lt;code&gt;None&lt;/code&gt; 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="c73cc83e59c2cc8b75ad073ccf807211d4803200" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value.</source>
          <target state="translated">제한 조건은 플래그가 처음 구문 분석 될 때 및 해당 플래그 값이 변경 될 때마다 유효성이 검증됩니다.</target>
        </trans-unit>
        <trans-unit id="adc492d7eedfc240429addc422d2a1187a94cf41" translate="yes" xml:space="preserve">
          <source>The constraint is validated when flags are initially parsed, and after each change of the corresponding flag's value. Args: flag_name: str, name of the flag to be checked. checker: callable, a function to validate the flag. input - A single positional argument: The value of the corresponding flag (string, boolean, etc. This value will be passed to checker by the library). output - bool, True if validator constraint is satisfied. If constraint is not satisfied, it should either return False or raise flags.ValidationError(desired_error_message). message: str, error text to be shown to the user if checker returns False. If checker raises flags.ValidationError, message from the raised error will be shown. flag_values: flags.FlagValues, optional FlagValues instance to validate against. Raises: AttributeError: Raised when flag_name is not registered as a valid flag name.</source>
          <target state="translated">제한 조건은 플래그가 처음 구문 분석 될 때 및 해당 플래그 값이 변경 될 때마다 유효성이 검증됩니다. Args : flag_name : str, 검사 할 플래그 이름. 검사기 : 호출 가능, 플래그를 검증하는 함수. input-단일 위치 인수 : 해당 플래그의 값 (문자열, 부울 등).이 값은 라이브러리에 의해 검사기로 전달됩니다. output-bool, 유효성 검사기 제약 조건이 충족되면 True입니다. 제약 조건이 충족되지 않으면 False를 반환하거나 플래그를 발생시켜야합니다 .ValidationError (desired_error_message). 메시지 : str, 검사기가 False를 반환하면 사용자에게 표시되는 오류 텍스트입니다. 검사기가 flags.ValidationError를 발생 시키면 발생한 오류의 메시지가 표시됩니다. flag_values ​​: flags.FlagValues, 검증 할 선택적 FlagValues ​​인스턴스. 발생합니다 : AttributeError :flag_name이 유효한 플래그 이름으로 등록되지 않은 경우 발생합니다.</target>
        </trans-unit>
        <trans-unit id="4dc698ae175b05a09fb4ee349bbc6ecaa1e8c775" translate="yes" xml:space="preserve">
          <source>The constructor adds ops to save and restore variables.</source>
          <target state="translated">생성자는 변수를 저장하고 복원하기 위해 op를 추가합니다.</target>
        </trans-unit>
        <trans-unit id="a67ba085bb1cb054e5519f5de4ec3d7a1afd97f0" translate="yes" xml:space="preserve">
          <source>The container string to use in the context.</source>
          <target state="translated">The container string to use in the context.</target>
        </trans-unit>
        <trans-unit id="88bfee8d69b86f8c88e1a6cd1fbfe637af690d6d" translate="yes" xml:space="preserve">
          <source>The container the flag is registered to.</source>
          <target state="translated">The container the flag is registered to.</target>
        </trans-unit>
        <trans-unit id="65be7a0d51d3df0c44e8373ef2d8cce6fba1ba7f" translate="yes" xml:space="preserve">
          <source>The contents of that resource.</source>
          <target state="translated">해당 자원의 내용</target>
        </trans-unit>
        <trans-unit id="62b621910705576177d148ac0a9d7924f1417008" translate="yes" xml:space="preserve">
          <source>The context in which the attribute child_name is to be changed.</source>
          <target state="translated">The context in which the attribute child_name is to be changed.</target>
        </trans-unit>
        <trans-unit id="b796712e9d45d917e86f476afcbd17188df9e41f" translate="yes" xml:space="preserve">
          <source>The context manager is typically used as follows:</source>
          <target state="translated">컨텍스트 관리자는 일반적으로 다음과 같이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="b4d7d6dd724445c75543c5c53e6ef9742d69f23b" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the exception as the 'exception' attribute. This allows you to inspect the exception after the assertion::</source>
          <target state="translated">컨텍스트 관리자는 예외에 대한 참조를 '예외'속성으로 유지합니다. 이를 통해 어설 션 후 예외를 검사 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b36c5f83db5c2031ce81fe755689bacbd226c222" translate="yes" xml:space="preserve">
          <source>The context manager keeps a reference to the first matching warning as the 'warning' attribute; similarly, the 'filename' and 'lineno' attributes give you information about the line of Python code from which the warning was triggered. This allows you to inspect the warning after the assertion::</source>
          <target state="translated">컨텍스트 관리자는 첫 번째 일치 경고를 '경고'속성으로 유지합니다. 마찬가지로 'filename'및 'lineno'속성은 경고가 트리거 된 Python 코드 라인에 대한 정보를 제공합니다. 이를 통해 어설 션 후 경고를 검사 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="4baa6600f582743434abf2183d3229add8562932" translate="yes" xml:space="preserve">
          <source>The context manager to enter.</source>
          <target state="translated">The context manager to enter.</target>
        </trans-unit>
        <trans-unit id="39b31dd33d6410a26fac94ed5cf60c3b73346aa3" translate="yes" xml:space="preserve">
          <source>The continual decay of learning rates throughout training</source>
          <target state="translated">The continual decay of learning rates throughout training</target>
        </trans-unit>
        <trans-unit id="3eb98e6489cd882c0c18e1586be464efd5024b02" translate="yes" xml:space="preserve">
          <source>The contracted &lt;code&gt;Tensor&lt;/code&gt;, with shape determined by &lt;code&gt;equation&lt;/code&gt;.</source>
          <target state="translated">계약 &lt;code&gt;Tensor&lt;/code&gt; 와 형상에 의해 결정 &lt;code&gt;equation&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="db43655e2d0d002f7fe5b43dfac52f092c80941c" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image or images.</source>
          <target state="translated">대비 조정 된 이미지입니다.</target>
        </trans-unit>
        <trans-unit id="d7ed10745c14b330776ee5fc3a5ec88c5d4b915d" translate="yes" xml:space="preserve">
          <source>The contrast-adjusted image(s).</source>
          <target state="translated">대비 조정 된 이미지.</target>
        </trans-unit>
        <trans-unit id="b873b8e81b36897bcb81b13c24b9d9584a21302b" translate="yes" xml:space="preserve">
          <source>The convenience function &lt;a href=&quot;../../image/resize&quot;&gt;&lt;code&gt;tf.image.resize&lt;/code&gt;&lt;/a&gt; supports both 4-D and 3-D tensors as input and output. 4-D tensors are for batches of images, 3-D tensors for individual images.</source>
          <target state="translated">The convenience function &lt;a href=&quot;../../image/resize&quot;&gt; &lt;code&gt;tf.image.resize&lt;/code&gt; &lt;/a&gt; supports both 4-D and 3-D tensors as input and output. 4-D tensors are for batches of images, 3-D tensors for individual images.</target>
        </trans-unit>
        <trans-unit id="c1ead59666a162707f70c2bb42eccfd78a56d994" translate="yes" xml:space="preserve">
          <source>The convenience function &lt;a href=&quot;image/resize&quot;&gt;&lt;code&gt;tf.image.resize&lt;/code&gt;&lt;/a&gt; supports both 4-D and 3-D tensors as input and output. 4-D tensors are for batches of images, 3-D tensors for individual images.</source>
          <target state="translated">The convenience function &lt;a href=&quot;image/resize&quot;&gt; &lt;code&gt;tf.image.resize&lt;/code&gt; &lt;/a&gt; supports both 4-D and 3-D tensors as input and output. 4-D tensors are for batches of images, 3-D tensors for individual images.</target>
        </trans-unit>
        <trans-unit id="14bfe517dc85759a813f2eb60977041c4d4420dc" translate="yes" xml:space="preserve">
          <source>The conversion function may return &lt;code&gt;NotImplemented&lt;/code&gt; for some inputs. In this case, the conversion process will continue to try subsequent conversion functions.</source>
          <target state="translated">변환 함수는 일부 입력에 대해 &lt;code&gt;NotImplemented&lt;/code&gt; 를 반환 할 수 있습니다 . 이 경우 변환 프로세스는 계속해서 후속 변환 기능을 시도합니다.</target>
        </trans-unit>
        <trans-unit id="993593e7b0bd02f95abe229cbbe58be1069a603a" translate="yes" xml:space="preserve">
          <source>The conversion function must have the following signature:</source>
          <target state="translated">변환 함수에는 다음 서명이 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="62c1d16c5d29bf1d22b745f14080c7842854b090" translate="yes" xml:space="preserve">
          <source>The conversion rules are as follows:</source>
          <target state="translated">변환 규칙은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="e10ca4df9812779b916afce6a1d1c3326adb544f" translate="yes" xml:space="preserve">
          <source>The converted code as string.</source>
          <target state="translated">문자열로 변환 된 코드입니다.</target>
        </trans-unit>
        <trans-unit id="1a4c4fcb504882f83a37ad22c73c28617ce613ed" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format.</source>
          <target state="translated">직렬화 된 형식으로 변환 된 데이터</target>
        </trans-unit>
        <trans-unit id="0f85bd8e5f77e08669b54d651dbd9c3373a46949" translate="yes" xml:space="preserve">
          <source>The converted data in serialized format. Either a TFLite Flatbuffer or a Graphviz graph depending on value in &lt;code&gt;output_format&lt;/code&gt;.</source>
          <target state="translated">직렬화 된 형식으로 변환 된 데이터 &lt;code&gt;output_format&lt;/code&gt; 의 값에 따라 TFLite Flatbuffer 또는 Graphviz 그래프 입니다.</target>
        </trans-unit>
        <trans-unit id="d1373b125f4cfa9b84ebc99ddf4f15c0c28515a5" translate="yes" xml:space="preserve">
          <source>The converted data. For example if TFLite was the destination, then this will be a tflite flatbuffer in a bytes array.</source>
          <target state="translated">변환 된 데이터 예를 들어 TFLite가 대상인 경우 바이트 배열의 tflite 플랫 버퍼가됩니다.</target>
        </trans-unit>
        <trans-unit id="60fb348ae8fb1997effd221344f7a9df143ed5c3" translate="yes" xml:space="preserve">
          <source>The converted grayscale image(s).</source>
          <target state="translated">변환 된 그레이 스케일 이미지.</target>
        </trans-unit>
        <trans-unit id="947c64ff75e26c329d08f9139c4ae882c26c7ee7" translate="yes" xml:space="preserve">
          <source>The copyright for Fashion-MNIST is held by Zalando SE. Fashion-MNIST is licensed under the &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE&quot;&gt;MIT license&lt;/a&gt;.</source>
          <target state="translated">Fashion-MNIST의 저작권은 Zalando SE가 보유합니다. Fashion-MNIST는 &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE&quot;&gt;MIT 라이센스에&lt;/a&gt; 따라 라이센스가 부여됩니다 .</target>
        </trans-unit>
        <trans-unit id="efcf46084087344d6f569da9f4649c1142f8c478" translate="yes" xml:space="preserve">
          <source>The core difference between the two APIs is that this function is a graph rewrite, and so it changes the graph to use mixed precision under the hood. You still build your graph in float32, and the graph rewrite will change certain ops to float16. The Keras mixed precision API directly builds the Keras Model using a mix of float16 and float32.</source>
          <target state="translated">The core difference between the two APIs is that this function is a graph rewrite, and so it changes the graph to use mixed precision under the hood. You still build your graph in float32, and the graph rewrite will change certain ops to float16. The Keras mixed precision API directly builds the Keras Model using a mix of float16 and float32.</target>
        </trans-unit>
        <trans-unit id="1800b9129135de634c28deac11e3c72d5b276b9a" translate="yes" xml:space="preserve">
          <source>The corresponding &lt;code&gt;equation&lt;/code&gt; is:</source>
          <target state="translated">해당 &lt;code&gt;equation&lt;/code&gt; 은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="d08fae5c7558eeecccf8b9086f7da5fad59afff7" translate="yes" xml:space="preserve">
          <source>The corresponding dense tensor satisfies:</source>
          <target state="translated">해당 조밀 한 텐서는 다음을 충족합니다.</target>
        </trans-unit>
        <trans-unit id="25e9a5d7d3994fde2a58974f329ed60d12e01398" translate="yes" xml:space="preserve">
          <source>The covariance between elements in a batch is defined as:</source>
          <target state="translated">배치에서 요소 간 공분산은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="3f7c01ee2660f457c23437a997e09405b750c261" translate="yes" xml:space="preserve">
          <source>The covariance for each batch member is defined as the following:</source>
          <target state="translated">각 배치 구성원의 공분산은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="ab3d07f930a48f37a430eaef5bc7e0c838a99b3b" translate="yes" xml:space="preserve">
          <source>The created &lt;a href=&quot;../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">생성 된 &lt;a href=&quot;../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bf06fef8a51d3d2222f888311b63cf162081ff33" translate="yes" xml:space="preserve">
          <source>The created Operation.</source>
          <target state="translated">생성 된 작업입니다.</target>
        </trans-unit>
        <trans-unit id="bf8da6d42e9abc38af87cab58b26796f2a78e3eb" translate="yes" xml:space="preserve">
          <source>The created or existing &lt;code&gt;Variable&lt;/code&gt; (or &lt;code&gt;PartitionedVariable&lt;/code&gt;, if a partitioner was used).</source>
          <target state="translated">생성되었거나 기존 &lt;code&gt;Variable&lt;/code&gt; (또는 &lt;code&gt;PartitionedVariable&lt;/code&gt; 사용 된 경우 PartitionedVariable )</target>
        </trans-unit>
        <trans-unit id="703c3b3c61be2bbfe2cef58610e4241c0cec208f" translate="yes" xml:space="preserve">
          <source>The created variable. Usually either a &lt;code&gt;Variable&lt;/code&gt; or &lt;code&gt;ResourceVariable&lt;/code&gt; instance. If &lt;code&gt;partitioner&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, a &lt;code&gt;PartitionedVariable&lt;/code&gt; instance is returned.</source>
          <target state="translated">생성 된 변수 일반적으로 &lt;code&gt;Variable&lt;/code&gt; 또는 &lt;code&gt;ResourceVariable&lt;/code&gt; 인스턴스입니다. 경우 &lt;code&gt;partitioner&lt;/code&gt; 되지 않습니다 &lt;code&gt;None&lt;/code&gt; 하는 &lt;code&gt;PartitionedVariable&lt;/code&gt; 인스턴스가 반환됩니다.</target>
        </trans-unit>
        <trans-unit id="a064f7a86a7da90002c28e35d9ae72e6f6639e8c" translate="yes" xml:space="preserve">
          <source>The creator is supposed to eventually call the next_creator to create a variable if it does want to create a variable and not call Variable or ResourceVariable directly. This helps make creators composable. A creator may choose to create multiple variables, return already existing variables, or simply register that a variable was created and defer to the next creators in line. Creators can also modify the keyword arguments seen by the next creators.</source>
          <target state="translated">변수 또는 ResourceVariable을 직접 호출하지 않고 변수를 작성하려는 경우 작성자는 변수를 작성하기 위해 next_creator를 호출해야합니다. 이렇게하면 제작자가 작곡 할 수 있습니다. 제작자는 여러 변수를 만들거나 기존 변수를 반환하거나 변수가 생성되었음을 등록하고 다음 작성자에게 줄을 지정할 수 있습니다. 제작자는 다음 제작자가 보는 키워드 인수를 수정할 수도 있습니다.</target>
        </trans-unit>
        <trans-unit id="caefb816a5bf9fa47c79fd26eae5407f9e0b0029" translate="yes" xml:space="preserve">
          <source>The cumulative density function (cdf) is,</source>
          <target state="translated">누적 밀도 함수 (cdf)는</target>
        </trans-unit>
        <trans-unit id="1e6cf6bfd84a9de01475c57535a86c638dabf3bb" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;replicacontext&quot;&gt;&lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt;&lt;/a&gt; object when in a replica context scope, else &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">현재 &lt;a href=&quot;replicacontext&quot;&gt; &lt;code&gt;tf.distribute.ReplicaContext&lt;/code&gt; 의&lt;/a&gt; 객체 때 복제 상황에 맞는 범위 내에서, 다른 &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f540e5e4425b87ae1543241ecadb7b9cf3701bab" translate="yes" xml:space="preserve">
          <source>The current &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">현재 &lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 객체.</target>
        </trans-unit>
        <trans-unit id="0e1e3663ead0f80d5379392c5fb54bbf32b5424f" translate="yes" xml:space="preserve">
          <source>The current implementation memmaps the tensor from a file.</source>
          <target state="translated">The current implementation memmaps the tensor from a file.</target>
        </trans-unit>
        <trans-unit id="7121b0671de74726a9379ae7d9c7f6f65ce0582e" translate="yes" xml:space="preserve">
          <source>The current scope, enabling or disabling compilation.</source>
          <target state="translated">컴파일을 활성화 또는 비활성화하는 현재 범위</target>
        </trans-unit>
        <trans-unit id="6bc15ae139d05655dd2c4e393854e2c5c2fbb9ce" translate="yes" xml:space="preserve">
          <source>The current step.</source>
          <target state="translated">The current step.</target>
        </trans-unit>
        <trans-unit id="d8745f63ae4946ac904ac85702804cdaabd80e53" translate="yes" xml:space="preserve">
          <source>The data format for input. Either &quot;NHWC&quot; (default) or &quot;NCHW&quot;.</source>
          <target state="translated">The data format for input. Either &quot;NHWC&quot; (default) or &quot;NCHW&quot;.</target>
        </trans-unit>
        <trans-unit id="e1197173f8eacaa8f59bfc457afa910117b2511e" translate="yes" xml:space="preserve">
          <source>The data format for x. Either &quot;NHWC&quot; (default) or &quot;NCHW&quot;.</source>
          <target state="translated">The data format for x. Either &quot;NHWC&quot; (default) or &quot;NCHW&quot;.</target>
        </trans-unit>
        <trans-unit id="62ecb5db83683dd3080a11272c27160c0ee495ee" translate="yes" xml:space="preserve">
          <source>The data to train on. It can be passed either as a tf.data Dataset, as a NumPy array, a string tensor, or as a list of texts.</source>
          <target state="translated">The data to train on. It can be passed either as a tf.data Dataset, as a NumPy array, a string tensor, or as a list of texts.</target>
        </trans-unit>
        <trans-unit id="eba17f1716c87ef57986eff77c3c1dd87e545657" translate="yes" xml:space="preserve">
          <source>The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array.</source>
          <target state="translated">The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array.</target>
        </trans-unit>
        <trans-unit id="050a7e1310c5296c653e9c4a8cdd359fd2123e3a" translate="yes" xml:space="preserve">
          <source>The data type expected by the input, as a string (&lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;...)</source>
          <target state="translated">The data type expected by the input, as a string ( &lt;code&gt;float32&lt;/code&gt; , &lt;code&gt;float64&lt;/code&gt; , &lt;code&gt;int32&lt;/code&gt; ...)</target>
        </trans-unit>
        <trans-unit id="02d8c288bbfe19ff5e3738bf18458a723f75bb21" translate="yes" xml:space="preserve">
          <source>The data type expected by the input. Default: &lt;code&gt;'float32'&lt;/code&gt;.</source>
          <target state="translated">The data type expected by the input. Default: &lt;code&gt;'float32'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bc1f2fe24c93178a0cdc99089b0070c826bc8e7a" translate="yes" xml:space="preserve">
          <source>The data type for the &lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="translated">The data type for the &lt;code&gt;RaggedTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cba4765f6f6eab73eaa37643a033ccaf9abbf020" translate="yes" xml:space="preserve">
          <source>The data type of the output tensor.</source>
          <target state="translated">The data type of the output tensor.</target>
        </trans-unit>
        <trans-unit id="f7dbd9f518a88378558ef3aa8f6e9b7c42f12504" translate="yes" xml:space="preserve">
          <source>The data type of this TensorArray.</source>
          <target state="translated">이 TensorArray의 데이터 유형입니다.</target>
        </trans-unit>
        <trans-unit id="5860939eea91c5f2bfc6092504ee0e23ca7c09b6" translate="yes" xml:space="preserve">
          <source>The data type to call this function on when both values are of the same type in assertEqual().</source>
          <target state="translated">The data type to call this function on when both values are of the same type in assertEqual().</target>
        </trans-unit>
        <trans-unit id="78041258434d725f1d8ee592df7ca0eb3e942ade" translate="yes" xml:space="preserve">
          <source>The data type to produce. Must be a floating point type.</source>
          <target state="translated">The data type to produce. Must be a floating point type.</target>
        </trans-unit>
        <trans-unit id="a7ba10f144cbc87647590b7009fafb20f1cb2173" translate="yes" xml:space="preserve">
          <source>The data will be looped over (in batches).</source>
          <target state="translated">데이터가 일괄 처리됩니다.</target>
        </trans-unit>
        <trans-unit id="79058d99313ceca7b802a44719e1215d8b01c4a7" translate="yes" xml:space="preserve">
          <source>The dataset produced by the &lt;code&gt;distribute&lt;/code&gt; transformation can be passed to Keras' &lt;a href=&quot;../../../keras/model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt; or Distribution Strategy's &lt;a href=&quot;../../../distribute/strategy#experimental_distribute_dataset&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset&lt;/code&gt;&lt;/a&gt; like any other &lt;a href=&quot;../../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;. We recommend setting a &lt;code&gt;job_name&lt;/code&gt; on the call to &lt;code&gt;distribute&lt;/code&gt; so that if there are multiple workers, they read data from the same job. Note that the autosharding normally performed by &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; will be disabled when setting a &lt;code&gt;job_name&lt;/code&gt;, since sharing the job already results in splitting data across the workers. When using a shared job, data will be dynamically balanced across workers, so that they reach end of input about the same time. This results in better worker utilization than with autosharding, where each worker processes an independent set of files, and some workers may run out of data earlier than others.</source>
          <target state="translated">The dataset produced by the &lt;code&gt;distribute&lt;/code&gt; transformation can be passed to Keras' &lt;a href=&quot;../../../keras/model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt; or Distribution Strategy's &lt;a href=&quot;../../../distribute/strategy#experimental_distribute_dataset&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset&lt;/code&gt; &lt;/a&gt; like any other &lt;a href=&quot;../../dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt;. We recommend setting a &lt;code&gt;job_name&lt;/code&gt; on the call to &lt;code&gt;distribute&lt;/code&gt; so that if there are multiple workers, they read data from the same job. Note that the autosharding normally performed by &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; will be disabled when setting a &lt;code&gt;job_name&lt;/code&gt; , since sharing the job already results in splitting data across the workers. When using a shared job, data will be dynamically balanced across workers, so that they reach end of input about the same time. This results in better worker utilization than with autosharding, where each worker processes an independent set of files, and some workers may run out of data earlier than others.</target>
        </trans-unit>
        <trans-unit id="c103aa56baa5c32c667b938b6ce2201d2873c73f" translate="yes" xml:space="preserve">
          <source>The dataset to save.</source>
          <target state="translated">The dataset to save.</target>
        </trans-unit>
        <trans-unit id="c7f912374554b917dc7b6ee9e848a59b9a0fe71e" translate="yes" xml:space="preserve">
          <source>The datatype of the gradients accumulated by this accumulator.</source>
          <target state="translated">이 누산기에 의해 누적 된 그래디언트의 데이터 유형입니다.</target>
        </trans-unit>
        <trans-unit id="a4e8811eed25239dbc70516d5c5274e75126f7f5" translate="yes" xml:space="preserve">
          <source>The debugging information is dumped to a directory on the file system specified as &lt;code&gt;dump_root&lt;/code&gt;.</source>
          <target state="translated">디버깅 정보는 &lt;code&gt;dump_root&lt;/code&gt; 로 지정된 파일 시스템의 디렉토리에 덤프됩니다 .</target>
        </trans-unit>
        <trans-unit id="af2ff91f6275afef5f274f54f89df6225cefc596" translate="yes" xml:space="preserve">
          <source>The decorated function will return the unbatched computation output Tensors.</source>
          <target state="translated">데코 레이팅 된 함수는 배치되지 않은 계산 출력 텐서를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="6284a54323a552b0a785e97eec39ef3920661508" translate="yes" xml:space="preserve">
          <source>The decorator argument &lt;code&gt;op_type&lt;/code&gt; is the string type of an operation. This corresponds to the &lt;code&gt;OpDef.name&lt;/code&gt; field for the proto that defines the operation.</source>
          <target state="translated">데코레이터 인수 &lt;code&gt;op_type&lt;/code&gt; 은 작업의 문자열 유형입니다. 이는 작업을 정의하는 프로토 타입 의 &lt;code&gt;OpDef.name&lt;/code&gt; 필드에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="f564553c5a97e5c3c841f380324c41f020971604" translate="yes" xml:space="preserve">
          <source>The decorator function must use &lt;code&gt;&amp;lt;decorator name&amp;gt;.__wrapped__&lt;/code&gt; instead of the wrapped function that is normally used:</source>
          <target state="translated">데코레이터 함수 는 일반적으로 사용되는 랩핑 된 함수 대신 &lt;code&gt;&amp;lt;decorator name&amp;gt;.__wrapped__&lt;/code&gt; 를 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="364632908db2fc42ec644ce9139f9d8cd2996dcc" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Graph&lt;/code&gt; being used in the current thread.</source>
          <target state="translated">현재 스레드에서 사용되는 기본 &lt;code&gt;Graph&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="d6131e418f0fe8f055f5c1a72e6a16e1545b1880" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;Session&lt;/code&gt; being used in the current thread.</source>
          <target state="translated">현재 스레드에서 사용중인 기본 &lt;code&gt;Session&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="1f66d887de726d32ad140fa1257a1df52151a3df" translate="yes" xml:space="preserve">
          <source>The default &lt;code&gt;atol&lt;/code&gt; and &lt;code&gt;rtol&lt;/code&gt; is &lt;code&gt;10 * eps&lt;/code&gt;, where &lt;code&gt;eps&lt;/code&gt; is the smallest representable positive number such that &lt;code&gt;1 + eps != 1&lt;/code&gt;. This is about &lt;code&gt;1.2e-6&lt;/code&gt; in &lt;code&gt;32bit&lt;/code&gt;, &lt;code&gt;2.22e-15&lt;/code&gt; in &lt;code&gt;64bit&lt;/code&gt;, and &lt;code&gt;0.00977&lt;/code&gt; in &lt;code&gt;16bit&lt;/code&gt;. See &lt;code&gt;numpy.finfo&lt;/code&gt;.</source>
          <target state="translated">기본 &lt;code&gt;atol&lt;/code&gt; 및 &lt;code&gt;rtol&lt;/code&gt; 은 &lt;code&gt;10 * eps&lt;/code&gt; . 여기서 &lt;code&gt;eps&lt;/code&gt; 는 &lt;code&gt;1 + eps != 1&lt;/code&gt; 과 같이 표시 가능한 가장 작은 양수 입니다. 이것은 관한 &lt;code&gt;1.2e-6&lt;/code&gt; 에서 &lt;code&gt;32bit&lt;/code&gt; , &lt;code&gt;2.22e-15&lt;/code&gt; 의 &lt;code&gt;64bit&lt;/code&gt; 및 &lt;code&gt;0.00977&lt;/code&gt; 에서 &lt;code&gt;16bit&lt;/code&gt; . &lt;code&gt;numpy.finfo&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="62dd8de847ac23e7ac8e6762e2b31102b93ee7ae" translate="yes" xml:space="preserve">
          <source>The default Scaffold local init op.</source>
          <target state="translated">기본 스캐 폴드 로컬 초기화 옵션입니다.</target>
        </trans-unit>
        <trans-unit id="d6e0519f99f3caed3a61af27ab387f572c9ce96e" translate="yes" xml:space="preserve">
          <source>The default dtype of variables created by &lt;a href=&quot;../../layers/layer#add_weight&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.add_weight&lt;/code&gt;&lt;/a&gt; is the layer's policy's variable dtype.</source>
          <target state="translated">The default dtype of variables created by &lt;a href=&quot;../../layers/layer#add_weight&quot;&gt; &lt;code&gt;tf.keras.layers.Layer.add_weight&lt;/code&gt; &lt;/a&gt; is the layer's policy's variable dtype.</target>
        </trans-unit>
        <trans-unit id="113557875e0d10c0495e5968c62aac634844babc" translate="yes" xml:space="preserve">
          <source>The default graph is a property of the current thread. If you create a new thread, and wish to use the default graph in that thread, you must explicitly add a &lt;code&gt;with g.as_default():&lt;/code&gt; in that thread's function.</source>
          <target state="translated">기본 그래프는 현재 스레드의 속성입니다. 새 스레드를 작성하고 해당 스레드에서 기본 그래프를 사용하려는 경우 해당 스레드 함수에서 &lt;code&gt;with g.as_default():&lt;/code&gt; 를 명시 적으로 추가해야합니다 .</target>
        </trans-unit>
        <trans-unit id="af54ef57315265afe23c10353375841fe5684e25" translate="yes" xml:space="preserve">
          <source>The default name to use if the &lt;code&gt;name&lt;/code&gt; argument is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">The default name to use if the &lt;code&gt;name&lt;/code&gt; argument is &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2836ebf9a61a1e040d248e87727142b11b48fa08" translate="yes" xml:space="preserve">
          <source>The default name to use if the &lt;code&gt;name_or_scope&lt;/code&gt; argument is &lt;code&gt;None&lt;/code&gt;, this name will be uniquified. If name_or_scope is provided it won't be used and therefore it is not required and can be None.</source>
          <target state="translated">The default name to use if the &lt;code&gt;name_or_scope&lt;/code&gt; argument is &lt;code&gt;None&lt;/code&gt; , this name will be uniquified. If name_or_scope is provided it won't be used and therefore it is not required and can be None.</target>
        </trans-unit>
        <trans-unit id="9102c8e082f516efb1ceffb5e0598d25f581124b" translate="yes" xml:space="preserve">
          <source>The default non-peephole implementation is based on (Gers et al., 1999). The peephole implementation is based on (Sak et al., 2014).</source>
          <target state="translated">The default non-peephole implementation is based on (Gers et al., 1999). The peephole implementation is based on (Sak et al., 2014).</target>
        </trans-unit>
        <trans-unit id="b3c4fe416ddd6e4cf097d426615758d9e0a2f0da" translate="yes" xml:space="preserve">
          <source>The default non-peephole implementation is based on:</source>
          <target state="translated">peepohole이 아닌 기본 구현은 다음을 기반으로합니다.</target>
        </trans-unit>
        <trans-unit id="b36d1ca5df94e6636114077cb6330c3dd4eb155f" translate="yes" xml:space="preserve">
          <source>The default type of the returned tensor is &lt;code&gt;'int32'&lt;/code&gt; to match TensorFlow's default.</source>
          <target state="translated">반환 된 텐서의 기본 유형은 &lt;code&gt;'int32'&lt;/code&gt; 이며 TensorFlow의 기본값과 일치합니다.</target>
        </trans-unit>
        <trans-unit id="9c204a6e1f3b1ac9d5e05754cf3c4c6bfcbf5ab6" translate="yes" xml:space="preserve">
          <source>The default value may be either a single value or an iterable of values. A single value is transformed into a single-item list of that value.</source>
          <target state="translated">기본값은 단일 값이거나 반복 가능한 값일 수 있습니다. 단일 값은 해당 값의 단일 항목 목록으로 변환됩니다.</target>
        </trans-unit>
        <trans-unit id="95591cde8a6af9f0d83c1cbffce3447430c66fd4" translate="yes" xml:space="preserve">
          <source>The default value of 1e-7 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since Adam uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="translated">The default value of 1e-7 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since Adam uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</target>
        </trans-unit>
        <trans-unit id="2676c22d8481d2093eb1222e6a62c6e07d9d33bd" translate="yes" xml:space="preserve">
          <source>The default value of 1e-7 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="translated">epsilon의 기본값 1e-7은 일반적으로 좋지 않습니다. 예를 들어 ImageNet에서 Inception 네트워크를 교육 할 때 현재 좋은 선택은 1.0 또는 0.1입니다. AdamOptimizer는 알고리즘 1의 공식이 아닌 Kingma 및 Ba 논문의 2.1 절 바로 앞의 공식을 사용하므로 여기서 언급 된 &quot;엡실론&quot;은 논문에서 &quot;엡실론 모자&quot;입니다.</target>
        </trans-unit>
        <trans-unit id="7dce55634f5d3cd5afd750385d4cb7a72c3b4e6e" translate="yes" xml:space="preserve">
          <source>The default value of 1e-8 for epsilon might not be a good default in general. For example, when training an Inception network on ImageNet a current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the formulation just before Section 2.1 of the Kingma and Ba paper rather than the formulation in Algorithm 1, the &quot;epsilon&quot; referred to here is &quot;epsilon hat&quot; in the paper.</source>
          <target state="translated">epsilon의 기본값 1e-8은 일반적으로 좋지 않습니다. 예를 들어 ImageNet에서 Inception 네트워크를 교육 할 때 현재 좋은 선택은 1.0 또는 0.1입니다. AdamOptimizer는 알고리즘 1의 공식이 아닌 Kingma 및 Ba 논문의 2.1 절 바로 앞의 공식을 사용하므로 여기서 언급 된 &quot;엡실론&quot;은 논문에서 &quot;엡실론 모자&quot;입니다.</target>
        </trans-unit>
        <trans-unit id="941c46320d31066669249101c341db7e0407ec86" translate="yes" xml:space="preserve">
          <source>The default value of the flag.</source>
          <target state="translated">The default value of the flag.</target>
        </trans-unit>
        <trans-unit id="615a8ce189d67deb5b00de2e039f587d13916340" translate="yes" xml:space="preserve">
          <source>The default value of the table.</source>
          <target state="translated">테이블의 기본값입니다.</target>
        </trans-unit>
        <trans-unit id="5db08c92a6a8c4d1a19b3993d9edfeea8416589f" translate="yes" xml:space="preserve">
          <source>The default_value will be broadcast to the output shape. After that, the values from the ragged tensor overwrite the default values. Note that the default_value must have less dimensions than the value.</source>
          <target state="translated">The default_value will be broadcast to the output shape. After that, the values from the ragged tensor overwrite the default values. Note that the default_value must have less dimensions than the value.</target>
        </trans-unit>
        <trans-unit id="89e2a62666c59169f6b3797f7e217d09c589a372" translate="yes" xml:space="preserve">
          <source>The delimiter to separate fields in a line.</source>
          <target state="translated">The delimiter to separate fields in a line.</target>
        </trans-unit>
        <trans-unit id="00a0e2bb4cc9be91006217ca3ee3c8c2cea06b3f" translate="yes" xml:space="preserve">
          <source>The dense shape of the &lt;code&gt;IndexedSlices&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; to allow any dense shape.</source>
          <target state="translated">The dense shape of the &lt;code&gt;IndexedSlices&lt;/code&gt; , or &lt;code&gt;None&lt;/code&gt; to allow any dense shape.</target>
        </trans-unit>
        <trans-unit id="afdbba2532bfdeb33e8af1bfa9b4559b2cf2e5ab" translate="yes" xml:space="preserve">
          <source>The dense shape of the &lt;code&gt;SparseTensor&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; to allow any dense shape.</source>
          <target state="translated">The dense shape of the &lt;code&gt;SparseTensor&lt;/code&gt; , or &lt;code&gt;None&lt;/code&gt; to allow any dense shape.</target>
        </trans-unit>
        <trans-unit id="becf28b4c84759149d018b04bb5b5bc5f4cec754" translate="yes" xml:space="preserve">
          <source>The dense tensor &lt;code&gt;b&lt;/code&gt; may be either a scalar; otherwise &lt;code&gt;a&lt;/code&gt; must be a rank-3 &lt;code&gt;SparseMatrix&lt;/code&gt;; in this case &lt;code&gt;b&lt;/code&gt; must be shaped &lt;code&gt;[batch_size, 1, 1]&lt;/code&gt; and the multiply operation broadcasts.</source>
          <target state="translated">The dense tensor &lt;code&gt;b&lt;/code&gt; may be either a scalar; otherwise &lt;code&gt;a&lt;/code&gt; must be a rank-3 &lt;code&gt;SparseMatrix&lt;/code&gt; ; in this case &lt;code&gt;b&lt;/code&gt; must be shaped &lt;code&gt;[batch_size, 1, 1]&lt;/code&gt; and the multiply operation broadcasts.</target>
        </trans-unit>
        <trans-unit id="726ed70f0dc33ddfe7a4cc805d63238531bb85eb" translate="yes" xml:space="preserve">
          <source>The dense tensor &lt;code&gt;dense&lt;/code&gt; represented by an &lt;code&gt;IndexedSlices&lt;/code&gt;&lt;code&gt;slices&lt;/code&gt; has</source>
          <target state="translated">&lt;code&gt;IndexedSlices&lt;/code&gt; &lt;code&gt;slices&lt;/code&gt; 표시되는 밀도 텐서 &lt;code&gt;dense&lt;/code&gt; 는</target>
        </trans-unit>
        <trans-unit id="4266ae52077c5b23e390601d308e04d84d60ebbe" translate="yes" xml:space="preserve">
          <source>The deprecated &quot;infer&quot; policy</source>
          <target state="translated">더 이상 사용되지 않는 &quot;추론&quot;정책</target>
        </trans-unit>
        <trans-unit id="47a704b6d6ba8a557d500ba37d0cbd25291c9ff6" translate="yes" xml:space="preserve">
          <source>The depth depends on profiling view. For 'scope' view, it's the depth of name scope hierarchy (tree), for 'op' view, it's the number of operation types (list), etc.</source>
          <target state="translated">깊이는 프로파일 링보기에 따라 다릅니다. '범위'보기의 경우 이름 범위 계층 구조 (트리)의 깊이이고 'op'보기의 경우 작업 유형 (목록)의 수 등입니다.</target>
        </trans-unit>
        <trans-unit id="2137c8c00ab29126bb362981cb4aca8aa9eecd42" translate="yes" xml:space="preserve">
          <source>The depth of the input tensor must be divisible by &lt;code&gt;block_size * block_size&lt;/code&gt;.</source>
          <target state="translated">입력 텐서의 깊이는 &lt;code&gt;block_size * block_size&lt;/code&gt; 로 나눌 수 있어야합니다 .</target>
        </trans-unit>
        <trans-unit id="856f925406c2e2660e650087c5e577d9ef121b34" translate="yes" xml:space="preserve">
          <source>The depth of the output tensor is &lt;code&gt;block_size * block_size * input_depth&lt;/code&gt;.</source>
          <target state="translated">출력 텐서의 깊이는 &lt;code&gt;block_size * block_size * input_depth&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="b3dbf4f851a379190dde773c74ad7ff19b84f6a4" translate="yes" xml:space="preserve">
          <source>The desired DType of the returned &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">The desired DType of the returned &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0745ef41dcfcf7dc3af6f9af5a9ea5d649093458" translate="yes" xml:space="preserve">
          <source>The desired output &lt;code&gt;DType&lt;/code&gt;.</source>
          <target state="translated">The desired output &lt;code&gt;DType&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aba8863b230b8558a7b0bbc35057be0011a2be11" translate="yes" xml:space="preserve">
          <source>The destination type. The list of supported dtypes is the same as &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">The destination type. The list of supported dtypes is the same as &lt;code&gt;x&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bcdbb419b80b09c56eaabe4016b06b5e0aa6fcbf" translate="yes" xml:space="preserve">
          <source>The device filters can be partically specified. For remote tasks that do not have device filters specified, all devices will be visible to them.</source>
          <target state="translated">The device filters can be partically specified. For remote tasks that do not have device filters specified, all devices will be visible to them.</target>
        </trans-unit>
        <trans-unit id="dfeda8f899a5e6b3bd48a82937d06ce834bf27e7" translate="yes" xml:space="preserve">
          <source>The device name or function to use in the context.</source>
          <target state="translated">The device name or function to use in the context.</target>
        </trans-unit>
        <trans-unit id="a06647ca6f050400b627e80f77759a71a57117ac" translate="yes" xml:space="preserve">
          <source>The device name to use in the context.</source>
          <target state="translated">The device name to use in the context.</target>
        </trans-unit>
        <trans-unit id="56afabb9b384a9ae87fad18ee9dbf3881d1ccc16" translate="yes" xml:space="preserve">
          <source>The device of this variable.</source>
          <target state="translated">이 변수의 장치.</target>
        </trans-unit>
        <trans-unit id="3225614cf1d4291df3f5e762921b470644535a9b" translate="yes" xml:space="preserve">
          <source>The device on which to run the embedding lookup. Valid options are &quot;cpu&quot;, &quot;tpu_tensor_core&quot;, and &quot;tpu_embedding_core&quot;. If specifying &quot;tpu_tensor_core&quot;, a tensor_core_shape must be supplied. Defaults to &quot;cpu&quot;. If not specified, the default behavior is embedding lookup on &quot;tpu_embedding_core&quot; for training and &quot;cpu&quot; for inference. Valid options for training : [&quot;tpu_embedding_core&quot;, &quot;tpu_tensor_core&quot;] Valid options for serving : [&quot;cpu&quot;, &quot;tpu_tensor_core&quot;] For training, tpu_embedding_core is good for large embedding vocab (&amp;gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck.</source>
          <target state="translated">The device on which to run the embedding lookup. Valid options are &quot;cpu&quot;, &quot;tpu_tensor_core&quot;, and &quot;tpu_embedding_core&quot;. If specifying &quot;tpu_tensor_core&quot;, a tensor_core_shape must be supplied. Defaults to &quot;cpu&quot;. If not specified, the default behavior is embedding lookup on &quot;tpu_embedding_core&quot; for training and &quot;cpu&quot; for inference. Valid options for training : [&quot;tpu_embedding_core&quot;, &quot;tpu_tensor_core&quot;] Valid options for serving : [&quot;cpu&quot;, &quot;tpu_tensor_core&quot;] For training, tpu_embedding_core is good for large embedding vocab (&amp;gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck.</target>
        </trans-unit>
        <trans-unit id="c44e9d347e5ccf542ed1c29e0c5e77c462ccf1ab" translate="yes" xml:space="preserve">
          <source>The device on which to run the embedding lookup. Valid options are &quot;cpu&quot;, &quot;tpu_tensor_core&quot;, and &quot;tpu_embedding_core&quot;. If specifying &quot;tpu_tensor_core&quot;, a tensor_core_shape must be supplied. If not specified, the default behavior is embedding lookup on &quot;tpu_embedding_core&quot; for training and &quot;cpu&quot; for inference. Valid options for training : [&quot;tpu_embedding_core&quot;, &quot;tpu_tensor_core&quot;] Valid options for serving : [&quot;cpu&quot;, &quot;tpu_tensor_core&quot;] For training, tpu_embedding_core is good for large embedding vocab (&amp;gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck.</source>
          <target state="translated">The device on which to run the embedding lookup. Valid options are &quot;cpu&quot;, &quot;tpu_tensor_core&quot;, and &quot;tpu_embedding_core&quot;. If specifying &quot;tpu_tensor_core&quot;, a tensor_core_shape must be supplied. If not specified, the default behavior is embedding lookup on &quot;tpu_embedding_core&quot; for training and &quot;cpu&quot; for inference. Valid options for training : [&quot;tpu_embedding_core&quot;, &quot;tpu_tensor_core&quot;] Valid options for serving : [&quot;cpu&quot;, &quot;tpu_tensor_core&quot;] For training, tpu_embedding_core is good for large embedding vocab (&amp;gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck.</target>
        </trans-unit>
        <trans-unit id="98f163e49909ba226b86dab21a009212ea93fb62" translate="yes" xml:space="preserve">
          <source>The device policy controls how operations requiring inputs on a specific device (e.g., on GPU:0) handle inputs on a different device (e.g. GPU:1).</source>
          <target state="translated">장치 정책은 특정 장치 (예 : GPU : 0)에서 입력이 필요한 작업이 다른 장치 (예 : GPU : 1)에서 입력을 처리하는 방법을 제어합니다.</target>
        </trans-unit>
        <trans-unit id="f251515ee7a7da78599205d7a6518a062a6c0f5e" translate="yes" xml:space="preserve">
          <source>The devices this replica is to be executed on, as a tuple of strings.</source>
          <target state="translated">이 복제본을 실행할 장치는 튜플 문자열입니다.</target>
        </trans-unit>
        <trans-unit id="87dd79764107968d1c698ee175a895a731232435" translate="yes" xml:space="preserve">
          <source>The difference between &lt;code&gt;stack&lt;/code&gt; and &lt;code&gt;parallel_stack&lt;/code&gt; is that &lt;code&gt;stack&lt;/code&gt; requires all the inputs be computed before the operation will begin but doesn't require that the input shapes be known during graph construction.</source>
          <target state="translated">차이 &lt;code&gt;stack&lt;/code&gt; 과 &lt;code&gt;parallel_stack&lt;/code&gt; 은 즉 &lt;code&gt;stack&lt;/code&gt; 동작을 시작하기 전에 모든 입력이 계산 될 필요하지만, 입력 도형을 그래프 구조 중에 공지 될 것을 요구하지 않는다.</target>
        </trans-unit>
        <trans-unit id="bcc3aba817880e065f4223ea3362fcfb9ea484b3" translate="yes" xml:space="preserve">
          <source>The difference between concat and parallel_concat is that concat requires all of the inputs be computed before the operation will begin but doesn't require that the input shapes be known during graph construction. Parallel concat will copy pieces of the input into the output as they become available, in some situations this can provide a performance benefit.</source>
          <target state="translated">The difference between concat and parallel_concat is that concat requires all of the inputs be computed before the operation will begin but doesn't require that the input shapes be known during graph construction. Parallel concat will copy pieces of the input into the output as they become available, in some situations this can provide a performance benefit.</target>
        </trans-unit>
        <trans-unit id="2969267833427bcd62d3db92c629c1bcf7573937" translate="yes" xml:space="preserve">
          <source>The dimension along which the cosine distance is computed.</source>
          <target state="translated">The dimension along which the cosine distance is computed.</target>
        </trans-unit>
        <trans-unit id="b1950ef9079ccb8fdab95487686c7eb37ab33631" translate="yes" xml:space="preserve">
          <source>The dimension softmax would be performed on. The default is -1 which indicates the last dimension.</source>
          <target state="translated">The dimension softmax would be performed on. The default is -1 which indicates the last dimension.</target>
        </trans-unit>
        <trans-unit id="a741b7f6b1d2304d511eed765b55f2d892e70b1b" translate="yes" xml:space="preserve">
          <source>The dimensions in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; are merged elementwise, according to the rules defined for &lt;code&gt;Dimension.merge_with()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Dimension.merge_with()&lt;/code&gt; 대해 정의 된 규칙에 따라 &lt;code&gt;self&lt;/code&gt; 및 &lt;code&gt;other&lt;/code&gt; 차원 이 요소 단위로 병합 됩니다.</target>
        </trans-unit>
        <trans-unit id="6e700d4efdcd9fa4c17a75442e4f67358801b0cd" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input), rank(input))&lt;/code&gt;.</source>
          <target state="translated">The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input), rank(input))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6c3884296f2f81a69d25f2d74a953505cb36e099" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input_tensor), rank(input_tensor))&lt;/code&gt;.</source>
          <target state="translated">The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input_tensor), rank(input_tensor))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="524dc0cac6bb52e1a46462ec8553ccc9e4362acf" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input_tensor), rank(input_tensor)]&lt;/code&gt;.</source>
          <target state="translated">The dimensions to reduce. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions. Must be in the range &lt;code&gt;[-rank(input_tensor), rank(input_tensor)]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e8ce19192adc15b5220fef2532366cfeacb9e19d" translate="yes" xml:space="preserve">
          <source>The dimensions to reduce; list or scalar. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions.</source>
          <target state="translated">The dimensions to reduce; list or scalar. If &lt;code&gt;None&lt;/code&gt; (the default), reduces all dimensions.</target>
        </trans-unit>
        <trans-unit id="2d1b6053c3cee0279e3dc86b7090198e408447ec" translate="yes" xml:space="preserve">
          <source>The direction in which to sort the values (&lt;code&gt;'ASCENDING'&lt;/code&gt; or &lt;code&gt;'DESCENDING'&lt;/code&gt;).</source>
          <target state="translated">The direction in which to sort the values ( &lt;code&gt;'ASCENDING'&lt;/code&gt; or &lt;code&gt;'DESCENDING'&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="7bc7db80b0d2774479326226a4890a6e2d843629" translate="yes" xml:space="preserve">
          <source>The directory as string.</source>
          <target state="translated">문자열 인 디렉토리.</target>
        </trans-unit>
        <trans-unit id="d47beb327611bfd25299d1d2b4c584bd5f48dbf4" translate="yes" xml:space="preserve">
          <source>The directory in which checkpoints are saved.</source>
          <target state="translated">The directory in which checkpoints are saved.</target>
        </trans-unit>
        <trans-unit id="8e7ea210352ff9e76412951da939c6e46cfe6639" translate="yes" xml:space="preserve">
          <source>The directory of checkpoints.</source>
          <target state="translated">The directory of checkpoints.</target>
        </trans-unit>
        <trans-unit id="115f901deb7759892ab1dbde3055bf4ffc36bc3e" translate="yes" xml:space="preserve">
          <source>The directory path where the dumping information will be written.</source>
          <target state="translated">The directory path where the dumping information will be written.</target>
        </trans-unit>
        <trans-unit id="23759a3b8009ddee2c9ccc70d3ee85712ccf2888" translate="yes" xml:space="preserve">
          <source>The directory to save the model results and log files.</source>
          <target state="translated">The directory to save the model results and log files.</target>
        </trans-unit>
        <trans-unit id="8f003820357db00c0553228e9493dca5bc931d2d" translate="yes" xml:space="preserve">
          <source>The directory where files specified in data attribute of py_test and py_binary are stored.</source>
          <target state="translated">py_test 및 py_binary의 data 속성에 지정된 파일이 저장되는 디렉토리입니다.</target>
        </trans-unit>
        <trans-unit id="57821be3cc06a5ba465c47d01aaf44aa61e1d383" translate="yes" xml:space="preserve">
          <source>The distance metric used for clustering. One of:</source>
          <target state="translated">The distance metric used for clustering. One of:</target>
        </trans-unit>
        <trans-unit id="3b7ccc3fd24de1a06b23a805fbbf6bc02487c531" translate="yes" xml:space="preserve">
          <source>The distances from each input point to each cluster center.</source>
          <target state="translated">각 입력 지점에서 각 클러스터 중심까지의 거리입니다.</target>
        </trans-unit>
        <trans-unit id="adcc609cd8c69dbaffd925d5301fb26f55e523e5" translate="yes" xml:space="preserve">
          <source>The distortion is used to skew the unigram probability distribution. Each weight is first raised to the distortion's power before adding to the internal unigram distribution. As a result, &lt;code&gt;distortion = 1.0&lt;/code&gt; gives regular unigram sampling (as defined by the vocab file), and &lt;code&gt;distortion = 0.0&lt;/code&gt; gives a uniform distribution.</source>
          <target state="translated">The distortion is used to skew the unigram probability distribution. Each weight is first raised to the distortion's power before adding to the internal unigram distribution. As a result, &lt;code&gt;distortion = 1.0&lt;/code&gt; gives regular unigram sampling (as defined by the vocab file), and &lt;code&gt;distortion = 0.0&lt;/code&gt; gives a uniform distribution.</target>
        </trans-unit>
        <trans-unit id="a47603ed00a4a39f84d7b7101c2b650f89e2c48b" translate="yes" xml:space="preserve">
          <source>The distribution from which the parameters of the random features map (layer) are sampled determines which shift-invariant kernel the layer approximates (see paper for more details). You can use the distribution of your choice. The layer supports out-of-the-box approximation sof the following two RBF kernels:</source>
          <target state="translated">The distribution from which the parameters of the random features map (layer) are sampled determines which shift-invariant kernel the layer approximates (see paper for more details). You can use the distribution of your choice. The layer supports out-of-the-box approximation sof the following two RBF kernels:</target>
        </trans-unit>
        <trans-unit id="5f58b91125c882dc2a62587a652492f254f94698" translate="yes" xml:space="preserve">
          <source>The distribution functions can be evaluated on counts.</source>
          <target state="translated">분포 함수는 카운트로 평가할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7b6104158da73f015822f02cd6abbe4e2cf5c6cf" translate="yes" xml:space="preserve">
          <source>The distribution strategy options associated with the dataset. See &lt;a href=&quot;experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 배포 전략 옵션. 자세한 내용은 &lt;a href=&quot;experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="bf743a144dc0600d6b32b4a4db31e72e8fcd7021" translate="yes" xml:space="preserve">
          <source>The distributions have degree of freedom &lt;code&gt;df&lt;/code&gt;, mean &lt;code&gt;loc&lt;/code&gt;, and scale &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="translated">분포는 자유도 &lt;code&gt;df&lt;/code&gt; , 평균 위치 및 스케일 &lt;code&gt;scale&lt;/code&gt; &lt;code&gt;loc&lt;/code&gt; 집니다.</target>
        </trans-unit>
        <trans-unit id="9974cdad7192faff5dd2133a51cc98b931250694" translate="yes" xml:space="preserve">
          <source>The document frequency of the OOV token. Only necessary if output_mode is TFIDF.</source>
          <target state="translated">The document frequency of the OOV token. Only necessary if output_mode is TFIDF.</target>
        </trans-unit>
        <trans-unit id="2de0b5493fea7bb1bb4b3e017251bece76051fd5" translate="yes" xml:space="preserve">
          <source>The drawn samples of shape &lt;code&gt;[batch_size, num_samples]&lt;/code&gt;.</source>
          <target state="translated">모양이 그려진 샘플 &lt;code&gt;[batch_size, num_samples]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5e74b8b7d0df8fed16c79b98fd21910718bbb784" translate="yes" xml:space="preserve">
          <source>The dropout rate, between 0 and 1. E.g. &lt;code&gt;rate=0.1&lt;/code&gt; would drop out 10% of input units.</source>
          <target state="translated">The dropout rate, between 0 and 1. E.g. &lt;code&gt;rate=0.1&lt;/code&gt; would drop out 10% of input units.</target>
        </trans-unit>
        <trans-unit id="b307d95f377afd55d64b7df5ef858732cff45363" translate="yes" xml:space="preserve">
          <source>The dtype for &lt;code&gt;row_splits&lt;/code&gt;. One of &lt;a href=&quot;../tf#int32&quot;&gt;&lt;code&gt;tf.int32&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The dtype for &lt;code&gt;row_splits&lt;/code&gt; . One of &lt;a href=&quot;../tf#int32&quot;&gt; &lt;code&gt;tf.int32&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;../tf#int64&quot;&gt; &lt;code&gt;tf.int64&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="650e6295ecdc851a5073e1cf59012505607bda82" translate="yes" xml:space="preserve">
          <source>The dtype for the return value. Defaults to &lt;code&gt;segment_ids.dtype&lt;/code&gt;, or &lt;a href=&quot;../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;segment_ids&lt;/code&gt; does not have a dtype.</source>
          <target state="translated">The dtype for the return value. Defaults to &lt;code&gt;segment_ids.dtype&lt;/code&gt; , or &lt;a href=&quot;../../tf#int64&quot;&gt; &lt;code&gt;tf.int64&lt;/code&gt; &lt;/a&gt; if &lt;code&gt;segment_ids&lt;/code&gt; does not have a dtype.</target>
        </trans-unit>
        <trans-unit id="651f8e3ce30e01a19884517237de61dd305a37d2" translate="yes" xml:space="preserve">
          <source>The dtype for the return value. Defaults to &lt;code&gt;splits.dtype&lt;/code&gt;, or &lt;a href=&quot;../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;splits&lt;/code&gt; does not have a dtype.</source>
          <target state="translated">The dtype for the return value. Defaults to &lt;code&gt;splits.dtype&lt;/code&gt; , or &lt;a href=&quot;../../tf#int64&quot;&gt; &lt;code&gt;tf.int64&lt;/code&gt; &lt;/a&gt; if &lt;code&gt;splits&lt;/code&gt; does not have a dtype.</target>
        </trans-unit>
        <trans-unit id="8d0125518627216e27c3aadddc389fb684e07985" translate="yes" xml:space="preserve">
          <source>The dtype of the layer's computations and weights (default of &lt;code&gt;None&lt;/code&gt; means use &lt;a href=&quot;../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx&lt;/code&gt;&lt;/a&gt; in TensorFlow 2, or the type of the first input in TensorFlow 1).</source>
          <target state="translated">The dtype of the layer's computations and weights (default of &lt;code&gt;None&lt;/code&gt; means use &lt;a href=&quot;../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx&lt;/code&gt; &lt;/a&gt; in TensorFlow 2, or the type of the first input in TensorFlow 1).</target>
        </trans-unit>
        <trans-unit id="80fd7b4c05a902c0f01fd54f89719616e3a0775c" translate="yes" xml:space="preserve">
          <source>The dtype of the layer's computations and weights. If mixed precision is used with a &lt;a href=&quot;../mixed_precision/experimental/policy&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.Policy&lt;/code&gt;&lt;/a&gt;, this is instead just the dtype of the layer's weights, as the computations are done in a different dtype.</source>
          <target state="translated">The dtype of the layer's computations and weights. If mixed precision is used with a &lt;a href=&quot;../mixed_precision/experimental/policy&quot;&gt; &lt;code&gt;tf.keras.mixed_precision.experimental.Policy&lt;/code&gt; &lt;/a&gt;, this is instead just the dtype of the layer's weights, as the computations are done in a different dtype.</target>
        </trans-unit>
        <trans-unit id="bd52ea2eb7ea5be6e405a118979acc052f206e1b" translate="yes" xml:space="preserve">
          <source>The dtype of the resulting tensor is inferred from the inputs unless it is provided explicitly.</source>
          <target state="translated">결과 텐서의 dtype은 명시 적으로 제공되지 않는 한 입력에서 유추됩니다.</target>
        </trans-unit>
        <trans-unit id="5d16a87cf006dd1b3cd4d0dcbb040b8f7357e681" translate="yes" xml:space="preserve">
          <source>The dtype that should be used for the &lt;code&gt;row_splits&lt;/code&gt; of any new ragged tensors. Existing &lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt; elements do not have their row_splits dtype changed.</source>
          <target state="translated">The dtype that should be used for the &lt;code&gt;row_splits&lt;/code&gt; of any new ragged tensors. Existing &lt;a href=&quot;../../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; elements do not have their row_splits dtype changed.</target>
        </trans-unit>
        <trans-unit id="4b69591d001104f8e2eec546d13dfde13802ef40" translate="yes" xml:space="preserve">
          <source>The dumped debugging information can be ingested by debugger UIs.</source>
          <target state="translated">덤프 된 디버깅 정보는 디버거 UI에서 수집 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="1c3bb311f55c44615e851ca1393dedf962117d6f" translate="yes" xml:space="preserve">
          <source>The dynamic calculation performed is, at time &lt;code&gt;t&lt;/code&gt; for batch row &lt;code&gt;b&lt;/code&gt;,</source>
          <target state="translated">수행 된 동적 계산은 배치 행 &lt;code&gt;b&lt;/code&gt; 의 시간 &lt;code&gt;t&lt;/code&gt; 에서</target>
        </trans-unit>
        <trans-unit id="8941174f7a82cad8c90f6e6a03ac3a820dea0104" translate="yes" xml:space="preserve">
          <source>The dynamic range of the images (i.e., the difference between the maximum the and minimum allowed values).</source>
          <target state="translated">The dynamic range of the images (i.e., the difference between the maximum the and minimum allowed values).</target>
        </trans-unit>
        <trans-unit id="2aae6b9d4f5b2d213b88b3723da3ddb26ced9416" translate="yes" xml:space="preserve">
          <source>The effective spatial dimensions of the zero-padded input tensor will be:</source>
          <target state="translated">제로 패딩 입력 텐서의 유효 공간 치수는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b9acfbbdfe245ea88de02f1a818fe0b504d8ee2c" translate="yes" xml:space="preserve">
          <source>The eigenvalues and eigenvectors for a non-Hermitian matrix in general are complex. The eigenvectors are not guaranteed to be linearly independent.</source>
          <target state="translated">비 -Hermitian 행렬에 대한 고유 값과 고유 벡터는 일반적으로 복잡합니다. 고유 벡터는 선형 독립성을 보장하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="ee408bc36c08a8eb79de0b041ba288a43ece416b" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x divided by y.</source>
          <target state="translated">x의 요소 별 값을 y로 나눈 값입니다.</target>
        </trans-unit>
        <trans-unit id="ee6f05fbd02c64e68c12a5dd5234049b70dd5c18" translate="yes" xml:space="preserve">
          <source>The element-wise value of the x times y.</source>
          <target state="translated">x의 요소 별 값에 y를 곱한 값입니다.</target>
        </trans-unit>
        <trans-unit id="5056d7193c98ed08aca24d8fed6317ade12de9af" translate="yes" xml:space="preserve">
          <source>The elements are shifted positively (towards larger indices) by the offset of &lt;code&gt;shift&lt;/code&gt; along the dimension of &lt;code&gt;axis&lt;/code&gt;. Negative &lt;code&gt;shift&lt;/code&gt; values will shift elements in the opposite direction. Elements that roll passed the last position will wrap around to the first and vice versa. Multiple shifts along multiple axes may be specified.</source>
          <target state="translated">&lt;code&gt;axis&lt;/code&gt; 치수를 따라 &lt;code&gt;shift&lt;/code&gt; 오프셋에 의해 요소가 양의 방향으로 (더 큰 인덱스를 향해) 이동 됩니다 . 음수 &lt;code&gt;shift&lt;/code&gt; 값은 요소를 반대 방향으로 이동시킵니다. 마지막 위치를 통과 한 롤은 첫 번째 위치로 감싸고 그 반대도 마찬가지입니다. 여러 축을 따라 여러 이동을 지정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c40643e8152d969c58abd0946b228718afbfd024" translate="yes" xml:space="preserve">
          <source>The elements in &lt;code&gt;input&lt;/code&gt; are considered to be complex numbers of the form \(a + bj\), where &lt;em&gt;a&lt;/em&gt; is the real part and &lt;em&gt;b&lt;/em&gt; is the imaginary part. If &lt;code&gt;input&lt;/code&gt; is real then &lt;em&gt;b&lt;/em&gt; is zero by definition.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 요소는 \ (a + bj \) 형식의 복소수로 간주됩니다. 여기서 &lt;em&gt;a&lt;/em&gt; 는 실수 부이고 &lt;em&gt;b&lt;/em&gt; 는 허수 부입니다. 경우 &lt;code&gt;input&lt;/code&gt; 진짜 후이고 &lt;em&gt;B는&lt;/em&gt; 정의에 의해 제로이다.</target>
        </trans-unit>
        <trans-unit id="bd6b82f2a01c27554a110fc1c60a8688cc656c5b" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;result&lt;/code&gt; will be:</source>
          <target state="translated">&lt;code&gt;result&lt;/code&gt; 의 요소 는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="7e5122262788d16dcc2a476a1ccd5d94e319a27e" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;sampled_candidates&lt;/code&gt; are drawn without replacement (if &lt;code&gt;unique=True&lt;/code&gt;) or with replacement (if &lt;code&gt;unique=False&lt;/code&gt;) from the base distribution.</source>
          <target state="translated">&lt;code&gt;sampled_candidates&lt;/code&gt; 의 요소 는 기본 분포에서 교체하지 않고 ( &lt;code&gt;unique=True&lt;/code&gt; 인 경우 ) 또는 교체 ( &lt;code&gt;unique=False&lt;/code&gt; 인 경우 )로 가져옵니다.</target>
        </trans-unit>
        <trans-unit id="f8cb760115d6699c4a14874f1c5206c7b83dc9f1" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;seq_lengths&lt;/code&gt; must obey &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_axis]&lt;/code&gt;, and &lt;code&gt;seq_lengths&lt;/code&gt; must be a vector of length &lt;code&gt;input.dims[batch_axis]&lt;/code&gt;.</source>
          <target state="translated">The elements of &lt;code&gt;seq_lengths&lt;/code&gt; must obey &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_axis]&lt;/code&gt; , and &lt;code&gt;seq_lengths&lt;/code&gt; must be a vector of length &lt;code&gt;input.dims[batch_axis]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="48ab33f1524aaeaed08c07c88c40746479f023b7" translate="yes" xml:space="preserve">
          <source>The elements of &lt;code&gt;seq_lengths&lt;/code&gt; must obey &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_dim]&lt;/code&gt;, and &lt;code&gt;seq_lengths&lt;/code&gt; must be a vector of length &lt;code&gt;input.dims[batch_dim]&lt;/code&gt;.</source>
          <target state="translated">의 요소 &lt;code&gt;seq_lengths&lt;/code&gt; 가 따라야 &lt;code&gt;seq_lengths[i] &amp;lt;= input.dims[seq_dim]&lt;/code&gt; 및 &lt;code&gt;seq_lengths&lt;/code&gt; 는 길이의 벡터이어야 &lt;code&gt;input.dims[batch_dim]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0d38c9da5faf42a7a6a14d9cb5caf234ae8f9c01" translate="yes" xml:space="preserve">
          <source>The elements of each job will be split between the two processes, with elements being consumed by the processes on a first-come first-served basis. One possible result is that process 1 prints</source>
          <target state="translated">The elements of each job will be split between the two processes, with elements being consumed by the processes on a first-come first-served basis. One possible result is that process 1 prints</target>
        </trans-unit>
        <trans-unit id="39f08dabb4ebd036182bf4e154d99641a60b1bde" translate="yes" xml:space="preserve">
          <source>The elements of the dataset must be scalar strings. To serialize dataset elements as strings, you can use the &lt;a href=&quot;../../io/serialize_tensor&quot;&gt;&lt;code&gt;tf.io.serialize_tensor&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">데이터 세트의 요소는 스칼라 문자열이어야합니다. 데이터 세트 요소를 문자열로 직렬화하기 위해 &lt;a href=&quot;../../io/serialize_tensor&quot;&gt; &lt;code&gt;tf.io.serialize_tensor&lt;/code&gt; &lt;/a&gt; 함수를 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="056215457d55383c82886d3fc40bfbe65262e4c1" translate="yes" xml:space="preserve">
          <source>The elements of the output vector are in range (0, 1) and sum to 1.</source>
          <target state="translated">The elements of the output vector are in range (0, 1) and sum to 1.</target>
        </trans-unit>
        <trans-unit id="b779b04f9885caafc27f0474205a244037f9aefe" translate="yes" xml:space="preserve">
          <source>The elements of the resulting dataset are created by zipping corresponding elements from each of the input datasets.</source>
          <target state="translated">The elements of the resulting dataset are created by zipping corresponding elements from each of the input datasets.</target>
        </trans-unit>
        <trans-unit id="3650e19170e124ae92368cff21395feb363f4884" translate="yes" xml:space="preserve">
          <source>The elements of this dataset correspond to records from the file(s). RFC 4180 format is expected for CSV files (https://tools.ietf.org/html/rfc4180) Note that we allow leading and trailing spaces with int or float field.</source>
          <target state="translated">이 데이터 세트의 요소는 파일의 레코드에 해당합니다. CSV 파일에는 RFC 4180 형식이 필요합니다 (https://tools.ietf.org/html/rfc4180) int 또는 float 필드를 사용하여 선행 및 후행 공백을 허용합니다.</target>
        </trans-unit>
        <trans-unit id="bd68739a9e7ae81bc68e96ee2b6122f5a70e5503" translate="yes" xml:space="preserve">
          <source>The embedding dimension (width) of the table.</source>
          <target state="translated">The embedding dimension (width) of the table.</target>
        </trans-unit>
        <trans-unit id="b86ebc65ff7fe45f105d160f18d2c35f7cb8da0f" translate="yes" xml:space="preserve">
          <source>The empty string, in which case the corresponding tensor is saved normally.</source>
          <target state="translated">The empty string, in which case the corresponding tensor is saved normally.</target>
        </trans-unit>
        <trans-unit id="c58cc0575d8bcfe00176a01cd63f2a1558bbe2e1" translate="yes" xml:space="preserve">
          <source>The encode and decode Ops apply to one image at a time. Their input and output are all of variable size. If you need fixed size images, pass the output of the decode Ops to one of the cropping and resizing Ops.</source>
          <target state="translated">The encode and decode Ops apply to one image at a time. Their input and output are all of variable size. If you need fixed size images, pass the output of the decode Ops to one of the cropping and resizing Ops.</target>
        </trans-unit>
        <trans-unit id="c3aeafaf8f36325e7f515de971621d719406107b" translate="yes" xml:space="preserve">
          <source>The end result is that if the input is marked as an explicit endianness the transcoding is faithful to all codepoints in the source. If it is not marked with an explicit endianness, the BOM is not considered part of the string itself but as metadata, and so is not preserved in the output.</source>
          <target state="translated">최종 결과는 입력이 명시 적 엔디안으로 표시되면 트랜스 코딩이 소스의 모든 코드 포인트에 충실하다는 것입니다. 명시 적 엔디안으로 표시되지 않은 경우 BOM은 문자열 자체의 일부가 아니라 메타 데이터로 간주되므로 출력에 유지되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="a7d3c35f0e85c1a6bf781b776ea72d3b7217b57e" translate="yes" xml:space="preserve">
          <source>The entire Python program exits when no alive non-daemon threads are left.</source>
          <target state="translated">살아있는 비 데몬 스레드가 남아 있지 않으면 전체 Python 프로그램이 종료됩니다.</target>
        </trans-unit>
        <trans-unit id="c67894db798c48ee917afae60b483f03b8c6455e" translate="yes" xml:space="preserve">
          <source>The entire Python program exits when only daemon threads are left.</source>
          <target state="translated">The entire Python program exits when only daemon threads are left.</target>
        </trans-unit>
        <trans-unit id="fcab26b6f1d2bad63f4beb447401d7b8916bee05" translate="yes" xml:space="preserve">
          <source>The entire optimizer is currently thread compatible, not thread-safe. The user needs to perform synchronization if necessary.</source>
          <target state="translated">전체 옵티마이 저는 현재 스레드 안전이 아니라 스레드 호환 가능합니다. 필요한 경우 사용자는 동기화를 수행해야합니다.</target>
        </trans-unit>
        <trans-unit id="c33387bb265f08d2eccc0ee4964677edfa18dfee" translate="yes" xml:space="preserve">
          <source>The error message that describes the error.</source>
          <target state="translated">오류를 설명하는 오류 메시지입니다.</target>
        </trans-unit>
        <trans-unit id="3992d2c2ef24613a2edd3a09184b92d4f6c82dcc" translate="yes" xml:space="preserve">
          <source>The estimator uses a user-specified head.</source>
          <target state="translated">추정기는 사용자 지정 헤드를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="c0f4a9f9118713f2c65753167fbc45edc83681df" translate="yes" xml:space="preserve">
          <source>The event shape and the batch shape are properties of a Distribution object, whereas the sample shape is associated with a specific call to &lt;code&gt;sample&lt;/code&gt; or &lt;code&gt;log_prob&lt;/code&gt;.</source>
          <target state="translated">이벤트 셰이프 및 배치 셰이프는 Distribution 객체의 속성 인 반면 샘플 셰이프는 &lt;code&gt;sample&lt;/code&gt; 또는 &lt;code&gt;log_prob&lt;/code&gt; 에 대한 특정 호출과 연결됩니다 .</target>
        </trans-unit>
        <trans-unit id="e19c4b1d5034eb4e65cdca6271a9f69191e90f42" translate="yes" xml:space="preserve">
          <source>The example above uses the keyword argument &quot;step_num&quot; to specify the training step being traced.</source>
          <target state="translated">The example above uses the keyword argument &quot;step_num&quot; to specify the training step being traced.</target>
        </trans-unit>
        <trans-unit id="d89bb90670419b9d3a4b50ee4e20b8624c955245" translate="yes" xml:space="preserve">
          <source>The example has two variables containing parameters, &lt;code&gt;dense.kernel&lt;/code&gt; (2 parameters) and &lt;code&gt;dense.bias&lt;/code&gt; (1 parameter). Considering the training data &lt;code&gt;x&lt;/code&gt; as a constant, this means the Jacobian matrix for the function mapping from parameters to loss has one row and three columns.</source>
          <target state="translated">이 예에는 &lt;code&gt;dense.kernel&lt;/code&gt; (2 개의 매개 변수) 및 &lt;code&gt;dense.bias&lt;/code&gt; (1 개의 매개 변수) 매개 변수가 포함 된 두 개의 변수가 있습니다. 훈련 데이터 &lt;code&gt;x&lt;/code&gt; 를 상수로 고려하면 , 이는 매개 변수에서 손실로의 함수 맵핑을위한 Jacobian 행렬이 1 행 3 열임을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="84c18ab207b5195ffc68356ad590594bcf1dfa71" translate="yes" xml:space="preserve">
          <source>The examples below are for the case when only indices have leading extra dimensions. If both 'params' and 'indices' have leading batch dimensions, use the 'batch_dims' parameter to run gather_nd in batch mode.</source>
          <target state="translated">아래의 예는 지수에만 추가 치수가있는 경우를위한 것입니다. 'params'및 'indices'둘 다 선행 배치 차원을 갖는 경우 'batch_dims'매개 변수를 사용하여 배치 모드에서 gather_nd를 실행하십시오.</target>
        </trans-unit>
        <trans-unit id="d6bb9f9b8e615c827d76fd441b8f54dc8cd4e856" translate="yes" xml:space="preserve">
          <source>The execution engine to connect to.</source>
          <target state="translated">The execution engine to connect to.</target>
        </trans-unit>
        <trans-unit id="8918766792e879b9d59da00a6e0e039a16054478" translate="yes" xml:space="preserve">
          <source>The expected cardinality of the input dataset.</source>
          <target state="translated">The expected cardinality of the input dataset.</target>
        </trans-unit>
        <trans-unit id="d5de696bdbf9044458c641e379962d440aa33f58" translate="yes" xml:space="preserve">
          <source>The expected datatype of the sequences, or None if no datatype should be enforced.</source>
          <target state="translated">The expected datatype of the sequences, or None if no datatype should be enforced.</target>
        </trans-unit>
        <trans-unit id="e3928718719fe99849e7ac1ac65a36c562e1538d" translate="yes" xml:space="preserve">
          <source>The expected hash string of the file after download. The sha256 and md5 hash algorithms are both supported.</source>
          <target state="translated">The expected hash string of the file after download. The sha256 and md5 hash algorithms are both supported.</target>
        </trans-unit>
        <trans-unit id="6e7988b38263986e25122de775533e193c686e78" translate="yes" xml:space="preserve">
          <source>The expected length of the container.</source>
          <target state="translated">The expected length of the container.</target>
        </trans-unit>
        <trans-unit id="bda1fab4530bea5769655be69388620ba7cc79a3" translate="yes" xml:space="preserve">
          <source>The expected numpy &lt;code&gt;ndarray&lt;/code&gt;, or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor), or any arbitrarily nested of structure of these.</source>
          <target state="translated">The expected numpy &lt;code&gt;ndarray&lt;/code&gt; , or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor), or any arbitrarily nested of structure of these.</target>
        </trans-unit>
        <trans-unit id="78ad8b1f8ab153e6768481eb32292aa26fa61403" translate="yes" xml:space="preserve">
          <source>The expected output of its iterations is:</source>
          <target state="translated">반복의 예상 출력은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="7a97b08c68384c6b725f7994e4ae0a05ba85ecb6" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string or int to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying the features to be passed to the model. Note: if &lt;code&gt;features&lt;/code&gt; passed is not a dict, it will be wrapped in a dict with a single entry, using 'feature' as the key. Consequently, the model must accept a feature dict of the form {'feature': tensor}. You may use &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; if you want the tensor to be passed as is. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="translated">예상되는 반환 값은 다음과 같습니다. features : &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 string 또는 int dict to &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 로 모델에 전달할 기능을 지정합니다. 참고 : 전달 된 &lt;code&gt;features&lt;/code&gt; 이 dict이 아닌 경우 'feature'를 키로 사용하여 단일 항목으로 dict에 래핑됩니다. 결과적으로 모델은 { 'feature': tensor} 형식의 지형 지법을 받아 들여야합니다. 텐서를 그대로 전달 하려면 &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; 를 사용할 수 있습니다 . receiver_tensors : &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; 또는 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 에 대한 문자열 dict이 수신기가 기본적으로 공급 될 것으로 예상되는 입력 노드를 지정합니다. 일반적으로 이것은 직렬화 된 &lt;code&gt;tf.Example&lt;/code&gt; 프로토 타입을 기대하는 단일 자리 표시 자 입니다. receiver_tensors_alternatives : 추가 그룹의 수신자 텐서에 대한 문자열 dict, 각각 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 문자열이 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 일 수 있습니다. 이러한 명명 된 수신기 텐서 대안은 추가 서빙 서명을 생성하는데, 이는 입력 수신기 서브 그래프 내의 다른 지점에서 입력을 공급하는데 사용될 수있다. 일반적인 사용법은 tf.parse_example () op 의 &lt;em&gt;다운 스트림&lt;/em&gt; 에 원시 기능 &lt;code&gt;Tensor&lt;/code&gt; 를 공급 하는 것입니다. 기본값은 없음입니다.&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="31f7e12f63f032ea1d264ce969a77506eba82800" translate="yes" xml:space="preserve">
          <source>The expected return values are: features: A single &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, representing the feature to be passed to the model. receiver_tensors: A &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt;, specifying input nodes where this receiver expects to be fed by default. Typically, this is a single placeholder expecting serialized &lt;code&gt;tf.Example&lt;/code&gt; protos. receiver_tensors_alternatives: a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="translated">예상되는 반환 값은 다음과 같습니다. features : 단일 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; . 모델에 전달할 기능을 나타냅니다. receiver_tensors : &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 에 대한 문자열 dict .이 수신기가 기본적으로 공급 될 것으로 예상되는 입력 노드를 지정합니다. 일반적으로 이것은 직렬화 된 &lt;code&gt;tf.Example&lt;/code&gt; 프로토 타입을 기대하는 단일 자리 표시 자 입니다. receiver_tensors_alternatives : 추가 그룹의 수신자 텐서에 대한 문자열 dict, 각각 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;SparseTensor&lt;/code&gt; , 또는 문자열이 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 일 수 있음. 이러한 명명 된 수신기 텐서 대안은 추가 서빙 서명을 생성하는데, 이는 입력 수신기 서브 그래프 내의 다른 지점에서 입력을 공급하는데 사용될 수있다. 일반적인 사용법은 tf.parse_example () op 의 &lt;em&gt;다운 스트림&lt;/em&gt; 에 원시 기능 &lt;code&gt;Tensor&lt;/code&gt; 를 공급 하는 것입니다. 기본값은 없음입니다.&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="a09896f6b4f647e3c96ed132a504af085f335053" translate="yes" xml:space="preserve">
          <source>The expected shape of the output tensor (excluding the batch dimension and any dimensions represented by ellipses). You can specify None for any dimension that is unknown or can be inferred from the input shape.</source>
          <target state="translated">The expected shape of the output tensor (excluding the batch dimension and any dimensions represented by ellipses). You can specify None for any dimension that is unknown or can be inferred from the input shape.</target>
        </trans-unit>
        <trans-unit id="a40612bf469e8a522446e66d41d431047e69cf63" translate="yes" xml:space="preserve">
          <source>The expected size of the &lt;code&gt;logits&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;logits&lt;/code&gt; 텐서 의 예상 크기입니다 .</target>
        </trans-unit>
        <trans-unit id="a0f440ff029659182acbea8855f46dd42d2a4e96" translate="yes" xml:space="preserve">
          <source>The expected table key dtype.</source>
          <target state="translated">예상 테이블 키 dtype입니다.</target>
        </trans-unit>
        <trans-unit id="31bcecc626aa91dd2b7d91005cf6117e6bde9f72" translate="yes" xml:space="preserve">
          <source>The expected table value dtype.</source>
          <target state="translated">예상 테이블 값 dtype입니다.</target>
        </trans-unit>
        <trans-unit id="376e0fcfa926199ad6e385d57f40bbf540152a01" translate="yes" xml:space="preserve">
          <source>The expected type of exception that should be raised.</source>
          <target state="translated">The expected type of exception that should be raised.</target>
        </trans-unit>
        <trans-unit id="ce7ef07c28defdcd9df2cbeda8fcff1eb3a70cf0" translate="yes" xml:space="preserve">
          <source>The expected values are &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">예상되는 값은 &lt;a href=&quot;../../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.SparseTensor&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="c7c8fde13147479cf3364c839442aedae9a726dc" translate="yes" xml:space="preserve">
          <source>The expected values are &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The expected values are &lt;a href=&quot;../../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt; &lt;code&gt;tf.sparse.SparseTensor&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="dec1b3abe2b21793505b8807293f4669331e6f37" translate="yes" xml:space="preserve">
          <source>The experimental_mode parameter can be used to export a single train/eval/predict graph as a &lt;code&gt;SavedModel&lt;/code&gt;. See &lt;code&gt;experimental_export_all_saved_models&lt;/code&gt; for full docs.</source>
          <target state="translated">Experiment_mode 매개 변수를 사용하여 단일 train / eval / predict 그래프를 &lt;code&gt;SavedModel&lt;/code&gt; 로 내보낼 수 있습니다 . 전체 문서는 &lt;code&gt;experimental_export_all_saved_models&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="7605e2fe49cffe7e518a9ae0d1ab56de778f3211" translate="yes" xml:space="preserve">
          <source>The exponential is computed using a combination of the scaling and squaring method and the Pade approximation. Details can be found in: Nicholas J. Higham, &quot;The scaling and squaring method for the matrix exponential revisited,&quot; SIAM J. Matrix Anal. Applic., 26:1179-1193, 2005.</source>
          <target state="translated">지수는 스케일링 및 제곱 방법과 Pade 근사값의 조합을 사용하여 계산됩니다. 자세한 내용은 다음을 참조하십시오. Nicholas J. Higham, &quot;매트릭스 지수 재검토를위한 스케일링 및 제곱 방법&quot;SIAM J. Matrix Anal. 출원, 26 : 1179-1193, 2005.</target>
        </trans-unit>
        <trans-unit id="4f5a78bc935e9e08409cbf0ad9095df30519c6ba" translate="yes" xml:space="preserve">
          <source>The exponential linear activation: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x)-1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt;.</source>
          <target state="translated">지수 선형 활성화 : &lt;code&gt;x&lt;/code&gt; 경우 &lt;code&gt;x &amp;gt; 0&lt;/code&gt; 과 &lt;code&gt;alpha * (exp(x)-1)&lt;/code&gt; 의 경우 &lt;code&gt;x &amp;lt; 0&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2d28f89676ea4197a32d7a392e0d037302ffbd35" translate="yes" xml:space="preserve">
          <source>The exponential linear unit (ELU) activation function: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt;.</source>
          <target state="translated">The exponential linear unit (ELU) activation function: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7cf62415d8dce700f1230ed830d364734140b756" translate="yes" xml:space="preserve">
          <source>The exponential linear unit (ELU) with &lt;code&gt;alpha &amp;gt; 0&lt;/code&gt; is: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; The ELU hyperparameter &lt;code&gt;alpha&lt;/code&gt; controls the value to which an ELU saturates for negative net inputs. ELUs diminish the vanishing gradient effect.</source>
          <target state="translated">The exponential linear unit (ELU) with &lt;code&gt;alpha &amp;gt; 0&lt;/code&gt; is: &lt;code&gt;x&lt;/code&gt; if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; and &lt;code&gt;alpha * (exp(x) - 1)&lt;/code&gt; if &lt;code&gt;x &amp;lt; 0&lt;/code&gt; The ELU hyperparameter &lt;code&gt;alpha&lt;/code&gt; controls the value to which an ELU saturates for negative net inputs. ELUs diminish the vanishing gradient effect.</target>
        </trans-unit>
        <trans-unit id="6a8c6448917add778eb240e31bd6ab87cce7e676" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;../../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="9e2875cf5dfc1a19c0a389906972c0cc62d32b4f" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;../../../estimator/export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="72c1a65a7779ecfbc3e340268769bc17bef0c731" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;../export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;../export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="f952c6857d4170532f4c4a40882608ceb9fe6cf5" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;MetaGraphDef&lt;/code&gt; will provide one &lt;code&gt;SignatureDef&lt;/code&gt; for each element of the &lt;code&gt;export_outputs&lt;/code&gt; dict returned from the &lt;code&gt;model_fn&lt;/code&gt;, named using the same keys. One of these keys is always &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;, indicating which signature will be served when a serving request does not specify one. For each signature, the outputs are provided by the corresponding &lt;a href=&quot;export/exportoutput&quot;&gt;&lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt;&lt;/a&gt;s, and the inputs are always the input receivers provided by the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;MetaGraphDef&lt;/code&gt; 는 하나 제공 &lt;code&gt;SignatureDef&lt;/code&gt; 을 의 각 요소에 대해 &lt;code&gt;export_outputs&lt;/code&gt; 으로부터 반환 DICT &lt;code&gt;model_fn&lt;/code&gt; 같은 키를 사용하여 명명. 이 키 중 하나는 항상 &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt; 이며, 서빙 요청에서 키를 지정하지 않은 경우 어떤 서명이 제공되는지 나타냅니다. 각 서명에 대해 출력은 해당 &lt;a href=&quot;export/exportoutput&quot;&gt; &lt;code&gt;tf.estimator.export.ExportOutput&lt;/code&gt; 에&lt;/a&gt; 의해 제공되며 입력은 항상 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 에 의해 제공되는 입력 수신기 입니다.</target>
        </trans-unit>
        <trans-unit id="7d89ddec6391085569ef9d73498cfde0f5e37d2b" translate="yes" xml:space="preserve">
          <source>The exported &lt;code&gt;SavedModel&lt;/code&gt; is a standalone serialization of Tensorflow objects, and is supported by TF language APIs and the Tensorflow Serving system. To load the model, use the function &lt;code&gt;tf.keras.experimental.load_from_saved_model&lt;/code&gt;.</source>
          <target state="translated">내 보낸 &lt;code&gt;SavedModel&lt;/code&gt; 은 Tensorflow 오브젝트의 독립형 직렬화이며 TF 언어 API 및 Tensorflow Serving 시스템에서 지원됩니다. 모델을로드하려면 &lt;code&gt;tf.keras.experimental.load_from_saved_model&lt;/code&gt; 함수를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="115b43cdf7131901fe589992324081fddba4d32c" translate="yes" xml:space="preserve">
          <source>The factory function &lt;a href=&quot;raggedtensor#from_nested_row_splits&quot;&gt;&lt;code&gt;RaggedTensor.from_nested_row_splits&lt;/code&gt;&lt;/a&gt; may be used to construct a &lt;code&gt;RaggedTensor&lt;/code&gt; with multiple ragged dimensions directly, by providing a list of &lt;code&gt;row_splits&lt;/code&gt; tensors:</source>
          <target state="translated">팩토리 함수 &lt;a href=&quot;raggedtensor#from_nested_row_splits&quot;&gt; &lt;code&gt;RaggedTensor.from_nested_row_splits&lt;/code&gt; &lt;/a&gt; 는 &lt;code&gt;row_splits&lt;/code&gt; 텐서 목록을 제공하여 여러 개의 비정형 치수를 사용하여 &lt;code&gt;RaggedTensor&lt;/code&gt; 를 직접 구성하는 데 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="2fe7017c754a0ab851bc9cefd6824cd6141a0f6a" translate="yes" xml:space="preserve">
          <source>The features dict.</source>
          <target state="translated">The features dict.</target>
        </trans-unit>
        <trans-unit id="5250bfc0637fd3caf98029dfc4f15e7f982fc0a9" translate="yes" xml:space="preserve">
          <source>The filename of the text file to be used for initialization. The path must be accessible from wherever the graph is initialized (eg. trainer or eval workers). The filename may be a scalar &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">The filename of the text file to be used for initialization. The path must be accessible from wherever the graph is initialized (eg. trainer or eval workers). The filename may be a scalar &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a8e6fb1c6f484ae15d3065837532041a4bcf6093" translate="yes" xml:space="preserve">
          <source>The filename.</source>
          <target state="translated">파일 이름</target>
        </trans-unit>
        <trans-unit id="88abaf7b1285ab3d50567c2571a1737eb63924d9" translate="yes" xml:space="preserve">
          <source>The files in the dump directory contain the following information:</source>
          <target state="translated">The files in the dump directory contain the following information:</target>
        </trans-unit>
        <trans-unit id="84412542c638bfe39a033a0e5c516c5c165f7f74" translate="yes" xml:space="preserve">
          <source>The files in the dump directory contain the following information: - TensorFlow Function construction (e.g., compilation of Python functions decorated with @tf.function), the op types, names (if available), context, the input and output tensors, and the associated stack traces. - Execution of TensorFlow operations (ops) and Functions and their stack traces, op types, names (if available) and contexts. In addition, depending on the value of the &lt;code&gt;tensor_debug_mode&lt;/code&gt; argument (see Args section below), the value(s) of the output tensors or more concise summaries of the tensor values will be dumped. - A snapshot of Python source files involved in the execution of the TensorFlow program.</source>
          <target state="translated">덤프 디렉토리의 파일에는 다음 정보가 포함됩니다.-TensorFlow 함수 구성 (예 : @ tf.function으로 장식 된 Python 함수 컴파일), op 유형, 이름 (사용 가능한 경우), 컨텍스트, 입력 및 출력 텐서 및 관련 스택 추적. -TensorFlow 작업 (ops) 및 기능 및 해당 스택 추적, op 유형, 이름 (사용 가능한 경우) 및 컨텍스트 실행 또한 &lt;code&gt;tensor_debug_mode&lt;/code&gt; 인수의 값 (아래 Args 섹션 참조)에 따라 출력 텐서의 값 또는 텐서 값의 간결한 요약이 덤프됩니다. -TensorFlow 프로그램 실행과 관련된 Python 소스 파일의 스냅 샷.</target>
        </trans-unit>
        <trans-unit id="9b2fccc77c27cb9da14140ce6802364bb75efc8d" translate="yes" xml:space="preserve">
          <source>The final callable to be wrapped.</source>
          <target state="translated">The final callable to be wrapped.</target>
        </trans-unit>
        <trans-unit id="09f8439348997f787869e438ea0a2a5a324c4fe3" translate="yes" xml:space="preserve">
          <source>The final state. If &lt;code&gt;cell.state_size&lt;/code&gt; is an int, this will be shaped &lt;code&gt;[batch_size, cell.state_size]&lt;/code&gt;. If it is a &lt;code&gt;TensorShape&lt;/code&gt;, this will be shaped &lt;code&gt;[batch_size] + cell.state_size&lt;/code&gt;. If it is a (possibly nested) tuple of ints or &lt;code&gt;TensorShape&lt;/code&gt;, this will be a tuple having the corresponding shapes. If cells are &lt;code&gt;LSTMCells&lt;/code&gt;&lt;code&gt;state&lt;/code&gt; will be a tuple containing a &lt;code&gt;LSTMStateTuple&lt;/code&gt; for each cell.</source>
          <target state="translated">The final state. If &lt;code&gt;cell.state_size&lt;/code&gt; is an int, this will be shaped &lt;code&gt;[batch_size, cell.state_size]&lt;/code&gt; . If it is a &lt;code&gt;TensorShape&lt;/code&gt; , this will be shaped &lt;code&gt;[batch_size] + cell.state_size&lt;/code&gt; . If it is a (possibly nested) tuple of ints or &lt;code&gt;TensorShape&lt;/code&gt; , this will be a tuple having the corresponding shapes. If cells are &lt;code&gt;LSTMCells&lt;/code&gt; &lt;code&gt;state&lt;/code&gt; will be a tuple containing a &lt;code&gt;LSTMStateTuple&lt;/code&gt; for each cell.</target>
        </trans-unit>
        <trans-unit id="36ee6080bb9a8b37b0bbd48b91307f93d8a3c47a" translate="yes" xml:space="preserve">
          <source>The first and last &lt;code&gt;summarize&lt;/code&gt; elements within each dimension are recursively printed per Tensor. If None, then the first 3 and last 3 elements of each dimension are printed for each tensor. If set to -1, it will print all elements of every tensor.</source>
          <target state="translated">The first and last &lt;code&gt;summarize&lt;/code&gt; elements within each dimension are recursively printed per Tensor. If None, then the first 3 and last 3 elements of each dimension are printed for each tensor. If set to -1, it will print all elements of every tensor.</target>
        </trans-unit>
        <trans-unit id="64d3781f8c1cf2f73b0435ec5f118276a042b180" translate="yes" xml:space="preserve">
          <source>The first argument in the example slice is turned into &lt;code&gt;begin = 1&lt;/code&gt; and &lt;code&gt;end = begin + 1 = 2&lt;/code&gt;. To disambiguate from the original spec &lt;code&gt;2:4&lt;/code&gt; we also set the appropriate bit in &lt;code&gt;shrink_axis_mask&lt;/code&gt;.</source>
          <target state="translated">The first argument in the example slice is turned into &lt;code&gt;begin = 1&lt;/code&gt; and &lt;code&gt;end = begin + 1 = 2&lt;/code&gt; . To disambiguate from the original spec &lt;code&gt;2:4&lt;/code&gt; we also set the appropriate bit in &lt;code&gt;shrink_axis_mask&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="50c753605d6ee518cbe6dced5742e28ec63d5987" translate="yes" xml:space="preserve">
          <source>The first dict contains the context key/values.</source>
          <target state="translated">첫 번째 dict에는 컨텍스트 키 / 값이 포함되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="5344b4467816487b27f53d3359aea3ba20354b84" translate="yes" xml:space="preserve">
          <source>The first distribution.</source>
          <target state="translated">The first distribution.</target>
        </trans-unit>
        <trans-unit id="8723eb87dd8e28a8fab5df851a599f355edbe887" translate="yes" xml:space="preserve">
          <source>The first list to compare.</source>
          <target state="translated">The first list to compare.</target>
        </trans-unit>
        <trans-unit id="21b3efb51e905408dc7d30df6c5476374dd7b033" translate="yes" xml:space="preserve">
          <source>The first matching Enum class member in Enum class.</source>
          <target state="translated">Enum 클래스에서 첫 번째로 일치하는 Enum 클래스 멤버</target>
        </trans-unit>
        <trans-unit id="aea8fe33a13a43f1f933680d9ce0f5a2db48535e" translate="yes" xml:space="preserve">
          <source>The first matching element from enum_values.</source>
          <target state="translated">enum_values에서 첫 번째로 일치하는 요소</target>
        </trans-unit>
        <trans-unit id="1bce44f5aa098a07b694b38a57e97ffc2fd000fa" translate="yes" xml:space="preserve">
          <source>The first operand; &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">The first operand; &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bf18fd4e6ab37edcfe93bf741aad23fe79581af4" translate="yes" xml:space="preserve">
          <source>The first output contains a Tensor with the content of the audio samples. The lowest dimension will be the number of channels, and the second will be the number of samples. For example, a ten-sample-long stereo WAV file should give an output shape of [10, 2].</source>
          <target state="translated">첫 번째 출력에는 오디오 샘플의 내용이 포함 된 Tensor가 포함됩니다. 가장 낮은 차원은 채널 수이고 두 번째는 샘플 수입니다. 예를 들어, 10 샘플 길이의 스테레오 WAV 파일은 [10, 2]의 출력 형태를 제공해야합니다.</target>
        </trans-unit>
        <trans-unit id="0febdfe0f37ee26156ab95b6c46f6c5edc75f5fb" translate="yes" xml:space="preserve">
          <source>The first port number to start with for processes on a node.</source>
          <target state="translated">The first port number to start with for processes on a node.</target>
        </trans-unit>
        <trans-unit id="619642211ad5dce04a43e25b202652de1a8fad1c" translate="yes" xml:space="preserve">
          <source>The first sequence to compare.</source>
          <target state="translated">The first sequence to compare.</target>
        </trans-unit>
        <trans-unit id="dc9c74061cbc9739e15176d22eb3bd77d76e6366" translate="yes" xml:space="preserve">
          <source>The first set to compare.</source>
          <target state="translated">The first set to compare.</target>
        </trans-unit>
        <trans-unit id="852357a82fe8610e108e7001278c4fd3f4edcf3b" translate="yes" xml:space="preserve">
          <source>The first structure to compare.</source>
          <target state="translated">The first structure to compare.</target>
        </trans-unit>
        <trans-unit id="386e01aa23336af9951f682033560f681c83315e" translate="yes" xml:space="preserve">
          <source>The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data.</source>
          <target state="translated">데이터 세트가 처음 반복 될 때, 해당 요소는 지정된 파일이나 메모리에 캐시됩니다. 후속 반복에서는 캐시 된 데이터를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="8262a6a814226b4d2cd3a8aa3b8db9e5eb5fc35b" translate="yes" xml:space="preserve">
          <source>The first tuple to compare.</source>
          <target state="translated">The first tuple to compare.</target>
        </trans-unit>
        <trans-unit id="7ef6022d2f562cb6afde1b6c189e84e6188a8d28" translate="yes" xml:space="preserve">
          <source>The first value used (&lt;code&gt;elems[-1]&lt;/code&gt; in case of None)</source>
          <target state="translated">The first value used ( &lt;code&gt;elems[-1]&lt;/code&gt; in case of None)</target>
        </trans-unit>
        <trans-unit id="d030300b3efc2ffafb70c636249365dc53dadd74" translate="yes" xml:space="preserve">
          <source>The first value used (&lt;code&gt;elems[0]&lt;/code&gt; in case of None)</source>
          <target state="translated">The first value used ( &lt;code&gt;elems[0]&lt;/code&gt; in case of None)</target>
        </trans-unit>
        <trans-unit id="b7831825ba8f0a4c3399d402b9f0a29404570764" translate="yes" xml:space="preserve">
          <source>The flag object for this flag.</source>
          <target state="translated">The flag object for this flag.</target>
        </trans-unit>
        <trans-unit id="0f90632e85082c59f117ebff04eaae1a05ddf870" translate="yes" xml:space="preserve">
          <source>The flag value is parsed with a CSV parser.</source>
          <target state="translated">플래그 값은 CSV 파서로 구문 분석됩니다.</target>
        </trans-unit>
        <trans-unit id="96f145cafd13cfdf0d9a0f61a17dd04e31f2f508" translate="yes" xml:space="preserve">
          <source>The flag's current value is also updated if the flag is currently using the default value, i.e. not specified in the command line, and not set by FLAGS.name = value.</source>
          <target state="translated">플래그가 현재 기본값을 사용하는 경우 (예 : 명령 행에 지정되지 않고 FLAGS.name = value로 설정되지 않은 경우) 플래그의 현재 값도 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="43c9fd434671ebe599abe72c41c1f1beb298f354" translate="yes" xml:space="preserve">
          <source>The flow &lt;code&gt;Tensor&lt;/code&gt; forcing ops leading to this TensorArray state.</source>
          <target state="translated">흐름 &lt;code&gt;Tensor&lt;/code&gt; 강제 op가이 TensorArray 상태로 연결됩니다.</target>
        </trans-unit>
        <trans-unit id="1099e35b936ecbdd40bed25b2b837d0cd15a755e" translate="yes" xml:space="preserve">
          <source>The folded size of each dimension D of the output is:</source>
          <target state="translated">The folded size of each dimension D of the output is:</target>
        </trans-unit>
        <trans-unit id="5802a84878124b124beac42194fc2361ed2f11d6" translate="yes" xml:space="preserve">
          <source>The following &lt;code&gt;DType&lt;/code&gt; objects are defined:</source>
          <target state="translated">다음과 같은 &lt;code&gt;DType&lt;/code&gt; 객체가 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="f23bf2a65eeb471ae91c72707d1429b81ec5054e" translate="yes" xml:space="preserve">
          <source>The following accumulators/queue are created:</source>
          <target state="translated">다음과 같은 누산기 / 큐가 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="591cee6bba7aa3b795b8bd5b56dc88de0c7af0c0" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are experimental and may not be supported in future releases:</source>
          <target state="translated">다음 집계 방법은 실험적이며 이후 릴리스에서 지원되지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0a5195ca6a5ce9a55280235bcdfa18337e633d87" translate="yes" xml:space="preserve">
          <source>The following aggregation methods are part of the stable API for aggregating gradients:</source>
          <target state="translated">다음 집계 방법은 그라디언트 집계를위한 안정적인 API의 일부입니다.</target>
        </trans-unit>
        <trans-unit id="ed747da915011723a2fa4461445d8b7e32c7a59d" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="translated">The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../../../saved_model/save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</target>
        </trans-unit>
        <trans-unit id="6a52726e4632c6900863c9f3672bf906f2f1bdf5" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="translated">The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../../saved_model/save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</target>
        </trans-unit>
        <trans-unit id="492121a81bde0442283493d70aeb6ab59ed150cf" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="translated">The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../../saved_model/save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</target>
        </trans-unit>
        <trans-unit id="48a55cd9397b04385ee28d777547e0bf00cef4d5" translate="yes" xml:space="preserve">
          <source>The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../saved_model/save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</source>
          <target state="translated">The following can be either inside or outside the scope: ** Creating the input datasets ** Defining &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;s that represent your training step ** Saving APIs such as &lt;a href=&quot;../saved_model/save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt;. Loading creates variables, so that should go inside the scope if you want to train the model in a distributed way. ** Checkpoint saving. As mentioned above - &lt;code&gt;checkpoint.restore&lt;/code&gt; may sometimes need to be inside scope if it creates variables.</target>
        </trans-unit>
        <trans-unit id="2ee6cb9dfe69d9d22f1caaeae67551de61d1e04d" translate="yes" xml:space="preserve">
          <source>The following code examples are equivalent:</source>
          <target state="translated">다음 코드 예제는 동일합니다.</target>
        </trans-unit>
        <trans-unit id="fe70fcf720ef0fde06fcd7d33ac8492a73efc566" translate="yes" xml:space="preserve">
          <source>The following example can be rewritten using a numpy.ndarray instead of the &lt;code&gt;value&lt;/code&gt; list, even reshaped, as shown in the two commented lines below the &lt;code&gt;value&lt;/code&gt; list initialization.</source>
          <target state="translated">다음 예제는 &lt;code&gt;value&lt;/code&gt; 목록 초기화 아래에 주석 처리 된 두 줄에 표시된 것처럼 &lt;code&gt;value&lt;/code&gt; 목록 대신 numpy.ndarray를 사용하여 다시 작성할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="dd2231c4c2e6ac8a925f85e0e3d53aba21ee51d7" translate="yes" xml:space="preserve">
          <source>The following example creates a TensorFlow graph with &lt;code&gt;np.sinh()&lt;/code&gt; as an operation in the graph:</source>
          <target state="translated">다음 예제 는 그래프에서 조작으로 &lt;code&gt;np.sinh()&lt;/code&gt; 를 사용하여 TensorFlow 그래프를 작성합니다 .</target>
        </trans-unit>
        <trans-unit id="96cf93e8858013a75fb44334359039c6f25c846e" translate="yes" xml:space="preserve">
          <source>The following example demonstrates disabling the first GPU on the machine.</source>
          <target state="translated">다음 예제는 머신에서 첫 번째 GPU를 비활성화하는 방법을 보여줍니다.</target>
        </trans-unit>
        <trans-unit id="f5252c999d447d634884b440e481ad68aacf0ae9" translate="yes" xml:space="preserve">
          <source>The following example lists the number of visible GPUs on the host.</source>
          <target state="translated">다음 예제는 호스트에서 보이는 GPU 수를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="2cdccf83ed29fb9603555106e738bca275fd3c3f" translate="yes" xml:space="preserve">
          <source>The following example splits the CPU into 2 logical devices:</source>
          <target state="translated">다음 예제는 CPU를 2 개의 논리 장치로 분할합니다.</target>
        </trans-unit>
        <trans-unit id="4ace04a5fda844a89c5ee4c9be9654bd7abe4446" translate="yes" xml:space="preserve">
          <source>The following example splits the GPU into 2 logical devices with 100 MB each:</source>
          <target state="translated">다음 예제는 GPU를 각각 100MB의 논리 장치 2 개로 분할합니다.</target>
        </trans-unit>
        <trans-unit id="e92322d00886dec66262eaafdb4b32cf9a853e78" translate="yes" xml:space="preserve">
          <source>The following example verifies all visible GPUs have been disabled:</source>
          <target state="translated">다음 예제는 모든 보이는 GPU가 비활성화되었는지 확인합니다.</target>
        </trans-unit>
        <trans-unit id="4d32c07164d7968452b087497fbdd283446aa73c" translate="yes" xml:space="preserve">
          <source>The following is an example</source>
          <target state="translated">다음은 예입니다</target>
        </trans-unit>
        <trans-unit id="ed38596eeae1ed9d7dcfb7df999c45674415489a" translate="yes" xml:space="preserve">
          <source>The following is an example:</source>
          <target state="translated">다음은 예입니다.</target>
        </trans-unit>
        <trans-unit id="24bdb030bb46a068c505477e8cd1862a69826946" translate="yes" xml:space="preserve">
          <source>The following local variable is created:</source>
          <target state="translated">다음과 같은 지역 변수가 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="6c83149474e8e1bdaa43183ac0053126fc2f29c2" translate="yes" xml:space="preserve">
          <source>The following optional keyword arguments are reserved for specific uses:</source>
          <target state="translated">다음의 선택적 키워드 인수는 특정 용도로 예약되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="6b2e176467ad37b3b7339e39c7c7f1f162f5fc98" translate="yes" xml:space="preserve">
          <source>The following pieces are directly accessible as attributes of the &lt;code&gt;Scaffold&lt;/code&gt; object:</source>
          <target state="translated">다음은 &lt;code&gt;Scaffold&lt;/code&gt; 객체의 속성으로 직접 액세스 할 수있는 부분입니다 .</target>
        </trans-unit>
        <trans-unit id="c2ed2efebe2e500e729949e45ea5460a93f492fe" translate="yes" xml:space="preserve">
          <source>The following snippet initializes a table with the first column as keys and second column as values:</source>
          <target state="translated">다음 코드 조각은 첫 번째 열을 키로, 두 번째 열을 값으로 사용하여 테이블을 초기화합니다.</target>
        </trans-unit>
        <trans-unit id="e6f97267e796a462cd648b32cdaea5e143b3612c" translate="yes" xml:space="preserve">
          <source>The following standard keys are &lt;em&gt;defined&lt;/em&gt;, but their collections are &lt;strong&gt;not&lt;/strong&gt; automatically populated as many of the others are:</source>
          <target state="translated">다음과 같은 표준 키가 &lt;em&gt;정의&lt;/em&gt; 되어 있지만 다른 표준 키와 &lt;em&gt;같이&lt;/em&gt; 해당 컬렉션은 자동으로 채워 &lt;strong&gt;지지 않습니다&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="99bfb2634af3adab05d0f542c47d1e0966b2dddf" translate="yes" xml:space="preserve">
          <source>The following standard keys are defined:</source>
          <target state="translated">다음과 같은 표준 키가 정의되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="afd1e679060dea3282d2910a495bdcd89bae687d" translate="yes" xml:space="preserve">
          <source>The following table describes the performance of</source>
          <target state="translated">The following table describes the performance of</target>
        </trans-unit>
        <trans-unit id="3c31091b8864e6e40a0add92be10029fb2426b1d" translate="yes" xml:space="preserve">
          <source>The following table describes the size and accuracy of the 100% MobileNet</source>
          <target state="translated">The following table describes the size and accuracy of the 100% MobileNet</target>
        </trans-unit>
        <trans-unit id="b3f6e3ce6202511b6216af33c5c3cad6bb0dbfc1" translate="yes" xml:space="preserve">
          <source>The following will raise an exception starting 2.0</source>
          <target state="translated">The following will raise an exception starting 2.0</target>
        </trans-unit>
        <trans-unit id="91b487c69a091d3a3e964a72f6e8d59454bf3d7c" translate="yes" xml:space="preserve">
          <source>The format definition of the pattern is:</source>
          <target state="translated">The format definition of the pattern is:</target>
        </trans-unit>
        <trans-unit id="c5b0b8ccd1f0abc3ddefae0423fee59c58a2cd57" translate="yes" xml:space="preserve">
          <source>The fraction of zeros in &lt;code&gt;value&lt;/code&gt;, with type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;float32&lt;/code&gt; 유형의 &lt;code&gt;value&lt;/code&gt; 에서 0의 분수입니다 .</target>
        </trans-unit>
        <trans-unit id="2501fc3382d34a61610662e4f61871c3957e8082" translate="yes" xml:space="preserve">
          <source>The frame hop size in samples. An integer or scalar &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">The frame hop size in samples. An integer or scalar &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8eacf4bf4a1e68b198d56b34b1c0c689db8338a7" translate="yes" xml:space="preserve">
          <source>The frame length in samples. An integer or scalar &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">The frame length in samples. An integer or scalar &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bcd354bde47573036d72572be433b39a54714152" translate="yes" xml:space="preserve">
          <source>The frequency it should save at. Currently, the callback supports saving at the end of every epoch, or after a fixed number of training batches.</source>
          <target state="translated">The frequency it should save at. Currently, the callback supports saving at the end of every epoch, or after a fixed number of training batches.</target>
        </trans-unit>
        <trans-unit id="71fdf778c80994adcf246068ec1f8befff71b20a" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that a checkpoint is saved using a default checkpoint saver. If both &lt;code&gt;save_checkpoint_steps&lt;/code&gt; and &lt;code&gt;save_checkpoint_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default checkpoint saver isn't used. If both are provided, then only &lt;code&gt;save_checkpoint_secs&lt;/code&gt; is used. Default not enabled.</source>
          <target state="translated">The frequency, in number of global steps, that a checkpoint is saved using a default checkpoint saver. If both &lt;code&gt;save_checkpoint_steps&lt;/code&gt; and &lt;code&gt;save_checkpoint_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt; , then the default checkpoint saver isn't used. If both are provided, then only &lt;code&gt;save_checkpoint_secs&lt;/code&gt; is used. Default not enabled.</target>
        </trans-unit>
        <trans-unit id="2fb7193e8657058899d68bff4052e052b9f275c9" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that the global step and the loss will be logged during training. Also controls the frequency that the global steps / s will be logged (and written to summary) during training.</source>
          <target state="translated">The frequency, in number of global steps, that the global step and the loss will be logged during training. Also controls the frequency that the global steps / s will be logged (and written to summary) during training.</target>
        </trans-unit>
        <trans-unit id="0b502ff4833f61fd9f9f6d0ad8bb30c38b89b253" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that the global step/sec is logged.</source>
          <target state="translated">The frequency, in number of global steps, that the global step/sec is logged.</target>
        </trans-unit>
        <trans-unit id="905a157c941ebd772aa422c7c4efd7a063f30d17" translate="yes" xml:space="preserve">
          <source>The frequency, in number of global steps, that the summaries are written to disk using a default summary saver. If both &lt;code&gt;save_summaries_steps&lt;/code&gt; and &lt;code&gt;save_summaries_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default summary saver isn't used. Default 100.</source>
          <target state="translated">The frequency, in number of global steps, that the summaries are written to disk using a default summary saver. If both &lt;code&gt;save_summaries_steps&lt;/code&gt; and &lt;code&gt;save_summaries_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt; , then the default summary saver isn't used. Default 100.</target>
        </trans-unit>
        <trans-unit id="d58dfeea5f5010f5f4f788d0923d660ec7ad4548" translate="yes" xml:space="preserve">
          <source>The frequency, in seconds, that a checkpoint is saved using a default checkpoint saver. If both &lt;code&gt;save_checkpoint_steps&lt;/code&gt; and &lt;code&gt;save_checkpoint_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default checkpoint saver isn't used. If both are provided, then only &lt;code&gt;save_checkpoint_secs&lt;/code&gt; is used. Default 600.</source>
          <target state="translated">The frequency, in seconds, that a checkpoint is saved using a default checkpoint saver. If both &lt;code&gt;save_checkpoint_steps&lt;/code&gt; and &lt;code&gt;save_checkpoint_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt; , then the default checkpoint saver isn't used. If both are provided, then only &lt;code&gt;save_checkpoint_secs&lt;/code&gt; is used. Default 600.</target>
        </trans-unit>
        <trans-unit id="b936a6236c199c7dbaccd7f328139e3e55255549" translate="yes" xml:space="preserve">
          <source>The frequency, in secs, that the summaries are written to disk using a default summary saver. If both &lt;code&gt;save_summaries_steps&lt;/code&gt; and &lt;code&gt;save_summaries_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt;, then the default summary saver isn't used. Default not enabled.</source>
          <target state="translated">The frequency, in secs, that the summaries are written to disk using a default summary saver. If both &lt;code&gt;save_summaries_steps&lt;/code&gt; and &lt;code&gt;save_summaries_secs&lt;/code&gt; are set to &lt;code&gt;None&lt;/code&gt; , then the default summary saver isn't used. Default not enabled.</target>
        </trans-unit>
        <trans-unit id="992778fe6a92285eff91d32500db456a86a4fc54" translate="yes" xml:space="preserve">
          <source>The full name of this operation.</source>
          <target state="translated">이 작업의 전체 이름입니다.</target>
        </trans-unit>
        <trans-unit id="743b7a6db57523722e378bc070ddcab709a5ac83" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint (i.e. &lt;code&gt;file_prefix&lt;/code&gt;).</source>
          <target state="translated">검사 점의 전체 경로 (예 : &lt;code&gt;file_prefix&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="17174d3c9eb2bd17d3031f0d66dc8f9b3b509e75" translate="yes" xml:space="preserve">
          <source>The full path to the checkpoint.</source>
          <target state="translated">검사 점의 전체 경로입니다.</target>
        </trans-unit>
        <trans-unit id="acdec3e98e6b61dcd2da29992ebc62ad6f5bf20c" translate="yes" xml:space="preserve">
          <source>The full path to the latest checkpoint or &lt;code&gt;None&lt;/code&gt; if no checkpoint was found.</source>
          <target state="translated">최신 검사 점의 전체 경로 또는 검사 점이없는 경우 &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3f455e1b045b42fc22bb44e2db67ba33bc859100" translate="yes" xml:space="preserve">
          <source>The function 'f' must be a numerical function which takes N inputs and produces M outputs. Its gradient function 'g', which is computed by this SymbolicGradient op is a function taking N + M inputs and produces N outputs.</source>
          <target state="translated">The function 'f' must be a numerical function which takes N inputs and produces M outputs. Its gradient function 'g', which is computed by this SymbolicGradient op is a function taking N + M inputs and produces N outputs.</target>
        </trans-unit>
        <trans-unit id="47f2fc665d0afe391e8a43fb1ae4db7142668b97" translate="yes" xml:space="preserve">
          <source>The function &lt;code&gt;grad_grad_fn&lt;/code&gt; will be calculating the first order gradient of &lt;code&gt;grad_fn&lt;/code&gt; with respect to &lt;code&gt;dy&lt;/code&gt;, which is used to generate forward-mode gradient graphs from backward-mode gradient graphs, but is not the same as the second order gradient of &lt;code&gt;op&lt;/code&gt; with respect to &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;grad_grad_fn&lt;/code&gt; 함수 는 &lt;code&gt;dy&lt;/code&gt; 에 대한 &lt;code&gt;grad_fn&lt;/code&gt; 의 1 차 그라디언트를 계산합니다 . 이는 그라디언트 모드 그라디언트 그래프에서 순방향 모드 그라디언트 그래프를 생성하는 데 사용되지만 &lt;code&gt;x&lt;/code&gt; 에 대한 &lt;code&gt;op&lt;/code&gt; 의 2 차 그라디언트와 동일하지 않습니다. .</target>
        </trans-unit>
        <trans-unit id="45872032316d782b7cca27465e024bb311aaa0d6" translate="yes" xml:space="preserve">
          <source>The function arguments use the same convention as Theano's arange: if only one argument is provided, it is in fact the &quot;stop&quot; argument and &quot;start&quot; is 0.</source>
          <target state="translated">함수 인수는 Theano의 배열과 동일한 규칙을 사용합니다. 하나의 인수 만 제공하면 실제로는 &quot;stop&quot;인수이고 &quot;start&quot;는 0입니다.</target>
        </trans-unit>
        <trans-unit id="5b48f1f01f262f6a95842647a89db44aed8acfaa" translate="yes" xml:space="preserve">
          <source>The function given by &lt;code&gt;f&lt;/code&gt; is assumed to be stateless, and is executed concurrently on all the slices; up to batch_size (i.e. the size of the 0th dimension of each argument) functions will be scheduled at once.</source>
          <target state="translated">The function given by &lt;code&gt;f&lt;/code&gt; is assumed to be stateless, and is executed concurrently on all the slices; up to batch_size (i.e. the size of the 0th dimension of each argument) functions will be scheduled at once.</target>
        </trans-unit>
        <trans-unit id="a54988c5a27bf3df304066330e8659cc62c5ae14" translate="yes" xml:space="preserve">
          <source>The function may use variable scopes and other templates internally to create and reuse variables, but it shouldn't use &lt;a href=&quot;global_variables&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt;&lt;/a&gt; to capture variables that are defined outside of the scope of the function.</source>
          <target state="translated">이 함수는 변수 범위 및 기타 템플릿을 내부적으로 사용하여 변수를 만들고 재사용 할 수 있지만 &lt;a href=&quot;global_variables&quot;&gt; &lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt; &lt;/a&gt; 를 사용 하여 함수 범위 밖에서 정의 된 변수를 캡처 해서는 안됩니다 .</target>
        </trans-unit>
        <trans-unit id="7473045784de1b0d1dced2ea1e88e2739636aca8" translate="yes" xml:space="preserve">
          <source>The function returns a 1-arg callable to compute the piecewise constant when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="translated">이 함수는 현재 최적화 단계를 통과 할 때 부분 상수를 계산하기 위해 1-arg 호출 가능을 반환합니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7935c69bd80f01354e2709843f6b51eb870975aa" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate while taking into account possible warm restarts. The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="translated">이 함수는 가능한 웜 재시작을 고려하면서 붕괴 된 학습 속도를 반환합니다. 학습 속도 승수 는 &lt;code&gt;first_decay_steps&lt;/code&gt; 단계에 대해 먼저 1에서 &lt;code&gt;alpha&lt;/code&gt; 로 감소 합니다. 그런 다음 웜 재시작이 수행됩니다. 각각의 새로운 웜 리 스타트는 &lt;code&gt;t_mul&lt;/code&gt; 배 더 많은 단계와 &lt;code&gt;m_mul&lt;/code&gt; 배 더 작은 초기 학습 속도로 실행됩니다.</target>
        </trans-unit>
        <trans-unit id="86355e2388af8622a11980472ee114bf3a474b98" translate="yes" xml:space="preserve">
          <source>The function returns the decayed learning rate. It is computed as:</source>
          <target state="translated">이 함수는 학습 속도 감소를 반환합니다. 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="bbeb4f9954a2b9fb0a88492d0bff2e967c29ba25" translate="yes" xml:space="preserve">
          <source>The function should create all trainable variables and any variables that should be reused by calling &lt;a href=&quot;get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt;&lt;/a&gt;. If a trainable variable is created using &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;, then a ValueError will be thrown. Variables that are intended to be locals can be created by specifying &lt;a href=&quot;../../variable&quot;&gt;&lt;code&gt;tf.Variable(..., trainable=false)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 함수는 훈련 가능한 모든 변수와 &lt;a href=&quot;get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt; &lt;/a&gt; 을 호출하여 재사용해야하는 모든 변수를 작성해야합니다 . 훈련 가능한 변수가 &lt;a href=&quot;../../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; 을&lt;/a&gt; 사용하여 생성 되면 ValueError가 발생합니다. &lt;a href=&quot;../../variable&quot;&gt; &lt;code&gt;tf.Variable(..., trainable=false)&lt;/code&gt; &lt;/a&gt; 를 지정하여 지역 변수로 만들려는 변수를 만들 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ba018ba32690d333b62a34c97deeda897ce164c2" translate="yes" xml:space="preserve">
          <source>The function to be evaluated. Takes input tensor as first argument.</source>
          <target state="translated">The function to be evaluated. Takes input tensor as first argument.</target>
        </trans-unit>
        <trans-unit id="e907a33ddfd6da0b56e4114475edd885278841a5" translate="yes" xml:space="preserve">
          <source>The function to execute. Must return at least one tensor.</source>
          <target state="translated">The function to execute. Must return at least one tensor.</target>
        </trans-unit>
        <trans-unit id="0e4d2297438553bf056c22e891e3cecb8fe842de" translate="yes" xml:space="preserve">
          <source>The function to run to generate values. It is called for each replica with &lt;code&gt;tf.distribute.ValueContext&lt;/code&gt; as the sole argument. It must return a Tensor or a type that can be converted to a Tensor.</source>
          <target state="translated">The function to run to generate values. It is called for each replica with &lt;code&gt;tf.distribute.ValueContext&lt;/code&gt; as the sole argument. It must return a Tensor or a type that can be converted to a Tensor.</target>
        </trans-unit>
        <trans-unit id="5cb705f7c58e8e1b04b26492ea1ad09028dbf43c" translate="yes" xml:space="preserve">
          <source>The function to run. The inputs to the function must match the outputs of &lt;code&gt;input_iterator.get_next()&lt;/code&gt;. The output must be a &lt;a href=&quot;../../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="translated">The function to run. The inputs to the function must match the outputs of &lt;code&gt;input_iterator.get_next()&lt;/code&gt; . The output must be a &lt;a href=&quot;../../../../nest&quot;&gt; &lt;code&gt;tf.nest&lt;/code&gt; &lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt; s.</target>
        </trans-unit>
        <trans-unit id="579f33c18a20c35d0e6bad8c31ac59b2c5a138bd" translate="yes" xml:space="preserve">
          <source>The function to run. The inputs to the function must match the outputs of &lt;code&gt;input_iterator.get_next()&lt;/code&gt;. The output must be a &lt;a href=&quot;../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="translated">The function to run. The inputs to the function must match the outputs of &lt;code&gt;input_iterator.get_next()&lt;/code&gt; . The output must be a &lt;a href=&quot;../../../nest&quot;&gt; &lt;code&gt;tf.nest&lt;/code&gt; &lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt; s.</target>
        </trans-unit>
        <trans-unit id="852a50a7728a6fd7607421cbe4af6011056e859b" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="translated">The function to run. The output must be a &lt;a href=&quot;../../../../nest&quot;&gt; &lt;code&gt;tf.nest&lt;/code&gt; &lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt; s.</target>
        </trans-unit>
        <trans-unit id="d27cb3a61380f733c1a764c217224b74c44ff381" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="translated">The function to run. The output must be a &lt;a href=&quot;../../../nest&quot;&gt; &lt;code&gt;tf.nest&lt;/code&gt; &lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt; s.</target>
        </trans-unit>
        <trans-unit id="cd6977a402d5af69ff9d5af0a33cb56304518592" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="translated">The function to run. The output must be a &lt;a href=&quot;../../nest&quot;&gt; &lt;code&gt;tf.nest&lt;/code&gt; &lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt; s.</target>
        </trans-unit>
        <trans-unit id="78ce4aa7e51e00f628bab76b1b138c468eab06e1" translate="yes" xml:space="preserve">
          <source>The function to run. The output must be a &lt;a href=&quot;../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt;s.</source>
          <target state="translated">The function to run. The output must be a &lt;a href=&quot;../nest&quot;&gt; &lt;code&gt;tf.nest&lt;/code&gt; &lt;/a&gt; of &lt;code&gt;Tensor&lt;/code&gt; s.</target>
        </trans-unit>
        <trans-unit id="7d78455957704f506f9390b364cd5e99854c75cd" translate="yes" xml:space="preserve">
          <source>The function to use for the KL divergence.</source>
          <target state="translated">The function to use for the KL divergence.</target>
        </trans-unit>
        <trans-unit id="818483846ef2282fe88a2ae296752a2d10573267" translate="yes" xml:space="preserve">
          <source>The function to wrap.</source>
          <target state="translated">랩핑하는 기능.</target>
        </trans-unit>
        <trans-unit id="8e1312f2dcf17101a4e17a36133e6bbffe530ce3" translate="yes" xml:space="preserve">
          <source>The function writes the SavedModel protocol buffer to the export directory in serialized format.</source>
          <target state="translated">이 함수는 SavedModel 프로토콜 버퍼를 직렬화 된 형식으로 내보내기 디렉토리에 씁니다.</target>
        </trans-unit>
        <trans-unit id="00cf308c9f40a9f1b859f12fd033e78caa4d14cd" translate="yes" xml:space="preserve">
          <source>The functions &lt;code&gt;f1&lt;/code&gt; and &lt;code&gt;f2&lt;/code&gt; will be executed serially, and updates to &lt;code&gt;v&lt;/code&gt; will be atomic.</source>
          <target state="translated">기능 &lt;code&gt;f1&lt;/code&gt; 및 &lt;code&gt;f2&lt;/code&gt; 는 순차적으로 실행되며 &lt;code&gt;v&lt;/code&gt; 에 대한 업데이트 는 원 자성입니다.</target>
        </trans-unit>
        <trans-unit id="dde4529b22d96c16a9b96a541d58c5d0a1f7056a" translate="yes" xml:space="preserve">
          <source>The generated &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt;&lt;code&gt;Summary&lt;/code&gt;&lt;/a&gt; has one summary value containing a histogram for &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="translated">생성 된 &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto&quot;&gt; &lt;code&gt;Summary&lt;/code&gt; &lt;/a&gt; 에는 값에 대한 히스토그램을 포함하는 하나의 요약 값이 &lt;code&gt;values&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="062e4980e54d60fb22e75f6c9b5206c3bc85ad28" translate="yes" xml:space="preserve">
          <source>The generated Summary has a Tensor.proto containing the input Tensor.</source>
          <target state="translated">생성 된 요약에는 입력 Tensor를 포함하는 Tensor.proto가 있습니다.</target>
        </trans-unit>
        <trans-unit id="83836bb270c947f8350589c70a4bb97f00394569" translate="yes" xml:space="preserve">
          <source>The generated batches contain augmented/normalized data.</source>
          <target state="translated">The generated batches contain augmented/normalized data.</target>
        </trans-unit>
        <trans-unit id="83e4f5e3d1731cbc1599b80b8ef76caeb81edab7" translate="yes" xml:space="preserve">
          <source>The generated values are uniform integers covering the whole range of &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">The generated values are uniform integers covering the whole range of &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e4d0e9a2a91b309d7ff0adf11bf3c435181bcb9c" translate="yes" xml:space="preserve">
          <source>The generated values are uniform integers in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded.</source>
          <target state="translated">The generated values are uniform integers in the range &lt;code&gt;[minval, maxval)&lt;/code&gt; . The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded.</target>
        </trans-unit>
        <trans-unit id="1a8e22261f08ee2c0135f17d838b4636ab11c865" translate="yes" xml:space="preserve">
          <source>The generated values follow a Poisson distribution with specified rate parameter.</source>
          <target state="translated">The generated values follow a Poisson distribution with specified rate parameter.</target>
        </trans-unit>
        <trans-unit id="2e6c1194a7570536aae2b3653d7c1dba93fd5851" translate="yes" xml:space="preserve">
          <source>The generated values follow a binomial distribution with specified count and probability of success parameters.</source>
          <target state="translated">생성 된 값은 지정된 개수와 성공 확률 매개 변수로 이항 분포를 따릅니다.</target>
        </trans-unit>
        <trans-unit id="8a3b970769a2106f11ed64fa7b1620c03aad121a" translate="yes" xml:space="preserve">
          <source>The generated values follow a gamma distribution with specified concentration (&lt;code&gt;alpha&lt;/code&gt;) and inverse scale (&lt;code&gt;beta&lt;/code&gt;) parameters.</source>
          <target state="translated">The generated values follow a gamma distribution with specified concentration ( &lt;code&gt;alpha&lt;/code&gt; ) and inverse scale ( &lt;code&gt;beta&lt;/code&gt; ) parameters.</target>
        </trans-unit>
        <trans-unit id="aaccd314351760e5cabf42f9640ec2685d7cb77b" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with mean 0 and standard deviation 1, except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked.</source>
          <target state="translated">The generated values follow a normal distribution with mean 0 and standard deviation 1, except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked.</target>
        </trans-unit>
        <trans-unit id="34cfd1936eb36f5d55d6eea6019586d8abfd6453" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked.</source>
          <target state="translated">생성 된 값은 평균과 표준 편차가 2보다 큰 표준 편차를 제외하고 지정된 평균 및 표준 편차를 갖는 정규 분포를 따릅니다.</target>
        </trans-unit>
        <trans-unit id="0f713a6a0ff6a46795bef18d9e29d3e2780e55f6" translate="yes" xml:space="preserve">
          <source>The generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than two standard deviations from the mean are dropped and re-picked.</source>
          <target state="translated">생성 된 값은 평균과 표준 편차가 2보다 큰 표준 편차를 제외하고 지정된 평균 및 표준 편차를 갖는 정규 분포를 따릅니다.</target>
        </trans-unit>
        <trans-unit id="ad922f688ee4660e4c8bf530c9eb75a9c98e5b45" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[0, 1)&lt;/code&gt;. The lower bound 0 is included in the range, while the upper bound 1 is excluded.</source>
          <target state="translated">The generated values follow a uniform distribution in the range &lt;code&gt;[0, 1)&lt;/code&gt; . The lower bound 0 is included in the range, while the upper bound 1 is excluded.</target>
        </trans-unit>
        <trans-unit id="74c424169a88b80e0d5085c0b28049f21d25d95f" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;.</source>
          <target state="translated">The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c4eafca9e4f8c3067d55709b52f16b752c27ed7e" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded.</source>
          <target state="translated">생성 된 값은 &lt;code&gt;[minval, maxval)&lt;/code&gt; 범위의 균일 한 분포를 따릅니다 . 하한 &lt;code&gt;minval&lt;/code&gt; 상한 동안 범위에 포함 &lt;code&gt;maxval&lt;/code&gt; 제외된다.</target>
        </trans-unit>
        <trans-unit id="729a8a331d955e25ac8cf2c6b6a31b0effcb1a59" translate="yes" xml:space="preserve">
          <source>The generated values follow a uniform distribution in the range &lt;code&gt;[minval, maxval)&lt;/code&gt;. The lower bound &lt;code&gt;minval&lt;/code&gt; is included in the range, while the upper bound &lt;code&gt;maxval&lt;/code&gt; is excluded. (For float numbers especially low-precision types like bfloat16, because of rounding, the result may sometimes include &lt;code&gt;maxval&lt;/code&gt;.)</source>
          <target state="translated">생성 된 값은 &lt;code&gt;[minval, maxval)&lt;/code&gt; 범위의 균일 한 분포를 따릅니다 . 하한 &lt;code&gt;minval&lt;/code&gt; 상한 동안 범위에 포함 &lt;code&gt;maxval&lt;/code&gt; 제외된다. (float 숫자 특히 bfloat16과 같은 정밀도가 낮은 유형의 경우 반올림으로 인해 결과에 때때로 &lt;code&gt;maxval&lt;/code&gt; 이 포함될 수 있습니다 .)</target>
        </trans-unit>
        <trans-unit id="3ef793d516e9c255e6083a55e2c214fa9d53e3d0" translate="yes" xml:space="preserve">
          <source>The generated values will have mean 0 and standard deviation 1.</source>
          <target state="translated">The generated values will have mean 0 and standard deviation 1.</target>
        </trans-unit>
        <trans-unit id="435c1caf59e1323627f0000c63fea7965b6e39ca" translate="yes" xml:space="preserve">
          <source>The gist of RMSprop is to:</source>
          <target state="translated">The gist of RMSprop is to:</target>
        </trans-unit>
        <trans-unit id="3f254b2b1969b3fd6753653a609c42efa67f8dfa" translate="yes" xml:space="preserve">
          <source>The given &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt; can be merged as long as there does not exist an attribute that is set to different values in &lt;code&gt;self&lt;/code&gt; and &lt;code&gt;options&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; 및 &lt;code&gt;options&lt;/code&gt; 에 다른 값으로 설정된 속성이없는 한 지정된 &lt;a href=&quot;options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; 를 병합 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="0d60ebc741d192476c8f1b6c1be3c6bd74a4d508" translate="yes" xml:space="preserve">
          <source>The given tensors are sliced along their first dimension. This operation preserves the structure of the input tensors, removing the first dimension of each tensor and using it as the dataset dimension. All input tensors must have the same size in their first dimensions.</source>
          <target state="translated">주어진 텐서는 첫 번째 치수를 따라 슬라이스됩니다. 이 작업은 입력 텐서의 구조를 유지하여 각 텐서의 첫 번째 차원을 제거하고이를 데이터 세트 차원으로 사용합니다. 모든 입력 텐서는 첫 번째 치수에서 동일한 크기를 가져야합니다.</target>
        </trans-unit>
        <trans-unit id="c5f30df096e972187d2845f5f792a695d8948e14" translate="yes" xml:space="preserve">
          <source>The global &lt;a href=&quot;generator&quot;&gt;&lt;code&gt;tf.random.Generator&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">The global &lt;a href=&quot;generator&quot;&gt; &lt;code&gt;tf.random.Generator&lt;/code&gt; &lt;/a&gt; object.</target>
        </trans-unit>
        <trans-unit id="ccd566669127e41c5c83f5e51e6e655e2023b466" translate="yes" xml:space="preserve">
          <source>The global Policy.</source>
          <target state="translated">글로벌 정책.</target>
        </trans-unit>
        <trans-unit id="d7a438a2cfde234e4966d3aff26afbb96ef542c4" translate="yes" xml:space="preserve">
          <source>The global batch size that you indend to use. Note that is fixed and the same batch size must be used for both training and evaluation.</source>
          <target state="translated">The global batch size that you indend to use. Note that is fixed and the same batch size must be used for both training and evaluation.</target>
        </trans-unit>
        <trans-unit id="7f44fcbf38635afbe0c45b61c517d01f18c4ad9b" translate="yes" xml:space="preserve">
          <source>The global id in the training cluster.</source>
          <target state="translated">교육 클러스터의 글로벌 ID입니다.</target>
        </trans-unit>
        <trans-unit id="c06234718e1efd425d9fee36736f9c49d1c25446" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no global policy is set, layers will instead default to a Policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2. In TensorFlow 1, layers default to an &quot;infer&quot; policy.</source>
          <target state="translated">전역 정책은 정책이 계층 생성자에 전달되지 않은 경우 계층에 사용되는 기본 정책입니다. 글로벌 정책이 설정되어 있지 않으면 레이어는 대신 TensorFlow 2의 &lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt; 로 구성된 정책으로 기본 설정됩니다 . TensorFlow 1에서 레이어는 기본적으로 &quot;추론&quot;정책으로 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="a24374cc9cda5c5142d42bd656066ec74ccfe3d0" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no global policy is set, layers will instead default to a Policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no global policy is set, layers will instead default to a Policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="c1016f9f2efa6dbdf2080ac5fb0e6a2efdf1abe3" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no policy has been set with &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt;, this will return a policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; (floatx defaults to float32).</source>
          <target state="translated">The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no policy has been set with &lt;a href=&quot;set_policy&quot;&gt; &lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt; &lt;/a&gt;, this will return a policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt; (floatx defaults to float32).</target>
        </trans-unit>
        <trans-unit id="9aa023817c66fefe7d12596fe9f5c2f950738ad5" translate="yes" xml:space="preserve">
          <source>The global policy is the default policy used for layers, if no policy is passed to the layer constructor. If no policy has been set with &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt;, this will return a policy constructed from &lt;a href=&quot;../../backend/floatx&quot;&gt;&lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt;&lt;/a&gt; in TensorFlow 2 (floatx defaults to float32), or an &quot;infer&quot; policy in TensorFlow 1.</source>
          <target state="translated">전역 정책은 정책이 계층 생성자에 전달되지 않은 경우 계층에 사용되는 기본 정책입니다. &lt;a href=&quot;set_policy&quot;&gt; &lt;code&gt;keras.mixed_precision.experimental.set_policy&lt;/code&gt; &lt;/a&gt; 로 설정된 정책이없는 경우 TensorFlow 2의 &lt;a href=&quot;../../backend/floatx&quot;&gt; &lt;code&gt;tf.keras.backend.floatx()&lt;/code&gt; &lt;/a&gt; 에서 구성된 정책 (floatx 기본값은 float32로 설정 됨) 또는 TensorFlow 1의 &quot;추론&quot;정책 이 반환됩니다. .</target>
        </trans-unit>
        <trans-unit id="147a0f3f093ca1fdfeeb131812693ae892afe50f" translate="yes" xml:space="preserve">
          <source>The global step tensor must be an integer variable. We first try to find it in the collection &lt;code&gt;GLOBAL_STEP&lt;/code&gt;, or by name &lt;code&gt;global_step:0&lt;/code&gt;.</source>
          <target state="translated">전역 단계 텐서는 정수 변수 여야합니다. 먼저 &lt;code&gt;GLOBAL_STEP&lt;/code&gt; 컬렉션 에서 또는 &lt;code&gt;global_step:0&lt;/code&gt; 이라는 이름 으로 찾아보십시오 .</target>
        </trans-unit>
        <trans-unit id="1b54d047ac096c3ae7f021822844b86acfbb5227" translate="yes" xml:space="preserve">
          <source>The global step tensor.</source>
          <target state="translated">글로벌 스텝 텐서.</target>
        </trans-unit>
        <trans-unit id="95db374c08adfbc24c444a5e0edf15c6723034b8" translate="yes" xml:space="preserve">
          <source>The global step value.</source>
          <target state="translated">글로벌 단계 값.</target>
        </trans-unit>
        <trans-unit id="27f92d2c600461e2b55ce1161093f706c000d648" translate="yes" xml:space="preserve">
          <source>The global step variable, or &lt;code&gt;None&lt;/code&gt; if none was found.</source>
          <target state="translated">글로벌 단계의 변수 또는 &lt;code&gt;None&lt;/code&gt; 전혀 발견되지 않은 경우.</target>
        </trans-unit>
        <trans-unit id="99d903697b9ca80a681aa088eea14a311d3cfb53" translate="yes" xml:space="preserve">
          <source>The goal of this op is to produce a new tensor with a subset of the elements from the &lt;code&gt;n&lt;/code&gt; dimensional &lt;code&gt;input&lt;/code&gt; tensor. The subset is chosen using a sequence of &lt;code&gt;m&lt;/code&gt; sparse range specifications encoded into the arguments of this function. Note, in some cases &lt;code&gt;m&lt;/code&gt; could be equal to &lt;code&gt;n&lt;/code&gt;, but this need not be the case. Each range specification entry can be one of the following:</source>
          <target state="translated">The goal of this op is to produce a new tensor with a subset of the elements from the &lt;code&gt;n&lt;/code&gt; dimensional &lt;code&gt;input&lt;/code&gt; tensor. The subset is chosen using a sequence of &lt;code&gt;m&lt;/code&gt; sparse range specifications encoded into the arguments of this function. Note, in some cases &lt;code&gt;m&lt;/code&gt; could be equal to &lt;code&gt;n&lt;/code&gt; , but this need not be the case. Each range specification entry can be one of the following:</target>
        </trans-unit>
        <trans-unit id="4b19676d8e2406a216d2d74b877270145ae7d383" translate="yes" xml:space="preserve">
          <source>The gradient &lt;code&gt;IndexedSlices&lt;/code&gt; to be applied.</source>
          <target state="translated">The gradient &lt;code&gt;IndexedSlices&lt;/code&gt; to be applied.</target>
        </trans-unit>
        <trans-unit id="a2344c5579f4717a0862d524efae16729bc6ed70" translate="yes" xml:space="preserve">
          <source>The gradient computation of this operation will only take advantage of sparsity in the input gradient when that gradient comes from a Relu.</source>
          <target state="translated">이 연산의 그래디언트 계산은 해당 그래디언트가 Relu에서 발생할 때 입력 그래디언트의 희소성을 활용합니다.</target>
        </trans-unit>
        <trans-unit id="d051520aa4dd277f3ed0bb66ae2aa2ab1b266a18" translate="yes" xml:space="preserve">
          <source>The gradient computed for 'op_type' will then propagate zeros.</source>
          <target state="translated">'op_type'에 대해 계산 된 그래디언트는 0을 전파합니다.</target>
        </trans-unit>
        <trans-unit id="71b1d3537cf96813de8a96c3c5f5d393309ab752" translate="yes" xml:space="preserve">
          <source>The gradient expression can be analytically simplified to provide numerical stability:</source>
          <target state="translated">수치 표현을 제공하기 위해 구배 표현을 분석적으로 단순화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="66f6394f68f095fb6407b72059c63e54607c1a7e" translate="yes" xml:space="preserve">
          <source>The gradient of SparseFillEmptyRows.</source>
          <target state="translated">The gradient of SparseFillEmptyRows.</target>
        </trans-unit>
        <trans-unit id="7ab3e3e9ec9dadb6bed29c4d9fadd240cfe53d58" translate="yes" xml:space="preserve">
          <source>The gradient of y with respect to x can be zero in two different ways: there could be no differentiable path in the graph connecting x to y (and so we can statically prove that the gradient is zero) or it could be that runtime values of tensors in a particular execution lead to a gradient of zero (say, if a relu unit happens to not be activated). To allow you to distinguish between these two cases you can choose what value gets returned for the gradient when there is no path in the graph from x to y:</source>
          <target state="translated">x에 대한 y의 기울기는 두 가지 방법으로 0이 될 수 있습니다. x에 y를 연결하는 그래프에 구별 가능한 경로가 없거나 (그래서 우리는 기울기가 0임을 정적으로 증명할 수 있습니다) 또는 다음의 런타임 값일 수 있습니다 특정 실행에서 텐서는 0의 기울기로 이어집니다 (즉, relu 장치가 활성화되지 않은 경우). 이 두 경우를 구별하기 위해 그래프에 x에서 y까지의 경로가 없을 때 그라디언트에 대해 반환되는 값을 선택할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="e557b207c1bf0f24f7b6478ec86b6e18a701dea1" translate="yes" xml:space="preserve">
          <source>The gradient operator for the SparseAdd op.</source>
          <target state="translated">The gradient operator for the SparseAdd op.</target>
        </trans-unit>
        <trans-unit id="1aa83bb60002d17ea0a36a621a83f096102e24dd" translate="yes" xml:space="preserve">
          <source>The gradient operator for the SparseSlice op.</source>
          <target state="translated">The gradient operator for the SparseSlice op.</target>
        </trans-unit>
        <trans-unit id="506e6c0e4b5d041a489d5af54d1312d2417b8fa8" translate="yes" xml:space="preserve">
          <source>The gradient tensor to be applied.</source>
          <target state="translated">The gradient tensor to be applied.</target>
        </trans-unit>
        <trans-unit id="f6537a20daecb5b5cdb196626f45c6602644de72" translate="yes" xml:space="preserve">
          <source>The gradients of SparseMatrixAdd outputs with respect to alpha and beta are not currently defined (TensorFlow will return zeros for these entries).</source>
          <target state="translated">The gradients of SparseMatrixAdd outputs with respect to alpha and beta are not currently defined (TensorFlow will return zeros for these entries).</target>
        </trans-unit>
        <trans-unit id="f5c157361d6bbe7fc68fa055766a81dc3624c016" translate="yes" xml:space="preserve">
          <source>The graph described by the protocol buffer will be displayed by TensorBoard. Most users pass a graph in the constructor instead.</source>
          <target state="translated">프로토콜 버퍼에 의해 설명 된 그래프는 TensorBoard에 의해 표시됩니다. 대부분의 사용자는 대신 생성자에 그래프를 전달합니다.</target>
        </trans-unit>
        <trans-unit id="cee27050675be79d589848fe27aab1e7b8f14449" translate="yes" xml:space="preserve">
          <source>The graph in which to create the global step tensor. If missing, use default graph.</source>
          <target state="translated">The graph in which to create the global step tensor. If missing, use default graph.</target>
        </trans-unit>
        <trans-unit id="fbdbb3541583ec055cc057fc7380e7b06e65a362" translate="yes" xml:space="preserve">
          <source>The graph is not frozen. input_arrays or output_arrays contains an invalid tensor name. input_shapes is not correctly defined when required</source>
          <target state="translated">The graph is not frozen. input_arrays or output_arrays contains an invalid tensor name. input_shapes is not correctly defined when required</target>
        </trans-unit>
        <trans-unit id="661d2d430bf12295ddf1be3a1e881f38bccfdb01" translate="yes" xml:space="preserve">
          <source>The graph is written as a text proto unless &lt;code&gt;as_text&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;as_text&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 가 아닌 한 그래프는 텍스트 프로토 타입으로 작성됩니다 .</target>
        </trans-unit>
        <trans-unit id="ed620881b1cf97ec1349e99d3e7fd253aa216b39" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the &lt;code&gt;dtype&lt;/code&gt; of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in  auto_mixed_precision_lists.h:</source>
          <target state="translated">그래프 재 작성 조작 은 그래프에서 특정 조작 의 &lt;code&gt;dtype&lt;/code&gt; 을 float32에서 float16으로 변경합니다. 이 다시 쓰기 작업에 포함되거나 제외되는 몇 가지 범주의 작업이 있습니다. 다음 범주의 Ops는 &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; 의 AutoMixedPrecisionLists 클래스 아래 해당 기능 내에 정의되어 있습니다 .</target>
        </trans-unit>
        <trans-unit id="f8a95853ba686885563f0cb093070ca0be189fd7" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the &lt;code&gt;dtype&lt;/code&gt; of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h&quot;&gt; auto_mixed_precision_lists.h&lt;/a&gt;:</source>
          <target state="translated">The graph rewrite operation changes the &lt;code&gt;dtype&lt;/code&gt; of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h&quot;&gt; auto_mixed_precision_lists.h&lt;/a&gt;:</target>
        </trans-unit>
        <trans-unit id="392b7dd1d0b2ec49c8bc79fcfe637691fe3461a3" translate="yes" xml:space="preserve">
          <source>The graph rewrite operation changes the dtype of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h&quot;&gt; auto_mixed_precision_lists.h&lt;/a&gt;:</source>
          <target state="translated">The graph rewrite operation changes the dtype of certain operations in the graph from float32 to float16. There are several categories of operations that are either included or excluded by this rewrite operation. The following categories of Ops are defined inside corresponding functions under the class &lt;code&gt;AutoMixedPrecisionLists&lt;/code&gt; in &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h&quot;&gt; auto_mixed_precision_lists.h&lt;/a&gt;:</target>
        </trans-unit>
        <trans-unit id="186101c609f7e0b73c5beb88b3d3fda49788c5a2" translate="yes" xml:space="preserve">
          <source>The graph should be constructed so if one op runs with shared_name value &lt;code&gt;c&lt;/code&gt;, then &lt;code&gt;num_devices&lt;/code&gt; ops will run with shared_name value &lt;code&gt;c&lt;/code&gt;. Failure to do so will cause the graph execution to fail to complete.</source>
          <target state="translated">The graph should be constructed so if one op runs with shared_name value &lt;code&gt;c&lt;/code&gt; , then &lt;code&gt;num_devices&lt;/code&gt; ops will run with shared_name value &lt;code&gt;c&lt;/code&gt; . Failure to do so will cause the graph execution to fail to complete.</target>
        </trans-unit>
        <trans-unit id="54dd05e38efeb9304c2e7af28168698a594f9293" translate="yes" xml:space="preserve">
          <source>The graph should be constructed so that all inputs have a valid device assignment, and the op itself is assigned one of these devices.</source>
          <target state="translated">The graph should be constructed so that all inputs have a valid device assignment, and the op itself is assigned one of these devices.</target>
        </trans-unit>
        <trans-unit id="c4be0b8b705593560d211ca0abc094810b42f770" translate="yes" xml:space="preserve">
          <source>The graph should be constructed so that all ops connected to the output have a valid device assignment, and the op itself is assigned one of these devices.</source>
          <target state="translated">The graph should be constructed so that all ops connected to the output have a valid device assignment, and the op itself is assigned one of these devices.</target>
        </trans-unit>
        <trans-unit id="ae4960be0391bc0449f500287c2e9601d2d28fb9" translate="yes" xml:space="preserve">
          <source>The graph that was launched in this session.</source>
          <target state="translated">이 세션에서 시작된 그래프입니다.</target>
        </trans-unit>
        <trans-unit id="40aa8e68a00de5dbe27aa7ae38408c5a0d4706a5" translate="yes" xml:space="preserve">
          <source>The graph to find the global step in. If missing, use default graph.</source>
          <target state="translated">The graph to find the global step in. If missing, use default graph.</target>
        </trans-unit>
        <trans-unit id="ff2ceded61c6685a839fd2d7a80fa7375d194758" translate="yes" xml:space="preserve">
          <source>The graph with quantize training done.</source>
          <target state="translated">양자화 훈련이 완료된 그래프.</target>
        </trans-unit>
        <trans-unit id="3e6f6623fe7498e3548d52e61a0b5aeb7212fa47" translate="yes" xml:space="preserve">
          <source>The graph-level random seed of this graph.</source>
          <target state="translated">이 그래프의 그래프 레벨 랜덤 시드입니다.</target>
        </trans-unit>
        <trans-unit id="b19682167ffcfe3c04ed8fb01a75a8aa799a4834" translate="yes" xml:space="preserve">
          <source>The ground truth output tensor, same dimensions as 'predictions'.</source>
          <target state="translated">The ground truth output tensor, same dimensions as 'predictions'.</target>
        </trans-unit>
        <trans-unit id="9d40415d775a65d5e9c240e06cfa7ef2938a3a8e" translate="yes" xml:space="preserve">
          <source>The ground truth output tensor, whose shape must match the shape of &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="translated">The ground truth output tensor, whose shape must match the shape of &lt;code&gt;predictions&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3ce49e07066730c52addc7241cd12da10f5be42a" translate="yes" xml:space="preserve">
          <source>The ground truth output tensor. Its shape should match the shape of logits. The values of the tensor are expected to be 0.0 or 1.0. Internally the {0,1} labels are converted to {-1,1} when calculating the hinge loss.</source>
          <target state="translated">The ground truth output tensor. Its shape should match the shape of logits. The values of the tensor are expected to be 0.0 or 1.0. Internally the {0,1} labels are converted to {-1,1} when calculating the hinge loss.</target>
        </trans-unit>
        <trans-unit id="5e5ec338b593d91f4875e9143cbbc83aa6f393e3" translate="yes" xml:space="preserve">
          <source>The ground truth values, a &lt;code&gt;Tensor&lt;/code&gt; whose dimensions must match &lt;code&gt;predictions&lt;/code&gt;. Will be cast to &lt;code&gt;bool&lt;/code&gt;.</source>
          <target state="translated">The ground truth values, a &lt;code&gt;Tensor&lt;/code&gt; whose dimensions must match &lt;code&gt;predictions&lt;/code&gt; . Will be cast to &lt;code&gt;bool&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="60096598c979dc6d254911e38f80ad100e27b230" translate="yes" xml:space="preserve">
          <source>The ground truth values, a &lt;code&gt;Tensor&lt;/code&gt; whose shape matches &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="translated">The ground truth values, a &lt;code&gt;Tensor&lt;/code&gt; whose shape matches &lt;code&gt;predictions&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="605e115f8ae90c28fbc9ece17ff2e60055be11a5" translate="yes" xml:space="preserve">
          <source>The ground truth values, with the same dimensions as &lt;code&gt;y_pred&lt;/code&gt;. Will be cast to &lt;code&gt;bool&lt;/code&gt;.</source>
          <target state="translated">The ground truth values, with the same dimensions as &lt;code&gt;y_pred&lt;/code&gt; . Will be cast to &lt;code&gt;bool&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="52b0a2c7f13eb68767ea820eccfa44a1fa1d1417" translate="yes" xml:space="preserve">
          <source>The ground truth values.</source>
          <target state="translated">The ground truth values.</target>
        </trans-unit>
        <trans-unit id="23fc95f30242886be69cc146eccbc44fbd3a9182" translate="yes" xml:space="preserve">
          <source>The ground truth values. &lt;code&gt;y_true&lt;/code&gt; values are expected to be -1 or 1. If binary (0 or 1) labels are provided we will convert them to -1 or 1. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt;.</source>
          <target state="translated">The ground truth values. &lt;code&gt;y_true&lt;/code&gt; values are expected to be -1 or 1. If binary (0 or 1) labels are provided we will convert them to -1 or 1. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="59439dc5cc92da495265d90185dbcfa8d277e54f" translate="yes" xml:space="preserve">
          <source>The ground truth values. &lt;code&gt;y_true&lt;/code&gt; values are expected to be 0 or 1.</source>
          <target state="translated">The ground truth values. &lt;code&gt;y_true&lt;/code&gt; values are expected to be 0 or 1.</target>
        </trans-unit>
        <trans-unit id="6db4406cca6113b5fab1f1335e874fc3df16b4d0" translate="yes" xml:space="preserve">
          <source>The handle flow_in forces the execution of the gradient lookup to occur only after certain other operations have occurred. For example, when the forward TensorArray is dynamically sized, writes to this TensorArray may resize the object. The gradient TensorArray is statically sized based on the size of the forward TensorArray when this operation executes. Furthermore, the size of the forward TensorArray is frozen by this call. As a result, the flow is used to ensure that the call to generate the gradient TensorArray only happens after all writes are executed.</source>
          <target state="translated">The handle flow_in forces the execution of the gradient lookup to occur only after certain other operations have occurred. For example, when the forward TensorArray is dynamically sized, writes to this TensorArray may resize the object. The gradient TensorArray is statically sized based on the size of the forward TensorArray when this operation executes. Furthermore, the size of the forward TensorArray is frozen by this call. As a result, the flow is used to ensure that the call to generate the gradient TensorArray only happens after all writes are executed.</target>
        </trans-unit>
        <trans-unit id="386f2f718150cc3d8ab94292f585fc5254536634" translate="yes" xml:space="preserve">
          <source>The hard sigmoid activation, defined as:</source>
          <target state="translated">The hard sigmoid activation, defined as:</target>
        </trans-unit>
        <trans-unit id="4ddc50d95cf25f219ea2579cde9bf22435bfdc02" translate="yes" xml:space="preserve">
          <source>The hard sigmoid activation:</source>
          <target state="translated">하드 시그 모이 드 활성화 :</target>
        </trans-unit>
        <trans-unit id="0f4987b71fd23d4d24937f4f99fea76affcae8b1" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process and will never change. However, it is not suitable for cryptography. This function may be used when CPU time is scarce and inputs are trusted or unimportant. There is a risk of adversaries constructing inputs that all hash to the same bucket. To prevent this problem, use a strong hash function with &lt;code&gt;tf.string_to_hash_bucket_strong&lt;/code&gt;.</source>
          <target state="translated">해시 함수는 프로세스 내의 문자열 내용에 결정적이며 절대 변경되지 않습니다. 그러나 암호화에는 적합하지 않습니다. 이 기능은 CPU 시간이 부족하고 입력을 신뢰할 수 있거나 중요하지 않은 경우에 사용할 수 있습니다. 공격자가 모두 동일한 버킷에 해시하는 입력을 구성 할 위험이 있습니다. 이 문제를 방지하려면 &lt;code&gt;tf.string_to_hash_bucket_strong&lt;/code&gt; 과 함께 강력한 해시 함수를 사용 하십시오 .</target>
        </trans-unit>
        <trans-unit id="fd0bfc8db5880e8eee54fb3385531988b2ad4a55" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process.</source>
          <target state="translated">해시 함수는 프로세스 내의 문자열 내용에 결정적입니다.</target>
        </trans-unit>
        <trans-unit id="61f428a10a4305c850461ee00f387b0cacfe0ef7" translate="yes" xml:space="preserve">
          <source>The hash function is deterministic on the content of the string within the process. The hash function is a keyed hash function, where attribute &lt;code&gt;key&lt;/code&gt; defines the key of the hash function. &lt;code&gt;key&lt;/code&gt; is an array of 2 elements.</source>
          <target state="translated">해시 함수는 프로세스 내의 문자열 내용에 결정적입니다. 해시 함수는 키가있는 해시 함수이며, 여기서 속성 &lt;code&gt;key&lt;/code&gt; 는 해시 함수의 키를 정의합니다. &lt;code&gt;key&lt;/code&gt; 는 2 개의 요소로 구성된 배열입니다.</target>
        </trans-unit>
        <trans-unit id="1e7a8b7c173f99d4be181a635239bd0a5322a9de" translate="yes" xml:space="preserve">
          <source>The hash function used for generating out-of-vocabulary buckets ID is Fingerprint64.</source>
          <target state="translated">어휘 외 버킷 ID를 생성하는 데 사용되는 해시 함수는 Fingerprint64입니다.</target>
        </trans-unit>
        <trans-unit id="69a6e09f76ddf4e19a4f8311d3f8fdc0b3c24b22" translate="yes" xml:space="preserve">
          <source>The head can be used with a canned estimator. Example:</source>
          <target state="translated">헤드는 통조림 추정기와 함께 사용할 수 있습니다. 예:</target>
        </trans-unit>
        <trans-unit id="d8faf861d99f75e3ed7e367680c294894cd4fcef" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, 1]&lt;/code&gt;.</source>
          <target state="translated">머리는 &lt;code&gt;[D0, D1, ... DN, 1]&lt;/code&gt; 모양의 &lt;code&gt;logits&lt;/code&gt; 을 예상 합니다. 많은 응용 프로그램에서 모양은 &lt;code&gt;[batch_size, 1]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="c11316cb9d31dc7288f1ee66c33f5379df0eac90" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;.</source>
          <target state="translated">머리는 &lt;code&gt;[D0, D1, ... DN, label_dimension]&lt;/code&gt; 모양의 &lt;code&gt;logits&lt;/code&gt; 을 예상 합니다. 많은 응용 프로그램에서 모양은 &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="bfb83e6dd754125ed65384336314d4dfea48278d" translate="yes" xml:space="preserve">
          <source>The head expects &lt;code&gt;logits&lt;/code&gt; with shape &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt;. In many applications, the shape is &lt;code&gt;[batch_size, n_classes]&lt;/code&gt;.</source>
          <target state="translated">머리는 &lt;code&gt;[D0, D1, ... DN, n_classes]&lt;/code&gt; 모양의 &lt;code&gt;logits&lt;/code&gt; 을 예상 합니다. 많은 응용 프로그램에서 모양은 &lt;code&gt;[batch_size, n_classes]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="0d067db23fc00d02a594d5d3f6689549c9f412c9" translate="yes" xml:space="preserve">
          <source>The higher the value, the more important the corresponding feature.</source>
          <target state="translated">값이 클수록 해당 기능이 더 중요합니다.</target>
        </trans-unit>
        <trans-unit id="8521813f904a22ffdfed697b68b5f435421da5d1" translate="yes" xml:space="preserve">
          <source>The hyperparameter dict.</source>
          <target state="translated">The hyperparameter dict.</target>
        </trans-unit>
        <trans-unit id="d8f83801fea0c2b2d476a98f4924fa4ac4c7e365" translate="yes" xml:space="preserve">
          <source>The id to use for an entry with no features.</source>
          <target state="translated">The id to use for an entry with no features.</target>
        </trans-unit>
        <trans-unit id="4057b28d9bdcaa801a67add7d2746bf429a07212" translate="yes" xml:space="preserve">
          <source>The id to use for an entry with no features. Defaults to 0-vector.</source>
          <target state="translated">The id to use for an entry with no features. Defaults to 0-vector.</target>
        </trans-unit>
        <trans-unit id="ec4887ee6136cea3e95782b65b373451d365f518" translate="yes" xml:space="preserve">
          <source>The ids and weights may be multi-dimensional. Embeddings are always aggregated along the last dimension.</source>
          <target state="translated">id 및 가중치는 다차원 일 수있다. 임베드는 항상 마지막 차원을 따라 집계됩니다.</target>
        </trans-unit>
        <trans-unit id="2dedfa9fac99909c847ee188683a18acc13d4781" translate="yes" xml:space="preserve">
          <source>The image sizes must be at least 11x11 because of the filter size.</source>
          <target state="translated">필터 크기로 인해 이미지 크기는 11x11 이상이어야합니다.</target>
        </trans-unit>
        <trans-unit id="64a71045d71d24f6cb099b242b2b3b3524c6c175" translate="yes" xml:space="preserve">
          <source>The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling.</source>
          <target state="translated">The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling.</target>
        </trans-unit>
        <trans-unit id="c48ed1044647075aee18b6c60d833446c1e6e4e9" translate="yes" xml:space="preserve">
          <source>The images have the same number of channels as the input tensor. For float input, the values are normalized one image at a time to fit in the range &lt;code&gt;[0, 255]&lt;/code&gt;. &lt;code&gt;uint8&lt;/code&gt; values are unchanged. The op uses two different normalization algorithms:</source>
          <target state="translated">The images have the same number of channels as the input tensor. For float input, the values are normalized one image at a time to fit in the range &lt;code&gt;[0, 255]&lt;/code&gt; . &lt;code&gt;uint8&lt;/code&gt; values are unchanged. The op uses two different normalization algorithms:</target>
        </trans-unit>
        <trans-unit id="7512c5f22af2e468e091d738afee317bd6f3ab0c" translate="yes" xml:space="preserve">
          <source>The implementation is based on</source>
          <target state="translated">구현은</target>
        </trans-unit>
        <trans-unit id="7d3ec374ef70a5b15f88b06660be75d304545cf4" translate="yes" xml:space="preserve">
          <source>The implementation is based on: http://arxiv.org/abs/1409.2329.</source>
          <target state="translated">구현은 http://arxiv.org/abs/1409.2329를 기반으로합니다.</target>
        </trans-unit>
        <trans-unit id="4ceeee7cb755fec502e82f78579a1a2aeacda20b" translate="yes" xml:space="preserve">
          <source>The implementation of reduce of &lt;code&gt;per_replica_value&lt;/code&gt; to &lt;code&gt;destinations&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;per_replica_value&lt;/code&gt; 를 &lt;code&gt;destinations&lt;/code&gt; 으로 축소 구현 .</target>
        </trans-unit>
        <trans-unit id="a45943ff8ffbe5eb14bb769ef477b63bf1e6634b" translate="yes" xml:space="preserve">
          <source>The implementation of this layer is based on the following paper: &lt;a href=&quot;https://people.eecs.berkeley.edu/%7Ebrecht/papers/07.rah.rec.nips.pdf&quot;&gt;&quot;Random Features for Large-Scale Kernel Machines&quot;&lt;/a&gt; by Ali Rahimi and Ben Recht.</source>
          <target state="translated">The implementation of this layer is based on the following paper: &lt;a href=&quot;https://people.eecs.berkeley.edu/%7Ebrecht/papers/07.rah.rec.nips.pdf&quot;&gt;&quot;Random Features for Large-Scale Kernel Machines&quot;&lt;/a&gt; by Ali Rahimi and Ben Recht.</target>
        </trans-unit>
        <trans-unit id="0bf2a5f575ee57fc6179092cf074536b99352e2c" translate="yes" xml:space="preserve">
          <source>The index &lt;code&gt;Tensor&lt;/code&gt;. Must be one of the following types: &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;int64&lt;/code&gt;. Must be in range &lt;code&gt;[0, params.shape[axis])&lt;/code&gt;.</source>
          <target state="translated">The index &lt;code&gt;Tensor&lt;/code&gt; . Must be one of the following types: &lt;code&gt;int32&lt;/code&gt; , &lt;code&gt;int64&lt;/code&gt; . Must be in range &lt;code&gt;[0, params.shape[axis])&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="39a73acc3a718d665ade71e6fcdb4d6f64ce1525" translate="yes" xml:space="preserve">
          <source>The index of the closest cluster center for each input point.</source>
          <target state="translated">각 입력 지점에서 가장 가까운 군집 중심의 색인입니다.</target>
        </trans-unit>
        <trans-unit id="bea3fce0b788c98ad4fd4961601d66fd0a86dd08" translate="yes" xml:space="preserve">
          <source>The index of this tensor in the outputs of its &lt;code&gt;Operation&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;Operation&lt;/code&gt; 출력에서이 텐서의 인덱스입니다 .</target>
        </trans-unit>
        <trans-unit id="14e09cd196d124b973e167954c771249f4762ea9" translate="yes" xml:space="preserve">
          <source>The indicator function</source>
          <target state="translated">표시기 기능</target>
        </trans-unit>
        <trans-unit id="e479f7d6722440bc7a24c4b0e9bd9fc43faf862a" translate="yes" xml:space="preserve">
          <source>The indices in &lt;code&gt;argmax&lt;/code&gt; are flattened, so that a maximum value at position &lt;code&gt;[b, y, x, c]&lt;/code&gt; becomes flattened index: &lt;code&gt;(y * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is False; &lt;code&gt;((b * height + y) * width + x) * channels + c&lt;/code&gt; if &lt;code&gt;include_batch_in_index&lt;/code&gt; is True.</source>
          <target state="translated">있는 인덱스 &lt;code&gt;argmax&lt;/code&gt; 는 제 위치에서 최대 값 것을 평탄화된다 &lt;code&gt;[b, y, x, c]&lt;/code&gt; 평면화 인덱스된다 : &lt;code&gt;(y * width + x) * channels + c&lt;/code&gt; 경우 &lt;code&gt;include_batch_in_index&lt;/code&gt; 가 거짓이고; &lt;code&gt;include_batch_in_index&lt;/code&gt; 가 True 인 경우 &lt;code&gt;((b * height + y) * width + x) * channels + c&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="aded17676aa9e31637aa4cd1d72c2f01005a52db" translate="yes" xml:space="preserve">
          <source>The indices of &lt;code&gt;values&lt;/code&gt; within the last dimension of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">The indices of &lt;code&gt;values&lt;/code&gt; within the last dimension of &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0c8ef3b2e283d0175df2945495378ccedf137327" translate="yes" xml:space="preserve">
          <source>The indices of any input &lt;code&gt;SparseTensor&lt;/code&gt; are assumed ordered in standard lexicographic order. If this is not the case, before this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="translated">모든 입력 &lt;code&gt;SparseTensor&lt;/code&gt; 의 색인은 표준 사전 순서대로 정렬 된 것으로 가정합니다. 그렇지 않은 경우이 단계 전에 &lt;code&gt;SparseReorder&lt;/code&gt; 를 실행 하여 인덱스 순서를 복원하십시오.</target>
        </trans-unit>
        <trans-unit id="b80ce2ebdd8a066053015d24d2b36c5006bb3c4b" translate="yes" xml:space="preserve">
          <source>The indices of non-zero values in the represented dense tensor.</source>
          <target state="translated">표시된 조밀 한 텐서에서 0이 아닌 값의 인덱스.</target>
        </trans-unit>
        <trans-unit id="6678184e53cf5eab61e8f12ffd050f2da0981541" translate="yes" xml:space="preserve">
          <source>The indices returned are always in &lt;code&gt;[0, height) x [0, width)&lt;/code&gt; before flattening, even if padding is involved and the mathematically correct answer is outside (either negative or too large). This is a bug, but fixing it is difficult to do in a safe backwards compatible way, especially due to flattening.</source>
          <target state="translated">패딩이 관련되어 있고 수학적으로 정답이 외부에 있거나 (음수이거나 너무 큰 경우 &lt;code&gt;[0, height) x [0, width)&lt;/code&gt; 반환 된 인덱스는 전개하기 전에 항상 [0, 높이) x [0, 너비 )입니다. 이것은 버그이지만 수정하는 것은 특히 병합으로 인해 이전 버전과 호환되는 안전한 방법으로 수행하기가 어렵습니다.</target>
        </trans-unit>
        <trans-unit id="308dc80a122084288a0ffca0b6ff7c164285d050" translate="yes" xml:space="preserve">
          <source>The indices to be used in the operation.</source>
          <target state="translated">The indices to be used in the operation.</target>
        </trans-unit>
        <trans-unit id="982eccddab4c7cb8698248ade435084245e7ba3a" translate="yes" xml:space="preserve">
          <source>The inferred shape of a tensor is used to provide shape information without having to launch the graph in a session. This can be used for debugging, and providing early error messages. For example:</source>
          <target state="translated">텐서의 유추 된 모양은 세션에서 그래프를 시작할 필요없이 모양 정보를 제공하는 데 사용됩니다. 디버깅 및 초기 오류 메시지 제공에 사용할 수 있습니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="d0cd21ff5f1c8bdcbdb1615eade35bd02cd426a1" translate="yes" xml:space="preserve">
          <source>The initial value for every thread's stack is set to the current value of the stack when &lt;code&gt;switch_to_thread_local()&lt;/code&gt; was first called.</source>
          <target state="translated">모든 스레드 스택의 초기 값은 &lt;code&gt;switch_to_thread_local()&lt;/code&gt; 이 처음 호출 될 때 스택의 현재 값으로 설정됩니다 .</target>
        </trans-unit>
        <trans-unit id="1520071416fcbbf59fdfe9d1fb1a38e0c5b7ec1a" translate="yes" xml:space="preserve">
          <source>The initializer operation for this variable.</source>
          <target state="translated">이 변수의 이니셜 라이저 조작.</target>
        </trans-unit>
        <trans-unit id="5fe0073bfbc54ff4aabd7ab72b5b3609d630078b" translate="yes" xml:space="preserve">
          <source>The inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT2D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 2 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 가장 안쪽 2 차원은 &lt;code&gt;RFFT2D&lt;/code&gt; 의 결과 인 것으로 가정합니다 . 가장 안쪽의 차원은 실수 값 신호의 DFT의 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 고유 성분을 포함합니다. 경우 &lt;code&gt;fft_length&lt;/code&gt; 가 제공되지 않고, 그것의 가장 안쪽 2 차원의 사이즈로부터 계산되어 &lt;code&gt;input&lt;/code&gt; . &lt;code&gt;input&lt;/code&gt; 계산에 사용 된 FFT 길이 가 홀수이면 제대로 추론 할 수 없으므로 입력 해야합니다.</target>
        </trans-unit>
        <trans-unit id="577a2328b01f8435a1e76dd0c500fccff4c87199" translate="yes" xml:space="preserve">
          <source>The inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt; are assumed to be the result of &lt;code&gt;RFFT3D&lt;/code&gt;: The inner-most dimension contains the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most 3 dimensions of &lt;code&gt;input&lt;/code&gt;. If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 가장 안쪽 3 차원은 &lt;code&gt;RFFT3D&lt;/code&gt; 의 결과 인 것으로 가정합니다 . 가장 안쪽의 차원은 실수 값 신호의 DFT의 &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 고유 성분을 포함합니다. 경우 &lt;code&gt;fft_length&lt;/code&gt; 가 제공되지 않고, 그것의 가장 안쪽 3 차원의 사이즈로부터 계산되어 &lt;code&gt;input&lt;/code&gt; . &lt;code&gt;input&lt;/code&gt; 계산에 사용 된 FFT 길이 가 홀수이면 제대로 추론 할 수 없으므로 입력 해야합니다.</target>
        </trans-unit>
        <trans-unit id="66227bf2a70d8c8a13c900791ef88cd485b7b62a" translate="yes" xml:space="preserve">
          <source>The inner-most dimension of &lt;code&gt;input&lt;/code&gt; is assumed to be the result of &lt;code&gt;RFFT&lt;/code&gt;: the &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; unique components of the DFT of a real-valued signal. If &lt;code&gt;fft_length&lt;/code&gt; is not provided, it is computed from the size of the inner-most dimension of &lt;code&gt;input&lt;/code&gt; (&lt;code&gt;fft_length = 2 * (inner - 1)&lt;/code&gt;). If the FFT length used to compute &lt;code&gt;input&lt;/code&gt; is odd, it should be provided since it cannot be inferred properly.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 가장 안쪽 차원은 &lt;code&gt;RFFT&lt;/code&gt; 의 결과 인 것으로 가정합니다 . &lt;code&gt;fft_length / 2 + 1&lt;/code&gt; 실수 값 신호의 DFT 고유 성분. 경우 &lt;code&gt;fft_length&lt;/code&gt; 가 제공되지 않고, 그것의 가장 안쪽 치수의 사이즈로부터 계산되어 &lt;code&gt;input&lt;/code&gt; ( &lt;code&gt;fft_length = 2 * (inner - 1)&lt;/code&gt; ). &lt;code&gt;input&lt;/code&gt; 계산에 사용 된 FFT 길이 가 홀수이면 제대로 추론 할 수 없으므로 입력 해야합니다.</target>
        </trans-unit>
        <trans-unit id="bb19a900483721ea4e289126af04d4611c3ccdec" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; array for this ragged tensor value.</source>
          <target state="translated">이 울퉁불퉁 한 텐서 값 의 가장 안쪽 &lt;code&gt;values&lt;/code&gt; 배열입니다.</target>
        </trans-unit>
        <trans-unit id="be345c7ea127005969c68124a7827e30c5e6f496" translate="yes" xml:space="preserve">
          <source>The innermost &lt;code&gt;values&lt;/code&gt; tensor for this ragged tensor.</source>
          <target state="translated">가장 안쪽 &lt;code&gt;values&lt;/code&gt; 이 너덜 너덜 텐서에 대한 텐서.</target>
        </trans-unit>
        <trans-unit id="8b90c8353eaabcd1c4389d292135b80ad60f5db5" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or &lt;code&gt;(P-K)&lt;/code&gt;-dimensional slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt; ) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt; ) or &lt;code&gt;(P-K)&lt;/code&gt; -dimensional slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt; ) along the &lt;code&gt;K&lt;/code&gt; th dimension of &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f25a7f282e145204d03b73aafeaa7a9ae16b013a" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of &lt;code&gt;ref&lt;/code&gt;.</source>
          <target state="translated">가장 긴 &lt;code&gt;indices&lt;/code&gt; 길이 (길이 &lt;code&gt;K&lt;/code&gt; ) 는 &lt;code&gt;ref&lt;/code&gt; 의 &lt;code&gt;K&lt;/code&gt; 번째 차원을 따라 요소 ( &lt;code&gt;K = P&lt;/code&gt; ) 또는 슬라이스 ( &lt;code&gt;K &amp;lt; P&lt;/code&gt; 경우)의 인덱스에 해당합니다 .</target>
        </trans-unit>
        <trans-unit id="5e89d3b63e4cb6ebffdeb167da39f2e0f1f1c9d2" translate="yes" xml:space="preserve">
          <source>The innermost dimension of &lt;code&gt;indices&lt;/code&gt; (with length &lt;code&gt;K&lt;/code&gt;) corresponds to indices into elements (if &lt;code&gt;K = P&lt;/code&gt;) or slices (if &lt;code&gt;K &amp;lt; P&lt;/code&gt;) along the &lt;code&gt;K&lt;/code&gt;th dimension of self.</source>
          <target state="translated">가장 안쪽 치수 &lt;code&gt;indices&lt;/code&gt; (길이와 &lt;code&gt;K&lt;/code&gt; 요소의 인덱스에 대응) (만약 &lt;code&gt;K = P&lt;/code&gt; ) 또는 조각 (경우 &lt;code&gt;K &amp;lt; P&lt;/code&gt; 따라) &lt;code&gt;K&lt;/code&gt; 자기 번째 차원.</target>
        </trans-unit>
        <trans-unit id="9d4e204148af56a0113e634b28635c0d262a9319" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; is represented via the tuple of inputs (&lt;code&gt;indices&lt;/code&gt;, &lt;code&gt;values&lt;/code&gt;, &lt;code&gt;dense_shape&lt;/code&gt;). The output &lt;code&gt;SparseTensor&lt;/code&gt; has the same &lt;code&gt;dense_shape&lt;/code&gt; but with indices &lt;code&gt;output_indices&lt;/code&gt; and values &lt;code&gt;output_values&lt;/code&gt;.</source>
          <target state="translated">The input &lt;code&gt;SparseTensor&lt;/code&gt; is represented via the tuple of inputs ( &lt;code&gt;indices&lt;/code&gt; , &lt;code&gt;values&lt;/code&gt; , &lt;code&gt;dense_shape&lt;/code&gt; ). The output &lt;code&gt;SparseTensor&lt;/code&gt; has the same &lt;code&gt;dense_shape&lt;/code&gt; but with indices &lt;code&gt;output_indices&lt;/code&gt; and values &lt;code&gt;output_values&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7e7a91084b5b310e293a78ea32ab3d511383ccff" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; must be in row-major order.</source>
          <target state="translated">입력 &lt;code&gt;SparseTensor&lt;/code&gt; 는 행 주요 순서 여야합니다.</target>
        </trans-unit>
        <trans-unit id="369bf999e77085bb3dbcbb8c678bff357cac4ab0" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; must have rank &lt;code&gt;R&lt;/code&gt; greater than 1, and the first dimension is treated as the minibatch dimension. Elements of the &lt;code&gt;SparseTensor&lt;/code&gt; must be sorted in increasing order of this first dimension. The stored &lt;code&gt;SparseTensor&lt;/code&gt; objects pointed to by each row of the output &lt;code&gt;sparse_handles&lt;/code&gt; will have rank &lt;code&gt;R-1&lt;/code&gt;.</source>
          <target state="translated">The input &lt;code&gt;SparseTensor&lt;/code&gt; must have rank &lt;code&gt;R&lt;/code&gt; greater than 1, and the first dimension is treated as the minibatch dimension. Elements of the &lt;code&gt;SparseTensor&lt;/code&gt; must be sorted in increasing order of this first dimension. The stored &lt;code&gt;SparseTensor&lt;/code&gt; objects pointed to by each row of the output &lt;code&gt;sparse_handles&lt;/code&gt; will have rank &lt;code&gt;R-1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="559dc2e144980c6b2098537801cec29d9fedba3c" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, after this step run &lt;a href=&quot;../sparse/reorder&quot;&gt;&lt;code&gt;sparse.reorder&lt;/code&gt;&lt;/a&gt; to restore index ordering.</source>
          <target state="translated">입력 &lt;code&gt;SparseTensor&lt;/code&gt; 오브젝트의 색인은 표준 사전 사전 순으로 정렬됩니다. 그렇지 않은 경우이 단계 후에 &lt;a href=&quot;../sparse/reorder&quot;&gt; &lt;code&gt;sparse.reorder&lt;/code&gt; &lt;/a&gt; 를 실행 하여 인덱스 순서를 복원하십시오.</target>
        </trans-unit>
        <trans-unit id="e24902595b5bc86bf69741800b0bbd97af15f6bd" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, after this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="translated">The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, after this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</target>
        </trans-unit>
        <trans-unit id="fbc5a9f23625ad51e259ef181b6a17732102c364" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, before this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</source>
          <target state="translated">The input &lt;code&gt;SparseTensor&lt;/code&gt; objects' indices are assumed ordered in standard lexicographic order. If this is not the case, before this step run &lt;code&gt;SparseReorder&lt;/code&gt; to restore index ordering.</target>
        </trans-unit>
        <trans-unit id="76f573f126a945d7c18465e0384fd69d0f88a658" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt; with &lt;code&gt;N&lt;/code&gt; non-empty elements.</source>
          <target state="translated">The input &lt;code&gt;SparseTensor&lt;/code&gt; with &lt;code&gt;N&lt;/code&gt; non-empty elements.</target>
        </trans-unit>
        <trans-unit id="f15580c2b04bab1dc867fb59f4c3b641b00ff298" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="translated">The input &lt;code&gt;SparseTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b2c6d3c475df3ca344370164bdadaba77954ef82" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must be a string matrix of shape &lt;code&gt;[N x 3]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to packed outputs of &lt;code&gt;SerializeSparse&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension).</source>
          <target state="translated">The input &lt;code&gt;serialized_sparse&lt;/code&gt; must be a string matrix of shape &lt;code&gt;[N x 3]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to packed outputs of &lt;code&gt;SerializeSparse&lt;/code&gt; . The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension).</target>
        </trans-unit>
        <trans-unit id="56bbf31df5c3f0a722000a2eadd2da99c153bf4d" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must be a string matrix of shape &lt;code&gt;[N x 3]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to packed outputs of &lt;code&gt;serialize_sparse&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension).</source>
          <target state="translated">입력 &lt;code&gt;serialized_sparse&lt;/code&gt; 는 &lt;code&gt;[N x 3]&lt;/code&gt; 모양의 문자열 행렬이어야합니다 . 여기서 &lt;code&gt;N&lt;/code&gt; 은 미니 배치 크기이고 행은 &lt;code&gt;serialize_sparse&lt;/code&gt; 의 압축 된 출력에 해당합니다 . 원본 &lt;code&gt;SparseTensor&lt;/code&gt; 객체 의 순위 가 모두 일치해야합니다. 최종 &lt;code&gt;SparseTensor&lt;/code&gt; 가 작성 될 때 수신 &lt;code&gt;SparseTensor&lt;/code&gt; 오브젝트 의 순위보다 하나 더 높은 순위를 갖습니다 (새 행 차원을 따라 연결됨).</target>
        </trans-unit>
        <trans-unit id="1a26b3031ce9b2139c0f9a566a88efe37f0d9f15" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;serialized_sparse&lt;/code&gt; must have the shape &lt;code&gt;[?, ?, ..., ?, 3]&lt;/code&gt; where the last dimension stores serialized &lt;code&gt;SparseTensor&lt;/code&gt; objects and the other N dimensions (N &amp;gt;= 0) correspond to a batch. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, its rank is the rank of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects plus N; the sparse tensors have been concatenated along new dimensions, one for each batch.</source>
          <target state="translated">The input &lt;code&gt;serialized_sparse&lt;/code&gt; must have the shape &lt;code&gt;[?, ?, ..., ?, 3]&lt;/code&gt; where the last dimension stores serialized &lt;code&gt;SparseTensor&lt;/code&gt; objects and the other N dimensions (N &amp;gt;= 0) correspond to a batch. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, its rank is the rank of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects plus N; the sparse tensors have been concatenated along new dimensions, one for each batch.</target>
        </trans-unit>
        <trans-unit id="0acda681393d7c0ea437e5f7eb4637e2f5dc3c0f" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;sparse_handles&lt;/code&gt; must be an &lt;code&gt;int64&lt;/code&gt; matrix of shape &lt;code&gt;[N, 1]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to the output handles of &lt;code&gt;AddSparseToTensorsMap&lt;/code&gt; or &lt;code&gt;AddManySparseToTensorsMap&lt;/code&gt;. The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects that went into the given input ops must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension on the left).</source>
          <target state="translated">The input &lt;code&gt;sparse_handles&lt;/code&gt; must be an &lt;code&gt;int64&lt;/code&gt; matrix of shape &lt;code&gt;[N, 1]&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the minibatch size and the rows correspond to the output handles of &lt;code&gt;AddSparseToTensorsMap&lt;/code&gt; or &lt;code&gt;AddManySparseToTensorsMap&lt;/code&gt; . The ranks of the original &lt;code&gt;SparseTensor&lt;/code&gt; objects that went into the given input ops must all match. When the final &lt;code&gt;SparseTensor&lt;/code&gt; is created, it has rank one higher than the ranks of the incoming &lt;code&gt;SparseTensor&lt;/code&gt; objects (they have been concatenated along a new row dimension on the left).</target>
        </trans-unit>
        <trans-unit id="6797d5a30fe0809d6c99b3fe7233e4388f788d3d" translate="yes" xml:space="preserve">
          <source>The input &lt;code&gt;tags&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt; must have the same shape. The generated summary has a summary value for each tag-value pair in &lt;code&gt;tags&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="translated">The input &lt;code&gt;tags&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt; must have the same shape. The generated summary has a summary value for each tag-value pair in &lt;code&gt;tags&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d39dc101c55542dec858072079860af67df42d8f" translate="yes" xml:space="preserve">
          <source>The input can be supplied in various formats: &lt;code&gt;matrix&lt;/code&gt;, &lt;code&gt;sequence&lt;/code&gt; and &lt;code&gt;compact&lt;/code&gt;, specified by the &lt;code&gt;diagonals_format&lt;/code&gt; arg.</source>
          <target state="translated">입력은 &lt;code&gt;matrix&lt;/code&gt; s , &lt;code&gt;sequence&lt;/code&gt; 및 &lt;code&gt;compact&lt;/code&gt; 의 다양한 형식으로 제공 될 수 있습니다 ( &lt;code&gt;diagonals_format&lt;/code&gt; _ 형식 arg에 의해 지정됨) .</target>
        </trans-unit>
        <trans-unit id="2d48efdb90f50c04e629b26b90744cae3caa313b" translate="yes" xml:space="preserve">
          <source>The input cannot be converted to a tensor, or the specified axis cannot be squeezed.</source>
          <target state="translated">The input cannot be converted to a tensor, or the specified axis cannot be squeezed.</target>
        </trans-unit>
        <trans-unit id="7a3aea890ab7c25d251475a5c0c175df4fead28f" translate="yes" xml:space="preserve">
          <source>The input data can be padded on both the start and end of the sequence, if desired, using the &lt;code&gt;pad_values&lt;/code&gt; argument. If set, &lt;code&gt;pad_values&lt;/code&gt; should contain either a tuple of strings or a single string; the 0th element of the tuple will be used to pad the left side of the sequence and the 1st element of the tuple will be used to pad the right side of the sequence. The &lt;code&gt;padding_width&lt;/code&gt; arg controls how many padding values are added to each side; it defaults to &lt;code&gt;ngram_width-1&lt;/code&gt;.</source>
          <target state="translated">원하는 경우 &lt;code&gt;pad_values&lt;/code&gt; 인수를 사용하여 입력 데이터를 시퀀스의 시작과 끝 모두에 채울 수 있습니다. 설정된 경우 &lt;code&gt;pad_values&lt;/code&gt; 는 튜플 문자열 또는 단일 문자열을 포함해야합니다. 튜플의 0 번째 요소는 시퀀스의 왼쪽을 채우는 데 사용되고 튜플의 첫 번째 요소는 시퀀스의 오른쪽을 채우는 데 사용됩니다. &lt;code&gt;padding_width&lt;/code&gt; 많은 패딩 값은 각면에 첨가하는 방법 ARG 제어; 기본값은 &lt;code&gt;ngram_width-1&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="04197da47b84221763ac70ad3af1dee562c7d6bb" translate="yes" xml:space="preserve">
          <source>The input function is not a valid one.</source>
          <target state="translated">The input function is not a valid one.</target>
        </trans-unit>
        <trans-unit id="3483a88e5028197c2c707cc3c8c51e5ba5c5cc43" translate="yes" xml:space="preserve">
          <source>The input has to be invertible.</source>
          <target state="translated">입력은 뒤집을 수 없어야합니다.</target>
        </trans-unit>
        <trans-unit id="6cb547f4554af98d950886c485fb31114efae486" translate="yes" xml:space="preserve">
          <source>The input has to be symmetric and positive definite. Only the lower-triangular part of the input will be used for this operation. The upper-triangular part will not be read.</source>
          <target state="translated">입력은 대칭적이고 양의 한정이어야합니다. 이 작업에는 입력의 삼각 삼각 부분 만 사용됩니다. 상단 삼각 부분은 읽히지 않습니다.</target>
        </trans-unit>
        <trans-unit id="d751c1504cdeea4fe2c77555b81110d615e4802e" translate="yes" xml:space="preserve">
          <source>The input image is considered in the RGB colorspace. Conceptually, the RGB colors are first mapped into HSV. A delta is then applied all the hue values, and then remapped back to RGB colorspace.</source>
          <target state="translated">The input image is considered in the RGB colorspace. Conceptually, the RGB colors are first mapped into HSV. A delta is then applied all the hue values, and then remapped back to RGB colorspace.</target>
        </trans-unit>
        <trans-unit id="6a0a6cfeac0c5da1f89ebf29a1c3a1974b9f86fa" translate="yes" xml:space="preserve">
          <source>The input image is considered in the RGB colorspace. Conceptually, the RGB colors are first mapped into HSV. A scale is then applied all the saturation values, and then remapped back to RGB colorspace.</source>
          <target state="translated">The input image is considered in the RGB colorspace. Conceptually, the RGB colors are first mapped into HSV. A scale is then applied all the saturation values, and then remapped back to RGB colorspace.</target>
        </trans-unit>
        <trans-unit id="9ab6f7a1383accb84e03cfc01fbf2de71cc3ce58" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The output is a string tensor of the same shape containing the transcoded strings. Output strings are always valid unicode. If the input contains invalid encoding positions, the &lt;code&gt;errors&lt;/code&gt; attribute sets the policy for how to deal with them. If the default error-handling policy is used, invalid formatting will be substituted in the output by the &lt;code&gt;replacement_char&lt;/code&gt;. If the errors policy is to &lt;code&gt;ignore&lt;/code&gt;, any invalid encoding positions in the input are skipped and not included in the output. If it set to &lt;code&gt;strict&lt;/code&gt; then any invalid formatting will result in an InvalidArgument error.</source>
          <target state="translated">입력은 모든 모양의 문자열 텐서입니다. 출력은 코드 변환 된 문자열을 포함하는 동일한 모양의 문자열 텐서입니다. 출력 문자열은 항상 유효한 유니 코드입니다. 입력에 유효하지 않은 인코딩 위치가 포함 된 경우 &lt;code&gt;errors&lt;/code&gt; 속성은 해당 위치 를 처리하는 방법에 대한 정책을 설정합니다. 기본 오류 처리 정책을 사용하면 &lt;code&gt;replacement_char&lt;/code&gt; 의 출력에서 ​​유효하지 않은 형식이 대체 됩니다. 오류 정책이 &lt;code&gt;ignore&lt;/code&gt; 인 경우 입력의 유효하지 않은 인코딩 위치는 건너 뛰고 출력에 포함되지 않습니다. &lt;code&gt;strict&lt;/code&gt; 설정 하면 유효하지 않은 형식으로 인해 InvalidArgument 오류가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="f41ed33e18d35e0df944af43170682bbfbe88dab" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The pattern is a scalar string tensor which is applied to every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.</source>
          <target state="translated">입력은 모든 모양의 문자열 텐서입니다. 패턴은 입력 텐서의 모든 요소에 적용되는 스칼라 문자열 텐서입니다. 출력 텐서의 부울 값 (True 또는 False)은 입력이 제공된 정규식 패턴과 일치하는지 여부를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="f8ccdd5a5cb3af5106d6fe3c083e5d2def727b0e" translate="yes" xml:space="preserve">
          <source>The input is a string tensor of any shape. The pattern is the regular expression to be matched with every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.</source>
          <target state="translated">The input is a string tensor of any shape. The pattern is the regular expression to be matched with every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.</target>
        </trans-unit>
        <trans-unit id="4ef8ae1c6e33447e6640de2cbf18a9aca428cda0" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices, with the same constraints as the single matrix SelfAdjointEig.</source>
          <target state="translated">The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices, with the same constraints as the single matrix SelfAdjointEig.</target>
        </trans-unit>
        <trans-unit id="a49b12f6890eee0fa5006296181dd36a3c0eae12" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다.</target>
        </trans-unit>
        <trans-unit id="4a95ccad7688f828b4538240858954215386b157" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor containing the determinants for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 의 결정자를 포함하는 텐서 입니다.</target>
        </trans-unit>
        <trans-unit id="bb52980da5474b532e1e714b4de037ffa27b4127" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the exponential for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 의 지수를 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="72c07ff69dfab5a23cee03f8eae86a2093c70b45" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the inverse for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 대한 역함수를 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="f84ae4c58a555dd2a241282a825d52ffb2a896e6" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[..., M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The output is a tensor of the same shape as the input containing the matrix square root for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">입력은 &lt;code&gt;[..., M, M]&lt;/code&gt; 모양의 텐서 로 가장 안쪽의 2 차원이 정사각 행렬을 형성합니다. 출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 대한 행렬 제곱근을 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="a47976575bd700d1896c1a9ad76ef8970d05df43" translate="yes" xml:space="preserve">
          <source>The input is a tensor of shape &lt;code&gt;[N, M, M]&lt;/code&gt; whose inner-most 2 dimensions form square matrices. The outputs are two tensors containing the signs and absolute values of the log determinants for all N input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt; such that the determinant = sign&lt;em&gt;exp(log_abs_determinant). The log_abs_determinant is computed as det(P)&lt;/em&gt;sum(log(diag(LU))) where LU is the LU decomposition of the input and P is the corresponding permutation matrix.</source>
          <target state="translated">입력은 가장 안쪽 2 차원이 정사각 행렬을 형성 하는 모양 &lt;code&gt;[N, M, M]&lt;/code&gt; 의 텐서입니다 . 출력은 결정자 = 부호 &lt;em&gt;exp (log_abs_determinant)가되도록&lt;/em&gt; 모든 N 개의 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 에 대한 로그 결정자의 부호와 절대 값을 포함하는 두 개의 텐서 &lt;em&gt;입니다. log_abs_determinant는 det (P)&lt;/em&gt; sum (log (diag (LU)))로 &lt;em&gt;계산됩니다.&lt;/em&gt; 여기서 LU는 입력의 LU 분해이고 P는 해당 순열 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="16509370e9a14e359dbc8b8062b8734116aafda6" translate="yes" xml:space="preserve">
          <source>The input matrix should be invertible. If the input matrix is real, it should have no eigenvalues which are real and negative (pairs of complex conjugate eigenvalues are allowed).</source>
          <target state="translated">입력 매트릭스는 뒤집을 수 없어야합니다. 입력 행렬이 실수 인 경우 실수와 음수 인 고유 값이 없어야합니다 (복소수 복소수 고유 값 쌍이 허용됨).</target>
        </trans-unit>
        <trans-unit id="b4fb5738c7b407c21bcad2cacc1ef5ec4dff9b6d" translate="yes" xml:space="preserve">
          <source>The input must be at least a matrix.</source>
          <target state="translated">입력은 적어도 행렬이어야합니다.</target>
        </trans-unit>
        <trans-unit id="3c4f7bbe843d34cb236ccedebe4df570c214e3da" translate="yes" xml:space="preserve">
          <source>The input pipeline checkpoint may be large, if there are large shuffle or prefetch buffers for instance, and may bloat the checkpoint size.</source>
          <target state="translated">예를 들어 큰 셔플 또는 프리 페치 버퍼가있는 경우 입력 파이프 라인 검사 점이 크며 검사 점 크기가 커질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="deff7be907795c0056b42668a7693ec0a82247dc" translate="yes" xml:space="preserve">
          <source>The input pixels values are scaled between 0 and 1 and each channel is normalized with respect to the ImageNet dataset.</source>
          <target state="translated">The input pixels values are scaled between 0 and 1 and each channel is normalized with respect to the ImageNet dataset.</target>
        </trans-unit>
        <trans-unit id="1771ed960e007f08f6b91d9fc4bf87f366612095" translate="yes" xml:space="preserve">
          <source>The input rank &lt;code&gt;R&lt;/code&gt;&lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="translated">The input rank &lt;code&gt;R&lt;/code&gt; &lt;code&gt;SparseTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0bf2cfde9a379c9cc0a2626ec6eaa414e577c963" translate="yes" xml:space="preserve">
          <source>The input samples are processed batch by batch.</source>
          <target state="translated">입력 샘플은 배치별로 처리됩니다.</target>
        </trans-unit>
        <trans-unit id="db9e617ad287d3e54cdcc5d77f3a84dc0ecefefc" translate="yes" xml:space="preserve">
          <source>The input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.</source>
          <target state="translated">입력 값은 3D 이상이어야하며 인덱스 1의 차원은 시간 차원으로 간주됩니다.</target>
        </trans-unit>
        <trans-unit id="4a7245281a652bfbac8628bc44c29674340d8332" translate="yes" xml:space="preserve">
          <source>The input signature of &lt;code&gt;map_func&lt;/code&gt; is determined by the structure of each element in this dataset.</source>
          <target state="translated">&lt;code&gt;map_func&lt;/code&gt; 의 입력 서명은 이 데이터 세트의 각 요소 구조에 의해 결정됩니다.</target>
        </trans-unit>
        <trans-unit id="d2a30b4754eaaadad621a00ac65ed1446d4c24f6" translate="yes" xml:space="preserve">
          <source>The input sparse matrix and the fill-in reducing permutation &lt;code&gt;permutation&lt;/code&gt; must have compatible shapes. If the sparse matrix has rank 3; with the batch dimension &lt;code&gt;B&lt;/code&gt;, then the &lt;code&gt;permutation&lt;/code&gt; must be of rank 2; with the same batch dimension &lt;code&gt;B&lt;/code&gt;. There is no support for broadcasting.</source>
          <target state="translated">The input sparse matrix and the fill-in reducing permutation &lt;code&gt;permutation&lt;/code&gt; must have compatible shapes. If the sparse matrix has rank 3; with the batch dimension &lt;code&gt;B&lt;/code&gt; , then the &lt;code&gt;permutation&lt;/code&gt; must be of rank 2; with the same batch dimension &lt;code&gt;B&lt;/code&gt; . There is no support for broadcasting.</target>
        </trans-unit>
        <trans-unit id="42875650119a49af17e9b194c7f7044943508dd9" translate="yes" xml:space="preserve">
          <source>The input sparse matrix may have rank 2 or rank 3. The output Tensor, representing would then have rank 1 or 2 respectively, with the same batch shape as the input.</source>
          <target state="translated">The input sparse matrix may have rank 2 or rank 3. The output Tensor, representing would then have rank 1 or 2 respectively, with the same batch shape as the input.</target>
        </trans-unit>
        <trans-unit id="1a4202e509f04a4e2e240929b7033cbd28325042" translate="yes" xml:space="preserve">
          <source>The input tensor (potentially converted to a &lt;code&gt;Tensor&lt;/code&gt;).</source>
          <target state="translated">입력 텐서 (잠재적으로 &lt;code&gt;Tensor&lt;/code&gt; 로 변환 됨 )</target>
        </trans-unit>
        <trans-unit id="f1339cf26956739f44025e7d445e29017a72d735" translate="yes" xml:space="preserve">
          <source>The input tensor can now be quantized by clipping values to the range &lt;code&gt;min_range&lt;/code&gt; to &lt;code&gt;max_range&lt;/code&gt;, then multiplying by scale_factor as follows:</source>
          <target state="translated">입력 텐서는 이제 &lt;code&gt;min_range&lt;/code&gt; ~ &lt;code&gt;max_range&lt;/code&gt; 범위로 값을 클리핑 한 다음 다음과 같이 scale_factor를 곱하여 양자화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="d3b2781a0d53ff2a6f99fd5cbdcd70a0377dfcba" translate="yes" xml:space="preserve">
          <source>The input tensor whose shape will be used to generate dropout mask.</source>
          <target state="translated">The input tensor whose shape will be used to generate dropout mask.</target>
        </trans-unit>
        <trans-unit id="de4692e0721f2fcc2ac3eb25677f89cdae882775" translate="yes" xml:space="preserve">
          <source>The input tensor's height and width must be divisible by block_size.</source>
          <target state="translated">입력 텐서의 높이와 너비는 block_size로 나눌 수 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="549cec4325e7bdb0f314e4738e2091614fdd06cc" translate="yes" xml:space="preserve">
          <source>The input tensor.</source>
          <target state="translated">The input tensor.</target>
        </trans-unit>
        <trans-unit id="8bd030040de18dc6a388054f2ae79e10c262d194" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;real&lt;/code&gt; and &lt;code&gt;imag&lt;/code&gt; must have the same shape.</source>
          <target state="translated">입력 텐서 &lt;code&gt;real&lt;/code&gt; 과 &lt;code&gt;imag&lt;/code&gt; 는 같은 모양이어야합니다.</target>
        </trans-unit>
        <trans-unit id="aa6b1cb251ad12bc98e4df6e1fe21cc0d8438940" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;starts&lt;/code&gt;, &lt;code&gt;limits&lt;/code&gt;, and &lt;code&gt;deltas&lt;/code&gt; may be scalars or vectors. The vector inputs must all have the same size. Scalar inputs are broadcast to match the size of the vector inputs.</source>
          <target state="translated">입력 텐서 &lt;code&gt;starts&lt;/code&gt; , &lt;code&gt;limits&lt;/code&gt; 및 &lt;code&gt;deltas&lt;/code&gt; 는 스칼라 또는 벡터 일 수 있습니다. 벡터 입력은 모두 같은 크기 여야합니다. 스칼라 입력은 벡터 입력의 크기와 일치하도록 브로드 캐스트됩니다.</target>
        </trans-unit>
        <trans-unit id="b8ff1df3e5bbb4197a5fcf6ebfa2ea96c023b0d7" translate="yes" xml:space="preserve">
          <source>The input tensors &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are 2-D or higher with shape &lt;code&gt;[..., r_x, c_x]&lt;/code&gt; and &lt;code&gt;[..., r_y, c_y]&lt;/code&gt;.</source>
          <target state="translated">The input tensors &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are 2-D or higher with shape &lt;code&gt;[..., r_x, c_x]&lt;/code&gt; and &lt;code&gt;[..., r_y, c_y]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ff60fbd9db5f41897771ca434c8e26b7b8f91862" translate="yes" xml:space="preserve">
          <source>The input tensors are all required to have size 1 in the first dimension.</source>
          <target state="translated">The input tensors are all required to have size 1 in the first dimension.</target>
        </trans-unit>
        <trans-unit id="d661f6ceb58229bddc491bc4e8ad81a91a05cfb1" translate="yes" xml:space="preserve">
          <source>The input tensors must have &lt;code&gt;rank=2&lt;/code&gt;, and must all have the same number of rows. The result is a &lt;code&gt;RaggedTensor&lt;/code&gt; with the same number of rows as the inputs, where &lt;code&gt;result[row]&lt;/code&gt; contains a list of all combinations of values formed by taking a single value from each input's corresponding row (&lt;code&gt;inputs[i][row]&lt;/code&gt;). Values are combined by hashing together their fingerprints. E.g.:</source>
          <target state="translated">The input tensors must have &lt;code&gt;rank=2&lt;/code&gt; , and must all have the same number of rows. The result is a &lt;code&gt;RaggedTensor&lt;/code&gt; with the same number of rows as the inputs, where &lt;code&gt;result[row]&lt;/code&gt; contains a list of all combinations of values formed by taking a single value from each input's corresponding row ( &lt;code&gt;inputs[i][row]&lt;/code&gt; ). Values are combined by hashing together their fingerprints. E.g.:</target>
        </trans-unit>
        <trans-unit id="3f325df8aa80a521b9173906f05b6c3d477009cc" translate="yes" xml:space="preserve">
          <source>The input tensors must have &lt;code&gt;rank=2&lt;/code&gt;, and must all have the same number of rows. The result is a &lt;code&gt;RaggedTensor&lt;/code&gt; with the same number of rows as the inputs, where &lt;code&gt;result[row]&lt;/code&gt; contains a list of all combinations of values formed by taking a single value from each input's corresponding row (&lt;code&gt;inputs[i][row]&lt;/code&gt;). Values are combined by joining their strings with '&lt;em&gt;X&lt;/em&gt;'. E.g.:</source>
          <target state="translated">The input tensors must have &lt;code&gt;rank=2&lt;/code&gt; , and must all have the same number of rows. The result is a &lt;code&gt;RaggedTensor&lt;/code&gt; with the same number of rows as the inputs, where &lt;code&gt;result[row]&lt;/code&gt; contains a list of all combinations of values formed by taking a single value from each input's corresponding row ( &lt;code&gt;inputs[i][row]&lt;/code&gt; ). Values are combined by joining their strings with '&lt;em&gt;X&lt;/em&gt;'. E.g.:</target>
        </trans-unit>
        <trans-unit id="dc0e2ea8ed20f6c76d70887002fa098e766f9ed8" translate="yes" xml:space="preserve">
          <source>The input values in are the log-odds of the resulting probability.</source>
          <target state="translated">The input values in are the log-odds of the resulting probability.</target>
        </trans-unit>
        <trans-unit id="b1846b54df868865021ca6028d9ca189f0c062b0" translate="yes" xml:space="preserve">
          <source>The input(s) of the model: a &lt;a href=&quot;input&quot;&gt;&lt;code&gt;keras.Input&lt;/code&gt;&lt;/a&gt; object or list of &lt;a href=&quot;input&quot;&gt;&lt;code&gt;keras.Input&lt;/code&gt;&lt;/a&gt; objects.</source>
          <target state="translated">The input(s) of the model: a &lt;a href=&quot;input&quot;&gt; &lt;code&gt;keras.Input&lt;/code&gt; &lt;/a&gt; object or list of &lt;a href=&quot;input&quot;&gt; &lt;code&gt;keras.Input&lt;/code&gt; &lt;/a&gt; objects.</target>
        </trans-unit>
        <trans-unit id="c7b5b4e0f6e030ce553913f501525ac473f64915" translate="yes" xml:space="preserve">
          <source>The input, unmodified.</source>
          <target state="translated">The input, unmodified.</target>
        </trans-unit>
        <trans-unit id="d39bc5c493315c0c2bb73635f284f6d3773b3fe6" translate="yes" xml:space="preserve">
          <source>The inputs and arguments of these functions both use an instance of the class so they can have independent numbering.</source>
          <target state="translated">이 함수의 입력과 인수는 모두 클래스의 인스턴스를 사용하므로 독립적 인 번호 매기기를 가질 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d0798e60c9a60a309c2780811ed22bf523e44034" translate="yes" xml:space="preserve">
          <source>The inputs are quantized tensors where the lowest value represents the real number of the associated minimum, and the highest represents the maximum. This means that you can only interpret the quantized output in the same way, by taking the returned minimum and maximum values into account.</source>
          <target state="translated">입력 값은 양자화 된 텐서이며, 가장 낮은 값은 연관된 최소값의 실수를 나타내고 가장 높은 값은 최대 값을 나타냅니다. 즉, 반환 된 최소값과 최대 값을 고려하여 양자화 된 출력 만 동일한 방식으로 해석 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7d5491d4d1fe59ff0b726933e4fd0f37e6b34849" translate="yes" xml:space="preserve">
          <source>The inputs are variable-length sequences provided by SparseTensors (hypothesis_indices, hypothesis_values, hypothesis_shape) and (truth_indices, truth_values, truth_shape).</source>
          <target state="translated">The inputs are variable-length sequences provided by SparseTensors (hypothesis_indices, hypothesis_values, hypothesis_shape) and (truth_indices, truth_values, truth_shape).</target>
        </trans-unit>
        <trans-unit id="9b2d715db408ed4c68b80c58649420f90265275e" translate="yes" xml:space="preserve">
          <source>The inputs are:</source>
          <target state="translated">The inputs are:</target>
        </trans-unit>
        <trans-unit id="5487c5634d45a531fcdfa8c1d83dcdf3f48a363d" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt;.</source>
          <target state="translated">The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2314b3685b224ccc966442df5d3a609d47564351" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt;. Then do relu activation to get non-negative result.</source>
          <target state="translated">The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt; . Then do relu activation to get non-negative result.</target>
        </trans-unit>
        <trans-unit id="e61d8b21ec9285bc0e40af26ba2ce90301743e71" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt;. Then do relu activation to get non-negative result. Then do requantize operation to get final uint8 result.</source>
          <target state="translated">The inputs must be two-dimensional matrices and 1D bias vector. And the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero). Then do broadcast add operation with bias values on the matrix multiplication result. The bias size must match inner dimension of &lt;code&gt;b&lt;/code&gt; . Then do relu activation to get non-negative result. Then do requantize operation to get final uint8 result.</target>
        </trans-unit>
        <trans-unit id="bd731653b58f2631c265c170d9e7475175fa31c7" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; (after being transposed if transpose_a is true) must match the outer dimension of &quot;b&quot; (after being transposed if transposed_b is true).</source>
          <target state="translated">The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; (after being transposed if transpose_a is true) must match the outer dimension of &quot;b&quot; (after being transposed if transposed_b is true).</target>
        </trans-unit>
        <trans-unit id="af76f45e776e3f0a5b635d397e36c82661d856e8" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; must match the outer dimension of &quot;b&quot;. Both &quot;a&quot; and &quot;b&quot; must be &lt;code&gt;Tensor&lt;/code&gt;s not &lt;code&gt;SparseTensor&lt;/code&gt;s. This op is optimized for the case where at least one of &quot;a&quot; or &quot;b&quot; is sparse, in the sense that they have a large proportion of zero values. The breakeven for using this versus a dense matrix multiply on one platform was 30% zero values in the sparse matrix.</source>
          <target state="translated">입력 값은 2 차원 행렬이어야하고 &quot;a&quot;의 내부 차원은 &quot;b&quot;의 외부 차원과 일치해야합니다. &quot;a&quot;와 &quot;b&quot;는 모두 &lt;code&gt;SparseTensor&lt;/code&gt; 가 아닌 &lt;code&gt;Tensor&lt;/code&gt; 여야합니다 . 이 op는 &quot;a&quot;또는 &quot;b&quot;중 하나 이상이 0 인 값이 크다는 점에서 드문 경우에 최적화됩니다. 하나의 플랫폼에서 이것을 밀도 행렬에 곱하기위한 손익분기는 희소 행렬에서 30 % 0 값이었습니다.</target>
        </trans-unit>
        <trans-unit id="ff06fbddb811e99d2772aad28bf55f55c80fc380" translate="yes" xml:space="preserve">
          <source>The inputs must be two-dimensional matrices and the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero).</source>
          <target state="translated">The inputs must be two-dimensional matrices and the inner dimension of &lt;code&gt;a&lt;/code&gt; (after being transposed if &lt;code&gt;transpose_a&lt;/code&gt; is non-zero) must match the outer dimension of &lt;code&gt;b&lt;/code&gt; (after being transposed if &lt;code&gt;transposed_b&lt;/code&gt; is non-zero).</target>
        </trans-unit>
        <trans-unit id="9ec73a355bd346786f44656782393b17ea3017cb" translate="yes" xml:space="preserve">
          <source>The inputs must have compatible shapes. That is, the inner dimension of &lt;code&gt;a&lt;/code&gt; must be equal to the outer dimension of &lt;code&gt;b&lt;/code&gt;. This requirement is adjusted according to whether either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; is transposed or adjointed.</source>
          <target state="translated">The inputs must have compatible shapes. That is, the inner dimension of &lt;code&gt;a&lt;/code&gt; must be equal to the outer dimension of &lt;code&gt;b&lt;/code&gt; . This requirement is adjusted according to whether either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; is transposed or adjointed.</target>
        </trans-unit>
        <trans-unit id="851dd7f69bc57652716eb3a5a344fc6b5525127d" translate="yes" xml:space="preserve">
          <source>The inputs must, following any transpositions, be tensors of rank &amp;gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</source>
          <target state="translated">입력은 모든 전치 다음에 랭크&amp;gt; = 2의 텐서 여야합니다. 여기서 내부 2 차원은 유효한 행렬 곱셈 차원을 지정하고 추가 외부 차원은 일치하는 배치 크기를 지정합니다.</target>
        </trans-unit>
        <trans-unit id="2af5973c44cbbca03420397524238d5ac415d59c" translate="yes" xml:space="preserve">
          <source>The inputs pixel values are scaled between -1 and 1, sample-wise.</source>
          <target state="translated">The inputs pixel values are scaled between -1 and 1, sample-wise.</target>
        </trans-unit>
        <trans-unit id="ea6567bbb82a2153b18593d35fddb52d49ff3e46" translate="yes" xml:space="preserve">
          <source>The inputs represent an N-D SparseTensor with logical shape &lt;code&gt;[..., B, C]&lt;/code&gt; (where &lt;code&gt;N &amp;gt;= 2&lt;/code&gt;), and with indices sorted in the canonical lexicographic order.</source>
          <target state="translated">입력 값은 논리적 모양 &lt;code&gt;[..., B, C]&lt;/code&gt; (여기서 &lt;code&gt;N &amp;gt;= 2&lt;/code&gt; )이며 표준 사전 사전 순으로 정렬 된 ND SparseTensor를 나타냅니다 .</target>
        </trans-unit>
        <trans-unit id="a4f1d56f863e44297f61aff16d5b045b54f4c8aa" translate="yes" xml:space="preserve">
          <source>The integer ID value to return for out-of-vocabulary feature values, defaults to &lt;code&gt;-1&lt;/code&gt;. This can not be specified with a positive &lt;code&gt;num_oov_buckets&lt;/code&gt;.</source>
          <target state="translated">The integer ID value to return for out-of-vocabulary feature values, defaults to &lt;code&gt;-1&lt;/code&gt; . This can not be specified with a positive &lt;code&gt;num_oov_buckets&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="786b18b1428c9b9d0c0ea9b230ad273866de4e7c" translate="yes" xml:space="preserve">
          <source>The integer error code that describes the error.</source>
          <target state="translated">오류를 설명하는 정수 오류 코드입니다.</target>
        </trans-unit>
        <trans-unit id="1f081e7633128ce109e045c67ad35e5e5ed00d6f" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="translated">이 라이브러리의 목적은 양식화 된 방식으로 알고리즘을 작성할 수 있으며 다양한 다른 &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 구현에서 사용할 수 있다는 것입니다. 각 자손은 여러 장치 / 기계에 알고리즘을 배포하기위한 다른 전략을 구현합니다. 또한 이러한 변경 사항은 분산 설정에서 실행하기 위해 특별한 처리가 필요한 특정 계층 및 기타 라이브러리 클래스 안에 숨겨져 대부분의 사용자 모델 정의 코드가 변경없이 실행될 수 있습니다. &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; API 열망과 그래프 실행과 같은 방식으로 작동합니다.</target>
        </trans-unit>
        <trans-unit id="88afca652283c5de09f863feb56ef262251ef585" translate="yes" xml:space="preserve">
          <source>The intent of this library is that you can write an algorithm in a stylized way and it will be usable with a variety of different &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; implementations. Each descendant will implement a different strategy for distributing the algorithm across multiple devices/machines. Furthermore, these changes can be hidden inside the specific layers and other library classes that need special treatment to run in a distributed setting, so that most users' model definition code can run unchanged. The &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; API works the same way with eager and graph execution.</source>
          <target state="translated">이 라이브러리의 목적은 양식화 된 방식으로 알고리즘을 작성할 수 있으며 다양한 다른 &lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; 구현에서 사용할 수 있다는 것입니다. 각 자손은 여러 장치 / 기계에 알고리즘을 배포하기위한 다른 전략을 구현합니다. 또한 이러한 변경 사항은 분산 설정에서 실행하기 위해 특별한 처리가 필요한 특정 계층 및 기타 라이브러리 클래스 안에 숨겨져 대부분의 사용자 모델 정의 코드가 변경없이 실행될 수 있습니다. &lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; API 열망과 그래프 실행과 같은 방식으로 작동합니다.</target>
        </trans-unit>
        <trans-unit id="bf691a6e4942a79a3eb610931eed1d4815c80c50" translate="yes" xml:space="preserve">
          <source>The internal state of the RNG.</source>
          <target state="translated">RNG의 내부 상태</target>
        </trans-unit>
        <trans-unit id="f4e9fea1c0c7520b3774550dafc300a0edeccb05" translate="yes" xml:space="preserve">
          <source>The inverse of fftshift.</source>
          <target state="translated">fftshift의 역수.</target>
        </trans-unit>
        <trans-unit id="6f58aa3901c7e60d466c168f7dbe6f460db432cc" translate="yes" xml:space="preserve">
          <source>The iterator only checks for new checkpoints when control flow has been reverted to it. This means it can miss checkpoints if your code takes longer to run between iterations than &lt;code&gt;min_interval_secs&lt;/code&gt; or the interval at which new checkpoints are written.</source>
          <target state="translated">반복자는 제어 플로우가 되돌려 졌을 때 새로운 체크 포인트 만 점검합니다. 즉, 코드가 &lt;code&gt;min_interval_secs&lt;/code&gt; 보다 반복 하거나 새 검사 점이 작성되는 간격 동안 실행하는 데 시간이 오래 걸리면 검사 점이 누락 될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="bbc287cd067fb3f315911c649ff5a7aa6eb20b54" translate="yes" xml:space="preserve">
          <source>The job (the XXX in TensorFlow device specification /job:XXX) that contains the TPU devices that will be initialized. If job=None it is assumed there is only one job in the TensorFlow flock, and an error will be returned if this assumption does not hold.</source>
          <target state="translated">The job (the XXX in TensorFlow device specification /job:XXX) that contains the TPU devices that will be initialized. If job=None it is assumed there is only one job in the TensorFlow flock, and an error will be returned if this assumption does not hold.</target>
        </trans-unit>
        <trans-unit id="7761a900373227a5908c2ab270802392dddf9229" translate="yes" xml:space="preserve">
          <source>The job (the XXX in TensorFlow device specification /job:XXX) that contains the TPU devices that will be shutdown. If job=None it is assumed there is only one job in the TensorFlow flock, and an error will be returned if this assumption does not hold.</source>
          <target state="translated">The job (the XXX in TensorFlow device specification /job:XXX) that contains the TPU devices that will be shutdown. If job=None it is assumed there is only one job in the TensorFlow flock, and an error will be returned if this assumption does not hold.</target>
        </trans-unit>
        <trans-unit id="16441d46dfcb0fd71d29af5e06be782473ef7ef7" translate="yes" xml:space="preserve">
          <source>The job name under which the new server will be accessible.</source>
          <target state="translated">The job name under which the new server will be accessible.</target>
        </trans-unit>
        <trans-unit id="751b0fbfa4aeea2c579ce7d09f30705a335965fb" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified by the &lt;code&gt;key_index&lt;/code&gt; and &lt;code&gt;value_index&lt;/code&gt;.</source>
          <target state="translated">각 행에서 가져올 키 및 값 컨텐츠는 &lt;code&gt;key_index&lt;/code&gt; 및 &lt;code&gt;value_index&lt;/code&gt; 로 지정됩니다 .</target>
        </trans-unit>
        <trans-unit id="e732a302356fd06e3da95b03500ebf97f84d0506" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line is specified either by the following, or a value &lt;code&gt;&amp;gt;=0&lt;/code&gt;.</source>
          <target state="translated">각 줄에서 가져올 키 및 값 내용은 다음에 의해 지정되거나 &lt;code&gt;&amp;gt;=0&lt;/code&gt; 값으로 지정됩니다 .</target>
        </trans-unit>
        <trans-unit id="c0771e36c5a66ef95bdba36fa510d228d752d2d4" translate="yes" xml:space="preserve">
          <source>The key and value content to get from each line.</source>
          <target state="translated">각 줄에서 가져올 키 및 값 내용.</target>
        </trans-unit>
        <trans-unit id="b464317f2f49a3771499c8be27b73752b57cff0e" translate="yes" xml:space="preserve">
          <source>The key and value type of the table to initialize is given by &lt;code&gt;key_dtype&lt;/code&gt; and &lt;code&gt;value_dtype&lt;/code&gt;.</source>
          <target state="translated">초기화 할 테이블의 키 및 값 유형은 &lt;code&gt;key_dtype&lt;/code&gt; 및 &lt;code&gt;value_dtype&lt;/code&gt; 에 의해 제공됩니다 .</target>
        </trans-unit>
        <trans-unit id="7f231eccba572c9745a56b810b3c3047e7ea0454" translate="yes" xml:space="preserve">
          <source>The key for the collection. For example, the &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="translated">The key for the collection. For example, the &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</target>
        </trans-unit>
        <trans-unit id="68713242651f0ec86fa38fc63c0f68575067f7ec" translate="yes" xml:space="preserve">
          <source>The key for the collection. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="translated">The key for the collection. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</target>
        </trans-unit>
        <trans-unit id="9f799300f7af4ad7bf22ac56cc9d8c592e154fb0" translate="yes" xml:space="preserve">
          <source>The key for the collections. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="translated">The key for the collections. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</target>
        </trans-unit>
        <trans-unit id="ffb06b79cd9a7c754d2c0b3d48045fd9d3624a00" translate="yes" xml:space="preserve">
          <source>The keys for the collections to add to. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</source>
          <target state="translated">The keys for the collections to add to. The &lt;code&gt;GraphKeys&lt;/code&gt; class contains many standard names for collections.</target>
        </trans-unit>
        <trans-unit id="93ae0a77af7d45a8107b1bfa71735de24854f107" translate="yes" xml:space="preserve">
          <source>The keyword arguments that are passed on to &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="translated">The keyword arguments that are passed on to &lt;code&gt;fn&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2c7afb2c0ad248ba222c168b5103cb8f08e6923f" translate="yes" xml:space="preserve">
          <source>The keyword arguments that are passed on to BaseLayer.&lt;strong&gt;init&lt;/strong&gt;.</source>
          <target state="translated">The keyword arguments that are passed on to BaseLayer.&lt;strong&gt;init&lt;/strong&gt;.</target>
        </trans-unit>
        <trans-unit id="339c24317a151f1ccadbe2bc95f1998f249689f6" translate="yes" xml:space="preserve">
          <source>The keyword arguments that are passed on to BaseLayer.&lt;strong&gt;init&lt;/strong&gt;. Allowed keyword arguments include &lt;code&gt;name&lt;/code&gt;.</source>
          <target state="translated">The keyword arguments that are passed on to BaseLayer.&lt;strong&gt;init&lt;/strong&gt;. Allowed keyword arguments include &lt;code&gt;name&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f2cb43e5a33cda57c35ab173bdca64268dd6064f" translate="yes" xml:space="preserve">
          <source>The last &lt;code&gt;concentration&lt;/code&gt; dimension parametrizes a single Dirichlet-Multinomial distribution. When calling distribution functions (e.g., &lt;code&gt;dist.prob(counts)&lt;/code&gt;), &lt;code&gt;concentration&lt;/code&gt;, &lt;code&gt;total_count&lt;/code&gt; and &lt;code&gt;counts&lt;/code&gt; are broadcast to the same shape. The last dimension of &lt;code&gt;counts&lt;/code&gt; corresponds single Dirichlet-Multinomial distributions.</source>
          <target state="translated">마지막 &lt;code&gt;concentration&lt;/code&gt; 치수는 단일 Dirichlet-Multinomial 분포를 매개 변수화합니다. 분포 함수 (예 : &lt;code&gt;dist.prob(counts)&lt;/code&gt; )를 호출 할 때 &lt;code&gt;concentration&lt;/code&gt; , &lt;code&gt;total_count&lt;/code&gt; 및 &lt;code&gt;counts&lt;/code&gt; 는 동일한 모양으로 브로드 캐스트됩니다. &lt;code&gt;counts&lt;/code&gt; 의 마지막 차원은 단일 Dirichlet-Multinomial 분포에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="78cc8d00f8e7491129a68b99d8285b81a0423488" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; can be at most the rank of &lt;code&gt;params&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 의 마지막 차원은 최대 &lt;code&gt;params&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ecdf342100af669eb1e5196eae29b7087572c686" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to elements (if &lt;code&gt;indices.shape[-1] == params.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; params.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;params&lt;/code&gt;. The output tensor has shape</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 의 마지막 차원 은 &lt;code&gt;params&lt;/code&gt; &lt;code&gt;indices.shape[-1]&lt;/code&gt; 차원을 따라 요소 ( &lt;code&gt;indices.shape[-1] == params.rank&lt;/code&gt; ) 또는 슬라이스 ( &lt;code&gt;indices.shape[-1] &amp;lt; params.rank&lt;/code&gt; )에 해당합니다. . 출력 텐서 모양</target>
        </trans-unit>
        <trans-unit id="286ceed5a9e73c8174db8660f8e7395f9150777f" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to indices into elements (if &lt;code&gt;indices.shape[-1] = shape.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; shape.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;shape&lt;/code&gt;. &lt;code&gt;updates&lt;/code&gt; is a tensor with shape</source>
          <target state="translated">마지막의 치수 &lt;code&gt;indices&lt;/code&gt; 요소의 인덱스에 대응한다 (만약 &lt;code&gt;indices.shape[-1] = shape.rank&lt;/code&gt; ) 또는 조각 (만약 &lt;code&gt;indices.shape[-1] &amp;lt; shape.rank&lt;/code&gt; 차원을 따라) &lt;code&gt;indices.shape[-1]&lt;/code&gt; 의 &lt;code&gt;shape&lt;/code&gt; . &lt;code&gt;updates&lt;/code&gt; 는 모양이있는 텐서입니다.</target>
        </trans-unit>
        <trans-unit id="2bf929456df7864e36863c3aad01721261ffcbb9" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to indices into elements (if &lt;code&gt;indices.shape[-1] = tensor.shape.rank&lt;/code&gt;) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; tensor.shape.rank&lt;/code&gt;) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;tensor.shape&lt;/code&gt;. &lt;code&gt;updates&lt;/code&gt; is a tensor with shape</source>
          <target state="translated">The last dimension of &lt;code&gt;indices&lt;/code&gt; corresponds to indices into elements (if &lt;code&gt;indices.shape[-1] = tensor.shape.rank&lt;/code&gt; ) or slices (if &lt;code&gt;indices.shape[-1] &amp;lt; tensor.shape.rank&lt;/code&gt; ) along dimension &lt;code&gt;indices.shape[-1]&lt;/code&gt; of &lt;code&gt;tensor.shape&lt;/code&gt; . &lt;code&gt;updates&lt;/code&gt; is a tensor with shape</target>
        </trans-unit>
        <trans-unit id="1334749bed79f5a39ed1f5844527d62a1a905c7c" translate="yes" xml:space="preserve">
          <source>The last dimension of &lt;code&gt;sp_input.indices&lt;/code&gt; is discarded and replaced with the values of &lt;code&gt;sp_input&lt;/code&gt;. If &lt;code&gt;sp_input.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt;, then &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt;, where</source>
          <target state="translated">&lt;code&gt;sp_input.indices&lt;/code&gt; 의 마지막 차원 은 버리고 &lt;code&gt;sp_input&lt;/code&gt; 값으로 대체됩니다 . 만약 &lt;code&gt;sp_input.dense_shape = [D0, D1, ..., Dn, K]&lt;/code&gt; 다음 &lt;code&gt;output.shape = [D0, D1, ..., Dn, vocab_size]&lt;/code&gt; 여기서</target>
        </trans-unit>
        <trans-unit id="fbd03a9648fd276c59e057bf5a188513a3c7e179" translate="yes" xml:space="preserve">
          <source>The last three dimensions of input are expected to be [height, width, depth].</source>
          <target state="translated">입력의 마지막 3 차원은 [높이, 너비, 깊이] 일 것으로 예상됩니다.</target>
        </trans-unit>
        <trans-unit id="d9e40b42f372ce30bcad2557b4fbb4971315076a" translate="yes" xml:space="preserve">
          <source>The layer to be wrapped.</source>
          <target state="translated">The layer to be wrapped.</target>
        </trans-unit>
        <trans-unit id="1d8c5a256ceb0281a5abfd9ab601681d1b6839bc" translate="yes" xml:space="preserve">
          <source>The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function that uses a different behavior at train time and test time.</source>
          <target state="translated">학습 단계 플래그는 부울 텐서 (0 = 테스트, 1 = 기차)로, 기차 시간과 테스트 시간에 다른 동작을 사용하는 모든 Keras 함수에 입력으로 전달됩니다.</target>
        </trans-unit>
        <trans-unit id="a0a124fd12c8c65bb6844115fdf183c1b942c532" translate="yes" xml:space="preserve">
          <source>The learning phase gets restored to its original value upon exiting the scope.</source>
          <target state="translated">학습 단계는 범위를 종료하면 원래 값으로 복원됩니다.</target>
        </trans-unit>
        <trans-unit id="1de5c67a1eb0290c7057fa80ed33f8f702db5481" translate="yes" xml:space="preserve">
          <source>The learning rate multiplier first decays from 1 to &lt;code&gt;alpha&lt;/code&gt; for &lt;code&gt;first_decay_steps&lt;/code&gt; steps. Then, a warm restart is performed. Each new warm restart runs for &lt;code&gt;t_mul&lt;/code&gt; times more steps and with &lt;code&gt;m_mul&lt;/code&gt; times smaller initial learning rate.</source>
          <target state="translated">학습 속도 승수 는 &lt;code&gt;first_decay_steps&lt;/code&gt; 단계에 대해 먼저 1에서 &lt;code&gt;alpha&lt;/code&gt; 로 감소 합니다. 그런 다음 웜 재시작이 수행됩니다. 각각의 새로운 웜 리 스타트는 &lt;code&gt;t_mul&lt;/code&gt; 배 더 많은 단계와 &lt;code&gt;m_mul&lt;/code&gt; 배 더 작은 초기 학습 속도로 실행됩니다.</target>
        </trans-unit>
        <trans-unit id="28b092429ddde1497c6f3dfbaf3344b66f15e153" translate="yes" xml:space="preserve">
          <source>The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">학습 속도 일정은 &lt;a href=&quot;serialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;deserialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt; 를&lt;/a&gt; 사용하여 직렬화 가능하고 역 직렬화 가능 합니다.</target>
        </trans-unit>
        <trans-unit id="01e40bb81194de53f99fe696ad30a914f2acff24" translate="yes" xml:space="preserve">
          <source>The learning rate. It should be a floating point value or a callable taking no arguments for a dynamic learning rate.</source>
          <target state="translated">The learning rate. It should be a floating point value or a callable taking no arguments for a dynamic learning rate.</target>
        </trans-unit>
        <trans-unit id="d51c3e8c1e064693087f30b29f778802b426021e" translate="yes" xml:space="preserve">
          <source>The left-hand side of the &lt;code&gt;!=&lt;/code&gt; operator.</source>
          <target state="translated">The left-hand side of the &lt;code&gt;!=&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="cf752d5e27436ab728a37f163c777a5586d0910a" translate="yes" xml:space="preserve">
          <source>The left-hand side of the &lt;code&gt;+&lt;/code&gt; operator.</source>
          <target state="translated">The left-hand side of the &lt;code&gt;+&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="15f4d7d0d6ba87c9c2b8ec8a96bd5bdea5cf5f18" translate="yes" xml:space="preserve">
          <source>The left-hand side of the &lt;code&gt;==&lt;/code&gt; operator.</source>
          <target state="translated">The left-hand side of the &lt;code&gt;==&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="5da8626faf43a1f562532d639d80375ea4ddfc06" translate="yes" xml:space="preserve">
          <source>The length of each row in this ragged tensor, or None if rows are ragged.</source>
          <target state="translated">The length of each row in this ragged tensor, or None if rows are ragged.</target>
        </trans-unit>
        <trans-unit id="622693f2c5cb15d1481ed89936db4a11927a96bd" translate="yes" xml:space="preserve">
          <source>The length of output lists are all of the same length, &lt;code&gt;num_features&lt;/code&gt;. The output shapes are compatible in a way that the first dimension of all tensors of all lists are the same and equal to the number of possible split nodes for each feature.</source>
          <target state="translated">The length of output lists are all of the same length, &lt;code&gt;num_features&lt;/code&gt; . The output shapes are compatible in a way that the first dimension of all tensors of all lists are the same and equal to the number of possible split nodes for each feature.</target>
        </trans-unit>
        <trans-unit id="69dda73634b99af43599a42bd633812c4b338c88" translate="yes" xml:space="preserve">
          <source>The length of the transform. If length is less than sequence length, only the first n elements of the sequence are considered for the DCT. If n is greater than the sequence length, zeros are padded and then the DCT is computed as usual.</source>
          <target state="translated">The length of the transform. If length is less than sequence length, only the first n elements of the sequence are considered for the DCT. If n is greater than the sequence length, zeros are padded and then the DCT is computed as usual.</target>
        </trans-unit>
        <trans-unit id="d85658d0fa4fe8b1b20f2beaec2fc4b746948c87" translate="yes" xml:space="preserve">
          <source>The level at which to log.</source>
          <target state="translated">The level at which to log.</target>
        </trans-unit>
        <trans-unit id="90bbcad1f9bed80766758a96fdfa14681f8c6dd6" translate="yes" xml:space="preserve">
          <source>The link flags.</source>
          <target state="translated">링크 플래그.</target>
        </trans-unit>
        <trans-unit id="eef29fe89c1421162e4e09274c7ca8daa2971972" translate="yes" xml:space="preserve">
          <source>The list is in arbitrary order. It does not contain the special entries &quot;.&quot; and &quot;..&quot;.</source>
          <target state="translated">목록은 임의의 순서입니다. 특수 항목 &quot;.&quot;을 포함하지 않습니다. 그리고 &quot;..&quot;.</target>
        </trans-unit>
        <trans-unit id="8a23b9208c8b55e07cbbf14bb7a18492cdb5be1b" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; arguments that are passed to the op function.</source>
          <target state="translated">The list of &lt;code&gt;Tensor&lt;/code&gt; arguments that are passed to the op function.</target>
        </trans-unit>
        <trans-unit id="4fe2aa6417d3855190d90b82f9abd178eaf4e42b" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects representing the outputs of this op.</source>
          <target state="translated">이 op의 출력을 나타내는 &lt;code&gt;Tensor&lt;/code&gt; 객체 의 목록입니다 .</target>
        </trans-unit>
        <trans-unit id="72b9f570910bc85398790d90eea0b57ff816aa6f" translate="yes" xml:space="preserve">
          <source>The list of &lt;code&gt;Tensor&lt;/code&gt; objects unstacked from &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;value&lt;/code&gt; 에서 스택 해제 된 &lt;code&gt;Tensor&lt;/code&gt; 객체 의 목록입니다 .</target>
        </trans-unit>
        <trans-unit id="e1da5ffc250e1d720f6279716c9d6aade88b1077" translate="yes" xml:space="preserve">
          <source>The list of arguments not parsed as options, including argv[0].</source>
          <target state="translated">argv [0]을 포함하여 옵션으로 구문 분석되지 않은 인수 목록.</target>
        </trans-unit>
        <trans-unit id="7a2668eec12c1d3cf3f187776719d83faec8967b" translate="yes" xml:space="preserve">
          <source>The list of concatenated tensors that was dequeued.</source>
          <target state="translated">큐에서 분리 된 연결된 텐서 목록입니다.</target>
        </trans-unit>
        <trans-unit id="70e71f616ed088b5e1a5217c440dcc82210678f0" translate="yes" xml:space="preserve">
          <source>The list of dtypes for each component of a queue element.</source>
          <target state="translated">큐 요소의 각 구성 요소에 대한 dtype 목록입니다.</target>
        </trans-unit>
        <trans-unit id="bfa264d47e9935a6a337f111d8bbcf3f713d945a" translate="yes" xml:space="preserve">
          <source>The list of names for each component of a queue element.</source>
          <target state="translated">큐 요소의 각 구성 요소에 대한 이름 목록입니다.</target>
        </trans-unit>
        <trans-unit id="afc23fa1ddc71634846115e66b755cdfe5e1dce3" translate="yes" xml:space="preserve">
          <source>The list of shapes for each component of a queue element.</source>
          <target state="translated">큐 요소의 각 구성 요소에 대한 모양 목록입니다.</target>
        </trans-unit>
        <trans-unit id="39c799e61ec6d452a92b2f433fe078d01b37f5db" translate="yes" xml:space="preserve">
          <source>The list of threads started for the &lt;code&gt;QueueRunners&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;QueueRunners&lt;/code&gt; 에 대해 시작된 스레드 목록입니다 .</target>
        </trans-unit>
        <trans-unit id="17c761809240285ed679e6893972139bfc169439" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection.</source>
          <target state="translated">주어진 &lt;code&gt;name&lt;/code&gt; 을 가진 컬렉션의 값 목록 또는 해당 컬렉션에 값이 추가되지 않은 경우 빈 목록.</target>
        </trans-unit>
        <trans-unit id="88981d3f5cd5ac5b5640b8a47ed0e63488d7e59c" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. Note that this returns the collection list itself, which can be modified in place to change the collection.</source>
          <target state="translated">주어진 &lt;code&gt;name&lt;/code&gt; 을 가진 컬렉션의 값 목록 또는 해당 컬렉션에 값이 추가되지 않은 경우 빈 목록. 이렇게하면 컬렉션 목록 자체가 반환되며 컬렉션을 변경하기 위해 수정 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d9ede6fcf47022786b23b7b18ee2bcbd80557011" translate="yes" xml:space="preserve">
          <source>The list of values in the collection with the given &lt;code&gt;name&lt;/code&gt;, or an empty list if no value has been added to that collection. The list contains the values in the order under which they were collected.</source>
          <target state="translated">주어진 &lt;code&gt;name&lt;/code&gt; 을 가진 컬렉션의 값 목록 또는 해당 컬렉션에 값이 추가되지 않은 경우 빈 목록. 이 목록에는 수집 된 순서대로 값이 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="6538ac74002e8b4bac2992b02a57d0b02a01c00b" translate="yes" xml:space="preserve">
          <source>The list or dictionary of tensors to enqueue.</source>
          <target state="translated">The list or dictionary of tensors to enqueue.</target>
        </trans-unit>
        <trans-unit id="72b6afead45a5c197fda6e2bbed35e9b2df07fc4" translate="yes" xml:space="preserve">
          <source>The local task index.</source>
          <target state="translated">The local task index.</target>
        </trans-unit>
        <trans-unit id="7bfb8caff21900bf5e14d413b5ce56c051949f79" translate="yes" xml:space="preserve">
          <source>The local tensor to the sum.</source>
          <target state="translated">The local tensor to the sum.</target>
        </trans-unit>
        <trans-unit id="7016678a2375c9753e8eaf54d3415095320d885f" translate="yes" xml:space="preserve">
          <source>The locations represented by indices in &lt;code&gt;indices&lt;/code&gt; take value &lt;code&gt;on_value&lt;/code&gt;, while all other locations take value &lt;code&gt;off_value&lt;/code&gt;.</source>
          <target state="translated">인덱스에서 &lt;code&gt;indices&lt;/code&gt; 표시되는 위치는 &lt;code&gt;on_value&lt;/code&gt; 값 을 사용하고 다른 모든 위치는 &lt;code&gt;off_value&lt;/code&gt; 값을 사용 합니다.</target>
        </trans-unit>
        <trans-unit id="3d12a72f932ac01058fe17db625020a638310386" translate="yes" xml:space="preserve">
          <source>The logarithm of \(|Beta(x)|\) reducing along the last dimension.</source>
          <target state="translated">마지막 차원을 따라 감소하는 \ (| Beta (x) | \)의 로그입니다.</target>
        </trans-unit>
        <trans-unit id="cc2a2b682bde19cda29671bdd447522bc2609c77" translate="yes" xml:space="preserve">
          <source>The logic for one evaluation step.</source>
          <target state="translated">The logic for one evaluation step.</target>
        </trans-unit>
        <trans-unit id="fb1c02a9347c76b0eb9525d98ba6d17466885bcd" translate="yes" xml:space="preserve">
          <source>The logic for one inference step.</source>
          <target state="translated">The logic for one inference step.</target>
        </trans-unit>
        <trans-unit id="91e2ef43e46f963e6adb77ffb3ae3fdcd8e43230" translate="yes" xml:space="preserve">
          <source>The logic for one training step.</source>
          <target state="translated">The logic for one training step.</target>
        </trans-unit>
        <trans-unit id="7cabf0d11d7d05a82a8264a276c299a29ceb6060" translate="yes" xml:space="preserve">
          <source>The logical device id presented is not consistent with total number of partitions specified by the device assignment.</source>
          <target state="translated">The logical device id presented is not consistent with total number of partitions specified by the device assignment.</target>
        </trans-unit>
        <trans-unit id="bcad86f6653e28bded1ae388b8b9d533057cc10b" translate="yes" xml:space="preserve">
          <source>The logical to physical core mapping.</source>
          <target state="translated">논리적 대 물리적 코어 매핑</target>
        </trans-unit>
        <trans-unit id="52db0b11c9a30f712036906862cfb94de23cb0bc" translate="yes" xml:space="preserve">
          <source>The logits, a float tensor. Note that logits are assumed to be unbounded and 0-centered. A value &amp;gt; 0 (resp. &amp;lt; 0) is considered a positive (resp. negative) binary prediction.</source>
          <target state="translated">The logits, a float tensor. Note that logits are assumed to be unbounded and 0-centered. A value &amp;gt; 0 (resp. &amp;lt; 0) is considered a positive (resp. negative) binary prediction.</target>
        </trans-unit>
        <trans-unit id="115853f39fe8d408f8bde4c8f093c2786d017e1d" translate="yes" xml:space="preserve">
          <source>The loss function to wrap, with signature &lt;code&gt;fn(y_true, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">The loss function to wrap, with signature &lt;code&gt;fn(y_true, y_pred, **kwargs)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="53c66b9be9a4d574723adcf23a86e3d3823c9748" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over all input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt;, the loss is the weighted sum over both &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;label_dimension&lt;/code&gt;.</source>
          <target state="translated">손실은 모든 입력 차원에 대한 가중치 합계입니다. 즉, 입력 레이블의 모양이 &lt;code&gt;[batch_size, label_dimension]&lt;/code&gt; 인 경우 손실은 &lt;code&gt;batch_size&lt;/code&gt; 및 &lt;code&gt;label_dimension&lt;/code&gt; 에 대한 가중치 합계 입니다.</target>
        </trans-unit>
        <trans-unit id="ed8e3f66cfff153d9268a06149cbecc331a07647" translate="yes" xml:space="preserve">
          <source>The loss is the weighted sum over the input dimensions. Namely, if the input labels have shape &lt;code&gt;[batch_size, 1]&lt;/code&gt;, the loss is the weighted sum over &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="translated">손실은 입력 차원에 대한 가중치 합계입니다. 즉, 입력 레이블의 모양이 &lt;code&gt;[batch_size, 1]&lt;/code&gt; 인 경우 손실은 &lt;code&gt;batch_size&lt;/code&gt; 에 대한 가중치 합계 입니다.</target>
        </trans-unit>
        <trans-unit id="6d3c5f122953381dbc3e40a95fb1e99d6fa1a036" translate="yes" xml:space="preserve">
          <source>The loss scale can either be a fixed constant, chosen by the user, or be dynamically determined. Dynamically determining the loss scale is convenient as a loss scale does not have to be explicitly chosen. However it reduces performance.</source>
          <target state="translated">손실 척도는 고정 상수이거나 사용자가 선택한 상수이거나 동적으로 결정될 수 있습니다. 손실 척도를 명시 적으로 선택할 필요가 없기 때문에 손실 척도를 동적으로 결정하는 것이 편리합니다. 그러나 성능이 저하됩니다.</target>
        </trans-unit>
        <trans-unit id="0f2c12568d11b3b33927e92671eaa159d3a45974" translate="yes" xml:space="preserve">
          <source>The loss scale is not updated for the lifetime of instances of this class. A given instance of this class always returns the same number when called.</source>
          <target state="translated">손실 등급은이 클래스의 인스턴스 수명 동안 업데이트되지 않습니다. 이 클래스의 주어진 인스턴스는 호출 될 때 항상 같은 숫자를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="e8cc3d97c2f9a64a6e0f3c844b54283387973842" translate="yes" xml:space="preserve">
          <source>The loss scale to scale the loss and gradients. This can either be an int/float to use a fixed loss scale, the string &quot;dynamic&quot; to use dynamic loss scaling, or an instance of a LossScale. The string &quot;dynamic&quot; equivalent to passing &lt;code&gt;DynamicLossScale()&lt;/code&gt;, and passing an int/float is equivalent to passing a FixedLossScale with the given loss scale.</source>
          <target state="translated">The loss scale to scale the loss and gradients. This can either be an int/float to use a fixed loss scale, the string &quot;dynamic&quot; to use dynamic loss scaling, or an instance of a LossScale. The string &quot;dynamic&quot; equivalent to passing &lt;code&gt;DynamicLossScale()&lt;/code&gt; , and passing an int/float is equivalent to passing a FixedLossScale with the given loss scale.</target>
        </trans-unit>
        <trans-unit id="1c182a3c24f8448fb2c7d3d37bb39bed65ff10d2" translate="yes" xml:space="preserve">
          <source>The loss scale will be potentially updated, based on the value of &lt;code&gt;grads&lt;/code&gt;. The tensor returned by calling this class is only updated when this function is evaluated.</source>
          <target state="translated">손실 척도는 &lt;code&gt;grads&lt;/code&gt; 값에 따라 잠재적으로 업데이트됩니다 . 이 클래스를 호출하여 리턴 된 텐서는이 함수가 평가 될 때만 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="d57e591f877f94ccd0c69a35ed4f95a452a44b64" translate="yes" xml:space="preserve">
          <source>The loss, which will be multiplied by the loss scale. Can either be a tensor or a callable returning a tensor.</source>
          <target state="translated">The loss, which will be multiplied by the loss scale. Can either be a tensor or a callable returning a tensor.</target>
        </trans-unit>
        <trans-unit id="90f307f8c8cab35fd072b8a08ea2d9e8126898ba" translate="yes" xml:space="preserve">
          <source>The lower regularized incomplete Gamma function is defined as:</source>
          <target state="translated">정규화되지 않은 불완전한 감마 함수는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="901b07d42e65c9f0c403e10ea3c5514df3c63502" translate="yes" xml:space="preserve">
          <source>The main advantage of the graph rewrite (this function) is that it works even if you do not use Keras layers or any other part of Keras. The Keras mixed precision API requires models which use Keras layers, as it only inserts casts inside Keras layers and models. Another advantage is that the graph rewrite never results in a TypeError, which the Keras API may introduce if you do certain operations outside Keras. For example, the following will result in a TypeError if the Keras mixed precision API is enabled, as a float16 and float32 tensor will be added: &lt;code&gt;tf.keras.layers.Dense(2)(x) + tf.keras.layers.Dense(2, dtype=&quot;float32&quot;)(x)&lt;/code&gt;</source>
          <target state="translated">The main advantage of the graph rewrite (this function) is that it works even if you do not use Keras layers or any other part of Keras. The Keras mixed precision API requires models which use Keras layers, as it only inserts casts inside Keras layers and models. Another advantage is that the graph rewrite never results in a TypeError, which the Keras API may introduce if you do certain operations outside Keras. For example, the following will result in a TypeError if the Keras mixed precision API is enabled, as a float16 and float32 tensor will be added: &lt;code&gt;tf.keras.layers.Dense(2)(x) + tf.keras.layers.Dense(2, dtype=&quot;float32&quot;)(x)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f2793511554b8b49f5f134322351c8feaf894969" translate="yes" xml:space="preserve">
          <source>The main reason to subclass &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt; instead of using a &lt;code&gt;Lambda&lt;/code&gt; layer is saving and inspecting a Model. &lt;code&gt;Lambda&lt;/code&gt; layers are saved by serializing the Python bytecode, whereas subclassed Layers can be saved via overriding their &lt;code&gt;get_config&lt;/code&gt; method. Overriding &lt;code&gt;get_config&lt;/code&gt; improves the portability of Models. Models that rely on subclassed Layers are also often easier to visualize and reason about.</source>
          <target state="translated">&lt;code&gt;Lambda&lt;/code&gt; 레이어 를 사용하는 대신 &lt;a href=&quot;layer&quot;&gt; &lt;code&gt;tf.keras.layers.Layer&lt;/code&gt; &lt;/a&gt; 를 서브 클래 싱하는 주된 이유 는 모델을 저장하고 검사하는 것입니다. &lt;code&gt;Lambda&lt;/code&gt; 레이어는 Python 바이트 코드를 직렬화하여 저장되는 반면 하위 클래스 레이어는 &lt;code&gt;get_config&lt;/code&gt; 메소드 를 재정 의하여 저장할 수 있습니다 . &lt;code&gt;get_config&lt;/code&gt; 를 재정의 하면 모델의 이식성이 향상됩니다. 서브 클래 싱 된 레이어에 의존하는 모델은 종종 시각화하고 추론하기가 더 쉽습니다.</target>
        </trans-unit>
        <trans-unit id="819f3cd059d735134db06c3d8502fabffae5741e" translate="yes" xml:space="preserve">
          <source>The main roles of the &lt;a href=&quot;../gfile&quot;&gt;&lt;code&gt;tf.io.gfile&lt;/code&gt;&lt;/a&gt; module are:</source>
          <target state="translated">The main roles of the &lt;a href=&quot;../gfile&quot;&gt; &lt;code&gt;tf.io.gfile&lt;/code&gt; &lt;/a&gt; module are:</target>
        </trans-unit>
        <trans-unit id="e62c58738b23223c2be9a210223b49cb5226c9b5" translate="yes" xml:space="preserve">
          <source>The main use case for this is to provide additional shape information that cannot be inferred from the graph alone.</source>
          <target state="translated">The main use case for this is to provide additional shape information that cannot be inferred from the graph alone.</target>
        </trans-unit>
        <trans-unit id="4a2c99d4f1e6d03bbc1af13e3314d300799e01bf" translate="yes" xml:space="preserve">
          <source>The map vectorization options associated with the dataset. See &lt;a href=&quot;mapvectorizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.MapVectorizationOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된지도 벡터화 옵션. 자세한 내용은 &lt;a href=&quot;mapvectorizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.MapVectorizationOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="f8214e9e9da90e26f5fe7ae19cb9d8f2cd4e068c" translate="yes" xml:space="preserve">
          <source>The masked &lt;code&gt;IndexedSlices&lt;/code&gt; instance.</source>
          <target state="translated">마스크 된 &lt;code&gt;IndexedSlices&lt;/code&gt; 인스턴스입니다.</target>
        </trans-unit>
        <trans-unit id="221a20910838d03246163841206f72d038ef571a" translate="yes" xml:space="preserve">
          <source>The matrix &lt;code&gt;a&lt;/code&gt; must, following any transpositions, be a tensor of rank &amp;gt;= 2, with &lt;code&gt;shape(a)[-1] == shape(b)[-1]&lt;/code&gt;, and &lt;code&gt;shape(a)[:-2]&lt;/code&gt; able to broadcast with &lt;code&gt;shape(b)[:-1]&lt;/code&gt;.</source>
          <target state="translated">모든 전위에 따라 행렬 &lt;code&gt;a&lt;/code&gt; 는 &lt;code&gt;shape(a)[-1] == shape(b)[-1]&lt;/code&gt; 및 &lt;code&gt;shape(a)[:-2]&lt;/code&gt; 수있는 &amp;gt;&amp;gt; 2의 텐서 여야합니다 . &lt;code&gt;shape(b)[:-1]&lt;/code&gt; 브로드 캐스트하십시오 .</target>
        </trans-unit>
        <trans-unit id="fd71aa391cda25307463e674c4cbc2ea6a909c84" translate="yes" xml:space="preserve">
          <source>The matrix can be used with &lt;a href=&quot;../tensordot&quot;&gt;&lt;code&gt;tf.tensordot&lt;/code&gt;&lt;/a&gt; to convert an arbitrary rank &lt;code&gt;Tensor&lt;/code&gt; of linear-scale spectral bins into the mel scale.</source>
          <target state="translated">이 매트릭스는 &lt;a href=&quot;../tensordot&quot;&gt; &lt;code&gt;tf.tensordot&lt;/code&gt; &lt;/a&gt; 과 함께 사용되어 선형 스케일 스펙트럼 빈 의 임의 랭크 &lt;code&gt;Tensor&lt;/code&gt; 를 멜 스케일 로 변환 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="11e987b7f304f6e3dd583d8302496f7bf0e8c7c9" translate="yes" xml:space="preserve">
          <source>The matrix columns represent the prediction labels and the rows represent the real labels. The confusion matrix is always a 2-D array of shape &lt;code&gt;[n, n]&lt;/code&gt;, where &lt;code&gt;n&lt;/code&gt; is the number of valid labels for a given classification task. Both prediction and labels must be 1-D arrays of the same shape in order for this function to work.</source>
          <target state="translated">행렬 열은 예측 레이블을 나타내고 행은 실제 레이블을 나타냅니다. 혼동 행렬은 항상 &lt;code&gt;[n, n]&lt;/code&gt; 모양의 2 차원 배열이며 , 여기서 &lt;code&gt;n&lt;/code&gt; 은 지정된 분류 작업에 유효한 레이블 수입니다. 이 함수가 작동하려면 예측 및 레이블이 동일한 모양의 1 차원 배열이어야합니다.</target>
        </trans-unit>
        <trans-unit id="1b5db825d45e0c9d1dc6abe9745f59c698b3a58a" translate="yes" xml:space="preserve">
          <source>The matrix square root is computed by first reducing the matrix to quasi-triangular form with the real Schur decomposition. The square root of the quasi-triangular matrix is then computed directly. Details of the algorithm can be found in: Nicholas J. Higham, &quot;Computing real square roots of a real matrix&quot;, Linear Algebra Appl., 1987.</source>
          <target state="translated">행렬 제곱근은 먼저 실제 Schur 분해를 통해 행렬을 준 삼각형으로 축소하여 계산됩니다. 그런 다음 준 삼각 행렬의 제곱근이 직접 계산됩니다. 알고리즘에 대한 자세한 내용은 Nicholas J. Higham, &quot;실제 행렬의 실제 제곱근 계산&quot;, Linear Algebra Appl., 1987에서 확인할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9a3f4491229c91cec072bbea8b93dd0af684f6f0" translate="yes" xml:space="preserve">
          <source>The matrix_inv, i.e., &lt;code&gt;tf.matrix_inverse(tf.linalg.lu_reconstruct(lu, perm))&lt;/code&gt;.</source>
          <target state="translated">The matrix_inv, i.e., &lt;code&gt;tf.matrix_inverse(tf.linalg.lu_reconstruct(lu, perm))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3cbe11326425a2d54b10de9163c8a24f5b723b61" translate="yes" xml:space="preserve">
          <source>The maximum depth of the batch queue. Defaults to 10.</source>
          <target state="translated">The maximum depth of the batch queue. Defaults to 10.</target>
        </trans-unit>
        <trans-unit id="5e52e55f2b2b641c09e44a69eccc168205a706b2" translate="yes" xml:space="preserve">
          <source>The maximum error in between the two Jacobians.</source>
          <target state="translated">두 야곱 인 사이의 최대 오차.</target>
        </trans-unit>
        <trans-unit id="3be13be49d81cebdf3179f6f054bd1716af0f051" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations allowed to run in parallel at any given time. Note that this does not guarantee parallel execution.</source>
          <target state="translated">The maximum number of iterations allowed to run in parallel at any given time. Note that this does not guarantee parallel execution.</target>
        </trans-unit>
        <trans-unit id="29ead67ff92bddff9eff04834e8bb493908a2db7" translate="yes" xml:space="preserve">
          <source>The maximum number of recent checkpoint files to keep. As new files are created, older files are deleted. If &lt;code&gt;None&lt;/code&gt; or 0, all checkpoint files are kept. Defaults to 5 (that is, the 5 most recent checkpoint files are kept). If a saver is passed to the estimator, this argument will be ignored.</source>
          <target state="translated">The maximum number of recent checkpoint files to keep. As new files are created, older files are deleted. If &lt;code&gt;None&lt;/code&gt; or 0, all checkpoint files are kept. Defaults to 5 (that is, the 5 most recent checkpoint files are kept). If a saver is passed to the estimator, this argument will be ignored.</target>
        </trans-unit>
        <trans-unit id="c842279a5926425077d49c4d323753d5555a6974" translate="yes" xml:space="preserve">
          <source>The maximum number of seconds to wait between checkpoints. If left as &lt;code&gt;None&lt;/code&gt;, then the process will wait indefinitely.</source>
          <target state="translated">The maximum number of seconds to wait between checkpoints. If left as &lt;code&gt;None&lt;/code&gt; , then the process will wait indefinitely.</target>
        </trans-unit>
        <trans-unit id="5fec7fdc53285af99f3c39f517df820603ae9970" translate="yes" xml:space="preserve">
          <source>The maximum number of shards in int created taking precedence over &lt;code&gt;max_shard_bytes&lt;/code&gt;.</source>
          <target state="translated">The maximum number of shards in int created taking precedence over &lt;code&gt;max_shard_bytes&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ce69417dfa16ffede7fef0c558fc36b98c931ccd" translate="yes" xml:space="preserve">
          <source>The maximum size any given shard is allowed to be.</source>
          <target state="translated">The maximum size any given shard is allowed to be.</target>
        </trans-unit>
        <trans-unit id="b2f9f6a5b1ba47e00d259277177486caa909f7c3" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary.</source>
          <target state="translated">The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary.</target>
        </trans-unit>
        <trans-unit id="bf7f7963ad951a38de619a169bd063732ab43414" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary contains 1 OOV token, so the effective number of tokens is &lt;code&gt;(max_tokens - 1 - (1 if output == &quot;int&quot; else 0))&lt;/code&gt;.</source>
          <target state="translated">The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary contains 1 OOV token, so the effective number of tokens is &lt;code&gt;(max_tokens - 1 - (1 if output == &quot;int&quot; else 0))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="823dcf626318cd7da7d9199f74b8dc7942281b83" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary includes the OOV and mask tokens, so the effective number of tokens is (max_tokens - num_oov_indices - (1 if mask_token else 0))</source>
          <target state="translated">The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary includes the OOV and mask tokens, so the effective number of tokens is (max_tokens - num_oov_indices - (1 if mask_token else 0))</target>
        </trans-unit>
        <trans-unit id="fce588fe3287d94ea0532f096d110229f0b8aff4" translate="yes" xml:space="preserve">
          <source>The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary includes the OOV and mask values, so the effective number of values is (max_values - num_oov_values - (1 if mask_token else 0))</source>
          <target state="translated">The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary includes the OOV and mask values, so the effective number of values is (max_values - num_oov_values - (1 if mask_token else 0))</target>
        </trans-unit>
        <trans-unit id="2c20357476750adc337729874b4e2eabc8868c3d" translate="yes" xml:space="preserve">
          <source>The mean and variance are calculated by aggregating the contents of &lt;code&gt;x&lt;/code&gt; across &lt;code&gt;axes&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is 1-D and &lt;code&gt;axes = [0]&lt;/code&gt; this is just the mean and variance of a vector.</source>
          <target state="translated">평균과 분산은 &lt;code&gt;x&lt;/code&gt; 의 내용 을 &lt;code&gt;axes&lt;/code&gt; 걸쳐 집계하여 계산됩니다 . 경우 &lt;code&gt;x&lt;/code&gt; 1-D이고 &lt;code&gt;axes = [0]&lt;/code&gt; 이 단지 평균 벡터 및의 분산이다.</target>
        </trans-unit>
        <trans-unit id="e3746fb2d4eae6a4ec87d65fc23bec2fa55150f2" translate="yes" xml:space="preserve">
          <source>The mean of Student's T equals &lt;code&gt;loc&lt;/code&gt; if &lt;code&gt;df &amp;gt; 1&lt;/code&gt;, otherwise it is &lt;code&gt;NaN&lt;/code&gt;. If &lt;code&gt;self.allow_nan_stats=True&lt;/code&gt;, then an exception will be raised rather than returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;df &amp;gt; 1&lt;/code&gt; 인 경우 Student 's T의 평균은 &lt;code&gt;loc&lt;/code&gt; 와 같고 , 그렇지 않으면 &lt;code&gt;NaN&lt;/code&gt; 입니다. 경우 &lt;code&gt;self.allow_nan_stats=True&lt;/code&gt; 는 예외가 리턴하는 대신 발생합니다 &lt;code&gt;NaN&lt;/code&gt; 이를 .</target>
        </trans-unit>
        <trans-unit id="66b167be0f051cc6e8d71c967e67b0309cb7feab" translate="yes" xml:space="preserve">
          <source>The meaning of &lt;code&gt;query&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; and &lt;code&gt;key&lt;/code&gt; depend on the application. In the case of text similarity, for example, &lt;code&gt;query&lt;/code&gt; is the sequence embeddings of the first piece of text and &lt;code&gt;value&lt;/code&gt; is the sequence embeddings of the second piece of text. &lt;code&gt;key&lt;/code&gt; is usually the same tensor as &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;query&lt;/code&gt; , &lt;code&gt;value&lt;/code&gt; 및 &lt;code&gt;key&lt;/code&gt; 의 의미 는 응용 프로그램에 따라 다릅니다. 텍스트 유사성의 경우, 예를 들어 &lt;code&gt;query&lt;/code&gt; 는 첫 번째 텍스트 조각의 시퀀스 임베딩 이고 &lt;code&gt;value&lt;/code&gt; 은 두 번째 텍스트 조각의 시퀀스 임베딩입니다. &lt;code&gt;key&lt;/code&gt; 는 일반적으로 &lt;code&gt;value&lt;/code&gt; 와 동일한 텐서 입니다.</target>
        </trans-unit>
        <trans-unit id="92510595be575a3f901083a76e505b27be4bea36" translate="yes" xml:space="preserve">
          <source>The meaning of setting &lt;code&gt;layer.trainable = False&lt;/code&gt; is to freeze the layer, i.e. its internal state will not change during training: its trainable weights will not be updated during &lt;code&gt;fit()&lt;/code&gt; or &lt;code&gt;train_on_batch()&lt;/code&gt;, and its state updates will not be run.</source>
          <target state="translated">&lt;code&gt;layer.trainable = False&lt;/code&gt; 설정의 의미는 레이어를 고정하는 것입니다. 즉, 훈련 중 내부 상태가 변경되지 않습니다. 훈련 가능한 가중치는 &lt;code&gt;fit()&lt;/code&gt; 또는 &lt;code&gt;train_on_batch()&lt;/code&gt; 중에 업데이트되지 않으며 상태 업데이트가 실행되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="528237c36c5e86dd6df7548b941e9ca56236a205" translate="yes" xml:space="preserve">
          <source>The message string describing the failure.</source>
          <target state="translated">The message string describing the failure.</target>
        </trans-unit>
        <trans-unit id="529560d839d515582efcee9c67d4aa3e5b977208" translate="yes" xml:space="preserve">
          <source>The message to be logged.</source>
          <target state="translated">The message to be logged.</target>
        </trans-unit>
        <trans-unit id="927b26e1d502dee1491ea322ed177902d5b783af" translate="yes" xml:space="preserve">
          <source>The message to be printed if the test fails.</source>
          <target state="translated">The message to be printed if the test fails.</target>
        </trans-unit>
        <trans-unit id="dc3b5afc215b729af496233be8e56b7e96ac2370" translate="yes" xml:space="preserve">
          <source>The method is primarily intended for use by higher level checkpoint management utilities that use &lt;code&gt;write()&lt;/code&gt; instead of &lt;code&gt;save()&lt;/code&gt; and have their own mechanisms to number and track checkpoints.</source>
          <target state="translated">The method is primarily intended for use by higher level checkpoint management utilities that use &lt;code&gt;write()&lt;/code&gt; instead of &lt;code&gt;save()&lt;/code&gt; and have their own mechanisms to number and track checkpoints.</target>
        </trans-unit>
        <trans-unit id="ae04b245da8a7e16dadcfeccbc7fd1f3884fcfad" translate="yes" xml:space="preserve">
          <source>The method returns the path prefix of the newly created checkpoint files. This string can be passed directly to a call to &lt;code&gt;restore()&lt;/code&gt;.</source>
          <target state="translated">이 메소드는 새로 작성된 체크 포인트 파일의 경로 접 두부를 리턴합니다. 이 문자열은 &lt;code&gt;restore()&lt;/code&gt; 호출로 직접 전달 될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="1836c8d92cb040c17ca773b41548d6aa87cf1d6f" translate="yes" xml:space="preserve">
          <source>The method sums gradients from all replicas in the presence of &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; by default. You can aggregate gradients yourself by passing &lt;code&gt;experimental_aggregate_gradients=False&lt;/code&gt;.</source>
          <target state="translated">The method sums gradients from all replicas in the presence of &lt;a href=&quot;../../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; by default. You can aggregate gradients yourself by passing &lt;code&gt;experimental_aggregate_gradients=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e0ac25102d39a598793fa8f0fe151f95b652dfdf" translate="yes" xml:space="preserve">
          <source>The method sums gradients from all replicas in the presence of &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; by default. You can aggregate gradients yourself by passing &lt;code&gt;experimental_aggregate_gradients=False&lt;/code&gt;.</source>
          <target state="translated">The method sums gradients from all replicas in the presence of &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; by default. You can aggregate gradients yourself by passing &lt;code&gt;experimental_aggregate_gradients=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6ff8c3ac6acac3abb6a93f8bb5141bf050b9a99b" translate="yes" xml:space="preserve">
          <source>The method to wrap.</source>
          <target state="translated">The method to wrap.</target>
        </trans-unit>
        <trans-unit id="3c6e6621d848cf3b840ae66983d6900ad6f06a8b" translate="yes" xml:space="preserve">
          <source>The metric creates two local variables, &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt; that are used to compute the precision. This value is ultimately returned as &lt;code&gt;precision&lt;/code&gt;, an idempotent operation that simply divides &lt;code&gt;true_positives&lt;/code&gt; by the sum of &lt;code&gt;true_positives&lt;/code&gt; and &lt;code&gt;false_positives&lt;/code&gt;.</source>
          <target state="translated">메트릭은 정밀도를 계산하는 데 사용되는 두 개의 로컬 변수 &lt;code&gt;true_positives&lt;/code&gt; 및 &lt;code&gt;false_positives&lt;/code&gt; 를 만듭니다 . 이 값은 궁극적 으로 &lt;code&gt;true_positives&lt;/code&gt; 를 &lt;code&gt;true_positives&lt;/code&gt; 와 &lt;code&gt;false_positives&lt;/code&gt; 의 합으로 나누는 pot 등식 연산 인 &lt;code&gt;precision&lt;/code&gt; 으로 반환됩니다 .</target>
        </trans-unit>
        <trans-unit id="a1847f02504cca83cac29940c7bc8134ccc574f2" translate="yes" xml:space="preserve">
          <source>The min and max can be the same size as &lt;code&gt;t&lt;/code&gt;, or broadcastable to that size.</source>
          <target state="translated">The min and max can be the same size as &lt;code&gt;t&lt;/code&gt; , or broadcastable to that size.</target>
        </trans-unit>
        <trans-unit id="c879ab9978d630c89fff8cae92e9db4343f09490" translate="yes" xml:space="preserve">
          <source>The minibatch size &lt;code&gt;N&lt;/code&gt; is extracted from &lt;code&gt;sparse_shape[0]&lt;/code&gt;.</source>
          <target state="translated">미니 배치 크기 &lt;code&gt;N&lt;/code&gt; 은 sparse_shape &lt;code&gt;sparse_shape[0]&lt;/code&gt; 에서 추출됩니다 .</target>
        </trans-unit>
        <trans-unit id="e7bc279c2507aa25ef22019845fdd46f52af29f0" translate="yes" xml:space="preserve">
          <source>The minimum number of seconds between yielding checkpoints.</source>
          <target state="translated">The minimum number of seconds between yielding checkpoints.</target>
        </trans-unit>
        <trans-unit id="e2ce5fd43a91250f68e4b68161729fe63f5fffc0" translate="yes" xml:space="preserve">
          <source>The minimum value to clip to. A scalar &lt;code&gt;Tensor&lt;/code&gt; or one that is broadcastable to the shape of &lt;code&gt;t&lt;/code&gt;.</source>
          <target state="translated">The minimum value to clip to. A scalar &lt;code&gt;Tensor&lt;/code&gt; or one that is broadcastable to the shape of &lt;code&gt;t&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="adafbd0cce3b5754618ae2da17c9902f6cae336a" translate="yes" xml:space="preserve">
          <source>The mode of a gamma distribution is &lt;code&gt;(shape - 1) / rate&lt;/code&gt; when &lt;code&gt;shape &amp;gt; 1&lt;/code&gt;, and &lt;code&gt;NaN&lt;/code&gt; otherwise. If &lt;code&gt;self.allow_nan_stats&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, an exception will be raised rather than returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">감마 분포의 모드는 &lt;code&gt;shape &amp;gt; 1&lt;/code&gt; 일 때 &lt;code&gt;(shape - 1) / rate&lt;/code&gt; 이고, 그렇지 않으면 &lt;code&gt;NaN&lt;/code&gt; 입니다. 경우 &lt;code&gt;self.allow_nan_stats&lt;/code&gt; 이 있다 &lt;code&gt;False&lt;/code&gt; , 예외가 리턴하는 대신 발생합니다 &lt;code&gt;NaN&lt;/code&gt; 이를 .</target>
        </trans-unit>
        <trans-unit id="ccf3763dcb0dcb0536020350fdb380b642b68362" translate="yes" xml:space="preserve">
          <source>The model architecture, allowing to re-instantiate the model.</source>
          <target state="translated">모델 아키텍처를 통해 모델을 다시 인스턴스화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2c5272bf28fc9b4f93ddcbb47262f8771af50748" translate="yes" xml:space="preserve">
          <source>The model weights.</source>
          <target state="translated">모델 가중치.</target>
        </trans-unit>
        <trans-unit id="ea7ad3d000098fbd9c3f8078136ad7545a66a1a5" translate="yes" xml:space="preserve">
          <source>The monitoring result is a light weight performance summary of your model execution. This method will block the caller thread until it receives the monitoring result. This method currently supports Cloud TPU only.</source>
          <target state="translated">The monitoring result is a light weight performance summary of your model execution. This method will block the caller thread until it receives the monitoring result. This method currently supports Cloud TPU only.</target>
        </trans-unit>
        <trans-unit id="ff3e822749aa45b217109835dbb8a4c4930f2cb5" translate="yes" xml:space="preserve">
          <source>The most basic RNN cell.</source>
          <target state="translated">가장 기본적인 RNN 셀.</target>
        </trans-unit>
        <trans-unit id="92ef4fa2dcf9047cf590c368e2e76fcb4cd1ce27" translate="yes" xml:space="preserve">
          <source>The most common initialization pattern is to use the convenience function &lt;code&gt;global_variables_initializer()&lt;/code&gt; to add an Op to the graph that initializes all the variables. You then run that Op after launching the graph.</source>
          <target state="translated">가장 일반적인 초기화 패턴은 편의 함수 &lt;code&gt;global_variables_initializer()&lt;/code&gt; 를 사용하여 모든 변수를 초기화하는 그래프에 Op를 추가하는 것입니다. 그런 다음 그래프를 시작한 후 해당 Op를 실행하십시오.</target>
        </trans-unit>
        <trans-unit id="be28bd956ec3dd71f96903bf3e90304d770c19da" translate="yes" xml:space="preserve">
          <source>The most common use case for this function occurs when feature ids and their corresponding values are stored in &lt;code&gt;Example&lt;/code&gt; protos on disk. &lt;code&gt;parse_example&lt;/code&gt; will return a batch of ids and a batch of values, and this function joins them into a single logical &lt;code&gt;SparseTensor&lt;/code&gt; for use in functions such as &lt;code&gt;sparse_tensor_dense_matmul&lt;/code&gt;, &lt;code&gt;sparse_to_dense&lt;/code&gt;, etc.</source>
          <target state="translated">이 기능의 가장 일반적인 사용 사례는 기능 ID와 해당 값이 디스크의 &lt;code&gt;Example&lt;/code&gt; 프로토 타에 저장 될 때 발생합니다 . &lt;code&gt;parse_example&lt;/code&gt; 은 일련의 id와 일련의 값을 반환하며,이 함수는 &lt;code&gt;sparse_tensor_dense_matmul&lt;/code&gt; , &lt;code&gt;sparse_to_dense&lt;/code&gt; 등과 같은 함수에서 사용하기 위해 단일 논리 &lt;code&gt;SparseTensor&lt;/code&gt; 에 결합합니다 .</target>
        </trans-unit>
        <trans-unit id="a69bd33774ebc03eef1cf8370253b0bcf30e7aa7" translate="yes" xml:space="preserve">
          <source>The moving average 'x' is updated with 'value' following:</source>
          <target state="translated">The moving average 'x' is updated with 'value' following:</target>
        </trans-unit>
        <trans-unit id="76823a81079db8809cfb267b11ddd3da1ded660e" translate="yes" xml:space="preserve">
          <source>The moving average momentum.</source>
          <target state="translated">The moving average momentum.</target>
        </trans-unit>
        <trans-unit id="4c37b111e7c1a2dfc5ac3657ac3eb40f6697f662" translate="yes" xml:space="preserve">
          <source>The moving averages are computed using exponential decay. You specify the decay value when creating the &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; object. The shadow variables are initialized with the same initial values as the trained variables. When you run the ops to maintain the moving averages, each shadow variable is updated with the formula:</source>
          <target state="translated">이동 평균은 지수 붕괴를 사용하여 계산됩니다. &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; 객체를 생성 할 때 소멸 값을 지정 합니다. 새도우 변수는 학습 된 변수와 동일한 초기 값으로 초기화됩니다. 이동 평균을 유지하기 위해 ops를 실행할 때 각 그림자 변수는 다음 공식으로 업데이트됩니다.</target>
        </trans-unit>
        <trans-unit id="f305dca235c43ee1a853f11ce26d4431d5e87ca7" translate="yes" xml:space="preserve">
          <source>The multiplier to use when increasing or decreasing the loss scale.</source>
          <target state="translated">The multiplier to use when increasing or decreasing the loss scale.</target>
        </trans-unit>
        <trans-unit id="3435f5d772da81bd99891e4904cc5b3c397d1c9f" translate="yes" xml:space="preserve">
          <source>The name argument that is passed to the op function.</source>
          <target state="translated">The name argument that is passed to the op function.</target>
        </trans-unit>
        <trans-unit id="d20e166c1cf227f369943da2e63973914a88b08e" translate="yes" xml:space="preserve">
          <source>The name associated with the object, or the default Python name if the object is not registered.</source>
          <target state="translated">The name associated with the object, or the default Python name if the object is not registered.</target>
        </trans-unit>
        <trans-unit id="2171b8f310d13c802a9a28d101182783fe8adb9e" translate="yes" xml:space="preserve">
          <source>The name for an operation.</source>
          <target state="translated">The name for an operation.</target>
        </trans-unit>
        <trans-unit id="2717d81e9c492087a9d97bf3dcb31386b0e2f366" translate="yes" xml:space="preserve">
          <source>The name of a device to which elements will be copied.</source>
          <target state="translated">The name of a device to which elements will be copied.</target>
        </trans-unit>
        <trans-unit id="e102ebd7e44cf3878287ddf4c08d8cb2be4fd58f" translate="yes" xml:space="preserve">
          <source>The name of the &lt;code&gt;Operation&lt;/code&gt; to return.</source>
          <target state="translated">The name of the &lt;code&gt;Operation&lt;/code&gt; to return.</target>
        </trans-unit>
        <trans-unit id="aec966e4ab5b0c806f06d99f9dc3e1f466185982" translate="yes" xml:space="preserve">
          <source>The name of the &lt;code&gt;Tensor&lt;/code&gt; to return.</source>
          <target state="translated">The name of the &lt;code&gt;Tensor&lt;/code&gt; to return.</target>
        </trans-unit>
        <trans-unit id="94df2d413ae96a0a117fa46769022f06a44e6ff4" translate="yes" xml:space="preserve">
          <source>The name of the &lt;code&gt;TensorArray&lt;/code&gt; (even if passed in) is uniquified: each time a new &lt;code&gt;TensorArray&lt;/code&gt; is created at runtime it is assigned its own name for the duration of the run. This avoids name collisions if a &lt;code&gt;TensorArray&lt;/code&gt; is created within a &lt;code&gt;while_loop&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;TensorArray&lt;/code&gt; 의 이름 (전달 된 경우에도)은 고유합니다. 런타임에 새 &lt;code&gt;TensorArray&lt;/code&gt; 가 작성 될 때마다 실행 기간 동안 고유 한 이름이 지정됩니다. 경우 피합니다는 충돌의 이름을 &lt;code&gt;TensorArray&lt;/code&gt; 이 내에서 생성된다 &lt;code&gt;while_loop&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f394dc9c1e1c5f94915c443c9936510156504edb" translate="yes" xml:space="preserve">
          <source>The name of the TPU job. Typically, this name is auto-inferred within TPUEstimator, however when using ClusterSpec propagation in more esoteric cluster configurations, you may need to specify the job name as a string.</source>
          <target state="translated">The name of the TPU job. Typically, this name is auto-inferred within TPUEstimator, however when using ClusterSpec propagation in more esoteric cluster configurations, you may need to specify the job name as a string.</target>
        </trans-unit>
        <trans-unit id="a1aa3a17d239638bffd8da87470925d90fc14587" translate="yes" xml:space="preserve">
          <source>The name of the activation function.</source>
          <target state="translated">The name of the activation function.</target>
        </trans-unit>
        <trans-unit id="d1fad2a11c1fa88593c78a2b8dbc37f823e55dcb" translate="yes" xml:space="preserve">
          <source>The name of the attr to fetch.</source>
          <target state="translated">The name of the attr to fetch.</target>
        </trans-unit>
        <trans-unit id="51b48f4480def25ba4d61ddbb25309d908422157" translate="yes" xml:space="preserve">
          <source>The name of the attribute to change.</source>
          <target state="translated">The name of the attribute to change.</target>
        </trans-unit>
        <trans-unit id="3411600001d2f7bf3a52d4bd93fdb012e4af3205" translate="yes" xml:space="preserve">
          <source>The name of the attribute to modify.</source>
          <target state="translated">수정할 속성의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="dbb0bb41743f114fce1ea1f179c3a700f65b6093" translate="yes" xml:space="preserve">
          <source>The name of the decorator. If &lt;code&gt;None&lt;/code&gt;, the name of the function calling make_decorator.</source>
          <target state="translated">The name of the decorator. If &lt;code&gt;None&lt;/code&gt; , the name of the function calling make_decorator.</target>
        </trans-unit>
        <trans-unit id="8fcdbd427dc016b6defe717193d13e8a5ff2954b" translate="yes" xml:space="preserve">
          <source>The name of the device on which &lt;code&gt;values&lt;/code&gt; will be produced, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">되는 장치명 &lt;code&gt;values&lt;/code&gt; 생성 될 것이며, 또는 &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="37ecde1c1b33e8dfdb61f844e3753c1a790bb482" translate="yes" xml:space="preserve">
          <source>The name of the device on which this tensor will be produced, or None.</source>
          <target state="translated">이 텐서가 생성 될 장치의 이름 또는 없음.</target>
        </trans-unit>
        <trans-unit id="513390ceda7c6a57cd491aa38c353737462bdd7c" translate="yes" xml:space="preserve">
          <source>The name of the device to which this op has been assigned, if any.</source>
          <target state="translated">이 op가 할당 된 장치의 이름입니다 (있는 경우).</target>
        </trans-unit>
        <trans-unit id="0484306d12f825b7f062712ebb91e1e5070c26cd" translate="yes" xml:space="preserve">
          <source>The name of the layer (string).</source>
          <target state="translated">The name of the layer (string).</target>
        </trans-unit>
        <trans-unit id="0e0dea9bfe26a7beb65886a09d49cbd06a620222" translate="yes" xml:space="preserve">
          <source>The name of the local job.</source>
          <target state="translated">The name of the local job.</target>
        </trans-unit>
        <trans-unit id="cf636fc4624183a99bcc4c7c7fbe0a44c0ebb8f7" translate="yes" xml:space="preserve">
          <source>The name of the module which registered the flag with this name. If no such module exists (i.e. no flag with this name exists), we return default.</source>
          <target state="translated">이 이름으로 플래그를 등록한 모듈의 이름입니다. 그러한 모듈이 존재하지 않으면 (즉,이 이름의 플래그가 존재하지 않는 경우), 기본값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="d507fbefee6f858beaba994a2d5222c827f1ac97" translate="yes" xml:space="preserve">
          <source>The name of the new or existing variable.</source>
          <target state="translated">The name of the new or existing variable.</target>
        </trans-unit>
        <trans-unit id="5bc9ed5993c993f81f4eb7f3f3150297cebf93a8" translate="yes" xml:space="preserve">
          <source>The name of the op.</source>
          <target state="translated">The name of the op.</target>
        </trans-unit>
        <trans-unit id="48b66664c86691b5553fd1d2c5bdf4eaa5d9161f" translate="yes" xml:space="preserve">
          <source>The name of the operation to be created</source>
          <target state="translated">The name of the operation to be created</target>
        </trans-unit>
        <trans-unit id="ca71906a25ae77a1092de8617dc7e418a294cb12" translate="yes" xml:space="preserve">
          <source>The name of the output &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="translated">The name of the output &lt;code&gt;SparseTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2e6f9aa3bfdd3d1620c355dda8c15d6285fa32c9" translate="yes" xml:space="preserve">
          <source>The name of the output &lt;code&gt;Tensor&lt;/code&gt; (optional).</source>
          <target state="translated">The name of the output &lt;code&gt;Tensor&lt;/code&gt; (optional).</target>
        </trans-unit>
        <trans-unit id="c7f41644b081b946d6a6996c5793e8e0c8a0ca0c" translate="yes" xml:space="preserve">
          <source>The name of the returned tensor.</source>
          <target state="translated">The name of the returned tensor.</target>
        </trans-unit>
        <trans-unit id="5d3b4cc387786491f2cb51bc2065fde0324f391f" translate="yes" xml:space="preserve">
          <source>The name of the scope itself can be captured by &lt;code&gt;with g.name_scope(...) as scope:&lt;/code&gt;, which stores the name of the scope in the variable &lt;code&gt;scope&lt;/code&gt;. This value can be used to name an operation that represents the overall result of executing the ops in a scope. For example:</source>
          <target state="translated">범위 자체의 이름은 &lt;code&gt;with g.name_scope(...) as scope:&lt;/code&gt; 캡처 할 수 있습니다 . scope : 는 범위 이름을 변수 &lt;code&gt;scope&lt;/code&gt; 에 저장합니다 . 이 값은 범위에서 ops를 실행 한 전체 결과를 나타내는 작업의 이름을 지정하는 데 사용할 수 있습니다. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="c5bdc797aad3e657271b859b7dc8d873a1c5776b" translate="yes" xml:space="preserve">
          <source>The name of the table.</source>
          <target state="translated">테이블 이름</target>
        </trans-unit>
        <trans-unit id="29294a5bc0faead00c55b881e7f2f01d1f8fd3c6" translate="yes" xml:space="preserve">
          <source>The name of the trace event.</source>
          <target state="translated">The name of the trace event.</target>
        </trans-unit>
        <trans-unit id="4f8f2953a3d445a0fc6a56065d426682fba17223" translate="yes" xml:space="preserve">
          <source>The name of the underlying accumulator.</source>
          <target state="translated">기본 누산기의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="96809ba43c27a83619ec011b30fe50853f001590" translate="yes" xml:space="preserve">
          <source>The name of the underlying queue.</source>
          <target state="translated">기본 대기열의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="f89f168ead7cdce407789bc51f70ca1fc8c5be20" translate="yes" xml:space="preserve">
          <source>The name of this &lt;code&gt;IndexedSlices&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;IndexedSlices&lt;/code&gt; 의 이름입니다 .</target>
        </trans-unit>
        <trans-unit id="da911221082c7da030b3afee2bb6138d5ed15e00" translate="yes" xml:space="preserve">
          <source>The name of this ExponentialMovingAverage object.</source>
          <target state="translated">이 ExponentialMovingAverage 객체의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="a0b8c507e7f0e7b6a1373421e05579d1965778f3" translate="yes" xml:space="preserve">
          <source>The name of this head.</source>
          <target state="translated">이 머리의 이름.</target>
        </trans-unit>
        <trans-unit id="d713b72d40825a59e98f4bc908a8370877bdd57f" translate="yes" xml:space="preserve">
          <source>The name of this variable.</source>
          <target state="translated">이 변수의 이름입니다.</target>
        </trans-unit>
        <trans-unit id="1d01abc5e97d43035681b7621f742a7e0e4f87f3" translate="yes" xml:space="preserve">
          <source>The name or URL of the session master.</source>
          <target state="translated">세션 마스터의 이름 또는 URL입니다.</target>
        </trans-unit>
        <trans-unit id="22b1df8c09c11cf1299228c2a025d453b2932406" translate="yes" xml:space="preserve">
          <source>The name passed to &lt;a href=&quot;../../name_scope&quot;&gt;&lt;code&gt;tf.name_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The name passed to &lt;a href=&quot;../../name_scope&quot;&gt; &lt;code&gt;tf.name_scope&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="647b627abb244e52e977dfb90e76736f5a70efdc" translate="yes" xml:space="preserve">
          <source>The name to look up.</source>
          <target state="translated">The name to look up.</target>
        </trans-unit>
        <trans-unit id="25e36e7449d4e0998fc78c6e3977716de004b31a" translate="yes" xml:space="preserve">
          <source>The name to serialize this class under in this package. If None, the class' name will be used.</source>
          <target state="translated">The name to serialize this class under in this package. If None, the class' name will be used.</target>
        </trans-unit>
        <trans-unit id="2c8e14eb227eb8d0282158234a5e6ae09b22ded5" translate="yes" xml:space="preserve">
          <source>The name to use for the coordinator. Set to None if the coordinator should not be included in the computed ClusterSpec.</source>
          <target state="translated">The name to use for the coordinator. Set to None if the coordinator should not be included in the computed ClusterSpec.</target>
        </trans-unit>
        <trans-unit id="5beb388dc9de0f3a44e8c2ae92390e5cddbd00f3" translate="yes" xml:space="preserve">
          <source>The name to use when creating the execute operation.</source>
          <target state="translated">The name to use when creating the execute operation.</target>
        </trans-unit>
        <trans-unit id="be158487fb11e20f31b9a766e704ebc058b51521" translate="yes" xml:space="preserve">
          <source>The named axis labels may be any single character other than those having special meaning, namely &lt;code&gt;,.-&amp;gt;&lt;/code&gt;. The behavior of this Op is undefined if it receives an ill-formatted equation; since the validation is done at graph-building time, we omit format validation checks at runtime.</source>
          <target state="translated">The named axis labels may be any single character other than those having special meaning, namely &lt;code&gt;,.-&amp;gt;&lt;/code&gt; . The behavior of this Op is undefined if it receives an ill-formatted equation; since the validation is done at graph-building time, we omit format validation checks at runtime.</target>
        </trans-unit>
        <trans-unit id="947e2daa3bb98d0bc923e5ca008b708b99d1db05" translate="yes" xml:space="preserve">
          <source>The natural log of the determinant of &lt;code&gt;matrix&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;matrix&lt;/code&gt; 결정 요인의 자연 로그입니다 .</target>
        </trans-unit>
        <trans-unit id="ca6f16df867a9e980034d2567f42c641b28a79b7" translate="yes" xml:space="preserve">
          <source>The need for a manually selected global learning rate</source>
          <target state="translated">The need for a manually selected global learning rate</target>
        </trans-unit>
        <trans-unit id="e172fe7e51a351d69f78266150cbe93d41a966dd" translate="yes" xml:space="preserve">
          <source>The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.</source>
          <target state="translated">전치 된 회선의 필요성은 일반적으로 일반 회선의 반대 방향으로 진행하는 변환을 사용하려는 요구, 즉 일부 회선의 출력 형태를 갖는 것에서 입력 형태를 갖는 것까지, 상기 회선과 호환되는 연결 패턴.</target>
        </trans-unit>
        <trans-unit id="497bcc780928cec8678167a0943cfb8a236572bc" translate="yes" xml:space="preserve">
          <source>The nest is or contains a dict with non-sortable keys.</source>
          <target state="translated">The nest is or contains a dict with non-sortable keys.</target>
        </trans-unit>
        <trans-unit id="87443d4ab1ed1b3ecff97672f0081e558c9e3e8c" translate="yes" xml:space="preserve">
          <source>The nested structure of &lt;code&gt;Tensor&lt;/code&gt;s to all-reduce. The structure must be compatible with &lt;a href=&quot;../nest&quot;&gt;&lt;code&gt;tf.nest&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The nested structure of &lt;code&gt;Tensor&lt;/code&gt; s to all-reduce. The structure must be compatible with &lt;a href=&quot;../nest&quot;&gt; &lt;code&gt;tf.nest&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="591766edefc12d264f15ba10d8ba1725a7aa8e44" translate="yes" xml:space="preserve">
          <source>The new axis location matches Python &lt;code&gt;list.insert(axis, 1)&lt;/code&gt;:</source>
          <target state="translated">The new axis location matches Python &lt;code&gt;list.insert(axis, 1)&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="958033fa33493f00248ba20803119af783c47f8d" translate="yes" xml:space="preserve">
          <source>The new batch size pulled from the queue.</source>
          <target state="translated">The new batch size pulled from the queue.</target>
        </trans-unit>
        <trans-unit id="3db6116c7d99fcd620f590077cbf1f7679e81227" translate="yes" xml:space="preserve">
          <source>The new callable signature of this decorator.</source>
          <target state="translated">The new callable signature of this decorator.</target>
        </trans-unit>
        <trans-unit id="a92087301e7ffb88316b9135c1aafd2aa583aa2a" translate="yes" xml:space="preserve">
          <source>The new default value.</source>
          <target state="translated">The new default value.</target>
        </trans-unit>
        <trans-unit id="e63348dbbced4923128564bd3253cc502100689d" translate="yes" xml:space="preserve">
          <source>The new generator will be initialized by one of the following ways, with decreasing precedence: (1) If &lt;code&gt;copy_from&lt;/code&gt; is not None, the new generator is initialized by copying information from another generator. (3) If &lt;code&gt;state&lt;/code&gt; and &lt;code&gt;alg&lt;/code&gt; are not None (they must be set together), the new generator is initialized by a state.</source>
          <target state="translated">새 생성기는 우선 순위가 감소하면서 다음 방법 중 하나로 초기화됩니다. (1) &lt;code&gt;copy_from&lt;/code&gt; 이 None이 아닌 경우 , 다른 생성기에서 정보를 복사하여 새 생성기가 초기화됩니다. (3) &lt;code&gt;state&lt;/code&gt; 와 &lt;code&gt;alg&lt;/code&gt; 가 None이 아닌 경우 (함께 설정해야 함) 새로운 생성기는 상태에 의해 초기화됩니다.</target>
        </trans-unit>
        <trans-unit id="8cbbc58e1d6e45f7538d48a88e9145ff0816310e" translate="yes" xml:space="preserve">
          <source>The new generator.</source>
          <target state="translated">새로운 발전기.</target>
        </trans-unit>
        <trans-unit id="c92d3a1d88d5bb846fb6922638676753f654e62e" translate="yes" xml:space="preserve">
          <source>The new generators will be put on the current device (possible different from the old generator's), for example:</source>
          <target state="translated">새 발전기는 현재 장치에 배치됩니다 (이전 발전기와 다를 수 있음).</target>
        </trans-unit>
        <trans-unit id="aed9e7e391104d869576ed733d9adb3a806218e3" translate="yes" xml:space="preserve">
          <source>The new value for the attribute.</source>
          <target state="translated">The new value for the attribute.</target>
        </trans-unit>
        <trans-unit id="b9b227961e3d04545a92b5ce44cb233f0e0e2e32" translate="yes" xml:space="preserve">
          <source>The new value of the attribute.</source>
          <target state="translated">속성의 새로운 값.</target>
        </trans-unit>
        <trans-unit id="e426c7afe47b5f55c3dfa85e599a773e3d38d777" translate="yes" xml:space="preserve">
          <source>The new variable is added to the graph collections listed in &lt;code&gt;collections&lt;/code&gt;, which defaults to &lt;code&gt;[GraphKeys.GLOBAL_VARIABLES]&lt;/code&gt;.</source>
          <target state="translated">새로운 변수에 표시된 그래프 컬렉션에 추가 &lt;code&gt;collections&lt;/code&gt; , 디폴트 &lt;code&gt;[GraphKeys.GLOBAL_VARIABLES]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b23ad53a08722aede7339ef0814174529ec55158" translate="yes" xml:space="preserve">
          <source>The next element in the queue, i.e. a tuple &lt;code&gt;(inputs, targets)&lt;/code&gt; or &lt;code&gt;(inputs, targets, sample_weights)&lt;/code&gt;.</source>
          <target state="translated">큐에서 다음 요소, 즉 튜플 &lt;code&gt;(inputs, targets)&lt;/code&gt; 또는 &lt;code&gt;(inputs, targets, sample_weights)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="44b4a8428f7aea36b41515b3369e33369a93a616" translate="yes" xml:space="preserve">
          <source>The node to be assigned to a device. Could be either an ops.Operation or NodeDef.</source>
          <target state="translated">The node to be assigned to a device. Could be either an ops.Operation or NodeDef.</target>
        </trans-unit>
        <trans-unit id="8bc3974c53a4bc03fb9e4842cff39c86a0d8870a" translate="yes" xml:space="preserve">
          <source>The non-zero values in the represented dense tensor.</source>
          <target state="translated">표시된 조밀 한 텐서에서 0이 아닌 값.</target>
        </trans-unit>
        <trans-unit id="a794ea3a692cf3249d1fcc991ee60c5b4cf01417" translate="yes" xml:space="preserve">
          <source>The normal &lt;code&gt;ServingInputReceiver&lt;/code&gt; always returns a feature dict, even if it contains only one entry, and so can be used only with models that accept such a dict. For models that accept only a single raw feature, the &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; provided to &lt;a href=&quot;../../compat/v1/estimator/estimator#export_saved_model&quot;&gt;&lt;code&gt;Estimator.export_saved_model()&lt;/code&gt;&lt;/a&gt; should return this &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; instead. See: https://github.com/tensorflow/tensorflow/issues/11674</source>
          <target state="translated">일반적인 &lt;code&gt;ServingInputReceiver&lt;/code&gt; 는 하나의 항목 만 포함하더라도 항상 기능 dict를 리턴하므로 해당 dict를 허용하는 모델에만 사용할 수 있습니다. 단 하나의 원시 기능의 수용 모델의 &lt;code&gt;serving_input_receiver_fn&lt;/code&gt; 제공 &lt;a href=&quot;../../compat/v1/estimator/estimator#export_saved_model&quot;&gt; &lt;code&gt;Estimator.export_saved_model()&lt;/code&gt; &lt;/a&gt; 이 반환해야 &lt;code&gt;TensorServingInputReceiver&lt;/code&gt; 을 대신. 참조 : https://github.com/tensorflow/tensorflow/issues/11674</target>
        </trans-unit>
        <trans-unit id="991f940c882656d1963be8e5f9d6859e831fc269" translate="yes" xml:space="preserve">
          <source>The normalization to apply. &lt;code&gt;None&lt;/code&gt; for no normalization or &lt;code&gt;'ortho'&lt;/code&gt; for orthonormal normalization.</source>
          <target state="translated">The normalization to apply. &lt;code&gt;None&lt;/code&gt; for no normalization or &lt;code&gt;'ortho'&lt;/code&gt; for orthonormal normalization.</target>
        </trans-unit>
        <trans-unit id="8c37a70332a45acca66a9732b1b0e6e1956e2217" translate="yes" xml:space="preserve">
          <source>The normalizer values with same shape as predictions.</source>
          <target state="translated">The normalizer values with same shape as predictions.</target>
        </trans-unit>
        <trans-unit id="61b02be5d26057c5d50879cdbf7a93b5057253da" translate="yes" xml:space="preserve">
          <source>The number of batches in the Sequence.</source>
          <target state="translated">시퀀스의 배치 수입니다.</target>
        </trans-unit>
        <trans-unit id="792c47def67649a01faf5dd32bfc0006287f5ca5" translate="yes" xml:space="preserve">
          <source>The number of bits for quantize training.</source>
          <target state="translated">The number of bits for quantize training.</target>
        </trans-unit>
        <trans-unit id="1e8251a908793c7f7ac158d55fc205bd7b475f75" translate="yes" xml:space="preserve">
          <source>The number of classes, &lt;code&gt;K&lt;/code&gt;, must not exceed:</source>
          <target state="translated">클래스 수 &lt;code&gt;K&lt;/code&gt; 는 다음을 초과하지 않아야합니다.</target>
        </trans-unit>
        <trans-unit id="a0b5ca9e1bc6804bae0a759249d34d9c89546684" translate="yes" xml:space="preserve">
          <source>The number of columns of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from &lt;code&gt;d_lower&lt;/code&gt;, &lt;code&gt;d_upper&lt;/code&gt;, and the innermost dimension of &lt;code&gt;diagonal&lt;/code&gt;.</source>
          <target state="translated">The number of columns of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from &lt;code&gt;d_lower&lt;/code&gt; , &lt;code&gt;d_upper&lt;/code&gt; , and the innermost dimension of &lt;code&gt;diagonal&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4d08b3ea9208738ea9c6ff069ba01794b88c8ec9" translate="yes" xml:space="preserve">
          <source>The number of consecutive elements to pull from an input &lt;code&gt;Dataset&lt;/code&gt; before advancing to the next input &lt;code&gt;Dataset&lt;/code&gt;.</source>
          <target state="translated">The number of consecutive elements to pull from an input &lt;code&gt;Dataset&lt;/code&gt; before advancing to the next input &lt;code&gt;Dataset&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="26bbe52e7e5ab91d858fdf92eb9164c22baffaaa" translate="yes" xml:space="preserve">
          <source>The number of cores per replica.</source>
          <target state="translated">복제 본당 코어 수</target>
        </trans-unit>
        <trans-unit id="14a13b9b3afa611575c6fded44823e34fb935055" translate="yes" xml:space="preserve">
          <source>The number of decimal places to compare.</source>
          <target state="translated">The number of decimal places to compare.</target>
        </trans-unit>
        <trans-unit id="7dc06462d30b8a2c0735ca8850d3a620b646263e" translate="yes" xml:space="preserve">
          <source>The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to &lt;code&gt;filters_in * depth_multiplier&lt;/code&gt;.</source>
          <target state="translated">The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to &lt;code&gt;filters_in * depth_multiplier&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="973da0cb517d5a151fa65418511378c398a77944" translate="yes" xml:space="preserve">
          <source>The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to &lt;code&gt;num_filters_in * depth_multiplier&lt;/code&gt;.</source>
          <target state="translated">The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to &lt;code&gt;num_filters_in * depth_multiplier&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f1fb954517b208177e2433a3bd0d5008bff1f85f" translate="yes" xml:space="preserve">
          <source>The number of devices attached to this input pipeline. This will be automatically set by MultiDeviceIterator.</source>
          <target state="translated">이 입력 파이프 라인에 연결된 장치의 수입니다. 이것은 MultiDeviceIterator에 의해 자동으로 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="a4e68945735abb3b2e9d8c11a95d91c8a876e87a" translate="yes" xml:space="preserve">
          <source>The number of dimensions of the input tensors must match, and all dimensions except &lt;code&gt;axis&lt;/code&gt; must be equal.</source>
          <target state="translated">입력 텐서의 치수 수는 일치 해야하며 &lt;code&gt;axis&lt;/code&gt; 제외한 모든 치수 는 같아야합니다.</target>
        </trans-unit>
        <trans-unit id="d8c231051c2a82603951bb4be6326674a1e8aa3c" translate="yes" xml:space="preserve">
          <source>The number of elements each iterator being interleaved should buffer (similar to the &lt;code&gt;.prefetch()&lt;/code&gt; transformation for each interleaved iterator).</source>
          <target state="translated">The number of elements each iterator being interleaved should buffer (similar to the &lt;code&gt;.prefetch()&lt;/code&gt; transformation for each interleaved iterator).</target>
        </trans-unit>
        <trans-unit id="8c94708e0d399f895eb43d6150e45fd77b82a379" translate="yes" xml:space="preserve">
          <source>The number of elements in the file, if known.</source>
          <target state="translated">The number of elements in the file, if known.</target>
        </trans-unit>
        <trans-unit id="b80ca01a0514c265b481f3eda4caaa27b83fdda1" translate="yes" xml:space="preserve">
          <source>The number of input &lt;code&gt;Dataset&lt;/code&gt;s to interleave from in parallel.</source>
          <target state="translated">The number of input &lt;code&gt;Dataset&lt;/code&gt; s to interleave from in parallel.</target>
        </trans-unit>
        <trans-unit id="e13e9c7600bcb73d445f6ddf6ab2c7a5b20cf4c7" translate="yes" xml:space="preserve">
          <source>The number of input elements to transform to iterators before they are needed for interleaving.</source>
          <target state="translated">The number of input elements to transform to iterators before they are needed for interleaving.</target>
        </trans-unit>
        <trans-unit id="0eab278bde3870b804deae9229a39fcd34b7b41a" translate="yes" xml:space="preserve">
          <source>The number of iterations allowed to run in parallel. It must be a positive integer.</source>
          <target state="translated">The number of iterations allowed to run in parallel. It must be a positive integer.</target>
        </trans-unit>
        <trans-unit id="486c99e01cf220bcbab45ab943b6612bf5691de3" translate="yes" xml:space="preserve">
          <source>The number of out-of-vocabulary tokens to use; defaults to</source>
          <target state="translated">The number of out-of-vocabulary tokens to use; defaults to</target>
        </trans-unit>
        <trans-unit id="ba07a119e82c4ff8c5cef8c905bb48f6f124a4db" translate="yes" xml:space="preserve">
          <source>The number of out-of-vocabulary values to use; defaults to</source>
          <target state="translated">The number of out-of-vocabulary values to use; defaults to</target>
        </trans-unit>
        <trans-unit id="a76e8c314c1da65707aae12379f6c7ff6a28dcd7" translate="yes" xml:space="preserve">
          <source>The number of parameters and number of multiply-adds can be modified by using the &lt;code&gt;alpha&lt;/code&gt; parameter, which increases/decreases the number of filters in each layer. By altering the image size and &lt;code&gt;alpha&lt;/code&gt; parameter, all 22 models from the paper can be built, with ImageNet weights provided.</source>
          <target state="translated">The number of parameters and number of multiply-adds can be modified by using the &lt;code&gt;alpha&lt;/code&gt; parameter, which increases/decreases the number of filters in each layer. By altering the image size and &lt;code&gt;alpha&lt;/code&gt; parameter, all 22 models from the paper can be built, with ImageNet weights provided.</target>
        </trans-unit>
        <trans-unit id="516b803f18d035a65572fcbdfc2900dc7b8d516a" translate="yes" xml:space="preserve">
          <source>The number of ragged dimensions in this ragged tensor value.</source>
          <target state="translated">이 비정형 텐서 값의 비정형 치수 수입니다.</target>
        </trans-unit>
        <trans-unit id="04f639280f7ec10513cb4839cfeda1135a578887" translate="yes" xml:space="preserve">
          <source>The number of ragged dimensions in this ragged tensor.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 울퉁불퉁 한 치수 수입니다.</target>
        </trans-unit>
        <trans-unit id="87460175f8c6b31c8d362f42e4ca508e7497ab37" translate="yes" xml:space="preserve">
          <source>The number of replicas of the computation.</source>
          <target state="translated">계산의 복제본 수입니다.</target>
        </trans-unit>
        <trans-unit id="4ca03556aba7a6aedb5ec7bb5f557eed2de6bf50" translate="yes" xml:space="preserve">
          <source>The number of rows in the constructed RaggedTensor. If not specified, then it defaults to &lt;code&gt;nvals/uniform_row_length&lt;/code&gt; (or &lt;code&gt;0&lt;/code&gt; if &lt;code&gt;uniform_row_length==0&lt;/code&gt;). &lt;code&gt;nrows&lt;/code&gt; only needs to be specified if &lt;code&gt;uniform_row_length&lt;/code&gt; might be zero. &lt;code&gt;uniform_row_length*nrows&lt;/code&gt; must be &lt;code&gt;nvals&lt;/code&gt;.</source>
          <target state="translated">The number of rows in the constructed RaggedTensor. If not specified, then it defaults to &lt;code&gt;nvals/uniform_row_length&lt;/code&gt; (or &lt;code&gt;0&lt;/code&gt; if &lt;code&gt;uniform_row_length==0&lt;/code&gt; ). &lt;code&gt;nrows&lt;/code&gt; only needs to be specified if &lt;code&gt;uniform_row_length&lt;/code&gt; might be zero. &lt;code&gt;uniform_row_length*nrows&lt;/code&gt; must be &lt;code&gt;nvals&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6ae2058fda59f914aa10436122a33d5b20b79d14" translate="yes" xml:space="preserve">
          <source>The number of rows of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from &lt;code&gt;d_lower&lt;/code&gt;, &lt;code&gt;d_upper&lt;/code&gt;, and the innermost dimension of &lt;code&gt;diagonal&lt;/code&gt;.</source>
          <target state="translated">The number of rows of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from &lt;code&gt;d_lower&lt;/code&gt; , &lt;code&gt;d_upper&lt;/code&gt; , and the innermost dimension of &lt;code&gt;diagonal&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f95cc9deb1ad31a316d21a1000cc42bf6795a45d" translate="yes" xml:space="preserve">
          <source>The number of seconds the infeed thread should wait before enqueueing the first batch. This helps avoid timeouts for models that require a long compilation time.</source>
          <target state="translated">The number of seconds the infeed thread should wait before enqueueing the first batch. This helps avoid timeouts for models that require a long compilation time.</target>
        </trans-unit>
        <trans-unit id="8b14ac2c4857aac3f94fec3f43b6a18b61307e30" translate="yes" xml:space="preserve">
          <source>The number of shards.</source>
          <target state="translated">The number of shards.</target>
        </trans-unit>
        <trans-unit id="feba654d8cbad0859a90722bb20fd89543e94016" translate="yes" xml:space="preserve">
          <source>The number of steps after which the updated cluster centers are synced back to a master copy. Used only if &lt;code&gt;use_mini_batch=True&lt;/code&gt;. See explanation above.</source>
          <target state="translated">The number of steps after which the updated cluster centers are synced back to a master copy. Used only if &lt;code&gt;use_mini_batch=True&lt;/code&gt; . See explanation above.</target>
        </trans-unit>
        <trans-unit id="605dc8d4d33374c29a7f650a9b0f5eab0e0e6145" translate="yes" xml:space="preserve">
          <source>The number of tasks defined in the given job.</source>
          <target state="translated">주어진 작업에 정의 된 작업 수</target>
        </trans-unit>
        <trans-unit id="7bc399a4786dff1562b68cd701307e615fd2d911" translate="yes" xml:space="preserve">
          <source>The number of threads enqueuing &lt;code&gt;tensor_list&lt;/code&gt;.</source>
          <target state="translated">The number of threads enqueuing &lt;code&gt;tensor_list&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f02da5b6da02a7c7e237c388ce04fe447f06fe0f" translate="yes" xml:space="preserve">
          <source>The number of threads enqueuing &lt;code&gt;tensors&lt;/code&gt;. The batching will be nondeterministic if &lt;code&gt;num_threads &amp;gt; 1&lt;/code&gt;.</source>
          <target state="translated">The number of threads enqueuing &lt;code&gt;tensors&lt;/code&gt; . The batching will be nondeterministic if &lt;code&gt;num_threads &amp;gt; 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ac616f1e962121eef44a63281771c333c773f02b" translate="yes" xml:space="preserve">
          <source>The number of thresholds to use for matching the given sensitivity.</source>
          <target state="translated">The number of thresholds to use for matching the given sensitivity.</target>
        </trans-unit>
        <trans-unit id="ce3752ac0167d41dbccfee2db45c450ff2ae474a" translate="yes" xml:space="preserve">
          <source>The number of thresholds to use for matching the given specificity.</source>
          <target state="translated">The number of thresholds to use for matching the given specificity.</target>
        </trans-unit>
        <trans-unit id="8e43e72ea1b04138c6081865e0dcfc5971740b57" translate="yes" xml:space="preserve">
          <source>The number of thresholds to use when discretizing the roc curve.</source>
          <target state="translated">The number of thresholds to use when discretizing the roc curve.</target>
        </trans-unit>
        <trans-unit id="b04f07fa32838fddf785b03c8a08de5c2a3e8304" translate="yes" xml:space="preserve">
          <source>The number of times this should be called before it is logged.</source>
          <target state="translated">The number of times this should be called before it is logged.</target>
        </trans-unit>
        <trans-unit id="1a2d5e323b8ac2af372dafbb2ccb4f737135220d" translate="yes" xml:space="preserve">
          <source>The numerics checking mechanism will cause any TensorFlow eager execution or graph execution to error out as soon as an op's output tensor contains infinity or NaN.</source>
          <target state="translated">숫자 검사 메커니즘으로 인해 op의 출력 텐서에 무한대 또는 NaN이 포함되면 TensorFlow 열성적인 실행 또는 그래프 실행이 오류가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="625fd6a720c05ff0edaf547e1f7c698308bb3918" translate="yes" xml:space="preserve">
          <source>The numpy &lt;code&gt;ndarray&lt;/code&gt;, or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor).</source>
          <target state="translated">The numpy &lt;code&gt;ndarray&lt;/code&gt; , or anything that can be converted into a numpy &lt;code&gt;ndarray&lt;/code&gt; (including Tensor).</target>
        </trans-unit>
        <trans-unit id="4302dccd839f803738d3151980944012f9528e1e" translate="yes" xml:space="preserve">
          <source>The numpy dtype of values in this tensor.</source>
          <target state="translated">이 텐서의 값이 numpy dtype입니다.</target>
        </trans-unit>
        <trans-unit id="7a3478da2033233febed2c5abb6b940a69ae44f9" translate="yes" xml:space="preserve">
          <source>The object to look up.</source>
          <target state="translated">The object to look up.</target>
        </trans-unit>
        <trans-unit id="4018ef2a9d807780c174adef5e5e353be6c00acd" translate="yes" xml:space="preserve">
          <source>The object whose attributes we want to modify.</source>
          <target state="translated">The object whose attributes we want to modify.</target>
        </trans-unit>
        <trans-unit id="10073c85f700d07cd9e27b920a2bb28c0e1e6aa0" translate="yes" xml:space="preserve">
          <source>The object will be registered under the key 'package&amp;gt;name' where &lt;code&gt;name&lt;/code&gt;, defaults to the object name if not passed.</source>
          <target state="translated">객체는 키 'package&amp;gt; name'에 등록됩니다. 여기서 &lt;code&gt;name&lt;/code&gt; 은 전달되지 않은 경우 기본적으로 객체 이름으로 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="45d19e778f47f1e0cf9ddae2e351bf27f7263440" translate="yes" xml:space="preserve">
          <source>The old (deprecated) name for &lt;code&gt;axis&lt;/code&gt;.</source>
          <target state="translated">The old (deprecated) name for &lt;code&gt;axis&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bfeb840ee57e08986b18ad64fb148a52d19a3b93" translate="yes" xml:space="preserve">
          <source>The old (deprecated) name for axis.</source>
          <target state="translated">The old (deprecated) name for axis.</target>
        </trans-unit>
        <trans-unit id="ceae2a98903e4e9554b3ffa1be72b116c87afeec" translate="yes" xml:space="preserve">
          <source>The one-hot tensor.</source>
          <target state="translated">원핫 텐서.</target>
        </trans-unit>
        <trans-unit id="2214e2794dfd82c41f2566b3dfe3c682d8ae3fc2" translate="yes" xml:space="preserve">
          <source>The only change you have to do to the single program code is to indicate if the program is running as the &lt;em&gt;chief&lt;/em&gt;.</source>
          <target state="translated">당신은 하나의 프로그램 코드에해야 할 유일한 변화는 프로그램으로 실행하는 경우 표시하는 것입니다 &lt;em&gt;최고&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="2ac713e042499abe0ad5ad2caf8a0b3b2c0f1068" translate="yes" xml:space="preserve">
          <source>The only difference with a regular &lt;code&gt;Session&lt;/code&gt; is that an &lt;code&gt;InteractiveSession&lt;/code&gt; installs itself as the default session on construction. The methods &lt;a href=&quot;../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../operation#run&quot;&gt;&lt;code&gt;tf.Operation.run&lt;/code&gt;&lt;/a&gt; will use that session to run ops.</source>
          <target state="translated">일반 &lt;code&gt;Session&lt;/code&gt; 과의 유일한 차이점 은 &lt;code&gt;InteractiveSession&lt;/code&gt; 이 구성시 기본 세션으로 설치 된다는 것 입니다. &lt;a href=&quot;../../tensor#eval&quot;&gt; &lt;code&gt;tf.Tensor.eval&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../../operation#run&quot;&gt; &lt;code&gt;tf.Operation.run&lt;/code&gt; &lt;/a&gt; 메소드 는 해당 세션을 사용하여 ops를 실행합니다.</target>
        </trans-unit>
        <trans-unit id="31601f998aa3aad1333ec413e01d618a81800515" translate="yes" xml:space="preserve">
          <source>The only public method of a 'Flag' object is parse(), but it is typically only called by a 'FlagValues' object. The parse() method is a thin wrapper around the 'ArgumentParser' parse() method. The parsed value is saved in .value, and the .present attribute is updated. If this flag was already present, an Error is raised.</source>
          <target state="translated">'Flag'객체의 유일한 공용 메소드는 parse ()이지만 일반적으로 'FlagValues'객체에 의해서만 호출됩니다. parse () 메소드는 'ArgumentParser'parse () 메소드 주위의 얇은 랩퍼입니다. 구문 분석 된 값이 .value에 저장되고 .present 속성이 업데이트됩니다. 이 플래그가 이미 존재하면 오류가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="e1d57348a97b9a1a6578e16bf09a6e76a32d9952" translate="yes" xml:space="preserve">
          <source>The op also returns a count of how many entries in the new vocabulary were present in the old vocabulary, which is used to calculate the number of values to initialize in a weight matrix remapping</source>
          <target state="translated">The op also returns a count of how many entries in the new vocabulary were present in the old vocabulary, which is used to calculate the number of values to initialize in a weight matrix remapping</target>
        </trans-unit>
        <trans-unit id="2a51ce2977b54408b0ebf05f943b7e7ef7f2b4b9" translate="yes" xml:space="preserve">
          <source>The op blocks until sufficient (i.e., more than num_required) gradients have been accumulated. If the accumulator has already aggregated more than num_required gradients, it returns the average of the accumulated gradients. Also automatically increments the recorded global_step in the accumulator by 1, and resets the aggregate to 0.</source>
          <target state="translated">The op blocks until sufficient (i.e., more than num_required) gradients have been accumulated. If the accumulator has already aggregated more than num_required gradients, it returns the average of the accumulated gradients. Also automatically increments the recorded global_step in the accumulator by 1, and resets the aggregate to 0.</target>
        </trans-unit>
        <trans-unit id="f0ab6e564ddbe98c027618ff7ffc593086f5c97a" translate="yes" xml:space="preserve">
          <source>The op extracts fields from a serialized protocol buffers message into tensors.</source>
          <target state="translated">op는 직렬화 된 프로토콜 버퍼 메시지에서 텐서로 필드를 추출합니다.</target>
        </trans-unit>
        <trans-unit id="4524786c0641258f1c43ff84a36d1e64fc7c7b2a" translate="yes" xml:space="preserve">
          <source>The op isn't guaranteed to raise an error if the input matrix is not invertible. &lt;a href=&quot;../debugging/check_numerics&quot;&gt;&lt;code&gt;tf.debugging.check_numerics&lt;/code&gt;&lt;/a&gt; can be applied to the output to detect invertibility problems.</source>
          <target state="translated">입력 행렬이 반전 불가능한 경우 op가 오류를 발생시킬 수 없습니다. &lt;a href=&quot;../debugging/check_numerics&quot;&gt; &lt;code&gt;tf.debugging.check_numerics&lt;/code&gt; &lt;/a&gt; 를 출력에 적용하여 가역성 문제를 감지 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7bd5e782cef1401f27f1a4ce3d8e792728deb240" translate="yes" xml:space="preserve">
          <source>The op name.</source>
          <target state="translated">The op name.</target>
        </trans-unit>
        <trans-unit id="03769badeb10027d149bea16946940ff275316cf" translate="yes" xml:space="preserve">
          <source>The op returns an error if no system is running.</source>
          <target state="translated">The op returns an error if no system is running.</target>
        </trans-unit>
        <trans-unit id="fb943cd0e3db6ad9fffc66a537388998786a4519" translate="yes" xml:space="preserve">
          <source>The op serializes protobuf messages provided in the input tensors.</source>
          <target state="translated">op는 입력 텐서에 제공된 프로토 부프 메시지를 직렬화합니다.</target>
        </trans-unit>
        <trans-unit id="b8b5527fcf850d5c166175ec39fd18231818c0f3" translate="yes" xml:space="preserve">
          <source>The op takes two lists, one of 2D &lt;code&gt;SparseTensor&lt;/code&gt; and one of 2D &lt;code&gt;Tensor&lt;/code&gt;, each representing features of one feature column. It outputs a 2D &lt;code&gt;SparseTensor&lt;/code&gt; with the batchwise crosses of these features.</source>
          <target state="translated">The op takes two lists, one of 2D &lt;code&gt;SparseTensor&lt;/code&gt; and one of 2D &lt;code&gt;Tensor&lt;/code&gt; , each representing features of one feature column. It outputs a 2D &lt;code&gt;SparseTensor&lt;/code&gt; with the batchwise crosses of these features.</target>
        </trans-unit>
        <trans-unit id="1331b377f4a8a3fc8082f77642e632d68fc16e64" translate="yes" xml:space="preserve">
          <source>The op to colocate all created ops with, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">The op to colocate all created ops with, or &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6fc6099d0a9bbd2e8df15fdd3fb6314367cb02cc" translate="yes" xml:space="preserve">
          <source>The op to dequeue a token so the replicas can exit this batch and start the next one. This is executed by each replica.</source>
          <target state="translated">The op to dequeue a token so the replicas can exit this batch and start the next one. This is executed by each replica.</target>
        </trans-unit>
        <trans-unit id="f4c5664cfd278d67f9bbf9eb0ae9656ce1cd8f8e" translate="yes" xml:space="preserve">
          <source>The op uses LU decomposition with partial pivoting to compute the inverses.</source>
          <target state="translated">op는 부분 피벗과 함께 LU 분해를 사용하여 역을 계산합니다.</target>
        </trans-unit>
        <trans-unit id="cdf5001b31416df4d7ddde7f5a11360958f3382b" translate="yes" xml:space="preserve">
          <source>The op will blocks until sufficient (i.e., more than num_required) gradients have been accumulated. If the accumulator has already aggregated more than num_required gradients, it will return its average of the accumulated gradients. Also automatically increments the recorded global_step in the accumulator by 1, and resets the aggregate to 0.</source>
          <target state="translated">The op will blocks until sufficient (i.e., more than num_required) gradients have been accumulated. If the accumulator has already aggregated more than num_required gradients, it will return its average of the accumulated gradients. Also automatically increments the recorded global_step in the accumulator by 1, and resets the aggregate to 0.</target>
        </trans-unit>
        <trans-unit id="47e700a39a6284fa854225b8729284d0f8f18e3a" translate="yes" xml:space="preserve">
          <source>The operation blocks until sufficient number of gradients have been successfully applied to the accumulator.</source>
          <target state="translated">충분한 수의 그래디언트가 누산기에 성공적으로 적용될 때까지 작업이 차단됩니다.</target>
        </trans-unit>
        <trans-unit id="8790d3057b1a7dc53661bb4f237b850fe1057d19" translate="yes" xml:space="preserve">
          <source>The operation casts &lt;code&gt;x&lt;/code&gt; (in case of &lt;code&gt;Tensor&lt;/code&gt;) or &lt;code&gt;x.values&lt;/code&gt; (in case of &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;IndexedSlices&lt;/code&gt;) to &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">동작 캐스트 &lt;code&gt;x&lt;/code&gt; (경우 &lt;code&gt;Tensor&lt;/code&gt; 또는) &lt;code&gt;x.values&lt;/code&gt; (경우 &lt;code&gt;SparseTensor&lt;/code&gt; 또는 &lt;code&gt;IndexedSlices&lt;/code&gt; 행) &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="776fb3f15a3fb7bc8e3ba0841d38241b6b787b08" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Tensor#__add__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;add&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="translated">The operation invoked by the &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Tensor#__add__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;add&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; operator.</target>
        </trans-unit>
        <trans-unit id="7306f5f9b2f16d84f1b9ff9bd10ca67995a18b69" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;tensor#__add__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;add&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="translated">The operation invoked by the &lt;a href=&quot;tensor#__add__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;add&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; operator.</target>
        </trans-unit>
        <trans-unit id="296ef5a55f3d72d1bc6447dffc6aa283d2bd9c3c" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;tensor#__eq__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;eq&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="translated">The operation invoked by the &lt;a href=&quot;tensor#__eq__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;eq&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; operator.</target>
        </trans-unit>
        <trans-unit id="d125afae21f1524ca9020b80d01460cbb92b8a4d" translate="yes" xml:space="preserve">
          <source>The operation invoked by the &lt;a href=&quot;tensor#__ne__&quot;&gt;&lt;code&gt;Tensor.&lt;strong&gt;ne&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; operator.</source>
          <target state="translated">The operation invoked by the &lt;a href=&quot;tensor#__ne__&quot;&gt; &lt;code&gt;Tensor.&lt;strong&gt;ne&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; operator.</target>
        </trans-unit>
        <trans-unit id="93211cf6300703e21c3cdf804cff040a7b2a55a6" translate="yes" xml:space="preserve">
          <source>The operation logs a warning if we attempt to set to a time step that is lower than the accumulator's own time step.</source>
          <target state="translated">누적 기 자체의 시간 단계보다 낮은 시간 단계로 설정하려고하면 작업이 경고를 기록합니다.</target>
        </trans-unit>
        <trans-unit id="ec87d8afa16231d11efcb471f5e52a7d2a894559" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;numpy_function&quot;&gt;&lt;code&gt;tf.numpy_function&lt;/code&gt;&lt;/a&gt; you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">작업은 &lt;a href=&quot;numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function()&lt;/code&gt; &lt;/a&gt; 을 호출하는 Python 프로그램과 동일한 주소 공간에서 실행해야합니다 . 당신이 TensorFlow 분산 사용하는 경우에는 실행해야합니다 &lt;a href=&quot;distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 호출하는 프로그램과 동일한 과정을 &lt;a href=&quot;numpy_function&quot;&gt; &lt;code&gt;tf.numpy_function&lt;/code&gt; &lt;/a&gt; 당신이 (예를 들어, 사용하여 해당 서버에서 장치에 생성 된 작업을 고정합니다 &lt;code&gt;with tf.device():&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="2eb160b49a8c0e9200d47f580c46000b2caec03e" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;py_func&quot;&gt;&lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;../../distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;py_func&quot;&gt;&lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt;&lt;/a&gt; and you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">작업은 &lt;a href=&quot;py_func&quot;&gt; &lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt; &lt;/a&gt; 를 호출하는 Python 프로그램과 동일한 주소 공간에서 실행해야합니다 . 분산 TensorFlow를 사용하는 경우 &lt;a href=&quot;py_func&quot;&gt; &lt;code&gt;tf.compat.v1.py_func()&lt;/code&gt; &lt;/a&gt; 를 호출하는 프로그램과 동일한 프로세스에서 &lt;a href=&quot;../../distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 를 실행 해야하며 작성된 조작을 해당 서버의 디바이스에 고정해야합니다 (예 : &lt;code&gt;with tf.device():&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3cd48c99e2e66fcb5c484164b2f3d03eb702bcd9" translate="yes" xml:space="preserve">
          <source>The operation must run in the same address space as the Python program that calls &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function()&lt;/code&gt;&lt;/a&gt;. If you are using distributed TensorFlow, you must run a &lt;a href=&quot;distribute/server&quot;&gt;&lt;code&gt;tf.distribute.Server&lt;/code&gt;&lt;/a&gt; in the same process as the program that calls &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function()&lt;/code&gt;&lt;/a&gt; and you must pin the created operation to a device in that server (e.g. using &lt;code&gt;with tf.device():&lt;/code&gt;).</source>
          <target state="translated">작업은 &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function()&lt;/code&gt; &lt;/a&gt; 을 호출하는 Python 프로그램과 동일한 주소 공간에서 실행해야합니다 . 분산 TensorFlow를 사용하는 경우 &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function()&lt;/code&gt; &lt;/a&gt; 을 호출하는 프로그램과 동일한 프로세스에서 &lt;a href=&quot;distribute/server&quot;&gt; &lt;code&gt;tf.distribute.Server&lt;/code&gt; &lt;/a&gt; 를 실행 해야하며 생성 된 조작을 해당 서버의 디바이스에 고정해야합니다 (예 : &lt;code&gt;with tf.device():&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="12a018d5761a73fb797a8185b603d78340c9da47" translate="yes" xml:space="preserve">
          <source>The operation of &lt;code&gt;raw_rnn&lt;/code&gt;, in pseudo-code, is basically the following:</source>
          <target state="translated">의사 코드에서 &lt;code&gt;raw_rnn&lt;/code&gt; 의 작업 은 기본적으로 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="666e744ea2e81d27484651c5a90d39fe7463b5f8" translate="yes" xml:space="preserve">
          <source>The operation returns the cardinality of &lt;code&gt;dataset&lt;/code&gt;. The operation may return &lt;a href=&quot;../experimental#INFINITE_CARDINALITY&quot;&gt;&lt;code&gt;tf.data.experimental.INFINITE_CARDINALITY&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;dataset&lt;/code&gt; contains an infinite number of elements or &lt;a href=&quot;../experimental#UNKNOWN_CARDINALITY&quot;&gt;&lt;code&gt;tf.data.experimental.UNKNOWN_CARDINALITY&lt;/code&gt;&lt;/a&gt; if the analysis fails to determine the number of elements in &lt;code&gt;dataset&lt;/code&gt; (e.g. when the dataset source is a file).</source>
          <target state="translated">이 작업은 &lt;code&gt;dataset&lt;/code&gt; 의 카디널리티를 반환합니다 . &lt;code&gt;dataset&lt;/code&gt; 에 무한한 수의 요소가 포함 된 경우 작업에서 &lt;a href=&quot;../experimental#INFINITE_CARDINALITY&quot;&gt; &lt;code&gt;tf.data.experimental.INFINITE_CARDINALITY&lt;/code&gt; 를&lt;/a&gt; 반환 하거나 분석에서 &lt;code&gt;dataset&lt;/code&gt; 의 요소 수를 결정하지 못한 경우 (예 : 데이터 세트 소스가 파일 인 경우) &lt;a href=&quot;../experimental#UNKNOWN_CARDINALITY&quot;&gt; &lt;code&gt;tf.data.experimental.UNKNOWN_CARDINALITY&lt;/code&gt; 를&lt;/a&gt; 반환 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b1aa4d33454ed3399a3f83fe0b47437e589dd1db" translate="yes" xml:space="preserve">
          <source>The operation supports data types (for &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt;) of &lt;code&gt;uint8&lt;/code&gt;, &lt;code&gt;uint16&lt;/code&gt;, &lt;code&gt;uint32&lt;/code&gt;, &lt;code&gt;uint64&lt;/code&gt;, &lt;code&gt;int8&lt;/code&gt;, &lt;code&gt;int16&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;int64&lt;/code&gt;, &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;, &lt;code&gt;bfloat16&lt;/code&gt;. In case of casting from complex types (&lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;) to real types, only the real part of &lt;code&gt;x&lt;/code&gt; is returned. In case of casting from real types to complex types (&lt;code&gt;complex64&lt;/code&gt;, &lt;code&gt;complex128&lt;/code&gt;), the imaginary part of the returned value is set to &lt;code&gt;0&lt;/code&gt;. The handling of complex types here matches the behavior of numpy.</source>
          <target state="translated">(동작의 지원 데이터 타입 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;dtype&lt;/code&gt; 의) &lt;code&gt;uint8&lt;/code&gt; , &lt;code&gt;uint16&lt;/code&gt; , &lt;code&gt;uint32&lt;/code&gt; , &lt;code&gt;uint64&lt;/code&gt; , &lt;code&gt;int8&lt;/code&gt; , &lt;code&gt;int16&lt;/code&gt; , &lt;code&gt;int32&lt;/code&gt; , &lt;code&gt;int64&lt;/code&gt; , &lt;code&gt;float16&lt;/code&gt; 과 , &lt;code&gt;float32&lt;/code&gt; , &lt;code&gt;float64&lt;/code&gt; , &lt;code&gt;complex64&lt;/code&gt; , &lt;code&gt;complex128&lt;/code&gt; , &lt;code&gt;bfloat16&lt;/code&gt; . 복잡한 유형 (에서 전송할 경우 &lt;code&gt;complex64&lt;/code&gt; , &lt;code&gt;complex128&lt;/code&gt; 실제 유형의 실수 부분) &lt;code&gt;x&lt;/code&gt; 반환된다. 실제 유형에서 복합 유형으로 캐스트하는 경우 ( &lt;code&gt;complex64&lt;/code&gt; , &lt;code&gt;complex128&lt;/code&gt; 은)에서 반환 된 값의 허수 부분은 &lt;code&gt;0&lt;/code&gt; 으로 설정됩니다 . 여기서 복잡한 유형의 처리는 numpy의 동작과 일치합니다.</target>
        </trans-unit>
        <trans-unit id="633cea8689c5cf5392fe403777889735793f4042" translate="yes" xml:space="preserve">
          <source>The operation that (conditionally) applies a gradient to the accumulator.</source>
          <target state="translated">조건부로 누적기에 기울기를 적용하는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="be412a34e6685ca321b38fae5794bdc3419b0f98" translate="yes" xml:space="preserve">
          <source>The operation that closes the queue.</source>
          <target state="translated">큐를 닫는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="b2e5f0ceeecca2686d84b94bc3fa75e7225fc1f4" translate="yes" xml:space="preserve">
          <source>The operation that enqueues a batch of tuples of tensors to the queue.</source>
          <target state="translated">튜플의 배치를 큐에 큐에 넣는 조작입니다.</target>
        </trans-unit>
        <trans-unit id="59123e207e4121d978f651d18670cf600162571e" translate="yes" xml:space="preserve">
          <source>The operation that enqueues a new tuple of tensors to the queue.</source>
          <target state="translated">큐에 새로운 튜플 튜플을 큐에 넣는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="99898763428cef52c27daa776a42aecf7741168c" translate="yes" xml:space="preserve">
          <source>The operation that failed, if known.</source>
          <target state="translated">알려진 작업이 실패했습니다.</target>
        </trans-unit>
        <trans-unit id="99d34ac6542deab6f4080fc89f4db33d67017bad" translate="yes" xml:space="preserve">
          <source>The operation that implements the reader.</source>
          <target state="translated">The operation that implements the reader.</target>
        </trans-unit>
        <trans-unit id="21259fcd1f38c739e8e877f9049101d45ed6faeb" translate="yes" xml:space="preserve">
          <source>The operation that initializes the table.</source>
          <target state="translated">테이블을 초기화하는 작업입니다.</target>
        </trans-unit>
        <trans-unit id="88d1101fb9e57b49ac3b0eb22875a3459c4f2b28" translate="yes" xml:space="preserve">
          <source>The operation that should be applied to the RaggedTensor &lt;code&gt;flat_values&lt;/code&gt;. &lt;code&gt;op&lt;/code&gt; is typically an element-wise operation (such as math_ops.add), but any operation that preserves the size of the outermost dimension can be used. I.e., &lt;code&gt;shape[0]&lt;/code&gt; of the value returned by &lt;code&gt;op&lt;/code&gt; must match &lt;code&gt;shape[0]&lt;/code&gt; of the &lt;code&gt;RaggedTensor&lt;/code&gt;s' &lt;code&gt;flat_values&lt;/code&gt; tensors.</source>
          <target state="translated">The operation that should be applied to the RaggedTensor &lt;code&gt;flat_values&lt;/code&gt; . &lt;code&gt;op&lt;/code&gt; is typically an element-wise operation (such as math_ops.add), but any operation that preserves the size of the outermost dimension can be used. I.e., &lt;code&gt;shape[0]&lt;/code&gt; of the value returned by &lt;code&gt;op&lt;/code&gt; must match &lt;code&gt;shape[0]&lt;/code&gt; of the &lt;code&gt;RaggedTensor&lt;/code&gt; s' &lt;code&gt;flat_values&lt;/code&gt; tensors.</target>
        </trans-unit>
        <trans-unit id="7d4203f69addf4215a9f75fa10050cf92a106167" translate="yes" xml:space="preserve">
          <source>The operation was aborted, typically due to a concurrent action.</source>
          <target state="translated">일반적으로 동시 작업으로 인해 작업이 중단되었습니다.</target>
        </trans-unit>
        <trans-unit id="182e7dce9af9390db25d63cce38f101933dc52f8" translate="yes" xml:space="preserve">
          <source>The operation works for the following input types:</source>
          <target state="translated">The operation works for the following input types:</target>
        </trans-unit>
        <trans-unit id="8d2fbee8f6406df6777f5eab458e89a6b6c00fa3" translate="yes" xml:space="preserve">
          <source>The operator before inversion.</source>
          <target state="translated">반전 전의 연산자.</target>
        </trans-unit>
        <trans-unit id="dca167c313a3afe14fe0a9adc69f0f5e8d1c9afb" translate="yes" xml:space="preserve">
          <source>The operator before taking the adjoint.</source>
          <target state="translated">인접하기 전에 연산자.</target>
        </trans-unit>
        <trans-unit id="dd77aed70dd9284b7d6c31fc643a9815d5df72eb" translate="yes" xml:space="preserve">
          <source>The optimization options associated with the dataset. See &lt;a href=&quot;experimental/optimizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 최적화 옵션. 자세한 내용은 &lt;a href=&quot;experimental/optimizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="d41bfab8487c080f4a52aaa4180a3c960ee957f3" translate="yes" xml:space="preserve">
          <source>The optimizer adds nodes to the graph to collect gradients and pause the trainers until variables are updated. For the Parameter Server job:</source>
          <target state="translated">옵티마이 저는 그래프에 노드를 추가하여 그라디언트를 수집하고 변수가 업데이트 될 때까지 트레이너를 일시 중지합니다. 매개 변수 서버 작업의 경우 :</target>
        </trans-unit>
        <trans-unit id="54fde7cedba37819ea597c67bd03d0eccd830d20" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;feed_dict&lt;/code&gt; argument allows the caller to override the value of tensors in the graph. Each key in &lt;code&gt;feed_dict&lt;/code&gt; can be one of the following types:</source>
          <target state="translated">선택적 &lt;code&gt;feed_dict&lt;/code&gt; 인수를 사용하면 호출자가 그래프의 텐서 값을 대체 할 수 있습니다. &lt;code&gt;feed_dict&lt;/code&gt; 의 각 키 는 다음 유형 중 하나 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="802a640d90b4b6b27f2c21f94a40f0d9fba6af8f" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;feed_dict&lt;/code&gt; argument allows the caller to override the value of tensors in the graph. See run() for more information.</source>
          <target state="translated">선택적 &lt;code&gt;feed_dict&lt;/code&gt; 인수를 사용하면 호출자가 그래프의 텐서 값을 대체 할 수 있습니다. 자세한 내용은 run ()을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="eacc79006fb44e1fd531dba67ace0548202f07d4" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;num_updates&lt;/code&gt; parameter allows one to tweak the decay rate dynamically. It is typical to pass the count of training steps, usually kept in a variable that is incremented at each step, in which case the decay rate is lower at the start of training. This makes moving averages move faster. If passed, the actual decay rate used is:</source>
          <target state="translated">선택적 &lt;code&gt;num_updates&lt;/code&gt; 매개 변수를 사용하면 감쇠율을 동적으로 조정할 수 있습니다. 일반적으로 각 단계에서 증가하는 변수로 유지되는 훈련 단계 수를 통과하는 것이 일반적이며,이 경우 훈련 시작시 붕괴율이 낮아집니다. 이것은 이동 평균이 더 빠르게 움직입니다. 통과하면 실제 붕괴율은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="4d5f2024e82b1f112cdc773a7a0d099d108bab47" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;options&lt;/code&gt; argument expects a [&lt;code&gt;RunOptions&lt;/code&gt;] proto. The options allow controlling the behavior of this particular step (e.g. turning tracing on).</source>
          <target state="translated">선택적 &lt;code&gt;options&lt;/code&gt; 인수에는 [ &lt;code&gt;RunOptions&lt;/code&gt; ] 프로토 타입이 필요합니다. 옵션을 사용하면이 특정 단계의 동작을 제어 할 수 있습니다 (예 : 추적 설정).</target>
        </trans-unit>
        <trans-unit id="5dd8b71d547dc1502ab3faa2f08ccf41ba7e8b18" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;reshape&lt;/code&gt; argument, if &lt;code&gt;True&lt;/code&gt;, allows restoring a variable from a save file where the variable had a different shape, but the same number of elements and type. This is useful if you have reshaped a variable and want to reload it from an older checkpoint.</source>
          <target state="translated">선택적 &lt;code&gt;reshape&lt;/code&gt; 인수는 &lt;code&gt;True&lt;/code&gt; 인 경우 변수의 모양은 다르지만 요소 및 유형은 동일한 저장 파일에서 변수를 복원 할 수 있습니다. 변수를 재 형성하고 이전 체크 포인트에서 변수를 다시로드하려는 경우에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="e970942946ff441e315a637342ca6559423698ca" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;run_metadata&lt;/code&gt; argument expects a [&lt;code&gt;RunMetadata&lt;/code&gt;] proto. When appropriate, the non-Tensor output of this step will be collected there. For example, when users turn on tracing in &lt;code&gt;options&lt;/code&gt;, the profiled info will be collected into this argument and passed back.</source>
          <target state="translated">선택적 &lt;code&gt;run_metadata&lt;/code&gt; 인수에는 [ &lt;code&gt;RunMetadata&lt;/code&gt; ] 프로토 타입이 필요합니다. 적절한 경우이 단계의 텐서가 아닌 출력이 여기에 수집됩니다. 예를 들어, 사용자가 &lt;code&gt;options&lt;/code&gt; 에서 추적을 켜면 프로파일 링 된 정보가이 인수로 수집되어 다시 전달됩니다.</target>
        </trans-unit>
        <trans-unit id="4463c9db10422ab0ce9fc83cbdf23e0b400b34c3" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;sharded&lt;/code&gt; argument, if &lt;code&gt;True&lt;/code&gt;, instructs the saver to shard checkpoints per device.</source>
          <target state="translated">선택적 &lt;code&gt;sharded&lt;/code&gt; 인수는 &lt;code&gt;True&lt;/code&gt; 이면 세이버가 장치 당 샤드 체크 포인트를 지시하도록 지시합니다.</target>
        </trans-unit>
        <trans-unit id="9211a71d92ea323063ffa11455da47bbb168e612" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;signatures&lt;/code&gt; argument controls which methods in &lt;code&gt;obj&lt;/code&gt; will be available to programs which consume &lt;code&gt;SavedModel&lt;/code&gt;s, for example serving APIs. Python functions may be decorated with &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; and passed as signatures directly, or lazily with a call to &lt;code&gt;get_concrete_function&lt;/code&gt; on the method decorated with &lt;code&gt;@tf.function&lt;/code&gt;.</source>
          <target state="translated">선택적 &lt;code&gt;signatures&lt;/code&gt; 인수는 &lt;code&gt;SavedModel&lt;/code&gt; 을 소비하는 프로그램 ( 예 : API 제공) 에서 &lt;code&gt;obj&lt;/code&gt; 의 어떤 메소드를 사용할 수 있는지 제어합니다 . 파이썬 함수는 &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; 로 장식 될 수 있으며 서명으로 직접 전달되거나 &lt;code&gt;@tf.function&lt;/code&gt; 장식 된 메소드 에서 &lt;code&gt;get_concrete_function&lt;/code&gt; 호출로 게으르게 전달 될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="7b76c8215965b6d6548dad5cc3be42ab9b948c2e" translate="yes" xml:space="preserve">
          <source>The optional &lt;code&gt;signatures&lt;/code&gt; argument controls which methods in &lt;code&gt;obj&lt;/code&gt; will be available to programs which consume &lt;code&gt;SavedModel&lt;/code&gt;s, for example, serving APIs. Python functions may be decorated with &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; and passed as signatures directly, or lazily with a call to &lt;code&gt;get_concrete_function&lt;/code&gt; on the method decorated with &lt;code&gt;@tf.function&lt;/code&gt;.</source>
          <target state="translated">The optional &lt;code&gt;signatures&lt;/code&gt; argument controls which methods in &lt;code&gt;obj&lt;/code&gt; will be available to programs which consume &lt;code&gt;SavedModel&lt;/code&gt; s, for example, serving APIs. Python functions may be decorated with &lt;code&gt;@tf.function(input_signature=...)&lt;/code&gt; and passed as signatures directly, or lazily with a call to &lt;code&gt;get_concrete_function&lt;/code&gt; on the method decorated with &lt;code&gt;@tf.function&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5eb10eb93ba6242a60bc81190f01e4562cc7c7f2" translate="yes" xml:space="preserve">
          <source>The options are &quot;global&quot; in the sense they apply to the entire dataset. If options are set multiple times, they are merged as long as different options do not use different non-default values.</source>
          <target state="translated">옵션은 전체 데이터 세트에 적용되는 의미에서 &quot;전역&quot;입니다. 옵션이 여러 번 설정된 경우 다른 옵션이 기본값이 아닌 다른 값을 사용하지 않는 한 병합됩니다.</target>
        </trans-unit>
        <trans-unit id="839958c9eddae1511a49cbdd886b3f520fbec271" translate="yes" xml:space="preserve">
          <source>The order of output arguments here is &lt;code&gt;s&lt;/code&gt;, &lt;code&gt;u&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; when &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, as opposed to &lt;code&gt;u&lt;/code&gt;, &lt;code&gt;s&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; for numpy.linalg.svd.</source>
          <target state="translated">The order of output arguments here is &lt;code&gt;s&lt;/code&gt; , &lt;code&gt;u&lt;/code&gt; , &lt;code&gt;v&lt;/code&gt; when &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , as opposed to &lt;code&gt;u&lt;/code&gt; , &lt;code&gt;s&lt;/code&gt; , &lt;code&gt;v&lt;/code&gt; for numpy.linalg.svd.</target>
        </trans-unit>
        <trans-unit id="f3bc730bbfda16a7dd0623a512f8a88cc6217898" translate="yes" xml:space="preserve">
          <source>The original device on which &lt;code&gt;input_dataset&lt;/code&gt; will be placed.</source>
          <target state="translated">The original device on which &lt;code&gt;input_dataset&lt;/code&gt; will be placed.</target>
        </trans-unit>
        <trans-unit id="18d387209dd33fca87db5f4de4ba44e61656b7a9" translate="yes" xml:space="preserve">
          <source>The original input to &lt;a href=&quot;lu&quot;&gt;&lt;code&gt;tf.linalg.lu&lt;/code&gt;&lt;/a&gt;, i.e., &lt;code&gt;x&lt;/code&gt; as in, &lt;code&gt;lu_reconstruct(*tf.linalg.lu(x))&lt;/code&gt;.</source>
          <target state="translated">The original input to &lt;a href=&quot;lu&quot;&gt; &lt;code&gt;tf.linalg.lu&lt;/code&gt; &lt;/a&gt;, i.e., &lt;code&gt;x&lt;/code&gt; as in, &lt;code&gt;lu_reconstruct(*tf.linalg.lu(x))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="af401239a74cc22bb0656ceab277ae88265e81dd" translate="yes" xml:space="preserve">
          <source>The original method wrapped such that it enters the module's name scope.</source>
          <target state="translated">원래의 메소드는 모듈의 이름 범위에 들어가도록 랩핑되었습니다.</target>
        </trans-unit>
        <trans-unit id="f891d19803fb509490762be082d2f8ade6148c86" translate="yes" xml:space="preserve">
          <source>The original registered Flag objects can be retrieved through the use of the dictionary-like operator, &lt;strong&gt;getitem&lt;/strong&gt;: x = FLAGS['longname'] # access the registered Flag object</source>
          <target state="translated">사전 등록 된 Flag 객체는 사전과 같은 연산자 &lt;strong&gt;getitem을&lt;/strong&gt; 사용하여 검색 할 수 있습니다 . x = FLAGS [ 'longname'] # 등록 된 Flag 객체에 액세스</target>
        </trans-unit>
        <trans-unit id="b71549bb8296bfb172b0e5fa059a19b9055f4136" translate="yes" xml:space="preserve">
          <source>The other method &lt;code&gt;uniform&lt;/code&gt; only covers the range [minval, maxval), which cannot be &lt;code&gt;dtype&lt;/code&gt;'s full range because &lt;code&gt;maxval&lt;/code&gt; is of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">다른 방법 &lt;code&gt;uniform&lt;/code&gt; 만 될 수 없다) MINVAL, MAXVAL 범위 커버 &lt;code&gt;dtype&lt;/code&gt; 때문에 S '전체 범위 &lt;code&gt;maxval&lt;/code&gt; 유형이다 &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8d650eca6a136e51fc7375e0969bc2ea1115b2e2" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; object's shape values for all dimensions but the first are the max across the input &lt;code&gt;SparseTensor&lt;/code&gt; objects' shape values for the corresponding dimensions. Its first shape value is &lt;code&gt;N&lt;/code&gt;, the minibatch size.</source>
          <target state="translated">모든 치수에 대한 출력 &lt;code&gt;SparseTensor&lt;/code&gt; 객체의 모양 값이지만 첫 번째는 해당 치수에 대한 입력 &lt;code&gt;SparseTensor&lt;/code&gt; 객체의 모양 값에 대한 최대 값입니다. 첫 번째 도형 값은 미니 배치 크기 인 &lt;code&gt;N&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="f7899fd3a60fa39b01002b08a0bd2e514e0a6d60" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; object's shape values for the original dimensions are the max across the input &lt;code&gt;SparseTensor&lt;/code&gt; objects' shape values for the corresponding dimensions. The new dimensions match the size of the batch.</source>
          <target state="translated">The output &lt;code&gt;SparseTensor&lt;/code&gt; object's shape values for the original dimensions are the max across the input &lt;code&gt;SparseTensor&lt;/code&gt; objects' shape values for the corresponding dimensions. The new dimensions match the size of the batch.</target>
        </trans-unit>
        <trans-unit id="27cd935b967006cc01a667a4b3f9d0444d7da4c5" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;SparseTensor&lt;/code&gt; will be in row-major order and will have the same shape as the input.</source>
          <target state="translated">출력 &lt;code&gt;SparseTensor&lt;/code&gt; 는 행 주요 순서이며 입력과 동일한 모양을 갖습니다.</target>
        </trans-unit>
        <trans-unit id="3ed7c320b010e6441e9928df89e4f8feea635e72" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;y&lt;/code&gt; has the same rank as &lt;code&gt;x&lt;/code&gt;. The shapes of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; satisfy: &lt;code&gt;y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]&lt;/code&gt;</source>
          <target state="translated">The output &lt;code&gt;y&lt;/code&gt; has the same rank as &lt;code&gt;x&lt;/code&gt; . The shapes of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; satisfy: &lt;code&gt;y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ac7bc3e3640548894477903c76a63029f0684b7b" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;y&lt;/code&gt; has the same rank as &lt;code&gt;x&lt;/code&gt;. The shapes of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; satisfy: &lt;code&gt;y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]&lt;/code&gt;&lt;code&gt;y[i,j,k,...,s,t,u] == conj(x[perm[i], perm[j], perm[k],...,perm[s], perm[t], perm[u]])&lt;/code&gt;</source>
          <target state="translated">The output &lt;code&gt;y&lt;/code&gt; has the same rank as &lt;code&gt;x&lt;/code&gt; . The shapes of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; satisfy: &lt;code&gt;y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]&lt;/code&gt; &lt;code&gt;y[i,j,k,...,s,t,u] == conj(x[perm[i], perm[j], perm[k],...,perm[s], perm[t], perm[u]])&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="25a24380035e136d9ea98af6a346f119051ef56c" translate="yes" xml:space="preserve">
          <source>The output Tensor as described above, dimensions will vary based on the op provided.</source>
          <target state="translated">위에서 설명한 출력 텐서, 치수는 제공된 op에 따라 다릅니다.</target>
        </trans-unit>
        <trans-unit id="47c4d6134bd40a175fa44afa8f9b377d5850de3c" translate="yes" xml:space="preserve">
          <source>The output consists of two tensors LU and P containing the LU decomposition of all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;. LU encodes the lower triangular and upper triangular factors.</source>
          <target state="translated">출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 의 LU 분해를 포함하는 두 개의 텐서 LU 및 P로 구성됩니다 . LU는 하부 삼각 및 상부 삼각 계수를 인코딩합니다.</target>
        </trans-unit>
        <trans-unit id="797ecd44b1fb4a552924484c7a55ad507593ed55" translate="yes" xml:space="preserve">
          <source>The output dtype; defaults to &lt;a href=&quot;../../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The output dtype; defaults to &lt;a href=&quot;../../../tf#int64&quot;&gt; &lt;code&gt;tf.int64&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="31482f2ff54a3aa8fae10ccd117f3f60685fed5f" translate="yes" xml:space="preserve">
          <source>The output dtype; defaults to &lt;a href=&quot;../../tf#int64&quot;&gt;&lt;code&gt;tf.int64&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The output dtype; defaults to &lt;a href=&quot;../../tf#int64&quot;&gt; &lt;code&gt;tf.int64&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="048c6e1cfd308f6012ab77e90cbc674670b136c0" translate="yes" xml:space="preserve">
          <source>The output elements are taken from the input at intervals given by the &lt;code&gt;rate&lt;/code&gt; argument, as in dilated convolutions.</source>
          <target state="translated">출력 요소는 확장 된 회선에서와 같이 &lt;code&gt;rate&lt;/code&gt; 인수에 의해 주어진 간격으로 입력에서 가져옵니다 .</target>
        </trans-unit>
        <trans-unit id="01cfec4a29cc69f6abe94502062c73070782ab76" translate="yes" xml:space="preserve">
          <source>The output elements will be resorted to preserve the sort order along increasing dimension number.</source>
          <target state="translated">치수 요소가 증가함에 따라 정렬 순서를 유지하기 위해 출력 요소가 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="38c8f8944795768b987abf44161bc29810671bc1" translate="yes" xml:space="preserve">
          <source>The output is a tensor of rank &lt;code&gt;k+1&lt;/code&gt; with dimensions &lt;code&gt;[I, J, ..., L, M, N]&lt;/code&gt;. If &lt;code&gt;k&lt;/code&gt; is scalar or &lt;code&gt;k[0] == k[1]&lt;/code&gt;:</source>
          <target state="translated">출력은 크기가 &lt;code&gt;[I, J, ..., L, M, N]&lt;/code&gt; 인 순위 &lt;code&gt;k+1&lt;/code&gt; 의 텐서입니다 . 경우 &lt;code&gt;k&lt;/code&gt; 는 스칼라이거나 &lt;code&gt;k[0] == k[1]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="b9f3b180f0596bc470d2fb79c1dedac7776f93d9" translate="yes" xml:space="preserve">
          <source>The output is a tensor of shape &lt;code&gt;[..., M, K]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the strictly then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;.</source>
          <target state="translated">출력은 모양 &lt;code&gt;[..., M, K]&lt;/code&gt; 의 텐서입니다 . 경우 &lt;code&gt;adjoint&lt;/code&gt; 인 &lt;code&gt;True&lt;/code&gt; 다음의 최 행렬 &lt;code&gt;output&lt;/code&gt; 만족 행렬 방정식을 &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt; . 경우 &lt;code&gt;adjoint&lt;/code&gt; 인 &lt;code&gt;False&lt;/code&gt; 후 엄격 다음의 최 행렬 &lt;code&gt;output&lt;/code&gt; 행렬 방정식을 만족 &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1488da1cb166b21e2e086e4e08f96c22ee229379" translate="yes" xml:space="preserve">
          <source>The output is a tensor of shape &lt;code&gt;[..., M, N]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the strictly then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;.</source>
          <target state="translated">The output is a tensor of shape &lt;code&gt;[..., M, N]&lt;/code&gt; . If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]&lt;/code&gt; . If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the strictly then the innermost matrices in &lt;code&gt;output&lt;/code&gt; satisfy matrix equations &lt;code&gt;adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6768fd2c3c792ee19a1c494dc0c8f3d25ef95d97" translate="yes" xml:space="preserve">
          <source>The output is a tensor of shape &lt;code&gt;[..., M, N]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in output satisfy matrix equations &lt;code&gt;sum_k matrix[..., i, k] * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;. If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the innermost matrices in output satisfy matrix equations &lt;code&gt;sum_k adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt;.</source>
          <target state="translated">The output is a tensor of shape &lt;code&gt;[..., M, N]&lt;/code&gt; . If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the innermost matrices in output satisfy matrix equations &lt;code&gt;sum_k matrix[..., i, k] * output[..., k, j] = rhs[..., i, j]&lt;/code&gt; . If &lt;code&gt;adjoint&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the innermost matrices in output satisfy matrix equations &lt;code&gt;sum_k adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="24258a9b3cf1537928d726a4c142766d14a612d5" translate="yes" xml:space="preserve">
          <source>The output is a tensor of the same shape as &lt;code&gt;rhs&lt;/code&gt;: either &lt;code&gt;[..., M]&lt;/code&gt; or &lt;code&gt;[..., M, K]&lt;/code&gt;.</source>
          <target state="translated">출력은 &lt;code&gt;rhs&lt;/code&gt; 와 동일한 모양의 텐서입니다 : &lt;code&gt;[..., M]&lt;/code&gt; 또는 &lt;code&gt;[..., M, K]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7d3db7f6f2ef07d73508fa555433bf8d83a75eaa" translate="yes" xml:space="preserve">
          <source>The output is a tensor of the same shape as the input containing the Cholesky decompositions for all input submatrices &lt;code&gt;[..., :, :]&lt;/code&gt;.</source>
          <target state="translated">출력은 모든 입력 하위 행렬 &lt;code&gt;[..., :, :]&lt;/code&gt; 대한 Cholesky 분해를 포함하는 입력과 동일한 모양의 텐서입니다 .</target>
        </trans-unit>
        <trans-unit id="6194740e93c206c46e0bfecd7aa22357ddec1b58" translate="yes" xml:space="preserve">
          <source>The output is computed as follows:</source>
          <target state="translated">The output is computed as follows:</target>
        </trans-unit>
        <trans-unit id="b74ff8ee45b0b8f3cea227a5cb8b0ca2512e0fa1" translate="yes" xml:space="preserve">
          <source>The output is:</source>
          <target state="translated">출력은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="02cc9038a532f36829ca3735f949f57712e9a776" translate="yes" xml:space="preserve">
          <source>The output locations corresponding to the implicitly zero elements in the sparse tensor will be zero (i.e., will not take up storage space), regardless of the contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).</source>
          <target state="translated">희박한 텐서의 암시 적으로 0 요소에 해당하는 출력 위치는 밀도 텐서의 내용에 관계없이 0입니다 (즉, 저장 공간을 차지하지 않습니다) (+/- INF이고 INF * 0 == 인 경우에도) NaN).</target>
        </trans-unit>
        <trans-unit id="4921b3c960168ec33230d0e2275991a2a480fee7" translate="yes" xml:space="preserve">
          <source>The output of &lt;a href=&quot;../compat/v1/estimator/estimator#evaluate&quot;&gt;&lt;code&gt;Estimator.evaluate&lt;/code&gt;&lt;/a&gt; on this checkpoint.</source>
          <target state="translated">The output of &lt;a href=&quot;../compat/v1/estimator/estimator#evaluate&quot;&gt; &lt;code&gt;Estimator.evaluate&lt;/code&gt; &lt;/a&gt; on this checkpoint.</target>
        </trans-unit>
        <trans-unit id="b30d98674beeba8558b72dc407638d1340b74552" translate="yes" xml:space="preserve">
          <source>The output of the 1-arg function that takes the &lt;code&gt;step&lt;/code&gt; is &lt;code&gt;values[0]&lt;/code&gt; when &lt;code&gt;step &amp;lt;= boundaries[0]&lt;/code&gt;, &lt;code&gt;values[1]&lt;/code&gt; when &lt;code&gt;step &amp;gt; boundaries[0]&lt;/code&gt; and &lt;code&gt;step &amp;lt;= boundaries[1]&lt;/code&gt;, ..., and values[-1] when &lt;code&gt;step &amp;gt; boundaries[-1]&lt;/code&gt;.</source>
          <target state="translated">걸리는 1 인수 함수의 출력 &lt;code&gt;step&lt;/code&gt; 인 &lt;code&gt;values[0]&lt;/code&gt; 때 &lt;code&gt;step &amp;lt;= boundaries[0]&lt;/code&gt; , &lt;code&gt;values[1]&lt;/code&gt; 때 &lt;code&gt;step &amp;gt; boundaries[0]&lt;/code&gt; 및 &lt;code&gt;step &amp;lt;= boundaries[1]&lt;/code&gt; , ..., 및 &lt;code&gt;step &amp;gt; boundaries[-1]&lt;/code&gt; 값 [-1] 일 때의 값 [ -1] .</target>
        </trans-unit>
        <trans-unit id="d04584f160db196293c2030ae17c2dacfbfcd30d" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../../../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;../../../image/draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="translated">이 Op의 출력은 원본 이미지를 자르는 데 사용할 수있는 단일 경계 상자입니다. 결과는 3 개의 텐서 ( &lt;code&gt;begin&lt;/code&gt; , &lt;code&gt;size&lt;/code&gt; 및 &lt;code&gt;bboxes&lt;/code&gt; )로 반환됩니다 . 처음 2 개의 텐서는 이미지를 자르기 위해 &lt;a href=&quot;../../../slice&quot;&gt; &lt;code&gt;tf.slice&lt;/code&gt; &lt;/a&gt; 에 직접 공급 될 수 있습니다 . 후자는 &lt;a href=&quot;../../../image/draw_bounding_boxes&quot;&gt; &lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt; &lt;/a&gt; 에 제공되어 경계 상자의 모양을 시각화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="cc8ae412cea3a206e259aeb86af6654e659ed171" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;../image/draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="translated">The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt; , &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt; . The first 2 tensors can be fed directly into &lt;a href=&quot;../slice&quot;&gt; &lt;code&gt;tf.slice&lt;/code&gt; &lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;../image/draw_bounding_boxes&quot;&gt; &lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt; &lt;/a&gt; to visualize what the bounding box looks like.</target>
        </trans-unit>
        <trans-unit id="5e995a951ce7a3cd16e04e8cd70419e327350a30" translate="yes" xml:space="preserve">
          <source>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;bboxes&lt;/code&gt;. The first 2 tensors can be fed directly into &lt;a href=&quot;../slice&quot;&gt;&lt;code&gt;tf.slice&lt;/code&gt;&lt;/a&gt; to crop the image. The latter may be supplied to &lt;a href=&quot;draw_bounding_boxes&quot;&gt;&lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt;&lt;/a&gt; to visualize what the bounding box looks like.</source>
          <target state="translated">이 Op의 출력은 원본 이미지를 자르는 데 사용할 수있는 단일 경계 상자입니다. 결과는 3 개의 텐서 ( &lt;code&gt;begin&lt;/code&gt; , &lt;code&gt;size&lt;/code&gt; 및 &lt;code&gt;bboxes&lt;/code&gt; )로 반환됩니다 . 처음 2 개의 텐서는 이미지를 자르기 위해 &lt;a href=&quot;../slice&quot;&gt; &lt;code&gt;tf.slice&lt;/code&gt; &lt;/a&gt; 에 직접 공급 될 수 있습니다 . 후자는 &lt;a href=&quot;draw_bounding_boxes&quot;&gt; &lt;code&gt;tf.image.draw_bounding_boxes&lt;/code&gt; &lt;/a&gt; 에 제공되어 경계 상자의 모양을 시각화 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="867a41c15dc52766b0de85d04ee44344a9063866" translate="yes" xml:space="preserve">
          <source>The output of this method is a 3D &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[batch_size, T, D]&lt;/code&gt;. &lt;code&gt;T&lt;/code&gt; is the maximum sequence length for this batch, which could differ from batch to batch.</source>
          <target state="translated">이 방법의 출력은 모양이 &lt;code&gt;[batch_size, T, D]&lt;/code&gt; 3D &lt;code&gt;Tensor&lt;/code&gt; 입니다 . &lt;code&gt;T&lt;/code&gt; 는이 배치의 최대 시퀀스 길이이며 배치마다 다를 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="753b9e20d6aac1628ca75bf0511c387d43eb2530" translate="yes" xml:space="preserve">
          <source>The output of this operation is a set of integers indexing into the input collection of bounding boxes representing the selected boxes. The bounding box coordinates corresponding to the selected indices can then be obtained using the &lt;code&gt;tf.gather operation&lt;/code&gt;. For example:</source>
          <target state="translated">The output of this operation is a set of integers indexing into the input collection of bounding boxes representing the selected boxes. The bounding box coordinates corresponding to the selected indices can then be obtained using the &lt;code&gt;tf.gather operation&lt;/code&gt; . For example:</target>
        </trans-unit>
        <trans-unit id="da6a14177a19f48147884875b20440b0d347e68f" translate="yes" xml:space="preserve">
          <source>The output shape is identical to the inputs', except along the concat dimension, where it is the sum of the inputs' sizes along that dimension.</source>
          <target state="translated">The output shape is identical to the inputs', except along the concat dimension, where it is the sum of the inputs' sizes along that dimension.</target>
        </trans-unit>
        <trans-unit id="3b30057b1110d4946855f0f7f77e28efcaa8cc94" translate="yes" xml:space="preserve">
          <source>The output shapes are compatible in a way that the first dimension of all tensors are the same and equal to the number of possible split nodes for each feature.</source>
          <target state="translated">The output shapes are compatible in a way that the first dimension of all tensors are the same and equal to the number of possible split nodes for each feature.</target>
        </trans-unit>
        <trans-unit id="3907a316796c56324c363351b8f0ffb1dbcb1c06" translate="yes" xml:space="preserve">
          <source>The output signature of &lt;code&gt;fn&lt;/code&gt;. Must be specified if &lt;code&gt;fn&lt;/code&gt;'s input and output signatures are different (i.e., if their structures, dtypes, or tensor types do not match). &lt;code&gt;fn_output_signature&lt;/code&gt; can be specified using any of the following:</source>
          <target state="translated">The output signature of &lt;code&gt;fn&lt;/code&gt; . Must be specified if &lt;code&gt;fn&lt;/code&gt; 's input and output signatures are different (i.e., if their structures, dtypes, or tensor types do not match). &lt;code&gt;fn_output_signature&lt;/code&gt; can be specified using any of the following:</target>
        </trans-unit>
        <trans-unit id="eac10a40d7ace5a75143c2fbccbd028ece77a9fb" translate="yes" xml:space="preserve">
          <source>The output slice &lt;code&gt;i&lt;/code&gt; along dimension &lt;code&gt;batch_axis&lt;/code&gt; is then given by input slice &lt;code&gt;i&lt;/code&gt;, with the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; slices along dimension &lt;code&gt;seq_axis&lt;/code&gt; reversed.</source>
          <target state="translated">출력 슬라이스 &lt;code&gt;i&lt;/code&gt; 사이즈에 따라 &lt;code&gt;batch_axis&lt;/code&gt; 가 다음 입력 슬라이스 주어진다 &lt;code&gt;i&lt;/code&gt; 처음으로 &lt;code&gt;seq_lengths[i]&lt;/code&gt; 사이즈에 따라 분할 &lt;code&gt;seq_axis&lt;/code&gt; 는 반대로.</target>
        </trans-unit>
        <trans-unit id="b24ce3e8aaca6570e3ec8cec6e775f6c5f2c52dd" translate="yes" xml:space="preserve">
          <source>The output slice &lt;code&gt;i&lt;/code&gt; along dimension &lt;code&gt;batch_dim&lt;/code&gt; is then given by input slice &lt;code&gt;i&lt;/code&gt;, with the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; slices along dimension &lt;code&gt;seq_dim&lt;/code&gt; reversed.</source>
          <target state="translated">The output slice &lt;code&gt;i&lt;/code&gt; along dimension &lt;code&gt;batch_dim&lt;/code&gt; is then given by input slice &lt;code&gt;i&lt;/code&gt; , with the first &lt;code&gt;seq_lengths[i]&lt;/code&gt; slices along dimension &lt;code&gt;seq_dim&lt;/code&gt; reversed.</target>
        </trans-unit>
        <trans-unit id="76e5d3d89821526e9a3ed69b0fc0e5605bddfe28" translate="yes" xml:space="preserve">
          <source>The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.logging.error are also supported. To print to a file, pass a string started with &quot;file://&quot; followed by the file path, e.g., &quot;file:///tmp/foo.out&quot;.</source>
          <target state="translated">The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.logging.error are also supported. To print to a file, pass a string started with &quot;file://&quot; followed by the file path, e.g., &quot;file:///tmp/foo.out&quot;.</target>
        </trans-unit>
        <trans-unit id="098e1ce5365a1d1a1384c17c4ced06e659b0880f" translate="yes" xml:space="preserve">
          <source>The output subscripts must contain only labels appearing in at least one of the input subscripts. Furthermore, all dimensions mapping to the same axis label must be equal.</source>
          <target state="translated">The output subscripts must contain only labels appearing in at least one of the input subscripts. Furthermore, all dimensions mapping to the same axis label must be equal.</target>
        </trans-unit>
        <trans-unit id="d0270145e0963e3fa6b4466fddef88fdbf60e481" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[1, 2, 2, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="aff644b1606cf977042c3f329c0b44912b343d5f" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[1, 2, 2, 3]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="26ecc2d485656620c8ddae36c3377b136f2c8ef6" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[1, 4, 4, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[1, 4, 4, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="413cce56d7e73e0557f6955da012eeb198f78207" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[2, 2, 4, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[2, 2, 4, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="580524501d7754a464d140a489afd8a69565b7e8" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 1, 1, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[4, 1, 1, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="43b93cea1c5beede2692779450404b22ddd16414" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 1, 1, 3]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[4, 1, 1, 3]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="863590a97a6747705662d02c1d09d524c465ba85" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[4, 2, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[4, 2, 2, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="951a2f1acb5ea54cd01c5c69fad552b3af0398ec" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[8, 1, 2, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[8, 1, 2, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="b991f9c184601aa1cf79a030dce35cd2e1811686" translate="yes" xml:space="preserve">
          <source>The output tensor has shape &lt;code&gt;[8, 1, 3, 1]&lt;/code&gt; and value:</source>
          <target state="translated">출력 텐서는 모양 &lt;code&gt;[8, 1, 3, 1]&lt;/code&gt; 과 값을 갖습니다 :</target>
        </trans-unit>
        <trans-unit id="8a7212b9117e06db921246aafe5499cc8ff0cedb" translate="yes" xml:space="preserve">
          <source>The output tensor is 2-D or higher with shape &lt;code&gt;[..., r_o, c_o]&lt;/code&gt;, where:</source>
          <target state="translated">The output tensor is 2-D or higher with shape &lt;code&gt;[..., r_o, c_o]&lt;/code&gt; , where:</target>
        </trans-unit>
        <trans-unit id="c6dc975d4ffc27e7fe4b516c5e078460e61b472d" translate="yes" xml:space="preserve">
          <source>The output tensor is a tensor with dimensions described by 'size' whose values are extracted from 'input' starting at the offsets in 'begin'.</source>
          <target state="translated">The output tensor is a tensor with dimensions described by 'size' whose values are extracted from 'input' starting at the offsets in 'begin'.</target>
        </trans-unit>
        <trans-unit id="018a92a28c57571fe5c1edcfb924689c52abc4b8" translate="yes" xml:space="preserve">
          <source>The output tensor, of rank 3.</source>
          <target state="translated">순위 3의 출력 텐서.</target>
        </trans-unit>
        <trans-unit id="1f5eef2e4414626524178eb10c4ab831f83220c9" translate="yes" xml:space="preserve">
          <source>The output tensor.</source>
          <target state="translated">The output tensor.</target>
        </trans-unit>
        <trans-unit id="f156d1cf6b13fd91d5c1751333de4bfa7481e5ec" translate="yes" xml:space="preserve">
          <source>The output tensors for the loop variables after the loop. If &lt;code&gt;return_same_structure&lt;/code&gt; is True, the return value has the same structure as &lt;code&gt;loop_vars&lt;/code&gt;. If &lt;code&gt;return_same_structure&lt;/code&gt; is False, the return value is a Tensor, TensorArray or IndexedSlice if the length of &lt;code&gt;loop_vars&lt;/code&gt; is 1, or a list otherwise.</source>
          <target state="translated">루프 뒤의 루프 변수에 대한 출력 텐서. 경우 &lt;code&gt;return_same_structure&lt;/code&gt; 이 사실 인 경우, 반환 값은 같은 구조가 &lt;code&gt;loop_vars&lt;/code&gt; 를 . 경우 &lt;code&gt;return_same_structure&lt;/code&gt; 이 False 인의 길이 경우, 반환 값은 텐서, TensorArray 또는 IndexedSlice입니다 &lt;code&gt;loop_vars&lt;/code&gt; 은 1, 또는 목록이 없습니다.</target>
        </trans-unit>
        <trans-unit id="0bda5fbd6b0783b500c1218ac7c4c0e7746a4905" translate="yes" xml:space="preserve">
          <source>The output tensors for the loop variables after the loop. The return value has the same structure as &lt;code&gt;loop_vars&lt;/code&gt;.</source>
          <target state="translated">루프 뒤의 루프 변수에 대한 출력 텐서. 리턴 값은 &lt;code&gt;loop_vars&lt;/code&gt; 와 동일한 구조를 갖습니다 .</target>
        </trans-unit>
        <trans-unit id="5a54d6c5881e40fdc200259b55b1119a1261f8a4" translate="yes" xml:space="preserve">
          <source>The output type (&lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt;). Default is &lt;a href=&quot;../tf#int32&quot;&gt;&lt;code&gt;tf.int32&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The output type ( &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt; ). Default is &lt;a href=&quot;../tf#int32&quot;&gt; &lt;code&gt;tf.int32&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="abf2d0fef772f974b83b58a081ba47917d2e0a4c" translate="yes" xml:space="preserve">
          <source>The output will be a 3x2 matrix:</source>
          <target state="translated">The output will be a 3x2 matrix:</target>
        </trans-unit>
        <trans-unit id="1bcada90c4c3eacc21413e8c1e200a0e90b07ffc" translate="yes" xml:space="preserve">
          <source>The output will then have shape &lt;code&gt;(32, 10, 32)&lt;/code&gt;.</source>
          <target state="translated">그러면 출력은 shape &lt;code&gt;(32, 10, 32)&lt;/code&gt; 됩니다.</target>
        </trans-unit>
        <trans-unit id="6d23cb786d0f9d1271884eaa7c1f7cc8c8a656c8" translate="yes" xml:space="preserve">
          <source>The output will then have shape &lt;code&gt;(32, 10, 8)&lt;/code&gt;.</source>
          <target state="translated">그러면 출력은 shape &lt;code&gt;(32, 10, 8)&lt;/code&gt; 됩니다.</target>
        </trans-unit>
        <trans-unit id="95238fe986246430e838c38242139b3ddafc69a1" translate="yes" xml:space="preserve">
          <source>The output(s) of the model. See Functional API example below.</source>
          <target state="translated">The output(s) of the model. See Functional API example below.</target>
        </trans-unit>
        <trans-unit id="25ae41f4c527c0741341a2f8b321fd1e43f0f98b" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt; and &lt;code&gt;seed&lt;/code&gt;.</source>
          <target state="translated">The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt; and &lt;code&gt;seed&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="179a09c09a45e5c62e2dec3d73d951ec617567f3" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, &lt;code&gt;counts&lt;/code&gt;, and &lt;code&gt;probs&lt;/code&gt;.</source>
          <target state="translated">The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt; , &lt;code&gt;seed&lt;/code&gt; , &lt;code&gt;counts&lt;/code&gt; , and &lt;code&gt;probs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d94bca360c8d84e96136112086d8b12a0b843587" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, &lt;code&gt;minval&lt;/code&gt;, and &lt;code&gt;maxval&lt;/code&gt;.</source>
          <target state="translated">The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt; , &lt;code&gt;seed&lt;/code&gt; , &lt;code&gt;minval&lt;/code&gt; , and &lt;code&gt;maxval&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="94289abe2083c6f7cb75f0c826a60167f1e5c8a7" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, and &lt;code&gt;alpha&lt;/code&gt;.</source>
          <target state="translated">The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt; , &lt;code&gt;seed&lt;/code&gt; , and &lt;code&gt;alpha&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="228f72119b53e369b51ce6a29a98f2313a7f281f" translate="yes" xml:space="preserve">
          <source>The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;seed&lt;/code&gt;, and &lt;code&gt;lam&lt;/code&gt;.</source>
          <target state="translated">The outputs are a deterministic function of &lt;code&gt;shape&lt;/code&gt; , &lt;code&gt;seed&lt;/code&gt; , and &lt;code&gt;lam&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="262b53d310948dd3d4d6f3d1b24c8027dcc78d4c" translate="yes" xml:space="preserve">
          <source>The outputs from all shards are concatenated back together along their 0-th dimension.</source>
          <target state="translated">모든 샤드의 출력은 0 차원을 따라 다시 연결됩니다.</target>
        </trans-unit>
        <trans-unit id="fec5d02e1747f7a22db33ab6777959dc638f2020" translate="yes" xml:space="preserve">
          <source>The outputs of functions used as &lt;code&gt;signatures&lt;/code&gt; must either be flat lists, in which case outputs will be numbered, or a dictionary mapping string keys to &lt;code&gt;Tensor&lt;/code&gt;, in which case the keys will be used to name outputs.</source>
          <target state="translated">&lt;code&gt;signatures&lt;/code&gt; 사용되는 함수의 출력은 플랫리스트 (출력의 경우 번호가 매겨 짐) 또는 사전에 문자열 키를 &lt;code&gt;Tensor&lt;/code&gt; 에 매핑해야 하며,이 경우 키를 사용하여 출력의 이름을 지정합니다.</target>
        </trans-unit>
        <trans-unit id="3777ae82c580b33611793d1c79fb38091c169efb" translate="yes" xml:space="preserve">
          <source>The package that this class belongs to.</source>
          <target state="translated">The package that this class belongs to.</target>
        </trans-unit>
        <trans-unit id="f4fe37226e907ad6b84032ccb7a1a60c428d9656" translate="yes" xml:space="preserve">
          <source>The padded size of each dimension D of the output is:</source>
          <target state="translated">출력의 각 차원 D의 패딩 크기는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="a3493bda610bfabe1d614c17be7bea5bab6bc509" translate="yes" xml:space="preserve">
          <source>The padding algorithm, must be &quot;SAME&quot; or &quot;VALID&quot;. Defaults to &quot;SAME&quot;. See the &quot;returns&quot; section of &lt;a href=&quot;convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">The padding algorithm, must be &quot;SAME&quot; or &quot;VALID&quot;. Defaults to &quot;SAME&quot;. See the &quot;returns&quot; section of &lt;a href=&quot;convolution&quot;&gt; &lt;code&gt;tf.nn.convolution&lt;/code&gt; &lt;/a&gt; for details.</target>
        </trans-unit>
        <trans-unit id="94a793cb35afefaa9825726cef177d5eba1c0835" translate="yes" xml:space="preserve">
          <source>The padding algorithm, must be &quot;SAME&quot; or &quot;VALID&quot;. See the &quot;returns&quot; section of &lt;a href=&quot;../../../nn/convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">The padding algorithm, must be &quot;SAME&quot; or &quot;VALID&quot;. See the &quot;returns&quot; section of &lt;a href=&quot;../../../nn/convolution&quot;&gt; &lt;code&gt;tf.nn.convolution&lt;/code&gt; &lt;/a&gt; for details.</target>
        </trans-unit>
        <trans-unit id="82cf1bc0ef022c1c7dcb21d0cd3cf77bf756e7b4" translate="yes" xml:space="preserve">
          <source>The paper demonstrates the performance of MobileNets using &lt;code&gt;alpha&lt;/code&gt; values of 1.0 (also called 100 % MobileNet), 0.35, 0.5, 0.75, 1.0, 1.3, and 1.4 For each of these &lt;code&gt;alpha&lt;/code&gt; values, weights for 5 different input image sizes are provided (224, 192, 160, 128, and 96).</source>
          <target state="translated">The paper demonstrates the performance of MobileNets using &lt;code&gt;alpha&lt;/code&gt; values of 1.0 (also called 100 % MobileNet), 0.35, 0.5, 0.75, 1.0, 1.3, and 1.4 For each of these &lt;code&gt;alpha&lt;/code&gt; values, weights for 5 different input image sizes are provided (224, 192, 160, 128, and 96).</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
