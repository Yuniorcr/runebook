<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="07d5b7b8864997727d8fb01740ad8b9e08b14f5f" translate="yes" xml:space="preserve">
          <source>The paper demonstrates the performance of MobileNets using &lt;code&gt;alpha&lt;/code&gt; values of 1.0 (also called 100 % MobileNet), 0.75, 0.5 and 0.25. For each of these &lt;code&gt;alpha&lt;/code&gt; values, weights for 4 different input image sizes are provided (224, 192, 160, 128).</source>
          <target state="translated">The paper demonstrates the performance of MobileNets using &lt;code&gt;alpha&lt;/code&gt; values of 1.0 (also called 100 % MobileNet), 0.75, 0.5 and 0.25. For each of these &lt;code&gt;alpha&lt;/code&gt; values, weights for 4 different input image sizes are provided (224, 192, 160, 128).</target>
        </trans-unit>
        <trans-unit id="d91e185b3ec2b95e4e28b058fb7de6ed54c4f63d" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;concentration&lt;/code&gt; and &lt;code&gt;rate&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g. &lt;code&gt;concentration + rate&lt;/code&gt; is a valid operation).</source>
          <target state="translated">매개 변수 &lt;code&gt;concentration&lt;/code&gt; 및 &lt;code&gt;rate&lt;/code&gt; 는 방송을 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;concentration + rate&lt;/code&gt; 는 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="c4bf0f9162b85380657aa85a48762d0989942eac" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;df&lt;/code&gt;, &lt;code&gt;loc&lt;/code&gt;, and &lt;code&gt;scale&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g. &lt;code&gt;df + loc + scale&lt;/code&gt; is a valid operation).</source>
          <target state="translated">매개 변수 &lt;code&gt;df&lt;/code&gt; , &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 은 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;df + loc + scale&lt;/code&gt; 은 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="f624db393a0283cdff3712a3c4bd723d749a30a5" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g. &lt;code&gt;loc + scale&lt;/code&gt; is a valid operation).</source>
          <target state="translated">매개 변수 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 은 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;loc + scale&lt;/code&gt; 은 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="a2bb7ef60bf0239928d550799fd1318ab8a8e22c" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g., &lt;code&gt;loc / scale&lt;/code&gt; is a valid operation).</source>
          <target state="translated">파라미터 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 은 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;loc / scale&lt;/code&gt; 은 유효한 작업입니다).</target>
        </trans-unit>
        <trans-unit id="caea2d657314fc74a3b4c82a6b1a8e2927d4e265" translate="yes" xml:space="preserve">
          <source>The parameters &lt;code&gt;low&lt;/code&gt; and &lt;code&gt;high&lt;/code&gt; must be shaped in a way that supports broadcasting (e.g., &lt;code&gt;high - low&lt;/code&gt; is a valid operation).</source>
          <target state="translated">&lt;code&gt;low&lt;/code&gt; 및 &lt;code&gt;high&lt;/code&gt; 매개 변수 는 브로드 캐스트를 지원하는 방식으로 형성되어야합니다 (예 : &lt;code&gt;high - low&lt;/code&gt; 이 유효한 작업).</target>
        </trans-unit>
        <trans-unit id="2da0524f5e34c476f58d52fd7e4bbaca30e3840a" translate="yes" xml:space="preserve">
          <source>The parameters apply to and only to the immediately enclosing loop. It only has effect if the loop is staged as a TF while_loop; otherwise the parameters have no effect.</source>
          <target state="translated">The parameters apply to and only to the immediately enclosing loop. It only has effect if the loop is staged as a TF while_loop; otherwise the parameters have no effect.</target>
        </trans-unit>
        <trans-unit id="f861e09ace62d9cf6a436ce61f90b0514dff3612" translate="yes" xml:space="preserve">
          <source>The parameters can be intuited via their relationship to mean and stddev,</source>
          <target state="translated">매개 변수는 mean 및 stddev와의 관계를 통해 직관 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="78832ff2cd51fc67f3284e123b0a8c7a1096d66b" translate="yes" xml:space="preserve">
          <source>The parent could be a module when the child is a function at module scope. Or the parent could be a class when a class' method is being replaced. The named child is set to new_child, while the prior definition is saved away for later, when UnsetAll() is called.</source>
          <target state="translated">자식이 모듈 범위에서 함수일 때 부모는 모듈 일 수 있습니다. 또는 클래스의 메서드를 교체 할 때 부모가 클래스가 될 수 있습니다. 명명 된 자식은 new_child로 설정되고 UnsetAll ()이 호출 될 때 이전 정의는 나중에 저장됩니다.</target>
        </trans-unit>
        <trans-unit id="cc13d476090ccb6ba884188ddcc28a81f62b0726" translate="yes" xml:space="preserve">
          <source>The parse() method checks to make sure that the string argument is a legal value and convert it to a native type. If the value cannot be converted, it should throw a 'ValueError' exception with a human readable explanation of why the value is illegal.</source>
          <target state="translated">parse () 메서드는 문자열 인수가 올바른 값인지 확인하고 기본 형식으로 변환합니다. 값을 변환 할 수 없으면 값이 잘못된 이유에 대한 사람이 읽을 수있는 설명과 함께 'ValueError'예외가 발생해야합니다.</target>
        </trans-unit>
        <trans-unit id="cf0794be97523b0be42896e118da1be5a61ff4da" translate="yes" xml:space="preserve">
          <source>The parsed value in native type.</source>
          <target state="translated">기본 유형의 구문 분석 된 값입니다.</target>
        </trans-unit>
        <trans-unit id="8cff8c184992ecf7d79d6a190fc8e2ad81b8dd10" translate="yes" xml:space="preserve">
          <source>The partitioned embedding in &lt;code&gt;embedding_weights&lt;/code&gt; must all be the same shape except for the first dimension. The first dimension is allowed to vary as the vocabulary size is not necessarily a multiple of &lt;code&gt;P&lt;/code&gt;. &lt;code&gt;embedding_weights&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../compat/v1/get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">분할에 매립 &lt;code&gt;embedding_weights&lt;/code&gt; 는 모든 제 치수 제외한 같은 형상이어야한다. 어휘 크기가 반드시 &lt;code&gt;P&lt;/code&gt; 의 배수 일 필요는 없으므로 첫 번째 차원을 변경할 수 있습니다 . &lt;code&gt;embedding_weights&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../compat/v1/get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="8e157288a667a186f035deba918682c801fa1abf" translate="yes" xml:space="preserve">
          <source>The partitioned embedding in &lt;code&gt;embedding_weights&lt;/code&gt; must all be the same shape except for the first dimension. The first dimension is allowed to vary as the vocabulary size is not necessarily a multiple of &lt;code&gt;P&lt;/code&gt;. &lt;code&gt;embedding_weights&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">분할에 매립 &lt;code&gt;embedding_weights&lt;/code&gt; 는 모든 제 치수 제외한 같은 형상이어야한다. 어휘 크기가 반드시 &lt;code&gt;P&lt;/code&gt; 의 배수 일 필요는 없으므로 첫 번째 차원을 변경할 수 있습니다 . &lt;code&gt;embedding_weights&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="1549f14314cb2911099be0c08464c7d5489a22a6" translate="yes" xml:space="preserve">
          <source>The partitioned embedding in &lt;code&gt;embedding_weights&lt;/code&gt; must all be the same shape except for the first dimension. The first dimension is allowed to vary as the vocabulary size is not necessarily a multiple of num of shards.</source>
          <target state="translated">The partitioned embedding in &lt;code&gt;embedding_weights&lt;/code&gt; must all be the same shape except for the first dimension. The first dimension is allowed to vary as the vocabulary size is not necessarily a multiple of num of shards.</target>
        </trans-unit>
        <trans-unit id="b3b7bcbb761db59d963bb51839f46a4b29f4af4e" translate="yes" xml:space="preserve">
          <source>The path is relative to tensorflow/</source>
          <target state="translated">경로는 tensorflow /</target>
        </trans-unit>
        <trans-unit id="f48baa97e568a9b9e3b5f52a6ab7e866fecd8550" translate="yes" xml:space="preserve">
          <source>The path of the output proto file.</source>
          <target state="translated">출력 프로토 파일의 경로입니다.</target>
        </trans-unit>
        <trans-unit id="ee14c49610bbef1394c243e137f1c0c32f1960be" translate="yes" xml:space="preserve">
          <source>The path to a directory in which to write checkpoints. A special file named &quot;checkpoint&quot; is also written to this directory (in a human-readable text format) which contains the state of the &lt;code&gt;CheckpointManager&lt;/code&gt;.</source>
          <target state="translated">The path to a directory in which to write checkpoints. A special file named &quot;checkpoint&quot; is also written to this directory (in a human-readable text format) which contains the state of the &lt;code&gt;CheckpointManager&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b3d2248f6c5ba1b79f5657059376b70c88f9d6c1" translate="yes" xml:space="preserve">
          <source>The path to an event file created by a &lt;code&gt;SummaryWriter&lt;/code&gt;.</source>
          <target state="translated">The path to an event file created by a &lt;code&gt;SummaryWriter&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a7713229c9d7bf490b65513fab0d07d2cad4f51" translate="yes" xml:space="preserve">
          <source>The path to the TFRecords file.</source>
          <target state="translated">The path to the TFRecords file.</target>
        </trans-unit>
        <trans-unit id="84c5edf8f8528c6dcc19dfeb36d929c09dc91f28" translate="yes" xml:space="preserve">
          <source>The path to the checkpoint as returned by &lt;code&gt;write&lt;/code&gt;.</source>
          <target state="translated">The path to the checkpoint as returned by &lt;code&gt;write&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b8030756c5c759c44f9f3cb2091477d30b127210" translate="yes" xml:space="preserve">
          <source>The path to the checkpoint, as returned by &lt;code&gt;save&lt;/code&gt; or &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt;&lt;code&gt;tf.train.latest_checkpoint&lt;/code&gt;&lt;/a&gt;. If None (as when there is no latest checkpoint for &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt;&lt;code&gt;tf.train.latest_checkpoint&lt;/code&gt;&lt;/a&gt; to return), returns an object which may run initializers for objects in the dependency graph. If the checkpoint was written by the name-based &lt;a href=&quot;saver&quot;&gt;&lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt;&lt;/a&gt;, names are used to match variables.</source>
          <target state="translated">The path to the checkpoint, as returned by &lt;code&gt;save&lt;/code&gt; or &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt; &lt;code&gt;tf.train.latest_checkpoint&lt;/code&gt; &lt;/a&gt;. If None (as when there is no latest checkpoint for &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt; &lt;code&gt;tf.train.latest_checkpoint&lt;/code&gt; &lt;/a&gt; to return), returns an object which may run initializers for objects in the dependency graph. If the checkpoint was written by the name-based &lt;a href=&quot;saver&quot;&gt; &lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt; &lt;/a&gt;, names are used to match variables.</target>
        </trans-unit>
        <trans-unit id="7d9bb46d11e0a3efc649638be0d00aa480e84e55" translate="yes" xml:space="preserve">
          <source>The path to the checkpoint, as returned by &lt;code&gt;save&lt;/code&gt; or &lt;a href=&quot;latest_checkpoint&quot;&gt;&lt;code&gt;tf.train.latest_checkpoint&lt;/code&gt;&lt;/a&gt;. If the checkpoint was written by the name-based &lt;a href=&quot;../compat/v1/train/saver&quot;&gt;&lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt;&lt;/a&gt;, names are used to match variables.</source>
          <target state="translated">The path to the checkpoint, as returned by &lt;code&gt;save&lt;/code&gt; or &lt;a href=&quot;latest_checkpoint&quot;&gt; &lt;code&gt;tf.train.latest_checkpoint&lt;/code&gt; &lt;/a&gt;. If the checkpoint was written by the name-based &lt;a href=&quot;../compat/v1/train/saver&quot;&gt; &lt;code&gt;tf.compat.v1.train.Saver&lt;/code&gt; &lt;/a&gt;, names are used to match variables.</target>
        </trans-unit>
        <trans-unit id="d3c8f8b6fd3cf107eb955208c8e6315d0e1a6163" translate="yes" xml:space="preserve">
          <source>The path to the exported directory as a bytes object.</source>
          <target state="translated">The path to the exported directory as a bytes object.</target>
        </trans-unit>
        <trans-unit id="2c6d384388d19ed3fa790b1769ea860a0e6be8d0" translate="yes" xml:space="preserve">
          <source>The path to the new checkpoint. It is also recorded in the &lt;code&gt;checkpoints&lt;/code&gt; and &lt;code&gt;latest_checkpoint&lt;/code&gt; properties.</source>
          <target state="translated">새 체크 포인트의 경로입니다. &lt;code&gt;checkpoints&lt;/code&gt; 및 &lt;code&gt;latest_checkpoint&lt;/code&gt; 속성 에도 기록됩니다 .</target>
        </trans-unit>
        <trans-unit id="995443700e473d68dc872f5c69aa35e966bca809" translate="yes" xml:space="preserve">
          <source>The path to the new checkpoint. It is also recorded in the &lt;code&gt;checkpoints&lt;/code&gt; and &lt;code&gt;latest_checkpoint&lt;/code&gt; properties. &lt;code&gt;None&lt;/code&gt; if no checkpoint is saved.</source>
          <target state="translated">The path to the new checkpoint. It is also recorded in the &lt;code&gt;checkpoints&lt;/code&gt; and &lt;code&gt;latest_checkpoint&lt;/code&gt; properties. &lt;code&gt;None&lt;/code&gt; if no checkpoint is saved.</target>
        </trans-unit>
        <trans-unit id="0ee0e0b9b831848f3b4065f81ba73b2d7593c0f8" translate="yes" xml:space="preserve">
          <source>The path to the specified file present in the data attribute of py_test or py_binary.</source>
          <target state="translated">py_test 또는 py_binary의 데이터 속성에 지정된 파일의 경로입니다.</target>
        </trans-unit>
        <trans-unit id="c28b39685fa19f5fe1fe963ce50d396e16dbe87f" translate="yes" xml:space="preserve">
          <source>The path to the specified file present in the data attribute of py_test or py_binary. Falls back to returning the same as get_data_files_path if it fails to detect a bazel runfiles directory.</source>
          <target state="translated">py_test 또는 py_binary의 데이터 속성에 지정된 파일의 경로입니다. bazel runfiles 디렉토리를 감지하지 못하면 get_data_files_path와 동일하게 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="87756ef48ceb2a46a88324fa1e20a23d5ed02a12" translate="yes" xml:space="preserve">
          <source>The path to which the SavedModel protocol buffer was written.</source>
          <target state="translated">SavedModel 프로토콜 버퍼가 작성된 경로입니다.</target>
        </trans-unit>
        <trans-unit id="8be5bab78d1909543ad9986a84ecdbc0832b8254" translate="yes" xml:space="preserve">
          <source>The path to which the SavedModel will be stored.</source>
          <target state="translated">The path to which the SavedModel will be stored.</target>
        </trans-unit>
        <trans-unit id="0dab2a06ad633869bd90e943c4184ac0e2fe54a0" translate="yes" xml:space="preserve">
          <source>The pattern follows the re2 syntax (&lt;a href=&quot;https://github.com/google/re2/wiki/Syntax&quot;&gt;https://github.com/google/re2/wiki/Syntax&lt;/a&gt;)</source>
          <target state="translated">The pattern follows the re2 syntax (&lt;a href=&quot;https://github.com/google/re2/wiki/Syntax&quot;&gt;https://github.com/google/re2/wiki/Syntax&lt;/a&gt;)</target>
        </trans-unit>
        <trans-unit id="c7281e72ad08903abeb2bd587c7c0dfd0d8772e6" translate="yes" xml:space="preserve">
          <source>The pattern follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)</source>
          <target state="translated">패턴은 re2 구문 (https://github.com/google/re2/wiki/Syntax)을 따릅니다.</target>
        </trans-unit>
        <trans-unit id="6073374fbdf4fdacc0b93351a02133e64c1915d8" translate="yes" xml:space="preserve">
          <source>The patterns are defined as strings. Supported patterns are defined here. Note that the pattern can be a Python iteratable of string patterns.</source>
          <target state="translated">The patterns are defined as strings. Supported patterns are defined here. Note that the pattern can be a Python iteratable of string patterns.</target>
        </trans-unit>
        <trans-unit id="5c52ca33f774b534fe80a4db87092be76893e002" translate="yes" xml:space="preserve">
          <source>The peephole implementation is based on:</source>
          <target state="translated">들여다 보는 구멍 구현은 다음을 기반으로합니다.</target>
        </trans-unit>
        <trans-unit id="baf8710cc0a85723dd8aa2526d303f0863e63136" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorAdjoint&lt;/code&gt; depends on the underlying operators performance.</source>
          <target state="translated">&lt;code&gt;LinearOperatorAdjoint&lt;/code&gt; 의 성능은 기본 연산자 성능에 따라 다릅니다.</target>
        </trans-unit>
        <trans-unit id="80d488d70fd1fbe1594d7c6c118ae3795bd1145d" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorBlockDiag&lt;/code&gt; on any operation is equal to the sum of the individual operators' operations.</source>
          <target state="translated">모든 작업 에서 &lt;code&gt;LinearOperatorBlockDiag&lt;/code&gt; 의 성능은 개별 운영자 작업의 합계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="9b2ab24a37ac3d66ce6ff090c15ce4c8f5b1d480" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorComposition&lt;/code&gt; on any operation is equal to the sum of the individual operators' operations.</source>
          <target state="translated">모든 작업 에서 &lt;code&gt;LinearOperatorComposition&lt;/code&gt; 의 성능은 개별 연산자 작업의 합계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="f94bad31467a9ea9f4b4d537674d8e77b0cf1a22" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorInversion&lt;/code&gt; depends on the underlying operators performance: &lt;code&gt;solve&lt;/code&gt; and &lt;code&gt;matmul&lt;/code&gt; are swapped, and determinant is inverted.</source>
          <target state="translated">&lt;code&gt;LinearOperatorInversion&lt;/code&gt; 의 성능은 기본 연산자 성능에 따라 다릅니다. &lt;code&gt;solve&lt;/code&gt; 및 &lt;code&gt;matmul&lt;/code&gt; 이 스왑되고 결정자가 반전됩니다.</target>
        </trans-unit>
        <trans-unit id="bc0efd32d22cd6d37162492744eb9c09073101ec" translate="yes" xml:space="preserve">
          <source>The performance of &lt;code&gt;LinearOperatorKronecker&lt;/code&gt; on any operation is equal to the sum of the individual operators' operations.</source>
          <target state="translated">모든 작업 에서 &lt;code&gt;LinearOperatorKronecker&lt;/code&gt; 의 성능은 개별 운영자 작업의 합계와 같습니다.</target>
        </trans-unit>
        <trans-unit id="3adcc83502b5bf35b4db3b88505bc6feb67f24c9" translate="yes" xml:space="preserve">
          <source>The polygamma function is defined as:</source>
          <target state="translated">폴리 감마 함수는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="58805a4c695a0c84e281d698b93c5605de911e7d" translate="yes" xml:space="preserve">
          <source>The port the TensorFlow server is listening on.</source>
          <target state="translated">The port the TensorFlow server is listening on.</target>
        </trans-unit>
        <trans-unit id="278a092ca102f6f63192c91f543df0b76f86bf53" translate="yes" xml:space="preserve">
          <source>The position where padding or truncation happens is determined by the arguments &lt;code&gt;padding&lt;/code&gt; and &lt;code&gt;truncating&lt;/code&gt;, respectively. Pre-padding or removing values from the beginning of the sequence is the default.</source>
          <target state="translated">The position where padding or truncation happens is determined by the arguments &lt;code&gt;padding&lt;/code&gt; and &lt;code&gt;truncating&lt;/code&gt; , respectively. Pre-padding or removing values from the beginning of the sequence is the default.</target>
        </trans-unit>
        <trans-unit id="9d524ae593bfca1cec825db026e283842ef95ed3" translate="yes" xml:space="preserve">
          <source>The possible number of labels the classification task can have. If this value is not provided, it will be calculated using both predictions and labels array.</source>
          <target state="translated">The possible number of labels the classification task can have. If this value is not provided, it will be calculated using both predictions and labels array.</target>
        </trans-unit>
        <trans-unit id="8efb3a74fd166658f111b04a0c0279818ee74864" translate="yes" xml:space="preserve">
          <source>The possible number of labels the prediction task can have. This value must be provided, since a confusion matrix of dimension = [num_classes, num_classes] will be allocated.</source>
          <target state="translated">The possible number of labels the prediction task can have. This value must be provided, since a confusion matrix of dimension = [num_classes, num_classes] will be allocated.</target>
        </trans-unit>
        <trans-unit id="3e0a01897541e4cc7358dd44c0abef35501aae05" translate="yes" xml:space="preserve">
          <source>The possible number of labels the prediction task can have. This value must be provided, since two variables with shape = [num_classes] will be allocated.</source>
          <target state="translated">The possible number of labels the prediction task can have. This value must be provided, since two variables with shape = [num_classes] will be allocated.</target>
        </trans-unit>
        <trans-unit id="692359d83812b544d928c04fadf8b5c3c2df67a0" translate="yes" xml:space="preserve">
          <source>The possible values are: &lt;code&gt;GATE_NONE&lt;/code&gt;, &lt;code&gt;GATE_OP&lt;/code&gt;, and &lt;code&gt;GATE_GRAPH&lt;/code&gt;.</source>
          <target state="translated">가능한 값은 &lt;code&gt;GATE_NONE&lt;/code&gt; , &lt;code&gt;GATE_OP&lt;/code&gt; 및 &lt;code&gt;GATE_GRAPH&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="d5d3e18deacf1c7ef93bee6d5b865603caff1a2a" translate="yes" xml:space="preserve">
          <source>The potentially support list contains a list of ops that are partially or fully supported, which is derived by simply scanning op names to check whether they can be handled without real conversion and specific parameters.</source>
          <target state="translated">잠재적으로 지원되는 목록에는 부분적으로 또는 완전히 지원되는 op 목록이 포함되어 있습니다. op 목록을 검색하여 실제 변환 및 특정 매개 변수없이 처리 할 수 ​​있는지 여부를 확인하면됩니다.</target>
        </trans-unit>
        <trans-unit id="7c853ad9a21d66e7bd6fdc646ae396c38787f2e0" translate="yes" xml:space="preserve">
          <source>The predicted outputs, a tensor of size &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt; where N+1 is the total number of dimensions in &lt;code&gt;predictions&lt;/code&gt;.</source>
          <target state="translated">The predicted outputs, a tensor of size &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt; where N+1 is the total number of dimensions in &lt;code&gt;predictions&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f104bcdd7d5f421504142d2c94d5f8c62a0e743f" translate="yes" xml:space="preserve">
          <source>The predicted outputs.</source>
          <target state="translated">The predicted outputs.</target>
        </trans-unit>
        <trans-unit id="a70f131e2a7ce29596591e28a1cfededaebaff6a" translate="yes" xml:space="preserve">
          <source>The predicted values, a &lt;code&gt;Tensor&lt;/code&gt; of any shape.</source>
          <target state="translated">The predicted values, a &lt;code&gt;Tensor&lt;/code&gt; of any shape.</target>
        </trans-unit>
        <trans-unit id="6728a30c6037094fe5c0a9ed3f50b7de76aa2e0d" translate="yes" xml:space="preserve">
          <source>The predicted values, a &lt;code&gt;Tensor&lt;/code&gt; of arbitrary dimensions. Will be cast to &lt;code&gt;bool&lt;/code&gt;.</source>
          <target state="translated">The predicted values, a &lt;code&gt;Tensor&lt;/code&gt; of arbitrary dimensions. Will be cast to &lt;code&gt;bool&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="71f7a8826bad533ae16d312cbce730009c206751" translate="yes" xml:space="preserve">
          <source>The predicted values.</source>
          <target state="translated">예측 된 값.</target>
        </trans-unit>
        <trans-unit id="c4778ceab3533971f6aa86d7a9cab9cffa7b4ebb" translate="yes" xml:space="preserve">
          <source>The predicted values. Each element must be in the range &lt;code&gt;[0, 1]&lt;/code&gt;.</source>
          <target state="translated">The predicted values. Each element must be in the range &lt;code&gt;[0, 1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="86f018a513047301d5f31c33cb992832bb0aa35d" translate="yes" xml:space="preserve">
          <source>The predicted values. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt;</source>
          <target state="translated">The predicted values. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e9916875b88168e8e1d45339b98305ac670cab32" translate="yes" xml:space="preserve">
          <source>The predicted values. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt;.</source>
          <target state="translated">The predicted values. shape = &lt;code&gt;[batch_size, d0, .. dN]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="350857c387e91589b30efc773f0aa8bb73f1dd8b" translate="yes" xml:space="preserve">
          <source>The prediction values.</source>
          <target state="translated">The prediction values.</target>
        </trans-unit>
        <trans-unit id="22221eb5e9024f9d30d6d77902385bdae34280a3" translate="yes" xml:space="preserve">
          <source>The prefix of a V1 or V2 checkpoint. Typically the result of &lt;code&gt;Saver.save()&lt;/code&gt; or that of &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt;&lt;code&gt;tf.train.latest_checkpoint()&lt;/code&gt;&lt;/a&gt;, regardless of sharded/non-sharded or V1/V2.</source>
          <target state="translated">The prefix of a V1 or V2 checkpoint. Typically the result of &lt;code&gt;Saver.save()&lt;/code&gt; or that of &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt; &lt;code&gt;tf.train.latest_checkpoint()&lt;/code&gt; &lt;/a&gt;, regardless of sharded/non-sharded or V1/V2.</target>
        </trans-unit>
        <trans-unit id="aaf184bbd1e736ec9f0efcfa8ff77fd74b286f9f" translate="yes" xml:space="preserve">
          <source>The prefix of the most recent checkpoint in &lt;code&gt;directory&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;directory&lt;/code&gt; 에서 가장 최근의 검사 점의 접두사 .</target>
        </trans-unit>
        <trans-unit id="0e79e9868436b7bc9300626a15307ccf5673bf8d" translate="yes" xml:space="preserve">
          <source>The prefix to use on all names created within the name scope.</source>
          <target state="translated">The prefix to use on all names created within the name scope.</target>
        </trans-unit>
        <trans-unit id="43a7df5de41d0edab56a0d1dc85f3a8f7b95e198" translate="yes" xml:space="preserve">
          <source>The primary case where you need extra work to support mixed precision or float64 is when you create a new tensor, such as with &lt;a href=&quot;../../../ones&quot;&gt;&lt;code&gt;tf.ones&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt;. In such cases, you must create the tensor of the correct dtype. For example, suppose you modify the &lt;code&gt;MyDense&lt;/code&gt; layer to add a random number to the output using &lt;a href=&quot;../../../random/normal&quot;&gt;&lt;code&gt;tf.random.normal&lt;/code&gt;&lt;/a&gt;. You must pass the input dtype to &lt;a href=&quot;../../../random/normal&quot;&gt;&lt;code&gt;tf.random.normal&lt;/code&gt;&lt;/a&gt; to ensure the dtypes match.</source>
          <target state="translated">The primary case where you need extra work to support mixed precision or float64 is when you create a new tensor, such as with &lt;a href=&quot;../../../ones&quot;&gt; &lt;code&gt;tf.ones&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;../../../constant&quot;&gt; &lt;code&gt;tf.constant&lt;/code&gt; &lt;/a&gt;. In such cases, you must create the tensor of the correct dtype. For example, suppose you modify the &lt;code&gt;MyDense&lt;/code&gt; layer to add a random number to the output using &lt;a href=&quot;../../../random/normal&quot;&gt; &lt;code&gt;tf.random.normal&lt;/code&gt; &lt;/a&gt;. You must pass the input dtype to &lt;a href=&quot;../../../random/normal&quot;&gt; &lt;code&gt;tf.random.normal&lt;/code&gt; &lt;/a&gt; to ensure the dtypes match.</target>
        </trans-unit>
        <trans-unit id="70445e39cb7672ad4a6b06501270c1f13979a70f" translate="yes" xml:space="preserve">
          <source>The primary use case for this API is to put tensors in a set/dictionary. We can't put tensors in a set/dictionary as &lt;code&gt;tensor.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</source>
          <target state="translated">The primary use case for this API is to put tensors in a set/dictionary. We can't put tensors in a set/dictionary as &lt;code&gt;tensor.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</target>
        </trans-unit>
        <trans-unit id="b0c5bb1e4f98a69939280a641cea06563cef1412" translate="yes" xml:space="preserve">
          <source>The primary use case for this API is to put variables in a set/dictionary. We can't put variables in a set/dictionary as &lt;code&gt;variable.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</source>
          <target state="translated">The primary use case for this API is to put variables in a set/dictionary. We can't put variables in a set/dictionary as &lt;code&gt;variable.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</target>
        </trans-unit>
        <trans-unit id="0cdbe0557abf05d8c31ba3846734c76d96d3bcc3" translate="yes" xml:space="preserve">
          <source>The primary usecase for this API is to put tensors in a set/dictionary. We can't put tensors in a set/dictionary as &lt;code&gt;tensor.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</source>
          <target state="translated">이 API의 기본 사용 사례는 텐서를 세트 / 사전에 배치하는 것입니다. &lt;code&gt;tensor.__hash__()&lt;/code&gt; 는 더 이상 Tensorflow 2.0부터 사용할 수 없으므로 세트 / 사전에 텐서를 넣을 수 없습니다 .</target>
        </trans-unit>
        <trans-unit id="14c5ca1e155e62f217839df947a76604aa7befe7" translate="yes" xml:space="preserve">
          <source>The primary usecase for this API is to put variables in a set/dictionary. We can't put variables in a set/dictionary as &lt;code&gt;variable.__hash__()&lt;/code&gt; is no longer available starting Tensorflow 2.0.</source>
          <target state="translated">이 API의 주요 사용 사례는 변수를 세트 / 사전에 넣는 것입니다. 변수를 set / dictionary에 넣을 수 없으므로 &lt;code&gt;variable.__hash__()&lt;/code&gt; 는 더 이상 Tensorflow 2.0부터 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="bfffea38233a7f94cfc568cf11eefdfb38392417" translate="yes" xml:space="preserve">
          <source>The probability density function (pdf) is,</source>
          <target state="translated">확률 밀도 함수 (pdf)는</target>
        </trans-unit>
        <trans-unit id="d639692ffbb24f5fe23fd0cf8f29f9ea56836d74" translate="yes" xml:space="preserve">
          <source>The probability density function (pdf) of this distribution is,</source>
          <target state="translated">이 분포의 확률 밀도 함수 (pdf)는</target>
        </trans-unit>
        <trans-unit id="c2092fccabcd3a2abdef73412d545365899001b8" translate="yes" xml:space="preserve">
          <source>The probability mass function (pmf) is,</source>
          <target state="translated">확률 질량 함수 (pmf)는</target>
        </trans-unit>
        <trans-unit id="331d712cc96a7cb254a89657cf4ba910cc781864" translate="yes" xml:space="preserve">
          <source>The processing of each sample contains the following steps:</source>
          <target state="translated">The processing of each sample contains the following steps:</target>
        </trans-unit>
        <trans-unit id="b1597763a35d57db9c807276fa76fead0e6bf3d7" translate="yes" xml:space="preserve">
          <source>The processing of each sample contains the following steps: 1) standardize each sample (usually lowercasing + punctuation stripping) 2) split each sample into substrings (usually words) 3) recombine substrings into tokens (usually ngrams) 4) index tokens (associate a unique int value with each token) 5) transform each sample using this index, either into a vector of ints or a dense float vector.</source>
          <target state="translated">각 샘플의 처리에는 다음 단계가 포함됩니다. 1) 각 샘플 표준화 (일반적으로 소문자 + 구두점 제거) 2) 각 샘플을 하위 문자열 (일반적으로 단어)로 분할 3) 하위 문자열을 토큰 (일반적으로 ngram)으로 재결합 4) 인덱스 토큰 ( 각 토큰으로 고유 한 int 값) 5)이 인덱스를 사용하여 각 샘플을 정수 벡터 또는 밀도가 높은 부동 벡터로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="bc3e043e3089ab9c2cc2954b166a1bf6364579df" translate="yes" xml:space="preserve">
          <source>The profiler server will exit when the process finishes. The service is defined in tensorflow/core/profiler/profiler_service.proto.</source>
          <target state="translated">The profiler server will exit when the process finishes. The service is defined in tensorflow/core/profiler/profiler_service.proto.</target>
        </trans-unit>
        <trans-unit id="e67a4435185658688f7c2b52360cda7ea81a0d75" translate="yes" xml:space="preserve">
          <source>The profiler session will be stopped and profile results can be saved.</source>
          <target state="translated">The profiler session will be stopped and profile results can be saved.</target>
        </trans-unit>
        <trans-unit id="ddcf3e7dfeb12410a9d6122f19a6f9f6186a333b" translate="yes" xml:space="preserve">
          <source>The protocol TensorFlow used to communicate between nodes. Defaults to 'grpc'.</source>
          <target state="translated">The protocol TensorFlow used to communicate between nodes. Defaults to 'grpc'.</target>
        </trans-unit>
        <trans-unit id="5e9c7a33590d968d1c4d2adb1f14e30ca9d6e013" translate="yes" xml:space="preserve">
          <source>The provided generator can be finite in which case the class will throw a &lt;code&gt;StopIteration&lt;/code&gt; exception.</source>
          <target state="translated">제공된 생성기는 유한 할 수 있으며이 경우 클래스에서 &lt;code&gt;StopIteration&lt;/code&gt; 예외가 발생합니다.</target>
        </trans-unit>
        <trans-unit id="8129f9559f62303b98c598e584d99bb1465d425d" translate="yes" xml:space="preserve">
          <source>The provided value can be a python boolean, a scalar boolean Tensor, or or a callable providing such a value; if a callable is passed it will be invoked on-demand to determine whether summary writing will occur.</source>
          <target state="translated">제공된 값은 파이썬 부울, 스칼라 부울 텐서 또는 이러한 값을 제공하는 호출 가능일 수 있습니다. 호출 가능 항목이 전달되면 요청시 요약 호출이 발생하는지 여부를 판별하기 위해 호출됩니다.</target>
        </trans-unit>
        <trans-unit id="d84a7589708b247ba11ef0a6241d0276fd1c0415" translate="yes" xml:space="preserve">
          <source>The pseudo-inverse of a matrix &lt;code&gt;A&lt;/code&gt;, is defined as: 'the matrix that 'solves' [the least-squares problem] &lt;code&gt;A @ x = b&lt;/code&gt;,' i.e., if &lt;code&gt;x_hat&lt;/code&gt; is a solution, then &lt;code&gt;A_pinv&lt;/code&gt; is the matrix such that &lt;code&gt;x_hat = A_pinv @ b&lt;/code&gt;. It can be shown that if &lt;code&gt;U @ Sigma @ V.T = A&lt;/code&gt; is the singular value decomposition of &lt;code&gt;A&lt;/code&gt;, then &lt;code&gt;A_pinv = V @ inv(Sigma) U^T&lt;/code&gt;. [(Strang, 1980)][1]</source>
          <target state="translated">행렬의 역행렬 &lt;code&gt;A&lt;/code&gt; 를 다음과 같이 정의한다 : &quot;매트릭스를 그 '로 해결할'[최소 제곱 문제] &lt;code&gt;A @ x = b&lt;/code&gt; '경우 즉 &lt;code&gt;x_hat&lt;/code&gt; 는 용액이고, 다음 &lt;code&gt;A_pinv&lt;/code&gt; 가 인 행렬되도록 &lt;code&gt;x_hat = A_pinv @ b&lt;/code&gt; . 이 표시 될 수있는 경우 &lt;code&gt;U @ Sigma @ V.T = A&lt;/code&gt; 의 특이 값 분해이다 다음 &lt;code&gt;A_pinv = V @ inv(Sigma) U^T&lt;/code&gt; . [(Strang, 1980)] [1] &lt;code&gt;A&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9b22641be848196f7d9c02ba6fc3610602324007" translate="yes" xml:space="preserve">
          <source>The purpose of this function is to allow users of existing layers to slowly transition to Keras layers API without breaking existing functionality.</source>
          <target state="translated">이 기능의 목적은 기존 레이어 사용자가 기존 기능을 중단하지 않고 Keras 레이어 API로 천천히 전환 할 수 있도록하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="d088d5e5d63d8b56ec540e3afc689671a1995e6f" translate="yes" xml:space="preserve">
          <source>The purpose of this scope is to allow users of existing layers to slowly transition to a Keras layers API without breaking existing functionality.</source>
          <target state="translated">이 범위의 목적은 기존 계층의 사용자가 기존 기능을 중단하지 않고 Keras 계층 API로 천천히 전환 할 수 있도록하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="7c5cb70c5a3b792465bd5ce774c8ea2af3bb85e3" translate="yes" xml:space="preserve">
          <source>The python function &lt;code&gt;fn&lt;/code&gt; will be called once with symbolic arguments specified in the &lt;code&gt;signature&lt;/code&gt;, traced, and turned into a graph function. Any variables created by &lt;code&gt;fn&lt;/code&gt; will be owned by the object returned by &lt;code&gt;wrap_function&lt;/code&gt;. The resulting graph function can be called with tensors which match the signature.</source>
          <target state="translated">python 함수 &lt;code&gt;fn&lt;/code&gt; 은 &lt;code&gt;signature&lt;/code&gt; 에 지정된 기호 인수를 사용하여 한 번 호출 되고 추적되며 그래프 함수로 바뀝니다. &lt;code&gt;fn&lt;/code&gt; 에 의해 작성된 모든 변수 는 &lt;code&gt;wrap_function&lt;/code&gt; 에 의해 리턴 된 오브젝트가 소유합니다 . 결과 그래프 함수는 서명과 일치하는 텐서로 호출 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d03bcbea9ec248eeaa20713d75d526a9879de1ff" translate="yes" xml:space="preserve">
          <source>The quantity to be monitored needs to be available in &lt;code&gt;logs&lt;/code&gt; dict. To make it so, pass the loss or metrics at &lt;code&gt;model.compile()&lt;/code&gt;.</source>
          <target state="translated">The quantity to be monitored needs to be available in &lt;code&gt;logs&lt;/code&gt; dict. To make it so, pass the loss or metrics at &lt;code&gt;model.compile()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4d8a7f5ae13c0deb4cd4a8012ab18a5fdec064e5" translate="yes" xml:space="preserve">
          <source>The queue reference, i.e. the output of the queue op.</source>
          <target state="translated">The queue reference, i.e. the output of the queue op.</target>
        </trans-unit>
        <trans-unit id="aaadc5a70ca763680cae28ccccd312176ae7929f" translate="yes" xml:space="preserve">
          <source>The ragged rank for the &lt;code&gt;RaggedTensor&lt;/code&gt;</source>
          <target state="translated">The ragged rank for the &lt;code&gt;RaggedTensor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cf2591fdff5d530b2526efe01b41c14d72949b69" translate="yes" xml:space="preserve">
          <source>The random integers are slightly biased unless &lt;code&gt;maxval - minval&lt;/code&gt; is an exact power of two. The bias is small for values of &lt;code&gt;maxval - minval&lt;/code&gt; significantly smaller than the range of the output (either &lt;code&gt;2^32&lt;/code&gt; or &lt;code&gt;2^64&lt;/code&gt;).</source>
          <target state="translated">The random integers are slightly biased unless &lt;code&gt;maxval - minval&lt;/code&gt; is an exact power of two. The bias is small for values of &lt;code&gt;maxval - minval&lt;/code&gt; significantly smaller than the range of the output (either &lt;code&gt;2^32&lt;/code&gt; or &lt;code&gt;2^64&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="b20ff491ff5822812275688511b761f22476aa65" translate="yes" xml:space="preserve">
          <source>The range of pixel values for the output image might be slightly different from the range for the input image because of limited numerical precision. To guarantee an output range, for example &lt;code&gt;[0.0, 1.0]&lt;/code&gt;, apply &lt;a href=&quot;../../../clip_by_value&quot;&gt;&lt;code&gt;tf.clip_by_value&lt;/code&gt;&lt;/a&gt; to the output.</source>
          <target state="translated">출력 이미지의 픽셀 값 범위는 제한된 숫자 정밀도로 인해 입력 이미지의 범위와 약간 다를 수 있습니다. 출력 범위 (예 : &lt;code&gt;[0.0, 1.0]&lt;/code&gt; 를 보장하려면 &lt;a href=&quot;../../../clip_by_value&quot;&gt; &lt;code&gt;tf.clip_by_value&lt;/code&gt; &lt;/a&gt; 를 출력에 적용 하십시오.</target>
        </trans-unit>
        <trans-unit id="e8fedfebee027b536f10130b6d675ab2045757c3" translate="yes" xml:space="preserve">
          <source>The range of pixel values for the output image might be slightly different from the range for the input image because of limited numerical precision. To guarantee an output range, for example &lt;code&gt;[0.0, 1.0]&lt;/code&gt;, apply &lt;a href=&quot;../clip_by_value&quot;&gt;&lt;code&gt;tf.clip_by_value&lt;/code&gt;&lt;/a&gt; to the output.</source>
          <target state="translated">The range of pixel values for the output image might be slightly different from the range for the input image because of limited numerical precision. To guarantee an output range, for example &lt;code&gt;[0.0, 1.0]&lt;/code&gt; , apply &lt;a href=&quot;../clip_by_value&quot;&gt; &lt;code&gt;tf.clip_by_value&lt;/code&gt; &lt;/a&gt; to the output.</target>
        </trans-unit>
        <trans-unit id="6294e1714e1b2b241bb1943b70eb74fc15a98222" translate="yes" xml:space="preserve">
          <source>The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; above is because the same &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; kernel (i.e. internal representation) is used by TensorFlow for all calls of it with the same arguments, and the kernel maintains an internal counter which is incremented every time it is executed, generating different results.</source>
          <target state="translated">The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; above is because the same &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; kernel (i.e. internal representation) is used by TensorFlow for all calls of it with the same arguments, and the kernel maintains an internal counter which is incremented every time it is executed, generating different results.</target>
        </trans-unit>
        <trans-unit id="afabff9ee6287914682ddea57965fb5330ae1825" translate="yes" xml:space="preserve">
          <source>The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; above is because the same &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; kernel (i.e. internel representation) is used by TensorFlow for all calls of it with the same arguments, and the kernel maintains an internal counter which is incremented every time it is executed, generating different results.</source>
          <target state="translated">위 의 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 의 두 번째 호출에서 'A1'대신 'A2'를 얻는 이유는 동일한 인수를 가진 모든 호출에 대해 동일한 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 커널 (즉, 인터 널 표현)이 TensorFlow에서 사용되기 때문입니다. 커널은 실행될 때마다 증가하는 내부 카운터를 유지하여 다른 결과를 생성합니다.</target>
        </trans-unit>
        <trans-unit id="466c31e39da78ea430b94cdcadf9fd7405e0f0cf" translate="yes" xml:space="preserve">
          <source>The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; above is because the secand call uses a different operation seed.</source>
          <target state="translated">위 의 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 의 두 번째 호출에서 'A1'대신 'A2'를 얻는 이유는 secand 호출이 다른 연산 시드를 사용하기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="784df8a2c4aec00572bf8c70feb9ae2a52a2afdd" translate="yes" xml:space="preserve">
          <source>The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; above is because the second call uses a different operation seed.</source>
          <target state="translated">The reason we get 'A2' instead 'A1' on the second call of &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; above is because the second call uses a different operation seed.</target>
        </trans-unit>
        <trans-unit id="1280cfc6968446075563e60ad83288d637db87ba" translate="yes" xml:space="preserve">
          <source>The reconstruct one or more matrices from their LU decomposition(s).</source>
          <target state="translated">LU 분해로부터 하나 이상의 매트릭스를 재구성한다.</target>
        </trans-unit>
        <trans-unit id="39397157700bab61929a7d8ce8314e15144efa4b" translate="yes" xml:space="preserve">
          <source>The reduced SparseTensor.</source>
          <target state="translated">감소 된 SparseTensor.</target>
        </trans-unit>
        <trans-unit id="162a81b2ee639009df98d0138880fb964fcbc8fc" translate="yes" xml:space="preserve">
          <source>The reduced Tensor or the reduced SparseTensor if &lt;code&gt;output_is_sparse&lt;/code&gt; is True.</source>
          <target state="translated">&lt;code&gt;output_is_sparse&lt;/code&gt; 가 True 인 경우 감소 된 Tensor 또는 감소 된 SparseTensor 입니다.</target>
        </trans-unit>
        <trans-unit id="1e34999a75a17ec65b85f93cb20fe03874e9d9e8" translate="yes" xml:space="preserve">
          <source>The reduced Tensor.</source>
          <target state="translated">줄어든 텐서.</target>
        </trans-unit>
        <trans-unit id="fa52820210f038254236a33cd72deaaa4f2921cc" translate="yes" xml:space="preserve">
          <source>The reduced tensor (number of nonzero values).</source>
          <target state="translated">감소 된 텐서 (0이 아닌 값의 수).</target>
        </trans-unit>
        <trans-unit id="5089f15002ac696c728750d278b7a2bb4b8292fd" translate="yes" xml:space="preserve">
          <source>The reduced tensor, of the same dtype as the input_tensor.</source>
          <target state="translated">input_tensor와 동일한 dtype의 축소 된 텐서.</target>
        </trans-unit>
        <trans-unit id="db036397ce15010ca38b7140e4ed7771da72f4bd" translate="yes" xml:space="preserve">
          <source>The reduced tensor, of the same dtype as the input_tensor. Note, for &lt;code&gt;complex64&lt;/code&gt; or &lt;code&gt;complex128&lt;/code&gt; input, the returned &lt;code&gt;Tensor&lt;/code&gt; will be of type &lt;code&gt;float32&lt;/code&gt; or &lt;code&gt;float64&lt;/code&gt;, respectively.</source>
          <target state="translated">The reduced tensor, of the same dtype as the input_tensor. Note, for &lt;code&gt;complex64&lt;/code&gt; or &lt;code&gt;complex128&lt;/code&gt; input, the returned &lt;code&gt;Tensor&lt;/code&gt; will be of type &lt;code&gt;float32&lt;/code&gt; or &lt;code&gt;float64&lt;/code&gt; , respectively.</target>
        </trans-unit>
        <trans-unit id="377005a84a788fcaae09139342bfe31ee6c3e407" translate="yes" xml:space="preserve">
          <source>The reduced tensor.</source>
          <target state="translated">줄어든 텐서.</target>
        </trans-unit>
        <trans-unit id="4ca20066ecafb2f76458db7f5aae15b94f4599bf" translate="yes" xml:space="preserve">
          <source>The reduction to apply to the shard losses.</source>
          <target state="translated">The reduction to apply to the shard losses.</target>
        </trans-unit>
        <trans-unit id="32126f130f539d8b348c3776e0d288e0eb3023ae" translate="yes" xml:space="preserve">
          <source>The reference to the TensorArray.</source>
          <target state="translated">TensorArray에 대한 참조입니다.</target>
        </trans-unit>
        <trans-unit id="bec5f1d035188c5f615977438d1fd8d80cd736d2" translate="yes" xml:space="preserve">
          <source>The regular expressions we want to match against str. See &quot;Notes&quot; above for detailed notes on how this is interpreted.</source>
          <target state="translated">The regular expressions we want to match against str. See &quot;Notes&quot; above for detailed notes on how this is interpreted.</target>
        </trans-unit>
        <trans-unit id="626421317b8daa7c4481578d7b1400cbc817027c" translate="yes" xml:space="preserve">
          <source>The regularized incomplete beta integral is defined as:</source>
          <target state="translated">정규화 된 불완전 베타 통합은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="6b4ae5690943cd94c52d8b3b53e424b70c0a6f84" translate="yes" xml:space="preserve">
          <source>The remapping tensors can be generated using the GenerateVocabRemapping op.</source>
          <target state="translated">The remapping tensors can be generated using the GenerateVocabRemapping op.</target>
        </trans-unit>
        <trans-unit id="6f76fd4e0a09c22f0b1432236fcf10360b759293" translate="yes" xml:space="preserve">
          <source>The remappings are 1-D tensors with the following properties:</source>
          <target state="translated">The remappings are 1-D tensors with the following properties:</target>
        </trans-unit>
        <trans-unit id="4eb549ec0edb51386556b04bcb293e63f29c79c8" translate="yes" xml:space="preserve">
          <source>The replacement character codepoint to be used in place of any invalid input when &lt;code&gt;errors='replace'&lt;/code&gt;. Any valid unicode codepoint may be used. The default value is the default unicode replacement character which is 0xFFFD (U+65533).</source>
          <target state="translated">The replacement character codepoint to be used in place of any invalid input when &lt;code&gt;errors='replace'&lt;/code&gt; . Any valid unicode codepoint may be used. The default value is the default unicode replacement character which is 0xFFFD (U+65533).</target>
        </trans-unit>
        <trans-unit id="dc58567cf18ed1da38d660adbff7112eaf4a0c43" translate="yes" xml:space="preserve">
          <source>The replacement codepoint to be used in place of invalid substrings in &lt;code&gt;input&lt;/code&gt; when &lt;code&gt;errors='replace'&lt;/code&gt;.</source>
          <target state="translated">The replacement codepoint to be used in place of invalid substrings in &lt;code&gt;input&lt;/code&gt; when &lt;code&gt;errors='replace'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5861bd77b8284cbd383ce9fa80004e5915d9c8c5" translate="yes" xml:space="preserve">
          <source>The replacement codepoint to be used in place of invalid substrings in &lt;code&gt;input&lt;/code&gt; when &lt;code&gt;errors='replace'&lt;/code&gt;; and in place of C0 control characters in &lt;code&gt;input&lt;/code&gt; when &lt;code&gt;replace_control_characters=True&lt;/code&gt;.</source>
          <target state="translated">The replacement codepoint to be used in place of invalid substrings in &lt;code&gt;input&lt;/code&gt; when &lt;code&gt;errors='replace'&lt;/code&gt; ; and in place of C0 control characters in &lt;code&gt;input&lt;/code&gt; when &lt;code&gt;replace_control_characters=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="08f7982eae76c3d1b8d5c546c5c6087586c14c26" translate="yes" xml:space="preserve">
          <source>The request does not have valid authentication credentials.</source>
          <target state="translated">요청에 유효한 인증 자격 증명이 없습니다.</target>
        </trans-unit>
        <trans-unit id="11fac311a887cb1b94b956ea27985cb8f91c9eab" translate="yes" xml:space="preserve">
          <source>The requirements to use the cuDNN implementation are:</source>
          <target state="translated">cuDNN 구현을 사용하기위한 요구 사항은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b7f944aa478f301b9d7d37d3ac6e02aa0ab614e1" translate="yes" xml:space="preserve">
          <source>The rescaling is applied both during training and inference.</source>
          <target state="translated">The rescaling is applied both during training and inference.</target>
        </trans-unit>
        <trans-unit id="e10dd1c4bdea08780ec12768ba2f0c0cc6e6418e" translate="yes" xml:space="preserve">
          <source>The resizing Ops accept input images as tensors of several types. They always output resized images as float32 tensors.</source>
          <target state="translated">The resizing Ops accept input images as tensors of several types. They always output resized images as float32 tensors.</target>
        </trans-unit>
        <trans-unit id="5f32138dd7f669a33bea7319cf66264923452d20" translate="yes" xml:space="preserve">
          <source>The restored checkpoint path if the lastest checkpoint is found and restored. Otherwise None.</source>
          <target state="translated">The restored checkpoint path if the lastest checkpoint is found and restored. Otherwise None.</target>
        </trans-unit>
        <trans-unit id="d06ff612c69fb3df1f3d794bb785e13f8da40620" translate="yes" xml:space="preserve">
          <source>The result is a 4-D tensor of shape &lt;code&gt;[batch_size, glimpse_height, glimpse_width, channels]&lt;/code&gt;. The channels and batch dimensions are the same as that of the input tensor. The height and width of the output windows are specified in the &lt;code&gt;size&lt;/code&gt; parameter.</source>
          <target state="translated">결과는 모양의 4 차원 텐서입니다 &lt;code&gt;[batch_size, glimpse_height, glimpse_width, channels]&lt;/code&gt; . 채널 및 배치 치수는 입력 텐서와 동일합니다. 출력 창의 높이와 너비는 &lt;code&gt;size&lt;/code&gt; 매개 변수에 지정되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="af8e15d374bd08a8ea2bebed96d25f27af99cc58" translate="yes" xml:space="preserve">
          <source>The result is a 4D tensor which is indexed by batch, row, and column. &lt;code&gt;output[i, x, y]&lt;/code&gt; contains a flattened patch of size &lt;code&gt;sizes[1], sizes[2]&lt;/code&gt; which is taken from the input starting at &lt;code&gt;images[i, x*strides[1], y*strides[2]]&lt;/code&gt;.</source>
          <target state="translated">결과는 배치, 행 및 열별로 색인이 생성 된 4D 텐서입니다. &lt;code&gt;output[i, x, y]&lt;/code&gt; 에는 크기 &lt;code&gt;sizes[1], sizes[2]&lt;/code&gt; 의 평탄화 된 패치가 포함됩니다 . &lt;code&gt;images[i, x*strides[1], y*strides[2]]&lt;/code&gt; 에서 시작하는 입력에서 가져온 .</target>
        </trans-unit>
        <trans-unit id="3408db8eec06fef64e88ca8c2438893f2827e593" translate="yes" xml:space="preserve">
          <source>The result is a [..., M+1, M] matrix with [..., 0,:] containing the eigenvalues, and subsequent [...,1:, :] containing the eigenvectors. The eigenvalues are sorted in non-decreasing order.</source>
          <target state="translated">The result is a [..., M+1, M] matrix with [..., 0,:] containing the eigenvalues, and subsequent [...,1:, :] containing the eigenvectors. The eigenvalues are sorted in non-decreasing order.</target>
        </trans-unit>
        <trans-unit id="91e981525729cfb7323f601fab3d959548453e14" translate="yes" xml:space="preserve">
          <source>The result is not a global index to the entire &lt;code&gt;Tensor&lt;/code&gt;, but rather just the index in the last dimension.</source>
          <target state="translated">The result is not a global index to the entire &lt;code&gt;Tensor&lt;/code&gt; , but rather just the index in the last dimension.</target>
        </trans-unit>
        <trans-unit id="cc0fc847805d05865dd1fc80479599ef10e030da" translate="yes" xml:space="preserve">
          <source>The result of calling parse_example on these examples will produce a dictionary with entries for &quot;ids&quot; and &quot;values&quot;. Passing those two objects to this function along with vocab_size=6, will produce a &lt;code&gt;SparseTensor&lt;/code&gt; that sparsely represents all three instances. Namely, the &lt;code&gt;indices&lt;/code&gt; property will contain the coordinates of the non-zero entries in the feature matrix (the first dimension is the row number in the matrix, i.e., the index within the batch, and the second dimension is the column number, i.e., the feature id); &lt;code&gt;values&lt;/code&gt; will contain the actual values. &lt;code&gt;shape&lt;/code&gt; will be the shape of the original matrix, i.e., (3, 6). For our example above, the output will be equal to:</source>
          <target state="translated">이 예제에서 parse_example을 호출하면 &quot;ids&quot;및 &quot;values&quot;에 대한 항목이있는 사전이 생성됩니다. vocab_size = 6과 함께이 두 객체를이 함수에 전달하면 세 인스턴스를 모두 희소하게 나타내는 &lt;code&gt;SparseTensor&lt;/code&gt; 가 생성됩니다 . 즉, &lt;code&gt;indices&lt;/code&gt; 속성은 피처 매트릭스에서 0이 아닌 항목의 좌표를 포함합니다 (첫 번째 차원은 매트릭스의 행 번호, 즉 배치 내 인덱스이고 두 번째 차원은 열 번호입니다. 기능 ID); &lt;code&gt;values&lt;/code&gt; 은 실제 값 을 포함합니다. &lt;code&gt;shape&lt;/code&gt; 는 원래 행렬의 모양, 즉 (3, 6)입니다. 위의 예에서 출력은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="c532f85716ab7d9d5ac1221540a16a00cf14d0f8" translate="yes" xml:space="preserve">
          <source>The result of one inference step, typically the output of calling the &lt;code&gt;Model&lt;/code&gt; on data.</source>
          <target state="translated">The result of one inference step, typically the output of calling the &lt;code&gt;Model&lt;/code&gt; on data.</target>
        </trans-unit>
        <trans-unit id="b712de5339fc3e663594598e87ccb0f331d98d0d" translate="yes" xml:space="preserve">
          <source>The result of the elementwise &lt;code&gt;!=&lt;/code&gt; operation, or &lt;code&gt;True&lt;/code&gt; if the arguments are not broadcast-compatible.</source>
          <target state="translated">The result of the elementwise &lt;code&gt;!=&lt;/code&gt; operation, or &lt;code&gt;True&lt;/code&gt; if the arguments are not broadcast-compatible.</target>
        </trans-unit>
        <trans-unit id="65bf62ac9a12a3ed583f3696b9ec4dfdd36908c0" translate="yes" xml:space="preserve">
          <source>The result of the elementwise &lt;code&gt;+&lt;/code&gt; operation.</source>
          <target state="translated">The result of the elementwise &lt;code&gt;+&lt;/code&gt; operation.</target>
        </trans-unit>
        <trans-unit id="4a0379f511e04f35dbfdf4e95a15f796515177e5" translate="yes" xml:space="preserve">
          <source>The result of the elementwise &lt;code&gt;==&lt;/code&gt; operation, or &lt;code&gt;False&lt;/code&gt; if the arguments are not broadcast-compatible.</source>
          <target state="translated">The result of the elementwise &lt;code&gt;==&lt;/code&gt; operation, or &lt;code&gt;False&lt;/code&gt; if the arguments are not broadcast-compatible.</target>
        </trans-unit>
        <trans-unit id="a7181bf7e73106c9b2b97d9fffba14ef65fbf1f8" translate="yes" xml:space="preserve">
          <source>The result of this op should be passed through a &lt;code&gt;sparse_to_dense&lt;/code&gt; operation, then added to the logits of the sampled classes. This removes the contradictory effect of accidentally sampling the true target classes as noise classes for the same example.</source>
          <target state="translated">이 op의 결과는 &lt;code&gt;sparse_to_dense&lt;/code&gt; 작업을 통과 한 다음 샘플링 된 클래스의 로그에 추가되어야합니다. 이것은 동일한 예제에서 실제 대상 클래스를 노이즈 클래스로 실수로 샘플링 한 모순 된 효과를 제거합니다.</target>
        </trans-unit>
        <trans-unit id="95bce95270c24fcef8ff10f45294119d2cbaf8aa" translate="yes" xml:space="preserve">
          <source>The result will be biased towards the initial value of the variable.</source>
          <target state="translated">The result will be biased towards the initial value of the variable.</target>
        </trans-unit>
        <trans-unit id="01298564c21aafdba5ad8531a719b0b62528e9fe" translate="yes" xml:space="preserve">
          <source>The result will have those bits set, that are different in &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. The computation is performed on the underlying representations of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">결과는 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 에서 다른 비트 세트를 갖게됩니다 . 계산은 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 의 기본 표현에 대해 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="685b62e5962fffb0313c314fe8766a83e91dc7ce" translate="yes" xml:space="preserve">
          <source>The result will have those bits set, that are set in &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; or both. The computation is performed on the underlying representations of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">결과는 &lt;code&gt;x&lt;/code&gt; , &lt;code&gt;y&lt;/code&gt; 또는 둘 다에 설정된 비트를 갖게됩니다 . 계산은 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 의 기본 표현에 대해 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="b74f37adc87a210e3154c60f498551da0c0a3084" translate="yes" xml:space="preserve">
          <source>The result will have those bits set, that are set in both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. The computation is performed on the underlying representations of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">결과는 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 모두에 설정된 비트를 갖게됩니다 . 계산은 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 의 기본 표현에 대해 수행됩니다 .</target>
        </trans-unit>
        <trans-unit id="a454b218545175a81109283a1b62827f2751cc1d" translate="yes" xml:space="preserve">
          <source>The resulting &lt;code&gt;Tensor&lt;/code&gt; of parsing a single &lt;code&gt;SequenceExample&lt;/code&gt; or &lt;code&gt;Example&lt;/code&gt; has a static &lt;code&gt;shape&lt;/code&gt; of &lt;code&gt;[None] + shape&lt;/code&gt; and the specified &lt;code&gt;dtype&lt;/code&gt;. The resulting &lt;code&gt;Tensor&lt;/code&gt; of parsing a &lt;code&gt;batch_size&lt;/code&gt; many &lt;code&gt;Example&lt;/code&gt;s has a static &lt;code&gt;shape&lt;/code&gt; of &lt;code&gt;[batch_size, None] + shape&lt;/code&gt; and the specified &lt;code&gt;dtype&lt;/code&gt;. The entries in the &lt;code&gt;batch&lt;/code&gt; from different &lt;code&gt;Examples&lt;/code&gt; will be padded with &lt;code&gt;default_value&lt;/code&gt; to the maximum length present in the &lt;code&gt;batch&lt;/code&gt;.</source>
          <target state="translated">단일 &lt;code&gt;SequenceExample&lt;/code&gt; 또는 &lt;code&gt;Example&lt;/code&gt; 을 구문 분석하는 결과 &lt;code&gt;Tensor&lt;/code&gt; 는 정적 &lt;code&gt;shape&lt;/code&gt; 이 &lt;code&gt;[None] + shape&lt;/code&gt; 이고 지정된 &lt;code&gt;dtype&lt;/code&gt; 입니다. &lt;code&gt;batch_size&lt;/code&gt; many &lt;code&gt;Example&lt;/code&gt; 을 구문 분석하는 결과 &lt;code&gt;Tensor&lt;/code&gt; 의 정적 &lt;code&gt;shape&lt;/code&gt; 은 &lt;code&gt;[batch_size, None] + shape&lt;/code&gt; 및 지정된 &lt;code&gt;dtype&lt;/code&gt; 입니다. 의 항목 &lt;code&gt;batch&lt;/code&gt; 다른 행 &lt;code&gt;Examples&lt;/code&gt; 패딩 될 &lt;code&gt;default_value&lt;/code&gt; 최대 길이로 본 &lt;code&gt;batch&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3a538e992c4e715c1f91b7c40110e2510e29c989" translate="yes" xml:space="preserve">
          <source>The resulting SavedModel is then servable with an input named &quot;x&quot;, its value having any shape and dtype float32.</source>
          <target state="translated">결과 SavedModel은 &quot;x&quot;라는 이름의 입력으로 서비스 가능하며 그 값은 모양과 dtype float32입니다.</target>
        </trans-unit>
        <trans-unit id="b71ce2b54de94b7e8ecf2e651366ba952c5ce3a3" translate="yes" xml:space="preserve">
          <source>The resulting dataset is similar to the &lt;code&gt;InterleaveDataset&lt;/code&gt;, except that the dataset will fetch records from the interleaved datasets in parallel.</source>
          <target state="translated">The resulting dataset is similar to the &lt;code&gt;InterleaveDataset&lt;/code&gt; , except that the dataset will fetch records from the interleaved datasets in parallel.</target>
        </trans-unit>
        <trans-unit id="5d8659c50ab2dced91f800b38d49965e49b25d1c" translate="yes" xml:space="preserve">
          <source>The resulting dataset is similar to the &lt;code&gt;InterleaveDataset&lt;/code&gt;, with the exception that if retrieving the next value from a dataset would cause the requester to block, it will skip that input dataset. This dataset is especially useful when loading data from a variable-latency datastores (e.g. HDFS, GCS), as it allows the training step to proceed so long as some data is available.</source>
          <target state="translated">The resulting dataset is similar to the &lt;code&gt;InterleaveDataset&lt;/code&gt; , with the exception that if retrieving the next value from a dataset would cause the requester to block, it will skip that input dataset. This dataset is especially useful when loading data from a variable-latency datastores (e.g. HDFS, GCS), as it allows the training step to proceed so long as some data is available.</target>
        </trans-unit>
        <trans-unit id="fd835a476d97294a9a531a06c729ae1427276dc8" translate="yes" xml:space="preserve">
          <source>The resulting function is assumed stateful and will never be optimized.</source>
          <target state="translated">The resulting function is assumed stateful and will never be optimized.</target>
        </trans-unit>
        <trans-unit id="1f53b61193a80c029c5a448efed06c1a8f6588c5" translate="yes" xml:space="preserve">
          <source>The resulting output shape when using the &quot;same&quot; padding option is: &lt;code&gt;output_shape = input_shape / strides&lt;/code&gt;</source>
          <target state="translated">The resulting output shape when using the &quot;same&quot; padding option is: &lt;code&gt;output_shape = input_shape / strides&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9ef25e64d2e423f7de1f3a02ba7a25085c38c8a1" translate="yes" xml:space="preserve">
          <source>The resulting tensor is populated with values of type &lt;code&gt;dtype&lt;/code&gt;, as specified by arguments &lt;code&gt;value&lt;/code&gt; and (optionally) &lt;code&gt;shape&lt;/code&gt; (see examples below).</source>
          <target state="translated">결과 텐서는 인수 &lt;code&gt;value&lt;/code&gt; 및 (선택적) 으로 지정된대로 &lt;code&gt;dtype&lt;/code&gt; 유형의 값으로 채워집니다. &lt;code&gt;shape&lt;/code&gt; (아래 예 참조).</target>
        </trans-unit>
        <trans-unit id="0b674f3072695f2111704701dbc3947bfb383f3f" translate="yes" xml:space="preserve">
          <source>The resulting tensor is populated with values of type &lt;code&gt;dtype&lt;/code&gt;, as specified by arguments &lt;code&gt;value&lt;/code&gt; following the desired &lt;code&gt;shape&lt;/code&gt; of the new tensor (see examples below).</source>
          <target state="translated">결과 텐서는 원하는 다음 인수 &lt;code&gt;value&lt;/code&gt; 으로 지정된 &lt;code&gt;dtype&lt;/code&gt; 유형의 값으로 채워집니다. &lt;code&gt;shape&lt;/code&gt; 새로운 텐서 모양 에 따라 (아래 예 참조).</target>
        </trans-unit>
        <trans-unit id="ef74e8f16df07a307babda0cfa120db0e980020d" translate="yes" xml:space="preserve">
          <source>The resulting tensor would look like this:</source>
          <target state="translated">결과 텐서는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="381b1e6543678db4ed459c1cba156ecc8ca01172" translate="yes" xml:space="preserve">
          <source>The resulting update to ref would look like this:</source>
          <target state="translated">ref에 대한 결과 업데이트는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="cbbd169c06c5469910e771887e06b5ed0c01b738" translate="yes" xml:space="preserve">
          <source>The resulting update to v would look like this:</source>
          <target state="translated">v에 대한 결과 업데이트는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="993bb51caef566927c6f2034eead7ae47fdb56d0" translate="yes" xml:space="preserve">
          <source>The resulting value &lt;code&gt;output&lt;/code&gt; would look like this:</source>
          <target state="translated">The resulting value &lt;code&gt;output&lt;/code&gt; would look like this:</target>
        </trans-unit>
        <trans-unit id="5cc6293ac412a772df6f0e78ca55482c98eb64a2" translate="yes" xml:space="preserve">
          <source>The results of the lookup are concatenated into a dense tensor. The returned tensor has shape &lt;code&gt;shape(ids) + shape(params)[1:]&lt;/code&gt;.</source>
          <target state="translated">조회 결과는 조밀 한 텐서로 연결됩니다. 반환 된 텐서는 모양 &lt;code&gt;shape(ids) + shape(params)[1:]&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="2f1f40e1bca978cc7aa38e548317ee19cb7dfd8c" translate="yes" xml:space="preserve">
          <source>The return value has the same type as &lt;code&gt;images&lt;/code&gt; if &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;../../../image/resizemethod#NEAREST_NEIGHBOR&quot;&gt;&lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt;&lt;/a&gt;. It will also have the same type as &lt;code&gt;images&lt;/code&gt; if the size of &lt;code&gt;images&lt;/code&gt; can be statically determined to be the same as &lt;code&gt;size&lt;/code&gt;, because &lt;code&gt;images&lt;/code&gt; is returned in this case. Otherwise, the return value has type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;method&lt;/code&gt; 가 &lt;a href=&quot;../../../image/resizemethod#NEAREST_NEIGHBOR&quot;&gt; &lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt; 인&lt;/a&gt; 경우 리턴 값은 &lt;code&gt;images&lt;/code&gt; 와 유형이 동일합니다 . 또한, 같은 유형의 것 &lt;code&gt;images&lt;/code&gt; 의 크기 경우 &lt;code&gt;images&lt;/code&gt; 정적으로 동일한 것으로 결정될 수있다 &lt;code&gt;size&lt;/code&gt; 때문에, &lt;code&gt;images&lt;/code&gt; 이 경우에 반환된다. 그렇지 않으면 반환 값의 유형은 &lt;code&gt;float32&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="d56a51802c9fd20b938ff0224e17cc92fbe0a0fd" translate="yes" xml:space="preserve">
          <source>The return value has the same type as &lt;code&gt;images&lt;/code&gt; if &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;../../../image/resizemethod#NEAREST_NEIGHBOR&quot;&gt;&lt;code&gt;tf.image.ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt;&lt;/a&gt;. It will also have the same type as &lt;code&gt;images&lt;/code&gt; if the size of &lt;code&gt;images&lt;/code&gt; can be statically determined to be the same as &lt;code&gt;size&lt;/code&gt;, because &lt;code&gt;images&lt;/code&gt; is returned in this case. Otherwise, the return value has type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">The return value has the same type as &lt;code&gt;images&lt;/code&gt; if &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;../../../image/resizemethod#NEAREST_NEIGHBOR&quot;&gt; &lt;code&gt;tf.image.ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt; &lt;/a&gt;. It will also have the same type as &lt;code&gt;images&lt;/code&gt; if the size of &lt;code&gt;images&lt;/code&gt; can be statically determined to be the same as &lt;code&gt;size&lt;/code&gt; , because &lt;code&gt;images&lt;/code&gt; is returned in this case. Otherwise, the return value has type &lt;code&gt;float32&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="90335752084dfbdd6479bc3425e07c2c184fac03" translate="yes" xml:space="preserve">
          <source>The return value has the same type as &lt;code&gt;images&lt;/code&gt; if &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;resizemethod#NEAREST_NEIGHBOR&quot;&gt;&lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt;&lt;/a&gt;. Otherwise, the return value has type &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;method&lt;/code&gt; 가 &lt;a href=&quot;resizemethod#NEAREST_NEIGHBOR&quot;&gt; &lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt; 인&lt;/a&gt; 경우 리턴 값은 &lt;code&gt;images&lt;/code&gt; 와 유형이 동일합니다 . 그렇지 않으면 반환 값의 유형은 &lt;code&gt;float32&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="8d380f2c5d4525994512f90f349c7eb51132c6e2" translate="yes" xml:space="preserve">
          <source>The return value has type &lt;code&gt;float32&lt;/code&gt;, unless the &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;resizemethod#NEAREST_NEIGHBOR&quot;&gt;&lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt;&lt;/a&gt;, then the return dtype is the dtype of &lt;code&gt;images&lt;/code&gt;:</source>
          <target state="translated">The return value has type &lt;code&gt;float32&lt;/code&gt; , unless the &lt;code&gt;method&lt;/code&gt; is &lt;a href=&quot;resizemethod#NEAREST_NEIGHBOR&quot;&gt; &lt;code&gt;ResizeMethod.NEAREST_NEIGHBOR&lt;/code&gt; &lt;/a&gt;, then the return dtype is the dtype of &lt;code&gt;images&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="6db6bf11d3c25e837bbcedc93fcb0930b2a99ab3" translate="yes" xml:space="preserve">
          <source>The return value is not the same Tensor as the original, but contains the same values. This operation is fast when used on the same device.</source>
          <target state="translated">The return value is not the same Tensor as the original, but contains the same values. This operation is fast when used on the same device.</target>
        </trans-unit>
        <trans-unit id="3e3b67eed807726677126c856d0a6214fa8f8e4a" translate="yes" xml:space="preserve">
          <source>The return value of &lt;code&gt;merge_fn&lt;/code&gt;, except for &lt;code&gt;PerReplica&lt;/code&gt; values which are unpacked.</source>
          <target state="translated">압축 해제 된 &lt;code&gt;PerReplica&lt;/code&gt; 값을 제외하고 &lt;code&gt;merge_fn&lt;/code&gt; 의 반환 값 .</target>
        </trans-unit>
        <trans-unit id="b729f575891182a1cf2b646557e584015983e0cf" translate="yes" xml:space="preserve">
          <source>The return values from &lt;code&gt;Session.run()&lt;/code&gt; corresponding to the fetches attribute returned in the RunArgs. Note that this has the same shape as the RunArgs fetches. For example: fetches = global_step_tensor =&amp;gt; results = nparray(int) fetches = [train_op, summary_op, global_step_tensor] =&amp;gt; results = [None, nparray(string), nparray(int)] fetches = {'step': global_step_tensor, 'summ': summary_op} =&amp;gt; results = {'step': nparray(int), 'summ': nparray(string)}</source>
          <target state="translated">The return values from &lt;code&gt;Session.run()&lt;/code&gt; corresponding to the fetches attribute returned in the RunArgs. Note that this has the same shape as the RunArgs fetches. For example: fetches = global_step_tensor =&amp;gt; results = nparray(int) fetches = [train_op, summary_op, global_step_tensor] =&amp;gt; results = [None, nparray(string), nparray(int)] fetches = {'step': global_step_tensor, 'summ': summary_op} =&amp;gt; results = {'step': nparray(int), 'summ': nparray(string)}</target>
        </trans-unit>
        <trans-unit id="1e968254f01cab6234b67bba030e47e2fb4dbf82" translate="yes" xml:space="preserve">
          <source>The returned &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The returned &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="e54bb88894be8aec22542ba047bf035708660a8b" translate="yes" xml:space="preserve">
          <source>The returned &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The returned &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="1bc73b952597eebba1bc9614e25b86603811dd74" translate="yes" xml:space="preserve">
          <source>The returned &lt;a href=&quot;../distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;../distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The returned &lt;a href=&quot;../distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;../distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="77573df9f9325728fade9f377ed047dae4204229" translate="yes" xml:space="preserve">
          <source>The returned &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The returned &lt;a href=&quot;distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt; can be iterated over similar to how regular datasets can. NOTE: The user cannot add any more transformations to a &lt;a href=&quot;distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="1dea02fa1b7f8947a51fb716ddcefda916820715" translate="yes" xml:space="preserve">
          <source>The returned &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; is determined at &lt;em&gt;build&lt;/em&gt; time, without executing the underlying kernel. It is not a &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;. If you need a shape &lt;em&gt;tensor&lt;/em&gt;, either convert the &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; to a &lt;a href=&quot;constant&quot;&gt;&lt;code&gt;tf.constant&lt;/code&gt;&lt;/a&gt;, or use the &lt;a href=&quot;shape&quot;&gt;&lt;code&gt;tf.shape(tensor)&lt;/code&gt;&lt;/a&gt; function, which returns the tensor's shape at &lt;em&gt;execution&lt;/em&gt; time.</source>
          <target state="translated">The returned &lt;a href=&quot;tensorshape&quot;&gt; &lt;code&gt;tf.TensorShape&lt;/code&gt; &lt;/a&gt; is determined at &lt;em&gt;build&lt;/em&gt; time, without executing the underlying kernel. It is not a &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt;. If you need a shape &lt;em&gt;tensor&lt;/em&gt;, either convert the &lt;a href=&quot;tensorshape&quot;&gt; &lt;code&gt;tf.TensorShape&lt;/code&gt; &lt;/a&gt; to a &lt;a href=&quot;constant&quot;&gt; &lt;code&gt;tf.constant&lt;/code&gt; &lt;/a&gt;, or use the &lt;a href=&quot;shape&quot;&gt; &lt;code&gt;tf.shape(tensor)&lt;/code&gt; &lt;/a&gt; function, which returns the tensor's shape at &lt;em&gt;execution&lt;/em&gt; time.</target>
        </trans-unit>
        <trans-unit id="111bba19cc7fb0062ed6fe66a53428292ab2ad62" translate="yes" xml:space="preserve">
          <source>The returned &lt;code&gt;RaggedTensor&lt;/code&gt; corresponds with the python list defined by:</source>
          <target state="translated">반환 된 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 다음에 의해 정의 된 python 목록과 일치합니다.</target>
        </trans-unit>
        <trans-unit id="ecbcae5eb984661e7de2445f57c60c5e40e3d894" translate="yes" xml:space="preserve">
          <source>The returned &lt;code&gt;Session&lt;/code&gt; will be the innermost session on which a &lt;code&gt;Session&lt;/code&gt; or &lt;code&gt;Session.as_default()&lt;/code&gt; context has been entered.</source>
          <target state="translated">반환 된 &lt;code&gt;Session&lt;/code&gt; 은 &lt;code&gt;Session&lt;/code&gt; 또는 &lt;code&gt;Session.as_default()&lt;/code&gt; 컨텍스트가 입력 된 가장 안쪽의 세션입니다 .</target>
        </trans-unit>
        <trans-unit id="95a65357f0f57659490bed4f233c4a4d8fc08588" translate="yes" xml:space="preserve">
          <source>The returned &lt;code&gt;Tensor&lt;/code&gt; will be close to an exact solution if &lt;code&gt;A&lt;/code&gt; is well conditioned. Otherwise closeness will vary. See class docstring for details.</source>
          <target state="translated">반환 된 &lt;code&gt;Tensor&lt;/code&gt; 는 &lt;code&gt;A&lt;/code&gt; 인 경우 정확한 솔루션에 가깝습니다 . 가 잘 조절 . 그렇지 않으면 친밀감이 달라질 수 있습니다. 자세한 내용은 클래스 docstring을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="210a2253a38d62adf49c231834e4374a228751a1" translate="yes" xml:space="preserve">
          <source>The returned callable will have the same return type as &lt;code&gt;tf.Session.run(fetches, ...)&lt;/code&gt;. For example, if &lt;code&gt;fetches&lt;/code&gt; is a &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;, the callable will return a numpy ndarray; if &lt;code&gt;fetches&lt;/code&gt; is a &lt;a href=&quot;../../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt;, it will return &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">리턴 된 콜 &lt;code&gt;tf.Session.run(fetches, ...)&lt;/code&gt; 은 tf.Session.run (fetches, ...) 와 동일한 리턴 유형을 갖습니다 . 예를 들어, &lt;code&gt;fetches&lt;/code&gt; 가 &lt;a href=&quot;../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 인 경우 호출 가능 항목은 numpy ndarray를 반환합니다. 경우 &lt;code&gt;fetches&lt;/code&gt; A는 &lt;a href=&quot;../../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; 이&lt;/a&gt; , 그것은 반환하지 않습니다 &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bfdda7d94aac832546a913098111bedb3a5af104" translate="yes" xml:space="preserve">
          <source>The returned callable will take &lt;code&gt;len(feed_list)&lt;/code&gt; arguments whose types must be compatible feed values for the respective elements of &lt;code&gt;feed_list&lt;/code&gt;. For example, if element &lt;code&gt;i&lt;/code&gt; of &lt;code&gt;feed_list&lt;/code&gt; is a &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;i&lt;/code&gt;th argument to the returned callable must be a numpy ndarray (or something convertible to an ndarray) with matching element type and shape. See &lt;code&gt;tf.Session.run&lt;/code&gt; for details of the allowable feed key and value types.</source>
          <target state="translated">리턴 된 호출 가능은 유형이 &lt;code&gt;feed_list&lt;/code&gt; 의 각 요소에 대해 호환 가능한 피드 값이어야하는 &lt;code&gt;len(feed_list)&lt;/code&gt; 인수를 사용합니다 . 예를 들어, 소자 경우 &lt;code&gt;i&lt;/code&gt; 의 &lt;code&gt;feed_list&lt;/code&gt; 는 A는 &lt;a href=&quot;../../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 상기 &lt;code&gt;i&lt;/code&gt; 에 번째 인수 반환 매칭 소자 종류와 형상의 NumPy와 ndarray (또는 ndarray로 전환 일) 여야 호출. 허용 가능한 피드 키 및 값 유형에 대한 자세한 내용은 &lt;code&gt;tf.Session.run&lt;/code&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="5ae9baaba07ae2a863bb456cb56b210b15bfeca4" translate="yes" xml:space="preserve">
          <source>The returned dataset is a wrapped strategy dataset which creates a multidevice iterator under the hood. It prefetches the input data to the specified devices on the worker. The returned distributed dataset can be iterated over similar to how regular datasets can.</source>
          <target state="translated">리턴 된 데이터 세트는 랩된 전략 데이터 세트이며 후드 아래에서 다중 디바이스 반복자를 작성합니다. 작업자의 지정된 장치로 입력 데이터를 프리 페치합니다. 리턴 된 분산 데이터 세트는 일반 데이터 세트와 유사한 방식으로 반복 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b16f128652226cd5df44d3210c5abe8996d2a7b8" translate="yes" xml:space="preserve">
          <source>The returned dict may have the following keys:</source>
          <target state="translated">The returned dict may have the following keys:</target>
        </trans-unit>
        <trans-unit id="6f7e2363fe125c1a5cdb798835abe8de5ac8aef0" translate="yes" xml:space="preserve">
          <source>The returned dictionary can be used as arg 'features' in &lt;a href=&quot;../../../io/parse_example&quot;&gt;&lt;code&gt;tf.io.parse_example&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">반환 된 사전은 &lt;a href=&quot;../../../io/parse_example&quot;&gt; &lt;code&gt;tf.io.parse_example&lt;/code&gt; &lt;/a&gt; 에서 arg 'features'로 사용될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="27148d9610fe5857a584045bc355cd08d4ce68b2" translate="yes" xml:space="preserve">
          <source>The returned dictionary can be used as arg 'features' in &lt;a href=&quot;../io/parse_example&quot;&gt;&lt;code&gt;tf.io.parse_example&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">반환 된 사전은 &lt;a href=&quot;../io/parse_example&quot;&gt; &lt;code&gt;tf.io.parse_example&lt;/code&gt; &lt;/a&gt; 에서 arg 'features'로 사용될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="e41cdf1dd9ec5b48c6c1a627e04bc9cd0f5646ec" translate="yes" xml:space="preserve">
          <source>The returned distributed dataset can be iterated over similar to how regular datasets can. NOTE: Currently, the user cannot add any more transformations to a distributed dataset.</source>
          <target state="translated">리턴 된 분산 데이터 세트는 일반 데이터 세트와 유사한 방식으로 반복 될 수 있습니다. 참고 : 현재 사용자는 분산 데이터 집합에 더 이상 변환을 추가 할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="8e5c9b1714c669dc39fd802e652891ab6982a58a" translate="yes" xml:space="preserve">
          <source>The returned graph will be the innermost graph on which a &lt;a href=&quot;../../graph#as_default&quot;&gt;&lt;code&gt;Graph.as_default()&lt;/code&gt;&lt;/a&gt; context has been entered, or a global default graph if none has been explicitly created.</source>
          <target state="translated">반환 된 그래프는 &lt;a href=&quot;../../graph#as_default&quot;&gt; &lt;code&gt;Graph.as_default()&lt;/code&gt; &lt;/a&gt; 컨텍스트가 입력 된 가장 안쪽 그래프 이거나 명시 적으로 생성되지 않은 경우 전역 기본 그래프입니다.</target>
        </trans-unit>
        <trans-unit id="a3ca6a76bf18bc7eb9e290fd0f8d92384b3fc63a" translate="yes" xml:space="preserve">
          <source>The returned graph will be the innermost graph on which a &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#as_default&quot;&gt;&lt;code&gt;Graph.as_default()&lt;/code&gt;&lt;/a&gt; context has been entered, or a global default graph if none has been explicitly created.</source>
          <target state="translated">The returned graph will be the innermost graph on which a &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#as_default&quot;&gt; &lt;code&gt;Graph.as_default()&lt;/code&gt; &lt;/a&gt; context has been entered, or a global default graph if none has been explicitly created.</target>
        </trans-unit>
        <trans-unit id="4983b6188d9b3a5503f72bc1978affb47cac7b6d" translate="yes" xml:space="preserve">
          <source>The returned iterator implements the Python Iterator protocol.</source>
          <target state="translated">The returned iterator implements the Python Iterator protocol.</target>
        </trans-unit>
        <trans-unit id="6b38dad137146b9ef38ba7c509e2c0442b75c1f0" translate="yes" xml:space="preserve">
          <source>The returned iterator implements the Python iterator protocol and therefore can only be used in eager mode.</source>
          <target state="translated">리턴 된 반복기는 Python 반복기 프로토콜을 구현하므로 열성 모드에서만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7e0593141fa29e4d333dddf121d2181c125317c5" translate="yes" xml:space="preserve">
          <source>The returned iterator is not bound to a particular dataset, and it has no &lt;code&gt;initializer&lt;/code&gt;. To initialize the iterator, run the operation returned by &lt;code&gt;Iterator.make_initializer(dataset)&lt;/code&gt;.</source>
          <target state="translated">리턴 된 반복자는 특정 데이터 세트에 바인드되지 않으며 &lt;code&gt;initializer&lt;/code&gt; 프로그램이 없습니다 . 반복자를 초기화하려면 &lt;code&gt;Iterator.make_initializer(dataset)&lt;/code&gt; 반환 한 작업을 실행하십시오 .</target>
        </trans-unit>
        <trans-unit id="35c004b6fa1c65f47bcd7047f0f10a1978a605f3" translate="yes" xml:space="preserve">
          <source>The returned operation is a dequeue operation and will throw &lt;a href=&quot;../../../errors/outofrangeerror&quot;&gt;&lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt;&lt;/a&gt; if the input queue is exhausted. If this operation is feeding another input queue, its queue runner will catch this exception, however, if this operation is used in your main thread you are responsible for catching this yourself.</source>
          <target state="translated">리턴 된 오퍼레이션은 큐 제거 조작이며 입력 큐가 소진되면 &lt;a href=&quot;../../../errors/outofrangeerror&quot;&gt; &lt;code&gt;tf.errors.OutOfRangeError&lt;/code&gt; 를&lt;/a&gt; 발생시킵니다. 이 오퍼레이션이 다른 입력 큐를 공급하는 경우 큐 러너가이 예외를 포착하지만이 오퍼레이션이 기본 스레드에서 사용되는 경우이를 직접 처리해야합니다.</target>
        </trans-unit>
        <trans-unit id="388161f4aeaed3801662f433bd19fe4a8d446b0a" translate="yes" xml:space="preserve">
          <source>The returned permutation may be used to permute the rows and columns of the given sparse matrix. This typically results in permuted sparse matrix's sparse Cholesky (or other decompositions) in having fewer zero fill-in compared to decomposition of the original matrix.</source>
          <target state="translated">The returned permutation may be used to permute the rows and columns of the given sparse matrix. This typically results in permuted sparse matrix's sparse Cholesky (or other decompositions) in having fewer zero fill-in compared to decomposition of the original matrix.</target>
        </trans-unit>
        <trans-unit id="34611a4904c47d805a50142b42fe43a0ecae787f" translate="yes" xml:space="preserve">
          <source>The returned sparse matrix has the same dense shape as the input sparse matrix. For each component &lt;code&gt;A&lt;/code&gt; of the input sparse matrix, the corresponding output sparse matrix represents &lt;code&gt;L&lt;/code&gt;, the lower triangular Cholesky factor satisfying the following identity:</source>
          <target state="translated">The returned sparse matrix has the same dense shape as the input sparse matrix. For each component &lt;code&gt;A&lt;/code&gt; of the input sparse matrix, the corresponding output sparse matrix represents &lt;code&gt;L&lt;/code&gt; , the lower triangular Cholesky factor satisfying the following identity:</target>
        </trans-unit>
        <trans-unit id="283d98979ab1e70cde916469a5e89b9e786cbb6c" translate="yes" xml:space="preserve">
          <source>The returned status object has the following methods:</source>
          <target state="translated">리턴 된 상태 오브젝트에는 다음 메소드가 있습니다.</target>
        </trans-unit>
        <trans-unit id="b692f2b05a18e92aff1d5bc6f670c1b3f429e602" translate="yes" xml:space="preserve">
          <source>The returned string will be in the form protocol://address, e.g. &quot;grpc://localhost:5050&quot;.</source>
          <target state="translated">The returned string will be in the form protocol://address, e.g. &quot;grpc://localhost:5050&quot;.</target>
        </trans-unit>
        <trans-unit id="c118b1fddbb7639875cad9b7ab197644effe14a5" translate="yes" xml:space="preserve">
          <source>The returned tensor uses the memory shared by dlpack capsules from other framework.</source>
          <target state="translated">The returned tensor uses the memory shared by dlpack capsules from other framework.</target>
        </trans-unit>
        <trans-unit id="76a9be24217f14af8b4e90ac374a00f3e69a4114" translate="yes" xml:space="preserve">
          <source>The returned tensor will contain a serialized &lt;a href=&quot;../../summary&quot;&gt;&lt;code&gt;tf.compat.v1.summary.Summary&lt;/code&gt;&lt;/a&gt; protocol buffer, which can be used with the standard TensorBoard logging facilities.</source>
          <target state="translated">반환 된 텐서는 표준 TensorBoard 로깅 기능과 함께 사용할 수 있는 직렬화 된 &lt;a href=&quot;../../summary&quot;&gt; &lt;code&gt;tf.compat.v1.summary.Summary&lt;/code&gt; &lt;/a&gt; 프로토콜 버퍼를 포함합니다 .</target>
        </trans-unit>
        <trans-unit id="c2eac31d16e8529bfab56c61e3821bc8b01c5d91" translate="yes" xml:space="preserve">
          <source>The returned tensor's dimension &lt;code&gt;i&lt;/code&gt; will correspond to the input dimension &lt;code&gt;perm[i]&lt;/code&gt;. If &lt;code&gt;perm&lt;/code&gt; is not given, it is set to (n-1...0), where n is the rank of the input tensor. Hence by default, this operation performs a regular matrix transpose on 2-D input Tensors.</source>
          <target state="translated">The returned tensor's dimension &lt;code&gt;i&lt;/code&gt; will correspond to the input dimension &lt;code&gt;perm[i]&lt;/code&gt; . If &lt;code&gt;perm&lt;/code&gt; is not given, it is set to (n-1...0), where n is the rank of the input tensor. Hence by default, this operation performs a regular matrix transpose on 2-D input Tensors.</target>
        </trans-unit>
        <trans-unit id="82d1c361e6f8f0d84bf0a1bcea9214b49e8cf3d3" translate="yes" xml:space="preserve">
          <source>The returned tensor's dimension i will correspond to the input dimension &lt;code&gt;perm[i]&lt;/code&gt;. If &lt;code&gt;perm&lt;/code&gt; is not given, it is set to (n-1...0), where n is the rank of the input tensor. Hence by default, this operation performs a regular matrix transpose on 2-D input Tensors.</source>
          <target state="translated">반환 된 텐서의 치수 i는 입력 치수 &lt;code&gt;perm[i]&lt;/code&gt; 합니다. 경우 &lt;code&gt;perm&lt;/code&gt; 부여되지 않으며, 그것은 (1 ... N-0)로 설정, 여기서 n은 입력 텐서의 계수이다. 따라서 기본적으로이 작업은 2 차원 입력 텐서에서 규칙적인 행렬 조옮김을 수행합니다.</target>
        </trans-unit>
        <trans-unit id="d9c115cc2d00147127224aefb2bd6a8e1bbe0c5c" translate="yes" xml:space="preserve">
          <source>The returned tensor's dimension i will correspond to the input dimension &lt;code&gt;perm[i]&lt;/code&gt;. If &lt;code&gt;perm&lt;/code&gt; is not given, it is set to (n-1...0), where n is the rank of the input tensor. Hence by default, this operation performs a regular matrix transpose on 2-D input Tensors. If conjugate is True and &lt;code&gt;a.dtype&lt;/code&gt; is either &lt;code&gt;complex64&lt;/code&gt; or &lt;code&gt;complex128&lt;/code&gt; then the values of &lt;code&gt;a&lt;/code&gt; are conjugated and transposed.</source>
          <target state="translated">반환 된 텐서의 치수 i는 입력 치수 &lt;code&gt;perm[i]&lt;/code&gt; 합니다. 경우 &lt;code&gt;perm&lt;/code&gt; 부여되지 않으며, 그것은 (1 ... N-0)로 설정, 여기서 n은 입력 텐서의 계수이다. 따라서 기본적으로이 작업은 2 차원 입력 텐서에서 규칙적인 행렬 조옮김을 수행합니다. 복합은 True입니다 및 경우 &lt;code&gt;a.dtype&lt;/code&gt; 는 중입니다 &lt;code&gt;complex64&lt;/code&gt; 또는 &lt;code&gt;complex128&lt;/code&gt; 다음의 값 &lt;code&gt;a&lt;/code&gt; 결합하고 전치된다.</target>
        </trans-unit>
        <trans-unit id="838e6e70eeb12ce61fde540b38b4044a46a8f134" translate="yes" xml:space="preserve">
          <source>The returned tensors are &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;s if &lt;code&gt;input&lt;/code&gt; is a scalar, or &lt;a href=&quot;../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;s otherwise.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 스칼라 이면 반환 된 텐서는 &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 이고, 그렇지 않으면 &lt;a href=&quot;../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="710644f5cd50999519cd748e88ddf36f02a2b455" translate="yes" xml:space="preserve">
          <source>The right-hand side of the &lt;code&gt;!=&lt;/code&gt; operator.</source>
          <target state="translated">The right-hand side of the &lt;code&gt;!=&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="e668edbb07540997101fa0f49a39faa5f38caec8" translate="yes" xml:space="preserve">
          <source>The right-hand side of the &lt;code&gt;+&lt;/code&gt; operator.</source>
          <target state="translated">The right-hand side of the &lt;code&gt;+&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="ff72258325f43cdf735f357c785333acbdbfc89a" translate="yes" xml:space="preserve">
          <source>The right-hand side of the &lt;code&gt;==&lt;/code&gt; operator.</source>
          <target state="translated">The right-hand side of the &lt;code&gt;==&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="ca75c2c84ca7c94aaa9f8f708d895cba56b5cf74" translate="yes" xml:space="preserve">
          <source>The row partition tensors are in the order of the dimensions. At present, the types can be:</source>
          <target state="translated">The row partition tensors are in the order of the dimensions. At present, the types can be:</target>
        </trans-unit>
        <trans-unit id="85216d0bd898c6d1680f5aac974d5348d1d96c2f" translate="yes" xml:space="preserve">
          <source>The row-split indices for this ragged tensor's &lt;code&gt;values&lt;/code&gt;.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 &lt;code&gt;values&lt;/code&gt; 대한 행 분할 인덱스 .</target>
        </trans-unit>
        <trans-unit id="5854e78835764512ec754b4ac011bb9b48f7d380" translate="yes" xml:space="preserve">
          <source>The row_splits for all ragged dimensions in this ragged tensor value.</source>
          <target state="translated">이 비정형 텐서 값의 모든 비정형 치수에 대해 row_splits입니다.</target>
        </trans-unit>
        <trans-unit id="5158c81c5ea5bb74de68daed2eacbf5dc32d4ad8" translate="yes" xml:space="preserve">
          <source>The runtime is then free to make optimizations based on this.</source>
          <target state="translated">그런 다음 런타임은이를 기반으로 최적화 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ca5cdf682a9605ca998129dd4a854da399041aba" translate="yes" xml:space="preserve">
          <source>The same array (Numpy array if &lt;code&gt;x&lt;/code&gt; was a Numpy array, or TensorFlow tensor if &lt;code&gt;x&lt;/code&gt; was a tensor), cast to its new type.</source>
          <target state="translated">동일한 배열 ( &lt;code&gt;x&lt;/code&gt; 가 Numpy 배열 인 경우 Numpy 배열 또는 &lt;code&gt;x&lt;/code&gt; 가 텐서 인 경우 TensorFlow 텐서)은 새 유형으로 캐스트됩니다.</target>
        </trans-unit>
        <trans-unit id="e4b3e7c37b806fc9d4b600343aa28d9179c53706" translate="yes" xml:space="preserve">
          <source>The same as &lt;a href=&quot;../../raggedtensor#__div__&quot;&gt;&lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt;&lt;/a&gt; for integers, but uses &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by &lt;code&gt;x // y&lt;/code&gt; floor division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;.</source>
          <target state="translated">정수의 경우 &lt;a href=&quot;../../raggedtensor#__div__&quot;&gt; &lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt; &lt;/a&gt; 와 동일 하지만 부동 소수점 인수에 &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; 를 사용하므로 결과는 항상 정수 ( 부동 소수점으로 표시되는 정수). 이 연산은 &lt;code&gt;from __future__ import division&lt;/code&gt; 하여 Python 3 및 Python 2.7의 &lt;code&gt;x // y&lt;/code&gt; 층 분할에 의해 생성됩니다 .</target>
        </trans-unit>
        <trans-unit id="07525f9495ce7a62b86179e9f6083e34f20d8d8b" translate="yes" xml:space="preserve">
          <source>The same as &lt;a href=&quot;../raggedtensor#__div__&quot;&gt;&lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt;&lt;/a&gt; for integers, but uses &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by &lt;code&gt;x // y&lt;/code&gt; floor division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;.</source>
          <target state="translated">정수의 경우 &lt;a href=&quot;../raggedtensor#__div__&quot;&gt; &lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt; &lt;/a&gt; 와 동일 하지만 부동 소수점 인수에 &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; 를 사용하므로 결과는 항상 정수 ( 부동 소수점으로 표시되는 정수). 이 연산은 &lt;code&gt;from __future__ import division&lt;/code&gt; 하여 Python 3 및 Python 2.7의 &lt;code&gt;x // y&lt;/code&gt; 층 분할에 의해 생성됩니다 .</target>
        </trans-unit>
        <trans-unit id="3240798db52d492b4a5e0a4f1101b0ce22e5dea6" translate="yes" xml:space="preserve">
          <source>The same as &lt;a href=&quot;raggedtensor#__div__&quot;&gt;&lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt;&lt;/a&gt; for integers, but uses &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by &lt;code&gt;x // y&lt;/code&gt; floor division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;.</source>
          <target state="translated">정수의 경우 &lt;a href=&quot;raggedtensor#__div__&quot;&gt; &lt;code&gt;tf.compat.v1.div(x,y)&lt;/code&gt; &lt;/a&gt; 와 동일 하지만 부동 소수점 인수에 &lt;code&gt;tf.floor(tf.compat.v1.div(x,y))&lt;/code&gt; 를 사용하므로 결과는 항상 정수 ( 부동 소수점으로 표시되는 정수). 이 연산은 &lt;code&gt;from __future__ import division&lt;/code&gt; 하여 Python 3 및 Python 2.7의 &lt;code&gt;x // y&lt;/code&gt; 층 분할에 의해 생성됩니다 .</target>
        </trans-unit>
        <trans-unit id="d6016fab50d93b1e77917677d258e0e003f237e6" translate="yes" xml:space="preserve">
          <source>The same tensor &lt;code&gt;x&lt;/code&gt;, unchanged.</source>
          <target state="translated">변경되지 않은 동일한 텐서 &lt;code&gt;x&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e28b3d74027804ad355c817f8c256af8b2d25a2a" translate="yes" xml:space="preserve">
          <source>The samples are differentiable w.r.t. alpha and beta. The derivatives are computed using the approach described in (Figurnov et al., 2018).</source>
          <target state="translated">The samples are differentiable w.r.t. alpha and beta. The derivatives are computed using the approach described in (Figurnov et al., 2018).</target>
        </trans-unit>
        <trans-unit id="2c3935638fc889928b31f22a28b40af71a593afd" translate="yes" xml:space="preserve">
          <source>The samples are differentiable w.r.t. alpha and beta. The derivatives are computed using the approach described in the paper</source>
          <target state="translated">샘플은 구별 가능한 wrt 알파 및 베타이다. 파생 상품은 논문에 설명 된 접근 방식을 사용하여 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="92952659dac1bf101ab8c26a5fd0e7570c899948" translate="yes" xml:space="preserve">
          <source>The sampling probabilities are generated according to the sampling distribution used in word2vec:</source>
          <target state="translated">샘플링 확률은 word2vec에 사용 된 샘플링 분포에 따라 생성됩니다.</target>
        </trans-unit>
        <trans-unit id="7e70c09e21b733e9d2a808af0f600268962663fb" translate="yes" xml:space="preserve">
          <source>The save counter variable.</source>
          <target state="translated">저장 카운터 변수</target>
        </trans-unit>
        <trans-unit id="ab43a8a642f72175fe828def8c8d03e9a692fe7b" translate="yes" xml:space="preserve">
          <source>The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">저장된 검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때이 개체에 따라 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="21ba0881308b74c027819f31603cfc6647b52c80" translate="yes" xml:space="preserve">
          <source>The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">저장된 검사 점에는이 개체에 의해 생성 된 변수와 &lt;a href=&quot;checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save()&lt;/code&gt; &lt;/a&gt; 가 호출 될 때이 개체에 따라 추적 가능한 개체 가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="38adbe2f58aa8b45a85ccd9d545a08f193885a40" translate="yes" xml:space="preserve">
          <source>The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#save&quot;&gt;&lt;code&gt;Checkpoint.save()&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#save&quot;&gt; &lt;code&gt;Checkpoint.save()&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="d6290af5f5d901c235fa2702c12d35d14bd8fbb8" translate="yes" xml:space="preserve">
          <source>The saved dataset is saved in multiple file &quot;shards&quot;. By default, the dataset output is divided to shards in a round-robin fashion but custom sharding can be specified via the &lt;code&gt;shard_func&lt;/code&gt; function. For example, you can save the dataset to using a single shard as follows:</source>
          <target state="translated">The saved dataset is saved in multiple file &quot;shards&quot;. By default, the dataset output is divided to shards in a round-robin fashion but custom sharding can be specified via the &lt;code&gt;shard_func&lt;/code&gt; function. For example, you can save the dataset to using a single shard as follows:</target>
        </trans-unit>
        <trans-unit id="32eabd05b895cc5cbd843e5d58a26478d871b570" translate="yes" xml:space="preserve">
          <source>The saved model contains:</source>
          <target state="translated">The saved model contains:</target>
        </trans-unit>
        <trans-unit id="d3b7070f1ecc16e817793f6b5d01b2b53b58703e" translate="yes" xml:space="preserve">
          <source>The saved model contains: - the model's configuration (topology) - the model's weights - the model's optimizer's state (if any)</source>
          <target state="translated">저장된 모델에는 다음이 포함됩니다.-모델 구성 (토폴로지)-모델 가중치-모델의 옵티 마이저 상태 (있는 경우)</target>
        </trans-unit>
        <trans-unit id="eeb866c0e9b8a790b2b06bb4bf72fe83fcf3b7fd" translate="yes" xml:space="preserve">
          <source>The savefile includes:</source>
          <target state="translated">저장 파일에는 다음이 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="2be8f8b013a0bea1b78a799bc083aef46d344f06" translate="yes" xml:space="preserve">
          <source>The scalar &lt;code&gt;default_value&lt;/code&gt; is the value output for keys not present in the table. It must also be of the same type as the table values.</source>
          <target state="translated">The scalar &lt;code&gt;default_value&lt;/code&gt; is the value output for keys not present in the table. It must also be of the same type as the table values.</target>
        </trans-unit>
        <trans-unit id="ff3fd5f27f08bbd84c446309ecdaecd1825d0b40" translate="yes" xml:space="preserve">
          <source>The scalar PSNR between a and b. The returned tensor has type &lt;a href=&quot;../../tf#float32&quot;&gt;&lt;code&gt;tf.float32&lt;/code&gt;&lt;/a&gt; and shape [batch_size, 1].</source>
          <target state="translated">a와 b 사이의 스칼라 PSNR 반환 된 텐서는 유형이 &lt;a href=&quot;../../tf#float32&quot;&gt; &lt;code&gt;tf.float32&lt;/code&gt; &lt;/a&gt; 이고 모양은 [batch_size, 1]입니다.</target>
        </trans-unit>
        <trans-unit id="dd78e4034ea5bbefe47a5585f3fa965bc5acaa8e" translate="yes" xml:space="preserve">
          <source>The scaled exponential unit activation: &lt;code&gt;scale * elu(x, alpha)&lt;/code&gt;.</source>
          <target state="translated">스케일 된 지수 단위 활성화 : &lt;code&gt;scale * elu(x, alpha)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7cdf9b27ca1dd2bbd540e30d82d6f1126674d88" translate="yes" xml:space="preserve">
          <source>The scaling_factor is determined from &lt;code&gt;min_range&lt;/code&gt;, &lt;code&gt;max_range&lt;/code&gt;, and &lt;code&gt;narrow_range&lt;/code&gt; in a way that is compatible with &lt;code&gt;QuantizeAndDequantize{V2|V3}&lt;/code&gt; and &lt;code&gt;QuantizeV2&lt;/code&gt;, using the following algorithm:</source>
          <target state="translated">scaling_factor는 다음 알고리즘을 사용하여 &lt;code&gt;QuantizeAndDequantize{V2|V3}&lt;/code&gt; 및 &lt;code&gt;QuantizeV2&lt;/code&gt; 와 호환되는 방식으로 &lt;code&gt;min_range&lt;/code&gt; , &lt;code&gt;max_range&lt;/code&gt; 및 &lt;code&gt;narrow_range&lt;/code&gt; 에서 결정됩니다 .</target>
        </trans-unit>
        <trans-unit id="d82c0e384909c0dd188de5ead9b2872459677ae8" translate="yes" xml:space="preserve">
          <source>The schedule a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="translated">현재 옵티 마이저 단계를 통과하면 학습 속도가 저하되는 1-arg 호출 가능 일정입니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c2ad88fa788374ec95b4583696db082a634b18eb" translate="yes" xml:space="preserve">
          <source>The schedule a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:</source>
          <target state="translated">현재 옵티 마이저 단계를 통과하면 학습 속도가 저하되는 1-arg 호출 가능 일정입니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다. 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="71d2993ed1ad7b32ffe04dab2486da899c3f2739" translate="yes" xml:space="preserve">
          <source>The schedule is a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:</source>
          <target state="translated">일정은 현재 최적화 단계를 통과 할 때 학습 속도가 저하되는 1-arg 호출 가능입니다. 이것은 옵티 마이저 함수의 다른 호출에서 학습 속도 값을 변경하는 데 유용 할 수 있습니다. 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="70da9d42a4b299e69bb575bc1c369e715f3022f0" translate="yes" xml:space="preserve">
          <source>The scope for the operations performed in computing the loss.</source>
          <target state="translated">The scope for the operations performed in computing the loss.</target>
        </trans-unit>
        <trans-unit id="2bf5542bf013cf2cd0c7e2cee3c5c6cd6c529ad0" translate="yes" xml:space="preserve">
          <source>The scope name.</source>
          <target state="translated">범위 이름</target>
        </trans-unit>
        <trans-unit id="50f230356c528b135a5e5c8be0185503e716f9b3" translate="yes" xml:space="preserve">
          <source>The second call of &lt;code&gt;foo&lt;/code&gt; returns '(A2, A2)' instead of '(A1, A1)' because &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; maintains an internal counter. If you want &lt;code&gt;foo&lt;/code&gt; to return '(A1, A1)' every time, use the stateless random ops such as &lt;a href=&quot;stateless_uniform&quot;&gt;&lt;code&gt;tf.random.stateless_uniform&lt;/code&gt;&lt;/a&gt;. Also see &lt;a href=&quot;experimental/generator&quot;&gt;&lt;code&gt;tf.random.experimental.Generator&lt;/code&gt;&lt;/a&gt; for a new set of stateful random ops that use external variables to manage their states.</source>
          <target state="translated">&lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 은 내부 카운터를 유지 하므로 &lt;code&gt;foo&lt;/code&gt; 의 두 번째 호출은 '(A1, A1)'대신 '(A2, A2)'를 반환합니다 . 당신이 원하는 경우 &lt;code&gt;foo&lt;/code&gt; 는 '(A1, A1)'반환에 모든 시간을, 같은 상태 비 무작위 작전을 사용 &lt;a href=&quot;stateless_uniform&quot;&gt; &lt;code&gt;tf.random.stateless_uniform&lt;/code&gt; &lt;/a&gt; . 외부 변수를 사용하여 상태를 관리하는 새로운 상태 저장 랜덤 연산 세트에 대해서는 &lt;a href=&quot;experimental/generator&quot;&gt; &lt;code&gt;tf.random.experimental.Generator&lt;/code&gt; &lt;/a&gt; 도 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="99c1ec05a48b05e1a2d2c74a95c41738070d1d52" translate="yes" xml:space="preserve">
          <source>The second call of &lt;code&gt;foo&lt;/code&gt; returns '(A2, A2)' instead of '(A1, A1)' because &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt; maintains an internal counter. If you want &lt;code&gt;foo&lt;/code&gt; to return '(A1, A1)' every time, use the stateless random ops such as &lt;a href=&quot;stateless_uniform&quot;&gt;&lt;code&gt;tf.random.stateless_uniform&lt;/code&gt;&lt;/a&gt;. Also see &lt;a href=&quot;generator&quot;&gt;&lt;code&gt;tf.random.experimental.Generator&lt;/code&gt;&lt;/a&gt; for a new set of stateful random ops that use external variables to manage their states.</source>
          <target state="translated">The second call of &lt;code&gt;foo&lt;/code&gt; returns '(A2, A2)' instead of '(A1, A1)' because &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; maintains an internal counter. If you want &lt;code&gt;foo&lt;/code&gt; to return '(A1, A1)' every time, use the stateless random ops such as &lt;a href=&quot;stateless_uniform&quot;&gt; &lt;code&gt;tf.random.stateless_uniform&lt;/code&gt; &lt;/a&gt;. Also see &lt;a href=&quot;generator&quot;&gt; &lt;code&gt;tf.random.experimental.Generator&lt;/code&gt; &lt;/a&gt; for a new set of stateful random ops that use external variables to manage their states.</target>
        </trans-unit>
        <trans-unit id="08568c721bd015f102f6c3ec1b535d6153171292" translate="yes" xml:space="preserve">
          <source>The second dict contains the feature_list key/values.</source>
          <target state="translated">두 번째 dict에는 feature_list 키 / 값이 포함되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="55c0e48b341890b90c7222213ebdf6711ed127c5" translate="yes" xml:space="preserve">
          <source>The second distribution.</source>
          <target state="translated">The second distribution.</target>
        </trans-unit>
        <trans-unit id="73916e07f6ea34c81abd799027349571045df1c6" translate="yes" xml:space="preserve">
          <source>The second innermost dimension of &lt;code&gt;diagonal&lt;/code&gt; has double meaning. When &lt;code&gt;k&lt;/code&gt; is scalar or &lt;code&gt;k[0] == k[1]&lt;/code&gt;, &lt;code&gt;M&lt;/code&gt; is part of the batch size [I, J, ..., M], and the output tensor is:</source>
          <target state="translated">&lt;code&gt;diagonal&lt;/code&gt; 의 두 번째 가장 안쪽 치수 는 이중 의미를 갖습니다. 되면 &lt;code&gt;k&lt;/code&gt; 는 스칼라이거나 &lt;code&gt;k[0] == k[1]&lt;/code&gt; , &lt;code&gt;M&lt;/code&gt; 은 배치 크기 [I, J, ..., M]의 일부이며, 상기 출력 텐서이다 :</target>
        </trans-unit>
        <trans-unit id="897c8f258e58c08596b32bdbc51f703aa19e32cb" translate="yes" xml:space="preserve">
          <source>The second list to compare.</source>
          <target state="translated">The second list to compare.</target>
        </trans-unit>
        <trans-unit id="07d2101b8340d508be1c61741652a76d9deb3b07" translate="yes" xml:space="preserve">
          <source>The second operand; &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt;. At least one operand must be sparse.</source>
          <target state="translated">The second operand; &lt;code&gt;SparseTensor&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt; . At least one operand must be sparse.</target>
        </trans-unit>
        <trans-unit id="eb28a5566b72083d75d5c15273e66594bb2b10e4" translate="yes" xml:space="preserve">
          <source>The second sequence to compare.</source>
          <target state="translated">The second sequence to compare.</target>
        </trans-unit>
        <trans-unit id="f44476a07dabc329393369e874eaf7a10133de21" translate="yes" xml:space="preserve">
          <source>The second set to compare.</source>
          <target state="translated">The second set to compare.</target>
        </trans-unit>
        <trans-unit id="f193b83c375843f2a04bc17c95ee85c91007fcdb" translate="yes" xml:space="preserve">
          <source>The second structure to compare.</source>
          <target state="translated">The second structure to compare.</target>
        </trans-unit>
        <trans-unit id="d1bef3c10ad61ff65c7724ce0d24e0698479866c" translate="yes" xml:space="preserve">
          <source>The second tuple to compare.</source>
          <target state="translated">The second tuple to compare.</target>
        </trans-unit>
        <trans-unit id="b310dae88696133dc7ed85369e494d665ee6beaf" translate="yes" xml:space="preserve">
          <source>The second variant is compatible with CuDNNGRU (GPU-only) and allows inference on CPU. Thus it has separate biases for &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;recurrent_kernel&lt;/code&gt;. To use this variant, set &lt;code&gt;'reset_after'=True&lt;/code&gt; and &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt;.</source>
          <target state="translated">두 번째 변형은 CuDNNGRU (GPU 전용)와 호환되며 CPU에 대한 추론을 허용합니다. 따라서 &lt;code&gt;kernel&lt;/code&gt; 과 &lt;code&gt;recurrent_kernel&lt;/code&gt; 에 대한 별도의 바이어스가 있습니다. 이 변형을 사용하려면 &lt;code&gt;'reset_after'=True&lt;/code&gt; 및 &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt; 를 설정하십시오 .</target>
        </trans-unit>
        <trans-unit id="44fd41a3b2fd550cb5e331da22b4349e8495f086" translate="yes" xml:space="preserve">
          <source>The second variant is compatible with CuDNNGRU (GPU-only) and allows inference on CPU. Thus it has separate biases for &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;recurrent_kernel&lt;/code&gt;. Use &lt;code&gt;'reset_after'=True&lt;/code&gt; and &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt;.</source>
          <target state="translated">두 번째 변형은 CuDNNGRU (GPU 전용)와 호환되며 CPU에 대한 추론을 허용합니다. 따라서 &lt;code&gt;kernel&lt;/code&gt; 과 &lt;code&gt;recurrent_kernel&lt;/code&gt; 에 대한 별도의 바이어스가 있습니다. 사용 &lt;code&gt;'reset_after'=True&lt;/code&gt; 과 &lt;code&gt;recurrent_activation='sigmoid'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5ef054429664e25cebbffadf1c7499db194568c6" translate="yes" xml:space="preserve">
          <source>The second way is through a callable function that does not accept any arguments.</source>
          <target state="translated">The second way is through a callable function that does not accept any arguments.</target>
        </trans-unit>
        <trans-unit id="9b1ff7b195e25bb1e934a1faddac3cb31e9dda14" translate="yes" xml:space="preserve">
          <source>The selected tensor.</source>
          <target state="translated">선택된 텐서.</target>
        </trans-unit>
        <trans-unit id="6d81fff9b6102438ec592417def3c2112c0846b7" translate="yes" xml:space="preserve">
          <source>The semantics of the input tensor depends on tensor_debug_mode. In typical usage, the input tensor comes directly from the user computation only when graph_debug_mode is FULL_TENSOR (see protobuf/debug_event.proto for a list of all the possible values of graph_debug_mode). For the other debug modes, the input tensor should be produced by an additional op or subgraph that computes summary information about one or more tensors.</source>
          <target state="translated">The semantics of the input tensor depends on tensor_debug_mode. In typical usage, the input tensor comes directly from the user computation only when graph_debug_mode is FULL_TENSOR (see protobuf/debug_event.proto for a list of all the possible values of graph_debug_mode). For the other debug modes, the input tensor should be produced by an additional op or subgraph that computes summary information about one or more tensors.</target>
        </trans-unit>
        <trans-unit id="1450544c35748cfa003192a74e09ceb10f67e4f7" translate="yes" xml:space="preserve">
          <source>The separator string used between ngram elements. Must be a string constant, not a Tensor.</source>
          <target state="translated">The separator string used between ngram elements. Must be a string constant, not a Tensor.</target>
        </trans-unit>
        <trans-unit id="c84f4757d0db527182bb06d2afdc87b1042d6fea" translate="yes" xml:space="preserve">
          <source>The sequence in which to look for prefix.</source>
          <target state="translated">The sequence in which to look for prefix.</target>
        </trans-unit>
        <trans-unit id="14448741add9013596276b373f9b2b4fe8b71b2b" translate="yes" xml:space="preserve">
          <source>The sequence of &lt;code&gt;Tensor&lt;/code&gt; objects representing the data inputs of this op.</source>
          <target state="translated">이 op의 데이터 입력을 나타내는 &lt;code&gt;Tensor&lt;/code&gt; 객체 의 시퀀스입니다 .</target>
        </trans-unit>
        <trans-unit id="ad56b1734b2aec94010201da62b3c74ae59652ee" translate="yes" xml:space="preserve">
          <source>The sequence that we are testing.</source>
          <target state="translated">The sequence that we are testing.</target>
        </trans-unit>
        <trans-unit id="9c721fd10cd508d808b1312a2194dc7e4890a7fc" translate="yes" xml:space="preserve">
          <source>The serialized &lt;code&gt;GraphDef&lt;/code&gt; can be imported into another &lt;code&gt;Graph&lt;/code&gt; (using &lt;a href=&quot;graph_util/import_graph_def&quot;&gt;&lt;code&gt;tf.import_graph_def&lt;/code&gt;&lt;/a&gt;) or used with the &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/cc/index&quot;&gt;C++ Session API&lt;/a&gt;.</source>
          <target state="translated">직렬화 된 &lt;code&gt;GraphDef&lt;/code&gt; 를 다른 &lt;code&gt;Graph&lt;/code&gt; 로 가져 오거나 ( &lt;a href=&quot;graph_util/import_graph_def&quot;&gt; &lt;code&gt;tf.import_graph_def&lt;/code&gt; &lt;/a&gt; 사용 ) &lt;a href=&quot;https://www.tensorflow.org/api_docs/api_docs/cc/index&quot;&gt;C ++ 세션 API&lt;/a&gt; 와 함께 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="73859165e320015abdcf466de88e9720ebb22082" translate="yes" xml:space="preserve">
          <source>The serialized &lt;code&gt;GraphDef&lt;/code&gt; can be imported into another &lt;code&gt;Graph&lt;/code&gt; (using &lt;a href=&quot;graph_util/import_graph_def&quot;&gt;&lt;code&gt;tf.import_graph_def&lt;/code&gt;&lt;/a&gt;) or used with the &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/cc/index&quot;&gt;C++ Session API&lt;/a&gt;.</source>
          <target state="translated">The serialized &lt;code&gt;GraphDef&lt;/code&gt; can be imported into another &lt;code&gt;Graph&lt;/code&gt; (using &lt;a href=&quot;graph_util/import_graph_def&quot;&gt; &lt;code&gt;tf.import_graph_def&lt;/code&gt; &lt;/a&gt;) or used with the &lt;a href=&quot;https://www.tensorflow.org/versions/r2.3/api_docs/api_docs/cc/index&quot;&gt;C++ Session API&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="766157bb0379c94a2b06eab4d5860dfc7335b141" translate="yes" xml:space="preserve">
          <source>The session to evaluate variables in. Ignored when executing eagerly. If not provided when graph building, the default session is used.</source>
          <target state="translated">The session to evaluate variables in. Ignored when executing eagerly. If not provided when graph building, the default session is used.</target>
        </trans-unit>
        <trans-unit id="4a72456f672e80ba24848fd6a912b31242ea6b05" translate="yes" xml:space="preserve">
          <source>The session to use to evaluate this variable. If none, the default session is used.</source>
          <target state="translated">The session to use to evaluate this variable. If none, the default session is used.</target>
        </trans-unit>
        <trans-unit id="ec73351af802bdf6746d29fb3d40b6d4c532bba4" translate="yes" xml:space="preserve">
          <source>The set of absent/default values may be specified using a vector of lengths or a padding value (but not both). If &lt;code&gt;lengths&lt;/code&gt; is specified, then the output tensor will satisfy &lt;code&gt;output[row] = tensor[row][:lengths[row]]&lt;/code&gt;. If 'lengths' is a list of lists or tuple of lists, those lists will be used as nested row lengths. If &lt;code&gt;padding&lt;/code&gt; is specified, then any row &lt;em&gt;suffix&lt;/em&gt; consisting entirely of &lt;code&gt;padding&lt;/code&gt; will be excluded from the returned &lt;code&gt;RaggedTensor&lt;/code&gt;. If neither &lt;code&gt;lengths&lt;/code&gt; nor &lt;code&gt;padding&lt;/code&gt; is specified, then the returned &lt;code&gt;RaggedTensor&lt;/code&gt; will have no absent/default values.</source>
          <target state="translated">부재 / 기본 값 세트는 길이 벡터 또는 패딩 값 (둘다는 아님)을 사용하여 지정할 수 있습니다. 경우 &lt;code&gt;lengths&lt;/code&gt; 지정되어, 출력 텐서 만족 &lt;code&gt;output[row] = tensor[row][:lengths[row]]&lt;/code&gt; . 'lengths'가 목록의 목록 또는 튜플 목록 인 경우 해당 목록은 중첩 행 길이로 사용됩니다. 경우 &lt;code&gt;padding&lt;/code&gt; 지정하면 모든 행 &lt;em&gt;접미사&lt;/em&gt; 완전히 구성된 &lt;code&gt;padding&lt;/code&gt; 반환에서 제외됩니다 &lt;code&gt;RaggedTensor&lt;/code&gt; . &lt;code&gt;lengths&lt;/code&gt; 와 &lt;code&gt;padding&lt;/code&gt; 이 모두 지정 되지 않으면 반환 된 &lt;code&gt;RaggedTensor&lt;/code&gt; 에 결근 값 / 기본값이 없습니다.</target>
        </trans-unit>
        <trans-unit id="0c1258f12879c9bd1b917a210f7db35cdd522088" translate="yes" xml:space="preserve">
          <source>The set of ops to be run as part of the main op upon the load operation.</source>
          <target state="translated">로드 작업시 기본 op의 일부로 실행되는 op 세트입니다.</target>
        </trans-unit>
        <trans-unit id="b8a942e9ca1e31cdbe28c47ba81e62ec5b4daae6" translate="yes" xml:space="preserve">
          <source>The set of variable names to convert (by default, all variables are converted).</source>
          <target state="translated">The set of variable names to convert (by default, all variables are converted).</target>
        </trans-unit>
        <trans-unit id="708ef0da29666e679f2d004edd19c8b18d49eb0b" translate="yes" xml:space="preserve">
          <source>The set of variable names to omit converting to constants.</source>
          <target state="translated">The set of variable names to omit converting to constants.</target>
        </trans-unit>
        <trans-unit id="4fc94cf8836a9ff2b4e0118d0144216371d4137e" translate="yes" xml:space="preserve">
          <source>The shape and dtype of any intermediate or output tensors in the computation of &lt;code&gt;fn&lt;/code&gt; should not depend on the input to &lt;code&gt;fn&lt;/code&gt;.</source>
          <target state="translated">The shape and dtype of any intermediate or output tensors in the computation of &lt;code&gt;fn&lt;/code&gt; should not depend on the input to &lt;code&gt;fn&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="915b2e710b3b023da7cd3921f1c34459542c194c" translate="yes" xml:space="preserve">
          <source>The shape for individual flat values in the &lt;code&gt;RaggedTensor&lt;/code&gt;.</source>
          <target state="translated">The shape for individual flat values in the &lt;code&gt;RaggedTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b1218538acb5cc473fe08e57d6e893aaca21938d" translate="yes" xml:space="preserve">
          <source>The shape format of the &lt;code&gt;inputs&lt;/code&gt; Tensors. If True, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[max_time, batch_size, num_classes]&lt;/code&gt;. If False, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[batch_size, max_time, num_classes]&lt;/code&gt;. Using &lt;code&gt;time_major = True&lt;/code&gt; (default) is a bit more efficient because it avoids transposes at the beginning of the ctc_loss calculation. However, most TensorFlow data is batch-major, so by this function also accepts inputs in batch-major form.</source>
          <target state="translated">The shape format of the &lt;code&gt;inputs&lt;/code&gt; Tensors. If True, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[max_time, batch_size, num_classes]&lt;/code&gt; . If False, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[batch_size, max_time, num_classes]&lt;/code&gt; . Using &lt;code&gt;time_major = True&lt;/code&gt; (default) is a bit more efficient because it avoids transposes at the beginning of the ctc_loss calculation. However, most TensorFlow data is batch-major, so by this function also accepts inputs in batch-major form.</target>
        </trans-unit>
        <trans-unit id="cd03f61b772d8cecf2105a6fa68f431df30d2490" translate="yes" xml:space="preserve">
          <source>The shape format of the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; Tensors. If true, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[max_time, batch_size, depth]&lt;/code&gt;. If false, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[batch_size, max_time, depth]&lt;/code&gt;. Using &lt;code&gt;time_major = True&lt;/code&gt; is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.</source>
          <target state="translated">The shape format of the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; Tensors. If true, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[max_time, batch_size, depth]&lt;/code&gt; . If false, these &lt;code&gt;Tensors&lt;/code&gt; must be shaped &lt;code&gt;[batch_size, max_time, depth]&lt;/code&gt; . Using &lt;code&gt;time_major = True&lt;/code&gt; is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.</target>
        </trans-unit>
        <trans-unit id="e4fa5d6d5a2b3f7febe8c6a21da6334423de8f46" translate="yes" xml:space="preserve">
          <source>The shape format of the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; tensors. If True, the inputs and outputs will be in shape &lt;code&gt;(timesteps, batch, ...)&lt;/code&gt;, whereas in the False case, it will be &lt;code&gt;(batch, timesteps, ...)&lt;/code&gt;. Using &lt;code&gt;time_major = True&lt;/code&gt; is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.</source>
          <target state="translated">The shape format of the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; tensors. If True, the inputs and outputs will be in shape &lt;code&gt;(timesteps, batch, ...)&lt;/code&gt; , whereas in the False case, it will be &lt;code&gt;(batch, timesteps, ...)&lt;/code&gt; . Using &lt;code&gt;time_major = True&lt;/code&gt; is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.</target>
        </trans-unit>
        <trans-unit id="1ca9d07b430e38f671c59fb716e05624f9098d82" translate="yes" xml:space="preserve">
          <source>The shape format of the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; tensors. If True, the inputs and outputs will be in shape &lt;code&gt;[timesteps, batch, feature]&lt;/code&gt;, whereas in the False case, it will be &lt;code&gt;[batch, timesteps, feature]&lt;/code&gt;. Using &lt;code&gt;time_major = True&lt;/code&gt; is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.</source>
          <target state="translated">The shape format of the &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; tensors. If True, the inputs and outputs will be in shape &lt;code&gt;[timesteps, batch, feature]&lt;/code&gt; , whereas in the False case, it will be &lt;code&gt;[batch, timesteps, feature]&lt;/code&gt; . Using &lt;code&gt;time_major = True&lt;/code&gt; is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.</target>
        </trans-unit>
        <trans-unit id="9705c68d850f3729f14c8b0e86c4e7a7c9b8a9c5" translate="yes" xml:space="preserve">
          <source>The shape inference functions propagate shapes to the extent possible:</source>
          <target state="translated">The shape inference functions propagate shapes to the extent possible:</target>
        </trans-unit>
        <trans-unit id="b9cb3dea60cfc74ebbae7817c2108c229a9e9930" translate="yes" xml:space="preserve">
          <source>The shape invariants for the loop variables.</source>
          <target state="translated">The shape invariants for the loop variables.</target>
        </trans-unit>
        <trans-unit id="081af2a7657fa36a381b1785e67936a8d191debb" translate="yes" xml:space="preserve">
          <source>The shape is computed using shape inference functions that are registered for each &lt;a href=&quot;operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The shape is computed using shape inference functions that are registered for each &lt;a href=&quot;operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="7bc1bd93e711b8be01e066d838cfcf34409f0c38" translate="yes" xml:space="preserve">
          <source>The shape is computed using shape inference functions that are registered in the Op for each &lt;code&gt;Operation&lt;/code&gt;. See &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; for more details of what a shape represents.</source>
          <target state="translated">셰이프는 각 &lt;code&gt;Operation&lt;/code&gt; 에 대해 Op에 등록 된 셰이프 유추 함수를 사용하여 계산됩니다 . 참조 &lt;a href=&quot;tensorshape&quot;&gt; &lt;code&gt;tf.TensorShape&lt;/code&gt; 을&lt;/a&gt; 모양이 무엇을 나타내는 자세한 내용.</target>
        </trans-unit>
        <trans-unit id="5319f783b1231c02b92342d27602eef300f0a629" translate="yes" xml:space="preserve">
          <source>The shape of arguments to &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;cdf&lt;/code&gt;, &lt;code&gt;log_cdf&lt;/code&gt;, &lt;code&gt;prob&lt;/code&gt;, and &lt;code&gt;log_prob&lt;/code&gt; reflect this broadcasting, as does the return value of &lt;code&gt;sample&lt;/code&gt; and &lt;code&gt;sample_n&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;__init__&lt;/code&gt; , &lt;code&gt;cdf&lt;/code&gt; , &lt;code&gt;log_cdf&lt;/code&gt; , &lt;code&gt;prob&lt;/code&gt; 및 &lt;code&gt;log_prob&lt;/code&gt; 의 인수 모양은 &lt;code&gt;sample&lt;/code&gt; 및 &lt;code&gt;sample_n&lt;/code&gt; 의 반환 값 과 마찬가지로이 브로드 캐스트를 반영합니다 .</target>
        </trans-unit>
        <trans-unit id="c9539ceccae379560bc28e4de427220124dc1b7f" translate="yes" xml:space="preserve">
          <source>The shape of each element in the &lt;code&gt;TensorArray&lt;/code&gt;.</source>
          <target state="translated">The shape of each element in the &lt;code&gt;TensorArray&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="019adcd66453633d864b6a68c6e8a1ef2fb39d18" translate="yes" xml:space="preserve">
          <source>The shape of the &lt;code&gt;indices&lt;/code&gt; component, which indicates how many slices are in the &lt;code&gt;IndexedSlices&lt;/code&gt;.</source>
          <target state="translated">The shape of the &lt;code&gt;indices&lt;/code&gt; component, which indicates how many slices are in the &lt;code&gt;IndexedSlices&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2a83199f6a8139b3838bc185a252e39d72f892d5" translate="yes" xml:space="preserve">
          <source>The shape of the RaggedTensor, or &lt;code&gt;None&lt;/code&gt; to allow any shape. If a shape is specified, then all ragged dimensions must have size &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">The shape of the RaggedTensor, or &lt;code&gt;None&lt;/code&gt; to allow any shape. If a shape is specified, then all ragged dimensions must have size &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aed84e9082260c1530ba06836ab583c0743099df" translate="yes" xml:space="preserve">
          <source>The shape of the elements of the given list, as a tensor.</source>
          <target state="translated">The shape of the elements of the given list, as a tensor.</target>
        </trans-unit>
        <trans-unit id="7ae769cd7a979ed862a9572cd30406fef8fee2dc" translate="yes" xml:space="preserve">
          <source>The shape of the input data per sequence id. E.g. if &lt;code&gt;shape=(2,)&lt;/code&gt;, each example must contain &lt;code&gt;2 * sequence_length&lt;/code&gt; values.</source>
          <target state="translated">The shape of the input data per sequence id. E.g. if &lt;code&gt;shape=(2,)&lt;/code&gt; , each example must contain &lt;code&gt;2 * sequence_length&lt;/code&gt; values.</target>
        </trans-unit>
        <trans-unit id="3720998b3d73539e8c9661d288914e2cdaa82ba7" translate="yes" xml:space="preserve">
          <source>The shape of the output tensor is:</source>
          <target state="translated">출력 텐서의 모양은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b54a3296d32e764f7303629c8f4e133de6a9a7b0" translate="yes" xml:space="preserve">
          <source>The shape of the output will be:</source>
          <target state="translated">출력 형태는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="ac04b940314214f5e17141730326fbc95d00e6e3" translate="yes" xml:space="preserve">
          <source>The shape of the resulting dense tensor. In particular, &lt;code&gt;result.shape[i]&lt;/code&gt; is &lt;code&gt;shape[i]&lt;/code&gt; (if &lt;code&gt;shape[i]&lt;/code&gt; is not None), or &lt;code&gt;self.bounding_shape(i)&lt;/code&gt; (otherwise).&lt;code&gt;shape.rank&lt;/code&gt; must be &lt;code&gt;None&lt;/code&gt; or equal to &lt;code&gt;self.rank&lt;/code&gt;.</source>
          <target state="translated">The shape of the resulting dense tensor. In particular, &lt;code&gt;result.shape[i]&lt;/code&gt; is &lt;code&gt;shape[i]&lt;/code&gt; (if &lt;code&gt;shape[i]&lt;/code&gt; is not None), or &lt;code&gt;self.bounding_shape(i)&lt;/code&gt; (otherwise). &lt;code&gt;shape.rank&lt;/code&gt; must be &lt;code&gt;None&lt;/code&gt; or equal to &lt;code&gt;self.rank&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2c9a810e455caa2b0b6f686bf9c200a962c54ef3" translate="yes" xml:space="preserve">
          <source>The shape of the state is algorithm-specific.</source>
          <target state="translated">The shape of the state is algorithm-specific.</target>
        </trans-unit>
        <trans-unit id="3389c6b2701837ccb66fc16af6826d909f63b514" translate="yes" xml:space="preserve">
          <source>The shape of the tensor to be fed (optional). If the shape is not specified, you can feed a sparse tensor of any shape.</source>
          <target state="translated">The shape of the tensor to be fed (optional). If the shape is not specified, you can feed a sparse tensor of any shape.</target>
        </trans-unit>
        <trans-unit id="376d2cc370b5ba232fdf37d951603c116bb04786" translate="yes" xml:space="preserve">
          <source>The shape of the tensor to be fed (optional). If the shape is not specified, you can feed a tensor of any shape.</source>
          <target state="translated">The shape of the tensor to be fed (optional). If the shape is not specified, you can feed a tensor of any shape.</target>
        </trans-unit>
        <trans-unit id="b04d4e03100c6f081b5e785ea772cca017db1933" translate="yes" xml:space="preserve">
          <source>The shapes of the two operands must match: broadcasting is not supported.</source>
          <target state="translated">두 피연산자의 모양이 일치해야합니다. 브로드 캐스트는 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="348113de328d02812f9ca2ed7f6d52b929c19ce9" translate="yes" xml:space="preserve">
          <source>The simplest form of RNN network generated is:</source>
          <target state="translated">생성 된 가장 간단한 형태의 RNN 네트워크는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="ff2f171ddc511ae06abeb2ff57b6d8a5b4678a63" translate="yes" xml:space="preserve">
          <source>The simplest form of scatter is to insert individual elements in a tensor by index. For example, say we want to insert 4 scattered elements in a rank-1 tensor with 8 elements.</source>
          <target state="translated">분산의 가장 간단한 형태는 인덱스로 텐서에 개별 요소를 삽입하는 것입니다. 예를 들어, 4 개의 산란 된 요소를 8 개의 요소가있는 랭크 -1 텐서에 삽입하려고합니다.</target>
        </trans-unit>
        <trans-unit id="f366cdfba69e2fc90954206f2645c89f45fbcd17" translate="yes" xml:space="preserve">
          <source>The simplest form of tensor_scatter_add is to add individual elements to a tensor by index. For example, say we want to add 4 elements in a rank-1 tensor with 8 elements.</source>
          <target state="translated">tensor_scatter_add의 가장 간단한 형식은 인덱스별로 개별 요소를 텐서에 추가하는 것입니다. 예를 들어 8 개의 요소가있는 순위 1 텐서에 4 개의 요소를 추가한다고 가정합니다.</target>
        </trans-unit>
        <trans-unit id="3af9f04f82cbb797b19d70da5fb65e10e6f6ef91" translate="yes" xml:space="preserve">
          <source>The simplest form of tensor_scatter_sub is to subtract individual elements from a tensor by index. For example, say we want to insert 4 scattered elements in a rank-1 tensor with 8 elements.</source>
          <target state="translated">tensor_scatter_sub의 가장 간단한 형식은 인덱스로 텐서에서 개별 요소를 빼는 것입니다. 예를 들어, 4 개의 산란 된 요소를 8 개의 요소가있는 랭크 -1 텐서에 삽입하려고합니다.</target>
        </trans-unit>
        <trans-unit id="802d517fc471afa54d770d15cdbc678a89e0c7a9" translate="yes" xml:space="preserve">
          <source>The simplest version of &lt;code&gt;map_fn&lt;/code&gt; repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from first to last. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt;. &lt;code&gt;dtype&lt;/code&gt; is the data type of the return value of &lt;code&gt;fn&lt;/code&gt;. Users must provide &lt;code&gt;dtype&lt;/code&gt; if it is different from the data type of &lt;code&gt;elems&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;map_fn&lt;/code&gt; 의 가장 간단한 버전은 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 처음부터 끝까지 일련의 요소에 반복적으로 적용합니다 . 요소는 &lt;code&gt;elems&lt;/code&gt; 에서 압축이 풀린 텐서로 만들어집니다 . &lt;code&gt;dtype&lt;/code&gt; 은 &lt;code&gt;fn&lt;/code&gt; 반환 값의 데이터 유형입니다 . 사용자가 제공해야 &lt;code&gt;dtype&lt;/code&gt; 그것의 데이터 유형과 다른 경우 &lt;code&gt;elems&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7f6d20e0852a13ae739990f6fedc34688b995c0" translate="yes" xml:space="preserve">
          <source>The simplest version of &lt;code&gt;scan&lt;/code&gt; repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from first to last. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt; on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn, and the second is the value at the current position of &lt;code&gt;elems&lt;/code&gt;. If &lt;code&gt;initializer&lt;/code&gt; is None, &lt;code&gt;elems&lt;/code&gt; must contain at least one element, and its first element is used as the initializer.</source>
          <target state="translated">가장 간단한 &lt;code&gt;scan&lt;/code&gt; 버전은 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 처음부터 끝까지 일련의 요소에 반복적으로 적용합니다 . 이 요소에서 압축 해제 텐서 이루어지는 &lt;code&gt;elems&lt;/code&gt; : 호출 FN 인수로 두 텐서 소요 치수에 0. 첫 번째 인수는 이전의 fn 호출에서 계산 된 누적 값이고 두 번째 인수는 현재 위치의 값입니다. &lt;code&gt;elems&lt;/code&gt; 입니다. 경우 &lt;code&gt;initializer&lt;/code&gt; 없음입니다, &lt;code&gt;elems&lt;/code&gt; 는 적어도 하나 개의 요소를 포함해야하고, 첫 번째 요소는 초기화로 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="7a38981091aad7a606ea4d4d2a567d64ac905976" translate="yes" xml:space="preserve">
          <source>The simplest way to create a dataset is to create it from a python &lt;code&gt;list&lt;/code&gt;:</source>
          <target state="translated">데이터 셋을 생성하는 가장 간단한 방법은 파이썬 &lt;code&gt;list&lt;/code&gt; 에서 생성하는 것입니다 .</target>
        </trans-unit>
        <trans-unit id="8c730f2755df0951b225a0138c6c5b2d885cf90a" translate="yes" xml:space="preserve">
          <source>The size of &lt;code&gt;tensor_names&lt;/code&gt; must match the number of tensors in &lt;code&gt;data&lt;/code&gt;. &lt;code&gt;data[i]&lt;/code&gt; is written to &lt;code&gt;filename&lt;/code&gt; with name &lt;code&gt;tensor_names[i]&lt;/code&gt;.</source>
          <target state="translated">The size of &lt;code&gt;tensor_names&lt;/code&gt; must match the number of tensors in &lt;code&gt;data&lt;/code&gt; . &lt;code&gt;data[i]&lt;/code&gt; is written to &lt;code&gt;filename&lt;/code&gt; with name &lt;code&gt;tensor_names[i]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ab51731901ff080d9eff54a48d6859d0f1323c1a" translate="yes" xml:space="preserve">
          <source>The size of the resulting dataset will match the size of the smallest input dataset, and no error will be raised if input datasets have different sizes.</source>
          <target state="translated">The size of the resulting dataset will match the size of the smallest input dataset, and no error will be raised if input datasets have different sizes.</target>
        </trans-unit>
        <trans-unit id="017e6c560666c8b8adcda856df4242248fd294ae" translate="yes" xml:space="preserve">
          <source>The sizes of the pooling regions are generated randomly but are fairly uniform. For example, let's look at the height dimension, and the constraints on the list of rows that will be pool boundaries.</source>
          <target state="translated">풀링 영역의 크기는 무작위로 생성되지만 상당히 균일합니다. 예를 들어, 높이 차원과 풀 경계가 될 행 목록의 제약 조건을 살펴 보겠습니다.</target>
        </trans-unit>
        <trans-unit id="3c43eb48e9249082c6dab3dc37ecd5648014a1b5" translate="yes" xml:space="preserve">
          <source>The snapshot API allows users to transparently persist the output of their preprocessing pipeline to disk, and materialize the pre-processed data on a different training run.</source>
          <target state="translated">The snapshot API allows users to transparently persist the output of their preprocessing pipeline to disk, and materialize the pre-processed data on a different training run.</target>
        </trans-unit>
        <trans-unit id="50a231b5d401442573df3e17bbb0c7335e8e5d44" translate="yes" xml:space="preserve">
          <source>The softmax of each vector x is calculated by &lt;code&gt;exp(x)/tf.reduce_sum(exp(x))&lt;/code&gt;. The input values in are the log-odds of the resulting probability.</source>
          <target state="translated">각 벡터 x의 소프트 맥스는 &lt;code&gt;exp(x)/tf.reduce_sum(exp(x))&lt;/code&gt; . 입력 값은 결과 확률의 로그 홀수입니다.</target>
        </trans-unit>
        <trans-unit id="887fc2159220b03235a84826c28912f3876b1988" translate="yes" xml:space="preserve">
          <source>The softmax of each vector x is computed as &lt;code&gt;exp(x) / tf.reduce_sum(exp(x))&lt;/code&gt;.</source>
          <target state="translated">The softmax of each vector x is computed as &lt;code&gt;exp(x) / tf.reduce_sum(exp(x))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b6d8793457c083f0d11acb319bb58de8dcf61657" translate="yes" xml:space="preserve">
          <source>The softplus activation: &lt;code&gt;log(exp(x) + 1)&lt;/code&gt;.</source>
          <target state="translated">softplus 활성화 : &lt;code&gt;log(exp(x) + 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a35f61726860bd793a42b2269f7f12bfff5f5061" translate="yes" xml:space="preserve">
          <source>The softplus activation: &lt;code&gt;x / (abs(x) + 1)&lt;/code&gt;.</source>
          <target state="translated">softplus 활성화 : &lt;code&gt;x / (abs(x) + 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6cdf43d3dd10a8cc3aa784daa0a9e1312644b77d" translate="yes" xml:space="preserve">
          <source>The softsign activation: &lt;code&gt;x / (abs(x) + 1)&lt;/code&gt;.</source>
          <target state="translated">The softsign activation: &lt;code&gt;x / (abs(x) + 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6542d7e39f0c310801daa6538837ad6138ffae82" translate="yes" xml:space="preserve">
          <source>The solution is to ensure any access to the underlying resource &lt;code&gt;v&lt;/code&gt; is only processed through a critical section:</source>
          <target state="translated">해결책은 기본 리소스에 대한 액세스를 보장하는 것입니다 &lt;code&gt;v&lt;/code&gt; 에 중요한 섹션을 통해서만 처리되도록하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="48c0d2fec393318121a3ea291f2dd8dccd7b38fa" translate="yes" xml:space="preserve">
          <source>The solution is to identify which gradient call this particular TensorArray gradient is being called in. This is performed by identifying a unique string (e.g. &quot;gradients&quot;, &quot;gradients_1&quot;, ...) from the input gradient Tensor's name. This string is used as a suffix when creating the TensorArray gradient object here (the attribute &lt;code&gt;source&lt;/code&gt;).</source>
          <target state="translated">The solution is to identify which gradient call this particular TensorArray gradient is being called in. This is performed by identifying a unique string (e.g. &quot;gradients&quot;, &quot;gradients_1&quot;, ...) from the input gradient Tensor's name. This string is used as a suffix when creating the TensorArray gradient object here (the attribute &lt;code&gt;source&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="8a9c87c3bbd16608d71f6244bf102c899fcfe323" translate="yes" xml:space="preserve">
          <source>The solution is to wrap the model construction and execution in a keras-style scope:</source>
          <target state="translated">해결책은 모델 구성 및 실행을 keras 스타일 범위로 감싸는 것입니다.</target>
        </trans-unit>
        <trans-unit id="e590f462584ca8d9fda3b6ea3ab70cb8db99fef3" translate="yes" xml:space="preserve">
          <source>The source of the non-determinism will be platform- and time-dependent.</source>
          <target state="translated">비결정론의 근원은 플랫폼 및 시간에 따라 다릅니다.</target>
        </trans-unit>
        <trans-unit id="7b94d68698f376ae68caf545ac2ad9ff65451535" translate="yes" xml:space="preserve">
          <source>The sparse implementation of this algorithm (used when the gradient is an IndexedSlices object, typically because of &lt;a href=&quot;../../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt; or an embedding lookup in the forward pass) does apply momentum to variable slices even if they were not used in the forward pass (meaning they have a gradient equal to zero). Momentum decay (beta1) is also applied to the entire momentum accumulator. This means that the sparse behavior is equivalent to the dense behavior (in contrast to some momentum implementations which ignore momentum unless a variable slice was actually used).</source>
          <target state="translated">이 알고리즘의 희소 한 구현 (그라디언트가 일반적으로 &lt;a href=&quot;../../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 또는 포워드 패스의 임베딩 조회로 인해 IndexedSlices 객체 인 경우 사용)은 포워드 패스에서 사용되지 않더라도 변수 슬라이스에 운동량을 적용합니다 (즉, 0과 같은 기울기를 가짐). 운동량 붕괴 (beta1)는 또한 전체 운동량 누산기에 적용됩니다. 이는 희박한 동작이 조밀 한 동작과 동일 함을 의미합니다 (가변 슬라이스가 실제로 사용되지 않는 한 운동량을 무시하는 일부 운동량 구현과 달리).</target>
        </trans-unit>
        <trans-unit id="2c28505e1992f5a2d21a399d52aaf1d49a6228f7" translate="yes" xml:space="preserve">
          <source>The sparse implementation of this algorithm (used when the gradient is an IndexedSlices object, typically because of &lt;a href=&quot;../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt; or an embedding lookup in the forward pass) does apply momentum to variable slices even if they were not used in the forward pass (meaning they have a gradient equal to zero). Momentum decay (beta1) is also applied to the entire momentum accumulator. This means that the sparse behavior is equivalent to the dense behavior (in contrast to some momentum implementations which ignore momentum unless a variable slice was actually used).</source>
          <target state="translated">이 알고리즘의 희소 한 구현 (그라디언트가 일반적으로 &lt;a href=&quot;../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 또는 포워드 패스의 임베딩 조회로 인해 IndexedSlices 객체 인 경우 사용)은 포워드 패스에서 사용되지 않더라도 변수 슬라이스에 운동량을 적용합니다 (즉, 0과 같은 기울기를 가짐). 운동량 붕괴 (beta1)는 또한 전체 운동량 누산기에 적용됩니다. 이는 희박한 동작이 조밀 한 동작과 동일 함을 의미합니다 (가변 슬라이스가 실제로 사용되지 않는 한 운동량을 무시하는 일부 운동량 구현과 달리).</target>
        </trans-unit>
        <trans-unit id="e5bdcabcaa194b28393438e39e1590c0f77ff2c8" translate="yes" xml:space="preserve">
          <source>The sparse matrix product may have numeric (non-structural) zeros.</source>
          <target state="translated">The sparse matrix product may have numeric (non-structural) zeros.</target>
        </trans-unit>
        <trans-unit id="dedfba1684c4375e13d104a45eb8d51735e2b834" translate="yes" xml:space="preserve">
          <source>The sparse tensor to convert. Must have rank 2.</source>
          <target state="translated">The sparse tensor to convert. Must have rank 2.</target>
        </trans-unit>
        <trans-unit id="b54e597f7fe46cc2667d4b65cc738c9c9db301ba" translate="yes" xml:space="preserve">
          <source>The specified output type of the operation (&lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt;). Defaults to &lt;a href=&quot;../tf#int32&quot;&gt;&lt;code&gt;tf.int32&lt;/code&gt;&lt;/a&gt;(optional).</source>
          <target state="translated">The specified output type of the operation ( &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt; ). Defaults to &lt;a href=&quot;../tf#int32&quot;&gt; &lt;code&gt;tf.int32&lt;/code&gt; &lt;/a&gt;(optional).</target>
        </trans-unit>
        <trans-unit id="8b88004b19728b58b00753256fbdb980b735e8d2" translate="yes" xml:space="preserve">
          <source>The split indices for the ragged tensor value.</source>
          <target state="translated">비정형 텐서 값의 분할 인덱스입니다.</target>
        </trans-unit>
        <trans-unit id="f49d81f2a44d35cf534ae7fd8c45debcfaf469ae" translate="yes" xml:space="preserve">
          <source>The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.</source>
          <target state="translated">The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.</target>
        </trans-unit>
        <trans-unit id="25fdcf5ad4499cdb6d4201c3ecb0186f730f52b9" translate="yes" xml:space="preserve">
          <source>The standard &lt;code&gt;segment_*&lt;/code&gt; functions assert that the segment indices are sorted. If you have unsorted indices use the equivalent &lt;code&gt;unsorted_segment_&lt;/code&gt; function. These functions take an additional argument &lt;code&gt;num_segments&lt;/code&gt; so that the output tensor can be efficiently allocated.</source>
          <target state="translated">The standard &lt;code&gt;segment_*&lt;/code&gt; functions assert that the segment indices are sorted. If you have unsorted indices use the equivalent &lt;code&gt;unsorted_segment_&lt;/code&gt; function. These functions take an additional argument &lt;code&gt;num_segments&lt;/code&gt; so that the output tensor can be efficiently allocated.</target>
        </trans-unit>
        <trans-unit id="b29667fc1f908940634484906fb6441d097a55ad" translate="yes" xml:space="preserve">
          <source>The standard &lt;code&gt;segment_*&lt;/code&gt; functions assert that the segment indices are sorted. If you have unsorted indices use the equivalent &lt;code&gt;unsorted_segment_&lt;/code&gt; function. Thses functions take an additional argument &lt;code&gt;num_segments&lt;/code&gt; so that the output tensor can be efficiently allocated.</source>
          <target state="translated">표준 &lt;code&gt;segment_*&lt;/code&gt; 함수는 세그먼트 인덱스가 정렬되도록합니다. 정렬되지 않은 인덱스가있는 경우 동등한 &lt;code&gt;unsorted_segment_&lt;/code&gt; 함수를 사용하십시오 . 이 함수는 추가 인수 &lt;code&gt;num_segments&lt;/code&gt; 를 사용합니다. 는 출력 텐서를 효율적으로 할당 할 수 있도록 를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="6cf74e13a5dc987612c9d705626f37de29ad545f" translate="yes" xml:space="preserve">
          <source>The standard library uses various well-known names to collect and retrieve values associated with a graph. For example, the &lt;code&gt;tf.Optimizer&lt;/code&gt; subclasses default to optimizing the variables collected under &lt;code&gt;tf.GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; if none is specified, but it is also possible to pass an explicit list of variables.</source>
          <target state="translated">표준 라이브러리는 잘 알려진 다양한 이름을 사용하여 그래프와 관련된 값을 수집하고 검색합니다. 예를 들어, &lt;code&gt;tf.Optimizer&lt;/code&gt; 서브 클래스는 기본값 이 지정되지 않은 경우 &lt;code&gt;tf.GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; 에서 수집 된 변수를 최적화하도록 기본 설정 되지만 명시적인 변수 목록을 전달할 수도 있습니다.</target>
        </trans-unit>
        <trans-unit id="ce8c36f190ecab29f1604c69bb1fdd2396d6f9bd" translate="yes" xml:space="preserve">
          <source>The standard pattern for updating variables is to:</source>
          <target state="translated">변수 업데이트의 표준 패턴은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="1df550e9ac2ff1efc86381fe4007d40151e6c36c" translate="yes" xml:space="preserve">
          <source>The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the &lt;code&gt;stop()&lt;/code&gt; method.</source>
          <target state="translated">시작된 스레드는 수퍼바이저가 관리하는 스레드 목록에 추가되므로 &lt;code&gt;stop()&lt;/code&gt; 메소드 로 전달할 필요가 없습니다 .</target>
        </trans-unit>
        <trans-unit id="22b0c0a61720b2b49f3bdb46b68ab2ffe3bd7116" translate="yes" xml:space="preserve">
          <source>The started thread.</source>
          <target state="translated">시작된 스레드.</target>
        </trans-unit>
        <trans-unit id="04fb16ca663bd50a2194064568a76d4c96b84f17" translate="yes" xml:space="preserve">
          <source>The starting value for accumulators. Only zero or positive values are allowed.</source>
          <target state="translated">The starting value for accumulators. Only zero or positive values are allowed.</target>
        </trans-unit>
        <trans-unit id="c25d85454a9ea543e59596d91af95b242b42d7a4" translate="yes" xml:space="preserve">
          <source>The state of the RNG after &lt;code&gt;rng_skip(n)&lt;/code&gt; will be the same as that after &lt;code&gt;stateful_uniform([n])&lt;/code&gt; (or any other distribution). The actual increment added to the counter is an unspecified implementation detail.</source>
          <target state="translated">The state of the RNG after &lt;code&gt;rng_skip(n)&lt;/code&gt; will be the same as that after &lt;code&gt;stateful_uniform([n])&lt;/code&gt; (or any other distribution). The actual increment added to the counter is an unspecified implementation detail.</target>
        </trans-unit>
        <trans-unit id="dd546c154f1294509a35cef6daf7e05272419f55" translate="yes" xml:space="preserve">
          <source>The state of the optimizer, allowing to resume training exactly where you left off.</source>
          <target state="translated">최적화의 상태로, 중단 한 곳에서 훈련을 재개 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="712f8a6f55bf7c5b4fd684dab030efe40f46ccee" translate="yes" xml:space="preserve">
          <source>The statically known shape of this ragged tensor.</source>
          <target state="translated">이 울퉁불퉁 한 텐서의 정적으로 알려진 모양.</target>
        </trans-unit>
        <trans-unit id="05eef5966a4733b45681c7bb2c1cfa7fcd7e3ded" translate="yes" xml:space="preserve">
          <source>The statistics options associated with the dataset. See &lt;a href=&quot;experimental/statsoptions&quot;&gt;&lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 통계 옵션. 자세한 내용은 &lt;a href=&quot;experimental/statsoptions&quot;&gt; &lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="a8c6e46a80c3223660eded889659ea2c4138b476" translate="yes" xml:space="preserve">
          <source>The step set by &lt;a href=&quot;set_step&quot;&gt;&lt;code&gt;tf.summary.experimental.set_step()&lt;/code&gt;&lt;/a&gt; if one has been set, otherwise None.</source>
          <target state="translated">&lt;a href=&quot;set_step&quot;&gt; &lt;code&gt;tf.summary.experimental.set_step()&lt;/code&gt; &lt;/a&gt; 의해 설정된 단계 (설정된 경우 ) , 그렇지 않은 경우 없음.</target>
        </trans-unit>
        <trans-unit id="5dff7b910b7ad17251b2c5a9c0f91aaacc64e975" translate="yes" xml:space="preserve">
          <source>The str() operator of a 'FlagValues' object provides help for all of the registered 'Flag' objects.</source>
          <target state="translated">'FlagValues'객체의 str () 연산자는 등록 된 모든 'Flag'객체에 대한 도움말을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="13be6068510e1bba9bcaba7458adf0809e711454" translate="yes" xml:space="preserve">
          <source>The strategy may choose to put the variable on multiple devices, like mirrored variables, but unlike mirrored variables we don't synchronize the updates to them to make sure they have the same value. Instead, the synchronization is performed when reading in cross-replica context. In a replica context, reads and writes are performed on the local copy (we allow reads so you can write code like &lt;code&gt;v = 0.9*v + 0.1*update&lt;/code&gt;). We don't allow operations like &lt;code&gt;v.assign_add&lt;/code&gt; in a cross-replica context for sync on read variables; right now we don't have a use case for such updates and depending on the aggregation mode such updates may not be sensible.</source>
          <target state="translated">이 전략은 변수를 미러링 된 변수와 같은 여러 장치에 배치하도록 선택할 수 있지만 미러링 된 변수와 달리 업데이트를 동기화하여 동일한 값을 갖지 않도록합니다. 대신, 교차 복제 컨텍스트에서 읽을 때 동기화가 수행됩니다. 복제본 컨텍스트에서 로컬 복사에 대해 읽기 및 쓰기가 수행됩니다 ( &lt;code&gt;v = 0.9*v + 0.1*update&lt;/code&gt; 와 같은 코드를 작성할 수 있도록 읽기 허용 ). 읽기 변수에 대한 동기화를 위해 교차 복제 컨텍스트에서 &lt;code&gt;v.assign_add&lt;/code&gt; 와 같은 작업을 허용하지 않습니다 . 현재로서는 이러한 업데이트에 대한 사용 사례가 없으며 집계 모드에 따라 이러한 업데이트가 감지되지 않을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d3fd5c3cf46ac06d0260b1f659bcc1a0b81cadee" translate="yes" xml:space="preserve">
          <source>The stream whose writes should be captured. This stream must have a file descriptor, support writing via using that file descriptor, and must have a &lt;code&gt;.flush()&lt;/code&gt; method.</source>
          <target state="translated">The stream whose writes should be captured. This stream must have a file descriptor, support writing via using that file descriptor, and must have a &lt;code&gt;.flush()&lt;/code&gt; method.</target>
        </trans-unit>
        <trans-unit id="644f3a81fca55d1677b34a373591148f236e0ab3" translate="yes" xml:space="preserve">
          <source>The string &quot;tensorflow&quot;.</source>
          <target state="translated">문자열 &quot;tensorflow&quot;.</target>
        </trans-unit>
        <trans-unit id="cc503fc832fae0582037d46d99a283b2143a5687" translate="yes" xml:space="preserve">
          <source>The string &lt;code&gt;-&lt;/code&gt; meaning that the slice covers all indices of this dimension</source>
          <target state="translated">The string &lt;code&gt;-&lt;/code&gt; meaning that the slice covers all indices of this dimension</target>
        </trans-unit>
        <trans-unit id="8540ba2c73157ed83e7a8b8d1ba5f66009b9e41f" translate="yes" xml:space="preserve">
          <source>The string name of a job in this cluster.</source>
          <target state="translated">The string name of a job in this cluster.</target>
        </trans-unit>
        <trans-unit id="56132600b50269345758de3a44957eaf5ba36a10" translate="yes" xml:space="preserve">
          <source>The string name of the device to which this op has been assigned, or an empty string if it has not been assigned to a device.</source>
          <target state="translated">이 op가 할당 된 장치의 문자열 이름이거나 장치에 할당되지 않은 경우 빈 문자열입니다.</target>
        </trans-unit>
        <trans-unit id="8992e1dfe2880c9a4de6beb1ac8e0230422a7a79" translate="yes" xml:space="preserve">
          <source>The string name of the underlying Queue.</source>
          <target state="translated">기본 큐의 문자열 이름입니다.</target>
        </trans-unit>
        <trans-unit id="a96aa4c9d9595a33bb0f9789d55b573d138edebb" translate="yes" xml:space="preserve">
          <source>The string name of this tensor.</source>
          <target state="translated">이 텐서의 문자열 이름입니다.</target>
        </trans-unit>
        <trans-unit id="c67de356b037fd5e8be6d855afae37205aa00794" translate="yes" xml:space="preserve">
          <source>The string path to the exported directory or &lt;code&gt;None&lt;/code&gt; if export is skipped.</source>
          <target state="translated">내 보낸 디렉토리에 대한 문자열 경로 또는 내보내기를 건너 뛰는 경우 &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e5efe1c4c830550f08c9bea1e979d7c9a7668a12" translate="yes" xml:space="preserve">
          <source>The string path to the exported directory.</source>
          <target state="translated">내 보낸 디렉토리의 문자열 경로입니다.</target>
        </trans-unit>
        <trans-unit id="e6d17d88d9f96bec8835a8d4d00d7ee284382edf" translate="yes" xml:space="preserve">
          <source>The string representation of a persistent tensor handle.</source>
          <target state="translated">The string representation of a persistent tensor handle.</target>
        </trans-unit>
        <trans-unit id="a8d628e9b8c8f44ad4c03facb818cd42847e7780" translate="yes" xml:space="preserve">
          <source>The string to use to separate the inputs. Defaults to &quot; &quot;.</source>
          <target state="translated">The string to use to separate the inputs. Defaults to &quot; &quot;.</target>
        </trans-unit>
        <trans-unit id="b4d0576ccdc2458c02c95d244e31139154833425" translate="yes" xml:space="preserve">
          <source>The string type of an operation. This corresponds to the &lt;code&gt;OpDef.name&lt;/code&gt; field for the proto that defines the operation.</source>
          <target state="translated">The string type of an operation. This corresponds to the &lt;code&gt;OpDef.name&lt;/code&gt; field for the proto that defines the operation.</target>
        </trans-unit>
        <trans-unit id="a17bd3da8a69a3dada0980459ac9d927bbc1c342" translate="yes" xml:space="preserve">
          <source>The string we try to match with the items in regexes.</source>
          <target state="translated">The string we try to match with the items in regexes.</target>
        </trans-unit>
        <trans-unit id="bb20559dca432fe77c06ffe1211357d7726b77ab" translate="yes" xml:space="preserve">
          <source>The structure of the components of this optional.</source>
          <target state="translated">이 옵션의 구성 요소 구조.</target>
        </trans-unit>
        <trans-unit id="636182e5686aa0b143279a1925716c9803dd42dc" translate="yes" xml:space="preserve">
          <source>The stubbing is using the builtin getattr and setattr. So, the &lt;strong&gt;get&lt;/strong&gt; and &lt;strong&gt;set&lt;/strong&gt; will be called when stubbing ( probably be to manipulate obj.&lt;strong&gt;dict&lt;/strong&gt; instead of getattr() and setattr()).</source>
          <target state="translated">The stubbing is using the builtin getattr and setattr. So, the &lt;strong&gt;get&lt;/strong&gt; and &lt;strong&gt;set&lt;/strong&gt; will be called when stubbing ( probably be to manipulate obj.&lt;strong&gt;dict&lt;/strong&gt; instead of getattr() and setattr()).</target>
        </trans-unit>
        <trans-unit id="10e607f82b834bedf8082612b2f31785cf1834ed" translate="yes" xml:space="preserve">
          <source>The stubbing is using the builtin getattr and setattr. So, the &lt;strong&gt;get&lt;/strong&gt; and &lt;strong&gt;set&lt;/strong&gt; will be called when stubbing (TODO: A better idea would probably be to manipulate obj.&lt;strong&gt;dict&lt;/strong&gt; instead of getattr() and setattr()).</source>
          <target state="translated">스터 빙은 내장 getattr 및 setattr을 사용하고 있습니다. 그래서, &lt;strong&gt;GET&lt;/strong&gt; 및 &lt;strong&gt;세트&lt;/strong&gt; 스텁 때 호출됩니다 (TODO를 :. 더 나은 아이디어는 아마 OBJ 조작하는 것입니다 &lt;strong&gt;DICT&lt;/strong&gt; 대신 getattr ()와 않은 setattr (의)).</target>
        </trans-unit>
        <trans-unit id="e3a83e1ccdb64a4c6aff88c02b12dcc686b2bf3b" translate="yes" xml:space="preserve">
          <source>The suffix for the variable that keeps the gradient squared accumulator. If not present, defaults to name.</source>
          <target state="translated">The suffix for the variable that keeps the gradient squared accumulator. If not present, defaults to name.</target>
        </trans-unit>
        <trans-unit id="628f884b08eaa26944d28d228cad39f4b6e377f6" translate="yes" xml:space="preserve">
          <source>The suffix for the variable that keeps the linear gradient accumulator. If not present, defaults to name + &quot;&lt;em&gt;1&quot;. &lt;/em&gt;</source>
          <target state="translated">The suffix for the variable that keeps the linear gradient accumulator. If not present, defaults to name + &quot;&lt;em&gt;1&quot;. &lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="0b87677b2e7091b18f84e0a5a53ce47bf2fbc17a" translate="yes" xml:space="preserve">
          <source>The sum of the squared distance from each point in the first batch of inputs to its nearest cluster center.</source>
          <target state="translated">첫 번째 입력 배치의 각 점에서 가장 가까운 군집 중심까지의 제곱 거리의 합입니다.</target>
        </trans-unit>
        <trans-unit id="b87e105d01203888c35de69e0d8cabac2d7238b3" translate="yes" xml:space="preserve">
          <source>The summary has up to &lt;code&gt;max_images&lt;/code&gt; summary values containing images. The images are built from &lt;code&gt;tensor&lt;/code&gt; which must be 4-D with shape &lt;code&gt;[batch_size, height, width, channels]&lt;/code&gt; and where &lt;code&gt;channels&lt;/code&gt; can be:</source>
          <target state="translated">The summary has up to &lt;code&gt;max_images&lt;/code&gt; summary values containing images. The images are built from &lt;code&gt;tensor&lt;/code&gt; which must be 4-D with shape &lt;code&gt;[batch_size, height, width, channels]&lt;/code&gt; and where &lt;code&gt;channels&lt;/code&gt; can be:</target>
        </trans-unit>
        <trans-unit id="f3f45fd11021d0fbbacbdd0bd0b9e463916250a5" translate="yes" xml:space="preserve">
          <source>The summary has up to &lt;code&gt;max_outputs&lt;/code&gt; summary values containing audio. The audio is built from &lt;code&gt;tensor&lt;/code&gt; which must be 3-D with shape &lt;code&gt;[batch_size, frames, channels]&lt;/code&gt; or 2-D with shape &lt;code&gt;[batch_size, frames]&lt;/code&gt;. The values are assumed to be in the range of &lt;code&gt;[-1.0, 1.0]&lt;/code&gt; with a sample rate of &lt;code&gt;sample_rate&lt;/code&gt;.</source>
          <target state="translated">The summary has up to &lt;code&gt;max_outputs&lt;/code&gt; summary values containing audio. The audio is built from &lt;code&gt;tensor&lt;/code&gt; which must be 3-D with shape &lt;code&gt;[batch_size, frames, channels]&lt;/code&gt; or 2-D with shape &lt;code&gt;[batch_size, frames]&lt;/code&gt; . The values are assumed to be in the range of &lt;code&gt;[-1.0, 1.0]&lt;/code&gt; with a sample rate of &lt;code&gt;sample_rate&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4c8749a05b6c387d61ef6d60497d42b829e20f04" translate="yes" xml:space="preserve">
          <source>The summary has up to &lt;code&gt;max_outputs&lt;/code&gt; summary values containing images. The images are built from &lt;code&gt;tensor&lt;/code&gt; which must be 4-D with shape &lt;code&gt;[batch_size, height, width, channels]&lt;/code&gt; and where &lt;code&gt;channels&lt;/code&gt; can be:</source>
          <target state="translated">The summary has up to &lt;code&gt;max_outputs&lt;/code&gt; summary values containing images. The images are built from &lt;code&gt;tensor&lt;/code&gt; which must be 4-D with shape &lt;code&gt;[batch_size, height, width, channels]&lt;/code&gt; and where &lt;code&gt;channels&lt;/code&gt; can be:</target>
        </trans-unit>
        <trans-unit id="45ad74c802e798c2d2739d6fd3d4c8a9a95f1067" translate="yes" xml:space="preserve">
          <source>The summary stats contains gradients and hessians accumulated for each node, bucket and dimension id.</source>
          <target state="translated">The summary stats contains gradients and hessians accumulated for each node, bucket and dimension id.</target>
        </trans-unit>
        <trans-unit id="3b4c4f21208a76ec80b0674286557919ec4d96bb" translate="yes" xml:space="preserve">
          <source>The summary stats contains gradients and hessians accumulated for each node, feature dimension id and bucket.</source>
          <target state="translated">The summary stats contains gradients and hessians accumulated for each node, feature dimension id and bucket.</target>
        </trans-unit>
        <trans-unit id="cdad9771b45b958101ba790c70a250dceed1de82" translate="yes" xml:space="preserve">
          <source>The summary stats contains gradients and hessians accumulated into the corresponding node and bucket for each example.</source>
          <target state="translated">The summary stats contains gradients and hessians accumulated into the corresponding node and bucket for each example.</target>
        </trans-unit>
        <trans-unit id="fa003ab56e1eb5342f9795fdbfba586bfe2f1900" translate="yes" xml:space="preserve">
          <source>The supervisor is notified of any exception raised by one of the services. After an exception is raised, &lt;code&gt;should_stop()&lt;/code&gt; returns &lt;code&gt;True&lt;/code&gt;. In that case the training loop should also stop. This is why the training loop has to check for &lt;code&gt;sv.should_stop()&lt;/code&gt;.</source>
          <target state="translated">서비스 중 하나에서 발생한 예외에 대해 감독자에게 알립니다. 예외가 발생하면 &lt;code&gt;should_stop()&lt;/code&gt; 은 &lt;code&gt;True&lt;/code&gt; 를 반환합니다 . 이 경우 훈련 루프도 중지해야합니다. 이것이 훈련 루프가 &lt;code&gt;sv.should_stop()&lt;/code&gt; 을 확인 해야하는 이유 입니다.</target>
        </trans-unit>
        <trans-unit id="50528fab5ce38e9d3b4fc6e5612ddf34e494bebf" translate="yes" xml:space="preserve">
          <source>The swish activation applied to &lt;code&gt;x&lt;/code&gt; (see reference paper for details).</source>
          <target state="translated">The swish activation applied to &lt;code&gt;x&lt;/code&gt; (see reference paper for details).</target>
        </trans-unit>
        <trans-unit id="c298d20320b239b254c85a68c7638e9b3d6999d9" translate="yes" xml:space="preserve">
          <source>The table initializer to use. See &lt;code&gt;HashTable&lt;/code&gt; kernel for supported key and value types.</source>
          <target state="translated">The table initializer to use. See &lt;code&gt;HashTable&lt;/code&gt; kernel for supported key and value types.</target>
        </trans-unit>
        <trans-unit id="b372ddff28f44f63c6e232f1c30d44e36e67c586" translate="yes" xml:space="preserve">
          <source>The table key dtype.</source>
          <target state="translated">테이블 키 dtype.</target>
        </trans-unit>
        <trans-unit id="92555821a111ce6704d66c3accb512005dcb54c2" translate="yes" xml:space="preserve">
          <source>The table to be initialized.</source>
          <target state="translated">The table to be initialized.</target>
        </trans-unit>
        <trans-unit id="284ce4f13ba5d1db3bbec94a52d693d3d2283853" translate="yes" xml:space="preserve">
          <source>The table to initialize.</source>
          <target state="translated">The table to initialize.</target>
        </trans-unit>
        <trans-unit id="45ea7c0740084e6be8859e3f6c6a5a25999322a4" translate="yes" xml:space="preserve">
          <source>The table value dtype.</source>
          <target state="translated">테이블 값 dtype.</target>
        </trans-unit>
        <trans-unit id="8e9701fdc91c90f3e0a50b0354216b715e7e2b61" translate="yes" xml:space="preserve">
          <source>The tag name for this metadata.</source>
          <target state="translated">The tag name for this metadata.</target>
        </trans-unit>
        <trans-unit id="2e6370789b18c4cef6f8f91690bde182484827c1" translate="yes" xml:space="preserve">
          <source>The target value of comparison.</source>
          <target state="translated">The target value of comparison.</target>
        </trans-unit>
        <trans-unit id="f6bc45ea60aa5301cecc35d1fbbe5b21036c5bda" translate="yes" xml:space="preserve">
          <source>The task index for this particular VM, within the GCE instance group. In particular, every single instance should be assigned a unique ordinal index within an instance group manually so that they can be distinguished from each other.</source>
          <target state="translated">The task index for this particular VM, within the GCE instance group. In particular, every single instance should be assigned a unique ordinal index within an instance group manually so that they can be distinguished from each other.</target>
        </trans-unit>
        <trans-unit id="39fc3d1afa951ce1fc0c6acdffe30bf9d05aaa6f" translate="yes" xml:space="preserve">
          <source>The task of an Enqueuer is to use parallelism to speed up preprocessing. This is done with processes or threads.</source>
          <target state="translated">Enqueuer의 임무는 병렬 처리를 사용하여 전처리 속도를 높이는 것입니다. 이것은 프로세스 또는 스레드로 수행됩니다.</target>
        </trans-unit>
        <trans-unit id="8d203e324545cf312d1311ac6ed39dbe8533902e" translate="yes" xml:space="preserve">
          <source>The temporary directory.</source>
          <target state="translated">임시 디렉토리.</target>
        </trans-unit>
        <trans-unit id="89760396be504814d1d16fffe685b4c4ed9d185b" translate="yes" xml:space="preserve">
          <source>The tensor &lt;code&gt;keys&lt;/code&gt; must be of the same type as the keys of the table. The tensor &lt;code&gt;values&lt;/code&gt; must be of the type of the table values.</source>
          <target state="translated">The tensor &lt;code&gt;keys&lt;/code&gt; must be of the same type as the keys of the table. The tensor &lt;code&gt;values&lt;/code&gt; must be of the type of the table values.</target>
        </trans-unit>
        <trans-unit id="ba629a56d84ff4136c8aeadbf5a5b5c5e14b4183" translate="yes" xml:space="preserve">
          <source>The tensor &lt;code&gt;keys&lt;/code&gt; must of the same type as the keys of the table. Keys not already in the table are silently ignored.</source>
          <target state="translated">The tensor &lt;code&gt;keys&lt;/code&gt; must of the same type as the keys of the table. Keys not already in the table are silently ignored.</target>
        </trans-unit>
        <trans-unit id="784e799f8d450863febee3c764bd275192b18bd8" translate="yes" xml:space="preserve">
          <source>The tensor &lt;code&gt;keys&lt;/code&gt; must of the same type as the keys of the table. The output &lt;code&gt;values&lt;/code&gt; is of the type of the table values.</source>
          <target state="translated">The tensor &lt;code&gt;keys&lt;/code&gt; must of the same type as the keys of the table. The output &lt;code&gt;values&lt;/code&gt; is of the type of the table values.</target>
        </trans-unit>
        <trans-unit id="ba8d97a1a9f6a392dad767f9f5f935fc3b942c5f" translate="yes" xml:space="preserve">
          <source>The tensor at index &lt;code&gt;index&lt;/code&gt;.</source>
          <target state="translated">인덱스에서 텐서 &lt;code&gt;index&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2316496cec696b46dadd19db7c5fa7648eaa2e07" translate="yes" xml:space="preserve">
          <source>The tensor for the keys.</source>
          <target state="translated">The tensor for the keys.</target>
        </trans-unit>
        <trans-unit id="0acc2ca709af133edb5533c7cf72d36eab353cfc" translate="yes" xml:space="preserve">
          <source>The tensor for the values.</source>
          <target state="translated">The tensor for the values.</target>
        </trans-unit>
        <trans-unit id="1b8bac0316b66126d9a5f3d03ead635dc9c4e503" translate="yes" xml:space="preserve">
          <source>The tensor is shuffled along dimension 0, such that each &lt;code&gt;value[j]&lt;/code&gt; is mapped to one and only one &lt;code&gt;output[i]&lt;/code&gt;. For example, a mapping that might occur for a 3x2 tensor is:</source>
          <target state="translated">텐서는 각각의 &lt;code&gt;value[j]&lt;/code&gt; 이 하나의 &lt;code&gt;output[i]&lt;/code&gt; 에만 매핑되도록 차원 0을 따라 섞 입니다. 예를 들어 3x2 텐서에서 발생할 수있는 매핑은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b2ebac51ffaed872fc6c58ab59a37320ff00d8b4" translate="yes" xml:space="preserve">
          <source>The tensor over which to pool. Must have rank 3.</source>
          <target state="translated">The tensor over which to pool. Must have rank 3.</target>
        </trans-unit>
        <trans-unit id="67d66a49c4d56f6740c34ad1abd2330c2a53d237" translate="yes" xml:space="preserve">
          <source>The tensor over which to pool. Must have rank 4.</source>
          <target state="translated">The tensor over which to pool. Must have rank 4.</target>
        </trans-unit>
        <trans-unit id="8d6751ac1718f3abff2c47f31b4ce194ddbe60a5" translate="yes" xml:space="preserve">
          <source>The tensor over which to pool. Must have rank 5.</source>
          <target state="translated">The tensor over which to pool. Must have rank 5.</target>
        </trans-unit>
        <trans-unit id="6ba96488585c7e70161cf56eacc0bc675e7c2bf5" translate="yes" xml:space="preserve">
          <source>The tensor returned by this operation is immutable.</source>
          <target state="translated">The tensor returned by this operation is immutable.</target>
        </trans-unit>
        <trans-unit id="374a08aed4e22028f8c4f1a7a5332f381742c546" translate="yes" xml:space="preserve">
          <source>The tensor to reduce. Should be of numeric type, &lt;code&gt;bool&lt;/code&gt;, or &lt;code&gt;string&lt;/code&gt;.</source>
          <target state="translated">The tensor to reduce. Should be of numeric type, &lt;code&gt;bool&lt;/code&gt; , or &lt;code&gt;string&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="af6cdbb07f5f2007c7664b9fc800d495933f2079" translate="yes" xml:space="preserve">
          <source>The tensor to reduce. Should have numeric type.</source>
          <target state="translated">The tensor to reduce. Should have numeric type.</target>
        </trans-unit>
        <trans-unit id="f76ee355f90903f0cc3c888c4e5cbb97172bd55d" translate="yes" xml:space="preserve">
          <source>The tensor to reduce. Should have real numeric type.</source>
          <target state="translated">The tensor to reduce. Should have real numeric type.</target>
        </trans-unit>
        <trans-unit id="c8f9620fdd17bd0ae7e2e11319433d1d510e064f" translate="yes" xml:space="preserve">
          <source>The tensor to reduce. Should have real or complex type.</source>
          <target state="translated">The tensor to reduce. Should have real or complex type.</target>
        </trans-unit>
        <trans-unit id="60a48c532dffc217f038e38531b427ddb3f91bda" translate="yes" xml:space="preserve">
          <source>The tensor to start from.</source>
          <target state="translated">The tensor to start from.</target>
        </trans-unit>
        <trans-unit id="bc7b892140fc1cca57f3b6847beb68b7faa703c7" translate="yes" xml:space="preserve">
          <source>The tensor type for the result: one of &lt;code&gt;&quot;RaggedTensor&quot;&lt;/code&gt; or &lt;code&gt;&quot;SparseTensor&quot;&lt;/code&gt;.</source>
          <target state="translated">The tensor type for the result: one of &lt;code&gt;&quot;RaggedTensor&quot;&lt;/code&gt; or &lt;code&gt;&quot;SparseTensor&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f1c73ec4612fec81093c6dca3603df5977d11e17" translate="yes" xml:space="preserve">
          <source>The tensor_shape to resize the input to.</source>
          <target state="translated">The tensor_shape to resize the input to.</target>
        </trans-unit>
        <trans-unit id="79aa982763ef4786022042e868a3556033a0c5ec" translate="yes" xml:space="preserve">
          <source>The tensors at corresponding positions in the three input lists (sample_indices, embedding_indices and aggregation_weights) must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding feature.</source>
          <target state="translated">The tensors at corresponding positions in the three input lists (sample_indices, embedding_indices and aggregation_weights) must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding feature.</target>
        </trans-unit>
        <trans-unit id="9f41fba569c688c2ad85251ea878f2cfba46898a" translate="yes" xml:space="preserve">
          <source>The tensors at corresponding positions in the three input lists must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding table_id.</source>
          <target state="translated">The tensors at corresponding positions in the three input lists must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding table_id.</target>
        </trans-unit>
        <trans-unit id="a5925b962b25493edc9ea9353afe8ff0989d3ebc" translate="yes" xml:space="preserve">
          <source>The tensors at corresponding positions in two of the input lists, embedding_indices and aggregation_weights, must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding feature.</source>
          <target state="translated">The tensors at corresponding positions in two of the input lists, embedding_indices and aggregation_weights, must have the same shape, i.e. rank 1 with dim_size() equal to the total number of lookups into the table described by the corresponding feature.</target>
        </trans-unit>
        <trans-unit id="263280cf1684ff5fb9dc90aff492167c49c357e8" translate="yes" xml:space="preserve">
          <source>The tensors in the &lt;code&gt;TensorArray&lt;/code&gt; selected by &lt;code&gt;indices&lt;/code&gt;, packed into one tensor.</source>
          <target state="translated">&lt;code&gt;indices&lt;/code&gt; 선택된 &lt;code&gt;TensorArray&lt;/code&gt; 의 텐서는 하나의 텐서로 압축됩니다.</target>
        </trans-unit>
        <trans-unit id="14d5f93ad26c02d132da873b0983deda8cc5ede0" translate="yes" xml:space="preserve">
          <source>The tensors returned by the callable identified by &lt;code&gt;branch_index&lt;/code&gt;, or those returned by &lt;code&gt;default&lt;/code&gt; if no key matches and &lt;code&gt;default&lt;/code&gt; was provided, or those returned by the max-keyed &lt;code&gt;branch_fn&lt;/code&gt; if no &lt;code&gt;default&lt;/code&gt; is provided.</source>
          <target state="translated">호출 가능한 의해 반환 된 텐서에 의해 확인 &lt;code&gt;branch_index&lt;/code&gt; , 또는 이들에 의해 반환 된 &lt;code&gt;default&lt;/code&gt; 키와 일치하고있는 경우 &lt;code&gt;default&lt;/code&gt; 제공되지 않았거나 사람들이 최대 - 키 입력에 의해 반환 &lt;code&gt;branch_fn&lt;/code&gt; 어떤 경우 &lt;code&gt;default&lt;/code&gt; 제공되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0ea9d9d23c406f164fd2c56245bf91a63b2aa423" translate="yes" xml:space="preserve">
          <source>The tensors returned by the first pair whose predicate evaluated to True, or those returned by &lt;code&gt;default&lt;/code&gt; if none does.</source>
          <target state="translated">술어가 True로 평가 된 첫 번째 쌍에서 리턴 된 텐서 또는 없는 경우 &lt;code&gt;default&lt;/code&gt; 리턴 된 텐서 입니다.</target>
        </trans-unit>
        <trans-unit id="62c909c71b66d6f5bfc11fa3e5279c6761971045" translate="yes" xml:space="preserve">
          <source>The tensors returned from &lt;code&gt;fn()&lt;/code&gt;.</source>
          <target state="translated">텐서는 &lt;code&gt;fn()&lt;/code&gt; 에서 반환되었습니다 .</target>
        </trans-unit>
        <trans-unit id="3ac69b5b20154b08a328b1d97feb7527a2ebab36" translate="yes" xml:space="preserve">
          <source>The tensors to print out if the condition is False. Defaults to error message and first few entries of &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">The tensors to print out if the condition is False. Defaults to error message and first few entries of &lt;code&gt;x&lt;/code&gt; , &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="de476c8a1f81cdd546d80c349f6129aaf3737e55" translate="yes" xml:space="preserve">
          <source>The tensors to print out if the condition is False. Defaults to error message and first few entries of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">The tensors to print out if the condition is False. Defaults to error message and first few entries of &lt;code&gt;x&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d755f0b97c63b7eff4b6dbe33de5d6acf734d32c" translate="yes" xml:space="preserve">
          <source>The tensors to print out if the condition is False. Defaults to error message and first few entries of the violating tensor.</source>
          <target state="translated">The tensors to print out if the condition is False. Defaults to error message and first few entries of the violating tensor.</target>
        </trans-unit>
        <trans-unit id="41e71fc634a3e1532ea4fdaf908aef7f0776c5d2" translate="yes" xml:space="preserve">
          <source>The tensors to print out if the condition is False. Defaults to error message and the shape of &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="translated">The tensors to print out if the condition is False. Defaults to error message and the shape of &lt;code&gt;x&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a3c87ea478ca9312b37363d8086e97ef6cac7d50" translate="yes" xml:space="preserve">
          <source>The tensors to print out when condition is false.</source>
          <target state="translated">The tensors to print out when condition is false.</target>
        </trans-unit>
        <trans-unit id="2f38446647c9bdb5f6c17c4098bf60d7f38504af" translate="yes" xml:space="preserve">
          <source>The tensors will be printed to the log, with &lt;code&gt;INFO&lt;/code&gt; severity. If you are not seeing the logs, you might want to add the following line after your imports:</source>
          <target state="translated">텐서는 &lt;code&gt;INFO&lt;/code&gt; 심각도 와 함께 로그에 인쇄됩니다 . 로그가 표시되지 않으면 가져 오기 후에 다음 행을 추가 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6922a3a9fd52a35b3e308cba8bec364b7d504e80" translate="yes" xml:space="preserve">
          <source>The tf.Graph in which tensors are looked up. If None, the current default graph is used.</source>
          <target state="translated">The tf.Graph in which tensors are looked up. If None, the current default graph is used.</target>
        </trans-unit>
        <trans-unit id="11bfdd9c3d39d4a32c1a375c3ce8bfd375bd0b18" translate="yes" xml:space="preserve">
          <source>The tf.tpu.Topology object for the topology of the TPU cluster.</source>
          <target state="translated">TPU 클러스터의 토폴로지에 대한 tf.tpu.Topology 오브젝트입니다.</target>
        </trans-unit>
        <trans-unit id="befdc8701902b7376e60ef81bed3d724c3bb2879" translate="yes" xml:space="preserve">
          <source>The the elements of the output vector are in range (0, 1) and sum to 1.</source>
          <target state="translated">출력 벡터의 요소는 (0, 1) 범위에 있고 합은 1입니다.</target>
        </trans-unit>
        <trans-unit id="e8a1b74b382d4bec7d008b052874fc8efea06387" translate="yes" xml:space="preserve">
          <source>The threading options associated with the dataset. See &lt;a href=&quot;experimental/threadingoptions&quot;&gt;&lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="translated">데이터 세트와 관련된 스레딩 옵션입니다. 자세한 내용은 &lt;a href=&quot;experimental/threadingoptions&quot;&gt; &lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="ed8f460f2dbd5613ea876b9d93397d3969bdc742" translate="yes" xml:space="preserve">
          <source>The thresholds used for evaluating AUC.</source>
          <target state="translated">The thresholds used for evaluating AUC.</target>
        </trans-unit>
        <trans-unit id="4d718a76c8894d5837a42ef966440d43045adca5" translate="yes" xml:space="preserve">
          <source>The token representing an out-of-vocabulary value. Defaults to &quot;[UNK]&quot;.</source>
          <target state="translated">The token representing an out-of-vocabulary value. Defaults to &quot;[UNK]&quot;.</target>
        </trans-unit>
        <trans-unit id="d3e4fd90c9e18807d72bafd4f4716080dd6bc34f" translate="yes" xml:space="preserve">
          <source>The total number of dimensions in a &lt;code&gt;RaggedTensor&lt;/code&gt; is called its &lt;em&gt;rank&lt;/em&gt;, and the number of ragged dimensions in a &lt;code&gt;RaggedTensor&lt;/code&gt; is called its &lt;em&gt;ragged-rank&lt;/em&gt;. A &lt;code&gt;RaggedTensor&lt;/code&gt;'s ragged-rank is fixed at graph creation time: it can't depend on the runtime values of &lt;code&gt;Tensor&lt;/code&gt;s, and can't vary dynamically for different session runs.</source>
          <target state="translated">A의 크기의 총계 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 그 호출 &lt;em&gt;순위&lt;/em&gt; 및 비정형의 차원 수 &lt;code&gt;RaggedTensor&lt;/code&gt; 는 그 호출 &lt;em&gt;울퉁불퉁 랭크를&lt;/em&gt; . &lt;code&gt;RaggedTensor&lt;/code&gt; 그것의 실행 값에 의존하지 수의 그래프 작성시에 고정되고, 랭크 - 울퉁불퉁 &lt;code&gt;Tensor&lt;/code&gt; 들 및 다른 세션 실행 동적으로 변화 할 수 없다.</target>
        </trans-unit>
        <trans-unit id="7366f216b0f07a06f98c4cfb72b6efd8edad2b69" translate="yes" xml:space="preserve">
          <source>The total variation is the sum of the absolute differences for neighboring pixel-values in the input images. This measures how much noise is in the images.</source>
          <target state="translated">총 변동은 입력 이미지에서 인접 픽셀 값의 절대 차이의 합입니다. 이미지의 노이즈 량을 측정합니다.</target>
        </trans-unit>
        <trans-unit id="4cd5555b6721cf29a977af9cf8bb6114222ca75d" translate="yes" xml:space="preserve">
          <source>The total variation of &lt;code&gt;images&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;images&lt;/code&gt; 의 총 변형입니다 .</target>
        </trans-unit>
        <trans-unit id="b1be006e04763947d6204304381da8047ab403c6" translate="yes" xml:space="preserve">
          <source>The trace of input tensor.</source>
          <target state="translated">입력 텐서의 흔적.</target>
        </trans-unit>
        <trans-unit id="e883a1ea41a9a9c563ecd15d66e0cea02e0fd475" translate="yes" xml:space="preserve">
          <source>The transformation calls &lt;code&gt;reduce_func&lt;/code&gt; successively on every element of the input dataset until the dataset is exhausted, aggregating information in its internal state. The &lt;code&gt;initial_state&lt;/code&gt; argument is used for the initial state and the final state is returned as the result.</source>
          <target state="translated">변환 은 데이터 세트가 소진 될 때까지 입력 데이터 세트의 모든 요소에 대해 &lt;code&gt;reduce_func&lt;/code&gt; 를 연속적으로 호출 하여 내부 상태로 정보를 집계합니다. &lt;code&gt;initial_state&lt;/code&gt; 인자는 초기 상태에 대해 사용되며, 최종 상태의 결과로서 반환된다.</target>
        </trans-unit>
        <trans-unit id="a76374d8db32ee668d78ea0cbd0b4fb2bd9d2baf" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;atrous_conv2d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;atrous_conv2d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="24fae844f58c6b39229d2519fcdd2125a204111b" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;conv1d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;conv1d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="e5584a45278a21e44f011bf21c57aa5501a09482" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;conv2d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;conv2d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="88458abd7b78099fd74249ee9fe81104261b47e7" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;conv3d&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;conv3d&lt;/code&gt; 의 전치입니다 .</target>
        </trans-unit>
        <trans-unit id="4974672a5f0bdf2f1f4a3ac2ea5cc95568047305" translate="yes" xml:space="preserve">
          <source>The transpose of &lt;code&gt;convolution&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;convolution&lt;/code&gt; 의 전치 .</target>
        </trans-unit>
        <trans-unit id="1519a20ef4fe586180643d48497a05b2e0fad92f" translate="yes" xml:space="preserve">
          <source>The tuple of concatenated tensors that was dequeued.</source>
          <target state="translated">연결 해제 된 연결된 텐서의 튜플입니다.</target>
        </trans-unit>
        <trans-unit id="947a12be95ae913828fb29965c58acb416f681d0" translate="yes" xml:space="preserve">
          <source>The tuple of tensors that was dequeued.</source>
          <target state="translated">큐어 링 된 텐서의 튜플.</target>
        </trans-unit>
        <trans-unit id="3ac8da8c53a0fe7729ca96dc99672e3deaee4160" translate="yes" xml:space="preserve">
          <source>The tutorials cover how to use &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; to do distributed training with native Keras APIs, custom training loops, and Esitmator APIs. They also cover how to save/load model when using &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The tutorials cover how to use &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; to do distributed training with native Keras APIs, custom training loops, and Esitmator APIs. They also cover how to save/load model when using &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="81263e37d187db94dad3d1abafbff5fd315364f1" translate="yes" xml:space="preserve">
          <source>The tutorials cover how to use &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; to do distributed training with native Keras APIs, custom training loops, and Esitmator APIs. They also cover how to save/load model when using &lt;a href=&quot;distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The tutorials cover how to use &lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; to do distributed training with native Keras APIs, custom training loops, and Esitmator APIs. They also cover how to save/load model when using &lt;a href=&quot;distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="fcce8e7308a1f27fd06f367ce630638c93d290a0" translate="yes" xml:space="preserve">
          <source>The two arguments should be data trees consisting of trees of dicts and lists. They will be deeply compared by walking into the contents of dicts and lists; other items will be compared using the == operator. If the two structures differ in content, the failure message will indicate the location within the structures where the first difference is found. This may be helpful when comparing large structures.</source>
          <target state="translated">두 가지 주장은 dicts와 list의 트리로 구성된 데이터 트리 여야합니다. 그것들은 dicts와 list의 내용으로 들어가서 깊이 비교 될 것입니다. 다른 항목은 == 연산자를 사용하여 비교됩니다. 두 구조의 내용이 다른 경우 실패 메시지는 첫 번째 차이점이 발견 된 구조 내의 위치를 ​​나타냅니다. 큰 구조를 비교할 때 도움이 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c63ea59f28eeb3c5ef7f12904295f5acd2abba7d" translate="yes" xml:space="preserve">
          <source>The two optional lists, &lt;code&gt;shapes&lt;/code&gt; and &lt;code&gt;names&lt;/code&gt;, must be of the same length as &lt;code&gt;dtypes&lt;/code&gt; if provided. The values at a given index &lt;code&gt;i&lt;/code&gt; indicate the shape and name to use for the corresponding queue component in &lt;code&gt;dtypes&lt;/code&gt;.</source>
          <target state="translated">두 개의 선택적 목록 인 &lt;code&gt;shapes&lt;/code&gt; 및 &lt;code&gt;names&lt;/code&gt; 는 제공된 경우 &lt;code&gt;dtypes&lt;/code&gt; 과 길이가 같아야 합니다. 지정된 인덱스 &lt;code&gt;i&lt;/code&gt; 의 값 은 &lt;code&gt;dtypes&lt;/code&gt; 의 해당 큐 구성 요소에 사용할 모양과 이름을 나타냅니다 .</target>
        </trans-unit>
        <trans-unit id="2509253fc683a9173057f5630f71d4971cacd9bd" translate="yes" xml:space="preserve">
          <source>The type of &lt;code&gt;values&lt;/code&gt; elements in the tensor to be fed.</source>
          <target state="translated">The type of &lt;code&gt;values&lt;/code&gt; elements in the tensor to be fed.</target>
        </trans-unit>
        <trans-unit id="7c1114eda45ad0aa9835c881c7ed41948119a5f6" translate="yes" xml:space="preserve">
          <source>The type of alpha, beta, and the output: &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, or &lt;code&gt;float64&lt;/code&gt;.</source>
          <target state="translated">The type of alpha, beta, and the output: &lt;code&gt;float16&lt;/code&gt; , &lt;code&gt;float32&lt;/code&gt; , or &lt;code&gt;float64&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fcb9c58891241a3653f7ed23f1f4e9ce6c454d7f" translate="yes" xml:space="preserve">
          <source>The type of an element in the resulting &lt;code&gt;Tensor&lt;/code&gt;</source>
          <target state="translated">The type of an element in the resulting &lt;code&gt;Tensor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8cccbb2c85e31880b8682b2d0adfb113b78b64da" translate="yes" xml:space="preserve">
          <source>The type of compression for the record.</source>
          <target state="translated">레코드 압축 유형입니다.</target>
        </trans-unit>
        <trans-unit id="1b4dd7863bb3d0a86631168ad97e3c5ad4e8e603" translate="yes" xml:space="preserve">
          <source>The type of element in the resulting &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">The type of element in the resulting &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="94422215aeace7edcb47320386970071b5179d19" translate="yes" xml:space="preserve">
          <source>The type of elements for the returned &lt;code&gt;RaggedTensor&lt;/code&gt;. If not specified, then a default is chosen based on the scalar values in &lt;code&gt;pylist&lt;/code&gt;.</source>
          <target state="translated">The type of elements for the returned &lt;code&gt;RaggedTensor&lt;/code&gt; . If not specified, then a default is chosen based on the scalar values in &lt;code&gt;pylist&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7a013615eda1f8f0ede1ff237cff4a624ad2cf8a" translate="yes" xml:space="preserve">
          <source>The type of elements in the tensor to be fed.</source>
          <target state="translated">The type of elements in the tensor to be fed.</target>
        </trans-unit>
        <trans-unit id="ffc1d3e87a785b70bd5fa0c191f6b8f9a2dab411" translate="yes" xml:space="preserve">
          <source>The type of encoding for the file. Defaults to none.</source>
          <target state="translated">The type of encoding for the file. Defaults to none.</target>
        </trans-unit>
        <trans-unit id="f00002f765021b74ae3866db29b33e5675d9c97a" translate="yes" xml:space="preserve">
          <source>The type of features. Only string and integer types are supported.</source>
          <target state="translated">The type of features. Only string and integer types are supported.</target>
        </trans-unit>
        <trans-unit id="405fc0a59f40a1f68ad3da9d2cbead3200ca93bb" translate="yes" xml:space="preserve">
          <source>The type of features. Only string and integer types are supported. If &lt;code&gt;None&lt;/code&gt;, it will be inferred from &lt;code&gt;vocabulary_list&lt;/code&gt;.</source>
          <target state="translated">The type of features. Only string and integer types are supported. If &lt;code&gt;None&lt;/code&gt; , it will be inferred from &lt;code&gt;vocabulary_list&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0e39ef94a4f11a83b4f0f2df2ede7e0ef31ede65" translate="yes" xml:space="preserve">
          <source>The type of loss reduction used in the head.</source>
          <target state="translated">헤드에서 사용되는 손실 감소 유형입니다.</target>
        </trans-unit>
        <trans-unit id="9e1c8635c975f4590fc90901ef34444f7e5713cc" translate="yes" xml:space="preserve">
          <source>The type of sharding that auto-shard should attempt. If this is set to FILE, then we will attempt to shard by files (each worker will get a set of files to process). If we cannot find a set of files to shard for at least one file per worker, we will error out. When this option is selected, make sure that you have enough files so that each worker gets at least one file. There will be a runtime error thrown if there are insufficient files. If this is set to DATA, then we will shard by elements produced by the dataset, and each worker will process the whole dataset and discard the portion that is not for itself. If this is set to OFF, then we will not autoshard, and each worker will receive a copy of the full dataset. This option is set to AUTO by default, AUTO will attempt to first shard by FILE, and fall back to sharding by DATA if we cannot find a set of files to shard.</source>
          <target state="translated">자동 샤드가 시도해야하는 샤딩 유형입니다. 이것이 FILE로 설정되면 파일별로 샤드를 시도합니다 (각 작업자가 처리 할 파일 세트를 얻습니다). 작업 자당 최소 하나의 파일을 파쇄 할 파일 세트를 찾을 수 없으면 오류가 발생합니다. 이 옵션을 선택하면 각 작업자가 하나 이상의 파일을받을 수 있도록 충분한 파일이 있는지 확인하십시오. 파일이 충분하지 않으면 런타임 오류가 발생합니다. 이것이 DATA로 설정되면, 우리는 데이터 세트에 의해 생성 된 요소들에 의해 샤드 될 것이고, 각 작업자는 전체 데이터 세트를 처리하고 그 자체가 아닌 부분을 폐기 할 것입니다. 이것이 OFF로 설정되면 자동 파쇄되지 않으며 각 작업자는 전체 데이터 세트의 사본을받습니다. 이 옵션은 기본적으로 AUTO로 설정되어 있으며 AUTO는 먼저 FILE로 샤드를 시도합니다.샤드 할 파일 세트를 찾을 수 없으면 DATA에 의한 샤딩으로 폴백합니다.</target>
        </trans-unit>
        <trans-unit id="1076c8ce1d97d2aae1dd52bec1be1eb1d7da0726" translate="yes" xml:space="preserve">
          <source>The type of the elements of the resulting tensor.</source>
          <target state="translated">The type of the elements of the resulting tensor.</target>
        </trans-unit>
        <trans-unit id="4e8bb7b7574042b37e7c6afeec47ae6a75f4b513" translate="yes" xml:space="preserve">
          <source>The type of the elements of the resulting tensor. If not specified, then a value is chosen based on the other args.</source>
          <target state="translated">The type of the elements of the resulting tensor. If not specified, then a value is chosen based on the other args.</target>
        </trans-unit>
        <trans-unit id="aed6e689e6786fb190bf4135aa5cf05a31f4f0b3" translate="yes" xml:space="preserve">
          <source>The type of the event samples (default: int32).</source>
          <target state="translated">The type of the event samples (default: int32).</target>
        </trans-unit>
        <trans-unit id="5a0617255d963a3d9373238c1968c00abc24574b" translate="yes" xml:space="preserve">
          <source>The type of the event samples. &lt;code&gt;None&lt;/code&gt; implies no type-enforcement.</source>
          <target state="translated">The type of the event samples. &lt;code&gt;None&lt;/code&gt; implies no type-enforcement.</target>
        </trans-unit>
        <trans-unit id="0e6ae3861b6b33f7202d6cb04f51d8a43f2ebb83" translate="yes" xml:space="preserve">
          <source>The type of the event samples. Default: &lt;code&gt;int32&lt;/code&gt;.</source>
          <target state="translated">The type of the event samples. Default: &lt;code&gt;int32&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e5ac8c9ef31246fab5b3b784f6fdb5ffec2b2eba" translate="yes" xml:space="preserve">
          <source>The type of the op (e.g. &lt;code&gt;&quot;MatMul&quot;&lt;/code&gt;).</source>
          <target state="translated">op의 유형입니다 (예 : &lt;code&gt;&quot;MatMul&quot;&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="067097eae217bc20b817dae41bcd6adaa941c2bf" translate="yes" xml:space="preserve">
          <source>The type of the op that generated the tensor with bad numerics.</source>
          <target state="translated">The type of the op that generated the tensor with bad numerics.</target>
        </trans-unit>
        <trans-unit id="08a9b8c589712a808dd41511f2b9583296c78486" translate="yes" xml:space="preserve">
          <source>The type of the output tensor.</source>
          <target state="translated">The type of the output tensor.</target>
        </trans-unit>
        <trans-unit id="6ac7350774189c9f4f0f6d153487ae1c0df2dfef" translate="yes" xml:space="preserve">
          <source>The type of the output.</source>
          <target state="translated">The type of the output.</target>
        </trans-unit>
        <trans-unit id="da83b3257815d9c8a52c8c2fe774ab08e0d4a548" translate="yes" xml:space="preserve">
          <source>The type of the output. Default: tf.int32</source>
          <target state="translated">The type of the output. Default: tf.int32</target>
        </trans-unit>
        <trans-unit id="aa045fdeece95a6373419965f4b455817b39af60" translate="yes" xml:space="preserve">
          <source>The type of the output: &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt;.</source>
          <target state="translated">The type of the output: &lt;code&gt;float16&lt;/code&gt; , &lt;code&gt;float32&lt;/code&gt; , &lt;code&gt;float64&lt;/code&gt; , &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f27b43df09bda0cc0e4bd074ae7a03dba23972ee" translate="yes" xml:space="preserve">
          <source>The type of the output: &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, or &lt;code&gt;int64&lt;/code&gt;.</source>
          <target state="translated">The type of the output: &lt;code&gt;float16&lt;/code&gt; , &lt;code&gt;float32&lt;/code&gt; , &lt;code&gt;float64&lt;/code&gt; , &lt;code&gt;int32&lt;/code&gt; , or &lt;code&gt;int64&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f8cc4d05affc30251cb4e72ec85d99c502c39e2b" translate="yes" xml:space="preserve">
          <source>The type of the output: &lt;code&gt;float16&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, or &lt;code&gt;int64&lt;/code&gt;. For unbounded uniform ints (&lt;code&gt;minval&lt;/code&gt;, &lt;code&gt;maxval&lt;/code&gt; both &lt;code&gt;None&lt;/code&gt;), &lt;code&gt;uint32&lt;/code&gt; and &lt;code&gt;uint64&lt;/code&gt; may be used.</source>
          <target state="translated">The type of the output: &lt;code&gt;float16&lt;/code&gt; , &lt;code&gt;float32&lt;/code&gt; , &lt;code&gt;float64&lt;/code&gt; , &lt;code&gt;int32&lt;/code&gt; , or &lt;code&gt;int64&lt;/code&gt; . For unbounded uniform ints ( &lt;code&gt;minval&lt;/code&gt; , &lt;code&gt;maxval&lt;/code&gt; both &lt;code&gt;None&lt;/code&gt; ), &lt;code&gt;uint32&lt;/code&gt; and &lt;code&gt;uint64&lt;/code&gt; may be used.</target>
        </trans-unit>
        <trans-unit id="5b2e4f649b30bc99091c2da410cb8448c8ba873a" translate="yes" xml:space="preserve">
          <source>The type of the this &lt;code&gt;LinearOperator&lt;/code&gt;. Arguments to &lt;code&gt;matmul&lt;/code&gt; and &lt;code&gt;solve&lt;/code&gt; will have to be this type.</source>
          <target state="translated">The type of the this &lt;code&gt;LinearOperator&lt;/code&gt; . Arguments to &lt;code&gt;matmul&lt;/code&gt; and &lt;code&gt;solve&lt;/code&gt; will have to be this type.</target>
        </trans-unit>
        <trans-unit id="74e0737155eb6c648136eb7aa61f1f5f53eaee2c" translate="yes" xml:space="preserve">
          <source>The type of the variable. Defaults to &lt;code&gt;self.dtype&lt;/code&gt; or &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">The type of the variable. Defaults to &lt;code&gt;self.dtype&lt;/code&gt; or &lt;code&gt;float32&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="89eb9b54cfc1eb5edbdf1804af86410f57c03f40" translate="yes" xml:space="preserve">
          <source>The type of values.</source>
          <target state="translated">The type of values.</target>
        </trans-unit>
        <trans-unit id="cc791524ffdf48de9024b17fb2e81e72b1743abc" translate="yes" xml:space="preserve">
          <source>The type specification of an element of &lt;a href=&quot;distributediterator&quot;&gt;&lt;code&gt;tf.distribute.DistributedIterator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The type specification of an element of &lt;a href=&quot;distributediterator&quot;&gt; &lt;code&gt;tf.distribute.DistributedIterator&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="586865cdc2362857bdac73e4d9d4aafd45add2e6" translate="yes" xml:space="preserve">
          <source>The type specification of an element of this &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">The type specification of an element of this &lt;a href=&quot;distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="9f4d546108b4584207f8473dd28294356ddeede5" translate="yes" xml:space="preserve">
          <source>The type specification of an element of this dataset.</source>
          <target state="translated">이 데이터 세트의 요소의 형태 사양입니다.</target>
        </trans-unit>
        <trans-unit id="31f5cdd5cadead57bcfc00f19cdc637b778a8dfa" translate="yes" xml:space="preserve">
          <source>The type specification of an element of this iterator.</source>
          <target state="translated">이 이터레이터의 요소의 타입 사양.</target>
        </trans-unit>
        <trans-unit id="31e1b2499af19cb707e87dbc9b32089b65e02169" translate="yes" xml:space="preserve">
          <source>The type specification of an element of this optional.</source>
          <target state="translated">The type specification of an element of this optional.</target>
        </trans-unit>
        <trans-unit id="bce40406c73aa0072207096be99446cc37cd3334" translate="yes" xml:space="preserve">
          <source>The types of the tensors in &lt;code&gt;values&lt;/code&gt; must match the schema for the fields specified in &lt;code&gt;field_names&lt;/code&gt;. All the tensors in &lt;code&gt;values&lt;/code&gt; must have a common shape prefix, &lt;em&gt;batch_shape&lt;/em&gt;.</source>
          <target state="translated">&lt;code&gt;values&lt;/code&gt; 의 텐서 유형은 &lt;code&gt;field_names&lt;/code&gt; 에 지정된 필드의 스키마와 일치해야합니다 . &lt;code&gt;values&lt;/code&gt; 모든 텐서 에는 공통 모양 접두어 &lt;em&gt;batch_shape가 있어야&lt;/em&gt; 합니다.</target>
        </trans-unit>
        <trans-unit id="e5381b2e579e07c748270f78ee35dd566e3eb442" translate="yes" xml:space="preserve">
          <source>The typical scenario for &lt;code&gt;ExponentialMovingAverage&lt;/code&gt; is to compute moving averages of variables during training, and restore the variables from the computed moving averages during evaluations.</source>
          <target state="translated">&lt;code&gt;ExponentialMovingAverage&lt;/code&gt; 의 일반적인 시나리오 는 학습 중에 변수의 이동 평균을 계산하고 평가 중에 계산 된 이동 평균에서 변수를 복원하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="3da77fbceb0e840441ce8c39192555e97fa2928b" translate="yes" xml:space="preserve">
          <source>The underlying accumulator reference.</source>
          <target state="translated">기본 누산기 참조</target>
        </trans-unit>
        <trans-unit id="c25ef637b6290d9c594d8a4f22f2ec949aa1bd01" translate="yes" xml:space="preserve">
          <source>The underlying queue reference.</source>
          <target state="translated">기본 큐 참조</target>
        </trans-unit>
        <trans-unit id="e903c075a80c182337230b41e8fc05a166057ed0" translate="yes" xml:space="preserve">
          <source>The unique &lt;code&gt;frame_name&lt;/code&gt; is used by the &lt;code&gt;Executor&lt;/code&gt; to identify frames. If &lt;code&gt;is_constant&lt;/code&gt; is true, &lt;code&gt;output&lt;/code&gt; is a constant in the child frame; otherwise it may be changed in the child frame. At most &lt;code&gt;parallel_iterations&lt;/code&gt; iterations are run in parallel in the child frame.</source>
          <target state="translated">The unique &lt;code&gt;frame_name&lt;/code&gt; is used by the &lt;code&gt;Executor&lt;/code&gt; to identify frames. If &lt;code&gt;is_constant&lt;/code&gt; is true, &lt;code&gt;output&lt;/code&gt; is a constant in the child frame; otherwise it may be changed in the child frame. At most &lt;code&gt;parallel_iterations&lt;/code&gt; iterations are run in parallel in the child frame.</target>
        </trans-unit>
        <trans-unit id="2570833b8fed9aa7ee0f6db077c7e434ab3d563b" translate="yes" xml:space="preserve">
          <source>The unpacked tuple, with &lt;code&gt;None&lt;/code&gt;s for &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; if they are not provided.</source>
          <target state="translated">The unpacked tuple, with &lt;code&gt;None&lt;/code&gt; s for &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; if they are not provided.</target>
        </trans-unit>
        <trans-unit id="d25a2d45745d4308947942d9bddb3fe51f90e219" translate="yes" xml:space="preserve">
          <source>The update rule for &lt;code&gt;variable&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; uses an optimization described at the end of section 2 of the paper:</source>
          <target state="translated">그래디언트 &lt;code&gt;g&lt;/code&gt; 가있는 &lt;code&gt;variable&lt;/code&gt; 에 대한 업데이트 규칙 은 논문의 섹션 2 끝에 설명 된 최적화를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="dcaa87717690c893cddcbb06c2774de0d640ef88" translate="yes" xml:space="preserve">
          <source>The update rule for &lt;code&gt;variable&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; uses an optimization described at the end of section 7.1 of the paper:</source>
          <target state="translated">그래디언트 &lt;code&gt;g&lt;/code&gt; 가있는 &lt;code&gt;variable&lt;/code&gt; 의 업데이트 규칙 은 본 논문의 7.1 절 끝에 설명 된 최적화를 사용합니다.</target>
        </trans-unit>
        <trans-unit id="0efd76819f39cf3bcb5dd14bc65d8c8c72cef23d" translate="yes" xml:space="preserve">
          <source>The update rule for parameter &lt;code&gt;w&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; is described at the end of section 7.1 of the paper:</source>
          <target state="translated">The update rule for parameter &lt;code&gt;w&lt;/code&gt; with gradient &lt;code&gt;g&lt;/code&gt; is described at the end of section 7.1 of the paper:</target>
        </trans-unit>
        <trans-unit id="1a9901f8d5a239b98ad1f04b6bbdac6a25b5dbe0" translate="yes" xml:space="preserve">
          <source>The updated config has something needed to run a strategy, e.g. configuration to run collective ops, or device filters to improve distributed training performance.</source>
          <target state="translated">업데이트 된 구성에는 전략을 실행하는 데 필요한 것이 있습니다 (예 : 집단 작전을 실행하기위한 구성 또는 분산 된 훈련 성능을 향상시키기위한 장치 필터).</target>
        </trans-unit>
        <trans-unit id="60dd7fe2afadb5341f05d411ef207c2859229807" translate="yes" xml:space="preserve">
          <source>The updated copy of the &lt;code&gt;config_proto&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;config_proto&lt;/code&gt; 의 업데이트 된 사본 .</target>
        </trans-unit>
        <trans-unit id="7d9e39fd60700bb347ed0039e54d9af3ef5a5100" translate="yes" xml:space="preserve">
          <source>The updated decorator. If decorator_func is not a tf_decorator, new_target is returned.</source>
          <target state="translated">업데이트 된 데코레이터. decorator_func가 tf_decorator가 아닌 경우 new_target이 리턴됩니다.</target>
        </trans-unit>
        <trans-unit id="fa6ecd5172af3b96400529c50d0c7eb9f4adaa33" translate="yes" xml:space="preserve">
          <source>The updated variable.</source>
          <target state="translated">The updated variable.</target>
        </trans-unit>
        <trans-unit id="bb0ce841932dc29d8f332a4acc96a1313d2133b7" translate="yes" xml:space="preserve">
          <source>The updated variable. If &lt;code&gt;read_value&lt;/code&gt; is false, instead returns None in Eager mode and the assign op in graph mode.</source>
          <target state="translated">The updated variable. If &lt;code&gt;read_value&lt;/code&gt; is false, instead returns None in Eager mode and the assign op in graph mode.</target>
        </trans-unit>
        <trans-unit id="5d8daec55baf3c813ce2f2fc4a5eab596ea78fbf" translate="yes" xml:space="preserve">
          <source>The upper regularized incomplete Gamma function is defined as:</source>
          <target state="translated">정규화 된 불완전한 상위 감마 함수는 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="a16fb2ccec6d9e76f7b18eacf6123674146710e7" translate="yes" xml:space="preserve">
          <source>The user could also use &lt;code&gt;make_input_fn_iterator&lt;/code&gt; if they want to customize which input is fed to which replica/worker etc.</source>
          <target state="translated">사용자는 어떤 입력이 어떤 복제본 / 작업자 등에 공급되는지 사용자 정의하려는 경우 &lt;code&gt;make_input_fn_iterator&lt;/code&gt; 를 사용할 수도 있습니다 .</target>
        </trans-unit>
        <trans-unit id="ab789081815c49957f21bd695c2a3924b82c20ff" translate="yes" xml:space="preserve">
          <source>The user is given the option of raising an exception or returning &lt;code&gt;NaN&lt;/code&gt;.</source>
          <target state="translated">사용자에게는 예외를 발생 시키거나 &lt;code&gt;NaN&lt;/code&gt; 을 반환하는 옵션이 제공 됩니다.</target>
        </trans-unit>
        <trans-unit id="2d78e502adf2b1729b9f368b8135c69dbb97bac0" translate="yes" xml:space="preserve">
          <source>The usual cross-entropy cost is defined as:</source>
          <target state="translated">일반적인 교차 엔트로피 비용은 다음과 같이 정의됩니다.</target>
        </trans-unit>
        <trans-unit id="55894b0693429bc52d5ca851ab5e7e50a45cb526" translate="yes" xml:space="preserve">
          <source>The valid keyword arguments in kwds are:</source>
          <target state="translated">kwds의 ​​유효한 키워드 인수는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="2e9dcb12c3ec9343c2b4d76ebee61442f18c708d" translate="yes" xml:space="preserve">
          <source>The value &lt;code&gt;delta&lt;/code&gt; is added to all components of the tensor &lt;code&gt;image&lt;/code&gt;. &lt;code&gt;image&lt;/code&gt; is converted to &lt;code&gt;float&lt;/code&gt; and scaled appropriately if it is in fixed-point representation, and &lt;code&gt;delta&lt;/code&gt; is converted to the same data type. For regular images, &lt;code&gt;delta&lt;/code&gt; should be in the range &lt;code&gt;[0,1)&lt;/code&gt;, as it is added to the image in floating point representation, where pixel values are in the &lt;code&gt;[0,1)&lt;/code&gt; range.</source>
          <target state="translated">&lt;code&gt;delta&lt;/code&gt; 값 은 텐서 &lt;code&gt;image&lt;/code&gt; 의 모든 구성 요소에 추가됩니다 . &lt;code&gt;image&lt;/code&gt; 가 고정 소수점 표현 인 경우 이미지 는 &lt;code&gt;float&lt;/code&gt; 으로 변환 되고 크기가 적절하게 조정되고 &lt;code&gt;delta&lt;/code&gt; 는 동일한 데이터 유형으로 변환됩니다. 일반적인 이미지를 들어 &lt;code&gt;delta&lt;/code&gt; 범위 내에 있어야 &lt;code&gt;[0,1)&lt;/code&gt; 이 픽셀 값은에 부동 소수점 표현으로 화상에 추가로, &lt;code&gt;[0,1)&lt;/code&gt; 범위.</target>
        </trans-unit>
        <trans-unit id="a0cc40289aaf5ca63368c701a28edf746620f686" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;gt; other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;gt; other.value&lt;/code&gt; 의 값을 모두 알고 있으면 그렇지 않으면 None입니다.</target>
        </trans-unit>
        <trans-unit id="28eee150e3c68dabbd6edcffc1df83846a31e392" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;gt;= other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;gt;= other.value&lt;/code&gt; 의 값을 모두 알고 있으면 그렇지 않으면 None입니다.</target>
        </trans-unit>
        <trans-unit id="1ac388cf68a7917e640172de08cfda57213cf191" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;lt; other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;lt; other.value&lt;/code&gt; 둘 다 알려진 경우 값 , 그렇지 않으면 None</target>
        </trans-unit>
        <trans-unit id="b01cea77304d81c49aa6bfe991a86b9994cc913b" translate="yes" xml:space="preserve">
          <source>The value of &lt;code&gt;self.value &amp;lt;= other.value&lt;/code&gt; if both are known, otherwise None.</source>
          <target state="translated">&lt;code&gt;self.value &amp;lt;= other.value&lt;/code&gt; 의 값을 모두 알고 있으면 그렇지 않으면 None입니다.</target>
        </trans-unit>
        <trans-unit id="97a93b3e6e5220aba9e50c43c510d2bbbc1a87e0" translate="yes" xml:space="preserve">
          <source>The value of such a flag is a list that contains the individual values from all the appearances of that flag on the command-line.</source>
          <target state="translated">이러한 플래그의 값은 명령 행에서 해당 플래그의 모든 모양의 개별 값을 포함하는 목록입니다.</target>
        </trans-unit>
        <trans-unit id="a54451b41292d69deaf5cd8ce0771065680d134d" translate="yes" xml:space="preserve">
          <source>The value of the attr, as a Python object.</source>
          <target state="translated">Python 객체 인 attr의 값입니다.</target>
        </trans-unit>
        <trans-unit id="6e7716dffe6353c157e4a2c3f2e655d155be6b4b" translate="yes" xml:space="preserve">
          <source>The value of the flag is always a list, even if the option was only supplied once, and even if the default value is a single value</source>
          <target state="translated">옵션이 한 번만 제공되고 기본값이 단일 값인 경우에도 플래그 값은 항상 목록입니다.</target>
        </trans-unit>
        <trans-unit id="f28d312af2bea03bbf52afb2a569177bf8ca705a" translate="yes" xml:space="preserve">
          <source>The value of the flag, empty if the flag is not defined.</source>
          <target state="translated">The value of the flag, empty if the flag is not defined.</target>
        </trans-unit>
        <trans-unit id="bf8b3cb3b48dec54fd1680c59ba7cefb3dfc3602" translate="yes" xml:space="preserve">
          <source>The value of the variable after the update.</source>
          <target state="translated">업데이트 후 변수의 값입니다.</target>
        </trans-unit>
        <trans-unit id="d29c684e1056225784225bef1dc61fddd3c411d6" translate="yes" xml:space="preserve">
          <source>The value of this dimension, or None if it is unknown.</source>
          <target state="translated">이 차원의 값이거나 알 수없는 경우 없음입니다.</target>
        </trans-unit>
        <trans-unit id="dc40d49743dfe15cf0fa34edb80ecfa5afa70d65" translate="yes" xml:space="preserve">
          <source>The value or values returned by &lt;code&gt;map_func&lt;/code&gt; determine the structure of each element in the returned dataset.</source>
          <target state="translated">&lt;code&gt;map_func&lt;/code&gt; 에 의해 리턴 된 값 은 리턴 된 데이터 세트에서 각 요소의 구조를 결정합니다.</target>
        </trans-unit>
        <trans-unit id="277f6e101a6f4f13a9cc5f1fee440972491084f4" translate="yes" xml:space="preserve">
          <source>The value representing an out-of-vocabulary value. Defaults to -1.</source>
          <target state="translated">The value representing an out-of-vocabulary value. Defaults to -1.</target>
        </trans-unit>
        <trans-unit id="27a9bdb78e692ccca6e6eeacfe9cf8259c37e6d7" translate="yes" xml:space="preserve">
          <source>The value returned by &lt;code&gt;run()&lt;/code&gt; has the same shape as the &lt;code&gt;fetches&lt;/code&gt; argument, where the leaves are replaced by the corresponding values returned by TensorFlow.</source>
          <target state="translated">&lt;code&gt;run()&lt;/code&gt; 의해 리턴 된 값 은 &lt;code&gt;fetches&lt;/code&gt; 인수 와 동일한 모양을 가지며 , 여기서 리프는 TensorFlow에 의해 리턴 된 해당 값으로 대체됩니다.</target>
        </trans-unit>
        <trans-unit id="6455c45d9b49b1bb8f4ec9b5dff00531b9342ec2" translate="yes" xml:space="preserve">
          <source>The value returned by the &lt;code&gt;activity_regularizer&lt;/code&gt; is divided by the input batch size so that the relative weighting between the weight regularizers and the activity regularizers does not change with the batch size.</source>
          <target state="translated">&lt;code&gt;activity_regularizer&lt;/code&gt; 에 의해 반환 된 값 은 입력 배치 크기로 나뉘어 가중치 정규화 기와 활동 정규화 기 간의 상대적 가중치가 배치 크기에 따라 변경되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="e67ea60a1d86085a3a91a8df093188ea7d78231f" translate="yes" xml:space="preserve">
          <source>The value returned by this operation is guaranteed to be influenced by all the writes on which this operation depends directly or indirectly, and to not be influenced by any of the writes which depend directly or indirectly on this operation.</source>
          <target state="translated">The value returned by this operation is guaranteed to be influenced by all the writes on which this operation depends directly or indirectly, and to not be influenced by any of the writes which depend directly or indirectly on this operation.</target>
        </trans-unit>
        <trans-unit id="ca8a88dac26c441fe66426635dcf33f3ecddba85" translate="yes" xml:space="preserve">
          <source>The value to add to the collection.</source>
          <target state="translated">The value to add to the collection.</target>
        </trans-unit>
        <trans-unit id="67488a526901c9a4f2769ad17a3b244c04775dbb" translate="yes" xml:space="preserve">
          <source>The value to add to the collections.</source>
          <target state="translated">The value to add to the collections.</target>
        </trans-unit>
        <trans-unit id="0467f1eec9e713645aba39b382503cafa6ae6856" translate="yes" xml:space="preserve">
          <source>The value to fill for empty rows, with the same type as &lt;code&gt;sp_input.&lt;/code&gt;</source>
          <target state="translated">The value to fill for empty rows, with the same type as &lt;code&gt;sp_input.&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6c9729e11273c726456e8e0c3c8e270a5166729e" translate="yes" xml:space="preserve">
          <source>The value to fill the area outside the specified diagonal band with. Default is 0.</source>
          <target state="translated">The value to fill the area outside the specified diagonal band with. Default is 0.</target>
        </trans-unit>
        <trans-unit id="53f548425b8c43bbee75c542b6da5327e5f5f507" translate="yes" xml:space="preserve">
          <source>The value to use if a key is missing in the table.</source>
          <target state="translated">The value to use if a key is missing in the table.</target>
        </trans-unit>
        <trans-unit id="46cf38cbb0627d0763f0f1b40f1bcbf960cd2dde" translate="yes" xml:space="preserve">
          <source>The values generated are similar to values from a &lt;a href=&quot;randomnormal&quot;&gt;&lt;code&gt;tf.keras.initializers.RandomNormal&lt;/code&gt;&lt;/a&gt; initializer except that values more than two standard deviations from the mean are discarded and re-drawn.</source>
          <target state="translated">The values generated are similar to values from a &lt;a href=&quot;randomnormal&quot;&gt; &lt;code&gt;tf.keras.initializers.RandomNormal&lt;/code&gt; &lt;/a&gt; initializer except that values more than two standard deviations from the mean are discarded and re-drawn.</target>
        </trans-unit>
        <trans-unit id="c61a71eb4077cf30110803e381657708b49ae932" translate="yes" xml:space="preserve">
          <source>The values must include 0. There can be no duplicate values or negative values.</source>
          <target state="translated">값은 0을 포함해야합니다. 중복 값이나 음수 값은있을 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="1050986413ba8aa09be08e1ada6c99bfa286c827" translate="yes" xml:space="preserve">
          <source>The values not defined in &lt;code&gt;sp_input&lt;/code&gt; don't participate in the reduce max, as opposed to be implicitly assumed 0 -- hence it can return negative values for sparse &lt;code&gt;axis&lt;/code&gt;. But, in case there are no values in &lt;code&gt;axis&lt;/code&gt;, it will reduce to 0. See second example below.</source>
          <target state="translated">&lt;code&gt;sp_input&lt;/code&gt; 에 정의되지 않은 값 은 암시 적으로 0으로 가정되는 것과 달리 reduce max에 참여하지 않으므로 스파 스 &lt;code&gt;axis&lt;/code&gt; 대해 음수 값을 반환 할 수 있습니다 . 그러나 &lt;code&gt;axis&lt;/code&gt; 에 값이 없으면 0으로 줄어 듭니다. 아래 두 번째 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="15f0cbbec41c8cec7a1600faa3fd0ba6c8267aeb" translate="yes" xml:space="preserve">
          <source>The values not defined in &lt;code&gt;sp_input&lt;/code&gt; don't participate in the reduce max, as opposed to be implicitly assumed 0 -- hence it can return negative values for sparse &lt;code&gt;reduction_axes&lt;/code&gt;. But, in case there are no values in &lt;code&gt;reduction_axes&lt;/code&gt;, it will reduce to 0. See second example below.</source>
          <target state="translated">&lt;code&gt;sp_input&lt;/code&gt; 에 정의되지 않은 값 은 암시 적으로 0으로 가정되는 것과 달리 reduce max에 참여하지 않으므로 sparse &lt;code&gt;reduction_axes&lt;/code&gt; 에 대해 음수 값을 반환 할 수 있습니다 . 그러나 &lt;code&gt;reduction_axes&lt;/code&gt; 에 값이 없으면 0으로 줄어 듭니다. 아래 두 번째 예를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="01b28056c2bd0c58a2e89c42fd350d1a9e497580" translate="yes" xml:space="preserve">
          <source>The values of &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see &lt;a href=&quot;../initializers/lecun_normal&quot;&gt;&lt;code&gt;lecun_normal&lt;/code&gt; initialization&lt;/a&gt;) and the number of inputs is &quot;large enough&quot; (see references for more information).</source>
          <target state="translated">&lt;code&gt;alpha&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 값은 가중치가 올바르게 초기화되고 ( &lt;a href=&quot;../initializers/lecun_normal&quot;&gt; &lt;code&gt;lecun_normal&lt;/code&gt; 초기화&lt;/a&gt; 참조 ) 입력 수가 &quot;충분히&quot;(입력 참조)하는 한 두 개의 연속 레이어간에 입력의 평균 및 분산이 유지되도록 선택됩니다. 추가 정보).</target>
        </trans-unit>
        <trans-unit id="64ea94b6b8cce4972e532c22a39ade0ab1c04bbd" translate="yes" xml:space="preserve">
          <source>The values of &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see &lt;a href=&quot;../initializers/lecunnormal&quot;&gt;&lt;code&gt;tf.keras.initializers.LecunNormal&lt;/code&gt;&lt;/a&gt; initializer) and the number of input units is &quot;large enough&quot; (see reference paper for more information).</source>
          <target state="translated">The values of &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt; are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see &lt;a href=&quot;../initializers/lecunnormal&quot;&gt; &lt;code&gt;tf.keras.initializers.LecunNormal&lt;/code&gt; &lt;/a&gt; initializer) and the number of input units is &quot;large enough&quot; (see reference paper for more information).</target>
        </trans-unit>
        <trans-unit id="f733a02fe3b03768ab1ca9ec4da3805a1ad4b791" translate="yes" xml:space="preserve">
          <source>The values of &lt;code&gt;value&lt;/code&gt; are assigned to the positions in the tensor &lt;code&gt;input&lt;/code&gt; that are selected by the slice parameters. The slice parameters &lt;code&gt;begin&lt;/code&gt;&lt;code&gt;end&lt;/code&gt;&lt;code&gt;strides&lt;/code&gt; etc. work exactly as in &lt;code&gt;StridedSlice&lt;/code&gt;.</source>
          <target state="translated">The values of &lt;code&gt;value&lt;/code&gt; are assigned to the positions in the tensor &lt;code&gt;input&lt;/code&gt; that are selected by the slice parameters. The slice parameters &lt;code&gt;begin&lt;/code&gt; &lt;code&gt;end&lt;/code&gt; &lt;code&gt;strides&lt;/code&gt; etc. work exactly as in &lt;code&gt;StridedSlice&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f39cb348464cd40ba244caddc3b9020cc754ba4b" translate="yes" xml:space="preserve">
          <source>The values of &lt;code&gt;value&lt;/code&gt; are assigned to the positions in the variable &lt;code&gt;ref&lt;/code&gt; that are selected by the slice parameters. The slice parameters &lt;code&gt;begin,&lt;/code&gt;end&lt;code&gt;,&lt;/code&gt;strides&lt;code&gt;, etc. work exactly as in&lt;/code&gt;StridedSlice`.</source>
          <target state="translated">The values of &lt;code&gt;value&lt;/code&gt; are assigned to the positions in the variable &lt;code&gt;ref&lt;/code&gt; that are selected by the slice parameters. The slice parameters &lt;code&gt;begin,&lt;/code&gt; end &lt;code&gt;,&lt;/code&gt; strides &lt;code&gt;, etc. work exactly as in&lt;/code&gt; StridedSlice`.</target>
        </trans-unit>
        <trans-unit id="1f2d5c98a3c37925f071ae528d2a1426fcf8d79c" translate="yes" xml:space="preserve">
          <source>The values of &lt;code&gt;value&lt;/code&gt; are assigned to the positions in the variable &lt;code&gt;ref&lt;/code&gt; that are selected by the slice parameters. The slice parameters &lt;code&gt;begin&lt;/code&gt;, &lt;code&gt;end&lt;/code&gt;, &lt;code&gt;strides&lt;/code&gt;, etc. work exactly as in &lt;code&gt;StridedSlice&lt;/code&gt;.</source>
          <target state="translated">The values of &lt;code&gt;value&lt;/code&gt; are assigned to the positions in the variable &lt;code&gt;ref&lt;/code&gt; that are selected by the slice parameters. The slice parameters &lt;code&gt;begin&lt;/code&gt; , &lt;code&gt;end&lt;/code&gt; , &lt;code&gt;strides&lt;/code&gt; , etc. work exactly as in &lt;code&gt;StridedSlice&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="823a169cfff816da0e0ed79e7aa0fca33f12184b" translate="yes" xml:space="preserve">
          <source>The values to be used in the operation.</source>
          <target state="translated">The values to be used in the operation.</target>
        </trans-unit>
        <trans-unit id="340b53ddcc61e1600456fa6a942b3a9db9dcd7f4" translate="yes" xml:space="preserve">
          <source>The variable &lt;code&gt;x&lt;/code&gt; updated.</source>
          <target state="translated">변수 &lt;code&gt;x&lt;/code&gt; 가 업데이트되었습니다.</target>
        </trans-unit>
        <trans-unit id="9b98520ded5c59855ccbb91e15451f218e4fed8a" translate="yes" xml:space="preserve">
          <source>The variable corresponding to &lt;code&gt;input_&lt;/code&gt; or None</source>
          <target state="translated">The variable corresponding to &lt;code&gt;input_&lt;/code&gt; or None</target>
        </trans-unit>
        <trans-unit id="b58067393f30493e389388e4808eed6d24490c13" translate="yes" xml:space="preserve">
          <source>The variable dtype of this policy, or None if the variable dtype should be inferred from the inputs.</source>
          <target state="translated">이 정책의 변수 dtype 또는 입력에서 변수 dtype을 유추해야하는 경우 None입니다.</target>
        </trans-unit>
        <trans-unit id="bb822034c75bacc81fb53dec6e4b25c54f49ac48" translate="yes" xml:space="preserve">
          <source>The variable dtype of this policy.</source>
          <target state="translated">이 정책의 변수 dtype</target>
        </trans-unit>
        <trans-unit id="cf801794eaaba6ef2f8f7f433ed37a63d7d2327d" translate="yes" xml:space="preserve">
          <source>The variance for Student's T equals</source>
          <target state="translated">스튜던트 T의 분산은</target>
        </trans-unit>
        <trans-unit id="d641778ea2685b7b78fd228569c0026aa6abdc9c" translate="yes" xml:space="preserve">
          <source>The vocabulary file name.</source>
          <target state="translated">The vocabulary file name.</target>
        </trans-unit>
        <trans-unit id="cde4cff8a5ecda6c3308cd587b5940a27adec93c" translate="yes" xml:space="preserve">
          <source>The vocabulary file should be in CSV-like format, with the last field being the weight associated with the word.</source>
          <target state="translated">The vocabulary file should be in CSV-like format, with the last field being the weight associated with the word.</target>
        </trans-unit>
        <trans-unit id="1063f666d548cfe042252b2f4239aa647a4b8506" translate="yes" xml:space="preserve">
          <source>The weights of a layer represent the state of the layer. This function returns both trainable and non-trainable weight values associated with this layer as a list of Numpy arrays, which can in turn be used to load state into similarly parameterized layers.</source>
          <target state="translated">The weights of a layer represent the state of the layer. This function returns both trainable and non-trainable weight values associated with this layer as a list of Numpy arrays, which can in turn be used to load state into similarly parameterized layers.</target>
        </trans-unit>
        <trans-unit id="bf4e9211223da35fb0cefc91c559dd39cd92d9f5" translate="yes" xml:space="preserve">
          <source>The weights of a layer represent the state of the layer. This function sets the weight values from numpy arrays. The weight values should be passed in the order they are created by the layer. Note that the layer's weights must be instantiated before calling this function by calling the layer.</source>
          <target state="translated">The weights of a layer represent the state of the layer. This function sets the weight values from numpy arrays. The weight values should be passed in the order they are created by the layer. Note that the layer's weights must be instantiated before calling this function by calling the layer.</target>
        </trans-unit>
        <trans-unit id="9c9c5e7f6fe29d5feb4e712a5efa9aacc5795ce1" translate="yes" xml:space="preserve">
          <source>The weights of an optimizer are its state (ie, variables). This function returns the weight values associated with this optimizer as a list of Numpy arrays. The first value is always the iterations count of the optimizer, followed by the optimizer's state variables in the order they were created. The returned list can in turn be used to load state into similarly parameterized optimizers.</source>
          <target state="translated">The weights of an optimizer are its state (ie, variables). This function returns the weight values associated with this optimizer as a list of Numpy arrays. The first value is always the iterations count of the optimizer, followed by the optimizer's state variables in the order they were created. The returned list can in turn be used to load state into similarly parameterized optimizers.</target>
        </trans-unit>
        <trans-unit id="1dbc3d68ba3835fc93e47564b7ed4f1325c6e8cd" translate="yes" xml:space="preserve">
          <source>The weights of an optimizer are its state (ie, variables). This function takes the weight values associated with this optimizer as a list of Numpy arrays. The first value is always the iterations count of the optimizer, followed by the optimizer's state variables in the order they are created. The passed values are used to set the new state of the optimizer.</source>
          <target state="translated">The weights of an optimizer are its state (ie, variables). This function takes the weight values associated with this optimizer as a list of Numpy arrays. The first value is always the iterations count of the optimizer, followed by the optimizer's state variables in the order they are created. The passed values are used to set the new state of the optimizer.</target>
        </trans-unit>
        <trans-unit id="15e91da427b6cf2b2fbc5ac9447fe8b24dd8aa82" translate="yes" xml:space="preserve">
          <source>The width the output tensor is &lt;code&gt;input_depth * block_size&lt;/code&gt;, whereas the height is &lt;code&gt;input_height * block_size&lt;/code&gt;.</source>
          <target state="translated">출력 텐서의 너비는 &lt;code&gt;input_depth * block_size&lt;/code&gt; &lt;code&gt;input_height * block_size&lt;/code&gt; 이고 높이는 input_height * block_size 입니다.</target>
        </trans-unit>
        <trans-unit id="4a165b5ce96be1f52d9f7edf6d8a65c227dd997f" translate="yes" xml:space="preserve">
          <source>The width(s) of the ngrams to create. If this is a list or tuple, the op will return ngrams of all specified arities in list order. Values must be non-Tensor integers greater than 0.</source>
          <target state="translated">The width(s) of the ngrams to create. If this is a list or tuple, the op will return ngrams of all specified arities in list order. Values must be non-Tensor integers greater than 0.</target>
        </trans-unit>
        <trans-unit id="78fda38eef982ddecbfd2142c00746b57a76815b" translate="yes" xml:space="preserve">
          <source>The word index dictionary.</source>
          <target state="translated">단어 색인 사전.</target>
        </trans-unit>
        <trans-unit id="524d27d9a78ab988dfdffc5a8ddf699fa93cbe93" translate="yes" xml:space="preserve">
          <source>The word index dictionary. Keys are word strings, values are their index.</source>
          <target state="translated">The word index dictionary. Keys are word strings, values are their index.</target>
        </trans-unit>
        <trans-unit id="273384d93f6363b2a2a4c34767e0268890f5d5af" translate="yes" xml:space="preserve">
          <source>The wrapped input tensor.</source>
          <target state="translated">랩핑 된 입력 텐서.</target>
        </trans-unit>
        <trans-unit id="e4a82e3bb086ae7e63715facddf72f40e0765006" translate="yes" xml:space="preserve">
          <source>The wrapped output tensor.</source>
          <target state="translated">랩핑 된 출력 텐서.</target>
        </trans-unit>
        <trans-unit id="52457270e7a01e13ee00378b3108ea8fc12315e0" translate="yes" xml:space="preserve">
          <source>The wrapped value.</source>
          <target state="translated">랩핑 된 값.</target>
        </trans-unit>
        <trans-unit id="bb274ffefe3874a86b65898ba52aa9be06563172" translate="yes" xml:space="preserve">
          <source>The wrapper function.</source>
          <target state="translated">The wrapper function.</target>
        </trans-unit>
        <trans-unit id="0c29d607aec40364caa8044d1b086cb311bf2d17" translate="yes" xml:space="preserve">
          <source>Theano-like behavior example</source>
          <target state="translated">테 아노 같은 행동 예제</target>
        </trans-unit>
        <trans-unit id="c3d562c283b894723caae359b0851a3c4fb15dc1" translate="yes" xml:space="preserve">
          <source>Then calling &lt;code&gt;image_dataset_from_directory(main_directory, labels='inferred')&lt;/code&gt; will return a &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; that yields batches of images from the subdirectories &lt;code&gt;class_a&lt;/code&gt; and &lt;code&gt;class_b&lt;/code&gt;, together with labels 0 and 1 (0 corresponding to &lt;code&gt;class_a&lt;/code&gt; and 1 corresponding to &lt;code&gt;class_b&lt;/code&gt;).</source>
          <target state="translated">Then calling &lt;code&gt;image_dataset_from_directory(main_directory, labels='inferred')&lt;/code&gt; will return a &lt;a href=&quot;../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; that yields batches of images from the subdirectories &lt;code&gt;class_a&lt;/code&gt; and &lt;code&gt;class_b&lt;/code&gt; , together with labels 0 and 1 (0 corresponding to &lt;code&gt;class_a&lt;/code&gt; and 1 corresponding to &lt;code&gt;class_b&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="f5fae7664a9f8954314f95eaa134030803e80ccc" translate="yes" xml:space="preserve">
          <source>Then calling &lt;code&gt;text_dataset_from_directory(main_directory, labels='inferred')&lt;/code&gt; will return a &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; that yields batches of texts from the subdirectories &lt;code&gt;class_a&lt;/code&gt; and &lt;code&gt;class_b&lt;/code&gt;, together with labels 0 and 1 (0 corresponding to &lt;code&gt;class_a&lt;/code&gt; and 1 corresponding to &lt;code&gt;class_b&lt;/code&gt;).</source>
          <target state="translated">Then calling &lt;code&gt;text_dataset_from_directory(main_directory, labels='inferred')&lt;/code&gt; will return a &lt;a href=&quot;../../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; that yields batches of texts from the subdirectories &lt;code&gt;class_a&lt;/code&gt; and &lt;code&gt;class_b&lt;/code&gt; , together with labels 0 and 1 (0 corresponding to &lt;code&gt;class_a&lt;/code&gt; and 1 corresponding to &lt;code&gt;class_b&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="fb44a39f5e3304ba1e47cd9001107c1190200e02" translate="yes" xml:space="preserve">
          <source>Then output is &lt;code&gt;[2 x 2 x 3]&lt;/code&gt;:</source>
          <target state="translated">Then output is &lt;code&gt;[2 x 2 x 3]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="70803c29e37a6cdd022ef83164306a19f47318ca" translate="yes" xml:space="preserve">
          <source>Then output is &lt;code&gt;[3 x 4]&lt;/code&gt;:</source>
          <target state="translated">Then output is &lt;code&gt;[3 x 4]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="609a89b6f4ea61b7d43929c28cac3cb16c1a8704" translate="yes" xml:space="preserve">
          <source>Then output is &lt;code&gt;[4 x 3]&lt;/code&gt;:</source>
          <target state="translated">Then output is &lt;code&gt;[4 x 3]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="b6380335743da8e76766d68f136c813dfdf80835" translate="yes" xml:space="preserve">
          <source>Then the final line will print out:</source>
          <target state="translated">Then the final line will print out:</target>
        </trans-unit>
        <trans-unit id="d073abde2a1df4b5c62a21448d955ee1c50a80df" translate="yes" xml:space="preserve">
          <source>Then the output is a dictionary:</source>
          <target state="translated">그런 다음 출력은 사전입니다.</target>
        </trans-unit>
        <trans-unit id="4c6244085178ac4f66fb4367c44b652758bf26c2" translate="yes" xml:space="preserve">
          <source>Then you can run a &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt; operation only on logical device 0.</source>
          <target state="translated">Then you can run a &lt;a href=&quot;../math/add&quot;&gt; &lt;code&gt;tf.add&lt;/code&gt; &lt;/a&gt; operation only on logical device 0.</target>
        </trans-unit>
        <trans-unit id="f77a2ae4d69da67530e4f97b9e84f16f29f79cdf" translate="yes" xml:space="preserve">
          <source>Then,</source>
          <target state="translated">Then,</target>
        </trans-unit>
        <trans-unit id="18c6dda9e31a83fdb5a90169c27005c658e8056f" translate="yes" xml:space="preserve">
          <source>Then, row_pooling_sequence should satisfy:</source>
          <target state="translated">그런 다음 row_pooling_sequence는 다음을 충족해야합니다.</target>
        </trans-unit>
        <trans-unit id="3debd4416d24691c45dc01b19b3489468194d8c2" translate="yes" xml:space="preserve">
          <source>There are a number of questions to ask in the decision process, including:</source>
          <target state="translated">의사 결정 과정에서 다음과 같은 여러 가지 질문이 있습니다.</target>
        </trans-unit>
        <trans-unit id="6f58afb7ffb8a1e95bc14a4cccd59e26c144fddb" translate="yes" xml:space="preserve">
          <source>There are a number of requirements on what needs to happen inside the scope. However, in places where we have information about which strategy is in use, we often enter the scope for the user, so they don't have to do it explicitly (i.e. calling those either inside or outside the scope is OK).</source>
          <target state="translated">There are a number of requirements on what needs to happen inside the scope. However, in places where we have information about which strategy is in use, we often enter the scope for the user, so they don't have to do it explicitly (i.e. calling those either inside or outside the scope is OK).</target>
        </trans-unit>
        <trans-unit id="f0dc8d396849561a849ade939c069a913c651243" translate="yes" xml:space="preserve">
          <source>There are different ways to quantize. This version uses only scaling, so 0.0 maps to 0.</source>
          <target state="translated">There are different ways to quantize. This version uses only scaling, so 0.0 maps to 0.</target>
        </trans-unit>
        <trans-unit id="372d16d9e0a1868251f75c59e5f513839dddd179" translate="yes" xml:space="preserve">
          <source>There are many different ways to implement atrous convolution (see the refs above). The implementation here reduces</source>
          <target state="translated">거친 컨볼 루션을 구현하는 방법에는 여러 가지가 있습니다 (위 참조 참조). 여기서 구현은 줄입니다.</target>
        </trans-unit>
        <trans-unit id="4b4c86e082be3a02799da3aa4833e74149042874" translate="yes" xml:space="preserve">
          <source>There are nodes like Identity and CheckNumerics that are only useful during training, and can be removed in graphs that will be used for nothing but inference. Here we identify and remove them, returning an equivalent graph. To be specific, CheckNumerics nodes are always removed, and Identity nodes that aren't involved in control edges are spliced out so that their input and outputs are directly connected.</source>
          <target state="translated">Identity 및 CheckNumerics와 같은 노드는 훈련 중에 만 유용하며 추론에만 사용되는 그래프에서 제거 할 수 있습니다. 여기서 우리는 그것들을 식별하고 제거하여 동등한 그래프를 반환합니다. 구체적으로 CheckNumerics 노드는 항상 제거되고 제어 에지에 포함되지 않은 Identity 노드는 연결되어 입력과 출력이 직접 연결됩니다.</target>
        </trans-unit>
        <trans-unit id="a4fe5597954ba439b4679d614be0e1e5164b606b" translate="yes" xml:space="preserve">
          <source>There are several delicate issues when running multiple threads that way: closing the queues in sequence as the input is exhausted, correctly catching and reporting exceptions, etc.</source>
          <target state="translated">여러 스레드를 실행하는 경우 몇 가지 섬세한 문제가 있습니다. 입력이 소진 될 때 순서대로 큐를 닫고, 예외를 정확하게 포착하고보고하는 등입니다.</target>
        </trans-unit>
        <trans-unit id="20bc80fe9d0b075a12bc0575d2ba4a5d5fe1269d" translate="yes" xml:space="preserve">
          <source>There are several ways to run the conversion:</source>
          <target state="translated">변환을 실행하는 방법에는 여러 가지가 있습니다.</target>
        </trans-unit>
        <trans-unit id="9a0c34e11b24dd273612b5e842b9ca3db6c2dc5f" translate="yes" xml:space="preserve">
          <source>There are three important concepts associated with TensorFlow Distributions shapes:</source>
          <target state="translated">TensorFlow Distributions 모양과 관련된 세 가지 중요한 개념이 있습니다.</target>
        </trans-unit>
        <trans-unit id="d89ee0299ae366416b4bb7507b2e32a19b6a4278" translate="yes" xml:space="preserve">
          <source>There are two APIs to create a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; object: &lt;a href=&quot;strategy#experimental_distribute_dataset&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset(dataset)&lt;/code&gt;&lt;/a&gt;and &lt;a href=&quot;strategy#experimental_distribute_datasets_from_function&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_datasets_from_function(dataset_fn)&lt;/code&gt;&lt;/a&gt;. &lt;em&gt;When to use which?&lt;/em&gt; When you have a &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance, and the regular batch splitting (i.e. re-batch the input &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance with a new batch size that is equal to the global batch size divided by the number of replicas in sync) and autosharding (i.e. the &lt;a href=&quot;../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; options) work for you, use the former API. Otherwise, if you are &lt;em&gt;not&lt;/em&gt; using a canonical &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance, or you would like to customize the batch splitting or sharding, you can wrap these logic in a &lt;code&gt;dataset_fn&lt;/code&gt; and use the latter API. Both API handles prefetch to device for the user. For more details and examples, follow the links to the APIs.</source>
          <target state="translated">There are two APIs to create a &lt;a href=&quot;distributeddataset&quot;&gt; &lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt; &lt;/a&gt; object: &lt;a href=&quot;strategy#experimental_distribute_dataset&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset(dataset)&lt;/code&gt; &lt;/a&gt;and &lt;a href=&quot;strategy#experimental_distribute_datasets_from_function&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_distribute_datasets_from_function(dataset_fn)&lt;/code&gt; &lt;/a&gt;. &lt;em&gt;When to use which?&lt;/em&gt; When you have a &lt;a href=&quot;../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; instance, and the regular batch splitting (i.e. re-batch the input &lt;a href=&quot;../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; instance with a new batch size that is equal to the global batch size divided by the number of replicas in sync) and autosharding (i.e. the &lt;a href=&quot;../data/experimental/autoshardpolicy&quot;&gt; &lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt; &lt;/a&gt; options) work for you, use the former API. Otherwise, if you are &lt;em&gt;not&lt;/em&gt; using a canonical &lt;a href=&quot;../data/dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; instance, or you would like to customize the batch splitting or sharding, you can wrap these logic in a &lt;code&gt;dataset_fn&lt;/code&gt; and use the latter API. Both API handles prefetch to device for the user. For more details and examples, follow the links to the APIs.</target>
        </trans-unit>
        <trans-unit id="6b8f13eb2103d67ac4feee46d41de0d462019931" translate="yes" xml:space="preserve">
          <source>There are two main usages of a &lt;code&gt;DistributedDataset&lt;/code&gt; object:</source>
          <target state="translated">There are two main usages of a &lt;code&gt;DistributedDataset&lt;/code&gt; object:</target>
        </trans-unit>
        <trans-unit id="3536015a851856ea989836d31de530e9b064da8c" translate="yes" xml:space="preserve">
          <source>There are two means to control the logging verbosity:</source>
          <target state="translated">로깅 세부 정보를 제어하는 ​​두 가지 방법이 있습니다.</target>
        </trans-unit>
        <trans-unit id="93dc11cfab5744c0fd203945e6587a775aa790bd" translate="yes" xml:space="preserve">
          <source>There are two modes under which the &lt;code&gt;TPUEmbedding&lt;/code&gt; class can used. This depends on if the class was created under a &lt;code&gt;TPUStrategy&lt;/code&gt; scope or not.</source>
          <target state="translated">There are two modes under which the &lt;code&gt;TPUEmbedding&lt;/code&gt; class can used. This depends on if the class was created under a &lt;code&gt;TPUStrategy&lt;/code&gt; scope or not.</target>
        </trans-unit>
        <trans-unit id="cfe77a90ab442852a7e0e410775f1f4aa154097a" translate="yes" xml:space="preserve">
          <source>There are two possible return values, &quot;google&quot; (when TensorFlow is running in a Google-internal environment) or an empty string (when TensorFlow is running elsewhere).</source>
          <target state="translated">&quot;google&quot;(TensorFlow가 Google 내부 환경에서 실행될 때) 또는 빈 문자열 (TensorFlow가 다른 곳에서 실행될 때)의 두 가지 반환 값이 있습니다.</target>
        </trans-unit>
        <trans-unit id="c121ae8dd46f0cedd4d9939e53220e70d1795c85" translate="yes" xml:space="preserve">
          <source>There are two questions to ask in the decision process: Do you need gradients computed as sparse too? Is your sparse data represented as two &lt;code&gt;SparseTensor&lt;/code&gt;s: ids and values? There is more explanation about data format below. If you answer any of these questions as yes, consider using &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt;&lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">의사 결정 과정에서 두 가지 질문이 있습니다. 희소로 계산 된 그래디언트가 필요합니까? 희소 데이터가 두 개의 &lt;code&gt;SparseTensor&lt;/code&gt; 로 표시 됩니까? id와 값입니까? 아래에 데이터 형식에 대한 자세한 설명이 있습니다. 이 질문에 예라고 대답하면 &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt; &lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt; &lt;/a&gt; 사용을 고려 하십시오 .</target>
        </trans-unit>
        <trans-unit id="0878716bd35f31f600ff16927cc66d2e1bdcca8d" translate="yes" xml:space="preserve">
          <source>There are two variants of the GRU implementation. The default one is based on &lt;a href=&quot;https://arxiv.org/abs/1406.1078v3&quot;&gt;v3&lt;/a&gt; and has reset gate applied to hidden state before matrix multiplication. The other one is based on &lt;a href=&quot;https://arxiv.org/abs/1406.1078v1&quot;&gt;original&lt;/a&gt; and has the order reversed.</source>
          <target state="translated">GRU 구현에는 두 가지 변형이 있습니다. 기본 값은 &lt;a href=&quot;https://arxiv.org/abs/1406.1078v3&quot;&gt;v3을&lt;/a&gt; 기반으로 하며 행렬 곱하기 전에 숨겨진 상태에 재설정 게이트가 적용됩니다. 다른 하나는 &lt;a href=&quot;https://arxiv.org/abs/1406.1078v1&quot;&gt;원본을&lt;/a&gt; 기반으로 하며 순서가 반대입니다.</target>
        </trans-unit>
        <trans-unit id="f3d0da97f844d09b6bac8339000119f443c41934" translate="yes" xml:space="preserve">
          <source>There are two variants. The default one is based on 1406.1078v3 and has reset gate applied to hidden state before matrix multiplication. The other one is based on original 1406.1078v1 and has the order reversed.</source>
          <target state="translated">두 가지 변형이 있습니다. 기본 값은 1406.1078v3을 기반으로하며 행렬 곱하기 전에 숨겨진 상태에 적용된 게이트 재설정을 가지고 있습니다. 다른 하나는 원본 1406.1078v1을 기반으로하며 순서가 반대입니다.</target>
        </trans-unit>
        <trans-unit id="f1e5ef8034bae35c3455bef5218f7a32bbdb1aa7" translate="yes" xml:space="preserve">
          <source>There are two versions of the API: 1 or 2.</source>
          <target state="translated">There are two versions of the API: 1 or 2.</target>
        </trans-unit>
        <trans-unit id="19c11322b50f362088a37650ccaf3b2e479b115a" translate="yes" xml:space="preserve">
          <source>There are two versions of the API: ExportSavedModelApiVersion.V1 and V2.</source>
          <target state="translated">API에는 ExportSavedModelApiVersion.V1과 V2의 두 가지 버전이 있습니다.</target>
        </trans-unit>
        <trans-unit id="c409af06e5c37c31d5d6e63ae53409968bb739b2" translate="yes" xml:space="preserve">
          <source>There are two ways to create decorators that TensorFlow can introspect into. This is important for documentation generation purposes, so that function signatures aren't obscured by the (*args, **kwds) signature that decorators often provide.</source>
          <target state="translated">TensorFlow가 조사 할 수있는 데코레이터를 만드는 방법에는 두 가지가 있습니다. 이것은 문서 생성 목적에 중요하므로, 데코레이터가 종종 제공하는 (* args, ** kwds) 서명으로 함수 서명이 가려지지 않습니다.</target>
        </trans-unit>
        <trans-unit id="49196c8dfb0588201d8b9733a14917623170a741" translate="yes" xml:space="preserve">
          <source>There are two ways to instantiate a &lt;code&gt;Model&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;Model&lt;/code&gt; 을 인스턴스화하는 방법에는 두 가지가 있습니다 .</target>
        </trans-unit>
        <trans-unit id="a3e498654dcff830e5be467e55fbbbbc20e2910f" translate="yes" xml:space="preserve">
          <source>There are two ways to use the moving averages for evaluations:</source>
          <target state="translated">평가에 이동 평균을 사용하는 두 가지 방법이 있습니다.</target>
        </trans-unit>
        <trans-unit id="14b50269ad70f1441184d03f5b9e983ae0e09462" translate="yes" xml:space="preserve">
          <source>There is a special node with &lt;code&gt;task_type&lt;/code&gt; as &lt;code&gt;evaluator&lt;/code&gt;, which is not part of the (training) &lt;code&gt;cluster_spec&lt;/code&gt;. It handles the distributed evaluation job.</source>
          <target state="translated">(훈련) &lt;code&gt;cluster_spec&lt;/code&gt; 의 일부가 아닌 &lt;code&gt;evaluator&lt;/code&gt; 로 &lt;code&gt;task_type&lt;/code&gt; 을 가진 특수 노드가 있습니다. 분산 평가 작업을 처리합니다.</target>
        </trans-unit>
        <trans-unit id="ff5a342ad76b4f6dbc02bde4742c1939d0847ee4" translate="yes" xml:space="preserve">
          <source>There is also a global generator:</source>
          <target state="translated">There is also a global generator:</target>
        </trans-unit>
        <trans-unit id="c0a273890eb3544a6c0002e05e862f10bbfd245d" translate="yes" xml:space="preserve">
          <source>There is an equivalent description in terms of the [batch] spectrum &lt;code&gt;H&lt;/code&gt; and Fourier transforms. Here we consider &lt;code&gt;A.shape = [N, N]&lt;/code&gt; and ignore batch dimensions.</source>
          <target state="translated">[배치] 스펙트럼 &lt;code&gt;H&lt;/code&gt; 및 푸리에 변환과 관련하여 동등한 설명이 있습니다 . 여기서는 &lt;code&gt;A.shape = [N, N]&lt;/code&gt; 을 고려 하고 배치 차원을 무시합니다.</target>
        </trans-unit>
        <trans-unit id="34b53209d83711d378deaa8b481a2f90355eb0e3" translate="yes" xml:space="preserve">
          <source>There is an equivalent description in terms of the [batch] spectrum &lt;code&gt;H&lt;/code&gt; and Fourier transforms. Here we consider &lt;code&gt;A.shape = [N, N]&lt;/code&gt; and ignore batch dimensions. Define the discrete Fourier transform (DFT) and its inverse by</source>
          <target state="translated">[배치] 스펙트럼 &lt;code&gt;H&lt;/code&gt; 및 푸리에 변환과 관련하여 동등한 설명이 있습니다 . 여기서는 &lt;code&gt;A.shape = [N, N]&lt;/code&gt; 을 고려 하고 배치 차원을 무시합니다. 이산 푸리에 변환 (DFT)과 그 역을</target>
        </trans-unit>
        <trans-unit id="70db84bf8987013d7aeb820bf2eec70af7a073ca" translate="yes" xml:space="preserve">
          <source>There is no need to delete the directory after the test.</source>
          <target state="translated">테스트 후 디렉토리를 삭제할 필요가 없습니다.</target>
        </trans-unit>
        <trans-unit id="897a9d5198f512dcaeb305f37bd31486ee120960" translate="yes" xml:space="preserve">
          <source>There is no transformation in the &lt;a href=&quot;../data&quot;&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; Python API for creating this dataset. Instead, it is created as a result of the &lt;code&gt;filter_with_random_uniform_fusion&lt;/code&gt; static optimization. Whether this optimization is performed is determined by the &lt;code&gt;experimental_optimization.filter_with_random_uniform_fusion&lt;/code&gt; option of &lt;a href=&quot;../data/options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">There is no transformation in the &lt;a href=&quot;../data&quot;&gt; &lt;code&gt;tf.data&lt;/code&gt; &lt;/a&gt; Python API for creating this dataset. Instead, it is created as a result of the &lt;code&gt;filter_with_random_uniform_fusion&lt;/code&gt; static optimization. Whether this optimization is performed is determined by the &lt;code&gt;experimental_optimization.filter_with_random_uniform_fusion&lt;/code&gt; option of &lt;a href=&quot;../data/options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="b246461630b3c81ed498d37ca7dc4b93263133aa" translate="yes" xml:space="preserve">
          <source>There is often a need to lift variable initialization ops out of control-flow scopes, function-building graphs, and gradient tapes. Entering an &lt;code&gt;init_scope&lt;/code&gt; is a mechanism for satisfying these desiderata. In particular, entering an &lt;code&gt;init_scope&lt;/code&gt; has three effects:</source>
          <target state="translated">제어 흐름 범위, 함수 작성 그래프 및 그래디언트 테이프에서 변수 초기화 작업을 해제해야하는 경우가 종종 있습니다. &lt;code&gt;init_scope&lt;/code&gt; 를 입력하는 것은 이러한 desiderata를 만족시키기위한 메커니즘입니다. 특히 &lt;code&gt;init_scope&lt;/code&gt; 를 입력하면 세 가지 효과가 있습니다.</target>
        </trans-unit>
        <trans-unit id="9600bed3adf3351d3b6785f43a000c7d51f5ddee" translate="yes" xml:space="preserve">
          <source>There is one exception: if the final (i.e., innermost) element(s) of &lt;code&gt;partitions&lt;/code&gt; are &lt;code&gt;UniformRowLength&lt;/code&gt;s, then the values are simply reshaped (as a higher-dimensional &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;), rather than being wrapped in a &lt;a href=&quot;../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;partitions&lt;/code&gt; 의 마지막 (즉, 가장 안쪽) 요소 가 &lt;code&gt;UniformRowLength&lt;/code&gt; 이면 예외 는 tf.RaggedTensor로 감싸지 않고 단순히 더 높은 차원의 &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 로 모양 이 &lt;a href=&quot;../raggedtensor&quot;&gt; &lt;code&gt;tf.RaggedTensor&lt;/code&gt; &lt;/a&gt; 됩니다.</target>
        </trans-unit>
        <trans-unit id="b0e762e9fe47e7a8aaa65fed7f11b0b738414c89" translate="yes" xml:space="preserve">
          <source>There should be no data dependency between the different semantic invocations of &lt;code&gt;fn&lt;/code&gt;, i.e. it should be safe to map the elements of the inputs in any order.</source>
          <target state="translated">There should be no data dependency between the different semantic invocations of &lt;code&gt;fn&lt;/code&gt; , i.e. it should be safe to map the elements of the inputs in any order.</target>
        </trans-unit>
        <trans-unit id="69f7128e30301479f7dbfc0ac8f483f3d6d00a4d" translate="yes" xml:space="preserve">
          <source>Therefore we introduce some decoupling using a queue. The queue contains the work units and the Reader dequeues from the queue when it is asked to produce a record (via Read()) but it has finished the last work unit.</source>
          <target state="translated">따라서 큐를 사용하여 몇 가지 디커플링을 소개합니다. 대기열에는 작업 단위가 포함되며 Reader는 읽기 ()를 통해 레코드를 생성하라는 요청을 받으면 대기열에서 대기열에서 제외하지만 마지막 작업 단위를 완료했습니다.</target>
        </trans-unit>
        <trans-unit id="86cd25893d67c9049a975fb7c203728b1fcc6c8b" translate="yes" xml:space="preserve">
          <source>These are arguments passed to the optimizer subclass constructor (the &lt;code&gt;__init__&lt;/code&gt; method), and then passed to &lt;code&gt;self._set_hyper()&lt;/code&gt;. They can be either regular Python values (like 1.0), tensors, or callables. If they are callable, the callable will be called during &lt;code&gt;apply_gradients()&lt;/code&gt; to get the value for the hyper parameter.</source>
          <target state="translated">이들은 옵티 마이저 서브 클래스 생성자 ( &lt;code&gt;__init__&lt;/code&gt; 메소드)에 전달 된 다음 &lt;code&gt;self._set_hyper()&lt;/code&gt; 전달되는 인수 입니다. 정규 Python 값 (예 : 1.0), 텐서 또는 호출 가능일 수 있습니다. 호출 가능하면 &lt;code&gt;apply_gradients()&lt;/code&gt; 중에 호출 가능 매개 변수 가 호출 되어 하이퍼 매개 변수의 값을 가져옵니다.</target>
        </trans-unit>
        <trans-unit id="d1eefae8eebd09f04dd361373c7c577f0cf1144d" translate="yes" xml:space="preserve">
          <source>These conversion options are experimental. They are subject to change without notice and offer no guarantees.</source>
          <target state="translated">이러한 전환 옵션은 실험적입니다. 사전 통지없이 변경 될 수 있으며 보장 할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="c291964ed47da0b87e8a53387f07ca95b28e890c" translate="yes" xml:space="preserve">
          <source>These indices specify where the values for each row begin in &lt;code&gt;self.values&lt;/code&gt;. &lt;code&gt;rt.row_starts()&lt;/code&gt; is equal to &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt;.</source>
          <target state="translated">이 색인은 각 행의 값이 &lt;code&gt;self.values&lt;/code&gt; 로 시작하는 위치를 지정합니다 . &lt;code&gt;rt.row_starts()&lt;/code&gt; 는 &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="99b0058dc30c77b214aebabddab907af2da4a216" translate="yes" xml:space="preserve">
          <source>These indices specify where the values for each row end in &lt;code&gt;self.values&lt;/code&gt;. &lt;code&gt;rt.row_limits(self)&lt;/code&gt; is equal to &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt;.</source>
          <target state="translated">이 색인은 각 행의 값이 &lt;code&gt;self.values&lt;/code&gt; 로 끝나는 위치를 지정 합니다. &lt;code&gt;rt.row_limits(self)&lt;/code&gt; 는 &lt;code&gt;rt.row_splits[:-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="23fdcaa94183d818b1595f88d3e5484cc7528a37" translate="yes" xml:space="preserve">
          <source>These layers expose 3 keyword arguments:</source>
          <target state="translated">이 레이어는 3 개의 키워드 인수를 노출합니다.</target>
        </trans-unit>
        <trans-unit id="76c2c66d43654cd0b29da8b2ca646058c82ed16b" translate="yes" xml:space="preserve">
          <source>These might be stored sparsely in the following Example protos by storing only the feature ids (column number if the vectors are treated as a matrix) of the non-zero elements and the corresponding values:</source>
          <target state="translated">이들은 0이 아닌 요소의 특징 ID (벡터가 행렬로 처리되는 경우 열 번호)와 해당 값만 저장하여 다음 예제 프로토스에 드물게 저장 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="e47f03b2a63c4e509a81c6c7d3f37f7d1be1a857" translate="yes" xml:space="preserve">
          <source>These sufficient statistics are computed using the one pass algorithm on an input that's optionally shifted. See: &lt;a href=&quot;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data&quot;&gt;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data&lt;/a&gt;</source>
          <target state="translated">These sufficient statistics are computed using the one pass algorithm on an input that's optionally shifted. See: &lt;a href=&quot;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data&quot;&gt;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="df0616278e0670c1f8a838c05616c2906a5ad628" translate="yes" xml:space="preserve">
          <source>These sufficient statistics are computed using the one pass algorithm on an input that's optionally shifted. See: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data</source>
          <target state="translated">이러한 충분한 통계는 선택적으로 이동 된 입력에서 원 패스 알고리즘을 사용하여 계산됩니다. 참조 : https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data</target>
        </trans-unit>
        <trans-unit id="5c983cdacd0a0593413a5e4ab438ec1b6414a3f5" translate="yes" xml:space="preserve">
          <source>These typically correspond to model heads.</source>
          <target state="translated">이들은 일반적으로 모델 헤드에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="a2e13849b656ad081d144e8fb21e76af2be31973" translate="yes" xml:space="preserve">
          <source>These values are similar to values from a &lt;code&gt;random_normal_initializer&lt;/code&gt; except that values more than two standard deviations from the mean are discarded and re-drawn. This is the recommended initializer for neural network weights and filters.</source>
          <target state="translated">이 값은 평균과의 표준 편차가 둘 이상인 값을 버리고 다시 그린다는 점을 제외하고 &lt;code&gt;random_normal_initializer&lt;/code&gt; 의 값과 비슷합니다 . 신경망 가중치 및 필터에 권장되는 초기화 프로그램입니다.</target>
        </trans-unit>
        <trans-unit id="6f69d15ae681fb68548cb2f0cf5da97b8f2f416c" translate="yes" xml:space="preserve">
          <source>They are not resettable. Once a one-shot iterator reaches the end of its underlying dataset, subsequent &quot;IteratorGetNext&quot; operations on that iterator will always produce an &lt;code&gt;OutOfRange&lt;/code&gt; error.</source>
          <target state="translated">They are not resettable. Once a one-shot iterator reaches the end of its underlying dataset, subsequent &quot;IteratorGetNext&quot; operations on that iterator will always produce an &lt;code&gt;OutOfRange&lt;/code&gt; error.</target>
        </trans-unit>
        <trans-unit id="82a7de6a736dfa8a46716669d941754c78b26714" translate="yes" xml:space="preserve">
          <source>They do not support parameterization: all logic for creating the underlying dataset must be bundled in the &lt;code&gt;dataset_factory&lt;/code&gt; function.</source>
          <target state="translated">They do not support parameterization: all logic for creating the underlying dataset must be bundled in the &lt;code&gt;dataset_factory&lt;/code&gt; function.</target>
        </trans-unit>
        <trans-unit id="035fa9e40dd64ae60fe7c5634de4cc5ea73a82db" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized to have shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; by providing &lt;code&gt;spectrum&lt;/code&gt;, a &lt;code&gt;[B1,...,Bb, N0, N1, N2]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; with &lt;code&gt;N0*N1*N2 = N&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 &lt;code&gt;N0*N1*N2 = N&lt;/code&gt; &lt;code&gt;spectrum&lt;/code&gt; , &lt;code&gt;[B1,...,Bb, N0, N1, N2]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 를 제공하여 모양 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 으로 초기화됩니다 .</target>
        </trans-unit>
        <trans-unit id="7dc76893f409505eb4af8e3ca9d9b50f0907d32c" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized to have shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; by providing &lt;code&gt;spectrum&lt;/code&gt;, a &lt;code&gt;[B1,...,Bb, N0, N1]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; with &lt;code&gt;N0*N1 = N&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형상을 갖도록 초기화된다 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 제공함으로써 &lt;code&gt;spectrum&lt;/code&gt; 하는 &lt;code&gt;[B1,...,Bb, N0, N1]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; 와 &lt;code&gt;N0*N1 = N&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="45faa2260146699c38e2dafd91d1b8425180a30a" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized to have shape &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; by providing &lt;code&gt;spectrum&lt;/code&gt;, a &lt;code&gt;[B1,...,Bb, N]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형상이 초기화된다 &lt;code&gt;[B1,...,Bb, N, N]&lt;/code&gt; 제공함으로써 &lt;code&gt;spectrum&lt;/code&gt; 하는 &lt;code&gt;[B1,...,Bb, N]&lt;/code&gt; &lt;code&gt;Tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="14d38c8190663bcf5aee0e569e1c9fa815f97d9a" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized with boolean flags of the form &lt;code&gt;is_X&lt;/code&gt;, for &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt;. These have the following meaning</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형태의 부울 플래그로 초기화됩니다 &lt;code&gt;is_X&lt;/code&gt; 를 들어, &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt; . 이들은 다음과 같은 의미가 있습니다</target>
        </trans-unit>
        <trans-unit id="59e2aeacdf121218eb0206f7223d277271e20ff4" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized with boolean flags of the form &lt;code&gt;is_X&lt;/code&gt;, for &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt;. These have the following meaning:</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형태의 부울 플래그로 초기화됩니다 &lt;code&gt;is_X&lt;/code&gt; 를 들어, &lt;code&gt;X = non_singular, self_adjoint, positive_definite, square&lt;/code&gt; . 다음과 같은 의미가 있습니다.</target>
        </trans-unit>
        <trans-unit id="c893a77a5cadc49b62c18f0fba68970cb1dcbaf6" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;LinearOperator&lt;/code&gt; is initialized with boolean flags of the form &lt;code&gt;is_X&lt;/code&gt;, for &lt;code&gt;X = non_singular&lt;/code&gt;, &lt;code&gt;self_adjoint&lt;/code&gt;, &lt;code&gt;positive_definite&lt;/code&gt;, &lt;code&gt;diag_update_positive&lt;/code&gt; and &lt;code&gt;square&lt;/code&gt;. These have the following meaning:</source>
          <target state="translated">이 &lt;code&gt;LinearOperator&lt;/code&gt; 는 형태의 부울 플래그로 초기화됩니다 &lt;code&gt;is_X&lt;/code&gt; 를 들어, &lt;code&gt;X = non_singular&lt;/code&gt; , &lt;code&gt;self_adjoint&lt;/code&gt; , &lt;code&gt;positive_definite&lt;/code&gt; , &lt;code&gt;diag_update_positive&lt;/code&gt; 및 &lt;code&gt;square&lt;/code&gt; . 다음과 같은 의미가 있습니다.</target>
        </trans-unit>
        <trans-unit id="1af767d14077ff11d4e7fc9b014e22bbf1d448de" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;Model&lt;/code&gt; has a dependency named &quot;input_transform&quot; on its &lt;code&gt;Dense&lt;/code&gt; layer, which in turn depends on its variables. As a result, saving an instance of &lt;code&gt;Regress&lt;/code&gt; using &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; will also save all the variables created by the &lt;code&gt;Dense&lt;/code&gt; layer.</source>
          <target state="translated">이 &lt;code&gt;Model&lt;/code&gt; 은 &lt;code&gt;Dense&lt;/code&gt; 계층 에 &quot;input_transform&quot;이라는 종속성 이 있으며 변수에 따라 달라집니다. 결과적으로 &lt;code&gt;Regress&lt;/code&gt; 사용하여 &lt;a href=&quot;../../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 인스턴스를 저장하면 &lt;code&gt;Dense&lt;/code&gt; 계층에서 생성 된 모든 변수도 저장됩니다 .</target>
        </trans-unit>
        <trans-unit id="6bb0cfce4d3ef61c634cae7fd40aef46d6d26e65" translate="yes" xml:space="preserve">
          <source>This &lt;code&gt;Model&lt;/code&gt; has a dependency named &quot;input_transform&quot; on its &lt;code&gt;Dense&lt;/code&gt; layer, which in turn depends on its variables. As a result, saving an instance of &lt;code&gt;Regress&lt;/code&gt; using &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; will also save all the variables created by the &lt;code&gt;Dense&lt;/code&gt; layer.</source>
          <target state="translated">이 &lt;code&gt;Model&lt;/code&gt; 은 &lt;code&gt;Dense&lt;/code&gt; 계층 에 &quot;input_transform&quot;이라는 종속성 이 있으며 변수에 따라 달라집니다. 결과적으로 &lt;code&gt;Regress&lt;/code&gt; 사용하여 &lt;a href=&quot;checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 인스턴스를 저장하면 &lt;code&gt;Dense&lt;/code&gt; 계층에서 생성 된 모든 변수도 저장됩니다 .</target>
        </trans-unit>
        <trans-unit id="b5871012b5796b5a485fbd2ea90e6e96dc8a6361" translate="yes" xml:space="preserve">
          <source>This API allows querying the physical hardware resources prior to runtime initialization. Thus, giving an opportunity to call any additional configuration APIs. This is in contrast to &lt;a href=&quot;list_logical_devices&quot;&gt;&lt;code&gt;tf.config.list_logical_devices&lt;/code&gt;&lt;/a&gt;, which triggers runtime initialization in order to list the configured devices.</source>
          <target state="translated">이 API를 사용하면 런타임 초기화 전에 실제 하드웨어 리소스를 쿼리 할 수 ​​있습니다. 따라서 추가 구성 API를 호출 할 수 있습니다. 이는 구성된 장치를 나열하기 위해 런타임 초기화를 트리거 하는 &lt;a href=&quot;list_logical_devices&quot;&gt; &lt;code&gt;tf.config.list_logical_devices&lt;/code&gt; &lt;/a&gt; 와 대조됩니다 .</target>
        </trans-unit>
        <trans-unit id="74aac56e82063765baca7f72b6ef73462943063c" translate="yes" xml:space="preserve">
          <source>This API enables repeated preprocessing steps to be consolidated, and allows re-use of already processed data, trading off disk storage and network bandwidth for freeing up more valuable CPU resources and accelerator compute time.</source>
          <target state="translated">This API enables repeated preprocessing steps to be consolidated, and allows re-use of already processed data, trading off disk storage and network bandwidth for freeing up more valuable CPU resources and accelerator compute time.</target>
        </trans-unit>
        <trans-unit id="762aea1a89e9b0e55d82633b7d3d567f5d2f187d" translate="yes" xml:space="preserve">
          <source>This API takes in a &lt;a href=&quot;../physicaldevice&quot;&gt;&lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt;&lt;/a&gt; returned by &lt;a href=&quot;../list_physical_devices&quot;&gt;&lt;code&gt;tf.config.list_physical_devices&lt;/code&gt;&lt;/a&gt;. It returns a dict with string keys containing various details about the device. Each key is only supported by a subset of devices, so you should not assume the returned dict will have any particular key.</source>
          <target state="translated">This API takes in a &lt;a href=&quot;../physicaldevice&quot;&gt; &lt;code&gt;tf.config.PhysicalDevice&lt;/code&gt; &lt;/a&gt; returned by &lt;a href=&quot;../list_physical_devices&quot;&gt; &lt;code&gt;tf.config.list_physical_devices&lt;/code&gt; &lt;/a&gt;. It returns a dict with string keys containing various details about the device. Each key is only supported by a subset of devices, so you should not assume the returned dict will have any particular key.</target>
        </trans-unit>
        <trans-unit id="22207bc9bfb65faecbe8df80de09b7c7ff71edfd" translate="yes" xml:space="preserve">
          <source>This API will connect to remote TPU cluster and initialize the TPU hardwares. Example usage:</source>
          <target state="translated">This API will connect to remote TPU cluster and initialize the TPU hardwares. Example usage:</target>
        </trans-unit>
        <trans-unit id="fb9102764cadc1d75fc4b0e80481d3d9ed63d68c" translate="yes" xml:space="preserve">
          <source>This Estimator implements the following variants of the K-means algorithm:</source>
          <target state="translated">이 추정기는 K- 평균 알고리즘의 다음 변형을 구현합니다.</target>
        </trans-unit>
        <trans-unit id="80c1b7fb2eecacd5d699b9ee230de5704ca37c8d" translate="yes" xml:space="preserve">
          <source>This Multinomial distribution is parameterized by &lt;code&gt;probs&lt;/code&gt;, a (batch of) length-&lt;code&gt;K&lt;/code&gt;&lt;code&gt;prob&lt;/code&gt; (probability) vectors (&lt;code&gt;K &amp;gt; 1&lt;/code&gt;) such that &lt;code&gt;tf.reduce_sum(probs, -1) = 1&lt;/code&gt;, and a &lt;code&gt;total_count&lt;/code&gt; number of trials, i.e., the number of trials per draw from the Multinomial. It is defined over a (batch of) length-&lt;code&gt;K&lt;/code&gt; vector &lt;code&gt;counts&lt;/code&gt; such that &lt;code&gt;tf.reduce_sum(counts, -1) = total_count&lt;/code&gt;. The Multinomial is identically the Binomial distribution when &lt;code&gt;K = 2&lt;/code&gt;.</source>
          <target state="translated">이 다항 분포가 매개 변수화되는 &lt;code&gt;probs&lt;/code&gt; A (일괄) 길이 - &lt;code&gt;K&lt;/code&gt; 의 &lt;code&gt;prob&lt;/code&gt; (확률) 벡터 ( &lt;code&gt;K &amp;gt; 1&lt;/code&gt; )이되도록 &lt;code&gt;tf.reduce_sum(probs, -1) = 1&lt;/code&gt; , 및 &lt;code&gt;total_count&lt;/code&gt; , 실험의 수 즉, 다항식에서 뽑기 당 시행 횟수. &lt;code&gt;tf.reduce_sum(counts, -1) = total_count&lt;/code&gt; 가 되도록 ( 일괄) 길이 &lt;code&gt;K&lt;/code&gt; 벡터 &lt;code&gt;counts&lt;/code&gt; 대해 정의 됩니다. &lt;code&gt;K = 2&lt;/code&gt; 때 다항식은 이항 분포 입니다.</target>
        </trans-unit>
        <trans-unit id="61586b843c2a7242a7ce5f726a415d728d094add" translate="yes" xml:space="preserve">
          <source>This Op also supports repeated indices in the output subscript, which is not supported by &lt;code&gt;numpy.einsum&lt;/code&gt;.</source>
          <target state="translated">This Op also supports repeated indices in the output subscript, which is not supported by &lt;code&gt;numpy.einsum&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d0c42e63acc7dcc7eea605a766b11674d1c53e82" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] != y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] != y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="74ec1aa4f8491ea53037a0fc532d4741eb9218bd" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt; 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt; 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="64284c5803db04a210d1a9048bfe82459a849a9d" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="382c384f5bde2874efffdf9480af145ba234b875" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt;= 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt;= 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="501dbba0dad9772b46dd6dbe6d32dfc34b3073e4" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="86a98c771b136d5122e127f8b045988c2c9039d5" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt; 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt; 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="a26f9f0c29e64714922c2bda7e956bffe84f5c0c" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="c63795d0aad1b74648e6a4624d3ec74f6c7d4a1e" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt;= 0&lt;/code&gt; holds for every element of &lt;code&gt;x&lt;/code&gt;. If &lt;code&gt;x&lt;/code&gt; is empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt;= 0&lt;/code&gt; 이 &lt;code&gt;x&lt;/code&gt; 의 모든 요소를 ​​보유 하는지 확인합니다 . 경우 &lt;code&gt;x&lt;/code&gt; 는 비어,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="52d38297a91871d25885ecc0eb75b01217f176df" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="a274dbd07debbab7fc4511fde87c45ce7dd5f11a" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] - y[i] &amp;lt; atol + rtol * tf.abs(y[i])&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] - y[i] &amp;lt; atol + rtol * tf.abs(y[i])&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 (브로드 캐스트) 요소에 대해 유지 되는지 확인 합니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="afe67f7444ede4a73d34ba9ae37a78f686f755dd" translate="yes" xml:space="preserve">
          <source>This Op checks that &lt;code&gt;x[i] == y[i]&lt;/code&gt; holds for every pair of (possibly broadcast) elements of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 Op는 &lt;code&gt;x[i] == y[i]&lt;/code&gt; 가 &lt;code&gt;x&lt;/code&gt; 및 &lt;code&gt;y&lt;/code&gt; 의 모든 요소 쌍 (방송 가능)을 보유 하는지 확인합니다 . 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="47fcdf77a806254f145cef6045f72f7418b87096" translate="yes" xml:space="preserve">
          <source>This Op checks that a collection of tensors shape relationships satisfies given constraints.</source>
          <target state="translated">이 Op는 텐서 모음의 관계가 주어진 제약 조건을 충족하는지 확인합니다.</target>
        </trans-unit>
        <trans-unit id="70d8b32973294baa04c2b6c2343f69d0d35b251b" translate="yes" xml:space="preserve">
          <source>This Op checks that the rank of &lt;code&gt;x&lt;/code&gt; is equal to &lt;code&gt;rank&lt;/code&gt;.</source>
          <target state="translated">이 조작 검사의 순위를 &lt;code&gt;x&lt;/code&gt; 동일하다 &lt;code&gt;rank&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="45bf526016d2ed135926c16509b05dd90dd8b920" translate="yes" xml:space="preserve">
          <source>This Op checks that the rank of &lt;code&gt;x&lt;/code&gt; is greater or equal to &lt;code&gt;rank&lt;/code&gt;.</source>
          <target state="translated">이 조작 검사의 순위를 &lt;code&gt;x&lt;/code&gt; 크거나 같은지 &lt;code&gt;rank&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ef8abcb7ef7c82e56e48acf10aee7a915b661e8e" translate="yes" xml:space="preserve">
          <source>This Op checks that the rank of &lt;code&gt;x&lt;/code&gt; is in &lt;code&gt;ranks&lt;/code&gt;.</source>
          <target state="translated">이 Op는 &lt;code&gt;x&lt;/code&gt; 의 순위 가 &lt;code&gt;ranks&lt;/code&gt; 인지 확인 합니다.</target>
        </trans-unit>
        <trans-unit id="9bbbc71838cec9daa4b798c766e634988ae8eda0" translate="yes" xml:space="preserve">
          <source>This Op does not require &lt;code&gt;a_indices&lt;/code&gt; be sorted in standard lexicographic order.</source>
          <target state="translated">This Op does not require &lt;code&gt;a_indices&lt;/code&gt; be sorted in standard lexicographic order.</target>
        </trans-unit>
        <trans-unit id="995662dbb5ee7bd63655bfa102038ae50bbbb546" translate="yes" xml:space="preserve">
          <source>This Op does not support implicit form. (i.e. equations without &lt;code&gt;-&amp;gt;&lt;/code&gt;).</source>
          <target state="translated">This Op does not support implicit form. (i.e. equations without &lt;code&gt;-&amp;gt;&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="b037dc8de7a8b2184874f7694988339f20126019" translate="yes" xml:space="preserve">
          <source>This Op eases the porting of code that uses embedding_lookup_sparse(), although some Python preprocessing of the SparseTensor arguments to embedding_lookup_sparse() is required to produce the arguments to this Op, since only a single EnqueueTPUEmbeddingSparseBatch Op is allowed per training step.</source>
          <target state="translated">This Op eases the porting of code that uses embedding_lookup_sparse(), although some Python preprocessing of the SparseTensor arguments to embedding_lookup_sparse() is required to produce the arguments to this Op, since only a single EnqueueTPUEmbeddingSparseBatch Op is allowed per training step.</target>
        </trans-unit>
        <trans-unit id="b3230f00e0154436022761e6b1f967d770055298" translate="yes" xml:space="preserve">
          <source>This Op first attempts to find the V2 index file pointed to by &quot;prefix&quot;, and if found proceed to read it as a V2 checkpoint;</source>
          <target state="translated">This Op first attempts to find the V2 index file pointed to by &quot;prefix&quot;, and if found proceed to read it as a V2 checkpoint;</target>
        </trans-unit>
        <trans-unit id="1ed5e982672256e8ea90d7bd0d72e83dbb1172c0" translate="yes" xml:space="preserve">
          <source>This Op only supports unary and binary forms of &lt;code&gt;numpy.einsum&lt;/code&gt;.</source>
          <target state="translated">This Op only supports unary and binary forms of &lt;code&gt;numpy.einsum&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="793a60433b6712b8062346cc2fb3747282971aed" translate="yes" xml:space="preserve">
          <source>This Op picks a random location in &lt;code&gt;image&lt;/code&gt; and crops a &lt;code&gt;height&lt;/code&gt; by &lt;code&gt;width&lt;/code&gt; rectangle from that location. The random location is picked so the cropped area will fit inside the original image.</source>
          <target state="translated">This Op picks a random location in &lt;code&gt;image&lt;/code&gt; and crops a &lt;code&gt;height&lt;/code&gt; by &lt;code&gt;width&lt;/code&gt; rectangle from that location. The random location is picked so the cropped area will fit inside the original image.</target>
        </trans-unit>
        <trans-unit id="214a679e138acba179edb8672f1201325c1e87b6" translate="yes" xml:space="preserve">
          <source>This Op produces a set of TPU cores (for warm-up) or a single TPU core (for regular inference) to execute the TPU program on. The output is consumed by TPUPartitionedCall.</source>
          <target state="translated">This Op produces a set of TPU cores (for warm-up) or a single TPU core (for regular inference) to execute the TPU program on. The output is consumed by TPUPartitionedCall.</target>
        </trans-unit>
        <trans-unit id="1956a13a2a0626040a0d05adca12d21c39b428f4" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In contrast to SparseReduceSum, this Op returns a SparseTensor.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. SparseReduceSum과 달리이 Op는 SparseTensor를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="21543202b1cccf9199ac85ba0b6367bb37a43438" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 희박한 &lt;code&gt;Tensor&lt;/code&gt; 대신에 조밀 한 텐서 를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="a92cf7c266fad63ba2ede16d013a7954c0a3ed23" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In contrast to SparseReduceSum, this Op returns a SparseTensor.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. SparseReduceSum과 달리이 Op는 SparseTensor를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="eff3316c87e58a0e09844e295d654acad826f230" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 희박한 &lt;code&gt;Tensor&lt;/code&gt; 대신에 조밀 한 텐서 를 반환합니다 .</target>
        </trans-unit>
        <trans-unit id="02bfe7eb6e17547c27337071dde6515aea09a633" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In contrast to SparseReduceMax, this Op returns a SparseTensor.</source>
          <target state="translated">This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt;. In contrast to SparseReduceMax, this Op returns a SparseTensor.</target>
        </trans-unit>
        <trans-unit id="7321159b3f380865d8a3ddbbd1ea9288e20a93c6" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, or a &lt;code&gt;SparseTensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 이면 밀도가 높은 &lt;code&gt;Tensor&lt;/code&gt; 를 , &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 이면 SparseTensor를 &lt;code&gt;SparseTensor&lt;/code&gt; 합니다 .</target>
        </trans-unit>
        <trans-unit id="b1103b246b6e1caad53d997c04c64c3898e6d3b5" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_max&quot;&gt;&lt;code&gt;tf.reduce_max()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</source>
          <target state="translated">This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_max&quot;&gt; &lt;code&gt;tf.reduce_max()&lt;/code&gt; &lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</target>
        </trans-unit>
        <trans-unit id="a81865bba66b7cb3ccd5c843f29a627466d44c58" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In contrast to SparseReduceSum, this Op returns a SparseTensor.</source>
          <target state="translated">This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt;. In contrast to SparseReduceSum, this Op returns a SparseTensor.</target>
        </trans-unit>
        <trans-unit id="a574e60c745da5b56aeabab5fc189ca97095b4e6" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, or a &lt;code&gt;SparseTensor&lt;/code&gt; if &lt;code&gt;output_is_sparse&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">이 Op는 SparseTensor를 사용하며 &lt;a href=&quot;../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt; 대한 스파 스 대응 입니다. 특히,이 Op는 &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;False&lt;/code&gt; 이면 밀도가 높은 &lt;code&gt;Tensor&lt;/code&gt; 를 , &lt;code&gt;output_is_sparse&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 이면 SparseTensor를 &lt;code&gt;SparseTensor&lt;/code&gt; 합니다 .</target>
        </trans-unit>
        <trans-unit id="0611fe28cd2ae42a84cd683414a5531be62247ed" translate="yes" xml:space="preserve">
          <source>This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_sum&quot;&gt;&lt;code&gt;tf.reduce_sum()&lt;/code&gt;&lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</source>
          <target state="translated">This Op takes a SparseTensor and is the sparse counterpart to &lt;a href=&quot;../math/reduce_sum&quot;&gt; &lt;code&gt;tf.reduce_sum()&lt;/code&gt; &lt;/a&gt;. In particular, this Op also returns a dense &lt;code&gt;Tensor&lt;/code&gt; instead of a sparse one.</target>
        </trans-unit>
        <trans-unit id="9513360fe89de6564516b0de822250d992516167" translate="yes" xml:space="preserve">
          <source>This adjusts the dynamic range of the gradient evaluation by scaling up the &lt;code&gt;loss&lt;/code&gt; value. The gradient values are then scaled back down by the recipricol of the loss scale. This is useful in reduced precision training where small gradient values would otherwise underflow the representable range.</source>
          <target state="translated">&lt;code&gt;loss&lt;/code&gt; 값 을 확대하여 그래디언트 평가의 동적 범위를 조정합니다 . 그래디언트 값은 손실 스케일의 역수에 따라 축소됩니다. 이것은 작은 기울기 값이 표현 가능한 범위를 넘치게하는 정밀 훈련에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="f5e97086794cce37b1d5d739075a4835500e01f8" translate="yes" xml:space="preserve">
          <source>This adjusts the dynamic range of the gradient evaluation by scaling up the &lt;code&gt;loss&lt;/code&gt; value. The gradient values are then scaled back down by the reciprocal of the loss scale. This is useful in reduced precision training where small gradient values would otherwise underflow the representable range.</source>
          <target state="translated">This adjusts the dynamic range of the gradient evaluation by scaling up the &lt;code&gt;loss&lt;/code&gt; value. The gradient values are then scaled back down by the reciprocal of the loss scale. This is useful in reduced precision training where small gradient values would otherwise underflow the representable range.</target>
        </trans-unit>
        <trans-unit id="33c2fc8a5963a345edc285e854dc6f61f0166cef" translate="yes" xml:space="preserve">
          <source>This allows 'names' which should be a list of names.</source>
          <target state="translated">This allows 'names' which should be a list of names.</target>
        </trans-unit>
        <trans-unit id="4742c30308cfd6082fa96c4df5f33b7fbb5afa83" translate="yes" xml:space="preserve">
          <source>This allows communication and coordination when there are multiple calls to the step_fn triggered by a call to &lt;code&gt;strategy.experimental_run_v2(step_fn, ...)&lt;/code&gt;.</source>
          <target state="translated">이는 &lt;code&gt;strategy.experimental_run_v2(step_fn, ...)&lt;/code&gt; 에 대한 호출에 의해 트리거 된 step_fn에 대한 여러 호출이있을 때 통신 및 조정을 허용합니다 .experimental_run_v2 (step_fn, ...) .</target>
        </trans-unit>
        <trans-unit id="54e8d42d088337b5915c0ad3a362c2e5bfd670e4" translate="yes" xml:space="preserve">
          <source>This allows communication and coordination when there are multiple calls to the step_fn triggered by a call to &lt;code&gt;strategy.run(step_fn, ...)&lt;/code&gt;.</source>
          <target state="translated">This allows communication and coordination when there are multiple calls to the step_fn triggered by a call to &lt;code&gt;strategy.run(step_fn, ...)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6406854276bccf2ce7a8330ff5c67c7e93bc6f24" translate="yes" xml:space="preserve">
          <source>This allows creating a sub-tensor from part of the current contents of a variable. See &lt;a href=&quot;../../tensor#__getitem__&quot;&gt;&lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; for detailed examples of slicing.</source>
          <target state="translated">이를 통해 변수의 현재 내용의 일부에서 하위 텐서를 만들 수 있습니다. &lt;a href=&quot;../../tensor#__getitem__&quot;&gt; &lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; 참조하십시오 . 슬라이스의 자세한 예는 &lt;strong&gt;getitem&lt;/strong&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="3f9bd14a03a5b9808d578e330775308ae0518e1f" translate="yes" xml:space="preserve">
          <source>This allows creating a sub-tensor from part of the current contents of a variable. See &lt;a href=&quot;tensor#__getitem__&quot;&gt;&lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt;&lt;/a&gt; for detailed examples of slicing.</source>
          <target state="translated">이를 통해 변수의 현재 내용의 일부에서 하위 텐서를 만들 수 있습니다. &lt;a href=&quot;tensor#__getitem__&quot;&gt; &lt;code&gt;tf.Tensor.&lt;strong&gt;getitem&lt;/strong&gt;&lt;/code&gt; &lt;/a&gt; 참조하십시오 . 슬라이스의 자세한 예는 &lt;strong&gt;getitem&lt;/strong&gt; 을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="4a0031976f29ed8ed5b38f0545ffe09ca05a84a3" translate="yes" xml:space="preserve">
          <source>This allows reading and writing to this tensors w/o copies. This more closely mirrors the C++ Interpreter class interface's tensor() member, hence the name. Be careful to not hold these output references through calls to &lt;code&gt;allocate_tensors()&lt;/code&gt; and &lt;code&gt;invoke()&lt;/code&gt;. This function cannot be used to read intermediate results.</source>
          <target state="translated">이를 통해 사본없이이 텐서에 읽고 쓸 수 있습니다. 이것은 C ++ 인터프리터 클래스 인터페이스의 tensor () 멤버를 더 밀접하게 반영하므로 이름입니다. assign_tensors &lt;code&gt;allocate_tensors()&lt;/code&gt; 및 &lt;code&gt;invoke()&lt;/code&gt; 호출을 통해 이러한 출력 참조를 보유하지 않도록주의하십시오 . 이 기능은 중간 결과를 읽는 데 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="aab58add7bb75e6c4119bf13ecc09894979d960d" translate="yes" xml:space="preserve">
          <source>This allows you to save the entirety of the state of a model in a single file.</source>
          <target state="translated">이를 통해 모델 상태 전체를 단일 파일로 저장할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="083c822ae2751294f6b801ab1aec618144643d76" translate="yes" xml:space="preserve">
          <source>This also supports either output striding via the optional &lt;code&gt;strides&lt;/code&gt; parameter or atrous convolution (also known as convolution with holes or dilated convolution, based on the French word &quot;trous&quot; meaning holes in English) via the optional &lt;code&gt;dilation_rate&lt;/code&gt; parameter. Currently, however, output striding is not supported for atrous convolutions.</source>
          <target state="translated">또한 선택적 &lt;code&gt;strides&lt;/code&gt; 매개 변수 를 통한 출력 보폭 또는 선택적 &lt;code&gt;dilation_rate&lt;/code&gt; 매개 변수 를 통해 거친 구 (또는 영어로 구멍을 의미하는 프랑스어 단어 &quot;trous&quot;를 기반으로하는 확장 된 회선으로도 알려져 있음) 또는 거친 컨볼 루션을 지원합니다 . 그러나 현재 출력 보폭은 격렬한 회선에 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0282c5f56f860d1be334e321248ec8429b6f156d" translate="yes" xml:space="preserve">
          <source>This also supports either output striding via the optional &lt;code&gt;strides&lt;/code&gt; parameter or atrous convolution (also known as convolution with holes or dilated convolution, based on the French word &quot;trous&quot; meaning holes in English) via the optional &lt;code&gt;dilations&lt;/code&gt; parameter. Currently, however, output striding is not supported for atrous convolutions.</source>
          <target state="translated">또한이 옵션을 통해 월쯤 중 출력 지원 &lt;code&gt;strides&lt;/code&gt; 옵션을 통해 (프랑스어 단어 영어로 &quot;trous&quot;를 의미하는 구멍을 기준으로도 구멍이나 팽창 회선과 회선으로 알려진) 매개 변수 또는 atrous 회선 &lt;code&gt;dilations&lt;/code&gt; 매개 변수를. 그러나 현재 출력 보폭은 격렬한 회선에 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="40ecf12ea54cbb9c03cee235c92870bdadc05d0e" translate="yes" xml:space="preserve">
          <source>This assumes the input dictionary contains a &lt;code&gt;SparseTensor&lt;/code&gt; for key 'terms', and a &lt;code&gt;SparseTensor&lt;/code&gt; for key 'frequencies'. These 2 tensors must have the same indices and dense shape.</source>
          <target state="translated">이는 입력 사전 에 키 'terms'에 대한 &lt;code&gt;SparseTensor&lt;/code&gt; 와 키 'frequencies'에 대한 &lt;code&gt;SparseTensor&lt;/code&gt; 가 포함되어 있다고 가정합니다 . 이 2 개의 텐서는 동일한 인덱스와 밀도가 있어야합니다.</target>
        </trans-unit>
        <trans-unit id="ec5e01502dedce9b5506d5284b5d16bed3dce6f8" translate="yes" xml:space="preserve">
          <source>This avoids adding &lt;code&gt;numpy_input&lt;/code&gt; as a large constant in the graph, and copies the data to the machine or machines that will be processing the input.</source>
          <target state="translated">이렇게하면 그래프에서 &lt;code&gt;numpy_input&lt;/code&gt; 을 큰 상수로 추가하지 않고 입력을 처리 할 기계에 데이터를 복사합니다.</target>
        </trans-unit>
        <trans-unit id="542cdf0657b556d7d4f13254bf996896da1af7f2" translate="yes" xml:space="preserve">
          <source>This behaves similarly to &lt;a href=&quot;../../name_scope&quot;&gt;&lt;code&gt;tf.name_scope&lt;/code&gt;&lt;/a&gt;, except that it returns a generated summary tag in addition to the scope name. The tag is structurally similar to the scope name - derived from the user-provided name, prefixed with enclosing name scopes if any - but we relax the constraint that it be uniquified, as well as the character set limitation (so the user-provided name can contain characters not legal for scope names; in the scope name these are removed).</source>
          <target state="translated">이것은 &lt;a href=&quot;../../name_scope&quot;&gt; &lt;code&gt;tf.name_scope&lt;/code&gt; &lt;/a&gt; 와 유사하게 동작 하지만 범위 이름 외에 생성 된 요약 태그를 반환한다는 점이 다릅니다. 이 태그는 범위 이름과 구조적으로 유사합니다 (사용자가 제공 한 이름에서 파생되고 접두어가있는 이름 범위가있는 경우 접두어가 있음). 그러나 문자 집합 제한 (사용자 설정 이름과 같이)으로 제한되어야한다는 제약 조건을 완화합니다. 범위 이름에 유효하지 않은 문자를 포함 할 수 있습니다 (범위 이름에서 제거됨).</target>
        </trans-unit>
        <trans-unit id="5d690c9d397a6da08fd08939e695a0fb6ea89e4b" translate="yes" xml:space="preserve">
          <source>This behavior gives control to callers on what to do if checkpoints do not come fast enough or stop being generated. For example, if callers have a way to detect that the training has stopped and know that no new checkpoints will be generated, they can provide a &lt;code&gt;timeout_fn&lt;/code&gt; that returns &lt;code&gt;True&lt;/code&gt; when the training has stopped. If they know that the training is still going on they return &lt;code&gt;False&lt;/code&gt; instead.</source>
          <target state="translated">이 동작은 체크 포인트가 충분히 빠르지 않거나 생성이 중지 될 경우 수행 할 작업을 호출자에게 제어합니다. 예를 들어, 호출자가 훈련이 중지되었음을 감지하고 새로운 검사 점이 생성되지 않음을 알 수있는 경우 훈련이 중지되면 &lt;code&gt;True&lt;/code&gt; 를 반환 하는 &lt;code&gt;timeout_fn&lt;/code&gt; 을 제공 할 수 있습니다 . 교육이 계속 진행되고 있음을 알고 있으면 대신 &lt;code&gt;False&lt;/code&gt; 를 반환 합니다.</target>
        </trans-unit>
        <trans-unit id="5d87911d57456c793352550a56288318dbdc2112" translate="yes" xml:space="preserve">
          <source>This behavior has been introduced in TensorFlow 2.0, in order to enable &lt;code&gt;layer.trainable = False&lt;/code&gt; to produce the most commonly expected behavior in the convnet fine-tuning use case.</source>
          <target state="translated">convnet 미세 조정 사용 사례에서 가장 일반적으로 예상되는 동작을 생성하기 위해 &lt;code&gt;layer.trainable = False&lt;/code&gt; 를 활성화하기 위해이 동작이 TensorFlow 2.0에 도입되었습니다 .</target>
        </trans-unit>
        <trans-unit id="566da943133ad9f7ff89e0ae58ccee97f0942cd9" translate="yes" xml:space="preserve">
          <source>This behavior only occurs as of TensorFlow 2.0. In 1.*, setting &lt;code&gt;layer.trainable = False&lt;/code&gt; would freeze the layer but would not switch it to inference mode.</source>
          <target state="translated">이 동작은 TensorFlow 2.0에서만 발생합니다. 1. *에서 &lt;code&gt;layer.trainable = False&lt;/code&gt; 설정 하면 레이어가 고정되지만 추론 모드로 전환하지는 않습니다.</target>
        </trans-unit>
        <trans-unit id="947e43a536a4f632b306b7d5c3e4805a08d13eec" translate="yes" xml:space="preserve">
          <source>This blocks the calling thread until the thread whose join() method is called terminates -- either normally or through an unhandled exception or until the optional timeout occurs.</source>
          <target state="translated">이것은 join () 메소드가 호출 된 스레드가 정상적으로 또는 처리되지 않은 예외를 통해 종료되거나 선택적 시간 종료가 발생할 때까지 호출 스레드를 차단합니다.</target>
        </trans-unit>
        <trans-unit id="f576e406288a87f269b5d6306d3d486ac32d4798" translate="yes" xml:space="preserve">
          <source>This boolean flag determines whether variables should be initialized as they are instantiated (default), or if the user should handle the initialization (e.g. via &lt;a href=&quot;../../compat/v1/initialize_all_variables&quot;&gt;&lt;code&gt;tf.compat.v1.initialize_all_variables()&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">이 부울 플래그는 변수를 인스턴스화 할 때 초기화해야하는지 (기본값) 또는 사용자가 초기화를 처리 &lt;a href=&quot;../../compat/v1/initialize_all_variables&quot;&gt; &lt;code&gt;tf.compat.v1.initialize_all_variables()&lt;/code&gt; &lt;/a&gt; 예 : tf.compat.v1.initialize_all_variables () 를 통해 ) 결정합니다.</target>
        </trans-unit>
        <trans-unit id="4711e34ac0b0f311f0826db62648fbfab1ecfcb6" translate="yes" xml:space="preserve">
          <source>This boolean is True when this is an export in the end of training. It is False for the intermediate exports during the training. When passing &lt;code&gt;Exporter&lt;/code&gt; to &lt;a href=&quot;train_and_evaluate&quot;&gt;&lt;code&gt;tf.estimator.train_and_evaluate&lt;/code&gt;&lt;/a&gt;&lt;code&gt;is_the_final_export&lt;/code&gt; is always False if &lt;a href=&quot;trainspec#max_steps&quot;&gt;&lt;code&gt;TrainSpec.max_steps&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">This boolean is True when this is an export in the end of training. It is False for the intermediate exports during the training. When passing &lt;code&gt;Exporter&lt;/code&gt; to &lt;a href=&quot;train_and_evaluate&quot;&gt; &lt;code&gt;tf.estimator.train_and_evaluate&lt;/code&gt; &lt;/a&gt; &lt;code&gt;is_the_final_export&lt;/code&gt; is always False if &lt;a href=&quot;trainspec#max_steps&quot;&gt; &lt;code&gt;TrainSpec.max_steps&lt;/code&gt; &lt;/a&gt; is &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0d320c46f5814a56c1f3f60058177b848b6fe981" translate="yes" xml:space="preserve">
          <source>This call blocks until a set of threads have terminated. The set of thread is the union of the threads passed in the &lt;code&gt;threads&lt;/code&gt; argument and the list of threads that registered with the coordinator by calling &lt;a href=&quot;coordinator#register_thread&quot;&gt;&lt;code&gt;Coordinator.register_thread()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 호출은 일련의 스레드가 종료 될 때까지 차단됩니다. 스레드 세트는 &lt;code&gt;threads&lt;/code&gt; 인수에 전달 된 스레드 와 &lt;a href=&quot;coordinator#register_thread&quot;&gt; &lt;code&gt;Coordinator.register_thread()&lt;/code&gt; &lt;/a&gt; 를 호출하여 코디네이터에 등록 된 스레드 목록의 결합 입니다.</target>
        </trans-unit>
        <trans-unit id="51c54c7d5726811d44822079b16e485771669c24" translate="yes" xml:space="preserve">
          <source>This call is ignored when eager execution is enabled (in that case, variable updates are run on the fly and thus do not need to be tracked for later execution).</source>
          <target state="translated">열망하는 실행이 활성화되면이 호출이 무시됩니다 (이 경우 변수 업데이트가 즉시 실행되므로 나중에 실행하기 위해 추적 할 필요가 없습니다).</target>
        </trans-unit>
        <trans-unit id="062df39159f4972c7eb0c0bbc3c621a80385af7d" translate="yes" xml:space="preserve">
          <source>This callback is automatically applied to every Keras model.</source>
          <target state="translated">이 콜백은 모든 Keras 모델에 자동으로 적용됩니다.</target>
        </trans-unit>
        <trans-unit id="4a2209138c3b99588918296a296e9d5cba348ee9" translate="yes" xml:space="preserve">
          <source>This callback is automatically applied to every Keras model. The &lt;code&gt;History&lt;/code&gt; object gets returned by the &lt;code&gt;fit&lt;/code&gt; method of models.</source>
          <target state="translated">이 콜백은 모든 Keras 모델에 자동으로 적용됩니다. &lt;code&gt;History&lt;/code&gt; 객체에 의해 반환됩니다 &lt;code&gt;fit&lt;/code&gt; 모델의 방법.</target>
        </trans-unit>
        <trans-unit id="9a8fccab0666eafd61c1fb78dee506da35fb92ce" translate="yes" xml:space="preserve">
          <source>This callback is constructed with anonymous functions that will be called at the appropriate time. Note that the callbacks expects positional arguments, as:</source>
          <target state="translated">이 콜백은 적절한 시간에 호출되는 익명 함수로 구성됩니다. 콜백에는 다음과 같은 위치 인수가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="d5a28ff485e6238d1ad10ebb9f92b4945e5fbef4" translate="yes" xml:space="preserve">
          <source>This callback is not compatible with disabling eager execution.</source>
          <target state="translated">This callback is not compatible with disabling eager execution.</target>
        </trans-unit>
        <trans-unit id="d2fd53cd69211c630c172b830b110ef6741f78e7" translate="yes" xml:space="preserve">
          <source>This callback logs events for TensorBoard, including:</source>
          <target state="translated">이 콜백은 다음을 포함하여 TensorBoard에 대한 이벤트를 기록합니다.</target>
        </trans-unit>
        <trans-unit id="6cbedc26a564f8697fb303c927049b43625f8671" translate="yes" xml:space="preserve">
          <source>This can also be used in a &lt;a href=&quot;tableconfig&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt;&lt;/a&gt; as the optimizer parameter to set a table specific optimizer. This will override the optimizer and parameters for global embedding optimizer defined above:</source>
          <target state="translated">This can also be used in a &lt;a href=&quot;tableconfig&quot;&gt; &lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt; &lt;/a&gt; as the optimizer parameter to set a table specific optimizer. This will override the optimizer and parameters for global embedding optimizer defined above:</target>
        </trans-unit>
        <trans-unit id="6c4d9ff06bd1c217d75cb9a57ebc28626f964add" translate="yes" xml:space="preserve">
          <source>This can always be checked statically, so this method returns nothing.</source>
          <target state="translated">항상 정적으로 확인할 수 있으므로이 메소드는 아무 것도 반환하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="6f195f030f5d6a3952c927a303c10a3d51f131c5" translate="yes" xml:space="preserve">
          <source>This can be faster than multiple individual &lt;code&gt;reduce&lt;/code&gt;s because we can fuse several tensors into one or multiple packs before reduction.</source>
          <target state="translated">이 빠른 개별 다중보다이 될 수 &lt;code&gt;reduce&lt;/code&gt; 우리가 감소하기 전에 하나 개 또는 여러 개의 팩으로 여러 텐서를 융합 할 수 있기 때문에들.</target>
        </trans-unit>
        <trans-unit id="ef728ae4ad68ee3a6531133cdd224d4406968fce" translate="yes" xml:space="preserve">
          <source>This can be passed to methods like &lt;code&gt;tf.distribute.get_replica_context().all_reduce()&lt;/code&gt; to optimize collective operation performance. Note that these are only hints, which may or may not change the actual behavior. Some options only apply to certain strategy and are ignored by others.</source>
          <target state="translated">This can be passed to methods like &lt;code&gt;tf.distribute.get_replica_context().all_reduce()&lt;/code&gt; to optimize collective operation performance. Note that these are only hints, which may or may not change the actual behavior. Some options only apply to certain strategy and are ignored by others.</target>
        </trans-unit>
        <trans-unit id="f4c1e8ee1a694edb65fdf5329eae65afdec683d9" translate="yes" xml:space="preserve">
          <source>This can be used as a &quot;join&quot; mechanism for parallel computations: all the argument tensors can be computed in parallel, but the values of any tensor returned by &lt;code&gt;tuple&lt;/code&gt; are only available after all the parallel computations are done.</source>
          <target state="translated">이것은 병렬 계산을위한 &quot;결합&quot;메커니즘으로 사용될 수 있습니다. 모든 인수 텐서는 병렬로 계산 될 수 있지만 &lt;code&gt;tuple&lt;/code&gt; 에 의해 반환 된 텐서의 값은 모든 병렬 계산이 완료된 후에 만 ​​사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="66b08400383b183cc1cba0b591ec90b5fe85d73d" translate="yes" xml:space="preserve">
          <source>This can be used as a loss-function during optimization so as to suppress noise in images. If you have a batch of images, then you should calculate the scalar loss-value as the sum: &lt;code&gt;loss = tf.reduce_sum(tf.image.total_variation(images))&lt;/code&gt;</source>
          <target state="translated">이것은 이미지에서 노이즈를 억제하기 위해 최적화 중에 손실 함수로 사용될 수 있습니다. 이미지 배치가있는 경우 스칼라 손실 값을 합으로 계산해야합니다. &lt;code&gt;loss = tf.reduce_sum(tf.image.total_variation(images))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f9d5c2eebbfc8025f5c8da3b80769337a79a6187" translate="yes" xml:space="preserve">
          <source>This can be used to hold some strategy specific configs.</source>
          <target state="translated">This can be used to hold some strategy specific configs.</target>
        </trans-unit>
        <trans-unit id="ff61da80eb1038583fadf6e588b06357b27a55d8" translate="yes" xml:space="preserve">
          <source>This can be useful for debugging or profiling. For example, let's say you implemented a simple iterative sqrt function, and you want to collect the intermediate values and plot the convergence. Appending the values to a list in &lt;code&gt;@tf.function&lt;/code&gt; normally wouldn't work since it will just record the Tensors being traced, not the values. Instead, you can do the following.</source>
          <target state="translated">디버깅 또는 프로파일 링에 유용 할 수 있습니다. 예를 들어 간단한 반복 sqrt 함수를 구현했으며 중간 값을 수집하고 수렴을 플로팅하려고한다고 가정 해 보겠습니다. &lt;code&gt;@tf.function&lt;/code&gt; 의 목록에 값을 추가하면 값 이 아닌 추적되는 텐서를 기록하기 때문에 일반적으로 작동하지 않습니다. 대신 다음을 수행 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5bc85a9ecd105989dec28b806afbbe4faa69f248" translate="yes" xml:space="preserve">
          <source>This can be useful if you want to log debug a training algorithm, report stats about the slots, etc.</source>
          <target state="translated">훈련 알고리즘을 디버그 디버그하고 슬롯에 대한 통계를보고하려는 경우에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="de803dd8ed0f3487c59166443a170b97850a2c8d" translate="yes" xml:space="preserve">
          <source>This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...</source>
          <target state="translated">이 클래스를 사용하면 각 텍스트를 정수 시퀀스 (각 정수는 사전의 토큰 색인 임) 또는 단어 수를 기준으로 각 토큰의 계수가 이진일 수있는 벡터로 변환하여 텍스트 코퍼스를 벡터화 할 수 있습니다. tf-idf를 기반으로 ...</target>
        </trans-unit>
        <trans-unit id="c35c7cb7e9df11039724d697524b210395fe269e" translate="yes" xml:space="preserve">
          <source>This class assumes each worker is running the same code independently, but parameter servers are running a standard server. This means that while each worker will synchronously compute a single gradient update across all GPUs, updates between workers proceed asynchronously. Operations that occur only on the first replica (such as incrementing the global step), will occur on the first replica &lt;em&gt;of every worker&lt;/em&gt;.</source>
          <target state="translated">이 클래스는 각 작업자가 동일한 코드를 독립적으로 실행하지만 매개 변수 서버는 표준 서버를 실행한다고 가정합니다. 즉, 각 작업자가 모든 GPU에서 단일 그라디언트 업데이트를 동 기적으로 계산하지만 작업자 간의 업데이트는 비동기 적으로 진행됩니다. 첫 번째 복제본에서만 발생하는 작업 (예 : 전역 단계 증가) &lt;em&gt;은 모든 작업자&lt;/em&gt; 의 첫 번째 복제본 &lt;em&gt;에서&lt;/em&gt; 발생합니다 .</target>
        </trans-unit>
        <trans-unit id="1ea4dadc6d5580b6a9567a54f238c77dab3d0a06" translate="yes" xml:space="preserve">
          <source>This class caches file writers, one per directory.</source>
          <target state="translated">이 클래스는 파일 작성자를 디렉토리 당 하나씩 캐시합니다.</target>
        </trans-unit>
        <trans-unit id="b8684cfbd26f7ff4ba54e9a816ce8e5ac6de8988" translate="yes" xml:space="preserve">
          <source>This class can be used to support training large embeddings on TPU. When creating an instance of this class, you must specify the complete set of tables and features you expect to lookup in those tables. See the documentation of &lt;a href=&quot;tableconfig&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;featureconfig&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.FeatureConfig&lt;/code&gt;&lt;/a&gt; for more details on the complete set of options. We will cover the basic usage here.</source>
          <target state="translated">This class can be used to support training large embeddings on TPU. When creating an instance of this class, you must specify the complete set of tables and features you expect to lookup in those tables. See the documentation of &lt;a href=&quot;tableconfig&quot;&gt; &lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;featureconfig&quot;&gt; &lt;code&gt;tf.tpu.experimental.embedding.FeatureConfig&lt;/code&gt; &lt;/a&gt; for more details on the complete set of options. We will cover the basic usage here.</target>
        </trans-unit>
        <trans-unit id="e9243b860278b8d7215f95a8eb101fc7a883ab5b" translate="yes" xml:space="preserve">
          <source>This class can create placeholders for tf.Tensors, tf.SparseTensors, and tf.RaggedTensors by choosing 'sparse=True' or 'ragged=True'.</source>
          <target state="translated">이 클래스는 'sparse = True'또는 'ragged = True'를 선택하여 tf.Tensors, tf.SparseTensors 및 tf.RaggedTensors에 대한 플레이스 홀더를 작성할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="805ec9c49684c57a889497d64617b10bca6259a1" translate="yes" xml:space="preserve">
          <source>This class can create placeholders for tf.Tensors, tf.SparseTensors, and tf.RaggedTensors by choosing 'sparse=True' or 'ragged=True'. Note that 'sparse' and 'ragged' can't be configured to True at same time. Usage:</source>
          <target state="translated">This class can create placeholders for tf.Tensors, tf.SparseTensors, and tf.RaggedTensors by choosing 'sparse=True' or 'ragged=True'. Note that 'sparse' and 'ragged' can't be configured to True at same time. Usage:</target>
        </trans-unit>
        <trans-unit id="b93eb86d4b8b199ed8de190972226d76d3ddbda5" translate="yes" xml:space="preserve">
          <source>This class defines the API to add Ops to train a model. You never use this class directly, but instead instantiate one of its subclasses such as &lt;a href=&quot;sgd&quot;&gt;&lt;code&gt;tf.keras.optimizers.SGD&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;adam&quot;&gt;&lt;code&gt;tf.keras.optimizers.Adam&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이 클래스는 모델 학습을 위해 Ops를 추가하는 API를 정의합니다. 이 클래스를 직접 사용하지 말고 대신 &lt;a href=&quot;sgd&quot;&gt; &lt;code&gt;tf.keras.optimizers.SGD&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;adam&quot;&gt; &lt;code&gt;tf.keras.optimizers.Adam&lt;/code&gt; &lt;/a&gt; 과 같은 서브 클래스 중 하나를 인스턴스화 하십시오 .</target>
        </trans-unit>
        <trans-unit id="1921ba1f544676f9bbcb9030a711c397087751d1" translate="yes" xml:space="preserve">
          <source>This class defines the API to add Ops to train a model. You never use this class directly, but instead instantiate one of its subclasses such as &lt;code&gt;GradientDescentOptimizer&lt;/code&gt;, &lt;code&gt;AdagradOptimizer&lt;/code&gt;, or &lt;code&gt;MomentumOptimizer&lt;/code&gt;.</source>
          <target state="translated">이 클래스는 모델 학습을 위해 Ops를 추가하는 API를 정의합니다. 이 클래스를 직접 사용하지 말고 &lt;code&gt;GradientDescentOptimizer&lt;/code&gt; , &lt;code&gt;AdagradOptimizer&lt;/code&gt; 또는 &lt;code&gt;MomentumOptimizer&lt;/code&gt; 와 같은 하위 클래스 중 하나를 인스턴스화하십시오 .</target>
        </trans-unit>
        <trans-unit id="f1b4934ebc6e87e946a8327b096ccaba6f902fbb" translate="yes" xml:space="preserve">
          <source>This class defines the key and value used for tf.lookup.TextFileInitializer.</source>
          <target state="translated">이 클래스는 tf.lookup.TextFileInitializer에 사용되는 키와 값을 정의합니다.</target>
        </trans-unit>
        <trans-unit id="bbef232ee84dd43e03ff0bb31e2fff3d62ddb086" translate="yes" xml:space="preserve">
          <source>This class exports the serving graph and checkpoints at the end.</source>
          <target state="translated">이 클래스는 마지막에 검색 그래프와 검사 점을 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="2398f265a0682e91ce8fc30c31cc00a32b85cf94" translate="yes" xml:space="preserve">
          <source>This class exports the serving graph and checkpoints of the best models.</source>
          <target state="translated">이 클래스는 최상의 모델의 검색 그래프 및 검사 점을 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="f378b5fe5691dc39f9cd3d236136a8685104c4fd" translate="yes" xml:space="preserve">
          <source>This class has been deprecated. Please use &lt;a href=&quot;../../../lite/tfliteconverter&quot;&gt;&lt;code&gt;lite.TFLiteConverter&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">이 클래스는 더 이상 사용되지 않습니다. 사용하십시오 &lt;a href=&quot;../../../lite/tfliteconverter&quot;&gt; &lt;code&gt;lite.TFLiteConverter&lt;/code&gt; 을&lt;/a&gt; 대신.</target>
        </trans-unit>
        <trans-unit id="56db13aef8a0368de7cd44eab17a2a6ce7b0dc42" translate="yes" xml:space="preserve">
          <source>This class has been deprecated. Please use &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter&quot;&gt;&lt;code&gt;lite.TFLiteConverter&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">This class has been deprecated. Please use &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter&quot;&gt; &lt;code&gt;lite.TFLiteConverter&lt;/code&gt; &lt;/a&gt; instead.</target>
        </trans-unit>
        <trans-unit id="8616741a1ce86b957920807cdf7bdf7cd9ce000e" translate="yes" xml:space="preserve">
          <source>This class has two primary purposes:</source>
          <target state="translated">이 수업에는 두 가지 주요 목적이 있습니다.</target>
        </trans-unit>
        <trans-unit id="42f7db2b92ba92041bfe671280afd36a3919a9f0" translate="yes" xml:space="preserve">
          <source>This class holds the configuration data for a single embedding feature. The main use is to assign features to &lt;a href=&quot;tableconfig&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt;&lt;/a&gt;s via the table parameter:</source>
          <target state="translated">This class holds the configuration data for a single embedding feature. The main use is to assign features to &lt;a href=&quot;tableconfig&quot;&gt; &lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt; &lt;/a&gt;s via the table parameter:</target>
        </trans-unit>
        <trans-unit id="3a9133b931fbc77d042cdefc7dee2428d484b0ed" translate="yes" xml:space="preserve">
          <source>This class holds the configuration data for a single embedding table. It is used as the &lt;code&gt;table&lt;/code&gt; parameter of a &lt;a href=&quot;featureconfig&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.FeatureConfig&lt;/code&gt;&lt;/a&gt;. Multiple &lt;a href=&quot;featureconfig&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.FeatureConfig&lt;/code&gt;&lt;/a&gt; objects can use the same &lt;a href=&quot;tableconfig&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt;&lt;/a&gt; object. In this case a shared table will be created for those feature lookups.</source>
          <target state="translated">This class holds the configuration data for a single embedding table. It is used as the &lt;code&gt;table&lt;/code&gt; parameter of a &lt;a href=&quot;featureconfig&quot;&gt; &lt;code&gt;tf.tpu.experimental.embedding.FeatureConfig&lt;/code&gt; &lt;/a&gt;. Multiple &lt;a href=&quot;featureconfig&quot;&gt; &lt;code&gt;tf.tpu.experimental.embedding.FeatureConfig&lt;/code&gt; &lt;/a&gt; objects can use the same &lt;a href=&quot;tableconfig&quot;&gt; &lt;code&gt;tf.tpu.experimental.embedding.TableConfig&lt;/code&gt; &lt;/a&gt; object. In this case a shared table will be created for those feature lookups.</target>
        </trans-unit>
        <trans-unit id="e41eb7b59b50f02eb388655630751957c627b643" translate="yes" xml:space="preserve">
          <source>This class implements &lt;code&gt;__enter__&lt;/code&gt; and &lt;code&gt;__exit__&lt;/code&gt;, and can be used in &lt;code&gt;with&lt;/code&gt; blocks like a normal file.</source>
          <target state="translated">이 클래스는 &lt;code&gt;__enter__&lt;/code&gt; 및 &lt;code&gt;__exit__&lt;/code&gt; 을 구현 하며 일반 파일처럼 블록과 &lt;code&gt;with&lt;/code&gt; 사용할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="8e6a775ae22bedf95251724d923983db37089b28" translate="yes" xml:space="preserve">
          <source>This class implements &lt;code&gt;__enter__&lt;/code&gt; and &lt;code&gt;__exit__&lt;/code&gt;, and can be used in &lt;code&gt;with&lt;/code&gt; blocks like a normal file. (See the usage example above.)</source>
          <target state="translated">This class implements &lt;code&gt;__enter__&lt;/code&gt; and &lt;code&gt;__exit__&lt;/code&gt; , and can be used in &lt;code&gt;with&lt;/code&gt; blocks like a normal file. (See the usage example above.)</target>
        </trans-unit>
        <trans-unit id="61d78e6233b72d451051551f631a8d253b9c0d10" translate="yes" xml:space="preserve">
          <source>This class implements a simple mechanism to coordinate the termination of a set of threads.</source>
          <target state="translated">이 클래스는 일련의 스레드 종료를 조정하는 간단한 메커니즘을 구현합니다.</target>
        </trans-unit>
        <trans-unit id="2c453470b9fb7d2dd4c8372805a2c5b45dcafe1a" translate="yes" xml:space="preserve">
          <source>This class in stateful and thread-compatible.</source>
          <target state="translated">이 클래스는 상태 저장 및 스레드 호환이 가능합니다.</target>
        </trans-unit>
        <trans-unit id="b6c71f2399c238428100228254e29a64f6c45e19" translate="yes" xml:space="preserve">
          <source>This class is a simple wrapper for a pair of &lt;code&gt;Tensor&lt;/code&gt; objects:</source>
          <target state="translated">이 클래스는 한 쌍의 &lt;code&gt;Tensor&lt;/code&gt; 객체에 대한 간단한 래퍼입니다 .</target>
        </trans-unit>
        <trans-unit id="aaddfb846b1d90d727149969bb3d79f9de0c7466" translate="yes" xml:space="preserve">
          <source>This class is a small wrapper that takes care of session creation and checkpoint recovery. It also provides functions that to facilitate coordination among multiple training threads or processes.</source>
          <target state="translated">이 클래스는 세션 작성 및 검사 점 복구를 처리하는 작은 래퍼입니다. 또한 여러 교육 스레드 또는 프로세스 간의 조정을 용이하게하는 기능을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="17463f3d93317c6b5e6f0cc508b2a6f39e7358ea" translate="yes" xml:space="preserve">
          <source>This class is deprecated. For synchrononous training, please use &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;Distribution Strategies&lt;/a&gt;.</source>
          <target state="translated">이 클래스는 더 이상 사용되지 않습니다. 동기식 교육의 경우 &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;배포 전략을&lt;/a&gt; 사용하십시오. .</target>
        </trans-unit>
        <trans-unit id="000d9e8de17ad9ab35fd8858d3f373310d7cf1c7" translate="yes" xml:space="preserve">
          <source>This class is deprecated. For synchronous training, please use &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;Distribution Strategies&lt;/a&gt;.</source>
          <target state="translated">This class is deprecated. For synchronous training, please use &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute&quot;&gt;Distribution Strategies&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="4616d8f2e476585f5e22705937707332b5baeb5b" translate="yes" xml:space="preserve">
          <source>This class is deprecated. Please use &lt;a href=&quot;monitoredtrainingsession&quot;&gt;&lt;code&gt;tf.compat.v1.train.MonitoredTrainingSession&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">이 클래스는 더 이상 사용되지 않습니다. &lt;a href=&quot;monitoredtrainingsession&quot;&gt; &lt;code&gt;tf.compat.v1.train.MonitoredTrainingSession&lt;/code&gt; 을&lt;/a&gt; 사용 하십시오 대신.</target>
        </trans-unit>
        <trans-unit id="42d3bc86be52a8736e6d7aa317815110401307ef" translate="yes" xml:space="preserve">
          <source>This class is heavily overloaded:</source>
          <target state="translated">이 클래스는 과도하게 오버로드되었습니다.</target>
        </trans-unit>
        <trans-unit id="22170de053f3420fc08a96260e613e3fa8486018" translate="yes" xml:space="preserve">
          <source>This class is meant to be used with dynamic iteration primitives such as &lt;code&gt;while_loop&lt;/code&gt; and &lt;code&gt;map_fn&lt;/code&gt;. It supports gradient back-propagation via special &quot;flow&quot; control flow dependencies.</source>
          <target state="translated">이 클래스는 &lt;code&gt;while_loop&lt;/code&gt; 및 &lt;code&gt;map_fn&lt;/code&gt; 과 같은 동적 반복 기본 요소와 함께 사용됩니다 . 특수한 &quot;흐름&quot;제어 흐름 종속성을 통한 그라디언트 역 전파를 지원합니다.</target>
        </trans-unit>
        <trans-unit id="3c5c516c190cd8f8be6eb152047649a9bf6735af" translate="yes" xml:space="preserve">
          <source>This class is not thread-safe.</source>
          <target state="translated">This class is not thread-safe.</target>
        </trans-unit>
        <trans-unit id="121c6274230c0f7d1b806b54f9d580ba8e2d228a" translate="yes" xml:space="preserve">
          <source>This class merges the output of multiple &lt;code&gt;Head&lt;/code&gt; objects. Specifically:</source>
          <target state="translated">이 클래스는 여러 &lt;code&gt;Head&lt;/code&gt; 의 출력을 병합합니다. 객체 합니다. 구체적으로 특별히:</target>
        </trans-unit>
        <trans-unit id="7cd980fdc04e7da43f8abb3e3be6ffdf25b7685d" translate="yes" xml:space="preserve">
          <source>This class performs a model export everytime the new model is better than any existing model.</source>
          <target state="translated">이 클래스는 새 모델이 기존 모델보다 낫을 때마다 모델 내보내기를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="391aed511e9154256ca236f23d6877cb0f9d37db" translate="yes" xml:space="preserve">
          <source>This class performs a single export at the end of training.</source>
          <target state="translated">이 클래스는 교육이 끝나면 단일 내보내기를 수행합니다.</target>
        </trans-unit>
        <trans-unit id="b83c252083ca3edbed9d1168a0ed9755da22c25f" translate="yes" xml:space="preserve">
          <source>This class performs a union given two or more existing ClusterResolvers. It merges the underlying ClusterResolvers, and returns one unified ClusterSpec when cluster_spec is called. The details of the merge function is documented in the cluster_spec function.</source>
          <target state="translated">이 클래스는 둘 이상의 기존 ClusterResolvers가 제공되는 통합을 수행합니다. 기본 ClusterResolvers를 병합하고 cluster_spec이 호출 될 때 하나의 통합 된 ClusterSpec을 반환합니다. 병합 함수의 세부 사항은 cluster_spec 함수에 문서화되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="631d6a58bb184da4fc166c1a1dbaf36a0e45d9c8" translate="yes" xml:space="preserve">
          <source>This class performs the softmax operation for you, so inputs should be e.g. linear projections of outputs by an LSTM.</source>
          <target state="translated">이 클래스는 softmax 연산을 수행하므로 입력은 LSTM에 의한 출력의 선형 투영이어야합니다.</target>
        </trans-unit>
        <trans-unit id="d2810b13f641fd9987b2ce8b38f939b3369079e3" translate="yes" xml:space="preserve">
          <source>This class processes one step within the whole time sequence input, whereas &lt;code&gt;tf.keras.layer.GRU&lt;/code&gt; processes the whole sequence.</source>
          <target state="translated">이 클래스는 전체 시간 시퀀스 입력 내에서 한 단계를 처리하는 반면 &lt;code&gt;tf.keras.layer.GRU&lt;/code&gt; 는 전체 시퀀스를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="9a1d5a35670a2cc4cfac2401e85535a1c8acffb8" translate="yes" xml:space="preserve">
          <source>This class processes one step within the whole time sequence input, whereas &lt;code&gt;tf.keras.layer.LSTM&lt;/code&gt; processes the whole sequence.</source>
          <target state="translated">이 클래스는 전체 시간 시퀀스 입력 내에서 한 단계를 처리하는 반면 &lt;code&gt;tf.keras.layer.LSTM&lt;/code&gt; 은 전체 시퀀스를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="85aecc3ec7757c0f4286579ce3ab5119031dd197" translate="yes" xml:space="preserve">
          <source>This class processes one step within the whole time sequence input, whereas &lt;code&gt;tf.keras.layer.SimpleRNN&lt;/code&gt; processes the whole sequence.</source>
          <target state="translated">이 클래스는 전체 시간 시퀀스 입력 내에서 한 단계를 처리하는 반면 &lt;code&gt;tf.keras.layer.SimpleRNN&lt;/code&gt; 은 전체 시퀀스를 처리합니다.</target>
        </trans-unit>
        <trans-unit id="c2cd1ab18438d633073fa2c3300d94950ce386b5" translate="yes" xml:space="preserve">
          <source>This class regularly exports the serving graph and checkpoints.</source>
          <target state="translated">이 클래스는 정기적으로 검색 그래프와 검사 점을 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="44829f1dbd5fa6ec4b7c405e96fb0cb7473fedd5" translate="yes" xml:space="preserve">
          <source>This class specifies the configurations for an &lt;code&gt;Estimator&lt;/code&gt; run.</source>
          <target state="translated">이 클래스는 &lt;code&gt;Estimator&lt;/code&gt; 실행 구성을 지정합니다 .</target>
        </trans-unit>
        <trans-unit id="349b70f1528f5d483fc48af054599841c5669982" translate="yes" xml:space="preserve">
          <source>This class takes in a sequence of data-points gathered at equal intervals, along with time series parameters such as stride, length of history, etc., to produce batches for training/validation.</source>
          <target state="translated">이 클래스는 보폭, 히스토리 길이 등과 같은 시계열 매개 변수와 함께 동일한 간격으로 수집 된 일련의 데이터 포인트를 사용하여 훈련 / 검증을위한 배치를 생성합니다.</target>
        </trans-unit>
        <trans-unit id="2020d8f19309c20263f69977f3eb5adfc93381e1" translate="yes" xml:space="preserve">
          <source>This class uses a &lt;a href=&quot;../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt; to manage its internal state. Every time random numbers are generated, the state of the generator will change. For example:</source>
          <target state="translated">This class uses a &lt;a href=&quot;../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; to manage its internal state. Every time random numbers are generated, the state of the generator will change. For example:</target>
        </trans-unit>
        <trans-unit id="45bad515b0c24287a7857bc49730849b980995da" translate="yes" xml:space="preserve">
          <source>This classifier ignores feature values and will learn to predict the average value of each label. For single-label problems, this will predict the probability distribution of the classes as seen in the labels. For multi-label problems, this will predict the fraction of examples that are positive for each class.</source>
          <target state="translated">이 분류기는 기능 값을 무시하고 각 레이블의 평균 값을 예측하는 방법을 배웁니다. 단일 레이블 문제의 경우 레이블에 표시된대로 클래스의 확률 분포를 예측합니다. 다중 레이블 문제의 경우 각 클래스에 긍정적 인 예제의 비율을 예측합니다.</target>
        </trans-unit>
        <trans-unit id="1203741987f9f009e5e86b580142b5f23085017c" translate="yes" xml:space="preserve">
          <source>This computes the internal data stats related to the data-dependent transformations, based on an array of sample data.</source>
          <target state="translated">샘플 데이터 배열을 기반으로 데이터 종속 변환과 관련된 내부 데이터 통계를 계산합니다.</target>
        </trans-unit>
        <trans-unit id="38619017d4eec4e645fa2f91a523c788477cd3cb" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 방송) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해</target>
        </trans-unit>
        <trans-unit id="462aa0ba39503de33a78d3a4ed1c72d0eb71fa77" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] != y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] != y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="e25b6ae62c3ffc2ef4953d25e9698856f0a3b77a" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;gt; y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="ad801aabcdd92fbf94ec233e05dfeadd68d460b3" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;gt;= y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="512ed74cbec98906ad1a4d1866d9484e4d2ad504" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;lt; y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="81434868d39629bbc35c170df36a994a92015b46" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] &amp;lt;= y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="93ee9d4d5438fdc7dae43626edce4fb33cefa73b" translate="yes" xml:space="preserve">
          <source>This condition holds if for every pair of (possibly broadcast) elements &lt;code&gt;x[i]&lt;/code&gt;, &lt;code&gt;y[i]&lt;/code&gt;, we have &lt;code&gt;x[i] == y[i]&lt;/code&gt;. If both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are empty, this is trivially satisfied.</source>
          <target state="translated">이 조건은 모든 요소 쌍 (가능한 브로드 캐스트) &lt;code&gt;x[i]&lt;/code&gt; , &lt;code&gt;y[i]&lt;/code&gt; 에 대해 &lt;code&gt;x[i] == y[i]&lt;/code&gt; 됩니다. 두 경우 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 비어있는,이 하찮게 만족된다.</target>
        </trans-unit>
        <trans-unit id="1107421e32062956898c5a66e60e49bd95c7ed45" translate="yes" xml:space="preserve">
          <source>This constraint can be applied to any &lt;code&gt;Conv2D&lt;/code&gt; layer version, including &lt;code&gt;Conv2DTranspose&lt;/code&gt; and &lt;code&gt;SeparableConv2D&lt;/code&gt;, and with either &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt; or &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; data format. The method assumes the weight tensor is of shape &lt;code&gt;(rows, cols, input_depth, output_depth)&lt;/code&gt;.</source>
          <target state="translated">이 제약은 적용 할 수있다 &lt;code&gt;Conv2D&lt;/code&gt; 을 포함한 층 버전 &lt;code&gt;Conv2DTranspose&lt;/code&gt; 및 &lt;code&gt;SeparableConv2D&lt;/code&gt; 및 하나와 &lt;code&gt;&quot;channels_last&quot;&lt;/code&gt; 또는 &lt;code&gt;&quot;channels_first&quot;&lt;/code&gt; 데이터 포맷. 이 방법은 가중치 텐서가 모양 &lt;code&gt;(rows, cols, input_depth, output_depth)&lt;/code&gt; 이라고 가정합니다 .</target>
        </trans-unit>
        <trans-unit id="e5e140df8d55549c17df75f17763f4c88b908cd9" translate="yes" xml:space="preserve">
          <source>This constructor creates both a &lt;code&gt;variable&lt;/code&gt; Op and an &lt;code&gt;assign&lt;/code&gt; Op to set the variable to its initial value.</source>
          <target state="translated">이 생성자는 &lt;code&gt;variable&lt;/code&gt; Op와 &lt;code&gt;assign&lt;/code&gt; Op를 모두 생성 하여 변수를 초기 값으로 설정합니다.</target>
        </trans-unit>
        <trans-unit id="0853b5f1d96849514913dcea4715e205fe7e9be9" translate="yes" xml:space="preserve">
          <source>This constructor is private -- please use one of the following ops to build &lt;code&gt;RaggedTensor&lt;/code&gt;s:</source>
          <target state="translated">이 생성자는 비공개입니다. &lt;code&gt;RaggedTensor&lt;/code&gt; 를 빌드하려면 다음 작업 중 하나를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="fa9706d28ea0bf76646310aace552e8f79dee4fd" translate="yes" xml:space="preserve">
          <source>This constructor only applies if the algorithm is a counter-based algorithm. See method &lt;code&gt;key&lt;/code&gt; for the meaning of &quot;key&quot; and &quot;counter&quot;.</source>
          <target state="translated">이 생성자는 알고리즘이 카운터 기반 알고리즘 인 경우에만 적용됩니다. &quot;키&quot;및 &quot;카운터&quot;의 의미는 메소드 &lt;code&gt;key&lt;/code&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="abd1f92b92080f9534139ad50b5578924ec063f6" translate="yes" xml:space="preserve">
          <source>This contains most of the synchronization implementation and also wraps the apply_gradients() from the real optimizer.</source>
          <target state="translated">여기에는 대부분의 동기화 구현이 포함되어 있으며 실제 최적화 프로그램에서 apply_gradients ()를 래핑합니다.</target>
        </trans-unit>
        <trans-unit id="dac62a0f0dbdc3c6a9231598871c80876ac21c3b" translate="yes" xml:space="preserve">
          <source>This context handler simplifies the exception handling. Use it as follows:</source>
          <target state="translated">이 컨텍스트 핸들러는 예외 처리를 단순화합니다. 다음과 같이 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="92e2326270a118c9b1678bb4952443a859f4c559" translate="yes" xml:space="preserve">
          <source>This context manager can be used to override the gradient function that will be used for ops within the scope of the context.</source>
          <target state="translated">이 컨텍스트 관리자를 사용하여 컨텍스트 범위 내에서 작업에 사용될 그라디언트 함수를 재정의 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="790e879037e30f5e5546c1be4c06bf6476dca2dd" translate="yes" xml:space="preserve">
          <source>This context manager captures all writes to a given stream inside of a &lt;code&gt;CapturedWrites&lt;/code&gt; object. When this context manager is created, it yields the &lt;code&gt;CapturedWrites&lt;/code&gt; object. The captured contents can be accessed by calling &lt;code&gt;.contents()&lt;/code&gt; on the &lt;code&gt;CapturedWrites&lt;/code&gt;.</source>
          <target state="translated">이 컨텍스트 관리자는 &lt;code&gt;CapturedWrites&lt;/code&gt; 객체 내부의 지정된 스트림에 대한 모든 쓰기를 캡처 합니다. 이 컨텍스트 관리자가 작성되면 &lt;code&gt;CapturedWrites&lt;/code&gt; 오브젝트 가 생성 됩니다. 캡처 된 컨텐츠는 &lt;code&gt;CapturedWrites&lt;/code&gt; 에서 &lt;code&gt;.contents()&lt;/code&gt; 를 호출하여 액세스 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="41c375fab79db6dca2a3052fe26a3bb1f0a48127" translate="yes" xml:space="preserve">
          <source>This context manager creates and automatically recovers a session. It optionally starts the standard services that handle checkpoints and summaries. It monitors exceptions raised from the &lt;code&gt;with&lt;/code&gt; block or from the services and stops the supervisor as needed.</source>
          <target state="translated">이 컨텍스트 관리자는 세션을 작성하고 자동으로 복구합니다. 선택적으로 검사 점 및 요약을 처리하는 표준 서비스를 시작합니다. &lt;code&gt;with&lt;/code&gt; 블록 또는 서비스에서 발생한 예외를 모니터링하고 필요에 따라 감독자를 중지합니다.</target>
        </trans-unit>
        <trans-unit id="1dfc6367da2112861ba5a19ab74136e2bfa59bd7" translate="yes" xml:space="preserve">
          <source>This context manager pushes a name scope, which will make the name of all operations added within it have a prefix.</source>
          <target state="translated">이 컨텍스트 관리자는 이름 범위를 푸시하여 이름 범위에 추가 된 모든 오퍼레이션의 이름에 접 두부를 붙입니다.</target>
        </trans-unit>
        <trans-unit id="cadf2e29564a69f6d9e78e18436e128fc8603a09" translate="yes" xml:space="preserve">
          <source>This context manager validates that the (optional) &lt;code&gt;values&lt;/code&gt; are from the same graph, ensures that graph is the default graph, and pushes a name scope and a variable scope.</source>
          <target state="translated">이 컨텍스트 관리자는 (선택적) &lt;code&gt;values&lt;/code&gt; 이 동일한 그래프에 있는지 확인하고 그래프가 기본 그래프인지 확인하고 이름 범위와 변수 범위를 푸시합니다.</target>
        </trans-unit>
        <trans-unit id="9fe8f8972b4d68b13082f0d96ff8de4b430acf3b" translate="yes" xml:space="preserve">
          <source>This context manager validates that the given &lt;code&gt;values&lt;/code&gt; are from the same graph, makes that graph the default graph, and pushes a name scope in that graph (see &lt;a href=&quot;../../../../graph#name_scope&quot;&gt;&lt;code&gt;tf.Graph.name_scope&lt;/code&gt;&lt;/a&gt; for more details on that).</source>
          <target state="translated">이 컨텍스트 관리자는 제공된 &lt;code&gt;values&lt;/code&gt; 이 동일한 그래프에 있는지 확인하고 해당 그래프를 기본 그래프로 만들고 해당 그래프에서 이름 범위를 푸시합니다 ( 자세한 내용 은 &lt;a href=&quot;../../../../graph#name_scope&quot;&gt; &lt;code&gt;tf.Graph.name_scope&lt;/code&gt; &lt;/a&gt; 참조 ).</target>
        </trans-unit>
        <trans-unit id="8bc9405ecd91e0aa7f29a32f0b001ccc17dfce1e" translate="yes" xml:space="preserve">
          <source>This convenience method requires a session where the graph containing this variable has been launched. If no session is passed, the default session is used. See &lt;a href=&quot;compat/v1/session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; for more information on launching a graph and on sessions.</source>
          <target state="translated">이 편리한 방법을 사용하려면이 변수를 포함하는 그래프가 시작된 세션이 필요합니다. 세션이 전달되지 않으면 기본 세션이 사용됩니다. 그래프 시작 및 세션에 대한 자세한 내용 은 &lt;a href=&quot;compat/v1/session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="69597b8afaecf26bf780e17dbe96db99a176f9db" translate="yes" xml:space="preserve">
          <source>This convenience method requires a session where the graph containing this variable has been launched. If no session is passed, the default session is used. See &lt;a href=&quot;session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; for more information on launching a graph and on sessions.</source>
          <target state="translated">이 편리한 방법을 사용하려면이 변수를 포함하는 그래프가 시작된 세션이 필요합니다. 세션이 전달되지 않으면 기본 세션이 사용됩니다. 그래프 시작 및 세션에 대한 자세한 내용 은 &lt;a href=&quot;session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; 을 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="049bd1098346a19ff3fab486ff6a7b47c3fd7819" translate="yes" xml:space="preserve">
          <source>This creates a &lt;code&gt;LinearOperator&lt;/code&gt; of the form &lt;code&gt;A = L + U D V^H&lt;/code&gt;, with &lt;code&gt;L&lt;/code&gt; a &lt;code&gt;LinearOperator&lt;/code&gt;, &lt;code&gt;U, V&lt;/code&gt; both [batch] matrices, and &lt;code&gt;D&lt;/code&gt; a [batch] diagonal matrix.</source>
          <target state="translated">이렇게하면 &lt;code&gt;A = L + U D V^H&lt;/code&gt; 형식 의 &lt;code&gt;LinearOperator&lt;/code&gt; 가 생성되고 , &lt;code&gt;L&lt;/code&gt; 은 &lt;code&gt;LinearOperator&lt;/code&gt; , &lt;code&gt;U, V&lt;/code&gt; 는 [일괄 처리] 행렬이고 &lt;code&gt;D&lt;/code&gt; 는 [일괄 처리] 대각선 행렬입니다.</target>
        </trans-unit>
        <trans-unit id="20e733fb47526c81e38b7224224a075d45127bb0" translate="yes" xml:space="preserve">
          <source>This creates a named directory on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary directories for test purposes, as well as makes it easier to setup directories and verify their contents.</source>
          <target state="translated">이렇게하면이 테스트와 격리 된 디스크에 명명 된 디렉토리가 생성되고 테스트에 의해 올바르게 정리됩니다. 이를 통해 테스트 목적으로 임시 디렉토리를 작성하는 데 따르는 함정을 피할 수있을뿐만 아니라 디렉토리를 쉽게 설정하고 내용을 확인할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="63a4f566bb13c25047e12750280d68497191b0d8" translate="yes" xml:space="preserve">
          <source>This creates a named directory on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary directories for test purposes, as well as makes it easier to setup directories and verify their contents. For example:</source>
          <target state="translated">This creates a named directory on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary directories for test purposes, as well as makes it easier to setup directories and verify their contents. For example:</target>
        </trans-unit>
        <trans-unit id="75714df8d9550841d3043fbd62dad500169275e6" translate="yes" xml:space="preserve">
          <source>This creates a named file on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary files for test purposes, as well as makes it easier to setup files, their data, read them back, and inspect them when a test fails.</source>
          <target state="translated">이렇게하면이 테스트와 격리 된 명명 된 파일이 디스크에 만들어지고 테스트에 의해 올바르게 정리됩니다. 이를 통해 테스트 목적으로 임시 파일을 작성하는 데 따르는 함정을 피할 수있을뿐만 아니라 파일, 데이터를 설정하고 다시 읽고 테스트에 실패 할 때 파일을 쉽게 검사 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2f4f8ffa306c5f0499e24ea63e1e0e690360c7a3" translate="yes" xml:space="preserve">
          <source>This creates a named file on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary files for test purposes, as well as makes it easier to setup files, their data, read them back, and inspect them when a test fails. For example:</source>
          <target state="translated">This creates a named file on disk that is isolated to this test, and will be properly cleaned up by the test. This avoids several pitfalls of creating temporary files for test purposes, as well as makes it easier to setup files, their data, read them back, and inspect them when a test fails. For example:</target>
        </trans-unit>
        <trans-unit id="42646afd71d42ede988399add1a74a5f6b4c93c2" translate="yes" xml:space="preserve">
          <source>This creates a tuple of tensors with the same values as the &lt;code&gt;tensors&lt;/code&gt; argument, except that the value of each tensor is only returned after the values of all tensors have been computed.</source>
          <target state="translated">이렇게하면 모든 텐서의 값이 계산 된 후에 만 ​​각 텐서의 값이 반환된다는 점을 제외하고 &lt;code&gt;tensors&lt;/code&gt; 인수 와 동일한 값으로 텐서의 튜플이 생성 됩니다.</target>
        </trans-unit>
        <trans-unit id="89651a110f241aba282c0d3c4d5816a82b95a5ce" translate="yes" xml:space="preserve">
          <source>This dataset attempts to determine whether a valid snapshot exists at the &lt;code&gt;snapshot_path&lt;/code&gt;, and reads from the snapshot in lieu of using &lt;code&gt;input_dataset&lt;/code&gt;. If not, it will run the preprocessing pipeline as usual, and write out a snapshot of the data processed for future use.</source>
          <target state="translated">This dataset attempts to determine whether a valid snapshot exists at the &lt;code&gt;snapshot_path&lt;/code&gt; , and reads from the snapshot in lieu of using &lt;code&gt;input_dataset&lt;/code&gt; . If not, it will run the preprocessing pipeline as usual, and write out a snapshot of the data processed for future use.</target>
        </trans-unit>
        <trans-unit id="f9dc1c4d1a56233dc4a8e886da12f3f0a495623a" translate="yes" xml:space="preserve">
          <source>This dataset fills a buffer with &lt;code&gt;buffer_size&lt;/code&gt; elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.</source>
          <target state="translated">이 데이터 세트는 &lt;code&gt;buffer_size&lt;/code&gt; 요소 로 버퍼를 채우고이 버퍼에서 요소를 무작위로 샘플링하여 선택한 요소를 새 요소로 바꿉니다. 완벽한 셔플 링을 위해서는 데이터 세트의 전체 크기보다 크거나 같은 버퍼 크기가 필요합니다.</target>
        </trans-unit>
        <trans-unit id="28c299276126ace248fef26b3267fca38b82ca7a" translate="yes" xml:space="preserve">
          <source>This dataset has been superseded by &lt;code&gt;ParallelInterleaveDatasetV2&lt;/code&gt;. New code should use &lt;code&gt;ParallelInterleaveDatasetV2&lt;/code&gt;.</source>
          <target state="translated">This dataset has been superseded by &lt;code&gt;ParallelInterleaveDatasetV2&lt;/code&gt; . New code should use &lt;code&gt;ParallelInterleaveDatasetV2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="97fff19a84ee410a08999fab8be4d199f9066fdc" translate="yes" xml:space="preserve">
          <source>This dataset operator is very useful when running distributed training, as it allows each worker to read a unique subset.</source>
          <target state="translated">이 데이터 세트 연산자는 각 작업자가 고유 한 하위 집합을 읽을 수 있도록 분산 교육을 실행할 때 매우 유용합니다.</target>
        </trans-unit>
        <trans-unit id="0601b18d7846c9e12aa36064d4b2b93f04fe9903" translate="yes" xml:space="preserve">
          <source>This dataset will throw a NotFound error if we cannot shard the dataset automatically.</source>
          <target state="translated">This dataset will throw a NotFound error if we cannot shard the dataset automatically.</target>
        </trans-unit>
        <trans-unit id="38966f21ae4fd315566bc2e9e41902f2d11ad1fd" translate="yes" xml:space="preserve">
          <source>This decorator allows fine grained control over the gradients of a sequence for operations. This may be useful for multiple reasons, including providing a more efficient or numerically stable gradient for a sequence of operations.</source>
          <target state="translated">이 데코레이터를 사용하면 작업 시퀀스의 그래디언트를 세밀하게 제어 할 수 있습니다. 이는 일련의 연산에 대해보다 효율적이거나 수치 적으로 안정적인 구배를 제공하는 것을 포함하여 여러 가지 이유로 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="507c4c48f689d10862643a9c65b8ad1497b61251" translate="yes" xml:space="preserve">
          <source>This decorator injects the decorated class or function into the Keras custom object dictionary, so that it can be serialized and deserialized without needing an entry in the user-provided custom object dict. It also injects a function that Keras will call to get the object's serializable string key.</source>
          <target state="translated">이 데코레이터는 데코 레이팅 된 클래스 나 함수를 Keras 커스텀 객체 딕셔너리에 삽입하여 사용자가 제공 한 커스텀 객체 dict에 항목을 입력하지 않고도 직렬화 및 역 직렬화 할 수 있습니다. 또한 Keras가 객체의 직렬화 가능 문자열 키를 얻기 위해 호출하는 함수를 주입합니다.</target>
        </trans-unit>
        <trans-unit id="99ba7a22516d6648f4353818a77d3239c06fe661" translate="yes" xml:space="preserve">
          <source>This decorator is only used when defining a new op type. For an op with &lt;code&gt;m&lt;/code&gt; inputs and &lt;code&gt;n&lt;/code&gt; outputs, the gradient function is a function that takes the original &lt;code&gt;Operation&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; objects (representing the gradients with respect to each output of the op), and returns &lt;code&gt;m&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; objects (representing the partial gradients with respect to each input of the op).</source>
          <target state="translated">이 데코레이터는 새로운 op 유형을 정의 할 때만 사용됩니다. &lt;code&gt;m&lt;/code&gt; 개의 입력과 &lt;code&gt;n&lt;/code&gt; 개의 출력을 갖는 op의 경우, 그래디언트 기능은 원래의 &lt;code&gt;Operation&lt;/code&gt; 및 &lt;code&gt;n&lt;/code&gt; 개의 &lt;code&gt;Tensor&lt;/code&gt; 객체 (op의 각 출력에 대한 그래디언트를 나타냄)를 가져오고 &lt;code&gt;m&lt;/code&gt; 개의 &lt;code&gt;Tensor&lt;/code&gt; 객체 ( op의 각 입력에 대해).</target>
        </trans-unit>
        <trans-unit id="f69390eec43b9170084ec67f23f7df44213faadc" translate="yes" xml:space="preserve">
          <source>This defines the skeleton for all implementations of ClusterResolvers. ClusterResolvers are a way for TensorFlow to communicate with various cluster management systems (e.g. GCE, AWS, etc...) and gives TensorFlow necessary information to set up distributed training.</source>
          <target state="translated">This defines the skeleton for all implementations of ClusterResolvers. ClusterResolvers are a way for TensorFlow to communicate with various cluster management systems (e.g. GCE, AWS, etc...) and gives TensorFlow necessary information to set up distributed training.</target>
        </trans-unit>
        <trans-unit id="31c4ff795b26f67c26110ef2a390028f451d7769" translate="yes" xml:space="preserve">
          <source>This defines the skeleton for all implementations of ClusterResolvers. ClusterResolvers are a way for TensorFlow to communicate with various cluster management systems (e.g. GCE, AWS, etc...).</source>
          <target state="translated">이는 ClusterResolvers의 모든 구현에 대한 골격을 정의합니다. ClusterResolvers는 TensorFlow가 다양한 클러스터 관리 시스템 (예 : GCE, AWS 등)과 통신 할 수있는 방법입니다.</target>
        </trans-unit>
        <trans-unit id="0df31e40439c17db3321616e25b535cdb0316252" translate="yes" xml:space="preserve">
          <source>This definition of cell differs from the definition used in the literature. In the literature, 'cell' refers to an object with a single scalar output. This definition refers to a horizontal array of such units.</source>
          <target state="translated">이러한 세포 정의는 문헌에 사용 된 정의와 다릅니다. 문헌에서 '셀'은 단일 스칼라 출력을 가진 객체를 나타냅니다. 이 정의는 이러한 단위의 수평 배열을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="0725a72c209eb53df1440f5a39a25dbf2ab21a14" translate="yes" xml:space="preserve">
          <source>This distribution has parameters: degree of freedom &lt;code&gt;df&lt;/code&gt;, location &lt;code&gt;loc&lt;/code&gt;, and &lt;code&gt;scale&lt;/code&gt;.</source>
          <target state="translated">이 분포에는 자유도 &lt;code&gt;df&lt;/code&gt; , 위치 &lt;code&gt;loc&lt;/code&gt; 및 &lt;code&gt;scale&lt;/code&gt; 매개 변수가 있습니다.</target>
        </trans-unit>
        <trans-unit id="11a222f9738197dadd6eb7c453e22ae24d0f3567" translate="yes" xml:space="preserve">
          <source>This does not close the session.</source>
          <target state="translated">세션이 닫히지 않습니다.</target>
        </trans-unit>
        <trans-unit id="e3bddf2a09aebf2b7d2bb27cde671e8328a7dc27" translate="yes" xml:space="preserve">
          <source>This does not undo the effects of loss scaling. Any optimizers wrapped with a LossScaleOptimizer will continue to do loss scaling, although this loss scaling will no longer be useful if the optimizer is used in new Sessions, as the graph rewrite no longer converts the graph to use float16.</source>
          <target state="translated">이것은 손실 스케일링의 영향을 취소하지 않습니다. 그래프 다시 쓰기가 더 이상 float16을 사용하도록 그래프를 변환하지 않기 때문에 LossScaleOptimizer로 랩핑 된 옵티마이 저는 계속해서 손실 스케일링을 수행하지만 옵티마이 저가 새 세션에서 사용되는 경우이 손실 스케일링은 더 이상 유용하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="02c54112c729e547b6e3e03e55cab5ced9766b9c" translate="yes" xml:space="preserve">
          <source>This does not undo the effects of loss scaling. Any optimizers wrapped with a LossScaleOptimizer will continue to do loss scaling, although this loss scaling will no longer be useful, as the graph rewrite no longer converts tf.functions to use float16.</source>
          <target state="translated">이것은 손실 스케일링의 영향을 취소하지 않습니다. 그래프 재 작성이 더 이상 tf.functions를 float16을 사용하도록 변환하지 않기 때문에 LossScaleOptimizer로 랩핑 된 옵티마이 저는 손실 스케일링을 계속 수행하지만이 손실 스케일링은 더 이상 유용하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="3bfa5300d7e625917e03fb074107ed12abbdcbbe" translate="yes" xml:space="preserve">
          <source>This eliminates the overhead of &lt;code&gt;k-1&lt;/code&gt; calls to &lt;code&gt;space_to_batch_nd&lt;/code&gt; and &lt;code&gt;batch_to_space_nd&lt;/code&gt;.</source>
          <target state="translated">이것은 &lt;code&gt;space_to_batch_nd&lt;/code&gt; 및 &lt;code&gt;batch_to_space_nd&lt;/code&gt; 에 대한 &lt;code&gt;k-1&lt;/code&gt; 호출 의 오버 헤드를 제거합니다 .</target>
        </trans-unit>
        <trans-unit id="4c1542adb4efbb08745cf8660782eb015be7e9a8" translate="yes" xml:space="preserve">
          <source>This enables the new behavior.</source>
          <target state="translated">이것은 새로운 행동을 가능하게합니다.</target>
        </trans-unit>
        <trans-unit id="e158c4e53eb8ef556e4d562ffa77e16f6fc696bb" translate="yes" xml:space="preserve">
          <source>This enables the user to close and release the resource in the middle of a step/run.</source>
          <target state="translated">This enables the user to close and release the resource in the middle of a step/run.</target>
        </trans-unit>
        <trans-unit id="b70309885ebd2feded30214b2bff057bfcef522b" translate="yes" xml:space="preserve">
          <source>This enables variables to be read as bfloat16 type when using get_variable.</source>
          <target state="translated">이를 통해 get_variable을 사용할 때 변수를 bfloat16 유형으로 읽을 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9b4ec5604b14a4a73674990062864327b53e189b" translate="yes" xml:space="preserve">
          <source>This enumeration represents optional conversion options.</source>
          <target state="translated">이 열거는 선택적 변환 옵션을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="26d8315a3de6d7adfdf3bbd23a3ef83e0e870212" translate="yes" xml:space="preserve">
          <source>This estimator ignores feature values and will learn to predict the average value of each label. E.g. for single-label classification problems, this will predict the probability distribution of the classes as seen in the labels. For multi-label classification problems, it will predict the ratio of examples that contain each class.</source>
          <target state="translated">이 추정기는 피처 값을 무시하고 각 레이블의 평균값을 예측하는 방법을 배웁니다. 예를 들어 단일 레이블 분류 문제의 경우 레이블에 표시된대로 클래스의 확률 분포를 예측합니다. 다중 레이블 분류 문제의 경우 각 클래스를 포함하는 예제의 비율을 예측합니다.</target>
        </trans-unit>
        <trans-unit id="c0a3c93652b7acdf673bb2d9770fb27696ed0299" translate="yes" xml:space="preserve">
          <source>This example creates a lookup layer and generates the vocabulary by analyzing the dataset.</source>
          <target state="translated">This example creates a lookup layer and generates the vocabulary by analyzing the dataset.</target>
        </trans-unit>
        <trans-unit id="a9de20f542fbd733883e56dc873754dfb758c273" translate="yes" xml:space="preserve">
          <source>This example creates a lookup layer with a pre-existing vocabulary.</source>
          <target state="translated">This example creates a lookup layer with a pre-existing vocabulary.</target>
        </trans-unit>
        <trans-unit id="c0b0f0177841bd64344b603ca5701c7a1c4bfeec" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to map indices to strings using this layer. (You can also use adapt() with inverse=True, but for simplicity we'll pass the vocab in this example.)</source>
          <target state="translated">This example demonstrates how to map indices to strings using this layer. (You can also use adapt() with inverse=True, but for simplicity we'll pass the vocab in this example.)</target>
        </trans-unit>
        <trans-unit id="3a755e66edb0249a30f62c3fbfa9da1107d08395" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to map indices to values using this layer. (You can also use adapt() with inverse=True, but for simplicity we'll pass the vocab in this example.)</source>
          <target state="translated">This example demonstrates how to map indices to values using this layer. (You can also use adapt() with inverse=True, but for simplicity we'll pass the vocab in this example.)</target>
        </trans-unit>
        <trans-unit id="494bbe4febd153531076a3e5cddcbab4e936bc24" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use a lookup layer with multiple OOV tokens. When a layer is created with more than one OOV token, any OOV values are hashed into the number of OOV buckets, distributing OOV values in a deterministic fashion across the set.</source>
          <target state="translated">This example demonstrates how to use a lookup layer with multiple OOV tokens. When a layer is created with more than one OOV token, any OOV values are hashed into the number of OOV buckets, distributing OOV values in a deterministic fashion across the set.</target>
        </trans-unit>
        <trans-unit id="69a4365d2fc53f53ca98893f19670abd4d1d2032" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use the vocabulary of a standard lookup layer to create an inverse lookup layer.</source>
          <target state="translated">This example demonstrates how to use the vocabulary of a standard lookup layer to create an inverse lookup layer.</target>
        </trans-unit>
        <trans-unit id="a68786f5a17b7958b628ee0e8691b24f56ab38dc" translate="yes" xml:space="preserve">
          <source>This example gives binary output instead of counting the occurrence.</source>
          <target state="translated">This example gives binary output instead of counting the occurrence.</target>
        </trans-unit>
        <trans-unit id="3f03708fe58a6d112475001cb64ef56af4e257ac" translate="yes" xml:space="preserve">
          <source>This example instantiates a TextVectorization layer that lowercases text, splits on whitespace, strips punctuation, and outputs integer vocab indices.</source>
          <target state="translated">이 예제에서는 텍스트를 소문자로 바꾸고 공백으로 나누고 문장 부호를 제거하고 정수 어휘 색인을 출력하는 TextVectorization 레이어를 인스턴스화합니다.</target>
        </trans-unit>
        <trans-unit id="ee52f3666629477330cedb91ea1ff2368d33cc78" translate="yes" xml:space="preserve">
          <source>This example shows how to instantiate a layer that applies the same dense operation to every element in a sequence, but uses the ellipsis notation instead of specifying the batch and sequence dimensions.</source>
          <target state="translated">This example shows how to instantiate a layer that applies the same dense operation to every element in a sequence, but uses the ellipsis notation instead of specifying the batch and sequence dimensions.</target>
        </trans-unit>
        <trans-unit id="0d7af74c46a4fae38ce9ff64ebe601e504aada00" translate="yes" xml:space="preserve">
          <source>This example shows how to instantiate a layer that applies the same dense operation to every element in a sequence. Here, the 'output_shape' has two values (since there are two non-batch dimensions in the output); the first dimension in the output_shape is &lt;code&gt;None&lt;/code&gt;, because the sequence dimension &lt;code&gt;b&lt;/code&gt; has an unknown shape.</source>
          <target state="translated">This example shows how to instantiate a layer that applies the same dense operation to every element in a sequence. Here, the 'output_shape' has two values (since there are two non-batch dimensions in the output); the first dimension in the output_shape is &lt;code&gt;None&lt;/code&gt; , because the sequence dimension &lt;code&gt;b&lt;/code&gt; has an unknown shape.</target>
        </trans-unit>
        <trans-unit id="a7e9f20f12802c04c896151951f7fd5800246d6c" translate="yes" xml:space="preserve">
          <source>This example shows how to instantiate a standard Keras dense layer using einsum operations. This example is equivalent to &lt;a href=&quot;../dense&quot;&gt;&lt;code&gt;tf.keras.layers.Dense(64, use_bias=True)&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">This example shows how to instantiate a standard Keras dense layer using einsum operations. This example is equivalent to &lt;a href=&quot;../dense&quot;&gt; &lt;code&gt;tf.keras.layers.Dense(64, use_bias=True)&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="bf32128894beae4e1d5986c66f68269f1ae0857f" translate="yes" xml:space="preserve">
          <source>This example takes a 2 dimensional input and returns a &lt;code&gt;Tensor&lt;/code&gt; with bincounting on each sample.</source>
          <target state="translated">This example takes a 2 dimensional input and returns a &lt;code&gt;Tensor&lt;/code&gt; with bincounting on each sample.</target>
        </trans-unit>
        <trans-unit id="8f9c3d77008f03aede1949e1e8b86cf490084ce8" translate="yes" xml:space="preserve">
          <source>This example takes an input (which could be a Tensor, RaggedTensor, or SparseTensor) and returns a SparseTensor where (i,j) is 1 if the value j appears in batch i at least once and is 0 otherwise. Note that, even though some values (like 20 in batch 1 and 11 in batch 2) appear more than once, the 'values' tensor is all 1s.</source>
          <target state="translated">This example takes an input (which could be a Tensor, RaggedTensor, or SparseTensor) and returns a SparseTensor where (i,j) is 1 if the value j appears in batch i at least once and is 0 otherwise. Note that, even though some values (like 20 in batch 1 and 11 in batch 2) appear more than once, the 'values' tensor is all 1s.</target>
        </trans-unit>
        <trans-unit id="d3981b34919fca04a3be3649adee342abfe3505a" translate="yes" xml:space="preserve">
          <source>This example takes an input (which could be a Tensor, RaggedTensor, or SparseTensor) and returns a SparseTensor where the value of (i,j) is the number of times value j appears in batch i.</source>
          <target state="translated">This example takes an input (which could be a Tensor, RaggedTensor, or SparseTensor) and returns a SparseTensor where the value of (i,j) is the number of times value j appears in batch i.</target>
        </trans-unit>
        <trans-unit id="8dd04c77a84f7fb7b79c65a0782e87dc8901b29b" translate="yes" xml:space="preserve">
          <source>This example takes an input (which could be a Tensor, RaggedTensor, or SparseTensor) and returns a SparseTensor where the value of (i,j) is the number of times value j appears in batch i. However, all values of j above 'maxlength' are ignored. The dense_shape of the output sparse tensor is set to 'minlength'. Note that, while the input is identical to the example above, the value '10001' in batch item 2 is dropped, and the dense shape is [2, 500] instead of [2,10002] or [2, 102].</source>
          <target state="translated">This example takes an input (which could be a Tensor, RaggedTensor, or SparseTensor) and returns a SparseTensor where the value of (i,j) is the number of times value j appears in batch i. However, all values of j above 'maxlength' are ignored. The dense_shape of the output sparse tensor is set to 'minlength'. Note that, while the input is identical to the example above, the value '10001' in batch item 2 is dropped, and the dense shape is [2, 500] instead of [2,10002] or [2, 102].</target>
        </trans-unit>
        <trans-unit id="9ad6c7816616b3241d748e89b2cfcff037903efa" translate="yes" xml:space="preserve">
          <source>This example takes two inputs - a values tensor and a weights tensor. These tensors must be identically shaped, and have the same row splits or indices in the case of RaggedTensors or SparseTensors. When performing a weighted count, the op will output a SparseTensor where the value of (i, j) is the sum of the values in the weight tensor's batch i in the locations where the values tensor has the value j. In this case, the output dtype is the same as the dtype of the weights tensor.</source>
          <target state="translated">This example takes two inputs - a values tensor and a weights tensor. These tensors must be identically shaped, and have the same row splits or indices in the case of RaggedTensors or SparseTensors. When performing a weighted count, the op will output a SparseTensor where the value of (i, j) is the sum of the values in the weight tensor's batch i in the locations where the values tensor has the value j. In this case, the output dtype is the same as the dtype of the weights tensor.</target>
        </trans-unit>
        <trans-unit id="3b8a0001b21c834c94ffc58110b29147780ed1bc" translate="yes" xml:space="preserve">
          <source>This exception is most commonly raised when running an operation that reads a &lt;a href=&quot;../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt; before it has been initialized.</source>
          <target state="translated">이 예외는 초기화되기 전에 &lt;a href=&quot;../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; 을 읽는 작업을 실행할 때 가장 일반적으로 발생 합니다.</target>
        </trans-unit>
        <trans-unit id="5c5a8c57c6d5ff0bef6c24b2e2bd3f673907515f" translate="yes" xml:space="preserve">
          <source>This exception is not currently used.</source>
          <target state="translated">이 예외는 현재 사용되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="f99d6b607eb42d98eb52dda612321114e3e91d9d" translate="yes" xml:space="preserve">
          <source>This exception is raised in &quot;end-of-file&quot; conditions, such as when a &lt;code&gt;tf.QueueBase.dequeue&lt;/code&gt; operation is blocked on an empty queue, and a &lt;code&gt;tf.QueueBase.close&lt;/code&gt; operation executes.</source>
          <target state="translated">이 예외 이러한 경우와 같이 &quot;파일 끝&quot;상태에서 발생 &lt;code&gt;tf.QueueBase.dequeue&lt;/code&gt; 의 동작이 비어있는 큐에서 차단되고, &lt;code&gt;tf.QueueBase.close&lt;/code&gt; 의 동작 실행한다.</target>
        </trans-unit>
        <trans-unit id="78d71c0636a2aa1fd087c8298d2d2e031276f9b2" translate="yes" xml:space="preserve">
          <source>This exception is raised when some invariant expected by the runtime has been broken. Catching this exception is not recommended.</source>
          <target state="translated">이 예외는 런타임에 예상되는 일부 불변이 깨졌을 때 발생합니다. 이 예외를 잡는 것은 권장되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="7057b737e9dfe1ba0218e510ec51533edf1eab95" translate="yes" xml:space="preserve">
          <source>This exists primarily to support the definition of type-specific summary ops like scalar() and image(), and is not intended for direct use unless defining a new type-specific summary op.</source>
          <target state="translated">이는 주로 scalar () 및 image ()와 같은 유형별 요약 연산의 정의를 지원하기 위해 존재하며 새로운 유형별 요약 연산을 정의하지 않으면 직접 사용하기위한 것이 아닙니다.</target>
        </trans-unit>
        <trans-unit id="42562f80c79b3f19581dfb21136c32f3ec5adea4" translate="yes" xml:space="preserve">
          <source>This facilitates a cleaner api around global state. Instead of</source>
          <target state="translated">This facilitates a cleaner api around global state. Instead of</target>
        </trans-unit>
        <trans-unit id="b7cea24b85385b2c626baad7c000ac087d0ac17d" translate="yes" xml:space="preserve">
          <source>This file includes functions and constants from core (model_utils) and export.py</source>
          <target state="translated">이 파일에는 코어 (model_utils) 및 export.py의 함수 및 상수가 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="1ed5997b223ee14f22d4d6301133fe48a3becd70" translate="yes" xml:space="preserve">
          <source>This flag will have a value of None, True or False. None is possible if default=None and the user does not specify the flag on the command line.</source>
          <target state="translated">이 플래그의 값은 None, True 또는 False입니다. default = None이고 사용자가 명령 행에 플래그를 지정하지 않으면 사용할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="edc3e42fb098d2f82cf52f313f0a2bbc39d59acf" translate="yes" xml:space="preserve">
          <source>This foldl operator repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from first to last. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt; on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn, and the second is the value at the current position of &lt;code&gt;elems&lt;/code&gt;. If &lt;code&gt;initializer&lt;/code&gt; is None, &lt;code&gt;elems&lt;/code&gt; must contain at least one element, and its first element is used as the initializer.</source>
          <target state="translated">이 폴더 연산자는 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 처음부터 끝까지 일련의 요소에 반복적으로 적용합니다 . 이 요소에서 압축 해제 텐서 이루어지는 &lt;code&gt;elems&lt;/code&gt; : 호출 FN 인수로 두 텐서 소요 치수에 0. 첫 번째 인수는 fn의 이전 호출에서 계산 된 누적 값이고 두 번째 인수는 &lt;code&gt;elems&lt;/code&gt; 의 현재 위치에있는 값 입니다. 경우 &lt;code&gt;initializer&lt;/code&gt; 없음입니다, &lt;code&gt;elems&lt;/code&gt; 는 적어도 하나 개의 요소를 포함해야하고, 첫 번째 요소는 초기화로 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="5c9efc4e60690682d054976cd526187b0ec74f90" translate="yes" xml:space="preserve">
          <source>This foldr operator repeatedly applies the callable &lt;code&gt;fn&lt;/code&gt; to a sequence of elements from last to first. The elements are made of the tensors unpacked from &lt;code&gt;elems&lt;/code&gt;. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn, and the second is the value at the current position of &lt;code&gt;elems&lt;/code&gt;. If &lt;code&gt;initializer&lt;/code&gt; is None, &lt;code&gt;elems&lt;/code&gt; must contain at least one element, and its first element is used as the initializer.</source>
          <target state="translated">이 폴더 연산자는 호출 가능한 &lt;code&gt;fn&lt;/code&gt; 을 마지막부터 처음까지 일련의 요소에 반복적으로 적용합니다 . 요소는 &lt;code&gt;elems&lt;/code&gt; 에서 압축이 풀린 텐서로 만들어집니다 . 호출 가능한 fn은 두 개의 텐서를 인수로 사용합니다. 첫 번째 인수는 fn의 이전 호출에서 계산 된 누적 값이고 두 번째 인수는 &lt;code&gt;elems&lt;/code&gt; 의 현재 위치에있는 값 입니다. 경우 &lt;code&gt;initializer&lt;/code&gt; 없음입니다, &lt;code&gt;elems&lt;/code&gt; 는 적어도 하나 개의 요소를 포함해야하고, 첫 번째 요소는 초기화로 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="e47bc5be6551c40b285b99814572b5e2b249a8b5" translate="yes" xml:space="preserve">
          <source>This function adds operations to the current session. To compute the error using a particular device, such as a GPU, use the standard methods for setting a device (e.g. using with sess.graph.device() or setting a device function in the session constructor).</source>
          <target state="translated">이 기능은 현재 세션에 작업을 추가합니다. GPU와 같은 특정 장치를 사용하여 오류를 계산하려면 장치를 설정하는 표준 방법 (예 : sess.graph.device () 사용 또는 세션 생성자에서 장치 기능 설정)을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="b1c988623a891fbccad5b0fbb3db51dcb83f9a90" translate="yes" xml:space="preserve">
          <source>This function adds the following to the current &lt;code&gt;Graph&lt;/code&gt;:</source>
          <target state="translated">이 함수는 현재 &lt;code&gt;Graph&lt;/code&gt; 다음을 추가합니다 .</target>
        </trans-unit>
        <trans-unit id="7391056d9f36003196c437fbb04f6186eed40dde" translate="yes" xml:space="preserve">
          <source>This function allows expressing computations in a TensorFlow graph as Python functions. In particular, it wraps a Python function &lt;code&gt;func&lt;/code&gt; in a once-differentiable TensorFlow operation that executes it with eager execution enabled. As a consequence, &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; makes it possible to express control flow using Python constructs (&lt;code&gt;if&lt;/code&gt;, &lt;code&gt;while&lt;/code&gt;, &lt;code&gt;for&lt;/code&gt;, etc.), instead of TensorFlow control flow constructs (&lt;a href=&quot;cond&quot;&gt;&lt;code&gt;tf.cond&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;while_loop&quot;&gt;&lt;code&gt;tf.while_loop&lt;/code&gt;&lt;/a&gt;). For example, you might use &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; to implement the log huber function:</source>
          <target state="translated">이 함수를 사용하면 TensorFlow 그래프에서 계산을 파이썬 함수로 표현할 수 있습니다. 특히, 파이썬 함수 &lt;code&gt;func&lt;/code&gt; 을 한 번만 구분할 수있는 TensorFlow 작업으로 래핑하여 실행을 열망으로 실행합니다. 결과적으로 &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; 을&lt;/a&gt; 사용하면 TensorFlow 제어 흐름 구문 ( &lt;a href=&quot;cond&quot;&gt; &lt;code&gt;tf.cond&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;while_loop&quot;&gt; &lt;code&gt;tf.while_loop&lt;/code&gt; &lt;/a&gt; ) 대신 Python 구문 ( &lt;code&gt;if&lt;/code&gt; , &lt;code&gt;while&lt;/code&gt; , &lt;code&gt;for&lt;/code&gt; 등)을 사용하여 제어 흐름을 표현할 수 있습니다 . 예를 들어, &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; &lt;/a&gt; 을 사용 하여 로그 허브 기능을 구현할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="fa49b9c5fb3cc27a08b15ff4c8fbc286bffc2bb3" translate="yes" xml:space="preserve">
          <source>This function allows replacing a function wrapped by &lt;code&gt;decorator_func&lt;/code&gt;, assuming the decorator that wraps the function is written as described below.</source>
          <target state="translated">이 함수는 함수를 랩핑하는 &lt;code&gt;decorator_func&lt;/code&gt; 가 아래와 같이 작성되었다고 가정하고 decorator_func에 의해 랩핑 된 함수를 대체 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="f1af1fe4443bcb9edf1df9ce5ca5cc1b073069a3" translate="yes" xml:space="preserve">
          <source>This function also returns a &lt;code&gt;should_apply_gradients&lt;/code&gt; bool. If False, gradients should not be applied to the variables that step, as nonfinite gradients were found, and the loss scale has been be updated to reduce the chance of finding nonfinite gradients in the next step. Some loss scale classes will always return True, as they cannot adjust themselves in response to nonfinite gradients.</source>
          <target state="translated">이 함수는 &lt;code&gt;should_apply_gradients&lt;/code&gt; bool 도 반환합니다 . False 인 경우 비정규 그라디언트가 발견되었으므로 그 단계에 변수에 그라디언트를 적용해서는 안되며 다음 단계에서 비정규 그라디언트를 찾을 가능성을 줄이기 위해 손실 스케일이 업데이트되었습니다. 일부 손실 스케일 클래스는 무한 그라데이션에 응답하여 스스로 조정할 수 없기 때문에 항상 True를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="a970dd1ee86d1ed9e7a0f4a5fcb3e14f9903fdf2" translate="yes" xml:space="preserve">
          <source>This function assumes that &lt;code&gt;img1&lt;/code&gt; and &lt;code&gt;img2&lt;/code&gt; are image batches, i.e. the last three dimensions are [height, width, channels].</source>
          <target state="translated">이 함수는 &lt;code&gt;img1&lt;/code&gt; 과 &lt;code&gt;img2&lt;/code&gt; 가 이미지 배치 라고 가정합니다 . 즉, 마지막 3 차원은 [높이, 너비, 채널]입니다.</target>
        </trans-unit>
        <trans-unit id="05e4418b517bd473a485966680131f4c4c444d83" translate="yes" xml:space="preserve">
          <source>This function attempts to partially evaluate the given tensor, and returns its value as a numpy ndarray if this succeeds.</source>
          <target state="translated">이 함수는 주어진 텐서를 부분적으로 평가하려고 시도하고 이것이 성공하면 그 값을 numpy ndarray로 반환합니다.</target>
        </trans-unit>
        <trans-unit id="cf86c424c057435bb07a468ed262a1bc87e5ff48" translate="yes" xml:space="preserve">
          <source>This function can be called at the beginning of the program (before &lt;code&gt;Tensors&lt;/code&gt;, &lt;code&gt;Graphs&lt;/code&gt; or other structures have been created, and before devices have been initialized. It switches all global behaviors that are different between TensorFlow 1.x and 2.x to behave as intended for 1.x.</source>
          <target state="translated">이 함수는 프로그램 시작시 ( &lt;code&gt;Tensors&lt;/code&gt; , &lt;code&gt;Graphs&lt;/code&gt; 또는 기타 구조가 생성되기 전과 장치가 초기화되기 전에) 호출 될 수 있습니다 . TensorFlow 1.x와 2.x 사이에 다른 모든 전역 동작이 다음과 같이 작동하도록 전환됩니다. 1.x를위한 것입니다.</target>
        </trans-unit>
        <trans-unit id="10057d11c28687d408d56022580e8ea6fe2a793b" translate="yes" xml:space="preserve">
          <source>This function can be called at the beginning of the program (before &lt;code&gt;Tensors&lt;/code&gt;, &lt;code&gt;Graphs&lt;/code&gt; or other structures have been created, and before devices have been initialized. It switches all global behaviors that are different between TensorFlow 1.x and 2.x to behave as intended for 2.x.</source>
          <target state="translated">이 함수는 프로그램 시작시 ( &lt;code&gt;Tensors&lt;/code&gt; , &lt;code&gt;Graphs&lt;/code&gt; 또는 기타 구조가 생성되기 전과 장치가 초기화되기 전에) 호출 될 수 있습니다 . TensorFlow 1.x와 2.x 사이에 다른 모든 전역 동작이 다음과 같이 작동하도록 전환됩니다. 2.x 용입니다.</target>
        </trans-unit>
        <trans-unit id="b42e569daa67e0a1534f20b78d521ba43e71fa0e" translate="yes" xml:space="preserve">
          <source>This function can be used to calculate a suitable paddings argument for use with space_to_batch_nd and batch_to_space_nd.</source>
          <target state="translated">이 함수는 space_to_batch_nd 및 batch_to_space_nd와 함께 사용하기에 적합한 패딩 인수를 계산하는 데 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c744362e6d55098ce01656aff7353b51e78a3f8e" translate="yes" xml:space="preserve">
          <source>This function can be useful when composing a new operation in Python (such as &lt;code&gt;my_func&lt;/code&gt; in the example above). All standard Python op constructors apply this function to each of their Tensor-valued inputs, which allows those ops to accept numpy arrays, Python lists, and scalars in addition to &lt;code&gt;Tensor&lt;/code&gt; objects.</source>
          <target state="translated">이 함수는 Python에서 새 작업을 작성할 때 유용합니다 (예 : &lt;code&gt;my_func&lt;/code&gt; ). 모든 표준 Python op 생성자는이 함수를 각 텐서 값 입력에 적용합니다.이를 통해 해당 op가 &lt;code&gt;Tensor&lt;/code&gt; 객체 외에도 numpy 배열, Python 목록 및 스칼라를 허용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="217d0b2441a5002feaf4d45bd68846f61852099e" translate="yes" xml:space="preserve">
          <source>This function can compute several different vector norms (the 1-norm, the Euclidean or 2-norm, the inf-norm, and in general the p-norm for p &amp;gt; 0) and matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).</source>
          <target state="translated">이 함수는 여러 가지 다른 벡터 규범 (1- 노름, 유클리드 또는 2- 노름, inf- 노름, 일반적으로 p&amp;gt; 0의 p- 노름)과 행렬 규범 (Frobenius, 1-norm, 2- 규범과 inf-norm).</target>
        </trans-unit>
        <trans-unit id="3ea434ce2125739c9300b55f884e2363f68836bb" translate="yes" xml:space="preserve">
          <source>This function can only be called before any Graphs, Ops, or Tensors have been created. It can be used at the beginning of the program for complex migration projects from TensorFlow 1.x to 2.x.</source>
          <target state="translated">이 함수는 그래프, 연산 또는 텐서가 생성되기 전에 만 호출 할 수 있습니다. 프로그램 시작 부분에서 TensorFlow 1.x에서 2.x로 복잡한 마이그레이션 프로젝트를 위해 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="588718f27309c0577e10569b211613b30b1126d6" translate="yes" xml:space="preserve">
          <source>This function casts the input to &lt;code&gt;dtype&lt;/code&gt; without applying any scaling. If there is a danger that values would over or underflow in the cast, this op applies the appropriate clamping before the cast.</source>
          <target state="translated">이 함수는 스케일링을 적용하지 않고 입력을 &lt;code&gt;dtype&lt;/code&gt; 으로 캐스팅합니다 . 캐스트에서 값이 오버플로 또는 언더 플로 될 위험이있는 경우이 op는 캐스트 전에 적절한 클램핑을 적용합니다.</target>
        </trans-unit>
        <trans-unit id="09decee67bf539dd150a70f2c58935c601acb068" translate="yes" xml:space="preserve">
          <source>This function computes the exponential of every element in the input tensor. i.e. &lt;code&gt;exp(x)&lt;/code&gt; or &lt;code&gt;e^(x)&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; is the input tensor. &lt;code&gt;e&lt;/code&gt; denotes Euler's number and is approximately equal to 2.718281. Output is positive for any real input.</source>
          <target state="translated">이 함수는 입력 텐서의 모든 요소에 대한 지수를 계산합니다. 즉 &lt;code&gt;exp(x)&lt;/code&gt; 또는 &lt;code&gt;e^(x)&lt;/code&gt; . 여기서 &lt;code&gt;x&lt;/code&gt; 는 입력 텐서입니다. &lt;code&gt;e&lt;/code&gt; 는 오일러의 수를 나타내며 대략 2.718281과 같습니다. 실제 입력에 대해 출력이 양수입니다.</target>
        </trans-unit>
        <trans-unit id="5fcc9bd16353155f925829234fcc96a9dbe0c86d" translate="yes" xml:space="preserve">
          <source>This function computes the exponential of the input tensor element-wise. i.e. &lt;a href=&quot;exp&quot;&gt;&lt;code&gt;math.exp(x)&lt;/code&gt;&lt;/a&gt; or \(e^x\), where &lt;code&gt;x&lt;/code&gt; is the input tensor. \(e\) denotes Euler's number and is approximately equal to 2.718281. Output is positive for any real input.</source>
          <target state="translated">This function computes the exponential of the input tensor element-wise. i.e. &lt;a href=&quot;exp&quot;&gt; &lt;code&gt;math.exp(x)&lt;/code&gt; &lt;/a&gt; or \(e^x\), where &lt;code&gt;x&lt;/code&gt; is the input tensor. \(e\) denotes Euler's number and is approximately equal to 2.718281. Output is positive for any real input.</target>
        </trans-unit>
        <trans-unit id="7c0a191a50e5e9af59c01d8569f306fc43d930b1" translate="yes" xml:space="preserve">
          <source>This function computes the matrix logarithm using the Schur-Parlett algorithm. Details of the algorithm can be found in Section 11.6.2 of: Nicholas J. Higham, Functions of Matrices: Theory and Computation, SIAM 2008. ISBN 978-0-898716-46-7.</source>
          <target state="translated">이 함수는 Schur-Parlett 알고리즘을 사용하여 행렬 로그를 계산합니다. 알고리즘에 대한 자세한 내용은 11.6.2 절 : Nicholas J. Higham, 행렬의 함수 : 이론 및 계산, SIAM 2008에 있습니다. ISBN 978-0-898716-46-7.</target>
        </trans-unit>
        <trans-unit id="be1f544dd8e61bda50e9ba11ee30c7fa32e6f8ea" translate="yes" xml:space="preserve">
          <source>This function converts Python objects of various types to &lt;code&gt;Tensor&lt;/code&gt; objects. It accepts &lt;code&gt;Tensor&lt;/code&gt; objects, numpy arrays, Python lists, and Python scalars. For example:</source>
          <target state="translated">이 함수는 다양한 유형의 Python 객체를 &lt;code&gt;Tensor&lt;/code&gt; 객체 로 변환 합니다. 그것은 받아 &lt;code&gt;Tensor&lt;/code&gt; 개체, NumPy와 배열, 파이썬 목록 및 파이썬 스칼라. 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="e487da37eb7d13adb8d956491efcafe1ed6b6abd" translate="yes" xml:space="preserve">
          <source>This function creates a new Generator object (and the Variable object within), which does not work well with tf.function because (1) tf.function puts restrictions on Variable creation thus reset_global_generator can't be freely used inside tf.function; (2) redirecting a global variable to a new object is problematic with tf.function because the old object may be captured by a 'tf.function'ed function and still be used by it. A 'tf.function'ed function only keeps weak references to variables, so deleting a variable and then calling that function again may raise an error, as demonstrated by random_test.py/RandomTest.testResetGlobalGeneratorBadWithDefun .</source>
          <target state="translated">이 함수는 (1) tf.function이 변수 생성을 제한하므로 reset_global_generator를 tf.function 내에서 자유롭게 사용할 수 없기 때문에 tf.function에서 제대로 작동하지 않는 새로운 Generator 객체 (및 그 안에있는 Variable 객체)를 만듭니다. (2) 전역 변수를 새 객체로 리디렉션하는 것은 tf.function에 문제가 있습니다. 이전 객체는 'tf.function'ed 함수에 의해 캡처되어 여전히 사용될 수 있기 때문입니다. 'tf.function'ed 함수는 변수에 대한 약한 참조 만 유지하므로 random_test.py/RandomTest.testResetGlobalGeneratorBadWithDefun에 표시된 것처럼 변수를 삭제 한 다음 해당 함수를 다시 호출하면 오류가 발생할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="7bd8be377fdf00edb4e98ffd4a0d17d3f66c21a2" translate="yes" xml:space="preserve">
          <source>This function divides &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, forcing Python 2 semantics. That is, if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are both integers then the result will be an integer. This is in contrast to Python 3, where division with &lt;code&gt;/&lt;/code&gt; is always a float while division with &lt;code&gt;//&lt;/code&gt; is always an integer.</source>
          <target state="translated">이 함수는 &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 를 나누고 파이썬 2 의미를 강제합니다. 즉, &lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;y&lt;/code&gt; 가 모두 정수이면 결과는 정수입니다. 이와 부문 파이썬 3에 대조적이다 &lt;code&gt;/&lt;/code&gt; 이 와 분열 동안 항상 부동이다 &lt;code&gt;//&lt;/code&gt; 이 항상 정수입니다.</target>
        </trans-unit>
        <trans-unit id="d24aa00a66ce40fc5a2092349ae7643f400f331a" translate="yes" xml:space="preserve">
          <source>This function enables you to use a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; in a stateless &quot;tensor-in tensor-out&quot; expression, without creating a &lt;a href=&quot;../../compat/v1/data/iterator&quot;&gt;&lt;code&gt;tf.compat.v1.data.Iterator&lt;/code&gt;&lt;/a&gt;. This can be useful when your preprocessing transformations are expressed as a &lt;code&gt;Dataset&lt;/code&gt;, and you want to use the transformation at serving time. For example:</source>
          <target state="translated">이 기능을 사용하면 사용할 수 있습니다 &lt;a href=&quot;../dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; 을&lt;/a&gt; &quot;텐서-에서 텐서 아웃&quot;표현하는 만들지 않고 무에서 &lt;a href=&quot;../../compat/v1/data/iterator&quot;&gt; &lt;code&gt;tf.compat.v1.data.Iterator&lt;/code&gt; 을&lt;/a&gt; . 이는 전처리 변환이 &lt;code&gt;Dataset&lt;/code&gt; 으로 표시되고 서비스 제공시 변환을 사용하려는 경우에 유용 할 수 있습니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="dcd4ee76305c19cb19df5a4e6d70410c1e1185ec" translate="yes" xml:space="preserve">
          <source>This function enables you to use a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; in a stateless &quot;tensor-in tensor-out&quot; expression, without creating an iterator. This can be useful when your preprocessing transformations are expressed as a &lt;code&gt;Dataset&lt;/code&gt;, and you want to use the transformation at serving time.</source>
          <target state="translated">This function enables you to use a &lt;a href=&quot;../dataset&quot;&gt; &lt;code&gt;tf.data.Dataset&lt;/code&gt; &lt;/a&gt; in a stateless &quot;tensor-in tensor-out&quot; expression, without creating an iterator. This can be useful when your preprocessing transformations are expressed as a &lt;code&gt;Dataset&lt;/code&gt; , and you want to use the transformation at serving time.</target>
        </trans-unit>
        <trans-unit id="43245fcf24b3e5f89c388ed18c02c0b4b9e1fd8d" translate="yes" xml:space="preserve">
          <source>This function enqueues a structure of features to be looked up in the embedding tables. We expect that the batch size of each of the tensors in features matches the per core batch size. This will automatically happen if your input dataset is batched to the global batch size and you use &lt;a href=&quot;../../../distribute/tpustrategy&quot;&gt;&lt;code&gt;tf.distribute.TPUStrategy&lt;/code&gt;&lt;/a&gt;'s &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; or if you use &lt;code&gt;experimental_distribute_datasets_from_function&lt;/code&gt; and batch to the per core batch size computed by the context passed to your input function.</source>
          <target state="translated">This function enqueues a structure of features to be looked up in the embedding tables. We expect that the batch size of each of the tensors in features matches the per core batch size. This will automatically happen if your input dataset is batched to the global batch size and you use &lt;a href=&quot;../../../distribute/tpustrategy&quot;&gt; &lt;code&gt;tf.distribute.TPUStrategy&lt;/code&gt; &lt;/a&gt;'s &lt;code&gt;experimental_distribute_dataset&lt;/code&gt; or if you use &lt;code&gt;experimental_distribute_datasets_from_function&lt;/code&gt; and batch to the per core batch size computed by the context passed to your input function.</target>
        </trans-unit>
        <trans-unit id="af17991dd15e2b7fa7774cc8e8187690043ab3dd" translate="yes" xml:space="preserve">
          <source>This function exists only for backwards compatibility purposes; new code should use &lt;code&gt;__floordiv__&lt;/code&gt; via the syntax &lt;code&gt;x // y&lt;/code&gt;. Using &lt;code&gt;x // y&lt;/code&gt; communicates clearly that the result rounds down, and is forward compatible to Python 3.</source>
          <target state="translated">이 기능은 이전 버전과의 호환성을 위해서만 존재합니다. 새 코드는 구문 &lt;code&gt;x // y&lt;/code&gt; 를 통해 &lt;code&gt;__floordiv__&lt;/code&gt; 를 사용해야합니다 . &lt;code&gt;x // y&lt;/code&gt; 사용 하면 결과가 반올림되고 명확하게 전달되며 Python 3과 호환됩니다.</target>
        </trans-unit>
        <trans-unit id="1a2f6439e571c218e4f990c2f6f9f31b011962aa" translate="yes" xml:space="preserve">
          <source>This function exists only to have a better error message. Instead of: &lt;code&gt;TypeError: unsupported operand type(s) for /: 'Dimension' and 'int'&lt;/code&gt;, this function will explicitly call for usage of &lt;code&gt;//&lt;/code&gt; instead.</source>
          <target state="translated">이 기능은 더 나은 오류 메시지를 표시하기 위해 존재합니다. 대신 : &lt;code&gt;TypeError: unsupported operand type(s) for /: 'Dimension' and 'int'&lt;/code&gt; 이 대신 이 함수는 &lt;code&gt;//&lt;/code&gt; 대신 사용을 명시 적으로 호출 합니다.</target>
        </trans-unit>
        <trans-unit id="6bf09410a9b47558afad7eb9fc6a9929885c6dd9" translate="yes" xml:space="preserve">
          <source>This function exists only to have a better error message. Instead of: &lt;code&gt;TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'&lt;/code&gt;, this function will explicitly call for usage of &lt;code&gt;//&lt;/code&gt; instead.</source>
          <target state="translated">이 기능은 더 나은 오류 메시지를 표시하기 위해 존재합니다. 대신 : &lt;code&gt;TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'&lt;/code&gt; 이 대신 이 함수는 &lt;code&gt;//&lt;/code&gt; 대신 사용을 명시 적으로 호출 합니다.</target>
        </trans-unit>
        <trans-unit id="7046a2ab2d223422699f2f1db88f8efbcff064ed" translate="yes" xml:space="preserve">
          <source>This function exports the graph, saver, and collection objects into &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer with the intention of it being imported at a later time or location to restart training, run inference, or be a subgraph.</source>
          <target state="translated">이 기능 은 나중에 다시 시작하거나 훈련을 시작하거나 추론을 실행하거나 하위 그래프가 될 수 있도록 그래프, 보호기 및 수집 객체를 &lt;code&gt;MetaGraphDef&lt;/code&gt; 프로토콜 버퍼 로 내 보냅니다 .</target>
        </trans-unit>
        <trans-unit id="7a855742752eb51788b391963ce908a091cbe366" translate="yes" xml:space="preserve">
          <source>This function follows the &lt;a href=&quot;http://htk.eng.cam.ac.uk/&quot;&gt;Hidden Markov Model Toolkit (HTK)&lt;/a&gt; convention, defining the mel scale in terms of a frequency in hertz according to the following formula:</source>
          <target state="translated">This function follows the &lt;a href=&quot;http://htk.eng.cam.ac.uk/&quot;&gt;Hidden Markov Model Toolkit (HTK)&lt;/a&gt; convention, defining the mel scale in terms of a frequency in hertz according to the following formula:</target>
        </trans-unit>
        <trans-unit id="6a27fb60b44269b202e3c908e7cb802642c2ac28" translate="yes" xml:space="preserve">
          <source>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal &lt;code&gt;x / y&lt;/code&gt; division in Python 3 and in Python 2.7 with &lt;code&gt;from __future__ import division&lt;/code&gt;. If you want integer division that rounds down, use &lt;code&gt;x // y&lt;/code&gt; or &lt;code&gt;tf.math.floordiv&lt;/code&gt;.</source>
          <target state="translated">이 함수는 모든 정수 인수가 부동 유형으로 먼저 캐스팅되는 Python 3 나누기 연산자 시맨틱을 강제합니다. 이 연산은 파이썬 3과 파이썬 2.7 &lt;code&gt;from __future__ import division&lt;/code&gt; 으로 일반 &lt;code&gt;x / y&lt;/code&gt; 나누기에 의해 생성됩니다 . 반올림하는 정수 나누기를 원하면 &lt;code&gt;x // y&lt;/code&gt; 또는 &lt;code&gt;tf.math.floordiv&lt;/code&gt; 를 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="4d4720bce15c58196c687612f77168d6737d499a" translate="yes" xml:space="preserve">
          <source>This function generalizes the &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt; op by also supporting a Soft-NMS (with Gaussian weighting) mode (c.f. Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score of other overlapping boxes instead of directly causing them to be pruned. Consequently, in contrast to &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;non_max_suppression_padded&quot;&gt;&lt;code&gt;tf.image.non_max_suppression_padded&lt;/code&gt;&lt;/a&gt; returns the new scores of each input box in the second output, &lt;code&gt;selected_scores&lt;/code&gt;.</source>
          <target state="translated">This function generalizes the &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt; op by also supporting a Soft-NMS (with Gaussian weighting) mode (c.f. Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score of other overlapping boxes instead of directly causing them to be pruned. Consequently, in contrast to &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt;, &lt;a href=&quot;non_max_suppression_padded&quot;&gt; &lt;code&gt;tf.image.non_max_suppression_padded&lt;/code&gt; &lt;/a&gt; returns the new scores of each input box in the second output, &lt;code&gt;selected_scores&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b139bf71180b25aa620a27f39c22f066fe31fcf7" translate="yes" xml:space="preserve">
          <source>This function generalizes the &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt; op by also supporting a Soft-NMS (with Gaussian weighting) mode (c.f. Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score of other overlapping boxes instead of directly causing them to be pruned. Consequently, in contrast to &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;tf.image.non_max_suppression_v2&lt;/code&gt; returns the new scores of each input box in the second output, &lt;code&gt;selected_scores&lt;/code&gt;.</source>
          <target state="translated">이 함수 는 상자가 다른 겹치는 상자의 점수를 줄이는 Soft-NMS (가우시안 가중) 모드 (cf Bodla et al, https://arxiv.org/abs/1704.04503)도 지원 하여 &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt; op를 일반화합니다. 직접 잘라내는 대신 따라서, 달리 &lt;a href=&quot;non_max_suppression&quot;&gt; &lt;code&gt;tf.image.non_max_suppression&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;tf.image.non_max_suppression_v2&lt;/code&gt; , 상기 제 2 출력의 각 입력 박스의 새로운 스코어를 반환 &lt;code&gt;selected_scores&lt;/code&gt; 를 .</target>
        </trans-unit>
        <trans-unit id="1f78cfdbddd70d6ebd322125da902964ca2c0221" translate="yes" xml:space="preserve">
          <source>This function generates a weighted sum based on output dimension &lt;code&gt;units&lt;/code&gt;. Weighted sum refers to logits in classification problems. It refers to the prediction itself for linear regression problems.</source>
          <target state="translated">이 함수는 출력 차원 &lt;code&gt;units&lt;/code&gt; 기반으로 가중치 합계를 생성합니다 . 가중 합은 분류 문제의 로짓을 나타냅니다. 선형 회귀 문제에 대한 예측 자체를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="b7164aa4227947230adf26e333ecf50d207f9d4e" translate="yes" xml:space="preserve">
          <source>This function ignores flags whose value is None. Each flag assignment is separated by a newline.</source>
          <target state="translated">이 함수는 값이 None 인 플래그를 무시합니다. 각 플래그 할당은 개행으로 구분됩니다.</target>
        </trans-unit>
        <trans-unit id="0c81aeff7442b1d7f71d30de1b5da89dfe187de7" translate="yes" xml:space="preserve">
          <source>This function in addition also allows assignment to a sliced range. This is similar to &lt;code&gt;__setitem__&lt;/code&gt; functionality in Python. However, the syntax is different so that the user can capture the assignment operation for grouping or passing to &lt;code&gt;sess.run()&lt;/code&gt;. For example,</source>
          <target state="translated">이 기능은 또한 슬라이스 범위에 할당 할 수 있습니다. 이것은 파이썬의 &lt;code&gt;__setitem__&lt;/code&gt; 기능 과 비슷합니다 . 그러나 사용자가 그룹화하거나 &lt;code&gt;sess.run()&lt;/code&gt; 전달하기위한 할당 작업을 캡처 할 수 있도록 구문이 다릅니다 . 예를 들어</target>
        </trans-unit>
        <trans-unit id="f477dc6f411c004d0b07e1741886385a8bad1741" translate="yes" xml:space="preserve">
          <source>This function is a more primitive version of &lt;code&gt;dynamic_rnn&lt;/code&gt; that provides more direct access to the inputs each iteration. It also provides more control over when to start and finish reading the sequence, and what to emit for the output.</source>
          <target state="translated">이 함수는 각 반복마다 입력에 더 직접 액세스 할 수 있는보다 원시적 인 &lt;code&gt;dynamic_rnn&lt;/code&gt; 버전입니다 . 또한 시퀀스 읽기 시작 및 완료시기와 출력을 위해 무엇을 방출해야하는지에 대한 더 많은 제어 기능을 제공합니다.</target>
        </trans-unit>
        <trans-unit id="b35cb926e7e56c5e0bb4984bfdd19c6c71696446" translate="yes" xml:space="preserve">
          <source>This function is a simpler wrapper around the more general &lt;a href=&quot;convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt;, and exists only for backwards compatibility. You can use &lt;a href=&quot;convolution&quot;&gt;&lt;code&gt;tf.nn.convolution&lt;/code&gt;&lt;/a&gt; to perform 1-D, 2-D, or 3-D atrous convolution.</source>
          <target state="translated">이 함수는보다 일반적인 &lt;a href=&quot;convolution&quot;&gt; &lt;code&gt;tf.nn.convolution&lt;/code&gt; 에&lt;/a&gt; 대한 간단한 래퍼 이며 이전 버전과의 호환성을 위해서만 존재합니다. &lt;a href=&quot;convolution&quot;&gt; &lt;code&gt;tf.nn.convolution&lt;/code&gt; &lt;/a&gt; 을 사용하여 1-D, 2D 또는 3D 집중 컨볼 루션을 수행 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="1fde94a598e8772eaea3cc47dd741a3aa23b5c85" translate="yes" xml:space="preserve">
          <source>This function is analogous to &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html&quot;&gt;&lt;code&gt;numpy.linalg.pinv&lt;/code&gt;&lt;/a&gt;. It differs only in default value of &lt;code&gt;rcond&lt;/code&gt;. In &lt;code&gt;numpy.linalg.pinv&lt;/code&gt;, the default &lt;code&gt;rcond&lt;/code&gt; is &lt;code&gt;1e-15&lt;/code&gt;. Here the default is &lt;code&gt;10. * max(num_rows, num_cols) * np.finfo(dtype).eps&lt;/code&gt;.</source>
          <target state="translated">이 함수는 &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html&quot;&gt; &lt;code&gt;numpy.linalg.pinv&lt;/code&gt; 와&lt;/a&gt; 유사합니다 . &lt;code&gt;rcond&lt;/code&gt; 의 기본값 만 다릅니다 . 에서 &lt;code&gt;numpy.linalg.pinv&lt;/code&gt; , 기본 &lt;code&gt;rcond&lt;/code&gt; 은 입니다 &lt;code&gt;1e-15&lt;/code&gt; . 여기서, 디폴트는 &lt;code&gt;10. * max(num_rows, num_cols) * np.finfo(dtype).eps&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c82b17de9fe920f72f7a5369e74c77b8a5f75d81" translate="yes" xml:space="preserve">
          <source>This function is based on the standard SSIM implementation from: Wang, Z., Bovik, A. C., Sheikh, H. R., &amp;amp; Simoncelli, E. P. (2004). Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing.</source>
          <target state="translated">이 기능은 Wang, Z., Bovik, AC, Sheikh, HR 및 Simoncelli, EP (2004)의 표준 SSIM 구현을 기반으로합니다. 이미지 품질 평가 : 오류 가시성에서 구조적 유사성까지. 이미지 처리에 관한 IEEE 트랜잭션.</target>
        </trans-unit>
        <trans-unit id="3f78f322021258197ee0401af332233d4fb6c937" translate="yes" xml:space="preserve">
          <source>This function is cached the first time &lt;a href=&quot;../model#evaluate&quot;&gt;&lt;code&gt;Model.evaluate&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../model#test_on_batch&quot;&gt;&lt;code&gt;Model.test_on_batch&lt;/code&gt;&lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;../model#compile&quot;&gt;&lt;code&gt;Model.compile&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">This function is cached the first time &lt;a href=&quot;../model#evaluate&quot;&gt; &lt;code&gt;Model.evaluate&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;../model#test_on_batch&quot;&gt; &lt;code&gt;Model.test_on_batch&lt;/code&gt; &lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;../model#compile&quot;&gt; &lt;code&gt;Model.compile&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="03d4062526248415274d1920f151d5925ea1d106" translate="yes" xml:space="preserve">
          <source>This function is cached the first time &lt;a href=&quot;../model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../model#train_on_batch&quot;&gt;&lt;code&gt;Model.train_on_batch&lt;/code&gt;&lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;../model#compile&quot;&gt;&lt;code&gt;Model.compile&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">This function is cached the first time &lt;a href=&quot;../model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;../model#train_on_batch&quot;&gt; &lt;code&gt;Model.train_on_batch&lt;/code&gt; &lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;../model#compile&quot;&gt; &lt;code&gt;Model.compile&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="a73ed236f67dee6103073403c6d29f26833958d9" translate="yes" xml:space="preserve">
          <source>This function is cached the first time &lt;a href=&quot;../model#predict&quot;&gt;&lt;code&gt;Model.predict&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../model#predict_on_batch&quot;&gt;&lt;code&gt;Model.predict_on_batch&lt;/code&gt;&lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;../model#compile&quot;&gt;&lt;code&gt;Model.compile&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">This function is cached the first time &lt;a href=&quot;../model#predict&quot;&gt; &lt;code&gt;Model.predict&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;../model#predict_on_batch&quot;&gt; &lt;code&gt;Model.predict_on_batch&lt;/code&gt; &lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;../model#compile&quot;&gt; &lt;code&gt;Model.compile&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="9c02b98872d235ad42d3656b50ce22017eda7ff2" translate="yes" xml:space="preserve">
          <source>This function is cached the first time &lt;a href=&quot;model#evaluate&quot;&gt;&lt;code&gt;Model.evaluate&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;model#test_on_batch&quot;&gt;&lt;code&gt;Model.test_on_batch&lt;/code&gt;&lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;model#compile&quot;&gt;&lt;code&gt;Model.compile&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">This function is cached the first time &lt;a href=&quot;model#evaluate&quot;&gt; &lt;code&gt;Model.evaluate&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;model#test_on_batch&quot;&gt; &lt;code&gt;Model.test_on_batch&lt;/code&gt; &lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;model#compile&quot;&gt; &lt;code&gt;Model.compile&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="9d1d8a8ff69ef7a941ba68b453aec429bfe458e1" translate="yes" xml:space="preserve">
          <source>This function is cached the first time &lt;a href=&quot;model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;model#train_on_batch&quot;&gt;&lt;code&gt;Model.train_on_batch&lt;/code&gt;&lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;model#compile&quot;&gt;&lt;code&gt;Model.compile&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">This function is cached the first time &lt;a href=&quot;model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;model#train_on_batch&quot;&gt; &lt;code&gt;Model.train_on_batch&lt;/code&gt; &lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;model#compile&quot;&gt; &lt;code&gt;Model.compile&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="5d0db761a3ad75448d327cc87f61eb8b0729f377" translate="yes" xml:space="preserve">
          <source>This function is cached the first time &lt;a href=&quot;model#predict&quot;&gt;&lt;code&gt;Model.predict&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;model#predict_on_batch&quot;&gt;&lt;code&gt;Model.predict_on_batch&lt;/code&gt;&lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;model#compile&quot;&gt;&lt;code&gt;Model.compile&lt;/code&gt;&lt;/a&gt; is called.</source>
          <target state="translated">This function is cached the first time &lt;a href=&quot;model#predict&quot;&gt; &lt;code&gt;Model.predict&lt;/code&gt; &lt;/a&gt; or &lt;a href=&quot;model#predict_on_batch&quot;&gt; &lt;code&gt;Model.predict_on_batch&lt;/code&gt; &lt;/a&gt; is called. The cache is cleared whenever &lt;a href=&quot;model#compile&quot;&gt; &lt;code&gt;Model.compile&lt;/code&gt; &lt;/a&gt; is called.</target>
        </trans-unit>
        <trans-unit id="ecacc04269db8f28f91780c2b346f24c2d101704" translate="yes" xml:space="preserve">
          <source>This function is called between epochs/steps, when a metric is evaluated during training.</source>
          <target state="translated">이 기능은 훈련 중에 메트릭을 평가할 때 에포크 / 스텝간에 호출됩니다.</target>
        </trans-unit>
        <trans-unit id="a75cbe1aa934dcb50e2537aae264b28dbab09250" translate="yes" xml:space="preserve">
          <source>This function is called by FLAGS(argv). It scans the input list for a flag that looks like: --flagfile=</source>
          <target state="translated">이 함수는 FLAGS (argv)에 의해 호출됩니다. 다음과 같은 플래그에 대한 입력 목록을 스캔합니다. --flagfile =</target>
        </trans-unit>
        <trans-unit id="e57b5dff2b7e230f6a359d3b07cb810778cc3047" translate="yes" xml:space="preserve">
          <source>This function is called in the main TensorFlow &lt;code&gt;__init__.py&lt;/code&gt; file, user should not need to call it, except during complex migrations.</source>
          <target state="translated">이 함수는 기본 TensorFlow &lt;code&gt;__init__.py&lt;/code&gt; 파일에서 호출되므로 복잡한 마이그레이션을 제외하고 사용자가 호출 할 필요가 없습니다.</target>
        </trans-unit>
        <trans-unit id="0831cfa041ba84a9c1bb953a8575728ee9dbe8bf" translate="yes" xml:space="preserve">
          <source>This function is faster and numerically stabler than &lt;code&gt;bessel_i0(x)&lt;/code&gt;.</source>
          <target state="translated">이 함수는 &lt;code&gt;bessel_i0(x)&lt;/code&gt; 보다 빠르고 수치 적으로 안정적 입니다.</target>
        </trans-unit>
        <trans-unit id="1f2e499db54e57708a372078c16af5df37036099" translate="yes" xml:space="preserve">
          <source>This function is faster and numerically stabler than &lt;code&gt;bessel_i1(x)&lt;/code&gt;.</source>
          <target state="translated">이 함수는 &lt;code&gt;bessel_i1(x)&lt;/code&gt; 보다 빠르고 수치 적으로 안정적 입니다.</target>
        </trans-unit>
        <trans-unit id="d7e374cf0f52d98689ddb22ec7b9e2a428cd4956" translate="yes" xml:space="preserve">
          <source>This function is implemented using a queue. A &lt;code&gt;QueueRunner&lt;/code&gt; for the queue is added to the current &lt;code&gt;Graph&lt;/code&gt;'s &lt;code&gt;QUEUE_RUNNER&lt;/code&gt; collection.</source>
          <target state="translated">이 기능은 대기열을 사용하여 구현됩니다. &lt;code&gt;QueueRunner&lt;/code&gt; 큐의 현재에 첨가 &lt;code&gt;Graph&lt;/code&gt; 의 &lt;code&gt;QUEUE_RUNNER&lt;/code&gt; 의 컬렉션.</target>
        </trans-unit>
        <trans-unit id="4c4c3026638168daaa4ab1a3c114680f01d9d246" translate="yes" xml:space="preserve">
          <source>This function is more numerically stable than log(sum(exp(input))). It avoids overflows caused by taking the exp of large inputs and underflows caused by taking the log of small inputs.</source>
          <target state="translated">이 함수는 log (sum (exp (input)))보다 수치 적으로 안정적입니다. 큰 입력의 소비로 인한 오버플로와 작은 입력의 로그로 인한 언더 플로를 방지합니다.</target>
        </trans-unit>
        <trans-unit id="80c0f02cfab4a0ee1574d2a1145f5fca28f12b11" translate="yes" xml:space="preserve">
          <source>This function is only available with the TensorFlow backend for the time being.</source>
          <target state="translated">이 기능은 당분간 TensorFlow 백엔드에서만 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="11a7ac7f028baf06c483242a158777b17ee8b353" translate="yes" xml:space="preserve">
          <source>This function is only used when defining a new op type. It may be used for ops such as &lt;a href=&quot;size&quot;&gt;&lt;code&gt;tf.size()&lt;/code&gt;&lt;/a&gt; that are not differentiable. For example:</source>
          <target state="translated">이 기능은 새로운 op 유형을 정의 할 때만 사용됩니다. 차별화 할 수없는 &lt;a href=&quot;size&quot;&gt; &lt;code&gt;tf.size()&lt;/code&gt; &lt;/a&gt; 와 같은 연산에 사용될 수 있습니다 . 예를 들면 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="61969c39a3dfe9d632e8e43316d05aa062590efa" translate="yes" xml:space="preserve">
          <source>This function is part of the Keras serialization and deserialization framework. It maps objects to the string names associated with those objects for serialization/deserialization.</source>
          <target state="translated">This function is part of the Keras serialization and deserialization framework. It maps objects to the string names associated with those objects for serialization/deserialization.</target>
        </trans-unit>
        <trans-unit id="7aa4be9a74ac3f90821c5e3ef2a47e10c4dfdcb8" translate="yes" xml:space="preserve">
          <source>This function is part of the Keras serialization and deserialization framework. It maps strings to the objects associated with them for serialization/deserialization.</source>
          <target state="translated">This function is part of the Keras serialization and deserialization framework. It maps strings to the objects associated with them for serialization/deserialization.</target>
        </trans-unit>
        <trans-unit id="577a32736f43471cd2cd1266738343fb80596d48" translate="yes" xml:space="preserve">
          <source>This function is the canonical way to get/validate an object of one of the allowed types from an external argument reference in the Session API.</source>
          <target state="translated">이 함수는 세션 API의 외부 인수 참조에서 허용 된 유형 중 하나의 객체를 가져 오거나 확인하는 표준 방법입니다.</target>
        </trans-unit>
        <trans-unit id="130785c66d51b0bf917ff1a83e8cb5fd0234052e" translate="yes" xml:space="preserve">
          <source>This function is to generate &lt;a href=&quot;../distributedvalues&quot;&gt;&lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt;&lt;/a&gt; to pass into &lt;code&gt;run&lt;/code&gt;, &lt;code&gt;reduce&lt;/code&gt;, or other methods that take distributed values when not using datasets.</source>
          <target state="translated">This function is to generate &lt;a href=&quot;../distributedvalues&quot;&gt; &lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt; &lt;/a&gt; to pass into &lt;code&gt;run&lt;/code&gt; , &lt;code&gt;reduce&lt;/code&gt; , or other methods that take distributed values when not using datasets.</target>
        </trans-unit>
        <trans-unit id="84ff67d2523742ed898675e46a84da4adae4f6b1" translate="yes" xml:space="preserve">
          <source>This function is to generate &lt;a href=&quot;distributedvalues&quot;&gt;&lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt;&lt;/a&gt; to pass into &lt;code&gt;run&lt;/code&gt;, &lt;code&gt;reduce&lt;/code&gt;, or other methods that take distributed values when not using datasets.</source>
          <target state="translated">This function is to generate &lt;a href=&quot;distributedvalues&quot;&gt; &lt;code&gt;tf.distribute.DistributedValues&lt;/code&gt; &lt;/a&gt; to pass into &lt;code&gt;run&lt;/code&gt; , &lt;code&gt;reduce&lt;/code&gt; , or other methods that take distributed values when not using datasets.</target>
        </trans-unit>
        <trans-unit id="691cc7f8251e205cf948be38afb6e034f26a2e72" translate="yes" xml:space="preserve">
          <source>This function is used to perform parallel lookups on the list of tensors in &lt;code&gt;params&lt;/code&gt;. It is a generalization of &lt;a href=&quot;../../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;, where &lt;code&gt;params&lt;/code&gt; is interpreted as a partitioning of a large embedding tensor. &lt;code&gt;params&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">이 함수는 &lt;code&gt;params&lt;/code&gt; 의 텐서 목록에서 병렬 조회를 수행하는 데 사용됩니다 . &lt;a href=&quot;../../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 의 일반화로 , &lt;code&gt;params&lt;/code&gt; 는 큰 임베딩 텐서의 분할로 해석됩니다. &lt;code&gt;params&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="4938f0a72e046cd0e52c1383bdb6cd4186015a22" translate="yes" xml:space="preserve">
          <source>This function is used to perform parallel lookups on the list of tensors in &lt;code&gt;params&lt;/code&gt;. It is a generalization of &lt;a href=&quot;../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;, where &lt;code&gt;params&lt;/code&gt; is interpreted as a partitioning of a large embedding tensor.</source>
          <target state="translated">This function is used to perform parallel lookups on the list of tensors in &lt;code&gt;params&lt;/code&gt; . It is a generalization of &lt;a href=&quot;../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt;, where &lt;code&gt;params&lt;/code&gt; is interpreted as a partitioning of a large embedding tensor.</target>
        </trans-unit>
        <trans-unit id="237e26d699d02ce05b0e4079a36fba68db8a8789" translate="yes" xml:space="preserve">
          <source>This function is used to perform parallel lookups on the list of tensors in &lt;code&gt;params&lt;/code&gt;. It is a generalization of &lt;a href=&quot;../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;, where &lt;code&gt;params&lt;/code&gt; is interpreted as a partitioning of a large embedding tensor. &lt;code&gt;params&lt;/code&gt; may be a &lt;code&gt;PartitionedVariable&lt;/code&gt; as returned by using &lt;a href=&quot;../compat/v1/get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt;&lt;/a&gt; with a partitioner.</source>
          <target state="translated">이 함수는 &lt;code&gt;params&lt;/code&gt; 의 텐서 목록에서 병렬 조회를 수행하는 데 사용됩니다 . &lt;a href=&quot;../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; 의 일반화로 , &lt;code&gt;params&lt;/code&gt; 는 큰 임베딩 텐서의 분할로 해석됩니다. &lt;code&gt;params&lt;/code&gt; 는 &lt;code&gt;PartitionedVariable&lt;/code&gt; &lt;a href=&quot;../compat/v1/get_variable&quot;&gt; &lt;code&gt;tf.compat.v1.get_variable()&lt;/code&gt; &lt;/a&gt; 함께 tf.compat.v1.get_variable () 을 사용하여 반환 된 PartitionedVariable 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="f577da20d8fc0c2379f7e51688987afe782aa9c2" translate="yes" xml:space="preserve">
          <source>This function is useful for unit testing. A unit test can test using the mixed precision graph rewrite, then disable it so future unit tests continue using float32.</source>
          <target state="translated">이 기능은 단위 테스트에 유용합니다. 단위 테스트는 혼합 정밀도 그래프 다시 쓰기를 사용하여 테스트 한 다음 비활성화하여 향후 단위 테스트에서 float32를 계속 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="d61d06f477fe487d45a847bca66c249257c10fe4" translate="yes" xml:space="preserve">
          <source>This function is useful for unit testing. A unit tests can test using the mixed precision graph rewrite, then disable it so future unit tests continue using float32. If this is done, unit tests should not share a single session, as &lt;code&gt;enable_mixed_precision_graph_rewrite&lt;/code&gt; and &lt;code&gt;disable_mixed_precision_graph_rewrite&lt;/code&gt; have no effect on existing sessions.</source>
          <target state="translated">이 기능은 단위 테스트에 유용합니다. 단위 테스트는 혼합 정밀도 그래프 다시 쓰기를 사용하여 테스트 한 다음 비활성화하여 향후 단위 테스트에서 float32를 계속 사용할 수 있습니다. 이것이 완료되면 &lt;code&gt;enable_mixed_precision_graph_rewrite&lt;/code&gt; 및 &lt;code&gt;disable_mixed_precision_graph_rewrite&lt;/code&gt; 는 기존 세션에 영향을 미치지 않으므로 단위 테스트는 단일 세션을 공유하지 않아야 합니다.</target>
        </trans-unit>
        <trans-unit id="929b9d5a5eeca32709da98b98c1fa20f11f6684a" translate="yes" xml:space="preserve">
          <source>This function may be used in the &lt;code&gt;options&lt;/code&gt; argument in functions that load a SavedModel (&lt;a href=&quot;load&quot;&gt;&lt;code&gt;tf.saved_model.load&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../keras/models/load_model&quot;&gt;&lt;code&gt;tf.keras.models.load_model&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">This function may be used in the &lt;code&gt;options&lt;/code&gt; argument in functions that load a SavedModel (&lt;a href=&quot;load&quot;&gt; &lt;code&gt;tf.saved_model.load&lt;/code&gt; &lt;/a&gt;, &lt;a href=&quot;../keras/models/load_model&quot;&gt; &lt;code&gt;tf.keras.models.load_model&lt;/code&gt; &lt;/a&gt;).</target>
        </trans-unit>
        <trans-unit id="d4e537bea1c76cb2cbcdaeafa3c9baedcb0e335e" translate="yes" xml:space="preserve">
          <source>This function may be used in the &lt;code&gt;options&lt;/code&gt; argument in functions that save a SavedModel (&lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../keras/models/save_model&quot;&gt;&lt;code&gt;tf.keras.models.save_model&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">이 함수는 SavedModel ( &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;../keras/models/save_model&quot;&gt; &lt;code&gt;tf.keras.models.save_model&lt;/code&gt; &lt;/a&gt; ) 을 저장하는 함수 의 &lt;code&gt;options&lt;/code&gt; 인수에 사용될 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="23d4449e48af4e4a9efae86d49cf037eac266df3" translate="yes" xml:space="preserve">
          <source>This function only gets the device policy for the current thread. Any subsequently started thread will again use the default policy.</source>
          <target state="translated">이 함수는 현재 스레드에 대한 장치 정책 만 가져옵니다. 이후에 시작된 스레드는 기본 정책을 다시 사용합니다.</target>
        </trans-unit>
        <trans-unit id="69c8cb582945069c7d9496b069e6902700fc7e3d" translate="yes" xml:space="preserve">
          <source>This function only sets the device policy for the current thread. Any subsequently started thread will again use the default policy.</source>
          <target state="translated">이 기능은 현재 스레드에 대한 장치 정책 만 설정합니다. 이후에 시작된 스레드는 기본 정책을 다시 사용합니다.</target>
        </trans-unit>
        <trans-unit id="128baaf391e006514e7e2e442ed3dbb64e14a3c9" translate="yes" xml:space="preserve">
          <source>This function performs the equivalent of</source>
          <target state="translated">이 기능은</target>
        </trans-unit>
        <trans-unit id="fac08ba1f46139129a2f42247910a712f1085f49" translate="yes" xml:space="preserve">
          <source>This function prefixes the name with the current variable scope and performs reuse checks. See the &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;Variable Scope How To&lt;/a&gt; for an extensive description of how reusing works. Here is a basic example:</source>
          <target state="translated">이 함수는 이름 앞에 현재 변수 범위를 붙이고 재사용 검사를 수행합니다. 재사용 작동 방법에 대한 자세한 설명은 &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;변수 범위&lt;/a&gt; 사용법 을 참조하십시오 . 기본 예는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="85bc4aa7e8b39b071c3a83bcd2bcb628b96948b5" translate="yes" xml:space="preserve">
          <source>This function produces signatures intended for use with the TensorFlow Serving Classify API (tensorflow_serving/apis/prediction_service.proto), and so constrains the input and output types to those allowed by TensorFlow Serving.</source>
          <target state="translated">이 함수는 TensorFlow Serving Classify API (tensorflow_serving / apis / prediction_service.proto)와 함께 사용하도록 서명을 생성하므로 입력 및 출력 유형을 TensorFlow Serving에서 허용하는 유형으로 제한합니다.</target>
        </trans-unit>
        <trans-unit id="795898cb16fc0e553ecaa87cbe16e8417edef412" translate="yes" xml:space="preserve">
          <source>This function produces signatures intended for use with the TensorFlow Serving Predict API (tensorflow_serving/apis/prediction_service.proto). This API imposes no constraints on the input and output types.</source>
          <target state="translated">이 함수는 TensorFlow Serving Predict API (tensorflow_serving / apis / prediction_service.proto)와 함께 사용하도록 서명을 생성합니다. 이 API는 입력 및 출력 유형에 제한을 두지 않습니다.</target>
        </trans-unit>
        <trans-unit id="0bd91f24173f9c6c06caccaa86fb2987286936b9" translate="yes" xml:space="preserve">
          <source>This function produces signatures intended for use with the TensorFlow Serving Regress API (tensorflow_serving/apis/prediction_service.proto), and so constrains the input and output types to those allowed by TensorFlow Serving.</source>
          <target state="translated">이 함수는 TensorFlow Serving Regress API (tensorflow_serving / apis / prediction_service.proto)와 함께 사용하도록 서명을 생성하므로 입력 및 출력 유형을 TensorFlow Serving에서 허용하는 유형으로 제한합니다.</target>
        </trans-unit>
        <trans-unit id="da2207550b053f2e41ed03fce80a539629a65e2e" translate="yes" xml:space="preserve">
          <source>This function provides a way to import a serialized TensorFlow &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto&quot;&gt;&lt;code&gt;GraphDef&lt;/code&gt;&lt;/a&gt; protocol buffer, and extract individual objects in the &lt;code&gt;GraphDef&lt;/code&gt; as &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../operation&quot;&gt;&lt;code&gt;tf.Operation&lt;/code&gt;&lt;/a&gt; objects. Once extracted, these objects are placed into the current default &lt;code&gt;Graph&lt;/code&gt;. See &lt;a href=&quot;../graph#as_graph_def&quot;&gt;&lt;code&gt;tf.Graph.as_graph_def&lt;/code&gt;&lt;/a&gt; for a way to create a &lt;code&gt;GraphDef&lt;/code&gt; proto.</source>
          <target state="translated">이 함수는, 직렬화 TensorFlow 가져올 수있는 방법 제공 &lt;a href=&quot;https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto&quot;&gt; &lt;code&gt;GraphDef&lt;/code&gt; 의&lt;/a&gt; 프로토콜 버퍼를, 상기 개별 개체를 추출 &lt;code&gt;GraphDef&lt;/code&gt; 같은 &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;../operation&quot;&gt; &lt;code&gt;tf.Operation&lt;/code&gt; &lt;/a&gt; 개체. 추출 된 객체는 현재 기본 &lt;code&gt;Graph&lt;/code&gt; 에 배치됩니다 . &lt;code&gt;GraphDef&lt;/code&gt; 프로토 를 생성하는 방법 은 &lt;a href=&quot;../graph#as_graph_def&quot;&gt; &lt;code&gt;tf.Graph.as_graph_def&lt;/code&gt; &lt;/a&gt; 를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="59bf9d9f9818c530570cd3baaed9172f0b655e0a" translate="yes" xml:space="preserve">
          <source>This function raises &lt;code&gt;ValueError&lt;/code&gt; unless it can be certain that the given &lt;code&gt;tensor&lt;/code&gt; is a scalar. &lt;code&gt;ValueError&lt;/code&gt; is also raised if the shape of &lt;code&gt;tensor&lt;/code&gt; is unknown.</source>
          <target state="translated">이 함수 는 주어진 &lt;code&gt;tensor&lt;/code&gt; 가 스칼라인지 확실하지 않은 경우 &lt;code&gt;ValueError&lt;/code&gt; 를 발생시킵니다 . &lt;code&gt;tensor&lt;/code&gt; 의 모양을 알 수없는 경우에도 &lt;code&gt;ValueError&lt;/code&gt; 가 발생합니다 .</target>
        </trans-unit>
        <trans-unit id="22fe780c67f001ded49fb5e4133cb0847481dd48" translate="yes" xml:space="preserve">
          <source>This function receives as input a string of text and returns a list of encoded integers each corresponding to a word (or token) in the given input string.</source>
          <target state="translated">This function receives as input a string of text and returns a list of encoded integers each corresponding to a word (or token) in the given input string.</target>
        </trans-unit>
        <trans-unit id="3009d910bdcd32cff99d1458043403e12c1c254c" translate="yes" xml:space="preserve">
          <source>This function reinstantiates model state by:</source>
          <target state="translated">This function reinstantiates model state by:</target>
        </trans-unit>
        <trans-unit id="a733b4ff78c36cb4d261221c5118416ce8061d8e" translate="yes" xml:space="preserve">
          <source>This function reinstantiates model state by: 1) loading model topology from json (this will eventually come from metagraph). 2) loading model weights from checkpoint.</source>
          <target state="translated">이 함수는 다음과 같이 모델 상태를 초기화합니다. 1) json에서 모델 토폴로지를로드합니다 (이는 결국 메타 그래프에서 가져옵니다). 2) 검사 점에서 모델 가중치로드.</target>
        </trans-unit>
        <trans-unit id="ff0b45b19346e757b8eb62e1bc7385c9d06f1d69" translate="yes" xml:space="preserve">
          <source>This function returns a tensor whose elements are defined by &lt;code&gt;equation&lt;/code&gt;, which is written in a shorthand form inspired by the Einstein summation convention. As an example, consider multiplying two matrices A and B to form a matrix C. The elements of C are given by:</source>
          <target state="translated">이 함수는 요소가 &lt;code&gt;equation&lt;/code&gt; 으로 정의 된 텐서를 반환하며 ,이 형식은 아인슈타인 합산 규칙에서 영감을 얻은 속기 형식으로 작성됩니다. 예를 들어, 두 개의 행렬 A와 B를 곱하여 행렬 C를 형성하는 것을 고려하십시오. C의 요소는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="0b7b7a286f6486a214583e48df98d413e08472ce" translate="yes" xml:space="preserve">
          <source>This function should &lt;em&gt;not&lt;/em&gt; be used for operations that have a well-defined gradient that is not yet implemented.</source>
          <target state="translated">아직 구현되지 않은 잘 정의 된 그래디언트가있는 작업 &lt;em&gt;에는&lt;/em&gt; 이 기능을 사용 &lt;em&gt;하지&lt;/em&gt; 않아야합니다.</target>
        </trans-unit>
        <trans-unit id="1b640a4c1fd849556e2182a5a501c968b01e5603" translate="yes" xml:space="preserve">
          <source>This function should contain the mathemetical logic for one step of evaluation. This typically includes the forward pass, loss calculation, and metrics updates.</source>
          <target state="translated">This function should contain the mathemetical logic for one step of evaluation. This typically includes the forward pass, loss calculation, and metrics updates.</target>
        </trans-unit>
        <trans-unit id="48eea658706b62c655231b07e7ecfd12850950f0" translate="yes" xml:space="preserve">
          <source>This function should only be called during TRAIN mode.</source>
          <target state="translated">This function should only be called during TRAIN mode.</target>
        </trans-unit>
        <trans-unit id="92add72d0f856bfc3fd4e7bcbf6ab90dc2a5a26d" translate="yes" xml:space="preserve">
          <source>This function specifies the device to be used for ops created/executed in a particular context. Nested contexts will inherit and also create/execute their ops on the specified device. If a specific device is not required, consider not using this function so that a device can be automatically assigned. In general the use of this function is optional. &lt;code&gt;device_name&lt;/code&gt; can be fully specified, as in &quot;/job:worker/task:1/device:cpu:0&quot;, or partially specified, containing only a subset of the &quot;/&quot;-separated fields. Any fields which are specified will override device annotations from outer scopes.</source>
          <target state="translated">This function specifies the device to be used for ops created/executed in a particular context. Nested contexts will inherit and also create/execute their ops on the specified device. If a specific device is not required, consider not using this function so that a device can be automatically assigned. In general the use of this function is optional. &lt;code&gt;device_name&lt;/code&gt; can be fully specified, as in &quot;/job:worker/task:1/device:cpu:0&quot;, or partially specified, containing only a subset of the &quot;/&quot;-separated fields. Any fields which are specified will override device annotations from outer scopes.</target>
        </trans-unit>
        <trans-unit id="c538dca8aca927a7d8bbd1b0bb2e590f6c5ad3a5" translate="yes" xml:space="preserve">
          <source>This function supports a subset of tf.gather, see tf.gather for details on usage.</source>
          <target state="translated">이 함수는 tf.gather의 서브셋을 지원합니다. 사용법에 대한 자세한 내용은 tf.gather를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="e857d76db9c7bac209f1715cec1437cf523540d8" translate="yes" xml:space="preserve">
          <source>This function swaps half-spaces for all axes listed (defaults to all). Note that &lt;code&gt;y[0]&lt;/code&gt; is the Nyquist component only if &lt;code&gt;len(x)&lt;/code&gt; is even.</source>
          <target state="translated">이 기능은 나열된 모든 축에 대해 반 공백을 바꿉니다 (기본값은 모두). 참고로 &lt;code&gt;y[0]&lt;/code&gt; 에만 성분 인 나이키 스트 &lt;code&gt;len(x)&lt;/code&gt; 짝수이다.</target>
        </trans-unit>
        <trans-unit id="700dee7b88966a0547c5ef0b6e43b47147bea1dd" translate="yes" xml:space="preserve">
          <source>This function takes a &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer as input. If the argument is a file containing a &lt;code&gt;MetaGraphDef&lt;/code&gt; protocol buffer , it constructs a protocol buffer from the file content. The function then adds all the nodes from the &lt;code&gt;graph_def&lt;/code&gt; field to the current graph, recreates all the collections, and returns a saver constructed from the &lt;code&gt;saver_def&lt;/code&gt; field.</source>
          <target state="translated">이 함수는 &lt;code&gt;MetaGraphDef&lt;/code&gt; 프로토콜 버퍼를 입력으로 사용합니다. 인수가 &lt;code&gt;MetaGraphDef&lt;/code&gt; 프로토콜 버퍼를 포함하는 파일 인 경우 파일 컨텐츠에서 프로토콜 버퍼를 구성합니다. 그런 다음이 함수는 &lt;code&gt;graph_def&lt;/code&gt; 필드 의 모든 노드를 현재 그래프에 추가하고 모든 콜렉션을 다시 작성하며 &lt;code&gt;saver_def&lt;/code&gt; 필드 에서 구성된 세이버를 리턴 합니다.</target>
        </trans-unit>
        <trans-unit id="fd08a12501f4bce4f0a38bb7f61e556860ac6186" translate="yes" xml:space="preserve">
          <source>This function takes in a sequence of data-points gathered at equal intervals, along with time series parameters such as length of the sequences/windows, spacing between two sequence/windows, etc., to produce batches of timeseries inputs and targets.</source>
          <target state="translated">This function takes in a sequence of data-points gathered at equal intervals, along with time series parameters such as length of the sequences/windows, spacing between two sequence/windows, etc., to produce batches of timeseries inputs and targets.</target>
        </trans-unit>
        <trans-unit id="f6d25a51ea520664ee90a7477aef16d45f240f73" translate="yes" xml:space="preserve">
          <source>This function transforms a list (of length &lt;code&gt;num_samples&lt;/code&gt;) of sequences (lists of integers) into a 2D Numpy array of shape &lt;code&gt;(num_samples, num_timesteps)&lt;/code&gt;. &lt;code&gt;num_timesteps&lt;/code&gt; is either the &lt;code&gt;maxlen&lt;/code&gt; argument if provided, or the length of the longest sequence in the list.</source>
          <target state="translated">This function transforms a list (of length &lt;code&gt;num_samples&lt;/code&gt; ) of sequences (lists of integers) into a 2D Numpy array of shape &lt;code&gt;(num_samples, num_timesteps)&lt;/code&gt; . &lt;code&gt;num_timesteps&lt;/code&gt; is either the &lt;code&gt;maxlen&lt;/code&gt; argument if provided, or the length of the longest sequence in the list.</target>
        </trans-unit>
        <trans-unit id="94fc01032dc6978adba1e0b4d64fc3f4b8d2c710" translate="yes" xml:space="preserve">
          <source>This function transforms a list of &lt;code&gt;num_samples&lt;/code&gt; sequences (lists of integers) into a 2D Numpy array of shape &lt;code&gt;(num_samples, num_timesteps)&lt;/code&gt;. &lt;code&gt;num_timesteps&lt;/code&gt; is either the &lt;code&gt;maxlen&lt;/code&gt; argument if provided, or the length of the longest sequence otherwise.</source>
          <target state="translated">이 함수는 &lt;code&gt;num_samples&lt;/code&gt; 시퀀스 (정수 목록) 목록을 2D Numpy 배열 모양 &lt;code&gt;(num_samples, num_timesteps)&lt;/code&gt; 합니다. &lt;code&gt;num_timesteps&lt;/code&gt; 는 제공된 경우 &lt;code&gt;maxlen&lt;/code&gt; 인수이거나 그렇지 않은 경우 가장 긴 시퀀스의 길이입니다.</target>
        </trans-unit>
        <trans-unit id="c60464500521000032d7d0dd44fb1270d9c6691c" translate="yes" xml:space="preserve">
          <source>This function transforms a sequence of word indexes (list of integers) into tuples of words of the form:</source>
          <target state="translated">이 함수는 일련의 단어 색인 (정수 목록)을 다음 형식의 단어 튜플로 변환합니다.</target>
        </trans-unit>
        <trans-unit id="109cf8b58e8d5422a5502fb692567a43d8008aa5" translate="yes" xml:space="preserve">
          <source>This function transforms a string of text into a list of words while ignoring &lt;code&gt;filters&lt;/code&gt; which include punctuations by default.</source>
          <target state="translated">This function transforms a string of text into a list of words while ignoring &lt;code&gt;filters&lt;/code&gt; which include punctuations by default.</target>
        </trans-unit>
        <trans-unit id="0cf6cff1a07ce3f9dd6dd3457b8400fd6ba9faf8" translate="yes" xml:space="preserve">
          <source>This function uses substring matching, i.e. the matching succeeds if &lt;em&gt;any&lt;/em&gt; substring of the error message matches &lt;em&gt;any&lt;/em&gt; regex in the list. This is more convenient for the user than full-string matching.</source>
          <target state="translated">경우이 기능을 사용하는 하위 문자열 매칭, 즉 일치하는 성공 &lt;em&gt;어떤&lt;/em&gt; 오류 메시지의 문자열이 일치하는 &lt;em&gt;모든&lt;/em&gt; 목록에서 정규식. 이것은 전체 문자열 일치보다 사용자에게 더 편리합니다.</target>
        </trans-unit>
        <trans-unit id="6ea3c37a0724be70d72aba9456ec479ad3e1efd0" translate="yes" xml:space="preserve">
          <source>This function validates that &lt;code&gt;obj&lt;/code&gt; represents an element of this graph, and gives an informative error message if it is not.</source>
          <target state="translated">이 함수는 &lt;code&gt;obj&lt;/code&gt; 가이 그래프의 요소를 나타내는 지 확인하고 그렇지 않은 경우 유익한 오류 메시지를 제공합니다.</target>
        </trans-unit>
        <trans-unit id="5535ae7e49ad8d44ba9e9cbd32412f5d3383ba9d" translate="yes" xml:space="preserve">
          <source>This function will check the outermost context for the program and see if it is in eager mode. It is useful comparing to &lt;a href=&quot;../../executing_eagerly&quot;&gt;&lt;code&gt;tf.executing_eagerly()&lt;/code&gt;&lt;/a&gt;, which checks the current context and will return &lt;code&gt;False&lt;/code&gt; within a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; body. It can be used to build library that behave differently in eager runtime and v1 session runtime (deprecated).</source>
          <target state="translated">This function will check the outermost context for the program and see if it is in eager mode. It is useful comparing to &lt;a href=&quot;../../executing_eagerly&quot;&gt; &lt;code&gt;tf.executing_eagerly()&lt;/code&gt; &lt;/a&gt;, which checks the current context and will return &lt;code&gt;False&lt;/code&gt; within a &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; body. It can be used to build library that behave differently in eager runtime and v1 session runtime (deprecated).</target>
        </trans-unit>
        <trans-unit id="1b809c8513edcf65ff2e661e67bc392f776c9e7e" translate="yes" xml:space="preserve">
          <source>This function will create the global generator the first time it is called, and the generator will be placed at the default device at that time, so one needs to be careful when this function is first called. Using a generator placed on a less-ideal device will incur performance regression.</source>
          <target state="translated">This function will create the global generator the first time it is called, and the generator will be placed at the default device at that time, so one needs to be careful when this function is first called. Using a generator placed on a less-ideal device will incur performance regression.</target>
        </trans-unit>
        <trans-unit id="89bde45a9d6e8e699bac43f2a09b2f06fe6c3d12" translate="yes" xml:space="preserve">
          <source>This function will modify the tensors passed in as it adds more operations and hence changing the consumers of the operations of the input tensors.</source>
          <target state="translated">이 함수는 더 많은 작업을 추가하고 입력 텐서 작업의 소비자를 변경함에 따라 전달 된 텐서를 수정합니다.</target>
        </trans-unit>
        <trans-unit id="e4e12e3274ef470af1606308b5afb5383f0e4373" translate="yes" xml:space="preserve">
          <source>This function works on either a single image (&lt;code&gt;image&lt;/code&gt; is a 3-D Tensor), or a batch of images (&lt;code&gt;image&lt;/code&gt; is a 4-D Tensor).</source>
          <target state="translated">이 기능은 단일 이미지 ( &lt;code&gt;image&lt;/code&gt; 는 3 차원 텐서) 또는 이미지 묶음 ( &lt;code&gt;image&lt;/code&gt; 는 4 차원 텐서)에서 작동합니다.</target>
        </trans-unit>
        <trans-unit id="3bc4d91f81e39f3ea54e11412256f8f82c2a442a" translate="yes" xml:space="preserve">
          <source>This function wraps tensor placeholders in a supervised_receiver_fn with the expectation that the features and labels appear precisely as the model_fn expects them. Features and labels can therefore be dicts of tensors, or raw tensors.</source>
          <target state="translated">이 함수는 기능 및 레이블이 model_fn에서 예상 한대로 정확하게 표시 될 것으로 예상하여 supervised_receiver_fn에서 텐서 자리 표시자를 랩핑합니다. 따라서 기능 및 레이블은 텐서 또는 원시 텐서의 기준이 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="390f51be88bc027febcd4f2fc680ab5ff0ecb909" translate="yes" xml:space="preserve">
          <source>This functionality can be used to remap both row vocabularies (typically, features) and column vocabularies (typically, classes) from TensorFlow checkpoints. Note that the partitioning logic relies on contiguous vocabularies corresponding to div-partitioned variables. Moreover, the underlying remapping uses an IndexTable (as opposed to an inexact CuckooTable), so client code should use the corresponding index_table_from_file() as the FeatureColumn framework does (as opposed to tf.feature_to_id(), which uses a CuckooTable).</source>
          <target state="translated">This functionality can be used to remap both row vocabularies (typically, features) and column vocabularies (typically, classes) from TensorFlow checkpoints. Note that the partitioning logic relies on contiguous vocabularies corresponding to div-partitioned variables. Moreover, the underlying remapping uses an IndexTable (as opposed to an inexact CuckooTable), so client code should use the corresponding index_table_from_file() as the FeatureColumn framework does (as opposed to tf.feature_to_id(), which uses a CuckooTable).</target>
        </trans-unit>
        <trans-unit id="061aef760e659c96c1579128f6e2913f90a85e0a" translate="yes" xml:space="preserve">
          <source>This has the effect of transforming sliding window operations into the corresponding &quot;atrous&quot; operation in which the input is sampled at the specified &lt;code&gt;dilation_rate&lt;/code&gt;.</source>
          <target state="translated">이는 슬라이딩 윈도우 작업을 입력이 지정된 &lt;code&gt;dilation_rate&lt;/code&gt; 로 샘플링되는 해당 &quot;atrous&quot;작업으로 변환하는 효과가 있습니다.</target>
        </trans-unit>
        <trans-unit id="10c41b6251ef0bcbec27e5d4c8ebb2292ccebcaa" translate="yes" xml:space="preserve">
          <source>This helper method provides a higher-level alternative to using &lt;code&gt;tf.contrib.summary.summary_writer_initializer_op&lt;/code&gt; and &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt;.</source>
          <target state="translated">이 헬퍼 메소드는 &lt;code&gt;tf.contrib.summary.summary_writer_initializer_op&lt;/code&gt; 및 &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt; 사용에 대한 상위 레벨 대안을 제공합니다 .</target>
        </trans-unit>
        <trans-unit id="671c9eb768ee498e26815ceb625e7ee7c309f7e7" translate="yes" xml:space="preserve">
          <source>This hook delays execution until global step reaches to &lt;code&gt;wait_until_step&lt;/code&gt;. It is used to gradually start workers in distributed settings. One example usage would be setting &lt;code&gt;wait_until_step=int(K*log(task_id+1))&lt;/code&gt; assuming that task_id=0 is the chief.</source>
          <target state="translated">이 후크는 글로벌 단계가 &lt;code&gt;wait_until_step&lt;/code&gt; 에 도달 할 때까지 실행을 지연 시킵니다 . 분산 설정에서 작업자를 점진적으로 시작하는 데 사용됩니다. 한 가지 사용법의 예 는 task_id = 0이 최고라고 가정하고 wait_until_step = &lt;code&gt;wait_until_step=int(K*log(task_id+1))&lt;/code&gt; 하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="1a0fa0f63117915fa2c817fa42b4c67a4f5c8b33" translate="yes" xml:space="preserve">
          <source>This hook requests stop after either a number of steps have been executed or a last step has been reached. Only one of the two options can be specified.</source>
          <target state="translated">이 후크 요청은 여러 단계가 실행되었거나 마지막 단계에 도달 한 후에 중지됩니다. 두 옵션 중 하나만 지정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="29326e19d0dc3f4c325692b2b9f948f424da0e4f" translate="yes" xml:space="preserve">
          <source>This hook saves the state of the iterators in the &lt;code&gt;Graph&lt;/code&gt; so that when training is resumed the input pipeline continues from where it left off. This could potentially avoid overfitting in certain pipelines where the number of training steps per eval are small compared to the dataset size or if the training pipeline is pre-empted.</source>
          <target state="translated">이 후크는 훈련이 재개 될 때 입력 파이프 라인이 중단 된 지점부터 계속되도록 &lt;code&gt;Graph&lt;/code&gt; 반복기의 상태를 저장합니다 . 이는 데이터 세트 크기에 비해 평가 당 교육 단계 수가 적거나 교육 파이프 라인이 선점 된 경우 특정 파이프 라인에서 과적 합을 피할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="362202ba29e8d6beed9c2059ae03ede13f3cd76f" translate="yes" xml:space="preserve">
          <source>This hook should be used if the input pipeline state needs to be saved separate from the model checkpoint. Doing so may be useful for a few reasons:</source>
          <target state="translated">입력 파이프 라인 상태를 모델 체크 포인트와 별도로 저장해야하는 경우이 후크를 사용해야합니다. 그렇게하는 것이 몇 가지 이유로 유용 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="b6ae1f6a6bb162ce4153046b8500ec1c1479c758" translate="yes" xml:space="preserve">
          <source>This identifies the replica that is part of a sync group. Currently we assume that all sync groups contain the same number of replicas. The value of the replica id can range from 0 to &lt;code&gt;num_replica_in_sync&lt;/code&gt; - 1.</source>
          <target state="translated">동기화 그룹의 일부인 복제본을 식별합니다. 현재 모든 동기화 그룹에 동일한 수의 복제본이 있다고 가정합니다. 복제본 ID 값의 범위는 0에서 &lt;code&gt;num_replica_in_sync&lt;/code&gt; -1입니다.</target>
        </trans-unit>
        <trans-unit id="1b29036c26df39b1ea3c52cbf28f86f795fcf9f0" translate="yes" xml:space="preserve">
          <source>This implementation is based off of the Cephes math library.</source>
          <target state="translated">This implementation is based off of the Cephes math library.</target>
        </trans-unit>
        <trans-unit id="3f20df5d52794499c7d70f58fc604ea383aee58e" translate="yes" xml:space="preserve">
          <source>This implementation is to be used in conjunction of BlockLSTMV2.</source>
          <target state="translated">This implementation is to be used in conjunction of BlockLSTMV2.</target>
        </trans-unit>
        <trans-unit id="e4e20691c6271c3052db6329ff09bab3c3926f92" translate="yes" xml:space="preserve">
          <source>This implementation is to be used in conjunction of LSTMBlock.</source>
          <target state="translated">This implementation is to be used in conjunction of LSTMBlock.</target>
        </trans-unit>
        <trans-unit id="2023d65f880c26efdc064ba734473728a5acce91" translate="yes" xml:space="preserve">
          <source>This implementation is to be used in conjunction of LSTMBlockCell.</source>
          <target state="translated">This implementation is to be used in conjunction of LSTMBlockCell.</target>
        </trans-unit>
        <trans-unit id="ecd5efd797cabcd540fdce983afef271dcb8292a" translate="yes" xml:space="preserve">
          <source>This implementation of RMSprop uses plain momentum, not Nesterov momentum.</source>
          <target state="translated">이 RMSprop 구현은 Nesterov 모멘텀이 아닌 일반 모멘텀을 사용합니다.</target>
        </trans-unit>
        <trans-unit id="32650114feea17cac9bd97ba7f3acc193158dc56" translate="yes" xml:space="preserve">
          <source>This implementation uses 1 weight matrix and 1 bias vector, and there's an optional peephole connection.</source>
          <target state="translated">This implementation uses 1 weight matrix and 1 bias vector, and there's an optional peephole connection.</target>
        </trans-unit>
        <trans-unit id="69398f914b35c5353b93476810576462db6eec45" translate="yes" xml:space="preserve">
          <source>This implements the anisotropic 2-D version of the formula described here:</source>
          <target state="translated">여기에 설명 된 이방성 2-D 버전의 수식이 구현됩니다.</target>
        </trans-unit>
        <trans-unit id="cd31200075bd4a5cc039e35e154eab86539a7999" translate="yes" xml:space="preserve">
          <source>This improves training speed. Please see &lt;code&gt;optimization_parameters.proto&lt;/code&gt; for details.</source>
          <target state="translated">This improves training speed. Please see &lt;code&gt;optimization_parameters.proto&lt;/code&gt; for details.</target>
        </trans-unit>
        <trans-unit id="eaa40933c0c7c31f3c54363539d17de16903a6ff" translate="yes" xml:space="preserve">
          <source>This includes ops from TF 2.0 tf.summary and TF 1.x tf.contrib.summary (except for &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt; and &lt;code&gt;tf.contrib.summary.import_event&lt;/code&gt;), but does &lt;em&gt;not&lt;/em&gt; include TF 1.x tf.summary ops.</source>
          <target state="translated">여기에는 TF 2.0 tf.summary 및 TF 1.x tf.contrib.summary ( &lt;code&gt;tf.contrib.summary.graph&lt;/code&gt; 및 &lt;code&gt;tf.contrib.summary.import_event&lt;/code&gt; 제외 )의 op 가 포함 되지만 TF 1.x는 포함 되지 &lt;em&gt;않습니다.&lt;/em&gt; 작전.</target>
        </trans-unit>
        <trans-unit id="2cbffbf5b87e7d08406cd7f76d2f7936c22b5d07" translate="yes" xml:space="preserve">
          <source>This includes the operations to synchronize replicas: aggregate gradients, apply to variables, increment global step, insert tokens to token queue.</source>
          <target state="translated">여기에는 복제본 동기화 작업 (그라데이션 집계, 변수에 적용, 전역 단계 증가, 토큰을 토큰 대기열에 삽입)이 포함됩니다.</target>
        </trans-unit>
        <trans-unit id="dc77baa2dba67576cde30b92064b3afa6abe84f1" translate="yes" xml:space="preserve">
          <source>This induces quasi-linear speedup on up to 8 GPUs.</source>
          <target state="translated">이는 최대 8 개의 GPU에서 준 선형 속도 향상을 유도합니다.</target>
        </trans-unit>
        <trans-unit id="9e91bcd2748922b865fbdb3c28f16a3f92c87b0e" translate="yes" xml:space="preserve">
          <source>This initializer assigns one entry in the table for each line in the file.</source>
          <target state="translated">이 이니셜 라이저는 파일의 각 줄에 대해 하나의 항목을 테이블에 할당합니다.</target>
        </trans-unit>
        <trans-unit id="93a30392533a2023857f78a57a8100de69db56b7" translate="yes" xml:space="preserve">
          <source>This initializes a new Kubernetes ClusterResolver. The ClusterResolver will attempt to talk to the Kubernetes master to retrieve all the instances of pods matching a label selector.</source>
          <target state="translated">새로운 Kubernetes ClusterResolver가 초기화됩니다. ClusterResolver는 Kubernetes 마스터와 대화하여 레이블 선택기와 일치하는 모든 포드 인스턴스를 검색합니다.</target>
        </trans-unit>
        <trans-unit id="ded15c2fc6dc030fcd9627bdc75c00460c2cb65d" translate="yes" xml:space="preserve">
          <source>This is (mostly) a special case of &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt; where &lt;code&gt;bias&lt;/code&gt; is restricted to 1-D. Broadcasting is supported, so &lt;code&gt;value&lt;/code&gt; may have any number of dimensions. Unlike &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt;, the type of &lt;code&gt;bias&lt;/code&gt; is allowed to differ from &lt;code&gt;value&lt;/code&gt; in the case where both types are quantized.</source>
          <target state="translated">이 (주로)의 특별한 경우이다 &lt;a href=&quot;../math/add&quot;&gt; &lt;code&gt;tf.add&lt;/code&gt; &lt;/a&gt; &lt;code&gt;bias&lt;/code&gt; 1-D로 제한된다. 브로드 캐스팅이 지원되므로 &lt;code&gt;value&lt;/code&gt; 은 여러 차원을 가질 수 있습니다. 달리 &lt;a href=&quot;../math/add&quot;&gt; &lt;code&gt;tf.add&lt;/code&gt; &lt;/a&gt; 의 입력 &lt;code&gt;bias&lt;/code&gt; 다를 수있다 &lt;code&gt;value&lt;/code&gt; 두 종류가 양자화되는 경우.</target>
        </trans-unit>
        <trans-unit id="9f67d123191520f4a8994999dc8cd88f7fe320b7" translate="yes" xml:space="preserve">
          <source>This is EXPERIMENTAL and subject to change.</source>
          <target state="translated">이것은 실험적인 것이며 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="02f8d625292f24a8f6fa6d8a843ae5c003159e97" translate="yes" xml:space="preserve">
          <source>This is a class method that describes what key/value arguments are required to instantiate the given &lt;code&gt;Distribution&lt;/code&gt; so that a particular shape is returned for that instance's call to &lt;code&gt;sample()&lt;/code&gt;.</source>
          <target state="translated">이것은 주어진 &lt;code&gt;Distribution&lt;/code&gt; 을 인스턴스화하기 위해 어떤 키 / 값 인수가 필요한지를 설명하는 클래스 메소드 로, &lt;code&gt;sample()&lt;/code&gt; 대한 해당 인스턴스 호출에 대해 특정 형태가 리턴됩니다 .</target>
        </trans-unit>
        <trans-unit id="012a7836bd88d1e3c2c595506564d4812be83ba5" translate="yes" xml:space="preserve">
          <source>This is a class method that describes what key/value arguments are required to instantiate the given &lt;code&gt;Distribution&lt;/code&gt; so that a particular shape is returned for that instance's call to &lt;code&gt;sample()&lt;/code&gt;. Assumes that the sample's shape is known statically.</source>
          <target state="translated">이것은 주어진 &lt;code&gt;Distribution&lt;/code&gt; 을 인스턴스화하기 위해 어떤 키 / 값 인수가 필요한지를 설명하는 클래스 메소드 로, &lt;code&gt;sample()&lt;/code&gt; 대한 해당 인스턴스 호출에 대해 특정 형태가 리턴됩니다 . 샘플의 모양이 정적으로 알려져 있다고 가정합니다.</target>
        </trans-unit>
        <trans-unit id="fead40a760af2fb3753f3e33415c41be437e055a" translate="yes" xml:space="preserve">
          <source>This is a companion method to &lt;code&gt;add_queue_runner()&lt;/code&gt;. It just starts threads for all queue runners collected in the graph. It returns the list of all threads.</source>
          <target state="translated">이것은 &lt;code&gt;add_queue_runner()&lt;/code&gt; 대한 동반 메소드 입니다. 그래프에서 수집 된 모든 큐 러너의 스레드 만 시작합니다. 모든 스레드 목록을 리턴합니다.</target>
        </trans-unit>
        <trans-unit id="9590afd024cc456ab84ee4d2f95cabc25b5ebe3a" translate="yes" xml:space="preserve">
          <source>This is a context class that is passed to the &lt;code&gt;value_fn&lt;/code&gt; in &lt;code&gt;strategy.experimental_distribute_values_from_function&lt;/code&gt; and contains information about the compute replicas. The &lt;code&gt;num_replicas_in_sync&lt;/code&gt; and &lt;code&gt;replica_id&lt;/code&gt; can be used to customize the value on each replica.</source>
          <target state="translated">This is a context class that is passed to the &lt;code&gt;value_fn&lt;/code&gt; in &lt;code&gt;strategy.experimental_distribute_values_from_function&lt;/code&gt; and contains information about the compute replicas. The &lt;code&gt;num_replicas_in_sync&lt;/code&gt; and &lt;code&gt;replica_id&lt;/code&gt; can be used to customize the value on each replica.</target>
        </trans-unit>
        <trans-unit id="309ae6e7b107ea04158b03fa5671cc2764a5cdf7" translate="yes" xml:space="preserve">
          <source>This is a context class that is passed to the user's input function and contains information about the compute replicas and input pipelines. The number of compute replicas (in sync training) helps compute the local batch size from the desired global batch size for each replica. The input pipeline information can be used to return a different subset of the input in each replica (for e.g. shard the input pipeline, use a different input source etc).</source>
          <target state="translated">이는 사용자의 입력 함수에 전달되는 컨텍스트 클래스이며 계산 복제본 및 입력 파이프 라인에 대한 정보를 포함합니다. 계산 복제본의 수 (동기 훈련)는 각 복제본에 대해 원하는 전역 배치 크기에서 로컬 배치 크기를 계산하는 데 도움이됩니다. 입력 파이프 라인 정보는 각 복제본에서 입력의 다른 서브 세트를 리턴하는 데 사용될 수 있습니다 (예 : 입력 파이프 라인의 샤드, 다른 입력 소스 사용 등).</target>
        </trans-unit>
        <trans-unit id="1659a3286a3bedb8cf721b60523b4bfde4d51caf" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts RGB images to float representation, adjusts their brightness, and then converts them back to the original data type. If several adjustments are chained, it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고 밝기를 조정 한 다음 다시 원래 데이터 형식으로 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="7bcc711030b8e6b303b05fbb2eadad7a51295960" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts RGB images to float representation, adjusts their contrast, and then converts them back to the original data type. If several adjustments are chained, it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고 대비를 조정 한 다음 다시 원래 데이터 형식으로 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="689582a22623e8b58ba6e0ed65682c48dc03d8f0" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts RGB images to float representation, converts them to HSV, add an offset to the saturation channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고, HSV로 변환하고, 채도 채널에 오프셋을 추가하고, 다시 RGB로 변환 한 다음 원래 데이터 유형으로 다시 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="154fc7928cd01964ea2a05b16a1fbc2cadc62c3b" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts RGB images to float representation, converts them to HSV, adds an offset to the saturation channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">This is a convenience method that converts RGB images to float representation, converts them to HSV, adds an offset to the saturation channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</target>
        </trans-unit>
        <trans-unit id="157983bd7b4bf865fccf95ec9e2bc8ddd381392d" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts an RGB image to float representation, converts it to HSV, add an offset to the hue channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">이것은 RGB 이미지를 부동 표현으로 변환하고, HSV로 변환하고, 색조 채널에 오프셋을 추가하고, 다시 RGB로 변환 한 다음 원래 데이터 유형으로 다시 변환하는 편리한 방법입니다. 여러 조정이 연결되어있는 경우 중복 변환 수를 최소화하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="bc1addde10acbe587836014417c1c886ecf1e9cf" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts an RGB image to float representation, converts it to HSV, adds an offset to the hue channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</source>
          <target state="translated">This is a convenience method that converts an RGB image to float representation, converts it to HSV, adds an offset to the hue channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.</target>
        </trans-unit>
        <trans-unit id="8b85cb6fb2b17c1cfe1f8becbb4b4eeadf576adb" translate="yes" xml:space="preserve">
          <source>This is a convenience method that converts an image to uint8 representation, encodes it to jpeg with &lt;code&gt;jpeg_quality&lt;/code&gt;, decodes it, and then converts back to the original data type.</source>
          <target state="translated">이것은 이미지를 uint8 표현으로 변환하고 &lt;code&gt;jpeg_quality&lt;/code&gt; 를 사용하여 jpeg로 인코딩 한 다음 디코딩 한 다음 원래 데이터 유형으로 다시 변환하는 편리한 방법입니다 .</target>
        </trans-unit>
        <trans-unit id="040dbe98920d5a5c1090b8783413f490c3abe113" translate="yes" xml:space="preserve">
          <source>This is a convenience utility for packing data into the tuple formats that &lt;a href=&quot;../model#fit&quot;&gt;&lt;code&gt;Model.fit&lt;/code&gt;&lt;/a&gt; uses.</source>
          <target state="translated">This is a convenience utility for packing data into the tuple formats that &lt;a href=&quot;../model#fit&quot;&gt; &lt;code&gt;Model.fit&lt;/code&gt; &lt;/a&gt; uses.</target>
        </trans-unit>
        <trans-unit id="177a96552c22761995fc2a02f86657fdf66dd73d" translate="yes" xml:space="preserve">
          <source>This is a convenience utility to be used when overriding &lt;a href=&quot;../model#train_step&quot;&gt;&lt;code&gt;Model.train_step&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../model#test_step&quot;&gt;&lt;code&gt;Model.test_step&lt;/code&gt;&lt;/a&gt;, or &lt;a href=&quot;../model#predict_step&quot;&gt;&lt;code&gt;Model.predict_step&lt;/code&gt;&lt;/a&gt;. This utility makes it easy to support data of the form &lt;code&gt;(x,)&lt;/code&gt;, &lt;code&gt;(x, y)&lt;/code&gt;, or &lt;code&gt;(x, y, sample_weight)&lt;/code&gt;.</source>
          <target state="translated">This is a convenience utility to be used when overriding &lt;a href=&quot;../model#train_step&quot;&gt; &lt;code&gt;Model.train_step&lt;/code&gt; &lt;/a&gt;, &lt;a href=&quot;../model#test_step&quot;&gt; &lt;code&gt;Model.test_step&lt;/code&gt; &lt;/a&gt;, or &lt;a href=&quot;../model#predict_step&quot;&gt; &lt;code&gt;Model.predict_step&lt;/code&gt; &lt;/a&gt;. This utility makes it easy to support data of the form &lt;code&gt;(x,)&lt;/code&gt; , &lt;code&gt;(x, y)&lt;/code&gt; , or &lt;code&gt;(x, y, sample_weight)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c0b259f9b8e5db6abf1f7ca2cc64744a095dde1b" translate="yes" xml:space="preserve">
          <source>This is a dataset of 11,228 newswires from Reuters, labeled over 46 topics.</source>
          <target state="translated">This is a dataset of 11,228 newswires from Reuters, labeled over 46 topics.</target>
        </trans-unit>
        <trans-unit id="768eb884c8ee5b48b0c147f90ce4407a6a9884da" translate="yes" xml:space="preserve">
          <source>This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer &quot;3&quot; encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: &quot;only consider the top 10,000 most common words, but eliminate the top 20 most common words&quot;.</source>
          <target state="translated">This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer &quot;3&quot; encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: &quot;only consider the top 10,000 most common words, but eliminate the top 20 most common words&quot;.</target>
        </trans-unit>
        <trans-unit id="e86bf0041eb6fb31b4e9ede482e55b7d43a98c80" translate="yes" xml:space="preserve">
          <source>This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories. See more info at the &lt;a href=&quot;https://www.cs.toronto.edu/%7Ekriz/cifar.html&quot;&gt;CIFAR homepage&lt;/a&gt;.</source>
          <target state="translated">This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories. See more info at the &lt;a href=&quot;https://www.cs.toronto.edu/%7Ekriz/cifar.html&quot;&gt;CIFAR homepage&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="435f80948690367d77e0f3784d30df76f7f3d98a" translate="yes" xml:space="preserve">
          <source>This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 100 fine-grained classes that are grouped into 20 coarse-grained classes. See more info at the &lt;a href=&quot;https://www.cs.toronto.edu/%7Ekriz/cifar.html&quot;&gt;CIFAR homepage&lt;/a&gt;.</source>
          <target state="translated">This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 100 fine-grained classes that are grouped into 20 coarse-grained classes. See more info at the &lt;a href=&quot;https://www.cs.toronto.edu/%7Ekriz/cifar.html&quot;&gt;CIFAR homepage&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="33a8fb4dd54ee096f6f9e8b6100e0ded183914c6" translate="yes" xml:space="preserve">
          <source>This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:</source>
          <target state="translated">This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:</target>
        </trans-unit>
        <trans-unit id="e30665bff921b2720a3a63831af563bf188d5b46" translate="yes" xml:space="preserve">
          <source>This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. More info can be found at the &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot;&gt;MNIST homepage&lt;/a&gt;.</source>
          <target state="translated">This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. More info can be found at the &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot;&gt;MNIST homepage&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="710ac221d7447de49c2c2452f75596e4bb685c1c" translate="yes" xml:space="preserve">
          <source>This is a dataset taken from the StatLib library which is maintained at Carnegie Mellon University.</source>
          <target state="translated">This is a dataset taken from the StatLib library which is maintained at Carnegie Mellon University.</target>
        </trans-unit>
        <trans-unit id="ab28ad9476b59e4ae1d47c731d1e80592c84261d" translate="yes" xml:space="preserve">
          <source>This is a deprecated version of &lt;code&gt;fractional_avg_pool&lt;/code&gt;.</source>
          <target state="translated">이것은 사용되지 않는 &lt;code&gt;fractional_avg_pool&lt;/code&gt; 버전입니다 .</target>
        </trans-unit>
        <trans-unit id="89fac60f109fd0365fd768e5b0c1efda980aac29" translate="yes" xml:space="preserve">
          <source>This is a deprecated version of &lt;code&gt;fractional_max_pool&lt;/code&gt;.</source>
          <target state="translated">이것은 사용되지 않는 &lt;code&gt;fractional_max_pool&lt;/code&gt; 버전입니다 .</target>
        </trans-unit>
        <trans-unit id="ec0b5065eeff136feb43dbfad07e272612b79d8c" translate="yes" xml:space="preserve">
          <source>This is a deprecated version of BiasAdd and will be soon removed.</source>
          <target state="translated">This is a deprecated version of BiasAdd and will be soon removed.</target>
        </trans-unit>
        <trans-unit id="066f7ab7935722a8bd3e79702ee438f7b2aad916" translate="yes" xml:space="preserve">
          <source>This is a difference between DatasetV1 and DatasetV2. DatasetV1 does not take anything in its constructor whereas in the DatasetV2, we expect subclasses to create a variant_tensor and pass it in to the super() call.</source>
          <target state="translated">이것은 DatasetV1과 DatasetV2의 차이점입니다. DatasetV1은 생성자에서 아무것도 가져 오지 않지만 DatasetV2에서는 하위 클래스가 variant_tensor를 만들어 super () 호출에 전달할 것으로 예상합니다.</target>
        </trans-unit>
        <trans-unit id="e7c85e6a460e7ff32a9089528b0d0f38042adaa0" translate="yes" xml:space="preserve">
          <source>This is a faster way to train a softmax classifier over a huge number of classes.</source>
          <target state="translated">이것은 많은 수의 클래스에서 softmax 분류기를 훈련시키는 가장 빠른 방법입니다.</target>
        </trans-unit>
        <trans-unit id="d7e11ee2edab133ca8b8374faafd78e7821ed539" translate="yes" xml:space="preserve">
          <source>This is a legacy behaviour of TensorFlow and is highly discouraged.</source>
          <target state="translated">이것은 TensorFlow의 레거시 동작이며 사용하지 않는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="a3be19c517fb6a6f6742dcaed9be8bb79e5a6a4d" translate="yes" xml:space="preserve">
          <source>This is a legacy version of the more general BatchToSpaceND.</source>
          <target state="translated">이것은보다 일반적인 BatchToSpaceND의 레거시 버전입니다.</target>
        </trans-unit>
        <trans-unit id="c2584be3bd38ee90f3ac17e87b40fd5fb1908bdb" translate="yes" xml:space="preserve">
          <source>This is a legacy version of the more general SpaceToBatchND.</source>
          <target state="translated">이것은 일반적인 SpaceToBatchND의 레거시 버전입니다.</target>
        </trans-unit>
        <trans-unit id="c0ae3cb7ef651d4c8fb957d4b4823d4c0713533f" translate="yes" xml:space="preserve">
          <source>This is a low-level interface for creating an &lt;code&gt;Operation&lt;/code&gt;. Most programs will not call this method directly, and instead use the Python op constructors, such as &lt;a href=&quot;constant&quot;&gt;&lt;code&gt;tf.constant()&lt;/code&gt;&lt;/a&gt;, which add ops to the default graph.</source>
          <target state="translated">이것은 &lt;code&gt;Operation&lt;/code&gt; 을 작성하기위한 저수준 인터페이스입니다 . 대부분의 프로그램은이 메소드를 직접 호출하지 않고 대신 기본 그래프에 op를 추가하는 &lt;a href=&quot;constant&quot;&gt; &lt;code&gt;tf.constant()&lt;/code&gt; &lt;/a&gt; 와 같은 Python op 생성자를 사용합니다 .</target>
        </trans-unit>
        <trans-unit id="1cd850dc655362d680df73debd3d92a42edd1883" translate="yes" xml:space="preserve">
          <source>This is a method that implementers of subclasses of &lt;code&gt;Layer&lt;/code&gt; or &lt;code&gt;Model&lt;/code&gt; can override if they need a state-creation step in-between layer instantiation and layer call.</source>
          <target state="translated">&lt;code&gt;Layer&lt;/code&gt; 또는 &lt;code&gt;Model&lt;/code&gt; 의 서브 클래스 구현자가 레이어 인스턴스화와 레이어 호출 사이에 상태 생성 단계가 필요한 경우 재정의 할 수 있는 방법입니다 .</target>
        </trans-unit>
        <trans-unit id="62c4042c7b665a4296b8d1a943304048eb64aec7" translate="yes" xml:space="preserve">
          <source>This is a nonzero integer. See the get_ident() function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited.</source>
          <target state="translated">이것은 0이 아닌 정수입니다. get_ident () 함수를 참조하십시오. 스레드 식별자는 스레드가 종료되고 다른 스레드가 작성 될 때 재활용 될 수 있습니다. 스레드가 종료 된 후에도 식별자를 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="31eb573dcb4f05e127842ce7a2c523b4f9fd2e61" translate="yes" xml:space="preserve">
          <source>This is a reduction created for Nvidia DGX-1 which assumes GPUs connects like that on DGX-1 machine. If you have different GPU inter-connections, it is likely that it would be slower than &lt;a href=&quot;reductiontoonedevice&quot;&gt;&lt;code&gt;tf.distribute.ReductionToOneDevice&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">이것은 GPU가 DGX-1 시스템에서와 같이 연결되는 것으로 가정하는 Nvidia DGX-1을 위해 작성된 축소입니다. 다른 GPU 상호 연결이있는 경우 &lt;a href=&quot;reductiontoonedevice&quot;&gt; &lt;code&gt;tf.distribute.ReductionToOneDevice&lt;/code&gt; &lt;/a&gt; 보다 느릴 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="85f7e8c05b61af3e5451f6e510d0b0985383c1d8" translate="yes" xml:space="preserve">
          <source>This is a special case of &lt;a href=&quot;../math/add&quot;&gt;&lt;code&gt;tf.add&lt;/code&gt;&lt;/a&gt; where &lt;code&gt;bias&lt;/code&gt; is restricted to be 1-D. Broadcasting is supported, so &lt;code&gt;value&lt;/code&gt; may have any number of dimensions.</source>
          <target state="translated">This is a special case of &lt;a href=&quot;../math/add&quot;&gt; &lt;code&gt;tf.add&lt;/code&gt; &lt;/a&gt; where &lt;code&gt;bias&lt;/code&gt; is restricted to be 1-D. Broadcasting is supported, so &lt;code&gt;value&lt;/code&gt; may have any number of dimensions.</target>
        </trans-unit>
        <trans-unit id="cbdbb1332709a943bc7d0db1d68caf76c3a99f69" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;../../../random/categorical&quot;&gt;&lt;code&gt;tf.random.categorical&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;a href=&quot;../../../random/categorical&quot;&gt; &lt;code&gt;tf.random.categorical&lt;/code&gt; &lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="81cb44c6cca42a31a07fbae208fd1a7a56619cfa" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;../../../random/categorical&quot;&gt;&lt;code&gt;tf.random.categorical&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;../../../random/categorical&quot;&gt; &lt;code&gt;tf.random.categorical&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="de68a47b12e07130e567ec24bb61927f4f535092" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;gamma&quot;&gt;&lt;code&gt;tf.random.gamma&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;a href=&quot;gamma&quot;&gt; &lt;code&gt;tf.random.gamma&lt;/code&gt; &lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="d527e38ee04e494f8d4e9909ef23824c02f218d2" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;generator#binomial&quot;&gt;&lt;code&gt;tf.random.Generator.binomial&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;a href=&quot;generator#binomial&quot;&gt; &lt;code&gt;tf.random.Generator.binomial&lt;/code&gt; &lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="1f9d7559f26ce2def191894981d83e7101b4893f" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;normal&quot;&gt;&lt;code&gt;tf.random.normal&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;a href=&quot;normal&quot;&gt; &lt;code&gt;tf.random.normal&lt;/code&gt; &lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="812a072511f22cc831859b50e28ff4fe62133693" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;normal&quot;&gt;&lt;code&gt;tf.random.normal&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;normal&quot;&gt; &lt;code&gt;tf.random.normal&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="eb02c3777bd174779389bb97e4e8d5e8436a288c" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;poisson&quot;&gt;&lt;code&gt;tf.random.poisson&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware, but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;a href=&quot;poisson&quot;&gt; &lt;code&gt;tf.random.poisson&lt;/code&gt; &lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware, but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="4ca51d036bc29518d8577d5bfc5e3dc7a0421db6" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;truncated_normal&quot;&gt;&lt;code&gt;tf.random.truncated_normal&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;a href=&quot;truncated_normal&quot;&gt; &lt;code&gt;tf.random.truncated_normal&lt;/code&gt; &lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="dd6096e0d7eff9f42170cc05a1fe61ba85be91f4" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;truncated_normal&quot;&gt;&lt;code&gt;tf.random.truncated_normal&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;truncated_normal&quot;&gt; &lt;code&gt;tf.random.truncated_normal&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="ac72baa117d9b4a5bdf610d359eb9848fb6723ce" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="7b120804ac2994699c2b37663ac0990fd63dfd70" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;a href=&quot;uniform&quot;&gt;&lt;code&gt;tf.random.uniform&lt;/code&gt;&lt;/a&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;a href=&quot;uniform&quot;&gt; &lt;code&gt;tf.random.uniform&lt;/code&gt; &lt;/a&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="93abfee5707aabda372725092df92726179f4164" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;code&gt;tf.categorical&lt;/code&gt;: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">This is a stateless version of &lt;code&gt;tf.categorical&lt;/code&gt; : if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</target>
        </trans-unit>
        <trans-unit id="ada11b1aaca11d67319d958bd7d1da13f15ebb7f" translate="yes" xml:space="preserve">
          <source>This is a stateless version of &lt;code&gt;tf.categorical&lt;/code&gt;: if run twice with the same seeds, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</source>
          <target state="translated">이것은 &lt;code&gt;tf.categorical&lt;/code&gt; 의 상태 비 저장 버전입니다 . 동일한 시드로 두 번 실행하면 동일한 의사 난수가 생성됩니다. 출력은 동일한 하드웨어 (및 CPU와 GPU 간)의 여러 실행에서 일관되지만 TensorFlow 버전 또는 비 CPU / GPU 하드웨어간에 변경 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="9603abb8f073d177d05702e0bc2ac4de5a04a74c" translate="yes" xml:space="preserve">
          <source>This is a wrapper to the &lt;code&gt;hashing_trick&lt;/code&gt; function using &lt;code&gt;hash&lt;/code&gt; as the hashing function; unicity of word to index mapping non-guaranteed.</source>
          <target state="translated">해시 함수로 &lt;code&gt;hash&lt;/code&gt; 를 사용 하는 &lt;code&gt;hashing_trick&lt;/code&gt; 함수 의 래퍼입니다 . 보장되지 않은 단어 대 인덱스 매핑의 단일성.</target>
        </trans-unit>
        <trans-unit id="5b00a32a0d99275c6a4a177506328b41e8a5cbe9" translate="yes" xml:space="preserve">
          <source>This is almost identical to QuantizeAndDequantizeV2, except that num_bits is a tensor, so its value can change during training.</source>
          <target state="translated">This is almost identical to QuantizeAndDequantizeV2, except that num_bits is a tensor, so its value can change during training.</target>
        </trans-unit>
        <trans-unit id="ac7a813777192ceaa721f12e2b167eefa5ce19d7" translate="yes" xml:space="preserve">
          <source>This is always checked statically, so this method returns nothing.</source>
          <target state="translated">항상 정적으로 검사되므로이 메소드는 아무 것도 반환하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="edf37ccd5d1846dec567da6f67dc930901f7907c" translate="yes" xml:space="preserve">
          <source>This is an abstract base class, so you cannot instantiate it directly. Instead, use one of its concrete subclasses:</source>
          <target state="translated">This is an abstract base class, so you cannot instantiate it directly. Instead, use one of its concrete subclasses:</target>
        </trans-unit>
        <trans-unit id="acb8330008d86d94ea39351a6992d0b396765e55" translate="yes" xml:space="preserve">
          <source>This is an abstract class which allows extensions to TensorFlow's object-based checkpointing (see &lt;a href=&quot;../checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;). For example a wrapper for NumPy arrays:</source>
          <target state="translated">이 클래스는 TensorFlow의 객체 기반 검사 점에 대한 확장을 허용하는 추상 클래스입니다 ( &lt;a href=&quot;../checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; 참조 ). 예를 들어 NumPy 배열의 래퍼는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="f0c3e68e0358a0f76609938022081ba5ccf573dd" translate="yes" xml:space="preserve">
          <source>This is an experimental op for internal use only and it is possible to use this op in unsafe ways. DO NOT USE unless you fully understand the risks.</source>
          <target state="translated">This is an experimental op for internal use only and it is possible to use this op in unsafe ways. DO NOT USE unless you fully understand the risks.</target>
        </trans-unit>
        <trans-unit id="8bbaa33b6f8b11a0355ba861cdf03d3e08622a92" translate="yes" xml:space="preserve">
          <source>This is an identity op (behaves like &lt;a href=&quot;../../identity&quot;&gt;&lt;code&gt;tf.identity&lt;/code&gt;&lt;/a&gt;) with the side effect of printing &lt;code&gt;data&lt;/code&gt; when evaluating.</source>
          <target state="translated">이것은 평가할 때 &lt;code&gt;data&lt;/code&gt; 를 인쇄하는 부작용 이있는 ID op ( &lt;a href=&quot;../../identity&quot;&gt; &lt;code&gt;tf.identity&lt;/code&gt; &lt;/a&gt; 와 동일 함 )입니다 .</target>
        </trans-unit>
        <trans-unit id="5c9b3651662523b2ca2e5016d6f25cb9aff58541" translate="yes" xml:space="preserve">
          <source>This is an implementation of ClusterResolver for Slurm clusters. This allows the specification of jobs and task counts, number of tasks per node, number of GPUs on each node and number of GPUs for each task. It retrieves system attributes by Slurm environment variables, resolves allocated computing node names, constructs a cluster and returns a ClusterResolver object which can be used for distributed TensorFlow.</source>
          <target state="translated">This is an implementation of ClusterResolver for Slurm clusters. This allows the specification of jobs and task counts, number of tasks per node, number of GPUs on each node and number of GPUs for each task. It retrieves system attributes by Slurm environment variables, resolves allocated computing node names, constructs a cluster and returns a ClusterResolver object which can be used for distributed TensorFlow.</target>
        </trans-unit>
        <trans-unit id="04be17d14e8556e45ddfd971016c00de8c4f5796" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for Kubernetes. When given the the Kubernetes namespace and label selector for pods, we will retrieve the pod IP addresses of all running pods matching the selector, and return a ClusterSpec based on that information.</source>
          <target state="translated">이것은 Kubernetes에 대한 클러스터 리졸버의 구현입니다. 포드에 대한 Kubernetes 네임 스페이스 및 레이블 선택기가 제공되면 선택기와 일치하는 모든 실행중인 포드의 포드 IP 주소를 검색하고 해당 정보를 기반으로 ClusterSpec을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="fbfdd6a723bd3e94666f26590d4249971ef2fb48" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for Slurm clusters. This allows the specification of jobs and task counts, number of tasks per node, number of GPUs on each node and number of GPUs for each task. It retrieves system attributes by Slurm environment variables, resolves allocated computing node names, constructs a cluster and returns a ClusterResolver object which can be use for distributed TensorFlow.</source>
          <target state="translated">이것은 Slurm 클러스터에 대한 클러스터 리졸버의 구현입니다. 이를 통해 작업 및 작업 수, 노드 당 작업 수, 각 노드의 GPU 수 및 각 작업의 GPU 수를 지정할 수 있습니다. Slurm 환경 변수로 시스템 속성을 검색하고 할당 된 컴퓨팅 노드 이름을 확인하며 클러스터를 구성하고 분산 TensorFlow에 사용할 수있는 ClusterResolver 객체를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="6c7332a1bfb936db2e58085e5162712580a9aab8" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for the Google Cloud TPU service.</source>
          <target state="translated">This is an implementation of cluster resolvers for the Google Cloud TPU service.</target>
        </trans-unit>
        <trans-unit id="71688349367e3a46bf633affe83f7f67a539cf79" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for the Google Cloud TPU service. As Cloud TPUs are in alpha, you will need to specify a API definition file for this to consume, in addition to a list of Cloud TPUs in your Google Cloud Platform project.</source>
          <target state="translated">Google Cloud TPU 서비스에 대한 클러스터 확인 자의 구현입니다. Cloud TPU가 알파이므로 Google Cloud Platform 프로젝트의 Cloud TPU 목록과 함께 사용할 API 정의 파일을 지정해야합니다.</target>
        </trans-unit>
        <trans-unit id="ad683e8f469fc31a1a6f2ec923965536267cfedf" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers for the Google Compute Engine instance group platform. By specifying a project, zone, and instance group, this will retrieve the IP address of all the instances within the instance group and return a ClusterResolver object suitable for use for distributed TensorFlow.</source>
          <target state="translated">Google Compute Engine 인스턴스 그룹 플랫폼을위한 클러스터 리졸버 구현입니다. 프로젝트, 영역 및 인스턴스 그룹을 지정하면 인스턴스 그룹 내의 모든 인스턴스의 IP 주소를 검색하고 분산 TensorFlow에 사용하기 적합한 ClusterResolver 객체를 반환합니다.</target>
        </trans-unit>
        <trans-unit id="a371677e8e3150f82fcdcb41fbdf4b2aece50db2" translate="yes" xml:space="preserve">
          <source>This is an implementation of cluster resolvers when using TF_CONFIG to set information about the cluster. The cluster spec returned will be initialized from the TF_CONFIG environment variable.</source>
          <target state="translated">이것은 TF_CONFIG를 사용하여 클러스터에 대한 정보를 설정할 때 클러스터 확인 자의 구현입니다. 리턴 된 클러스터 스펙은 TF_CONFIG 환경 변수에서 초기화됩니다.</target>
        </trans-unit>
        <trans-unit id="f2e4a40b99bc22ad76a6b8d488160787266d96b7" translate="yes" xml:space="preserve">
          <source>This is because evaluating the gradient graph does not require evaluating the constant(1) op created in the forward pass.</source>
          <target state="translated">그래디언트 그래프를 평가할 때는 정방향 패스에서 생성 된 constant (1) op를 평가할 필요가 없기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="b402b2ea93d17cfe8814c2e2dd9513661013af48" translate="yes" xml:space="preserve">
          <source>This is called to signal the hooks that a new session has been created. This has two essential differences with the situation in which &lt;code&gt;begin&lt;/code&gt; is called:</source>
          <target state="translated">새 세션이 작성되었음을 알리기 위해 호출됩니다. 여기에는 &lt;code&gt;begin&lt;/code&gt; 이라는 상황과 두 가지 근본적인 차이점이 있습니다 .</target>
        </trans-unit>
        <trans-unit id="e53a92d847e73238072fa6528b3217c26234a931" translate="yes" xml:space="preserve">
          <source>This is completely equivalent to the slightly longer code:</source>
          <target state="translated">이것은 약간 긴 코드와 완전히 같습니다.</target>
        </trans-unit>
        <trans-unit id="bb94386b1c4a4c290298db5397c611953054ddc2" translate="yes" xml:space="preserve">
          <source>This is convenient in interactive shells and &lt;a href=&quot;http://ipython.org&quot;&gt;IPython notebooks&lt;/a&gt;, as it avoids having to pass an explicit &lt;code&gt;Session&lt;/code&gt; object to run ops.</source>
          <target state="translated">이것은 ops를 실행하기 위해 명시적인 &lt;code&gt;Session&lt;/code&gt; 객체를 전달할 필요가 &lt;a href=&quot;http://ipython.org&quot;&gt;없으므로&lt;/a&gt; 대화식 쉘 및 IPython 노트북 에서 편리합니다 .</target>
        </trans-unit>
        <trans-unit id="9c4ed05585b78549393533536c5eaedd31668459" translate="yes" xml:space="preserve">
          <source>This is different from &lt;code&gt;get_collection()&lt;/code&gt; which always returns a copy of the collection list if it exists and never creates an empty collection.</source>
          <target state="translated">이것은 콜렉션리스트가 존재하는 경우 항상 콜렉션리스트의 사본을 리턴하고 빈 콜렉션을 작성하지 않는 &lt;code&gt;get_collection()&lt;/code&gt; 과 다릅니다 .</target>
        </trans-unit>
        <trans-unit id="6e7866f4c4c548ff00d81ad9995e04b7c1f8a6da" translate="yes" xml:space="preserve">
          <source>This is different from &lt;code&gt;get_collection_ref()&lt;/code&gt; which always returns the actual collection list if it exists in that it returns a new list each time it is called.</source>
          <target state="translated">이것은 &lt;code&gt;get_collection_ref()&lt;/code&gt; 와는 다릅니다. get_collection_ref () 는 호출 할 때마다 새 목록을 반환한다는 점에서 항상 실제 컬렉션 목록을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="c1f83f54b0650a6fa73b0409ff1516763b5fe7d4" translate="yes" xml:space="preserve">
          <source>This is equivalent to applying LSTMBlockCell in a loop, like so:</source>
          <target state="translated">This is equivalent to applying LSTMBlockCell in a loop, like so:</target>
        </trans-unit>
        <trans-unit id="731ffc6237ea1b1cd740ef79a9e5ef7a26a2d7c5" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;assign(self, value)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;assign(self, value)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="0bbe53c86ac89d70d42d35929c4d3967934b3af3" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;assign_add(self, delta)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;assign_add(self, delta)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="13da478f41797a8113b6021c13a3264c6404bfc3" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;assign_sub(self, delta)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;assign_sub(self, delta)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="e2b79a6063d963599f65675c034b474bb3cf4380" translate="yes" xml:space="preserve">
          <source>This is essentially a shortcut for &lt;code&gt;count_up_to(self, limit)&lt;/code&gt;.</source>
          <target state="translated">이것은 본질적으로 &lt;code&gt;count_up_to(self, limit)&lt;/code&gt; 의 지름길입니다 .</target>
        </trans-unit>
        <trans-unit id="1f513c169143d5db244b63790e45478adc90df06" translate="yes" xml:space="preserve">
          <source>This is expected to return a constant value that will not be changed throughout its life cycle.</source>
          <target state="translated">이는 수명주기 내내 변경되지 않는 일정한 값을 반환 할 것으로 예상됩니다.</target>
        </trans-unit>
        <trans-unit id="cf3c566ed68759dd2e1f8f0b989dfbaaf3ac89b7" translate="yes" xml:space="preserve">
          <source>This is for example useful if you want to save to a local directory, such as &quot;/tmp&quot; when running in a distributed setting. In that case pass a device for the host where the &quot;/tmp&quot; directory is accessible.</source>
          <target state="translated">This is for example useful if you want to save to a local directory, such as &quot;/tmp&quot; when running in a distributed setting. In that case pass a device for the host where the &quot;/tmp&quot; directory is accessible.</target>
        </trans-unit>
        <trans-unit id="cbd5047389c2714c42e18e715b6900b97495f191" translate="yes" xml:space="preserve">
          <source>This is for use with models that expect a single &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;SparseTensor&lt;/code&gt; as an input feature, as opposed to a dict of features.</source>
          <target state="translated">이는 기능에 반대되는 것이 아니라 단일 &lt;code&gt;Tensor&lt;/code&gt; 또는 &lt;code&gt;SparseTensor&lt;/code&gt; 를 입력 기능으로 예상하는 모델에 사용됩니다 .</target>
        </trans-unit>
        <trans-unit id="76d3e8dd92950ccc6782125edfc083318d1af070" translate="yes" xml:space="preserve">
          <source>This is implemented as a generalized linear model, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Generalized_linear_model&quot;&gt;https://en.wikipedia.org/wiki/Generalized_linear_model&lt;/a&gt;</source>
          <target state="translated">This is implemented as a generalized linear model, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Generalized_linear_model&quot;&gt;https://en.wikipedia.org/wiki/Generalized_linear_model&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4f78d4311c49702fc3e064ee729929a77dc6e0a0" translate="yes" xml:space="preserve">
          <source>This is implemented as a generalized linear model, see https://en.wikipedia.org/wiki/Generalized_linear_model.</source>
          <target state="translated">이것은 일반화 된 선형 모델로 구현됩니다 (https://en.wikipedia.org/wiki/Generalized_linear_model 참조).</target>
        </trans-unit>
        <trans-unit id="7a79baaefeeabffec27522a961ac347462293274" translate="yes" xml:space="preserve">
          <source>This is important for the RNN layer to invoke this in it call() method so that the cached mask is cleared before calling the cell.call(). The mask should be cached across the timestep within the same batch, but shouldn't be cached between batches. Otherwise it will introduce unreasonable bias against certain index of data within the batch.</source>
          <target state="translated">This is important for the RNN layer to invoke this in it call() method so that the cached mask is cleared before calling the cell.call(). The mask should be cached across the timestep within the same batch, but shouldn't be cached between batches. Otherwise it will introduce unreasonable bias against certain index of data within the batch.</target>
        </trans-unit>
        <trans-unit id="b5e2c7b524f309c97d9b307ab3f360df187084ea" translate="yes" xml:space="preserve">
          <source>This is intended to be used on signals (or images). Produces a PSNR value for each image in batch.</source>
          <target state="translated">신호 (또는 이미지)에 사용됩니다. 배치별로 각 이미지에 대한 PSNR 값을 생성합니다.</target>
        </trans-unit>
        <trans-unit id="5c8364ff06f44a0d2f95291cd9a883d7572dfead" translate="yes" xml:space="preserve">
          <source>This is just a shortcut for &lt;code&gt;variables_initializer(global_variables())&lt;/code&gt;</source>
          <target state="translated">이것은 &lt;code&gt;variables_initializer(global_variables())&lt;/code&gt; 의 바로 가기입니다.</target>
        </trans-unit>
        <trans-unit id="df7f814ad895f2447cfabb704fb289f9c5058c9f" translate="yes" xml:space="preserve">
          <source>This is just a shortcut for &lt;code&gt;variables_initializer(local_variables())&lt;/code&gt;</source>
          <target state="translated">이것은 &lt;code&gt;variables_initializer(local_variables())&lt;/code&gt; 의 바로 가기입니다.</target>
        </trans-unit>
        <trans-unit id="1f3a1e67435c460ebf6c9461373717a014d4077f" translate="yes" xml:space="preserve">
          <source>This is like &lt;code&gt;Restore&lt;/code&gt; except that restored tensor can be listed as filling only a slice of a larger tensor. &lt;code&gt;shape_and_slice&lt;/code&gt; specifies the shape of the larger tensor and the slice that the restored tensor covers.</source>
          <target state="translated">This is like &lt;code&gt;Restore&lt;/code&gt; except that restored tensor can be listed as filling only a slice of a larger tensor. &lt;code&gt;shape_and_slice&lt;/code&gt; specifies the shape of the larger tensor and the slice that the restored tensor covers.</target>
        </trans-unit>
        <trans-unit id="9a946a8e53161857f667092e8b20dfd7b65825b0" translate="yes" xml:space="preserve">
          <source>This is like &lt;code&gt;Save&lt;/code&gt; except that tensors can be listed in the saved file as being a slice of a larger tensor. &lt;code&gt;shapes_and_slices&lt;/code&gt; specifies the shape of the larger tensor and the slice that this tensor covers. &lt;code&gt;shapes_and_slices&lt;/code&gt; must have as many elements as &lt;code&gt;tensor_names&lt;/code&gt;.</source>
          <target state="translated">This is like &lt;code&gt;Save&lt;/code&gt; except that tensors can be listed in the saved file as being a slice of a larger tensor. &lt;code&gt;shapes_and_slices&lt;/code&gt; specifies the shape of the larger tensor and the slice that this tensor covers. &lt;code&gt;shapes_and_slices&lt;/code&gt; must have as many elements as &lt;code&gt;tensor_names&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3f6a76852476cdaa13e9bdd3f2afe687e9e8f273" translate="yes" xml:space="preserve">
          <source>This is like &lt;code&gt;sigmoid_cross_entropy_with_logits()&lt;/code&gt; except that &lt;code&gt;pos_weight&lt;/code&gt;, allows one to trade off recall and precision by up- or down-weighting the cost of a positive error relative to a negative error.</source>
          <target state="translated">이처럼 &lt;code&gt;sigmoid_cross_entropy_with_logits()&lt;/code&gt; 것을 제외 &lt;code&gt;pos_weight&lt;/code&gt; , 위쪽으로 또는 아래쪽 가중치 네거티브 에러 포지티브 에러 상대적인 비용을 회수하고 정확도 트레이드 오프를 허용한다.</target>
        </trans-unit>
        <trans-unit id="45f8d315bd404d0acf0d22377d0fcd8dbfde7b6a" translate="yes" xml:space="preserve">
          <source>This is mathematically equivalent to the classic formula below, but the use of an &lt;code&gt;assign_sub&lt;/code&gt; op (the &lt;code&gt;&quot;-=&quot;&lt;/code&gt; in the formula) allows concurrent lockless updates to the variables:</source>
          <target state="translated">이는 수학적으로 아래의 고전적인 공식과 동일하지만 &lt;code&gt;assign_sub&lt;/code&gt; op ( 공식 의 &lt;code&gt;&quot;-=&quot;&lt;/code&gt; )를 사용하면 변수에 대한 동시 잠금없는 업데이트가 가능합니다.</target>
        </trans-unit>
        <trans-unit id="a748c5d3b3b745591c3f3c629fe6702e2487d204" translate="yes" xml:space="preserve">
          <source>This is matrix product, not element-wise product.</source>
          <target state="translated">This is matrix product, not element-wise product.</target>
        </trans-unit>
        <trans-unit id="e3ce6465dd501a9c64e67f9787b8dbacdd54e8b7" translate="yes" xml:space="preserve">
          <source>This is matrix-vector product, not element-wise product.</source>
          <target state="translated">This is matrix-vector product, not element-wise product.</target>
        </trans-unit>
        <trans-unit id="8c5b780da30371ec04532fe08dfb27ab4f7f20a6" translate="yes" xml:space="preserve">
          <source>This is more efficient than using separate &lt;a href=&quot;../reverse&quot;&gt;&lt;code&gt;tf.reverse&lt;/code&gt;&lt;/a&gt; ops.</source>
          <target state="translated">이것은 별도의 &lt;a href=&quot;../reverse&quot;&gt; &lt;code&gt;tf.reverse&lt;/code&gt; &lt;/a&gt; ops를 사용하는 것보다 효율적 입니다.</target>
        </trans-unit>
        <trans-unit id="eabc0e8c9ba11bd382b9ff6e31e4cc504e020ab9" translate="yes" xml:space="preserve">
          <source>This is more efficient than using separate &lt;a href=&quot;../reverse&quot;&gt;&lt;code&gt;tf.reverse&lt;/code&gt;&lt;/a&gt; ops. The &lt;code&gt;reverse&lt;/code&gt; and &lt;code&gt;exclusive&lt;/code&gt; kwargs can also be combined:</source>
          <target state="translated">이것은 별도의 &lt;a href=&quot;../reverse&quot;&gt; &lt;code&gt;tf.reverse&lt;/code&gt; &lt;/a&gt; ops를 사용하는 것보다 효율적 입니다. &lt;code&gt;reverse&lt;/code&gt; 및 &lt;code&gt;exclusive&lt;/code&gt; kwargs로도 결합 될 수있다 :</target>
        </trans-unit>
        <trans-unit id="80ea1c276768e8dc61eb8fd686066ffd896d6dd9" translate="yes" xml:space="preserve">
          <source>This is not a graph construction method, it does not add ops to the graph.</source>
          <target state="translated">이것은 그래프 생성 방법이 아니며 그래프에 op를 추가하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="afbcb9b1912c3cf36d0b4a3b3d79a1accb7231d9" translate="yes" xml:space="preserve">
          <source>This is particularly useful for creating a critical section when used in conjunction with &lt;code&gt;MutexLockIdentity&lt;/code&gt;:</source>
          <target state="translated">This is particularly useful for creating a critical section when used in conjunction with &lt;code&gt;MutexLockIdentity&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="be0ccfef7a257148d1bd487cc01dfdee2f9dcbb7" translate="yes" xml:space="preserve">
          <source>This is similar to &lt;code&gt;embedding_column&lt;/code&gt;, except that it produces a list of embedding columns that share the same embedding weights.</source>
          <target state="translated">이는 동일한 포함 가중치를 공유하는 포함 열 목록을 생성한다는 점을 제외하면 &lt;code&gt;embedding_column&lt;/code&gt; 과 유사합니다 .</target>
        </trans-unit>
        <trans-unit id="16ef5940d98e86cc048c2b1d955cc28ebe55e81d" translate="yes" xml:space="preserve">
          <source>This is supposed to be executed in the beginning of the chief/sync thread so that even if the total_num_replicas is less than replicas_to_aggregate, the model can still proceed as the replicas can compute multiple steps per variable update. Make sure: &lt;code&gt;num_tokens &amp;gt;= replicas_to_aggregate - total_num_replicas&lt;/code&gt;.</source>
          <target state="translated">이는 total / num_replicas가 replicas_to_aggregate보다 작더라도 복제본이 변수 업데이트 당 여러 단계를 계산할 수 있으므로 모델이 계속 진행될 수 있도록 chief / sync 스레드의 시작 부분에서 실행되어야합니다. &lt;code&gt;num_tokens &amp;gt;= replicas_to_aggregate - total_num_replicas&lt;/code&gt; 확인하십시오 .</target>
        </trans-unit>
        <trans-unit id="b0eb2e902e8ddf903b8c32989be7bc5b84650328" translate="yes" xml:space="preserve">
          <source>This is the Python 2.x counterpart to &lt;code&gt;__bool__()&lt;/code&gt; above.</source>
          <target state="translated">위의 &lt;code&gt;__bool__()&lt;/code&gt; 해당하는 Python 2.x 입니다.</target>
        </trans-unit>
        <trans-unit id="a177ea545dfd38bd683f27da57349ab86dcbee74" translate="yes" xml:space="preserve">
          <source>This is the V1 version of this layer that uses variable_scope's or partitioner to create variables which works well with PartitionedVariables. Variable scopes are deprecated in V2, so the V2 version uses name_scopes instead. But currently that lacks support for partitioned variables. Use this if you need partitioned variables. Use the partitioner argument if you have a Keras model and uses &lt;a href=&quot;../estimator/model_to_estimator&quot;&gt;&lt;code&gt;tf.compat.v1.keras.estimator.model_to_estimator&lt;/code&gt;&lt;/a&gt; for training.</source>
          <target state="translated">This is the V1 version of this layer that uses variable_scope's or partitioner to create variables which works well with PartitionedVariables. Variable scopes are deprecated in V2, so the V2 version uses name_scopes instead. But currently that lacks support for partitioned variables. Use this if you need partitioned variables. Use the partitioner argument if you have a Keras model and uses &lt;a href=&quot;../estimator/model_to_estimator&quot;&gt; &lt;code&gt;tf.compat.v1.keras.estimator.model_to_estimator&lt;/code&gt; &lt;/a&gt; for training.</target>
        </trans-unit>
        <trans-unit id="8d8b6a8f2029ea1fc60a937a0c43797bc06e4fc9" translate="yes" xml:space="preserve">
          <source>This is the V1 version of this layer that uses variable_scope's to create variables which works well with PartitionedVariables. Variable scopes are deprecated in V2, so the V2 version uses name_scopes instead. But currently that lacks support for partitioned variables. Use this if you need partitioned variables.</source>
          <target state="translated">이것은 variable_scope를 사용하여 PartitionedVariables와 잘 작동하는 변수를 만드는이 계층의 V1 버전입니다. 변수 범위는 V2에서 더 이상 사용되지 않으므로 V2 버전은 대신 name_scopes를 사용합니다. 그러나 현재는 분할 변수에 대한 지원이 부족합니다. 파티션 된 변수가 필요한 경우이를 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="f355bc341013b9a7925572a2dcb6ac68143ef849" translate="yes" xml:space="preserve">
          <source>This is the V2 version of this layer that uses name_scopes to create variables instead of variable_scopes. But this approach currently lacks support for partitioned variables. In that case, use the V1 version instead.</source>
          <target state="translated">이 레이어의 V2 버전은 name_scopes를 사용하여 variable_scopes 대신 변수를 만듭니다. 그러나이 방법에는 현재 분할 된 변수에 대한 지원이 없습니다. 이 경우 대신 V1 버전을 사용하십시오.</target>
        </trans-unit>
        <trans-unit id="45048f38a2e249e88fc3cdaca3ce8480b40e2329" translate="yes" xml:space="preserve">
          <source>This is the angle ( \theta \in [-\pi, \pi] ) such that [ x = r \cos(\theta) ] and [ y = r \sin(\theta) ] where (r = \sqrt(x^2 + y^2) ).</source>
          <target state="translated">이것은 [x = r \ cos (\ theta)] 및 [y = r \ sin (\ theta)]와 같이 각도 (\ theta \ in [-\ pi, \ pi])입니다. 여기서 (r = \ sqrt ( x ^ 2 + y ^ 2)).</target>
        </trans-unit>
        <trans-unit id="d2e50218603262fb1a544e117d169f38db78b601" translate="yes" xml:space="preserve">
          <source>This is the base class for implementing RNN cells with custom behavior.</source>
          <target state="translated">이것은 커스텀 행동으로 RNN 셀을 구현하기위한 기본 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="9e013372239f70ba2378635884ba4bb573e7d626" translate="yes" xml:space="preserve">
          <source>This is the class from which all layers inherit.</source>
          <target state="translated">이것은 모든 레이어가 상속하는 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="ff34740f3f60fdf70d3491fdb28647e761a272fb" translate="yes" xml:space="preserve">
          <source>This is the correct way to perform gradient clipping (Pascanu et al., 2012).</source>
          <target state="translated">This is the correct way to perform gradient clipping (Pascanu et al., 2012).</target>
        </trans-unit>
        <trans-unit id="8fa4ff7f2578477f255b6f02a47ae45758b90edc" translate="yes" xml:space="preserve">
          <source>This is the correct way to perform gradient clipping (for example, see &lt;a href=&quot;http://arxiv.org/abs/1211.5063&quot;&gt;Pascanu et al., 2012&lt;/a&gt; (&lt;a href=&quot;http://arxiv.org/pdf/1211.5063.pdf&quot;&gt;pdf&lt;/a&gt;)).</source>
          <target state="translated">그래디언트 클리핑을 수행하는 올바른 방법입니다 (예 : &lt;a href=&quot;http://arxiv.org/abs/1211.5063&quot;&gt;Pascanu et al., 2012&lt;/a&gt; ( &lt;a href=&quot;http://arxiv.org/pdf/1211.5063.pdf&quot;&gt;pdf&lt;/a&gt; ) 참조).</target>
        </trans-unit>
        <trans-unit id="76694ede23dda167a78335c0c1bd3e85284fad75" translate="yes" xml:space="preserve">
          <source>This is the crossentropy metric class to be used when there are multiple label classes (2 or more). Here we assume that labels are given as a &lt;code&gt;one_hot&lt;/code&gt; representation. eg., When labels values are [2, 0, 1], &lt;code&gt;y_true&lt;/code&gt; = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].</source>
          <target state="translated">여러 레이블 클래스 (2 이상)가있을 때 사용되는 교차 엔트로피 메트릭 클래스입니다. 여기서 레이블은 &lt;code&gt;one_hot&lt;/code&gt; 표현으로 제공된다고 가정합니다 . 예를 들어, 라벨 값이 [2, 0, 1] 인 경우 &lt;code&gt;y_true&lt;/code&gt; = [[0, 0, 1], [1, 0, 0], [0, 1, 0]]입니다.</target>
        </trans-unit>
        <trans-unit id="d187cef3999e110bfd14733d1bc7141db46b4d0d" translate="yes" xml:space="preserve">
          <source>This is the crossentropy metric class to be used when there are only two label classes (0 and 1).</source>
          <target state="translated">이것은 두 개의 레이블 클래스 (0 및 1)가있을 때 사용되는 교차 엔트로피 메트릭 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="fb90fff0e52ece653003dbcf512572b6437c5795" translate="yes" xml:space="preserve">
          <source>This is the dtype layers will create their variables in, unless a layer explicitly chooses a different dtype. If this is different than &lt;a href=&quot;policy#compute_dtype&quot;&gt;&lt;code&gt;Policy.compute_dtype&lt;/code&gt;&lt;/a&gt;, Layers will cast variables to the compute dtype to avoid type errors.</source>
          <target state="translated">레이어가 명시 적으로 다른 dtype을 선택하지 않는 한 이것은 dtype 레이어가 변수를 생성합니다. 이것이 &lt;a href=&quot;policy#compute_dtype&quot;&gt; &lt;code&gt;Policy.compute_dtype&lt;/code&gt; &lt;/a&gt; 와 다른 경우 과 레이어는 유형 오류를 피하기 위해 변수를 계산 dtype으로 캐스팅합니다.</target>
        </trans-unit>
        <trans-unit id="08b035fd1ef991c0ac17661834339a93b3d11556" translate="yes" xml:space="preserve">
          <source>This is the dtype layers will do their computations in.</source>
          <target state="translated">이것은 dtype 레이어가 계산을 수행하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="5e888c610bf02b0ac69c58288afbe898eebab389" translate="yes" xml:space="preserve">
          <source>This is the first part of &lt;code&gt;minimize()&lt;/code&gt;. It returns a list of (gradient, variable) pairs where &quot;gradient&quot; is the gradient for &quot;variable&quot;. Note that &quot;gradient&quot; can be a &lt;code&gt;Tensor&lt;/code&gt;, an &lt;code&gt;IndexedSlices&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; if there is no gradient for the given variable.</source>
          <target state="translated">이것은 &lt;code&gt;minimize()&lt;/code&gt; 의 첫 번째 부분입니다 . &quot;gradient&quot;가 &quot;variable&quot;에 대한 기울기 인 (gradient, variable) 쌍의 목록을 리턴합니다. &quot;gradient&quot;는 &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;IndexedSlices&lt;/code&gt; 또는 지정된 변수에 대한 기울기가없는 경우 &lt;code&gt;None&lt;/code&gt; 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="d316c810415832d0f55adcb10b604f9c47cbd2e8" translate="yes" xml:space="preserve">
          <source>This is the number of train steps running in TPU system before returning to CPU host for each &lt;code&gt;Session.run&lt;/code&gt;. This means global step is increased &lt;code&gt;iterations_per_loop&lt;/code&gt; times in one &lt;code&gt;Session.run&lt;/code&gt;. It is recommended to be set as number of global steps for next checkpoint. Note that in evaluation don't use this value, instead we run total eval &lt;code&gt;steps&lt;/code&gt; on TPU for a single &lt;code&gt;Session.run&lt;/code&gt;. [Experimental]: &lt;code&gt;iterations_per_loop&lt;/code&gt; can be specified as a time interval. To specify N seconds in one &lt;code&gt;Session.run&lt;/code&gt;, one can specify it as &lt;code&gt;Ns&lt;/code&gt; and substitute the N with the N with the number of desired seconds. Alternatively, the unit of time can also be specified in minutes or hours, e.g. &lt;code&gt;3600s&lt;/code&gt; or &lt;code&gt;60m&lt;/code&gt; or &lt;code&gt;1h&lt;/code&gt;.</source>
          <target state="translated">This is the number of train steps running in TPU system before returning to CPU host for each &lt;code&gt;Session.run&lt;/code&gt; . This means global step is increased &lt;code&gt;iterations_per_loop&lt;/code&gt; times in one &lt;code&gt;Session.run&lt;/code&gt; . It is recommended to be set as number of global steps for next checkpoint. Note that in evaluation don't use this value, instead we run total eval &lt;code&gt;steps&lt;/code&gt; on TPU for a single &lt;code&gt;Session.run&lt;/code&gt; . [Experimental]: &lt;code&gt;iterations_per_loop&lt;/code&gt; can be specified as a time interval. To specify N seconds in one &lt;code&gt;Session.run&lt;/code&gt; , one can specify it as &lt;code&gt;Ns&lt;/code&gt; and substitute the N with the N with the number of desired seconds. Alternatively, the unit of time can also be specified in minutes or hours, e.g. &lt;code&gt;3600s&lt;/code&gt; or &lt;code&gt;60m&lt;/code&gt; or &lt;code&gt;1h&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a40023f76ab90114029e1bcc91749b2e4391f638" translate="yes" xml:space="preserve">
          <source>This is the opposite of &lt;code&gt;pack&lt;/code&gt;.</source>
          <target state="translated">This is the opposite of &lt;code&gt;pack&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c3ea6e7a75310a4a77e1b1f56fba56b3219204d9" translate="yes" xml:space="preserve">
          <source>This is the opposite of &lt;code&gt;unpack&lt;/code&gt;.</source>
          <target state="translated">This is the opposite of &lt;code&gt;unpack&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b03c235347a9cd23cdcbcc99319938e9531d2ad0" translate="yes" xml:space="preserve">
          <source>This is the opposite of stack.</source>
          <target state="translated">이것은 스택의 반대입니다.</target>
        </trans-unit>
        <trans-unit id="2e4bca768b327e659a826ca7018b5b658cdefd12" translate="yes" xml:space="preserve">
          <source>This is the opposite of unstack. The numpy equivalent is</source>
          <target state="translated">언 스택의 반대입니다. numpy에 해당하는 것은</target>
        </trans-unit>
        <trans-unit id="40e4198c7947cb171a27f0f2b96b5e41f088c377" translate="yes" xml:space="preserve">
          <source>This is the opposite of unstack. The numpy equivalent is &lt;code&gt;np.stack&lt;/code&gt;</source>
          <target state="translated">언 스택의 반대입니다. numpy에 해당하는 것은 &lt;code&gt;np.stack&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="97cb38281f3bf589012ea6423fb54fdf27897538" translate="yes" xml:space="preserve">
          <source>This is the recommended way to check if a checkpoint exists, since it takes into account the naming difference between V1 and V2 formats.</source>
          <target state="translated">이것은 체크 포인트가 존재하는지 확인하기 위해 권장되는 방법입니다. V1과 V2 형식의 이름 차이를 고려하기 때문입니다.</target>
        </trans-unit>
        <trans-unit id="1ffa5c6451bfed59ad42e7f927c856cf80634c8e" translate="yes" xml:space="preserve">
          <source>This is the recommended way to get the mtimes, since it takes into account the naming difference between V1 and V2 formats.</source>
          <target state="translated">V1과 V2 형식의 이름 차이를 고려하므로 mtimes를 얻는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="e10b2d35c35f3fc21ee9a235cd260123a0e63325" translate="yes" xml:space="preserve">
          <source>This is the same as the number of Read executions that have succeeded.</source>
          <target state="translated">성공한 읽기 실행 횟수와 동일합니다.</target>
        </trans-unit>
        <trans-unit id="85a191debc0e75e9aae4867ba1a3abb350e8cdbd" translate="yes" xml:space="preserve">
          <source>This is the same as the number of ReaderRead executions that have succeeded.</source>
          <target state="translated">This is the same as the number of ReaderRead executions that have succeeded.</target>
        </trans-unit>
        <trans-unit id="f339ca988bca6265b32a0422f47f6bd298db3ffc" translate="yes" xml:space="preserve">
          <source>This is the second part of &lt;code&gt;minimize()&lt;/code&gt;. It returns an &lt;code&gt;Operation&lt;/code&gt; that applies gradients.</source>
          <target state="translated">이것은 &lt;code&gt;minimize()&lt;/code&gt; 의 두 번째 부분입니다 . &lt;code&gt;Operation&lt;/code&gt; 반환합니다그라디언트를 적용 을 합니다.</target>
        </trans-unit>
        <trans-unit id="929a719e4fd77bb16e29532f382d40f922f3c1e7" translate="yes" xml:space="preserve">
          <source>This is the second part of &lt;code&gt;minimize()&lt;/code&gt;. It returns an &lt;code&gt;Operation&lt;/code&gt; that conditionally applies gradients if all gradient values are finite. Otherwise no update is performed (nor is &lt;code&gt;global_step&lt;/code&gt; incremented).</source>
          <target state="translated">이것은 &lt;code&gt;minimize()&lt;/code&gt; 의 두 번째 부분입니다 . 모든 그래디언트 값이 유한 한 경우 조건부 그래디언트를 적용 하는 &lt;code&gt;Operation&lt;/code&gt; 을 반환합니다 . 그렇지 않으면 업데이트가 수행되지 않습니다 ( &lt;code&gt;global_step&lt;/code&gt; 도 아닙니다) 증가 ).</target>
        </trans-unit>
        <trans-unit id="e8ee3ea42d612b02e009f45c4fa84d1cc896a5de" translate="yes" xml:space="preserve">
          <source>This is true if the variable dtype is not the same as the compute dtype.</source>
          <target state="translated">변수 dtype이 계산 dtype과 동일하지 않은 경우에 해당됩니다.</target>
        </trans-unit>
        <trans-unit id="91423d96c0eed87b88e95950664bbf721548ff0b" translate="yes" xml:space="preserve">
          <source>This is typically used by gradient computations for a broadcasting operation.</source>
          <target state="translated">This is typically used by gradient computations for a broadcasting operation.</target>
        </trans-unit>
        <trans-unit id="a06d1207d293755800555755a98a415474a76700" translate="yes" xml:space="preserve">
          <source>This is typically used by gradient computations for a concat operation.</source>
          <target state="translated">This is typically used by gradient computations for a concat operation.</target>
        </trans-unit>
        <trans-unit id="599e1941b7c0f4f9a0022f3bce79b85ba3adcf41" translate="yes" xml:space="preserve">
          <source>This is typically used to create the weights of &lt;code&gt;Layer&lt;/code&gt; subclasses.</source>
          <target state="translated">이것은 일반적으로 &lt;code&gt;Layer&lt;/code&gt; 의 가중치를 만드는 데 사용됩니다 서브 클래스 .</target>
        </trans-unit>
        <trans-unit id="c448d69e13a9acb17ee778d9369e5a1d63cab697" translate="yes" xml:space="preserve">
          <source>This is used for converting legacy Theano-saved model files.</source>
          <target state="translated">This is used for converting legacy Theano-saved model files.</target>
        </trans-unit>
        <trans-unit id="05a2eba266c663d9424df49b8db51e4cc8c2df9e" translate="yes" xml:space="preserve">
          <source>This is used only for TfLite, it provides hints and it also makes the variables in the desired for the tflite ops (transposed and seaparated).</source>
          <target state="translated">이것은 TfLite에만 사용되며 힌트를 제공하며 tflite ops (transpose 및 seaparated)에 원하는 변수를 만듭니다.</target>
        </trans-unit>
        <trans-unit id="48e3efb832cfd45bd13919fdfde1ca19835cc159" translate="yes" xml:space="preserve">
          <source>This is used only for TfLite, it provides hints and it also makes the variables in the desired for the tflite ops (transposed and separated).</source>
          <target state="translated">This is used only for TfLite, it provides hints and it also makes the variables in the desired for the tflite ops (transposed and separated).</target>
        </trans-unit>
        <trans-unit id="ad15eb7677663d9a7242cb23213706bc03ee0734" translate="yes" xml:space="preserve">
          <source>This is used only for TfLite, it provides hints and it also makes the variables in the desired for the tflite ops.</source>
          <target state="translated">이것은 TfLite에만 사용되며 힌트를 제공하며 tflite ops에 원하는 변수를 만듭니다.</target>
        </trans-unit>
        <trans-unit id="aa63c8ad524a0fffe274fd0f59f47f9f37029b1b" translate="yes" xml:space="preserve">
          <source>This is used to convert from a TensorFlow GraphDef, SavedModel or tf.keras model into either a TFLite FlatBuffer or graph visualization.</source>
          <target state="translated">TensorFlow GraphDef, SavedModel 또는 tf.keras 모델에서 TFLite FlatBuffer 또는 그래프 시각화로 변환하는 데 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="42aa887e1a89f1c6a2cebd74bb895f76b927be77" translate="yes" xml:space="preserve">
          <source>This is used to decide whether loss should be scaled in optimizer (used only for estimator + v1 optimizer use case).</source>
          <target state="translated">이는 옵티 마이저에서 손실을 조정해야하는지 여부를 결정하는 데 사용됩니다 (추정기 + v1 옵티 마이저 사용 사례에만 사용).</target>
        </trans-unit>
        <trans-unit id="b17cf82d54ada528ca921a0efa90b52815fa4b91" translate="yes" xml:space="preserve">
          <source>This is used to prepare for toco conversion of complex intrinsic usages. Note: only one of session or graph_def should be used, not both.</source>
          <target state="translated">복잡한 고유 사용의 토코 변환을 준비하는 데 사용됩니다. 참고 : session 또는 graph_def 중 하나만 사용해야합니다.</target>
        </trans-unit>
        <trans-unit id="c7bb1bcc7e14a92bfe2b3cdc7e1ae060a3c52e44" translate="yes" xml:space="preserve">
          <source>This is useful any time you want to compute a value with TensorFlow but need to pretend that the value was a constant. Some examples include:</source>
          <target state="translated">이것은 TensorFlow로 값을 계산하려고하지만 값이 상수 인 척해야 할 때 유용합니다. 몇 가지 예는 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="615f9e8a59ff4f1c3fc7f3ec9b1dd3650508efec" translate="yes" xml:space="preserve">
          <source>This is useful as a placeholder in code that expects a context manager.</source>
          <target state="translated">컨텍스트 관리자가 필요한 코드의 자리 표시 자로 유용합니다.</target>
        </trans-unit>
        <trans-unit id="150d8f70445d33c34b068178e2af6c26bf08bf36" translate="yes" xml:space="preserve">
          <source>This is useful for debugging and providing early errors. For example, when tracing a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, no ops are being executed, shapes may be unknown (See the &lt;a href=&quot;https://www.tensorflow.org/guide/concrete_function&quot;&gt;Concrete Functions Guide&lt;/a&gt; for details).</source>
          <target state="translated">This is useful for debugging and providing early errors. For example, when tracing a &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt;, no ops are being executed, shapes may be unknown (See the &lt;a href=&quot;https://www.tensorflow.org/guide/concrete_function&quot;&gt;Concrete Functions Guide&lt;/a&gt; for details).</target>
        </trans-unit>
        <trans-unit id="b9563699660ae889442bbf807a27eb9beba27100" translate="yes" xml:space="preserve">
          <source>This is useful for separating training updates and state updates, e.g. when we need to update a layer's internal state during prediction.</source>
          <target state="translated">예를 들어 예측 중에 레이어의 내부 상태를 업데이트해야하는 경우 훈련 업데이트와 상태 업데이트를 분리하는 데 유용합니다.</target>
        </trans-unit>
        <trans-unit id="946e89dc12a7c9a5e1ede20576867301b896367c" translate="yes" xml:space="preserve">
          <source>This is useful for sequence tasks in which the elements have variable length. Grouping together elements that have similar lengths reduces the total fraction of padding in a batch which increases training step efficiency.</source>
          <target state="translated">이는 요소의 길이가 가변적 인 시퀀스 작업에 유용합니다. 길이가 비슷한 요소를 그룹화하면 배치에서 패딩의 총 비율이 줄어 훈련 단계 효율성이 향상됩니다.</target>
        </trans-unit>
        <trans-unit id="750a87642623af70551e01a6394d91315e9bfbb7" translate="yes" xml:space="preserve">
          <source>This is useful if you don't want to exit the context manager for the tape, or can't because the desired reset point is inside a control flow construct:</source>
          <target state="translated">테이프의 컨텍스트 관리자를 종료하지 않으려는 경우 또는 원하는 재설정 지점이 제어 플로우 구성 내에 있기 때문에 종료 할 수없는 경우에 유용합니다.</target>
        </trans-unit>
        <trans-unit id="1c4209d707783ab42b6537361cd0e771e2838f9d" translate="yes" xml:space="preserve">
          <source>This is useful in summaries to measure and report sparsity. For example,</source>
          <target state="translated">희소성을 측정하고보고하는 요약에 유용합니다. 예를 들어</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
