<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ko" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="584da06db551e34afe167aa9b87c9a9f268850eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(batch, input_size)&lt;/code&gt;: tensor containing input features</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(batch, input_size)&lt;/code&gt; : 입력 특성을 포함하는 텐서</target>
        </trans-unit>
        <trans-unit id="4a3704197e0eca68967963d49706554f7e113eb5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt;: tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt; : 입력 시퀀스의 특징을 포함하는 텐서. 입력은 패킹 된 가변 길이 시퀀스 일 수도 있습니다. 자세한 내용은 &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="9ae74c54ba996ad29eb2561904532cd22f9106ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt;: tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.nn.utils.rnn.pack_sequence#torch.nn.utils.rnn.pack_sequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.pack_sequence()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">&lt;strong&gt;input&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, input_size)&lt;/code&gt; : 입력 시퀀스의 특징을 포함하는 텐서. 입력은 패킹 된 가변 길이 시퀀스 일 수도 있습니다. 자세한 내용은 &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.pack_padded_sequence()&lt;/code&gt; &lt;/a&gt; 또는 &lt;a href=&quot;torch.nn.utils.rnn.pack_sequence#torch.nn.utils.rnn.pack_sequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.pack_sequence()&lt;/code&gt; &lt;/a&gt; 를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="d073db700f14add42abc2cdb78180dfcfcd6265b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_lengths&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;input_lengths&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="5aab54f56e166a12d78bbb3bb93f9dd9e315d0e5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to reduce and scatter.</source>
          <target state="translated">&lt;strong&gt;input_list&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 축소 및 분산 할 텐서 목록입니다.</target>
        </trans-unit>
        <trans-unit id="717931cd002baccf50d9c1a13fdb425f6fc9f174" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_names&lt;/strong&gt; (&lt;em&gt;list of strings&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty list&lt;/em&gt;) &amp;ndash; names to assign to the input nodes of the graph, in order</source>
          <target state="translated">&lt;strong&gt;input_names&lt;/strong&gt; ( &lt;em&gt;문자열 목록 &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;기본 빈 목록&lt;/em&gt; ) &amp;ndash; 그래프의 입력 노드에 순서대로 할당 할 이름</target>
        </trans-unit>
        <trans-unit id="9f6472508915540bb1432835a90442a80c1103a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_size&lt;/strong&gt; &amp;ndash; The number of expected features in the input &lt;code&gt;x&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;input_size&lt;/strong&gt; &amp;ndash; 입력 &lt;code&gt;x&lt;/code&gt; 에서 예상되는 기능의 수</target>
        </trans-unit>
        <trans-unit id="c79f2d549859c0d70790524045ea3d4bb1424ec0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_tensor_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to scatter one per rank.</source>
          <target state="translated">&lt;strong&gt;input_tensor_list&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 랭크 당 하나씩 분산 할 텐서 목록입니다.</target>
        </trans-unit>
        <trans-unit id="a9e6c1bd49660ef92968bbc7c3dbb9f033fb2e46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors(on different GPUs) to be broadcast from current process. Note that &lt;code&gt;len(input_tensor_list)&lt;/code&gt; needs to be the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;input_tensor_list&lt;/strong&gt; ( &lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 현재 프로세스에서 브로드 캐스트 할 텐서 (다른 GPU에있는) 목록입니다. 참고 &lt;code&gt;len(input_tensor_list)&lt;/code&gt; 요구가이 함수를 호출하는 모든 분산 된 프로세스에 대해 동일합니다.</target>
        </trans-unit>
        <trans-unit id="22e3bf528f143b22c44616b9a8dc2f788e501ebd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_tensor_lists&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;input_tensor_lists&lt;/strong&gt; ( &lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="e3999ded48b1c7630b579dd8899eda50d65501cf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;input_to_model&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;list of torch.Tensor&lt;/em&gt;) &amp;ndash; A variable or a tuple of variables to be fed.</source>
          <target state="translated">&lt;strong&gt;input_to_model&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;torch.Tensor &lt;em&gt;목록&lt;/em&gt; ) &amp;ndash; &lt;em&gt;공급할&lt;/em&gt; 변수 또는 변수 튜플입니다.</target>
        </trans-unit>
        <trans-unit id="f2029d7d088f0d74beff905706cfd5a1a9481029" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; A dict containing sample inputs indexed by method names in &lt;code&gt;mod&lt;/code&gt;. The inputs will be passed to methods whose names correspond to inputs&amp;rsquo; keys while tracing. &lt;code&gt;{ 'forward' : example_forward_input, 'method2': example_method2_input}&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;inputs&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt; ) &amp;ndash; &lt;code&gt;mod&lt;/code&gt; 에서 메서드 이름으로 인덱싱 된 샘플 입력을 포함하는 dict 입니다. 입력은 추적하는 동안 이름이 입력의 키에 해당하는 메서드로 전달됩니다. &lt;code&gt;{ 'forward' : example_forward_input, 'method2': example_method2_input}&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="259474d5c791b17db10ad248774065b0e9b78321" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inputs&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; inputs to the module</source>
          <target state="translated">&lt;strong&gt;입력&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모듈에 대한 입력</target>
        </trans-unit>
        <trans-unit id="f465a3e8d61ca508a03930e50b813d53ad7144f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;inverse_indices&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): (optional) if &lt;code&gt;return_inverse&lt;/code&gt; is True, there will be an additional returned tensor (same shape as input) representing the indices for where elements in the original input map to in the output; otherwise, this function will only return a single tensor.</source>
          <target state="translated">&lt;strong&gt;inverse_indices&lt;/strong&gt; ( &lt;em&gt;Tensor&lt;/em&gt; ) : (선택 사항) &lt;code&gt;return_inverse&lt;/code&gt; 가 True이면 원래 입력의 요소가 출력에서 ​​매핑되는 위치에 대한 인덱스를 나타내는 추가 반환 된 텐서 (입력과 동일한 모양)가 있습니다. 그렇지 않으면이 함수는 단일 텐서 만 반환합니다.</target>
        </trans-unit>
        <trans-unit id="d10b06bfdce2639f080a4d99b489d84dd548cc49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;is_master&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; True when initializing the server store, False for client stores.</source>
          <target state="translated">&lt;strong&gt;is_master&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 서버 저장소를 초기화 할 때 True, 클라이언트 저장소의 경우 False입니다.</target>
        </trans-unit>
        <trans-unit id="862ecdae56fdc1758ca8dd0945b92aba6b666d54" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;is_python_module&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt; (default), imports the produced shared library as a Python module. If &lt;code&gt;False&lt;/code&gt;, loads it into the process as a plain dynamic library.</source>
          <target state="translated">&lt;strong&gt;is_python_module&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; (기본값)이면 생성 된 공유 라이브러리를 Python 모듈로 가져옵니다. 만약 &lt;code&gt;False&lt;/code&gt; 일반 동적 라이브러리와 같은 과정으로,로드합니다.</target>
        </trans-unit>
        <trans-unit id="c36211dc611d5f7962125dc176c17631f0fc9ec6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; &amp;ndash; additive factor. Default: 1</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt; &amp;ndash; 가산 계수. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="e95587d3412a9d195f0a6e77a6567373e57381f7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; k for the k-th smallest element</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; k 번째로 작은 요소의 경우 k</target>
        </trans-unit>
        <trans-unit id="010b00e48fedcebcad1d2f9692050c44dd1f26ea" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of times to rotate</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 회전 횟수</target>
        </trans-unit>
        <trans-unit id="f1a820c8c605e02de337a9983694a9f1d90c85ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the k in &amp;ldquo;top-k&amp;rdquo;</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; &quot;top-k&quot;의 ​​k</target>
        </trans-unit>
        <trans-unit id="e84cdd778b11f55c6727a09ff5312f00f77186ba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;k&lt;/strong&gt; (&lt;em&gt;integer&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of requested eigenpairs. Default is the number of</source>
          <target state="translated">&lt;strong&gt;k&lt;/strong&gt; ( &lt;em&gt;integer &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 요청 된 고유 쌍의 수. 기본값은</target>
        </trans-unit>
        <trans-unit id="46176694182befc26b76cf4ee9533bb916707744" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kdim&lt;/strong&gt; &amp;ndash; total number of features in key. Default: None.</source>
          <target state="translated">&lt;strong&gt;kdim&lt;/strong&gt; &amp;ndash; 키의 총 기능 수입니다. 기본값 : 없음.</target>
        </trans-unit>
        <trans-unit id="057988e71b8851f3d3a181e82f00cb24d94ed154" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keep_initializers_as_inputs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default None&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;keep_initializers_as_inputs&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;기본값 없음&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="16ca1136f6f7d7eedc320cddba2ed4a25d910b78" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 출력 텐서가 &lt;code&gt;dim&lt;/code&gt; 유지 되었는지 여부</target>
        </trans-unit>
        <trans-unit id="18f7933e87f35c73c988304272aacb2824e2088e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not.</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 출력 텐서가 &lt;code&gt;dim&lt;/code&gt; 유지 되었는지 여부 .</target>
        </trans-unit>
        <trans-unit id="b8941cf07c98d813d55809e96bc7f701eb5365e5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 출력 텐서가 &lt;code&gt;dim&lt;/code&gt; 유지 되었는지 여부 . 기본값 : &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5cc82008e4660ec6acca882ad0953eda363fe762" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the output tensor has &lt;code&gt;dim&lt;/code&gt; retained or not. Ignored if &lt;code&gt;dim=None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 출력 텐서가 &lt;code&gt;dim&lt;/code&gt; 유지 되었는지 여부 . &lt;code&gt;dim=None&lt;/code&gt; 이면 무시됩니다 .</target>
        </trans-unit>
        <trans-unit id="e56a9eeb53ccea32a9904a25d931267678cd1dec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Determines whether or not to keep the vector dimension. Default: False</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 벡터 차원을 유지할지 여부를 결정합니다. 기본값 : False</target>
        </trans-unit>
        <trans-unit id="ad4ef3b64308f3d8dc47146285eef285afa65b13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If set to True, the reduced dimensions are retained in the result as dimensions with size one. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; True로 설정하면 축소 된 치수가 크기가 1 인 치수로 결과에 유지됩니다. 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="49656d1fc9d8e7326c0f9cd0a4a399d7d00a8efc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keepdim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether the output tensors have &lt;code&gt;dim&lt;/code&gt; retained or not. Ignored if &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;keepdim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서가 &lt;code&gt;dim&lt;/code&gt; 유지 여부 . &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; 이고 &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; 이면 무시됩니다 . 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e926f558ead95bc431753d8cae0a5a04ab0c981c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; The size of the sliding window, must be &amp;gt; 0.</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 슬라이딩 창의 크기는&amp;gt; 0이어야합니다.</target>
        </trans-unit>
        <trans-unit id="f384943e590807dc76a3468582f227aedc4a238c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; a single int, the size of the window</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 단일 정수, 창 크기</target>
        </trans-unit>
        <trans-unit id="572a73e28152cca7b78a46ac5637d93451f8a981" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; size of the pooling region. Can be a single number or a tuple &lt;code&gt;(kH, kW)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 풀링 영역의 크기. 단일 숫자 또는 튜플 &lt;code&gt;(kH, kW)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="014e7d7bdeac3998dbeeee898f78081432eebec9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; size of the pooling region. Can be a single number or a tuple &lt;code&gt;(kT, kH, kW)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 풀링 영역의 크기. 단일 숫자 또는 튜플 &lt;code&gt;(kT, kH, kW)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a26c47fa3182db8a890cdda0e99882bc0c208430" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 창의 크기</target>
        </trans-unit>
        <trans-unit id="6caea6991ef207d1f8220f4b3d0bf3cc83fa3f4e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window to take a max over</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 최대 값을 차지할 창의 크기</target>
        </trans-unit>
        <trans-unit id="771b7c3eece18f47a1bfb3f3eecd292084766b6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window to take a max over. Can be a single number k (for a square kernel of k x k) or a tuple &lt;code&gt;(kh, kw)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 최대 값을 차지할 창의 크기. 단일 숫자 k (kxk의 제곱 커널) 또는 튜플 &lt;code&gt;(kh, kw)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="86dbe9a6fa4b3ebfff876256dbee957af7b6f899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; the size of the window. Can be a single number or a tuple &lt;code&gt;(kW,)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; &amp;ndash; 창의 크기. 단일 숫자 또는 튜플 &lt;code&gt;(kW,)&lt;/code&gt; 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="6983b15f4f38a9ac825f42d5eb9c0f2f04b3cf67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Size of the convolving kernel</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 컨 볼빙 커널의 크기</target>
        </trans-unit>
        <trans-unit id="be2e08d3d82748f43712995275bcdf4a3dd15ad5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Size of the max pooling window.</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 최대 풀링 창의 크기입니다.</target>
        </trans-unit>
        <trans-unit id="cd3efc67efa8a3a8afc9e450066251f14074f4dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kernel_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the sliding blocks</source>
          <target state="translated">&lt;strong&gt;kernel_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 슬라이딩 블록의 크기</target>
        </trans-unit>
        <trans-unit id="0114fc6c0cd33e2cd2e18270605b3182ff85045a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key, and value have the same number of features.&lt;/strong&gt; (&lt;em&gt;query&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;키 및 값은 동일한 수의 기능을 갖습니다. &lt;/strong&gt;( &lt;em&gt;검색어 &lt;/em&gt;&lt;em&gt;,&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="84a1ee94b9552fbe98a263714fe34401d07c1736" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key, value&lt;/strong&gt; (&lt;em&gt;query&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash; map a query and a set of key-value pairs to an output. See &amp;ldquo;Attention Is All You Need&amp;rdquo; for more details.</source>
          <target state="translated">&lt;strong&gt;key, value&lt;/strong&gt; ( &lt;em&gt;query &lt;/em&gt;&lt;em&gt;,&lt;/em&gt; ) &amp;ndash; 쿼리와 키-값 쌍 집합을 출력에 매핑합니다. 자세한 내용은 &quot;주의가 필요한 모든 것&quot;을 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="f0822e8093f74e590339677b718f3d7e76f763f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The function will return the value associated with this key.</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash;이 함수는이 키와 관련된 값을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="b269c0df40f6a8dea8192305fc8edbdb790e8a51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The key in the store whose counter will be incremented.</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 카운터가 증가 할 저장소의 키입니다.</target>
        </trans-unit>
        <trans-unit id="a79165af1a31b78c12a0c79537ce451875db8c0a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The key to be added to the store.</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 저장소에 추가 할 키입니다.</target>
        </trans-unit>
        <trans-unit id="a420b4a7c78ffaa362bae22a02d609b5238dbdad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The key to be deleted from the store</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 저장소에서 삭제할 키</target>
        </trans-unit>
        <trans-unit id="dbc5adefc4e865a7f69b4455755c908e2aa6cbdc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; key to pop from the ModuleDict</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; ModuleDict에서 팝할 키</target>
        </trans-unit>
        <trans-unit id="4f26ac6300ccaa9e27a066b28715d3964edce7d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; key to pop from the ParameterDict</source>
          <target state="translated">&lt;strong&gt;key&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; ParameterDict에서 팝할 키</target>
        </trans-unit>
        <trans-unit id="78144a9a3d220664056838664be8661e6c3c9060" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;key_padding_mask&lt;/strong&gt; &amp;ndash; if provided, specified padding elements in the key will be ignored by the attention. When given a binary mask and a value is True, the corresponding value on the attention layer will be ignored. When given a byte mask and a value is non-zero, the corresponding value on the attention layer will be ignored</source>
          <target state="translated">&lt;strong&gt;key_padding_mask&lt;/strong&gt; &amp;ndash; 제공된 경우 키의 지정된 패딩 요소가주의에 의해 무시됩니다. 이진 마스크가 주어지고 값이 True이면 관심 레이어의 해당 값이 무시됩니다. 바이트 마스크가 주어지고 값이 0이 아닌 경우주의 레이어의 해당 값이 무시됩니다.</target>
        </trans-unit>
        <trans-unit id="64d040096feaaa3ad1d281fdbf7b1e7688897fff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;keys&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; List of keys on which to wait until they are set in the store.</source>
          <target state="translated">&lt;strong&gt;키&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;목록&lt;/a&gt; ) &amp;ndash; 상점에 설정 될 때까지 대기 할 키 목록입니다.</target>
        </trans-unit>
        <trans-unit id="f1a566ba7fd0d874e168c17e63abfc5faaeda0fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; any keyword argument (unused)</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; 모든 키워드 인수 (사용되지 않음)</target>
        </trans-unit>
        <trans-unit id="266f88e78551cdfc4dd3b12f3bdb84242fe5cbc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; arguments to pass to the optimizer constructor on each worker.</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; 각 워커의 최적화 생성자에 전달할 인수입니다.</target>
        </trans-unit>
        <trans-unit id="792aa49fbbca0bb348cbf77a79dc714af59b3ad2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; keyword arguments passed on to a subclass of a &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod&quot;&gt; &lt;code&gt;BasePruningMethod&lt;/code&gt; &lt;/a&gt; 의 서브 클래스에 전달되는 키워드 인수</target>
        </trans-unit>
        <trans-unit id="fedd0f20c005d43f5156a1e433f31ab84c26bd81" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; keyword arguments passed on to a subclass of a &lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt;&lt;code&gt;BasePruningMethod&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; &lt;a href=&quot;torch.nn.utils.prune.basepruningmethod#torch.nn.utils.prune.BasePruningMethod&quot;&gt; &lt;code&gt;BasePruningMethod&lt;/code&gt; &lt;/a&gt; 의 서브 클래스에 전달되는 키워드 인수</target>
        </trans-unit>
        <trans-unit id="1c0b946c6e8e6d58a96c5dc6767edc5a0986bd04" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; other keyword arguments such as: amount (int or float): quantity of parameters to prune across the specified parameters. If &lt;code&gt;float&lt;/code&gt;, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If &lt;code&gt;int&lt;/code&gt;, it represents the absolute number of parameters to prune.</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; &amp;ndash; 다음과 같은 기타 키워드 인수 : amount (int 또는 float) : 지정된 매개 변수에서 제거 할 매개 변수의 양. &lt;code&gt;float&lt;/code&gt; 인 경우 0.0과 1.0 사이 여야하며 프 루닝 할 매개 변수의 비율을 나타냅니다. 경우 &lt;code&gt;int&lt;/code&gt; , 그것을 비우기 파라미터의 절대 값을 나타낸다.</target>
        </trans-unit>
        <trans-unit id="d0fd99fc795f5d48a5e60df282d78e00104ba241" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;kwargs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; is a dictionary of keyword arguments for the &lt;code&gt;func&lt;/code&gt; invocation.</source>
          <target state="translated">&lt;strong&gt;kwargs&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt; ) &amp;ndash; &lt;code&gt;func&lt;/code&gt; 호출을 위한 키워드 인수의 사전입니다 .</target>
        </trans-unit>
        <trans-unit id="13138447f871c2af389a4fca56a99836f8077860" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;label_img&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Images correspond to each data point</source>
          <target state="translated">&lt;strong&gt;label_img&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt; ) &amp;ndash; 이미지는 각 데이터 포인트에 해당합니다.</target>
        </trans-unit>
        <trans-unit id="c49724fe69a85b49c33c508646fb23cf737c434f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;labels&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Ground truth data. Binary label for each element.</source>
          <target state="translated">&lt;strong&gt;labels&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array &lt;/em&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;string / blobname&lt;/em&gt; ) &amp;ndash; Ground Truth 데이터입니다. 각 요소에 대한 이진 레이블입니다.</target>
        </trans-unit>
        <trans-unit id="264535b79c947ac6ae0426c447265ae41129aa0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lambd&lt;/strong&gt; &amp;ndash; the</source>
          <target state="translated">&lt;strong&gt;lambd&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="1661e6401aad1339abbf5bd62f0c278ec8d6d90e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;largest&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return largest or smallest elements</source>
          <target state="translated">&lt;strong&gt;가장 큰&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 가장 큰 요소 또는 가장 작은 요소를 반환할지 여부를 제어합니다.</target>
        </trans-unit>
        <trans-unit id="fdf7fc35f25f5906a12f37c633b280b391c3c3d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;largest&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; when True, solve the eigenproblem for the largest eigenvalues. Otherwise, solve the eigenproblem for smallest eigenvalues. Default is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;최대&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; True 인 경우 가장 큰 고유 값에 대한 고유 문제를 해결합니다. 그렇지 않으면 가장 작은 고유 값에 대한 고유 문제를 풉니 다. 기본값은 &lt;code&gt;True&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="3c816953802bf0955cc5760c186166581884c57d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;last element is the size of the input, or the ending index position of the last bag&lt;/strong&gt; (&lt;em&gt;The&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;마지막 요소는 입력의 크기 또는 마지막 백의 끝 인덱스 위치입니다&lt;/strong&gt; ( &lt;em&gt;The&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="88e9ebec7af1894b1a89ea6a01d54fd47775eace" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; currently only support &lt;code&gt;torch.strided&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;레이아웃&lt;/strong&gt; ( &lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt; , 선택 사항) &amp;ndash; 현재 &lt;code&gt;torch.strided&lt;/code&gt; 만 지원 합니다 .</target>
        </trans-unit>
        <trans-unit id="7bf3f4fbf68fed19ae95979f8c8178ebe6d46e40" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired layout of returned Tensor. Default: &lt;code&gt;torch.strided&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;layout&lt;/strong&gt; ( &lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt; , 선택 사항) &amp;ndash; 반환 된 Tensor의 원하는 레이아웃입니다. 기본값 : &lt;code&gt;torch.strided&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="94414c640396bd9bbbf2ad80f1e3206b610ac0ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired layout of returned tensor. Default: if &lt;code&gt;None&lt;/code&gt;, defaults to the layout of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;layout&lt;/strong&gt; ( &lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt; , 선택 사항) &amp;ndash; 반환 된 텐서의 원하는 레이아웃입니다. 기본값 : &lt;code&gt;None&lt;/code&gt; 이면 &lt;code&gt;input&lt;/code&gt; 의 레이아웃이 기본값 입니다.</target>
        </trans-unit>
        <trans-unit id="0db1c24c17c8fb5d6f179479b0b643184229505b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired layout of returned window tensor. Only &lt;code&gt;torch.strided&lt;/code&gt; (dense layout) is supported.</source>
          <target state="translated">&lt;strong&gt;layout&lt;/strong&gt; ( &lt;a href=&quot;../tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt; , 선택 사항) &amp;ndash; 반환 된 창 텐서의 원하는 레이아웃입니다. 만 &lt;code&gt;torch.strided&lt;/code&gt; (조밀 한 레이아웃)이 지원됩니다.</target>
        </trans-unit>
        <trans-unit id="46d7f78e6035019338c7eef0206b97309c29f933" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;layout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; {categoryName: &lt;em&gt;charts&lt;/em&gt;}, where &lt;em&gt;charts&lt;/em&gt; is also a dictionary {chartName: &lt;em&gt;ListOfProperties&lt;/em&gt;}. The first element in &lt;em&gt;ListOfProperties&lt;/em&gt; is the chart&amp;rsquo;s type (one of &lt;strong&gt;Multiline&lt;/strong&gt; or &lt;strong&gt;Margin&lt;/strong&gt;) and the second element should be a list containing the tags you have used in add_scalar function, which will be collected into the new chart.</source>
          <target state="translated">&lt;strong&gt;layout&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt; ) &amp;ndash; {categoryName : &lt;em&gt;charts&lt;/em&gt; }. 여기서 &lt;em&gt;charts&lt;/em&gt; 는 사전 {chartName : &lt;em&gt;ListOfProperties&lt;/em&gt; } 이기도합니다 . &lt;em&gt;ListOfProperties&lt;/em&gt; 의 첫 번째 요소 는 차트의 유형 ( &lt;strong&gt;Multiline&lt;/strong&gt; 또는 &lt;strong&gt;Margin&lt;/strong&gt; 중 하나 )이고 두 번째 요소는 새 차트로 수집 될 add_scalar 함수에서 사용한 태그를 포함하는 목록이어야합니다.</target>
        </trans-unit>
        <trans-unit id="e94626f3232ee79b88ea32ac6e17800f0711856b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the distance to the ending dimension</source>
          <target state="translated">&lt;strong&gt;length&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 끝 차원까지의 거리</target>
        </trans-unit>
        <trans-unit id="8f03be3c5e51ff8247aa0a57df0a1b4f93ee5396" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;length&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The amount to trim the signal by (i.e. the original signal length). (Default: whole signal)</source>
          <target state="translated">&lt;strong&gt;length&lt;/strong&gt; ( &lt;em&gt;선택 사항 &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 신호를 트리밍 할 양 (예 : 원래 신호 길이). (기본값 : 전체 신호)</target>
        </trans-unit>
        <trans-unit id="b4ad30add260bff538fca1a6ab975e7e36e60203" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lengths&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; list of sequences lengths of each batch element.</source>
          <target state="translated">&lt;strong&gt;lengths&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 각 배치 요소의 시퀀스 길이 목록입니다.</target>
        </trans-unit>
        <trans-unit id="e2ddc7f0cb0f7aa1279d7434e7a52c24cdfc3d5a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;linewidth&lt;/strong&gt; &amp;ndash; The number of characters per line for the purpose of inserting line breaks (default = 80). Thresholded matrices will ignore this parameter.</source>
          <target state="translated">&lt;strong&gt;linewidth&lt;/strong&gt; &amp;ndash; 줄 바꿈을 삽입하기위한 줄당 문자 수 (기본값 = 80). 임계 값 행렬은이 매개 변수를 무시합니다.</target>
        </trans-unit>
        <trans-unit id="9a0b73f33b90888a42c750b6b973c0a4519c14cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;list&lt;/strong&gt; (&lt;em&gt;tensor&lt;/em&gt;) &amp;ndash; List of input and output tensors of the collective. The function operates in-place and requires that each tensor to be a GPU tensor on different GPUs. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;list&lt;/strong&gt; ( &lt;em&gt;tensor&lt;/em&gt; ) &amp;ndash; 집합체의 입력 및 출력 텐서 목록입니다. 이 함수는 제자리에서 작동하며 각 텐서가 서로 다른 GPU의 GPU 텐서가되어야합니다. 또한 이 함수를 호출하는 모든 분산 프로세스에 대해 &lt;code&gt;len(tensor_list)&lt;/code&gt; 가 동일한 지 확인해야 합니다.</target>
        </trans-unit>
        <trans-unit id="a6af9ed1c4f286897f05981280cbd8b1f3ff4ebb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_dir&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Save directory location. Default is runs/&lt;strong&gt;CURRENT_DATETIME_HOSTNAME&lt;/strong&gt;, which changes after each run. Use hierarchical folder structure to compare between runs easily. e.g. pass in &amp;lsquo;runs/exp1&amp;rsquo;, &amp;lsquo;runs/exp2&amp;rsquo;, etc. for each new experiment to compare across them.</source>
          <target state="translated">&lt;strong&gt;log_dir&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 디렉토리 위치를 저장합니다. 기본값은 runs / &lt;strong&gt;CURRENT_DATETIME_HOSTNAME&lt;/strong&gt; 이며 각 실행 후에 변경됩니다. 계층 적 폴더 구조를 사용하여 실행간에 쉽게 비교할 수 있습니다. 예를 들어 각각의 새 실험을 비교하기 위해 'runs / exp1', 'runs / exp2'등을 전달합니다.</target>
        </trans-unit>
        <trans-unit id="e21a2b0779d46aa79f400ad4cdf3c0dba396033e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_input&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; the loss is computed as</source>
          <target state="translated">&lt;strong&gt;log_input&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; 인 경우 손실은 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="c6e337713f719f7f73fae5c0a44576d8936beac7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_input&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt; the loss is computed as</source>
          <target state="translated">&lt;strong&gt;log_input&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;True&lt;/code&gt; 인 경우 손실은 다음과 같이 계산됩니다.</target>
        </trans-unit>
        <trans-unit id="0f3912ec8124045880111aeedd237bc31f76c3a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_probs&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;log_probs&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="a96e8db96ae8039870ee95945a0d311143381324" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_target&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; A flag indicating whether &lt;code&gt;target&lt;/code&gt; is passed in the log space. It is recommended to pass certain distributions (like &lt;code&gt;softmax&lt;/code&gt;) in the log space to avoid numerical issues caused by explicit &lt;code&gt;log&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;log_target&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; &lt;code&gt;target&lt;/code&gt; 이 로그 공간에서 전달 되는지 여부를 나타내는 플래그 입니다. 명시 적 &lt;code&gt;log&lt;/code&gt; 인한 수치 문제를 방지하기 위해 로그 공간에서 특정 분포 (예 : &lt;code&gt;softmax&lt;/code&gt; ) 를 전달하는 것이 좋습니다 . 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7071da2a7b3f7ca5a3045161a47ac564d02ec18a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;log_target&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies whether &lt;code&gt;target&lt;/code&gt; is passed in the log space. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;log_target&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;target&lt;/code&gt; 이 로그 공간에서 전달 되는지 여부를 지정합니다 . 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b5bfe7f9ad9a8759384f7463a9f5c13f4bcc1cdb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;logits&lt;/strong&gt; &amp;ndash; &lt;code&gt;[&amp;hellip;, num_features]&lt;/code&gt; unnormalized log probabilities</source>
          <target state="translated">&lt;strong&gt;로짓&lt;/strong&gt; &amp;ndash; &lt;code&gt;[&amp;hellip;, num_features]&lt;/code&gt; 비정규 화 된 로그 확률</target>
        </trans-unit>
        <trans-unit id="8bef4bf0c6f4823e7e112fc81eda3d3be435f702" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;loss&lt;/strong&gt; is a Scalar representing the computed negative log likelihood loss</source>
          <target state="translated">&lt;strong&gt;loss&lt;/strong&gt; 는 계산 된 음의 로그 우도 손실을 나타내는 스칼라입니다.</target>
        </trans-unit>
        <trans-unit id="70e041ec68422ba2e379d712b1ccecdb156099a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;low&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Lowest integer to be drawn from the distribution. Default: 0.</source>
          <target state="translated">&lt;strong&gt;low&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 분포에서 가져올 가장 낮은 정수입니다. 기본값 : 0.</target>
        </trans-unit>
        <trans-unit id="7c5a7d8df51ea63239d3ca2a365d80e7b7f44e08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;lower&lt;/strong&gt; &amp;ndash; lower bound of the uniform distribution. Default:</source>
          <target state="translated">&lt;strong&gt;하한&lt;/strong&gt; &amp;ndash; 균일 분포의 하한. 기본:</target>
        </trans-unit>
        <trans-unit id="4f0a9fa0370655d11d3532fe9815ce442456bb8a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;m&lt;/strong&gt; &amp;ndash; A &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; to save.</source>
          <target state="translated">&lt;strong&gt;m&lt;/strong&gt; &amp;ndash; 저장할 &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="fd123d273fbb02028d3c0300d6ad3c2fce942d1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;m&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of columns with default being &lt;code&gt;n&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;m&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 기본값이 &lt;code&gt;n&lt;/code&gt; 인 열 수</target>
        </trans-unit>
        <trans-unit id="70f0c622ba7f16dab21096968ca88594ae3eb5fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;main_tag&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; The parent name for the tags</source>
          <target state="translated">&lt;strong&gt;main_tag&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 태그의 상위 이름</target>
        </trans-unit>
        <trans-unit id="44bef03b746085c112465e22dd0b732f7855866e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;map_location&lt;/strong&gt; &amp;ndash; a function, &lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, string or a dict specifying how to remap storage locations</source>
          <target state="translated">&lt;strong&gt;map_location&lt;/strong&gt; &amp;ndash; a function, &lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;, string or a dict specifying how to remap storage locations</target>
        </trans-unit>
        <trans-unit id="ef33fe86d546f14a70960dd930eacfcbfad6910b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;map_location&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a function or a dict specifying how to remap storage locations (see torch.load)</source>
          <target state="translated">&lt;strong&gt;map_location&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a function or a dict specifying how to remap storage locations (see torch.load)</target>
        </trans-unit>
        <trans-unit id="914b80d642dfeaba6272f2de3bf65d1022719a77" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;map_location&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; A simplified version of &lt;code&gt;map_location&lt;/code&gt; in &lt;code&gt;torch.jit.save&lt;/code&gt; used to dynamically remap storages to an alternative set of devices.</source>
          <target state="translated">&lt;strong&gt;map_location&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; A simplified version of &lt;code&gt;map_location&lt;/code&gt; in &lt;code&gt;torch.jit.save&lt;/code&gt; used to dynamically remap storages to an alternative set of devices.</target>
        </trans-unit>
        <trans-unit id="a76d819de26b9a69327b4e9ff4618411dff8d317" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A non-negative margin representing the minimum difference between the positive and negative distances required for the loss to be 0. Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives. Default:</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; A non-negative margin representing the minimum difference between the positive and negative distances required for the loss to be 0. Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives. Default:</target>
        </trans-unit>
        <trans-unit id="d33d454f6271f798670e376263ffba9cbf000630" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Default:</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Default:</target>
        </trans-unit>
        <trans-unit id="56ee260326698f65dd6b6c40f6a508083eb54156" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of</target>
        </trans-unit>
        <trans-unit id="024e1f6072ab1c5c9f6954c815378eb35255dec0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of &lt;code&gt;1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0a1c2406f918b1a2ebe9a9c579789d15e7910666" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Should be a number from</source>
          <target state="translated">&lt;strong&gt;margin&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Should be a number from</target>
        </trans-unit>
        <trans-unit id="dc236878c72bde16cfeffe2cac289d6375b4d7f4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; &amp;ndash; the mask for the src sequence (optional).</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt; &amp;ndash; the mask for the src sequence (optional).</target>
        </trans-unit>
        <trans-unit id="e18ffc51ffd4959b08fbd0a3bfc5fa56421b9e3e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; the boolean mask</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; the boolean mask</target>
        </trans-unit>
        <trans-unit id="6415d8f4fc74353778af124a9edd9fa991dc2d49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; the tensor containing the binary mask to index with</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.BoolTensor&quot;&gt;BoolTensor&lt;/a&gt;) &amp;ndash; the tensor containing the binary mask to index with</target>
        </trans-unit>
        <trans-unit id="09b9037dad942fd7a7535f675e34e4544c3bd0e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; binary mask to be applied to the parameter.</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; binary mask to be applied to the parameter.</target>
        </trans-unit>
        <trans-unit id="e34cd5d03db7bc2e1ff2fedd665486796048ea46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mask&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; a SparseTensor which we filter &lt;code&gt;input&lt;/code&gt; based on its indices</source>
          <target state="translated">&lt;strong&gt;mask&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; a SparseTensor which we filter &lt;code&gt;input&lt;/code&gt; based on its indices</target>
        </trans-unit>
        <trans-unit id="e019f9c4c52d2f155730f344ebf436e60e0683e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first matrix to be multiplied</target>
        </trans-unit>
        <trans-unit id="3b6257ac15daec460e7856dfaf4bb8570f4c2d6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat1&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; a sparse matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat1&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; a sparse matrix to be multiplied</target>
        </trans-unit>
        <trans-unit id="0d5be763c9e61f15bd0bc4d527929a6c1dd8cf14" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat1&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; the first sparse matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat1&lt;/strong&gt; (&lt;em&gt;SparseTensor&lt;/em&gt;) &amp;ndash; the first sparse matrix to be multiplied</target>
        </trans-unit>
        <trans-unit id="98880e96bbe3ad0fcc2eae35bc3ea2b501838cf1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second batch of matrices to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second batch of matrices to be multiplied</target>
        </trans-unit>
        <trans-unit id="0dc66f375564c02c1c9b573824bb73a7b00eaf7d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second matrix to be multiplied</target>
        </trans-unit>
        <trans-unit id="f696dccd1ae44ddee20d75e7dbc3ff06722bc099" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a dense matrix be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a dense matrix be multiplied</target>
        </trans-unit>
        <trans-unit id="b94541c2bb36a977f8a383b6790acb61c7f9672c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second dense matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second dense matrix to be multiplied</target>
        </trans-unit>
        <trans-unit id="1b163b780efadeab4d13fd7393ace98318c94610" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; matrix to be multiplied</source>
          <target state="translated">&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; matrix to be multiplied</target>
        </trans-unit>
        <trans-unit id="02d4e6fa23ead0a267a7e63391cb2505b4395991" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a dense matrix to be added</source>
          <target state="translated">&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a dense matrix to be added</target>
        </trans-unit>
        <trans-unit id="a658df425748dff8f4417d65ab2c445b2fdf38ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;) &amp;ndash; A matrix which each row is the feature vector of the data point</source>
          <target state="translated">&lt;strong&gt;mat&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;) &amp;ndash; A matrix which each row is the feature vector of the data point</target>
        </trans-unit>
        <trans-unit id="d80f81e280edcd37fa8ee208223d3ff8f1c41090" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;matrices&lt;/strong&gt; (&lt;em&gt;Tensors...&lt;/em&gt;) &amp;ndash; a sequence of 2 or more 2-D tensors whose product is to be determined.</source>
          <target state="translated">&lt;strong&gt;matrices&lt;/strong&gt; (&lt;em&gt;Tensors...&lt;/em&gt;) &amp;ndash; a sequence of 2 or more 2-D tensors whose product is to be determined.</target>
        </trans-unit>
        <trans-unit id="85dfbb6d8965fcf255941fecf0a3f9636ed92d49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; upper end of the range (inclusive)</source>
          <target state="translated">&lt;strong&gt;max&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; upper end of the range (inclusive)</target>
        </trans-unit>
        <trans-unit id="ebd724e75db34df9a1697eb48e3e36ab4d0a6944" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; maximal value of each element in the output</source>
          <target state="translated">&lt;strong&gt;max&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; maximal value of each element in the output</target>
        </trans-unit>
        <trans-unit id="408cb0787a19c61a9e10d267b40c421e0d8c65b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; upper-bound of the range to be clamped to</source>
          <target state="translated">&lt;strong&gt;max&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; upper-bound of the range to be clamped to</target>
        </trans-unit>
        <trans-unit id="18d2c9f69eba48f7e795f2b2a4286820cf804061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; max norm of the gradients</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; max norm of the gradients</target>
        </trans-unit>
        <trans-unit id="d4b953b25b1cba200ce3cd937a97f9f2c77d5eca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, each embedding vector with norm larger than &lt;code&gt;max_norm&lt;/code&gt; is renormalized to have norm &lt;code&gt;max_norm&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, each embedding vector with norm larger than &lt;code&gt;max_norm&lt;/code&gt; is renormalized to have norm &lt;code&gt;max_norm&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7395b83c4b6884514e3400766844db4079e5559" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, each embedding vector with norm larger than &lt;code&gt;max_norm&lt;/code&gt; is renormalized to have norm &lt;code&gt;max_norm&lt;/code&gt;. Note: this will modify &lt;code&gt;weight&lt;/code&gt; in-place.</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, each embedding vector with norm larger than &lt;code&gt;max_norm&lt;/code&gt; is renormalized to have norm &lt;code&gt;max_norm&lt;/code&gt; . Note: this will modify &lt;code&gt;weight&lt;/code&gt; in-place.</target>
        </trans-unit>
        <trans-unit id="ccc83f5976a7da4c6cce23bdc0f1b550bc1baf18" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</target>
        </trans-unit>
        <trans-unit id="616f5bd5271f84469f902e32daf9266f05355e51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;max_norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f11300b5f0eb3648d7a253d285d8f366217f4085" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_queue&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Size of the queue for pending events and summaries before one of the &amp;lsquo;add&amp;rsquo; calls forces a flush to disk. Default is ten items.</source>
          <target state="translated">&lt;strong&gt;max_queue&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Size of the queue for pending events and summaries before one of the &amp;lsquo;add&amp;rsquo; calls forces a flush to disk. Default is ten items.</target>
        </trans-unit>
        <trans-unit id="ac66a7d2aa72c2c8115cd465665fc5e11e447283" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;max_val&lt;/strong&gt; &amp;ndash; maximum value of the linear region range. Default: 1</source>
          <target state="translated">&lt;strong&gt;max_val&lt;/strong&gt; &amp;ndash; maximum value of the linear region range. Default: 1</target>
        </trans-unit>
        <trans-unit id="6600d2ace21bcb0602e70b0bbacf60b6d9d7c70c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;maxnorm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the maximum norm to keep each sub-tensor under</source>
          <target state="translated">&lt;strong&gt;maxnorm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the maximum norm to keep each sub-tensor under</target>
        </trans-unit>
        <trans-unit id="5a295daf527fa3a8e842c0df2995c65b39e71553" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; &amp;ndash; the mean of the normal distribution</source>
          <target state="translated">&lt;strong&gt;mean&lt;/strong&gt; &amp;ndash; the mean of the normal distribution</target>
        </trans-unit>
        <trans-unit id="a707f91e951faba9097d24d07d405e7ec311e6c6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor of per-element means</source>
          <target state="translated">&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor of per-element means</target>
        </trans-unit>
        <trans-unit id="08c50d1f521b5ba09f6ffb7ce6539bb06a4a3f5b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the mean for all distributions</source>
          <target state="translated">&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the mean for all distributions</target>
        </trans-unit>
        <trans-unit id="2955cca12dc9b4a6d69879869214d1c6770dfaaf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the mean for all distributions</source>
          <target state="translated">&lt;strong&gt;mean&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the mean for all distributions</target>
        </trans-unit>
        <trans-unit id="29ba1a569247c06dc81809a7bf872a0c7a96859b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory&lt;/strong&gt; &amp;ndash; the sequence from the last layer of the encoder (required).</source>
          <target state="translated">&lt;strong&gt;memory&lt;/strong&gt; &amp;ndash; the sequence from the last layer of the encoder (required).</target>
        </trans-unit>
        <trans-unit id="588fc531f83b03eab1da4a2dc038d37bcca7f732" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_efficient&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;memory_efficient&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="a683ca0a51a8aaad293fb3004568d17d8503ae0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_efficient&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; but slower. Default: &lt;em&gt;False&lt;/em&gt;. See &lt;a href=&quot;https://arxiv.org/pdf/1707.06990.pdf&quot;&gt;&amp;ldquo;paper&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">&lt;strong&gt;memory_efficient&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; but slower. Default: &lt;em&gt;False&lt;/em&gt;. See &lt;a href=&quot;https://arxiv.org/pdf/1707.06990.pdf&quot;&gt;&amp;ldquo;paper&amp;rdquo;&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="847323568a90086efa211de3ba9bf7786ee86423" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="60c76323a555a35cf5636b2f519a421ab878338e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c42c5648937cafb3804b61b720f4bb1140320b64" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cb50e6c46386db61725174c03fb49b8c28339fd5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; Specifies memory allocation order. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; Specifies memory allocation order. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5d82e413d97971822435897c587b2c7a54d9ab8b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;. Note that memory format of &lt;code&gt;self&lt;/code&gt; is going to be unaffected if &lt;code&gt;self.size()&lt;/code&gt; matches &lt;code&gt;sizes&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; the desired memory format of Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt; . Note that memory format of &lt;code&gt;self&lt;/code&gt; is going to be unaffected if &lt;code&gt;self.size()&lt;/code&gt; matches &lt;code&gt;sizes&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bce750b8912dc23c58101b3c62c2faebe272c06d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;. Note that memory format of &lt;code&gt;self&lt;/code&gt; is going to be unaffected if &lt;code&gt;self.size()&lt;/code&gt; matches &lt;code&gt;tensor.size()&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; the desired memory format of Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt; . Note that memory format of &lt;code&gt;self&lt;/code&gt; is going to be unaffected if &lt;code&gt;self.size()&lt;/code&gt; matches &lt;code&gt;tensor.size()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c209a0208ea88f4d30020b7c6ec0aa20f55f05ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.contiguous_format&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e31755556d7e8f828a7fc59bf5245af37dfc95a9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;a href=&quot;tensor_attributes#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; &lt;/a&gt;, optional) &amp;ndash; the desired memory format of returned Tensor. Default: &lt;code&gt;torch.preserve_format&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="287794474bd0369fafef4c83cd018633d29d34b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_format&lt;/strong&gt; (&lt;code&gt;torch.memory_format&lt;/code&gt;) &amp;ndash; the desired memory format for 4D parameters and buffers in this module (keyword only argument)</source>
          <target state="translated">&lt;strong&gt;memory_format&lt;/strong&gt; ( &lt;code&gt;torch.memory_format&lt;/code&gt; ) &amp;ndash; the desired memory format for 4D parameters and buffers in this module (keyword only argument)</target>
        </trans-unit>
        <trans-unit id="a5a2da6780e7a50206f83afa209cf1daa2cf9b20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for memory keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for memory keys per batch (optional).</target>
        </trans-unit>
        <trans-unit id="ad4fdd31c064f05525f133141ae55c8a9f9fb730" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the memory keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;memory_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the memory keys per batch (optional).</target>
        </trans-unit>
        <trans-unit id="915d393bbda00e2dfc80c100ff44fe1a257646ed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash; the additive mask for the encoder output (optional).</source>
          <target state="translated">&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash; the additive mask for the encoder output (optional).</target>
        </trans-unit>
        <trans-unit id="edbbc733c4baf5f4bca52c77bb7dfb7d5e94c518" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash; the mask for the memory sequence (optional).</source>
          <target state="translated">&lt;strong&gt;memory_mask&lt;/strong&gt; &amp;ndash; the mask for the memory sequence (optional).</target>
        </trans-unit>
        <trans-unit id="420038f9d23e71250d8fc76d6db641779f55d944" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;metadata&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; A list of labels, each element will be convert to string</source>
          <target state="translated">&lt;strong&gt;metadata&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; A list of labels, each element will be convert to string</target>
        </trans-unit>
        <trans-unit id="fbe6c83a85e6ac8b011f0e187353dedf1dd97a86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; select LOBPCG method. See the description of the function above. Default is &amp;ldquo;ortho&amp;rdquo;.</source>
          <target state="translated">&lt;strong&gt;method&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; select LOBPCG method. See the description of the function above. Default is &amp;ldquo;ortho&amp;rdquo;.</target>
        </trans-unit>
        <trans-unit id="d982ed54ceb117939247c462414b383f4294a298" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;method&lt;/strong&gt; (&lt;em&gt;subclass of BasePruningMethod&lt;/em&gt;) &amp;ndash; child pruning method to be added to the container.</source>
          <target state="translated">&lt;strong&gt;method&lt;/strong&gt; (&lt;em&gt;subclass of BasePruningMethod&lt;/em&gt;) &amp;ndash; child pruning method to be added to the container.</target>
        </trans-unit>
        <trans-unit id="ffaae191023c8ad384bc60a006a096527ebb2fe7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;metric_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Each key-value pair in the dictionary is the name of the metric and it&amp;rsquo;s corresponding value. Note that the key used here should be unique in the tensorboard record. Otherwise the value you added by &lt;code&gt;add_scalar&lt;/code&gt; will be displayed in hparam plugin. In most cases, this is unwanted.</source>
          <target state="translated">&lt;strong&gt;metric_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Each key-value pair in the dictionary is the name of the metric and it&amp;rsquo;s corresponding value. Note that the key used here should be unique in the tensorboard record. Otherwise the value you added by &lt;code&gt;add_scalar&lt;/code&gt; will be displayed in hparam plugin. In most cases, this is unwanted.</target>
        </trans-unit>
        <trans-unit id="6dd8004576bc7350c9204a1c0262ab2ddb2d227d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; lower end of the range (inclusive)</source>
          <target state="translated">&lt;strong&gt;min&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; lower end of the range (inclusive)</target>
        </trans-unit>
        <trans-unit id="cef73dc49333eeeba5dd9f4d0c270dee0f730953" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; lower-bound of the range to be clamped to</source>
          <target state="translated">&lt;strong&gt;min&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; lower-bound of the range to be clamped to</target>
        </trans-unit>
        <trans-unit id="55821f56c0bcd501a5ab8f1798c3910d8b63ffff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; minimal value of each element in the output</source>
          <target state="translated">&lt;strong&gt;min&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; minimal value of each element in the output</target>
        </trans-unit>
        <trans-unit id="894532a159ed88aec99c8849664d2c1374ab2e44" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;min_val&lt;/strong&gt; &amp;ndash; minimum value of the linear region range. Default: -1</source>
          <target state="translated">&lt;strong&gt;min_val&lt;/strong&gt; &amp;ndash; minimum value of the linear region range. Default: -1</target>
        </trans-unit>
        <trans-unit id="a625bfe7a46218038f5b0ece187b38a8f18c7b30" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;minlength&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; optional, minimum number of bins. Should be non-negative.</source>
          <target state="translated">&lt;strong&gt;minlength&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; optional, minimum number of bins. Should be non-negative.</target>
        </trans-unit>
        <trans-unit id="d62614dd84cb7f7218048107638c24812180feed" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;missing_keys&lt;/strong&gt; is a list of str containing the missing keys</source>
          <target state="translated">&lt;strong&gt;missing_keys&lt;/strong&gt; is a list of str containing the missing keys</target>
        </trans-unit>
        <trans-unit id="311fd585d83045aa88cc3eccbed4762dcd351324" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mod&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; a float module, either produced by torch.quantization utilities or provided by the user</source>
          <target state="translated">&lt;strong&gt;mod&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; a float module, either produced by torch.quantization utilities or provided by the user</target>
        </trans-unit>
        <trans-unit id="84a7cd86ad210aba9a85651fe50b04b508106e2f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mod&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; A &lt;code&gt;torch.nn.Module&lt;/code&gt; containing methods whose names are specified in &lt;code&gt;inputs&lt;/code&gt;. The given methods will be compiled as a part of a single &lt;code&gt;ScriptModule&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;mod&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; A &lt;code&gt;torch.nn.Module&lt;/code&gt; containing methods whose names are specified in &lt;code&gt;inputs&lt;/code&gt; . The given methods will be compiled as a part of a single &lt;code&gt;ScriptModule&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f3ad16e3543c64bbf2963c9325a83ed0fc537280" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; &amp;ndash; &lt;code&gt;'constant'&lt;/code&gt;, &lt;code&gt;'reflect'&lt;/code&gt;, &lt;code&gt;'replicate'&lt;/code&gt; or &lt;code&gt;'circular'&lt;/code&gt;. Default: &lt;code&gt;'constant'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; &amp;ndash; &lt;code&gt;'constant'&lt;/code&gt; , &lt;code&gt;'reflect'&lt;/code&gt; , &lt;code&gt;'replicate'&lt;/code&gt; or &lt;code&gt;'circular'&lt;/code&gt; . Default: &lt;code&gt;'constant'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3ead1532b9e3bb8d41618811a33c97bd27a1a40b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; &amp;ndash; either &lt;code&gt;'fan_in'&lt;/code&gt; (default) or &lt;code&gt;'fan_out'&lt;/code&gt;. Choosing &lt;code&gt;'fan_in'&lt;/code&gt; preserves the magnitude of the variance of the weights in the forward pass. Choosing &lt;code&gt;'fan_out'&lt;/code&gt; preserves the magnitudes in the backwards pass.</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; &amp;ndash; either &lt;code&gt;'fan_in'&lt;/code&gt; (default) or &lt;code&gt;'fan_out'&lt;/code&gt; . Choosing &lt;code&gt;'fan_in'&lt;/code&gt; preserves the magnitude of the variance of the weights in the forward pass. Choosing &lt;code&gt;'fan_out'&lt;/code&gt; preserves the magnitudes in the backwards pass.</target>
        </trans-unit>
        <trans-unit id="de67441ea808eb9718fb3c1203b927e8646bf7b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Controls whether to enable flush denormal mode or not</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Controls whether to enable flush denormal mode or not</target>
        </trans-unit>
        <trans-unit id="5f0ebb80a4f6d234b3bdc8d88adb240b1631fa72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag whether to enable grad (&lt;code&gt;True&lt;/code&gt;), or disable (&lt;code&gt;False&lt;/code&gt;). This can be used to conditionally enable gradients.</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Flag whether to enable grad ( &lt;code&gt;True&lt;/code&gt; ), or disable ( &lt;code&gt;False&lt;/code&gt; ). This can be used to conditionally enable gradients.</target>
        </trans-unit>
        <trans-unit id="c77c2993453675a1ae62a895e8af92b271ac8912" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to set training mode (&lt;code&gt;True&lt;/code&gt;) or evaluation mode (&lt;code&gt;False&lt;/code&gt;). Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to set training mode ( &lt;code&gt;True&lt;/code&gt; ) or evaluation mode ( &lt;code&gt;False&lt;/code&gt; ). Default: &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d7c74d3b555f009043988d195fb2bcd2f8149f0e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f9c27d3e94ffaa56b5363537c49d87d1a211071d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt; | &lt;code&gt;'area'&lt;/code&gt;. Default: &lt;code&gt;'nearest'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt; | &lt;code&gt;'area'&lt;/code&gt; . Default: &lt;code&gt;'nearest'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="385c5b4f0ae5e9736769d454130ca5949542ab90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; interpolation mode to calculate output values &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'nearest'&lt;/code&gt;. Default: &lt;code&gt;'bilinear'&lt;/code&gt; Note: When &lt;code&gt;mode='bilinear'&lt;/code&gt; and the input is 5-D, the interpolation mode used internally will actually be trilinear. However, when the input is 4-D, the interpolation mode will legitimately be bilinear.</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; interpolation mode to calculate output values &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'nearest'&lt;/code&gt; . Default: &lt;code&gt;'bilinear'&lt;/code&gt; Note: When &lt;code&gt;mode='bilinear'&lt;/code&gt; and the input is 5-D, the interpolation mode used internally will actually be trilinear. However, when the input is 4-D, the interpolation mode will legitimately be bilinear.</target>
        </trans-unit>
        <trans-unit id="4471a06de253ea298b84fb5695bcc2a35de32568" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the upsampling algorithm: one of &lt;code&gt;'nearest'&lt;/code&gt;, &lt;code&gt;'linear'&lt;/code&gt;, &lt;code&gt;'bilinear'&lt;/code&gt;, &lt;code&gt;'bicubic'&lt;/code&gt; and &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;'nearest'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the upsampling algorithm: one of &lt;code&gt;'nearest'&lt;/code&gt; , &lt;code&gt;'linear'&lt;/code&gt; , &lt;code&gt;'bilinear'&lt;/code&gt; , &lt;code&gt;'bicubic'&lt;/code&gt; and &lt;code&gt;'trilinear'&lt;/code&gt; . Default: &lt;code&gt;'nearest'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e579f4ae9e49fbfc6b51a7253cb4e53b5007b03e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0454ac8b9a020a3d1a98ccef37fc6aef70ca1aae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt;. Default: &lt;code&gt;'nearest'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; algorithm used for upsampling: &lt;code&gt;'nearest'&lt;/code&gt; | &lt;code&gt;'linear'&lt;/code&gt; | &lt;code&gt;'bilinear'&lt;/code&gt; | &lt;code&gt;'bicubic'&lt;/code&gt; | &lt;code&gt;'trilinear'&lt;/code&gt; . Default: &lt;code&gt;'nearest'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ac9a2bfc1170980964589f394256a29c3c8507f9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt;, &lt;code&gt;&quot;mean&quot;&lt;/code&gt; or &lt;code&gt;&quot;max&quot;&lt;/code&gt;. Specifies the way to reduce the bag. &lt;code&gt;&quot;sum&quot;&lt;/code&gt; computes the weighted sum, taking &lt;code&gt;per_sample_weights&lt;/code&gt; into consideration. &lt;code&gt;&quot;mean&quot;&lt;/code&gt; computes the average of the values in the bag, &lt;code&gt;&quot;max&quot;&lt;/code&gt; computes the max value over each bag. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt; , &lt;code&gt;&quot;mean&quot;&lt;/code&gt; or &lt;code&gt;&quot;max&quot;&lt;/code&gt; . Specifies the way to reduce the bag. &lt;code&gt;&quot;sum&quot;&lt;/code&gt; computes the weighted sum, taking &lt;code&gt;per_sample_weights&lt;/code&gt; into consideration. &lt;code&gt;&quot;mean&quot;&lt;/code&gt; computes the average of the values in the bag, &lt;code&gt;&quot;max&quot;&lt;/code&gt; computes the max value over each bag. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c098c83728e1a75267ad9d800f600477ae405fc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt;, &lt;code&gt;&quot;mean&quot;&lt;/code&gt; or &lt;code&gt;&quot;max&quot;&lt;/code&gt;. Specifies the way to reduce the bag. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;&quot;sum&quot;&lt;/code&gt; , &lt;code&gt;&quot;mean&quot;&lt;/code&gt; or &lt;code&gt;&quot;max&quot;&lt;/code&gt; . Specifies the way to reduce the bag. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="83cf0f99fac2d6532263c56e5750c95e9d23633d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;&quot;mean&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cce56abc7cd237dbad132a5abb856634ed2030b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; Model to draw.</source>
          <target state="translated">&lt;strong&gt;model&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; Model to draw.</target>
        </trans-unit>
        <trans-unit id="c7f141d3875fe7470c5eeb6311e3f52659403c7c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; the model to be exported.</source>
          <target state="translated">&lt;strong&gt;model&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;torch.nn.Module&lt;/a&gt;) &amp;ndash; the model to be exported.</target>
        </trans-unit>
        <trans-unit id="5f38a617ca9f3ce30bb1aa507b57c0f8b9bb5233" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; a string of entrypoint name defined in repo&amp;rsquo;s hubconf.py</source>
          <target state="translated">&lt;strong&gt;model&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; a string of entrypoint name defined in repo&amp;rsquo;s hubconf.py</target>
        </trans-unit>
        <trans-unit id="522ae153c9de2225d354ad39a76bc7201f1315a4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; the name of a callable (entrypoint) defined in the repo/dir&amp;rsquo;s &lt;code&gt;hubconf.py&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;model&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; the name of a callable (entrypoint) defined in the repo/dir&amp;rsquo;s &lt;code&gt;hubconf.py&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="047b6c0ef907781caf5f3b90b83833193ffbb540" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;model_dir&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; directory in which to save the object</source>
          <target state="translated">&lt;strong&gt;model_dir&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; directory in which to save the object</target>
        </trans-unit>
        <trans-unit id="ff92bd1f8822db4dee990724fb95f189b28d6861" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; child module to be added to the module.</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; child module to be added to the module.</target>
        </trans-unit>
        <trans-unit id="4911eeef12d8491f308531700e789704028a53b0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; the module to evaluate in parallel</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; the module to evaluate in parallel</target>
        </trans-unit>
        <trans-unit id="c599015a8c55f21c464f35319477082682454deb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; child module to be added to the module.</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; child module to be added to the module.</target>
        </trans-unit>
        <trans-unit id="13729f6038be326761df6ac3ec24b201e785b71f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; containing module</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; containing module</target>
        </trans-unit>
        <trans-unit id="f81af303cce1d2b13d56b554d4c54084215c693d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; module to be parallelized</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; module to be parallelized</target>
        </trans-unit>
        <trans-unit id="af97e1697d5f0c0f0186596bfc816ba5d1b7233e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; containing module</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; containing module</target>
        </trans-unit>
        <trans-unit id="ca220270bc403ee33276152d6bc7a361e3f02584" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module containing one or more attr:&lt;code&gt;BatchNorm*D&lt;/code&gt; layers</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module containing one or more attr: &lt;code&gt;BatchNorm*D&lt;/code&gt; layers</target>
        </trans-unit>
        <trans-unit id="4aa37d25cda1e46d9840e5ce1e3bb87b97cabc4c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module containing the tensor to prune</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module containing the tensor to prune</target>
        </trans-unit>
        <trans-unit id="c58562dc7c80d28ea1d3eb37836c8dd81358feb4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module to append</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module to append</target>
        </trans-unit>
        <trans-unit id="49d181f6c9a5ed2484bd66e1605a7cd8ed49448c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module to insert</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; module to insert</target>
        </trans-unit>
        <trans-unit id="60a1ae701ce0942d303d74786dea8b40965fbefe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; object that is either pruned or unpruned</source>
          <target state="translated">&lt;strong&gt;module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;nn.Module&lt;/a&gt;) &amp;ndash; object that is either pruned or unpruned</target>
        </trans-unit>
        <trans-unit id="b1cf5810a0ac4510111b7830d78e712ab1696f2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; a mapping (dictionary) from string to &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt;, or an iterable of key-value pairs of type (string, &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt;)</source>
          <target state="translated">&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; a mapping (dictionary) from string to &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;, or an iterable of key-value pairs of type (string, &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;Module&lt;/code&gt; &lt;/a&gt;)</target>
        </trans-unit>
        <trans-unit id="36d886b50a323b839fe922cbffadfc70109408b5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; iterable of modules to append</source>
          <target state="translated">&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; iterable of modules to append</target>
        </trans-unit>
        <trans-unit id="f8c11c9ebc42a4e244f2c526e48d9476468d0936" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a mapping (dictionary) of (string: module) or an iterable of key-value pairs of type (string, module)</source>
          <target state="translated">&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a mapping (dictionary) of (string: module) or an iterable of key-value pairs of type (string, module)</target>
        </trans-unit>
        <trans-unit id="82d83ba7e9a63e6fb88f202a85d0e2b54d0d5137" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;modules&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; an iterable of modules to add</source>
          <target state="translated">&lt;strong&gt;모듈&lt;/strong&gt; ( &lt;em&gt;iterable &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 추가 할 모듈의 반복 가능</target>
        </trans-unit>
        <trans-unit id="338d2bdd3427c2acd5798eb121524c531792b37a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;momentum&lt;/strong&gt; &amp;ndash; the value used for the running_mean and running_var computation. Can be set to &lt;code&gt;None&lt;/code&gt; for cumulative moving average (i.e. simple average). Default: 0.1</source>
          <target state="translated">&lt;strong&gt;momentum&lt;/strong&gt; &amp;ndash; running_mean 및 running_var 계산에 사용되는 값입니다. 누적 이동 평균 (예 : 단순 평균)에 대해 &lt;code&gt;None&lt;/code&gt; 으로 설정할 수 있습니다 . 기본값 : 0.1</target>
        </trans-unit>
        <trans-unit id="2f0648d0e331c6484261bc1cae891f8cb0fe0f77" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;momentum&lt;/strong&gt; &amp;ndash; the value used for the running_mean and running_var computation. Default: 0.1</source>
          <target state="translated">&lt;strong&gt;momentum&lt;/strong&gt; &amp;ndash; running_mean 및 running_var 계산에 사용되는 값입니다. 기본값 : 0.1</target>
        </trans-unit>
        <trans-unit id="2ffcdc1e2419287f46a2eda06597a5711ebd39cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of rows</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 행 수</target>
        </trans-unit>
        <trans-unit id="a3afc73d777f69bfccc910de139a6b9b0a792a61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the order of the polygamma function</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 폴리 감마 함수의 순서</target>
        </trans-unit>
        <trans-unit id="8d0ffe3929c3dd260792f2cfcd25cf94c93f071d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the power to raise the matrix to</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 행렬을 올리는 힘</target>
        </trans-unit>
        <trans-unit id="bb3a47c4c5e60d1d87f9833a363f367729f6f4f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the upper bound (exclusive)</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 상한 (배타적)</target>
        </trans-unit>
        <trans-unit id="62cd9cb1469a9c478de28e4b1f09e1a6c903f1e0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt;) &amp;ndash; See documentation of valid entries for argument &lt;code&gt;p&lt;/code&gt; in &lt;a href=&quot;torch.norm#torch.norm&quot;&gt;&lt;code&gt;torch.norm()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro' &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt; ) &amp;ndash; &lt;a href=&quot;torch.norm#torch.norm&quot;&gt; &lt;code&gt;torch.norm()&lt;/code&gt; &lt;/a&gt; 인수 &lt;code&gt;p&lt;/code&gt; 에 대한 유효한 항목 문서를 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="360665e64fcf6fd508a3beb2effb1f77d9cc3d75" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Output signal length. This determines the length of the output signal. If given, the input will either be zero-padded or trimmed to this length before computing the real IFFT. Defaults to even output: &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 신호 길이. 이것은 출력 신호의 길이를 결정합니다. 주어진 경우 입력은 실제 IFFT를 계산하기 전에 0으로 채워지거나이 길이로 트리밍됩니다. 기본값은 짝수 출력입니다 : &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3f3dcf24d971f3f927b31f57cb8d0f3aa39957de" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Output signal length. This determines the length of the real output. If given, the input will either be zero-padded or trimmed to this length before computing the Hermitian FFT. Defaults to even output: &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 신호 길이. 이것은 실제 출력의 길이를 결정합니다. 주어진 경우 입력은 Hermitian FFT를 계산하기 전에 제로 패딩되거나이 길이로 트리밍됩니다. 기본값은 짝수 출력입니다 : &lt;code&gt;n=2*(input.size(dim) - 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="765bbbc030c273dcfddf61dec277dea877826f3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the FFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 신호 길이. 주어진 경우 입력은 0으로 채워지거나 FFT를 계산하기 전에이 길이로 트리밍됩니다.</target>
        </trans-unit>
        <trans-unit id="280814a17cd4d7c5c87be0ac03bb06c0096d600b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the Hermitian IFFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 신호 길이. 주어진 경우 입력은 Hermitian IFFT를 계산하기 전에 0으로 채워지거나이 길이로 트리밍됩니다.</target>
        </trans-unit>
        <trans-unit id="19a143bdd240b89803874ef31fae83cbc10ad3d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the IFFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 신호 길이. 주어진 경우 입력은 IFFT를 계산하기 전에 0으로 채워지거나이 길이로 트리밍됩니다.</target>
        </trans-unit>
        <trans-unit id="437d2ca26e7ac533d4bd5f39effee7652ff0b3a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the real FFT.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 신호 길이. 주어진 경우 입력은 실제 FFT를 계산하기 전에 0으로 채워지거나이 길이로 트리밍됩니다.</target>
        </trans-unit>
        <trans-unit id="8742179ec0bc2a9eaec8d9e4144c1b9a9f8cd29e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;) &amp;ndash; The number of steps to fast-forward by.</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;em&gt;Int&lt;/em&gt; ) &amp;ndash; 빨리 감을 단계 수입니다.</target>
        </trans-unit>
        <trans-unit id="0a8c721a95c8d2c05e104145a151d6fead527c01" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The length of sequence of points to draw. Default: 1</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;em&gt;Int &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 그릴 점 시퀀스의 길이입니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="86e79b2a07cba2a326622f21aedf96b60e044c1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n&lt;/strong&gt; (&lt;em&gt;integer&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if</source>
          <target state="translated">&lt;strong&gt;n&lt;/strong&gt; ( &lt;em&gt;정수 &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 경우</target>
        </trans-unit>
        <trans-unit id="9509b9869a54b18b43d0ef80248e150060481aa5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of classes in the dataset</source>
          <target state="translated">&lt;strong&gt;n_classes&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 데이터 세트의 클래스 수</target>
        </trans-unit>
        <trans-unit id="664468f137b786aae9b4053649115d89d17971a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_fft&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Size of Fourier transform</source>
          <target state="translated">&lt;strong&gt;n_fft&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 푸리에 변환의 크기</target>
        </trans-unit>
        <trans-unit id="64c539b9a2fc08964cebb89aafe82cd323a6d67b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_fft&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; size of Fourier transform</source>
          <target state="translated">&lt;strong&gt;n_fft&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 푸리에 변환의 크기</target>
        </trans-unit>
        <trans-unit id="73f1e40726186373d5acaec57f94cdeb84386c79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;n_power_iterations&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; number of power iterations to calculate spectral norm</source>
          <target state="translated">&lt;strong&gt;n_power_iterations&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 스펙트럼 표준을 계산하기위한 전력 반복 횟수</target>
        </trans-unit>
        <trans-unit id="be6a1d5fe41bddbb64767aa43f1844148b7a2d5d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; &amp;ndash; The name of the extension to build. This MUST be the same as the name of the pybind11 module!</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; &amp;ndash; 빌드 할 확장의 이름입니다. 이것은 pybind11 모듈의 이름과 동일해야합니다!</target>
        </trans-unit>
        <trans-unit id="8c69de6701f67b2c147cd64b9cd2a3b47551823b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; a globally unique name of this node. (e.g., &lt;code&gt;Trainer3&lt;/code&gt;, &lt;code&gt;ParameterServer2&lt;/code&gt;, &lt;code&gt;Master&lt;/code&gt;, &lt;code&gt;Worker1&lt;/code&gt;) Name can only contain number, alphabet, underscore, colon, and/or dash, and must be shorter than 128 characters.</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash;이 노드의 전역 적으로 고유 한 이름입니다. (예 : &lt;code&gt;Trainer3&lt;/code&gt; , &lt;code&gt;ParameterServer2&lt;/code&gt; , &lt;code&gt;Master&lt;/code&gt; , &lt;code&gt;Worker1&lt;/code&gt; ) 이름은 숫자, 알파벳, 밑줄, 콜론 및 / 또는 대시 만 포함 할 수 있으며 128 자 미만이어야합니다.</target>
        </trans-unit>
        <trans-unit id="5183afed8cf3601b43896332cb5eec33dea53c97" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; parameter name within &lt;code&gt;module&lt;/code&gt; on which pruning will act.</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 정리가 작동 할 &lt;code&gt;module&lt;/code&gt; 내의 매개 변수 이름 입니다.</target>
        </trans-unit>
        <trans-unit id="cd742c4f6eedba1b2162f8cb069fd19852c81f0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; name of weight parameter</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 가중치 매개 변수의 이름</target>
        </trans-unit>
        <trans-unit id="34a6862e100f7bbd8be83c2e2456ade36746f257" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; name of the buffer. The buffer can be accessed from this module using the given name</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 버퍼의 이름입니다. 주어진 이름을 사용하여이 모듈에서 버퍼에 액세스 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="0a86d2efe3016120aa2e1ea06fc78fd6bcd8369d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; name of the child module. The child module can be accessed from this module using the given name</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 하위 모듈의 이름입니다. 주어진 이름을 사용하여이 모듈에서 하위 모듈에 액세스 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="369152d10b48dccc5d7997cedd438126e9bd2abc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;name&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; name of the parameter. The parameter can be accessed from this module using the given name</source>
          <target state="translated">&lt;strong&gt;name&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 매개 변수의 이름입니다. 주어진 이름을 사용하여이 모듈에서 매개 변수에 액세스 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="c67b5abf72fae7d381fa3b1d37bcbc664d754902" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;names&lt;/strong&gt; (&lt;em&gt;iterable of str&lt;/em&gt;) &amp;ndash; The desired dimension ordering of the output tensor. May contain up to one Ellipsis that is expanded to all unmentioned dim names of &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;names&lt;/strong&gt; ( &lt;em&gt;iterable of str&lt;/em&gt; ) &amp;ndash; 출력 텐서의 원하는 차원 순서. 언급되지 않은 모든 희미한 &lt;code&gt;self&lt;/code&gt; 이름으로 확장되는 줄임표를 하나까지 포함 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="18ba741fd674f07602eeb307e77e22ffd8697dcb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;names&lt;/strong&gt; (&lt;em&gt;iterable of str&lt;/em&gt;) &amp;ndash; The desired names of the output tensor. May contain up to one Ellipsis.</source>
          <target state="translated">&lt;strong&gt;names&lt;/strong&gt; ( &lt;em&gt;str의 반복 가능&lt;/em&gt; ) &amp;ndash; 출력 텐서의 원하는 이름입니다. 최대 하나의 줄임표를 포함 할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="3dcce6a007ca6ff3a948d0e46c57a9b25d051833" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;need_weights&lt;/strong&gt; &amp;ndash; output attn_output_weights.</source>
          <target state="translated">&lt;strong&gt;need_weights&lt;/strong&gt; &amp;ndash; &lt;strong&gt;attn_output_weights를&lt;/strong&gt; 출력합니다.</target>
        </trans-unit>
        <trans-unit id="343ed070ed3d41cc4c3ee63a9a133db9d809bff0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;negative_slope&lt;/strong&gt; &amp;ndash; Controls the angle of the negative slope. Default: 1e-2</source>
          <target state="translated">&lt;strong&gt;negative_slope&lt;/strong&gt; &amp;ndash; 음의 경사 각도를 제어합니다. 기본값 : 1e-2</target>
        </trans-unit>
        <trans-unit id="c70cf625cede657dde5d0c120d5a1f74a918a253" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_state&lt;/strong&gt; (&lt;em&gt;torch.ByteTensor&lt;/em&gt;) &amp;ndash; The desired state</source>
          <target state="translated">&lt;strong&gt;new_state&lt;/strong&gt; ( &lt;em&gt;torch.ByteTensor&lt;/em&gt; ) &amp;ndash; 원하는 상태</target>
        </trans-unit>
        <trans-unit id="7fd74008cc5669b78289c4a9b06d25331220701d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;new_state&lt;/strong&gt; (&lt;em&gt;torch.ByteTensor&lt;/em&gt;) &amp;ndash; The desired state.</source>
          <target state="translated">&lt;strong&gt;new_state&lt;/strong&gt; ( &lt;em&gt;torch.ByteTensor&lt;/em&gt; ) &amp;ndash; 원하는 상태.</target>
        </trans-unit>
        <trans-unit id="3684197908f63147ef8bf8af4038b1e7eef5b679" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash; the number of heads in the multiheadattention models (default=8).</source>
          <target state="translated">&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash; 다중 헤드 &lt;strong&gt;어텐션&lt;/strong&gt; 모델의 헤드 수 (기본값 = 8).</target>
        </trans-unit>
        <trans-unit id="8c047d9990ce17c7638516b2eb9cd4d4eefd9f13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash; the number of heads in the multiheadattention models (required).</source>
          <target state="translated">&lt;strong&gt;nhead&lt;/strong&gt; &amp;ndash; 다중 헤드 &lt;strong&gt;어텐션&lt;/strong&gt; 모델의 헤드 수 (필수).</target>
        </trans-unit>
        <trans-unit id="bf9b1d87107478239f509cdbfbfba2359192e4ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;niter&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; maximum number of iterations. When reached, the iteration process is hard-stopped and the current approximation of eigenpairs is returned. For infinite iteration but until convergence criteria is met, use &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;niter&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 최대 반복 횟수. 도달하면 반복 프로세스가 강제 중지되고 고유 쌍의 현재 근사값이 반환됩니다. 무한 반복의 경우 수렴 기준이 충족 될 때까지 &lt;code&gt;-1&lt;/code&gt; 을 사용하십시오 .</target>
        </trans-unit>
        <trans-unit id="474b45a07e5133e74b4680b4ebef67231879479c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;niter&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of subspace iterations to conduct; niter must be a nonnegative integer, and defaults to 2.</source>
          <target state="translated">&lt;strong&gt;niter&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 수행 할 부분 공간 반복 횟수. niter는 음이 아닌 정수 여야하며 기본값은 2입니다.</target>
        </trans-unit>
        <trans-unit id="179187db6714db7b86343992867677ff4ff75191" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt; and the source is in pinned memory, the copy will be asynchronous with respect to the host. Otherwise, the argument has no effect.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; &lt;code&gt;True&lt;/code&gt; 이고 소스가 고정 된 메모리에있는 경우 복제본은 호스트에 대해 비동기식입니다. 그렇지 않으면 인수가 효과가 없습니다.</target>
        </trans-unit>
        <trans-unit id="fda458f2f7dc476cf65c2462d3a8061f49814e9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt; and the source is in pinned memory, the copy will be asynchronous with respect to the host. Otherwise, the argument has no effect. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; &lt;code&gt;True&lt;/code&gt; 이고 소스가 고정 된 메모리에있는 경우 복제본은 호스트에 대해 비동기식입니다. 그렇지 않으면 인수가 효과가 없습니다. 기본값 : &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f5e9c95303e9f5242b9e3eeef2ca091abb7d7587" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; &lt;code&gt;True&lt;/code&gt; 이고 소스가 고정 된 메모리에 있고 대상이 GPU에 있거나 그 반대 인 경우 복사가 호스트에 대해 비동기 적으로 수행됩니다. 그렇지 않으면 인수가 효과가 없습니다.</target>
        </trans-unit>
        <trans-unit id="00b13dec03b43a1e31572c6206c49d66e2649772" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt; and this copy is between CPU and GPU, the copy may occur asynchronously with respect to the host. For other cases, this argument has no effect.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; &lt;code&gt;True&lt;/code&gt; &lt;strong&gt;이고이&lt;/strong&gt; 복사본이 CPU와 GPU 사이에있는 경우 복사는 호스트에 대해 비동기 적으로 발생할 수 있습니다. 다른 경우에는이 인수가 효과가 없습니다.</target>
        </trans-unit>
        <trans-unit id="dc977ce4adf32dbf0bccc2e0e481f93caf29accf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; The non-linearity to use. Can be either &lt;code&gt;'tanh'&lt;/code&gt; or &lt;code&gt;'relu'&lt;/code&gt;. Default: &lt;code&gt;'tanh'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;비선형 성&lt;/strong&gt; &amp;ndash; 사용할 비선형 성입니다. &lt;code&gt;'tanh'&lt;/code&gt; 또는 &lt;code&gt;'relu'&lt;/code&gt; 가 될 수 있습니다 . 기본값 : &lt;code&gt;'tanh'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3130318f0a7fea9d363cd7ece82482a7951ecf83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; the non-linear function (&lt;code&gt;nn.functional&lt;/code&gt; name)</source>
          <target state="translated">&lt;strong&gt;비선형&lt;/strong&gt; &amp;ndash; 비선형 함수 ( &lt;code&gt;nn.functional&lt;/code&gt; 기능 이름)</target>
        </trans-unit>
        <trans-unit id="4aa37508fa49cde50a4584a0a4a2daca12ff537e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; the non-linear function (&lt;code&gt;nn.functional&lt;/code&gt; name), recommended to use only with &lt;code&gt;'relu'&lt;/code&gt; or &lt;code&gt;'leaky_relu'&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;비선형 성&lt;/strong&gt; &amp;ndash; 비선형 함수 ( &lt;code&gt;nn.functional&lt;/code&gt; 기능 이름), &lt;code&gt;'relu'&lt;/code&gt; 또는 &lt;code&gt;'leaky_relu'&lt;/code&gt; (기본값) 와 함께 사용하는 것이 좋습니다 .</target>
        </trans-unit>
        <trans-unit id="af1aae5aa50bc026c9cb830597267216d05aa8f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm&lt;/strong&gt; &amp;ndash; the layer normalization component (optional).</source>
          <target state="translated">&lt;strong&gt;norm&lt;/strong&gt; &amp;ndash; 계층 정규화 구성 요소 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="042826a4724ce41d943ad1739990aba3a85a4a51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;표준&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="25b7d7d86b234b69e97817612f3d8411fbdc3831" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; type of the used p-norm. Can be &lt;code&gt;'inf'&lt;/code&gt; for infinity norm.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 사용 된 p-norm의 유형입니다. 무한대 표준의 경우 &lt;code&gt;'inf'&lt;/code&gt; 일 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="5fbeccb6b749ceedad0227342ff93bd8d1b3c38e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default &lt;code&gt;2&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 모듈 초기화 문서를 참조하십시오. 기본값 &lt;code&gt;2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="67a00acec5420f77031cf95c030b9e478dabf5ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The &lt;code&gt;p&lt;/code&gt; in the &lt;code&gt;p&lt;/code&gt;-norm to compute for the &lt;code&gt;max_norm&lt;/code&gt; option. Default &lt;code&gt;2&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;플로트 &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;옵션&lt;/em&gt; 참조) - &lt;code&gt;p&lt;/code&gt; 에서 &lt;code&gt;p&lt;/code&gt; -norm는 대한 계산하기 &lt;code&gt;max_norm&lt;/code&gt; 의 옵션을 선택합니다. 기본값 &lt;code&gt;2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6c0575ab7282d8575f927d745ef2b2ba33374a8d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The p of the p-norm to compute for the &lt;code&gt;max_norm&lt;/code&gt; option. Default &lt;code&gt;2&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;max_norm&lt;/code&gt; 옵션에 대해 계산할 p-norm의 p 입니다. 기본값 &lt;code&gt;2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f7e673690158062d96a0d2ab65a7cef662314e39" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether the STFT was normalized. (Default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;normalized&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; STFT가 정규화되었는지 여부. (기본값 : &lt;code&gt;False&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="e814d9b9d8871174bb71b430fdad8deb479f898c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return normalized results. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;normalized&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 정규화 된 결과를 반환할지 여부를 제어합니다. 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="55c2c1e33d4fa16ec0ad8d020fa793df29564524" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return the normalized STFT results Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;normalized&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 정규화 된 STFT 결과를 반환할지 여부를 제어합니다. 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="46fbb1084d5f3c7db6c165371d7dc2e34cf14b9f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized_shape&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;normalized_shape&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="0893590e108f46268f24f1a5dcb2dddba9556031" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_channels&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of channels expected in input</source>
          <target state="translated">&lt;strong&gt;num_channels&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 입력에서 예상되는 채널 수</target>
        </trans-unit>
        <trans-unit id="5cfb2a3b4581e8308eef2a0a6f8caba338ba2eb1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Total number of classes. If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor.</source>
          <target state="translated">&lt;strong&gt;num_classes&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 총 클래스 수입니다. -1로 설정하면 클래스 수가 입력 텐서에서 가장 큰 클래스 값보다 큰 것으로 추론됩니다.</target>
        </trans-unit>
        <trans-unit id="0cedc9f268bdd45102c976aafc252937bfb35224" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of output classes of the model (including the background)</source>
          <target state="translated">&lt;strong&gt;num_classes&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 모델의 출력 클래스 수 (배경 포함)</target>
        </trans-unit>
        <trans-unit id="b89059d982eca861114c424da98eed8e996d7cf1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_decoder_layers&lt;/strong&gt; &amp;ndash; the number of sub-decoder-layers in the decoder (default=6).</source>
          <target state="translated">&lt;strong&gt;num_decoder_layers&lt;/strong&gt; &amp;ndash; 디코더의 하위 디코더 계층 수 (기본값 = 6).</target>
        </trans-unit>
        <trans-unit id="849f5a2c21cc33c1cacad354c0a79d6a1f17b0c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_embeddings&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; size of the dictionary of embeddings</source>
          <target state="translated">&lt;strong&gt;num_embeddings&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 임베딩 사전의 크기</target>
        </trans-unit>
        <trans-unit id="8181be00d6cb90d97280a1382ec1a1a05ca6c394" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_encoder_layers&lt;/strong&gt; &amp;ndash; the number of sub-encoder-layers in the encoder (default=6).</source>
          <target state="translated">&lt;strong&gt;num_encoder_layers&lt;/strong&gt; &amp;ndash; 인코더의 하위 인코더 계층 수 (기본값 = 6).</target>
        </trans-unit>
        <trans-unit id="fb50075c2dd76286e5338792fc9e620415adf047" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_features&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;num_features&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="b606c4e5166178414dc02bf646ef98468d9aef12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_groups&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of groups to separate the channels into</source>
          <target state="translated">&lt;strong&gt;num_groups&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 채널을 분리 할 그룹 수</target>
        </trans-unit>
        <trans-unit id="93f81723e37eb2609764e3fe95a3bac369d5a4b0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_heads&lt;/strong&gt; &amp;ndash; parallel attention heads.</source>
          <target state="translated">&lt;strong&gt;num_heads&lt;/strong&gt; &amp;ndash; 평행주의 헤드.</target>
        </trans-unit>
        <trans-unit id="716e2a8f4f7ad74c1067fb5b8a90a00f71da6a83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two GRUs together to form a &lt;code&gt;stacked GRU&lt;/code&gt;, with the second GRU taking in outputs of the first GRU and computing the final results. Default: 1</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; 반복 레이어 수입니다. 예를 들어, &lt;code&gt;num_layers=2&lt;/code&gt; 를 설정 하면 두 GRU를 함께 &lt;code&gt;stacked GRU&lt;/code&gt; 를 형성 하고 두 번째 GRU가 첫 번째 GRU의 출력을 가져와 최종 결과를 계산하는 것을 의미합니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="848be87c245b176a092f816c28a51ec302bfbd9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two LSTMs together to form a &lt;code&gt;stacked LSTM&lt;/code&gt;, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; 반복 레이어 수입니다. 예를 들어 &lt;code&gt;num_layers=2&lt;/code&gt; 를 설정 하면 두 LSTM을 함께 &lt;code&gt;stacked LSTM&lt;/code&gt; 을 형성 하고 두 번째 LSTM은 첫 번째 LSTM의 출력을 가져와 최종 결과를 계산합니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="3f20f56b362366655c5f5d500d3983ccb38896b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two RNNs together to form a &lt;code&gt;stacked RNN&lt;/code&gt;, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; 반복 레이어 수입니다. 예를 들어 &lt;code&gt;num_layers=2&lt;/code&gt; 를 설정 하면 두 개의 &lt;code&gt;stacked RNN&lt;/code&gt; 을 함께 쌓아 쌓인 RNN 을 형성 하고 두 번째 RNN은 첫 번째 RNN의 출력을 가져와 최종 결과를 계산합니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="80d0325c2a7e14f3b87f5fbe564e95166bea3899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; the number of sub-decoder-layers in the decoder (required).</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; 디코더의 하위 디코더 계층 수 (필수).</target>
        </trans-unit>
        <trans-unit id="6981d7fa46aee8b590e66abd7ac32bb99332f4b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; the number of sub-encoder-layers in the encoder (required).</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; 인코더의 하위 인코더 계층 수 (필수).</target>
        </trans-unit>
        <trans-unit id="1c6217d241d0c6e30110c21e501846e588f977b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_parameters&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of</source>
          <target state="translated">&lt;strong&gt;num_parameters&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 개수</target>
        </trans-unit>
        <trans-unit id="217f93399a3e49b6a211efe4dfeb93b9b074c795" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_samples&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of samples to draw</source>
          <target state="translated">&lt;strong&gt;num_samples&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 그릴 샘플 수</target>
        </trans-unit>
        <trans-unit id="261b75892c45e73ce2bcf393c665d4350903ddd0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_send_recv_threads&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The number of threads in the thread-pool used by &lt;code&gt;ProcessGroupAgent&lt;/code&gt; (default: 4).</source>
          <target state="translated">&lt;strong&gt;num_send_recv_threads&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;ProcessGroupAgent&lt;/code&gt; 에서 사용하는 스레드 풀의 스레드 수 (기본값 : 4).</target>
        </trans-unit>
        <trans-unit id="9e30ae31cb163bad5dd2dce2717b84e6e7ebd501" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_thresholds&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of thresholds used to draw the curve.</source>
          <target state="translated">&lt;strong&gt;num_thresholds&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 곡선을 그리는 데 사용되는 임계 값 수입니다.</target>
        </trans-unit>
        <trans-unit id="b15859c381baa669db57383f7570015c6f11a1eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_worker_threads&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The number of threads in the thread-pool used by &lt;code&gt;TensorPipeAgent&lt;/code&gt; to execute requests (default: 16).</source>
          <target state="translated">&lt;strong&gt;num_worker_threads&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;TensorPipeAgent&lt;/code&gt; 에서 요청을 실행 하는 데 사용하는 스레드 풀의 스레드 수 (기본값 : 16).</target>
        </trans-unit>
        <trans-unit id="f2a5564d5b72bbb54db0dee38713bf01705f62e8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;obj&lt;/strong&gt; &amp;ndash; saved object</source>
          <target state="translated">&lt;strong&gt;obj&lt;/strong&gt; &amp;ndash; 저장된 개체</target>
        </trans-unit>
        <trans-unit id="9df8cf76692544b5e3907cc50ab40d5bd8586e94" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;obj&lt;/strong&gt; (&lt;em&gt;Object&lt;/em&gt;) &amp;ndash; Object to test</source>
          <target state="translated">&lt;strong&gt;obj&lt;/strong&gt; ( &lt;em&gt;Object&lt;/em&gt; ) &amp;ndash; 테스트 할 객체</target>
        </trans-unit>
        <trans-unit id="1efcc773a7594d495f38b29dce91f4e0fcb2d526" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;obj&lt;/strong&gt; (callable, class, or &lt;code&gt;nn.Module&lt;/code&gt;) &amp;ndash; The &lt;code&gt;nn.Module&lt;/code&gt;, function, or class type to compile.</source>
          <target state="translated">&lt;strong&gt;obj&lt;/strong&gt; (callable, class 또는 &lt;code&gt;nn.Module&lt;/code&gt; ) &amp;ndash; 컴파일 할 &lt;code&gt;nn.Module&lt;/code&gt; , 함수 또는 클래스 유형입니다.</target>
        </trans-unit>
        <trans-unit id="4d631610135b6d78e1caf59354dfcdfe0e55f151" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the diagonal to consider. Default: 0 (main diagonal).</source>
          <target state="translated">&lt;strong&gt;offset&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 고려할 대각선입니다. 기본값 : 0 (주 대각선).</target>
        </trans-unit>
        <trans-unit id="a23fd1c737ac34111ea6878cbb466517bbf61204" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; which diagonal to consider. Default: 0 (main diagonal).</source>
          <target state="translated">&lt;strong&gt;offset&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 고려할 대각선입니다. 기본값 : 0 (주 대각선).</target>
        </trans-unit>
        <trans-unit id="b094d10e5ad29ad4b91fe1094a0e0451c35935ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offset&lt;/strong&gt; (&lt;code&gt;int&lt;/code&gt;) &amp;ndash; diagonal offset from the main diagonal. Default: if not provided, 0.</source>
          <target state="translated">&lt;strong&gt;offset&lt;/strong&gt; ( &lt;code&gt;int&lt;/code&gt; ) &amp;ndash; 주 대각선으로부터의 대각선 오프셋. 기본값 : 제공되지 않은 경우 0.</target>
        </trans-unit>
        <trans-unit id="59680b913232bfc3f5ca8eefc5ea0a3e439f606d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offsets&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Only used when &lt;code&gt;input&lt;/code&gt; is 1D. &lt;code&gt;offsets&lt;/code&gt; determines the starting index position of each bag (sequence) in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;offsets&lt;/strong&gt; ( &lt;em&gt;LongTensor &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; &lt;code&gt;input&lt;/code&gt; 이 1D 인 경우에만 사용됩니다 . &lt;code&gt;offsets&lt;/code&gt; 은 &lt;code&gt;input&lt;/code&gt; 에서 각 백 (시퀀스)의 시작 인덱스 위치를 결정합니다 .</target>
        </trans-unit>
        <trans-unit id="f3eeb1215829aa860254719c6ed490994631af72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether &lt;code&gt;input&lt;/code&gt; was halfed to avoid redundancy, e.g., by &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 예를 들어 &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt; 의해 중복을 피하기 위해 &lt;code&gt;input&lt;/code&gt; 이 절반으로 되었는지 여부를 제어합니다 . 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c3828107f07c747332fcb7869a55bac90d7123f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return half of results to avoid redundancy for real inputs. Default: &lt;code&gt;True&lt;/code&gt; for real &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;window&lt;/code&gt;, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 실제 입력에 대한 중복을 피하기 위해 결과의 절반을 반환할지 여부를 제어합니다. 기본값 : 실제 &lt;code&gt;input&lt;/code&gt; 및 &lt;code&gt;window&lt;/code&gt; 대해 &lt;code&gt;True&lt;/code&gt; , &lt;code&gt;False&lt;/code&gt; 않으면 False .</target>
        </trans-unit>
        <trans-unit id="b8c4c667951698c100009eb45a650b471858d1c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return half of results to avoid redundancy. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 중복을 피하기 위해 결과의 절반을 반환할지 여부를 제어합니다. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="227c5f582067ca753f45fef8e7cb4cc34373476c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Whether the STFT was onesided. (Default: &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;n_fft != fft_size&lt;/code&gt; in the input size)</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; ( &lt;em&gt;선택 사항 &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; STFT가 일방적 이었는지 여부. (기본값 : 입력 크기에서 &lt;code&gt;n_fft != fft_size&lt;/code&gt; 경우 &lt;code&gt;True&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="b0dae8ba515d13e7989bf49ea6f91f0aa98dcae4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;op&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; One of the values from &lt;code&gt;torch.distributed.ReduceOp&lt;/code&gt; enum. Specifies an operation used for element-wise reductions.</source>
          <target state="translated">&lt;strong&gt;op&lt;/strong&gt; ( &lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; &lt;code&gt;torch.distributed.ReduceOp&lt;/code&gt; 열거 형 의 값 중 하나입니다 . 요소 별 감소에 사용되는 연산을 지정합니다.</target>
        </trans-unit>
        <trans-unit id="ca9e3fe2123059286c3e6e03e1667d5bcbe86c04" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;operands&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The operands to compute the Einstein sum of.</source>
          <target state="translated">&lt;strong&gt;피연산자&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 아인슈타인 합계를 계산할 피연산자입니다.</target>
        </trans-unit>
        <trans-unit id="64c84dfc01211648b09d190f92dcde0b67c4d354" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;operator_export_type&lt;/strong&gt; (&lt;em&gt;enum&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default OperatorExportTypes.ONNX&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;operator_export_type&lt;/strong&gt; ( &lt;em&gt;enum &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;기본값 OperatorExportTypes.ONNX&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="ae2e7fa69f17a2f7d525734c74794c386a5f53af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;opset_version&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default is 9&lt;/em&gt;) &amp;ndash; by default we export the model to the opset version of the onnx submodule. Since ONNX&amp;rsquo;s latest opset may evolve before next stable release, by default we export to one stable opset version. Right now, supported stable opset version is 9. The opset_version must be _onnx_master_opset or in _onnx_stable_opsets which are defined in torch/onnx/symbolic_helper.py</source>
          <target state="translated">&lt;strong&gt;opset_version&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;기본값은 9&lt;/em&gt; ) &amp;ndash; 기본적으로 모델을 onnx 하위 모듈의 opset 버전으로 내 보냅니다. ONNX의 최신 opset은 다음 안정된 릴리스 이전에 발전 할 수 있으므로 기본적으로 하나의 안정된 opset 버전으로 내 보냅니다. 현재 지원되는 안정적인 opset 버전은 9입니다. opset_version은 _onnx_master_opset 또는 torch / onnx / symbolic_helper.py에 정의 된 _onnx_stable_opsets 여야합니다.</target>
        </trans-unit>
        <trans-unit id="341b800a5d451a2739a7cf894c4169dfd8a8ab69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimization_blocklist&lt;/strong&gt; &amp;ndash; A set with type of MobileOptimizerType. When set is not passed, optimization method will run all the optimizer pass; otherwise, optimizer method will run the optimization pass that is not included inside optimization_blocklist.</source>
          <target state="translated">&lt;strong&gt;Optimization_blocklist&lt;/strong&gt; &amp;ndash; 유형이 MobileOptimizerType 인 집합입니다. 설정이 전달되지 않으면 최적화 방법이 모든 최적화 프로그램 전달을 실행합니다. 그렇지 않으면 옵티 마이저 메소드가 Optimization_blocklist에 포함되지 않은 최적화 패스를 실행합니다.</target>
        </trans-unit>
        <trans-unit id="3eb51832b6aa0f276cb8df9ff35933a83aafdcb4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimizer_class&lt;/strong&gt; (&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;optim.Optimizer&lt;/a&gt;) &amp;ndash; the class of optimizer to instantiate on each worker.</source>
          <target state="translated">&lt;strong&gt;optimizer_class&lt;/strong&gt; ( &lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;optim.Optimizer&lt;/a&gt; ) &amp;ndash; 각 작업자에서 인스턴스화 할 최적화 프로그램의 클래스입니다.</target>
        </trans-unit>
        <trans-unit id="d4b6fe40a78147f10f4276a3fff8e0f880f89f66" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ord&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;ord&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro' &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc' &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="c278df20ef2016b751d8544cf7c0d4206d20cb20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ortho_fparams, ortho_bparams&lt;/strong&gt; (&lt;em&gt;ortho_iparams&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash; various parameters to LOBPCG algorithm when using &lt;code&gt;method=&amp;rdquo;ortho&amp;rdquo;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;ortho_fparams, ortho_bparams&lt;/strong&gt; ( &lt;em&gt;ortho_iparams &lt;/em&gt;&lt;em&gt;,&lt;/em&gt; ) &amp;ndash; &lt;code&gt;method=&amp;rdquo;ortho&amp;rdquo;&lt;/code&gt; 사용할 때 LOBPCG 알고리즘에 대한 다양한 매개 변수 .</target>
        </trans-unit>
        <trans-unit id="3de7c1b5054808fbf162ba527fa5af49d0d5b2a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; &amp;ndash; the second input tensor</source>
          <target state="translated">&lt;strong&gt;기타&lt;/strong&gt; &amp;ndash; 두 번째 입력 텐서</target>
        </trans-unit>
        <trans-unit id="9830ed943f8f4c46a3eaf71558a02ad41461cee1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The result tensor has the same shape as &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt; ) &amp;ndash; 결과 텐서의 모양은 &lt;code&gt;other&lt;/code&gt; 와 같습니다 .</target>
        </trans-unit>
        <trans-unit id="d83937e2055c79b7eeec7c9e6cd7007e8c6ba7b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The result tensor has the same size as &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt; ) &amp;ndash; 결과 텐서의 크기가 &lt;code&gt;other&lt;/code&gt; 와 같습니다 .</target>
        </trans-unit>
        <trans-unit id="575d583c4e3da2e5f40414a1c2ac1f8053858442" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; second tensor in the dot product.</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 내적의 두 번째 텐서.</target>
        </trans-unit>
        <trans-unit id="9683962d0d021c44b4feb57563050d15e672f921" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; second tensor to compare</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 비교할 두 번째 텐서</target>
        </trans-unit>
        <trans-unit id="1c95b6612a9c23b59a8184a8bc3fac93a55448ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the Right-hand-side input tensor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 오른쪽 입력 텐서</target>
        </trans-unit>
        <trans-unit id="03ddfd5bad09382b4da8e30aba277bed53e1d92c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second input tensor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 두 번째 입력 텐서</target>
        </trans-unit>
        <trans-unit id="7a7c2bdc488731ec762bebe69342927cf0cc7a4e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second multiplicand tensor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 두 번째 곱셈 텐서</target>
        </trans-unit>
        <trans-unit id="006601c4fdb977844e03c057c807959c8ed0607e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second tensor to be multiplied</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 곱할 두 번째 텐서</target>
        </trans-unit>
        <trans-unit id="669f8aaad77167734f2e1b5bbdc071b3c8cca4fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute AND with</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 계산할 텐서 AND</target>
        </trans-unit>
        <trans-unit id="812d6aefc371af303841ae4e35623a96b151d7af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute OR with</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 계산할 텐서 OR</target>
        </trans-unit>
        <trans-unit id="cc9311b9409e52a798efcdc865571b70ee24d69a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute XOR with</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; XOR을 계산할 텐서</target>
        </trans-unit>
        <trans-unit id="1dc58021bcaef0b4c84bf5fbd8eac7072cf21ee6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the divisor that may be either a number or a Tensor of the same shape as the dividend</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 피제수와 같은 모양의 숫자 또는 Tensor 일 수있는 제수</target>
        </trans-unit>
        <trans-unit id="4af20d1a0478746ed342d723899ffae24e31673f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the divisor, which may be either a number or a tensor of the same shape as the dividend</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 제수, 피제수와 동일한 모양의 숫자 또는 텐서 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="5f7bb660268bfc1f1ce99fb1f5d6144452802639" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the tensor or value to compare</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 비교할 텐서 또는 값</target>
        </trans-unit>
        <trans-unit id="2083d9580c98436be500de8f122860e994452f50" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the divisor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt; ) &amp;ndash; 제수</target>
        </trans-unit>
        <trans-unit id="24c486bb19e0b203a2a62ea6e87e873812911826" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the tensor or scalar to subtract from &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt; ) &amp;ndash; &lt;code&gt;input&lt;/code&gt; 에서 뺄 텐서 또는 스칼라</target>
        </trans-unit>
        <trans-unit id="6897c0ab62af0e375bdc00c90649a3563fa23660" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the tensor or value to compare</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt; ) &amp;ndash; 비교할 텐서 또는 값</target>
        </trans-unit>
        <trans-unit id="1ca11bab125e2ff340132dc741c4418bbb9be48f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the number to be multiplied to each element of &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; ( &lt;em&gt;Number&lt;/em&gt; ) &amp;ndash; 각 &lt;code&gt;input&lt;/code&gt; 요소에 곱할 숫자</target>
        </trans-unit>
        <trans-unit id="8bbe00078fcdd90156cc48ebd3d452934d098736" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서</target>
        </trans-unit>
        <trans-unit id="4909287a5578c3077500a804d4cacd409ba1cbb4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; If the inputs are &lt;code&gt;torch.float32&lt;/code&gt;, must be &lt;code&gt;torch.complex64&lt;/code&gt;. If the inputs are &lt;code&gt;torch.float64&lt;/code&gt;, must be &lt;code&gt;torch.complex128&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;밖으로&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;텐서&lt;/a&gt; ) - 입력이 경우 &lt;code&gt;torch.float32&lt;/code&gt; 이어야합니다 &lt;code&gt;torch.complex64&lt;/code&gt; . 입력이 경우 &lt;code&gt;torch.float64&lt;/code&gt; 이어야합니다 &lt;code&gt;torch.complex128&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="49191fc918c7fbbf6b67857e145e1c13e69615dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The output tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서</target>
        </trans-unit>
        <trans-unit id="865f26f7ba269d26b55b78b56f8c40704e8bdc68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; optional output matrix</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 선택적 출력 매트릭스</target>
        </trans-unit>
        <trans-unit id="c4d5ed5877e75a302ce827729fa9cc1a243e1951" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the destination tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 대상 텐서</target>
        </trans-unit>
        <trans-unit id="c65d5e1626eb8eac6c27cd8f3a19ef6cfca82d2b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output matrix</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 행렬</target>
        </trans-unit>
        <trans-unit id="dc670798304fb38fad30b85d22d05a85c1854899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서</target>
        </trans-unit>
        <trans-unit id="2913addd49fe786d1b73d0259fcdb7a5929ea3da" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor for &lt;code&gt;c&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;c&lt;/code&gt; 에 대한 출력 텐서</target>
        </trans-unit>
        <trans-unit id="14f81c54913f4111d9238607d8ce61fae4bd2cc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor for &lt;code&gt;inv&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;inv&lt;/code&gt; 의 출력 텐서</target>
        </trans-unit>
        <trans-unit id="485744ee6c684eac51b20a24c837baecaa778471" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor, must be the same size as &lt;code&gt;input&lt;/code&gt; if provided.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서 가 제공되는 경우 &lt;code&gt;input&lt;/code&gt; 과 크기가 같아야합니다 .</target>
        </trans-unit>
        <trans-unit id="3ebd6deba9d17676dd19fc0c1b7635fe63639228" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor, must be the same size as &lt;code&gt;values&lt;/code&gt; if provided.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서 가 제공된 경우 &lt;code&gt;values&lt;/code&gt; 과 크기가 같아야합니다 .</target>
        </trans-unit>
        <trans-unit id="964eb34dca913baad53314e60e02dd63488de605" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서.</target>
        </trans-unit>
        <trans-unit id="fa34d018743c897888089d8a79ee1afc57d1450c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor. Ignored if &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서. &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; 이고 &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; 이면 무시됩니다 .</target>
        </trans-unit>
        <trans-unit id="606bdb70440f1c778aed44d5a2f91dc6db6f4c37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; optional output tuple. If &lt;code&gt;get_infos&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the elements in the tuple are Tensor, IntTensor, and IntTensor. If &lt;code&gt;get_infos&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the elements in the tuple are Tensor, IntTensor. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 선택적 출력 튜플입니다. 경우 &lt;code&gt;get_infos&lt;/code&gt; 가 있다 &lt;code&gt;True&lt;/code&gt; , 다음 튜플의 요소는 텐서, IntTensor 및 IntTensor 있습니다. 경우 &lt;code&gt;get_infos&lt;/code&gt; 이 있다 &lt;code&gt;False&lt;/code&gt; , 다음 튜플의 요소는 텐서, IntTensor 있습니다. 기본값 : &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b8efb0d2ac488f256c5bbb46000794a0044cbe5c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the optional destination tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 선택적 대상 텐서</target>
        </trans-unit>
        <trans-unit id="5381b6d62cf34413978a3eab8706a0bde8040c25" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensors</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서</target>
        </trans-unit>
        <trans-unit id="f069527b4f11758b1081d0eb36c8c58ea9e99e0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (&lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;LongTensor&lt;/code&gt;) that can be optionally given to be used as output buffers</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 버퍼로 사용되도록 선택적으로 제공 할 수있는 ( &lt;code&gt;Tensor&lt;/code&gt; , &lt;code&gt;LongTensor&lt;/code&gt; ) 의 출력 튜플</target>
        </trans-unit>
        <trans-unit id="e270a7a389c717e8d14893d5b4ccc1bd8f03693e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (Tensor, LongTensor) can be optionally given to be used as output buffers</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; (Tensor, LongTensor)의 출력 튜플을 선택적으로 제공하여 출력 버퍼로 사용할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="1ffc56309f4997d2adc30f856fbd91f3447214a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (Tensor, LongTensor) that can be optionally given to be used as output buffers</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 버퍼로 사용하도록 선택적으로 제공 할 수있는 (Tensor, LongTensor)의 출력 튜플</target>
        </trans-unit>
        <trans-unit id="489596f4185eee384c4b282ccfc92c2a9977b741" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (Tensor, Tensor)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; (Tensor, Tensor)의 출력 튜플</target>
        </trans-unit>
        <trans-unit id="d316ec30ac2f8ba6b2289f13dd8a11cf7021e946" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of tensors</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 텐서의 출력 튜플</target>
        </trans-unit>
        <trans-unit id="7708a683bac6a7fafb6df65ba8e0784d087454b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the result tuple of two output tensors (max, max_indices)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 두 출력 텐서의 결과 튜플 (max, max_indices)</target>
        </trans-unit>
        <trans-unit id="6a9bb0824abf9ea55c48cd268133b1146f437fd0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the result tuple of two output tensors (values, indices)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 두 출력 텐서의 결과 튜플 (값, 인덱스)</target>
        </trans-unit>
        <trans-unit id="c901d01fb46bbe38d29cc46eda894f717e98cbb5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the tuple of two output tensors (min, min_indices)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 두 출력 텐서의 튜플 (min, min_indices)</target>
        </trans-unit>
        <trans-unit id="197a7a690b00cbe491d5fbf6fc25fcca33fdffa6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; tuple of &lt;code&gt;Q&lt;/code&gt; and &lt;code&gt;R&lt;/code&gt; tensors satisfying &lt;code&gt;input = torch.matmul(Q, R)&lt;/code&gt;. The dimensions of &lt;code&gt;Q&lt;/code&gt; and &lt;code&gt;R&lt;/code&gt; are</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;input = torch.matmul(Q, R)&lt;/code&gt; 충족하는 &lt;code&gt;Q&lt;/code&gt; 및 &lt;code&gt;R&lt;/code&gt; 텐서의 튜플 . &lt;code&gt;Q&lt;/code&gt; 와 &lt;code&gt;R&lt;/code&gt; 의 치수는 다음 과 같습니다.</target>
        </trans-unit>
        <trans-unit id="b5510b7d23f0333ea37fb16d363c66ea86b78cc1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The output tensor. Ignored if &lt;code&gt;None&lt;/code&gt;. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서입니다. &lt;code&gt;None&lt;/code&gt; 이면 무시됩니다 . 기본값 : &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="11b25d060a0bb91a3a6bd4eb9234921ee682e10d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor. If &lt;code&gt;out&lt;/code&gt; is used, this operation won&amp;rsquo;t be differentiable.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서. 경우 &lt;code&gt;out&lt;/code&gt; 사용되며,이 작업은 미분되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="d7bbe5a42e951041522cf9dd2a446fdcc33325b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;)&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; optional output tuple.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;em&gt;( &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;) &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 선택적 출력 튜플입니다.</target>
        </trans-unit>
        <trans-unit id="209dfca5f1c305b375517af898ffea87b3b235b7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor containing indices</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt; ( &lt;em&gt;LongTensor &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 인덱스를 포함하는 출력 텐서</target>
        </trans-unit>
        <trans-unit id="fbf9c4879b754e5485d4adfd6cf789f5297488df" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out_channels&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of channels produced by the convolution</source>
          <target state="translated">&lt;strong&gt;out_channels&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 컨볼 루션에 의해 생성 된 채널 수</target>
        </trans-unit>
        <trans-unit id="cb2ef6ac4d28b8ca3c953e0855d6ae16d965ac4f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out_features&lt;/strong&gt; &amp;ndash; size of each output sample</source>
          <target state="translated">&lt;strong&gt;out_features&lt;/strong&gt; &amp;ndash; 각 출력 샘플의 크기</target>
        </trans-unit>
        <trans-unit id="d7de66fc4b74ea02276b09800cfd2ae532e3bc76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out_int32&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; indicate the output data type. torch.int32 if True, torch.int64 otherwise. Default value is False, i.e. default output data type is torch.int64.</source>
          <target state="translated">&lt;strong&gt;out_int32&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 데이터 유형을 나타냅니다. True이면 torch.int32, 그렇지 않으면 torch.int64. 기본값은 False입니다. 즉, 기본 출력 데이터 유형은 torch.int64입니다.</target>
        </trans-unit>
        <trans-unit id="d4c83d604511fcf859161efc385f906819b96864" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Output tensor.</source>
          <target state="translated">&lt;strong&gt;output&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 텐서.</target>
        </trans-unit>
        <trans-unit id="54e1f470236ead45903663caa70f84c32cb8d0d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the output list of unique scalar elements.</source>
          <target state="translated">&lt;strong&gt;output&lt;/strong&gt; ( &lt;em&gt;Tensor&lt;/em&gt; ) : 고유 한 스칼라 요소의 출력 목록입니다.</target>
        </trans-unit>
        <trans-unit id="8042cc420b9244c9f4146afa6f88da5858ea8729" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; is a Tensor of size &lt;code&gt;N&lt;/code&gt; containing computed target log probabilities for each example</source>
          <target state="translated">&lt;strong&gt;출력&lt;/strong&gt; 은 각 예제에 대해 계산 된 대상 로그 확률을 포함하는 크기 &lt;code&gt;N&lt;/code&gt; 의 Tensor입니다.</target>
        </trans-unit>
        <trans-unit id="ee40fd7a70a6bf8cc86c927f28159d12e52c4fcd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt;: tensor containing the output features (&lt;code&gt;h_t&lt;/code&gt;) from the last layer of the RNN, for each &lt;code&gt;t&lt;/code&gt;. If a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt;&lt;/a&gt; has been given as the input, the output will also be a packed sequence.</source>
          <target state="translated">&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt; : 각 &lt;code&gt;t&lt;/code&gt; 에 대해 RNN의 마지막 계층에서 출력 특성 ( &lt;code&gt;h_t&lt;/code&gt; )을 포함하는 텐서 . 경우 &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt; 가&lt;/a&gt; 입력으로 주어졌다 출력은 또한 압축 된 시퀀스 일 것이다.</target>
        </trans-unit>
        <trans-unit id="1dc2c70a675e8e584ab85a82d21f959742d0aaf7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt;: tensor containing the output features &lt;code&gt;(h_t)&lt;/code&gt; from the last layer of the LSTM, for each &lt;code&gt;t&lt;/code&gt;. If a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt;&lt;/a&gt; has been given as the input, the output will also be a packed sequence.</source>
          <target state="translated">&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt; : 각 &lt;code&gt;t&lt;/code&gt; 에 대해 LSTM의 마지막 계층에서 출력 특성 &lt;code&gt;(h_t)&lt;/code&gt; 을 포함하는 텐서 . 경우 &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt; 가&lt;/a&gt; 입력으로 주어졌다 출력은 또한 압축 된 시퀀스 일 것이다.</target>
        </trans-unit>
        <trans-unit id="44bac24d4e0073747a76bcde5580e1630789e3cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt;: tensor containing the output features h_t from the last layer of the GRU, for each &lt;code&gt;t&lt;/code&gt;. If a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt;&lt;/a&gt; has been given as the input, the output will also be a packed sequence. For the unpacked case, the directions can be separated using &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt;, with forward and backward being direction &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; respectively.</source>
          <target state="translated">&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt; : 각 &lt;code&gt;t&lt;/code&gt; 에 대해 GRU의 마지막 계층에서 출력 기능 h_t를 포함하는 텐서 . 경우 &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt; 가&lt;/a&gt; 입력으로 주어졌다 출력은 또한 압축 된 시퀀스 일 것이다. 압축이 풀린 경우 방향은 &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt; 사용하여 분리 할 수 ​​있으며 , 앞으로 및 뒤로는 각각 방향 &lt;code&gt;0&lt;/code&gt; 과 &lt;code&gt;1&lt;/code&gt; 이 됩니다.</target>
        </trans-unit>
        <trans-unit id="255f1d7d987dadd4223a022923279a9324511b84" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; Device location of output for single-device CUDA modules. For multi-device modules and CPU modules, it must be &lt;code&gt;None&lt;/code&gt;, and the module itself dictates the output location. (default: &lt;code&gt;device_ids[0]&lt;/code&gt; for single-device modules)</source>
          <target state="translated">&lt;strong&gt;output_device&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt; ) &amp;ndash; 단일 장치 CUDA 모듈에 대한 출력의 장치 위치입니다. 다중 장치 모듈 및 CPU 모듈의 경우 &lt;code&gt;None&lt;/code&gt; 이어야하며 모듈 자체가 출력 위치를 지정합니다. (기본값 : 단일 장치 모듈의 경우 &lt;code&gt;device_ids[0]&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="8b601fc16628c28a84e5091b7164b5ba737b9327" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; device location of output (default: device_ids[0])</source>
          <target state="translated">&lt;strong&gt;output_device&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt; ) &amp;ndash; 출력 장치 위치 (기본값 : device_ids [0])</target>
        </trans-unit>
        <trans-unit id="2e98efe0558eb0f88016b3110b664c00e2dd175e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_device&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; GPU location of the output Use -1 to indicate the CPU. (default: device_ids[0])</source>
          <target state="translated">&lt;strong&gt;output_device&lt;/strong&gt; ( &lt;em&gt;list of python : int &lt;/em&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt; ) &amp;ndash; 출력의 GPU 위치 -1을 사용하여 CPU를 나타냅니다. (기본값 : device_ids [0])</target>
        </trans-unit>
        <trans-unit id="cd583af9b2638b2ed135367bf25e08abf6423093" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_names&lt;/strong&gt; (&lt;em&gt;list of strings&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty list&lt;/em&gt;) &amp;ndash; names to assign to the output nodes of the graph, in order</source>
          <target state="translated">&lt;strong&gt;output_names&lt;/strong&gt; ( &lt;em&gt;list of strings &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty list&lt;/em&gt; ) &amp;ndash; 순서대로 그래프의 출력 노드에 할당 할 이름</target>
        </trans-unit>
        <trans-unit id="f491b241ade48cc378ec5122b4841e99e9754e6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; additional size added to one side of each dimension in the output shape. Can be a single number or a tuple &lt;code&gt;(out_padH, out_padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; 출력 모양에서 각 차원의 한면에 추가되는 추가 크기입니다. 단일 숫자 또는 튜플 &lt;code&gt;(out_padH, out_padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="734ccdbb1e5796890980cb4649cd409e247b53a2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; additional size added to one side of each dimension in the output shape. Can be a single number or a tuple &lt;code&gt;(out_padT, out_padH, out_padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; 출력 모양에서 각 차원의 한면에 추가되는 추가 크기입니다. 단일 숫자 또는 튜플 &lt;code&gt;(out_padT, out_padH, out_padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="658b917621e239d640e2b03f43964b708d2c55ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; additional size added to one side of each dimension in the output shape. Can be a single number or a tuple &lt;code&gt;(out_padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; 출력 모양에서 각 차원의 한면에 추가되는 추가 크기입니다. 단일 숫자 또는 튜플 &lt;code&gt;(out_padW)&lt;/code&gt; 일 수 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="f16b08ff1eb258821023064b32148058b9079ce3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Additional size added to one side of each dimension in the output shape. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 모양에서 각 차원의 한면에 추가 크기가 추가됩니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="a4a46c3866c2c1510433f2a4903dbbbe5fde896f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Additional size added to one side of the output shape. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 모양의 한면에 추가 된 크기입니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="2d697a1fa9ed20cfea2be8860a73c26c65201a48" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_ratio&lt;/strong&gt; &amp;ndash; If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</source>
          <target state="translated">&lt;strong&gt;output_ratio&lt;/strong&gt; &amp;ndash; 입력 크기의 비율로 출력 크기를 원할 경우이 옵션을 지정할 수 있습니다. 이것은 (0, 1) 범위의 숫자 또는 튜플이어야합니다.</target>
        </trans-unit>
        <trans-unit id="d139558d8497f0a45efe69a095d8ca0b00a79bb1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size (single integer or double-integer tuple)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; 대상 출력 크기 (단일 정수 또는 이중 정수 튜플)</target>
        </trans-unit>
        <trans-unit id="9aef33d381ddbb64a977de5875d434c15130e1b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size (single integer or triple-integer tuple)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; 대상 출력 크기 (단일 정수 또는 삼중 정수 튜플)</target>
        </trans-unit>
        <trans-unit id="d7553c6c16b6821129bbbbffa2b2ab7a88d48c73" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size (single integer)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; 대상 출력 크기 (단일 정수)</target>
        </trans-unit>
        <trans-unit id="5b92d42ba70c23bb2437e683e87b4a32323b7656" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size H</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; 대상 출력 크기 H</target>
        </trans-unit>
        <trans-unit id="72273a2ad460dccb1f289d60806321a98b8260ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the form D x H x W. Can be a tuple (D, H, W) or a single number D for a cube D x D x D. D, H and W can be either a &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; which means the size will be the same as that of the input.</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; - 폼 D의 목표 출력 크기는 H가 W. 터플 (D, H, W) 또는 큐브 단일 번호 D 일 수 X X D x 세로 x D. D, H 및 W는 일 수 &lt;code&gt;int&lt;/code&gt; , 또는 &lt;code&gt;None&lt;/code&gt; 은 크기가 입력의 크기와 동일하다는 것을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="ffbcc66c67e1dc1781d70637ab1a7011a5a86b0c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the image of the form &lt;code&gt;oH x oW&lt;/code&gt;. Can be a tuple &lt;code&gt;(oH, oW)&lt;/code&gt; or a single number oH for a square image &lt;code&gt;oH x oH&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; &lt;code&gt;oH x oW&lt;/code&gt; &lt;strong&gt;oW&lt;/strong&gt; 형식 이미지의 목표 출력 크기 . 튜플 &lt;code&gt;(oH, oW)&lt;/code&gt; 또는 정사각형 이미지 &lt;code&gt;oH x oH&lt;/code&gt; 의 경우 단일 숫자 oH 일 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2b13fdfcd89a724ec673724cf570c1569f4c6c2e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the image of the form D x H x W. Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; which means the size will be the same as that of the input.</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; D x H x W 형식 이미지의 대상 출력 크기. 튜플 (D, H, W) 또는 큐브 D x D x D의 단일 D 일 수 있습니다. D, H 및 W는 다음 중 하나 일 수 있습니다. &lt;code&gt;int&lt;/code&gt; 또는 &lt;code&gt;None&lt;/code&gt; 크기의 입력 수단과 동일한 것이다.</target>
        </trans-unit>
        <trans-unit id="3da4b11e13dd7cb4717e94a2c74219954c4fc38b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. H and W can be either a &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; which means the size will be the same as that of the input.</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; H x W 형식 이미지의 대상 출력 크기. 정사각형 이미지 H x H의 경우 튜플 (H, W) 또는 단일 H 일 수 있습니다. H 및 W는 &lt;code&gt;int&lt;/code&gt; 또는 &lt;code&gt;None&lt;/code&gt; 을 의미합니다. 크기는 입력의 크기와 동일합니다.</target>
        </trans-unit>
        <trans-unit id="94b03ab4769532cfd586a9f93960f9dbdb397633" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the shape of the spatial dimensions of the output (i.e., &lt;code&gt;output.sizes()[2:]&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 출력의 공간 차원 모양 (예 : &lt;code&gt;output.sizes()[2:]&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="a3faf432bc4aa5f657bed43eb96ddf6068193374" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_tensor_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to be gathered one per rank.</source>
          <target state="translated">&lt;strong&gt;output_tensor_list&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 랭크 당 하나씩 수집 할 텐서 목록입니다.</target>
        </trans-unit>
        <trans-unit id="859379055368818b2ccae1f2f63e2ee0a75004d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;output_tensor_list&lt;/strong&gt; ( &lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="0978f0a55922d996ca9a0fd7211f8e99295fc05a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_tensor_lists&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;output_tensor_lists&lt;/strong&gt; ( &lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="79584f8c8990b1c876dbadf460c2b02b547a0a20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; dropout probability of a channel to be zeroed. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; 제로화 될 채널의 드롭 아웃 확률. 기본값 : 0.5</target>
        </trans-unit>
        <trans-unit id="bd6aaa726614b383781b34c1c9759a061af7eef1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; p value for the p-norm distance to calculate between each vector pair</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; 각 벡터 쌍간에 계산할 p- 노름 거리에 대한 p 값</target>
        </trans-unit>
        <trans-unit id="60e05b10c2aa191fd0f512b35139ad3f5166ee85" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; probability of a channel to be zeroed. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; 채널이 0이 될 확률. 기본값 : 0.5</target>
        </trans-unit>
        <trans-unit id="055d3b3dc7e2825662e52c7899ba890592b92a5b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; probability of an element to be zeroed. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; 요소가 0이 될 확률. 기본값 : 0.5</target>
        </trans-unit>
        <trans-unit id="fc61e4898026558df455ea228711212cc5f6bf2e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; probability of an element to be dropped. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 요소가 드롭 될 확률. 기본값 : 0.5</target>
        </trans-unit>
        <trans-unit id="be2c8a91ba679dbe9334ded6489b8da7b91810a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the exponent value in the norm formulation. Default: 2</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 표준 공식의 지수 값. 기본값 : 2</target>
        </trans-unit>
        <trans-unit id="8ba0723e1b20dae5871248bdf08777de23e09a35" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the power for the norm computation</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 표준 계산을위한 검정력</target>
        </trans-unit>
        <trans-unit id="e35faf459e929b30d01b57525c4b3b7ff20ddb4b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; probability of an element to be zero-ed.</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 요소가 0이 될 확률.</target>
        </trans-unit>
        <trans-unit id="c610f90195dd6efe31a7edae7cac213bdfe97ff2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; probability of an element to be zeroed.</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 요소가 0이 될 확률.</target>
        </trans-unit>
        <trans-unit id="b58fa037642d7f64f2e095fa9889db70e6bb817b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the norm to be computed</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 계산할 표준</target>
        </trans-unit>
        <trans-unit id="d02eaf36455552ed32ca3c35a59e5ff0754e7bc2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of dimensions</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 차원 수</target>
        </trans-unit>
        <trans-unit id="94c331619b61acdfddc0975afbf5ab2cd627bfa1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro' &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc' &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="5885620cdb9d6e6007a7bfaa1257ea3fcbf35862" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 기본값은 다음과 같습니다.</target>
        </trans-unit>
        <trans-unit id="eca1775966b053a849d07171e8c7fca4bc68e061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The norm degree for pairwise distance. Default:</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 쌍별 거리의 표준 차수입니다. 기본:</target>
        </trans-unit>
        <trans-unit id="fd42949d40f645424a960ea51a5b0155e9547aae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;em&gt;real&lt;/em&gt;) &amp;ndash; the norm degree. Default: 2</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; ( &lt;em&gt;실수&lt;/em&gt; ) &amp;ndash; 표준 정도. 기본값 : 2</target>
        </trans-unit>
        <trans-unit id="2a7801e112cc1d15948e989881ab27456d36b8d7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; m-elements tuple, where</source>
          <target state="translated">&lt;strong&gt;pad&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; m- 요소 튜플, 여기서</target>
        </trans-unit>
        <trans-unit id="f2e07cdbfd62345d8b7cd60d6940e8a0fbab4ae2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pad_mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls the padding method used when &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;. Default: &lt;code&gt;&quot;reflect&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;pad_mode&lt;/strong&gt; ( &lt;em&gt;문자열 &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; &lt;code&gt;center&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 일 때 사용되는 패딩 방법을 제어합니다 . 기본값 : &lt;code&gt;&quot;reflect&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8a9ca37fdb632d5816c23727858cdabb73430e65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Can be a single number or a tuple &lt;code&gt;(padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding이 입력에서 각 차원의 양쪽에 추가됩니다. 단일 숫자 또는 튜플 &lt;code&gt;(padH, padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="7562e0bf8b2fbf8f0612a3b04ddb3e0c77c8e2de" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Can be a single number or a tuple &lt;code&gt;(padT, padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding이 입력에서 각 차원의 양쪽에 추가됩니다. 단일 숫자 또는 튜플 &lt;code&gt;(padT, padH, padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="448222bb6d7290e9d682e5dc18b926f4f3f2a062" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Can be a single number or a tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding이 입력에서 각 차원의 양쪽에 추가됩니다. 단일 숫자 또는 튜플 &lt;code&gt;(padW,)&lt;/code&gt; 일 수 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="c82509396ecabb06e2ab93e27c0d96e3494c85e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; Implicit negative infinity padding to be added on both sides, must be &amp;gt;= 0 and &amp;lt;= kernel_size / 2.</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 양쪽에 추가 할 암시 적 음의 무한대 패딩은&amp;gt; = 0 및 &amp;lt;= kernel_size / 2 여야합니다.</target>
        </trans-unit>
        <trans-unit id="035775c3f31b9fdf2b9087a4ab72feb97800345a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a one-element tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시 적 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 단일 요소 튜플 &lt;code&gt;(padW,)&lt;/code&gt; 일 수 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="eb115b29f2d4e8986dbb7361d1bde22d523aa2fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padD, padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시 적 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 튜플 &lt;code&gt;(padD, padH, padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="c77720bd3be235f43a31a948921e71d65c1c2909" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시 적 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 튜플 &lt;code&gt;(padH, padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="3615da94c4b802be1f5c636b261921ec43ca9b61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padT, padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시 적 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 튜플 &lt;code&gt;(padT, padH, padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="0da72c244db3c1c00f8e0e0ec331cec0af62c835" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시 적 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 튜플 &lt;code&gt;(padW,)&lt;/code&gt; 일 수 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="d76aaa6cddce6d9de011fab349f55959decabc91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero padding to be added on all three sides</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 세면 모두에 추가 할 암시 적 제로 채우기</target>
        </trans-unit>
        <trans-unit id="c6eb557a7d88c437df862c9c9d77547955ec2e9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero padding to be added on both sides</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 양쪽에 추가 할 암시 적 0 채우기</target>
        </trans-unit>
        <trans-unit id="5b5113170b2a3f7e706888c5ccdb6b94ee870598" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시적인 0 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 튜플 &lt;code&gt;(padH, padW)&lt;/code&gt; 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="85e6b037c865499fe258c3d24a4079141415f86f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padT, padH, padW)&lt;/code&gt;, Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시적인 0 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 튜플 &lt;code&gt;(padT, padH, padW)&lt;/code&gt; 일 수 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="fe955794273a21194f7067e1ae48e4951e5e799b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; 입력의 양쪽에 암시적인 0 &lt;strong&gt;채우기&lt;/strong&gt; . 단일 숫자 또는 튜플 &lt;code&gt;(padW,)&lt;/code&gt; 일 수 있습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="1772edf760a9f7e7c4c981c7145fff686e883581" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Padding that was added to the input</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 입력에 추가 된 채우기</target>
        </trans-unit>
        <trans-unit id="9378d98a5c97c1044f08880972e01ac3393dbb72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding이 입력에서 각 차원의 양쪽에 추가됩니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="6bab43419d41e24875998f0b0d4b8567ba1bd7b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding이 입력의 양쪽에 추가됩니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="198506b9fb9056c9654540b4487b630e49f578c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Zero-padding added to all three sides of the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 입력의 세면 모두에 제로 채우기가 추가되었습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="71ff1d7f40410d7f42df028ec0f884ae0b40ef54" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Zero-padding added to both sides of the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 입력의 양쪽에 제로 패딩이 추가되었습니다. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="acde30c2a2360aeb1bb9367ebe202c70986d7598" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; implicit zero padding to be added on both sides of input. Default: 0</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 입력의 양쪽에 추가 할 암시 적 0 채우기. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="661ddd64fdf787533b21bb87f5850bcd7ca62102" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in all boundaries. If a 2-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 안쪽 여백의 크기입니다. 경우 &lt;code&gt;int&lt;/code&gt; , 모든 경계에서 같은 패딩을 사용한다. 2- &lt;code&gt;tuple&lt;/code&gt; 이면 (</target>
        </trans-unit>
        <trans-unit id="f8c452117fc928955dd2bd55760ff8548c5d6e4c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in all boundaries. If a 4-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 안쪽 여백의 크기입니다. 경우 &lt;code&gt;int&lt;/code&gt; , 모든 경계에서 같은 패딩을 사용한다. 4- &lt;code&gt;tuple&lt;/code&gt; 이면 (</target>
        </trans-unit>
        <trans-unit id="0c871849a3c90385e2d2dfb4fade7f685e558919" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in all boundaries. If a 6-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 안쪽 여백의 크기입니다. 경우 &lt;code&gt;int&lt;/code&gt; , 모든 경계에서 같은 패딩을 사용한다. 6- &lt;code&gt;tuple&lt;/code&gt; 이면 (</target>
        </trans-unit>
        <trans-unit id="de0fe1f500b814cb0dab544c02e18d3f627fc075" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in both boundaries. If a 2-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;padding&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 안쪽 여백의 크기입니다. 경우 &lt;code&gt;int&lt;/code&gt; , 모두 경계에서 같은 패딩을 사용한다. 2- &lt;code&gt;tuple&lt;/code&gt; 이면 (</target>
        </trans-unit>
        <trans-unit id="9401caef7f5afbf352224bad95b3fe76778191fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_idx&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, pads the output with the embedding vector at &lt;code&gt;padding_idx&lt;/code&gt; (initialized to zeros) whenever it encounters the index.</source>
          <target state="translated">&lt;strong&gt;padding_idx&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 주어진 경우 , 인덱스를 만날 때마다 &lt;code&gt;padding_idx&lt;/code&gt; (0으로 초기화 됨) 에서 임베딩 벡터로 출력을 채 웁니다 .</target>
        </trans-unit>
        <trans-unit id="9ada542978419d7c3da9e87c076d2586fc884e6e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_idx&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</source>
          <target state="translated">&lt;strong&gt;padding_idx&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 모듈 초기화 문서를 참조하십시오.</target>
        </trans-unit>
        <trans-unit id="3943fa317748711d3f74fb28e963a67dc6ae1023" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_mode&lt;/strong&gt; &amp;ndash; the padding mode to use. Only &amp;ldquo;zeros&amp;rdquo; is supported for quantized convolution at the moment. Default: &amp;ldquo;zeros&amp;rdquo;</source>
          <target state="translated">&lt;strong&gt;padding_mode&lt;/strong&gt; &amp;ndash; 사용할 패딩 모드. 현재 양자화 된 컨볼 루션에는 &quot;0&quot;만 지원됩니다. 기본값 : &quot;0&quot;</target>
        </trans-unit>
        <trans-unit id="d48e37505fe88a204a4698afd9bd53c6178eb622" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; padding mode for outside grid values &lt;code&gt;'zeros'&lt;/code&gt; | &lt;code&gt;'border'&lt;/code&gt; | &lt;code&gt;'reflection'&lt;/code&gt;. Default: &lt;code&gt;'zeros'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;padding_mode&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 외부 그리드 값 &lt;code&gt;'zeros'&lt;/code&gt; 대한 패딩 모드 | &lt;code&gt;'border'&lt;/code&gt; | &lt;code&gt;'reflection'&lt;/code&gt; . 기본값 : &lt;code&gt;'zeros'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4afe9a05f840c246091966bf0c12fea8eff4ade1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;'zeros'&lt;/code&gt;, &lt;code&gt;'reflect'&lt;/code&gt;, &lt;code&gt;'replicate'&lt;/code&gt; or &lt;code&gt;'circular'&lt;/code&gt;. Default: &lt;code&gt;'zeros'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;padding_mode&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;'zeros'&lt;/code&gt; , &lt;code&gt;'reflect'&lt;/code&gt; , &lt;code&gt;'replicate'&lt;/code&gt; 또는 &lt;code&gt;'circular'&lt;/code&gt; . 기본값 : &lt;code&gt;'zeros'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1c8930299bc472b0bf01b43e4876b43bc57b0afd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; value for padded elements. Default: 0.</source>
          <target state="translated">&lt;strong&gt;padding_value&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 패딩 된 요소의 값입니다. 기본값 : 0.</target>
        </trans-unit>
        <trans-unit id="e46a4080234de5b81dc28aa5cf6494e583b2dfc4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; values for padded elements.</source>
          <target state="translated">&lt;strong&gt;padding_value&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 패딩 된 요소의 값입니다.</target>
        </trans-unit>
        <trans-unit id="1e944f55958d7c17e7297fead1ace3158d4a22b0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;param&lt;/strong&gt; &amp;ndash; optional parameter for the non-linear function</source>
          <target state="translated">&lt;strong&gt;param&lt;/strong&gt; &amp;ndash; 비선형 함수에 대한 선택적 매개 변수</target>
        </trans-unit>
        <trans-unit id="2a439f504eecae5ec1487c4ee52295b7169b16a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;param&lt;/strong&gt; (&lt;a href=&quot;torch.nn.parameter.parameter#torch.nn.parameter.Parameter&quot;&gt;Parameter&lt;/a&gt;) &amp;ndash; parameter to be added to the module.</source>
          <target state="translated">&lt;strong&gt;param&lt;/strong&gt; ( &lt;a href=&quot;torch.nn.parameter.parameter#torch.nn.parameter.Parameter&quot;&gt;Parameter&lt;/a&gt; ) &amp;ndash; 모듈에 추가 할 매개 변수입니다.</target>
        </trans-unit>
        <trans-unit id="f75a00d4efb185ff63b6a63af312bfa294122453" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameter&lt;/strong&gt; (&lt;em&gt;nn.Parameter&lt;/em&gt;) &amp;ndash; parameter to append</source>
          <target state="translated">&lt;strong&gt;parameter&lt;/strong&gt; ( &lt;em&gt;nn.Parameter&lt;/em&gt; ) &amp;ndash; 추가 할 매개 변수</target>
        </trans-unit>
        <trans-unit id="489497c61c6c4ca41d36025fee2d4513e38423ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;Iterable of&lt;/em&gt;&lt;em&gt; (&lt;/em&gt;&lt;em&gt;module&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;name&lt;/em&gt;&lt;em&gt;) &lt;/em&gt;&lt;em&gt;tuples&lt;/em&gt;) &amp;ndash; parameters of the model to prune in a global fashion, i.e. by aggregating all weights prior to deciding which ones to prune. module must be of type &lt;code&gt;nn.Module&lt;/code&gt;, and name must be a string.</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt; ( &lt;em&gt;Iterable of &lt;/em&gt;&lt;em&gt;( &lt;/em&gt;&lt;em&gt;module &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;name &lt;/em&gt;&lt;em&gt;) &lt;/em&gt;&lt;em&gt;tuples&lt;/em&gt; ) &amp;ndash; 정리할 가중치를 결정하기 전에 모든 가중치를 집계하여 글로벌 방식으로 정리할 모델의 매개 변수입니다. 모듈은 &lt;code&gt;nn.Module&lt;/code&gt; 유형 이어야 하며 이름은 문자열이어야합니다.</target>
        </trans-unit>
        <trans-unit id="d320f6d02ed2f210bc2bb94d849c5a4a0333a948" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; an iterable of Tensors or a single Tensor that will have gradients normalized</source>
          <target state="translated">&lt;strong&gt;매개 변수&lt;/strong&gt; ( &lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;] 또는 &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 텐서 의 이터 러블 또는 그래디언트가 정규화 된 단일 텐서</target>
        </trans-unit>
        <trans-unit id="088332766231b5fb1e917d8a22e9be51803d3339" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; an iterator of Tensors that are the parameters of a model.</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt; ( &lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 모델의 매개 변수 인 Tensor 의 반복자입니다.</target>
        </trans-unit>
        <trans-unit id="22d3c60c713a7260e180dbfeec107c5a3c8c8e37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; a mapping (dictionary) from string to &lt;code&gt;Parameter&lt;/code&gt;, or an iterable of key-value pairs of type (string, &lt;code&gt;Parameter&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt; ( &lt;em&gt;iterable&lt;/em&gt; ) &amp;ndash; string에서 &lt;code&gt;Parameter&lt;/code&gt; 로의 매핑 (사전) 또는 유형 (string, &lt;code&gt;Parameter&lt;/code&gt; ) 의 키-값 쌍 반복 가능</target>
        </trans-unit>
        <trans-unit id="b029593b0723b3ed9d1778d6c527b9cc13f2e3dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; iterable of parameters to append</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt; ( &lt;em&gt;iterable&lt;/em&gt; ) &amp;ndash; 추가 할 매개 변수의 반복 가능</target>
        </trans-unit>
        <trans-unit id="b756d03d964186ac93672f10364095cbcb790305" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a mapping (dictionary) of (string : &lt;code&gt;Parameter&lt;/code&gt;) or an iterable of key-value pairs of type (string, &lt;code&gt;Parameter&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt; ( &lt;em&gt;iterable &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; (string : &lt;code&gt;Parameter&lt;/code&gt; ) 의 매핑 (사전 ) 또는 유형 (string, &lt;code&gt;Parameter&lt;/code&gt; ) 의 키-값 쌍의 반복 가능</target>
        </trans-unit>
        <trans-unit id="7a1a7adbc39a4daf48449acfbbb118da27774d19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; an iterable of &lt;code&gt;Parameter&lt;/code&gt; to add</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt; ( &lt;em&gt;iterable &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 추가 할 &lt;code&gt;Parameter&lt;/code&gt; 의 반복 가능</target>
        </trans-unit>
        <trans-unit id="88c32fc1811dc3014215ab77e8ab52e5f171a72c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;params_rref&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;RRef&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; list of RRefs to local or remote parameters to optimize.</source>
          <target state="translated">&lt;strong&gt;params_rref&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;RRef &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 최적화 할 로컬 또는 원격 매개 변수에 대한 RRef 목록입니다.</target>
        </trans-unit>
        <trans-unit id="c73980a2dbe97d6cc5f31cd9778490dcbce3fd01" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;per_sample_weights&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a tensor of float / double weights, or None to indicate all weights should be taken to be 1. If specified, &lt;code&gt;per_sample_weights&lt;/code&gt; must have exactly the same shape as input and is treated as having the same &lt;code&gt;offsets&lt;/code&gt;, if those are not None.</source>
          <target state="translated">&lt;strong&gt;per_sample_weights&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;텐서 &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사양&lt;/em&gt; ) - 플로트 / 더블 무게, 또는 모든 가중치를 나타내는 없음의 텐서는 지정한 경우 1.로 이동해야 &lt;code&gt;per_sample_weights&lt;/code&gt; 이 입력으로 정확히 같은 모양을 가지고 있어야하고 동일한 것으로 취급된다 &lt;code&gt;offsets&lt;/code&gt; 경우, 그들은 None이 아닙니다.</target>
        </trans-unit>
        <trans-unit id="1e8c363177f0382a2ca52911b44cd26dbb02b01b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;periodic&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If True, returns a periodic window suitable for use in spectral analysis. If False, returns a symmetric window suitable for use in filter design.</source>
          <target state="translated">&lt;strong&gt;periodic&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; True 인 경우 스펙트럼 분석에 사용하기에 적합한 주기적 창을 반환합니다. False이면 필터 설계에 사용하기에 적합한 대칭 창을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="9dc935030f617a99daedb64a9e2141255a78596a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;periodic&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If True, returns a window to be used as periodic function. If False, return a symmetric window.</source>
          <target state="translated">&lt;strong&gt;periodic&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; True 인 경우 주기적 함수로 사용할 창을 반환합니다. False이면 대칭 창을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="10ac8ca2d66e3e1712e04c036b9bf70de5e5b9a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;perserved_methods&lt;/strong&gt; &amp;ndash; A list of methods that needed to be preserved when freeze_module pass is invoked</source>
          <target state="translated">&lt;strong&gt;perserved_methods&lt;/strong&gt; &amp;ndash; freeze_module 패스가 호출 될 때 보존되어야하는 메소드 목록</target>
        </trans-unit>
        <trans-unit id="27ea671e2a5ede173ebe44a6fbf6a5dfc8e07a55" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;영구&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 버퍼가이 모듈의 &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 일부인지 여부 .</target>
        </trans-unit>
        <trans-unit id="00ab29ea4c85832585125194a8d3ce432d70b86b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;영구&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 버퍼가이 모듈의 &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 일부인지 여부 .</target>
        </trans-unit>
        <trans-unit id="d9ed1cdbc115cc96411a0714a99ba4f42fb9ffaf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;영구&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 버퍼가이 모듈의 &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 일부인지 여부 .</target>
        </trans-unit>
        <trans-unit id="730eade83c492cb9c9d61b0d4e948adf920f85d5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;영구&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 버퍼가이 모듈의 &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 일부인지 여부 .</target>
        </trans-unit>
        <trans-unit id="6616e16bfa20c63814b50ea16a8dbe20de09b074" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_load_args&lt;/strong&gt; &amp;ndash; (Python 3 only) optional keyword arguments passed over to &lt;code&gt;pickle_module.load()&lt;/code&gt; and &lt;code&gt;pickle_module.Unpickler()&lt;/code&gt;, e.g., &lt;code&gt;errors=...&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;pickle_load_args&lt;/strong&gt; &amp;ndash; (Python 3 전용) &lt;code&gt;pickle_module.load()&lt;/code&gt; 및 &lt;code&gt;pickle_module.Unpickler()&lt;/code&gt; 전달 된 선택적 키워드 인수 ( 예 : &lt;code&gt;errors=...&lt;/code&gt; ) .</target>
        </trans-unit>
        <trans-unit id="80a816c0ab01c996cd7ea1aa403c557f4fa9c91f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash; module used for pickling metadata and objects</source>
          <target state="translated">&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash; 메타 데이터 및 개체를 피클 링하는 데 사용되는 모듈</target>
        </trans-unit>
        <trans-unit id="2f4bba92d9ab262c68a9aa63c263e3ecc1546639" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash; module used for unpickling metadata and objects (has to match the &lt;code&gt;pickle_module&lt;/code&gt; used to serialize file)</source>
          <target state="translated">&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash; 메타 데이터 및 개체를 언 피클 링하는 데 사용되는 모듈 ( 파일 직렬화에 사용 된 &lt;code&gt;pickle_module&lt;/code&gt; 과 일치해야 함 )</target>
        </trans-unit>
        <trans-unit id="d45a398e45519ff88900ce547f84f72e8159bc02" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_protocol&lt;/strong&gt; &amp;ndash; can be specified to override the default protocol</source>
          <target state="translated">&lt;strong&gt;pickle_protocol&lt;/strong&gt; &amp;ndash; 기본 프로토콜을 재정의하도록 지정할 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="158a245072a4f4a11829d7283abb48b4e1e9eb19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pin_memory&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;pin_memory&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 설정되면 반환 된 텐서가 고정 된 메모리에 할당됩니다. CPU 텐서에서만 작동합니다. 기본값 : &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="30a109270dbf3f6ec8bac6d1654792ed9100f8cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pivot&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether pivoting is done. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;pivot&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 피벗 수행 여부를 제어합니다. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cd32ee50a83eb126fa1a1c22993913d7830c61d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pivots&lt;/strong&gt; (&lt;em&gt;IntTensor&lt;/em&gt;): the pivots of size</source>
          <target state="translated">&lt;strong&gt;피벗&lt;/strong&gt; ( &lt;em&gt;IntTensor&lt;/em&gt; ) : 크기의 피벗</target>
        </trans-unit>
        <trans-unit id="f2e2c490dcdc08b15ee53f75826edaf1f53d7fd1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;port&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The port on which the server store should listen for incoming requests.</source>
          <target state="translated">&lt;strong&gt;port&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 서버 저장소가 들어오는 요청을 수신해야하는 포트입니다.</target>
        </trans-unit>
        <trans-unit id="a7e3a169027105e593b1192ecd8a9853f1788650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pos_weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a weight of positive examples. Must be a vector with length equal to the number of classes.</source>
          <target state="translated">&lt;strong&gt;pos_weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 긍정적 인 예시의 가중치. 길이가 클래스 수와 같은 벡터 여야합니다.</target>
        </trans-unit>
        <trans-unit id="5d9e32c819f28a6d6eb1c4b5e3bf66285ee0131e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pos_weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a weight of positive examples. Must be a vector with length equal to the number of classes.</source>
          <target state="translated">&lt;strong&gt;pos_weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 긍정적 인 예시의 가중치. 길이가 클래스 수와 같은 벡터 여야합니다.</target>
        </trans-unit>
        <trans-unit id="63a4d9260aa840607a810cbe8d0437c578111576" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;precision&lt;/strong&gt; &amp;ndash; Number of digits of precision for floating point output (default = 4).</source>
          <target state="translated">&lt;strong&gt;precision&lt;/strong&gt; &amp;ndash; 부동 소수점 출력의 정밀도 자릿수입니다 (기본값 = 4).</target>
        </trans-unit>
        <trans-unit id="abaf92d6b3ab9531ecb8cfe273227a30db2aba37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;predictions&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; The probability that an element be classified as true. Value should in [0, 1]</source>
          <target state="translated">&lt;strong&gt;예측&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array &lt;/em&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;string / blobname&lt;/em&gt; ) &amp;ndash; 요소가 참으로 분류 될 확률. 값은 [0, 1]이어야합니다.</target>
        </trans-unit>
        <trans-unit id="739bd144f8a0f654bdebf94781331327df2092bf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prefix&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The prefix string that is prepended to each key before being inserted into the store.</source>
          <target state="translated">&lt;strong&gt;prefix&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 저장소에 삽입되기 전에 각 키 앞에 추가되는 접두사 문자열입니다.</target>
        </trans-unit>
        <trans-unit id="fa8d87d0a691a6a353587f6a788059707272207e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prefix&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; prefix to prepend to all buffer names.</source>
          <target state="translated">&lt;strong&gt;prefix&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 모든 버퍼 이름 앞에 추가 할 접두사.</target>
        </trans-unit>
        <trans-unit id="a986463f78b9961525aa208023a9f037690aad13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prefix&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; prefix to prepend to all parameter names.</source>
          <target state="translated">&lt;strong&gt;prefix&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 모든 매개 변수 이름 앞에 추가 할 접두사.</target>
        </trans-unit>
        <trans-unit id="87f996b18f2064a1da55736eae49c39b0a0515d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;preserve_rng_state&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default=True&lt;/em&gt;) &amp;ndash; Omit stashing and restoring the RNG state during each checkpoint.</source>
          <target state="translated">&lt;strong&gt;preserve_rng_state&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default = True&lt;/em&gt; ) &amp;ndash; 각 체크 포인트 동안 RNG 상태 숨김 및 복원을 생략합니다.</target>
        </trans-unit>
        <trans-unit id="7c2241fe546f8b691ed0b5ac683a6b12c7593208" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on COCO train2017</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True 인 경우 COCO train2017에서 사전 훈련 된 모델을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="4130c1fbf426acf115174024390b36c99e17bb23" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on COCO train2017 which contains the same classes as Pascal VOC</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True 인 경우 Pascal VOC와 동일한 클래스를 포함하는 COCO train2017에서 사전 학습 된 모델을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="3368d37398eeaa3adc0a4b2005b7ee2eb4eae69a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on ImageNet</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True이면 ImageNet에서 사전 훈련 된 모델을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="f82401ac0221d2cb1ccfd88239494a6d6471b218" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on Kinetics-400</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True 인 경우 Kinetics-400에서 사전 훈련 된 모델을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="7c650eeb51be2510d223d56911e3f6d5151fafd9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained_backbone&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model with backbone pre-trained on Imagenet</source>
          <target state="translated">&lt;strong&gt;pretrained_backbone&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True 인 경우 Imagenet에서 사전 학습 된 백본이있는 모델을 반환합니다.</target>
        </trans-unit>
        <trans-unit id="c9bb8392d89004ba45474c8414a4e0ac5c0dec7d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash; The process group to be used for distributed data all-reduction. If &lt;code&gt;None&lt;/code&gt;, the default process group, which is created by &lt;a href=&quot;../distributed#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt;&lt;/a&gt;, will be used. (default: &lt;code&gt;None&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash; 분산 데이터 전체 축소에 사용할 프로세스 그룹입니다. 경우 &lt;code&gt;None&lt;/code&gt; 에 의해 생성되는 기본 프로세스 그룹, &lt;a href=&quot;../distributed#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt; &lt;/a&gt; , 사용됩니다. (기본값 : &lt;code&gt;None&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="ada49fdca36ec13c35249cb76cecbfce751dce94" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash; synchronization of stats happen within each process group individually. Default behavior is synchronization across the whole world</source>
          <target state="translated">&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash; 통계 동기화는 각 프로세스 그룹 내에서 개별적으로 발생합니다. 기본 동작은 전 세계 동기화입니다.</target>
        </trans-unit>
        <trans-unit id="ab933fbb9c2c9f17574f6d3222ab8887ecfcdd68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;process_group&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; process group to scope synchronization, default is the whole world</source>
          <target state="translated">&lt;strong&gt;process_group&lt;/strong&gt; ( &lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 프로세스 그룹 간 동기화, 기본값은 전 세계입니다.</target>
        </trans-unit>
        <trans-unit id="63cde1066d72754dbf25cd05b0ce992cd2c0bf1a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;profile&lt;/strong&gt; &amp;ndash; Sane defaults for pretty printing. Can override with any of the above options. (any one of &lt;code&gt;default&lt;/code&gt;, &lt;code&gt;short&lt;/code&gt;, &lt;code&gt;full&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;profile&lt;/strong&gt; &amp;ndash; 예쁜 인쇄를위한 Sane 기본값. 위의 옵션 중 하나로 재정의 할 수 있습니다. ( &lt;code&gt;default&lt;/code&gt; , &lt;code&gt;short&lt;/code&gt; , &lt;code&gt;full&lt;/code&gt; 중 하나 )</target>
        </trans-unit>
        <trans-unit id="4b15a59aebfcfe93a0fb0b923c3d5e9329cf089d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;progress&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, displays a progress bar of the download to stderr</source>
          <target state="translated">&lt;strong&gt;progress&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True이면 stderr로 다운로드 진행률 표시 줄을 표시합니다.</target>
        </trans-unit>
        <trans-unit id="fb2a87f24d269533a9f43524829d450e3c20d9a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;progress&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether or not to display a progress bar to stderr Default: True</source>
          <target state="translated">&lt;strong&gt;progress&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; stderr에 진행률 표시 줄을 표시할지 여부 기본값 : True</target>
        </trans-unit>
        <trans-unit id="1f4a965676c83faefeff0a640a396640b206ce90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;progress&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether or not to display a progress bar to stderr. Default: True</source>
          <target state="translated">&lt;strong&gt;progress&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; stderr에 진행률 표시 줄을 표시할지 여부입니다. 기본값 : True</target>
        </trans-unit>
        <trans-unit id="904f28013662ab6c545488f5c421363d39caa951" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pruning_method&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;) &amp;ndash; a valid pruning function from this module, or a custom one implemented by the user that satisfies the implementation guidelines and has &lt;code&gt;PRUNING_TYPE='unstructured'&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;pruning_method&lt;/strong&gt; ( &lt;em&gt;function&lt;/em&gt; ) &amp;ndash;이 모듈의 유효한 정리 함수 또는 구현 지침을 충족하고 &lt;code&gt;PRUNING_TYPE='unstructured'&lt;/code&gt; 가있는 사용자가 구현 한 사용자 정의 함수 입니다.</target>
        </trans-unit>
        <trans-unit id="e2d5c802a24580a7de621d4fd574838b9fee79a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;purge_step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; When logging crashes at step</source>
          <target state="translated">&lt;strong&gt;purge_step&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 로깅이 단계에서 충돌 할 때</target>
        </trans-unit>
        <trans-unit id="d1cf443a5e0dc3febcb5f16e5dcd17ebe5190074" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;q&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a scalar or 1D tensor of quantile values in the range [0, 1]</source>
          <target state="translated">&lt;strong&gt;q&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; [0, 1] 범위에있는 분위수 값의 스칼라 또는 1D 텐서</target>
        </trans-unit>
        <trans-unit id="a79e6547c6d8a86b6b38364e5726183256af0cff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;q&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a slightly overestimated rank of</source>
          <target state="translated">&lt;strong&gt;q&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 약간 과대 평가 된 순위</target>
        </trans-unit>
        <trans-unit id="2b03c96abe488a3ad5cb0d36a695b5ff1baba3a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;r&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; number of elements to combine</source>
          <target state="translated">&lt;strong&gt;r&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 결합 할 요소 수</target>
        </trans-unit>
        <trans-unit id="46b43eec40a9385ec340e004393520434a0a5eff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; a globally unique id/rank of this node.</source>
          <target state="translated">&lt;strong&gt;rank&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash;이 노드의 전역 적으로 고유 한 ID / 순위입니다.</target>
        </trans-unit>
        <trans-unit id="213d6776c2e063ecf8780712ac1852b9cd773740" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Rank of the current process. Required if &lt;code&gt;store&lt;/code&gt; is specified.</source>
          <target state="translated">&lt;strong&gt;rank&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 현재 프로세스의 순위입니다. &lt;code&gt;store&lt;/code&gt; 이 지정된 경우 필수 입니다.</target>
        </trans-unit>
        <trans-unit id="eded7c6be7a599ab9e04149f80d8815426799286" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ranks&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of ranks of group members. If &lt;code&gt;None&lt;/code&gt;, will be set to all ranks. Default is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;순위&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 그룹 구성원의 순위 목록입니다. 경우 &lt;code&gt;None&lt;/code&gt; , 모든 계급으로 설정됩니다. 기본값은 &lt;code&gt;None&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="75f1a5c80836b92712f937ef8445c423fd9ea3f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rcond&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; A floating point value to determine the cutoff for small singular values. Default: 1e-15</source>
          <target state="translated">&lt;strong&gt;rcond&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 작은 특이 값에 대한 컷오프를 결정하는 부동 소수점 값입니다. 기본값 : 1e-15</target>
        </trans-unit>
        <trans-unit id="af581fa7827e69e59f0e4da3fc56082b354bc569" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;real&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The real part of the complex tensor. Must be float or double.</source>
          <target state="translated">&lt;strong&gt;real&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 복잡한 텐서의 실수 부분입니다. float 또는 double이어야합니다.</target>
        </trans-unit>
        <trans-unit id="d062ec2db1e149329c436d3f85532b1325d11a04" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;recompute_scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; recompute the scale_factor for use in the interpolation calculation. When &lt;code&gt;scale_factor&lt;/code&gt; is passed as a parameter, it is used to compute the &lt;code&gt;output_size&lt;/code&gt;. If &lt;code&gt;recompute_scale_factor&lt;/code&gt; is &lt;code&gt;`False&lt;/code&gt; or not specified, the passed-in &lt;code&gt;scale_factor&lt;/code&gt; will be used in the interpolation computation. Otherwise, a new &lt;code&gt;scale_factor&lt;/code&gt; will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed &lt;code&gt;output_size&lt;/code&gt; were passed-in explicitly). Note that when &lt;code&gt;scale_factor&lt;/code&gt; is floating-point, the recomputed scale_factor may differ from the one passed in due to rounding and precision issues.</source>
          <target state="translated">&lt;strong&gt;recompute_scale_factor&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 보간 계산에 사용할 scale_factor를 다시 계산합니다. 때 &lt;code&gt;scale_factor&lt;/code&gt; 가 매개 변수로 전달되고, 계산하는 데 사용됩니다 &lt;code&gt;output_size&lt;/code&gt; 을 . 경우 &lt;code&gt;recompute_scale_factor&lt;/code&gt; 가 있다 &lt;code&gt;`False&lt;/code&gt; 지정된 아니든는 전달 된 &lt;code&gt;scale_factor&lt;/code&gt; 보간 계산에서 사용될 것이다. 그렇지 않으면 새로운 &lt;code&gt;scale_factor&lt;/code&gt; 가 보간 계산에 사용하기위한 출력 및 입력 크기를 기반으로 계산됩니다 (즉, 계산 된 &lt;code&gt;output_size&lt;/code&gt; 가 명시 적으로 전달 된 경우와 계산이 동일합니다 ). 참고 때 &lt;code&gt;scale_factor&lt;/code&gt; 부동 소수점 인 경우 재 계산 된 scale_factor는 반올림 및 정밀도 문제로 인해 전달 된 것과 다를 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="66b7e6f37f61ed7bcaf736cc00b93f71e3e9d94f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;recurse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if True, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module.</source>
          <target state="translated">&lt;strong&gt;recurse&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True이면이 모듈과 모든 하위 모듈의 버퍼를 생성합니다. 그렇지 않으면이 모듈의 직접 멤버 인 버퍼 만 생성합니다.</target>
        </trans-unit>
        <trans-unit id="644d5b1b0bd86304bca7dd80429d10befe174346" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;recurse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that are direct members of this module.</source>
          <target state="translated">&lt;strong&gt;recurse&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True이면이 모듈과 모든 하위 모듈의 매개 변수를 생성합니다. 그렇지 않으면이 모듈의 직접 멤버 인 매개 변수 만 생성합니다.</target>
        </trans-unit>
        <trans-unit id="9d6ed3cdc238c90248d062e02e2aeb40a792fd6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduce&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt;). By default, the losses are averaged or summed over observations for each minibatch depending on &lt;code&gt;size_average&lt;/code&gt;. When &lt;code&gt;reduce&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, returns a loss per batch element instead and ignores &lt;code&gt;size_average&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduce&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 더 이상 사용되지 않습니다 ( &lt;code&gt;reduction&lt;/code&gt; 참조 ). 기본적으로 손실은 평균거나에 따라 각각의 minibatch에 대한 관찰을 통해 요약 &lt;code&gt;size_average&lt;/code&gt; . 때 &lt;code&gt;reduce&lt;/code&gt; 입니다 &lt;code&gt;False&lt;/code&gt; 대신 배치 요소마다 손실을 반환하고 무시 &lt;code&gt;size_average&lt;/code&gt; 을 . 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ec48eb52fa8aaaf96330bc31ea80796de3009600" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduce&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; reduction operation to apply, can be either &amp;lsquo;add&amp;rsquo; or &amp;lsquo;multiply&amp;rsquo;.</source>
          <target state="translated">&lt;strong&gt;reduce&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 적용 할 감소 작업으로 'add'또는 'multiply'가 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="999d2f01d581c18979dd9cf3c2b7eed8f5feaf65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the (optional) reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the sum of the output will be divided by the number of elements in the output, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduction&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력에 적용 할 (선택 사항) 축소를 지정합니다. &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; . &lt;code&gt;'none'&lt;/code&gt; : 감소가 적용되지 않음, &lt;code&gt;'mean'&lt;/code&gt; : 출력의 합계를 출력의 요소 수로 나눈다, &lt;code&gt;'sum'&lt;/code&gt; : 출력을 합산합니다. 기본값 : &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="be1520205497ebdaeafa4280ed8c7e38f481ddbb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied &lt;code&gt;'batchmean'&lt;/code&gt;: the sum of the output will be divided by the batchsize &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed &lt;code&gt;'mean'&lt;/code&gt;: the output will be divided by the number of elements in the output Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduction&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력에 적용 할 축소를 지정합니다. &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; . &lt;code&gt;'none'&lt;/code&gt; : 감소가 적용되지 않습니다. &lt;code&gt;'batchmean'&lt;/code&gt; : 출력의 합계가 배치 크기로 나뉩니다. &lt;code&gt;'sum'&lt;/code&gt; : 출력이 합산됩니다. &lt;code&gt;'mean'&lt;/code&gt; : 출력이 출력의 요소 수로 나뉩니다. 기본값 : &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c4b4f64c1d6c7c3276f90a766a11f80a1ea5e149" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied. &lt;code&gt;'batchmean'&lt;/code&gt;: the sum of the output will be divided by batchsize. &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. &lt;code&gt;'mean'&lt;/code&gt;: the output will be divided by the number of elements in the output. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduction&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력에 적용 할 축소를 지정합니다. &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; . &lt;code&gt;'none'&lt;/code&gt; : 축소가 적용되지 않습니다. &lt;code&gt;'batchmean'&lt;/code&gt; : 출력의 합계를 batchsize로 나눕니다. &lt;code&gt;'sum'&lt;/code&gt; : 출력이 합산됩니다. &lt;code&gt;'mean'&lt;/code&gt; : 출력이 출력의 요소 수로 나뉩니다. 기본값 : &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="550432cc430b06db5fb2ea76d0d512f8f5fde312" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the output losses will be divided by the target lengths and then the mean over the batch is taken, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduction&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력에 적용 할 축소를 지정합니다. &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; . &lt;code&gt;'none'&lt;/code&gt; : 감소가 적용되지 않음, &lt;code&gt;'mean'&lt;/code&gt; : 출력 손실을 목표 길이로 나눈 다음 배치에 대한 평균을 취합니다. &lt;code&gt;'sum'&lt;/code&gt; : 출력을 합산합니다. 기본값 : &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="fab0f58a76f5ab9a119f22747e3687485076ce27" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the output losses will be divided by the target lengths and then the mean over the batch is taken. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduction&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력에 적용 할 축소를 지정합니다. &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; . &lt;code&gt;'none'&lt;/code&gt; : 감소가 적용되지 않음, &lt;code&gt;'mean'&lt;/code&gt; : 출력 손실을 목표 길이로 나눈 다음 배치에 대한 평균을 취합니다. 기본값 : &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2038b00821d8c29dc11b468c90bec48a089c2703" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the sum of the output will be divided by the number of elements in the output, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Note: &lt;code&gt;size_average&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; are in the process of being deprecated, and in the meantime, specifying either of those two args will override &lt;code&gt;reduction&lt;/code&gt;. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduction&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력에 적용 할 축소를 지정합니다. &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; . &lt;code&gt;'none'&lt;/code&gt; : 감소가 적용되지 않음, &lt;code&gt;'mean'&lt;/code&gt; : 출력의 합계를 출력의 요소 수로 나눈다, &lt;code&gt;'sum'&lt;/code&gt; : 출력을 합산합니다. 참고 : &lt;code&gt;size_average&lt;/code&gt; 및 &lt;code&gt;reduce&lt;/code&gt; 는 더 이상 사용되지 않으며 그 동안 두 인수 중 하나를 지정하면 &lt;code&gt;reduction&lt;/code&gt; 을 재정의 합니다. 기본값 : &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="eeb5334dd27eff929df501296bde2d45292263ba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the weighted mean of the output is taken, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Note: &lt;code&gt;size_average&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; are in the process of being deprecated, and in the meantime, specifying either of those two args will override &lt;code&gt;reduction&lt;/code&gt;. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduction&lt;/strong&gt; ( &lt;em&gt;string &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력에 적용 할 축소를 지정합니다. &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; . &lt;code&gt;'none'&lt;/code&gt; : 감소가 적용되지 않음, &lt;code&gt;'mean'&lt;/code&gt; : 출력의 가중 평균이 사용됨, &lt;code&gt;'sum'&lt;/code&gt; : 출력이 합산됩니다. 참고 : &lt;code&gt;size_average&lt;/code&gt; 및 &lt;code&gt;reduce&lt;/code&gt; 는 더 이상 사용되지 않으며 그 동안 두 인수 중 하나를 지정하면 &lt;code&gt;reduction&lt;/code&gt; 을 재정의 합니다. 기본값 : &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6a3f6bd6ab2f6e4081336546b9b09a6627d4bd3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;repeats&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The number of repetitions for each element. repeats is broadcasted to fit the shape of the given axis.</source>
          <target state="translated">&lt;strong&gt;repeats&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 각 요소의 반복 횟수입니다. 반복은 주어진 축의 모양에 맞게 방송됩니다.</target>
        </trans-unit>
        <trans-unit id="624d56544251a5adb1f3f92beef5fbb3779fffe6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;replacement&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to draw with replacement or not</source>
          <target state="translated">&lt;strong&gt;replacement&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 교체로 그릴 지 여부</target>
        </trans-unit>
        <trans-unit id="c9636def42aa5ea6379407cbf86e341937067fa5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;repo_or_dir&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; repo name (&lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt;), if &lt;code&gt;source = 'github'&lt;/code&gt;; or a path to a local directory, if &lt;code&gt;source = 'local'&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;repo_or_dir&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; repo 이름 ( &lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt; ), if &lt;code&gt;source = 'github'&lt;/code&gt; ; 또는 &lt;code&gt;source = 'local'&lt;/code&gt; 인 경우 로컬 디렉토리의 경로 입니다.</target>
        </trans-unit>
        <trans-unit id="9d8769220135033f3f9eb757c4af510a8fde0c5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If autograd should record operations on this tensor. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;requires_grad&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; autograd가이 텐서에 대한 작업을 기록해야하는 경우. 기본값 : &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4b55034c998f6c870737977254bec184876385d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether autograd should record operations on parameters in this module. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;requires_grad&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; autograd가이 모듈의 매개 변수에 대한 작업을 기록해야하는지 여부입니다. 기본값 : &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7483a3c1ab04560df78ce5fcc47dc422c5b6fb38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If autograd should record operations on the returned tensor. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;requires_grad&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; autograd가 반환 된 텐서에 작업을 기록해야하는 경우. 기본값 : &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4f8da86e61fff9872b332d5a83e86f2da79513dc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if the parameter requires gradient. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/autograd.html#excluding-subgraphs&quot;&gt;Excluding subgraphs from backward&lt;/a&gt; for more details. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;requires_grad&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 매개 변수에 그라디언트가 필요한 경우. 자세한 내용 &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/autograd.html#excluding-subgraphs&quot;&gt;은 뒤로 부분 그래프 제외&lt;/a&gt; 를 참조하세요. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="50f6783d1e07f9c1440a696e4976ac787e5b69d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;result&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#object&quot;&gt;object&lt;/a&gt;) &amp;ndash; the result object of this &lt;code&gt;Future&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;result&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#object&quot;&gt;object&lt;/a&gt; ) &amp;ndash;이 &lt;code&gt;Future&lt;/code&gt; 의 결과 객체 .</target>
        </trans-unit>
        <trans-unit id="90a602776d12962951cc0385731c01ed3bcab28d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;retain_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, the graph used to compute the grads will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Defaults to the value of &lt;code&gt;create_graph&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;preserve_graph&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;False&lt;/code&gt; 이면 그레이드를 계산하는 데 사용 된 그래프가 해제됩니다. 거의 모든 경우에이 옵션을 True로 설정하는 것은 필요하지 않으며 훨씬 더 효율적인 방법으로 해결할 수 있습니다. 기본값은 &lt;code&gt;create_graph&lt;/code&gt; 값입니다 .</target>
        </trans-unit>
        <trans-unit id="2cfcdef9f1e81b511c2a831483836e1d2395c58f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;retain_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If False, the graph used to compute the grad will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Usually, you need to set this to True to run backward multiple times.</source>
          <target state="translated">&lt;strong&gt;preserve_graph&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; False이면 grad 계산에 사용 된 그래프가 해제됩니다. 거의 모든 경우에이 옵션을 True로 설정하는 것은 필요하지 않으며 훨씬 더 효율적인 방법으로 해결할 수 있습니다. 일반적으로 여러 번 뒤로 실행하려면이 값을 True로 설정해야합니다.</target>
        </trans-unit>
        <trans-unit id="a53068eb20e1703e6fae54e116c28d41c909b9cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_complex&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to return a complex tensor, or a real tensor with an extra last dimension for the real and imaginary components.</source>
          <target state="translated">&lt;strong&gt;return_complex&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 복소수 텐서를 반환할지 아니면 실수 및 허수 구성 요소에 대한 추가 마지막 차원이있는 실수 텐서를 반환할지 여부입니다.</target>
        </trans-unit>
        <trans-unit id="6e3ba44aedb23f32452a877f1431281949acdfbc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_complex&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Whether the output should be complex, or if the input should be assumed to derive from a real signal and window. Note that this is incompatible with &lt;code&gt;onesided=True&lt;/code&gt;. (Default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;return_complex&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Whether the output should be complex, or if the input should be assumed to derive from a real signal and window. Note that this is incompatible with &lt;code&gt;onesided=True&lt;/code&gt; . (Default: &lt;code&gt;False&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="451a8ec8a7c215fb8c9eb2bcdfe93c4066ee62d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_counts&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to also return the counts for each unique element.</source>
          <target state="translated">&lt;strong&gt;return_counts&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to also return the counts for each unique element.</target>
        </trans-unit>
        <trans-unit id="be0b737a57d022be99ca3806d10ba96bda8a2e6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, will return the argmax along with the max values. Useful for &lt;a href=&quot;torch.nn.maxunpool1d#torch.nn.MaxUnpool1d&quot;&gt;&lt;code&gt;torch.nn.MaxUnpool1d&lt;/code&gt;&lt;/a&gt; later</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt; , will return the argmax along with the max values. Useful for &lt;a href=&quot;torch.nn.maxunpool1d#torch.nn.MaxUnpool1d&quot;&gt; &lt;code&gt;torch.nn.MaxUnpool1d&lt;/code&gt; &lt;/a&gt; later</target>
        </trans-unit>
        <trans-unit id="dfccddd5be08bd3e21421b7d578619f610a4ebf2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to &lt;code&gt;nn.MaxUnpool2d()&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; , will return the indices along with the outputs. Useful to pass to &lt;code&gt;nn.MaxUnpool2d()&lt;/code&gt; . Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="24f9f4b06fa0e2c9a270a8c0bf40171f36526e9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to nn.MaxUnpool1d. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; , will return the indices along with the outputs. Useful to pass to nn.MaxUnpool1d. Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3acdc3b1a33b53e4798f96fee93430c34612b83e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to nn.MaxUnpool2d. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; , will return the indices along with the outputs. Useful to pass to nn.MaxUnpool2d. Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="dc9007ec5c0f693cbc0478e2780a9eeb50ea22b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to nn.MaxUnpool3d. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; , will return the indices along with the outputs. Useful to pass to nn.MaxUnpool3d. Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e2e8bb04f084571c1e2d5a7885f2d614f58c1003" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the max indices along with the outputs. Useful for &lt;a href=&quot;torch.nn.maxunpool2d#torch.nn.MaxUnpool2d&quot;&gt;&lt;code&gt;torch.nn.MaxUnpool2d&lt;/code&gt;&lt;/a&gt; later</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; , will return the max indices along with the outputs. Useful for &lt;a href=&quot;torch.nn.maxunpool2d#torch.nn.MaxUnpool2d&quot;&gt; &lt;code&gt;torch.nn.MaxUnpool2d&lt;/code&gt; &lt;/a&gt; later</target>
        </trans-unit>
        <trans-unit id="cb3879f13bacb4ac2075aca61af136eb87bb632e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the max indices along with the outputs. Useful for &lt;a href=&quot;torch.nn.maxunpool3d#torch.nn.MaxUnpool3d&quot;&gt;&lt;code&gt;torch.nn.MaxUnpool3d&lt;/code&gt;&lt;/a&gt; later</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt; , will return the max indices along with the outputs. Useful for &lt;a href=&quot;torch.nn.maxunpool3d#torch.nn.MaxUnpool3d&quot;&gt; &lt;code&gt;torch.nn.MaxUnpool3d&lt;/code&gt; &lt;/a&gt; later</target>
        </trans-unit>
        <trans-unit id="c2d9bba5ad78165f7e64c1456856426896f737bb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; whether to return pooling indices. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; whether to return pooling indices. Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0ccd823978e457f89c779b1144535100d72c2c1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_inverse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to also return the indices for where elements in the original input ended up in the returned unique list.</source>
          <target state="translated">&lt;strong&gt;return_inverse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to also return the indices for where elements in the original input ended up in the returned unique list.</target>
        </trans-unit>
        <trans-unit id="dac774a90d09e020fc94b8cf488f1c4dac29e906" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;right&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if False, return the first suitable location that is found. If True, return the last such index. If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of &lt;code&gt;boundaries&lt;/code&gt; (one pass the last index). In other words, if False, gets the lower bound index for each value in &lt;code&gt;input&lt;/code&gt; from &lt;code&gt;boundaries&lt;/code&gt;. If True, gets the upper bound index instead. Default value is False.</source>
          <target state="translated">&lt;strong&gt;right&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if False, return the first suitable location that is found. If True, return the last such index. If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of &lt;code&gt;boundaries&lt;/code&gt; (one pass the last index). In other words, if False, gets the lower bound index for each value in &lt;code&gt;input&lt;/code&gt; from &lt;code&gt;boundaries&lt;/code&gt; . If True, gets the upper bound index instead. Default value is False.</target>
        </trans-unit>
        <trans-unit id="5f99ca7c7e81085a92ca3b1ee3f61f4f25afa5c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;right&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if False, return the first suitable location that is found. If True, return the last such index. If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of &lt;em&gt;innermost&lt;/em&gt; dimension within &lt;code&gt;sorted_sequence&lt;/code&gt; (one pass the last index of the &lt;em&gt;innermost&lt;/em&gt; dimension). In other words, if False, gets the lower bound index for each value in &lt;code&gt;values&lt;/code&gt; on the corresponding &lt;em&gt;innermost&lt;/em&gt; dimension of the &lt;code&gt;sorted_sequence&lt;/code&gt;. If True, gets the upper bound index instead. Default value is False.</source>
          <target state="translated">&lt;strong&gt;right&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if False, return the first suitable location that is found. If True, return the last such index. If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of &lt;em&gt;innermost&lt;/em&gt; dimension within &lt;code&gt;sorted_sequence&lt;/code&gt; (one pass the last index of the &lt;em&gt;innermost&lt;/em&gt; dimension). In other words, if False, gets the lower bound index for each value in &lt;code&gt;values&lt;/code&gt; on the corresponding &lt;em&gt;innermost&lt;/em&gt; dimension of the &lt;code&gt;sorted_sequence&lt;/code&gt; . If True, gets the upper bound index instead. Default value is False.</target>
        </trans-unit>
        <trans-unit id="8af0242748d4ccc71f6d117d72964f9f1a6dfc76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;roots&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Tensors which represent the roots of the autograd computation. All the tensors should be scalars.</source>
          <target state="translated">&lt;strong&gt;roots&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Tensors which represent the roots of the autograd computation. All the tensors should be scalars.</target>
        </trans-unit>
        <trans-unit id="6e703cfc7b66dc3da520fdcf8d4940424403970a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;row&lt;/strong&gt; (&lt;code&gt;int&lt;/code&gt;) &amp;ndash; number of rows in the 2-D matrix.</source>
          <target state="translated">&lt;strong&gt;row&lt;/strong&gt; ( &lt;code&gt;int&lt;/code&gt; ) &amp;ndash; number of rows in the 2-D matrix.</target>
        </trans-unit>
        <trans-unit id="df8808dbd32331cc487f9561ab89f6497d98b06d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rpc_backend_options&lt;/strong&gt; (&lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;RpcBackendOptions&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The options passed to the RpcAgent constructor. It must be an agent-specific subclass of &lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;&lt;code&gt;RpcBackendOptions&lt;/code&gt;&lt;/a&gt; and contains agent-specific initialization configurations. By default, for all agents, it sets the default timeout to 60 seconds and performs the rendezvous with an underlying process group initialized using &lt;code&gt;init_method = &quot;env://&quot;&lt;/code&gt;, meaning that environment variables &lt;code&gt;MASTER_ADDR&lt;/code&gt; and &lt;code&gt;MASTER_PORT&lt;/code&gt; need to be set properly. See &lt;a href=&quot;#rpc-backends&quot;&gt;Backends&lt;/a&gt; for more information and find which options are available.</source>
          <target state="translated">&lt;strong&gt;rpc_backend_options&lt;/strong&gt; (&lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;RpcBackendOptions&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The options passed to the RpcAgent constructor. It must be an agent-specific subclass of &lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt; &lt;code&gt;RpcBackendOptions&lt;/code&gt; &lt;/a&gt; and contains agent-specific initialization configurations. By default, for all agents, it sets the default timeout to 60 seconds and performs the rendezvous with an underlying process group initialized using &lt;code&gt;init_method = &quot;env://&quot;&lt;/code&gt; , meaning that environment variables &lt;code&gt;MASTER_ADDR&lt;/code&gt; and &lt;code&gt;MASTER_PORT&lt;/code&gt; need to be set properly. See &lt;a href=&quot;#rpc-backends&quot;&gt;Backends&lt;/a&gt; for more information and find which options are available.</target>
        </trans-unit>
        <trans-unit id="fa0b9defbfa21ac977266023b0b5c46f0b2f3e8a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rpc_timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The default timeout, in seconds, for RPC requests (default: 60 seconds). If the RPC has not completed in this timeframe, an exception indicating so will be raised. Callers can override this timeout for individual RPCs in &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt;&lt;code&gt;rpc_sync()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; if necessary.</source>
          <target state="translated">&lt;strong&gt;rpc_timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The default timeout, in seconds, for RPC requests (default: 60 seconds). If the RPC has not completed in this timeframe, an exception indicating so will be raised. Callers can override this timeout for individual RPCs in &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt; &lt;code&gt;rpc_sync()&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt; if necessary.</target>
        </trans-unit>
        <trans-unit id="bacc9f0e60fd24a901f52d44a4638e9e04c80978" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rtol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; relative tolerance. Default: 1e-05</source>
          <target state="translated">&lt;strong&gt;rtol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; relative tolerance. Default: 1e-05</target>
        </trans-unit>
        <trans-unit id="4b07538c76cf919ebc72b7a60c06e46f59f69d90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;run_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; Name of the run, to be included as part of the logdir. If unspecified, will use current timestamp.</source>
          <target state="translated">&lt;strong&gt;run_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; Name of the run, to be included as part of the logdir. If unspecified, will use current timestamp.</target>
        </trans-unit>
        <trans-unit id="d393489b76cacef3a8a7486c7be0cd8c3544afb0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="383f45f0226b4e5e81f81f93c4ac71001b0283d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the IFFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the IFFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3025f4149f55dd0264a95f1c44c06d665d4e4023" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the real FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the real FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7febbe2af643e6ca772e051b519b3c65a06281d0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the real FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Defaults to even output in the last dimension: &lt;code&gt;s[-1] = 2*(input.size(dim[-1]) - 1)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the real FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Defaults to even output in the last dimension: &lt;code&gt;s[-1] = 2*(input.size(dim[-1]) - 1)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e00929ae140d39c48352cf6fa3194ee39c66f5ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sample_rate&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; sample rate in Hz</source>
          <target state="translated">&lt;strong&gt;sample_rate&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; sample rate in Hz</target>
        </trans-unit>
        <trans-unit id="0f88769c8058a6eff5bd8fee7b065e6e5f50592a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scalar_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Value to save</source>
          <target state="translated">&lt;strong&gt;scalar_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Value to save</target>
        </trans-unit>
        <trans-unit id="70829693ef66298f30df8e08fe38a1e8755c2ac6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; quantization scale for the output. Default: 1.0</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; quantization scale for the output. Default: 1.0</target>
        </trans-unit>
        <trans-unit id="8194d48378537f087c73ec0589aa42997e1c5c42" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; quantization scale of the output tensor</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; quantization scale of the output tensor</target>
        </trans-unit>
        <trans-unit id="0a965b18684d8dfdbd37cc4f8057ea12da1baa61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; scale of the output Quantized Tensor</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; scale of the output Quantized Tensor</target>
        </trans-unit>
        <trans-unit id="d171e9b1743bffba5ac11a6cc0337364c0f09257" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; scale to apply in quantization formula</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; scale to apply in quantization formula</target>
        </trans-unit>
        <trans-unit id="7bf27f94abfecc48294933aebaa97dc03946f28b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;em&gt;double&lt;/em&gt;) &amp;ndash; output scale. If None, derived from the input scale</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; (&lt;em&gt;double&lt;/em&gt;) &amp;ndash; output scale. If None, derived from the input scale</target>
        </trans-unit>
        <trans-unit id="2b336660f6fee25a7f04192c1f5d9cf1fa688414" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; - quantization scale of the output, type: double.</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; - quantization scale of the output, type: double.</target>
        </trans-unit>
        <trans-unit id="a683de9da2c79075bf71043aa5f98cf77b5329fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for spatial size.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for spatial size.</target>
        </trans-unit>
        <trans-unit id="87bbe589969398126c66e3c05dc45cc47c8a68bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to match input size if it is a tuple.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to match input size if it is a tuple.</target>
        </trans-unit>
        <trans-unit id="0990d26d84ad85e506c48292c1fe24a540c4e742" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to be an integer.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to be an integer.</target>
        </trans-unit>
        <trans-unit id="c6a7cf25445a5d29d088501a3080baadf196fbe1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to match input size if it is a tuple.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to match input size if it is a tuple.</target>
        </trans-unit>
        <trans-unit id="9aec3e62b7b949348936978b7c1cb99d932c0d1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; multiplier for spatial size. Has to be an integer.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; multiplier for spatial size. Has to be an integer.</target>
        </trans-unit>
        <trans-unit id="74af9ed5d3017b743baa3848deaf6665c7f9adf4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size</target>
        </trans-unit>
        <trans-unit id="dc440c6b67388bb8565432e11af1c8daf58557ee" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1a079c4c0b1c3e38cde6fc8a641cfa06c56a1010" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="85cf53fa92b9f2533942327656544089d09a9765" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default &lt;code&gt;False&lt;/code&gt;. Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default &lt;code&gt;False&lt;/code&gt; . Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1979e70804c1eb78b8633c391b664926b49b8921" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scales&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; float 1D tensor of scales to use, size should match &lt;code&gt;input.size(axis)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;scales&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; float 1D tensor of scales to use, size should match &lt;code&gt;input.size(axis)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="97926b134c895c01bbe8f6c26f328a2eb031fb49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scatter_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to scatter (default is None, must be specified on the source rank)</source>
          <target state="translated">&lt;strong&gt;scatter_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to scatter (default is None, must be specified on the source rank)</target>
        </trans-unit>
        <trans-unit id="95f54acc947d1c59dde2c9179fd3865f972d8dfa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sci_mode&lt;/strong&gt; &amp;ndash; Enable (True) or disable (False) scientific notation. If None (default) is specified, the value is defined by &lt;code&gt;torch._tensor_str._Formatter&lt;/code&gt;. This value is automatically chosen by the framework.</source>
          <target state="translated">&lt;strong&gt;sci_mode&lt;/strong&gt; &amp;ndash; Enable (True) or disable (False) scientific notation. If None (default) is specified, the value is defined by &lt;code&gt;torch._tensor_str._Formatter&lt;/code&gt; . This value is automatically chosen by the framework.</target>
        </trans-unit>
        <trans-unit id="31b95efb697eb9d32d8d0513d989798a369d679f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scramble&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Setting this to &lt;code&gt;True&lt;/code&gt; will produce scrambled Sobol sequences. Scrambling is capable of producing better Sobol sequences. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;scramble&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Setting this to &lt;code&gt;True&lt;/code&gt; will produce scrambled Sobol sequences. Scrambling is capable of producing better Sobol sequences. Default: &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0ace9de306213673d4dcea0e235e9069d516de2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;script_module&lt;/strong&gt; &amp;ndash; An instance of torch script module with type of ScriptModule.</source>
          <target state="translated">&lt;strong&gt;script_module&lt;/strong&gt; &amp;ndash; An instance of torch script module with type of ScriptModule.</target>
        </trans-unit>
        <trans-unit id="9556506326cc7e5aba9d2bab7c9e945c1aa33011" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;seed&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The desired seed. Value must be within the inclusive range &lt;code&gt;[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]&lt;/code&gt;. Otherwise, a RuntimeError is raised. Negative inputs are remapped to positive values with the formula &lt;code&gt;0xffff_ffff_ffff_ffff + seed&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;seed&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The desired seed. Value must be within the inclusive range &lt;code&gt;[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]&lt;/code&gt; . Otherwise, a RuntimeError is raised. Negative inputs are remapped to positive values with the formula &lt;code&gt;0xffff_ffff_ffff_ffff + seed&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="42e3c476b10a593814d704cb92704cdb7628a925" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;seed&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; This is the seed for the scrambling. The seed of the random number generator is set to this, if specified. Otherwise, it uses a random seed. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;seed&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; This is the seed for the scrambling. The seed of the random number generator is set to this, if specified. Otherwise, it uses a random seed. Default: &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="34b993f82c0bff4c8876e51f86a4d0cd94041cd4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;segments&lt;/strong&gt; &amp;ndash; Number of chunks to create in the model</source>
          <target state="translated">&lt;strong&gt;segments&lt;/strong&gt; &amp;ndash; Number of chunks to create in the model</target>
        </trans-unit>
        <trans-unit id="b234df8ca1796df94acd4f2582e16d322c4d7b53" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;self&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the scalar base value for the power operation</source>
          <target state="translated">&lt;strong&gt;self&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the scalar base value for the power operation</target>
        </trans-unit>
        <trans-unit id="3db3b9e470815a2d029e3df80be582d9373bb440" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sequence&lt;/strong&gt; (&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;PackedSequence&lt;/a&gt;) &amp;ndash; batch to pad</source>
          <target state="translated">&lt;strong&gt;sequence&lt;/strong&gt; (&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;PackedSequence&lt;/a&gt;) &amp;ndash; batch to pad</target>
        </trans-unit>
        <trans-unit id="b266c49abe7b1dae13bdcaca6267d611f6a53c0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sequences&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; A list of sequences of decreasing length.</source>
          <target state="translated">&lt;strong&gt;sequences&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; A list of sequences of decreasing length.</target>
        </trans-unit>
        <trans-unit id="d2e643683d77e2e4974f3cca173d349dcef11874" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sequences&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; list of variable length sequences.</source>
          <target state="translated">&lt;strong&gt;sequences&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; list of variable length sequences.</target>
        </trans-unit>
        <trans-unit id="516d3113df1d3fc366757f1c749d6916067ab846" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;set_to_none&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; instead of setting to zero, set the grads to None. See &lt;a href=&quot;../optim#torch.optim.Optimizer.zero_grad&quot;&gt;&lt;code&gt;torch.optim.Optimizer.zero_grad()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">&lt;strong&gt;set_to_none&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; instead of setting to zero, set the grads to None. See &lt;a href=&quot;../optim#torch.optim.Optimizer.zero_grad&quot;&gt; &lt;code&gt;torch.optim.Optimizer.zero_grad()&lt;/code&gt; &lt;/a&gt; for details.</target>
        </trans-unit>
        <trans-unit id="1192414a9f920287eff5dbc4ec8c50b8a59e87d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired size</source>
          <target state="translated">&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired size</target>
        </trans-unit>
        <trans-unit id="dcd529c43883015420ed4381022949480a774183" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the new shape</source>
          <target state="translated">&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the new shape</target>
        </trans-unit>
        <trans-unit id="afa1bc3f88d2613db86fb8ef6b22d240a6775e5f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired shape</source>
          <target state="translated">&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired shape</target>
        </trans-unit>
        <trans-unit id="182b2a09bf2ce9bed6ebdfb84b2291a8e31953a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shared&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to share memory</source>
          <target state="translated">&lt;strong&gt;shared&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to share memory</target>
        </trans-unit>
        <trans-unit id="6bb7f0e432956024dc35ef632a85dc75136860f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shifts&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; The number of places by which the elements of the tensor are shifted. If shifts is a tuple, dims must be a tuple of the same size, and each dimension will be rolled by the corresponding value</source>
          <target state="translated">&lt;strong&gt;shifts&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; The number of places by which the elements of the tensor are shifted. If shifts is a tuple, dims must be a tuple of the same size, and each dimension will be rolled by the corresponding value</target>
        </trans-unit>
        <trans-unit id="03ea4cf5be76330e494785ae14e7e331672f9049" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;signal_ndim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of dimensions in each signal. &lt;code&gt;signal_ndim&lt;/code&gt; can only be 1, 2 or 3</source>
          <target state="translated">&lt;strong&gt;signal_ndim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of dimensions in each signal. &lt;code&gt;signal_ndim&lt;/code&gt; can only be 1, 2 or 3</target>
        </trans-unit>
        <trans-unit id="3943ffb53f48c82b94eeb325494fc3c504f9b9b5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;signal_sizes&lt;/strong&gt; (list or &lt;code&gt;torch.Size&lt;/code&gt;, optional) &amp;ndash; the size of the original signal (without batch dimension). Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;signal_sizes&lt;/strong&gt; (list or &lt;code&gt;torch.Size&lt;/code&gt; , optional) &amp;ndash; the size of the original signal (without batch dimension). Default: &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="50e5115f0007f7707ab429cdfe68e39549183aab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; &amp;ndash; amount of neighbouring channels used for normalization</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; &amp;ndash; amount of neighbouring channels used for normalization</target>
        </trans-unit>
        <trans-unit id="8fa4eb29dfbddf8f29442f7879d71c63e1cbeecf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of elements in the storage</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of elements in the storage</target>
        </trans-unit>
        <trans-unit id="275c9f306dba8511bb3cfa93aa9598de38ef32ca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the size of each slice that is unfolded</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the size of each slice that is unfolded</target>
        </trans-unit>
        <trans-unit id="0b59659707a6fdfb9c664448cffe7da20582f359" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatia size.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatia size.</target>
        </trans-unit>
        <trans-unit id="cdf514b8ff20b8c4739f70c9f9e484a81b944c49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</target>
        </trans-unit>
        <trans-unit id="149915349ce02ffdf5ceea93fe5bb247fae568e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</target>
        </trans-unit>
        <trans-unit id="16964d2ffbdb9acd4dd1156889d58d0dbd349b50" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output spatial sizes</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output spatial sizes</target>
        </trans-unit>
        <trans-unit id="ec88c2bc82655addd9428024abd5b8f71a7f9cae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</target>
        </trans-unit>
        <trans-unit id="efc98ce302823923f910c2ca140408828b2cf385" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output spatial sizes</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output spatial sizes</target>
        </trans-unit>
        <trans-unit id="0f7b874897c486cf1ce74a993c5f615d99fa025b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; a tuple defining the shape of the output tensor.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; a tuple defining the shape of the output tensor.</target>
        </trans-unit>
        <trans-unit id="03a0a29e015390c8b6d2b6595aefea70b182be7a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;ints&lt;/em&gt;) &amp;ndash; the shape of the output tensor</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;ints&lt;/em&gt;) &amp;ndash; the shape of the output tensor</target>
        </trans-unit>
        <trans-unit id="26a6ff6e605560d0327d5d701a4a8866e0a1e65d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a list, tuple, or &lt;code&gt;torch.Size&lt;/code&gt; of integers defining the shape of the output tensor.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a list, tuple, or &lt;code&gt;torch.Size&lt;/code&gt; of integers defining the shape of the output tensor.</target>
        </trans-unit>
        <trans-unit id="1a4f563f5d02f780ce83e0cc48b42515c2124c45" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a sequence of integers defining the shape of the output tensor.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a sequence of integers defining the shape of the output tensor.</target>
        </trans-unit>
        <trans-unit id="6f9a10015b06b51485833aee1a18eb0d6ca9ec1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple.</target>
        </trans-unit>
        <trans-unit id="94baf289fa3f083898ae05024e21746311170982" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;) &amp;ndash; the target output image size. (</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;) &amp;ndash; the target output image size. (</target>
        </trans-unit>
        <trans-unit id="f072e677d05eac98b80bb810fa352b0b054f140e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the desired size. Defaults to the size of the source.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the desired size. Defaults to the size of the source.</target>
        </trans-unit>
        <trans-unit id="3fc5235f279542b6d70b7bd49613ee59572fce51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the shape of the output tensor</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the shape of the output tensor</target>
        </trans-unit>
        <trans-unit id="bd9344ee97a013a9847fea7b4e8e18307f4e8e61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (list, tuple, or &lt;code&gt;torch.Size&lt;/code&gt;, optional) &amp;ndash; Size of the sparse tensor. If not provided the size will be inferred as the minimum size big enough to hold all non-zero elements.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt; (list, tuple, or &lt;code&gt;torch.Size&lt;/code&gt; , optional) &amp;ndash; Size of the sparse tensor. If not provided the size will be inferred as the minimum size big enough to hold all non-zero elements.</target>
        </trans-unit>
        <trans-unit id="7c9af3450b1512ce0b9ac6b4af383477e20316fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size_average&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt;). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field &lt;code&gt;size_average&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;, the losses are instead summed for each minibatch. Ignored when reduce is &lt;code&gt;False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;size_average&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt; ). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field &lt;code&gt;size_average&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt; , the losses are instead summed for each minibatch. Ignored when reduce is &lt;code&gt;False&lt;/code&gt; . Default: &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a285cc358e12c5f4409aa06b08afb278f4b8c558" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size_average&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt;). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field &lt;code&gt;size_average&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;, the losses are instead summed for each minibatch. Ignored when reduce is &lt;code&gt;False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;size_average&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt; ). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field &lt;code&gt;size_average&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt; , the losses are instead summed for each minibatch. Ignored when reduce is &lt;code&gt;False&lt;/code&gt; . Default: &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5308eb7679205686160791ca8161c5d58dbfe2c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; New shape of the unflattened dimension</source>
          <target state="translated">&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; New shape of the unflattened dimension</target>
        </trans-unit>
        <trans-unit id="e1ebc0e50c25e5537cd83715368f39f3ae4ecbfc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; The number of times to repeat this tensor along each dimension</source>
          <target state="translated">&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; The number of times to repeat this tensor along each dimension</target>
        </trans-unit>
        <trans-unit id="0a54d8fbd33de9da7dc0fc42b5e2c08cb4d412fd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired size</source>
          <target state="translated">&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired size</target>
        </trans-unit>
        <trans-unit id="3ed38299ca2e29a9d9250d3fd4689c245a1c9056" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;snd_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Sound data</source>
          <target state="translated">&lt;strong&gt;snd_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Sound data</target>
        </trans-unit>
        <trans-unit id="04df36410cc80bf7688b9b2775248dad717b281c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;solution&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the least squares solution</source>
          <target state="translated">&lt;strong&gt;solution&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the least squares solution</target>
        </trans-unit>
        <trans-unit id="a7ea50e0998478f8190ddf227de9fc8ccad28e5a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;some&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Set to &lt;code&gt;True&lt;/code&gt; for reduced QR decomposition and &lt;code&gt;False&lt;/code&gt; for complete QR decomposition.</source>
          <target state="translated">&lt;strong&gt;some&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Set to &lt;code&gt;True&lt;/code&gt; for reduced QR decomposition and &lt;code&gt;False&lt;/code&gt; for complete QR decomposition.</target>
        </trans-unit>
        <trans-unit id="07a0dcb8d5e99634c38c0e2c2522103284a69856" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;some&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls the shape of returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;some&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls the shape of returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c964615183041f78000d335f6006659de8eaa42a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to sort the unique elements in ascending order before returning as output.</source>
          <target state="translated">&lt;strong&gt;sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to sort the unique elements in ascending order before returning as output.</target>
        </trans-unit>
        <trans-unit id="d9cd0c6e3bf7a9c26be9ab6eb578de1df1d27078" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return the elements in sorted order</source>
          <target state="translated">&lt;strong&gt;sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return the elements in sorted order</target>
        </trans-unit>
        <trans-unit id="ba3bc3fc862fb1d978c7e8f26f45ac4560b6cbb6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sorted_sequence&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; N-D or 1-D tensor, containing monotonically increasing sequence on the &lt;em&gt;innermost&lt;/em&gt; dimension.</source>
          <target state="translated">&lt;strong&gt;sorted_sequence&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; N-D or 1-D tensor, containing monotonically increasing sequence on the &lt;em&gt;innermost&lt;/em&gt; dimension.</target>
        </trans-unit>
        <trans-unit id="ff092f5a8d7513d4041f8ec05bf6db9a6433a55a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to copy from</source>
          <target state="translated">&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to copy from</target>
        </trans-unit>
        <trans-unit id="d3e050c1ccd84c4a56619568303f30198e45f1ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Storage&lt;/em&gt;) &amp;ndash; the tensor or storage to use</source>
          <target state="translated">&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Storage&lt;/em&gt;) &amp;ndash; the tensor or storage to use</target>
        </trans-unit>
        <trans-unit id="537a3683bbbd7cb37d1a1e68afc20c93f4950810" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; Original positions of the dims to move. These must be unique.</source>
          <target state="translated">&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; Original positions of the dims to move. These must be unique.</target>
        </trans-unit>
        <trans-unit id="736b5df270b468d2d70fee90f0c6304038935e20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;'github'&lt;/code&gt; | &lt;code&gt;'local'&lt;/code&gt;. Specifies how &lt;code&gt;repo_or_dir&lt;/code&gt; is to be interpreted. Default is &lt;code&gt;'github'&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;source&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;'github'&lt;/code&gt; | &lt;code&gt;'local'&lt;/code&gt; . Specifies how &lt;code&gt;repo_or_dir&lt;/code&gt; is to be interpreted. Default is &lt;code&gt;'github'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7e187210f431543be9a1749f439d018aa4b11087" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sources&lt;/strong&gt; &amp;ndash; A list of relative or absolute paths to C++ source files.</source>
          <target state="translated">&lt;strong&gt;sources&lt;/strong&gt; &amp;ndash; A list of relative or absolute paths to C++ source files.</target>
        </trans-unit>
        <trans-unit id="16b83bb63832023cd48fcbf7cf2e3c51644ad4e7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; matrix will be a sparse tensor. See Notes for more details regarding sparse gradients.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt; , gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; matrix will be a sparse tensor. See Notes for more details regarding sparse gradients.</target>
        </trans-unit>
        <trans-unit id="d82071676e26d482c374d70ee42605a5252d8f79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; will be a sparse tensor. See Notes under &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt;&lt;code&gt;torch.nn.Embedding&lt;/code&gt;&lt;/a&gt; for more details regarding sparse gradients.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt; , gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; will be a sparse tensor. See Notes under &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt; &lt;code&gt;torch.nn.Embedding&lt;/code&gt; &lt;/a&gt; for more details regarding sparse gradients.</target>
        </trans-unit>
        <trans-unit id="490e7f9dc42b376ca2804c6155a64ad37564fb2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</target>
        </trans-unit>
        <trans-unit id="ef9a73bc582ac8360689c39a1c63c78ddde0dd12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ac1945361265423208febe431a5add209b0405e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; matrix will be a sparse tensor. See Notes for more details regarding sparse gradients. Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt; , gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; matrix will be a sparse tensor. See Notes for more details regarding sparse gradients. Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="264742d3a555bb6302cc2b99bcbdbaea90e73571" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; will be a sparse tensor. See Notes under &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt;&lt;code&gt;torch.nn.Embedding&lt;/code&gt;&lt;/a&gt; for more details regarding sparse gradients. Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;True&lt;/code&gt; 이면 그래디언트 wrt &lt;code&gt;weight&lt;/code&gt; 가 희소 텐서가됩니다. 희소 그라디언트에 대한 자세한 내용은 &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt; &lt;code&gt;torch.nn.Embedding&lt;/code&gt; 의&lt;/a&gt; 참고 사항을 참조하십시오 . 참고 :이 옵션은 &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt; 인 경우 지원되지 않습니다 .</target>
        </trans-unit>
        <trans-unit id="94981b1994886031e5de3502e8d05e4753cd4159" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparseDims&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of sparse dimensions to include in the new sparse tensor</source>
          <target state="translated">&lt;strong&gt;sparseDims&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 새 희소 텐서에 포함 할 희소 차원의 수</target>
        </trans-unit>
        <trans-unit id="4b18e538096fb082b8177bc1560caf9a9d7bc9a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;input&lt;/code&gt; will be a sparse tensor.</source>
          <target state="translated">&lt;strong&gt;sparse_grad&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;True&lt;/code&gt; 이면 gradient wrt &lt;code&gt;input&lt;/code&gt; 은 희소 텐서가됩니다.</target>
        </trans-unit>
        <trans-unit id="b37daeb607924ba93a0bda59b58e026064bd654d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparsity&lt;/strong&gt; &amp;ndash; The fraction of elements in each column to be set to zero</source>
          <target state="translated">&lt;strong&gt;희소성&lt;/strong&gt; &amp;ndash; 0으로 설정할 각 열의 요소 비율</target>
        </trans-unit>
        <trans-unit id="e30145ed58f140ce4c89e2f335125ba650c4f507" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;split_size_or_sections&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;) or &lt;/em&gt;&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;)&lt;/em&gt;) &amp;ndash; size of a single chunk or list of sizes for each chunk</source>
          <target state="translated">&lt;strong&gt;split_size_or_sections&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;) 또는 &lt;/em&gt;&lt;em&gt;( &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;( &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;)&lt;/em&gt; ) &amp;ndash; 단일 청크의 크기 또는 각 청크의 크기 목록</target>
        </trans-unit>
        <trans-unit id="9b97dbfc339fde5bc389bd8ab93d7f7cb7c44dfc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; &amp;ndash; the sequence to the encoder (required).</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; &amp;ndash; 인코더에 대한 시퀀스 (필수).</target>
        </trans-unit>
        <trans-unit id="78fa5919448d76e6a64f4bd45287924a3a34df33" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; &amp;ndash; the sequence to the encoder layer (required).</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; &amp;ndash; 인코더 계층에 대한 시퀀스 (필수).</target>
        </trans-unit>
        <trans-unit id="3cbdd89942669cde945cfe86a26dcfcd5645519c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source element(s) to scatter, incase &lt;code&gt;value&lt;/code&gt; is not specified</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 분산 할 소스 요소, &lt;code&gt;value&lt;/code&gt; 이 지정되지 않은 경우</target>
        </trans-unit>
        <trans-unit id="c00ac345411ae3480e897e5cbdd023e0d52ba5ba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source elements to scatter and add</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 분산 및 추가 할 소스 요소</target>
        </trans-unit>
        <trans-unit id="cca60735cb66c0fd24e9daf6bd9a2d6affdd8b18" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source tensor to copy from</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 복사 할 소스 텐서</target>
        </trans-unit>
        <trans-unit id="2605c126b88196f5cf7d630fe3b356d67096670b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Source rank (default is 0)</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 소스 순위 (기본값은 0)</target>
        </trans-unit>
        <trans-unit id="5422756d7624b629fb6d789ff63552dac7a631ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Source rank.</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 소스 순위.</target>
        </trans-unit>
        <trans-unit id="6ecfc113b4210a133571a1ba6eee75db6462f3ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Source rank. Will receive from any process if unspecified.</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 소스 순위. 지정되지 않은 경우 모든 프로세스에서 수신합니다.</target>
        </trans-unit>
        <trans-unit id="1bf7cb7495026465a5e025f645be215970d3c3f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for src keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash; 일괄 처리 당 src 키에 대한 ByteTensor 마스크 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="20d1aac54a28167b80b444f3e283804c33610581" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the src keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash; 배치 당 src 키의 마스크 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="2e4d7f0b7f046f61667e190129080811355c102a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; the additive mask for the src sequence (optional).</source>
          <target state="translated">&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; src 시퀀스에 대한 추가 마스크 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="b8ff899002109344c4f233e16bca9c3f67cf5740" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; the mask for the src sequence (optional).</source>
          <target state="translated">&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; src 시퀀스의 마스크 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="480ed9f7356f0f1438f0c3e67548752e2e88b19d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_tensor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Source tensor rank within &lt;code&gt;tensor_list&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;src_tensor&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;tensor_list&lt;/code&gt; 내의 소스 텐서 순위</target>
        </trans-unit>
        <trans-unit id="6c54e581b4a64152f841eae4b7132eca48a8ce38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the starting value for the set of points</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 포인트 집합의 시작 값</target>
        </trans-unit>
        <trans-unit id="fd9b8604b8d10a61d30a016be638c8f89e228f17" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the starting value for the set of points. Default: &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 포인트 집합의 시작 값. 기본값 : &lt;code&gt;0&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="61cea1b64e6864ce3fd4c5cdb9ba97526597a0e9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the starting dimension</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 시작 차원</target>
        </trans-unit>
        <trans-unit id="017f9db566260fcc32ff561f6f41f549f1ab1b1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the starting value for the set of points. Default: &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt; ( &lt;em&gt;Number&lt;/em&gt; ) &amp;ndash; 포인트 집합의 시작 값입니다. 기본값 : &lt;code&gt;0&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="db305563060fce9be4b380f28e1127159859b2ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start_dim&lt;/strong&gt; &amp;ndash; first dim to flatten (default = 1).</source>
          <target state="translated">&lt;strong&gt;start_dim&lt;/strong&gt; &amp;ndash; 평면화 할 첫 번째 어둡게 (기본값 = 1).</target>
        </trans-unit>
        <trans-unit id="1aa7a3bfd2813f5dbf3d94b9c4043556308d2159" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the first dim to flatten</source>
          <target state="translated">&lt;strong&gt;start_dim&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 평면화 할 첫 번째 dim</target>
        </trans-unit>
        <trans-unit id="e706afdee5bbb0a79b5a2f832271401d69b23519" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;state_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; a dict containing parameters and persistent buffers.</source>
          <target state="translated">&lt;strong&gt;state_dict&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt; ) &amp;ndash; 매개 변수와 영구 버퍼를 포함하는 dict.</target>
        </trans-unit>
        <trans-unit id="397f739ec24999cef4aedd3f271bf305d11784f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; &amp;ndash; the standard deviation of the normal distribution</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt; &amp;ndash; 정규 분포의 표준 편차</target>
        </trans-unit>
        <trans-unit id="19af3df9428cf525a7500c9af96c43b782849a34" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; &amp;ndash; the standard deviation of the normal distribution used to generate the non-zero values</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt; &amp;ndash; 0이 아닌 값을 생성하는 데 사용되는 정규 분포의 표준 편차</target>
        </trans-unit>
        <trans-unit id="8fd58ae2ac219c0c179d6b0c321bc9877f3d5c08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor of per-element standard deviations</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 요소 별 표준 편차의 텐서</target>
        </trans-unit>
        <trans-unit id="cc539f1fbf4c4bdbab694cd3aa4e1e85f66c6288" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the standard deviation for all distributions</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 모든 분포에 대한 표준 편차</target>
        </trans-unit>
        <trans-unit id="5c558f61587c7e53fc6d918f3a17c5e6dd6e0602" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the standard deviation for all distributions</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 모든 분포에 대한 표준 편차</target>
        </trans-unit>
        <trans-unit id="baf9f5309ab39bb6c1581c5f3b05b5bdbedb7c06" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the gap between each pair of adjacent points. Default: &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;step&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 각 인접 지점 쌍 사이의 간격. 기본값 : &lt;code&gt;1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1abac8c895387b0b9cd2795f79c2431234a95f31" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the step between each slice</source>
          <target state="translated">&lt;strong&gt;step&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 각 슬라이스 사이의 단계</target>
        </trans-unit>
        <trans-unit id="55d5b2b9ad99b0efd35850f714bb971bc246e22f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the gap between each pair of adjacent points. Default: &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;단계&lt;/strong&gt; ( &lt;em&gt;Number&lt;/em&gt; ) &amp;ndash; 각 인접 지점 쌍 사이의 간격. 기본값 : &lt;code&gt;1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a166db3ce9222d4bcbe13cb6bde4fbbfc394f117" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;steps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; size of the constructed tensor</source>
          <target state="translated">&lt;strong&gt;steps&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 구성된 텐서의 크기</target>
        </trans-unit>
        <trans-unit id="2401eb00fd1cd4eb0e88575af75256fc34e93df2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;storage_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the offset in the storage</source>
          <target state="translated">&lt;strong&gt;storage_offset&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 저장소의 오프셋</target>
        </trans-unit>
        <trans-unit id="a464ae09605bcd29232df8491b551330fa7b201e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;storage_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the offset in the underlying storage of the output tensor</source>
          <target state="translated">&lt;strong&gt;storage_offset&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 출력 텐서의 기본 저장소에있는 오프셋</target>
        </trans-unit>
        <trans-unit id="36921320f19d087af835850826666bf4b078eaa7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;store&lt;/strong&gt; (&lt;a href=&quot;#torch.distributed.Store&quot;&gt;Store&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Key/value store accessible to all workers, used to exchange connection/address information. Mutually exclusive with &lt;code&gt;init_method&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;store&lt;/strong&gt; ( &lt;a href=&quot;#torch.distributed.Store&quot;&gt;Store &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 연결 / 주소 정보를 교환하는 데 사용되는 모든 작업자가 액세스 할 수있는 키 / 값 저장소입니다. &lt;code&gt;init_method&lt;/code&gt; 와 상호 배타적입니다 .</target>
        </trans-unit>
        <trans-unit id="4dc03df96ec79acaac3452a59e6207bd786c9d6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;store&lt;/strong&gt; (&lt;em&gt;torch.distributed.store&lt;/em&gt;) &amp;ndash; A store object that forms the underlying key-value store.</source>
          <target state="translated">&lt;strong&gt;store&lt;/strong&gt; ( &lt;em&gt;torch.distributed.store&lt;/em&gt; ) &amp;ndash; 기본 키-값 저장소를 형성하는 저장소 객체입니다.</target>
        </trans-unit>
        <trans-unit id="aef94a04df5ea5876b7e12de6f0824f58976f3e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 키가이 모듈의 &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt; 함수 에서 반환 된 키와 일치 하도록 엄격하게 적용할지 여부 입니다. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="33b205deb049448da3c0a8dc2d460e0783955775" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 키가이 모듈의 &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt; 함수 에서 반환 된 키와 일치 하도록 엄격하게 적용할지 여부 입니다. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ea9289c76d8286090b8a4f3dd767eca0a4c5e0c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 키가이 모듈의 &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt; 함수 에서 반환 된 키와 일치 하도록 엄격하게 적용할지 여부 입니다. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1544925b842cb8d8b87627d19af858e20b780645" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt; 의 키가이 모듈의 &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt; 함수 에서 반환 된 키와 일치 하도록 엄격하게 적용할지 여부 입니다. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="685790b38e543d30d0b76c6ee8fcd86be2ab18e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;code&gt;bool&lt;/code&gt;, optional) &amp;ndash; run the tracer in a strict mode or not (default: &lt;code&gt;True&lt;/code&gt;). Only turn this off when you want the tracer to record your mutable container types (currently &lt;code&gt;list&lt;/code&gt;/&lt;code&gt;dict&lt;/code&gt;) and you are sure that the container you are using in your problem is a &lt;code&gt;constant&lt;/code&gt; structure and does not get used as control flow (if, for) conditions.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt; ( &lt;code&gt;bool&lt;/code&gt; , optional) &amp;ndash; 엄격한 모드에서 추적 프로그램을 실행하거나 실행하지 않습니다 (기본값 : &lt;code&gt;True&lt;/code&gt; ). 추적 프로그램이 변경 가능한 컨테이너 유형 (현재 &lt;code&gt;list&lt;/code&gt; / &lt;code&gt;dict&lt;/code&gt; ) 을 기록 하도록하고 문제에서 사용중인 컨테이너가 &lt;code&gt;constant&lt;/code&gt; 구조이고 제어 흐름으로 사용되지 않는 경우에만이 기능을 끄 십시오 ( ) 조건.</target>
        </trans-unit>
        <trans-unit id="d42c648d3610293a7cf248220e9664c5134177bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; The stride of the sliding window, must be &amp;gt; 0. Default value is &lt;code&gt;kernel_size&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 슬라이딩 창의 보폭은&amp;gt; 0이어야합니다 . 기본값은 &lt;code&gt;kernel_size&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="ece50bfaa1c42101ecdb71c0cdd588d8acf212c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; a single int, the stride of the window. Default value is &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 단일 정수, 창의 보폭. 기본값은 &lt;code&gt;kernel_size&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="3d66128b0d5b6f8a04eda5e5cafb00185fe896d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; stride of the pooling operation. Can be a single number or a tuple &lt;code&gt;(sH, sW)&lt;/code&gt;. Default: &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 풀링 작업의 보폭. 단일 숫자 또는 튜플 &lt;code&gt;(sH, sW)&lt;/code&gt; 수 있습니다 . 기본값 : &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="214b0bd7f37429dbe8ebc6dded03c3882c664098" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; stride of the pooling operation. Can be a single number or a tuple &lt;code&gt;(sT, sH, sW)&lt;/code&gt;. Default: &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 풀링 작업의 보폭. 단일 숫자 또는 튜플 &lt;code&gt;(sT, sH, sW)&lt;/code&gt; 있습니다. 기본값 : &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c0738f57cba9ff50e90a91a07935ba7bfbd70a60" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a one-element tuple &lt;code&gt;(sW,)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 컨 볼빙 커널의 보폭. 단일 숫자 또는 단일 요소 튜플 &lt;code&gt;(sW,)&lt;/code&gt; 일 수 있습니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="a8bfc0051811863634e34e362ca2dc7ac04c0a76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sD, sH, sW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 컨 볼빙 커널의 보폭. 단일 숫자 또는 튜플 &lt;code&gt;(sD, sH, sW)&lt;/code&gt; 있습니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="e99fe233d3379e77fe12415abc7f2b4a4414ea6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sH, sW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 컨 볼빙 커널의 보폭. 단일 숫자 또는 튜플 &lt;code&gt;(sH, sW)&lt;/code&gt; 수 있습니다 . 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="dc03b1c42fd2881680cf96ca6f9def163d1c788c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sT, sH, sW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 컨 볼빙 커널의 보폭. 단일 숫자 또는 튜플 &lt;code&gt;(sT, sH, sW)&lt;/code&gt; 있습니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="1e07709d5ef30fc3327e2bffbfec50c789ae30d7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sW,)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 컨 볼빙 커널의 보폭. 단일 숫자 또는 튜플 &lt;code&gt;(sW,)&lt;/code&gt; 일 수 있습니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="6a3d3677bf8aef87647950a0175bf46a290a6881" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the window. Can be a single number or a tuple &lt;code&gt;(sW,)&lt;/code&gt;. Default: &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 창의 보폭. 단일 숫자 또는 튜플 &lt;code&gt;(sW,)&lt;/code&gt; 일 수 있습니다. 기본값 : &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4d1ac3de99275d24a51b19deff5f49a4c626918a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the window. Default value is &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; 창의 보폭. 기본값은 &lt;code&gt;kernel_size&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="0e83b71423e0fab8d3fec82e9b62f9e213048e07" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Stride of the max pooling window. It is set to &lt;code&gt;kernel_size&lt;/code&gt; by default.</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 최대 풀링 창의 보폭입니다. 기본적 으로 &lt;code&gt;kernel_size&lt;/code&gt; 로 설정됩니다.</target>
        </trans-unit>
        <trans-unit id="d642049bdaf0da3e7ac2a9bb747d7157b42b5143" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the stride of the sliding blocks in the input spatial dimensions. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt; ) &amp;ndash; 입력 공간 차원에서 슬라이딩 블록의 보폭. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="32f6fe46ead4028a3ff5fec9da1140af45a6f195" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Stride of the convolution. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 회선의 보폭입니다. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="c28631e28f33721680bff83305d7dc712c049afc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the stride of the sliding blocks in the input spatial dimensions. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 입력 공간 차원에서 슬라이딩 블록의 보폭. 기본값 : 1</target>
        </trans-unit>
        <trans-unit id="5286e3c0bfd8223f9b20165f169fcac7223712b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;ints&lt;/em&gt;) &amp;ndash; the stride of the output tensor</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;ints&lt;/em&gt; ) &amp;ndash; 출력 텐서의 stride</target>
        </trans-unit>
        <trans-unit id="6af3c97a48669b717945a12fdf9a7cc81362788e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the desired stride. Defaults to C-contiguous strides.</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 원하는 stride. 기본값은 C- 연속 보폭입니다.</target>
        </trans-unit>
        <trans-unit id="9ed1797b9bf63c6b5db820aab38cf98e6f4f5b0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the strides of the output tensor</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; ( &lt;em&gt;tuple of python : ints&lt;/em&gt; ) &amp;ndash; 출력 텐서의 스트라이드</target>
        </trans-unit>
        <trans-unit id="b449245dfa29c41483eaf98f7744e5e9162391f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strip_doc_string&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default True&lt;/em&gt;) &amp;ndash; if True, strips the field &amp;ldquo;doc_string&amp;rdquo; from the exported model, which information about the stack trace.</source>
          <target state="translated">&lt;strong&gt;strip_doc_string&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;기본값 True&lt;/em&gt; ) &amp;ndash; True 인 경우 내 보낸 모델에서 &quot;doc_string&quot;필드를 제거하여 스택 추적에 대한 정보를 제공합니다.</target>
        </trans-unit>
        <trans-unit id="19ac5a27007bad74f30226abe0c536a26c0a089d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;swap&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The distance swap is described in detail in the paper &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; by V. Balntas, E. Riba et al. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;swap&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 거리 스왑은 V. Balntas, E. Riba et al.의 &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; 논문에 자세히 설명되어 있습니다. 기본값 : &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b154c5f2ebad9bb907ebc07611f820bf1efab1c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;swap&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether to use the distance swap described in the paper &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; by V. Balntas, E. Riba et al. If True, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;스왑&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;BOOL &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택적&lt;/em&gt; ) - 여부는 용지에 기재 한 거리 스왑 사용 &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; V. Balntas, E. RIBA 등에 의한한다. True이고 양의 예가 앵커보다 음의 예에 더 가까운 경우 손실 계산에서 양의 예와 앵커를 바꿉니다. 기본값 : &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="65dc3057d66834aa80e6916cc4680ab2424ee9dc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;symmetric&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; indicates whether &lt;code&gt;input&lt;/code&gt; is symmetric. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;symmetric&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;input&lt;/code&gt; 이 대칭 인지 여부를 나타냅니다 . 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0da7b9236fa7ec34aca8677755a15ff355bf2e5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; tensor representing the parameter to prune</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt; ) &amp;ndash; 잘라낼 매개 변수를 나타내는 텐서</target>
        </trans-unit>
        <trans-unit id="11deee4e01f144b32149bba99489b147b2b2f8c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; tensor representing the parameter to prune (of same dimensions as &lt;code&gt;default_mask&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt; ) &amp;ndash; 잘라낼 매개 변수를 나타내는 텐서 ( &lt;code&gt;default_mask&lt;/code&gt; 와 동일한 차원 ).</target>
        </trans-unit>
        <trans-unit id="4a7620705c26f4724dfdfc18ad935e7dca1d4ba2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; tensor to prune (of same dimensions as &lt;code&gt;default_mask&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt; ) &amp;ndash; 정리할 텐서 ( &lt;code&gt;default_mask&lt;/code&gt; 와 동일한 차원 ).</target>
        </trans-unit>
        <trans-unit id="bad38a299dffdc28afcdbc450487e34252d433d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string&lt;/em&gt;) &amp;ndash; the floating point tensor type or its name</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;유형 &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;문자열&lt;/em&gt; ) &amp;ndash; 부동 소수점 텐서 유형 또는 이름</target>
        </trans-unit>
        <trans-unit id="148b2bfd250a2dd94c21a77dac7daca25f087bca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tag to match recv with remote send</source>
          <target state="translated">&lt;strong&gt;tag&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; recv를 원격 전송과 일치시키는 태그</target>
        </trans-unit>
        <trans-unit id="f3d72f85bf8966156f98c3d0b833f53240d28797" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tag to match send with remote recv</source>
          <target state="translated">&lt;strong&gt;tag&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 송신을 원격 수신과 일치시킬 태그</target>
        </trans-unit>
        <trans-unit id="24131f44dbc1a3c7ca0a89f0809f0ba1b31deb1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Data identifier</source>
          <target state="translated">&lt;strong&gt;tag&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 데이터 식별자</target>
        </trans-unit>
        <trans-unit id="1e47865c46d7c3937ed182d2bce842b69d717584" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Name for the embedding</source>
          <target state="translated">&lt;strong&gt;tag&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 임베딩 이름</target>
        </trans-unit>
        <trans-unit id="6d1b78b5bcbeb528ec42020fb51c475acd78d770" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag_scalar_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Key-value pair storing the tag and corresponding values</source>
          <target state="translated">&lt;strong&gt;tag_scalar_dict&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt; ) &amp;ndash; 태그 및 해당 값을 저장하는 키-값 쌍</target>
        </trans-unit>
        <trans-unit id="8f30aad2305773e67a4ac76efb57c166bcbc5811" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;타겟&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="719f030afe3ca4c13961bb8f325f84d710260d20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; &amp;ndash; Tensor of the same shape as input</source>
          <target state="translated">&lt;strong&gt;target&lt;/strong&gt; &amp;ndash; 입력과 같은 모양의 텐서</target>
        </trans-unit>
        <trans-unit id="9206762f88088e88aeb5e77137d3fbb745052050" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; &amp;ndash; random sample</source>
          <target state="translated">&lt;strong&gt;target&lt;/strong&gt; &amp;ndash; 무작위 샘플</target>
        </trans-unit>
        <trans-unit id="e65a2d46ca874e2e756d7350a646d869ef4c730d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;타겟&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;텐서&lt;/a&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="72a23b074b2288d4e0ffc008a1ed4dc002ba4f88" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target_lengths&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;target_lengths&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="c98a50b7621481810ef1add02c8fb6b879a9c206" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;targets&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;타겟&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="1e8d2e93abbf10103deb46414323861cf338c14e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tau&lt;/strong&gt; &amp;ndash; non-negative scalar temperature</source>
          <target state="translated">&lt;strong&gt;tau&lt;/strong&gt; &amp;ndash; 음이 아닌 스칼라 온도</target>
        </trans-unit>
        <trans-unit id="582dba7550e8ec990794ee9bb0c943f9584d6a9a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the numerator tensor</source>
          <target state="translated">&lt;strong&gt;tensor1&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 분자 텐서</target>
        </trans-unit>
        <trans-unit id="fe51c36bff59a01f2f78ad03d8e073164d1af5b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be multiplied</source>
          <target state="translated">&lt;strong&gt;tensor1&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 곱할 텐서</target>
        </trans-unit>
        <trans-unit id="d7c8f48497c84ad5e4208e1eddc9d137b9867057" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; an input tensor or number</source>
          <target state="translated">&lt;strong&gt;tensor1&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt; ) &amp;ndash; 입력 텐서 또는 숫자</target>
        </trans-unit>
        <trans-unit id="0ddefe13e55f57fbd638c942ea4f7390bcbffe28" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the denominator tensor</source>
          <target state="translated">&lt;strong&gt;tensor2&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 분모 텐서</target>
        </trans-unit>
        <trans-unit id="41bea45291973dd63ddd884b78f07e00d3ab7d86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be multiplied</source>
          <target state="translated">&lt;strong&gt;tensor2&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 곱할 텐서</target>
        </trans-unit>
        <trans-unit id="b7570a5e6d003c7758abda29ee8e97e855d23054" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; an input tensor or number</source>
          <target state="translated">&lt;strong&gt;tensor2&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt; ) &amp;ndash; 입력 텐서 또는 숫자</target>
        </trans-unit>
        <trans-unit id="8f71579bdc06e7c9c71d37a5240b5de48b5701ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; a 2-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; 2 차원 &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;strong&gt;텐서&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="1efb28f257d49ada4a2b28823d609173cc47778d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; a tensor to be exported</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; 내보낼 텐서</target>
        </trans-unit>
        <trans-unit id="ebd185db4dcd0096fd7b5c3f6d3e9f89f2fe9c11" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; a {3, 4, 5}-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;텐서&lt;/strong&gt; &amp;ndash; {3, 4, 5} 차원 &lt;code&gt;torch.Tensor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="38120be427a851f124349ce7081bb1e1d17f8071" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; an n-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;텐서&lt;/strong&gt; &amp;ndash; n 차원 &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;strong&gt;텐서&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="9324a2a3b49e2c9c5b1f421b1679082153eb02c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; an n-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;, where</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; n 차원 &lt;code&gt;torch.Tensor&lt;/code&gt; , 여기서</target>
        </trans-unit>
        <trans-unit id="fd9f9b08ebf1b11c3c6c5c2342c4729faa2bd202" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor containing values to add</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 더할 값을 포함하는 텐서</target>
        </trans-unit>
        <trans-unit id="f130d0f3db6962333521550a2aac19265d9b05ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor containing values to copy</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 복사 할 값을 포함하는 텐서</target>
        </trans-unit>
        <trans-unit id="48b5c5ac8e5e9b826ebcd51ac110f06caead74d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor containing values to copy from</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 복사 할 값을 포함하는 텐서</target>
        </trans-unit>
        <trans-unit id="db831c557616296e8156131ded5d0c40f87ca1c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor which has the desired type</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 원하는 유형을 가진 텐서</target>
        </trans-unit>
        <trans-unit id="43e7c30902c9179fb0b37459c8ea94f10d65684d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; A quantized Tensor</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 양자화 된 Tensor</target>
        </trans-unit>
        <trans-unit id="595262930a1db5ff17082aa694d1b0f8665e76ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; buffer to be registered.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 등록 할 버퍼.</target>
        </trans-unit>
        <trans-unit id="daa8d39d1206451461ce1d0b71e54ecbc3499778" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; tensor to split.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 분할 할 텐서.</target>
        </trans-unit>
        <trans-unit id="c5119c9d3c84560f70044a06335745fbc7690c5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Tensor whose dtype and device are the desired dtype and device for all parameters and buffers in this module</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt; ) &amp;ndash; dtype 및 device가이 모듈의 모든 매개 변수 및 버퍼에 대해 원하는 dtype 및 device 인 Tensor</target>
        </trans-unit>
        <trans-unit id="4ea925f35e05eeec0ce6c6ede21012597e80ba1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Data to be sent if &lt;code&gt;src&lt;/code&gt; is the rank of current process, and tensor to be used to save received data otherwise.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; &lt;code&gt;src&lt;/code&gt; 가 현재 프로세스의 순위 인 경우 전송할 데이터, 그렇지 않으면 수신 된 데이터를 저장하는 데 사용할 tensor.</target>
        </trans-unit>
        <trans-unit id="0ea5bf92870a7e63a9dc7b73483e6447ea902554" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Input and output of the collective. The function operates in-place.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 집합체의 입력 및 출력. 이 기능은 제자리에서 작동합니다.</target>
        </trans-unit>
        <trans-unit id="871bd0fcd2a298c26c4d81bf5750fd9c2750ed91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Input tensor.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 입력 텐서.</target>
        </trans-unit>
        <trans-unit id="4086bda3a1c5df109757d3e351db5cbbd66ea1c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Output tensor.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 텐서.</target>
        </trans-unit>
        <trans-unit id="d003bad4eb45ea45fc9aa2947e6f3d43bd663f2d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to be broadcast from current process.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 현재 프로세스에서 브로드 캐스트 할 Tensor입니다.</target>
        </trans-unit>
        <trans-unit id="8057a0b7b9e31fa19b74af90d185d7232521ede8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to fill with received data.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 수신 된 데이터를 채울 Tensor입니다.</target>
        </trans-unit>
        <trans-unit id="c5e9e88f62d8e8a8f1bab1c4e5838b8d932d6e95" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to send.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 보낼 텐서.</target>
        </trans-unit>
        <trans-unit id="6ed36b8ea65f06efab795d8ef00bc8f1d04ff81c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; class values of any shape.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; ( &lt;em&gt;LongTensor&lt;/em&gt; ) &amp;ndash; 모든 모양의 클래스 값.</target>
        </trans-unit>
        <trans-unit id="771c4af8e8d1e14069a64799aa2b6b2856c84f0a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Output list. It should contain correctly-sized tensors to be used for output of the collective.</source>
          <target state="translated">&lt;strong&gt;tensor_list&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 출력 목록. 집합체의 출력에 사용할 올바른 크기의 텐서를 포함해야합니다.</target>
        </trans-unit>
        <trans-unit id="0529bcde8eee4077490565e65382a12d0014ef8d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Input and output GPU tensors of the collective. The function operates in-place. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;tensor_list&lt;/strong&gt; ( &lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 집합체의 입력 및 출력 GPU 텐서. 이 기능은 제자리에서 작동합니다. 또한 이 함수를 호출하는 모든 분산 프로세스에 대해 &lt;code&gt;len(tensor_list)&lt;/code&gt; 가 동일한 지 확인해야 합니다.</target>
        </trans-unit>
        <trans-unit id="fd42e4e4f033181e34931a8527efa00ab289b6ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Tensors that participate in the collective operation. If &lt;code&gt;src&lt;/code&gt; is the rank, then the specified &lt;code&gt;src_tensor&lt;/code&gt; element of &lt;code&gt;tensor_list&lt;/code&gt; (&lt;code&gt;tensor_list[src_tensor]&lt;/code&gt;) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in &lt;code&gt;tensor_list&lt;/code&gt; of other non-src processes. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;tensor_list&lt;/strong&gt; ( &lt;em&gt;List &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 집합 연산에 참여하는 텐서 . 경우 &lt;code&gt;src&lt;/code&gt; 랭크 후 지정된 &lt;code&gt;src_tensor&lt;/code&gt; 용 의 소자 &lt;code&gt;tensor_list&lt;/code&gt; ( &lt;code&gt;tensor_list[src_tensor]&lt;/code&gt; )의 SRC 공정에서, (다른 GPU에서) 다른 텐서 모든 텐서에 방송된다 &lt;code&gt;tensor_list&lt;/code&gt; 다른 비 SRC 프로세스. 또한 이 함수를 호출하는 모든 분산 프로세스에 대해 &lt;code&gt;len(tensor_list)&lt;/code&gt; 가 동일한 지 확인해야 합니다.</target>
        </trans-unit>
        <trans-unit id="6c11521362c09d9790c6e10205b4f5e9d4d0f8d2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; A list of quantized Tensors</source>
          <target state="translated">&lt;strong&gt;tensors&lt;/strong&gt; ( &lt;em&gt;sequence of Tensors&lt;/em&gt; ) &amp;ndash; 양자화 된 Tensor 목록</target>
        </trans-unit>
        <trans-unit id="56d11e41f90bcf5265e9b581f446c4e0dd727f96" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; any python sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.</source>
          <target state="translated">&lt;strong&gt;tensors&lt;/strong&gt; ( &lt;em&gt;sequence of Tensors&lt;/em&gt; ) &amp;ndash; 같은 유형의 텐서의 파이썬 시퀀스. 제공된 비어 있지 않은 텐서는 고양이 차원을 제외하고 동일한 모양이어야합니다.</target>
        </trans-unit>
        <trans-unit id="17a8b4a65e76b16fe0001dce91103bc1f0d95788" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; sequence of tensors to concatenate</source>
          <target state="translated">&lt;strong&gt;tensors&lt;/strong&gt; ( &lt;em&gt;sequence of Tensors&lt;/em&gt; ) &amp;ndash; 연결할 텐서의 순서</target>
        </trans-unit>
        <trans-unit id="eac06248fef5ff01ab7df814f04387fca91e048c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;text_string&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; String to save</source>
          <target state="translated">&lt;strong&gt;text_string&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 저장할 문자열</target>
        </trans-unit>
        <trans-unit id="23bc89e013fe710997ceb4e02308dc814861dd46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; the sequence to the decoder (required).</source>
          <target state="translated">&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; 디코더에 대한 시퀀스 (필수).</target>
        </trans-unit>
        <trans-unit id="a97b7e4ae84d91f24d47d3e533654ba0c637aeda" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; the sequence to the decoder layer (required).</source>
          <target state="translated">&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; 디코더 계층에 대한 시퀀스 (필수).</target>
        </trans-unit>
        <trans-unit id="46691f105bd3761d4561a84637a0dc690d56304c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for tgt keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; 배치 당 tgt 키에 대한 ByteTensor 마스크 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="c272aa66d6d78c6319db9bd44d86112843bcbd0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the tgt keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; 배치 당 tgt 키의 마스크입니다 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="ed8a93d25be2a772ab9ad79f5fd98f7466a44647" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; the additive mask for the tgt sequence (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; tgt 시퀀스에 대한 추가 마스크입니다 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="132d016583670fccbcfcac0d15e9840ebbe1f4a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; the mask for the tgt sequence (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; tgt 시퀀스의 마스크 (선택 사항).</target>
        </trans-unit>
        <trans-unit id="5601a92236ec47fd0c06d7f0fed5b5b6c8fcc29b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;that need to be respected after the new mask is&lt;/strong&gt; (&lt;em&gt;iterations&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;새 마스크 이후에 존중되어야하는 것은&lt;/strong&gt; ( &lt;em&gt;반복 &lt;/em&gt;&lt;em&gt;,&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="6712ad21050e25aa58857f430d28e66ca2b72d67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;theta&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input batch of affine matrices with shape (</source>
          <target state="translated">&lt;strong&gt;theta&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양이있는 아핀 행렬의 입력 배치 (</target>
        </trans-unit>
        <trans-unit id="1f97d9939a572f78a3fab174d3aace7d899626d1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; The value to threshold at</source>
          <target state="translated">&lt;strong&gt;임계 값&lt;/strong&gt; &amp;ndash; 임계 값</target>
        </trans-unit>
        <trans-unit id="4e72f74774d99b133267f9808f645ba3f90baa42" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; Total number of array elements which trigger summarization rather than full &lt;code&gt;repr&lt;/code&gt; (default = 1000).</source>
          <target state="translated">&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; 전체 &lt;code&gt;repr&lt;/code&gt; 아닌 요약을 트리거하는 배열 요소의 총 수 (기본값 = 1000).</target>
        </trans-unit>
        <trans-unit id="9beeeb50002c6e9c428d419f497bfffeb0df1d1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; values above this revert to a linear function. Default: 20</source>
          <target state="translated">&lt;strong&gt;임계 값&lt;/strong&gt; &amp;ndash;이 이상의 값은 선형 함수로 되돌아갑니다. 기본값 : 20</target>
        </trans-unit>
        <trans-unit id="a4158143cd3f539f6f9f4f75136861c57fa1f337" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for &lt;code&gt;to_here&lt;/code&gt;. If the call does not complete within this timeframe, an exception indicating so will be raised. If this argument is not provided, the default RPC timeout (60s) will be used.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;to_here&lt;/code&gt; 에 대한 시간 초과 . 이 기간 내에 호출이 완료되지 않으면이를 나타내는 예외가 발생합니다. 이 인수가 제공되지 않으면 기본 RPC 제한 시간 (60 초)이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="e0ca20ba1ac1f4702011bcb3b44292663520556f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; timeout in seconds for this remote call. If the creation of this &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt; on worker &lt;code&gt;to&lt;/code&gt; is not successfully processed on this worker within this timeout, then the next time there is an attempt to use the RRef (such as &lt;code&gt;to_here()&lt;/code&gt;), a timeout will be raised indicating this failure. A value of 0 indicates an infinite timeout, i.e. a timeout error will never be raised. If not provided, the default value set during initialization or with &lt;code&gt;_set_rpc_timeout&lt;/code&gt; is used.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash;이 원격 호출에 대한 시간 제한 (초)입니다. &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt; 에 대한이 RRef 생성 이이 타임 아웃 내에이 워커 &lt;code&gt;to&lt;/code&gt; 성공적으로 처리되지 않으면 다음에 RRef (예 : &lt;code&gt;to_here()&lt;/code&gt; ) 를 사용하려고 시도 할 때이 실패를 나타내는 타임 아웃이 발생합니다. 값 0은 제한 시간이 무한함을 나타냅니다. 즉, 시간 초과 오류가 발생하지 않습니다. 제공되지 않으면 초기화 중 또는 &lt;code&gt;_set_rpc_timeout&lt;/code&gt; 으로 설정된 기본값 이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="cb09a1d9765bc72d97aa2aa954e843c0cc306ebd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; timeout in seconds to use for this RPC. If the RPC does not complete in this amount of time, an exception indicating it has timed out will be raised. A value of 0 indicates an infinite timeout, i.e. a timeout error will never be raised. If not provided, the default value set during initialization or with &lt;code&gt;_set_rpc_timeout&lt;/code&gt; is used.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash;이 RPC에 사용할 시간 제한 (초)입니다. RPC가이 시간 동안 완료되지 않으면 시간 초과를 나타내는 예외가 발생합니다. 값 0은 제한 시간이 무한함을 나타냅니다. 즉, 시간 초과 오류가 발생하지 않습니다. 제공되지 않으면 초기화 중 또는 &lt;code&gt;_set_rpc_timeout&lt;/code&gt; 으로 설정된 기본값 이 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="9273f5efc9a2168581a1563dc88271535c09449c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; Time to wait for the keys to be added before throwing an exception.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; ( &lt;em&gt;timedelta&lt;/em&gt; ) &amp;ndash; 예외를 발생시키기 전에 키가 추가되기를 기다리는 시간입니다.</target>
        </trans-unit>
        <trans-unit id="52d6695e842a69c4f1f1155be378bf5f945bf62e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; Timeout used by the store during initialization and for methods such as &lt;code&gt;get()&lt;/code&gt; and &lt;code&gt;wait()&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; ( &lt;em&gt;timedelta&lt;/em&gt; ) &amp;ndash; 초기화하는 동안 저장소와 &lt;code&gt;get()&lt;/code&gt; 및 &lt;code&gt;wait()&lt;/code&gt; 같은 메서드에 사용되는 시간 초과 입니다.</target>
        </trans-unit>
        <trans-unit id="8232ad0889858559e2f3203547e409d87becb68e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; timeout to be set in the store.</source>
          <target state="translated">&lt;strong&gt;타임 아웃&lt;/strong&gt; ( &lt;em&gt;timedelta&lt;/em&gt; ) &amp;ndash; 스토어에서 설정할 타임 아웃.</target>
        </trans-unit>
        <trans-unit id="2751f8d0a7ffb7b1eea973ad31d6029c6cf7b2ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for operations executed against the process group. Default value equals 30 minutes. This is applicable for the &lt;code&gt;gloo&lt;/code&gt; backend. For &lt;code&gt;nccl&lt;/code&gt;, this is applicable only if the environment variable &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; or &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; is set to 1. When &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; is set, this is the duration for which the process will block and wait for collectives to complete before throwing an exception. When &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; is set, this is the duration after which collectives will be aborted asynchronously and the process will crash. &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; will provide errors to the user which can be caught and handled, but due to its blocking nature, it has a performance overhead. On the other hand, &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; has little performance overhead, but crashes the process on errors. This is done since CUDA execution is async and it is no longer safe to continue executing user code since failed async NCCL operations might result in subsequent CUDA operations to run on corrupted data. Only one of these two environment variables should be set.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; ( &lt;em&gt;timedelta &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 프로세스 그룹에 대해 실행되는 작업의 시간 초과입니다. 기본값은 30 분입니다. 이것은 &lt;code&gt;gloo&lt;/code&gt; 백엔드에 적용됩니다 . 들어 &lt;code&gt;nccl&lt;/code&gt; ,이 환경 변수 경우에만 적용 &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; 또는 &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; 가 1로 설정되어 &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; 이 설정은,이 집단은 예외를 던지기 전에 완료 될 때까지 프로세스를 차단하고 대기하는 기간입니다. 때 &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; 가 설정되어,이 집단이 비동기 적으로 중단되고 프로세스가 충돌합니다 후 시간입니다. &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; 사용자에게 잡아서 처리 할 수있는 오류를 제공하지만 차단 특성으로 인해 성능 오버 헤드가 있습니다. 반면에 &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; 은 성능 오버 헤드가 거의 없지만 오류가 발생하면 프로세스가 충돌합니다. 이는 CUDA 실행이 비동기이기 때문에 수행되며 실패한 비동기 NCCL 작업으로 인해 후속 CUDA 작업이 손상된 데이터에서 실행될 수 있기 때문에 더 이상 사용자 코드를 계속 실행하는 것이 안전하지 않습니다. 이 두 환경 변수 중 하나만 설정해야합니다.</target>
        </trans-unit>
        <trans-unit id="00a4cf1534a34a3e1bdbf78c948e2ba0bebb6650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for operations executed against the process group. Default value equals 30 minutes. This is only applicable for the &lt;code&gt;gloo&lt;/code&gt; backend.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; ( &lt;em&gt;timedelta &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 프로세스 그룹에 대해 실행되는 작업의 시간 초과입니다. 기본값은 30 분입니다. 이것은 &lt;code&gt;gloo&lt;/code&gt; 백엔드 에만 적용됩니다 .</target>
        </trans-unit>
        <trans-unit id="02c882e856aedbce8abb8c0907459899847d1718" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;to&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;WorkerInfo&lt;/a&gt;) &amp;ndash; id or name of the destination worker.</source>
          <target state="translated">&lt;strong&gt;to&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;WorkerInfo&lt;/a&gt; ) &amp;ndash; 대상 작업자의 ID 또는 이름입니다.</target>
        </trans-unit>
        <trans-unit id="ea9f5f30be6e298274025992da4c6c4ec845554e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;to&lt;/strong&gt; (&lt;em&gt;dpython:type&lt;/em&gt;) &amp;ndash; The target &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;to&lt;/strong&gt; ( &lt;em&gt;dpython : type&lt;/em&gt; ) &amp;ndash; 대상 &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e52fdd2bd38561ad6a0c5c61e130e89b4aada3ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; residual tolerance for stopping criterion. Default is &lt;code&gt;feps ** 0.5&lt;/code&gt; where &lt;code&gt;feps&lt;/code&gt; is smallest non-zero floating-point number of the given input tensor &lt;code&gt;A&lt;/code&gt; data type.</source>
          <target state="translated">&lt;strong&gt;tol&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 중지 기준에 대한 잔여 허용 오차. 기본값은 &lt;code&gt;feps ** 0.5&lt;/code&gt; 여기서 &lt;code&gt;feps&lt;/code&gt; 는 주어진 입력 텐서 &lt;code&gt;A&lt;/code&gt; 데이터 유형의 가장 작은 0이 아닌 부동 소수점 숫자입니다 .</target>
        </trans-unit>
        <trans-unit id="ebb57295704495b7e390dfbf06821990d8f2e8d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the tolerance value. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;tol&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 공차 값. 기본값 : &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c6231da05b67c6d40cc466aa082bc7aa1fceb57f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;total_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if not &lt;code&gt;None&lt;/code&gt;, the output will be padded to have length &lt;code&gt;total_length&lt;/code&gt;. This method will throw &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#ValueError&quot;&gt;&lt;code&gt;ValueError&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;total_length&lt;/code&gt; is less than the max sequence length in &lt;code&gt;sequence&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;total_length&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;None&lt;/code&gt; 이 아니면 출력이 &lt;code&gt;total_length&lt;/code&gt; 길이를 갖도록 패딩됩니다 . 이 방법은 발생합니다 &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#ValueError&quot;&gt; &lt;code&gt;ValueError&lt;/code&gt; 를을&lt;/a&gt; 경우 &lt;code&gt;total_length&lt;/code&gt; 가 의 최대 시퀀스 길이보다 작은 &lt;code&gt;sequence&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="07c5deb90e808db58c55e72b715383a8fbfd19d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module tracks the running mean and variance, and when set to &lt;code&gt;False&lt;/code&gt;, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; 로 설정하면 이 모듈이 실행 평균 및 분산을 추적하고 &lt;code&gt;False&lt;/code&gt; 로 설정하면 이 모듈이 이러한 통계를 추적하지 않고 항상 학습 및 평가 모드에서 배치 통계를 사용 하는 부울 값입니다 . 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3efa70ce9f7603a628298aac133f6c2ebf2aea12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module tracks the running mean and variance, and when set to &lt;code&gt;False&lt;/code&gt;, this module does not track such statistics, and initializes statistics buffers &lt;code&gt;running_mean&lt;/code&gt; and &lt;code&gt;running_var&lt;/code&gt; as &lt;code&gt;None&lt;/code&gt;. When these buffers are &lt;code&gt;None&lt;/code&gt;, this module always uses batch statistics. in both training and eval modes. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; 로 설정하면 이 모듈이 실행 평균 및 분산을 추적하고 &lt;code&gt;False&lt;/code&gt; 로 설정하면 이 모듈이 이러한 통계를 추적하지 않고 통계 버퍼 &lt;code&gt;running_mean&lt;/code&gt; 및 &lt;code&gt;running_var&lt;/code&gt; 를 &lt;code&gt;None&lt;/code&gt; 으로 초기화 하는 부울 값입니다 . 이러한 버퍼가 &lt;code&gt;None&lt;/code&gt; 이면이 모듈은 항상 배치 통계를 사용합니다. 훈련 및 평가 모드 모두에서. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="83e1567d195f61030af1691e6408ec395faa36b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tracker&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;추적기&lt;/strong&gt; ( &lt;em&gt;호출 가능 &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="cae553a329b41a39ac2ef28a1128e47f2aff1a79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;trainable_backbone_layers&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of trainable (not frozen) resnet layers starting from final block. Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.</source>
          <target state="translated">&lt;strong&gt;trainable_backbone_layers&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 최종 블록에서 시작하는 훈련 가능한 (고정되지 않은) resnet 레이어의 수입니다. 유효한 값은 0에서 5 사이이며 5는 모든 백본 레이어가 학습 가능함을 의미합니다.</target>
        </trans-unit>
        <trans-unit id="1918b886e2cf75d47f208888e3bf63f2ca3faa0e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;training&lt;/strong&gt; &amp;ndash; apply dropout if is &lt;code&gt;True&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;교육&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; 인 경우 드롭 아웃을 적용 합니다. 기본값 : &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9b04f39ddad8101f7db51608eea54f5bf896eeb7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;training&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Boolean represents whether this module is in training or evaluation mode.</source>
          <target state="translated">&lt;strong&gt;training&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; Boolean은이 모듈이 교육 모드인지 평가 모드인지를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="51af50b75452e3c060a548901f1c86020bc06d08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;training&lt;/strong&gt; (&lt;em&gt;enum&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default TrainingMode.EVAL&lt;/em&gt;) &amp;ndash; TrainingMode.EVAL: export the model in inference mode. TrainingMode.PRESERVE: export the model in inference mode if model.training is False and to a training friendly mode if model.training is True. TrainingMode.TRAINING: export the model in a training friendly mode.</source>
          <target state="translated">&lt;strong&gt;training&lt;/strong&gt; ( &lt;em&gt;enum &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;기본 TrainingMode.EVAL&lt;/em&gt; ) &amp;ndash; TrainingMode.EVAL : 모델을 추론 모드로 내 보냅니다. TrainingMode.PRESERVE : model.training이 False이면 모델을 추론 모드로 내보내고 model.training이 True이면 훈련 친화적 모드로 내 보냅니다. TrainingMode.TRAINING : 훈련 친화적 모드로 모델을 내 보냅니다.</target>
        </trans-unit>
        <trans-unit id="6b489d8a5fd1b48c8841b422261d73f6fc9f5019" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;transform_input&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, preprocesses the input according to the method with which it was trained on ImageNet. Default: &lt;em&gt;False&lt;/em&gt;</source>
          <target state="translated">&lt;strong&gt;transform_input&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; True 인 경우 ImageNet에서 학습 된 방법에 따라 입력을 전처리합니다. 기본값 : &lt;em&gt;False&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="0f7f01bd2f696782296281656611b9d7f0e11af1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;transpose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether</source>
          <target state="translated">&lt;strong&gt;transpose&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 여부</target>
        </trans-unit>
        <trans-unit id="5d7f3ae8d3896d551417a34cad2154f4876e37e8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;type1&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;type1&lt;/strong&gt; ( &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="db83431c42acbc4313b6844960f9f9b62081f0cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;type2&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;type2&lt;/strong&gt; ( &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="2ebcbce8f74baa28dc73e78635230701acf753b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unbiased&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to use the unbiased estimation or not</source>
          <target state="translated">&lt;strong&gt;unbiased&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; unbiased 추정을 사용할지 여부</target>
        </trans-unit>
        <trans-unit id="2e13564fc77541067b4971002e5a668623c64ae3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unexpected_keys&lt;/strong&gt; is a list of str containing the unexpected keys</source>
          <target state="translated">&lt;strong&gt;예기치&lt;/strong&gt; 않은 키는 예상치 못한 키를 포함하는 str 목록입니다.</target>
        </trans-unit>
        <trans-unit id="40c65479b90b1228aa4509bb18c068347e1a8396" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unflattened_size&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;NamedShape&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; New shape of the unflattened dimension</source>
          <target state="translated">&lt;strong&gt;unflattened_size&lt;/strong&gt; ( &lt;em&gt;Union &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;em&gt;torch.Size &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;NamedShape &lt;/em&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; &lt;em&gt;평탄화되지&lt;/em&gt; 않은 차원의 새 모양</target>
        </trans-unit>
        <trans-unit id="6577f53f07c6b82453a5e4d8ee1cdce173f1095c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unitriangular&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether</source>
          <target state="translated">&lt;strong&gt;unitriangular&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 여부</target>
        </trans-unit>
        <trans-unit id="f6abb29d9132a1cca0511aeb0026c03c9d5e185c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unpack_data&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; flag indicating if the data should be unpacked</source>
          <target state="translated">&lt;strong&gt;unpack_data&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 데이터의 압축을 &lt;strong&gt;풀어야&lt;/strong&gt; 하는지 여부를 나타내는 플래그</target>
        </trans-unit>
        <trans-unit id="04e96028a5908db9b44aee6aad14f15f640b0004" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unpack_pivots&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; flag indicating if the pivots should be unpacked</source>
          <target state="translated">&lt;strong&gt;unpack_pivots&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 피벗을 &lt;strong&gt;풀어야&lt;/strong&gt; 하는지 여부를 나타내는 플래그</target>
        </trans-unit>
        <trans-unit id="f545e5ba1e2fb058ee8bbcf81cc46f57b737b0f7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; &amp;ndash; upper bound of the uniform distribution. Default:</source>
          <target state="translated">&lt;strong&gt;상한&lt;/strong&gt; &amp;ndash; 균일 분포의 상한. 기본:</target>
        </trans-unit>
        <trans-unit id="078b557c79445664413d140b19483eb01fc4a40b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; flag that indicates whether to return a upper or lower triangular matrix. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 상위 또는 하위 삼각 행렬을 반환할지 여부를 나타내는 플래그입니다. 기본값 : &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f6e194e2ffa34563a9da2cd5695fbad2b195aeb3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to consider the Cholesky factor as a lower or upper triangular matrix. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 촐레 스키 인자를 하부 또는 상부 삼각 행렬로 간주할지 여부. 기본값 : &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e4c027c4ea86e34928bea3afd23c0befc2ae84dc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to return a lower (default) or upper triangular matrix</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 하부 (기본값) 또는 상부 삼각 행렬을 반환할지 여부</target>
        </trans-unit>
        <trans-unit id="e817dde6e0d6a551d34fc3800e9ab1a2430679a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to solve the upper-triangular system of equations (default) or the lower-triangular system of equations. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 상부 삼각 방정식 시스템 (기본값) 또는 하부 삼각 방정식 시스템을 풀지 여부. 기본값 : &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f6bd6cb43a30358db4258c20658d93f8d71b69f5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to consider upper-triangular or lower-triangular region</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; ( &lt;em&gt;boolean &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 상부 삼각 또는 하부 삼각 영역을 고려할지 여부를 제어합니다.</target>
        </trans-unit>
        <trans-unit id="f8ed541c4bbf8acbeeefe806b08d772cdb213ba6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upscale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; factor to increase spatial resolution by</source>
          <target state="translated">&lt;strong&gt;upscale_factor&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 공간 해상도를 증가시키는 요인</target>
        </trans-unit>
        <trans-unit id="dbbba1d51581a2e6efdbd392cc9848e659d8b9c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;url&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; URL of the object to download</source>
          <target state="translated">&lt;strong&gt;url&lt;/strong&gt; ( &lt;em&gt;string&lt;/em&gt; ) &amp;ndash; 다운로드 할 객체의 URL</target>
        </trans-unit>
        <trans-unit id="98118f8f62fd734993f566a38ff617a7ee9952b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;val&lt;/strong&gt; &amp;ndash; the value to fill the tensor with</source>
          <target state="translated">&lt;strong&gt;val&lt;/strong&gt; &amp;ndash; 텐서를 채울 값</target>
        </trans-unit>
        <trans-unit id="7e6a7de4d7910c74c696408d838f32027dedb43c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;val&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the value to fill with</source>
          <target state="translated">&lt;strong&gt;val&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 채울 값</target>
        </trans-unit>
        <trans-unit id="e1ad2ed4dd7f0bf60e90e62bbcab68ef4dd2b46f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; The value to replace with</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; 대체 할 값</target>
        </trans-unit>
        <trans-unit id="5ea89c83b46186a326f0e2a0c5a74bf1b7ed29c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; fill value for &lt;code&gt;'constant'&lt;/code&gt; padding. Default: &lt;code&gt;0&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; &lt;code&gt;'constant'&lt;/code&gt; 패딩 값을 채 웁니다 . 기본값 : &lt;code&gt;0&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7b65f448578fca2733acf40a459ffeecb2eddae8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; tensor of same dtype as &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; ( &lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; &lt;code&gt;self&lt;/code&gt; 와 같은 dtype의 텐서 .</target>
        </trans-unit>
        <trans-unit id="1d73cf9df184ed1151607fad31d5ce6f0c1674e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the source element(s) to scatter, incase &lt;code&gt;src&lt;/code&gt; is not specified</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; &lt;code&gt;src&lt;/code&gt; 가 지정되지 않은 경우 분산 할 소스 요소</target>
        </trans-unit>
        <trans-unit id="2231cde0326d2e7cbe7a063bea9dd6db2ca090b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the value to fill in with</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 채울 값</target>
        </trans-unit>
        <trans-unit id="9b8e6c78f63bfe21f3c21ce8282ea0ac124b1636" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The value associated with &lt;code&gt;key&lt;/code&gt; to be added to the store.</source>
          <target state="translated">&lt;strong&gt;값&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 상점에 추가 할 &lt;code&gt;key&lt;/code&gt; 와 연관된 값 입니다.</target>
        </trans-unit>
        <trans-unit id="dbe8188f9a9c1f457d68930c71ccb9451d1315c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the number to be added to each element of &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; ( &lt;em&gt;Number&lt;/em&gt; ) &amp;ndash; &lt;code&gt;input&lt;/code&gt; 각 요소에 추가 할 숫자</target>
        </trans-unit>
        <trans-unit id="b0865065739e87d295963220665d5169b7839527" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; ( &lt;em&gt;Number &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 승수</target>
        </trans-unit>
        <trans-unit id="83dafd80344b2148557bddd1e22227cc205b7bf0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The values to use where &lt;code&gt;input&lt;/code&gt; is zero.</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; &lt;code&gt;input&lt;/code&gt; 이 0 인 경우 사용할 값 입니다.</target>
        </trans-unit>
        <trans-unit id="a0a6ed69f7bb031d32442c8207e6351c28728f97" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; N-D tensor or a Scalar containing the search value(s).</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt; ) &amp;ndash; ND tensor 또는 검색 값을 포함하는 Scalar입니다.</target>
        </trans-unit>
        <trans-unit id="068141ee62e0c741721a1ca247da7418337fa905" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Values to build histogram</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array &lt;/em&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;string / blobname&lt;/em&gt; ) &amp;ndash; 히스토그램을 작성할 값</target>
        </trans-unit>
        <trans-unit id="81346c9c646d8fdc4c0b129427baa5e0d2452356" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; Initial values for the tensor. Can be a list, tuple, NumPy &lt;code&gt;ndarray&lt;/code&gt;, scalar, and other types.</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; ( &lt;em&gt;array_like&lt;/em&gt; ) &amp;ndash; 텐서의 초기 값. 목록, 튜플, NumPy &lt;code&gt;ndarray&lt;/code&gt; , 스칼라 및 기타 유형이 될 수 있습니다.</target>
        </trans-unit>
        <trans-unit id="2514f73a2f02b616f12aa53311fb41936e3843bc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vdim&lt;/strong&gt; &amp;ndash; total number of features in value. Default: None.</source>
          <target state="translated">&lt;strong&gt;vdim&lt;/strong&gt; &amp;ndash; 가치있는 총 기능 수입니다. 기본값 : 없음.</target>
        </trans-unit>
        <trans-unit id="819b9c6fd109a7c509127d79322ef0512ba65bd2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first vector of the outer product</source>
          <target state="translated">&lt;strong&gt;vec1&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 외적의 첫 번째 벡터</target>
        </trans-unit>
        <trans-unit id="4e73eb0cbf6f2a91979ca7e439e5aa7d715d0300" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D input vector</source>
          <target state="translated">&lt;strong&gt;vec2&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 1 차원 입력 벡터</target>
        </trans-unit>
        <trans-unit id="131877debbb3166e16ce26108f5a3eed6fc2f019" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second vector of the outer product</source>
          <target state="translated">&lt;strong&gt;vec2&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 외적의 두 번째 벡터</target>
        </trans-unit>
        <trans-unit id="4d0559907de880bfcd717f1f78869a200f9027f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a single vector represents the parameters of a model.</source>
          <target state="translated">&lt;strong&gt;vec&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 단일 벡터는 모델의 매개 변수를 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="daede4c661612057da3d485c36e667e3f8d4dad0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; vector to be multiplied</source>
          <target state="translated">&lt;strong&gt;vec&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 곱할 벡터</target>
        </trans-unit>
        <trans-unit id="ff9a7e40dc82a226dc8f29f776ec07c36e2e317b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, turns on verbose logging of load steps.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; 이면로드 단계의 자세한 로깅을 켭니다.</target>
        </trans-unit>
        <trans-unit id="2094bc9935f0b3c92d97f3cf874c37a89b5048a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to print graph structure in console.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; 콘솔에서 그래프 구조를 인쇄할지 여부.</target>
        </trans-unit>
        <trans-unit id="c171e7c8da79938ba578ce62f6d80ce02e508b76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; if specified, we will print out a debug description of the trace being exported.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;기본값 False&lt;/em&gt; ) &amp;ndash; 지정된 경우 내보내는 추적에 대한 디버그 설명을 인쇄합니다.</target>
        </trans-unit>
        <trans-unit id="f3599691f4621301d1623dd0c2e7a30947cc6548" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, mute messages about hitting local caches. Note that the message about first download cannot be muted. Does not have any effect if &lt;code&gt;source = 'local'&lt;/code&gt;. Default is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; &lt;code&gt;False&lt;/code&gt; 이면 로컬 캐시 적중에 대한 메시지를 음소거합니다. 첫 번째 다운로드에 대한 메시지는 음소거 할 수 없습니다. &lt;code&gt;source = 'local'&lt;/code&gt; 이면 효과가 없습니다 . 기본값은 &lt;code&gt;True&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="c849d403c5b92168af96b652290de46caebea368" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vertices&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; List of the 3D coordinates of vertices.</source>
          <target state="translated">&lt;strong&gt;vertices&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt; ) &amp;ndash; &lt;strong&gt;정점&lt;/strong&gt; 의 3D 좌표 목록입니다.</target>
        </trans-unit>
        <trans-unit id="f13839df85806a7d212ed83a81c31127bf2c2237" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vid_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Video data</source>
          <target state="translated">&lt;strong&gt;vid_tensor&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt; ) &amp;ndash; 비디오 데이터</target>
        </trans-unit>
        <trans-unit id="dc84a7d8a07edfd6dc468d5b20a74d4a8841fdbe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;walltime&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Optional override default walltime (time.time()) seconds after epoch of event</source>
          <target state="translated">&lt;strong&gt;walltime&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 선택적으로 이벤트 발생 후 기본 walltime (time.time ()) 초를 재정의합니다.</target>
        </trans-unit>
        <trans-unit id="f41030565ca27ea1362cda461c42d37902d0ff5c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;walltime&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Optional override default walltime (time.time()) with seconds after epoch of event</source>
          <target state="translated">&lt;strong&gt;walltime&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt; ) &amp;ndash; 선택적으로 이벤트 발생 후 초로 기본 walltime (time.time ())을 재정의합니다.</target>
        </trans-unit>
        <trans-unit id="f9d74e109cb0a14286b98abd2e21c589f1814826" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; &amp;ndash; filters of shape</source>
          <target state="translated">&lt;strong&gt;무게&lt;/strong&gt; &amp;ndash; 모양의 필터</target>
        </trans-unit>
        <trans-unit id="f9a334f0285a62a48b2313f31b6d8a7b66efc571" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; &amp;ndash; quantized filters of shape</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; &amp;ndash; 모양의 양자화 된 필터</target>
        </trans-unit>
        <trans-unit id="ab4ea073acb19584f6540d88c6edee778c2582cc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, has to be a Tensor of size &lt;code&gt;C&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 각 클래스에 주어진 수동 크기 조정 가중치입니다. 주어진 경우 크기 &lt;code&gt;C&lt;/code&gt; 의 텐서 여야합니다.</target>
        </trans-unit>
        <trans-unit id="70e8975c00d113cb45edf143611e73c84cc5ce44" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, it has to be a Tensor of size &lt;code&gt;C&lt;/code&gt;. Otherwise, it is treated as if having all ones.</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 각 클래스에 주어진 수동 크기 조정 가중치입니다. 주어진 경우 크기 &lt;code&gt;C&lt;/code&gt; 의 Tensor 여야합니다 . 그렇지 않으면 모든 항목이있는 것처럼 처리됩니다.</target>
        </trans-unit>
        <trans-unit id="954e4537a940f3ba78802ce2a539fbef33a42e08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to the loss of each batch element. If given, has to be a Tensor of size &lt;code&gt;nbatch&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 각 배치 요소의 손실에 부여되는 수동 크기 조정 가중치입니다. 주어진 경우 &lt;code&gt;nbatch&lt;/code&gt; 크기의 Tensor 이어야 합니다.</target>
        </trans-unit>
        <trans-unit id="a1f17f82ec381f64b173aaca9f8effdf46eb1689" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tensor&lt;/em&gt;) &amp;ndash; the weight for the interpolation formula</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;tensor&lt;/em&gt; ) &amp;ndash; 보간 공식에 대한 가중치</target>
        </trans-unit>
        <trans-unit id="22154f27393e88b905a5d41b51a84b23ab22932b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Quantized weight of type &lt;code&gt;torch.qint8&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; &lt;code&gt;torch.qint8&lt;/code&gt; 유형의 양자화 된 무게</target>
        </trans-unit>
        <trans-unit id="c4cf9889c18f266792e6d5b0d19e359c339fffa5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 가능한 최대 인덱스 + 1과 동일한 행 수와 임베딩 크기와 동일한 열 수를 갖는 임베딩 행렬</target>
        </trans-unit>
        <trans-unit id="0b17239462ca378c70577124e3fcde25d087b526" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, has to be a Tensor of size &lt;code&gt;C&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;선택 사항&lt;/em&gt; ) &amp;ndash; 각 클래스에 주어진 수동 크기 조정 가중치입니다. 주어진 경우 크기 &lt;code&gt;C&lt;/code&gt; 의 텐서 여야합니다.</target>
        </trans-unit>
        <trans-unit id="ceb298880b72c5ea4b42cc8ffeba86de3610e3c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight if provided it&amp;rsquo;s repeated to match input tensor shape</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 입력 텐서 모양과 일치하도록 반복되는 경우 수동 크기 조정 가중치</target>
        </trans-unit>
        <trans-unit id="30220330ec8f9548f71ee65df724e11d72d2b160" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weights&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; optional, weight for each value in the input tensor. Should be of same size as input tensor.</source>
          <target state="translated">&lt;strong&gt;weights&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 선택 사항, 입력 텐서의 각 값에 대한 가중치. 입력 텐서와 크기가 같아야합니다.</target>
        </trans-unit>
        <trans-unit id="1dacae6023a61e8210dc97a03d769ec15092e68e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;win_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the size of window frame and STFT filter. Default: &lt;code&gt;None&lt;/code&gt; (treated as equal to &lt;code&gt;n_fft&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;win_length&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 창 프레임 및 STFT 필터의 크기. 기본값 : &lt;code&gt;None&lt;/code&gt; ( &lt;code&gt;n_fft&lt;/code&gt; 와 동일하게 처리됨 )</target>
        </trans-unit>
        <trans-unit id="6b1bf34b632ccb28e0c558a94dd1b77ac54ce12b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;win_length&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The size of window frame and STFT filter. (Default: &lt;code&gt;n_fft&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;win_length&lt;/strong&gt; ( &lt;em&gt;선택 사항 &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 창 프레임 및 STFT 필터의 크기입니다. (기본값 : &lt;code&gt;n_fft&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="7d9a9a55c05cd5b2885fb65d4e15a0e9d0340b49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the optional window function. Default: &lt;code&gt;None&lt;/code&gt; (treated as window of all</source>
          <target state="translated">&lt;strong&gt;window&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 선택적 창 함수입니다. 기본값 : &lt;code&gt;None&lt;/code&gt; (모두의 창으로 처리</target>
        </trans-unit>
        <trans-unit id="f0f614133f5e416c9d9f06c46de251960734b001" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The optional window function. (Default: &lt;code&gt;torch.ones(win_length)&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;window&lt;/strong&gt; ( &lt;em&gt;선택적 &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt; ) &amp;ndash; 선택적 창 기능입니다. (기본값 : &lt;code&gt;torch.ones(win_length)&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="49b7cd3881023ff5bbecb687d60192ac07560fe8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; length of the window.</source>
          <target state="translated">&lt;strong&gt;window_length&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 창의 길이.</target>
        </trans-unit>
        <trans-unit id="4e3bec63120999c913a0f66ab321260fd1dfb2c9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the size of returned window</source>
          <target state="translated">&lt;strong&gt;window_length&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 반환 된 창의 크기</target>
        </trans-unit>
        <trans-unit id="9ccfcc0cdca44901901265e154f3e79d9b261692" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_cuda&lt;/strong&gt; &amp;ndash; Determines whether CUDA headers and libraries are added to the build. If set to &lt;code&gt;None&lt;/code&gt; (default), this value is automatically determined based on the existence of &lt;code&gt;.cu&lt;/code&gt; or &lt;code&gt;.cuh&lt;/code&gt; in &lt;code&gt;sources&lt;/code&gt;. Set it to &lt;code&gt;True`&lt;/code&gt; to force CUDA headers and libraries to be included.</source>
          <target state="translated">&lt;strong&gt;with_cuda&lt;/strong&gt; &amp;ndash; CUDA 헤더 및 라이브러리가 빌드에 추가되는지 여부를 결정합니다. &lt;code&gt;None&lt;/code&gt; (기본값)으로 설정하면 이 값은 &lt;code&gt;sources&lt;/code&gt; 에 &lt;code&gt;.cu&lt;/code&gt; 또는 &lt;code&gt;.cuh&lt;/code&gt; 가 있는지에 따라 자동으로 결정 됩니다 . CUDA 헤더 및 라이브러리가 포함되도록 하려면 &lt;code&gt;True`&lt;/code&gt; 로 설정하십시오 .</target>
        </trans-unit>
        <trans-unit id="bd3ed9cacd1f8bdf1897ff6845942937dc2aa6cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_cuda&lt;/strong&gt; &amp;ndash; Determines whether CUDA headers and libraries are added to the build. If set to &lt;code&gt;None&lt;/code&gt; (default), this value is automatically determined based on whether &lt;code&gt;cuda_sources&lt;/code&gt; is provided. Set it to &lt;code&gt;True&lt;/code&gt; to force CUDA headers and libraries to be included.</source>
          <target state="translated">&lt;strong&gt;with_cuda&lt;/strong&gt; &amp;ndash; CUDA 헤더 및 라이브러리가 빌드에 추가되는지 여부를 결정합니다. &lt;code&gt;None&lt;/code&gt; (기본값)으로 설정하면 이 값은 &lt;code&gt;cuda_sources&lt;/code&gt; 제공 여부에 따라 자동으로 결정 됩니다. CUDA 헤더 및 라이브러리가 포함되도록 하려면 &lt;code&gt;True&lt;/code&gt; 로 설정하십시오 .</target>
        </trans-unit>
        <trans-unit id="4815336ed54522c0846013f45d4ba87f409a2251" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_pytorch_error_handling&lt;/strong&gt; &amp;ndash; Determines whether pytorch error and warning macros are handled by pytorch instead of pybind. To do this, each function &lt;code&gt;foo&lt;/code&gt; is called via an intermediary &lt;code&gt;_safe_foo&lt;/code&gt; function. This redirection might cause issues in obscure cases of cpp. This flag should be set to &lt;code&gt;False&lt;/code&gt; when this redirect causes issues.</source>
          <target state="translated">&lt;strong&gt;with_pytorch_error_handling&lt;/strong&gt; &amp;ndash; pytorch 오류 및 경고 매크로가 pybind 대신 pytorch에서 처리되는지 여부를 결정합니다. 이를 위해 각 함수 &lt;code&gt;foo&lt;/code&gt; 는 중개 &lt;code&gt;_safe_foo&lt;/code&gt; 함수 를 통해 호출됩니다 . 이 리디렉션으로 인해 모호한 cpp 사례에서 문제가 발생할 수 있습니다. 이 리디렉션으로 인해 문제가 발생하면 이 플래그를 &lt;code&gt;False&lt;/code&gt; 로 설정해야합니다 .</target>
        </trans-unit>
        <trans-unit id="4a19e10a55ff5cbaf67b76afd814820dc5724ee4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_replacement&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to allow duplication in combination</source>
          <target state="translated">&lt;strong&gt;with_replacement&lt;/strong&gt; ( &lt;em&gt;boolean &lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 조합으로 복제를 허용할지 여부</target>
        </trans-unit>
        <trans-unit id="d520029ad1a21541a6983cd1bbd1d13e71672aaf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;worker_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; the string name of a worker. If &lt;code&gt;None&lt;/code&gt;, return the the id of the current worker. (default &lt;code&gt;None&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;worker_name&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt; ) &amp;ndash; 작업자의 문자열 이름입니다. 경우 &lt;code&gt;None&lt;/code&gt; , 현재 노동자의 ID를 반환합니다. (기본값 &lt;code&gt;None&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="bb05a633103b92865e059e320074b5a31b7d0338" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The number of workers in the group.</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 그룹의 작업자 수입니다.</target>
        </trans-unit>
        <trans-unit id="8944fd0aa7e0a543d0eb0d57230c998dddc0f01f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The total number of processes using the store</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 저장소를 사용하는 총 프로세스 수</target>
        </trans-unit>
        <trans-unit id="4b40d216b7322f8dca0f99cbebec725fe60f6e0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The total number of store users (number of clients + 1 for the server).</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 총 상점 사용자 수 (클라이언트 수 + 서버의 경우 1).</target>
        </trans-unit>
        <trans-unit id="d09ea2fd888d7766224d3eb255ea7484752c0c9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Number of processes participating in the job. Required if &lt;code&gt;store&lt;/code&gt; is specified.</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 작업에 참여하는 프로세스 수. &lt;code&gt;store&lt;/code&gt; 이 지정된 경우 필수 입니다.</target>
        </trans-unit>
        <trans-unit id="e6ab46733a3cf79484335cfec30ffadc77125f0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;wrap&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; the diagonal &amp;lsquo;wrapped&amp;rsquo; after N columns for tall matrices.</source>
          <target state="translated">&lt;strong&gt;wrap&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt; ) &amp;ndash; tall 형 행렬에 대해 N 열 뒤에 '래핑 된'대각선입니다.</target>
        </trans-unit>
        <trans-unit id="039b003cafbdb956a808db4a8f6a45acd6067df8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input tensor of shape</source>
          <target state="translated">&lt;strong&gt;x1&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양의 입력 텐서</target>
        </trans-unit>
        <trans-unit id="4e34f43957ff13fc9b613484e5941ff19da8a3ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x1&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; First input.</source>
          <target state="translated">&lt;strong&gt;x1&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 첫 번째 입력.</target>
        </trans-unit>
        <trans-unit id="8c4e3cfe4db7965d9ad32d9b63db999f3ce5916d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input tensor of shape</source>
          <target state="translated">&lt;strong&gt;x2&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양의 입력 텐서</target>
        </trans-unit>
        <trans-unit id="3da2f4cab51d1d5ba9a574263a3bb5682b0875ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Second input (of size matching x1).</source>
          <target state="translated">&lt;strong&gt;x2&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 두 번째 입력 (x1과 일치하는 크기).</target>
        </trans-unit>
        <trans-unit id="b14756a562cc7fda7e1454cc0eb57d083473e78a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D input tensor.</source>
          <target state="translated">&lt;strong&gt;x&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 1-D 입력 텐서.</target>
        </trans-unit>
        <trans-unit id="8604fc9ce7b9564333699bb4a5095a672bbc3ef3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The points at which the function &lt;code&gt;y&lt;/code&gt; is sampled. If &lt;code&gt;x&lt;/code&gt; is not in ascending order, intervals on which it is decreasing contribute negatively to the estimated integral (i.e., the convention</source>
          <target state="translated">&lt;strong&gt;x&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 함수 &lt;code&gt;y&lt;/code&gt; 가 샘플링 되는 지점 입니다. &lt;code&gt;x&lt;/code&gt; 가 오름차순이 아닌 경우 감소하는 간격은 추정 된 적분에 부정적으로 기여합니다 (예 :</target>
        </trans-unit>
        <trans-unit id="e7876837160f02de9f8a91a92f6b6e1b84b26b5d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; value (if :attr:x is a scalar) or values selected at indices where &lt;code&gt;condition&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;x&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt; ) &amp;ndash; 값 (: attr : x가 스칼라 인 경우) 또는 &lt;code&gt;condition&lt;/code&gt; 이 &lt;code&gt;True&lt;/code&gt; 인 인덱스에서 선택된 값</target>
        </trans-unit>
        <trans-unit id="c68f34fbda8cdacd4cc4e099cfcd5fcf6cc52209" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;y&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The values of the function to integrate</source>
          <target state="translated">&lt;strong&gt;y&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 통합 할 함수의 값</target>
        </trans-unit>
        <trans-unit id="72163565538ba72a52711498c5bfc9bb0d1c872a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;y&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; value (if :attr:x is a scalar) or values selected at indices where &lt;code&gt;condition&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;y&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;또는 &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt; ) &amp;ndash; 값 (: attr : x가 스칼라 인 경우) 또는 &lt;code&gt;condition&lt;/code&gt; 이 &lt;code&gt;False&lt;/code&gt; 인 인덱스에서 선택된 값</target>
        </trans-unit>
        <trans-unit id="3ba6c96ac6975a47208ccc9a0b52c75bb531c910" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_infinity&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether to zero infinite losses and the associated gradients. Default: &lt;code&gt;False&lt;/code&gt; Infinite losses mainly occur when the inputs are too short to be aligned to the targets.</source>
          <target state="translated">&lt;strong&gt;zero_infinity&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 무한 손실 및 관련 기울기를 0으로 설정할지 여부입니다. 기본값 : &lt;code&gt;False&lt;/code&gt; 무한 손실은 주로 입력이 너무 짧아 대상에 맞출 수 없을 때 발생합니다.</target>
        </trans-unit>
        <trans-unit id="8638d6633ab7a4cf4da345720cc4bf2ac60e6815" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point, dtype&lt;/strong&gt; (&lt;em&gt;`scale`&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;영점, dtype&lt;/strong&gt; ( &lt;em&gt;` &lt;/em&gt;&lt;strong&gt;scale` &lt;/strong&gt;&lt;em&gt;,&lt;/em&gt; ) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="a1615df751082d4be9fb7cb31b4bb34695adfb0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; quantization zero point of the output tensor</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; 출력 텐서의 양자화 영점</target>
        </trans-unit>
        <trans-unit id="7247c88b2e908aea42f2ec3b7339d9a256569c09" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; quantization zero_point for the output. Default: 0</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; 출력을위한 양자화 zero_point. 기본값 : 0</target>
        </trans-unit>
        <trans-unit id="c2f7a803cb5fc582e2a288ee7168564bc33aa879" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; zero_point of output Quantized Tensor</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; 출력 양자화 된 텐서의 zero_point</target>
        </trans-unit>
        <trans-unit id="223a725fe4e09c854eee949c752211f3d9820057" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; offset in integer value that maps to float zero</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; float 0에 매핑되는 정수 값의 오프셋</target>
        </trans-unit>
        <trans-unit id="4989efaac53b9d7d2d13c26d99d3def10531a636" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; (&lt;em&gt;long&lt;/em&gt;) &amp;ndash; output zero point. If None, derived from the input zero_point</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; ( &lt;em&gt;long&lt;/em&gt; ) &amp;ndash; 출력 영점. None이면 입력 zero_point에서 파생 됨</target>
        </trans-unit>
        <trans-unit id="429279404949d69c49587e68892b656c79b73f46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; - quantization zero point of the output, type: long.</source>
          <target state="translated">&lt;strong&gt;zero_point-&lt;/strong&gt; 출력의 양자화 제로 포인트, 유형 : long.</target>
        </trans-unit>
        <trans-unit id="ffac724f17c0594d2ca1937a69bcfaf236dd1829" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_points&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; integer 1D tensor of offset to use, size should match &lt;code&gt;input.size(axis)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;zero_points&lt;/strong&gt; ( &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt; ) &amp;ndash; 사용할 오프셋의 정수 1D 텐서, 크기는 &lt;code&gt;input.size(axis)&lt;/code&gt; 와 일치해야합니다.</target>
        </trans-unit>
        <trans-unit id="47893dd3bbacac551e16f1ea5a7f8a26eeaf9113" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;{input}&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;{input}&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="20c4529cd2a28cc535afcdbc8ecd226b45340d70" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;{out}&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;{out}&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="b7c764a4f83bf4672db31e3ba964ce2216c4e083" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Bilinear.bias&lt;/strong&gt; &amp;ndash; the learnable bias of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Bilinear.bias&lt;/strong&gt; &amp;ndash; 모양 모듈의 학습 가능한 편향</target>
        </trans-unit>
        <trans-unit id="f89b33be0a086eb9b0633fea112be0da1cf2bd2d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Bilinear.weight&lt;/strong&gt; &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Bilinear.weight&lt;/strong&gt; &amp;ndash; 모양 모듈의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="786e19415c7aa959d92f4e6681a37e6161c762ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;~ Conv1d.bias&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈 (out_channels)의 학습 가능한 편향. 경우 &lt;code&gt;bias&lt;/code&gt; 입니다 &lt;code&gt;True&lt;/code&gt; , 이들 가중치의 값에서 샘플링</target>
        </trans-unit>
        <trans-unit id="e06e33e99b955e617b52597dc55cd653ebf70f55" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.scale&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output scale</source>
          <target state="translated">&lt;strong&gt;~ Conv1d.scale&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 스케일에 대한 스칼라</target>
        </trans-unit>
        <trans-unit id="54e6f2689f69e48b8f9ee81ce716072bcf839a90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Conv1d.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="2b1b80d43979766fbec56a2cf03434689febed6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; packed tensor derived from the learnable weight parameter.</source>
          <target state="translated">&lt;strong&gt;~ Conv1d.weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 학습 가능한 가중치 매개 변수에서 파생 된 패킹 된 텐서입니다.</target>
        </trans-unit>
        <trans-unit id="7fe271f7c736601cbe58a60730d1ba367c3b713a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.zero_point&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output zero point</source>
          <target state="translated">&lt;strong&gt;~ Conv1d.zero_point&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 영점에 대한 스칼라</target>
        </trans-unit>
        <trans-unit id="cab585d0b3b7a1e8311f27f86e9c9020f1f22fd7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;~ Conv2d.bias&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈 (out_channels)의 학습 가능한 편향. 경우 &lt;code&gt;bias&lt;/code&gt; 입니다 &lt;code&gt;True&lt;/code&gt; , 이들 가중치의 값에서 샘플링</target>
        </trans-unit>
        <trans-unit id="491e2d85ab2736d7aafefcdd0aaf9951c3be3bd0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.scale&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output scale</source>
          <target state="translated">&lt;strong&gt;~ Conv2d.scale&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 스케일에 대한 스칼라</target>
        </trans-unit>
        <trans-unit id="1dbb931cba576b031f6690c20c53e86c7d5dd799" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Conv2d.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="bbb22808d75f21da185917b5905c1df4c0e208f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; packed tensor derived from the learnable weight parameter.</source>
          <target state="translated">&lt;strong&gt;~ Conv2d.weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 학습 가능한 가중치 매개 변수에서 파생 된 패킹 된 텐서.</target>
        </trans-unit>
        <trans-unit id="b3438ce5dca3a7cf14dc3bcf4aa9bbd6b0f92e36" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;~ Conv2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; 가중치에 대한 가짜 퀀트 모듈</target>
        </trans-unit>
        <trans-unit id="7b8c7c333216763559ed33e7c4b13fa4f678413a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.zero_point&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output zero point</source>
          <target state="translated">&lt;strong&gt;~ Conv2d.zero_point&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 영점에 대한 스칼라</target>
        </trans-unit>
        <trans-unit id="e2b641a6ffee3b2c43dbc8fe09c7d0c721cd8b22" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;~ Conv3d.bias&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈 (out_channels)의 학습 가능한 편향. 경우 &lt;code&gt;bias&lt;/code&gt; 입니다 &lt;code&gt;True&lt;/code&gt; , 이들 가중치의 값에서 샘플링</target>
        </trans-unit>
        <trans-unit id="aa18d65289a64a7ca20ed8be2d410df1bdc536a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.scale&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output scale</source>
          <target state="translated">&lt;strong&gt;~ Conv3d.scale&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 스케일에 대한 스칼라</target>
        </trans-unit>
        <trans-unit id="a72fbf59ce9ea685622e291418b9e3268a772b76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Conv3d.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="a3ad7c44a3e4e0fbec86bf00ce697cd744bb9a39" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; packed tensor derived from the learnable weight parameter.</source>
          <target state="translated">&lt;strong&gt;~ Conv3d.weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 학습 가능한 가중치 매개 변수에서 파생 된 패킹 된 텐서.</target>
        </trans-unit>
        <trans-unit id="99396f2687699c53375347ac0faddcdc798b2e6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.zero_point&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output zero point</source>
          <target state="translated">&lt;strong&gt;~ Conv3d.zero_point&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 출력 영점에 대한 스칼라</target>
        </trans-unit>
        <trans-unit id="378d1f43230566f1da52f54e6a88d20a5d7790c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvBn2d.freeze_bn&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;~ ConvBn2d.freeze_bn&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="d3bca18d068926bc6367e11701b6f03abca19647" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvBn2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;~ ConvBn2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; 가중치에 대한 가짜 퀀트 모듈</target>
        </trans-unit>
        <trans-unit id="a55571977e6df390a36d65d847d2bb319eff0223" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvBnReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;~ ConvBnReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; 가중치를위한 가짜 퀀트 모듈</target>
        </trans-unit>
        <trans-unit id="ebcdaceff86165d2388fbceb90c8330fe2a56cad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;~ ConvReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; 가중치에 대한 가짜 퀀트 모듈</target>
        </trans-unit>
        <trans-unit id="e9364c34d7f64012a1bdca3fb740fa3d412f113d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose1d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;~ ConvTranspose1d.bias&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈 (out_channels)의 학습 가능한 편향. 경우 &lt;code&gt;bias&lt;/code&gt; 입니다 &lt;code&gt;True&lt;/code&gt; , 이들 가중치의 값에서 샘플링</target>
        </trans-unit>
        <trans-unit id="a79a77bf8698fc3e5d49fe813734ef802e085354" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose1d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ ConvTranspose1d.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="aa3f13f16be4b75d562347e054c32c5197265a17" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose2d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels) If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;~ ConvTranspose2d.bias&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 가능한 편향 (out_channels) &lt;code&gt;bias&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 이면 이러한 가중치의 값은 다음에서 샘플링됩니다.</target>
        </trans-unit>
        <trans-unit id="53cb49c11f8899c6db6dd4eb8c1f8305369a4456" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose2d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ ConvTranspose2d.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="114696aaba144dbc47af743af9b2db6c274492f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose3d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels) If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;~ ConvTranspose3d.bias&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 형태 모듈의 학습 가능한 편향 (out_channels) &lt;code&gt;bias&lt;/code&gt; 가 &lt;code&gt;True&lt;/code&gt; 이면 이러한 가중치의 값은 다음에서 샘플링됩니다.</target>
        </trans-unit>
        <trans-unit id="b02b6fb26cf3d035db5c31efc0adbe6ef4663d46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose3d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ ConvTranspose3d.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="97aab65ac8b5ca1756a2ee2ae4334c7bb0f4c4cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~DataParallel.module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; the module to be parallelized</source>
          <target state="translated">&lt;strong&gt;~ DataParallel.module&lt;/strong&gt; ( &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt; ) &amp;ndash; 병렬화 할 모듈</target>
        </trans-unit>
        <trans-unit id="7badf98694d23be19ae92b4f0b3ca4ed320885bb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~DistributedDataParallel.module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; the module to be parallelized.</source>
          <target state="translated">&lt;strong&gt;~ DistributedDataParallel.module&lt;/strong&gt; ( &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt; ) &amp;ndash; 병렬화 할 모듈입니다.</target>
        </trans-unit>
        <trans-unit id="4a07a3b857af99d25c9450da6034aa156ec65dd7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Embedding.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape (num_embeddings, embedding_dim) initialized from</source>
          <target state="translated">&lt;strong&gt;~ Embedding.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 초기화 된 모양 모듈 (num_embeddings, embedding_dim)의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="4792bf3140649d4ebb921e27eb721fd115e1989e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~EmbeddingBag.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape &lt;code&gt;(num_embeddings, embedding_dim)&lt;/code&gt; initialized from</source>
          <target state="translated">&lt;strong&gt;~ EmbeddingBag.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 초기화 된 형태 모듈 &lt;code&gt;(num_embeddings, embedding_dim)&lt;/code&gt; 의 학습 가능한 가중치</target>
        </trans-unit>
        <trans-unit id="486db63a3b0eb7b18fc654f2a679c9e1761d4529" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.bias_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;~ GRU.bias_hh_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 숨겨진 숨겨진 편향</target>
        </trans-unit>
        <trans-unit id="568c0d45242b2e051763f666ab66932f82363330" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.bias_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;~ GRU.bias_ih_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 입력 숨겨진 편향</target>
        </trans-unit>
        <trans-unit id="b93874bd3ab7dfbc56dd2f71474633014b2b0a34" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.weight_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;~ GRU.weight_hh_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 숨겨진 숨겨진 가중치</target>
        </trans-unit>
        <trans-unit id="9a37d1757288e74e92d126a36c7070cd51271da9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.weight_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;~ GRU.weight_ih_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 입력 숨김 가중치</target>
        </trans-unit>
        <trans-unit id="397fce9905ce991267cadb4abd4e3c29554129d2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.bias_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias, of shape &lt;code&gt;(3*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ GRUCell.bias_hh&lt;/strong&gt; &amp;ndash; 학습 가능한 은닉 형 편향 &lt;code&gt;(3*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="98348f5219246cc6f34a9fbbfd7a43291f274e65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.bias_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias, of shape &lt;code&gt;(3*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ GRUCell.bias_ih&lt;/strong&gt; &amp;ndash; 학습 가능한 입력 숨겨진 편향, 형태 &lt;code&gt;(3*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4b4ebd2844961149a79509e03328089d66209c3c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.weight_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights, of shape &lt;code&gt;(3*hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ GRUCell.weight_hh&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(3*hidden_size, hidden_size)&lt;/code&gt; 의 학습 가능한 숨겨진 숨겨진 가중치</target>
        </trans-unit>
        <trans-unit id="3cae575d5f85368dddcd51b697fe12eaeafcac2f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.weight_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights, of shape &lt;code&gt;(3*hidden_size, input_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ GRUCell.weight_ih&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(3*hidden_size, input_size)&lt;/code&gt; 의 학습 가능한 입력 숨김 가중치</target>
        </trans-unit>
        <trans-unit id="67b82474914eb62986326c4401fa4d0253bcf5b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.bias_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;~ LSTM.bias_hh_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 숨겨진 숨겨진 편향</target>
        </trans-unit>
        <trans-unit id="418dca198dc36225a9737c2df2779e304936c820" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.bias_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;~ LSTM.bias_ih_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 입력 숨겨진 편향</target>
        </trans-unit>
        <trans-unit id="761d7bd5940b869c800a8cec2a3765c298134c32" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.weight_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;~ LSTM.weight_hh_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 숨겨진 숨겨진 가중치</target>
        </trans-unit>
        <trans-unit id="8ba84e472b18b379b7629198d242e16cefb87b3a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.weight_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;~ LSTM.weight_ih_l [k]&lt;/strong&gt; &amp;ndash; 학습 가능한 입력 숨겨진 가중치</target>
        </trans-unit>
        <trans-unit id="e9139487e553f7287b9b802b6302d1d46e37ac6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.bias_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias, of shape &lt;code&gt;(4*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ LSTMCell.bias_hh&lt;/strong&gt; &amp;ndash; 학습 가능한 은닉 형 편향 &lt;code&gt;(4*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="896732c137e496c5eb6b474667fdc650df4d1ba0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.bias_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias, of shape &lt;code&gt;(4*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ LSTMCell.bias_ih&lt;/strong&gt; &amp;ndash; 학습 가능한 입력 은닉 편향, 형태 &lt;code&gt;(4*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="83260aa680a5b73dc2123fca87588a53fe5ecabb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.weight_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights, of shape &lt;code&gt;(4*hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ LSTMCell.weight_hh&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(4*hidden_size, hidden_size)&lt;/code&gt; 의 학습 가능한 숨겨진 숨겨진 가중치</target>
        </trans-unit>
        <trans-unit id="ef0a5b92b7bdcb40d6493138f43418d1354cc221" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.weight_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights, of shape &lt;code&gt;(4*hidden_size, input_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ LSTMCell.weight_ih&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(4*hidden_size, input_size)&lt;/code&gt; 의 학습 가능한 입력 숨김 가중치</target>
        </trans-unit>
        <trans-unit id="d0bff85ad6b7e10c45ded2385264495acab8f4ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.bias&lt;/strong&gt; &amp;ndash; the learnable bias of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Linear.bias&lt;/strong&gt; &amp;ndash; 모양 모듈의 학습 가능한 편향</target>
        </trans-unit>
        <trans-unit id="ae7d6b9dea3f23c1bf0ec9b92c65617e42b54758" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.bias&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the non-learnable bias of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Linear.bias&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 불가능한 편향</target>
        </trans-unit>
        <trans-unit id="fb2839a507719a2a7e1c7f3c45c3a78738935aff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.scale&lt;/strong&gt; &amp;ndash; &lt;code&gt;scale&lt;/code&gt; parameter of output Quantized Tensor, type: double</source>
          <target state="translated">&lt;strong&gt;~ Linear.scale&lt;/strong&gt; &amp;ndash; 출력 Quantized Tensor의 &lt;code&gt;scale&lt;/code&gt; 매개 변수, 유형 : double</target>
        </trans-unit>
        <trans-unit id="aa119f3519a628ea703e857ef172d9d75ef8b21f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.weight&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;~ Linear.weight&lt;/strong&gt; &amp;ndash; 가중치를위한 가짜 &lt;strong&gt;퀀텀&lt;/strong&gt; 모듈</target>
        </trans-unit>
        <trans-unit id="315c79b44e7a362abc428a093029318a5cb6ebc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.weight&lt;/strong&gt; &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Linear.weight&lt;/strong&gt; &amp;ndash; 학습 가능한 형태 모듈의 가중치</target>
        </trans-unit>
        <trans-unit id="74afca0120ba709897a38dc272bc9981208e2d0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the non-learnable quantized weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;~ Linear.weight&lt;/strong&gt; ( &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 모양 모듈의 학습 불가능한 양자화 된 가중치</target>
        </trans-unit>
        <trans-unit id="3afcb3e4388b0cbfaa40fe5fcad92e725f9bf434" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.zero_point&lt;/strong&gt; &amp;ndash; &lt;code&gt;zero_point&lt;/code&gt; parameter for output Quantized Tensor, type: long</source>
          <target state="translated">&lt;strong&gt;~ Linear.zero_point&lt;/strong&gt; &amp;ndash; Quantized Tensor 출력을위한 &lt;code&gt;zero_point&lt;/code&gt; 매개 변수, 유형 : long</target>
        </trans-unit>
        <trans-unit id="522c0534c3e108071d6f81950228abd00552637b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LinearReLU.weight&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;~ LinearReLU.weight&lt;/strong&gt; &amp;ndash; 가중치를위한 가짜 퀀트 모듈</target>
        </trans-unit>
        <trans-unit id="8895a1b0c2e6107ada5018ca16d43d982c7d6188" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PReLU.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of shape (&lt;code&gt;num_parameters&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;~ PReLU.weight&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 학습 가능한 모양 가중치 ( &lt;code&gt;num_parameters&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="cc864c7bcceabd4bb9ba42bcf609c115c46dde97" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.batch_sizes&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor of integers holding information about the batch size at each sequence step</source>
          <target state="translated">&lt;strong&gt;~ PackedSequence.batch_sizes&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 각 시퀀스 단계에서 배치 크기에 대한 정보를 보유하는 정수 텐서</target>
        </trans-unit>
        <trans-unit id="2e648b81d63ca51e2c59bfb2670172ffa0bdcd12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor containing packed sequence</source>
          <target state="translated">&lt;strong&gt;~ PackedSequence.data&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; ) &amp;ndash; 패킹 된 시퀀스를 포함하는 Tensor</target>
        </trans-unit>
        <trans-unit id="21b5da5ef8600388a81b311dc469708b1a243874" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.sorted_indices&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tensor of integers holding how this &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;PackedSequence&lt;/code&gt;&lt;/a&gt; is constructed from sequences.</source>
          <target state="translated">&lt;strong&gt;~ PackedSequence.sorted_indices&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash;이 &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;PackedSequence&lt;/code&gt; &lt;/a&gt; 가 시퀀스에서 어떻게 구성 되는지를 담는 정수 텐서 .</target>
        </trans-unit>
        <trans-unit id="2f61547990dd4c37a589c3d1c949f534ce964d34" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.unsorted_indices&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tensor of integers holding how this to recover the original sequences with correct order.</source>
          <target state="translated">&lt;strong&gt;~ PackedSequence.unsorted_indices&lt;/strong&gt; ( &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt; ) &amp;ndash; 올바른 순서로 원래 시퀀스를 복구하는 방법을 보유하는 정수 텐서.</target>
        </trans-unit>
        <trans-unit id="235904bb81615face6c03f7fdd0762f01a44c648" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.bias_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias of the k-th layer, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNN.bias_hh_l [k]&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(hidden_size)&lt;/code&gt; 의 k 번째 계층의 학습 가능한 은닉 형 편향</target>
        </trans-unit>
        <trans-unit id="e8ba0fa05da47543bfecbc4b3d0f4f691b034e37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.bias_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias of the k-th layer, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNN.bias_ih_l [k]&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(hidden_size)&lt;/code&gt; 의 k 번째 레이어의 학습 가능한 입력 은닉 편향</target>
        </trans-unit>
        <trans-unit id="fe5a76d8bdd2bfbda4a600d6f968bab8b67aadc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.weight_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights of the k-th layer, of shape &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNN.weight_hh_l [k]&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt; 의 k 번째 계층의 학습 가능한 숨겨진 숨겨진 가중치</target>
        </trans-unit>
        <trans-unit id="6b55d7debcf00b4a9aace4971974309ba4880f3c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.weight_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights of the k-th layer, of shape &lt;code&gt;(hidden_size, input_size)&lt;/code&gt; for &lt;code&gt;k = 0&lt;/code&gt;. Otherwise, the shape is &lt;code&gt;(hidden_size, num_directions * hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNN.weight_ih_l [k]&lt;/strong&gt; &amp;ndash; &lt;code&gt;k = 0&lt;/code&gt; 대한 모양 &lt;code&gt;(hidden_size, input_size)&lt;/code&gt; 의 k 번째 레이어의 학습 가능한 입력 숨김 가중치 . 그렇지 않으면 모양은 &lt;code&gt;(hidden_size, num_directions * hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2d2a5ac7fe67f4afaa29c61a8d22a1372b50c310" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.bias_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNNCell.bias_hh&lt;/strong&gt; &amp;ndash; 형태 &lt;code&gt;(hidden_size)&lt;/code&gt; 의 학습 가능한 은닉 편향</target>
        </trans-unit>
        <trans-unit id="ca09dd35f6974547104a869f45041f8189618781" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.bias_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNNCell.bias_ih&lt;/strong&gt; &amp;ndash; 학습 가능한 입력 숨김 편향, 형태 &lt;code&gt;(hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5b9525f25b880e8e32703e40cb26509bc4d00f20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.weight_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights, of shape &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNNCell.weight_hh&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt; 의 학습 가능한 숨겨진 숨겨진 가중치</target>
        </trans-unit>
        <trans-unit id="6fdb4b833f363ac5882e1551bb76b1d609be001c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.weight_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights, of shape &lt;code&gt;(hidden_size, input_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;~ RNNCell.weight_ih&lt;/strong&gt; &amp;ndash; 모양 &lt;code&gt;(hidden_size, input_size)&lt;/code&gt; 의 학습 가능한 입력 숨김 가중치</target>
        </trans-unit>
        <trans-unit id="4363d72fe0148f9fd5bda59b03b2597b475ecb3d" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;hidden_size&lt;/code&gt; Defaults to zero if not provided.</source>
          <target state="translated">= &lt;code&gt;hidden_size&lt;/code&gt; 제공되지 않은 경우 기본값은 0입니다.</target>
        </trans-unit>
        <trans-unit id="76c6be0a47b9e469e03f3d72ce03df30479e07c5" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;input_size&lt;/code&gt;</source>
          <target state="translated">= 입력 &lt;code&gt;input_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="22b30cde9b5535b0a766c1d74e242d402d5dfdfd" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;signal_ndim&lt;/code&gt; is number of dimensions for the signal, and</source>
          <target state="translated">= &lt;code&gt;signal_ndim&lt;/code&gt; 은 신호의 차원 수이며</target>
        </trans-unit>
        <trans-unit id="74a544e408284dc448cde186b7b615c6eac7a62c" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;signal_ndim&lt;/code&gt;. &lt;code&gt;onesided&lt;/code&gt; flag controls whether to avoid redundancy in the output results. If set to &lt;code&gt;True&lt;/code&gt; (default), the output will not be full complex result of shape</source>
          <target state="translated">= &lt;code&gt;signal_ndim&lt;/code&gt; . &lt;code&gt;onesided&lt;/code&gt; 플래그는 출력 결과에서 중복을 방지할지 여부를 제어합니다. 로 설정하면 &lt;code&gt;True&lt;/code&gt; (기본), 출력은 모양의 전체 복잡한 결과가 될 수 없습니다</target>
        </trans-unit>
        <trans-unit id="f9c16f2184526910dd910a4f6192e4c698a5444c" translate="yes" xml:space="preserve">
          <source>≠</source>
          <target state="translated">≠</target>
        </trans-unit>
        <trans-unit id="6dcd4ce23d88e2ee9568ba546c007c63d9131c1b" translate="yes" xml:space="preserve">
          <source>A</source>
          <target state="translated">A</target>
        </trans-unit>
        <trans-unit id="0ba2b2257c8b8d78f6250b41bc82133cdb8d0d85" translate="yes" xml:space="preserve">
          <source>A (Tensor): the input tensor of size</source>
          <target state="translated">A (텐서) : 크기의 입력 텐서</target>
        </trans-unit>
        <trans-unit id="c771998369e681962e03e40a977496f10f66e4ab" translate="yes" xml:space="preserve">
          <source>A - M</source>
          <target state="translated">A ~ M</target>
        </trans-unit>
        <trans-unit id="163f6731aec462243f49bce7b3f447cfca092a3d" translate="yes" xml:space="preserve">
          <source>A 1-D tensor of size</source>
          <target state="translated">크기의 1 차원 텐서</target>
        </trans-unit>
        <trans-unit id="5ea1abe027131df5fe0f08815006944c348e7434" translate="yes" xml:space="preserve">
          <source>A 2 dimensional tensor with all the input tensors arranged in</source>
          <target state="translated">모든 입력 텐서가 배열 된 2 차원 텐서</target>
        </trans-unit>
        <trans-unit id="2da7899e802f2306f976e1aaf402515d02db4967" translate="yes" xml:space="preserve">
          <source>A 2-D tensor with ones on the diagonal and zeros elsewhere</source>
          <target state="translated">대각선에 1이 있고 다른 곳에 0이있는 2 차원 텐서</target>
        </trans-unit>
        <trans-unit id="94dae2aa29f01378af45a02523af98deeb730db7" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; is a multi-dimensional matrix containing elements of a single data type.</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; 는&lt;/a&gt; 단일 데이터 유형의 요소를 포함하는 다차원 행렬이다.</target>
        </trans-unit>
        <trans-unit id="30862db2302d182cfad7095752f0185b9568d784" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; can be constructed via a string or via a string and device ordinal</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; 은&lt;/a&gt; 스트링을 통해 또는 문자열 및 장치 순서로 구성 될 수있다</target>
        </trans-unit>
        <trans-unit id="24d39a42c40922c085cc28a510764783ea381734" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; is an object representing the device on which a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; is or will be allocated.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; 는&lt;/a&gt; 되는 기기를 나타내는 목적 &lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; 이&lt;/a&gt; 없거나 할당 될 것이다.</target>
        </trans-unit>
        <trans-unit id="194543d5c9873e7986896f48770c7b948114ce57" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; is an object that represents the data type of a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;. PyTorch has twelve different data types:</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; 는&lt;/a&gt; (A)의 데이터 형식을 나타내는 목적 &lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; 를&lt;/a&gt; . PyTorch에는 12 가지 데이터 유형이 있습니다.</target>
        </trans-unit>
        <trans-unit id="38e208177382a27c53d72149eef4e9baaa2dc1d2" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.finfo&quot;&gt;&lt;code&gt;torch.finfo&lt;/code&gt;&lt;/a&gt; is an object that represents the numerical properties of a floating point &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, (i.e. &lt;code&gt;torch.float32&lt;/code&gt;, &lt;code&gt;torch.float64&lt;/code&gt;, and &lt;code&gt;torch.float16&lt;/code&gt;). This is similar to &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.finfo.html&quot;&gt;numpy.finfo&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.finfo&quot;&gt; &lt;code&gt;torch.finfo&lt;/code&gt; 은&lt;/a&gt; 부동 소수점의 수치 적 특성을 나타내는 것을 목적으로한다 &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt; (즉 &lt;code&gt;torch.float32&lt;/code&gt; , &lt;code&gt;torch.float64&lt;/code&gt; 및 &lt;code&gt;torch.float16&lt;/code&gt; 을 ). 이것은 &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.finfo.html&quot;&gt;numpy.finfo&lt;/a&gt; 와 유사합니다 .</target>
        </trans-unit>
        <trans-unit id="e9b5788e7f1ba02d4ce5b044c5845d26ea320e06" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.finfo&quot;&gt;&lt;code&gt;torch.finfo&lt;/code&gt;&lt;/a&gt; provides the following attributes:</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.finfo&quot;&gt; &lt;code&gt;torch.finfo&lt;/code&gt; 는&lt;/a&gt; 다음과 같은 속성을 제공합니다 :</target>
        </trans-unit>
        <trans-unit id="dc99c23c305b6eee6243eadd6e2b8739deea9e14" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.iinfo&quot;&gt;&lt;code&gt;torch.iinfo&lt;/code&gt;&lt;/a&gt; is an object that represents the numerical properties of a integer &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; (i.e. &lt;code&gt;torch.uint8&lt;/code&gt;, &lt;code&gt;torch.int8&lt;/code&gt;, &lt;code&gt;torch.int16&lt;/code&gt;, &lt;code&gt;torch.int32&lt;/code&gt;, and &lt;code&gt;torch.int64&lt;/code&gt;). This is similar to &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.iinfo.html&quot;&gt;numpy.iinfo&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.iinfo&quot;&gt; &lt;code&gt;torch.iinfo&lt;/code&gt; 은&lt;/a&gt; 정수의 숫자를 나타내는 특성 목적 &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; 을&lt;/a&gt; (즉 &lt;code&gt;torch.uint8&lt;/code&gt; , &lt;code&gt;torch.int8&lt;/code&gt; , &lt;code&gt;torch.int16&lt;/code&gt; , &lt;code&gt;torch.int32&lt;/code&gt; 및 &lt;code&gt;torch.int64&lt;/code&gt; ). 이것은 &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.iinfo.html&quot;&gt;numpy.iinfo&lt;/a&gt; 와 유사합니다 .</target>
        </trans-unit>
        <trans-unit id="ea287a33429f2668f3a29b9f646857cd3589f455" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.iinfo&quot;&gt;&lt;code&gt;torch.iinfo&lt;/code&gt;&lt;/a&gt; provides the following attributes:</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.iinfo&quot;&gt; &lt;code&gt;torch.iinfo&lt;/code&gt; 는&lt;/a&gt; 다음과 같은 속성을 제공합니다 :</target>
        </trans-unit>
        <trans-unit id="c2142ddfec581443f517442f35bb15b0be1e58bb" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt; is an object that represents the memory layout of a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;. Currently, we support &lt;code&gt;torch.strided&lt;/code&gt; (dense Tensors) and have beta support for &lt;code&gt;torch.sparse_coo&lt;/code&gt; (sparse COO Tensors).</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; 는&lt;/a&gt; (A)의 메모리 레이아웃 나타내는 목적 &lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; 를&lt;/a&gt; . 현재 우리는 &lt;code&gt;torch.strided&lt;/code&gt; (밀집 텐서)를 지원하고 &lt;code&gt;torch.sparse_coo&lt;/code&gt; (sparse COO Tensor)에 대한 베타 지원을 제공합니다 .</target>
        </trans-unit>
        <trans-unit id="de355853c58ee99175ccddd4a1b61f2e88daa33a" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt; is an object representing the memory format on which a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; is or will be allocated.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; 는&lt;/a&gt; 되는 메모리 포맷을 나타내는 목적 &lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; 이&lt;/a&gt; 없거나 할당 될 것이다.</target>
        </trans-unit>
        <trans-unit id="10fbed407aac8b67f8332747c3e4586eb1dec2dc" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torchscript-class&quot;&gt;TorchScript Class&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torchscript-class&quot;&gt;TorchScript 클래스&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="87a00529d12368e11ecb0951f6020b25b804bf4c" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torchscript-enum&quot;&gt;TorchScript Enum&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torchscript-enum&quot;&gt;TorchScript 열거&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7404dcf6cb59834c3f935967f5f2cff903cab0d1" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; with a single &lt;code&gt;forward&lt;/code&gt; method will have an attribute &lt;code&gt;code&lt;/code&gt;, which you can use to inspect the &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;&amp;rsquo;s code. If the &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; has more than one method, you will need to access &lt;code&gt;.code&lt;/code&gt; on the method itself and not the module. We can inspect the code of a method named &lt;code&gt;foo&lt;/code&gt; on a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; by accessing &lt;code&gt;.foo.code&lt;/code&gt;. The example above produces this output:</source>
          <target state="translated">&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; 하나와 &lt;code&gt;forward&lt;/code&gt; 방법은 속성해야합니다 &lt;code&gt;code&lt;/code&gt; 는 검사하는 데 사용할 수있는, &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; 의 코드를. 는 IF &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 이&lt;/a&gt; 하나 이상의 방법을 가지고, 당신은 액세스가 필요합니다 &lt;code&gt;.code&lt;/code&gt; 방법 자체가 아니라 모듈. &lt;code&gt;.foo.code&lt;/code&gt; 에 액세스 하여 &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 에서&lt;/a&gt; &lt;code&gt;foo&lt;/code&gt; 라는 메서드의 코드를 검사 할 수 있습니다 . 위의 예는 다음 출력을 생성합니다.</target>
        </trans-unit>
        <trans-unit id="fe55e59d1093f23c98c38d66836a27b73eecda96" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/collections.html#collections.namedtuple&quot;&gt;&lt;code&gt;collections.namedtuple&lt;/code&gt;&lt;/a&gt; tuple type</source>
          <target state="translated">&lt;a href=&quot;https://docs.python.org/3/library/collections.html#collections.namedtuple&quot;&gt; &lt;code&gt;collections.namedtuple&lt;/code&gt; 의&lt;/a&gt; 튜플 타입</target>
        </trans-unit>
        <trans-unit id="52f3bfdc6708921215b778992e2b2023ce0cf17c" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that controls where TensorFloat-32 tensor cores may be used in cuDNN convolutions on Ampere or newer GPUs. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat-32(TF32) on Ampere devices&lt;/a&gt;.</source>
          <target state="translated">Ampere 또는 최신 GPU의 cuDNN 회선에서 TensorFloat-32 텐서 코어를 사용할 수있는 위치를 제어 하는 &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt; 입니다. &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;암페어 장치의 TensorFloat-32 (TF32)를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="ee7cf0dafdb20b0870f4ba1b8b3c1c9c0b0961ae" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that controls whether TensorFloat-32 tensor cores may be used in matrix multiplications on Ampere or newer GPUs. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat-32(TF32) on Ampere devices&lt;/a&gt;.</source>
          <target state="translated">TensorFloat-32 텐서 코어를 Ampere 또는 최신 GPU에서 행렬 곱셈에 사용할 수 있는지 여부를 제어 하는 &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt; 입니다. &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;암페어 장치의 TensorFloat-32 (TF32)를&lt;/a&gt; 참조하십시오 .</target>
        </trans-unit>
        <trans-unit id="132439c11835b26ffb69dbea90cbf5ac7df424e2" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that controls whether cuDNN is enabled.</source>
          <target state="translated">cuDNN 사용 여부를 제어 하는 &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="f8f9daed2aeb319caf641cde5cc61730c1047610" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that, if True, causes cuDNN to benchmark multiple convolution algorithms and select the fastest.</source>
          <target state="translated">True 인 경우 cuDNN이 다중 회선 알고리즘을 벤치마킹하고 가장 빠른 알고리즘을 선택하도록 하는 &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="ad8b39b030a50343fcfc5491aa61a98d87ef927a" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that, if True, causes cuDNN to only use deterministic convolution algorithms. See also &lt;a href=&quot;generated/torch.is_deterministic#torch.is_deterministic&quot;&gt;&lt;code&gt;torch.is_deterministic()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.set_deterministic#torch.set_deterministic&quot;&gt;&lt;code&gt;torch.set_deterministic()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">True 인 경우 cuDNN이 결정적 회선 알고리즘 만 사용하도록 하는 &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt; 입니다. &lt;a href=&quot;generated/torch.is_deterministic#torch.is_deterministic&quot;&gt; &lt;code&gt;torch.is_deterministic()&lt;/code&gt; &lt;/a&gt; 및 &lt;a href=&quot;generated/torch.set_deterministic#torch.set_deterministic&quot;&gt; &lt;code&gt;torch.set_deterministic()&lt;/code&gt; &lt;/a&gt; 도 참조하세요 .</target>
        </trans-unit>
        <trans-unit id="363a5bf37cd0bd5599a7ac4f74f15c234a572c9d" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/a&gt; that controls cache capacity of cuFFT plan.</source>
          <target state="translated">cuFFT 계획의 캐시 용량을 제어 하는 &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt; &lt;code&gt;int&lt;/code&gt; &lt;/a&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="15086d30a742ea962251815a98fb5f43c932d666" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;&amp;rsquo;s device can be accessed via the &lt;a href=&quot;tensors#torch.Tensor.device&quot;&gt;&lt;code&gt;Tensor.device&lt;/code&gt;&lt;/a&gt; property.</source>
          <target state="translated">&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt; 의 장치는를 통해 액세스 할 수 &lt;a href=&quot;tensors#torch.Tensor.device&quot;&gt; &lt;code&gt;Tensor.device&lt;/code&gt; 의&lt;/a&gt; 속성.</target>
        </trans-unit>
        <trans-unit id="669a8dfbb51e49ee0a4e2b45cc3fe7e68a5626a0" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object with a single &lt;code&gt;forward&lt;/code&gt; method containing the traced code. When &lt;code&gt;func&lt;/code&gt; is a &lt;code&gt;torch.nn.Module&lt;/code&gt;, the returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; will have the same set of sub-modules and parameters as &lt;code&gt;func&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 의&lt;/a&gt; 단일 객체로 &lt;code&gt;forward&lt;/code&gt; 추적 된 코드를 포함하는 방법. 경우 &lt;code&gt;func&lt;/code&gt; A는 &lt;code&gt;torch.nn.Module&lt;/code&gt; 는 , 반환 &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 는&lt;/a&gt; 서브 모듈과 같은 파라미터들의 집합 같은 것 &lt;code&gt;func&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="41acf1053b0302918ca7cea8e31ad650f225d642" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; 의&lt;/a&gt; 객체입니다.</target>
        </trans-unit>
        <trans-unit id="7ba4764527a7c1083db1bd25ed8621fc70d8ebcb" translate="yes" xml:space="preserve">
          <source>A &lt;code&gt;dim&lt;/code&gt; value within the range &lt;code&gt;[-input.dim() - 1, input.dim() + 1)&lt;/code&gt; can be used. Negative &lt;code&gt;dim&lt;/code&gt; will correspond to &lt;a href=&quot;#torch.unsqueeze&quot;&gt;&lt;code&gt;unsqueeze()&lt;/code&gt;&lt;/a&gt; applied at &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;dim + input.dim() + 1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;dim&lt;/code&gt; 범위 내의 값 &lt;code&gt;[-input.dim() - 1, input.dim() + 1)&lt;/code&gt; 를 사용할 수있다. 네거티브 &lt;code&gt;dim&lt;/code&gt; 에 해당 할 것이다 &lt;a href=&quot;#torch.unsqueeze&quot;&gt; &lt;code&gt;unsqueeze()&lt;/code&gt; &lt;/a&gt; 적용 &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;dim + input.dim() + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a4042276aa29d077b69d47201952f51420b20aea" translate="yes" xml:space="preserve">
          <source>A &lt;code&gt;torch.ByteTensor&lt;/code&gt; which contains all the necessary bits to restore a Generator to a specific point in time.</source>
          <target state="translated">Generator를 특정 시점으로 복원하는 데 필요한 모든 비트를 포함 하는 &lt;code&gt;torch.ByteTensor&lt;/code&gt; 입니다.</target>
        </trans-unit>
        <trans-unit id="651aaa3c833905f7faa2adf76b8bd668ead8cca6" translate="yes" xml:space="preserve">
          <source>A &lt;code&gt;torch.Storage&lt;/code&gt; is a contiguous, one-dimensional array of a single data type.</source>
          <target state="translated">&lt;code&gt;torch.Storage&lt;/code&gt; 는 하나의 데이터 유형의 연속, 1 차원 배열이다.</target>
        </trans-unit>
        <trans-unit id="8d3fcf73542a1b9a5f63963e6df264f067c5be6b" translate="yes" xml:space="preserve">
          <source>A = LL^T</source>
          <target state="translated">A = LL ^ T</target>
        </trans-unit>
        <trans-unit id="9a98c44769eae9961b395c0bbcfcad7880070dff" translate="yes" xml:space="preserve">
          <source>A = U diag(S) V^T</source>
          <target state="translated">A = U diag (S) V ^ T</target>
        </trans-unit>
        <trans-unit id="e0c55a36f7072ee8c943df73addbc18e8cc62aa0" translate="yes" xml:space="preserve">
          <source>A = U^TU</source>
          <target state="translated">A = U ^ TU</target>
        </trans-unit>
        <trans-unit id="1c931baf3955ce6642a1157d462795c45a1e4f6a" translate="yes" xml:space="preserve">
          <source>A Conv2d module attached with FakeQuantize modules for weight, used for quantization aware training.</source>
          <target state="translated">가중치를 위해 FakeQuantize 모듈과 함께 연결된 Conv2d 모듈은 양자화 인식 훈련에 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="72876496e2dc3bd4b4d55b0ee6148f21eda8c0c7" translate="yes" xml:space="preserve">
          <source>A ConvBn2d module is a module fused from Conv2d and BatchNorm2d, attached with FakeQuantize modules for weight, used in quantization aware training.</source>
          <target state="translated">ConvBn2d 모듈은 Conv2d와 BatchNorm2d가 융합 된 모듈로, 가중치를 위해 FakeQuantize 모듈이 부착되어 양자화 인식 훈련에 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="096a086e744907bafa054ddb3c822576842bca8b" translate="yes" xml:space="preserve">
          <source>A ConvBnReLU2d module is a module fused from Conv2d, BatchNorm2d and ReLU, attached with FakeQuantize modules for weight, used in quantization aware training.</source>
          <target state="translated">ConvBnReLU2d 모듈은 Conv2d, BatchNorm2d 및 ReLU에서 융합 된 모듈로, 가중치 용 FakeQuantize 모듈이 부착되어 양자화 인식 교육에 사용됩니다.</target>
        </trans-unit>
        <trans-unit id="6056ceba54b6d5f2f7479fdf0420885d4c9ee2d7" translate="yes" xml:space="preserve">
          <source>A ConvReLU2d module is a fused module of Conv2d and ReLU</source>
          <target state="translated">ConvReLU2d 모듈은 Conv2d와 ReLU가 결합 된 모듈입니다.</target>
        </trans-unit>
        <trans-unit id="2680c03e7de7a88804eb33c2fdac5905f71c50af" translate="yes" xml:space="preserve">
          <source>A ConvReLU2d module is a fused module of Conv2d and ReLU, attached with FakeQuantize modules for weight for quantization aware training.</source>
          <target state="translated">ConvReLU2d 모듈은 Conv2d와 ReLU의 융합 모듈로, 양자화 인식 훈련을위한 가중치를 위해 FakeQuantize 모듈이 부착되어 있습니다.</target>
        </trans-unit>
        <trans-unit id="6f481e2f39df1d5e690d89d168813ffb2098eecf" translate="yes" xml:space="preserve">
          <source>A ConvReLU3d module is a fused module of Conv3d and ReLU</source>
          <target state="translated">ConvReLU3d 모듈은 Conv3d와 ReLU가 결합 된 모듈입니다.</target>
        </trans-unit>
        <trans-unit id="c581294889f60e363c7316ff06c75be3343c616d" translate="yes" xml:space="preserve">
          <source>A LinearReLU module fused from Linear and ReLU modules</source>
          <target state="translated">Linear 및 ReLU 모듈에서 융합 된 LinearReLU 모듈</target>
        </trans-unit>
        <trans-unit id="d75cf067e6cff790d10b968c6dfc06b15a74c001" translate="yes" xml:space="preserve">
          <source>A LinearReLU module fused from Linear and ReLU modules, attached with FakeQuantize modules for weight, used in quantization aware training.</source>
          <target state="translated">양자화 인식 훈련에 사용되는 가중치 용 FakeQuantize 모듈과 함께 연결된 Linear 및 ReLU 모듈에서 융합 된 LinearReLU 모듈입니다.</target>
        </trans-unit>
        <trans-unit id="f014741eaa3c28d99fb30934bea4ac8630cb0954" translate="yes" xml:space="preserve">
          <source>A PyTorch tensor of any dtype, dimension, or backend</source>
          <target state="translated">모든 dtype, 차원 또는 백엔드의 PyTorch 텐서</target>
        </trans-unit>
        <trans-unit id="606edcfedaa2aed46ccbb45e395a66931ad76205" translate="yes" xml:space="preserve">
          <source>A TCP-based distributed key-value store implementation. The server store holds the data, while the client stores can connect to the server store over TCP and perform actions such as &lt;code&gt;set()&lt;/code&gt; to insert a key-value pair, &lt;code&gt;get()&lt;/code&gt; to retrieve a key-value pair, etc.</source>
          <target state="translated">TCP 기반 분산 키-값 저장소 구현입니다. 서버 저장소는 데이터를 보유하고 클라이언트 저장소는 TCP를 통해 서버 저장소에 연결 하고 키-값 쌍을 삽입하는 &lt;code&gt;set()&lt;/code&gt; , 키-값 쌍 을 검색하는 &lt;code&gt;get()&lt;/code&gt; 등과 같은 작업을 수행 할 수 있습니다 .</target>
        </trans-unit>
        <trans-unit id="934bb2f6ce37592fed6983ebae538926df9a870a" translate="yes" xml:space="preserve">
          <source>A Tensor with the same shape as the input, except with &lt;code&gt;dim&lt;/code&gt; removed. Each element of the returned tensor represents the estimated integral</source>
          <target state="translated">&lt;code&gt;dim&lt;/code&gt; 제거 된 것을 제외하고 입력과 동일한 모양을 가진 Tensor . 반환 된 텐서의 각 요소는 추정 된 적분을 나타냅니다.</target>
        </trans-unit>
        <trans-unit id="ba88f3b238bb390167a791ceb442cf7b95e4e5ce" translate="yes" xml:space="preserve">
          <source>A \approx U diag(S) V^T</source>
          <target state="translated">A \ 대략 U diag (S) V ^ T</target>
        </trans-unit>
        <trans-unit id="448d4ffe506866b86729dc826b5e940db7f330bc" translate="yes" xml:space="preserve">
          <source>A boolean output tensor cannot accept a non-boolean tensor.</source>
          <target state="translated">부울 출력 텐서는 부울이 아닌 텐서를 허용 할 수 없습니다.</target>
        </trans-unit>
        <trans-unit id="575d060b7c5e05a4efb184af85c6381a6c7e4517" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is NaN and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 NaN이고 다른 곳에서는 False 인 True 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="a32a86eb86fd42f1d26cffcd478d118053b7a4fa" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 &lt;code&gt;other&lt;/code&gt; 것과 같고 다른 곳에서는 False 인 경우 True 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="158a2b9240f238280e9de635efb432409a1f50cc" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is finite and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 유한하고 다른 곳에서는 False 인 True 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="80aa5dd6aaf0df9d8b8247b87a9a03b74284fb4e" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is greater than &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 &lt;code&gt;other&lt;/code&gt; 것보다 크면 True이고 다른 곳에서는 False 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="0ab5ab93711aaebbc75e0a5f02857973e9b97aab" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is greater than or equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 &lt;code&gt;other&lt;/code&gt; 것보다 크거나 같고 다른 곳에서는 False 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="db5355275d060aecda9b99bd049b1fb3bb2b5999" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is infinite and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 무한하고 다른 곳에서는 False 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="d1a62ed7f7827621e58d59ed2687cad0159c8094" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is less than &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 &lt;code&gt;other&lt;/code&gt; 것보다 적고 다른 곳에서는 False 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="3c0627ce37f19d66b3d1de89c44e210f0dac3318" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is less than or equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 &lt;code&gt;other&lt;/code&gt; 것보다 작거나 같고 다른 곳에서는 False 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="a1eaf30e5ae09b5f416d4f43e58dcb2543097d23" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is not equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 &lt;code&gt;other&lt;/code&gt; 것과 같지 않은 True이고 다른 곳에서는 False 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="8e7be5071d915aabc81f850d18a45204a8c662e6" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is real and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 이 실수이고 다른 곳에서는 False 인 부울 텐서</target>
        </trans-unit>
        <trans-unit id="cd05f7a1045f3d5c6441bd51c29203b6005476c5" translate="yes" xml:space="preserve">
          <source>A boolean value</source>
          <target state="translated">부울 값</target>
        </trans-unit>
        <trans-unit id="aa26eb075c756a3b55b4838f819fe3b9550e2c75" translate="yes" xml:space="preserve">
          <source>A common PyTorch convention is to save tensors using .pt file extension.</source>
          <target state="translated">일반적인 PyTorch 규칙은 .pt 파일 확장자를 사용하여 텐서를 저장하는 것입니다.</target>
        </trans-unit>
        <trans-unit id="476d5990029ab426aac50c8ed35adab4427abf1f" translate="yes" xml:space="preserve">
          <source>A context manager to be used in conjunction with an instance of &lt;a href=&quot;#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt;&lt;/a&gt; to be able to train with uneven inputs across participating processes.</source>
          <target state="translated">참여하는 프로세스에서 고르지 않은 입력으로 학습 할 수 있도록 &lt;a href=&quot;#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt; &lt;/a&gt; 의 인스턴스와 함께 사용할 컨텍스트 관리자 입니다.</target>
        </trans-unit>
        <trans-unit id="260ba8ca717d75756a968a13317edb397e545889" translate="yes" xml:space="preserve">
          <source>A context manager to disable gradient synchronizations across DDP processes. Within this context, gradients will be accumulated on module variables, which will later be synchronized in the first forward-backward pass exiting the context.</source>
          <target state="translated">DDP 프로세스에서 그래디언트 동기화를 비활성화하는 컨텍스트 관리자. 이 컨텍스트 내에서 그래디언트는 모듈 변수에 누적되며 나중에 컨텍스트를 종료하는 첫 번째 앞뒤 패스에서 동기화됩니다.</target>
        </trans-unit>
        <trans-unit id="f56526cfd84150a791f8131f272572b491286ff2" translate="yes" xml:space="preserve">
          <source>A context manager to temporarily set the training mode of &amp;lsquo;model&amp;rsquo; to &amp;lsquo;mode&amp;rsquo;, resetting it when we exit the with-block. A no-op if mode is None.</source>
          <target state="translated">'모델'의 훈련 모드를 '모드'로 일시적으로 설정하고 with-block을 종료 할 때 재설정하는 컨텍스트 관리자. 모드가 없음이면 작동하지 않습니다.</target>
        </trans-unit>
        <trans-unit id="e87e0ea4a2441712bbddd88006ff260be6cf01e8" translate="yes" xml:space="preserve">
          <source>A custom &lt;code&gt;setuptools&lt;/code&gt; build extension .</source>
          <target state="translated">사용자 정의 &lt;code&gt;setuptools&lt;/code&gt; 빌드 확장.</target>
        </trans-unit>
        <trans-unit id="4879ed25bb5ad2e7dbdac9f4ce13e07cb540cd8d" translate="yes" xml:space="preserve">
          <source>A decorator for a function indicating that the return value of the function is guaranteed to be a &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object and this function can run asynchronously on the RPC callee. More specifically, the callee extracts the &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; returned by the wrapped function and installs subsequent processing steps as a callback to that &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt;. The installed callback will read the value from the &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; when completed and send the value back as the RPC response. That also means the returned &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; only exists on the callee side and is never sent through RPC. This decorator is useful when the wrapped function&amp;rsquo;s (&lt;code&gt;fn&lt;/code&gt;) execution needs to pause and resume due to, e.g., containing &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; or waiting for other signals.</source>
          <target state="translated">함수의 반환 값이 &lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt; 개체 임을 나타내는 함수의 데코레이터이며이 함수는 RPC 호출 수신자에서 비동기 적으로 실행될 수 있습니다. 보다 구체적으로 피 호출자는 래핑 된 함수에서 반환 된 &lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; 를&lt;/a&gt; 추출하고 후속 처리 단계를 해당 &lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; 에&lt;/a&gt; 대한 콜백으로 설치합니다 . 설치된 콜백은 완료되면 &lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt; 에서 값을 읽고 값을 RPC 응답으로 다시 보냅니다. 이는 또한 반환 된 &lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt; 가 수신자 측에만 존재하고 RPC를 통해 전송되지 않음을 의미합니다 . 이 데코레이터는 래핑 된 함수의 ( &lt;code&gt;fn&lt;/code&gt; ) 실행이 &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt; 포함으로 인해 일시 중지 및 재개되어야 할 때 유용합니다. 또는 다른 신호를 기다리고 있습니다.</target>
        </trans-unit>
        <trans-unit id="1802e436eb51e9216bfa3579e7b06f1deabcfc67" translate="yes" xml:space="preserve">
          <source>A dict with key type &lt;code&gt;K&lt;/code&gt; and value type &lt;code&gt;V&lt;/code&gt;. Only &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, and &lt;code&gt;float&lt;/code&gt; are allowed as key types.</source>
          <target state="translated">키 유형 &lt;code&gt;K&lt;/code&gt; 및 값 유형 &lt;code&gt;V&lt;/code&gt; 인 dict . &lt;code&gt;str&lt;/code&gt; , &lt;code&gt;int&lt;/code&gt; 및 &lt;code&gt;float&lt;/code&gt; 만 키 유형으로 허용됩니다.</target>
        </trans-unit>
        <trans-unit id="7a9fd856e77dfc3abad8cb7687ffa5e312c2b57f" translate="yes" xml:space="preserve">
          <source>A distributed request object. None, if not part of the group</source>
          <target state="translated">분산 요청 객체. 그룹의 일부가 아닌 경우 없음</target>
        </trans-unit>
        <trans-unit id="582df41a91e883c691f7f02b4e1fc90ccc670cb7" translate="yes" xml:space="preserve">
          <source>A float indicating the timeout to use for all RPCs. If an RPC does not complete in this timeframe, it will complete with an exception indicating that it has timed out.</source>
          <target state="translated">모든 RPC에 사용할 시간 제한을 나타내는 부동 소수점입니다. RPC가이 기간 내에 완료되지 않으면 시간이 초과되었음을 나타내는 예외와 함께 완료됩니다.</target>
        </trans-unit>
        <trans-unit id="a62b336a0d844d8b369172276cac660873819d03" translate="yes" xml:space="preserve">
          <source>A floating point scalar operand has dtype &lt;code&gt;torch.get_default_dtype()&lt;/code&gt; and an integral non-boolean scalar operand has dtype &lt;code&gt;torch.int64&lt;/code&gt;. Unlike numpy, we do not inspect values when determining the minimum &lt;code&gt;dtypes&lt;/code&gt; of an operand. Quantized and complex types are not yet supported.</source>
          <target state="translated">부동 소수점 스칼라 피연산자는 dtype &lt;code&gt;torch.get_default_dtype()&lt;/code&gt; 가지며 정수가 아닌 부울이 아닌 스칼라 피연산자는 dtype &lt;code&gt;torch.int64&lt;/code&gt; 를 갖 습니다 . numpy와 달리 피연산자 의 최소 &lt;code&gt;dtypes&lt;/code&gt; 을 결정할 때 값을 검사하지 않습니다 . 양자화 및 복합 유형은 아직 지원되지 않습니다.</target>
        </trans-unit>
        <trans-unit id="b9ed960bad6396547e811b3062f43d2d9d84c3b7" translate="yes" xml:space="preserve">
          <source>A gated recurrent unit (GRU) cell</source>
          <target state="translated">GRU (gated recurrent unit) 셀</target>
        </trans-unit>
        <trans-unit id="6500e1e873505e9557317cbc126e48e477677230" translate="yes" xml:space="preserve">
          <source>A handful of CUDA operations are nondeterministic if the CUDA version is 10.2 or greater, unless the environment variable &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:8&lt;/code&gt; or &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; is set. See the CUDA documentation for more details: &lt;a href=&quot;https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility&quot;&gt;https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility&lt;/a&gt; If one of these environment variable configurations is not set, a &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#RuntimeError&quot;&gt;&lt;code&gt;RuntimeError&lt;/code&gt;&lt;/a&gt; will be raised from these operations when called with CUDA tensors:</source>
          <target state="translated">환경 변수 &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:8&lt;/code&gt; 또는 &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; 이 설정되어 있지 않으면 CUDA 버전이 10.2 이상이면 소수의 CUDA 작업이 비 결정적 입니다. 자세한 내용은 CUDA 설명서를 참조하십시오. &lt;a href=&quot;https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility&quot;&gt;https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility&lt;/a&gt; 이러한 환경 변수 구성 중 하나가 설정되지 않은 경우 CUDA로 호출 할 때 이러한 작업에서 &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#RuntimeError&quot;&gt; &lt;code&gt;RuntimeError&lt;/code&gt; &lt;/a&gt; 가 발생합니다. 텐서 :</target>
        </trans-unit>
        <trans-unit id="7749157cec3d641bd4967868e0fa47bf1bc04040" translate="yes" xml:space="preserve">
          <source>A handle of distributed group that can be given to collective calls.</source>
          <target state="translated">집합 호출에 제공 할 수있는 분산 그룹의 핸들입니다.</target>
        </trans-unit>
        <trans-unit id="206d2d1444ddd6b067f98b835b8bca7ba47b6c99" translate="yes" xml:space="preserve">
          <source>A helper function for checkpointing sequential models.</source>
          <target state="translated">순차 모델을 검사하기위한 도우미 기능입니다.</target>
        </trans-unit>
        <trans-unit id="3fa20b5ac9b07bb8e81b28cca1e0d1e80ac301dd" translate="yes" xml:space="preserve">
          <source>A kind of Tensor that is to be considered a module parameter.</source>
          <target state="translated">모듈 매개 변수로 간주되는 일종의 Tensor입니다.</target>
        </trans-unit>
        <trans-unit id="f9cebb2a15f669cb89a337fe94399d68f146852b" translate="yes" xml:space="preserve">
          <source>A known limitation that worth mentioning here is user &lt;strong&gt;CANNOT&lt;/strong&gt; load two different branches of the same repo in the &lt;strong&gt;same python process&lt;/strong&gt;. It&amp;rsquo;s just like installing two packages with the same name in Python, which is not good. Cache might join the party and give you surprises if you actually try that. Of course it&amp;rsquo;s totally fine to load them in separate processes.</source>
          <target state="translated">가치가 여기에 언급 것으로 알려진 제한은 사용자입니다 &lt;strong&gt;수없는&lt;/strong&gt; 에서 같은 REPO의 서로 다른 두 가지를로드 &lt;strong&gt;같은 파이썬 과정&lt;/strong&gt; . 파이썬에서 같은 이름을 가진 두 개의 패키지를 설치하는 것과 같지만 좋지 않습니다. 캐시는 파티에 참여하고 실제로 시도하면 놀라움을 줄 수 있습니다. 물론 별도의 프로세스로로드하는 것이 좋습니다.</target>
        </trans-unit>
        <trans-unit id="5b6768469e9cca4e490d35bd92c3d9b2169e1d91" translate="yes" xml:space="preserve">
          <source>A linear module attached with FakeQuantize modules for weight, used for quantization aware training.</source>
          <target state="translated">양자화 인식 훈련에 사용되는 가중치 용 FakeQuantize 모듈이 부착 된 선형 모듈입니다.</target>
        </trans-unit>
        <trans-unit id="dc7b6582ee399c321872ca72686d97afecec5335" translate="yes" xml:space="preserve">
          <source>A list of include path strings.</source>
          <target state="translated">포함 경로 문자열 목록입니다.</target>
        </trans-unit>
        <trans-unit id="670f1df273800a76faec2dce35ff3b26f07b45a5" translate="yes" xml:space="preserve">
          <source>A list of the completed &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; results. This method will throw an error if &lt;code&gt;wait&lt;/code&gt; on any &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; throws.</source>
          <target state="translated">완료된 &lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt; 결과 목록입니다 . 경우이 메소드는 오류가 발생합니다 &lt;code&gt;wait&lt;/code&gt; 어떤에 &lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt; 발생합니다.</target>
        </trans-unit>
        <trans-unit id="957409376e9513abfec84a7b922ff172b12a1b20" translate="yes" xml:space="preserve">
          <source>A list of which all members are type &lt;code&gt;T&lt;/code&gt;</source>
          <target state="translated">모든 구성원이 &lt;code&gt;T&lt;/code&gt; 유형 인 목록</target>
        </trans-unit>
        <trans-unit id="087cf02c32b2e05acb68308382032450a4a20257" translate="yes" xml:space="preserve">
          <source>A long short-term memory (LSTM) cell.</source>
          <target state="translated">장단기 기억 (LSTM) 세포.</target>
        </trans-unit>
        <trans-unit id="f18e48f94bce7b9c4d48d2ece0fb5fb7d9efe971" translate="yes" xml:space="preserve">
          <source>A map where the key is the Tensor and the value is the associated gradient for that Tensor.</source>
          <target state="translated">키가 Tensor이고 값이 해당 Tensor에 대한 관련 그라디언트 인 맵입니다.</target>
        </trans-unit>
        <trans-unit id="96c11bff8b88f586e9213a9a4fa4c5da81e27dfc" translate="yes" xml:space="preserve">
          <source>A namedtuple (eigenvalues, eigenvectors) containing</source>
          <target state="translated">다음을 포함하는 명명 된 튜플 (고유 값, 고유 벡터)</target>
        </trans-unit>
        <trans-unit id="728e8297f47bdf6af1113fc81a7338a6111e3fbb" translate="yes" xml:space="preserve">
          <source>A namedtuple (sign, logabsdet) containing the sign of the determinant, and the log value of the absolute determinant.</source>
          <target state="translated">행렬식의 부호와 절대 행렬식의 로그 값을 포함하는 명명 된 튜플 (부호, logabsdet).</target>
        </trans-unit>
        <trans-unit id="f051d331990381212770691e09eaebbe9dbf0969" translate="yes" xml:space="preserve">
          <source>A namedtuple (solution, QR) containing:</source>
          <target state="translated">다음을 포함하는 명명 된 튜플 (솔루션, QR) :</target>
        </trans-unit>
        <trans-unit id="1c9b39e663c1fba635b37123383556801e4f83c6" translate="yes" xml:space="preserve">
          <source>A namedtuple &lt;code&gt;(solution, cloned_coefficient)&lt;/code&gt; where &lt;code&gt;cloned_coefficient&lt;/code&gt; is a clone of</source>
          <target state="translated">namedtuple &lt;code&gt;(solution, cloned_coefficient)&lt;/code&gt; &lt;code&gt;cloned_coefficient&lt;/code&gt; 가 의 클론</target>
        </trans-unit>
        <trans-unit id="5a372625038d1c917e3aaa8e230582a3f57787f0" translate="yes" xml:space="preserve">
          <source>A namedtuple of (values, indices) is returned, where the &lt;code&gt;values&lt;/code&gt; are the sorted values and &lt;code&gt;indices&lt;/code&gt; are the indices of the elements in the original &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">(값, 인덱스)의 명명 된 튜플이 반환됩니다. 여기서 &lt;code&gt;values&lt;/code&gt; 은 정렬 된 값이고 &lt;code&gt;indices&lt;/code&gt; 는 원래 &lt;code&gt;input&lt;/code&gt; 텐서 에있는 요소의 인덱스입니다 .</target>
        </trans-unit>
        <trans-unit id="604316c9ed5b0a04586de06d5b7c827e9c474f1c" translate="yes" xml:space="preserve">
          <source>A namedtuple of &lt;code&gt;(values, indices)&lt;/code&gt; is returned, where the &lt;code&gt;indices&lt;/code&gt; are the indices of the elements in the original &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;(values, indices)&lt;/code&gt; 의 명명 된 튜플 이 반환됩니다. 여기서 &lt;code&gt;indices&lt;/code&gt; 는 원래 &lt;code&gt;input&lt;/code&gt; 텐서 에있는 요소의 인덱스입니다 .</target>
        </trans-unit>
        <trans-unit id="2869157b898ed95d4d84e8714207a533d4266c67" translate="yes" xml:space="preserve">
          <source>A new &lt;code&gt;Future&lt;/code&gt; object that holds the return value of the &lt;code&gt;callback&lt;/code&gt; and will be marked as completed when the given &lt;code&gt;callback&lt;/code&gt; finishes.</source>
          <target state="translated">&lt;code&gt;callback&lt;/code&gt; 의 반환 값을 보유하고 지정된 &lt;code&gt;callback&lt;/code&gt; 이 완료되면 완료된 것으로 표시되는 새로운 &lt;code&gt;Future&lt;/code&gt; 객체입니다 .</target>
        </trans-unit>
        <trans-unit id="86f61ab629b1ba7d19f7dcc0bb8025724554b7cc" translate="yes" xml:space="preserve">
          <source>A new optimized torch script module</source>
          <target state="translated">최적화 된 새로운 토치 스크립트 모듈</target>
        </trans-unit>
        <trans-unit id="42ae237d21ac89e5671cbfe0c552756ff6818727" translate="yes" xml:space="preserve">
          <source>A newly quantized tensor</source>
          <target state="translated">A newly quantized tensor</target>
        </trans-unit>
        <trans-unit id="0f1ef90ea70757aed597fc7161c74a26091c5cc9" translate="yes" xml:space="preserve">
          <source>A non-complex output tensor cannot accept a complex tensor</source>
          <target state="translated">A non-complex output tensor cannot accept a complex tensor</target>
        </trans-unit>
        <trans-unit id="8860b725134278b328cae593df46234adf438aae" translate="yes" xml:space="preserve">
          <source>A placeholder identity operator that is argument-insensitive.</source>
          <target state="translated">A placeholder identity operator that is argument-insensitive.</target>
        </trans-unit>
        <trans-unit id="68cb032d3fee685e7e338c671eb8bac87e4a9de4" translate="yes" xml:space="preserve">
          <source>A quantized linear module with quantized tensor as inputs and outputs. We adopt the same interface as &lt;code&gt;torch.nn.Linear&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&lt;/a&gt; for documentation.</source>
          <target state="translated">A quantized linear module with quantized tensor as inputs and outputs. We adopt the same interface as &lt;code&gt;torch.nn.Linear&lt;/code&gt; , please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&lt;/a&gt; for documentation.</target>
        </trans-unit>
        <trans-unit id="90e1352af2e81f61b051ad3af1316a3695d6f809" translate="yes" xml:space="preserve">
          <source>A readonly &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/a&gt; that shows the number of plans currently in the cuFFT plan cache.</source>
          <target state="translated">A readonly &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt; &lt;code&gt;int&lt;/code&gt; &lt;/a&gt; that shows the number of plans currently in the cuFFT plan cache.</target>
        </trans-unit>
        <trans-unit id="4fd9c2aa54ec6edcb5667f155a92b1ad827136ed" translate="yes" xml:space="preserve">
          <source>A scalar floating point number</source>
          <target state="translated">A scalar floating point number</target>
        </trans-unit>
        <trans-unit id="ab6a03d7d6d156530f83f56670a446dfe49b0bed" translate="yes" xml:space="preserve">
          <source>A scalar integer</source>
          <target state="translated">A scalar integer</target>
        </trans-unit>
        <trans-unit id="f6cc25f2f216f722bfbd2ae25c5bbc684d2ee1fd" translate="yes" xml:space="preserve">
          <source>A sequential container.</source>
          <target state="translated">A sequential container.</target>
        </trans-unit>
        <trans-unit id="b8abdf9e14775972dca4bbd0c85df17f123918a1" translate="yes" xml:space="preserve">
          <source>A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.</source>
          <target state="translated">A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.</target>
        </trans-unit>
        <trans-unit id="1eb58c4c0d2493633735de8b616a63c6ada9e2fd" translate="yes" xml:space="preserve">
          <source>A simple lookup table that looks up embeddings in a fixed dictionary and size.</source>
          <target state="translated">A simple lookup table that looks up embeddings in a fixed dictionary and size.</target>
        </trans-unit>
        <trans-unit id="28b7624a806a8a7fcea708395f29b1cdc6294a33" translate="yes" xml:space="preserve">
          <source>A simple lookup table that stores embeddings of a fixed dictionary and size.</source>
          <target state="translated">A simple lookup table that stores embeddings of a fixed dictionary and size.</target>
        </trans-unit>
        <trans-unit id="55e7985c56ca03421c43dc04192249c84e14dc6a" translate="yes" xml:space="preserve">
          <source>A single dimension may be -1, in which case it&amp;rsquo;s inferred from the remaining dimensions and the number of elements in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">A single dimension may be -1, in which case it&amp;rsquo;s inferred from the remaining dimensions and the number of elements in &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
