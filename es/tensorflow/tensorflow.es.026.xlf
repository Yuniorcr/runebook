<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="es" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="cea56f6fda7d999d314aba39c0fdf92a26a4a3d0" translate="yes" xml:space="preserve">
          <source>Thread Compatibility</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c707a1c58a3c28cb78f0eb8786b82d358ba76091" translate="yes" xml:space="preserve">
          <source>Thread code:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1bfe9290c9416a7b4254caec7ab391081602a4c" translate="yes" xml:space="preserve">
          <source>Thread identifier of this thread or None if it has not been started.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf8ab928262e89058d10a418722762edfa599e46" translate="yes" xml:space="preserve">
          <source>Thresholded Rectified Linear Unit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19453fe8b327db6c16c490630fc6fcb997c1883b" translate="yes" xml:space="preserve">
          <source>Thus the saved model can be reinstantiated in the exact same state, without any of the code used for model definition or training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea13a52ff3b11f3a3cff17d94eddba0db805c4f1" translate="yes" xml:space="preserve">
          <source>Time series forecasting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d96b16498245359e1fc62fcf077cd9c20e575ff4" translate="yes" xml:space="preserve">
          <source>Timer that triggers at most once every N seconds or once every N steps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0bee40a202555900d8a3e86b930a56b855407cd" translate="yes" xml:space="preserve">
          <source>To &lt;code&gt;run&lt;/code&gt; without hooks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="010eecd6ae7f583a0121a3a0180c941339655bd9" translate="yes" xml:space="preserve">
          <source>To apply a functional operation to the nonzero elements of a SparseTensor one of the following methods is recommended. First, if the function is expressible as TensorFlow ops, use</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eb084feee66304e2da16fe914a839b30b34c9ff" translate="yes" xml:space="preserve">
          <source>To associate a &lt;code&gt;StatsAggregator&lt;/code&gt; with a &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; object, use the following pattern:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c154cd080332e723a840721f93b48724110f7c06" translate="yes" xml:space="preserve">
          <source>To associate a &lt;code&gt;StatsAggregator&lt;/code&gt; with a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; object, use the following pattern:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="936085b5545471dc42df6c7c7d391847c9751475" translate="yes" xml:space="preserve">
          <source>To avoid copies, if the consumer of the returned value is on the same device as the variable, this actually returns the live value of the variable, not a copy. Updates to the variable are seen by the consumer. If the consumer is on a different device it will get a copy of the variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c1421196dd351f3e8d18229f5901c13e59818be" translate="yes" xml:space="preserve">
          <source>To avoid this operation one can looping over the first &lt;code&gt;ndims&lt;/code&gt; of the variable and using &lt;code&gt;scatter_update&lt;/code&gt; on the subtensors that result of slicing the first dimension. This is a valid option for &lt;code&gt;ndims = 1&lt;/code&gt;, but less efficient than this implementation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d93bb75610f7b39567f5b306f3397077993ff8e1" translate="yes" xml:space="preserve">
          <source>To avoid this operation there would be 2 alternatives: 1) Reshaping the variable by merging the first &lt;code&gt;ndims&lt;/code&gt; dimensions. However, this is not possible because &lt;a href=&quot;../../reshape&quot;&gt;&lt;code&gt;tf.reshape&lt;/code&gt;&lt;/a&gt; returns a Tensor, which we cannot use &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt; on. 2) Looping over the first &lt;code&gt;ndims&lt;/code&gt; of the variable and using &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt; on the subtensors that result of slicing the first dimension. This is a valid option for &lt;code&gt;ndims = 1&lt;/code&gt;, but less efficient than this implementation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9183a300f45fff79988522f16235dc4e2de646c" translate="yes" xml:space="preserve">
          <source>To be implemented by subclasses:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52f2d1556ade9e7f9e4af5a180af2690b66cec6f" translate="yes" xml:space="preserve">
          <source>To be used together with &lt;code&gt;initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')&lt;/code&gt;. For correct dropout, use &lt;code&gt;tf.contrib.nn.alpha_dropout&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53dd8873954bfa79dfd0bea43d6ef54fe742261a" translate="yes" xml:space="preserve">
          <source>To build a SavedModel, the first meta graph must be saved with variables. Subsequent meta graphs will simply be saved with their graph definitions. If assets need to be saved and written or copied to disk, they can be provided when the meta graph def is added. If multiple meta graph defs are associated an asset of the same name, only the first version is retained.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44fe360fd9bf0e087ab467407a9221a32654e234" translate="yes" xml:space="preserve">
          <source>To construct a TPUStrategy object, you need to run the initialization code as below:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83c7623c3022948b14096264ce7d526cb9408c74" translate="yes" xml:space="preserve">
          <source>To consume the statistics, associate a &lt;code&gt;StatsAggregator&lt;/code&gt; with the output dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2287264f43a3ef6c22b5d232bbf5118319287d4" translate="yes" xml:space="preserve">
          <source>To create a &lt;a href=&quot;../compat/v1/session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; that connects to this server, use the following snippet:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6382ce12824513eb2d0429e1935eb788cf98fff" translate="yes" xml:space="preserve">
          <source>To create a cluster with two jobs and five tasks, you specify the mapping from job names to lists of network addresses (typically hostname-port pairs).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="162a52ef0e892f8de2d469fbf8a8ede583aeb2c2" translate="yes" xml:space="preserve">
          <source>To create a dataset of all files matching a pattern, use &lt;a href=&quot;dataset#list_files&quot;&gt;&lt;code&gt;tf.data.Dataset.list_files&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="baed8fb95bde1dbbdafd79f549daf02185ceb494" translate="yes" xml:space="preserve">
          <source>To enable a public method, subclasses should implement the leading-underscore version of the method. The argument signature should be identical except for the omission of &lt;code&gt;name=&quot;...&quot;&lt;/code&gt;. For example, to enable &lt;code&gt;matmul(x, adjoint=False, name=&quot;matmul&quot;)&lt;/code&gt; a subclass should implement &lt;code&gt;_matmul(x, adjoint=False)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a64f441e5dd84fd06f79adb0f1f3a053a7155dea" translate="yes" xml:space="preserve">
          <source>To enable and control broadcasting, use an ellipsis. For example, to perform batch matrix multiplication with NumPy-style broadcasting across the batch dimensions, use:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01b6fd9e2269c63a7f1c5eddbf780087a139a252" translate="yes" xml:space="preserve">
          <source>To enable statefulness: - Specify &lt;code&gt;stateful=True&lt;/code&gt; in the layer constructor. - Specify a fixed batch size for your model, by passing If sequential model: &lt;code&gt;batch_input_shape=(...)&lt;/code&gt; to the first layer in your model. Else for functional model with 1 or more Input layers: &lt;code&gt;batch_shape=(...)&lt;/code&gt; to all the first layers in your model. This is the expected shape of your inputs &lt;em&gt;including the batch size&lt;/em&gt;. It should be a tuple of integers, e.g. &lt;code&gt;(32, 10, 100)&lt;/code&gt;. - Specify &lt;code&gt;shuffle=False&lt;/code&gt; when calling fit().</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63aaf92714daf46639926647a3d0a69e133b8f2a" translate="yes" xml:space="preserve">
          <source>To enable this Soft-NMS mode, set the &lt;code&gt;soft_nms_sigma&lt;/code&gt; parameter to be larger than 0. When &lt;code&gt;soft_nms_sigma&lt;/code&gt; equals 0, the behavior of &lt;code&gt;tf.image.non_max_suppression_v2&lt;/code&gt; is identical to that of &lt;a href=&quot;non_max_suppression&quot;&gt;&lt;code&gt;tf.image.non_max_suppression&lt;/code&gt;&lt;/a&gt; (except for the extra output) both in function and in running time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30dc95cd6fb2fe82cb6bde586b190076a23204d3" translate="yes" xml:space="preserve">
          <source>To ensure forward compatibility of generated graphs (see &lt;code&gt;forward_compatible&lt;/code&gt;) with older binaries, new features can be gated with:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fdc8715d19df576a528e05d54600b3b8b7e951d" translate="yes" xml:space="preserve">
          <source>To ensure that loading is complete and no more assignments will take place, use the &lt;code&gt;assert_consumed()&lt;/code&gt; method of the status object returned by &lt;code&gt;restore&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f9135f3ba27360a5d60098a844664f0e165caf9" translate="yes" xml:space="preserve">
          <source>To extend, inherit from this class; from the subclass &lt;strong&gt;init&lt;/strong&gt;, call</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5d8cbeafaa3eeb0c6165bfa56b4aafe15d6a9db" translate="yes" xml:space="preserve">
          <source>To generate different sequences across sessions, set neither graph-level nor op-level seeds:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b8fda9f12ffa5af323a889062c3aa890309e2cb" translate="yes" xml:space="preserve">
          <source>To generate the same repeatable sequence for an op across sessions, set the seed for the op:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec9fe6e91399876e841634556ab27d6bee162948" translate="yes" xml:space="preserve">
          <source>To get a protocol buffer summary of the currently aggregated statistics, use the &lt;code&gt;StatsAggregator.get_summary()&lt;/code&gt; tensor. The easiest way to do this is to add the returned tensor to the &lt;code&gt;tf.GraphKeys.SUMMARIES&lt;/code&gt; collection, so that the summaries will be included with any existing summaries.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eecdfb3013e20388a17f33fbb93597b30d4ef349" translate="yes" xml:space="preserve">
          <source>To get the current default session, use &lt;a href=&quot;get_default_session&quot;&gt;&lt;code&gt;tf.compat.v1.get_default_session&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="273ca78fffe894af5651288f4a1f4c051d209749" translate="yes" xml:space="preserve">
          <source>To illustrate the user-visible effects, consider these examples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce5890e8d9ded5f833a93abef51a8a4c147da863" translate="yes" xml:space="preserve">
          <source>To instead reorder the data to rearrange the dimensions of a tensor, see &lt;a href=&quot;transpose&quot;&gt;&lt;code&gt;tf.transpose&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58521b85b5941fed07e375b8c580b661cb67962d" translate="yes" xml:space="preserve">
          <source>To load a network from a JSON save file, use &lt;a href=&quot;../models/model_from_json&quot;&gt;&lt;code&gt;keras.models.model_from_json(json_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc1f35de200c65966b97907804a085417fa2674d" translate="yes" xml:space="preserve">
          <source>To load a network from a JSON save file, use &lt;a href=&quot;models/model_from_json&quot;&gt;&lt;code&gt;keras.models.model_from_json(json_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="171ed2725b41e726794d8676fc06308b4d649fcf" translate="yes" xml:space="preserve">
          <source>To load a network from a yaml save file, use &lt;a href=&quot;../models/model_from_yaml&quot;&gt;&lt;code&gt;keras.models.model_from_yaml(yaml_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32acfa401b4c952f2dcfef233deb7f737a491a64" translate="yes" xml:space="preserve">
          <source>To load a network from a yaml save file, use &lt;a href=&quot;models/model_from_yaml&quot;&gt;&lt;code&gt;keras.models.model_from_yaml(yaml_string, custom_objects={})&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84dbf2d04bfcc507efa1aac8fcfb0ed50455e091" translate="yes" xml:space="preserve">
          <source>To make the random sequences generated by all ops be repeatable across sessions, set a graph-level seed:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bca5a7e3515ab70d1734fcf9290f94f57a539f3" translate="yes" xml:space="preserve">
          <source>To mimic the behavior of &lt;code&gt;np.flatten&lt;/code&gt; (which flattens all dimensions), use &lt;code&gt;rt.merge_dims(0, -1). To mimic the behavior of&lt;/code&gt;tf.layers.Flatten&lt;code&gt;(which flattens all dimensions except the outermost batch dimension), use&lt;/code&gt;rt.merge_dims(1, -1)`.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9a3e8831e7d974549f1a0383e7928bbabcfacd7" translate="yes" xml:space="preserve">
          <source>To obtain an individual graph, use the &lt;code&gt;get_concrete_function&lt;/code&gt; method of the callable created by &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. It can be called with the same arguments as &lt;code&gt;func&lt;/code&gt; and returns a special &lt;a href=&quot;graph&quot;&gt;&lt;code&gt;tf.Graph&lt;/code&gt;&lt;/a&gt; object:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0110a07b243d67a47edf557bd54d79fd2de9674" translate="yes" xml:space="preserve">
          <source>To perform the clipping, the values &lt;code&gt;t_list[i]&lt;/code&gt; are set to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e552f3cce7d0e03051d89f4e0255d1c49f37d1b" translate="yes" xml:space="preserve">
          <source>To prevent accidental sharing of variables, we raise an exception when getting an existing variable in a non-reusing scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b90b39244fd5711de404a1ed79326b6635b08950" translate="yes" xml:space="preserve">
          <source>To process lines from files, use &lt;a href=&quot;textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa139b98ea790b72d4805462346af0f7c690db65" translate="yes" xml:space="preserve">
          <source>To process records written in the &lt;code&gt;TFRecord&lt;/code&gt; format, use &lt;code&gt;TFRecordDataset&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b683767243ad0f37ed1467c8125bf95f601a1fc4" translate="yes" xml:space="preserve">
          <source>To read back the elements, use &lt;code&gt;TFRecordDataset&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff235c20472c16fd213bae4a4af01054d920d420" translate="yes" xml:space="preserve">
          <source>To reconstruct an original waveform, a complementary window function should be used with &lt;code&gt;inverse_stft&lt;/code&gt;. Such a window function can be constructed with &lt;a href=&quot;inverse_stft_window_fn&quot;&gt;&lt;code&gt;tf.signal.inverse_stft_window_fn&lt;/code&gt;&lt;/a&gt;. Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca5c9dd44204672cbbbbaf3d7ffdd096d2e60573" translate="yes" xml:space="preserve">
          <source>To record statistics, use one of the custom transformation functions defined in this module when defining your &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;. All statistics will be aggregated by the &lt;code&gt;StatsAggregator&lt;/code&gt; that is associated with a particular iterator (see below). For example, to record the latency of producing each element by iterating over a dataset:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84004f640543424d2c71289d24eec0f0b8df9f20" translate="yes" xml:space="preserve">
          <source>To record statistics, use one of the custom transformation functions defined in this module when defining your &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;. All statistics will be aggregated by the &lt;code&gt;StatsAggregator&lt;/code&gt; that is associated with a particular iterator (see below). For example, to record the latency of producing each element by iterating over a dataset:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bf5571681c9436431c1ed224b52ea46ea226e1b" translate="yes" xml:space="preserve">
          <source>To reset the states of your model, call &lt;code&gt;.reset_states()&lt;/code&gt; on either a specific layer, or on your entire model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f2fb526cb8dbaa2bd872bcdf1bffcdc847f4f4f" translate="yes" xml:space="preserve">
          <source>To restore variables, you have to know the name of the shadow variables. That name and the original variable can then be passed to a &lt;code&gt;Saver()&lt;/code&gt; object to restore the variable from the moving average value with: &lt;code&gt;saver = tf.compat.v1.train.Saver({ema.average_name(var): var})&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61b9174bc024e647c5c9bf1631b4141790c76fd9" translate="yes" xml:space="preserve">
          <source>To run TF2 programs on TPUs, you can either use &lt;code&gt;.compile&lt;/code&gt; and &lt;code&gt;.fit&lt;/code&gt; APIs in &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; with TPUStrategy, or write your own customized training loop by calling &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; directly. Note that TPUStrategy doesn't support pure eager execution, so please make sure the function passed into &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; is a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; us called inside a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; if running in eager mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e990fa899ccbe4b80cb8729867536ff2b0542458" translate="yes" xml:space="preserve">
          <source>To save and restore.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b35673692b203b1580cc459164c684b7c71fe1e4" translate="yes" xml:space="preserve">
          <source>To shard a &lt;code&gt;dataset&lt;/code&gt; across multiple TFRecord files:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc6bb2051a5897d4a8d4dac929c8a069356b9e0c" translate="yes" xml:space="preserve">
          <source>To simplify the thread implementation, the Coordinator provides a context handler &lt;code&gt;stop_on_exception()&lt;/code&gt; that automatically requests a stop if an exception is raised. Using the context handler the thread code above can be written as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a72b5fda5da9fdf55b3bf54113912820e04f4679" translate="yes" xml:space="preserve">
          <source>To stop the trace and export the collected information, use &lt;a href=&quot;trace_export&quot;&gt;&lt;code&gt;tf.summary.trace_export&lt;/code&gt;&lt;/a&gt;. To stop the trace without exporting, use &lt;a href=&quot;trace_off&quot;&gt;&lt;code&gt;tf.summary.trace_off&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78edbe912a6ec7dfbde2fa6ca3dbd293be354b5e" translate="yes" xml:space="preserve">
          <source>To train with replicas you deploy the same program in a &lt;code&gt;Cluster&lt;/code&gt;. One of the tasks must be identified as the &lt;em&gt;chief&lt;/em&gt;: the task that handles initialization, checkpoints, summaries, and recovery. The other tasks depend on the &lt;em&gt;chief&lt;/em&gt; for these services.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a01c3edc32585755d57328d40fa48f8fdb3ab82" translate="yes" xml:space="preserve">
          <source>To treat a sparse input as dense, provide &lt;code&gt;allow_missing=True&lt;/code&gt;; otherwise, the parse functions will fail on any examples missing this feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f70a87293b647de36d39cf376105ebfad1b65755" translate="yes" xml:space="preserve">
          <source>To treat sparse input as dense, provide a &lt;code&gt;default_value&lt;/code&gt;; otherwise, the parse functions will fail on any examples missing this feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2cf2713de328f732331e0697fff7bd058371175a" translate="yes" xml:space="preserve">
          <source>To use &lt;code&gt;MirroredStrategy&lt;/code&gt; with multiple workers, please refer to &lt;code&gt;tf.distribute.MultiWorkerMirroredStrategy&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12770f5e5f15720c161e4a87129f9d9bb0774bc6" translate="yes" xml:space="preserve">
          <source>To use SyncReplicasOptimizer with an &lt;code&gt;Estimator&lt;/code&gt;, you need to send sync_replicas_hook while calling the fit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="783180a85bf045e00f72afe9cf4aeba0310e67f8" translate="yes" xml:space="preserve">
          <source>To use a listener, implement a class and pass the listener to a &lt;code&gt;CheckpointSaverHook&lt;/code&gt;, as in this example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82a8f0d7938dca39dd9baa444dbabf12a6beff73" translate="yes" xml:space="preserve">
          <source>To use crossed column in DNN model, you need to add it in an embedding column as in this example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df232f0149a3304cb55f19e9533d29d033c88a07" translate="yes" xml:space="preserve">
          <source>To use it with Keras &lt;code&gt;compile&lt;/code&gt;/&lt;code&gt;fit&lt;/code&gt;, &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_keras&quot;&gt;please read&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52761ad57b4e88f15825661793f52089d3153688" translate="yes" xml:space="preserve">
          <source>To use mixed precision in a Keras model, the &lt;code&gt;'mixed_float16'&lt;/code&gt; or &lt;code&gt;'mixed_bfloat16'&lt;/code&gt; policy can be used. &lt;a href=&quot;set_policy&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.set_policy&lt;/code&gt;&lt;/a&gt; can be used to set the default policy for layers if no policy is passed to them. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3bc90b596c6a06641f646fd21855a01a15f891a" translate="yes" xml:space="preserve">
          <source>To use partial execution, a user first calls &lt;code&gt;partial_run_setup()&lt;/code&gt; and then a sequence of &lt;code&gt;partial_run()&lt;/code&gt;. &lt;code&gt;partial_run_setup&lt;/code&gt; specifies the list of feeds and fetches that will be used in the subsequent &lt;code&gt;partial_run&lt;/code&gt; calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0486110c8c71e38a21a240cd6d1c94b9eb3a8e49" translate="yes" xml:space="preserve">
          <source>To use the pprof file:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77972f247631f66b18016dae59b6ae8450d1266a" translate="yes" xml:space="preserve">
          <source>To use the replacement for variables which does not have these issues:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9fed22a474957718b6e8cceaa345a94b692ff2f" translate="yes" xml:space="preserve">
          <source>To use, enqueue filenames in a Queue. The output of Read will be a filename (key) and the contents of that file (value).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="936bb6e71e849ce05ab2a85d8c98f04120f3012d" translate="yes" xml:space="preserve">
          <source>To use, enqueue strings in a Queue. Read will take the front work string and output (work, work).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b5c6be676ffa47f64b992a379fa3a687addb427" translate="yes" xml:space="preserve">
          <source>To warm-start an &lt;code&gt;Estimator&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33d27663923e948257deb0ac3f48e158f539a021" translate="yes" xml:space="preserve">
          <source>Toeplitz means that &lt;code&gt;A&lt;/code&gt; has constant diagonals. Hence, &lt;code&gt;A&lt;/code&gt; can be generated with two vectors. One represents the first column of the matrix, and the other represents the first row.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="121fe412af2d5e916662ca3ec0794ef40b1e2f67" translate="yes" xml:space="preserve">
          <source>Trace of the linear operator, equal to sum of &lt;code&gt;self.diag_part()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3cd08d7e53167c39ff4df8ac6fd7573ac51ea11" translate="yes" xml:space="preserve">
          <source>Traces argument information at compilation time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="235a91222dd28e8e16c0e133dc2cba6c6d12742f" translate="yes" xml:space="preserve">
          <source>Train a linear model to classify instances into one of multiple possible classes. When number of possible classes is 2, this is binary classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee3c9790cb66e90ecfd717511a371fde17bac07c" translate="yes" xml:space="preserve">
          <source>Train a linear regression model to predict label value given observation of feature values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3efa73c7139b833a96e690294f1f5dee0c8dafcf" translate="yes" xml:space="preserve">
          <source>Train and evaluate the &lt;code&gt;estimator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="beb3053fd8366acd014d9b2f3ece6098b4b72e55" translate="yes" xml:space="preserve">
          <source>Train and evaluate with Keras</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc6f15e9d8d0df93c841a4bfbdce1ebcc8b8e338" translate="yes" xml:space="preserve">
          <source>Trainable variables (created by &lt;a href=&quot;variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;compat/v1/get_variable&quot;&gt;&lt;code&gt;tf.compat.v1.get_variable&lt;/code&gt;&lt;/a&gt;, where &lt;code&gt;trainable=True&lt;/code&gt; is default in both cases) are automatically watched. Tensors can be manually watched by invoking the &lt;code&gt;watch&lt;/code&gt; method on this context manager.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d85aa0db75043b2fc7e6d076a658d6108e846757" translate="yes" xml:space="preserve">
          <source>Training checkpoints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10de55a426007543588aad0c26e9034f2ddc3a47" translate="yes" xml:space="preserve">
          <source>Training graph visualization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7db0d855207cb66583c78145b39525c5633639da" translate="yes" xml:space="preserve">
          <source>Training helper that restores from checkpoint and creates session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf6759c44ad41b3091516c81e1bc49fed1c443ea" translate="yes" xml:space="preserve">
          <source>Trains a model given training data &lt;code&gt;input_fn&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b7a7a43991418e3ac5adb5f5a2111146e234e48" translate="yes" xml:space="preserve">
          <source>Trains a recurrent neural network model to classify instances into one of multiple classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d8eb1e5694e7e09ad702ee89cbe5988334450c" translate="yes" xml:space="preserve">
          <source>Trains the model for a fixed number of epochs (iterations on a dataset).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5238d35744e76f113cfe81d17fbfa29f295ac05" translate="yes" xml:space="preserve">
          <source>Transcode the input text from a source encoding to a destination encoding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="983dff86700d17b79a819dfaab7edfc9d23e3e22" translate="yes" xml:space="preserve">
          <source>Transfer learning with TensorFlow Hub</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db752c46f6cefcfd15e6ab5a7acbda3b3ec8bdb7" translate="yes" xml:space="preserve">
          <source>Transfer learning with a pretrained ConvNet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3f4cdda163a694c3d7aafb554148d5d45b68f92" translate="yes" xml:space="preserve">
          <source>Transform [batch] matrix &lt;code&gt;x&lt;/code&gt; with left multiplication: &lt;code&gt;x --&amp;gt; Ax&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42db4158efb02ff54237870e3243b8f49a10cb88" translate="yes" xml:space="preserve">
          <source>Transform [batch] vector &lt;code&gt;x&lt;/code&gt; with left multiplication: &lt;code&gt;x --&amp;gt; Ax&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d685ad7c59aeb1945ef867b52857539b62c1b81c" translate="yes" xml:space="preserve">
          <source>Transformations</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a65cfd47338728767e1d8fe389f325154f22e3d2" translate="yes" xml:space="preserve">
          <source>Transformer model for language understanding</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae192d97c8bb43adae60e73f077c7a262798214c" translate="yes" xml:space="preserve">
          <source>Transforms a Tensor into a serialized TensorProto proto.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fe37f8377ecffffde4f3405645d41e0b3b001bd" translate="yes" xml:space="preserve">
          <source>Transforms a serialized tensorflow.TensorProto proto into a Tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="655ffb734eb7a488c9c872982dd743f0f56654c3" translate="yes" xml:space="preserve">
          <source>Transforms each input point to its distances to all cluster centers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcd8235ad6fe846d496fe3b5ab9ef987b5075ab1" translate="yes" xml:space="preserve">
          <source>Transforms each sequence in &lt;code&gt;sequences&lt;/code&gt; to a list of texts(strings).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5d4ddf915c1a321118b7e1927e1abe917834a51" translate="yes" xml:space="preserve">
          <source>Transforms each sequence into a list of text.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15870f729495d9cc692bfd46436e8e2286a88257" translate="yes" xml:space="preserve">
          <source>Transforms each text in &lt;code&gt;texts&lt;/code&gt; to a sequence of integers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86add4b4e27d9c231884be5bf0ca73d7ca67d517" translate="yes" xml:space="preserve">
          <source>Transforms each text in texts to a sequence of integers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6f3940520a66558ccbf4deb29b8ad759ce2893f" translate="yes" xml:space="preserve">
          <source>Transpose image(s) by swapping the height and width dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaef5878a51828ef045b24256f979251b2fa2f09" translate="yes" xml:space="preserve">
          <source>Transposed 2D convolution layer (sometimes called 2D Deconvolution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20b55b4579cc2c500b14b1401912fc234412af61" translate="yes" xml:space="preserve">
          <source>Transposed 3D convolution layer (sometimes called 3D Deconvolution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8af454b225f62d0dcbcdc7d510f5d2a829dab734" translate="yes" xml:space="preserve">
          <source>Transposed convolution layer (sometimes called Deconvolution).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4559d9f372084e43321f8c8b67aa21b4b3be2db7" translate="yes" xml:space="preserve">
          <source>Transposes &lt;code&gt;a&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f6a95a7cfa0d75e4317493ed12e7c428f7e9164" translate="yes" xml:space="preserve">
          <source>Transposes a &lt;code&gt;SparseTensor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2262bf9a92872de90cc8f31b3040779445c53825" translate="yes" xml:space="preserve">
          <source>Transposes a tensor and returns it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52d7d3690c76e45b3f4ac6d7704301666eae2d1f" translate="yes" xml:space="preserve">
          <source>Transposes last two dimensions of tensor &lt;code&gt;a&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad508b5e8ca6e24e73ed31c06d7f5a032986b9fa" translate="yes" xml:space="preserve">
          <source>Transposes the last two dimensions of and conjugates tensor &lt;code&gt;matrix&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c2872020c8add34a2cf2fcba50775a603f0d0e2" translate="yes" xml:space="preserve">
          <source>True if &lt;code&gt;v&lt;/code&gt; was created inside the scope, False if not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea6d3038da7212df43580d700019b440b6df39f7" translate="yes" xml:space="preserve">
          <source>True if a GPU device of the requested kind is available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0182552244a71267208d89b4ec5f7f593b52459d" translate="yes" xml:space="preserve">
          <source>True if a Tensor of the &lt;code&gt;other&lt;/code&gt;&lt;code&gt;DType&lt;/code&gt; will be implicitly converted to this &lt;code&gt;DType&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d65dfa1082053356f76fa7e32f60ffc009e106a5" translate="yes" xml:space="preserve">
          <source>True if a stop was requested.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fba54694bed7e972eba04ddb43445b6835518a56" translate="yes" xml:space="preserve">
          <source>True if inside a &lt;code&gt;with strategy.scope():&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d356c240016a0c32cb15a7f51543e8af63f4aad" translate="yes" xml:space="preserve">
          <source>True if spec_or_tensor is compatible with self.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f031713f493f44a87f541097d9a6c4633a7c4174" translate="yes" xml:space="preserve">
          <source>True if the Coordinator is told stop, False if the timeout expired.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40e3b3363df1be71fab94fcf563145f01a88073c" translate="yes" xml:space="preserve">
          <source>True if the caller can expect that serialized TensorFlow graphs produced can be consumed by programs that are compiled with the TensorFlow library source code after (year, month, day).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4faef914883a1a10aa15778c49f35fb98be8732e" translate="yes" xml:space="preserve">
          <source>True if the coordinator was told to stop, False otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41bb9eed11faf580e5cf2243f1284401f224c42a" translate="yes" xml:space="preserve">
          <source>True if the difference between the current time and the time of the last trigger exceeds &lt;code&gt;every_secs&lt;/code&gt;, or if the difference between the current step and the last triggered step exceeds &lt;code&gt;every_steps&lt;/code&gt;. False otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfc13f68b704941e80142d04a3ed7c6629e6c664" translate="yes" xml:space="preserve">
          <source>True if the export directory contains SavedModel files, False otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a900b62e1edba1c0e27907e12139238da6afb94" translate="yes" xml:space="preserve">
          <source>True if the given node must run on CPU, otherwise False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5ad15e25e43eb5bd9cd393c44c117efba29c6f6" translate="yes" xml:space="preserve">
          <source>True if the path exists, whether it's a file or a directory. False if the path does not exist and there are no filesystem errors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12521f184e32516a21dbe08fda414904f64f4716" translate="yes" xml:space="preserve">
          <source>True if the queue is closed and false if the queue is open.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3d692e2a1a03f9a580cbe6af7887c076366f28a" translate="yes" xml:space="preserve">
          <source>True if the sequence is a not a string and is a collections.abc.Sequence or a dict.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e846d2ffe93240497692f8c335b561f9a3b5ca4b" translate="yes" xml:space="preserve">
          <source>True if this Dimension and &lt;code&gt;other&lt;/code&gt; are compatible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1af9f77f297353d13cc2052ce5add84a77143e29" translate="yes" xml:space="preserve">
          <source>True if this graph has been finalized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13ac567ddd78dbff91bfa15ccdc8c27002125b9d" translate="yes" xml:space="preserve">
          <source>True iff &lt;code&gt;self&lt;/code&gt; is compatible with &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84ec63366604b21f0a1cd748c6c806b8cc035002" translate="yes" xml:space="preserve">
          <source>True on success, or false if no summary was emitted because no default summary writer was available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc591d62fe392ab5c3a30eaf5e21967f39695530" translate="yes" xml:space="preserve">
          <source>True on success, or false if no summary was written because no default summary writer was available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f16aacc072df96e8b74050ff74d241c633ad1f94" translate="yes" xml:space="preserve">
          <source>True, if the path is a directory; False otherwise</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b14f591e5a76ce927e3d51f5d369ecadec7b9175" translate="yes" xml:space="preserve">
          <source>True, if variables should be casted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0398d49e6ea66afbb212b36d04e2616800d64ac3" translate="yes" xml:space="preserve">
          <source>True: executes each operation synchronously.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d9fd66a7778c40e3dba2083356a599b52f25d88" translate="yes" xml:space="preserve">
          <source>Truncation designates that negative numbers will round fractional quantities toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different than Python semantics. See &lt;code&gt;FloorDiv&lt;/code&gt; for a division function that matches Python Semantics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b36302f1d8a1cd0c40fa6d16b6fe2aaaa964f68" translate="yes" xml:space="preserve">
          <source>Tuple of Numpy arrays: &lt;code&gt;(x_train, y_train), (x_test, y_test)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2613ea839d069df0d5c8d9c5f47854631d09fc20" translate="yes" xml:space="preserve">
          <source>Tuple used by LSTM Cells for &lt;code&gt;state_size&lt;/code&gt;, &lt;code&gt;zero_state&lt;/code&gt;, and output state.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b48f912499203c94d01ac7a5a26aea7a05b21fa" translate="yes" xml:space="preserve">
          <source>Turn a nD tensor into a 2D tensor with same 0th dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c0c370c16aa336bb6f7381c737e4c2aba96f9e" translate="yes" xml:space="preserve">
          <source>Turns positive integers (indexes) into dense vectors of fixed size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1970692bb6c07bd87f9682c04edd6a7dc8b64ed" translate="yes" xml:space="preserve">
          <source>Tutorials and examples can be found in: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="698a7f116a9d0145fa7461b0cd8612ceab6c65c3" translate="yes" xml:space="preserve">
          <source>Two 2-d numpy arrays representing the theoretical and numerical Jacobian for dy/dx. Each has &quot;x_size&quot; rows and &quot;y_size&quot; columns where &quot;x_size&quot; is the number of elements in x and &quot;y_size&quot; is the number of elements in y. If x is a list, returns a list of two numpy arrays.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e61ae5fa9a8a338e450ea4521d3c90e37b3fce55" translate="yes" xml:space="preserve">
          <source>Two &lt;code&gt;Tensor&lt;/code&gt; objects: &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;variance&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18f9e0ca8006912df25de0a98edea35700ad81f2" translate="yes" xml:space="preserve">
          <source>Two accumulation steps are required: 1) the accumulation of gradients squared, 2) the accumulation of updates squared.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1d8ed408945a366f45477724e8c9686614ca2d7" translate="yes" xml:space="preserve">
          <source>Two different templates are guaranteed to be unique, unless you reenter the same variable scope as the initial definition of a template and redefine it. An examples of this exception:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="641506872a34040c078fdb14eeef6b25c62c6fc9" translate="yes" xml:space="preserve">
          <source>Two generators are independent of each other in the sense that the random-number streams they generate don't have statistically detectable correlations. The new generators are also independent of the old one. The old generator's state will be changed (like other random-number generating methods), so two calls of &lt;code&gt;split&lt;/code&gt; will return different new generators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="609ab801a6e4c68686c97569df58fbb61201051d" translate="yes" xml:space="preserve">
          <source>Two known Dimensions are compatible if they have the same value. An unknown Dimension is compatible with all other Dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6133911db30a0e3197c09499734a8919b0cbd3bf" translate="yes" xml:space="preserve">
          <source>Two or more words may be assigned to the same index, due to possible collisions by the hashing function. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Birthday_problem#Probability_table&quot;&gt;probability&lt;/a&gt; of a collision is in relation to the dimension of the hashing space and the number of distinct objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa46f48d3d26a8be473e57169e56d3f2b7f57692" translate="yes" xml:space="preserve">
          <source>Two possibly-partially-defined shapes are compatible if there exists a fully-defined shape that both shapes can represent. Thus, compatibility allows the shape inference code to reason about partially-defined shapes. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b0a6ae6ca7d62abe9867da93517fe68a65fffe7" translate="yes" xml:space="preserve">
          <source>Two static instances exist in the distributions library, signifying one of two possible properties for samples from a distribution:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="304880baecfd0af0b3d1da16c178a413930af3d7" translate="yes" xml:space="preserve">
          <source>Two tensors are considered compatible if they have the same dtype and their shapes are compatible (see &lt;a href=&quot;tensorshape#is_compatible_with&quot;&gt;&lt;code&gt;tf.TensorShape.is_compatible_with&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c808e735cf1d9acc205c12bc34a1db874936c96" translate="yes" xml:space="preserve">
          <source>Two tensors: &lt;code&gt;weighted_mean&lt;/code&gt; and &lt;code&gt;weighted_variance&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="197f1a152813e8754c3ab4ada0aee8e8eb0ab0e1" translate="yes" xml:space="preserve">
          <source>Type collections</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89bccb1027fad55abb521d6f7f2c0ac6a074c8f5" translate="yes" xml:space="preserve">
          <source>Type specification for &lt;a href=&quot;dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ffc6a6652502645af83819deceaf071d1bee7ae" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db38e64c6790f1fa6a4046e1608589e1baafdb4f" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="506637460ca723fc98125655b0c45f16d689f183" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="097420656a3bb835a98ade8d3c1d8d6e161e4abc" translate="yes" xml:space="preserve">
          <source>Type specification for a &lt;a href=&quot;tensorarray&quot;&gt;&lt;code&gt;tf.TensorArray&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fa80254c7cf732908a6ef92e8bcb16a8cbc3031" translate="yes" xml:space="preserve">
          <source>TypeError if &lt;code&gt;cluster&lt;/code&gt; is not a dictionary or &lt;code&gt;ClusterDef&lt;/code&gt; protocol buffer, or if &lt;code&gt;ps_strategy&lt;/code&gt; is provided but not a callable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a7a3cb39cba799635ae97a5b59c3c35fb2a8e05" translate="yes" xml:space="preserve">
          <source>TypeError.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9e719623f3a5418b899a4ace2cf4d169670e417" translate="yes" xml:space="preserve">
          <source>Types of loss reduction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa3c047f418cf4b489027ae070f266970331772f" translate="yes" xml:space="preserve">
          <source>Typical usage example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f86aad613fa5c3ee99a3b5451654d3e3136022f7" translate="yes" xml:space="preserve">
          <source>Typical usage for the &lt;code&gt;SavedModelBuilder&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1dc96cc06e4c88360c7be195760a73e5c44fb2f7" translate="yes" xml:space="preserve">
          <source>Typical usage of this strategy could be testing your code with the tf.distribute.Strategy API before switching to other strategies which actually distribute to multiple devices/machines.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f433de3a09f2cf5cd13a827c57725457d725e39" translate="yes" xml:space="preserve">
          <source>Typical usage:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0271771c7069a116c3373c269a63be4c6aca6198" translate="yes" xml:space="preserve">
          <source>Typical users will use one of the more specialized DEFINE_xxx functions, such as DEFINE_string or DEFINE_integer. But developers who need to create Flag objects themselves should use this function to register their flags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2637b9cc80067f35b6391fac2edcbf9be59d7ab4" translate="yes" xml:space="preserve">
          <source>Typically only used in a cross-replica context:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="770e50ed1c5b312d1ae6d0b8292c12f6aec34dd4" translate="yes" xml:space="preserve">
          <source>Typically this function is used to convert from TensorFlow GraphDef to TFLite. Conversion can be customized by providing arguments that are forwarded to &lt;code&gt;build_toco_convert_protos&lt;/code&gt; (see documentation for details). This function has been deprecated. Please use &lt;a href=&quot;../../../lite/tfliteconverter&quot;&gt;&lt;code&gt;lite.TFLiteConverter&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f937cb551b8e8625cac21b8a54df64070d57507" translate="yes" xml:space="preserve">
          <source>Typically, constructing a file writer creates a new event file in &lt;code&gt;logdir&lt;/code&gt;. This event file will contain &lt;code&gt;Event&lt;/code&gt; protocol buffers constructed when you call one of the following functions: &lt;code&gt;add_summary()&lt;/code&gt;, &lt;code&gt;add_session_log()&lt;/code&gt;, &lt;code&gt;add_event()&lt;/code&gt;, or &lt;code&gt;add_graph()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aff7b1a518fb0d16f85d64959ece4d247dd8cf1c" translate="yes" xml:space="preserve">
          <source>Typically, different numerical approximations can be used for the log survival function, which are more accurate than &lt;code&gt;1 - cdf(x)&lt;/code&gt; when &lt;code&gt;x &amp;gt;&amp;gt; 1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc11d475cf6eeccc4ccad2799b660daf47f6e97d" translate="yes" xml:space="preserve">
          <source>Typically, this is used for contiguous ranges of integer indexes, but it doesn't have to be. This might be inefficient, however, if many of IDs are unused. Consider &lt;code&gt;categorical_column_with_hash_bucket&lt;/code&gt; in that case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f2505b6c39bb7db973660c096d38f1739c74197" translate="yes" xml:space="preserve">
          <source>Undoes all SmartSet() &amp;amp; Set() calls, restoring original definitions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90ac7bb3b01b32e952ee295aa92163d24d25615d" translate="yes" xml:space="preserve">
          <source>Unicode strings</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="976c215ff49db1df66b6e17319495979c35769ef" translate="yes" xml:space="preserve">
          <source>Uniform Inner Dimensions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8560175804cd279f78f66d9a95299a6ca618dbfc" translate="yes" xml:space="preserve">
          <source>Uniform Outer Dimensions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="877e52ac4e7248f2800c12c1d91696ac0ce4e843" translate="yes" xml:space="preserve">
          <source>Uniform and ragged outer dimensions may be interleaved, meaning that a tensor with any combination of ragged and uniform dimensions may be created. For example, a RaggedTensor &lt;code&gt;t4&lt;/code&gt; with shape &lt;code&gt;[3, None, 4, 8, None, 2]&lt;/code&gt; could be constructed as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f358f22f84035b210a806ebde2b7ba64470c6103" translate="yes" xml:space="preserve">
          <source>Uniform distribution on an integer type's entire range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a636a3f76b9605e2629209f45efcb9cace24843" translate="yes" xml:space="preserve">
          <source>Uniform distribution with &lt;code&gt;low&lt;/code&gt; and &lt;code&gt;high&lt;/code&gt; parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82b9b64659267074d1c1ba85abf6981423a4e4d2" translate="yes" xml:space="preserve">
          <source>UniformRowLength(length,)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dd84a267eb06050e1d51577f84d2e5f9d140c27" translate="yes" xml:space="preserve">
          <source>Unique integer ID.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3716d64264f900396f1af7fc16d7b86fdf992a50" translate="yes" xml:space="preserve">
          <source>Unknown error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ecf9df1b9c446def763a4926348afbeccb07217" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../../data/dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb9a4a5a4e9492ece2558573a0acc8a789ddc313" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../data/dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4abe35be36c6363497bfcbdede20ee0472e70d3" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;to_graph&lt;/code&gt; is a low-level transpiler that converts Python code to TensorFlow graph code. It does not implement any caching, variable management or create any actual ops, and is best used where greater control over the generated TensorFlow graph is desired. Another difference from &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; is that &lt;code&gt;to_graph&lt;/code&gt; will not wrap the graph into a TensorFlow function or a Python callable. Internally, &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; uses &lt;code&gt;to_graph&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c289f8aae64df7cd4ff7fdb8457061e6c012cdc6" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;wrap_function&lt;/code&gt; will only trace the Python function once. As with placeholders in TF 1.x, shapes and dtypes must be provided to &lt;code&gt;wrap_function&lt;/code&gt;'s &lt;code&gt;signature&lt;/code&gt; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="704bf993fd1f302cbdbbea9b08e8e2b996cf4dcb" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and each batch will be encoded as a &lt;a href=&quot;../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;. Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ebb4bc2458197f2fb3172235869b74c91d350b2" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69eb42951cde2b887407e0d83e6a95dc1668220b" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;to_graph&lt;/code&gt; is a low-level transpiler that converts Python code to TensorFlow graph code. It does not implement any caching, variable management or create any actual ops, and is best used where greater control over the generated TensorFlow graph is desired. Another difference from &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; is that &lt;code&gt;to_graph&lt;/code&gt; will not wrap the graph into a TensorFlow function or a Python callable. Internally, &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; uses &lt;code&gt;to_graph&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcde43ba32f97c1ff2549287396cb94e24747c3e" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;dataset#batch&quot;&gt;&lt;code&gt;tf.data.Dataset.batch&lt;/code&gt;&lt;/a&gt;, the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in &lt;code&gt;padding_shapes&lt;/code&gt;. The &lt;code&gt;padding_shapes&lt;/code&gt; argument determines the resulting shape for each dimension of each component in an output element:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c42cd1138a7b09e8aab4b48a275bce9fecd055c5" translate="yes" xml:space="preserve">
          <source>Unlike &lt;code&gt;mean_squared_error&lt;/code&gt;, which is a measure of the differences between corresponding elements of &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;, &lt;code&gt;mean_pairwise_squared_error&lt;/code&gt; is a measure of the differences between pairs of corresponding elements of &lt;code&gt;predictions&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54b3e19f1658856fdd01905f7b1d827a5e2c7da2" translate="yes" xml:space="preserve">
          <source>Unlike &lt;code&gt;stack&lt;/code&gt;, &lt;code&gt;parallel_stack&lt;/code&gt; does NOT support backpropagation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13fc8fd7e6240efedf349e3dbe4446fea97e3c13" translate="yes" xml:space="preserve">
          <source>Unlike a TensorShape object, a TensorSpec object contains both shape and dtype information for a tensor. This method allows layers to provide output dtype information if it is different from the input dtype. For any layer that doesn't implement this function, the framework will fall back to use &lt;code&gt;compute_output_shape&lt;/code&gt;, and will assume that the output dtype matches the input dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43b00e58be5bd1f34d6a3d43cebfb8995414356d" translate="yes" xml:space="preserve">
          <source>Unlike assertRaisesRegex, this method takes a literal string, not a regular expression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="780bb9592c9dfb9fae30e2efc18623daa3e2cff4" translate="yes" xml:space="preserve">
          <source>Unlike the older op &lt;a href=&quot;compat/v1/squeeze&quot;&gt;&lt;code&gt;tf.compat.v1.squeeze&lt;/code&gt;&lt;/a&gt;, this op does not accept a deprecated &lt;code&gt;squeeze_dims&lt;/code&gt; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9828410fab6a8798616092f30a5aa2ae3611617b" translate="yes" xml:space="preserve">
          <source>Unordered dictionaries are not supported in eager mode when &lt;code&gt;exclusive=False&lt;/code&gt;. Use a list of tuples instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0657883ef20cc657b888740e46664440ff735ff1" translate="yes" xml:space="preserve">
          <source>Unpacking behavior for iterator-like inputs: A common pattern is to pass a tf.data.Dataset, generator, or tf.keras.utils.Sequence to the &lt;code&gt;x&lt;/code&gt; argument of fit, which will in fact yield not only features (x) but optionally targets (y) and sample weights. Keras requires that the output of such iterator-likes be unambiguous. The iterator should return a tuple of length 1, 2, or 3, where the optional second and third elements will be used for y and sample_weight respectively. Any other type provided will be wrapped in a length one tuple, effectively treating everything as 'x'. When yielding dicts, they should still adhere to the top-level tuple structure. e.g. &lt;code&gt;({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)&lt;/code&gt;. Keras will not attempt to separate features, targets, and weights from the keys of a single dict. A notable unsupported data type is the namedtuple. The reason is that it behaves like both an ordered datatype (tuple) and a mapping datatype (dict). So given a namedtuple of the form: &lt;code&gt;namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])&lt;/code&gt; it is ambiguous whether to reverse the order of the elements when interpreting the value. Even worse is a tuple of the form: &lt;code&gt;namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])&lt;/code&gt; where it is unclear if the tuple was intended to be unpacked into x, y, and sample_weight or passed through as a single element to &lt;code&gt;x&lt;/code&gt;. As a result the data processing code will simply raise a ValueError if it encounters a namedtuple. (Along with instructions to remedy the issue.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="243ed91dcd10a0424df6d36deb350e6391df8548" translate="yes" xml:space="preserve">
          <source>Unpacks &lt;code&gt;num&lt;/code&gt; tensors from &lt;code&gt;value&lt;/code&gt; by chipping it along the &lt;code&gt;axis&lt;/code&gt; dimension. If &lt;code&gt;num&lt;/code&gt; is not specified (the default), it is inferred from &lt;code&gt;value&lt;/code&gt;'s shape. If &lt;code&gt;value.shape[axis]&lt;/code&gt; is not known, &lt;code&gt;ValueError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48918b5563a8ceafb76129f6bc60ab73e49603cf" translate="yes" xml:space="preserve">
          <source>Unpacks the given dimension of a rank-&lt;code&gt;R&lt;/code&gt; tensor into rank-&lt;code&gt;(R-1)&lt;/code&gt; tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05dc9402d9793ff470926b16aca6821cb0999026" translate="yes" xml:space="preserve">
          <source>Unparses all flags to the point before any FLAGS(argv) was called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e5da72ba27bb718f2dac7fc946f26f49a76ad43" translate="yes" xml:space="preserve">
          <source>Unscales the gradients by the loss scale.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c32922004f1cab6d2b368005f373dc639dc0003a" translate="yes" xml:space="preserve">
          <source>Unspecified run-time error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b986cea6fdf9453b34548d5133226ff149db996f" translate="yes" xml:space="preserve">
          <source>Unstack the values of a &lt;code&gt;Tensor&lt;/code&gt; in the TensorArray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5093a3d1578793a3f4e74f50d7ce016ac60ef3d" translate="yes" xml:space="preserve">
          <source>Untested. Very likely will not learn to output repeated classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a0115166e5bef4246c231811f6b2ed301118eb7" translate="yes" xml:space="preserve">
          <source>Until the release of TF 2.0, we need the legacy behavior of &lt;code&gt;TensorShape&lt;/code&gt; to coexist with the new behavior. This utility is a bridge between the two.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45306172633156360fe411da89aad86bcba27d77" translate="yes" xml:space="preserve">
          <source>Unwrapping and merging: Consider calling a function &lt;code&gt;fn&lt;/code&gt; on multiple replicas, like &lt;code&gt;experimental_run_v2(fn, args=[w])&lt;/code&gt; with an argument &lt;code&gt;w&lt;/code&gt; that is a wrapped value. This means &lt;code&gt;w&lt;/code&gt; will have a map taking replica id &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;w0&lt;/code&gt;, replica id &lt;code&gt;11&lt;/code&gt; to &lt;code&gt;w1&lt;/code&gt;, etc. &lt;code&gt;experimental_run_v2()&lt;/code&gt; unwraps &lt;code&gt;w&lt;/code&gt; before calling &lt;code&gt;fn&lt;/code&gt;, so it calls &lt;code&gt;fn(w0)&lt;/code&gt; on &lt;code&gt;d0&lt;/code&gt;, &lt;code&gt;fn(w1)&lt;/code&gt; on &lt;code&gt;d1&lt;/code&gt;, etc. It then merges the return values from &lt;code&gt;fn()&lt;/code&gt;, which can possibly result in wrapped values. For example, let's say &lt;code&gt;fn()&lt;/code&gt; returns a tuple with three components: &lt;code&gt;(x, a, v0)&lt;/code&gt; from replica 0, &lt;code&gt;(x, b, v1)&lt;/code&gt; on replica 1, etc. If the first component is the same object &lt;code&gt;x&lt;/code&gt; from every replica, then the first component of the merged result will also be &lt;code&gt;x&lt;/code&gt;. If the second component is different (&lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, ...) from each replica, then the merged value will have a wrapped map from replica device to the different values. If the third component is the members of a mirrored variable (&lt;code&gt;v&lt;/code&gt; maps &lt;code&gt;d0&lt;/code&gt; to &lt;code&gt;v0&lt;/code&gt;, &lt;code&gt;d1&lt;/code&gt; to &lt;a href=&quot;../../v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt;, etc.), then the merged result will be that mirrored variable (&lt;code&gt;v&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="452d19a44e1939a79c6b1e46110b7518ec2e32f4" translate="yes" xml:space="preserve">
          <source>Unwrapping and merging: Consider calling a function &lt;code&gt;fn&lt;/code&gt; on multiple replicas, like &lt;code&gt;experimental_run_v2(fn, args=[w])&lt;/code&gt; with an argument &lt;code&gt;w&lt;/code&gt; that is a wrapped value. This means &lt;code&gt;w&lt;/code&gt; will have a map taking replica id &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;w0&lt;/code&gt;, replica id &lt;code&gt;11&lt;/code&gt; to &lt;code&gt;w1&lt;/code&gt;, etc. &lt;code&gt;experimental_run_v2()&lt;/code&gt; unwraps &lt;code&gt;w&lt;/code&gt; before calling &lt;code&gt;fn&lt;/code&gt;, so it calls &lt;code&gt;fn(w0)&lt;/code&gt; on &lt;code&gt;d0&lt;/code&gt;, &lt;code&gt;fn(w1)&lt;/code&gt; on &lt;code&gt;d1&lt;/code&gt;, etc. It then merges the return values from &lt;code&gt;fn()&lt;/code&gt;, which can possibly result in wrapped values. For example, let's say &lt;code&gt;fn()&lt;/code&gt; returns a tuple with three components: &lt;code&gt;(x, a, v0)&lt;/code&gt; from replica 0, &lt;code&gt;(x, b, v1)&lt;/code&gt; on replica 1, etc. If the first component is the same object &lt;code&gt;x&lt;/code&gt; from every replica, then the first component of the merged result will also be &lt;code&gt;x&lt;/code&gt;. If the second component is different (&lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, ...) from each replica, then the merged value will have a wrapped map from replica device to the different values. If the third component is the members of a mirrored variable (&lt;code&gt;v&lt;/code&gt; maps &lt;code&gt;d0&lt;/code&gt; to &lt;code&gt;v0&lt;/code&gt;, &lt;code&gt;d1&lt;/code&gt; to &lt;a href=&quot;../compat/v1&quot;&gt;&lt;code&gt;v1&lt;/code&gt;&lt;/a&gt;, etc.), then the merged result will be that mirrored variable (&lt;code&gt;v&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="447e8380a0660bcbaf0b5a0132d4263bb7475a27" translate="yes" xml:space="preserve">
          <source>Unwraps an object into a list of TFDecorators and a final target.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f84ad806586080c9477df4b9148217324f31d72e" translate="yes" xml:space="preserve">
          <source>Up-to-date gradients (i.e., time step at which gradient was computed is equal to the accumulator's time step) are added to the accumulator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fe8e246cbfb66ec49e8326c839db8c07c5c7366" translate="yes" xml:space="preserve">
          <source>Update (</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6509bc67c069e61a7a1a3a68aa4391deff81b6d2" translate="yes" xml:space="preserve">
          <source>Update &lt;code&gt;ref&lt;/code&gt; by adding &lt;code&gt;value&lt;/code&gt; to it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05a75e8ad72ec7a17916b0418183b2ae49757686" translate="yes" xml:space="preserve">
          <source>Update &lt;code&gt;ref&lt;/code&gt; by assigning &lt;code&gt;value&lt;/code&gt; to it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0da9a4ecf7a09eb5b3d6a68070c44c71f746dcb9" translate="yes" xml:space="preserve">
          <source>Update &lt;code&gt;ref&lt;/code&gt; by subtracting &lt;code&gt;value&lt;/code&gt; from it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d6d9dee5acd7031de9e9744560f0e2f29a28a2c" translate="yes" xml:space="preserve">
          <source>Update op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3f52bac13b63cbb6e97bf073a84b716bbe078b6" translate="yes" xml:space="preserve">
          <source>Update step:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a77038db17ca8f9cacdb34920018f09eddc93c47" translate="yes" xml:space="preserve">
          <source>Update the last triggered time and step number.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d386d7ccaa88b6dedf1b5040c55b451c526442d6" translate="yes" xml:space="preserve">
          <source>Update the value of &lt;code&gt;x&lt;/code&gt; by adding &lt;code&gt;increment&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbd7754fb14c25638e64d5d064bb72937445b6c4" translate="yes" xml:space="preserve">
          <source>Update the value of &lt;code&gt;x&lt;/code&gt; by subtracting &lt;code&gt;decrement&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdd024c3635252f3a95af60168a7a02c85468f31" translate="yes" xml:space="preserve">
          <source>Updated base class for optimizers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f63d62e4ed45a361aebb6397e1fccc02f07b3ec2" translate="yes" xml:space="preserve">
          <source>Updates eval metrics. See &lt;code&gt;base_head.Head&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25882cbb9d1b53825b652d00bf42872915dbaa9e" translate="yes" xml:space="preserve">
          <source>Updates internal vocabulary based on a list of sequences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="852460ee15870b6e90ad0684cbc07e2e2a1a46d1" translate="yes" xml:space="preserve">
          <source>Updates internal vocabulary based on a list of texts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf38595a5f74f710192dab7d4c5a5b9f35f64f69" translate="yes" xml:space="preserve">
          <source>Updates loss scale based on if gradients are finite in current step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ff6b49a83b568897a31a71591847bcb981cfe8c" translate="yes" xml:space="preserve">
          <source>Updates metric objects and returns a &lt;code&gt;dict&lt;/code&gt; of the updated metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04014643289292114c04f072ec1d42a7ffcf535f" translate="yes" xml:space="preserve">
          <source>Updates the content of the 'checkpoint' file. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="114215d83f25c29dd880192b62cf9c4d735d8aca" translate="yes" xml:space="preserve">
          <source>Updates the progress bar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3aa5183ae2c5fffe19c95fc5154e5548921fe2d" translate="yes" xml:space="preserve">
          <source>Updates the shape of a tensor and checks at runtime that the shape holds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d45fc3ae1d9fcc9b117583faaa29b9c68525b6d1" translate="yes" xml:space="preserve">
          <source>Updates the shape of this tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd283fb80513334be997d84fc1ce654a3740f2f1" translate="yes" xml:space="preserve">
          <source>Updates the value of the loss scale.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56d5a06c3dd0023752b72f3ca770e1ae3effe80d" translate="yes" xml:space="preserve">
          <source>Updates this variable with the max of &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b0e1aa88bedb98a31d52dc0db2aabdbdc628dd2" translate="yes" xml:space="preserve">
          <source>Updates this variable with the max of &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="729d65b580f1272ed91207fc8a10aa3312f5c72c" translate="yes" xml:space="preserve">
          <source>Updates this variable with the min of &lt;a href=&quot;../../indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee9c6cf89fa6d5d3bc7214b300a7628504d2e372" translate="yes" xml:space="preserve">
          <source>Updates this variable with the min of &lt;a href=&quot;indexedslices&quot;&gt;&lt;code&gt;tf.IndexedSlices&lt;/code&gt;&lt;/a&gt; and itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b62b62db1c38cdd8d87bd06d704758f1b3977490" translate="yes" xml:space="preserve">
          <source>Updating and clearing custom objects using &lt;code&gt;custom_object_scope&lt;/code&gt; is preferred, but &lt;code&gt;get_custom_objects&lt;/code&gt; can be used to directly access &lt;code&gt;_GLOBAL_CUSTOM_OBJECTS&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="281cba0fb3149b6c3774ed01f37649638874e882" translate="yes" xml:space="preserve">
          <source>Upon a load, the subset of variables and assets supplied as part of the specific meta graph def, will be restored into the supplied session. The values of the variables though will correspond to the saved values from the first meta graph added to the SavedModel using &lt;code&gt;add_meta_graph_and_variables(...)&lt;/code&gt; in &lt;code&gt;builder.py&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e44dc51c175ff5c0db1e82d8dfe21d3d95479e8" translate="yes" xml:space="preserve">
          <source>Upper boundary of the output interval.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c31d78903813b3bcaeecbae756ddce1af8f35bae" translate="yes" xml:space="preserve">
          <source>Upsampling layer for 1D inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b0d1a97658971e96b3f9be123da52362174eefa" translate="yes" xml:space="preserve">
          <source>Upsampling layer for 2D inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8e99e181057faa2a85bca621f7cd639c1901c16" translate="yes" xml:space="preserve">
          <source>Upsampling layer for 3D inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bb18642b70b9f8a9c12ccf39487328f306b8e19" translate="yes" xml:space="preserve">
          <source>Usage</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9629fc5be7eebf84f66a1a4fe14d7eee29fbc498" translate="yes" xml:space="preserve">
          <source>Usage Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fec43ce445f974147bd0eb223a50147e7fb7202d" translate="yes" xml:space="preserve">
          <source>Usage example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77817d0a0c43f5e8811381e684f28870ad0caaef" translate="yes" xml:space="preserve">
          <source>Usage in a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7f68eccfb39ab6d5044b1fe94d8202e173daf81" translate="yes" xml:space="preserve">
          <source>Usage with distribution strategy and custom training loop:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e394973fc15ca8e6a0ab7b5e15b6537c110fcd61" translate="yes" xml:space="preserve">
          <source>Usage with tf.keras API:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b672bfd407587ac4347c7d14f539f0167c943965" translate="yes" xml:space="preserve">
          <source>Usage with the &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt; API:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3a64fc9df2f2b5aa9b2b0f2f696a9fa962d415a" translate="yes" xml:space="preserve">
          <source>Usage with the &lt;code&gt;compile&lt;/code&gt; API:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="861a0e430ffac5e4ae6e11b7a947f2c32d388cf4" translate="yes" xml:space="preserve">
          <source>Usage:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="030e432f7e4bb780778d21710d19d27e9dde09e7" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;../keras/models/load_model&quot;&gt;&lt;code&gt;tf.keras.models.load_model&lt;/code&gt;&lt;/a&gt; to restore the Keras model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4c2fa90899bd40eef81dcc968f1e443a9a43ef7" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;global_variables&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables&lt;/code&gt;&lt;/a&gt; instead. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3209823decab9f9b116ef0a97be20eccaaae6362" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;strategy#experimental_distribute_dataset&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_dataset&lt;/code&gt;&lt;/a&gt; to convert a &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; to something that produces &quot;per-replica&quot; values. If you want to manually specify how the dataset should be partitioned across replicas, use &lt;a href=&quot;strategy#experimental_distribute_datasets_from_function&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_distribute_datasets_from_function&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ee5b2fdcd82632d020da9ff566a06840585c6ea" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;strategy#experimental_run_v2&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt;&lt;/a&gt; to run a function once per replica, taking values that may be &quot;per-replica&quot; (e.g. from a distributed dataset) and returning &quot;per-replica&quot; values. This function is executed in &quot;replica context&quot;, which means each operation is performed separately on each replica.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b44531c2feeada9ccb9c2de903665876111434ff" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;__floordiv__&lt;/code&gt; via &lt;code&gt;x // y&lt;/code&gt; instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2767ed64c3817a4622daa8e917be1f662fce734c" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;as_numpy_iterator&lt;/code&gt; to inspect the content of your dataset. To see element shapes and types, print dataset elements directly instead of using &lt;code&gt;as_numpy_iterator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5eb34124b3d3c72e61b1960b8b0273621cb17166" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;distribution&lt;/code&gt; to create a linear combination of &lt;code&gt;value&lt;/code&gt; with shape &lt;code&gt;batch_size, Tq, dim]&lt;/code&gt;: &lt;code&gt;return tf.matmul(distribution, value)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44e30be08758ea8ade80932cd95cdb8d64bb47a8" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;flat_map&lt;/code&gt; if you want to make sure that the order of your dataset stays the same. For example, to flatten a dataset of batches into a dataset of their elements:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a992c4c721de761461c5374c7bd3a4aff948363" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;get_slot_names()&lt;/code&gt; to get the list of slot names created by the &lt;code&gt;Optimizer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91f7ee28a1020db4d8680f6cfcc039630f6cf6c7" translate="yes" xml:space="preserve">
          <source>Use Keras-style variable management.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9643c07a64899011c5e66444b786696c2c1f292c" translate="yes" xml:space="preserve">
          <source>Use a GPU</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ef12200042309c3ec0320c88bb43b5872439b7c" translate="yes" xml:space="preserve">
          <source>Use a TPU</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55e615040b350f7d0e69b2efeab665769ae7dff0" translate="yes" xml:space="preserve">
          <source>Use cached_session instead. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a45a7fcfd0c3a826284614faab211360451f5baa" translate="yes" xml:space="preserve">
          <source>Use control flow v2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="370035f7e921eeac90f213974c56e368a0053937" translate="yes" xml:space="preserve">
          <source>Use for a single program</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f43fa9092b2f91bd555938c5ea3e365d94b5e8be" translate="yes" xml:space="preserve">
          <source>Use for multiple replicas</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8399a93fbe608ceae7467ffa9f4443f49ecb43c5" translate="yes" xml:space="preserve">
          <source>Use regexes=[''] for a regex that will always pass.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89fcdf03d75c5035154abf603c2a5d6a8e7923ee" translate="yes" xml:space="preserve">
          <source>Use scores to calculate a distribution with shape &lt;code&gt;[batch_size, Tq, Tv]&lt;/code&gt;: &lt;code&gt;distribution = tf.nn.softmax(scores)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="434fa6ee48f96c719d58baf9d88af78b48a7c5de" translate="yes" xml:space="preserve">
          <source>Use the &lt;code&gt;use_gpu&lt;/code&gt; and &lt;code&gt;force_gpu&lt;/code&gt; options to control where ops are run. If &lt;code&gt;force_gpu&lt;/code&gt; is True, all ops are pinned to &lt;code&gt;/device:GPU:0&lt;/code&gt;. Otherwise, if &lt;code&gt;use_gpu&lt;/code&gt; is True, TensorFlow tries to run as many ops on the GPU as possible. If both &lt;code&gt;force_gpu and&lt;/code&gt;use_gpu` are False, all ops are pinned to the CPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd23d3f693402848b5c571179d734fa24d293240" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple enum values into the list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2ec95228b5df088b9e12de695d7a5b48f073d13" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple enum values into the list. The 'default' may be a single string (which will be converted into a single-element list) or a list of strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cd854f1deb653ced29c38efa8b46ec0bd203ec8" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple float values into the list. The 'default' may be a single float (which will be converted into a single-element list) or a list of floats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ba777030d82e3febc7f170821e4862f2ace63cd" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple integer values into the list. The 'default' may be a single integer (which will be converted into a single-element list) or a list of integers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b36c5e7734d6891179ff0616c0be42883b3178af" translate="yes" xml:space="preserve">
          <source>Use the flag on the command line multiple times to place multiple string values into the list. The 'default' may be a single string (which will be converted into a single-element list) or a list of strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3dd2345ae786232011837f1b50ba242eb1986f2" translate="yes" xml:space="preserve">
          <source>Use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). For each example, there should be a single floating-point value per prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cea461fc9af427f5cd3544343b029f1c2bab9d0b" translate="yes" xml:space="preserve">
          <source>Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided as integers. If you want to provide labels using &lt;code&gt;one-hot&lt;/code&gt; representation, please use &lt;code&gt;CategoricalCrossentropy&lt;/code&gt; loss. There should be &lt;code&gt;# classes&lt;/code&gt; floating point values per feature for &lt;code&gt;y_pred&lt;/code&gt; and a single floating point value per feature for &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78d33f54d7ac855026c26bfd507ca58a0c209d64" translate="yes" xml:space="preserve">
          <source>Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a &lt;code&gt;one_hot&lt;/code&gt; representation. If you want to provide labels as integers, please use &lt;code&gt;SparseCategoricalCrossentropy&lt;/code&gt; loss. There should be &lt;code&gt;# classes&lt;/code&gt; floating point values per feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c6c9c3f9fd66d91bb804a873975c909932a10ca" translate="yes" xml:space="preserve">
          <source>Use this crossentropy metric when there are two or more label classes. We expect labels to be provided as integers. If you want to provide labels using &lt;code&gt;one-hot&lt;/code&gt; representation, please use &lt;code&gt;CategoricalCrossentropy&lt;/code&gt; metric. There should be &lt;code&gt;# classes&lt;/code&gt; floating point values per feature for &lt;code&gt;y_pred&lt;/code&gt; and a single floating point value per feature for &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d8dc9e6eb45eed6afcf79258afbec19d798dabb" translate="yes" xml:space="preserve">
          <source>Use this function in place of &lt;a href=&quot;../../../../feature_column/embedding_column&quot;&gt;&lt;code&gt;tf.compat.v1.feature_column.embedding_column&lt;/code&gt;&lt;/a&gt; when you want to use the TPU to accelerate your embedding lookups via TPU embeddings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cc5d4e2629c110ebe8857052924d43b36a33d1a" translate="yes" xml:space="preserve">
          <source>Use this function in place of tf.compat.v1.feature_column.shared_embedding_columns` when you want to use the TPU to accelerate your embedding lookups via TPU embeddings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e33c1dd0300e16f424a91617a667c9261bc9be4c" translate="yes" xml:space="preserve">
          <source>Use this function to prevent regularization of variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9622b2273be64542684f76f86eb661f385ac65c8" translate="yes" xml:space="preserve">
          <source>Use this function to wrap any op, maintaining its behavior in the forward pass, but replacing the original op in the backward graph with an identity. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe53876e652ed0ef4c2e62692c0a8476320563f1" translate="yes" xml:space="preserve">
          <source>Use this interface if you need to provide a custom loss/head. For example, the following will be equivalent to using BoostedTreesRegressor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fc9a09a598f08be35c9b3e469cc86fb8ef5c5c8" translate="yes" xml:space="preserve">
          <source>Use this method with the &lt;code&gt;with&lt;/code&gt; keyword to specify that ops created within the scope of a block should be added to this graph. In this case, once the scope of the &lt;code&gt;with&lt;/code&gt; is exited, the previous default graph is set again as default. There is a stack, so it's ok to have multiple nested levels of &lt;code&gt;as_default&lt;/code&gt; calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cb0006ae0bc4a4d2c6cc55d9288fc8e40392087" translate="yes" xml:space="preserve">
          <source>Use this transformation to produce a dataset that contains one instance of each unique element in the input. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1ae07580001407b54ea6c15a5ff62a49d8bc47c" translate="yes" xml:space="preserve">
          <source>Use this transformation to produce a dataset that contains the same elements as the input, but silently drops any elements that caused an error. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ecb994c8af6ea20690f2149dd63292f77fb37b5" translate="yes" xml:space="preserve">
          <source>Use this when each of your sparse inputs has both an ID and a value. For example, if you're representing text documents as a collection of word frequencies, you can provide 2 parallel sparse input features ('terms' and 'frequencies' below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="579c3daf1696275881a685fed877b2bca49537c7" translate="yes" xml:space="preserve">
          <source>Use this when the caller knows that this FlagValues has been parsed as if a &lt;strong&gt;call&lt;/strong&gt;() invocation has happened. This is only a public method for use by things like appcommands which do additional command like parsing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2352dd0c45545d0dddd83edf7a87ae1c7d6a2a5" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are in string or integer format, and you have a vocabulary file that maps each value to an integer ID. By default, out-of-vocabulary values are ignored. Use either (but not both) of &lt;code&gt;num_oov_buckets&lt;/code&gt; and &lt;code&gt;default_value&lt;/code&gt; to specify how to include out-of-vocabulary values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebfbbc24af8cd5c1b3325ddc7e9b9110d158077e" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are in string or integer format, and you have an in-memory vocabulary mapping each value to an integer ID. By default, out-of-vocabulary values are ignored. Use either (but not both) of &lt;code&gt;num_oov_buckets&lt;/code&gt; and &lt;code&gt;default_value&lt;/code&gt; to specify how to include out-of-vocabulary values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c2d5c81b6b22ab6aebbd8420d0922e66fb231ec" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are integers in the range &lt;code&gt;[0, num_buckets)&lt;/code&gt;, and you want to use the input value itself as the categorical ID. Values outside this range will result in &lt;code&gt;default_value&lt;/code&gt; if specified, otherwise it will fail.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be55e7e6d26bbf4b36ff797d2545265b0a6866e3" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are sparse and of the same type (e.g. watched and impression video IDs that share the same vocabulary), and you want to convert them to a dense representation (e.g., to feed to a DNN).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce58da03135c2b5ad93ed7aa78fffe6ae161dd6d" translate="yes" xml:space="preserve">
          <source>Use this when your inputs are sparse, but you want to convert them to a dense representation (e.g., to feed to a DNN).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c980245437253028d09a527c56663fc1386fb381" translate="yes" xml:space="preserve">
          <source>Use this when your sparse features are in string or integer format, and you want to distribute your inputs into a finite number of buckets by hashing. output_id = Hash(input_feature_string) % bucket_size for string type input. For int type input, the value is converted to its string representation first and then hashed by the same formula.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0594027b100d87bb5949b9d94aec04e20184fe6" translate="yes" xml:space="preserve">
          <source>Use with &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b2a8e4ff6f36d2ae408104e160d5b3b9371d34a" translate="yes" xml:space="preserve">
          <source>Use with the &lt;code&gt;with&lt;/code&gt; keyword to specify that all operations constructed within the context should have control dependencies on &lt;code&gt;control_inputs&lt;/code&gt;. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69dd6dc7e65c4b9fe7cd1454b69ad4047ff65a5d" translate="yes" xml:space="preserve">
          <source>Use with the &lt;code&gt;with&lt;/code&gt; keyword to specify that calls to &lt;a href=&quot;../../operation#run&quot;&gt;&lt;code&gt;tf.Operation.run&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt; should be executed in this session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="687844afc928e1515653eca2dc67313bcb251adb" translate="yes" xml:space="preserve">
          <source>Used for Tensor.&lt;strong&gt;div&lt;/strong&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ed98ab98b4d3bc08d8823f62d5fecc305aaf972" translate="yes" xml:space="preserve">
          <source>Used for generating the &lt;code&gt;sampling_table&lt;/code&gt; argument for &lt;code&gt;skipgrams&lt;/code&gt;. &lt;code&gt;sampling_table[i]&lt;/code&gt; is the probability of sampling the word i-th most common word in a dataset (more common words should be sampled less frequently, for balance).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="838a9c1b2b1ad8d0483e3efe3752a2cfa857bf97" translate="yes" xml:space="preserve">
          <source>Used in &lt;code&gt;fit_generator&lt;/code&gt;, &lt;code&gt;evaluate_generator&lt;/code&gt;, &lt;code&gt;predict_generator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce35a302d37a4e5f24d1589056ce4a8ade1153e6" translate="yes" xml:space="preserve">
          <source>Used in the guide:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d57c19f05b013abb121e6d7231e8fb33b04353e" translate="yes" xml:space="preserve">
          <source>Used in the tutorials:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d5b31850f6cd998b34c1f803e97f421ab5e927c" translate="yes" xml:space="preserve">
          <source>Used to implement efficient stacked RNNs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1dc2e0b551da6f4f100efb7639cb33de1b18f9c4" translate="yes" xml:space="preserve">
          <source>Used to number checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33e1b276d404a935dc5326f961aab709a74eaaa4" translate="yes" xml:space="preserve">
          <source>Useful for e.g. connecting RNNs and convnets together.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c162068f6d2673c0d1e37e670b21e118d35909f" translate="yes" xml:space="preserve">
          <source>Useful special cases:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="288dbdb9bfd68b877505e5e2d999c8a104f5d6ad" translate="yes" xml:space="preserve">
          <source>Useful to avoid clutter from old models / layers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab56083300b8a34ad1a803f46ebcd7c664f460f2" translate="yes" xml:space="preserve">
          <source>User can call this function to disable 2.x behavior during complex migrations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="157f011efb63e43996c3b578c255e7d5545ba313" translate="yes" xml:space="preserve">
          <source>Users can write it to file for offline analysis by tfprof commandline or graphical interface.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0ec32691eaba97311f1cccd2dad97641a499fa1" translate="yes" xml:space="preserve">
          <source>Users must not modify any collections used in nest while this function is running.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06b0870bd9d2eea911ba0bf24a44afc23e3b6358" translate="yes" xml:space="preserve">
          <source>Users need to combine parsing spec of features with labels and weights (if any) since they are all parsed from same tf.Example instance. This utility combines these specs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="182c1f1a391ebf26b9c0b763f027f3059f9e6bd2" translate="yes" xml:space="preserve">
          <source>Users of &lt;code&gt;step_fn&lt;/code&gt; may perform &lt;code&gt;run()&lt;/code&gt; calls without running hooks by accessing the &lt;code&gt;session&lt;/code&gt;. A &lt;code&gt;run()&lt;/code&gt; call with hooks may be performed using &lt;code&gt;run_with_hooks()&lt;/code&gt;. Computation flow can be interrupted using &lt;code&gt;request_stop()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f188fa1f43efe8bdab97db20fb68ecadd592af6" translate="yes" xml:space="preserve">
          <source>Users will just instantiate a layer and then treat it as a callable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c72c8f3ece626a4705405cb3a7b8af47ef729815" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy&lt;/code&gt; loss average over classes and weighted sum over the batch. Namely, if the input logits have shape &lt;code&gt;[batch_size, n_classes]&lt;/code&gt;, the loss is the average over &lt;code&gt;n_classes&lt;/code&gt; and the weighted sum over &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11a9b701f656adfafd6806eb9e7ef756d209ed2e" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss, which is the same as &lt;code&gt;BinaryClassHead&lt;/code&gt;. The differences compared to &lt;code&gt;BinaryClassHead&lt;/code&gt; are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d8209fd0815d68d4830b41bd06d14a5cb947aa2" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e004400a6e3754313301e3fd9261a2c189b3474a" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sparse_softmax_cross_entropy&lt;/code&gt; loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e2b61f4b530febb6503deed927b41c373ddaaf3" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;str(value)&lt;/code&gt;, except for &lt;code&gt;bytes&lt;/code&gt; typed inputs, which are converted using &lt;code&gt;as_str&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2973e6aa554e21daa4adef06a74539c445b14d95" translate="yes" xml:space="preserve">
          <source>Uses utf-8 encoding for text by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="217a51c3037aab24f119676b38ba458afe249401" translate="yes" xml:space="preserve">
          <source>Using &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt;&lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt;&lt;/a&gt; for sparse multiplication:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="159ac66854831fd41477c6614f26e3ff55888f88" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt; with same shape as &lt;code&gt;input&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20acdd8f39a8fcbb172a5237734f68ee0d2be386" translate="yes" xml:space="preserve">
          <source>Using float64 is similar to mixed precision. Either the global policy can be set to float64, or &lt;code&gt;dtype='float64'&lt;/code&gt; can be passed to individual layers. For example, to set the global policy:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6b2bb4ba02dab533aac4565623cbaf2d9684521" translate="yes" xml:space="preserve">
          <source>Using graphs directly (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45c1897ccbe225e4b4bb0b5776304a91ccc424dd" translate="yes" xml:space="preserve">
          <source>Using scalar &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55be0948f7db3ef4c4e1ab2c5b8f53c076ac5356" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TensorBoard&lt;/code&gt; callback will work when eager execution is enabled, with the restriction that outputting histogram summaries of weights and gradients is not supported. Consequently, &lt;code&gt;histogram_freq&lt;/code&gt; will be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10b4feb7db468a7b136fb7eedc7778e772ed7977" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;Uniform&lt;/code&gt; distribution as an example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a70f4ea74dc28a0759892b77d899be11c4a630a4" translate="yes" xml:space="preserve">
          <source>Using the SavedModel format</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d5a6c95117b542db8bf88cf405c6beac37d2a3c" translate="yes" xml:space="preserve">
          <source>Using the above module would produce &lt;a href=&quot;variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;s and &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;s whose names included the module name:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ad33ae89a6d279a16ce6134859a442eac2581c4" translate="yes" xml:space="preserve">
          <source>Using the default job_name of worker, you can schedule ops to run remotely as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a6462b40df0780171c71c9fb37d8c4d54d01a02" translate="yes" xml:space="preserve">
          <source>Using this strategy will place any variables created in its scope on the specified device. Input distributed through this strategy will be prefetched to the specified device. Moreover, any functions called via &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; will also be placed on the specified device as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71b01f087dc4062f216f4b3e8e8c06a8b29e198c" translate="yes" xml:space="preserve">
          <source>Usually, this does not necessarily mean that the layer is run in inference mode (which is normally controlled by the &lt;code&gt;training&lt;/code&gt; argument that can be passed when calling a layer). &quot;Frozen state&quot; and &quot;inference mode&quot; are two separate concepts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cf4bb7b1492b783c6bc69633b0fe1693771c5d9" translate="yes" xml:space="preserve">
          <source>Utilities for ImageNet data preprocessing &amp;amp; prediction decoding.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08fb7be2421c2bdf2a78c1776aba074edf57a478" translate="yes" xml:space="preserve">
          <source>Utilities for preprocessing sequence data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae6bf25944794d7df424031b54eed9e8c6e9c537" translate="yes" xml:space="preserve">
          <source>Utilities for text input preprocessing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41900282bff2287f65ac5f2919d6b167c32aa670" translate="yes" xml:space="preserve">
          <source>Utilities for writing compatible code</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4209295b2fe1eb250fb221ec6cd68f34f854faae" translate="yes" xml:space="preserve">
          <source>Utility class for generating batches of temporal data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f80dd65b77c781d8eb1f4f65d0db44d5b92a1de" translate="yes" xml:space="preserve">
          <source>Utility function to build TensorInfo proto from a Tensor. (deprecated)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d66171638f7d7dc0d33fb68081060b45caf826a1" translate="yes" xml:space="preserve">
          <source>Utility function to build a SignatureDef protocol buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1fc6fdd2556af786588697b8b4da900e88da0b4" translate="yes" xml:space="preserve">
          <source>Utility functions for building and inspecting SignatureDef protos.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41a205ecd48940b5d4f27244d92bd652c4f4f6d1" translate="yes" xml:space="preserve">
          <source>Utility functions to assist with setup and construction of the SavedModel proto.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25e1689ca50193bb7593b638ace3275be8fc9300" translate="yes" xml:space="preserve">
          <source>Utility methods to create simple input_fns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98c6a5322edf6827b19ea21d2e974ec573fb37d2" translate="yes" xml:space="preserve">
          <source>V2 Compatibility</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f4dce99bbaf012216e610738a930ee809e1a1dd" translate="yes" xml:space="preserve">
          <source>VGG16 model for Keras.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16578957bc13d8fcce797647de9c6287bbab95bd" translate="yes" xml:space="preserve">
          <source>VGG19 model for Keras.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35d73c1e3e748be7af4094274c7c669844f7b39a" translate="yes" xml:space="preserve">
          <source>Validate and return float type based on &lt;code&gt;tensors&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cfbc94b8562d35a1a624063af44283471348553" translate="yes" xml:space="preserve">
          <source>Validated type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44cdd81777401755111de56bb90c9f9e4f31fb50" translate="yes" xml:space="preserve">
          <source>ValueError if &lt;code&gt;num_packs&lt;/code&gt; is negative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b03333735384a88c2a20365a2ab9d19d0855bf6a" translate="yes" xml:space="preserve">
          <source>ValueError if data format is unrecognized, if &lt;code&gt;value&lt;/code&gt; has less than two dimensions when &lt;code&gt;data_format&lt;/code&gt; is 'N..C'/&lt;code&gt;None&lt;/code&gt; or &lt;code&gt;value&lt;/code&gt; has less then three dimensions when &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;NC..&lt;/code&gt;, if &lt;code&gt;bias&lt;/code&gt; does not have exactly one dimension (is a vector), or if the size of &lt;code&gt;bias&lt;/code&gt; does not match the size of the channel dimension of &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1cad1ac50b9d58fe699af8d3719130c04596c12" translate="yes" xml:space="preserve">
          <source>ValueRowIds(key,)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9989c8b816fd103fa17ba450218cc3f655b85003" translate="yes" xml:space="preserve">
          <source>Values are merged in order, so if an index appears in both &lt;code&gt;indices[m][i]&lt;/code&gt; and &lt;code&gt;indices[n][j]&lt;/code&gt; for &lt;code&gt;(m,i) &amp;lt; (n,j)&lt;/code&gt; the slice &lt;code&gt;data[n][j]&lt;/code&gt; will appear in the merged result. If you do not need this guarantee, ParallelDynamicStitch might perform better on some devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31517cd57e02e0d5266cab70a1c38e47fcd19844" translate="yes" xml:space="preserve">
          <source>Values are not loaded immediately, but when the initializer is run (typically by running a &lt;a href=&quot;../global_variables_initializer&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables_initializer&lt;/code&gt;&lt;/a&gt; op).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7b1102521bf7adb2b3f3d054e8e942970be2d94" translate="yes" xml:space="preserve">
          <source>Values can also have the same locality as a variable, which is a mirrored value but residing on the same devices as the variable (as opposed to the compute devices). Such values may be passed to a call to &lt;a href=&quot;../../../distribute/strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt;&lt;/a&gt; to update the value of a variable. You may use &lt;a href=&quot;../../../distribute/strategyextended#colocate_vars_with&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt;&lt;/a&gt; to give a variable the same locality as another variable. This is useful, for example, for &quot;slot&quot; variables used by an optimizer for keeping track of statistics used to update a primary/model variable. You may convert a per-replica value to a variable's locality by using &lt;a href=&quot;../../../distribute/strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../distribute/strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2143538d5a76006c2fb34d48a187c9999b4ce092" translate="yes" xml:space="preserve">
          <source>Values can also have the same locality as a variable, which is a mirrored value but residing on the same devices as the variable (as opposed to the compute devices). Such values may be passed to a call to &lt;a href=&quot;strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt;&lt;/a&gt; to update the value of a variable. You may use &lt;a href=&quot;strategyextended#colocate_vars_with&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt;&lt;/a&gt; to give a variable the same locality as another variable. This is useful, for example, for &quot;slot&quot; variables used by an optimizer for keeping track of statistics used to update a primary/model variable. You may convert a per-replica value to a variable's locality by using &lt;a href=&quot;strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="332770f6ea1035cc31b26b51a3ff43d26f36a8a6" translate="yes" xml:space="preserve">
          <source>Values returned by all methods, such as &lt;code&gt;matmul&lt;/code&gt; or &lt;code&gt;determinant&lt;/code&gt; will be cast to &lt;code&gt;DTYPE&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b550e406a084548380628fd2909bf25b85b7d1f" translate="yes" xml:space="preserve">
          <source>Variable Constraint</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d982c2fd72628882252beffffe7353608ac38df" translate="yes" xml:space="preserve">
          <source>Variable regularization tensors are created when this property is accessed, so it is eager safe: accessing &lt;code&gt;losses&lt;/code&gt; under a &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will propagate gradients back to the corresponding variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9becbe8191297fcb35681c2cb0fd8d5255180628" translate="yes" xml:space="preserve">
          <source>Variable scope allows you to create new variables and to share already created ones while providing checks to not create or share by accident. For details, see the &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;Variable Scope How To&lt;/a&gt;, here we present only a few basic examples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78a94c97c2babdd8664aa38c452645afd7c11def" translate="yes" xml:space="preserve">
          <source>Variable scope object to carry defaults to provide to &lt;code&gt;get_variable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f736193c89669392caf0903ec1e19730e643644" translate="yes" xml:space="preserve">
          <source>Variable. The number of training steps this Optimizer has run.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f628de42a66fa9f6ab10a5ed8f37f3bfec4938d4" translate="yes" xml:space="preserve">
          <source>Variables are assigned to local CPU or the only GPU. If there is more than one GPU, compute operations (other than variable update operations) will be replicated across all GPUs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70a30a529e57576d822cecd0f271a7b5d39f84b7" translate="yes" xml:space="preserve">
          <source>Variables are automatically tracked when assigned to attributes of types inheriting from &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1655acbcc407ca5c5cc17d4daaba10766362006a" translate="yes" xml:space="preserve">
          <source>Variables are often captured and manipulated by &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s. This works the same way the un-decorated function would have:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9422ebfe912588a94b4db8ceb623ec6943b8ae1a" translate="yes" xml:space="preserve">
          <source>Variables created inside a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; must be owned outside the function and be created only once:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="198e5fbedc6e80bc4c09f5cf7cecc37f23ca5651" translate="yes" xml:space="preserve">
          <source>Variables created inside the strategy scope are &quot;owned&quot; by it:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecf6360262e709b4fb787134a5207269f78afa79" translate="yes" xml:space="preserve">
          <source>Variables created outside the strategy are not owned by it:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e85b51c74744b26c07cb066853860450f1f5376" translate="yes" xml:space="preserve">
          <source>Variables must be tracked by assigning them to an attribute of a tracked object or to an attribute of &lt;code&gt;obj&lt;/code&gt; directly. TensorFlow objects (e.g. layers from &lt;a href=&quot;../keras/layers&quot;&gt;&lt;code&gt;tf.keras.layers&lt;/code&gt;&lt;/a&gt;, optimizers from &lt;a href=&quot;../train&quot;&gt;&lt;code&gt;tf.train&lt;/code&gt;&lt;/a&gt;) track their variables automatically. This is the same tracking scheme that &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; uses, and an exported &lt;code&gt;Checkpoint&lt;/code&gt; object may be restored as a training checkpoint by pointing &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt; to the SavedModel's &quot;variables/&quot; subdirectory. Currently variables are the only stateful objects supported by &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;, but others (e.g. tables) will be supported in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51a7e747ba069953d31cbdce4de5483d9446f49f" translate="yes" xml:space="preserve">
          <source>Variables, placeholders, and independent operations can also be stored, as shown in the following example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="612d2ee1679ef5637187e20c4629a406547bfef9" translate="yes" xml:space="preserve">
          <source>Variables:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb96e64e18e9a621cc7ceb2976a5e75548f771d4" translate="yes" xml:space="preserve">
          <source>Variance is defined as,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d282722043467708dfd05bebcd66f9f1d34aee3d" translate="yes" xml:space="preserve">
          <source>Variance of a tensor, alongside the specified axis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99189c611d030a5281d712eaa2b886309eb67a6b" translate="yes" xml:space="preserve">
          <source>Variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="108fd2238efb49f633daf84e4120ae9f47cfdec6" translate="yes" xml:space="preserve">
          <source>Various libraries built on top of the core TensorFlow library take care of creating some or all of these pieces and storing them in well known collections in the graph. The &lt;code&gt;Scaffold&lt;/code&gt; class helps pick these pieces from the graph collections, creating and adding them to the collections if needed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6a6801f04fd08c4cf3ed0c985c50e0b3cc573dd" translate="yes" xml:space="preserve">
          <source>Vector length = Maximum element in vector &lt;code&gt;values&lt;/code&gt; is 5. Adding 1, which is 6 will be the vector length.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5115b80229d0ab74c010431ae650645a075fb17" translate="yes" xml:space="preserve">
          <source>Vector of coordinatewise logits.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="444c2b1f0bb53e9255195603b2fe9758758fc528" translate="yes" xml:space="preserve">
          <source>Vector of coordinatewise probabilities.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31a7604a3c742ea454ff128dd267ca1e16472796" translate="yes" xml:space="preserve">
          <source>View source</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a11a63ecf581d6810e65e62968e93200e384c05b" translate="yes" xml:space="preserve">
          <source>View source on GitHub</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d07bb0bd533bc6a8f9cecf11b29b925415f286e8" translate="yes" xml:space="preserve">
          <source>Vocabulary information for warm-starting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ec053f91b0e4f43b0ff9856f1f431195070e64b" translate="yes" xml:space="preserve">
          <source>WARNING: Experimental interface, subject to change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec7aa071ac596c65b3d8973549288f00dd9060fe" translate="yes" xml:space="preserve">
          <source>WARNING: If &lt;code&gt;sloppy&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the order of produced elements is not deterministic.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20a9fc48c3697f74feddc8ad93eb4c90b0d2bc47" translate="yes" xml:space="preserve">
          <source>WARNING: This function is nondeterministic, since it starts a separate thread for each tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e747855abeb092a18ebf6b91688f8d9d0024a93d" translate="yes" xml:space="preserve">
          <source>WARNING: tf.Variable objects by default have a non-intuitive memory model. A Variable is represented internally as a mutable Tensor which can non-deterministically alias other Tensors in a graph. The set of operations which consume a Variable and can lead to aliasing is undetermined and can change across TensorFlow versions. Avoid writing code which relies on the value of a Variable either changing or not changing as other operations happen. For example, using Variable objects or simple functions thereof as predicates in a &lt;a href=&quot;../../cond&quot;&gt;&lt;code&gt;tf.cond&lt;/code&gt;&lt;/a&gt; is dangerous and error-prone:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d2a3e7fd14becda3ad79ab623ee02dcfb3c4815" translate="yes" xml:space="preserve">
          <source>WRONG:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b55f8ed036408ccdecc6c75f53cbf2cbe602c833" translate="yes" xml:space="preserve">
          <source>Wait for threads to terminate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="480279e397ed207ff6dcb2138e6d19a402c6acab" translate="yes" xml:space="preserve">
          <source>Wait till the Coordinator is told to stop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd3c945de3bbe026196979524e2513d29b8047c4" translate="yes" xml:space="preserve">
          <source>Wait until the thread terminates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fcf196e2d36a225ff59aa7e988a3bab54a62688" translate="yes" xml:space="preserve">
          <source>Warm-start all TRAINABLE variables:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77a75fce3b44ee7c1b7330f94b51f223f12aced8" translate="yes" xml:space="preserve">
          <source>Warm-start all variables (including non-TRAINABLE):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="385cb07f1382ec501efc556d03af6fccd0c3bc88" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the embedding parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in the current model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="584c6949a375264781ffa7a3f30012c7d4ac99ba" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in current checkpoint and the parameters corresponding to &lt;code&gt;sc_vocab_list&lt;/code&gt; have a different name from the current checkpoint:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aee3196d9918b3cb93e150d394afe537d71e12b7" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in current checkpoint, and only 100 of those entries were used:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdac2057c8ebeb309f57754501e81125700d9646" translate="yes" xml:space="preserve">
          <source>Warm-start all weights in the model (input layer and hidden weights). Either the directory or a specific checkpoint can be provided (in the case of the former, the latest checkpoint will be used):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b13568e15d19ce108f966610dd72d6f433fdac5" translate="yes" xml:space="preserve">
          <source>Warm-start non-TRAINABLE variables &quot;v1&quot;, &quot;v1/Momentum&quot;, and &quot;v2&quot; but not &quot;v2/momentum&quot;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2a6608bb90e8edcca0d24db3c7888d49894818d" translate="yes" xml:space="preserve">
          <source>Warm-start only &lt;code&gt;sc_vocab_file&lt;/code&gt; embeddings (and no other variables), which have a different vocab from the one used in the current model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8454c4aaa6884d63b21f47b182bea32dff06b1d9" translate="yes" xml:space="preserve">
          <source>Warm-start only the embeddings (input layer):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="053dd1f00688a5e1c6f7bb11994384338437241d" translate="yes" xml:space="preserve">
          <source>Warm-starts a model using the given settings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="005fd2adc416b2f84c9268603969a31365422ae0" translate="yes" xml:space="preserve">
          <source>We add forget_bias (default: 1) to the biases of the forget gate in order to reduce the scale of forgetting in the beginning of the training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea902771c0c609fef23987d09209f89de6ea6624" translate="yes" xml:space="preserve">
          <source>We assume that the word frequencies follow Zipf's law (s=1) to derive a numerical approximation of frequency(rank):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee7344fa99f19a3db805ed04f05f653d28a573dc" translate="yes" xml:space="preserve">
          <source>We call it an 'accidental hit' when one of the target classes matches one of the sampled classes. This operation reports accidental hits as triples &lt;code&gt;(index, id, weight)&lt;/code&gt;, where &lt;code&gt;index&lt;/code&gt; represents the row number in &lt;code&gt;true_classes&lt;/code&gt;, &lt;code&gt;id&lt;/code&gt; represents the position in &lt;code&gt;sampled_candidates&lt;/code&gt;, and weight is &lt;code&gt;-FLOAT_MAX&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e90ccb70a2df6831216576e3e93ad8f84e29aaa" translate="yes" xml:space="preserve">
          <source>We can again draw the effect, this time using the symbols &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;o&lt;/code&gt; to distinguish the patches:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ec1d6719eaed84adca414b94403fe4b9bce8b6a" translate="yes" xml:space="preserve">
          <source>We can also, insert entire slices of a higher rank tensor all at once. For example, if we wanted to insert two slices in the first dimension of a rank-3 tensor with two matrices of new values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75a6bd3ac0e29b2d99ddde37882f73b9484c4c89" translate="yes" xml:space="preserve">
          <source>We can compute the mean and variance of the batch</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="141a486e547cdd8105ede80b487557001daeacfc" translate="yes" xml:space="preserve">
          <source>We can construct a CsvDataset from it as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="798032cd2519c55922a86a65a97aa8223721d2bf" translate="yes" xml:space="preserve">
          <source>We can use arguments:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfe0a32bb694084e323bdf39d8ca5b3bf5acf3b4" translate="yes" xml:space="preserve">
          <source>We first define two int64 tensors &lt;code&gt;paddings&lt;/code&gt; and &lt;code&gt;crops&lt;/code&gt; of shape &lt;code&gt;[num_spatial_dims, 2]&lt;/code&gt; based on the value of &lt;code&gt;padding&lt;/code&gt; and the spatial dimensions of the &lt;code&gt;input&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d6f96925005fe200b4a2292648a063218b208f4" translate="yes" xml:space="preserve">
          <source>We keep track of which flag is defined by which module so that we can later sort the flags by module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e09363c49b193f1ac1770f115d6d8136f2ddc43c" translate="yes" xml:space="preserve">
          <source>We next use the scale_factor to adjust min_range and max_range as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d1134ee5b3f5d2c7da4505ac717468ba6967616" translate="yes" xml:space="preserve">
          <source>We presuppose that the &lt;code&gt;sampled_candidates&lt;/code&gt; are unique.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f093997d3edad673438d9d10c06d984c5a8a5f76" translate="yes" xml:space="preserve">
          <source>We recommend that descendants of &lt;code&gt;Layer&lt;/code&gt; implement the following methods:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="664f0b931d5bb248f3df03fa1a45aa162e8bb7fc" translate="yes" xml:space="preserve">
          <source>We recommend using https://github.com/tensorflow/io to load your HDF5 data into a tf.data Dataset and passing that dataset to Keras.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6b1e174afc80b9d454ce2447d6b106dd858888d" translate="yes" xml:space="preserve">
          <source>We retrieve the information from the GCE APIs every time this method is called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e18048f9e04e3012f6199dfe11668988e00f3d9" translate="yes" xml:space="preserve">
          <source>We retrieve the information from the Kubernetes master every time this method is called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee86e3990a38d113aeda3e686a64aed6a6c21a17" translate="yes" xml:space="preserve">
          <source>We specify the size-related attributes as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d371d0dcdb3a29109c4aec0bd9662ca4cc225c96" translate="yes" xml:space="preserve">
          <source>We will assume that the input dataset is batched by the global batch size. With this assumption, we will make a best effort to divide each batch across all the replicas (one or more workers).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1e896bf769945f02ba4270d6713548acfff861f" translate="yes" xml:space="preserve">
          <source>Web-safe means that the encoder uses - and _ instead of + and /.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5ecd420b68c6ca62b2880bcb67d127d7527fd45" translate="yes" xml:space="preserve">
          <source>Weight updates (for instance, the updates of the moving mean and variance in a BatchNormalization layer) may be dependent on the inputs passed when calling a layer. Hence, when reusing the same layer on different inputs &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, some entries in &lt;code&gt;layer.updates&lt;/code&gt; may be dependent on &lt;code&gt;a&lt;/code&gt; and some on &lt;code&gt;b&lt;/code&gt;. This method automatically keeps track of dependencies.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="012994d31dee39cea10e34d13b123636095aef6d" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has shape &lt;code&gt;[batch_size]&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d1005c1318b48c01558d66a2ac013b81040339a" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;labels&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="834de6c05706f24229c420c387a2f8167f0b45d5" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;logits&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b075652dc6120aaf1d41f8a4dc2daf694ffa4a69" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;losses&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;losses&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8f11d4c7a3da229788db34932231d37e05fbe0b" translate="yes" xml:space="preserve">
          <source>Weighted loss float &lt;code&gt;Tensor&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has shape &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt;; otherwise, it is scalar. (Note &lt;code&gt;dN-1&lt;/code&gt; because all loss functions reduce by 1 dimension, usually axis=-1.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37a14c45a506771a19d570992ffb74e2a8ababd3" translate="yes" xml:space="preserve">
          <source>Weighted loss float &lt;code&gt;Tensor&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;labels&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23f94c92282719a4052aebc7d476aba406e80f05" translate="yes" xml:space="preserve">
          <source>Weights values as a list of numpy arrays.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79699365f3dd7ea5c60a1201001103f0e4d8e414" translate="yes" xml:space="preserve">
          <source>What &lt;code&gt;master&lt;/code&gt; string to use</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8126fc60320a74dd637a7bb9a583488f0b14222c" translate="yes" xml:space="preserve">
          <source>What happens in &lt;code&gt;adapt&lt;/code&gt;: Compute mean and variance of the data and store them as the layer's weights. &lt;code&gt;adapt&lt;/code&gt; should be called before &lt;code&gt;fit&lt;/code&gt;, &lt;code&gt;evaluate&lt;/code&gt;, or &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97233c5c3c8d20a5e9ffbdbe3b7ccb6a51db597b" translate="yes" xml:space="preserve">
          <source>When 'TF_CONFIG' environment variable is set, it parses cluster_spec, task_type and task_id from 'TF_CONFIG' and turns into a multi-worker strategy which mirrores models on GPUs of all machines in a cluster. In the current implementation, it uses all GPUs in a cluster and it assumes all workers have the same number of GPUs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5e1d55c89f446271b947fe72a857c539201c7dc" translate="yes" xml:space="preserve">
          <source>When 'antialias' is true, the sampling filter will anti-alias the input image as well as interpolate. When downsampling an image with &lt;a href=&quot;https://en.wikipedia.org/wiki/Spatial_anti-aliasing&quot;&gt;anti-aliasing&lt;/a&gt; the sampling filter kernel is scaled in order to properly anti-alias the input image signal. 'antialias' has no effect when upsampling an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aacbccc1a065c95aea812e79f50b9fb0809ae76" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;distribute&lt;/code&gt; or &lt;code&gt;experimental_distribute.train_distribute&lt;/code&gt; and &lt;code&gt;experimental_distribute.remote_cluster&lt;/code&gt; is set, this method will start a client running on the current host which connects to the &lt;code&gt;remote_cluster&lt;/code&gt; for training and evaluation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01497840225ce1bb0dcac0f82d53eb47485d512b" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;enable&lt;/code&gt; is set to None, an appropriate value will be picked automatically. The value picked may change between TensorFlow releases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d3c29ba7c1915daf444dfa9480a120b9d259cc0" translate="yes" xml:space="preserve">
          <source>When a DistributionStrategy is used, this function may only be called in a cross-replica context.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ee3d0211a7961d1892863b309bfae8dc55d02c2" translate="yes" xml:space="preserve">
          <source>When a Summary op is instantiated, a SummaryDescription of associated metadata is stored in its NodeDef. This method retrieves the description.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2c0bd0de968bcd753736a8da6d2db14223d5cf" translate="yes" xml:space="preserve">
          <source>When a op's float-type output tensor contains any Infinity or NaN, an &lt;a href=&quot;../errors/invalidargumenterror&quot;&gt;&lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt;&lt;/a&gt; will be thrown, with an error message that reveals the following information: - The type of the op that generated the tensor with bad numerics. - Data type (dtype) of the tensor. - Shape of the tensor (to the extent known at the time of eager execution or graph construction). - Name of the containing graph (if available). - (Graph mode only): The stack trace of the intra-graph op's creation, with a stack-height limit and a path-length limit for visual clarity. The stack frames that belong to the user's code (as opposed to tensorflow's internal code) are highlighted with a text arrow (&quot;-&amp;gt;&quot;). - (Eager mode only): How many of the offending tensor's elements are &lt;code&gt;Infinity&lt;/code&gt; and &lt;code&gt;NaN&lt;/code&gt;, respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b898b5ad811100780dad4051c33f639fd70aa1be" translate="yes" xml:space="preserve">
          <source>When a tf.random operation is built with XLA, the implementation doesn't pass the user provided seed to the XLA compiler. As such, the XLA compiler generates a random number and uses it as a seed when compiling the operation. This implementation causes a violation of the Tensorflow defined semantics in two aspects. First, changing the value of the user defined seed doesn't change the numbers generated by the operation. Second, when a seed is not specified, running the program multiple times will generate the same numbers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="493652c7a3597db99acb0cc5aae0cc36b4d15e47" translate="yes" xml:space="preserve">
          <source>When a trackable object is exported via &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save()&lt;/code&gt;&lt;/a&gt;, all the &lt;code&gt;Asset&lt;/code&gt;s reachable from it are copied into the SavedModel assets directory. Upon loading, the assets and the serialized functions that depend on them will refer to the correct filepaths inside the SavedModel directory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f1183817b3726ec7266e15fa411e144c4d1a1bb" translate="yes" xml:space="preserve">
          <source>When accessing the value of a TensorShape dimension, use this utility, like this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e15681c5c4d660d694d5dcc65f824f2819119a6a" translate="yes" xml:space="preserve">
          <source>When attempting to multiply a nD tensor with a nD tensor, it reproduces the Theano behavior. (e.g. &lt;code&gt;(2, 3) * (4, 3, 5) -&amp;gt; (2, 4, 5)&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c06f27a3b19deaf8176a82559892b7885f9b161" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), determines the CPU budget to use. Values greater than the number of schedulable CPU cores are allowed but may result in CPU contention. If None, defaults to the number of schedulable CPU cores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa75a73b6c69b49d6e19ddace76d0dc9e6d20863" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), determines whether to also autotune buffer sizes for datasets with parallelism. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="283f72551210c9459423ecb79011f0f8519629e6" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), identifies the algorithm to use for the autotuning optimization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32eb733d84fe74265b206fb4da02dbc0b66960e1" translate="yes" xml:space="preserve">
          <source>When building a complex model that uses many queues it is often difficult to gather all the queue runners that need to be run. This convenience function allows you to add a queue runner to a well known collection in the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5bcf632e0c577d3a09737c01de056496ad7c080" translate="yes" xml:space="preserve">
          <source>When building a machine learning model it is often convenient to distinguish between variables holding the trainable model parameters and other variables such as a &lt;code&gt;global step&lt;/code&gt; variable used to count training steps. To make this easier, the variable constructor supports a &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; parameter. If &lt;code&gt;True&lt;/code&gt;, the new variable is also added to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;. The convenience function &lt;code&gt;trainable_variables()&lt;/code&gt; returns the contents of this collection. The various &lt;code&gt;Optimizer&lt;/code&gt; classes use this collection as the default list of variables to optimize.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68a44f742db33e692724433083d54a9691c316e1" translate="yes" xml:space="preserve">
          <source>When building a machine learning model it is often convenient to distinguish between variables holding trainable model parameters and other variables such as a &lt;code&gt;step&lt;/code&gt; variable used to count training steps. To make this easier, the variable constructor supports a &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; parameter. &lt;a href=&quot;gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; watches trainable variables by default:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11e07c6fbcce2a9ab5d49a2c9fc58743be530d36" translate="yes" xml:space="preserve">
          <source>When building ops to compute gradients, this op prevents the contribution of its inputs to be taken into account. Normally, the gradient generator adds ops to a graph to compute the derivatives of a specified 'loss' by recursively finding out inputs that contributed to its computation. If you insert this op in the graph it inputs are masked from the gradient generator. They are not taken into account for computing gradients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d35f4de41040fd9e01e658fd5001879a66a9c2d" translate="yes" xml:space="preserve">
          <source>When caching to a file, the cached data will persist across runs. Even the first iteration through the data will read from the cache file. Changing the input pipeline before the call to &lt;code&gt;.cache()&lt;/code&gt; will have no effect until the cache file is removed or the filename is changed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b38df97ed344603f1f1650ff0bfe2600641ba555" translate="yes" xml:space="preserve">
          <source>When calculating the gradient of a weighted loss contributions from both &lt;code&gt;losses&lt;/code&gt; and &lt;code&gt;weights&lt;/code&gt; are considered. If your &lt;code&gt;weights&lt;/code&gt; depend on some model parameters but you do not want this to affect the loss gradient, you need to apply &lt;a href=&quot;../../../stop_gradient&quot;&gt;&lt;code&gt;tf.stop_gradient&lt;/code&gt;&lt;/a&gt; to &lt;code&gt;weights&lt;/code&gt; before passing them to &lt;code&gt;compute_weighted_loss&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e31beadd763eb7afc2237f8c90a1ca311bfd077a" translate="yes" xml:space="preserve">
          <source>When called, the default graph is the one that will be launched in the session. The hook can modify the graph by adding new operations to it. After the &lt;code&gt;begin()&lt;/code&gt; call the graph will be finalized and the other callbacks can not modify the graph anymore. Second call of &lt;code&gt;begin()&lt;/code&gt; on the same graph, should not change the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d7e4d9de8d529939e37509a2b98e74b3e5ae079" translate="yes" xml:space="preserve">
          <source>When combining specs, &lt;code&gt;dev&lt;/code&gt; will take precidence over the current spec. So for instance:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02d1051ddba9ce90040906dafc1d04ba61223ccf" translate="yes" xml:space="preserve">
          <source>When constructed with a &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; parameter, a &lt;code&gt;FileWriter&lt;/code&gt; instead forms a compatibility layer over new graph-based summaries (&lt;code&gt;tf.contrib.summary&lt;/code&gt;) to facilitate the use of new summary writing with pre-existing code that expects a &lt;code&gt;FileWriter&lt;/code&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa47f312128ac2a3285768f283bc01e3ade90f81" translate="yes" xml:space="preserve">
          <source>When consuming SavedModels asynchronously (the producer is a separate process), the SavedModel directory will appear before all files have been written, and &lt;a href=&quot;load&quot;&gt;&lt;code&gt;tf.saved_model.load&lt;/code&gt;&lt;/a&gt; will fail if pointed at an incomplete SavedModel. Rather than checking for the directory, check for &quot;saved_model_dir/saved_model.pb&quot;. This file is written atomically as the last &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; file operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2db902f77ce37ed9d0c7614f639ced1da648ed42" translate="yes" xml:space="preserve">
          <source>When desired_channels is set, if the input contains fewer channels than this then the last channel will be duplicated to give the requested number, else if the input has more channels than requested then the additional channels will be ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87468be68aa798b87299469214116a53bdacd212" translate="yes" xml:space="preserve">
          <source>When documenting the shape of a RaggedTensor, ragged dimensions can be indicated by enclosing them in parentheses. For example, the shape of a 3-D &lt;code&gt;RaggedTensor&lt;/code&gt; that stores the fixed-size word embedding for each word in a sentence, for each sentence in a batch, could be written as &lt;code&gt;[num_sentences, (num_words), embedding_size]&lt;/code&gt;. The parentheses around &lt;code&gt;(num_words)&lt;/code&gt; indicate that dimension is ragged, and that the length of each element list in that dimension may vary for each item.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd3848450984baae9593cd8c988bd98ec36231eb" translate="yes" xml:space="preserve">
          <source>When each worker has more than one GPU, operations will be replicated on all GPUs. Even though operations may be replicated, variables are not and each worker shares a common view for which parameter server a variable is assigned to.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1dfe4b0bd2fe2cdea509ee0800c577901d8b6927" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;gate_gradients&lt;/code&gt;, &lt;code&gt;aggregation_method&lt;/code&gt;, and &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="148b464485213e809e25fd2427e6df10ddb7913a" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;momentum&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f483d1759bf06f09369c7c2c6504ed890b4f074" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt; can be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eb0adbeafdc09876e4693f8ca8e165f9c0c0985" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;beta_1&lt;/code&gt;, &lt;code&gt;beta_2&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88cf25c3162efb5267e479cbb3ca75d9e84020c2" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;decay&lt;/code&gt;, &lt;code&gt;momentum&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a51c69c938604c7d227cd40cf800aac6b43df507" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;rho&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78865de3a670b7422c397c1e12a0d6935fb3e356" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;loss&lt;/code&gt; should be a Python function that takes no arguments and computes the value to be minimized. Minimization (and gradient computation) is done with respect to the elements of &lt;code&gt;var_list&lt;/code&gt; if not None, else with respect to any trainable variables created during the execution of the &lt;code&gt;loss&lt;/code&gt; function. &lt;code&gt;gate_gradients&lt;/code&gt;, &lt;code&gt;aggregation_method&lt;/code&gt;, &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; and &lt;code&gt;grad_loss&lt;/code&gt; are ignored when eager execution is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a739b33250bbc25214beaa9599eadabdb7bb4665" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;var_list&lt;/code&gt; must specify a &lt;code&gt;list&lt;/code&gt; or &lt;code&gt;dict&lt;/code&gt; of variables to save. Otherwise, a &lt;code&gt;RuntimeError&lt;/code&gt; will be raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58de3a1f5573eceefbc002055806cdf8a10b2832" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, any callable object in the &lt;code&gt;control_inputs&lt;/code&gt; list will be called.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91a58274042c41959ab2122ef94206a6a2a7792d" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, code inside an init_scope block runs with eager execution enabled even when tracing a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7644973d82350f411122d3333c3da0b3f33b32bb" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, executes ops specified by &lt;code&gt;fn&lt;/code&gt; on each replica. Otherwise, builds a graph to execute the ops on each replica.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2c02abca5b8ce6f6c1965307850901a9a73db40" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, learning_rate can be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfdc83fece145a8a3ec7bfd53296a084c4dce787" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, returns &lt;code&gt;True&lt;/code&gt; in most cases. However, this API might return &lt;code&gt;False&lt;/code&gt; in the following use cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fca6e6a28c0b1d4d30760e6ed2b604579bf812fc" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, as outside &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, there is no graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6892adfb044f1fdf15d846e00b609e83b202685" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, as outside &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, there is no graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4ced4e377065fa4ed9d5e9a06ab2254081c3e07" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, this function returns a function which in turn returns the decayed learning rate Tensor. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2e71dc36f6cf8dc4084a1f274669076eb23a06d" translate="yes" xml:space="preserve">
          <source>When enabled, TensorFlow runtime will collection information that can later be exported and consumed by TensorBoard. The trace is activated across the entire TensorFlow runtime and affects all threads of execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4e19c79dfb2ba307013a448936b4d81569267d0" translate="yes" xml:space="preserve">
          <source>When executed in a graph, this op outputs its input tensor as-is.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cecfcec22d59fa24fae039affcbd309fee3e65f" translate="yes" xml:space="preserve">
          <source>When executed, the Tensor &lt;code&gt;a&lt;/code&gt; will have the name &lt;code&gt;MyOp/a&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae9202cb150768cbd21e4a56c23a5fe6d721d720" translate="yes" xml:space="preserve">
          <source>When executed, the Tensors &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, will have names &lt;code&gt;MyOp/a&lt;/code&gt;, &lt;code&gt;MyOp/b&lt;/code&gt;, and &lt;code&gt;MyOp/c&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50bb271b7e16cf32dee4edabc5aa3fa56b53275c" translate="yes" xml:space="preserve">
          <source>When executing eagerly, either assigns values immediately if variables to restore have been created already, or defers restoration until the variables are created. Dependencies added after this call will be matched if they have a corresponding object in the checkpoint (the restore request will queue in any trackable object waiting for the expected dependency to be added).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f2dc68be8f34aeff876ac6aadeee84459d20f11" translate="yes" xml:space="preserve">
          <source>When executing eagerly, map_fn does not execute in parallel even if &lt;code&gt;parallel_iterations&lt;/code&gt; is set to a value &amp;gt; 1. You can still get the performance benefits of running a function in parallel by using the &lt;code&gt;tf.contrib.eager.defun&lt;/code&gt; decorator,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f8e307109474cb2469b10f7555dc21ae2944eac" translate="yes" xml:space="preserve">
          <source>When graph building, &lt;code&gt;assert_consumed()&lt;/code&gt; indicates that all of the restore ops that will be created for this checkpoint have been created. They can be run via the &lt;code&gt;run_restore_ops()&lt;/code&gt; method of the status object:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79f071b74a52cc1dc25696f12242191a62439461" translate="yes" xml:space="preserve">
          <source>When graph building, restoration ops are added to the graph but not run immediately.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3400d0e372dbb4d788999038a1fa59202da9146e" translate="yes" xml:space="preserve">
          <source>When indices is a 1D tensor, this operation is equivalent to &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2e52528636ed4172136496c48a5c9c765f21cc1" translate="yes" xml:space="preserve">
          <source>When initializing a deep network, it is in principle advantageous to keep the scale of the input variance constant, so it does not explode or diminish by reaching the final layer. If the input is &lt;code&gt;x&lt;/code&gt; and the operation &lt;code&gt;x * W&lt;/code&gt;, and we want to initialize &lt;code&gt;W&lt;/code&gt; uniformly at random, we need to pick &lt;code&gt;W&lt;/code&gt; from</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f77eb406d2a652e408c888d240e8eb2d9cb755" translate="yes" xml:space="preserve">
          <source>When invoking a signature in an exported SavedModel, &lt;code&gt;Tensor&lt;/code&gt; arguments are identified by name. These names will come from the Python function's argument names by default. They may be overridden by specifying a &lt;code&gt;name=...&lt;/code&gt; argument in the corresponding &lt;a href=&quot;../tensorspec&quot;&gt;&lt;code&gt;tf.TensorSpec&lt;/code&gt;&lt;/a&gt; object. Explicit naming is required if multiple &lt;code&gt;Tensor&lt;/code&gt;s are passed through a single argument to the Python function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaecdf3e3e9d1409f6d5971a54eef9da389f9db7" translate="yes" xml:space="preserve">
          <source>When loading a weight file in TensorFlow format, returns the same status object as &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. When graph building, restore ops are run automatically as soon as the network is built (on first call for user-defined classes inheriting from &lt;code&gt;Model&lt;/code&gt;, immediately if it is already built).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad0500aa71cc2e13561fbb9f3ccb38e89738eb04" translate="yes" xml:space="preserve">
          <source>When loading a weight file in TensorFlow format, returns the same status object as &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. When graph building, restore ops are run automatically as soon as the network is built (on first call for user-defined classes inheriting from &lt;code&gt;Model&lt;/code&gt;, immediately if it is already built).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3a6d69d15b5f2b1e2641796ab481024196abbd1" translate="yes" xml:space="preserve">
          <source>When loading weights in HDF5 format, returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caebbca103b05daa9db25a1f91ee52187b92666d" translate="yes" xml:space="preserve">
          <source>When mixed precision training is used, most layers will instead have a float16 or bfloat16 compute dtype and a float32 variable dtype, and so the layer does not have a single dtype. See &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html&quot;&gt;this link&lt;/a&gt; for more information on mixed precision training. When the variable dtype does not match the compute dtype, variables will be automatically casted to the compute dtype to avoid type errors. In this case, &lt;a href=&quot;../../layers/layer#dtype&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt;&lt;/a&gt; refers to the variable dtype, not the compute dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e594a784be178d46ade99237614f3d81b376cb0c" translate="yes" xml:space="preserve">
          <source>When multiple identical random ops are wrapped in a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, their behaviors change because the ops no long share the same counter. For example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3fc5b0a3b9961cb77e88c8942ce57281e9ad832" translate="yes" xml:space="preserve">
          <source>When passed &lt;code&gt;trainable=True&lt;/code&gt;, the &lt;code&gt;Variable()&lt;/code&gt; constructor automatically adds new variables to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;. This convenience function returns the contents of that collection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b6a28f5fad1b02dbaf2abf3b2bcae0d38a29c7b" translate="yes" xml:space="preserve">
          <source>When reading a single input file, you can shard elements as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d6c412525d35ed49e0a016246bbab95a1ad4343" translate="yes" xml:space="preserve">
          <source>When run, it returns a 1-D tensor containing the names of uninitialized variables if there are any, or an empty array if there are none.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cd96e8d064773862a00f08fa46097675a613f49" translate="yes" xml:space="preserve">
          <source>When run, reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if &lt;code&gt;tensor&lt;/code&gt; has any values that are not a number (NaN) or infinity (Inf). Otherwise, passes &lt;code&gt;tensor&lt;/code&gt; as-is.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a08b94134a846722329d59d0e06daaabf9e81c0e" translate="yes" xml:space="preserve">
          <source>When run, the returned Op will raise the exception &lt;code&gt;FailedPreconditionError&lt;/code&gt; if any of the variables has not yet been initialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="612235a5e3b2319598b46d42d78d5e3939c685ba" translate="yes" xml:space="preserve">
          <source>When running in graph mode, you must evaluate the tensor returned by &lt;code&gt;tf.tables_initializer()&lt;/code&gt; before evaluating the tensor returned by this class's &lt;code&gt;lookup()&lt;/code&gt; method. Example usage in graph mode:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7eea4af19c3fd0977360ee69dfc63bed5794fb89" translate="yes" xml:space="preserve">
          <source>When running in graph mode, you should add a dependency on this operation to ensure that it runs. Example of adding a dependency to an operation:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23b4a5289feb34fa15683e70f83d2559b44972e8" translate="yes" xml:space="preserve">
          <source>When saving in HDF5 format, the weight file has: - &lt;code&gt;layer_names&lt;/code&gt; (attribute), a list of strings (ordered names of model layers). - For every layer, a &lt;code&gt;group&lt;/code&gt; named &lt;code&gt;layer.name&lt;/code&gt; - For every such layer group, a group attribute &lt;code&gt;weight_names&lt;/code&gt;, a list of strings (ordered names of weights tensor of the layer). - For every weight in the layer, a dataset storing the weight value, named after the weight tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c275f46f84d94fb1e86dc221ba0e2772a4b65944" translate="yes" xml:space="preserve">
          <source>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;, including any &lt;code&gt;Layer&lt;/code&gt; instances or &lt;code&gt;Optimizer&lt;/code&gt; instances assigned to object attributes. For networks constructed from inputs and outputs using &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt;, &lt;code&gt;Layer&lt;/code&gt; instances used by the network are tracked/saved automatically. For user-defined classes which inherit from &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Layer&lt;/code&gt; instances must be assigned to object attributes, typically in the constructor. See the documentation of &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58ff97a8bb50647c4ab49957faee2741efb3b467" translate="yes" xml:space="preserve">
          <source>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;, including any &lt;code&gt;Layer&lt;/code&gt; instances or &lt;code&gt;Optimizer&lt;/code&gt; instances assigned to object attributes. For networks constructed from inputs and outputs using &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt;, &lt;code&gt;Layer&lt;/code&gt; instances used by the network are tracked/saved automatically. For user-defined classes which inherit from &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Layer&lt;/code&gt; instances must be assigned to object attributes, typically in the constructor. See the documentation of &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="784c3ca10c1f2c8309f633399d4061eef62d41bd" translate="yes" xml:space="preserve">
          <source>When shape_x and shape_y are Tensors representing shapes (i.e. the result of calling tf.shape on another Tensor) this computes a Tensor which is the shape of the result of a broadcasting op applied in tensors of shapes shape_x and shape_y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="382f3819ea47b409f9da2d9eacd00a3f2dc7a1b2" translate="yes" xml:space="preserve">
          <source>When shape_x and shape_y are fully known TensorShapes this computes a TensorShape which is the shape of the result of a broadcasting op applied in tensors of shapes shape_x and shape_y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b25a4e208695ca5ecbc4dac0901769cfec692d0d" translate="yes" xml:space="preserve">
          <source>When sparse_delta.indices is a 1D tensor, this operation is equivalent to &lt;code&gt;scatter_update&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fee3dffe2d54b65ce0a85843a0d39fb34dec340" translate="yes" xml:space="preserve">
          <source>When that Op is run it tries to increment the variable by &lt;code&gt;1&lt;/code&gt;. If incrementing the variable would bring it above &lt;code&gt;limit&lt;/code&gt; then the Op raises the exception &lt;code&gt;OutOfRangeError&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ae5f82f4e0944c8fdd12da34fb5e45708d0e8f6" translate="yes" xml:space="preserve">
          <source>When the CrossShardOptimizer is constructed with &lt;code&gt;reduction == losses.Reduction.MEAN&lt;/code&gt; (default), this function scales the loss by &lt;code&gt;1.0 / num_shards&lt;/code&gt; before computing the gradients. Assuming the optimizer uses the default implementation of &lt;code&gt;compute_gradients()&lt;/code&gt;, the gradients of the scaled loss are scaled by &lt;code&gt;1.0 / num_shards&lt;/code&gt; compared to the gradients of the original loss. This scaling factor is important because &lt;code&gt;apply_gradients()&lt;/code&gt; sums gradients across shards, rather than averaging them. However, the scaling factor must be taken into account when clipping the norm of the gradients or performing other postprocessing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62b085231fa47179e1be16442d315153db83ffe4" translate="yes" xml:space="preserve">
          <source>When the Op is run, it reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if multiple values in the summaries to merge use the same tag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3584f2f08e6dde164e436c25cc19bcd86167e861" translate="yes" xml:space="preserve">
          <source>When the timeout argument is not present or None, the operation will block until the thread terminates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93008cafbefd82e0878a6b1b3873678eb838ef6d" translate="yes" xml:space="preserve">
          <source>When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call isAlive() after join() to decide whether a timeout happened -- if the thread is still alive, the join() call timed out.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5afcb3cf29a4af014bb340f2f0c516a9732b6d10" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should only be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. Gradients should not be computed with &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. This is because the returned optimizer will apply loss scaling, and &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will not. If you do directly use &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, your model may not converge due to float16 underflow problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caac8e6b5e9c55ec72ae9a078f806e80238a5f0b" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should only be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. Gradients should not be computed with &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. This is because the returned optimizer will apply loss scaling, and &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will not. If you do directly use &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, your model may not converge due to float16 underflow problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00a169e018bcf148a01078627fb468a85b4f57d1" translate="yes" xml:space="preserve">
          <source>When this is called, the graph is finalized and ops can no longer be added to the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f06429721d1fc01498f2381f4946b62026a0283c" translate="yes" xml:space="preserve">
          <source>When this op finishes, all ops in &lt;code&gt;inputs&lt;/code&gt; have finished. This op has no output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db72b6d879a1722ab8b371aaaee80aaed3e96f22" translate="yes" xml:space="preserve">
          <source>When training a model, it is often beneficial to maintain moving averages of the trained parameters. Evaluations that use averaged parameters sometimes produce significantly better results than the final trained values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="927a8a21e9e3520f84a7ae9e37d363926dbaebe1" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d86dcb91899a78227813e8c0d47037c6ee19dfd" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a cosine decay function with restarts to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90010651f41909cacf9403b614efcb8bd58e1369" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a linear cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a9c3656ff265f4bda198cf8e5dfd044fb933790" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a noisy linear cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64048e6ec72e37dd6f4daf26af9d33a56f72d8c7" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an exponential decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d181a155b50eadc32c09739aa94b40b51fe01a65" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an exponential decay function to a provided initial learning rate. It requires an &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f6fc97dc42e006ec89048c76f7f47de1eeb3d9a" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an inverse decay function to a provided initial learning rate. It requires an &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ddff8c9e5ff83f95e35cc80fb672fdcfe082715" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="512b0ee6d1762189943ee9ddad5e78bda622dc14" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a cosine decay function with restarts to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93d56e5e126f6377bdf1a06e2189c730d031c2b4" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a linear cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57bf3cf4acea41746a7afc38b8058640564015fe" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a noisy linear cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94deb77d4f75eb579f72f3db2e455ef2c44c44e1" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies an exponential decay function to an optimizer step, given a provided initial learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb18244719acd2825faa9890d721d54e05f0a037" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies the inverse decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cf6ec8113a82c824118b19bb4f2d871de8f3f5d" translate="yes" xml:space="preserve">
          <source>When used with &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;, outside of built-in training loops such as &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt;&lt;code&gt;compile&lt;/code&gt; and &lt;code&gt;fit&lt;/code&gt;, please use 'SUM' or 'NONE' reduction types, and reduce losses explicitly in your training loop. Using 'AUTO' or 'SUM_OVER_BATCH_SIZE' will raise an error.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0724c7bfb29f8f0c6cdcbe1954184f010886b9c" translate="yes" xml:space="preserve">
          <source>When using multiple critical sections on the same resources, there is no guarantee of exclusive access to those resources. This behavior is disallowed by default (but see the kwarg &lt;code&gt;exclusive_resource_access&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="005ecd21a6428476fbceb142b210d5384fc2790a" translate="yes" xml:space="preserve">
          <source>When using the default, an appropriate policy will be picked automatically. The default policy may change over time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67d49a53dc96e389873c164cb198f138ecc7ff2f" translate="yes" xml:space="preserve">
          <source>When using these moments for batch normalization (see &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="591b74326af491d6abfab42a671eba7ebb5be83e" translate="yes" xml:space="preserve">
          <source>When using these moments for batch normalization (see &lt;a href=&quot;batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea3d2206487c99a74b50234d9380045457ab56b2" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide an &lt;code&gt;input_shape&lt;/code&gt; argument (tuple of integers or &lt;code&gt;None&lt;/code&gt;, e.g. &lt;code&gt;(10, 128)&lt;/code&gt; for sequences of 10 vectors of 128-dimensional vectors, or &lt;code&gt;(None, 128)&lt;/code&gt; for variable-length sequences of 128-dimensional vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a409624f20a1b12afa97b438af1e2c02851ec80" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 128, 1)&lt;/code&gt; for 128x128x128 volumes with a single channel, in &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14d463d2a8afe47183522c1acdade8296e826653" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 128, 3)&lt;/code&gt; for a 128x128x128 volume with 3 channels if &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b700c0ba9e5af2d79f0ea705fd60f2846a05cd69" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 3)&lt;/code&gt; for 128x128 RGB pictures in &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90420d916accea41b90f4795021da2ee04f4f6d6" translate="yes" xml:space="preserve">
          <source>When variables are assigned to multiple workers, each worker writes its own section of the checkpoint. These sections are then merged/re-indexed to behave as a single checkpoint. This avoids copying all variables to one worker, but does require that all workers see a common filesystem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5727fc2aeafda851fc9ab281a980ef4c906dc39b" translate="yes" xml:space="preserve">
          <source>When you build a model for training you usually need ops to initialize variables, a &lt;code&gt;Saver&lt;/code&gt; to checkpoint them, an op to collect summaries for the visualizer, and so on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39d490a1a6c041251d0a268b335edd8cf95e7a4b" translate="yes" xml:space="preserve">
          <source>When you later call the &lt;code&gt;create_threads()&lt;/code&gt; method, the &lt;code&gt;QueueRunner&lt;/code&gt; will create one thread for each op in &lt;code&gt;enqueue_ops&lt;/code&gt;. Each thread will run its enqueue op in parallel with the other threads. The enqueue ops do not have to all be the same op, but it is expected that they all enqueue tensors in &lt;code&gt;queue&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3a2e77e985cdd0c4ca04ebfb7ec15ae2eed6e37" translate="yes" xml:space="preserve">
          <source>When you launch the graph, variables have to be explicitly initialized before you can run Ops that use their value. You can initialize a variable by running its &lt;em&gt;initializer op&lt;/em&gt;, restoring the variable from a save file, or simply running an &lt;code&gt;assign&lt;/code&gt; Op that assigns a value to the variable. In fact, the variable &lt;em&gt;initializer op&lt;/em&gt; is just an &lt;code&gt;assign&lt;/code&gt; Op that assigns the variable's initial value to the variable itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e2218d66173c9095f9d7c0c982dd0a7b7b1d0cb" translate="yes" xml:space="preserve">
          <source>Whenever possible, the session will raise a more specific subclass of &lt;code&gt;OpError&lt;/code&gt; from the &lt;a href=&quot;../errors&quot;&gt;&lt;code&gt;tf.errors&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5a5757b0332ab74cd51749fc4f26f2282d43f68" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;j&lt;/code&gt; is the &lt;code&gt;i&lt;/code&gt;th &lt;code&gt;True&lt;/code&gt; entry of &lt;code&gt;mask[a1...aA]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9e5e6939cbf334efa1154ae5d005e3955d0f0b7" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;key&lt;/code&gt; is a feature key whose values are used to partition the values. Partitions are listed from outermost to innermost.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17e66517ae2fa6c4b3f8472462247a694203eb5e" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;year&lt;/code&gt;, &lt;code&gt;month&lt;/code&gt;, and &lt;code&gt;day&lt;/code&gt; specify the date beyond which binaries that consume a model are expected to have been updated to include the new operations. This date is typically at least 3 weeks beyond the date the code that adds the new operation is committed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="743987e43173da0b07d4299cc71758449720108f" translate="yes" xml:space="preserve">
          <source>Where &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt;, &lt;em&gt;M&lt;/em&gt; = &lt;code&gt;ndims(indices)&lt;/code&gt;, and &lt;em&gt;B&lt;/em&gt; = &lt;code&gt;batch_dims&lt;/code&gt;. Note that &lt;code&gt;params.shape[:batch_dims]&lt;/code&gt; must be identical to &lt;code&gt;indices.shape[:batch_dims]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13aa13f1ced8020c65b238cd2e5743aaab5f6a97" translate="yes" xml:space="preserve">
          <source>Where &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df5ee0a432194eaf058dafaec560ccdd5751f85a" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the first dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;../../gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37006b5e3234b3a81d34b49c1399e20287f6f5fd" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the first dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6717cbbf5b0f27136d029a9a5a4fe644c3d0bdb" translate="yes" xml:space="preserve">
          <source>Whether a &lt;code&gt;DType&lt;/code&gt; is unsigned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43c8b1e245711e513da5fb3224a94014bfbd2ea6" translate="yes" xml:space="preserve">
          <source>Whether checkpointing is needed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6a6ce44ff2b603ee993694c9f88f39e13a58c1f" translate="yes" xml:space="preserve">
          <source>Whether initialization is needed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b62856eef3b197086ffc08e6c1915a9c8bdb4a27" translate="yes" xml:space="preserve">
          <source>Whether only account the statistics of displayed profiler nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c16fc5a5fb92977ae5605b686e098e91fe724b8" translate="yes" xml:space="preserve">
          <source>Whether saving summaries is needed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="254e76001f48c136c6f2b62d065c4a944ffb37c6" translate="yes" xml:space="preserve">
          <source>Whether the Reader implementation can serialize its state.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="decf851b03ac228e9313cade0b5957f7b666dae0" translate="yes" xml:space="preserve">
          <source>Whether the outputs need to be produced in deterministic order. If None, defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f124179378e71744cfb3660434035ba0a965f11a" translate="yes" xml:space="preserve">
          <source>Whether the strategy uses between-graph replication or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25debb8437d8df1e4a47ad52d47cdffdeaed2fdb" translate="yes" xml:space="preserve">
          <source>Whether to add latency measurements on all edges. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04a904d718701877a2e0c411c4fe23b4c4e3dd17" translate="yes" xml:space="preserve">
          <source>Whether to apply default static optimizations. If False, only static optimizations that have been explicitly enabled will be applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dfe28cb36c9e4043cc3c258d3d2b5adbf5c6fcb" translate="yes" xml:space="preserve">
          <source>Whether to automatically tune performance knobs. If None, defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7f5fb7a744d7e22b32c2f61ab042329f9cf9f1e" translate="yes" xml:space="preserve">
          <source>Whether to eliminate no-op transformations. If None, defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ccd7cdfaf0055cafb944adeab223f3187d39f6f" translate="yes" xml:space="preserve">
          <source>Whether to fuse filter dataset that predicts random_uniform &amp;lt; rate into a sampling dataset. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d46b05c402499222a82d4000612dbe3e69e3543" translate="yes" xml:space="preserve">
          <source>Whether to fuse filter transformations. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14622b8d2b800d5545010933d2dce355f7878e20" translate="yes" xml:space="preserve">
          <source>Whether to fuse map and batch transformations. If None, defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89d5416ec9ee3bbc766239f06ad6082f104072da" translate="yes" xml:space="preserve">
          <source>Whether to fuse map and filter transformations. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed238b5a1a92f1cdcc3146430339e440df04eeef" translate="yes" xml:space="preserve">
          <source>Whether to fuse map transformations. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bf1515795584c1b97bc7e2ce679a96ff89a3700" translate="yes" xml:space="preserve">
          <source>Whether to fuse shuffle and repeat transformations. If None, defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d8df6452e0ce74559d9d9e2cb01ae9313b462e1" translate="yes" xml:space="preserve">
          <source>Whether to hoist &lt;code&gt;tf.random_uniform()&lt;/code&gt; ops out of map transformations. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54c4b54df643bc4abc643e55545e0c75e91b663" translate="yes" xml:space="preserve">
          <source>Whether to introduce 'slack' in the last &lt;code&gt;prefetch&lt;/code&gt; of the input pipeline, if it exists. This may reduce CPU contention with accelerator host-side activity at the start of a step. The slack frequency is determined by the number of devices attached to this input pipeline. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="914df09e28d1c64c2b3ad87baeeb42bb6e13c04f" translate="yes" xml:space="preserve">
          <source>Whether to output all intermediates from functional control flow ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02821348292f56a84707e75ec632d05c62475235" translate="yes" xml:space="preserve">
          <source>Whether to parallelize copying of batch elements. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="735760deb2a9c67ef0c7efaa6a50691fc4a6f0e0" translate="yes" xml:space="preserve">
          <source>Whether to parallelize stateless map transformations. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7ceb047bcc05fae84d262bcb0f0a4c42d80112e" translate="yes" xml:space="preserve">
          <source>Whether to use ChooseFastestBranchDataset with this transformation. If True, the pipeline picks between the vectorized and original segment at runtime based on their iterations speed. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4f7ae19a819559a645d06cbc4b8c196628f89ca" translate="yes" xml:space="preserve">
          <source>Whether to vectorize map transformations. If None, defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbe339fdd2ca55a9615f6086f8ab79036c1a5e5d" translate="yes" xml:space="preserve">
          <source>Whether you are running on your machine or in the cluster you can use the following values for the --master flag:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f517d8a1e3e3925fb5d9497fd0a8aca7ed0a886e" translate="yes" xml:space="preserve">
          <source>Which profile step to use for profiling.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c51ff24d93bea432325c091aee3e33a6598af2c" translate="yes" xml:space="preserve">
          <source>While &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; save in the same format, note that the root of the resulting checkpoint is the object the save method is attached to. This means saving a &lt;a href=&quot;../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details. Prefer &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; for training checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af5169034174d26fcbbcf3598b642bb6291299f0" translate="yes" xml:space="preserve">
          <source>While &lt;a href=&quot;../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; save in the same format, note that the root of the resulting checkpoint is the object the save method is attached to. This means saving a &lt;a href=&quot;../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details. Prefer &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;a href=&quot;../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; for training checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="721826e30de58e9f292f39ea411e1bcf62df9289" translate="yes" xml:space="preserve">
          <source>While it is possible to use Variables with Lambda layers, this practice is discouraged as it can easily lead to bugs. For instance, consider the following layer:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7ab51f21fc0c3654c10e148c98ad2c3c102cbcf" translate="yes" xml:space="preserve">
          <source>While the formats are the same, do not mix &lt;code&gt;save_weights&lt;/code&gt; and &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;. Checkpoints saved by &lt;a href=&quot;../model#save_weights&quot;&gt;&lt;code&gt;Model.save_weights&lt;/code&gt;&lt;/a&gt; should be loaded using &lt;a href=&quot;../model#load_weights&quot;&gt;&lt;code&gt;Model.load_weights&lt;/code&gt;&lt;/a&gt;. Checkpoints saved using &lt;a href=&quot;../../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; should be restored using the corresponding &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. Prefer &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;code&gt;save_weights&lt;/code&gt; for training checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d3c899f37d2d7cda82e12e4a5abbb5d78c486a6" translate="yes" xml:space="preserve">
          <source>While the formats are the same, do not mix &lt;code&gt;save_weights&lt;/code&gt; and &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;. Checkpoints saved by &lt;a href=&quot;model#save_weights&quot;&gt;&lt;code&gt;Model.save_weights&lt;/code&gt;&lt;/a&gt; should be loaded using &lt;a href=&quot;model#load_weights&quot;&gt;&lt;code&gt;Model.load_weights&lt;/code&gt;&lt;/a&gt;. Checkpoints saved using &lt;a href=&quot;../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; should be restored using the corresponding &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. Prefer &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;code&gt;save_weights&lt;/code&gt; for training checkpoints.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f64f547104eca8ffa08df75b0d127da08fb96ecc" translate="yes" xml:space="preserve">
          <source>While using distribution strategies, the variables created within strategy's scope will be replicated across all the replicas and can be kept in sync using all-reduce algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bc1c4e835b1b69225a6dcb4af4e28a2c06f52c5" translate="yes" xml:space="preserve">
          <source>Wide &amp;amp; Deep Model for regression and classification problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1e4a70a64ee6594b6f0a462b10bce93878f9218" translate="yes" xml:space="preserve">
          <source>Will NOT work in 2.x:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c0b2946d9427a7aeee307da8f37197ad5dcc849" translate="yes" xml:space="preserve">
          <source>Will dequeue a work unit from queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8c3a8bad2b347c018d978650b0ad1f0a7153646" translate="yes" xml:space="preserve">
          <source>Will dequeue a work unit from queue if necessary (e.g., when the Reader needs to start reading from a new file since it has finished with the previous file). It may return less than num_records even before the last batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="261f27a1f3bf63caf50878a078d18d17744de09c" translate="yes" xml:space="preserve">
          <source>Will make devices on the cluster available to use. Note that calling this more than once will work, but will invalidate any tensor handles on the old remote devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6897db1eb6c38899798f94d9b426756d03b49e8" translate="yes" xml:space="preserve">
          <source>Will make devices on the remote host available to use. Note that calling this more than once will work, but will invalidate any tensor handles on the old remote devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4a06c844340471315b54b0dfa65c9f440e60872" translate="yes" xml:space="preserve">
          <source>Will the SparseTensor &lt;code&gt;A&lt;/code&gt; fit in memory if densified?</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0922711fb24b94894ef90c6a73b66b5cfaf62cb6" translate="yes" xml:space="preserve">
          <source>Will work in 1.x and 2.x (though deprecated in 2.x):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7969fd6214a6335899a24dac6e8f7bd3aba9e39c" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;A&lt;/code&gt; the dense representation of this &lt;code&gt;Operator&lt;/code&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="234aca2d96fedfdf359061dabe09edd1bc5db7b3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt;, samples are drawn from a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after truncation, if used) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt; where n is: - number of input units in the weight tensor, if mode = &quot;fan_in&quot; - number of output units, if mode = &quot;fan_out&quot; - average of the numbers of input and output units, if mode = &quot;fan_avg&quot;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5835e02899f12405b436a06a34c5acc97b07515" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;uniform&quot;&lt;/code&gt;, samples are drawn from a uniform distribution within [-limit, limit], with &lt;code&gt;limit = sqrt(3 * scale / n)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8c1f4cf8df7060458ea559fb96747e733cc6916" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;height_shift_range=2&lt;/code&gt; possible values are integers &lt;code&gt;[-1, 0, +1]&lt;/code&gt;, same as with &lt;code&gt;height_shift_range=[-1, 0, +1]&lt;/code&gt;, while with &lt;code&gt;height_shift_range=1.0&lt;/code&gt; possible values are floats in the interval [-1.0, +1.0).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f0be93f34340dbd9dbce5872c897c11744e5be0" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;width_shift_range=2&lt;/code&gt; possible values are integers &lt;code&gt;[-1, 0, +1]&lt;/code&gt;, same as with &lt;code&gt;width_shift_range=[-1, 0, +1]&lt;/code&gt;, while with &lt;code&gt;width_shift_range=1.0&lt;/code&gt; possible values are floats in the interval [-1.0, +1.0).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3c5ce075d1d1fd6a0d1aad83b3d8c72b5bbfb7b" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the first dimension, which is &lt;code&gt;height&lt;/code&gt;. Otherwise output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dafbf9ee96525bc588fdd1a819189c2c04be4c99" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the second dimension, which is &lt;code&gt;width&lt;/code&gt;. Otherwise output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb0883b4bf2a7901f51949844c31237c43d86ecb" translate="yes" xml:space="preserve">
          <source>With a &lt;code&gt;Coordinator&lt;/code&gt;, exceptions are reported to the coordinator and forgotten by the &lt;code&gt;QueueRunner&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf97c0b53fe731e0899e5aa3d7d1c5c2588e5d9e" translate="yes" xml:space="preserve">
          <source>With default values, it returns element-wise &lt;code&gt;max(x, 0)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db85e495eb55636b020a2a32657d103899296f2f" translate="yes" xml:space="preserve">
          <source>With default values, this returns the standard ReLU activation: &lt;code&gt;max(x, 0)&lt;/code&gt;, the element-wise maximum of 0 and the input tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b2addb5c48d67261f0b9d05eab9810322d19c59" translate="yes" xml:space="preserve">
          <source>With forwardprop, we specify a length-three vector in advance which multiplies the Jacobian. The &lt;code&gt;primals&lt;/code&gt; constructor argument is the parameter (a &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;) we're specifying a vector for, and the &lt;code&gt;tangents&lt;/code&gt; argument is the &quot;vector&quot; in Jacobian-vector product. If our goal is to compute the entire Jacobian matrix, forwardprop computes one column at a time while backprop computes one row at a time. Since the Jacobian in the linear regression example has only one row, backprop requires fewer invocations:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81932d1ace29ea95c92392af364f6a28c2c74781" translate="yes" xml:space="preserve">
          <source>With this definition, the gradient at x=100 will be correctly evaluated as 1.0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="317a1dfdd7bd7e17378c7a66cabfcee42b3896df" translate="yes" xml:space="preserve">
          <source>With y = f(x), computes the theoretical and numeric Jacobian dy/dx.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="659abe1496bd7876fc022d3e2b6b9cead33d30d8" translate="yes" xml:space="preserve">
          <source>Within a particular block, exactly one of these two things will be true:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e7aeeddf89020677af5b4472b077bda01df8909" translate="yes" xml:space="preserve">
          <source>Within each worker, we will also split the data among all the worker devices (if more than one a present), and this will happen even if multi-worker sharding is disabled using the method above.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d99119d2f84477c4512754d5e0fcbfbe0f69b29" translate="yes" xml:space="preserve">
          <source>Within the &lt;code&gt;with sv.managed_session()&lt;/code&gt; block all variables in the graph have been initialized. In addition, a few services have been started to checkpoint the model and add summaries to the event log.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab6e550ba7dbaa5e409cc2c91f32bbe98623ef14" translate="yes" xml:space="preserve">
          <source>Without &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt; but with a &lt;code&gt;seed&lt;/code&gt; argument is specified, small changes to function graphs or previously executed operations will change the returned value. See &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8ccb2ad531bd87f8226e54b9b6a39a6b2307357" translate="yes" xml:space="preserve">
          <source>Without a &lt;code&gt;Coordinator&lt;/code&gt;, exceptions are captured by the &lt;code&gt;QueueRunner&lt;/code&gt; and made available in this &lt;code&gt;exceptions_raised&lt;/code&gt; property.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e696e263864301b6aa5902a80a4d0bff70cd1786" translate="yes" xml:space="preserve">
          <source>Word embeddings</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d98a4a13cdc22212a308bf1d89d6b7b049c03e2f" translate="yes" xml:space="preserve">
          <source>Worker devices vs. parameter devices: Most replica computations will happen on worker devices. Since we don't yet support model parallelism, there will be one worker device per replica. When using parameter servers or central storage, the set of devices holding variables may be different, otherwise the parameter devices might match the worker devices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a41e51968848ca6ebbc48f555f3248a673bee90" translate="yes" xml:space="preserve">
          <source>Wrapped inputs (identity standins that have additional metadata). These are also are also tf.Tensor's.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="384f837341c0fc0fa71de4eb8e929b11e7daf27f" translate="yes" xml:space="preserve">
          <source>Wrapped outputs (identity standins that have additional metadata). These are also tf.Tensor's.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a298562930ec81f39bad36c204ae1b1059782591" translate="yes" xml:space="preserve">
          <source>Wrapped values: In order to represent values parallel across devices (either replicas or the devices associated with a particular value), we wrap them in a &quot;PerReplica&quot; or &quot;Mirrored&quot; object that contains a map from replica id to values. &quot;PerReplica&quot; is used when the value may be different across replicas, and &quot;Mirrored&quot; when the value are the same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="890d066e219e9b18bb1c24edca8341903adbf397" translate="yes" xml:space="preserve">
          <source>Wrapper allowing a stack of RNN cells to behave as a single cell.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4013106a25f53b1f217b9c3881270bfb6839489" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#add_to_collection&quot;&gt;&lt;code&gt;Graph.add_to_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caa4198da3fc275ac76081f0b3d1bfe03cdd54fe" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#add_to_collections&quot;&gt;&lt;code&gt;Graph.add_to_collections()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="264584356d25721fe348ac95a81a23f4cca709f4" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#container&quot;&gt;&lt;code&gt;Graph.container()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55f30bd6389eac4a761d1daf54731878db305f29" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#device&quot;&gt;&lt;code&gt;Graph.device()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d1e4b32d773cedbb0330530a2382ac0bddfaba8" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#get_collection&quot;&gt;&lt;code&gt;Graph.get_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="190d7f80a83427a732312702b0799aa4fd4270f6" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#get_collection_ref&quot;&gt;&lt;code&gt;Graph.get_collection_ref()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89aa6df88d5fbd573c88df4510194a5615a938d5" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;graph#control_dependencies&quot;&gt;&lt;code&gt;Graph.control_dependencies()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f37a810bede5b1390f81fea4b6be44aec37fbe5" translate="yes" xml:space="preserve">
          <source>Wrapper for using the Scikit-Learn API with Keras models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fff217e51e30156f66782f095344b6ef97a4794" translate="yes" xml:space="preserve">
          <source>Wrappers for primitive Neural Net (NN) Operations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7837b0cc643e2f001702979a842efc255ca9da70" translate="yes" xml:space="preserve">
          <source>Wrappers take another layer and augment it in various ways. Do not use this class as a layer, it is only an abstract base class. Two usable wrappers are the &lt;code&gt;TimeDistributed&lt;/code&gt; and &lt;code&gt;Bidirectional&lt;/code&gt; wrappers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3381242ca6a26b413c24d45326c44a72bdf78124" translate="yes" xml:space="preserve">
          <source>Wraps &lt;code&gt;call&lt;/code&gt;, applying pre- and post-processing steps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c62cdbd485fcae9d06ca69b5b8397cfed846cb17" translate="yes" xml:space="preserve">
          <source>Wraps a given text to a maximum line length and returns it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8829b71bb0967a49348c7e7adf87bb1886403153" translate="yes" xml:space="preserve">
          <source>Wraps a python function and uses it as a TensorFlow op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8abaa30206e6292e5e70829b82947753e40ac335" translate="yes" xml:space="preserve">
          <source>Wraps a python function into a TensorFlow op that executes it eagerly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82ab6329b627d91bd83e44d4fe219ae9ac70441c" translate="yes" xml:space="preserve">
          <source>Wraps a value that may/may not be present at runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19c9eb1de0862700ff8502bf5e2ae450855f9133" translate="yes" xml:space="preserve">
          <source>Wraps arbitrary expressions as a &lt;code&gt;Layer&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="352659d98f226f42ae5f9c0345757253d7e85e6e" translate="yes" xml:space="preserve">
          <source>Wraps the TF 1.x function fn into a graph function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20b643b52957c38a95449d4001fccba2e0bcd12a" translate="yes" xml:space="preserve">
          <source>Write &lt;code&gt;value&lt;/code&gt; into index &lt;code&gt;index&lt;/code&gt; of the TensorArray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="483cdae75a267d35fd6e83b5653511d5a80cff0f" translate="yes" xml:space="preserve">
          <source>Write a customized optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8c630765322886f9847c22284b5fa8d2851f2ce" translate="yes" xml:space="preserve">
          <source>Write a histogram summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0075d853115d3caa9b112367f26a9151c343826" translate="yes" xml:space="preserve">
          <source>Write a scalar summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="76fe5c36d30ae305e5a6503ba46502eb4a13331d" translate="yes" xml:space="preserve">
          <source>Write a string record to the file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b53b6d51e993b431470b37c217c59753ff1cc50" translate="yes" xml:space="preserve">
          <source>Write a text summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d21f1a898ccfeda0fe2e731850a28cfafae9bb2b" translate="yes" xml:space="preserve">
          <source>Write an audio summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21a6eeb1ed26a2be90d3ee27390e8e2bda8c0962" translate="yes" xml:space="preserve">
          <source>Write an image summary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a6db3a59303fe109b5b5137b804a970c912e147" translate="yes" xml:space="preserve">
          <source>Write this:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29a4cf60a26ded7a2c3aed4855011f0c8495cfe3" translate="yes" xml:space="preserve">
          <source>Writes &lt;code&gt;MetaGraphDef&lt;/code&gt; to save_path/filename.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fa9b02b6070f8899e280b451f66b6bd6b575f93" translate="yes" xml:space="preserve">
          <source>Writes &lt;code&gt;Summary&lt;/code&gt; protocol buffers to event files.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="babca584f4aae5499f0f80472fec83895337e06c" translate="yes" xml:space="preserve">
          <source>Writes a &lt;code&gt;SavedModel&lt;/code&gt; protocol buffer to disk.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec531d54bcd6301e96265e18d2ce6d1e6c9a4e3b" translate="yes" xml:space="preserve">
          <source>Writes a dataset to a TFRecord file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="233cc84a3671355de983f6c125f1b2c0c8c7fc01" translate="yes" xml:space="preserve">
          <source>Writes a generic summary to the default SummaryWriter if one exists.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d15430e669e23755ec2b520aa11323169d62858a" translate="yes" xml:space="preserve">
          <source>Writes a graph proto to a file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0faccf4f9a4005aa59d77d68c1f6677070d11c1f" translate="yes" xml:space="preserve">
          <source>Writes a summary using raw &lt;a href=&quot;../../compat/v1/summary&quot;&gt;&lt;code&gt;tf.compat.v1.Summary&lt;/code&gt;&lt;/a&gt; protocol buffers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5adf0b1064881763cf04269a02e41a3ea90a5906" translate="yes" xml:space="preserve">
          <source>Writes a training checkpoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2b611268944160d96a5b9a8fcf79249e74eb83f" translate="yes" xml:space="preserve">
          <source>Writes contents to the file at input filename. Creates file and recursively</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fb1d95dfee1bc896877fefd9cbe8b4b9c44e0bf" translate="yes" xml:space="preserve">
          <source>Writes file_content to the file. Appends to the end of the file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2ce6c85367b8678f1f61797d0dc74828b05ea19" translate="yes" xml:space="preserve">
          <source>Writes new value to variable's memory. Doesn't add ops to the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45f84d521a5351104bc075acf3695dd6bad6898e" translate="yes" xml:space="preserve">
          <source>Writing custom layers and models with Keras</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6a0c4f8b902d47bac80ddaf6bf34b2fbf4f9666" translate="yes" xml:space="preserve">
          <source>Xception V1 model for Keras.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfea80b5fe13bab375ae2dddcdd3dbb43f1a3633" translate="yes" xml:space="preserve">
          <source>Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset, which is a derivative work from original NIST datasets. MNIST dataset is made available under the terms of the &lt;a href=&quot;https://creativecommons.org/licenses/by-sa/3.0/&quot;&gt;Creative Commons Attribution-Share Alike 3.0 license.&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0d948a8bdb9eb6bb818e3240fb3b2534756d8f7" translate="yes" xml:space="preserve">
          <source>Yields predictions for given features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e930f451f4aa0e180bfec9e3ca9b3c51172a0d23" translate="yes" xml:space="preserve">
          <source>You can access a layer's regularization penalties by calling &lt;code&gt;layer.losses&lt;/code&gt; after calling the layer on inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59874a67ef5f7bd864b9ef3d3bb9393f8444ef02" translate="yes" xml:space="preserve">
          <source>You can access the raw &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; object used by &lt;code&gt;SingularMonitoredSession&lt;/code&gt;, whereas in MonitoredSession the raw session is private. This can be used:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7c18d1ca2444e96db7357ab3243c23ba7a401f2" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e5fb70392b78f99083230f0a97aa193ef7fda3b" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea8ecb649a2869edbe22ed0fa4b60b444f6b3240" translate="yes" xml:space="preserve">
          <source>You can also pass the following additional pieces to the constructor:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52dc5982a3012b85661499626a8a8038241b7ffd" translate="yes" xml:space="preserve">
          <source>You can also use &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; to debug your models at runtime using Python tools, i.e., you can isolate portions of your code that you want to debug, wrap them in Python functions and insert &lt;code&gt;pdb&lt;/code&gt; tracepoints or print statements as desired, and wrap those functions in &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9bf7e26d5c0cf51e4e4917f1eb23c3d37328691" translate="yes" xml:space="preserve">
          <source>You can cast a Keras variable but it still returns a Keras tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c77d6bc9128a9a471ae009d158974ccffab599c2" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abcd404b6ec568dc3b6a192e74ff39fd2a467efc" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="755b5985c40de671a4eb4bfb403b9e1a2cab5a03" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="823e308b708edca072a13279a53e3cee2ec00199" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77348208b8f388d909966c4b5fc03169d2df6ba3" translate="yes" xml:space="preserve">
          <source>You can find more information about TensorBoard &lt;a href=&quot;https://www.tensorflow.org/get_started/summaries_and_tensorboard&quot;&gt;here&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0be849f93096dd779e7a88c6ab36a4f32c9e43a7" translate="yes" xml:space="preserve">
          <source>You can implement 'SUM_OVER_BATCH_SIZE' using global batch size like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afa5195343dbaa120879b06f025ea84ad87e6a32" translate="yes" xml:space="preserve">
          <source>You can modify the operations in place, but modifications to the list such as inserts/delete have no effect on the list of operations known to the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c02260f75018990666dbe2089789cfb29e9e718" translate="yes" xml:space="preserve">
          <source>You can pass None to clear the control dependencies:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="215f1df4bc1261bbb6f65d825790eea599447ab5" translate="yes" xml:space="preserve">
          <source>You can pass any of the returned values to &lt;code&gt;restore()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac470d84ff347998661ececab5ea81ac9cc6a909" translate="yes" xml:space="preserve">
          <source>You can pass the result of evaluating any summary op, using &lt;code&gt;tf.Session.run&lt;/code&gt; or &lt;a href=&quot;../../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt;, to this function. Alternatively, you can pass a &lt;a href=&quot;../summary&quot;&gt;&lt;code&gt;tf.compat.v1.Summary&lt;/code&gt;&lt;/a&gt; protocol buffer that you populate with your own data. The latter is commonly done to report evaluation results in event files.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69155a67a44012b4f51b2dc8d0ccd534aa7907a1" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: Fit a Keras model when decaying 1/t with a rate of 0.5:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48f5a8f4038134ce54531b0e709a77dbf5681703" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: Fit a model while decaying from 0.1 to 0.01 in 10000 steps using sqrt (i.e. power=0.5):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40b491f9b541bdf48952295bf5d5a0ca64ae94b3" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: When fitting a Keras model, decay every 100000 steps with a base of 0.96:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="573311646e6161dd40916f132e58fdf271d90b7d" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5458dcea309d742dc1ae87c297fbd433242a68c9" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;../optimizers/schedules/serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../optimizers/schedules/deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0779a4d81e795874a050ef63a764491cc356c1c7" translate="yes" xml:space="preserve">
          <source>You can return from this call a &lt;code&gt;SessionRunArgs&lt;/code&gt; object indicating ops or tensors to add to the upcoming &lt;code&gt;run()&lt;/code&gt; call. These ops/tensors will be run together with the ops/tensors originally passed to the original run() call. The run args you return can also contain feeds to be added to the run() call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ae0a59fa6ec6a5af526342b6817b045dd0db4e8" translate="yes" xml:space="preserve">
          <source>You can set the distribution options of a dataset through the &lt;code&gt;experimental_distribute&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38287133e2e375cb065b8aff1223591e0429addd" translate="yes" xml:space="preserve">
          <source>You can set the optimization options of a dataset through the &lt;code&gt;experimental_optimization&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;optimizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4942db36ae427216d9ed0a514b6b4124827857d" translate="yes" xml:space="preserve">
          <source>You can set the stats options of a dataset through the &lt;code&gt;experimental_stats&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;statsoptions&quot;&gt;&lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt;&lt;/a&gt;. For example, to collect latency stats on all dataset edges, use the following pattern:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0286d405fc4b694404c86890a3b0233533e44d1a" translate="yes" xml:space="preserve">
          <source>You can set the threading options of a dataset through the &lt;code&gt;experimental_threading&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;threadingoptions&quot;&gt;&lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5821880102274e82922a0313317c1a0e00262ef7" translate="yes" xml:space="preserve">
          <source>You can specify the initial state of RNN layers numerically by calling &lt;code&gt;reset_states&lt;/code&gt; with the keyword argument &lt;code&gt;states&lt;/code&gt;. The value of &lt;code&gt;states&lt;/code&gt; should be a numpy array or list of numpy arrays representing the initial state of the RNN layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0934b024d096c8c6f1a29dcdebc76afd185fc96d" translate="yes" xml:space="preserve">
          <source>You can then use &lt;code&gt;TimeDistributed&lt;/code&gt; to apply a &lt;code&gt;Dense&lt;/code&gt; layer to each of the 10 timesteps, independently:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49b9bca1daa199f82797585539058cf0bff378d8" translate="yes" xml:space="preserve">
          <source>You can use &lt;a href=&quot;get_replica_context&quot;&gt;&lt;code&gt;tf.distribute.get_replica_context&lt;/code&gt;&lt;/a&gt; to get an instance of &lt;code&gt;ReplicaContext&lt;/code&gt;. This should be inside your replicated step function, such as in a &lt;a href=&quot;strategy#experimental_run_v2&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt;&lt;/a&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbd80087e0ae69c397a70f9c2b3b4a4570f57c0a" translate="yes" xml:space="preserve">
          <source>You can use the &lt;code&gt;reduce&lt;/code&gt; API to aggregate results across replicas and use this as a return value from one iteration over the distributed dataset. Or you can use &lt;a href=&quot;../keras/metrics&quot;&gt;&lt;code&gt;tf.keras.metrics&lt;/code&gt;&lt;/a&gt; (such as loss, accuracy, etc.) to accumulate metrics across steps in a given epoch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="849e0f628a638e3510c8fe215b32ce36d057b4e1" translate="yes" xml:space="preserve">
          <source>You can use the Dense layer as you would expect:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffad7cddd33e66d73417586d2382f64196240d65" translate="yes" xml:space="preserve">
          <source>You can use this function to read events written to an event file. It returns a Python iterator that yields &lt;code&gt;Event&lt;/code&gt; protocol buffers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8746f4908e5bf18e74cecb0263457015fb63a862" translate="yes" xml:space="preserve">
          <source>You could also use vocabulary lookup before crossing:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2314a9b2a621f208986f86ed4dc02fe23da32fe1" translate="yes" xml:space="preserve">
          <source>You may override this method in a subclass. The standard run() method invokes the callable object passed to the object's constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9f39d075c01a25e9820f6a67df1a4ab21c825d3" translate="yes" xml:space="preserve">
          <source>You may pass descendant of &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; to &lt;a href=&quot;../estimator/runconfig&quot;&gt;&lt;code&gt;tf.estimator.RunConfig&lt;/code&gt;&lt;/a&gt; to specify how a &lt;a href=&quot;../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt; should distribute its computation. See &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_estimator_limited_support&quot;&gt;guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4caa6c70be3989fa593907ab37426f9ba5e5385e" translate="yes" xml:space="preserve">
          <source>You may provide either a constant &lt;code&gt;window_size&lt;/code&gt; or a window size determined by the key through &lt;code&gt;window_size_func&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="246729df98351fdf262d7a7f6c3229e8ff176c5b" translate="yes" xml:space="preserve">
          <source>You must have set the task_type and task_id object properties before calling this function, or pass in the &lt;code&gt;task_type&lt;/code&gt; and &lt;code&gt;task_id&lt;/code&gt; parameters when using this function. If you do both, the function parameters will override the object properties.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="843e6067b5e147efe5ecbea6ee6b24b54cc1cca5" translate="yes" xml:space="preserve">
          <source>You number checkpoint filenames by passing a value to the optional &lt;code&gt;global_step&lt;/code&gt; argument to &lt;code&gt;save()&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d943ec0774ebc46f132a6e012d0ef8ae2735a29" translate="yes" xml:space="preserve">
          <source>You should use this instead of the variable itself to initialize another variable with a value that depends on the value of this variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bcb3cc3036b6c1787fd4b43072cd172e65fd9dd" translate="yes" xml:space="preserve">
          <source>You typically pass looper threads to the supervisor &lt;code&gt;Join()&lt;/code&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="866c1e20e145360ff1c2d3fac51cd421f0959538" translate="yes" xml:space="preserve">
          <source>You usually do not need to call this method as all ops that need the value of the variable call it automatically through a &lt;code&gt;convert_to_tensor()&lt;/code&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28b1f658f43504f27e0b8dad06c688c5569a5b43" translate="yes" xml:space="preserve">
          <source>You want os.path.exists() to always return true during testing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c152968210a9e92278d1a3f141b891e56657c41" translate="yes" xml:space="preserve">
          <source>Zero-pad the start and end of dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; of the input according to &lt;code&gt;paddings&lt;/code&gt; to produce &lt;code&gt;padded&lt;/code&gt; of shape &lt;code&gt;padded_shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec7ae133fd762cea93146fc3c7001608432a59c7" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 1D input (e.g. temporal sequence).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b78ee89fd119fbc58af59c013afefa4ada9d7ed" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 2D input (e.g. picture).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81f93ad811573d34a01e1dda72548f7bcac0984e" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 3D data (spatial or spatio-temporal).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4650f7edf1724b78bd849b1c2cb32632cbf26f09" translate="yes" xml:space="preserve">
          <source>Zero-pads and then rearranges (permutes) blocks of spatial data into batch. More specifically, this op outputs a copy of the input tensor where values from the &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; dimensions are moved to the &lt;code&gt;batch&lt;/code&gt; dimension. After the zero-padding, both &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; of the input must be divisible by the block size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd22950e542e583caceeef78dc9ae8586fc6a2c9" translate="yes" xml:space="preserve">
          <source>[1] Nicholas J. Higham (2002). Accuracy and Stability of Numerical Algorithms: Second Edition. SIAM. p. 175. ISBN 978-0-89871-802-7.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b99fc78b4d7545fcd138b54f0e14096e6f4551ca" translate="yes" xml:space="preserve">
          <source>[1] http://en.wikipedia.org/wiki/Gamma_correction</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b402dbbbcbda420a8c8a62323dde3dbd63d7a5e" translate="yes" xml:space="preserve">
          <source>[1]: G. Strang. 'Linear Algebra and Its Applications, 2nd Ed.' Academic Press, Inc., 1980, pp. 139-142.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3431dfde47f5f77802dc8c1e589fe801ed9dd223" translate="yes" xml:space="preserve">
          <source>[Flag], a new list of Flag instances. Caller may update this list as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fbe9b43ff0aeb17fee44c25d05877c8cdce9b59" translate="yes" xml:space="preserve">
          <source>[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69883aca3ab9b1512329fe1f31a31a2297068297" translate="yes" xml:space="preserve">
          <source>[batch&lt;em&gt;block_size&lt;/em&gt;block_size, height_pad/block_size, width_pad/block_size, depth]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a99f9eae6edb2aeb1e4c6a1434cfbcae41146183" translate="yes" xml:space="preserve">
          <source>[batch] + [padded_shape[1] / block_shape[0], block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a018842c23398495c71954bf778c4b46f8056996" translate="yes" xml:space="preserve">
          <source>[batch_size, num_channels] + output_spatial_shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51a4c96f9f2ac53566fd73823e05a471562bcdfc" translate="yes" xml:space="preserve">
          <source>[filename1, filename2, ... filenameN] as strings</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="143b12af78e15f28dfa0f3a68b2560666f6d5995" translate="yes" xml:space="preserve">
          <source>[min_range, max_range] are scalar floats that specify the range for the 'input' data. The 'mode' attribute controls exactly which calculations are used to convert the float values to their quantized equivalents. The 'round_mode' attribute controls which rounding tie-breaking algorithm is used when rounding float values to their quantized equivalents.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fa2da75f60f4f3a22685794db19c7508c0c1baa" translate="yes" xml:space="preserve">
          <source>[min_range, max_range] are scalar floats that specify the range for the output. The 'mode' attribute controls exactly which calculations are used to convert the float values to their quantized equivalents.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bebaab027f4bff5b0c289cd914950701e571abd" translate="yes" xml:space="preserve">
          <source>[num_batches, input_spatial_shape[0], ..., input_spatial_shape[N-1], num_input_channels],</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8157d4fe8eda67ef4b3a3b791fa8bb98678ccc" translate="yes" xml:space="preserve">
          <source>[spatial_filter_shape[0], ..., spatial_filter_shape[N-1], num_input_channels, num_output_channels],</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0305e4e8314312d7aab76df54a2e11f81f096064" translate="yes" xml:space="preserve">
          <source>[str], the parsed flag value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06a4ee1356819500657e1855f1838410080d3362" translate="yes" xml:space="preserve">
          <source>\( c_{jklm} = \sum_i a_{ijk} b_{lmi} \).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c88dd9089928bec50c06f1f5a9b847c1bc1189e" translate="yes" xml:space="preserve">
          <source>\(B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dd8170c96a11e0fac54775aa5e03b07d872abb3" translate="yes" xml:space="preserve">
          <source>\(Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4f68edbf74b4238178695327b403faa736fbba4" translate="yes" xml:space="preserve">
          <source>\(I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b977890dfd27609aefecb3c22cf9edc2b5b6c7c" translate="yes" xml:space="preserve">
          <source>\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c43fa9908d595b3f6dccdce0d125247c097b9f4" translate="yes" xml:space="preserve">
          <source>\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37291deb0e6026c081430c96a800990fc3edcaa7" translate="yes" xml:space="preserve">
          <source>\(\beta\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff41b6103716ee7c998d6e81784bdf83320ba7f2" translate="yes" xml:space="preserve">
          <source>\(\ell_1\,\,penalty =\ell_1\sum_{i=0}^n|x_i|\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9335deefcc4fff06a8f47ea88b57b74222c6ee2a" translate="yes" xml:space="preserve">
          <source>\(\ell_2\,\,penalty =\ell_2\sum_{i=0}^nx_i^2\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c62e7aed7aab85e0bc7679b7b1654447c10071b7" translate="yes" xml:space="preserve">
          <source>\(\frac{\gamma(x-\mu)}{\sigma}+\beta\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a0660a89253bc5ba688c6d45badc9f8ddf6380e" translate="yes" xml:space="preserve">
          <source>\(\psi^{(a)}(x) = \frac{d^a}{dx^a} \psi(x)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57cfcb3ce0118881ab066bb534ef79062b9ae613" translate="yes" xml:space="preserve">
          <source>\(\sigma_{t,i} = (\sqrt{n_{t,i}} - \sqrt{n_{t-1,i}}) / \alpha\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c402d7a692489cd97ce624829b28b4af2556f395" translate="yes" xml:space="preserve">
          <source>\(\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea1119f555233a8d758e9686e809fbc51e48a520" translate="yes" xml:space="preserve">
          <source>\(gamma(a, x) = \\int_{0}^{x} t^{a-1} exp(-t) dt\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="553f6c65213b82afcc0c043d8233d0d411b11d70" translate="yes" xml:space="preserve">
          <source>\(i\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cad97ed2e69a3cdad8082dd06f3ff6c16e2928db" translate="yes" xml:space="preserve">
          <source>\(lbeta(x)[i1, ..., in] = Log(|Beta(x[i1, ..., in, :])|)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e122b351d32a233056a0dc92eef090ec82833970" translate="yes" xml:space="preserve">
          <source>\(log(exp(A)) = A\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6e6475c1d10a33b250fca653ee8cfd040c5e589" translate="yes" xml:space="preserve">
          <source>\(lr_t := \text{learning\_rate} * \sqrt{1 - beta_2^t} / (1 - beta_1^t)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f6d1fd07abb052ec6fac4e52945c2c9c481cefa" translate="yes" xml:space="preserve">
          <source>\(m_0 := 0 \text{(Initialize initial 1st moment vector)}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3dada6e7ecd7d65376b81a16036f8e723616d85" translate="yes" xml:space="preserve">
          <source>\(m_t := beta_1 * m_{t-1} + (1 - beta_1) * g\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36cf9049b0822fc2658dd5393471d4a9bc14521f" translate="yes" xml:space="preserve">
          <source>\(n_{t,i} = n_{t-1,i} + g_{t,i}^{2}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e58cad3c2a2e7d2a68a0cec41e11be1d3da882e6" translate="yes" xml:space="preserve">
          <source>\(output_i = 1/N_i \sum_{j...} data[j...]\) where the sum is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; with \N_i\ being the number of occurrences of id \i\.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eff44ad7c5ba3196137c591dc7d87b8984229557" translate="yes" xml:space="preserve">
          <source>\(output_i = 1/sqrt(N_i) \sum_{j...} data[j...]\) where the sum is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; with \N_i\ being the number of occurrences of id \i\.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd27c9aa6e45dbe63e023f46fe5fdca3d93fbc19" translate="yes" xml:space="preserve">
          <source>\(output_i = \max_{j...} data[j...]\) where max is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="529b95e92276e5f1ac9b067c9474b5798a2da7c5" translate="yes" xml:space="preserve">
          <source>\(output_i = \min_{j...} data_[j...]\) where min is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bf71665be24061201465110b49af7b8c6429f1f" translate="yes" xml:space="preserve">
          <source>\(output_i = \prod_{j...} data[j...]\) where the product is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcf88899f36fe32859ba4eebac881718864b3a68" translate="yes" xml:space="preserve">
          <source>\(predictions_i\) be the predictions for all classes for example &lt;code&gt;i&lt;/code&gt;, \(targets_i\) be the target class for example &lt;code&gt;i&lt;/code&gt;, \(out_i\) be the output for example &lt;code&gt;i&lt;/code&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb6c03745499b6a9eb903031a775345057a8d436" translate="yes" xml:space="preserve">
          <source>\(t := 0 \text{(Initialize timestep)}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="467d92f4cfe1c3cd183f798d119891376eebfa6b" translate="yes" xml:space="preserve">
          <source>\(t := t + 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5334cf7b7c8be8a554d2684840ca9468e2d3597" translate="yes" xml:space="preserve">
          <source>\(t = t + 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a4815b823d6a6bd996f5174a896a936100c82c4" translate="yes" xml:space="preserve">
          <source>\(v_0 := 0 \text{(Initialize initial 2nd moment vector)}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe2806cab7064b169c451375ea09662f2387835c" translate="yes" xml:space="preserve">
          <source>\(v_hat_0 := 0 \text{(Initialize initial 2nd moment vector)}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95246ed68fccf6f4caddd1734e3779b6b21f4b80" translate="yes" xml:space="preserve">
          <source>\(v_hat_t := max(v_hat_{t-1}, v_t)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f4d3c48642e5d2288a5d23ba51224f14bb68e11" translate="yes" xml:space="preserve">
          <source>\(v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceb29146344acce0db4068ea0c682c74bad08207" translate="yes" xml:space="preserve">
          <source>\(variable := variable - lr_t * m_t / (\sqrt{v_hat_t} + \epsilon)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a5065284239af79ffad5fd4634aca805131acd5" translate="yes" xml:space="preserve">
          <source>\(variable := variable - lr_t * m_t / (\sqrt{v_t} + \epsilon)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c42d66b235e7446c048f4defb1b795d3ee38b09" translate="yes" xml:space="preserve">
          <source>\(w_{i}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b25b3312f2ef7cacd25276352e73b5ab48846cf" translate="yes" xml:space="preserve">
          <source>\(w_{t,i} = - ((\beta+\sqrt{n+{t}}) / \alpha + \lambda_{2})^{-1} * (z_{i} - sgn(z_{i}) * \lambda_{1}) if \abs{z_{i}} &amp;gt; \lambda_{i} else 0\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba90f7c8012e09317d8c902b37294fee9c1c8163" translate="yes" xml:space="preserve">
          <source>\(y = \beta + \sum_{i=1}^{N} w_{i} * x_{i}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dec4db0fcb32e5c79e8ecb6c6414661d0289001" translate="yes" xml:space="preserve">
          <source>\(z_{t,i} = z_{t-1,i} + g_{t,i} - \sigma_{t,i} * w_{t,i}\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31d5b9df6c8b26532e6975198879e8066c930cd4" translate="yes" xml:space="preserve">
          <source>], 'bias': [</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebb0f535eb870cf683880d2973390bc12e206de5" translate="yes" xml:space="preserve">
          <source>], _NumericColumn( key='numeric_feature2', shape=(2,)): [</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a961fbc1cc31eed81a5be94725a3b10dfcfb3f0e" translate="yes" xml:space="preserve">
          <source>]} If a column creates no variables, its value will be an empty list. Note that cols_to_vars will also contain a string key 'bias' that maps to a list of Variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82253180c6e96af25f2a21fff7bcfa0218b5a1e9" translate="yes" xml:space="preserve">
          <source>_normal_initializer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87ea43bbd5b9352fbaeea30b2cc056ed63741cfd" translate="yes" xml:space="preserve">
          <source>_uniform_initializer</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09cc8a0e53d6d87d6a7d95e6a2118c05a24fa639" translate="yes" xml:space="preserve">
          <source>a 1-D tensor whose size depends on the algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a0723a300b3e5a3037c5eec9b6314d294f925e8" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;SavedModel&lt;/code&gt; proto containing the Tensorflow backend graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model has not been compiled, then only the graph computing predictions will be exported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd5e709c8e1b6963fd07bdd51f6a8e7d5b1a115e" translate="yes" xml:space="preserve">
          <source>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) a # 2-D tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b60dce959a5722be8d9ace37f6ea58387cc7a978" translate="yes" xml:space="preserve">
          <source>a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3]) a # 3-D tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cac282a286b145e90bbae0cb74e2d64c49b7f387" translate="yes" xml:space="preserve">
          <source>a GraphNodeProto that records the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02fdc18cf71e7d138c4670ddd2b89252810f0b7c" translate="yes" xml:space="preserve">
          <source>a Mirrored object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a65d1b63a2aa1329f486140387a944abe2d35ab" translate="yes" xml:space="preserve">
          <source>a MultiGraphNodeProto that records the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b5462387fade93b713b97cb5dd916b0db334352" translate="yes" xml:space="preserve">
          <source>a callable that takes a single &lt;code&gt;DType&lt;/code&gt; argument and returns a Python &lt;code&gt;boolean&lt;/code&gt; indicating whether the dtype is to be included in the data dumping. Examples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dadf9b05790e565e376db89427e055d3cb91682a" translate="yes" xml:space="preserve">
          <source>a checkpoint containing the model weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8527fc8500abdc7bc32e70d3d9218debeaf5253f" translate="yes" xml:space="preserve">
          <source>a feature with &lt;code&gt;key=column.name&lt;/code&gt; whose &lt;code&gt;value&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9fc2e7b4a4a43e13919ca0d29891f8252c3bdeb" translate="yes" xml:space="preserve">
          <source>a keras.Model instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="825f328ed6cb35d3a0907c277ea200144eea6b05" translate="yes" xml:space="preserve">
          <source>a list of Mirrored objects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca7a0932035e5c9de07f92110d3540ab4ff578d3" translate="yes" xml:space="preserve">
          <source>a list of loss tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91a77371e3824445e17865c21a8864e288e638bc" translate="yes" xml:space="preserve">
          <source>a list or nested structure of Tensors (or IndexedSlices, or None), one for each element in &lt;code&gt;sources&lt;/code&gt;. Returned structure is the same as the structure of &lt;code&gt;sources&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2b8519688d6e08f0ef3f1f53563b370c82f252c" translate="yes" xml:space="preserve">
          <source>a list or tuple of &lt;code&gt;DType&lt;/code&gt; objects or strings that can be converted to &lt;code&gt;DType&lt;/code&gt; objects via &lt;a href=&quot;../../dtypes/as_dtype&quot;&gt;&lt;code&gt;tf.as_dtype()&lt;/code&gt;&lt;/a&gt;. Examples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="beb20ec17e12b3a92d15870c8fb928b39be9384e" translate="yes" xml:space="preserve">
          <source>a new instance of &lt;code&gt;RunConfig&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ebfcefc6e47ac4ed9512e51f768d3cbe5c823cb" translate="yes" xml:space="preserve">
          <source>a numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3267c112f6d4d3c0519780ece91f770b5ea07cc2" translate="yes" xml:space="preserve">
          <source>a rank (N+2) &lt;code&gt;filter&lt;/code&gt; Tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="567bea64cd23153635d3d86fe4dc29e83b999e55" translate="yes" xml:space="preserve">
          <source>a rank (N+2) &lt;code&gt;filters&lt;/code&gt; Tensor of shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f317a91fbf6fd20ea76003a27e77d226e69d5e9f" translate="yes" xml:space="preserve">
          <source>a string of the form /job:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a00a84ed543b41fac41116a0ecb87c993c7cda7" translate="yes" xml:space="preserve">
          <source>a summary_pb2.SummaryDescription</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af97be5a0dcfe7dd967ed814e5c51b34d26e758a" translate="yes" xml:space="preserve">
          <source>a) If a loop variable is a SparseTensor, the shape invariant must be TensorShape([r]) where r is the rank of the dense tensor represented by the sparse tensor. It means the shapes of the three tensors of the SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here is the shape of the SparseTensor.dense_shape property. It must be the shape of a vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a35ea6647dc95b90fe453d98f66e284fc5f0c506" translate="yes" xml:space="preserve">
          <source>a[0] = 0 : the first value of the sequence is 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="deda22cbcad48bb3a1413dc8ff28a54f1e5592e8" translate="yes" xml:space="preserve">
          <source>a[end] = input_row_length : the last value of the sequence is the size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d0442ecdcd49f18c5f26a6c7ac65eb7852e6a16" translate="yes" xml:space="preserve">
          <source>adjoints (conjugate transposes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0e72c8db0ec39595db76cd9ab3ea0b01fa0a54e" translate="yes" xml:space="preserve">
          <source>adjusted_dilation_rate is an int64 tensor of shape [max(spatial&lt;em&gt;dims)], adjusted&lt;/em&gt;{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05ab368bb50c30f0ad36866b483ced3c24cef7fa" translate="yes" xml:space="preserve">
          <source>adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i] adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :] adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10582f7ebb86265685f2d94ac9bf45194c26c416" translate="yes" xml:space="preserve">
          <source>aggregation: Indicates how a distributed variable will be aggregated. Accepted values are constants defined in the class &lt;a href=&quot;../../variableaggregation&quot;&gt;&lt;code&gt;tf.VariableAggregation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95142e8db6f0e670c6cdd282ebda2a8dc3235286" translate="yes" xml:space="preserve">
          <source>aggregation: Indicates how a distributed variable will be aggregated. Accepted values are constants defined in the class &lt;a href=&quot;variableaggregation&quot;&gt;&lt;code&gt;tf.VariableAggregation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b47a9fb6a6098b56fa005c9bf092d1ede95a90d" translate="yes" xml:space="preserve">
          <source>alpha = input_row_length / output_row_length : our reduction ratio</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15bd4e656cd87110cb6d06a7f5b3f1e300030cdd" translate="yes" xml:space="preserve">
          <source>an optional &lt;code&gt;dilation_rate&lt;/code&gt; tensor of shape &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N&lt;/a&gt; specifying the filter upsampling/input downsampling rate, and an optional list of N &lt;code&gt;strides&lt;/code&gt; (defaulting [1]*N), this computes for each N-D spatial output position (x[0], ..., x[N-1]):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ee24f38b8e109fbd5639cc2b47bec50e32475ed" translate="yes" xml:space="preserve">
          <source>an optional &lt;code&gt;dilations&lt;/code&gt; tensor of shape &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N&lt;/a&gt; specifying the filter upsampling/input downsampling rate, and an optional list of N &lt;code&gt;strides&lt;/code&gt; (defaulting [1]*N), this computes for each N-D spatial output position (x[0], ..., x[N-1]):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cffa50a32cb13a240d705317bcec65dd1f31b6ad" translate="yes" xml:space="preserve">
          <source>and</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebd46f618c63c3e212b1d778f0a25f4660c23598" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;SparseFeature&lt;/code&gt; config with 2 &lt;code&gt;index_key&lt;/code&gt;s</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6140381926bf0d082343ace25ade2e3cf221f627" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;default_value&lt;/code&gt; is &lt;code&gt;x&lt;/code&gt;, then the output will be a dense &lt;code&gt;[3, 5]&lt;/code&gt; string tensor with values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2d759c667e68226ece3acd5aa4e1cc6620b0ca0" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;max&lt;/code&gt; to 'outputs' tensor of same shape as &lt;code&gt;inputs&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78fbe88a4e8420d083776e826c4b0cd5bb232375" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;shape&lt;/code&gt; is &lt;code&gt;[9, -1]&lt;/code&gt;, then the output will be a &lt;code&gt;SparseTensor&lt;/code&gt; of shape &lt;code&gt;[9, 4]&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23cce7bb518f569f4a001bd92a904ee1f95e7599" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;to_retain = [True, False, False, True]&lt;/code&gt;, then the output will be a &lt;code&gt;SparseTensor&lt;/code&gt; of shape &lt;code&gt;[4, 5]&lt;/code&gt; with 2 non-empty values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b2da781f92810fe2701eb25993573d612b9c1c1" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;vocab_size = 200&lt;/code&gt;, then the output will be a &lt;code&gt;[2, 3, 200]&lt;/code&gt; dense bool tensor with False everywhere except at positions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb47192727f17143a048825f4ab10f7ac6f7e0a3" translate="yes" xml:space="preserve">
          <source>and False elsewhere in &lt;code&gt;output&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2223100c859ddb72353f03c35f828882929aa04b" translate="yes" xml:space="preserve">
          <source>and if &lt;code&gt;M = N&lt;/code&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34d19665daa7f1410ef46ef88c82079153b1d866" translate="yes" xml:space="preserve">
          <source>and then compute a normalized (x), including a small factor ({\epsilon}) for numerical stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aafd247e69aac8e786d351d47d5cdf462d0745f" translate="yes" xml:space="preserve">
          <source>arithmetic_optimization: Simplify arithmetic ops with common sub-expression elimination and arithmetic simplification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25c002c4154dbe462f9f8f1755f73522b0671750" translate="yes" xml:space="preserve">
          <source>array([[ 0., 0., 0.], [ 0., 0., 0.]], dtype=float32)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0c679f2bbcaf59c6d5d58d588516277aa10113f" translate="yes" xml:space="preserve">
          <source>as cpu and gpu are mutually exclusive. All entries are optional.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="307d5c7893e1f246cb5e563745a0402addd02464" translate="yes" xml:space="preserve">
          <source>assertSameElements([1, 1, 1, 0, 0, 0], [0, 1]) # Doesn't raise an AssertionError</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2454abb84d63a230ebc92ebe78cf3aff74dea1e0" translate="yes" xml:space="preserve">
          <source>assertSetEqual uses ducktyping to support different types of sets, and is optimized for sets specifically (parameters must support a difference method).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="223c6148b033dfedd56732627314f568565b952f" translate="yes" xml:space="preserve">
          <source>assertTotallyOrdered will check that instances can be ordered correctly. For example,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="619488f89279c23ae3a2459830944ea15030660d" translate="yes" xml:space="preserve">
          <source>auto_mixed_precision: Change certain float32 ops to float16 on Volta GPUs and above. Without the use of loss scaling, this can cause numerical underflow (see &lt;a href=&quot;../../keras/mixed_precision/experimental/lossscaleoptimizer&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.LossScaleOptimizer&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42196d958f18bea2afbb96730ce41e0664400c9e" translate="yes" xml:space="preserve">
          <source>b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2]) b # 2-D tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="331c18342e7de328d492864220ecd97a17015fe4" translate="yes" xml:space="preserve">
          <source>b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2]) b # 3-D tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3320d5417b786180d6a88859ca33be71ffb5b58" translate="yes" xml:space="preserve">
          <source>b) If a loop variable is an IndexedSlices, the shape invariant must be a shape invariant of the values tensor of the IndexedSlices. It means the shapes of the three tensors of the IndexedSlices are (shape, [shape[0]], [shape.ndims]).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ccc035633d62f88de0622d178fdcb0294d354f1" translate="yes" xml:space="preserve">
          <source>batch_to_space_nd( op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings), num_spatial_dims, &quot;VALID&quot;) adjusted_dilation_rate, adjusted_crops),</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c9bc5128b98bd8e78ed572fa0d85d3ece46ead7" translate="yes" xml:space="preserve">
          <source>because a pair of consecutive &lt;code&gt;space_to_batch&lt;/code&gt; and &lt;code&gt;batch_to_space&lt;/code&gt; ops with the same &lt;code&gt;block_size&lt;/code&gt; cancel out when their respective &lt;code&gt;paddings&lt;/code&gt; and &lt;code&gt;crops&lt;/code&gt; inputs are identical.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba8592abd982bea11fcaf0e400a42a85e26ee543" translate="yes" xml:space="preserve">
          <source>block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfe0b741c205bd8b78c7a9dfbaae7ede18737dc7" translate="yes" xml:space="preserve">
          <source>c = tf.matmul(a, b) c # &lt;code&gt;a&lt;/code&gt; * &lt;code&gt;b&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="320b384a8312ebd4e71df6cff7eb697ad2c9cebc" translate="yes" xml:space="preserve">
          <source>caching_device: Optional device string describing where the Variable should be cached for reading. Defaults to the Variable's device. If not &lt;code&gt;None&lt;/code&gt;, caches on another device. Typical use is to cache on the device where the Ops using the Variable reside, to deduplicate copying through &lt;code&gt;Switch&lt;/code&gt; and other conditional statements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d15c40326c4c52aca4d634221675089ef3f9372d" translate="yes" xml:space="preserve">
          <source>calls &lt;code&gt;hook.after_create_session()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6560c3a7d1fd751cac5e526396f58761ea2bec0" translate="yes" xml:space="preserve">
          <source>calls &lt;code&gt;hook.after_run()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fff680f28bca9038a2a088f909e686ea245d855f" translate="yes" xml:space="preserve">
          <source>calls &lt;code&gt;hook.before_run()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4620eebcbe111662aca04ec4fc8ffe7c11876ed" translate="yes" xml:space="preserve">
          <source>calls &lt;code&gt;hook.begin()&lt;/code&gt; for each given hook</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fff1a970af5c5efc7567de429c5998ea9aab947" translate="yes" xml:space="preserve">
          <source>calls &lt;code&gt;hook.end()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b2f096e00b533f3d41f20c9803f45c55f018092" translate="yes" xml:space="preserve">
          <source>calls TensorFlow &lt;code&gt;session.run()&lt;/code&gt; with merged fetches and feed_dict</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="213006ad598dbc0f82a89503d141ea76ff1598cb" translate="yes" xml:space="preserve">
          <source>can be combined into a single &lt;code&gt;with_space_to_batch&lt;/code&gt; operation as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8134ccfff78bbf2590e5607ee1803365874833d" translate="yes" xml:space="preserve">
          <source>can be equivalently performed cheaper in terms of computation and memory as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d36bf326f969cd786725e34418bdbaa4b2bae0e" translate="yes" xml:space="preserve">
          <source>can be rewritten as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce949af1a07f93922c5d731ded6dbb99391a90dd" translate="yes" xml:space="preserve">
          <source>class A(object): def &lt;strong&gt;init&lt;/strong&gt;(self, x, y): self.x = x self.y = y</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea1ab55353c766d5bfc461fe922ecb5077a2b166" translate="yes" xml:space="preserve">
          <source>class CallCounter(tf_decorator.TFDecorator): def &lt;strong&gt;init&lt;/strong&gt;(self, target): super(CallCounter, self).&lt;strong&gt;init&lt;/strong&gt;('count_calls', target) self.call_count = 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a14acbf5679090cec23f9a4cf3c00bd1e06896b6" translate="yes" xml:space="preserve">
          <source>closes the queue runners and the session</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="572db9c8e76fcbc4e0380c7e93a22fc5924631e1" translate="yes" xml:space="preserve">
          <source>collections: List of graph collections keys. The new variable is added to these collections. Defaults to &lt;code&gt;[GraphKeys.GLOBAL_VARIABLES]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="166b4a7b91b0c6668491a451cd849528db0a522b" translate="yes" xml:space="preserve">
          <source>config: config attribute of the &lt;code&gt;estimator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0e8de333b8aad23c2224f01cc326128d46c7350" translate="yes" xml:space="preserve">
          <source>constant_folding: Fold constants Statically infer the value of tensors when possible, and materialize the result using constants.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1004203b7f9920db9cbb5f51d7bea7471804e200" translate="yes" xml:space="preserve">
          <source>constraint: A constraint function to be applied to the variable after updates by some algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55cda5c2f5a8a893f7508d7aef54f08d18d16281" translate="yes" xml:space="preserve">
          <source>control flow v2 (cfv2) is an improved version of control flow in TensorFlow with support for higher order derivatives. Enabling cfv2 will change the graph/function representation of control flow, e.g., &lt;a href=&quot;../../while_loop&quot;&gt;&lt;code&gt;tf.while_loop&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../cond&quot;&gt;&lt;code&gt;tf.cond&lt;/code&gt;&lt;/a&gt; will generate functional &lt;code&gt;While&lt;/code&gt; and &lt;code&gt;If&lt;/code&gt; ops instead of low-level &lt;code&gt;Switch&lt;/code&gt;, &lt;code&gt;Merge&lt;/code&gt; etc. ops. Note: Importing and running graphs exported with old control flow will still be supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7aa223ce6606fc4db86496b58246b64d1e1d5e7e" translate="yes" xml:space="preserve">
          <source>convolution(input, data_format, **kwargs) = tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]), **kwargs), [0, N+1] + range(1, N+1))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2dfa6e41645b6d695da7f9c140140df1cb9e8a8d" translate="yes" xml:space="preserve">
          <source>cosine similarity = (a . b) / ||a|| ||b|| &lt;a href=&quot;https://en.wikipedia.org/wiki/Cosine_similarity&quot;&gt;Cosine Similarity&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6561407d8111db6f65b97909d1531b90b91a1cbd" translate="yes" xml:space="preserve">
          <source>create session</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="067554dfada58ece552f7c58c038dc321b5e6471" translate="yes" xml:space="preserve">
          <source>create_slots (if your optimizer algorithm requires additional variables)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e89165c664759ed118a849ac5e157c7a7420cee" translate="yes" xml:space="preserve">
          <source>creates directory if not existing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="081b707adb8ee559bb4d1ff71e37620e1d554dbc" translate="yes" xml:space="preserve">
          <source>crops = [[crop_top, crop_bottom], [crop_left, crop_right]]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ac8931b552de49d36c8c10b3b173cffe6cfde0b" translate="yes" xml:space="preserve">
          <source>crops[i, 0] = 0 crops[i, 1] = paddings[i, 1] - base_paddings[i, 1]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9891128069c86fb92a3fabee7a8253451caf028" translate="yes" xml:space="preserve">
          <source>ctc_unique_labels([[3, 4, 4, 3]]) -&amp;gt; unique labels padded with 0: [[3, 4, 0, 0]] indices of original labels in unique: [0, 1, 1, 0]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c6f87a5f7e23412684ce83f622fb8f3ce90a78c" translate="yes" xml:space="preserve">
          <source>d = a @ b @ [[10], [11]] d = tf.matmul(tf.matmul(a, b), [[10], [11]])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="01a0cbfc434d066ddea05f77d478859793878755" translate="yes" xml:space="preserve">
          <source>dataset For the first two cases, &lt;code&gt;batch_size&lt;/code&gt; must be provided. For the last case, &lt;code&gt;validation_steps&lt;/code&gt; could be provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e234129c60dec6324b5f643e695cdba1a5e75012" translate="yes" xml:space="preserve">
          <source>debug_stripper: Strips debug-related nodes from the graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ea0884d65eb8ec7c27c7eb7bc4d7980cfd33ff6" translate="yes" xml:space="preserve">
          <source>def &lt;strong&gt;call&lt;/strong&gt;(self, *args, *&lt;em&gt;kwargs): self.call_count += 1 return super(CallCounter, self).decorated_target(&lt;/em&gt;args, **kwargs)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6bf158433cfae2c912d4d20037c21436b88a3ad" translate="yes" xml:space="preserve">
          <source>def &lt;strong&gt;hash&lt;/strong&gt;(self): return hash(self.x)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7d64ddea4a1a04222372fd1d42ba7a9b83ec2c4" translate="yes" xml:space="preserve">
          <source>def &lt;strong&gt;lt&lt;/strong&gt;(self, other): try: return self.x &amp;lt; other.x except AttributeError: return NotImplemented</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b739d3451ecc417ae38b94f2b12e255e2e0fde9" translate="yes" xml:space="preserve">
          <source>def combined_op(converted_input, num_spatial_dims, _): result = op_1(converted_input, num_spatial_dims, &quot;SAME&quot;) ... result = op_k(result, num_spatial_dims, &quot;SAME&quot;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d99321e9860b560a343cc60276965958dcaffe8" translate="yes" xml:space="preserve">
          <source>def combined_op(converted_input, num_spatial_dims, _): result = op_1(converted_input, num_spatial_dims, &quot;VALID&quot;) ... result = op_k(result, num_spatial_dims, &quot;VALID&quot;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6742c4d87eb8a1588bec5ca35789ce0447474e4" translate="yes" xml:space="preserve">
          <source>def computation_with_string_ops(x): # strings types are not supported on TPU's and below ops must # run on CPU instead. output = tf.strings.format('1{}', x) return tf.strings.to_number(output)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d125938822ce482a4fb184fcc6acf85bec343142" translate="yes" xml:space="preserve">
          <source>def count_calls(target): return CallCounter(target)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="930f4fd3edf0ac478abd5997dcc865ae04ba3d2c" translate="yes" xml:space="preserve">
          <source>def my_op(a): with tf.name_scope(&quot;MyOp&quot;) as scope: a = tf.convert_to_tensor(a, name=&quot;a&quot;) # Define some computation that uses &lt;code&gt;a&lt;/code&gt;. return foo_op(..., name=scope)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3af6c8098e50bc574f6a3cdf577cf3684ed6722d" translate="yes" xml:space="preserve">
          <source>def print_hello_before_calling(target): def wrapper(*args, *&lt;em&gt;kwargs): print('hello') return target(&lt;/em&gt;args, **kwargs) return tf_decorator.make_decorator(target, wrapper)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00f6bf283c943399d3fa5039f0fc82bfcd676c75" translate="yes" xml:space="preserve">
          <source>def simple_parametrized_wrapper(*args, *&lt;em&gt;kwds): return simple_parametrized&lt;em&gt;wrapper.&lt;/em&gt;&lt;em&gt;wrapped&lt;/em&gt;_(&lt;/em&gt;args, **kwds)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="431b8cb088ce9ca3cee3c518bded03d8cb933ed5" translate="yes" xml:space="preserve">
          <source>def simple_parametrized_wrapper(*args, *&lt;em&gt;kwds): return wrapped_fn(&lt;/em&gt;args, **kwds)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6ccade472b6591a10dd1ec758fc3200663939d7" translate="yes" xml:space="preserve">
          <source>def tpu_computation(): # Expected output is 11. output = tf.tpu.outside_compilation(computation_with_string_ops, 1)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2edfaa4edca3dd5e04811717f4c45fd83392e6b" translate="yes" xml:space="preserve">
          <source>defined as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f59d2465a9e6561ffe24c2765287f07a897f8194" translate="yes" xml:space="preserve">
          <source>dependency_optimization: Control dependency optimizations. Remove redundant control dependencies, which may enable other optimization. This optimizer is also essential for pruning Identity and NoOp nodes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad8948bc0b427190ac45b31779cc166ea6971ae1" translate="yes" xml:space="preserve">
          <source>dilated_filter_shape = filter_shape + (filter_shape - 1) * (dilation_rate - 1)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec2a096ac42b541b6ba4e5f86b3b26d83884ec8d" translate="yes" xml:space="preserve">
          <source>disable_meta_optimizer: Disable the entire meta optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7669cabb379d4201a0a0c139ed40b145de2fe0b" translate="yes" xml:space="preserve">
          <source>disable_model_pruning: Disable removal of unnecessary ops from the graph</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6805ffc8131dc12b5975373f4780ea8386107058" translate="yes" xml:space="preserve">
          <source>divide gradient by the root of this average</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55f409129e3c9d7ff39481afc14068aab3ee29fb" translate="yes" xml:space="preserve">
          <source>dot product between tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60543d5ec749e1c0f644902aa7c1882b775cc309" translate="yes" xml:space="preserve">
          <source>dtype: If set, initial_value will be converted to the given type. If &lt;code&gt;None&lt;/code&gt;, either the datatype will be kept (if &lt;code&gt;initial_value&lt;/code&gt; is a Tensor), or &lt;code&gt;convert_to_tensor&lt;/code&gt; will decide.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a9b71c488471889c55b47d4766ff91a7e4f6f56" translate="yes" xml:space="preserve">
          <source>e.g. &lt;code&gt;[[4], [20]] -&amp;gt; [[0.25, 0.1], [0.6, -0.2]]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2ecc8cbd684804dbd286d8d9ddde733ac357de4" translate="yes" xml:space="preserve">
          <source>e.g. if T = qint8, and initially min_range = -10, and max_range = 9, we would compare -128/-10.0 = 12.8 to 127/9.0 = 14.11, and set scaling_factor = 12.8 In this case, min_range would remain -10, but max_range would be adjusted to 127 / 12.8 = 9.921875</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43f791ea4b7a318f6de4208c6fa294af266559df" translate="yes" xml:space="preserve">
          <source>errors.NotFoundError if directory doesn't exist</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dac5a34e0b232b7c5b77788538b81d1e3545258" translate="yes" xml:space="preserve">
          <source>evaluated using Horner's method, i.e.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95d6621d260ac7736e3a565c4519088053159865" translate="yes" xml:space="preserve">
          <source>exp(A) = \sum_{n=0}^\infty A^n/n!</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5be23c121a9df7a920185c3e3e3af39fe5f1fca4" translate="yes" xml:space="preserve">
          <source>f(5)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a747fda8314eecb773c1b00112b1461f66c74f2d" translate="yes" xml:space="preserve">
          <source>features: A &lt;a href=&quot;../../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; or a dictionary of string feature name to &lt;code&gt;Tensor&lt;/code&gt;. features are consumed by &lt;code&gt;model_fn&lt;/code&gt;. They should satisfy the expectation of &lt;code&gt;model_fn&lt;/code&gt; from inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb5783827f7821e69a871a9b65b321281d0220c9" translate="yes" xml:space="preserve">
          <source>features: A &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; or a dictionary of string feature name to &lt;code&gt;Tensor&lt;/code&gt;. features are consumed by &lt;code&gt;model_fn&lt;/code&gt;. They should satisfy the expectation of &lt;code&gt;model_fn&lt;/code&gt; from inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="042dc4921c022cfaf1737bea340bf4acf986181f" translate="yes" xml:space="preserve">
          <source>features: A &lt;a href=&quot;../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; or a dictionary of string feature name to &lt;code&gt;Tensor&lt;/code&gt;. features are consumed by &lt;code&gt;model_fn&lt;/code&gt;. They should satisfy the expectation of &lt;code&gt;model_fn&lt;/code&gt; from inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63004d39309ac253fef9ee42c74ef18a5130ca4d" translate="yes" xml:space="preserve">
          <source>features: A &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; or a dictionary of string feature name to &lt;code&gt;Tensor&lt;/code&gt;. features are consumed by &lt;code&gt;model_fn&lt;/code&gt;. They should satisfy the expectation of &lt;code&gt;model_fn&lt;/code&gt; from inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4f4aaa673316e77ae40eec02042b35f5fba2e91" translate="yes" xml:space="preserve">
          <source>features: Input &lt;code&gt;dict&lt;/code&gt; of &lt;code&gt;Tensor&lt;/code&gt; objects created by &lt;code&gt;input_fn&lt;/code&gt; which is given to &lt;code&gt;estimator.evaluate&lt;/code&gt; as an argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3db266482de5f3a58e5d72b3c66aab6027f2958" translate="yes" xml:space="preserve">
          <source>fibonacci(7)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74a02d4079e5f47f7b4ea33cff804fafdbb823f0" translate="yes" xml:space="preserve">
          <source>finalizes the graph via &lt;code&gt;scaffold.finalize()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21324a41e8c7c6c0df5c83692bc8fe1571de7320" translate="yes" xml:space="preserve">
          <source>flags.declare_key_flag('flag_1')</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d672077bfe52307086791b4fa3a011645d528b96" translate="yes" xml:space="preserve">
          <source>float: fraction of total height, if &amp;lt; 1, or pixels if &amp;gt;= 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89c144a1c987c2122f2afa4cff925295efa2d190" translate="yes" xml:space="preserve">
          <source>float: fraction of total width, if &amp;lt; 1, or pixels if &amp;gt;= 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7cfde982d3bb21c7a417aed9f324f3029dfdfc2" translate="yes" xml:space="preserve">
          <source>foldl on the list of tensors unpacked from &lt;code&gt;elems&lt;/code&gt; on dimension 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bf5c450b886f3aee9cc8558fb3938e2df5dacb6" translate="yes" xml:space="preserve">
          <source>foldr on the list of tensors unpacked from &lt;code&gt;elems&lt;/code&gt; on dimension 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5d719c6036135c155db1d621534ac4230131af3" translate="yes" xml:space="preserve">
          <source>foo = tf.constant([-10, -5, 0.0, 5, 10], dtype = tf.float32) tf.keras.activations.relu(foo).numpy() array([ 0., 0., 0., 5., 10.], dtype=float32) tf.keras.activations.relu(foo, alpha=0.5).numpy() array([-5. , -2.5, 0. , 5. , 10. ], dtype=float32) tf.keras.activations.relu(foo, max_value=5).numpy() array([0., 0., 0., 5., 5.], dtype=float32) tf.keras.activations.relu(foo, threshold=5).numpy() array([-0., -0., 0., 0., 10.], dtype=float32)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa2a3ecfed7ec15e6f256b3268387743a7d39f71" translate="yes" xml:space="preserve">
          <source>for each &lt;code&gt;column&lt;/code&gt; in &lt;code&gt;context_feature_columns&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2838a9979a6d44c333fc536508bf80fd9c268f0" translate="yes" xml:space="preserve">
          <source>for each &lt;code&gt;column&lt;/code&gt; in &lt;code&gt;dnn_feature_columns&lt;/code&gt; + &lt;code&gt;linear_feature_columns&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a577528de83e53a337075075c6a83fd4deb27ab" translate="yes" xml:space="preserve">
          <source>for each &lt;code&gt;column&lt;/code&gt; in &lt;code&gt;feature_columns&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="041e2897f9d31acbc6eaa576e6ce502753484251" translate="yes" xml:space="preserve">
          <source>for each &lt;code&gt;column&lt;/code&gt; in &lt;code&gt;sequence_feature_columns&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b85e69dca6e6675f3ba8c4df79dbb1db28116007" translate="yes" xml:space="preserve">
          <source>for simple batch normalization pass &lt;code&gt;axes=[0]&lt;/code&gt; (batch only).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5505d86ad1685caa0fd04e3cd0ef935afd88aea" translate="yes" xml:space="preserve">
          <source>for so-called &quot;global normalization&quot;, used with convolutional filters with shape &lt;code&gt;[batch, height, width, depth]&lt;/code&gt;, pass &lt;code&gt;axes=[0, 1, 2]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ccfce04c7ee64f088843c6af5489db41451f05a" translate="yes" xml:space="preserve">
          <source>from tensorflow.keras import backend as K kvar = K.variable(np.random.random((2,3))) kvar_zeros = K.zeros_like(kvar) K.eval(kvar_zeros)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9df1da832177ed8791c7a5e33cfb39e054897e71" translate="yes" xml:space="preserve">
          <source>from tensorflow_estimator.python.estimator.canned import head_lib</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8510b934f74662730c458c176d82cae8ae0ebaaa" translate="yes" xml:space="preserve">
          <source>full_name</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13ba475db05aba9651e3af08cae2330ec1a9d2d1" translate="yes" xml:space="preserve">
          <source>full_shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="378f5fcadde0ec3c67542cd6d10ef8457b80efa3" translate="yes" xml:space="preserve">
          <source>function instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee17ed0fabb2d60e80b358ab2dad1ea5fa7ac858" translate="yes" xml:space="preserve">
          <source>function_optimization: Function optimizations and inlining.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7daa598ab5e37c9b5eda2a3430f7630440c55daa" translate="yes" xml:space="preserve">
          <source>get_config (serialization of the optimizer, include all hyper parameters)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0a4af1d55cff81c76113bbf327008f090d6646e" translate="yes" xml:space="preserve">
          <source>gradient is evaluated at theta(t) + momentum * v(t), and the variables always store theta + beta_1 * m / sqrt(v) instead of theta.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e7a47755d59da94be35e420e8ba81d7781e798a" translate="yes" xml:space="preserve">
          <source>head = head_lib._regression_head(label_dimension=1) est = boosted_trees.BoostedTreesEstimator( feature_columns=..., n_batches_per_layer=..., head=head, n_trees=..., max_depth=...)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80097e068e45b969c07f48907945f1be4890875a" translate="yes" xml:space="preserve">
          <source>here &lt;code&gt;range(T) = numeric_limits&amp;lt;T&amp;gt;::max() - numeric_limits&amp;lt;T&amp;gt;::min()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="936b7ec6322f6e9d6b2d036d56bb9dcf9196fca0" translate="yes" xml:space="preserve">
          <source>i.e. &lt;code&gt;exp(x) - 1&lt;/code&gt; or &lt;code&gt;e^(x) - 1&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; is the input tensor. &lt;code&gt;e&lt;/code&gt; denotes Euler's number and is approximately equal to 2.718281.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e29791878048667885d8ab4512f563fbed880b90" translate="yes" xml:space="preserve">
          <source>if &amp;lt; 0, &lt;code&gt;scale * features&lt;/code&gt; otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52c55c208ccbce987d24f14a7210af9603812cd0" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;AbortedError&lt;/code&gt; or &lt;code&gt;UnavailableError&lt;/code&gt; occurs, it recovers or reinitializes the session before executing the run() call again</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ba0b2cb6429da38c0d59b5ecd1d8ae4cadf64aa" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;axis == 0&lt;/code&gt; then the &lt;code&gt;output&lt;/code&gt; tensor will have the shape &lt;code&gt;(N, A, B, C)&lt;/code&gt;. if &lt;code&gt;axis == 1&lt;/code&gt; then the &lt;code&gt;output&lt;/code&gt; tensor will have the shape &lt;code&gt;(A, N, B, C)&lt;/code&gt;. Etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07d874d1cf7b89f2f2c7ce20ccd10bf6c9caa80a" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;axis&lt;/code&gt;=None, per-tensor quantization is performed as normal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5af843a4d564fe1883b1af206a31294b3df249fc" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;column&lt;/code&gt; is a &lt;code&gt;CategoricalColumn&lt;/code&gt;, a feature with &lt;code&gt;key=column.name&lt;/code&gt; whose &lt;code&gt;value&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4bea04012338785875d8e879d50703a0721e107" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;column&lt;/code&gt; is a &lt;code&gt;DenseColumn&lt;/code&gt;, a feature with &lt;code&gt;key=column.name&lt;/code&gt; whose &lt;code&gt;value&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b50fbd504730c8c0ab1d9f44dbe776c2995b91df" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;column&lt;/code&gt; is a &lt;code&gt;RealValuedColumn&lt;/code&gt;, a feature with &lt;code&gt;key=column.name&lt;/code&gt; whose &lt;code&gt;value&lt;/code&gt; is a &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93cc00148e12371b1e41cb97a0738d42b3ab099d" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;column&lt;/code&gt; is a &lt;code&gt;SparseColumn&lt;/code&gt;, a feature with &lt;code&gt;key=column.name&lt;/code&gt; whose &lt;code&gt;value&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3308287f5f98b2793cb3552ce59e4ee239d058a0" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;column&lt;/code&gt; is a &lt;code&gt;WeightedCategoricalColumn&lt;/code&gt;, two features: the first with &lt;code&gt;key&lt;/code&gt; the id column name, the second with &lt;code&gt;key&lt;/code&gt; the weight column name. Both features' &lt;code&gt;value&lt;/code&gt; must be a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a9c533761ac9bb527388d7229c3fc93bb96102d" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;column&lt;/code&gt; is a &lt;code&gt;WeightedSparseColumn&lt;/code&gt;, two features: the first with &lt;code&gt;key&lt;/code&gt; the id column name, the second with &lt;code&gt;key&lt;/code&gt; the weight column name. Both features' &lt;code&gt;value&lt;/code&gt; must be a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7dc3a6f6fc2238c0bd84bf66fdfaec1b78bf443" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;fn&lt;/code&gt; calls &lt;code&gt;get_replica_context().merge_call(merge_fn, ...)&lt;/code&gt;, then inside &lt;code&gt;merge_fn&lt;/code&gt; you are back in the cross-replica context (and again this function will return &lt;code&gt;None&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9588e8736c4e1fd30713ca3c32be658aa3818798" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;num_or_size_splits&lt;/code&gt; is a scalar returns &lt;code&gt;num_or_size_splits&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; objects; if &lt;code&gt;num_or_size_splits&lt;/code&gt; is a 1-D Tensor returns &lt;code&gt;num_or_size_splits.get_shape[0]&lt;/code&gt;&lt;code&gt;Tensor&lt;/code&gt; objects resulting from splitting &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="720a2a53074517f81984bf36577db4f22fcd5c3d" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;num_steps&lt;/code&gt; is specified, it indicates the number of steps to execute after &lt;code&gt;begin()&lt;/code&gt; is called. If instead &lt;code&gt;last_step&lt;/code&gt; is specified, it indicates the last step we want to execute, as passed to the &lt;code&gt;after_run()&lt;/code&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8867f4aacd830504ca9e31a8f9915efefd9e01d6" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;weight_column&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, a feature with &lt;code&gt;key=weight_column&lt;/code&gt; whose value is a &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28b3afd1c36d8e5df24ab0b324bdbfa0500a32ad" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;weight_column&lt;/code&gt; is specified in the &lt;code&gt;head&lt;/code&gt; constructor (and not None) for the head passed to BaselineEstimator's constructor, a feature with &lt;code&gt;key=weight_column&lt;/code&gt; whose value is a &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afb80bb98b3fb7eaa2edab5d23cf46f005344bdb" translate="yes" xml:space="preserve">
          <source>if &lt;code&gt;x&lt;/code&gt; has shape (samples, dim) and &lt;code&gt;n&lt;/code&gt; is &lt;code&gt;2&lt;/code&gt;, the output will have shape &lt;code&gt;(samples, 2, dim)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebdc529b2b9b83567e407871f5a9bb0c35cde4ce" translate="yes" xml:space="preserve">
          <source>if &lt;strong&gt;name&lt;/strong&gt; == '&lt;strong&gt;main&lt;/strong&gt;': flags.mark_flag_as_required('your_flag_name') app.run()</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73df495545d68f890e5e29cede7171242a4dea1f" translate="yes" xml:space="preserve">
          <source>if &lt;strong&gt;name&lt;/strong&gt; == '&lt;strong&gt;main&lt;/strong&gt;': flags.mark_flags_as_required(['flag1', 'flag2', 'flag3']) app.run()</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31d24dc55622b812437e622f85d77d1d8fcf1404" translate="yes" xml:space="preserve">
          <source>if data_format is None or does not start with &quot;NC&quot;, or</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8a573407f16d7aca1b9b15ef7d75f763c901cb6" translate="yes" xml:space="preserve">
          <source>if data_format starts with &quot;NC&quot;, where &lt;code&gt;output_spatial_shape&lt;/code&gt; depends on the value of &lt;code&gt;padding&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6054be2a7214b032d47a8c7dc017af767b16116" translate="yes" xml:space="preserve">
          <source>if data_format starts with &quot;NC&quot;, where &lt;code&gt;output_spatial_shape&lt;/code&gt; depends on the value of padding:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a65b87bdb12d758b8d7f47e56a9669bd4df78c45" translate="yes" xml:space="preserve">
          <source>if expand_nonconcat_dim = False, this will result in an error. But if expand_nonconcat_dim = True, this will result in:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4202dcdea20a233b67b6b76a48f2fac8b88945c" translate="yes" xml:space="preserve">
          <source>if more than one session.run call is simultaneously trying to compute &lt;code&gt;b&lt;/code&gt; the values of &lt;code&gt;w&lt;/code&gt; will be gathered, non-deterministically concatenated along the first axis, and only one thread will run the computation. See the documentation of the &lt;code&gt;Batch&lt;/code&gt; op for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13e66b6eac059533d69b2fa730269f2dc37eb59a" translate="yes" xml:space="preserve">
          <source>if the head's &lt;code&gt;weight_column&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, a feature with &lt;code&gt;key=weight_column&lt;/code&gt; whose value is a &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4e06aaa2393a44b881c4f4d68e2ea91dfacf3aa" translate="yes" xml:space="preserve">
          <source>images = np.array( ... [ ... [[[1], [2]], [[3], [4]]], ... [[[5], [6]], [[7], [8]]] ... ]) tf.image.random_flip_left_right(images, 6).numpy().tolist() [[[[2], [1]], [[4], [3]]], [[[5], [6]], [[7], [8]]]]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0482853f7a3978a9e3e80770dd2609a35a1a146f" translate="yes" xml:space="preserve">
          <source>images = np.array( ... [ ... [[[1], [2]], [[3], [4]]], ... [[[5], [6]], [[7], [8]]] ... ]) tf.image.random_flip_up_down(images, 4).numpy().tolist() [[[[3], [4]], [[1], [2]]], [[[5], [6]], [[7], [8]]]]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24d46238512c2be6af91681cf4ce6649fccc4812" translate="yes" xml:space="preserve">
          <source>implementation_selector: Enable the swap of kernel implementations based on the device placement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcab709e15bed658b61ee4181f314cd59ed91952" translate="yes" xml:space="preserve">
          <source>import numpy as np</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61169edc7e14dee7c69b04e8658ab8f22496afd1" translate="yes" xml:space="preserve">
          <source>initial_value: A &lt;code&gt;Tensor&lt;/code&gt;, or Python object convertible to a &lt;code&gt;Tensor&lt;/code&gt;, which is the initial value for the Variable. The initial value must have a shape specified unless &lt;code&gt;validate_shape&lt;/code&gt; is set to False. Can also be a callable with no argument that returns the initial value when called. In that case, &lt;code&gt;dtype&lt;/code&gt; must be specified. (Note that initializer functions from init_ops.py must first be bound to a shape before being used here.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84f5e915f74fca9c6e1ead23ba7ffebfa8108c47" translate="yes" xml:space="preserve">
          <source>initializes the model via initialization ops provided by &lt;code&gt;Scaffold&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6636d976b19900c17bca1fac423d73e4d6eb288" translate="yes" xml:space="preserve">
          <source>input_row_length : the number of rows from the input set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="215a6dcf472f6c123943af88a21bbf3143d9ebee" translate="yes" xml:space="preserve">
          <source>input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1], ..., input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d36dc3b6c97433831476772c5fa29cae87f5700" translate="yes" xml:space="preserve">
          <source>input_shape[1] * block_shape[0], ..., input_shape[M] * block_shape[M-1],</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63f5e29ebb7d178d9dfb7b2f4ea4565fd5f6a4a4" translate="yes" xml:space="preserve">
          <source>input_shape[1], block_shape[0], ..., input_shape[M], block_shape[M-1],</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="582b93828bed7d84c78292a961b930efdc258c75" translate="yes" xml:space="preserve">
          <source>input_shape[M+1], ..., input_shape[N-1]]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6568964b0e39083c6acb94093d9e6cd117dbe508" translate="yes" xml:space="preserve">
          <source>instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc527931e976f53f23a0e88c398e756d2e88fc29" translate="yes" xml:space="preserve">
          <source>int: integer number of pixels from interval &lt;code&gt;(-height_shift_range, +height_shift_range)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8f7cdaeefccaf14822ef0c14861152b6b6ce396" translate="yes" xml:space="preserve">
          <source>int: integer number of pixels from interval &lt;code&gt;(-width_shift_range, +width_shift_range)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2c0ac917d5350fc1a4cf40b10454dda60aca31" translate="yes" xml:space="preserve">
          <source>int_A^B{Precision.dP} = TP_B - TP_A + intercept * log(P_B / P_A)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb0ad77554cdd0adb1dbb32ec50fd302af02ad5f" translate="yes" xml:space="preserve">
          <source>int_A^B{Precision.dP} = int_A^B{(TP_A + slope * (P - P_A)) * dP / P} int_A^B{Precision.dP} = int_A^B{slope * dP + intercept * dP / P}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39e14144cd47793f78fb4552d74a0e79713534a3" translate="yes" xml:space="preserve">
          <source>int_A^B{Precision.dTP} = int_A^B{slope * dTP} = slope * (TP_B - TP_A)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ec285792f84b2006557cfe7a76ef03e4dffbd46" translate="yes" xml:space="preserve">
          <source>is equivalent to</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="18ab6ac7001b131bc4dc74bd619c612205dff372" translate="yes" xml:space="preserve">
          <source>is equivalent to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f676744fe1cc3cdeedd163ef5929b52761f5e2b1" translate="yes" xml:space="preserve">
          <source>is the bias and</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dcf56b0234c8aefebc21b87a267f1607f2ebd4e" translate="yes" xml:space="preserve">
          <source>is the incomplete beta function and \(B(a, b)\) is the &lt;em&gt;complete&lt;/em&gt; beta function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d6ec29819896c7154ba310ecfb294ffe6dd6d28" translate="yes" xml:space="preserve">
          <source>is the lower incomplete Gamma function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="142410405cb1c972e9f58af8472ded75d6af685d" translate="yes" xml:space="preserve">
          <source>is the upper incomplete Gama function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fe98637c52118c1b88b8e69237d3989ab4385e5" translate="yes" xml:space="preserve">
          <source>is the weight for each feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b558105be66aeb17157d59d874d5960ad8485e8" translate="yes" xml:space="preserve">
          <source>is this::</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b217fdb184b9d9882d21ca5fad129a9fbae103d" translate="yes" xml:space="preserve">
          <source>is variable index):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a269871329b58d031adee27475a94b6e6e1000d" translate="yes" xml:space="preserve">
          <source>it cannot be directly used here as there is no fast way of applying it to each prefix &lt;code&gt;x[:i]&lt;/code&gt;. Instead, this function implements a prefix scan using pairwise log-add-exp, which is a commutative and associative (up to floating point precision) operator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c91b64061d65424690ab93c1cadfda56911f5863" translate="yes" xml:space="preserve">
          <source>it cannot be sent to saver.save.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7ed9bb61b5e9527391909f9689ba90b9c8a52db" translate="yes" xml:space="preserve">
          <source>it cannot be sent to tf.train.start_queue_runners.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="979398de5704ce65c4da53333edd85506c0856eb" translate="yes" xml:space="preserve">
          <source>it cannot be set as default session.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09b7c03ec646d98cecbdc829c7cb94fc14b897a1" translate="yes" xml:space="preserve">
          <source>join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6d10c00c34234489f716bd2e3f78dd7440668ea" translate="yes" xml:space="preserve">
          <source>k1 = 0.01, k2 = 0.03 as in the original paper.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="746933d303018c9218bbc90844b142026fe52928" translate="yes" xml:space="preserve">
          <source>key: Optional key &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[batch_size, Tv, dim]&lt;/code&gt;. If not given, will use &lt;code&gt;value&lt;/code&gt; for both &lt;code&gt;key&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt;, which is the most common case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86b3e86d41182d7b39ce5d557e3cd1a85d63c1f8" translate="yes" xml:space="preserve">
          <source>kl_fn</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24abaadf79e408cd76a10c64d002674f26391ff5" translate="yes" xml:space="preserve">
          <source>kvar = tf.keras.backend.random_normal_variable((2,3), 0, 1) kvar</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3c9a96154cb7c4bd07af48c88b12aa1479bb2b6" translate="yes" xml:space="preserve">
          <source>kvar = tf.keras.backend.random_uniform_variable((2,3), 0, 1) kvar</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e0723fd76ed9f3c2c5df83628e9240f5b0ae65e" translate="yes" xml:space="preserve">
          <source>labels: Labels &lt;code&gt;Tensor&lt;/code&gt; or dict of &lt;code&gt;Tensor&lt;/code&gt; created by &lt;code&gt;input_fn&lt;/code&gt; which is given to &lt;code&gt;estimator.evaluate&lt;/code&gt; as an argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d49ed7bf167bb64f672116300ae6f34b6b9a7ba" translate="yes" xml:space="preserve">
          <source>launches queue runners</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="033f565e01d360e75a63cfc4ed8abc2d9bcbc29e" translate="yes" xml:space="preserve">
          <source>layout_optimizer: Optimize tensor layouts e.g. This will try to use NCHW layout on GPU which is faster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="162fcf77aa289dc1be6b089b206972465dbb0e6c" translate="yes" xml:space="preserve">
          <source>length(row_pooling_sequence) = output_row_length+1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="947b76ec4efd6f9898868316cb4d3a02b4e37eba" translate="yes" xml:space="preserve">
          <source>linear models with L1 + L2 regularization. As global optimization objective is strongly-convex, the optimizer optimizes the dual objective at each step. The optimizer applies each update one example at a time. Examples are sampled uniformly, and the optimizer is learning rate free and enjoys linear convergence rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed540c2d7f8194fd56e5e404ef02b72cd59fc8b2" translate="yes" xml:space="preserve">
          <source>logits = [[4.0, 2.0, 1.0], [0.0, 5.0, 1.0]] labels = [[1.0, 0.0, 0.0], [0.0, 0.8, 0.2]] tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6185c7f71f7d2edd8df9ccc47928847262a2bb51" translate="yes" xml:space="preserve">
          <source>logits = np.array([[-1., 1., 2., -2., 2.], [-1.5, 1., -3., 2., -2.]],</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="866c662734c366b09041687025e6b355bd1714a8" translate="yes" xml:space="preserve">
          <source>logits_dict = {'head1_name': [[-1., 1.], [-1.5, 1.]],</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3585aa2c2ebbed634c28803cc016cb3ccb9f8aaa" translate="yes" xml:space="preserve">
          <source>loop_optimization: Loop optimizations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa328dac5d4e4d7e5ca5561900b7fd26e5e4787f" translate="yes" xml:space="preserve">
          <source>maintain a moving (discounted) average of the square of gradients</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6cfa9d32b834c1fc1fb3ff3fa471263651c38c9" translate="yes" xml:space="preserve">
          <source>map on the list of tensors unpacked from &lt;code&gt;elems&lt;/code&gt; on dimension 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e7b625b92e734eb002c177ddba41adf281266b5" translate="yes" xml:space="preserve">
          <source>matmul(sqrtm(A), sqrtm(A)) = A</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e113b391c148ef4e9fe73c27b142fe7cf14e0176" translate="yes" xml:space="preserve">
          <source>maximum of two tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0bc9d34bb8354e3db17530dd6256fd0f6187184" translate="yes" xml:space="preserve">
          <source>min_graph_nodes: The minimum number of nodes in a graph to optimizer. For smaller graphs, optimization is skipped.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="507140bf767842aa1b3801d26f6a121d86619e77" translate="yes" xml:space="preserve">
          <source>model_fn can populate all arguments independent of mode. In this case, some arguments will be ignored by an &lt;code&gt;Estimator&lt;/code&gt;. E.g. &lt;code&gt;train_op&lt;/code&gt; will be ignored in eval and infer modes. Example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8ef030a50b21a74a99f14166d8aa16efd1f0d78" translate="yes" xml:space="preserve">
          <source>name: A name for the operation (optional).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bdaedca23cabc92898abdcfd6923e6d26d0fa2c" translate="yes" xml:space="preserve">
          <source>name: An arbitrary name for this output.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="996cf0c22ba5f416f74ff08ee41b19a938cf6072" translate="yes" xml:space="preserve">
          <source>name: Optional name for the variable. Defaults to &lt;code&gt;'Variable'&lt;/code&gt; and gets uniquified automatically.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7fa81b7fbc7f3cee2d6b448e447ff014bda8363" translate="yes" xml:space="preserve">
          <source>name: Optional name for the variable. Defaults to &lt;code&gt;'Variable'&lt;/code&gt; and gets uniquified automatically. dtype: If set, initial_value will be converted to the given type. If &lt;code&gt;None&lt;/code&gt;, either the datatype will be kept (if &lt;code&gt;initial_value&lt;/code&gt; is a Tensor), or &lt;code&gt;convert_to_tensor&lt;/code&gt; will decide.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="507425dfcc920659b4327a4b5f458a65401b84ff" translate="yes" xml:space="preserve">
          <source>net = with_space_to_batch(net, dilation_rate, &quot;SAME&quot;, op_1, filter_shape_1) ... net = with_space_to_batch(net, dilation_rate, &quot;SAME&quot;, op_k, filter_shape_k)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9629de86541bc09ca56a588ec520b31047774cac" translate="yes" xml:space="preserve">
          <source>net = with_space_to_batch(net, dilation_rate, &quot;VALID&quot;, combined_op)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f23f7d60f11f4328364d8ccbf2e748e87ea0ee4d" translate="yes" xml:space="preserve">
          <source>net = with_space_to_batch(net, dilation_rate, &quot;VALID&quot;, op_1) ... net = with_space_to_batch(net, dilation_rate, &quot;VALID&quot;, op_k)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcd40bdd507bf54590c9aac3d2d0c4746626a065" translate="yes" xml:space="preserve">
          <source>nothing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74bfcfc74aa173db322155154667e22541967f81" translate="yes" xml:space="preserve">
          <source>np.prod(strides))&lt;code&gt;, where inputs to and outputs of the layer are assumed to have shapes&lt;/code&gt;input_size + (input_filters,)&lt;code&gt;,&lt;/code&gt;output_size + (filters,)` respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a306a67e4f4dfdc875d231e14009cf618949ba70" translate="yes" xml:space="preserve">
          <source>number of inputs or their shapes are inconsistent with &lt;code&gt;equation&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4910abb32b1e7bb7b618b96c243f75162e392911" translate="yes" xml:space="preserve">
          <source>one or more square matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09aabb6bc528855c68e16842ecbd23d4dd197619" translate="yes" xml:space="preserve">
          <source>op(input, num_spatial_dims, padding)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4cf5407d6170cc098a24db2830af8d91cc0342c" translate="yes" xml:space="preserve">
          <source>operator.shape = [B1,...,Bb] + [N, N], with b &amp;gt;= 0 x.shape = [C1,...,Cc] + [N, R], and [C1,...,Cc] broadcasts with [B1,...,Bb] to [D1,...,Dd]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1758356db21759f7c5a0da9b4dd1db8fd6feab3f" translate="yes" xml:space="preserve">
          <source>or</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd541cc3c68f3ef91373cec69451d3b76f56e593" translate="yes" xml:space="preserve">
          <source>or /job:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d43d16984a64536e2a464f0e93cd2bdf2e45fb1" translate="yes" xml:space="preserve">
          <source>or Computes (if &lt;code&gt;nesterov = False&lt;/code&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="830265d787441d1beac539e2bcbd559ae280180d" translate="yes" xml:space="preserve">
          <source>or, if &lt;code&gt;staircase&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f6d717f194cd224c2028a5f320d74be818984c4" translate="yes" xml:space="preserve">
          <source>output: an &lt;code&gt;ExportOutput&lt;/code&gt; object such as &lt;code&gt;ClassificationOutput&lt;/code&gt;, &lt;code&gt;RegressionOutput&lt;/code&gt;, or &lt;code&gt;PredictOutput&lt;/code&gt;. Single-headed models only need to specify one entry in this dictionary. Multi-headed models should specify one entry for each head, one of which must be named using &lt;code&gt;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY&lt;/code&gt;. If no entry is provided, a default &lt;code&gt;PredictOutput&lt;/code&gt; mapping to &lt;code&gt;predictions&lt;/code&gt; will be created.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b72e1d002d084174fd4b79fe4876d09fce7ee868" translate="yes" xml:space="preserve">
          <source>output_row_length : which will be smaller than the input</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f358e871419fb2490bac439cb45d64be8fbf7953" translate="yes" xml:space="preserve">
          <source>outputs is a length T list of outputs (one for each input), or a nested tuple of such elements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21010b5635dfe61011bf39ba7ec46eb59f94b0b6" translate="yes" xml:space="preserve">
          <source>p(x) = coeffs[n-1] + coeffs[n-2] * x + ... + coeffs[0] * x**(n-1)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13ebac9b892f43a8bbaa27f1eb1a2b2a68364dc6" translate="yes" xml:space="preserve">
          <source>p(x) = coeffs[n-1] + x * (coeffs[n-2] + ... + x * (coeffs[1] + x * coeffs[0]))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a8f2a31112ec7027bad1e42c76111e09e2d539f" translate="yes" xml:space="preserve">
          <source>paddings, crops = required_space_to_batch_paddings( input_shape[spatial_dims], dilation_rate)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6f0cc4dcfa78d598a7318ca58056f743675cd22" translate="yes" xml:space="preserve">
          <source>paddings, crops = required_space_to_batch_paddings( input_shape[spatial_dims], dilation_rate, [(dilated_filter_shape - 1) // 2, dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49ed3ce8815b0f1c023b0f3764f86fc3b935b981" translate="yes" xml:space="preserve">
          <source>param_shapes with static (i.e. &lt;code&gt;TensorShape&lt;/code&gt;) shapes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4b8a8cea68a6ae5ee46a98e249e2dc5a39612fb" translate="yes" xml:space="preserve">
          <source>parse() is also called during &lt;strong&gt;init&lt;/strong&gt; to parse the default value and initialize the .value attribute. This enables other python modules to safely use flags even if the &lt;strong&gt;main&lt;/strong&gt; module neglects to parse the command line arguments. The .present attribute is cleared after &lt;strong&gt;init&lt;/strong&gt; parsing. If the default value is set to None, then the &lt;strong&gt;init&lt;/strong&gt; parsing step is skipped and the .value attribute is initialized to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fabde60aa75e1cd006b643998fc0e174b2d7bb18" translate="yes" xml:space="preserve">
          <source>pin_to_host_optimization: Force small ops onto the CPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb12f2f652f57f55e2637aeeb627de4e59c52c44" translate="yes" xml:space="preserve">
          <source>pprof -png --nodecount=100 --sample_index=1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cbb65f63a43dde4454fdf620d85eed7da2182d9" translate="yes" xml:space="preserve">
          <source>predictions: Predictions &lt;code&gt;Tensor&lt;/code&gt; or dict of &lt;code&gt;Tensor&lt;/code&gt; created by given &lt;code&gt;estimator&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f5aa39f1449421d2beeca37812e3dc8fffd8a98" translate="yes" xml:space="preserve">
          <source>produces the same output as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04ab52557c87382099dd62ce1b1fc8a17019adcd" translate="yes" xml:space="preserve">
          <source>pylint: disable=line-too-long</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="787fb2efed06eaec76aeca89412b1b481b4fc2a8" translate="yes" xml:space="preserve">
          <source>query: Query &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[batch_size, Tq, dim]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a21ec2522ccb6ed671ded21cdb008d6fde237c2" translate="yes" xml:space="preserve">
          <source>query_mask: A boolean mask &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;[batch_size, Tq]&lt;/code&gt;. If given, the output will be zero at the positions where &lt;code&gt;mask==False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
